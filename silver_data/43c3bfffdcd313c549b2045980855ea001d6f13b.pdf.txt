This is page iii Printer : Opaque this Jorge Nocedal Stephen J . Wright Numerical Optimization Second Edition This is pag Printer : O Jorge Nocedal Stephen J . Wright EECS Department Computer Sciences Department Northwestern University University of Wisconsin Evanston , IL 60208 - 3118 1210 West Dayton Street USA Madison , WI 53706 – 1613 nocedal @ eecs . northwestern . edu USA swright @ cs . wisc . edu Series Editors : Thomas V . Mikosch University of Copenhagen Laboratory of Actuarial Mathematics DK - 1017 Copenhagen Denmark mikosch @ act . ku . dk Sidney I . Resnick Cornell University School of Operations Research and Industrial Engineering Ithaca , NY 14853 USA sirl @ cornell . edu Stephen M . Robinson Department of Industrial and Systems Engineering University of Wisconsin 1513 University Avenue Madison , WI 53706 – 1539 USA smrobins @ facstaff . wise . edu Mathematics Subject Classiﬁcation ( 2000 ) : 90B30 , 90C11 , 90 - 01 , 90 - 02 Library of Congress Control Number : 2006923897 ISBN - 10 : 0 - 387 - 30303 - 0 ISBN - 13 : 978 - 0387 - 30303 - 1 Printed on acid - free paper . C (cid:1) 2006 Springer Science + Business Media , LLC . All rights reserved . This work may not be translated or copied in whole or in part without the written permission of the publisher ( Springer Science + Business Media , LLC , 233 Spring Street , New York , NY 10013 , USA ) , except for brief excerpts in connection with reviews or scholarly analysis . Use in connection with any form of information storage and retrieval , electronic adaptation , computer software , or by similar or dissimilar methodology now known or hereafter developed is forbidden . The use in this publication of trade names , trademarks , service marks , and similar terms , even if they are not identiﬁed as such , is not to be taken as an expression of opinion as to whether or not they are subject to proprietary rights . Printed in the United States of America . ( TB / HAM ) 9 8 7 6 5 4 3 2 1 springer . com This is page v Printer : Opaque this To Sue , Isabel and Martin andToMum and Dad This is page vii Printer : Opaque this Contents Preface xvii Preface to the Second Edition xxi 1 Introduction 1 Mathematical Formulation . . . . . . . . . . . . . . . . . . . . . . . . 2 Example : A Transportation Problem . . . . . . . . . . . . . . . . . . . 4 Continuous versus Discrete Optimization . . . . . . . . . . . . . . . . . 5 Constrained and Unconstrained Optimization . . . . . . . . . . . . . . 6 Global and Local Optimization . . . . . . . . . . . . . . . . . . . . . . 6 Stochastic and Deterministic Optimization . . . . . . . . . . . . . . . . 7 Convexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Optimization Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 8 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2 Fundamentals of Unconstrained Optimization 10 2 . 1 What Is a Solution ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 viii C O N T E N T S Recognizing a Local Minimum . . . . . . . . . . . . . . . . . . . . . . 14 Nonsmooth Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 2 . 2 Overview of Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Two Strategies : Line Search and Trust Region . . . . . . . . . . . . . . . 19 Search Directions for Line Search Methods . . . . . . . . . . . . . . . . 20 Models for Trust - Region Methods . . . . . . . . . . . . . . . . . . . . . 25 Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3 Line Search Methods 30 3 . 1 Step Length . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 The Wolfe Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 The Goldstein Conditions . . . . . . . . . . . . . . . . . . . . . . . . . 36 Sufﬁcient Decrease and Backtracking . . . . . . . . . . . . . . . . . . . 37 3 . 2 Convergence of Line Search Methods . . . . . . . . . . . . . . . . . . . 37 3 . 3 Rate of Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 Convergence Rate of Steepest Descent . . . . . . . . . . . . . . . . . . . 42 Newton’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Quasi - Newton Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 46 3 . 4 Newton’s Method with Hessian Modiﬁcation . . . . . . . . . . . . . . . 48 Eigenvalue Modiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . 49 Adding a Multiple of the Identity . . . . . . . . . . . . . . . . . . . . . 51 Modiﬁed Cholesky Factorization . . . . . . . . . . . . . . . . . . . . . 52 Modiﬁed Symmetric Indeﬁnite Factorization . . . . . . . . . . . . . . . 54 3 . 5 Step - Length Selection Algorithms . . . . . . . . . . . . . . . . . . . . . 56 Interpolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Initial Step Length . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 A Line Search Algorithm for the Wolfe Conditions . . . . . . . . . . . . 60 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 4 Trust - Region Methods 66 Outline of the Trust - Region Approach . . . . . . . . . . . . . . . . . . 68 4 . 1 Algorithms Based on the Cauchy Point . . . . . . . . . . . . . . . . . . 71 The Cauchy Point . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 Improving on the Cauchy Point . . . . . . . . . . . . . . . . . . . . . . 73 The Dogleg Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 Two - Dimensional Subspace Minimization . . . . . . . . . . . . . . . . 76 4 . 2 Global Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 Reduction Obtained by the Cauchy Point . . . . . . . . . . . . . . . . . 77 Convergence to Stationary Points . . . . . . . . . . . . . . . . . . . . . 79 4 . 3 Iterative Solution of the Subproblem . . . . . . . . . . . . . . . . . . . 83 C O N T E N T S ix The Hard Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87 Proof of Theorem 4 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 Convergence of Algorithms Based on Nearly Exact Solutions . . . . . . . 91 4 . 4 Local Convergence of Trust - Region Newton Methods . . . . . . . . . . 92 4 . 5 Other Enhancements . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 Scaling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 Trust Regions in Other Norms . . . . . . . . . . . . . . . . . . . . . . . 97 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 5 Conjugate Gradient Methods 101 5 . 1 The Linear Conjugate Gradient Method . . . . . . . . . . . . . . . . . . 102 Conjugate Direction Methods . . . . . . . . . . . . . . . . . . . . . . . 102 Basic Properties of the Conjugate Gradient Method . . . . . . . . . . . 107 A Practical Form of the Conjugate Gradient Method . . . . . . . . . . . 111 Rate of Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 Preconditioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 Practical Preconditioners . . . . . . . . . . . . . . . . . . . . . . . . . 120 5 . 2 Nonlinear Conjugate Gradient Methods . . . . . . . . . . . . . . . . . 121 The Fletcher – Reeves Method . . . . . . . . . . . . . . . . . . . . . . . 121 The Polak – Ribi ` ere Method and Variants . . . . . . . . . . . . . . . . . 122 Quadratic Termination and Restarts . . . . . . . . . . . . . . . . . . . . 124 Behavior of the Fletcher – Reeves Method . . . . . . . . . . . . . . . . . 125 Global Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127 Numerical Performance . . . . . . . . . . . . . . . . . . . . . . . . . . 131 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 6 Quasi - Newton Methods 135 6 . 1 The BFGS Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136 Properties of the BFGS Method . . . . . . . . . . . . . . . . . . . . . . 141 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 6 . 2 The SR1 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 Properties of SR1 Updating . . . . . . . . . . . . . . . . . . . . . . . . 147 6 . 3 The Broyden Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149 6 . 4 Convergence Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 153 Global Convergence of the BFGS Method . . . . . . . . . . . . . . . . . 153 Superlinear Convergence of the BFGS Method . . . . . . . . . . . . . . 156 Convergence Analysis of the SR1 Method . . . . . . . . . . . . . . . . . 160 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 x C O N T E N T S 7 Large - Scale Unconstrained Optimization 164 7 . 1 Inexact Newton Methods . . . . . . . . . . . . . . . . . . . . . . . . . 165 Local Convergence of Inexact Newton Methods . . . . . . . . . . . . . . 166 Line Search Newton – CG Method . . . . . . . . . . . . . . . . . . . . . 168 Trust - Region Newton – CG Method . . . . . . . . . . . . . . . . . . . . 170 Preconditioning the Trust - Region Newton – CG Method . . . . . . . . . 174 Trust - Region Newton – Lanczos Method . . . . . . . . . . . . . . . . . . 175 7 . 2 Limited - Memory Quasi - Newton Methods . . . . . . . . . . . . . . . . 176 Limited - Memory BFGS . . . . . . . . . . . . . . . . . . . . . . . . . . 177 Relationship with Conjugate Gradient Methods . . . . . . . . . . . . . 180 General Limited - Memory Updating . . . . . . . . . . . . . . . . . . . . 181 Compact Representation of BFGS Updating . . . . . . . . . . . . . . . 181 Unrolling the Update . . . . . . . . . . . . . . . . . . . . . . . . . . . 184 7 . 3 Sparse Quasi - Newton Updates . . . . . . . . . . . . . . . . . . . . . . 185 7 . 4 Algorithms for Partially Separable Functions . . . . . . . . . . . . . . . 186 7 . 5 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 189 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 8 Calculating Derivatives 193 8 . 1 Finite - Difference Derivative Approximations . . . . . . . . . . . . . . . 194 Approximating the Gradient . . . . . . . . . . . . . . . . . . . . . . . . 195 Approximating a Sparse Jacobian . . . . . . . . . . . . . . . . . . . . . 197 Approximating the Hessian . . . . . . . . . . . . . . . . . . . . . . . . 201 Approximating a Sparse Hessian . . . . . . . . . . . . . . . . . . . . . . 202 8 . 2 Automatic Differentiation . . . . . . . . . . . . . . . . . . . . . . . . . 204 An Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205 The Forward Mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206 The Reverse Mode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207 Vector Functions and Partial Separability . . . . . . . . . . . . . . . . . 210 Calculating Jacobians of Vector Functions . . . . . . . . . . . . . . . . . 212 Calculating Hessians : Forward Mode . . . . . . . . . . . . . . . . . . . 213 Calculating Hessians : Reverse Mode . . . . . . . . . . . . . . . . . . . . 215 Current Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217 9 Derivative - Free Optimization 220 9 . 1 Finite Differences and Noise . . . . . . . . . . . . . . . . . . . . . . . . 221 9 . 2 Model - Based Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 223 Interpolation and Polynomial Bases . . . . . . . . . . . . . . . . . . . . 226 Updating the Interpolation Set . . . . . . . . . . . . . . . . . . . . . . 227 C O N T E N T S xi A Method Based on Minimum - Change Updating . . . . . . . . . . . . . 228 9 . 3 Coordinate and Pattern - Search Methods . . . . . . . . . . . . . . . . . 229 Coordinate Search Method . . . . . . . . . . . . . . . . . . . . . . . . 230 Pattern - Search Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 231 9 . 4 A Conjugate - Direction Method . . . . . . . . . . . . . . . . . . . . . . 234 9 . 5 Nelder – Mead Method . . . . . . . . . . . . . . . . . . . . . . . . . . . 238 9 . 6 Implicit Filtering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242 10 Least - Squares Problems 245 10 . 1 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247 10 . 2 Linear Least - Squares Problems . . . . . . . . . . . . . . . . . . . . . . 250 10 . 3 Algorithms for Nonlinear Least - Squares Problems . . . . . . . . . . . . 254 The Gauss – Newton Method . . . . . . . . . . . . . . . . . . . . . . . . 254 Convergence of the Gauss – Newton Method . . . . . . . . . . . . . . . . 255 The Levenberg – Marquardt Method . . . . . . . . . . . . . . . . . . . . 258 Implementation of the Levenberg – Marquardt Method . . . . . . . . . . 259 Convergence of the Levenberg – Marquardt Method . . . . . . . . . . . . 261 Methods for Large - Residual Problems . . . . . . . . . . . . . . . . . . . 262 10 . 4 Orthogonal Distance Regression . . . . . . . . . . . . . . . . . . . . . . 265 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269 11 Nonlinear Equations 270 11 . 1 Local Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274 Newton’s Method for Nonlinear Equations . . . . . . . . . . . . . . . . 274 Inexact Newton Methods . . . . . . . . . . . . . . . . . . . . . . . . . 277 Broyden’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279 Tensor Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283 11 . 2 Practical Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285 Merit Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285 Line Search Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287 Trust - Region Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 290 11 . 3 Continuation / Homotopy Methods . . . . . . . . . . . . . . . . . . . . 296 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296 Practical Continuation Methods . . . . . . . . . . . . . . . . . . . . . . 297 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302 12 Theory of Constrained Optimization 304 Local and Global Solutions . . . . . . . . . . . . . . . . . . . . . . . . 305 xii C O N T E N T S Smoothness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306 12 . 1 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307 A Single Equality Constraint . . . . . . . . . . . . . . . . . . . . . . . . 308 A Single Inequality Constraint . . . . . . . . . . . . . . . . . . . . . . . 310 Two Inequality Constraints . . . . . . . . . . . . . . . . . . . . . . . . 313 12 . 2 Tangent Cone and Constraint Qualiﬁcations . . . . . . . . . . . . . . . 315 12 . 3 First - Order Optimality Conditions . . . . . . . . . . . . . . . . . . . . 320 12 . 4 First - Order Optimality Conditions : Proof . . . . . . . . . . . . . . . . . 323 Relating the Tangent Cone and the First - Order Feasible Direction Set . . 323 A Fundamental Necessary Condition . . . . . . . . . . . . . . . . . . . 325 Farkas’ Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326 Proof of Theorem 12 . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . 329 12 . 5 Second - Order Conditions . . . . . . . . . . . . . . . . . . . . . . . . . 330 Second - Order Conditions and Projected Hessians . . . . . . . . . . . . 337 12 . 6 Other Constraint Qualiﬁcations . . . . . . . . . . . . . . . . . . . . . . 338 12 . 7 A Geometric Viewpoint . . . . . . . . . . . . . . . . . . . . . . . . . . 340 12 . 8 Lagrange Multipliers and Sensitivity . . . . . . . . . . . . . . . . . . . . 341 12 . 9 Duality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351 13 Linear Programming : The Simplex Method 355 Linear Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356 13 . 1 Optimality and Duality . . . . . . . . . . . . . . . . . . . . . . . . . . 358 Optimality Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 358 The Dual Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359 13 . 2 Geometry of the Feasible Set . . . . . . . . . . . . . . . . . . . . . . . . 362 Bases and Basic Feasible Points . . . . . . . . . . . . . . . . . . . . . . 362 Vertices of the Feasible Polytope . . . . . . . . . . . . . . . . . . . . . . 365 13 . 3 The Simplex Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366 A Single Step of the Method . . . . . . . . . . . . . . . . . . . . . . . . 370 13 . 4 Linear Algebra in the Simplex Method . . . . . . . . . . . . . . . . . . 372 13 . 5 Other Important Details . . . . . . . . . . . . . . . . . . . . . . . . . . 375 Pricing and Selection of the Entering Index . . . . . . . . . . . . . . . . 375 Starting the Simplex Method . . . . . . . . . . . . . . . . . . . . . . . 378 Degenerate Steps and Cycling . . . . . . . . . . . . . . . . . . . . . . . 381 13 . 6 The Dual Simplex Method . . . . . . . . . . . . . . . . . . . . . . . . . 382 13 . 7 Presolving . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385 13 . 8 Where Does the Simplex Method Fit ? . . . . . . . . . . . . . . . . . . . 388 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 389 C O N T E N T S xiii 14 Linear Programming : Interior - Point Methods 392 14 . 1 Primal - Dual Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . 393 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393 The Central Path . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397 Central Path Neighborhoods and Path - Following Methods . . . . . . . . 399 14 . 2 Practical Primal - Dual Algorithms . . . . . . . . . . . . . . . . . . . . . 407 Corrector and Centering Steps . . . . . . . . . . . . . . . . . . . . . . . 407 Step Lengths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409 Starting Point . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410 A Practical Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 411 Solving the Linear Systems . . . . . . . . . . . . . . . . . . . . . . . . . 411 14 . 3 Other Primal - Dual Algorithms and Extensions . . . . . . . . . . . . . . 413 Other Path - Following Methods . . . . . . . . . . . . . . . . . . . . . . 413 Potential - Reduction Methods . . . . . . . . . . . . . . . . . . . . . . . 414 Extensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 415 14 . 4 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 416 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418 15 Fundamentals of Algorithms for Nonlinear Constrained Optimization 421 15 . 1 Categorizing Optimization Algorithms . . . . . . . . . . . . . . . . . . 422 15 . 2 The Combinatorial Difﬁculty of Inequality - Constrained Problems . . . . 424 15 . 3 Elimination of Variables . . . . . . . . . . . . . . . . . . . . . . . . . . 426 Simple Elimination using Linear Constraints . . . . . . . . . . . . . . . 428 General Reduction Strategies for Linear Constraints . . . . . . . . . . . 431 Effect of Inequality Constraints . . . . . . . . . . . . . . . . . . . . . . 434 15 . 4 Merit Functions and Filters . . . . . . . . . . . . . . . . . . . . . . . . 435 Merit Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435 Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 437 15 . 5 The Maratos Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440 15 . 6 Second - Order Correction and Nonmonotone Techniques . . . . . . . . 443 Nonmonotone ( Watchdog ) Strategy . . . . . . . . . . . . . . . . . . . 444 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446 16 Quadratic Programming 448 16 . 1 Equality - Constrained Quadratic Programs . . . . . . . . . . . . . . . . 451 Properties of Equality - Constrained QPs . . . . . . . . . . . . . . . . . . 451 16 . 2 Direct Solution of the KKT System . . . . . . . . . . . . . . . . . . . . 454 Factoring the Full KKT System . . . . . . . . . . . . . . . . . . . . . . 454 Schur - Complement Method . . . . . . . . . . . . . . . . . . . . . . . . 455 Null - Space Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457 xiv C O N T E N T S 16 . 3 Iterative Solution of the KKT System . . . . . . . . . . . . . . . . . . . 459 CG Applied to the Reduced System . . . . . . . . . . . . . . . . . . . . 459 The Projected CG Method . . . . . . . . . . . . . . . . . . . . . . . . . 461 16 . 4 Inequality - Constrained Problems . . . . . . . . . . . . . . . . . . . . . 463 Optimality Conditions for Inequality - Constrained Problems . . . . . . . 464 Degeneracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465 16 . 5 Active - Set Methods for Convex QPs . . . . . . . . . . . . . . . . . . . . 467 Speciﬁcation of the Active - Set Method for Convex QP . . . . . . . . . . 472 Further Remarks on the Active - Set Method . . . . . . . . . . . . . . . . 476 Finite Termination of Active - Set Algorithm on Strictly Convex QPs . . . 477 Updating Factorizations . . . . . . . . . . . . . . . . . . . . . . . . . . 478 16 . 6 Interior - Point Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 480 Solving the Primal - Dual System . . . . . . . . . . . . . . . . . . . . . . 482 Step Length Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . 483 A Practical Primal - Dual Method . . . . . . . . . . . . . . . . . . . . . 484 16 . 7 The Gradient Projection Method . . . . . . . . . . . . . . . . . . . . . 485 Cauchy Point Computation . . . . . . . . . . . . . . . . . . . . . . . . 486 Subspace Minimization . . . . . . . . . . . . . . . . . . . . . . . . . . 488 16 . 8 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 490 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492 17 Penalty and Augmented Lagrangian Methods 497 17 . 1 The Quadratic Penalty Method . . . . . . . . . . . . . . . . . . . . . . 498 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 498 Algorithmic Framework . . . . . . . . . . . . . . . . . . . . . . . . . . 501 Convergence of the Quadratic Penalty Method . . . . . . . . . . . . . . 502 Ill Conditioning and Reformulations . . . . . . . . . . . . . . . . . . . 505 17 . 2 Nonsmooth Penalty Functions . . . . . . . . . . . . . . . . . . . . . . 507 A Practical (cid:1) 1 Penalty Method . . . . . . . . . . . . . . . . . . . . . . . 511 A General Class of Nonsmooth Penalty Methods . . . . . . . . . . . . . 513 17 . 3 Augmented Lagrangian Method : Equality Constraints . . . . . . . . . . 514 Motivation and Algorithmic Framework . . . . . . . . . . . . . . . . . 514 Properties of the Augmented Lagrangian . . . . . . . . . . . . . . . . . 517 17 . 4 Practical Augmented Lagrangian Methods . . . . . . . . . . . . . . . . 519 Bound - Constrained Formulation . . . . . . . . . . . . . . . . . . . . . 519 Linearly Constrained Formulation . . . . . . . . . . . . . . . . . . . . 522 Unconstrained Formulation . . . . . . . . . . . . . . . . . . . . . . . . 523 17 . 5 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 525 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 526 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527 C O N T E N T S xv 18 Sequential Quadratic Programming 529 18 . 1 Local SQP Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 530 SQP Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 531 Inequality Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . 532 18 . 2 Preview of Practical SQP Methods . . . . . . . . . . . . . . . . . . . . . 533 IQP and EQP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 533 Enforcing Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . 534 18 . 3 Algorithmic Development . . . . . . . . . . . . . . . . . . . . . . . . . 535 Handling Inconsistent Linearizations . . . . . . . . . . . . . . . . . . . 535 Full Quasi - Newton Approximations . . . . . . . . . . . . . . . . . . . . 536 Reduced - Hessian Quasi - Newton Approximations . . . . . . . . . . . . 538 Merit Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540 Second - Order Correction . . . . . . . . . . . . . . . . . . . . . . . . . 543 18 . 4 A Practical Line Search SQP Method . . . . . . . . . . . . . . . . . . . 545 18 . 5 Trust - Region SQP Methods . . . . . . . . . . . . . . . . . . . . . . . . 546 A Relaxation Method for Equality - Constrained Optimization . . . . . . 547 S (cid:1) 1 QP ( Sequential (cid:1) 1 Quadratic Programming ) . . . . . . . . . . . . . 549 Sequential Linear - Quadratic Programming ( SLQP ) . . . . . . . . . . . 551 A Technique for Updating the Penalty Parameter . . . . . . . . . . . . . 553 18 . 6 Nonlinear Gradient Projection . . . . . . . . . . . . . . . . . . . . . . 554 18 . 7 Convergence Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 556 Rate of Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557 18 . 8 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 560 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 561 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 561 19 Interior - Point Methods for Nonlinear Programming 563 19 . 1 Two Interpretations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 564 19 . 2 A Basic Interior - Point Algorithm . . . . . . . . . . . . . . . . . . . . . 566 19 . 3 Algorithmic Development . . . . . . . . . . . . . . . . . . . . . . . . . 569 Primal vs . Primal - Dual System . . . . . . . . . . . . . . . . . . . . . . 570 Solving the Primal - Dual System . . . . . . . . . . . . . . . . . . . . . . 570 Updating the Barrier Parameter . . . . . . . . . . . . . . . . . . . . . . 572 Handling Nonconvexity and Singularity . . . . . . . . . . . . . . . . . . 573 Step Acceptance : Merit Functions and Filters . . . . . . . . . . . . . . . 575 Quasi - Newton Approximations . . . . . . . . . . . . . . . . . . . . . . 575 Feasible Interior - Point Methods . . . . . . . . . . . . . . . . . . . . . . 576 19 . 4 A Line Search Interior - Point Method . . . . . . . . . . . . . . . . . . . 577 19 . 5 A Trust - Region Interior - Point Method . . . . . . . . . . . . . . . . . . 578 An Algorithm for Solving the Barrier Problem . . . . . . . . . . . . . . 578 Step Computation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 580 Lagrange Multipliers Estimates and Step Acceptance . . . . . . . . . . . 581 xvi C O N T E N T S Description of a Trust - Region Interior - Point Method . . . . . . . . . . . 582 19 . 6 The Primal Log - Barrier Method . . . . . . . . . . . . . . . . . . . . . . 583 19 . 7 Global Convergence Properties . . . . . . . . . . . . . . . . . . . . . . 587 Failure of the Line Search Approach . . . . . . . . . . . . . . . . . . . . 587 Modiﬁed Line Search Methods . . . . . . . . . . . . . . . . . . . . . . 589 Global Convergence of the Trust - Region Approach . . . . . . . . . . . . 589 19 . 8 Superlinear Convergence . . . . . . . . . . . . . . . . . . . . . . . . . 591 19 . 9 Perspectives and Software . . . . . . . . . . . . . . . . . . . . . . . . . 592 Notes and References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 593 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594 A Background Material 598 A . 1 Elements of Linear Algebra . . . . . . . . . . . . . . . . . . . . . . . . 598 Vectors and Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . 598 Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 600 Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602 Eigenvalues , Eigenvectors , and the Singular - Value Decomposition . . . . 603 Determinant and Trace . . . . . . . . . . . . . . . . . . . . . . . . . . 605 Matrix Factorizations : Cholesky , LU , QR . . . . . . . . . . . . . . . . . 606 Symmetric Indeﬁnite Factorization . . . . . . . . . . . . . . . . . . . . 610 Sherman – Morrison – Woodbury Formula . . . . . . . . . . . . . . . . . 612 Interlacing Eigenvalue Theorem . . . . . . . . . . . . . . . . . . . . . . 613 Error Analysis and Floating - Point Arithmetic . . . . . . . . . . . . . . . 613 Conditioning and Stability . . . . . . . . . . . . . . . . . . . . . . . . . 616 A . 2 Elements of Analysis , Geometry , Topology . . . . . . . . . . . . . . . . 617 Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617 Rates of Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . 619 Topology of the Euclidean Space IR n . . . . . . . . . . . . . . . . . . . . 620 Convex Sets in IR n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621 Continuity and Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . 623 Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 625 Directional Derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . 628 Mean Value Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . 629 Implicit Function Theorem . . . . . . . . . . . . . . . . . . . . . . . . 630 Order Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 631 Root - Finding for Scalar Equations . . . . . . . . . . . . . . . . . . . . 633 B A Regularization Procedure 635 References 637 Index 653 This is page xvii Printer : Opaque this Preface This is a book for people interested in solving optimization problems . Because of the wide ( and growing ) use of optimization in science , engineering , economics , and industry , it is essential for students and practitioners alike to develop an understanding of optimization algorithms . Knowledge of the capabilities and limitations of these algorithms leads to a better understanding of their impact on various applications , and points the way to future research on improving and extending optimization algorithms and software . Our goal in this book is to give a comprehensive description of the most powerful , state - of - the - art , techniques for solving continuous optimization problems . By presenting the motivating ideas for each algorithm , we try to stimulate the reader’s intuition and make the technical details easier to follow . Formal mathematical requirements are kept to a minimum . Because of our focus on continuous problems , we have omitted discussion of impor - tant optimization topics such as discrete and stochastic optimization . However , there are a great many applications that can be formulated as continuous optimization problems ; for instance , ﬁnding the optimal trajectory for an aircraft or a robot arm ; identifying the seismic properties of a piece of the earth’s crust by ﬁtting a model of the region under study to a set of readings from a network of recording stations ; xviii P R E F A C E designing a portfolio of investments to maximize expected return while maintaining an acceptable level of risk ; controlling a chemical process or a mechanical device to optimize performance or meet standards of robustness ; computing the optimal shape of an automobile or aircraft component . Every year optimization algorithms are being called on to handle problems that are much larger and complex than in the past . Accordingly , the book emphasizes large - scale optimization techniques , such as interior - point methods , inexact Newton methods , limited - memory methods , and the role of partially separable functions and automatic differentiation . It treats important topics such as trust - region methods and sequential quadratic programming more thoroughly than existing texts , and includes comprehensive discussion of such “core curriculum” topics as constrained optimization theory , Newton and quasi - Newton methods , nonlinear least squares and nonlinear equations , the simplex method , and penalty and barrier methods for nonlinear programming . The Audience We intend that this book will be used in graduate - level courses in optimization , as of - fered in engineering , operations research , computer science , and mathematics departments . There is enough material here for a two - semester ( or three - quarter ) sequence of courses . We hope , too , that this book will be used by practitioners in engineering , basic science , and industry , and our presentation style is intended to facilitate self - study . Since the book treats a number of new algorithms and ideas that have not been described in earlier textbooks , we hope that this book will also be a useful reference for optimization researchers . Prerequisites for this book include some knowledge of linear algebra ( including nu - merical linear algebra ) and the standard sequence of calculus courses . To make the book as self - contained as possible , we have summarized much of the relevant material from these ar - eas in the Appendix . Our experience in teaching engineering students has shown us that the material is best assimilated when combined with computer programming projects in which the student gains a good feeling for the algorithms—their complexity , memory demands , and elegance—and for the applications . In most chapters we provide simple computer exercises that require only minimal programming proﬁciency . Emphasis and Writing Style We have used a conversational style to motivate the ideas and present the numerical algorithms . Rather than being as concise as possible , our aim is to make the discussion ﬂow in a natural way . As a result , the book is comparatively long , but we believe that it can be read relatively rapidly . The instructor can assign substantial reading assignments from the text and focus in class only on the main ideas . A typical chapter begins with a nonrigorous discussion of the topic at hand , including ﬁguresanddiagramsandexcludingtechnicaldetailsasfaraspossible . Insubsequentsections , P R E F A C E xix the algorithms are motivated and discussed , and then stated explicitly . The major theoretical results are stated , and in many cases proved , in a rigorous fashion . These proofs can be skipped by readers who wish to avoid technical details . The practice of optimization depends not only on efﬁcient and robust algorithms , but also on good modeling techniques , careful interpretation of results , and user - friendly software . In this book we discuss the various aspects of the optimization process—modeling , optimality conditions , algorithms , implementation , and interpretation of results—but not with equal weight . Examples throughout the book show how practical problems are formu - lated as optimization problems , but our treatment of modeling is light and serves mainly to set the stage for algorithmic developments . We refer the reader to Dantzig [ 86 ] and Fourer , Gay , and Kernighan [ 112 ] for more comprehensive discussion of this issue . Our treatment of optimality conditions is thorough but not exhaustive ; some concepts are dis - cussed more extensively in Mangasarian [ 198 ] and Clarke [ 62 ] . As mentioned above , we are quite comprehensive in discussing optimization algorithms . Topics Not Covered We omit some important topics , such as network optimization , integer programming , stochastic programming , nonsmooth optimization , and global optimization . Network and integeroptimizationaredescribedinsomeexcellenttexts : forinstance , Ahuja , Magnanti , and Orlin [ 1 ] in the case of network optimization and Nemhauser and Wolsey [ 224 ] , Papadim - itriou and Steiglitz [ 235 ] , and Wolsey [ 312 ] in the case of integer programming . Books on stochastic optimization are only now appearing ; we mention those of Kall and Wallace [ 174 ] , Birge and Louveaux [ 22 ] . Nonsmooth optimization comes in many ﬂavors . The relatively simple structures that arise in robust data ﬁtting ( which is sometimes based on the (cid:1) 1 norm ) are treated by Osborne [ 232 ] and Fletcher [ 101 ] . The latter book also discusses algorithms for nonsmooth penalty functions that arise in constrained optimization ; we discuss these brieﬂy , too , in Chapter 18 . A more analytical treatment of nonsmooth optimization is given by Hiriart - Urruty and Lemar´echal [ 170 ] . We omit detailed treatment of some important topics that are the focus of intense current research , including interior - point methods for nonlinear programming and algorithms for complementarity problems . Additional Resource The material in the book is complemented by an online resource called the NEOS Guide , which can be found on the World - Wide Web at http : / / www . mcs . anl . gov / otc / Guide / The Guide contains information about most areas of optimization , and presents a number of case studies that describe applications of various optimization algorithms to real - world problems such as portfolio optimization and optimal dieting . Some of this material is interactive in nature and has been used extensively for class exercises . xx P R E F A C E For the most part , we have omitted detailed discussions of speciﬁc software packages , and refer the reader to Mor´e and Wright [ 217 ] or to the Software Guide section of the NEOS Guide , which can be found at http : / / www . mcs . anl . gov / otc / Guide / SoftwareGuide / Users of optimization software refer in great numbers to this web site , which is being constantly updated to reﬂect new packages and changes to existing software . Acknowledgments Wearemostgratefultothefollowingcolleaguesfortheirinputandfeedbackonvarious sections of this work : Chris Bischof , Richard Byrd , George Corliss , Bob Fourer , David Gay , Jean - Charles Gilbert , Phillip Gill , Jean - Pierre Goux , Don Goldfarb , Nick Gould , Andreas Griewank , Matthias Heinkenschloss , Marcelo Marazzi , Hans Mittelmann , Jorge Mor´e , Will Naylor , Michael Overton , Bob Plemmons , Hugo Scolnik , David Stewart , Philippe Toint , Luis Vicente , Andreas W¨achter , and Ya - xiang Yuan . We thank Guanghui Liu , who provided help with many of the exercises , and Jill Lavelle who assisted us in preparing the ﬁgures . We also express our gratitude to our sponsors at the Department of Energy and the National Science Foundation , who have strongly supported our research efforts in optimization over the years . Oneofus ( JN ) wouldliketoexpresshisdeepgratitudetoRichardByrd , whohastaught him so much about optimization and who has helped him in very many ways throughout the course of his career . Final Remark Intheprefacetohis1987book [ 101 ] , RogerFletcherdescribedtheﬁeldofoptimization as a “fascinating blend of theory and computation , heuristics and rigor . ” The ever - growing realm of applications and the explosion in computing power is driving optimization research in new and exciting directions , and the ingredients identiﬁed by Fletcher will continue to play important roles for many years to come . Jorge Nocedal Stephen J . Wright Evanston , IL Argonne , IL This is page xxi Printer : Opaque this Preface to the Second Edition During the six years since the ﬁrst edition of this book appeared , the ﬁeld of continuous optimization has continued to grow and evolve . This new edition reﬂects a better under - standing of constrained optimization at both the algorithmic and theoretical levels , and of the demands imposed by practical applications . Perhaps most notably , new chapters have been added on two important topics : derivative - free optimization ( Chapter 9 ) and interior - point methods for nonlinear programming ( Chapter 19 ) . The former topic has proved to be of great interest in applications , while the latter topic has come into its own in recent years and now forms the basis of successful codes for nonlinear programming . Apart from the new chapters , we have revised and updated throughout the book , de - emphasizing or omitting less important topics , enhancing the treatment of subjects of evident interest , and adding new material in many places . The ﬁrst part ( unconstrained opti - mization ) has been comprehensively reorganized to improve clarity . Discussion of Newton’s method—the touchstone method for unconstrained problems—is distributed more nat - urally throughout this part rather than being isolated in a single chapter . An expanded discussion of large - scale problems appears in Chapter 7 . Some reorganization has taken place also in the second part ( constrained optimiza - tion ) , with material common to sequential quadratic programming and interior - point methods now appearing in the chapter on fundamentals of nonlinear programming xxii P R E F A C E T O T H E S E C O N D E D I T I O N algorithms ( Chapter 15 ) and the discussion of primal barrier methods moved to the new interior - point chapter . There is much new material in this part , including a treatment of nonlinear programming duality , an expanded discussion of algorithms for inequality con - strained quadratic programming , a discussion of dual simplex and presolving in linear programming , a summary of practical issues in the implementation of interior - point linear programming algorithms , a description of conjugate - gradient methods for quadratic pro - gramming , and a discussion of ﬁlter methods and nonsmooth penalty methods in nonlinear programming algorithms . In many chapters we have added a Perspectives and Software section near the end , to place the preceding discussion in context and discuss the state of the art in software . The appendix has been rearranged with some additional topics added , so that it can be used in a more stand - alone fashion to cover some of the mathematical background required for the rest of the book . The exercises have been revised in most chapters . After these many additions , deletions , and changes , the second edition is only slightly longer than the ﬁrst , reﬂecting our belief that careful selection of the material to include and exclude is an important responsibility for authors of books of this type . A manual containing solutions for selected problems will be available to bona ﬁde instructors through the publisher . A list of typos will be maintained on the book’s web site , which is accessible from the web pages of both authors . We acknowledge with gratitude the comments and suggestions of many readers of the ﬁrst edition , who sent corrections to many errors and provided valuable perspectives on the material , which led often to substantial changes . We mention in particular Frank Curtis , Michael Ferris , Andreas Griewank , Jacek Gondzio , Sven Leyffer , Philip Loewen , Rembert Reemtsen , and David Stewart . Our special thanks goes to Michael Overton , who taught from a draft of the second edition and sent many detailed and excellent suggestions . We also thank colleagues who read various chapters of the new edition carefully during development , including Richard Byrd , Nick Gould , Paul Hovland , Gabo Lop´ez - Calva , Long Hei , Katya Scheinberg , Andreas W¨achter , and Richard Waltz . We thank Jill Wright for improving some of the ﬁgures and for the new cover graphic . We mentioned in the original preface several areas of optimization that are not covered in this book . During the past six years , this list has only grown longer , as the ﬁeld has continued to expand in new directions . In this regard , the following areas are particularly noteworthy : optimization problems with complementarity constraints , second - order cone and semideﬁnite programming , simulation - based optimization , robust optimization , and mixed - integer nonlinear programming . All these areas have seen theoretical and algorithmic advances in recent years , and in many cases developments are being driven by new classes of applications . Although this book does not cover any of these areas directly , it provides a foundation from which they can be studied . Jorge Nocedal Stephen J . Wright Evanston , IL Madison , WI This is page 1 Printer : Opaque this C H A P T E R 1 Introduction People optimize . Investors seek to create portfolios that avoid excessive risk while achieving a high rate of return . Manufacturers aim for maximum efﬁciency in the design and operation of their production processes . Engineers adjust parameters to optimize the performance of their designs . Nature optimizes . Physical systems tend to a state of minimum energy . The molecules in an isolated chemical system react with each other until the total potential energy of their electrons is minimized . Rays of light follow paths that minimize their travel time . 2 C H A P T E R 1 . I N T R O D U C T I O N Optimization is an important tool in decision science and in the analysis of physical systems . To make use of this tool , we must ﬁrst identify some objective , a quantitative measure of the performance of the system under study . This objective could be proﬁt , time , potential energy , or any quantity or combination of quantities that can be represented by a single number . The objective depends on certain characteristics of the system , called variables or unknowns . Our goal is to ﬁnd values of the variables that optimize the objective . Often the variables are restricted , or constrained , in some way . For instance , quantities such as electron density in a molecule and the interest rate on a loan cannot be negative . The process of identifying objective , variables , and constraints for a given problem is known as modeling . Construction of an appropriate model is the ﬁrst step—sometimes the most important step—in the optimization process . If the model is too simplistic , it will not give useful insights into the practical problem . If it is too complex , it may be too difﬁcult to solve . Once the model has been formulated , an optimization algorithm can be used to ﬁnd its solution , usually with the help of a computer . There is no universal optimization algorithm but rather a collection of algorithms , each of which is tailored to a particular type of optimization problem . The responsibility of choosing the algorithm that is appropriate for a speciﬁc application often falls on the user . This choice is an important one , as it may determine whether the problem is solved rapidly or slowly and , indeed , whether the solution is found at all . After an optimization algorithm has been applied to the model , we must be able to recognize whether it has succeeded in its task of ﬁnding a solution . In many cases , there are elegant mathematical expressions known as optimality conditions for checking that the current set of variables is indeed the solution of the problem . If the optimality conditions are not satisﬁed , they may give useful information on how the current estimate of the solution can be improved . The model may be improved by applying techniques such as sensitivity analysis , which reveals the sensitivity of the solution to changes in the model and data . Interpretation of the solution in terms of the application may also suggest ways in which the model can be reﬁned or improved ( or corrected ) . If any changes are made to the model , the optimization problem is solved anew , and the process repeats . MATHEMATICAL FORMULATION Mathematically speaking , optimization is the minimization or maximization of a function subject to constraints on its variables . We use the following notation : - x is the vector of variables , also called unknowns or parameters ; - f is the objective function , a ( scalar ) function of x that we want to maximize or minimize ; - c i are constraint functions , which are scalar functions of x that deﬁne certain equations and inequalities that the unknown vector x must satisfy . C H A P T E R 1 . I N T R O D U C T I O N 3 1 2 x c 1 c 2 x x * contours of f feasible region Figure 1 . 1 Geometrical representation of the problem ( 1 . 2 ) . Using this notation , the optimization problem can be written as follows : min x ∈ IR n f ( x ) subject to c i ( x ) (cid:3) 0 , i ∈ E , c i ( x ) ≥ 0 , i ∈ I . ( 1 . 1 ) Here I and E are sets of indices for equality and inequality constraints , respectively . As a simple example , consider the problem min ( x 1 − 2 ) 2 + ( x 2 − 1 ) 2 subject to x 2 1 − x 2 ≤ 0 , x 1 + x 2 ≤ 2 . ( 1 . 2 ) We can write this problem in the form ( 1 . 1 ) by deﬁning f ( x ) (cid:3) ( x 1 − 2 ) 2 + ( x 2 − 1 ) 2 , x (cid:3) (cid:1) x 1 x 2 (cid:2) , c ( x ) (cid:3) (cid:1) c 1 ( x ) c 2 ( x ) (cid:2) (cid:3) (cid:1) − x 21 + x 2 − x 1 − x 2 + 2 (cid:2) , I (cid:3) { 1 , 2 } , E (cid:3) ∅ . Figure 1 . 1 shows the contours of the objective function , that is , the set of points for which f ( x ) has a constant value . It also illustrates the feasible region , which is the set of points satisfying all the constraints ( the area between the two constraint boundaries ) , and the point 4 C H A P T E R 1 . I N T R O D U C T I O N x ∗ , which is the solution of the problem . Note that the “infeasible side” of the inequality constraints is shaded . The example above illustrates , too , that transformations are often necessary to express an optimization problem in the particular form ( 1 . 1 ) . Often it is more natural or convenient to label the unknowns with two or three subscripts , or to refer to different variables by completely different names , so that relabeling is necessary to pose the problem in the form ( 1 . 1 ) . Another common difference is that we are required to maximize rather than minimize f , but we can accommodate this change easily by minimizing − f in the formulation ( 1 . 1 ) . Good modeling systems perform the conversion to standardized formulations such as ( 1 . 1 ) transparently to the user . EXAMPLE : A TRANSPORTATION PROBLEM We begin with a much simpliﬁed example of a problem that might arise in manufac - turing and transportation . A chemical company has 2 factories F 1 and F 2 and a dozen retail outlets R 1 , R 2 , . . . , R 12 . Each factory F i can produce a i tons of a certain chemical product each week ; a i is called the capacity of the plant . Each retail outlet R j has a known weekly demand of b j tons of the product . The cost of shipping one ton of the product from factory F i to retail outlet R j is c ij . The problem is to determine how much of the product to ship from each factory to each outlet so as to satisfy all the requirements and minimize cost . The variables of the problem are x ij , i (cid:3) 1 , 2 , j (cid:3) 1 , . . . , 12 , where x ij is the number of tons of the product shipped from factory F i to retail outlet R j ; see Figure 1 . 2 . We can write the problem as min (cid:3) ij c ij x ij ( 1 . 3a ) subject to 12 (cid:3) j (cid:3) 1 x ij ≤ a i , i (cid:3) 1 , 2 , ( 1 . 3b ) 2 (cid:3) i (cid:3) 1 x ij ≥ b j , j (cid:3) 1 , . . . , 12 , ( 1 . 3c ) x ij ≥ 0 , i (cid:3) 1 , 2 , j (cid:3) 1 , . . . , 12 . ( 1 . 3d ) This type of problem is known as a linear programming problem , since the objective function and the constraints are all linear functions . In a more practical model , we would also include costsassociatedwithmanufacturingandstoringtheproduct . Theremaybevolumediscounts in practice for shipping the product ; for example the cost ( 1 . 3a ) could be represented by (cid:4) ij c ij (cid:5) δ + x ij , where δ > 0 is a small subscription fee . In this case , the problem is a nonlinear program because the objective function is nonlinear . C H A P T E R 1 . I N T R O D U C T I O N 5 R R F F R R 12 1 3 X 21 2 2 1 Figure 1 . 2 A transportation problem . CONTINUOUS VERSUS DISCRETE OPTIMIZATION In some optimization problems the variables make sense only if they take on integer values . For example , a variable x i could represent the number of power plants of type i that should be constructed by an electicity provider during the next 5 years , or it could indicate whether or not a particular factory should be located in a particular city . The mathematical formulation of such problems includes integrality constraints , which have the form x i ∈ Z , where Z is the set of integers , or binary constraints , which have the form x i ∈ { 0 , 1 } , in addition to algebraic constraints like those appearing in ( 1 . 1 ) . Problems of this type are called integer programming problems . If some of the variables in the problem are not restricted to be integer or binary variables , they are sometimes called mixed integer programming problems , or MIPs for short . Integer programming problems are a type of discrete optimization problem . Generally , discrete optimization problems may contain not only integers and binary variables , but also more abstract variable objects such as permutations of an ordered set . The deﬁning feature of a discrete optimization problem is that the unknown x is drawn from a a ﬁnite ( but often very large ) set . By contrast , the feasible set for continuous optimization problems—the class of problems studied in this book—is usually uncountably inﬁnite , as when the components of x are allowed to be real numbers . Continuous optimization problems are normally easier to solve because the smoothness of the functions makes it possible to use objective and constraint information at a particular point x to deduce information about the function’s behavior at all points close to x . In discrete problems , by constrast , the behavior of the objective and constraints may change signiﬁcantly as we move from one feasible point to another , even if the two points are “close” by some measure . The feasible sets for discrete optimization problems can be thought of as exhibiting an extreme form of nonconvexity , as a convex combination of two feasible points is in general not feasible . 6 C H A P T E R 1 . I N T R O D U C T I O N Discrete optimization problems are not addressed directly in this book ; we refer the reader to the texts by Papadimitriou and Steiglitz [ 235 ] , Nemhauser and Wolsey [ 224 ] , Cook et al . [ 77 ] , and Wolsey [ 312 ] for comprehensive treatments of this subject . We note , however , that continuous optimization techniques often play an important role in solving discrete optimization problems . For instance , the branch - and - bound method for integer linear programming problems requires the repeated solution of linear programming “relaxations , ” in which some of the integer variables are ﬁxed at integer values , while for other integer variables the integrality constraints are temporarily ignored . These subproblems are usually solved by the simplex method , which is discussed in Chapter 13 of this book . CONSTRAINED AND UNCONSTRAINED OPTIMIZATION Problems with the general form ( 1 . 1 ) can be classiﬁed according to the nature of the objective function and constraints ( linear , nonlinear , convex ) , the number of variables ( large or small ) , the smoothness of the functions ( differentiable or nondifferentiable ) , and so on . An important distinction is between problems that have constraints on the variables and those that do not . This book is divided into two parts according to this classiﬁcation . Unconstrained optimization problems , for which we have E (cid:3) I (cid:3) ∅ in ( 1 . 1 ) , arise directly in many practical applications . Even for some problems with natural constraints on the variables , it may be safe to disregard them as they do not affect on the solution and do not interfere with algorithms . Unconstrained problems arise also as reformulations of constrained optimization problems , in which the constraints are replaced by penalization terms added to objective function that have the effect of discouraging constraint violations . Constrained optimization problems arise from models in which constraints play an essential role , for example in imposing budgetary constraints in an economic problem or shape constraints in a design problem . These constraints may be simple bounds such as 0 ≤ x 1 ≤ 100 , more general linear constraints such as (cid:4) i x i ≤ 1 , or nonlinear inequalities that represent complex relationships among the variables . When the objective function and all the constraints are linear functions of x , the problem is a linear programming problem . Problems of this type are probably the most widely formulated and solved of all optimization problems , particularly in management , ﬁnancial , and economic applications . Nonlinear programming problems , in which at least some of the constraints or the objective are nonlinear functions , tend to arise naturally in the physical sciences and engineering , and are becoming more widely used in management and economic sciences as well . GLOBAL AND LOCAL OPTIMIZATION Many algorithms for nonlinear optimization problems seek only a local solution , a point at which the objective function is smaller than at all other feasible nearby points . They do not always ﬁnd the global solution , which is the point with lowest function value among all feasiblepoints . Globalsolutionsareneededinsomeapplications , butformanyproblemsthey C H A P T E R 1 . I N T R O D U C T I O N 7 aredifﬁculttorecognizeandevenmoredifﬁculttolocate . For convexprogramming problems , and more particularly for linear programs , local solutions are also global solutions . General nonlinear problems , both constrained and unconstrained , may possess local solutions that are not global solutions . In this book we treat global optimization only in passing and focus instead on the computation and characterization of local solutions . We note , however , that many successful global optimization algorithms require the solution of many local optimization problems , to which the algorithms described in this book can be applied . Research papers on global optimization can be found in Floudas and Pardalos [ 109 ] and in the Journal of Global Optimization . STOCHASTIC AND DETERMINISTIC OPTIMIZATION Insomeoptimizationproblems , themodelcannotbefullyspeciﬁedbecauseitdepends on quantities that are unknown at the time of formulation . This characteristic is shared by many economic and ﬁnancial planning models , which may depend for example on future interest rates , future demands for a product , or future commodity prices , but uncertainty can arise naturally in almost any type of application . Rather than just use a “best guess” for the uncertain quantities , modelers may obtain more useful solutions by incorporating additional knowledge about these quantities into the model . For example , they may know a number of possible scenarios for the uncertain demand , along with estimates of the probabilities of each scenario . Stochastic optimization algorithms use these quantiﬁcations of the uncertainty to produce solutions that optimize the expected performance of the model . Related paradigms for dealing with uncertain data in the model include chance - constrained optimization , in which we ensure that the variables x satisfy the given constraints to some speciﬁed probability , and robust optimization , in which certain constraints are required to hold for all possible values of the uncertain data . We do not consider stochastic optimization problems further in this book , focusing instead on deterministic optimization problems , in which the model is completely known . Many algorithms for stochastic optimization do , however , proceed by formulating one or more deterministic subproblems , each of which can be solved by the techniques outlined here . Stochastic and robust optimization have seen a great deal of recent research activity . For further information on stochastic optimization , consult the books of Birge and Louveaux [ 22 ] and Kall and Wallace [ 174 ] . Robust optimization is discussed in Ben - Tal and Nemirovski [ 15 ] . CONVEXITY The concept of convexity is fundamental in optimization . Many practical problems possess this property , which generally makes them easier to solve both in theory and practice . 8 C H A P T E R 1 . I N T R O D U C T I O N The term “convex” can be applied both to sets and to functions . A set S ∈ IR n is a convex set if the straight line segment connecting any two points in S lies entirely inside S . Formally , for any two points x ∈ S and y ∈ S , we have α x + ( 1 − α ) y ∈ S for all α ∈ [ 0 , 1 ] . The function f is a convex function if its domain S is a convex set and if for any two points x and y in S , the following property is satisﬁed : f ( α x + ( 1 − α ) y ) ≤ α f ( x ) + ( 1 − α ) f ( y ) , for all α ∈ [ 0 , 1 ] . ( 1 . 4 ) Simple instances of convex sets include the unit ball { y ∈ IR n | (cid:8) y (cid:8) 2 ≤ 1 } ; and any polyhedron , which is a set deﬁned by linear equalities and inequalities , that is , { x ∈ IR n | Ax (cid:3) b , Cx ≤ d } , where A and C are matrices of appropriate dimension , and b and d are vectors . Simple instances of convex functions include the linear function f ( x ) (cid:3) c T x + α , for any constant vector c ∈ IR n and scalar α ; and the convex quadratic function f ( x ) (cid:3) x T Hx , where H is a symmetric positive semideﬁnite matrix . We say that f is strictly convex if the inequality in ( 1 . 4 ) is strict whenever x (cid:9)(cid:3) y and α is in the open interval ( 0 , 1 ) . A function f is said to be concave if − f is convex . If the objective function in the optimization problem ( 1 . 1 ) and the feasible region are both convex , then any local solution of the problem is in fact a global solution . The term convex programming is used to describe a special case of the general constrained optimization problem ( 1 . 1 ) in which • the objective function is convex , • the equality constraint functions c i ( · ) , i ∈ E , are linear , and • the inequality constraint functions c i ( · ) , i ∈ I , are concave . OPTIMIZATION ALGORITHMS Optimization algorithms are iterative . They begin with an initial guess of the variable x and generate a sequence of improved estimates ( called “iterates” ) until they terminate , hopefully at a solution . The strategy used to move from one iterate to the next distinguishes one algorithm from another . Most strategies make use of the values of the objective function f , theconstraintfunctions c i , andpossiblytheﬁrstandsecondderivativesofthesefunctions . Some algorithms accumulate information gathered at previous iterations , while others use only local information obtained at the current point . Regardless of these speciﬁcs ( which will receive plenty of attention in the rest of the book ) , good algorithms should possess the following properties : • Robustness . They should perform well on a wide variety of problems in their class , for all reasonable values of the starting point . C H A P T E R 1 . I N T R O D U C T I O N 9 • Efﬁciency . They should not require excessive computer time or storage . • Accuracy . They should be able to identify a solution with precision , without being overly sensitive to errors in the data or to the arithmetic rounding errors that occur when the algorithm is implemented on a computer . These goals may conﬂict . For example , a rapidly convergent method for a large uncon - strained nonlinear problem may require too much computer storage . On the other hand , a robust method may also be the slowest . Tradeoffs between convergence rate and storage requirements , and between robustness and speed , and so on , are central issues in numerical optimization . They receive careful consideration in this book . The mathematical theory of optimization is used both to characterize optimal points and to provide the basis for most algorithms . It is not possible to have a good understanding of numerical optimization without a ﬁrm grasp of the supporting theory . Accordingly , this book gives a solid ( though not comprehensive ) treatment of optimality conditions , as well as convergence analysis that reveals the strengths and weaknesses of some of the most important algorithms . NOTES AND REFERENCES Optimization traces its roots to the calculus of variations and the work of Euler and Lagrange . The development of linear programming n the 1940s broadened the ﬁeld and stimulated much of the progress in modern optimization theory and practice during the past 60 years . Optimization is often called mathematical programming , a somewhat confusing term coined in the 1940s , before the word “programming” became inextricably linked with computer software . The original meaning of this word ( and the intended one in this context ) was more inclusive , with connotations of algorithm design and analysis . Modeling will not be treated extensively in the book . It is an essential subject in its own right , as it makes the connection between optimization algorithms and software on the one hand , and applications on the other hand . Information about modeling techniques for various application areas can be found in Dantzig [ 86 ] , Ahuja , Magnanti , and Orlin [ 1 ] , Fourer , Gay , and Kernighan [ 112 ] , Winston [ 308 ] , and Rardin [ 262 ] . This is pag Printer : O C H A P T E R 2 Fundamentals of Unconstrained Optimization In unconstrained optimization , we minimize an objective function that depends on real variables , with no restrictions at all on the values of these variables . The mathematical formulation is min x f ( x ) , ( 2 . 1 ) where x ∈ IR n is a real vector with n ≥ 1 components and f : IR n → IR is a smooth function . C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N 11 y . . . . . y 3 y 2 y 1 t 1 t 3 t m t 2 t Figure 2 . 1 Least squares data ﬁtting problem . Usually , we lack a global perspective on the function f . All we know are the values of f and maybe some of its derivatives at a set of points x 0 , x 1 , x 2 , . . . . Fortunately , our algorithms get to choose these points , and they try to do so in a way that identiﬁes a solution reliably and without using too much computer time or storage . Often , the information about f does not come cheaply , so we usually prefer algorithms that do not call for this information unnecessarily . ❏ E XAMPLE 2 . 1 Suppose that we are trying to ﬁnd a curve that ﬁts some experimental data . Figure 2 . 1 plots measurements y 1 , y 2 , . . . , y m of a signal taken at times t 1 , t 2 , . . . , t m . From the data and our knowledge of the application , we deduce that the signal has exponential and oscillatory behavior of certain types , and we choose to model it by the function φ ( t ; x ) (cid:3) x 1 + x 2 e − ( x 3 − t ) 2 / x 4 + x 5 cos ( x 6 t ) . The real numbers x i , i (cid:3) 1 , 2 , . . . , 6 , are the parameters of the model ; we would like to choose them to make the model values φ ( t j ; x ) ﬁt the observed data y j as closely as possible . To state our objective as an optimization problem , we group the parameters x i into a vector of unknowns x (cid:3) ( x 1 , x 2 , . . . , x 6 ) T , and deﬁne the residuals r j ( x ) (cid:3) y j − φ ( t j ; x ) , j (cid:3) 1 , 2 , . . . , m , ( 2 . 2 ) which measure the discrepancy between the model and the observed data . Our estimate of 12 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N x will be obtained by solving the problem min x ∈ IR 6 f ( x ) (cid:3) r 21 ( x ) + r 22 ( x ) + · · · + r 2 m ( x ) . ( 2 . 3 ) This is a nonlinear least - squares problem , a special case of unconstrained optimization . It illustrates that some objective functions can be expensive to evaluate even when the number of variables is small . Here we have n (cid:3) 6 , but if the number of measurements m is large ( 10 5 , say ) , evaluation of f ( x ) for a given parameter vector x is a signiﬁcant computation . ❐ Suppose that for the data given in Figure 2 . 1 the optimal solution of ( 2 . 3 ) is ap - proximately x ∗ (cid:3) ( 1 . 1 , 0 . 01 , 1 . 2 , 1 . 5 , 2 . 0 , 1 . 5 ) and the corresponding function value is f ( x ∗ ) (cid:3) 0 . 34 . Because the optimal objective is nonzero , there must be discrepancies be - tween the observed measurements y j and the model predictions φ ( t j , x ∗ ) for some ( usually most ) values of j —the model has not reproduced all the data points exactly . How , then , can we verify that x ∗ is indeed a minimizer of f ? To answer this question , we need to deﬁne the term “solution” and explain how to recognize solutions . Only then can we discuss algorithms for unconstrained optimization problems . 2 . 1 WHAT IS A SOLUTION ? Generally , we would be happiest if we found a global minimizer of f , a point where the function attains its least value . A formal deﬁnition is A point x ∗ is a global minimizer if f ( x ∗ ) ≤ f ( x ) for all x , where x ranges over all of IR n ( or at least over the domain of interest to the modeler ) . The global minimizer can be difﬁcult to ﬁnd , because our knowledge of f is usually only local . Since our algorithm does not visit many points ( we hope ! ) , we usually do not have a good picture of the overall shape of f , and we can never be sure that the function does not take a sharp dip in some region that has not been sampled by the algorithm . Most algorithms are able to ﬁnd only a local minimizer , which is a point that achieves the smallest value of f in its neighborhood . Formally , we say : A point x ∗ is a local minimizer if there is a neighborhood N of x ∗ such that f ( x ∗ ) ≤ f ( x ) for all x ∈ N . ( Recallthataneighborhoodof x ∗ issimplyanopensetthatcontains x ∗ . ) Apointthatsatisﬁes this deﬁnition is sometimes called a weak local minimizer . This terminology distinguishes 2 . 1 . W H A T I S A S O L U T I O N ? 13 it from a strict local minimizer , which is the outright winner in its neighborhood . Formally , A point x ∗ is a strict local minimizer ( also called a strong local minimizer ) if there is a neighborhood N of x ∗ such that f ( x ∗ ) < f ( x ) for all x ∈ N with x (cid:9)(cid:3) x ∗ . For the constant function f ( x ) (cid:3) 2 , every point x is a weak local minimizer , while the function f ( x ) (cid:3) ( x − 2 ) 4 has a strict local minimizer at x (cid:3) 2 . A slightly more exotic type of local minimizer is deﬁned as follows . A point x ∗ is an isolated local minimizer if there is a neighborhood N of x ∗ such that x ∗ is the only local minimizer in N . Some strict local minimizers are not isolated , as illustrated by the function f ( x ) (cid:3) x 4 cos ( 1 / x ) + 2 x 4 , f ( 0 ) (cid:3) 0 , which is twice continuously differentiable and has a strict local minimizer at x ∗ (cid:3) 0 . However , there are strict local minimizers at many nearby points x j , and we can label these points so that x j → 0 as j → ∞ . While strict local minimizers are not always isolated , it is true that all isolated local minimizers are strict . Figure 2 . 2 illustrates a function with many local minimizers . It is usually difﬁcult to ﬁnd the global minimizer for such functions , because algorithms tend to be “trapped” at local minimizers . This example is by no means pathological . In optimization problems associated with the determination of molecular conformation , the potential function to be minimized may have millions of local minima . f x Figure 2 . 2 A difﬁcult case for global minimization . 14 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N Sometimes we have additional “global” knowledge about f that may help in identi - fying global minima . An important special case is that of convex functions , for which every local minimizer is also a global minimizer . RECOGNIZING A LOCAL MINIMUM From the deﬁnitions given above , it might seem that the only way to ﬁnd out whether a point x ∗ is a local minimum is to examine all the points in its immediate vicinity , to make sure that none of them has a smaller function value . When the function f is smooth , however , there are more efﬁcient and practical ways to identify local minima . In particular , if f is twice continuously differentiable , we may be able to tell that x ∗ is a local minimizer ( and possibly a strict local minimizer ) by examining just the gradient ∇ f ( x ∗ ) and the Hessian ∇ 2 f ( x ∗ ) . The mathematical tool used to study minimizers of smooth functions is Taylor’s theorem . Because this theorem is central to our analysis throughout the book , we state it now . Its proof can be found in any calculus textbook . Theorem 2 . 1 ( Taylor’s Theorem ) . Suppose that f : IR n → IR is continuously differentiable and that p ∈ IR n . Then we have that f ( x + p ) (cid:3) f ( x ) + ∇ f ( x + tp ) T p , ( 2 . 4 ) for some t ∈ ( 0 , 1 ) . Moreover , if f is twice continuously differentiable , we have that ∇ f ( x + p ) (cid:3) ∇ f ( x ) + (cid:6) 1 0 ∇ 2 f ( x + tp ) p dt , ( 2 . 5 ) and that f ( x + p ) (cid:3) f ( x ) + ∇ f ( x ) T p + 12 p T ∇ 2 f ( x + tp ) p , ( 2 . 6 ) for some t ∈ ( 0 , 1 ) . Necessary conditions for optimality are derived by assuming that x ∗ is a local minimizer and then proving facts about ∇ f ( x ∗ ) and ∇ 2 f ( x ∗ ) . Theorem 2 . 2 ( First - Order Necessary Conditions ) . If x ∗ is a local minimizer and f is continuously differentiable in an open neighborhood of x ∗ , then ∇ f ( x ∗ ) (cid:3) 0 . 2 . 1 . W H A T I S A S O L U T I O N ? 15 P ROOF . Suppose for contradiction that ∇ f ( x ∗ ) (cid:9)(cid:3) 0 . Deﬁne the vector p (cid:3) −∇ f ( x ∗ ) and note that p T ∇ f ( x ∗ ) (cid:3) −(cid:8)∇ f ( x ∗ ) (cid:8) 2 < 0 . Because ∇ f is continuous near x ∗ , there is a scalar T > 0 such that p T ∇ f ( x ∗ + tp ) < 0 , for all t ∈ [ 0 , T ] . For any ¯ t ∈ ( 0 , T ] , we have by Taylor’s theorem that f ( x ∗ + ¯ t p ) (cid:3) f ( x ∗ ) + ¯ t p T ∇ f ( x ∗ + tp ) , for some t ∈ ( 0 , ¯ t ) . Therefore , f ( x ∗ + ¯ t p ) < f ( x ∗ ) for all ¯ t ∈ ( 0 , T ] . We have found a direction leading away from x ∗ along which f decreases , so x ∗ is not a local minimizer , and we have a contradiction . (cid:1) We call x ∗ a stationary point if ∇ f ( x ∗ ) (cid:3) 0 . According to Theorem 2 . 2 , any local minimizer must be a stationary point . For the next result we recall that a matrix B is positive deﬁnite if p T Bp > 0 for all p (cid:9)(cid:3) 0 , and positive semideﬁnite if p T Bp ≥ 0 for all p ( see the Appendix ) . Theorem 2 . 3 ( Second - Order Necessary Conditions ) . If x ∗ is a local minimizer of f and ∇ 2 f exists and is continuous in an open neighborhood of x ∗ , then ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) is positive semideﬁnite . P ROOF . We know from Theorem 2 . 2 that ∇ f ( x ∗ ) (cid:3) 0 . For contradiction , assume that ∇ 2 f ( x ∗ ) is not positive semideﬁnite . Then we can choose a vector p such that p T ∇ 2 f ( x ∗ ) p < 0 , and because ∇ 2 f is continuous near x ∗ , there is a scalar T > 0 such that p T ∇ 2 f ( x ∗ + tp ) p < 0 for all t ∈ [ 0 , T ] . By doing a Taylor series expansion around x ∗ , we have for all ¯ t ∈ ( 0 , T ] and some t ∈ ( 0 , ¯ t ) that f ( x ∗ + ¯ t p ) (cid:3) f ( x ∗ ) + ¯ t p T ∇ f ( x ∗ ) + 12 ¯ t 2 p T ∇ 2 f ( x ∗ + tp ) p < f ( x ∗ ) . As in Theorem 2 . 2 , we have found a direction from x ∗ along which f is decreasing , and so again , x ∗ is not a local minimizer . (cid:1) We now describe sufﬁcient conditions , which are conditions on the derivatives of f at the point z ∗ that guarantee that x ∗ is a local minimizer . 16 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N Theorem 2 . 4 ( Second - Order Sufﬁcient Conditions ) . Suppose that ∇ 2 f is continuous in an open neighborhood of x ∗ and that ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) is positive deﬁnite . Then x ∗ is a strict local minimizer of f . P ROOF . Because the Hessian is continuous and positive deﬁnite at x ∗ , we can choose a radius r > 0 so that ∇ 2 f ( x ) remains positive deﬁnite for all x in the open ball D (cid:3) { z | (cid:8) z − x ∗ (cid:8) < r } . Taking any nonzero vector p with (cid:8) p (cid:8) < r , we have x ∗ + p ∈ D and so f ( x ∗ + p ) (cid:3) f ( x ∗ ) + p T ∇ f ( x ∗ ) + 12 p T ∇ 2 f ( z ) p (cid:3) f ( x ∗ ) + 12 p T ∇ 2 f ( z ) p , where z (cid:3) x ∗ + tp for some t ∈ ( 0 , 1 ) . Since z ∈ D , we have p T ∇ 2 f ( z ) p > 0 , and therefore f ( x ∗ + p ) > f ( x ∗ ) , giving the result . (cid:1) Note that the second - order sufﬁcient conditions of Theorem 2 . 4 guarantee something stronger than the necessary conditions discussed earlier ; namely , that the minimizer is a strict local minimizer . Note too that the second - order sufﬁcient conditions are not necessary : A point x ∗ may be a strict local minimizer , and yet may fail to satisfy the sufﬁcient conditions . A simple example is given by the function f ( x ) (cid:3) x 4 , for which the point x ∗ (cid:3) 0 is a strict local minimizer at which the Hessian matrix vanishes ( and is therefore not positive deﬁnite ) . When the objective function is convex , local and global minimizers are simple to characterize . Theorem 2 . 5 . When f is convex , any local minimizer x ∗ is a global minimizer of f . If in addition f is differentiable , then any stationary point x ∗ is a global minimizer of f . P ROOF . Suppose that x ∗ is a local but not a global minimizer . Then we can ﬁnd a point z ∈ IR n with f ( z ) < f ( x ∗ ) . Consider the line segment that joins x ∗ to z , that is , x (cid:3) λ z + ( 1 − λ ) x ∗ , for some λ ∈ ( 0 , 1 ] . ( 2 . 7 ) By the convexity property for f , we have f ( x ) ≤ λ f ( z ) + ( 1 − λ ) f ( x ∗ ) < f ( x ∗ ) . ( 2 . 8 ) Any neighborhood N of x ∗ contains a piece of the line segment ( 2 . 7 ) , so there will always be points x ∈ N at which ( 2 . 8 ) is satisﬁed . Hence , x ∗ is not a local minimizer . 2 . 1 . W H A T I S A S O L U T I O N ? 17 For the second part of the theorem , suppose that x ∗ is not a global minimizer and choose z as above . Then , from convexity , we have ∇ f ( x ∗ ) T ( z − x ∗ ) (cid:3) d d λ f ( x ∗ + λ ( z − x ∗ ) ) | λ (cid:3) 0 ( see the Appendix ) (cid:3) lim λ ↓ 0 f ( x ∗ + λ ( z − x ∗ ) ) − f ( x ∗ ) λ ≤ lim λ ↓ 0 λ f ( z ) + ( 1 − λ ) f ( x ∗ ) − f ( x ∗ ) λ (cid:3) f ( z ) − f ( x ∗ ) < 0 . Therefore , ∇ f ( x ∗ ) (cid:9)(cid:3) 0 , and so x ∗ is not a stationary point . (cid:1) These results , which are based on elementary calculus , provide the foundations for unconstrained optimization algorithms . In one way or another , all algorithms seek a point where ∇ f ( · ) vanishes . NONSMOOTH PROBLEMS This book focuses on smooth functions , by which we generally mean functions whose second derivatives exist and are continuous . We note , however , that there are interesting problems in which the functions involved may be nonsmooth and even discontinuous . It is not possible in general to identify a minimizer of a general discontinuous function . If , how - ever , the function consists of a few smooth pieces , with discontinuities between the pieces , it may be possible to ﬁnd the minimizer by minimizing each smooth piece individually . If the function is continuous everywhere but nondifferentiable at certain points , as in Figure 2 . 3 , we can identify a solution by examing the subgradient or generalized * f x x Figure 2 . 3 Nonsmooth function with minimum at a kink . 18 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N gradient , which are generalizations of the concept of gradient to the nonsmooth case . Nonsmooth optimization is beyond the scope of this book ; we refer instead to Hiriart - Urruty and Lemar´echal [ 170 ] for an extensive discussion of theory . Here , we mention only that the minimization of a function such as the one illustrated in Figure 2 . 3 ( which contains a jump discontinuity in the ﬁrst derivative f (cid:14) ( x ) at the minimum ) is difﬁcult because the behavior of f is not predictable near the point of nonsmoothness . That is , we cannot be sure that information about f obtained at one point can be used to infer anything about f at neighboring points , because points of nondifferentiabil - ity may intervene . However , minimization of certain special nondifferentiable functions , such as f ( x ) (cid:3) (cid:8) r ( x ) (cid:8) 1 , f ( x ) (cid:3) (cid:8) r ( x ) (cid:8) ∞ ( 2 . 9 ) ( where r ( x ) is a vector function ) , can be reformulated as smooth constrained optimiza - tion problems ; see Exercise 12 . 5 in Chapter 12 and ( 17 . 31 ) . The functions ( 2 . 9 ) are useful in data ﬁtting , where r ( x ) is the residual vector whose components are deﬁned in ( 2 . 2 ) . 2 . 2 OVERVIEW OF ALGORITHMS The last forty years have seen the development of a powerful collection of algorithms for unconstrained optimization of smooth functions . We now give a broad description of their main properties , and we describe them in more detail in Chapters 3 , 4 , 5 , 6 , and 7 . All algorithms for unconstrained minimization require the user to supply a starting point , which we usually denote by x 0 . The user with knowledge about the application and the data set may be in a good position to choose x 0 to be a reasonable estimate of the solution . Otherwise , the starting point must be chosen by the algorithm , either by a systematic approach or in some arbitrary manner . Beginning at x 0 , optimization algorithms generate a sequence of iterates { x k } ∞ k (cid:3) 0 that terminate when either no more progress can be made or when it seems that a so - lution point has been approximated with sufﬁcient accuracy . In deciding how to move from one iterate x k to the next , the algorithms use information about the function f at x k , and possibly also information from earlier iterates x 0 , x 1 , . . . , x k − 1 . They use this in - formation to ﬁnd a new iterate x k + 1 with a lower function value than x k . ( There exist nonmonotone algorithms that do not insist on a decrease in f at every step , but even these algorithms require f to be decreased after some prescribed number m of iterations , that is , f ( x k ) < f ( x k − m ) . ) There are two fundamental strategies for moving from the current point x k to a new iterate x k + 1 . Most of the algorithms described in this book follow one of these approaches . 2 . 2 . O V E R V I E W O F A L G O R I T H M S 19 TWO STRATEGIES : LINE SEARCH AND TRUST REGION In the line search strategy , the algorithm chooses a direction p k and searches along this direction from the current iterate x k for a new iterate with a lower function value . The distance to move along p k can be found by approximately solving the following one - dimensional minimization problem to ﬁnd a step length α : min α > 0 f ( x k + α p k ) . ( 2 . 10 ) By solving ( 2 . 10 ) exactly , we would derive the maximum beneﬁt from the direction p k , but an exact minimization may be expensive and is usually unnecessary . Instead , the line search algorithm generates a limited number of trial step lengths until it ﬁnds one that loosely approximates the minimum of ( 2 . 10 ) . At the new point , a new search direction and step length are computed , and the process is repeated . In the second algorithmic strategy , known as trust region , the information gathered about f is used to construct a model function m k whose behavior near the current point x k is similar to that of the actual objective function f . Because the model m k may not be a good approximation of f when x is far from x k , we restrict the search for a minimizer of m k to some region around x k . In other words , we ﬁnd the candidate step p by approximately solving the following subproblem : min p m k ( x k + p ) , where x k + p lies inside the trust region . ( 2 . 11 ) If the candidate solution does not produce a sufﬁcient decrease in f , we conclude that the trust region is too large , and we shrink it and re - solve ( 2 . 11 ) . Usually , the trust region is a ball deﬁned by (cid:8) p (cid:8) 2 ≤ (cid:6) , where the scalar (cid:6) > 0 is called the trust - region radius . Elliptical and box - shaped trust regions may also be used . The model m k in ( 2 . 11 ) is usually deﬁned to be a quadratic function of the form m k ( x k + p ) (cid:3) f k + p T ∇ f k + 12 p T B k p , ( 2 . 12 ) where f k , ∇ f k , and B k are a scalar , vector , and matrix , respectively . As the notation indicates , f k and ∇ f k are chosen to be the function and gradient values at the point x k , so that m k and f are in agreement to ﬁrst order at the current iterate x k . The matrix B k is either the Hessian ∇ 2 f k or some approximation to it . Suppose that the objective function is given by f ( x ) (cid:3) 10 ( x 2 − x 21 ) 2 + ( 1 − x 1 ) 2 . At the point x k (cid:3) ( 0 , 1 ) its gradient and Hessian are ∇ f k (cid:3) (cid:1) − 2 20 (cid:2) , ∇ 2 f k (cid:3) (cid:1) − 38 0 0 20 (cid:2) . 20 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N k k k f x p p * unconstrained minimizer contours 1 m = m = contours 12 of model of Figure2 . 4 Two possible trust regions ( circles ) and their corresponding steps p k . The solid lines are contours of the model function m k . The contour lines of the quadratic model ( 2 . 12 ) with B k (cid:3) ∇ 2 f k are depicted in Figure 2 . 4 , which also illustrates the contours of the objective function f and the trust region . We have indicated contour lines where the model m k has values 1 and 12 . Note from Figure 2 . 4 that each time we decrease the size of the trust region after failure of a candidate iterate , the step from x k to the new candidate will be shorter , and it usually points in a different direction from the previous candidate . The trust - region strategy differs in this respect from line search , which stays with a single search direction . In a sense , the line search and trust - region approaches differ in the order in which they choose the direction and distance of the move to the next iterate . Line search starts by ﬁxing the direction p k and then identifying an appropriate distance , namely the step length α k . In trust region , we ﬁrst choose a maximum distance—the trust - region radius (cid:6) k —and then seek a direction and step that attain the best improvement possible subject to this distance constraint . If this step proves to be unsatisfactory , we reduce the distance measure (cid:6) k and try again . The line search approach is discussed in more detail in Chapter 3 . Chapter 4 discusses the trust - region strategy , including techniques for choosing and adjusting the size of the re - gion and for computing approximate solutions to the trust - region problems ( 2 . 11 ) . We now previewtwomajorissues : choiceofthesearchdirection p k inlinesearchmethods , andchoice oftheHessian B k intrust - regionmethods . Theseissuesarecloselyrelated , aswenowobserve . SEARCH DIRECTIONS FOR LINE SEARCH METHODS The steepest descent direction −∇ f k is the most obvious choice for search direction for a line search method . It is intuitive ; among all the directions we could move from x k , 2 . 2 . O V E R V I E W O F A L G O R I T H M S 21 it is the one along which f decreases most rapidly . To verify this claim , we appeal again to Taylor’s theorem ( Theorem 2 . 1 ) , which tells us that for any search direction p and step - length parameter α , we have f ( x k + α p ) (cid:3) f ( x k ) + α p T ∇ f k + 12 α 2 p T ∇ 2 f ( x k + tp ) p , for some t ∈ ( 0 , α ) ( see ( 2 . 6 ) ) . The rate of change in f along the direction p at x k is simply the coefﬁcient of α , namely , p T ∇ f k . Hence , the unit direction p of most rapid decrease is the solution to the problem min p p T ∇ f k , subject to (cid:8) p (cid:8) (cid:3) 1 . ( 2 . 13 ) Since p T ∇ f k (cid:3) (cid:8) p (cid:8) (cid:8)∇ f k (cid:8) cos θ (cid:3) (cid:8)∇ f k (cid:8) cos θ , where θ is the angle between p and ∇ f k , it is easy to see that the minimizer is attained when cos θ (cid:3) − 1 and p (cid:3) −∇ f k / (cid:8)∇ f k (cid:8) , as claimed . As we illustrate in Figure 2 . 5 , this direction is orthogonal to the contours of the function . The steepest descent method is a line search method that moves along p k (cid:3) −∇ f k at everystep . Itcanchoosethesteplength α k inavarietyofways , aswediscussinChapter3 . One advantage of the steepest descent direction is that it requires calculation of the gradient ∇ f k but not of second derivatives . However , it can be excruciatingly slow on difﬁcult problems . Line search methods may use search directions other than the steepest descent direc - tion . In general , any descent direction—one that makes an angle of strictly less than π / 2 radians with −∇ f k —is guaranteed to produce a decrease in f , provided that the step length * x p x k k . Figure 2 . 5 Steepest descent direction for a function of two variables . 22 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N k ∆ – k f p Figure 2 . 6 A downhill direction p k . is sufﬁciently small ( see Figure 2 . 6 ) . We can verify this claim by using Taylor’s theorem . From ( 2 . 6 ) , we have that f ( x k + (cid:9) p k ) (cid:3) f ( x k ) + (cid:9) p Tk ∇ f k + O ( (cid:9) 2 ) . When p k is a downhill direction , the angle θ k between p k and ∇ f k has cos θ k < 0 , so that p Tk ∇ f k (cid:3) (cid:8) p k (cid:8) (cid:8)∇ f k (cid:8) cos θ k < 0 . It follows that f ( x k + (cid:9) p k ) < f ( x k ) for all positive but sufﬁciently small values of (cid:9) . Another important search direction—perhaps the most important one of all— is the Newton direction . This direction is derived from the second - order Taylor series approximation to f ( x k + p ) , which is f ( x k + p ) ≈ f k + p T ∇ f k + 1 2 p T ∇ 2 f k p def (cid:3) m k ( p ) . ( 2 . 14 ) Assuming for the moment that ∇ 2 f k is positive deﬁnite , we obtain the Newton direction by ﬁnding the vector p that minimizes m k ( p ) . By simply setting the derivative of m k ( p ) to zero , we obtain the following explicit formula : p N k (cid:3) − (cid:7) ∇ 2 f k (cid:8) − 1 ∇ f k . ( 2 . 15 ) The Newton direction is reliable when the difference between the true function f ( x k + p ) and its quadratic model m k ( p ) is not too large . By comparing ( 2 . 14 ) with ( 2 . 6 ) , we see that the only difference between these functions is that the matrix ∇ 2 f ( x k + tp ) in the third term of the expansion has been replaced by ∇ 2 f k . If ∇ 2 f is sufﬁciently smooth , this difference introduces a perturbation of only O ( (cid:8) p (cid:8) 3 ) into the expansion , so that when (cid:8) p (cid:8) is small , the approximation f ( x k + p ) ≈ m k ( p ) is quite accurate . 2 . 2 . O V E R V I E W O F A L G O R I T H M S 23 The Newton direction can be used in a line search method when ∇ 2 f k is positive deﬁnite , for in this case we have ∇ f Tk p N k (cid:3) − p N k T ∇ 2 f k p N k ≤ − σ k (cid:8) p N k (cid:8) 2 for some σ k > 0 . Unless the gradient ∇ f k ( and therefore the step p N k ) is zero , we have that ∇ f Tk p N k < 0 , so the Newton direction is a descent direction . Unlike the steepest descent direction , there is a “natural” step length of 1 associated with the Newton direction . Most line search implementations of Newton’s method use the unit step α (cid:3) 1 where possible and adjust α only when it does not produce a satisfactory reduction in the value of f . When ∇ 2 f k is not positive deﬁnite , the Newton direction may not even be deﬁned , since (cid:7) ∇ 2 f k (cid:8) − 1 may not exist . Even when it is deﬁned , it may not satisfy the descent property ∇ f Tk p N k < 0 , in which case it is unsuitable as a search direction . In these situations , line search methods modify the deﬁnition of p k to make it satisfy the descent condition while retaining the beneﬁt of the second - order information contained in ∇ 2 f k . We describe these modiﬁcations in Chapter 3 . Methods that use the Newton direction have a fast rate of local convergence , typically quadratic . After a neighborhood of the solution is reached , convergence to high accuracy often occurs in just a few iterations . The main drawback of the Newton direction is the need for the Hessian ∇ 2 f ( x ) . Explicit computation of this matrix of second derivatives can sometimes be a cumbersome , error - prone , and expensive process . Finite - difference and automatic differentiation techniques described in Chapter 8 may be useful in avoiding the need to calculate second derivatives by hand . Quasi - Newton search directions provide an attractive alternative to Newton’s method in that they do not require computation of the Hessian and yet still attain a superlinear rate of convergence . In place of the true Hessian ∇ 2 f k , they use an approximation B k , which is updated after each step to take account of the additional knowledge gained during the step . The updates make use of the fact that changes in the gradient g provide information about the second derivative of f along the search direction . By using the expression ( 2 . 5 ) from our statement of Taylor’s theorem , we have by adding and subtracting the term ∇ 2 f ( x ) p that ∇ f ( x + p ) (cid:3) ∇ f ( x ) + ∇ 2 f ( x ) p + (cid:6) 1 0 (cid:9) ∇ 2 f ( x + tp ) − ∇ 2 f ( x ) (cid:10) p dt . Because ∇ f ( · ) is continuous , the size of the ﬁnal integral term is o ( (cid:8) p (cid:8) ) . By setting x (cid:3) x k and p (cid:3) x k + 1 − x k , we obtain ∇ f k + 1 (cid:3) ∇ f k + ∇ 2 f k ( x k + 1 − x k ) + o ( (cid:8) x k + 1 − x k (cid:8) ) . When x k and x k + 1 lie in a region near the solution x ∗ , within which ∇ 2 f is positive deﬁnite , the ﬁnal term in this expansion is eventually dominated by the ∇ 2 f k ( x k + 1 − x k ) term , and 24 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N we can write ∇ 2 f k ( x k + 1 − x k ) ≈ ∇ f k + 1 − ∇ f k . ( 2 . 16 ) We choose the new Hessian approximation B k + 1 so that it mimics the property ( 2 . 16 ) of the true Hessian , that is , we require it to satisfy the following condition , known as the secant equation : B k + 1 s k (cid:3) y k , ( 2 . 17 ) where s k (cid:3) x k + 1 − x k , y k (cid:3) ∇ f k + 1 − ∇ f k . Typically , we impose additional conditions on B k + 1 , such as symmetry ( motivated by symmetry of the exact Hessian ) , and a requirement that the difference between successive approximations B k and B k + 1 have low rank . Two of the most popular formulae for updating the Hessian approximation B k are the symmetric - rank - one ( SR1 ) formula , deﬁned by B k + 1 (cid:3) B k + ( y k − B k s k ) ( y k − B k s k ) T ( y k − B k s k ) T s k , ( 2 . 18 ) and the BFGS formula , named after its inventors , Broyden , Fletcher , Goldfarb , and Shanno , which is deﬁned by B k + 1 (cid:3) B k − B k s k s Tk B k s Tk B k s k + y k y Tk y Tk s k . ( 2 . 19 ) Note that the difference between the matrices B k and B k + 1 is a rank - one matrix in the case of ( 2 . 18 ) and a rank - two matrix in the case of ( 2 . 19 ) . Both updates satisfy the secant equation and both maintain symmetry . One can show that BFGS update ( 2 . 19 ) generates positive deﬁnite approximations whenever the initial approximation B 0 is positive deﬁnite and s Tk y k > 0 . We discuss these issues further in Chapter 6 . The quasi - Newton search direction is obtained by using B k in place of the exact Hessian in the formula ( 2 . 15 ) , that is , p k (cid:3) − B − 1 k ∇ f k . ( 2 . 20 ) Some practical implementations of quasi - Newton methods avoid the need to factorize B k at each iteration by updating the inverse of B k , instead of B k itself . In fact , the equivalent 2 . 2 . O V E R V I E W O F A L G O R I T H M S 25 formula for ( 2 . 18 ) and ( 2 . 19 ) , applied to the inverse approximation H k def (cid:3) B − 1 k , is H k + 1 (cid:3) (cid:7) I − ρ k s k y Tk (cid:8) H k (cid:7) I − ρ k y k s Tk (cid:8) + ρ k s k s Tk , ρ k (cid:3) 1 y Tk s k . ( 2 . 21 ) Calculation of p k can then be performed by using the formula p k (cid:3) − H k ∇ f k . This matrix – vector multiplication is simpler than the factorization / back - substitution procedure that is needed to implement the formula ( 2 . 20 ) . Two variants of quasi - Newton methods designed to solve large problems—partially separable and limited - memory updating—are described in Chapter 7 . The last class of search directions we preview here is that generated by nonlinear conjugate gradient methods . They have the form p k (cid:3) −∇ f ( x k ) + β k p k − 1 , where β k is a scalar that ensures that p k and p k − 1 are conjugate —an important concept in the minimization of quadratic functions that will be deﬁned in Chapter 5 . Conjugate gradient methods were originally designed to solve systems of linear equations Ax (cid:3) b , where the coefﬁcient matrix A is symmetric and positive deﬁnite . The problem of solving this linear system is equivalent to the problem of minimizing the convex quadratic function deﬁned by φ ( x ) (cid:3) 12 x T Ax − b T x , so it was natural to investigate extensions of these algorithms to more general types of unconstrained minimization problems . In general , nonlinear conjugate gradient directions are much more effective than the steepest descent direction and are almost as simple to compute . These methods do not attain the fast convergence rates of Newton or quasi - Newton methods , but they have the advantage of not requiring storage of matrices . An extensive discussion of nonlinear conjugate gradient methods is given in Chapter 5 . All of the search directions discussed so far can be used directly in a line search framework . They give rise to the steepest descent , Newton , quasi - Newton , and conjugate gradient line search methods . All except conjugate gradients have an analogue in the trust - region framework , as we now discuss . MODELS FOR TRUST - REGION METHODS If we set B k (cid:3) 0 in ( 2 . 12 ) and deﬁne the trust region using the Euclidean norm , the trust - region subproblem ( 2 . 11 ) becomes min p f k + p T ∇ f k subject to (cid:8) p (cid:8) 2 ≤ (cid:6) k . 26 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N We can write the solution to this problem in closed form as p k (cid:3) − (cid:6) k ∇ f k (cid:8)∇ f k (cid:8) . This is simply a steepest descent step in which the step length is determined by the trust - regionradius ; thetrust - regionandlinesearchapproachesareessentiallythesameinthiscase . A more interesting trust - region algorithm is obtained by choosing B k to be the exact Hessian ∇ 2 f k in the quadratic model ( 2 . 12 ) . Because of the trust - region restriction (cid:8) p (cid:8) 2 ≤ (cid:6) k , the subproblem ( 2 . 11 ) is guaranteed to have a solution even when ∇ 2 f k is not positive deﬁnite p k , as we see in Figure 2 . 4 . The trust - region Newton method has proved to be highly effective in practice , as we discuss in Chapter 7 . If the matrix B k in the quadratic model function m k of ( 2 . 12 ) is deﬁned by means of a quasi - Newton approximation , we obtain a trust - region quasi - Newton method . SCALING The performance of an algorithm may depend crucially on how the problem is formu - lated . Oneimportantissueinproblemformulationis scaling . Inunconstrainedoptimization , a problem is said to be poorly scaled if changes to x in a certain direction produce much larger variations in the value of f than do changes to x in another direction . A simple example is provided by the function f ( x ) (cid:3) 10 9 x 21 + x 22 , which is very sensitive to small changes in x 1 but not so sensitive to perturbations in x 2 . Poorly scaled functions arise , for example , in simulations of physical and chemical systems where different processes are taking place at very different rates . To be more speciﬁc , consider a chemical system in which four reactions occur . Associated with each reaction is a rate constant that describes the speed at which the reaction takes place . The optimization problem is to ﬁnd values for these rate constants by observing the concentrations of each chemicalinthesystematdifferenttimes . Thefourconstantsdiffergreatlyinmagnitude , since the reactions take place at vastly different speeds . Suppose we have the following rough esti - mates for the ﬁnal values of the constants , each correct to within , say , an order of magnitude : x 1 ≈ 10 − 10 , x 2 ≈ x 3 ≈ 1 , x 4 ≈ 10 5 . Before solving this problem we could introduce a new variable z deﬁned by ⎡ ⎢⎢⎢⎢⎣ x 1 x 2 x 3 x 4 ⎤ ⎥⎥⎥⎥⎦ (cid:3) ⎡ ⎢⎢⎢⎢⎣ 10 − 10 0 0 0 0 1 0 0 0 0 1 0 0 0 0 10 5 ⎤ ⎥⎥⎥⎥⎦ ⎡ ⎢⎢⎢⎢⎣ z 1 z 2 z 3 z 4 ⎤ ⎥⎥⎥⎥⎦ , and then deﬁne and solve the optimization problem in terms of the new variable z . The 2 . 2 . O V E R V I E W O F A L G O R I T H M S 27 ∆ k ∆ f k – f – Figure 2 . 7 Poorly scaled and well scaled problems , and performance of the steepest descent direction . optimal values of z will be within about an order of magnitude of 1 , making the solution more balanced . This kind of scaling of the variables is known as diagonal scaling . Scaling is performed ( sometimes unintentionally ) when the units used to represent variables are changed . During the modeling process , we may decide to change the units of some variables , say from meters to millimeters . If we do , the range of those variables and their size relative to the other variables will both change . Some optimization algorithms , such as steepest descent , are sensitive to poor scaling , while others , such as Newton’s method , are unaffected by it . Figure 2 . 7 shows the contours of two convex nearly quadratic functions , the ﬁrst of which is poorly scaled , while the second is well scaled . For the poorly scaled problem , the one with highly elongated contours , the steepest descent direction does not yield much reduction in the function , while for the well - scaled problem it performs much better . In both cases , Newton’s method will produce a much better step , since the second - order quadratic model ( m k in ( 2 . 14 ) ) happens to be a good approximation of f . Algorithms that are not sensitive to scaling are preferable , because they can handle poor problem formulations in a more robust fashion . In designing complete algorithms , we try to incorporate scale invariance into all aspects of the algorithm , including the line search or trust - region strategies and convergence tests . Generally speaking , it is easier to preserve scale invariance for line search algorithms than for trust - region algorithms . ✐ E X E R C I S E S ✐ 2 . 1 Compute the gradient ∇ f ( x ) and Hessian ∇ 2 f ( x ) of the Rosenbrock function f ( x ) (cid:3) 100 ( x 2 − x 2 1 ) 2 + ( 1 − x 1 ) 2 . ( 2 . 22 ) 28 C H A P T E R 2 . F U N D A M E N T A L S O F U N C O N S T R A I N E D O P T I M I Z A T I O N Show that x ∗ (cid:3) ( 1 , 1 ) T is the only local minimizer of this function , and that the Hessian matrix at that point is positive deﬁnite . ✐ 2 . 2 Show that the function f ( x ) (cid:3) 8 x 1 + 12 x 2 + x 21 − 2 x 22 has only one stationary point , and that it is neither a maximum or minimum , but a saddle point . Sketch the contour lines of f . ✐ 2 . 3 Let a be a given n - vector , and A be a given n × n symmetric matrix . Compute the gradient and Hessian of f 1 ( x ) (cid:3) a T x and f 2 ( x ) (cid:3) x T Ax . ✐ 2 . 4 Write the second - order Taylor expansion ( 2 . 6 ) for the function cos ( 1 / x ) around a nonzero point x , and the third - order Taylor expansion of cos ( x ) around any point x . Evaluate the second expansion for the speciﬁc case of x (cid:3) 1 . ✐ 2 . 5 Consider the function f : IR 2 → IR deﬁned by f ( x ) (cid:3) (cid:8) x (cid:8) 2 . Show that the sequence of iterates { x k } deﬁned by x k (cid:3) (cid:17) 1 + 1 2 k (cid:18) (cid:1) cos k sin k (cid:2) satisﬁes f ( x k + 1 ) < f ( x k ) for k (cid:3) 0 , 1 , 2 , . . . . Show that every point on the unit circle { x | (cid:8) x (cid:8) 2 (cid:3) 1 } is a limit point for { x k } . Hint : Every value θ ∈ [ 0 , 2 π ] is a limit point of the subsequence { ξ k } deﬁned by ξ k (cid:3) k ( mod 2 π ) (cid:3) k − 2 π (cid:19) k 2 π (cid:20) , where the operator (cid:16)·(cid:17) denotes rounding down to the next integer . ✐ 2 . 6 Prove that all isolated local minimizers are strict . ( Hint : Take an isolated local minimizer x ∗ and a neighborhood N . Show that for any x ∈ N , x (cid:9)(cid:3) x ∗ we must have f ( x ) > f ( x ∗ ) . ) ✐ 2 . 7 Suppose that f ( x ) (cid:3) x T Qx , where Q is an n × n symmetric positive semideﬁnite matrix . Show using the deﬁnition ( 1 . 4 ) that f ( x ) is convex on the domain IR n . Hint : It may be convenient to prove the following equivalent inequality : f ( y + α ( x − y ) ) − α f ( x ) − ( 1 − α ) f ( y ) ≤ 0 , for all α ∈ [ 0 , 1 ] and all x , y ∈ IR n . ✐ 2 . 8 Suppose that f is a convex function . Show that the set of global minimizers of f is a convex set . 2 . 2 . O V E R V I E W O F A L G O R I T H M S 29 ✐ 2 . 9 Consider the function f ( x 1 , x 2 ) (cid:3) (cid:7) x 1 + x 22 (cid:8) 2 . At the point x T (cid:3) ( 1 , 0 ) we consider the search direction p T (cid:3) ( − 1 , 1 ) . Show that p is a descent direction and ﬁnd all minimizers of the problem ( 2 . 10 ) . ✐ 2 . 10 Suppose that ˜ f ( z ) (cid:3) f ( x ) , where x (cid:3) Sz + s for some S ∈ IR n × n and s ∈ IR n . Show that ∇ ˜ f ( z ) (cid:3) S T ∇ f ( x ) , ∇ 2 ˜ f ( z ) (cid:3) S T ∇ 2 f ( x ) S . ( Hint : Use the chain rule to express d ˜ f / dz j in terms of d f / dx i and dx i / dz j for all i , j (cid:3) 1 , 2 , . . . , n . ) ✐ 2 . 11 Show that the symmetric rank - one update ( 2 . 18 ) and the BFGS update ( 2 . 19 ) are scale - invariant if the initial Hessian approximations B 0 are chosen appropriately . That is , using the notation of the previous exercise , show that if these methods are applied to f ( x ) starting from x 0 (cid:3) Sz 0 + s with initial Hessian B 0 , and to ˜ f ( z ) starting from z 0 with initial Hessian S T B 0 S , then all iterates are related by x k (cid:3) Sz k + s . ( Assume for simplicity that the methods take unit step lengths . ) ✐ 2 . 12 Suppose that a function f of two variables is poorly scaled at the solution x ∗ . Write two Taylor expansions of f around x ∗ —one along each coordinate direction—and use them to show that the Hessian ∇ 2 f ( x ∗ ) is ill - conditioned . ✐ 2 . 13 ( For this and the following three questions , refer to the material on “Rates of Convergence” in Section A . 2 of the Appendix . ) Show that the sequence x k (cid:3) 1 / k is not Q - linearly convergent , though it does converge to zero . ( This is called sublinear convergence . ) ✐ 2 . 14 Show that the sequence x k (cid:3) 1 + ( 0 . 5 ) 2 k is Q - quadratically convergent to 1 . ✐ 2 . 15 Does the sequence x k (cid:3) 1 / k ! converge Q - superlinearly ? Q - quadratically ? ✐ 2 . 16 Consider the sequence { x k } deﬁned by x k (cid:3) (cid:21) (cid:7) 14 (cid:8) 2 k , k even , ( x k − 1 ) / k , k odd . Is this sequence Q - superlinearly convergent ? Q - quadratically convergent ? R - quadratically convergent ? This is pag Printer : O C H A P T E R 3 Line Search Methods Each iteration of a line search method computes a search direction p k and then decides how far to move along that direction . The iteration is given by x k + 1 (cid:3) x k + α k p k , ( 3 . 1 ) where the positive scalar α k is called the step length . The success of a line search method depends on effective choices of both the direction p k and the step length α k . Most line search algorithms require p k to be a descent direction —one for which p Tk ∇ f k < 0—because this property guarantees that the function f can be reduced along 3 . 1 . S T E P L E N G T H 31 this direction , as discussed in the previous chapter . Moreover , the search direction often has the form p k (cid:3) − B − 1 k ∇ f k , ( 3 . 2 ) where B k is a symmetric and nonsingular matrix . In the steepest descent method , B k is simply the identity matrix I , while in Newton’s method , B k is the exact Hessian ∇ 2 f ( x k ) . In quasi - Newton methods , B k is an approximation to the Hessian that is updated at every iteration by means of a low - rank formula . When p k is deﬁned by ( 3 . 2 ) and B k is positive deﬁnite , we have p Tk ∇ f k (cid:3) −∇ f Tk B − 1 k ∇ f k < 0 , and therefore p k is a descent direction . In this chapter , we discuss how to choose α k and p k to promote convergence from remote starting points . We also study the rate of convergence of steepest descent , quasi - Newton , andNewtonmethods . SincethepureNewtoniterationisnotguaranteedtoproduce descentdirectionswhenthecurrentiterateisnotclosetoasolution , wediscussmodiﬁcations in Section 3 . 4 that allow it to start from any initial point . We now give careful consideration to the choice of the step - length parameter α k . 3 . 1 STEP LENGTH In computing the step length α k , we face a tradeoff . We would like to choose α k to give a substantial reduction of f , but at the same time we do not want to spend too much time making the choice . The ideal choice would be the global minimizer of the univariate function φ ( · ) deﬁned by φ ( α ) (cid:3) f ( x k + α p k ) , α > 0 , ( 3 . 3 ) but in general , it is too expensive to identify this value ( see Figure 3 . 1 ) . To ﬁnd even a local minimizer of φ to moderate precision generally requires too many evaluations of the objec - tive function f and possibly the gradient ∇ f . More practical strategies perform an inexact line search to identify a step length that achieves adequate reductions in f at minimal cost . Typical line search algorithms try out a sequence of candidate values for α , stopping to accept one of these values when certain conditions are satisﬁed . The line search is done in two stages : A bracketing phase ﬁnds an interval containing desirable step lengths , and a bisection or interpolation phase computes a good step length within this interval . Sophisticated line search algorithms can be quite complicated , so we defer a full description until Section 3 . 5 . 32 C H A P T E R 3 . L I N E S E A R C H M E T H O D S ( φ α ) pointstationaryfirst minimizer local first global minimizer α Figure 3 . 1 The ideal step length is the global minimizer . We now discuss various termination conditions for line search algorithms and show that effective step lengths need not lie near minimizers of the univariate function φ ( α ) deﬁned in ( 3 . 3 ) . A simple condition we could impose on α k is to require a reduction in f , that is , f ( x k + α k p k ) < f ( x k ) . That this requirement is not enough to produce convergence to x ∗ is illustrated in Figure 3 . 2 , for which the minimum function value is f ∗ (cid:3) − 1 , but a sequence of iterates { x k } for which f ( x k ) (cid:3) 5 / k , k (cid:3) 0 , 1 , . . . yields a decrease at each iteration but has a limiting function value of zero . The insufﬁcient reduction in f at each step causes it to fail to converge to the minimizer of this convex function . To avoid this behavior we need to enforce a sufﬁcient decrease condition , a concept we discuss next . 2 x 0 x 1 x x x f ( ) Figure 3 . 2 Insufﬁcient reduction in f . 3 . 1 . S T E P L E N G T H 33 THE WOLFE CONDITIONS A popular inexact line search condition stipulates that α k should ﬁrst of all give sufﬁcient decrease in the objective function f , as measured by the following inequality : f ( x k + α p k ) ≤ f ( x k ) + c 1 α ∇ f Tk p k , ( 3 . 4 ) for some constant c 1 ∈ ( 0 , 1 ) . In other words , the reduction in f should be proportional to both the step length α k and the directional derivative ∇ f Tk p k . Inequality ( 3 . 4 ) is sometimes called the Armijo condition . The sufﬁcient decrease condition is illustrated in Figure 3 . 3 . The right - hand - side of ( 3 . 4 ) , which is a linear function , can be denoted by l ( α ) . The function l ( · ) has negative slope c 1 ∇ f Tk p k , but because c 1 ∈ ( 0 , 1 ) , it lies above the graph of φ for small positive values of α . The sufﬁcient decrease condition states that α is acceptable only if φ ( α ) ≤ l ( α ) . The intervals on which this condition is satisﬁed are shown in Figure 3 . 3 . In practice , c 1 is chosen to be quite small , say c 1 (cid:3) 10 − 4 . The sufﬁcient decrease condition is not enough by itself to ensure that the algorithm makes reasonable progress because , as we see from Figure 3 . 3 , it is satisﬁed for all sufﬁciently small values of α . To rule out unacceptably short steps we introduce a second requirement , called the curvature condition , which requires α k to satisfy ∇ f ( x k + α k p k ) T p k ≥ c 2 ∇ f Tk p k , ( 3 . 5 ) for some constant c 2 ∈ ( c 1 , 1 ) , where c 1 is the constant from ( 3 . 4 ) . Note that the left - hand - side is simply the derivative φ (cid:14) ( α k ) , so the curvature condition ensures that the slope of φ at α k is greater than c 2 times the initial slope φ (cid:14) ( 0 ) . This makes sense because if the slope φ (cid:14) ( α ) α l ( ) φ ( α f ( x + ) = k α k p ) acceptable acceptable α Figure 3 . 3 Sufﬁcient decrease condition . 34 C H A P T E R 3 . L I N E S E A R C H M E T H O D S desired slope k ) φ ( α ) = f ( x k + α p tangent α acceptable acceptable Figure 3 . 4 The curvature condition . is strongly negative , we have an indication that we can reduce f signiﬁcantly by moving further along the chosen direction . On the other hand , if φ (cid:14) ( α k ) is only slightly negative or even positive , it is a sign that we cannot expect much more decrease in f in this direction , so it makes sense to terminate the line search . The curvature condition is illustrated in Figure 3 . 4 . Typical values of c 2 are 0 . 9 when the search direction p k is chosen by a Newton or quasi - Newton method , and 0 . 1 when p k is obtained from a nonlinear conjugate gradient method . The sufﬁcient decrease and curvature conditions are known collectively as the Wolfe conditions . We illustrate them in Figure 3 . 5 and restate them here for future reference : f ( x k + α k p k ) ≤ f ( x k ) + c 1 α k ∇ f T k p k , ( 3 . 6a ) ∇ f ( x k + α k p k ) T p k ≥ c 2 ∇ f Tk p k , ( 3 . 6b ) with 0 < c 1 < c 2 < 1 . A step length may satisfy the Wolfe conditions without being particularly close to a minimizer of φ , as we show in Figure 3 . 5 . We can , however , modify the curvature condition to force α k to lie in at least a broad neighborhood of a local minimizer or stationary point of φ . The strong Wolfe conditions require α k to satisfy f ( x k + α k p k ) ≤ f ( x k ) + c 1 α k ∇ f T k p k , ( 3 . 7a ) | ∇ f ( x k + α k p k ) T p k | ≤ c 2 | ∇ f Tk p k | , ( 3 . 7b ) with 0 < c 1 < c 2 < 1 . The only difference with the Wolfe conditions is that we no longer allow the derivative φ (cid:14) ( α k ) to be too positive . Hence , we exclude points that are far from stationary points of φ . 3 . 1 . S T E P L E N G T H 35 slopedesired line of sufficient decrease l ( α ) acceptable α φ ( α ) = α p f ( x + k k ) acceptable Figure 3 . 5 Step lengths satisfying the Wolfe conditions . It is not difﬁcult to prove that there exist step lengths that satisfy the Wolfe conditions for every function f that is smooth and bounded below . Lemma 3 . 1 . Suppose that f : IR n → IR is continuously differentiable . Let p k be a descent direction at x k , and assume that f is bounded below along the ray { x k + α p k | α > 0 } . Then if 0 < c 1 < c 2 < 1 , there exist intervals of step lengths satisfying the Wolfe conditions ( 3 . 6 ) and the strong Wolfe conditions ( 3 . 7 ) . P ROOF . Note that φ ( α ) (cid:3) f ( x k + α p k ) is bounded below for all α > 0 . Since 0 < c 1 < 1 , the line l ( α ) (cid:3) f ( x k ) + α c 1 ∇ f Tk p k is unbounded below and must therefore intersect the graph of φ at least once . Let α (cid:14) > 0 be the smallest intersecting value of α , that is , f ( x k + α (cid:14) p k ) (cid:3) f ( x k ) + α (cid:14) c 1 ∇ f Tk p k . ( 3 . 8 ) The sufﬁcient decrease condition ( 3 . 6a ) clearly holds for all step lengths less than α (cid:14) . By the mean value theorem ( see ( A . 55 ) ) , there exists α (cid:14)(cid:14) ∈ ( 0 , α (cid:14) ) such that f ( x k + α (cid:14) p k ) − f ( x k ) (cid:3) α (cid:14) ∇ f ( x k + α (cid:14)(cid:14) p k ) T p k . ( 3 . 9 ) By combining ( 3 . 8 ) and ( 3 . 9 ) , we obtain ∇ f ( x k + α (cid:14)(cid:14) p k ) T p k (cid:3) c 1 ∇ f Tk p k > c 2 ∇ f Tk p k , ( 3 . 10 ) since c 1 < c 2 and ∇ f Tk p k < 0 . Therefore , α (cid:14)(cid:14) satisﬁes the Wolfe conditions ( 3 . 6 ) , and the inequalities hold strictly in both ( 3 . 6a ) and ( 3 . 6b ) . Hence , by our smoothness assumption on f , there is an interval around α (cid:14)(cid:14) for which the Wolfe conditions hold . Moreover , since 36 C H A P T E R 3 . L I N E S E A R C H M E T H O D S the term in the left - hand side of ( 3 . 10 ) is negative , the strong Wolfe conditions ( 3 . 7 ) hold in the same interval . (cid:1) The Wolfe conditions are scale - invariant in a broad sense : Multiplying the objective function by a constant or making an afﬁne change of variables does not alter them . They can be used in most line search methods , and are particularly important in the implementation of quasi - Newton methods , as we see in Chapter 6 . THE GOLDSTEIN CONDITIONS Like the Wolfe conditions , the Goldstein conditions ensure that the step length α achieves sufﬁcient decrease but is not too short . The Goldstein conditions can also be stated as a pair of inequalities , in the following way : f ( x k ) + ( 1 − c ) α k ∇ f Tk p k ≤ f ( x k + α k p k ) ≤ f ( x k ) + c α k ∇ f Tk p k , ( 3 . 11 ) with 0 < c < 1 / 2 . The second inequality is the sufﬁcient decrease condition ( 3 . 4 ) , whereas the ﬁrst inequality is introduced to control the step length from below ; see Figure 3 . 6 A disadvantage of the Goldstein conditions vis - ` a - vis the Wolfe conditions is that the ﬁrst inequality in ( 3 . 11 ) may exclude all minimizers of φ . However , the Goldstein and Wolfe conditions have much in common , and their convergence theories are quite similar . The Goldstein conditions are often used in Newton - type methods but are not well suited for quasi - Newton methods that maintain a positive deﬁnite Hessian approximation . f kT p k c α T p k k α ( 1 _ c ) f φ ( = f ( x k + α p α ) k ) acceptable steplengths α Figure 3 . 6 The Goldstein conditions . 3 . 2 . C O N V E R G E N C E O F L I N E S E A R C H M E T H O D S 37 SUFFICIENT DECREASE AND BACKTRACKING We have mentioned that the sufﬁcient decrease condition ( 3 . 6a ) alone is not sufﬁcient to ensure that the algorithm makes reasonable progress along the given search direction . However , if the line search algorithm chooses its candidate step lengths appropriately , by using a so - called backtracking approach , we can dispense with the extra condition ( 3 . 6b ) and use just the sufﬁcient decrease condition to terminate the line search procedure . In its most basic form , backtracking proceeds as follows . Algorithm 3 . 1 ( Backtracking Line Search ) . Choose ¯ α > 0 , ρ ∈ ( 0 , 1 ) , c ∈ ( 0 , 1 ) ; Set α ← ¯ α ; repeat until f ( x k + α p k ) ≤ f ( x k ) + c α ∇ f Tk p k α ← ρα ; end ( repeat ) Terminate with α k (cid:3) α . In this procedure , the initial step length ¯ α is chosen to be 1 in Newton and quasi - Newton methods , but can have different values in other algorithms such as steepest descent or conjugate gradient . An acceptable step length will be found after a ﬁnite number of trials , because α k will eventually become small enough that the sufﬁcient decrease condition holds ( see Figure 3 . 3 ) . In practice , the contraction factor ρ is often allowed to vary at each iteration of the line search . For example , it can be chosen by safeguarded interpolation , as we describe later . We need ensure only that at each iteration we have ρ ∈ [ ρ lo , ρ hi ] , for some ﬁxed constants 0 < ρ lo < ρ hi < 1 . The backtracking approach ensures either that the selected step length α k is some ﬁxed value ( the initial choice ¯ α ) , or else that it is short enough to satisfy the sufﬁcient decrease condition but not too short . The latter claim holds because the accepted value α k is within a factor ρ of the previous trial value , α k / ρ , which was rejected for violating the sufﬁcient decrease condition , that is , for being too long . This simple and popular strategy for terminating a line search is well suited for Newton methods but is less appropriate for quasi - Newton and conjugate gradient methods . 3 . 2 CONVERGENCE OF LINE SEARCH METHODS To obtain global convergence , we must not only have well chosen step lengths but also well chosen search directions p k . We discuss requirements on the search direction in this section , focusing on one key property : the angle θ k between p k and the steepest descent direction −∇ f k , deﬁned by cos θ k (cid:3) −∇ f T k p k (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) . ( 3 . 12 ) 38 C H A P T E R 3 . L I N E S E A R C H M E T H O D S Thefollowingtheorem , duetoZoutendijk , hasfar - reachingconsequences . Itquantiﬁes theeffectofproperlychosensteplengths α k , andshows , forexample , thatthesteepestdescent method is globally convergent . For other algorithms , it describes how far p k can deviate from the steepest descent direction and still produce a globally convergent iteration . Various line search termination conditions can be used to establish this result , but for concreteness we will consider only the Wolfe conditions ( 3 . 6 ) . Though Zoutendijk’s result appears at ﬁrst to be technical and obscure , its power will soon become evident . Theorem 3 . 2 . Consider any iteration of the form ( 3 . 1 ) , where p k is a descent direction and α k satisﬁes the Wolfe conditions ( 3 . 6 ) . Suppose that f is bounded below in IR n and that f is continuously differentiable in an open set N containing the level set L def (cid:3) { x : f ( x ) ≤ f ( x 0 ) } , where x 0 is the starting point of the iteration . Assume also that the gradient ∇ f is Lipschitz continuous on N , that is , there exists a constant L > 0 such that (cid:8)∇ f ( x ) − ∇ f ( ˜ x ) (cid:8) ≤ L (cid:8) x − ˜ x (cid:8) , for all x , ˜ x ∈ N . ( 3 . 13 ) Then (cid:3) k ≥ 0 cos 2 θ k (cid:8)∇ f k (cid:8) 2 < ∞ . ( 3 . 14 ) P ROOF . From ( 3 . 6b ) and ( 3 . 1 ) we have that ( ∇ f k + 1 − ∇ f k ) T p k ≥ ( c 2 − 1 ) ∇ f Tk p k , while the Lipschitz condition ( 3 . 13 ) implies that ( ∇ f k + 1 − ∇ f k ) T p k ≤ α k L (cid:8) p k (cid:8) 2 . By combining these two relations , we obtain α k ≥ c 2 − 1 L ∇ f Tk p k (cid:8) p k (cid:8) 2 . By substituting this inequality into the ﬁrst Wolfe condition ( 3 . 6a ) , we obtain f k + 1 ≤ f k − c 1 1 − c 2 L ( ∇ f Tk p k ) 2 (cid:8) p k (cid:8) 2 . From the deﬁnition ( 3 . 12 ) , we can write this relation as f k + 1 ≤ f k − c cos 2 θ k (cid:8)∇ f k (cid:8) 2 , 3 . 2 . C O N V E R G E N C E O F L I N E S E A R C H M E T H O D S 39 where c (cid:3) c 1 ( 1 − c 2 ) / L . By summing this expression over all indices less than or equal to k , we obtain f k + 1 ≤ f 0 − c k (cid:3) j (cid:3) 0 cos 2 θ j (cid:8)∇ f j (cid:8) 2 . ( 3 . 15 ) Since f is bounded below , we have that f 0 − f k + 1 is less than some positive constant , for all k . Hence , by taking limits in ( 3 . 15 ) , we obtain ∞ (cid:3) k (cid:3) 0 cos 2 θ k (cid:8)∇ f k (cid:8) 2 < ∞ , which concludes the proof . (cid:1) Similar results to this theorem hold when the Goldstein conditions ( 3 . 11 ) or strong Wolfe conditions ( 3 . 7 ) are used in place of the Wolfe conditions . For all these strategies , the step length selection implies inequality ( 3 . 14 ) , which we call the Zoutendijk condition . NotethattheassumptionsofTheorem3 . 2arenottoorestrictive . Ifthefunction f were not bounded below , the optimization problem would not be well deﬁned . The smoothness assumption—Lipschitz continuity of the gradient—is implied by many of the smoothness conditions that are used in local convergence theorems ( see Chapters 6 and 7 ) and are often satisﬁed in practice . The Zoutendijk condition ( 3 . 14 ) implies that cos 2 θ k (cid:8)∇ f k (cid:8) 2 → 0 . ( 3 . 16 ) This limit can be used in turn to derive global convergence results for line search algorithms . If our method for choosing the search direction p k in the iteration ( 3 . 1 ) ensures that the angle θ k deﬁned by ( 3 . 12 ) is bounded away from 90 ◦ , there is a positive constant δ such that cos θ k ≥ δ > 0 , for all k . ( 3 . 17 ) It follows immediately from ( 3 . 16 ) that lim k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . ( 3 . 18 ) In other words , we can be sure that the gradient norms (cid:8)∇ f k (cid:8) converge to zero , provided that the search directions are never too close to orthogonality with the gradient . In particular , the method of steepest descent ( for which the search direction p k is parallel to the negative 40 C H A P T E R 3 . L I N E S E A R C H M E T H O D S gradient ) produces a gradient sequence that converges to zero , provided that it uses a line search satisfying the Wolfe or Goldstein conditions . We use the term globally convergent to refer to algorithms for which the property ( 3 . 18 ) is satisﬁed , but note that this term is sometimes used in other contexts to mean different things . For line search methods of the general form ( 3 . 1 ) , the limit ( 3 . 18 ) is the strongest global convergence result that can be obtained : We cannot guarantee that the method converges to a minimizer , but only that it is attracted by stationary points . Only by making additional requirements on the search direction p k —by introducing negative curvature information from the Hessian ∇ 2 f ( x k ) , for example—can we strengthen these results to include convergence to a local minimum . See the Notes and References at the end of this chapter for further discussion of this point . Consider now the Newton - like method ( 3 . 1 ) , ( 3 . 2 ) and assume that the matrices B k are positive deﬁnite with a uniformly bounded condition number . That is , there is a constant M such that (cid:8) B k (cid:8) (cid:8) B − 1 k (cid:8) ≤ M , for all k . It is easy to show from the deﬁnition ( 3 . 12 ) that cos θ k ≥ 1 / M ( 3 . 19 ) ( see Exercise 3 . 5 ) . By combining this bound with ( 3 . 16 ) we ﬁnd that lim k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . ( 3 . 20 ) Therefore , we have shown that Newton and quasi - Newton methods are globally convergent if the matrices B k have a bounded condition number and are positive deﬁnite ( which is needed to ensure that p k is a descent direction ) , and if the step lengths satisfy the Wolfe conditions . For some algorithms , such as conjugate gradient methods , we will be able to prove the limit ( 3 . 18 ) , but only the weaker result lim inf k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . ( 3 . 21 ) In other words , just a subsequence of the gradient norms (cid:8)∇ f k j (cid:8) converges to zero , rather than the whole sequence ( see Appendix A ) . This result , too , can be proved by using Zou - tendijk’s condition ( 3 . 14 ) , but instead of a constructive proof , we outline a proof by contradiction . Suppose that ( 3 . 21 ) does not hold , so that the gradients remain bounded away from zero , that is , there exists γ > 0 such that (cid:8)∇ f k (cid:8) ≥ γ , for all k sufﬁciently large . ( 3 . 22 ) 3 . 3 . R A T E O F C O N V E R G E N C E 41 Then from ( 3 . 16 ) we conclude that cos θ k → 0 , ( 3 . 23 ) that is , the entire sequence { cos θ k } converges to 0 . To establish ( 3 . 21 ) , therefore , it is enough to show that a subsequence { cos θ k j } is bounded away from zero . We will use this strategy in Chapter 5 to study the convergence of nonlinear conjugate gradient methods . By applying this proof technique , we can prove global convergence in the sense of ( 3 . 20 ) or ( 3 . 21 ) for a general class of algorithms . Consider any algorithm for which ( i ) every iteration produces a decrease in the objective function , and ( ii ) every m th iteration is a steepest descent step , with step length chosen to satisfy the Wolfe or Goldstein conditions . Then , since cos θ k (cid:3) 1 for the steepest descent steps , the result ( 3 . 21 ) holds . Of course , we would design the algorithm so that it does something “better " than steepest descent at the other m − 1 iterates . The occasional steepest descent steps may not make much progress , but they at least guarantee overall global convergence . Note that throughout this section we have used only the fact that Zoutendijk’s condi - tion implies the limit ( 3 . 16 ) . In later chapters we will make use of the bounded sum condition ( 3 . 14 ) , which forces the sequence { cos 2 θ k (cid:8)∇ f k (cid:8) 2 } to converge to zero at a sufﬁciently rapid rate . 3 . 3 RATE OF CONVERGENCE It would seem that designing optimization algorithms with good convergence properties is easy , since all we need to ensure is that the search direction p k does not tend to become orthogonal to the gradient ∇ f k , or that steepest descent steps are taken regularly . We could simply compute cos θ k at every iteration and turn p k toward the steepest descent direction if cos θ k is smaller than some preselected constant δ > 0 . Angle tests of this type ensure global convergence , but they are undesirable for two reasons . First , they may impede a fast rate of convergence , because for problems with an ill - conditioned Hessian , it may be necessary to produce search directions that are almost orthogonal to the gradient , and an inappropriate choice of the parameter δ may cause such steps to be rejected . Second , angle tests destroy the invariance properties of quasi - Newton methods . Algorithmic strategies that achieve rapid convergence can sometimes conﬂict with the requirements of global convergence , and vice versa . For example , the steepest descent method is the quintessential globally convergent algorithm , but it is quite slow in practice , as we shall see below . On the other hand , the pure Newton iteration converges rapidly when started close enough to a solution , but its steps may not even be descent directions away from the solution . The challenge is to design algorithms that incorporate both properties : good global convergence guarantees and a rapid rate of convergence . We begin our study of convergence rates of line search methods by considering the most basic approach of all : the steepest descent method . 42 C H A P T E R 3 . L I N E S E A R C H M E T H O D S Figure 3 . 7 Steepest descent steps . CONVERGENCE RATE OF STEEPEST DESCENT We can learn much about the steepest descent method by considering the ideal case , in which the objective function is quadratic and the line searches are exact . Let us suppose that f ( x ) (cid:3) 12 x T Qx − b T x , ( 3 . 24 ) where Q is symmetric and positive deﬁnite . The gradient is given by ∇ f ( x ) (cid:3) Qx − b and the minimizer x ∗ is the unique solution of the linear system Qx (cid:3) b . Itiseasytocomputethesteplength α k thatminimizes f ( x k − α ∇ f k ) . Bydifferentiating the function f ( x k − α ∇ f k ) (cid:3) 1 2 ( x k − α ∇ f k ) T Q ( x k − α ∇ f k ) − b T ( x k − α ∇ f k ) with respect to α , and setting the derivative to zero , we obtain α k (cid:3) ∇ f Tk ∇ f k ∇ f Tk Q ∇ f k . ( 3 . 25 ) If we use this exact minimizer α k , the steepest descent iteration for ( 3 . 24 ) is given by x k + 1 (cid:3) x k − (cid:17) ∇ f Tk ∇ f k ∇ f Tk Q ∇ f k (cid:18) ∇ f k . ( 3 . 26 ) Since ∇ f k (cid:3) Qx k − b , this equation yields a closed - form expression for x k + 1 in terms of x k . In Figure 3 . 7 we plot a typical sequence of iterates generated by the steepest descent method on a two - dimensional quadratic objective function . The contours of f are ellipsoids whose 3 . 3 . R A T E O F C O N V E R G E N C E 43 axes lie along the orthogonal eigenvectors of Q . Note that the iterates zigzag toward the solution . To quantify the rate of convergence we introduce the weighted norm (cid:8) x (cid:8) 2 Q (cid:3) x T Qx . By using the relation Qx ∗ (cid:3) b , we can show that 12 (cid:8) x − x ∗ (cid:8) 2 Q (cid:3) f ( x ) − f ( x ∗ ) , ( 3 . 27 ) so this norm measures the difference between the current objective value and the optimal value . By using the equality ( 3 . 26 ) and noting that ∇ f k (cid:3) Q ( x k − x ∗ ) , we can derive the equality (cid:8) x k + 1 − x ∗ (cid:8) 2 Q (cid:3) (cid:21) 1 − (cid:7) ∇ f Tk ∇ f k (cid:8) 2 (cid:7) ∇ f Tk Q ∇ f k (cid:8) (cid:7) ∇ f Tk Q − 1 ∇ f k (cid:8) (cid:22) (cid:8) x k − x ∗ (cid:8) 2 Q ( 3 . 28 ) ( see Exercise 3 . 7 ) . This expression describes the exact decrease in f at each iteration , but since the term inside the brackets is difﬁcult to interpret , it is more useful to bound it in terms of the condition number of the problem . Theorem 3 . 3 . When the steepest descent method with exact line searches ( 3 . 26 ) is applied to the strongly convex quadratic function ( 3 . 24 ) , the error norm ( 3 . 27 ) satisﬁes (cid:8) x k + 1 − x ∗ (cid:8) 2 Q ≤ (cid:17) λ n − λ 1 λ n + λ 1 (cid:18) 2 (cid:8) x k − x ∗ (cid:8) 2 Q , ( 3 . 29 ) where 0 < λ 1 ≤ λ 2 ≤ · · · ≤ λ n are the eigenvalues of Q . The proof of this result is given by Luenberger [ 195 ] . The inequalities ( 3 . 29 ) and ( 3 . 27 ) show that the function values f k converge to the minimum f ∗ at a linear rate . As a special case of this result , we see that convergence is achieved in one iteration if all the eigenvalues are equal . In this case , Q is a multiple of the identity matrix , so the contours in Figure 3 . 7 are circles and the steepest descent direction always points at the solution . In general , as the condition number κ ( Q ) (cid:3) λ n / λ 1 increases , the contours of the quadratic become more elongated , the zigzagging in Figure 3 . 7 becomes more pronounced , and ( 3 . 29 ) implies that the convergence degrades . Even though ( 3 . 29 ) is a worst - case bound , it gives an accurate indication of the behavior of the algorithm when n > 2 . The rate - of - convergence behavior of the steepest descent method is essentially the same on general nonlinear objective functions . In the following result we assume that the step length is the global minimizer along the search direction . Theorem 3 . 4 . Suppose that f : IR n → IR is twice continuously differentiable , and that the iterates generated by the steepest - descent method with exact line searches converge to a point x ∗ at 44 C H A P T E R 3 . L I N E S E A R C H M E T H O D S which the Hessian matrix ∇ 2 f ( x ∗ ) is positive deﬁnite . Let r be any scalar satisfying r ∈ (cid:17) λ n − λ 1 λ n + λ 1 , 1 (cid:18) , where λ 1 ≤ λ 2 ≤ · · · ≤ λ n are the eigenvalues of ∇ 2 f ( x ∗ ) . Then for all k sufﬁciently large , we have f ( x k + 1 ) − f ( x ∗ ) ≤ r 2 [ f ( x k ) − f ( x ∗ ) ] . In general , we cannot expect the rate of convergence to improve if an inexact line search is used . Therefore , Theorem 3 . 4 shows that the steepest descent method can have an unacceptablyslowrateofconvergence , evenwhentheHessianisreasonablywellconditioned . For example , if κ ( Q ) (cid:3) 800 , f ( x 1 ) (cid:3) 1 , and f ( x ∗ ) (cid:3) 0 , Theorem 3 . 4 suggests that the function value will still be about 0 . 08 after one thousand iterations of the steepest descent method with exact line search . NEWTON’S METHOD We now consider the Newton iteration , for which the search is given by p N k (cid:3) −∇ 2 f − 1 k ∇ f k . ( 3 . 30 ) Since the Hessian matrix ∇ 2 f k may not always be positive deﬁnite , p N k may not always be a descent direction , and many of the ideas discussed so far in this chapter no longer apply . In Section 3 . 4 and Chapter 4 we will describe two approaches for obtaining a globally convergent iteration based on the Newton step : a line search approach , in which the Hessian ∇ 2 f k is modiﬁed , if necessary , to make it positive deﬁnite and thereby yield descent , and a trust region approach , in which ∇ 2 f k is used to form a quadratic model that is minimized in a ball around the current iterate x k . Here we discuss just the local rate - of - convergence properties of Newton’s method . We know that for all x in the vicinity of a solution point x ∗ such that ∇ 2 f ( x ∗ ) is positive deﬁnite , the Hessian ∇ 2 f ( x ) will also be positive deﬁnite . Newton’s method will be well deﬁned in this region and will converge quadratically , provided that the step lengths α k are eventually always 1 . Theorem 3 . 5 . Supposethat f istwicedifferentiableandthattheHessian ∇ 2 f ( x ) isLipschitzcontinuous ( see ( A . 42 ) ) in a neighborhood of a solution x ∗ at which the sufﬁcient conditions ( Theorem 2 . 4 ) are satisﬁed . Consider the iteration x k + 1 (cid:3) x k + p k , where p k is given by ( 3 . 30 ) . Then ( i ) if the starting point x 0 is sufﬁciently close to x ∗ , the sequence of iterates converges to x ∗ ; ( ii ) the rate of convergence of { x k } is quadratic ; and ( iii ) the sequence of gradient norms { (cid:8)∇ f k (cid:8) } converges quadratically to zero . 3 . 3 . R A T E O F C O N V E R G E N C E 45 P ROOF . From the deﬁnition of the Newton step and the optimality condition ∇ f ∗ (cid:3) 0 we have that x k + p N k − x ∗ (cid:3) x k − x ∗ − ∇ 2 f − 1 k ∇ f k (cid:3) ∇ 2 f − 1 k (cid:9) ∇ 2 f k ( x k − x ∗ ) − ( ∇ f k − ∇ f ∗ ) (cid:10) . ( 3 . 31 ) Since Taylor’s theorem ( Theorem 2 . 1 ) tells us that ∇ f k − ∇ f ∗ (cid:3) (cid:6) 1 0 ∇ 2 f ( x k + t ( x ∗ − x k ) ) ( x k − x ∗ ) dt , we have (cid:23)(cid:23) ∇ 2 f ( x k ) ( x k − x ∗ ) − ( ∇ f k − ∇ f ( x ∗ ) ) (cid:23)(cid:23) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:6) 1 0 (cid:9) ∇ 2 f ( x k ) − ∇ 2 f ( x k + t ( x ∗ − x k ) ) (cid:10) ( x k − x ∗ ) dt (cid:23)(cid:23)(cid:23)(cid:23) ≤ (cid:6) 1 0 (cid:23)(cid:23) ∇ 2 f ( x k ) − ∇ 2 f ( x k + t ( x ∗ − x k ) ) (cid:23)(cid:23) (cid:8) x k − x ∗ (cid:8) dt ≤ (cid:8) x k − x ∗ (cid:8) 2 (cid:6) 1 0 Lt dt (cid:3) 12 L (cid:8) x k − x ∗ (cid:8) 2 , ( 3 . 32 ) where L is the Lipschitz constant for ∇ 2 f ( x ) for x near x ∗ . Since ∇ 2 f ( x ∗ ) is nonsingular , there is a radius r > 0 such that (cid:8)∇ 2 f − 1 k (cid:8) ≤ 2 (cid:8)∇ 2 f ( x ∗ ) − 1 (cid:8) for all x k with (cid:8) x k − x ∗ (cid:8) ≤ r . By substituting in ( 3 . 31 ) and ( 3 . 32 ) , we obtain (cid:8) x k + p N k − x ∗ (cid:8) ≤ L (cid:8)∇ 2 f ( x ∗ ) − 1 (cid:8)(cid:8) x k − x ∗ (cid:8) 2 (cid:3) ˜ L (cid:8) x k − x ∗ (cid:8) 2 , ( 3 . 33 ) where ˜ L (cid:3) L (cid:8)∇ 2 f ( x ∗ ) − 1 (cid:8) . Choosing x 0 so that (cid:8) x 0 − x ∗ (cid:8) ≤ min ( r , 1 / ( 2 ˜ L ) ) , we can use this inequality inductively to deduce that the sequence converges to x ∗ , and the rate of convergence is quadratic . By using the relations x k + 1 − x k (cid:3) p N k and ∇ f k + ∇ 2 f k p N k (cid:3) 0 , we obtain that (cid:8)∇ f ( x k + 1 ) (cid:8) (cid:3) (cid:8)∇ f ( x k + 1 ) − ∇ f k − ∇ 2 f ( x k ) p N k (cid:8) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:6) 1 0 ∇ 2 f ( x k + t p N k ) ( x k + 1 − x k ) dt − ∇ 2 f ( x k ) p N k (cid:23)(cid:23)(cid:23)(cid:23) ≤ (cid:6) 1 0 (cid:23)(cid:23) ∇ 2 f ( x k + t p N k ) − ∇ 2 f ( x k ) (cid:23)(cid:23) (cid:8) p N k (cid:8) dt ≤ 1 2 L (cid:8) p N k (cid:8) 2 ≤ 12 L (cid:8)∇ 2 f ( x k ) − 1 (cid:8) 2 (cid:8)∇ f k (cid:8) 2 ≤ 2 L (cid:8)∇ 2 f ( x ∗ ) − 1 (cid:8) 2 (cid:8)∇ f k (cid:8) 2 , proving that the gradient norms converge to zero quadratically . (cid:1) 46 C H A P T E R 3 . L I N E S E A R C H M E T H O D S As the iterates generated by Newton’s method approach the solution , the Wolfe ( or Goldstein ) conditions will accept the step length α k (cid:3) 1 for all large k . This observation follows from Theorem 3 . 6 below . Indeed , when the search direction is given by Newton’s method , the limit ( 3 . 35 ) is satisﬁed—the ratio is zero for all k ! Implementations of Newton’s method using these line search conditions , and in which the line search always tries the unit step length ﬁrst , will set α k (cid:3) 1 for all large k and attain a local quadratic rate of convergence . QUASI - NEWTON METHODS Suppose now that the search direction has the form p k (cid:3) − B − 1 k ∇ f k , ( 3 . 34 ) where the symmetric and positive deﬁnite matrix B k is updated at every iteration by a quasi - Newton updating formula . We already encountered one quasi - Newton formula , the BFGS formula , in Chapter 2 ; others will be discussed in Chapter 6 . We assume here that the step length α k is computed by an inexact line search that satisﬁes the Wolfe or strong Wolfe conditions , with the same proviso mentioned above for Newton’s method : The line search algorithm will always try the step length α (cid:3) 1 ﬁrst , and will accept this value if it satisﬁes the Wolfe conditions . ( We could enforce this condition by setting ¯ α (cid:3) 1 in Algorithm 3 . 1 , for example . ) This implementation detail turns out to be crucial in obtaining a fast rate of convergence . The following result shows that if the search direction of a quasi - Newton method approximates the Newton direction well enough , then the unit step length will satisfy the Wolfe conditions as the iterates converge to the solution . It also speciﬁes a condition that the search direction must satisfy in order to give rise to a superlinearly convergent iteration . To bring out the full generality of this result , we state it ﬁrst in terms of a general descent iteration , and then examine its consequences for quasi - Newton and Newton methods . Theorem 3 . 6 . Suppose that f : IR n → IR is twice continuously differentiable . Consider the iteration x k + 1 (cid:3) x k + α k p k , where p k is a descent direction and α k satisﬁes the Wolfe conditions ( 3 . 6 ) with c 1 ≤ 1 / 2 . If the sequence { x k } converges to a point x ∗ such that ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) is positive deﬁnite , and if the search direction satisﬁes lim k →∞ (cid:8)∇ f k + ∇ 2 f k p k (cid:8) (cid:8) p k (cid:8) (cid:3) 0 , ( 3 . 35 ) then ( i ) the step length α k (cid:3) 1 is admissible for all k greater than a certain index k 0 ; and ( ii ) if α k (cid:3) 1 for all k > k 0 , { x k } converges to x ∗ superlinearly . 3 . 3 . R A T E O F C O N V E R G E N C E 47 It is easy to see that if c 1 > 1 / 2 , then the line search would exclude the minimizer of a quadratic , and unit step lengths may not be admissible . If p k is a quasi - Newton search direction of the form ( 3 . 34 ) , then ( 3 . 35 ) is equivalent to lim k →∞ (cid:8) ( B k − ∇ 2 f ( x ∗ ) ) p k (cid:8) (cid:8) p k (cid:8) (cid:3) 0 . ( 3 . 36 ) Hence , we have the surprising ( and delightful ) result that a superlinear convergence rate can be attained even if the sequence of quasi - Newton matrices B k does not converge to ∇ 2 f ( x ∗ ) ; it sufﬁces that the B k become increasingly accurate approximations to ∇ 2 f ( x ∗ ) along the search directions p k . Importantly , condition ( 3 . 36 ) is both necessary and sufﬁcient for the superlinear convergence of quasi - Newton methods . Theorem 3 . 7 . Suppose that f : IR n → IR is twice continuously differentiable . Consider the iteration x k + 1 (cid:3) x k + p k ( that is , the step length α k is uniformly 1 ) and that p k is given by ( 3 . 34 ) . Let us assume also that { x k } converges to a point x ∗ such that ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) is positive deﬁnite . Then { x k } converges superlinearly if and only if ( 3 . 36 ) holds . P ROOF . We ﬁrst show that ( 3 . 36 ) is equivalent to p k − p N k (cid:3) o ( (cid:8) p k (cid:8) ) , ( 3 . 37 ) where p N k (cid:3) −∇ 2 f − 1 k ∇ f k is the Newton step . Assuming that ( 3 . 36 ) holds , we have that p k − p N k (cid:3) ∇ 2 f − 1 k ( ∇ 2 f k p k + ∇ f k ) (cid:3) ∇ 2 f − 1 k ( ∇ 2 f k − B k ) p k (cid:3) O ( (cid:8) ( ∇ 2 f k − B k ) p k (cid:8) ) (cid:3) o ( (cid:8) p k (cid:8) ) , where we have used the fact that (cid:8)∇ 2 f − 1 k (cid:8) is bounded above for x k sufﬁciently close to x ∗ , since the limiting Hessian ∇ 2 f ( x ∗ ) is positive deﬁnite . The converse follows readily if we multiply both sides of ( 3 . 37 ) by ∇ 2 f k and recall ( 3 . 34 ) . By combining ( 3 . 33 ) and ( 3 . 37 ) , we obtain that (cid:8) x k + p k − x ∗ (cid:8) ≤ (cid:8) x k + p N k − x ∗ (cid:8) + (cid:8) p k − p N k (cid:8) (cid:3) O ( (cid:8) x k − x ∗ (cid:8) 2 ) + o ( (cid:8) p k (cid:8) ) . A simple manipulation of this inequality reveals that (cid:8) p k (cid:8) (cid:3) O ( (cid:8) x k − x ∗ (cid:8) ) , so we obtain (cid:8) x k + p k − x ∗ (cid:8) ≤ o ( (cid:8) x k − x ∗ (cid:8) ) , giving the superlinear convergence result . (cid:1) 48 C H A P T E R 3 . L I N E S E A R C H M E T H O D S We will see in Chapter 6 that quasi - Newton methods normally satisfy condition ( 3 . 36 ) and are therefore superlinearly convergent . 3 . 4 NEWTON’S METHOD WITH HESSIAN MODIFICATION Away from the solution , the Hessian matrix ∇ 2 f ( x ) may not be positive deﬁnite , so the Newton direction p N k deﬁned by ∇ 2 f ( x k ) p N k (cid:3) −∇ f ( x k ) ( 3 . 38 ) ( see ( 3 . 30 ) ) may not be a descent direction . We now describe an approach to overcome this difﬁculty when a direct linear algebra technique , such as Gaussian elimination , is used to solve the Newton equations ( 3 . 38 ) . This approach obtains the step p k from a linear system identical to ( 3 . 38 ) , except that the coefﬁcient matrix is replaced with a positive deﬁnite approximation , formed before or during the solution process . The modiﬁed Hessian is obtained by adding either a positive diagonal matrix or a full matrix to the true Hessian ∇ 2 f ( x k ) . A general description of this method follows . Algorithm 3 . 2 ( Line Search Newton with Modiﬁcation ) . Given initial point x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Factorize the matrix B k (cid:3) ∇ 2 f ( x k ) + E k , where E k (cid:3) 0 if ∇ 2 f ( x k ) is sufﬁciently positive deﬁnite ; otherwise , E k is chosen to ensure that B k is sufﬁciently positive deﬁnite ; Solve B k p k (cid:3) −∇ f ( x k ) ; Set x k + 1 ← x k + α k p k , where α k satisﬁes the Wolfe , Goldstein , or Armijo backtracking conditions ; end Some approaches do not compute E k explicitly , but rather introduce extra steps and tests into standard factorization procedures , modifying these procedures “on the ﬂy” so that the computed factors are the factors of a positive deﬁnite matrix . Strategies based on modifying a Cholesky factorization and on modifying a symmetric indeﬁnite factorization of the Hessian are described in this section . Algorithm 3 . 2 is a practical Newton method that can be applied from any starting point . We can establish fairly satisfactory global convergence results for it , provided that the strategy for choosing E k ( and hence B k ) satisﬁes the bounded modiﬁed factorization property . This property is that the matrices in the sequence { B k } have bounded condition number whenever the sequence of Hessians { ∇ 2 f ( x k ) } is bounded ; that is , κ ( B k ) (cid:3) (cid:8) B k (cid:8) (cid:8) B − 1 k (cid:8) ≤ C , some C > 0 and all k (cid:3) 0 , 1 , 2 , . . . . ( 3 . 39 ) 3 . 4 . N E W T O N ’ S M E T H O D W I T H H E S S I A N M O D I F I C A T I O N 49 Ifthispropertyholds , globalconvergenceofthemodiﬁedlinesearchNewtonmethodfollows from the results of Section 3 . 2 . Theorem 3 . 8 . Let f be twice continuously differentiable on an open set D , and assume that the starting point x 0 of Algorithm 3 . 2 is such that the level set L (cid:3) { x ∈ D : f ( x ) ≤ f ( x 0 ) } is compact . Then if the bounded modiﬁed factorization property holds , we have that lim k →∞ ∇ f ( x k ) (cid:3) 0 . For a proof this result see [ 215 ] . We now consider the convergence rate of Algorithm 3 . 2 . Suppose that the sequence of iterates x k converges to a point x ∗ where ∇ 2 f ( x ∗ ) is sufﬁciently positive deﬁnite in the sense that the modiﬁcation strategies described in the next section return the modiﬁcation E k (cid:3) 0 for all sufﬁciently large k . By Theorem 3 . 6 , we have that α k (cid:3) 1 for all sufﬁciently large k , so that Algorithm 3 . 2 reduces to a pure Newton method , and the rate of convergence is quadratic . For problems in which ∇ f ∗ is close to singular , there is no guarantee that the mod - iﬁcation E k will eventually vanish , and the convergence rate may be only linear . Besides requiring the modiﬁed matrix B k to be well conditioned ( so that Theorem 3 . 8 holds ) , we would like the modiﬁcation to be as small as possible , so that the second - order information in the Hessian is preserved as far as possible . Naturally , we would also like the modiﬁed factorization to be computable at moderate cost . To set the stage for the matrix factorization techniques that will be used in Al - gorithm 3 . 2 , we will begin by assuming that the eigenvalue decomposition of ∇ 2 f ( x k ) is available . Thisisnotrealisticforlarge - scaleproblemsbecausethisdecompositionisgenerally too expensive to compute , but it will motivate several practical modiﬁcation strategies . EIGENVALUE MODIFICATION Consider a problem in which , at the current iterate x k , ∇ f ( x k ) (cid:3) ( 1 , − 3 , 2 ) T and ∇ 2 f ( x k ) (cid:3) diag ( 10 , 3 , − 1 ) , which is clearly indeﬁnite . By the spectral decomposition theorem ( see Appendix A ) we can deﬁne Q (cid:3) I and (cid:16) (cid:3) diag ( λ 1 , λ 2 , λ 3 ) , and write ∇ 2 f ( x k ) (cid:3) Q (cid:16) Q T (cid:3) n (cid:3) i (cid:3) 1 λ i q i q Ti . ( 3 . 40 ) The pure Newton step—the solution of ( 3 . 38 ) —is p N k (cid:3) ( − 0 . 1 , 1 , 2 ) T , which is not a de - scent direction , since ∇ f ( x k ) T p N k > 0 . One might suggest a modiﬁed strategy in which we replace ∇ 2 f ( x k ) by a positive deﬁnite approximation B k , in which all negative eigenvalues in ∇ 2 f ( x k ) are replaced by a small positive number δ that is somewhat larger than ma - chine precision u ; say δ (cid:3) √ u . For a machine precision of 10 − 16 , the resulting matrix in 50 C H A P T E R 3 . L I N E S E A R C H M E T H O D S our example is B k (cid:3) 2 (cid:3) i (cid:3) 1 λ i q i q Ti + δ q 3 q T 3 (cid:3) diag (cid:7) 10 , 3 , 10 − 8 (cid:8) , ( 3 . 41 ) which is numerically positive deﬁnite and whose curvature along the eigenvectors q 1 and q 2 has been preserved . Note , however , that the search direction based on this modiﬁed Hessian is p k (cid:3) − B − 1 k ∇ f k (cid:3) − 2 (cid:3) i (cid:3) 1 1 λ i q i (cid:7) q Ti ∇ f k (cid:8) − 1 δ q 3 (cid:7) q T 3 ∇ f ( x k ) (cid:8) ≈ − (cid:7) 2 × 10 8 (cid:8) q 3 . ( 3 . 42 ) For small δ , this step is nearly parallel to q 3 ( with relatively small contributions from q 1 and q 2 ) and quite long . Although f decreases along the direction p k , its extreme length violates the spirit of Newton’s method , which relies on a quadratic approximation of the objective function that is valid in a neighborhood of the current iterate x k . It is therefore not clear that this search direction is effective . Various other modiﬁcation strategies are possible . We could ﬂip the signs of the negative eigenvalues in ( 3 . 40 ) , which amounts to setting δ (cid:3) 1 in our example . We could set the last term in ( 3 . 42 ) to zero , so that the search direction has no components along the negative curvature directions . We could adapt the choice of δ to ensure that the length of the step is not excessive , a strategy that has the ﬂavor of trust - region methods . As this discussion shows , there is a great deal of freedom in devising modiﬁcation strategies , and there is currently no agreement on which strategy is best . Setting the issue of the choice of δ aside for the moment , let us look more closely at the process of modifying a matrix so that it becomes positive deﬁnite . The modiﬁcation ( 3 . 41 ) to the example matrix ( 3 . 40 ) can be shown to be optimal in the following sense . If A is a symmetric matrix with spectral decomposition A (cid:3) Q (cid:16) Q T , then the correction matrix (cid:6) A of minimum Frobenius norm that ensures that λ min ( A + (cid:6) A ) ≥ δ is given by (cid:6) A (cid:3) Q diag ( τ i ) Q T , with τ i (cid:3) (cid:21) 0 , λ i ≥ δ , δ − λ i , λ i < δ . ( 3 . 43 ) Here , λ min ( A ) denotes the smallest eigenvalue of A , and the Frobenius norm of a matrix is deﬁned as (cid:8) A (cid:8) 2 F (cid:3) (cid:4) ni , j (cid:3) 1 a 2 ij ( see ( A . 9 ) ) . Note that (cid:6) A is not diagonal in general , and that the modiﬁed matrix is given by A + (cid:6) A (cid:3) Q ( (cid:16) + diag ( τ i ) ) Q T . By using a different norm we can obtain a diagonal modiﬁcation . Suppose again that A is a symmetric matrix with spectral decomposition A (cid:3) Q (cid:16) Q T . A correction matrix 3 . 4 . N E W T O N ’ S M E T H O D W I T H H E S S I A N M O D I F I C A T I O N 51 (cid:6) A with minimum Euclidean norm that satisﬁes λ min ( A + (cid:6) A ) ≥ δ is given by (cid:6) A (cid:3) τ I , with τ (cid:3) max ( 0 , δ − λ min ( A ) ) . ( 3 . 44 ) The modiﬁed matrix now has the form A + τ I , ( 3 . 45 ) which happens to have the same form as the matrix occurring in ( unscaled ) trust – region methods ( see Chapter 4 ) . All the eigenvalues of ( 3 . 45 ) have thus been shifted , and all are greater than δ . These results suggest that both diagonal and nondiagonal modiﬁcations can be con - sidered . Even though we have not answered the question of what constitutes a good modiﬁcation , various practical diagonal and nondiagonal modiﬁcations have been pro - posed and implemented in software . They do not make use of the spectral decomposition of the Hessian , since it is generally too expensive to compute . Instead , they use Gaussian elim - ination , choosing the modiﬁcations indirectly and hoping that somehow they will produce good steps . Numerical experience indicates that the strategies described next often ( but not always ) produce good search directions . ADDING A MULTIPLE OF THE IDENTITY Perhapsthesimplestideaistoﬁndascalar τ > 0suchthat ∇ 2 f ( x k ) + τ I issufﬁciently positive deﬁnite . From the previous discussion we know that τ must satisfy ( 3 . 44 ) , but a good estimate of the smallest eigenvalue of the Hessian is normally not available . The following algorithm describes a method that tries successively larger values of τ . ( Here , a ii denotes a diagonal element of A . ) Algorithm 3 . 3 ( Cholesky with Added Multiple of the Identity ) . Choose β > 0 ; if min i a ii > 0 set τ 0 ← 0 ; else τ 0 (cid:3) − min ( a ii ) + β ; end ( if ) for k (cid:3) 0 , 1 , 2 , . . . Attempt to apply the Cholesky algorithm to obtain LL T (cid:3) A + τ k I ; if the factorization is completed successfully stop and return L ; else τ k + 1 ← max ( 2 τ k , β ) ; end ( if ) end ( for ) 52 C H A P T E R 3 . L I N E S E A R C H M E T H O D S The choice of β is heuristic ; a typical value is β (cid:3) 10 − 3 . We could choose the ﬁrst nonzero shift τ 0 to be proportional to be the ﬁnal value of τ used in the latest Hessian modiﬁcation ; see also Algorithm B . 1 . The strategy implemented in Algorithm 3 . 3 is quite simple and may be preferable to the modiﬁed factorization techniques described next , but it suffers from one drawback . Every value of τ k requires a new factorization of A + τ k I , and the algorithm can be quite expensive if several trial values are generated . Therefore it may be advantageous to increase τ more rapidly , say by a factor of 10 instead of 2 in the last else clause . MODIFIED CHOLESKY FACTORIZATION Another approach for modifying a Hessian matrix that is not positive deﬁnite is to perform a Cholesky factorization of ∇ 2 f ( x k ) , but to increase the diagonal elements encountered during the factorization ( where necessary ) to ensure that they are sufﬁciently positive . This modiﬁed Cholesky approach is designed to accomplish two goals : It guarantees that the modiﬁed Cholesky factors exist and are bounded relative to the norm of the actual Hessian , and it does not modify the Hessian if it is sufﬁciently positive deﬁnite . We begin our description of this approach by brieﬂy reviewing the Cholesky factorization . Every symmetric positive deﬁnite matrix A can be written as A (cid:3) L DL T , ( 3 . 46 ) where L is a lower triangular matrix with unit diagonal elements and D is a diagonal matrix with positive elements on the diagonal . By equating the elements in ( 3 . 46 ) , column by column , it is easy to derive formulas for computing L and D . ❏ E XAMPLE 3 . 1 Consider the case n (cid:3) 3 . The equation A (cid:3) L DL T is given by ⎡ ⎢⎣ a 11 a 21 a 31 a 21 a 22 a 32 a 31 a 32 a 33 ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎢⎣ 1 0 0 l 21 1 0 l 31 l 32 1 ⎤ ⎥⎥⎦ ⎡ ⎢⎣ d 1 0 0 0 d 2 0 0 0 d 3 ⎤ ⎥⎦ ⎡ ⎢⎣ 1 l 21 l 31 0 1 l 32 0 0 1 ⎤ ⎥⎦ . ( The notation indicates that A is symmetric . ) By equating the elements of the ﬁrst column , we have a 11 (cid:3) d 1 , a 21 (cid:3) d 1 l 21 ⇒ l 21 (cid:3) a 21 / d 1 , a 31 (cid:3) d 1 l 31 ⇒ l 31 (cid:3) a 31 / d 1 . 3 . 4 . N E W T O N ’ S M E T H O D W I T H H E S S I A N M O D I F I C A T I O N 53 Proceeding with the next two columns , we obtain a 22 (cid:3) d 1 l 221 + d 2 ⇒ d 2 (cid:3) a 22 − d 1 l 221 , a 32 (cid:3) d 1 l 31 l 21 + d 2 l 32 ⇒ l 32 (cid:3) ( a 32 − d 1 l 31 l 21 ) / d 2 , a 33 (cid:3) d 1 l 231 + d 2 l 232 + d 3 ⇒ d 3 (cid:3) a 33 − d 1 l 231 − d 2 l 232 . ❐ This procedure is generalized in the following algorithm . Algorithm 3 . 4 ( Cholesky Factorization , L DL T Form ) . for j (cid:3) 1 , 2 , . . . , n c jj ← a jj − (cid:4) j − 1 s (cid:3) 1 d s l 2 js ; d j ← c jj ; for i (cid:3) j + 1 , . . . , n c ij ← a ij − (cid:4) j − 1 s (cid:3) 1 d s l is l js ; l ij ← c ij / d j ; end end One can show ( see , for example , Golub and Van Loan [ 136 , Section 4 . 2 . 3 ] ) that the diagonal elements d jj are all positive whenever A is positive deﬁnite . The scalars c ij have been introduced only to facilitate the description of the modiﬁed factorization discussed below . We should note that Algorithm 3 . 4 differs a little from the standard form of the Cholesky factorization , which produces a lower triangular matrix M such that A (cid:3) M M T . ( 3 . 47 ) In fact , we can make the identiﬁcation M (cid:3) L D 1 / 2 to relate M to the factors L and D computed in Algorithm 3 . 4 . The technique for computing M appears as Algorithm A . 2 in Appendix A . If A is indeﬁnite , the factorization A (cid:3) L DL T may not exist . Even if it does exist , Algorithm 3 . 4 is numerically unstable when applied to such matrices , in the sense that the elements of L and D can become arbitrarily large . It follows that a strategy of computing the L DL T factorization and then modifying the diagonal after the fact to force its elements to be positive may break down , or may result in a matrix that is drastically different from A . Instead , we can modify the matrix A during the course of the factorization in such a way that all elements in D are sufﬁciently positive , and so that the elements of D and L are not too large . To control the quality of the modiﬁcation , we choose two positive parameters δ and β , and require that during the computation of the j th columns of L and D in Algorithm 3 . 4 ( that is , for each j in the outer loop of the algorithm ) the following 54 C H A P T E R 3 . L I N E S E A R C H M E T H O D S bounds be satisﬁed : d j ≥ δ , | m ij | ≤ β , i (cid:3) j + 1 , j + 2 , . . . , n , ( 3 . 48 ) where m ij (cid:3) l ij (cid:5) d j . To satisfy these bounds we only need to change one step in Algo - rithm 3 . 4 : The formula for computing the diagonal element d j in Algorithm 3 . 4 is replaced by d j (cid:3) max (cid:24) | c jj | , (cid:17) θ j β (cid:18) 2 , δ (cid:25) , with θ j (cid:3) max j < i ≤ n | c ij | . ( 3 . 49 ) To verify that ( 3 . 48 ) holds , we note from Algorithm 3 . 4 that c ij (cid:3) l ij d j , and therefore | m ij | (cid:3) | l ij (cid:5) d j | (cid:3) | c ij | (cid:5) d j ≤ | c ij | β θ j ≤ β , for all i > j . We note that θ j can be computed prior to d j because the elements c ij in the second for loop of Algorithm 3 . 4 do not involve d j . In fact , this is the reason for introducing the quantities c ij into the algorithm . TheseobservationsarethebasisofthemodiﬁedCholeskyalgorithmdescribedindetail in Gill , Murray , and Wright [ 130 ] , which introduces symmetric interchanges of rows and columns to try to reduce the size of the modiﬁcation . If P denotes the permutation matrix associated with the row and column interchanges , the algorithm produces the Cholesky factorization of the permuted , modiﬁed matrix P AP T + E , that is , P AP T + E (cid:3) L DL T (cid:3) M M T , ( 3 . 50 ) where E is a nonnegative diagonal matrix that is zero if A is sufﬁciently positive deﬁnite . One can show ( Mor´e and Sorensen [ 215 ] ) that the matrices B k obtained by this modiﬁed Cholesky algorithm to the exact Hessians ∇ 2 f ( x k ) have bounded condition numbers , that is , the bound ( 3 . 39 ) holds for some value of C . MODIFIED SYMMETRIC INDEFINITE FACTORIZATION Another strategy for modifying an indeﬁnite Hessian is to use a procedure based on a symmetric indeﬁnite factorization . Any symmetric matrix A , whether positive deﬁnite or not , can be written as P AP T (cid:3) L BL T , ( 3 . 51 ) where L is unit lower triangular , B is a block diagonal matrix with blocks of dimension 1 or 2 , and P is a permutation matrix ( see our discussion in Appendix A and also Golub and 3 . 4 . N E W T O N ’ S M E T H O D W I T H H E S S I A N M O D I F I C A T I O N 55 Van Loan [ 136 , Section 4 . 4 ] ) . We mentioned earlier that attempting to compute the L DL T factorization of an indeﬁnite matrix ( where D is a diagonal matrix ) is inadvisable because even if the factors L and D are well deﬁned , they may contain entries that are larger than the original elements of A , thus amplifying rounding errors that arise during the computation . However , by using the block diagonal matrix B , which allows 2 × 2 blocks as well as 1 × 1 blocks on the diagonal , we can guarantee that the factorization ( 3 . 51 ) always exists and can be computed by a numerically stable process . ❏ E XAMPLE 3 . 2 The matrix A (cid:3) ⎡ ⎢⎢⎢⎢⎣ 0 1 2 3 1 2 2 2 2 2 3 3 3 2 3 4 ⎤ ⎥⎥⎥⎥⎦ can be written in the form ( 3 . 51 ) with P (cid:3) [ e 1 , e 4 , e 3 , e 2 ] , L (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎣ 1 0 0 0 0 1 0 0 1 9 2 3 1 0 2 9 1 3 0 1 ⎤ ⎥⎥⎥⎥⎥⎥⎦ , B (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎣ 0 3 0 0 3 4 0 0 0 0 7 9 5 9 0 0 5 9 10 9 ⎤ ⎥⎥⎥⎥⎥⎥⎦ . ( 3 . 52 ) Note that both diagonal blocks in B are 2 × 2 . Several algorithms for computing symmetric indeﬁnite factorizations are discussed in Section A . 1 of Appendix A . ❐ The symmetric indeﬁnite factorization allows us to determine the inertia of a matrix , that is , the number of positive , zero , and negative eigenvalues . One can show that the inertia of B equals the inertia of A . Moreover , the 2 × 2 blocks in B are always constructed to have one positive and one negative eigenvalue . Thus the number of positive eigenvalues in A equals the number of positive 1 × 1 blocks plus the number of 2 × 2 blocks . As for the Cholesky factorization , an indeﬁnite symmetric factorization algorithm can be modiﬁed to ensure that the modiﬁed factors are the factors of a positive deﬁnite matrix . The strategy is ﬁrst to compute the factorization ( 3 . 51 ) , as well as the spectral decomposition B (cid:3) Q (cid:16) Q T , which is inexpensive to compute because B is block diagonal 56 C H A P T E R 3 . L I N E S E A R C H M E T H O D S ( see Exercise 3 . 12 ) . We then construct a modiﬁcation matrix F such that L ( B + F ) L T is sufﬁciently positive deﬁnite . Motivated by the modiﬁed spectral decomposition ( 3 . 43 ) , we choose a parameter δ > 0 and deﬁne F to be F (cid:3) Q diag ( τ i ) Q T , τ i (cid:3) (cid:21) 0 , λ i ≥ δ , δ − λ i , λ i < δ , i (cid:3) 1 , 2 , . . . , n , ( 3 . 53 ) where λ i are the eigenvalues of B . The matrix F is thus the modiﬁcation of minimum Frobenius norm that ensures that all eigenvalues of the modiﬁed matrix B + F are no less than δ . This strategy therefore modiﬁes the factorization ( 3 . 51 ) as follows : P ( A + E ) P T (cid:3) L ( B + F ) L T , where E (cid:3) P T LFL T P . ( Note that E will not be diagonal , in general . ) Hence , in contrast to the modiﬁed Cholesky approach , this modiﬁcation strategy changes the entire matrix A , not just its diagonal . The aim of strategy ( 3 . 53 ) is that the modiﬁed matrix satisﬁes λ min ( A + E ) ≈ δ whenever the original matrix A has λ min ( A ) < δ . It is not clear , however , whether it always comes close to attaining this goal . 3 . 5 STEP - LENGTH SELECTION ALGORITHMS We now consider techniques for ﬁnding a minimum of the one - dimensional function φ ( α ) (cid:3) f ( x k + α p k ) , ( 3 . 54 ) or for simply ﬁnding a step length α k satisfying one of the termination conditions described in Section 3 . 1 . We assume that p k is a descent direction—that is , φ (cid:14) ( 0 ) < 0—so that our search can be conﬁned to positive values of α . If f is a convex quadratic , f ( x ) (cid:3) 12 x T Qx − b T x , its one - dimensional minimizer along the ray x k + α p k can be computed analytically and is given by α k (cid:3) −∇ f Tk p k p Tk Qp k . ( 3 . 55 ) For general nonlinear functions , it is necessary to use an iterative procedure . The line search procedure deserves particular attention because it has a major impact on the robustness and efﬁciency of all nonlinear optimization methods . 3 . 5 . S T E P - L E N G T H S E L E C T I O N A L G O R I T H M S 57 Linesearchprocedurescanbeclassiﬁedaccordingtothetypeofderivativeinformation they use . Algorithms that use only function values can be inefﬁcient since , to be theoretically sound , they need to continue iterating until the search for the minimizer is narrowed down to a small interval . In contrast , knowledge of gradient information allows us to determine whether a suitable step length has been located , as stipulated , for example , by the Wolfe conditions ( 3 . 6 ) or Goldstein conditions ( 3 . 11 ) . Often , particularly when x k is close to the solution , the very ﬁrst choice of α satisﬁes these conditions , so the line search need not be invoked at all . In the rest of this section , we discuss only algorithms that make use of derivative information . More information on derivative - free procedures is given in the notes at the end of this chapter . All line search procedures require an initial estimate α 0 and generate a sequence { α i } that either terminates with a step length satisfying the conditions speciﬁed by the user ( for example , the Wolfe conditions ) or determines that such a step length does not exist . Typical procedures consist of two phases : a bracketing phase that ﬁnds an interval [ ¯ a , ¯ b ] containing acceptable step lengths , and a selection phase that zooms in to locate the ﬁnal step length . The selection phase usually reduces the bracketing interval during its search for the desired step length and interpolates some of the function and derivative information gathered on earlier steps to guess the location of the minimizer . We ﬁrst discuss how to perform this interpolation . In the following discussion we let α k and α k − 1 denote the step lengths used at iterations k and k − 1 of the optimization algorithm , respectively . On the other hand , we denote the trial step lengths generated during the line search by α i and α i − 1 and also α j . We use α 0 to denote the initial guess . INTERPOLATION We begin by describing a line search procedure based on interpolation of known function and derivative values of the function φ . This procedure can be viewed as an enhancement of Algorithm 3 . 1 . The aim is to ﬁnd a value of α that satisﬁes the sufﬁcient decrease condition ( 3 . 6a ) , without being “too small . ” Accordingly , the procedures here generate a decreasing sequence of values α i such that each value α i is not too much smaller than its predecessor α i − 1 . Note that we can write the sufﬁcient decrease condition in the notation of ( 3 . 54 ) as φ ( α k ) ≤ φ ( 0 ) + c 1 α k φ (cid:14) ( 0 ) , ( 3 . 56 ) and that since the constant c 1 is usually chosen to be small in practice ( c 1 (cid:3) 10 − 4 , say ) , this condition asks for little more than descent in f . We design the procedure to be “efﬁcient” in the sense that it computes the derivative ∇ f ( x ) as few times as possible . Suppose that the initial guess α 0 is given . If we have φ ( α 0 ) ≤ φ ( 0 ) + c 1 α 0 φ (cid:14) ( 0 ) , 58 C H A P T E R 3 . L I N E S E A R C H M E T H O D S this step length satisﬁes the condition , and we terminate the search . Otherwise , we know that the interval [ 0 , α 0 ] contains acceptable step lengths ( see Figure 3 . 3 ) . We form a quadratic approximation φ q ( α ) to φ by interpolating the three pieces of information available— φ ( 0 ) , φ (cid:14) ( 0 ) , and φ ( α 0 ) —to obtain φ q ( α ) (cid:3) (cid:17) φ ( α 0 ) − φ ( 0 ) − α 0 φ (cid:14) ( 0 ) α 2 0 (cid:18) α 2 + φ (cid:14) ( 0 ) α + φ ( 0 ) . ( 3 . 57 ) ( Note that this function is constructed so that it satisﬁes the interpolation conditions φ q ( 0 ) (cid:3) φ ( 0 ) , φ (cid:14) q ( 0 ) (cid:3) φ (cid:14) ( 0 ) , and φ q ( α 0 ) (cid:3) φ ( α 0 ) . ) The new trial value α 1 is deﬁned as the minimizer of this quadratic , that is , we obtain α 1 (cid:3) − φ (cid:14) ( 0 ) α 20 2 [ φ ( α 0 ) − φ ( 0 ) − φ (cid:14) ( 0 ) α 0 ] . ( 3 . 58 ) If the sufﬁcient decrease condition ( 3 . 56 ) is satisﬁed at α 1 , we terminate the search . Oth - erwise , we construct a cubic function that interpolates the four pieces of information φ ( 0 ) , φ (cid:14) ( 0 ) , φ ( α 0 ) , and φ ( α 1 ) , obtaining φ c ( α ) (cid:3) a α 3 + b α 2 + αφ (cid:14) ( 0 ) + φ ( 0 ) , where (cid:1) a b (cid:2) (cid:3) 1 α 20 α 21 ( α 1 − α 0 ) (cid:1) α 20 − α 21 − α 30 α 31 (cid:2) (cid:1) φ ( α 1 ) − φ ( 0 ) − φ (cid:14) ( 0 ) α 1 φ ( α 0 ) − φ ( 0 ) − φ (cid:14) ( 0 ) α 0 (cid:2) . By differentiating φ c ( x ) , we see that the minimizer α 2 of φ c lies in the interval [ 0 , α 1 ] and is given by α 2 (cid:3) − b + (cid:5) b 2 − 3 a φ (cid:14) ( 0 ) 3 a . If necessary , this process is repeated , using a cubic interpolant of φ ( 0 ) , φ (cid:14) ( 0 ) and the two most recent values of φ , until an α that satisﬁes ( 3 . 56 ) is located . If any α i is either too close to its predecessor α i − 1 or else too much smaller than α i − 1 , we reset α i (cid:3) α i − 1 / 2 . This safeguard procedure ensures that we make reasonable progress on each iteration and that the ﬁnal α is not too small . The strategy just described assumes that derivative values are signiﬁcantly more ex - pensive to compute than function values . It is often possible , however , to compute the directional derivative simultaneously with the function , at little additional cost ; see Chap - ter 8 . Accordingly , we can design an alternative strategy based on cubic interpolation of the values of φ and φ (cid:14) at the two most recent values of α . 3 . 5 . S T E P - L E N G T H S E L E C T I O N A L G O R I T H M S 59 Cubic interpolation provides a good model for functions with signiﬁcant changes of curvature . Suppose we have an interval [ ¯ a , ¯ b ] known to contain desirable step lengths , and two previous step length estimates α i − 1 and α i in this interval . We use a cubic function to interpolate φ ( α i − 1 ) , φ (cid:14) ( α i − 1 ) , φ ( α i ) , and φ (cid:14) ( α i ) . ( This cubic function always exists and is unique ; see , for example , Bulirsch and Stoer [ 41 , p . 52 ] . ) The minimizer of this cubic in [ ¯ a , ¯ b ] is either at one of the endpoints or else in the interior , in which case it is given by α i + 1 (cid:3) α i − ( α i − α i − 1 ) (cid:26) φ (cid:14) ( α i ) + d 2 − d 1 φ (cid:14) ( α i ) − φ (cid:14) ( α i − 1 ) + 2 d 2 (cid:27) , ( 3 . 59 ) with d 1 (cid:3) φ (cid:14) ( α i − 1 ) + φ (cid:14) ( α i ) − 3 φ ( α i − 1 ) − φ ( α i ) α i − 1 − α i , d 2 (cid:3) sign ( α i − α i − 1 ) (cid:9) d 21 − φ (cid:14) ( α i − 1 ) φ (cid:14) ( α i ) (cid:10) 1 / 2 . The interpolation process can be repeated by discarding the data at one of the step lengths α i − 1 or α i and replacing it by φ ( α i + 1 ) and φ (cid:14) ( α i + 1 ) . The decision on which of α i − 1 and α i should be kept and which discarded depends on the speciﬁc conditions used to terminate the line search ; we discuss this issue further below in the context of the Wolfe conditions . Cubic interpolation is a powerful strategy , since it usually produces a quadratic rate of convergence of the iteration ( 3 . 59 ) to the minimizing value of α . INITIAL STEP LENGTH For Newton and quasi - Newton methods , the step α 0 (cid:3) 1 should always be used as the initial trial step length . This choice ensures that unit step lengths are taken whenever they satisfy the termination conditions and allows the rapid rate - of - convergence properties of these methods to take effect . For methods that do not produce well scaled search directions , such as the steepest de - scent and conjugate gradient methods , it is important to use current information about the problem and the algorithm to make the initial guess . A popular strategy is to assume that the ﬁrst - order change in the function at iterate x k will be the same as that obtained at the previ - ous step . In other words , we choose the initial guess α 0 so that α 0 ∇ f Tk p k (cid:3) α k − 1 ∇ f Tk − 1 p k − 1 , that is , α 0 (cid:3) α k − 1 ∇ f Tk − 1 p k − 1 ∇ f T k p k . Another useful strategy is to interpolate a quadratic to the data f ( x k − 1 ) , f ( x k ) , and ∇ f Tk − 1 p k − 1 and to deﬁne α 0 to be its minimizer . This strategy yields α 0 (cid:3) 2 ( f k − f k − 1 ) φ (cid:14) ( 0 ) . ( 3 . 60 ) 60 C H A P T E R 3 . L I N E S E A R C H M E T H O D S It can be shown that if x k → x ∗ superlinearly , then the ratio in this expression converges to 1 . If we adjust the choice ( 3 . 60 ) by setting α 0 ← min ( 1 , 1 . 01 α 0 ) , we ﬁnd that the unit step length α 0 (cid:3) 1 will eventually always be tried and accepted , and the superlinear convergence properties of Newton and quasi - Newton methods will be observed . A LINE SEARCH ALGORITHM FOR THE WOLFE CONDITIONS The Wolfe ( or strong Wolfe ) conditions are among the most widely applicable and useful termination conditions . We now describe in some detail a one - dimensional search procedure that is guaranteed to ﬁnd a step length satisfying the strong Wolfe conditions ( 3 . 7 ) for any parameters c 1 and c 2 satisfying 0 < c 1 < c 2 < 1 . As before , we assume that p is a descent direction and that f is bounded below along the direction p . The algorithm has two stages . This ﬁrst stage begins with a trial estimate α 1 , and keeps increasing it until it ﬁnds either an acceptable step length or an interval that brackets the desired step lengths . In the latter case , the second stage is invoked by calling a function called zoom ( Algorithm 3 . 6 , below ) , which successively decreases the size of the interval until an acceptable step length is identiﬁed . A formal speciﬁcation of the line search algorithm follows . We refer to ( 3 . 7a ) as the sufﬁcient decrease condition and to ( 3 . 7b ) as the curvature condition . The parameter α max is a user - supplied bound on the maximum step length allowed . The line search algorithm terminates with α ∗ set to a step length that satisﬁes the strong Wolfe conditions . Algorithm 3 . 5 ( Line Search Algorithm ) . Set α 0 ← 0 , choose α max > 0 and α 1 ∈ ( 0 , α max ) ; i ← 1 ; repeat Evaluate φ ( α i ) ; if φ ( α i ) > φ ( 0 ) + c 1 α i φ (cid:14) ( 0 ) or [ φ ( α i ) ≥ φ ( α i − 1 ) and i > 1 ] α ∗ ← zoom ( α i − 1 , α i ) and stop ; Evaluate φ (cid:14) ( α i ) ; if | φ (cid:14) ( α i ) | ≤ − c 2 φ (cid:14) ( 0 ) set α ∗ ← α i and stop ; if φ (cid:14) ( α i ) ≥ 0 set α ∗ ← zoom ( α i , α i − 1 ) and stop ; Choose α i + 1 ∈ ( α i , α max ) ; i ← i + 1 ; end ( repeat ) 3 . 5 . S T E P - L E N G T H S E L E C T I O N A L G O R I T H M S 61 Note that the sequence of trial step lengths { α i } is monotonically increasing , but that the order of the arguments supplied to the zoom function may vary . The procedure uses the knowledge that the interval ( α i − 1 , α i ) contains step lengths satisfying the strong Wolfe conditions if one of the following three conditions is satisﬁed : ( i ) α i violates the sufﬁcient decrease condition ; ( ii ) φ ( α i ) ≥ φ ( α i − 1 ) ; ( iii ) φ (cid:14) ( α i ) ≥ 0 . The last step of the algorithm performs extrapolation to ﬁnd the next trial value α i + 1 . To implement this step we can use approaches like the interpolation procedures above , or we can simply set α i + 1 to some constant multiple of α i . Whichever strategy we use , it is important that the successive steps increase quickly enough to reach the upper limit α max in a ﬁnite number of iterations . We now specify the function zoom , which requires a little explanation . The order of its input arguments is such that each call has the form zoom ( α lo , α hi ) , where ( a ) the interval bounded by α lo and α hi contains step lengths that satisfy the strong Wolfe conditions ; ( b ) α lo is , among all step lengths generated so far and satisfying the sufﬁcient decrease condition , the one giving the smallest function value ; and ( c ) α hi is chosen so that φ (cid:14) ( α lo ) ( α hi − α lo ) < 0 . Each iteration of zoom generates an iterate α j between α lo and α hi , and then replaces one of these endpoints by α j in such a way that the properties ( a ) , ( b ) , and ( c ) continue to hold . Algorithm 3 . 6 ( zoom ) . repeat Interpolate ( using quadratic , cubic , or bisection ) to ﬁnd a trial step length α j between α lo and α hi ; Evaluate φ ( α j ) ; if φ ( α j ) > φ ( 0 ) + c 1 α j φ (cid:14) ( 0 ) or φ ( α j ) ≥ φ ( α lo ) α hi ← α j ; else Evaluate φ (cid:14) ( α j ) ; if | φ (cid:14) ( α j ) | ≤ − c 2 φ (cid:14) ( 0 ) Set α ∗ ← α j and stop ; if φ (cid:14) ( α j ) ( α hi − α lo ) ≥ 0 α hi ← α lo ; α lo ← α j ; end ( repeat ) 62 C H A P T E R 3 . L I N E S E A R C H M E T H O D S If the new estimate α j happens to satisfy the strong Wolfe conditions , then zoom has served its purpose of identifying such a point , so it terminates with α ∗ (cid:3) α j . Otherwise , if α j satisﬁes the sufﬁcient decrease condition and has a lower function value than x lo , then we set α lo ← α j to maintain condition ( b ) . If this setting results in a violation of condition ( c ) , we remedy the situation by setting α hi to the old value of α lo . Readers should sketch some graphs to see for themselves how zoom works ! As mentioned earlier , the interpolation step that determines α j should be safeguarded to ensure that the new step length is not too close to the endpoints of the interval . Practical line search algorithms also make use of the properties of the interpolating polynomials to make educated guesses of where the next step length should lie ; see [ 39 , 216 ] . A problem that can arise is that as the optimization algorithm approaches the solution , two consecutive function values f ( x k ) and f ( x k − 1 ) may be indistinguishable in ﬁnite - precision arithmetic . Therefore , the line search must include a stopping test if it cannot attain a lower function value after a certain number ( typically , ten ) of trial step lengths . Some procedures also stop if the relative change in x is close to machine precision , or to some user - speciﬁed threshold . A line search algorithm that incorporates all these features is difﬁcult to code . We advocate the use of one of the several good software implementations available in the public domain . See Dennis and Schnabel [ 92 ] , Lemar´echal [ 189 ] , Fletcher [ 101 ] , Mor´e and Thuente [ 216 ] ( in particular ) , and Hager and Zhang [ 161 ] . One may ask how much more expensive it is to require the strong Wolfe conditions instead of the regular Wolfe conditions . Our experience suggests that for a “loose” line search ( with parameters such as c 1 (cid:3) 10 − 4 and c 2 (cid:3) 0 . 9 ) , both strategies require a similar amount of work . The strong Wolfe conditions have the advantage that by decreasing c 2 we can directly control the quality of the search , by forcing the accepted value of α to lie closer to a local minimum . This feature is important in steepest descent or nonlinear conjugate gradient methods , and therefore a step selection routine that enforces the strong Wolfe conditions has wide applicability . NOTES AND REFERENCES For an extensive discussion of line search termination conditions see Ortega and Rheinboldt [ 230 ] . Akaike [ 2 ] presents a probabilistic analysis of the steepest descent method with exact line searches on quadratic functions . He shows that when n > 2 , the worst - case bound ( 3 . 29 ) can be expected to hold for most starting points . The case n (cid:3) 2 can be studied in closed form ; see Bazaraa , Sherali , and Shetty [ 14 ] . Theorem 3 . 6 is due to Dennis and Mor ´ e . Somelinesearchmethods ( seeGoldfarb [ 132 ] andMor ´ eandSorensen [ 213 ] ) compute a direction of negative curvature , whenever it exists , to prevent the iteration from converging to nonminimizing stationary points . A direction of negative curvature p − is one that satisﬁes p T − ∇ 2 f ( x k ) p − < 0 . These algorithms generate a search direction by combining p − with the steepest descent direction −∇ f k , often performing a curvilinear backtracking line search . 3 . 5 . S T E P - L E N G T H S E L E C T I O N A L G O R I T H M S 63 It is difﬁcult to determine the relative contributions of the steepest descent and negative curvature directions . Because of this fact , the approach fell out of favor after the introduction of trust - region methods . For a more thorough treatment of the modiﬁed Cholesky factorization see Gill , Murray , and Wright [ 130 ] or Dennis and Schnabel [ 92 ] . A modiﬁed Cholesky factorization based on Gershgorin disk estimates is described in Schnabel and Eskow [ 276 ] . The modiﬁed indeﬁnite factorization is from Cheng and Higham [ 58 ] . Another strategy for implementing a line search Newton method when the Hessian contains negative eigenvalues is to compute a direction of negative curvature and use it to deﬁne the search direction ( see Mor´e and Sorensen [ 213 ] and Goldfarb [ 132 ] ) . Derivative - free line search algorithms include golden section and Fibonacci search . They share some of the features with the line search method given in this chapter . They typically store three trial points that determine an interval containing a one - dimensional minimizer . Golden section and Fibonacci differ in the way in which the trial step lengths are generated ; see , for example , [ 79 , 39 ] . Our discussion of interpolation follows Dennis and Schnabel [ 92 ] , and the algorithm for ﬁnding a step length satisfying the strong Wolfe conditions can be found in Fletcher [ 101 ] . ✐ E X E R C I S E S ✐ 3 . 1 Program the steepest descent and Newton algorithms using the backtracking line search , Algorithm 3 . 1 . Use them to minimize the Rosenbrock function ( 2 . 22 ) . Set the initial step length α 0 (cid:3) 1 and print the step length used by each method at each iteration . First try the initial point x 0 (cid:3) ( 1 . 2 , 1 . 2 ) T and then the more difﬁcult starting point x 0 (cid:3) ( − 1 . 2 , 1 ) T . ✐ 3 . 2 Show that if 0 < c 2 < c 1 < 1 , there may be no step lengths that satisfy the Wolfe conditions . ✐ 3 . 3 Showthattheone - dimensionalminimizerofastronglyconvexquadraticfunction is given by ( 3 . 55 ) . ✐ 3 . 4 Showthattheone - dimensionalminimizerofastronglyconvexquadraticfunction always satisﬁes the Goldstein conditions ( 3 . 11 ) . ✐ 3 . 5 Prove that (cid:8) Bx (cid:8) ≥ (cid:8) x (cid:8) / (cid:8) B − 1 (cid:8) for any nonsingular matrix B . Use this fact to establish ( 3 . 19 ) . ✐ 3 . 6 Consider the steepest descent method with exact line searches applied to the convex quadratic function ( 3 . 24 ) . Using the properties given in this chapter , show that if the initial point is such that x 0 − x ∗ is parallel to an eigenvector of Q , then the steepest descent method will ﬁnd the solution in one step . 64 C H A P T E R 3 . L I N E S E A R C H M E T H O D S ✐ 3 . 7 Prove the result ( 3 . 28 ) by working through the following steps . First , use ( 3 . 26 ) to show that (cid:8) x k − x ∗ (cid:8) 2 Q − (cid:8) x k + 1 − x ∗ (cid:8) 2 Q (cid:3) 2 α k ∇ f Tk Q ( x k − x ∗ ) − α 2 k ∇ f Tk Q ∇ f k , where (cid:8) · (cid:8) Q is deﬁned by ( 3 . 27 ) . Second , use the fact that ∇ f k (cid:3) Q ( x k − x ∗ ) to obtain (cid:8) x k − x ∗ (cid:8) 2 Q − (cid:8) x k + 1 − x ∗ (cid:8) 2 Q (cid:3) 2 ( ∇ f Tk ∇ f k ) 2 ( ∇ f Tk Q ∇ f k ) − ( ∇ f Tk ∇ f k ) 2 ( ∇ f Tk Q ∇ f k ) and (cid:8) x k − x ∗ (cid:8) 2 Q (cid:3) ∇ f Tk Q − 1 ∇ f k . ✐ 3 . 8 Let Q be a positive deﬁnite symmetric matrix . Prove that for any vector x , we have ( x T x ) 2 ( x T Qx ) ( x T Q − 1 x ) ≥ 4 λ n λ 1 ( λ n + λ 1 ) 2 , where λ n and λ 1 are , respectively , the largest and smallest eigenvalues of Q . ( This relation , which is known as the Kantorovich inequality , can be used to deduce ( 3 . 29 ) from ( 3 . 28 ) . ) ✐ 3 . 9 Program the BFGS algorithm using the line search algorithm described in this chapter that implements the strong Wolfe conditions . Have the code verify that y Tk s k is always positive . Use it to minimize the Rosenbrock function using the starting points given in Exercise 3 . 1 . ✐ 3 . 10 Compute the eigenvalues of the 2 diagonal blocks of ( 3 . 52 ) and verify that each block has a positive and a negative eigenvalue . Then compute the eigenvalues of A and verify that its inertia is the same as that of B . ✐ 3 . 11 Describe the effect that the modiﬁed Cholesky factorization ( 3 . 50 ) would have on the Hessian ∇ 2 f ( x k ) (cid:3) diag ( − 2 , 12 , 4 ) . ✐ 3 . 12 Consider a block diagonal matrix B with 1 × 1 and 2 × 2 blocks . Show that the eigenvalues and eigenvectors of B can be obtained by computing the spectral decomposition of each diagonal block separately . ✐ 3 . 13 Show that the quadratic function that interpolates φ ( 0 ) , φ (cid:14) ( 0 ) , and φ ( α 0 ) is given by ( 3 . 57 ) . Then , make use of the fact that the sufﬁcient decrease condition ( 3 . 6a ) is not satisﬁed at α 0 to show that this quadratic has positive curvature and that the minimizer satisﬁes α 1 < α 0 2 ( 1 − c 1 ) . 3 . 5 . S T E P - L E N G T H S E L E C T I O N A L G O R I T H M S 65 Since c 1 is chosen to be quite small in practice , this inequality indicates that α 1 cannot be much greater than 12 ( and may be smaller ) , which gives us an idea of the new step length . ✐ 3 . 14 If φ ( α 0 ) is large , ( 3 . 58 ) shows that α 1 can be quite small . Give an example of a function and a step length α 0 for which this situation arises . ( Drastic changes to the estimate of the step length are not desirable , since they indicate that the current interpolant does not provide a good approximation to the function and that it should be modiﬁed before being trusted to produce a good step length estimate . In practice , one imposes a lower bound— typically , ρ (cid:3) 0 . 1—and deﬁnes the new step length as α i (cid:3) max ( ρα i − 1 , ˆ α i ) , where ˆ α i is the minimizer of the interpolant . ) ✐ 3 . 15 Suppose that the sufﬁcient decrease condition ( 3 . 6a ) is not satisﬁed at the step lengths α 0 , and α 1 , and consider the cubic interpolating φ ( 0 ) , φ (cid:14) ( 0 ) , φ ( α 0 ) and φ ( α 1 ) . By drawing graphs illustrating the two situations that can arise , show that the mini - mizer of the cubic lies in [ 0 , α 1 ] . Then show that if φ ( 0 ) < φ ( α 1 ) , the minimizer is less than 23 α 1 . This is pag Printer : O C H A P T E R 4 Trust - Region Methods Line search methods and trust - region methods both generate steps with the help of a quadratic model of the objective function , but they use this model in different ways . Line search methods use it to generate a search direction , and then focus their efforts on ﬁnding a suitable step length α along this direction . Trust - region methods deﬁne a region around the current iterate within which they trust the model to be an adequate representation of the objective function , and then choose the step to be the approximate minimizer of the model in this region . In effect , they choose the direction and length of the step simul - taneously . If a step is not acceptable , they reduce the size of the region and ﬁnd a new C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S 67 minimizer . In general , the direction of the step changes whenever the size of the trust region is altered . The size of the trust region is critical to the effectiveness of each step . If the region is too small , the algorithm misses an opportunity to take a substantial step that will move it much closer to the minimizer of the objective function . If too large , the minimizer of the model may be far from the minimizer of the objective function in the region , so we may have to reduce the size of the region and try again . In practical algorithms , we choose the size of the region according to the performance of the algorithm during previous iterations . If the model is consistently reliable , producing good steps and accurately predicting the behavior of the objective function along these steps , the size of the trust region may be increased to allow longer , more ambitious , steps to be taken . A failed step is an indication that our model is an inadequate representation of the objective function over the current trust region . After such a step , we reduce the size of the region and try again . Figure 4 . 1 illustrates the trust - region approach on a function f of two variables in which the current point x k and the minimizer x ∗ lie at opposite ends of a curved valley . The quadratic model function m k , whose elliptical contours are shown as dashed lines , is constructedfromfunctionandderivativeinformationat x k andpossiblyalsooninformation accumulated from previous iterations and steps . A line search method based on this model searches along the step to the minimizer of m k ( shown ) , but this direction will yield at most a small reduction in f , even if the optimal steplength is used . The trust - region method steps to the minimizer of m k within the dotted circle ( shown ) , yielding a more signiﬁcant reduction in f and better progress toward the solution . In this chapter , we will assume that the model function m k that is used at each iterate x k is quadratic . Moreover , m k is based on the Taylor - series expansion of f around k contours of contours of f Trust region step Trust region m Line search direction Figure 4 . 1 Trust - region and line search steps . 68 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S x k , which is f ( x k + p ) (cid:3) f k + g Tk p + 12 p T ∇ 2 f ( x k + tp ) p , ( 4 . 1 ) where f k (cid:3) f ( x k ) and g k (cid:3) ∇ f ( x k ) , and t is some scalar in the interval ( 0 , 1 ) . By using an approximation B k to the Hessian in the second - order term , m k is deﬁned as follows : m k ( p ) (cid:3) f k + g Tk p + 12 p T B k p , ( 4 . 2 ) where B k is some symmetric matrix . The difference between m k ( p ) and f ( x k + p ) is O (cid:7) (cid:8) p (cid:8) 2 (cid:8) , which is small when p is small . When B k is equal to the true Hessian ∇ 2 f ( x k ) , the approximation error in the model function m k is O (cid:7) (cid:8) p (cid:8) 3 (cid:8) , so this model is especially accurate when (cid:8) p (cid:8) is small . This choice B k (cid:3) ∇ 2 f ( x k ) leads to the trust - region Newton method , and will be discussed further in Section 4 . 4 . In other sections of this chapter , we emphasize the generality of the trust - region approach by assuming little about B k except symmetry and uniform boundedness . To obtain each step , we seek a solution of the subproblem min p ∈ IR n m k ( p ) (cid:3) f k + g Tk p + 12 p T B k p s . t . (cid:8) p (cid:8) ≤ (cid:6) k , ( 4 . 3 ) where (cid:6) k > 0 is the trust - region radius . In most of our discussions , we deﬁne (cid:8) · (cid:8) to be the Euclidean norm , so that the solution p ∗ k of ( 4 . 3 ) is the minimizer of m k in the ball of radius (cid:6) k . Thus , the trust - region approach requires us to solve a sequence of subproblems ( 4 . 3 ) in which the objective function and constraint ( which can be written as p T p ≤ (cid:6) 2 k ) are both quadratic . When B k is positive deﬁnite and (cid:8) B − 1 k g k (cid:8) ≤ (cid:6) k , the solution of ( 4 . 3 ) is easy to identify—it is simply the unconstrained minimum p B k (cid:3) − B − 1 k g k of the quadratic m k ( p ) . In this case , we call p B k the full step . The solution of ( 4 . 3 ) is not so obvious in other cases , but it can usually be found without too much computational expense . In any case , as described below , we need only an approximate solution to obtain convergence and good practical behavior . OUTLINE OF THE TRUST - REGION APPROACH One of the key ingredients in a trust - region algorithm is the strategy for choosing the trust - region radius (cid:6) k at each iteration . We base this choice on the agreement between the model function m k and the objective function f at previous iterations . Given a step p k we deﬁne the ratio ρ k (cid:3) f ( x k ) − f ( x k + p k ) m k ( 0 ) − m k ( p k ) ; ( 4 . 4 ) the numerator is called the actual reduction , and the denominator is the predicted reduction ( that is , the reduction in f predicted by the model function ) . Note that since the step p k C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S 69 is obtained by minimizing the model m k over a region that includes p (cid:3) 0 , the predicted reduction will always be nonnegative . Hence , if ρ k is negative , the new objective value f ( x k + p k ) is greater than the current value f ( x k ) , so the step must be rejected . On the other hand , if ρ k is close to 1 , there is good agreement between the model m k and the function f over this step , so it is safe to expand the trust region for the next iteration . If ρ k is positive but signiﬁcantly smaller than 1 , we do not alter the trust region , but if it is close to zero or negative , we shrink the trust region by reducing (cid:6) k at the next iteration . The following algorithm describes the process . Algorithm 4 . 1 ( Trust Region ) . Given ˆ (cid:6) > 0 , (cid:6) 0 ∈ ( 0 , ˆ (cid:6) ) , and η ∈ (cid:9) 0 , 14 (cid:8) : for k (cid:3) 0 , 1 , 2 , . . . Obtain p k by ( approximately ) solving ( 4 . 3 ) ; Evaluate ρ k from ( 4 . 4 ) ; if ρ k < 14 (cid:6) k + 1 (cid:3) 14 (cid:6) k else if ρ k > 34 and (cid:8) p k (cid:8) (cid:3) (cid:6) k (cid:6) k + 1 (cid:3) min ( 2 (cid:6) k , ˆ (cid:6) ) else (cid:6) k + 1 (cid:3) (cid:6) k ; if ρ k > η x k + 1 (cid:3) x k + p k else x k + 1 (cid:3) x k ; end ( for ) . Here ˆ (cid:6) is an overall bound on the step lengths . Note that the radius is increased only if (cid:8) p k (cid:8) actually reaches the boundary of the trust region . If the step stays strictly inside the region , we infer that the current value of (cid:6) k is not interfering with the progress of the algorithm , so we leave its value unchanged for the next iteration . To turn Algorithm 4 . 1 into a practical algorithm , we need to focus on solving the trust - region subproblem ( 4 . 3 ) . In discussing this matter , we sometimes drop the iteration subscript k and restate the problem ( 4 . 3 ) as follows : min p ∈ IR n m ( p ) def (cid:3) f + g T p + 12 p T Bp s . t . (cid:8) p (cid:8) ≤ (cid:6) . ( 4 . 5 ) A ﬁrst step to characterizing exact solutions of ( 4 . 5 ) is given by the following theorem ( due to Mor ´ e and Sorensen [ 214 ] ) , which shows that the solution p ∗ of ( 4 . 5 ) satisﬁes ( B + λ I ) p ∗ (cid:3) − g ( 4 . 6 ) for some λ ≥ 0 . 70 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S Theorem 4 . 1 . The vector p ∗ is a global solution of the trust - region problem min p ∈ IR n m ( p ) (cid:3) f + g T p + 12 p T Bp , s . t . (cid:8) p (cid:8) ≤ (cid:6) , ( 4 . 7 ) if and only if p ∗ is feasible and there is a scalar λ ≥ 0 such that the following conditions are satisﬁed : ( B + λ I ) p ∗ (cid:3) − g , ( 4 . 8a ) λ ( (cid:6) − | | p ∗ | | ) (cid:3) 0 , ( 4 . 8b ) ( B + λ I ) is positive semideﬁnite . ( 4 . 8c ) We delay the proof of this result until Section 4 . 3 , and instead discuss just its key featuresherewiththehelpofFigure4 . 2 . Thecondition ( 4 . 8b ) isacomplementaritycondition that states that at least one of the nonnegative quantities λ and ( (cid:6) − (cid:8) p ∗ (cid:8) ) must be zero . Hence , when the solution lies strictly inside the trust region ( as it does when (cid:6) (cid:3) (cid:6) 1 in Figure 4 . 2 ) , we must have λ (cid:3) 0 and so Bp ∗ (cid:3) − g with B positive semideﬁnite , from ( 4 . 8a ) and ( 4 . 8c ) , respectively . In the other cases (cid:6) (cid:3) (cid:6) 2 and (cid:6) (cid:3) (cid:6) 3 , we have (cid:8) p ∗ (cid:8) (cid:3) (cid:6) , and so λ is allowed to take a positive value . Note from ( 4 . 8a ) that λ p ∗ (cid:3) − Bp ∗ − g (cid:3) −∇ m ( p ∗ ) . m 1 contours of * 3 p ∆ ∆ ∆ 2 3 p * 2 p * 1 Figure 4 . 2 Solution of trust - region subproblem for different radii (cid:6) 1 , (cid:6) 2 , (cid:6) 3 . 4 . 1 . A L G O R I T H M S B A S E D O N T H E C A U C H Y P O I N T 71 Thus , when λ > 0 , the solution p ∗ is collinear with the negative gradient of m and normal to its contours . These properties can be seen in Figure 4 . 2 . In Section 4 . 1 , we describe two strategies for ﬁnding approximate solutions of the subproblem ( 4 . 3 ) , which achieve at least as much reduction in m k as the reduction achieved by the so - called Cauchy point . This point is simply the minimizer of m k along the steepest descent direction − g k . subject to the trust - region bound . The ﬁrst approximate strategy is the dogleg method , which is appropriate when the model Hessian B k is positive deﬁnite . The second strategy , known as two - dimensional subspace minimization , can be applied when B k is indeﬁnite , though it requires an estimate of the most negative eigenvalue of this matrix . A third strategy , described in Section 7 . 1 , uses an approach based on the conjugate gradient method to minimize m k , and can therefore be applied when B is large and sparse . Section 4 . 3 is devoted to a strategy in which an iterative method is used to identify the value of λ for which ( 4 . 6 ) is satisﬁed by the solution of the subproblem . We prove global convergence results in Section 4 . 2 . Section 4 . 4 discusses the trust - region Newton method , in which the Hessian B k of the model function is equal to the Hessian ∇ 2 f ( x k ) of the objective function . The key result of this section is that , when the trust - region Newton algorithm con - verges to a point x ∗ satisfying second - order sufﬁcient conditions , it converges superlinearly . 4 . 1 ALGORITHMS BASED ON THE CAUCHY POINT THE CAUCHY POINT As we saw in Chapter 3 , line search methods can be globally convergent even when the optimal step length is not used at each iteration . In fact , the step length α k need only satisfy fairlyloosecriteria . Asimilarsituationappliesintrust - regionmethods . Althoughinprinciple we seek the optimal solution of the subproblem ( 4 . 3 ) , it is enough for purposes of global convergence to ﬁnd an approximate solution p k that lies within the trust region and gives a sufﬁcient reduction in the model . The sufﬁcient reduction can be quantiﬁed in terms of the Cauchy point , which we denote by p C k and deﬁne in terms of the following simple procedure . Algorithm 4 . 2 ( Cauchy Point Calculation ) . Find the vector p S k that solves a linear version of ( 4 . 3 ) , that is , p S k (cid:3) arg min p ∈ IR n f k + g Tk p s . t . (cid:8) p (cid:8) ≤ (cid:6) k ; ( 4 . 9 ) Calculate the scalar τ k > 0 that minimizes m k ( τ p S k ) subject to satisfying the trust - region bound , that is , τ k (cid:3) arg min τ ≥ 0 m k ( τ p S k ) s . t . (cid:8) τ p S k (cid:8) ≤ (cid:6) k ; ( 4 . 10 ) Set p C k (cid:3) τ k p S k . 72 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S It is easy to write down a closed - form deﬁnition of the Cauchy point . For a start , the solution of ( 4 . 9 ) is simply p S k (cid:3) − (cid:6) k (cid:8) g k (cid:8) g k . To obtain τ k explicitly , we consider the cases of g Tk B k g k ≤ 0 and g Tk B k g k > 0 separately . For the former case , the function m k ( τ p S k ) decreases monotonically with τ whenever g k (cid:9)(cid:3) 0 , so τ k is simply the largest value that satisﬁes the trust - region bound , namely , τ k (cid:3) 1 . For the case g Tk B k g k > 0 , m k ( τ p S k ) is a convex quadratic in τ , so τ k is either the unconstrained minimizer of this quadratic , (cid:8) g k (cid:8) 3 / ( (cid:6) k g Tk B k g k ) , or the boundary value 1 , whichever comes ﬁrst . In summary , we have p C k (cid:3) − τ k (cid:6) k (cid:8) g k (cid:8) g k , ( 4 . 11 ) where τ k (cid:3) (cid:21) 1 if g Tk B k g k ≤ 0 ; min (cid:7) (cid:8) g k (cid:8) 3 / ( (cid:6) k g Tk B k g k ) , 1 (cid:8) otherwise . ( 4 . 12 ) Figure 4 . 3 illustrates the Cauchy point for a subproblem in which B k is positive deﬁnite . In this example , p C k lies strictly inside the trust region . The Cauchy step p C k is inexpensive to calculate—no matrix factorizations are required—and is of crucial importance in deciding if an approximate solution of the trust - region subproblem is acceptable . Speciﬁcally , a trust - region method will be globally — k C m k g k Trust region contours of p Figure 4 . 3 The Cauchy point . 4 . 1 . A L G O R I T H M S B A S E D O N T H E C A U C H Y P O I N T 73 convergent if its steps p k give a reduction in the model m k that is at least some ﬁxed positive multiple of the decrease attained by the Cauchy step . IMPROVING ON THE CAUCHY POINT Since the Cauchy point p C k provides sufﬁcient reduction in the model function m k to yield global convergence , and since the cost of calculating it is so small , why should we look any further for a better approximate solution of ( 4 . 3 ) ? The reason is that by always taking the Cauchy point as our step , we are simply implementing the steepest descent method with a particular choice of step length . As we have seen in Chap - ter 3 , steepest descent performs poorly even if an optimal step length is used at each iteration . The Cauchy point does not depend very strongly on the matrix B k , which is used only in the calculation of the step length . Rapid convergence can be expected only if B k plays a role in determining the direction of the step as well as its length , and if B k contains valid curvature information about the function . A number of trust - region algorithms compute the Cauchy point and then try to improve on it . The improvement strategy is often designed so that the full step p B k (cid:3) − B − 1 k g k is chosen whenever B k is positive deﬁnite and (cid:8) p B k (cid:8) ≤ (cid:6) k . When B k is the exact Hessian ∇ 2 f ( x k ) oraquasi - Newtonapproximation , thisstrategycanbeexpectedtoyieldsuperlinear convergence . We now consider three methods for ﬁnding approximate solutions to ( 4 . 3 ) that have the features just described . Throughout this section we will be focusing on the internal workings of a single iteration , so we simplify the notation by dropping the subscript “ k ” from the quantities (cid:6) k , p k , m k , and g k and refer to the formulation ( 4 . 5 ) of the subproblem . In this section , we denote the solution of ( 4 . 5 ) by p ∗ ( (cid:6) ) , to emphasize the dependence on (cid:6) . THE DOGLEG METHOD The ﬁrst approach we discuss goes by the descriptive title of the dogleg method . It can be used when B is positive deﬁnite . To motivate this method , we start by examining the effect of the trust - region radius (cid:6) on the solution p ∗ ( (cid:6) ) of the subproblem ( 4 . 5 ) . When B is positive deﬁnite , we have already noted that the unconstrained minimizer of m is p B (cid:3) − B − 1 g . When this point is feasible for ( 4 . 5 ) , it is obviously a solution , so we have p ∗ ( (cid:6) ) (cid:3) p B , when (cid:6) ≥ (cid:8) p B (cid:8) . ( 4 . 13 ) When (cid:6) is small relative to p B , the restriction (cid:8) p (cid:8) ≤ (cid:6) ensures that the quadratic term in m has little effect on the solution of ( 4 . 5 ) . For such (cid:6) , we can get an approximation to p ( (cid:6) ) 74 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S ) ∆ p B full step ( ) —g ) p U — g Trust region p Optimal trajectory dogleg path unconstrained min along ( ( Figure 4 . 4 Exact trajectory and dogleg approximation . by simply omitting the quadratic term from ( 4 . 5 ) and writing p ∗ ( (cid:6) ) ≈ − (cid:6) g (cid:8) g (cid:8) , when (cid:6) is small . ( 4 . 14 ) For intermediate values of (cid:6) , the solution p ∗ ( (cid:6) ) typically follows a curved trajectory like the one in Figure 4 . 4 . The dogleg method ﬁnds an approximate solution by replacing the curved trajectory for p ∗ ( (cid:6) ) with a path consisting of two line segments . The ﬁrst line segment runs from the origin to the minimizer of m along the steepest descent direction , which is p U (cid:3) − g T g g T Bg g , ( 4 . 15 ) while the second line segment runs from p U to p B ( see Figure 4 . 4 ) . Formally , we denote this trajectory by ˜ p ( τ ) for τ ∈ [ 0 , 2 ] , where ˜ p ( τ ) (cid:3) (cid:21) τ p U , 0 ≤ τ ≤ 1 , p U + ( τ − 1 ) ( p B − p U ) , 1 ≤ τ ≤ 2 . ( 4 . 16 ) The dogleg method chooses p to minimize the model m along this path , subject to the trust - region bound . The following lemma shows that the minimum along the dogleg path can be found easily . 4 . 1 . A L G O R I T H M S B A S E D O N T H E C A U C H Y P O I N T 75 Lemma 4 . 2 . Let B be positive deﬁnite . Then ( i ) (cid:8) ˜ p ( τ ) (cid:8) is an increasing function of τ , and ( ii ) m ( ˜ p ( τ ) ) is a decreasing function of τ . P ROOF . It is easy to show that ( i ) and ( ii ) both hold for τ ∈ [ 0 , 1 ] , so we restrict our attention to the case of τ ∈ [ 1 , 2 ] . For ( i ) , deﬁne h ( α ) by h ( α ) (cid:3) 12 (cid:8) ˜ p ( 1 + α ) (cid:8) 2 (cid:3) 12 (cid:8) p U + α ( p B − p U ) (cid:8) 2 (cid:3) 12 (cid:8) p U (cid:8) 2 + α ( p U ) T ( p B − p U ) + 12 α 2 (cid:8) p B − p U (cid:8) 2 . Our result is proved if we can show that h (cid:14) ( α ) ≥ 0 for α ∈ ( 0 , 1 ) . Now , h (cid:14) ( α ) (cid:3) − ( p U ) T ( p U − p B ) + α (cid:8) p U − p B (cid:8) 2 ≥ − ( p U ) T ( p U − p B ) (cid:3) g T g g T Bg g T (cid:17) − g T g g T Bg g + B − 1 g (cid:18) (cid:3) g T g gB − 1 g g T Bg (cid:26) 1 − ( g T g ) 2 ( g T Bg ) ( g T B − 1 g ) (cid:27) ≥ 0 , where the ﬁnal inequality is a consequence of the Cauchy - Schwarz inequality . ( We leave the details as an exercise . ) For ( ii ) , we deﬁne ˆ h ( α ) (cid:3) m ( ˜ p ( 1 + α ) ) and show that ˆ h (cid:14) ( α ) ≤ 0 for α ∈ ( 0 , 1 ) . Substitution of ( 4 . 16 ) into ( 4 . 5 ) and differentiation with respect to the argument leads to ˆ h (cid:14) ( α ) (cid:3) ( p B − p U ) T ( g + B p U ) + α ( p B − p U ) T B ( p B − p U ) ≤ ( p B − p U ) T ( g + B p U + B ( p B − p U ) ) (cid:3) ( p B − p U ) T ( g + B p B ) (cid:3) 0 , giving the result . (cid:1) It follows from this lemma that the path ˜ p ( τ ) intersects the trust - region boundary (cid:8) p (cid:8) (cid:3) (cid:6) at exactly one point if (cid:8) p B (cid:8) ≥ (cid:6) , and nowhere otherwise . Since m is decreasing along the path , the chosen value of p will be at p B if (cid:8) p B (cid:8) ≤ (cid:6) , otherwise at the point of intersection of the dogleg and the trust - region boundary . In the latter case , we compute the appropriate value of τ by solving the following scalar quadratic equation : (cid:8) p U + ( τ − 1 ) ( p B − p U ) (cid:8) 2 (cid:3) (cid:6) 2 . 76 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S Consider now the case in which the exact Hessian ∇ 2 f ( x k ) is available for use in the model problem ( 4 . 5 ) . When ∇ 2 f ( x k ) is positive deﬁnite , we can simply set B (cid:3) ∇ 2 f ( x k ) ( that is , p B (cid:3) ( ∇ 2 f ( x k ) ) − 1 g k ) and apply the procedure above to ﬁnd the Newton - dogleg step . Otherwise , we can deﬁne p B by choosing B to be one of the positive deﬁnite modiﬁed Hessians described in Section 3 . 4 , then proceed as above to ﬁnd the dogleg step . Near a solution satisfying second - order sufﬁcient conditions ( see Theorem 2 . 4 ) , p B will be set to the usual Newton step , allowing the possibility of rapid local convergence of Newton’s method ( see Section 4 . 4 ) . The use of a modiﬁed Hessian in the Newton - dogleg method is not completely satisfying from an intuitive viewpoint , however . A modiﬁed factorization perturbs the diagonals of ∇ 2 f ( x k ) in a somewhat arbitrary manner , and the beneﬁts of the trust - region approach may not be realized . In fact , the modiﬁcation introduced during the factorization of the Hessian is redundant in some sense because the trust - region strategy introduces its own modiﬁcation . As we show in Section 4 . 3 , the exact solution of the trust - region problem ( 4 . 3 ) with B k (cid:3) ∇ 2 f ( x k ) is ( ∇ 2 f ( x k ) + λ I ) − 1 g k , where λ is chosen large enough to make ( ∇ 2 f ( x k ) + λ I ) positive deﬁnite , and its value depends on the trust - region radius (cid:6) k . We conclude that the Newton - dogleg method is most appropriate when the objective function is convex ( that is , ∇ 2 f ( x k ) is always positive semideﬁnite ) . The techniques described below may be more suitable for the general case . The dogleg strategy can be adapted to handle indeﬁnite matrices B , but there is not much point in doing so because the full step p B is not the unconstrained minimizer of m in this case . Instead , we now describe another strategy , which aims to include directions of negative curvature ( that is , directions d for which d T Bd < 0 ) in the space of candidate trust - region steps . TWO - DIMENSIONAL SUBSPACE MINIMIZATION When B is positive deﬁnite , the dogleg method strategy can be made slightly more sophisticated by widening the search for p to the entire two - dimensional subspace spanned by p U and p B ( equivalently , g and − B − 1 g ) . The subproblem ( 4 . 5 ) is replaced by min p m ( p ) (cid:3) f + g T p + 1 2 p T Bp s . t . (cid:8) p (cid:8) ≤ (cid:6) , p ∈ span [ g , B − 1 g ] . ( 4 . 17 ) This is a problem in two variables that is computationally inexpensive to solve . ( After some algebraic manipulation it can be reduced to ﬁnding the roots of a fourth degree polynomial . ) Clearly , the Cauchy point p C is feasible for ( 4 . 17 ) , so the optimal solution of this subproblem yields at least as much reduction in m as the Cauchy point , resulting in global convergence of the algorithm . The two - dimensional subspace minimization strategy is obviously an extension of the dogleg method as well , since the entire dogleg path lies in span [ g , B − 1 g ] . Thisstrategycanbemodiﬁedtohandlethecaseofindeﬁnite B inawaythatisintuitive , practical , and theoretically sound . We mention just the salient points of the handling of the 4 . 2 . G L O B A L C O N V E R G E N C E 77 indeﬁniteness here , and refer the reader to papers by Byrd , Schnabel , and Schultz ( see [ 54 ] and [ 279 ] ) for details . When B has negative eigenvalues , the two - dimensional subspace in ( 4 . 17 ) is changed to span [ g , ( B + α I ) − 1 g ] , for some α ∈ ( − λ 1 , − 2 λ 1 ] , ( 4 . 18 ) where λ 1 denotes the most negative eigenvalue of B . ( This choice of α ensures that B + α I is positive deﬁnite , and the ﬂexibility in the choice of α allows us to use a numerical procedure such as the Lanczos method to compute it . ) When (cid:8) ( B + α I ) − 1 g (cid:8) ≤ (cid:6) , we discard the subspace search of ( 4 . 17 ) , ( 4 . 18 ) and instead deﬁne the step to be p (cid:3) − ( B + α I ) − 1 g + v , ( 4 . 19 ) where v is a vector that satisﬁes v T ( B + α I ) − 1 g ≤ 0 . ( This condition ensures that (cid:8) p (cid:8) ≥ (cid:8) ( B + α I ) − 1 g (cid:8) . ) When B has zero eigenvalues but no negative eigenvalues , we deﬁne the step to be the Cauchy point p (cid:3) p C . When the exact Hessian is available , we can set B (cid:3) ∇ 2 f ( x k ) , and note that B − 1 g is the Newton step . Hence , when the Hessian is positive deﬁnite at the solution x ∗ and when x k is close to x ∗ and (cid:6) is sufﬁciently large , the subspace minimization problem ( 4 . 17 ) will be solved by the Newton step . The reduction in model function m achieved by the two - dimensional subspace min - imization strategy often is close to the reduction achieved by the exact solution of ( 4 . 5 ) . Most of the computational effort lies in a single factorization of B or B + α I ( estimation of α and solution of ( 4 . 17 ) are less signiﬁcant ) , while strategies that ﬁnd nearly exact solutions of ( 4 . 5 ) typically require two or three such factorizations ( see Section 4 . 3 ) . 4 . 2 GLOBAL CONVERGENCE REDUCTION OBTAINED BY THE CAUCHY POINT In the preceding discussion of algorithms for approximately solving the trust - region subproblem , we have repeatedly emphasized that global convergence depends on the ap - proximate solution obtaining at least as much decrease in the model function m as the Cauchy point . ( In fact , a ﬁxed positive fraction of the Cauchy decrease sufﬁces . ) We start the global convergence analysis by obtaining an estimate of the decrease in m achieved by the Cauchy point . We then use this estimate to prove that the sequence of gradients { g k } generated by Algorithm 4 . 1 has an accumulation point at zero , and in fact converges to zero when η is strictly positive . Our ﬁrst main result is that the dogleg and two - dimensional subspace minimization algorithms and Steihaug’s algorithm ( Algorithm 7 . 2 ) produce approximate solutions p k of the subproblem ( 4 . 3 ) that satisfy the following estimate of decrease in the model function : m k ( 0 ) − m k ( p k ) ≥ c 1 (cid:8) g k (cid:8) min (cid:17) (cid:6) k , (cid:8) g k (cid:8) (cid:8) B k (cid:8) (cid:18) , ( 4 . 20 ) 78 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S for some constant c 1 ∈ ( 0 , 1 ] . The usefulness of this estimate will become clear in the following two sections . For now , we note that when (cid:6) k is the minimum value in ( 4 . 20 ) , the condition is slightly reminiscent of the ﬁrst Wolfe condition : The desired reduction in the model is proportional to the gradient and the size of the step . We show now that the Cauchy point p C k satisﬁes ( 4 . 20 ) , with c 1 (cid:3) 12 . Lemma 4 . 3 . The Cauchy point p C k satisﬁes ( 4 . 20 ) with c 1 (cid:3) 12 , that is , m k ( 0 ) − m k ( p C k ) ≥ 12 (cid:8) g k (cid:8) min (cid:17) (cid:6) k , (cid:8) g k (cid:8) (cid:8) B k (cid:8) (cid:18) . ( 4 . 21 ) P ROOF . For simplicity , we drop the iteration index k in the proof . We consider ﬁrst the case g T Bg ≤ 0 . Here , we have m ( p C ) − m ( 0 ) (cid:3) m ( − (cid:6) g / (cid:8) g (cid:8) ) − f (cid:3) − (cid:6) (cid:8) g (cid:8)(cid:8) g (cid:8) 2 + 12 (cid:6) 2 (cid:8) g (cid:8) 2 g T Bg ≤ − (cid:6) (cid:8) g (cid:8) ≤ −(cid:8) g (cid:8) min (cid:17) (cid:6) , (cid:8) g (cid:8) (cid:8) B (cid:8) (cid:18) , and so ( 4 . 21 ) certainly holds . For the next case , consider g T Bg > 0 and (cid:8) g (cid:8) 3 (cid:6) g T Bg ≤ 1 . ( 4 . 22 ) From ( 4 . 12 ) , we have τ (cid:3) (cid:8) g (cid:8) 3 / (cid:7) (cid:6) g T Bg (cid:8) , and so from ( 4 . 11 ) it follows that m ( p C ) − m ( 0 ) (cid:3) − (cid:8) g (cid:8) 4 g T Bg + 12 g T Bg (cid:8) g (cid:8) 4 ( g T Bg ) 2 (cid:3) − 12 (cid:8) g (cid:8) 4 g T Bg ≤ − 12 (cid:8) g (cid:8) 4 (cid:8) B (cid:8)(cid:8) g (cid:8) 2 (cid:3) − 12 (cid:8) g (cid:8) 2 (cid:8) B (cid:8) ≤ − 12 (cid:8) g (cid:8) min (cid:17) (cid:6) , (cid:8) g (cid:8) (cid:8) B (cid:8) (cid:18) , so ( 4 . 21 ) holds here too . In the remaining case , ( 4 . 22 ) does not hold , and therefore g T Bg < (cid:8) g (cid:8) 3 (cid:6) . ( 4 . 23 ) 4 . 2 . G L O B A L C O N V E R G E N C E 79 From ( 4 . 12 ) , we have τ (cid:3) 1 , and using this fact together with ( 4 . 23 ) , we obtain m ( p C ) − m ( 0 ) (cid:3) − (cid:6) (cid:8) g (cid:8)(cid:8) g (cid:8) 2 + 1 2 (cid:6) 2 (cid:8) g (cid:8) 2 g T Bg ≤ − (cid:6) (cid:8) g (cid:8) + 1 2 (cid:6) 2 (cid:8) g (cid:8) 2 (cid:8) g (cid:8) 3 (cid:6) (cid:3) − 1 2 (cid:6) (cid:8) g (cid:8) ≤ − 12 (cid:8) g (cid:8) min (cid:17) (cid:6) , (cid:8) g (cid:8) (cid:8) B (cid:8) (cid:18) , yielding the desired result ( 4 . 21 ) once again . (cid:1) To satisfy ( 4 . 20 ) , our approximate solution p k has only to achieve a reduction that is at least some ﬁxed fraction c 2 of the reduction achieved by the Cauchy point . We state the observation formally as a theorem . Theorem 4 . 4 . Let p k be any vector such that (cid:8) p k (cid:8) ≤ (cid:6) k and m k ( 0 ) − m k ( p k ) ≥ c 2 (cid:7) m k ( 0 ) − m k ( p C k ) (cid:8) . Then p k satisﬁes ( 4 . 20 ) with c 1 (cid:3) c 2 / 2 . In particular , if p k is the exact solution p ∗ k of ( 4 . 3 ) , then it satisﬁes ( 4 . 20 ) with c 1 (cid:3) 12 . P ROOF . Since (cid:8) p k (cid:8) ≤ (cid:6) k , we have from Lemma 4 . 3 that m k ( 0 ) − m k ( p k ) ≥ c 2 (cid:7) m k ( 0 ) − m k ( p C k ) (cid:8) ≥ 12 c 2 (cid:8) g k (cid:8) min (cid:17) (cid:6) k , (cid:8) g k (cid:8) (cid:8) B k (cid:8) (cid:18) , giving the result . (cid:1) Note that the dogleg and two - dimensional subspace minimization algorithms both satisfy ( 4 . 20 ) with c 1 (cid:3) 12 , because they all produce approximate solutions p k for which m k ( p k ) ≤ m k ( p C k ) . CONVERGENCE TO STATIONARY POINTS Global convergence results for trust - region methods come in two varieties , depending on whether we set the parameter η in Algorithm 4 . 1 to zero or to some small positive value . When η (cid:3) 0 ( that is , the step is taken whenever it produces a lower value of f ) , we can show that the sequence of gradients { g k } has a limit point at zero . For the more stringent acceptance test with η > 0 , which requires the actual decrease in f to be at least some small fraction of the predicted decrease , we have the stronger result that g k → 0 . In this section we prove the global convergence results for both cases . We assume throughout that the approximate Hessians B k are uniformly bounded in norm , and that f 80 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S is bounded below on the level set S def (cid:3) { x | f ( x ) ≤ f ( x 0 ) } . ( 4 . 24 ) For later reference , we deﬁne an open neighborhood of this set by S ( R 0 ) def (cid:3) { x | (cid:8) x − y (cid:8) < R 0 for some y ∈ S } , where R 0 is a positive constant . To allow our results to be applied more generally , we also allow the length of the approximate solution p k of ( 4 . 3 ) to exceed the trust - region bound , provided that it stays within some ﬁxed multiple of the bound ; that is , (cid:8) p k (cid:8) ≤ γ (cid:6) k , for some constant γ ≥ 1 . ( 4 . 25 ) The ﬁrst result deals with the case η (cid:3) 0 . Theorem 4 . 5 . Let η (cid:3) 0 in Algorithm 4 . 1 . Suppose that (cid:8) B k (cid:8) ≤ β for some constant β , that f is bounded below on the level set S deﬁned by ( 4 . 24 ) and Lipschitz continuously differentiable in the neighborhood S ( R 0 ) for some R 0 > 0 , and that all approximate solutions of ( 4 . 3 ) satisfy the inequalities ( 4 . 20 ) and ( 4 . 25 ) , for some positive constants c 1 and γ . We then have lim inf k →∞ (cid:8) g k (cid:8) (cid:3) 0 . ( 4 . 26 ) P ROOF . By performing some technical manipulation with the ratio ρ k from ( 4 . 4 ) , we obtain | ρ k − 1 | (cid:3) (cid:28)(cid:28)(cid:28)(cid:28) ( f ( x k ) − f ( x k + p k ) ) − ( m k ( 0 ) − m k ( p k ) ) m k ( 0 ) − m k ( p k ) (cid:28)(cid:28)(cid:28)(cid:28) (cid:3) (cid:28)(cid:28)(cid:28)(cid:28) m k ( p k ) − f ( x k + p k ) m k ( 0 ) − m k ( p k ) (cid:28)(cid:28)(cid:28)(cid:28) . Since from Taylor’s theorem ( Theorem 2 . 1 ) we have that f ( x k + p k ) (cid:3) f ( x k ) + g ( x k ) T p k + (cid:6) 1 0 [ g ( x k + tp k ) − g ( x k ) ] T p k dt , for some t ∈ ( 0 , 1 ) , it follows from the deﬁnition ( 4 . 2 ) of m k that | m k ( p k ) − f ( x k + p k ) | (cid:3) (cid:28)(cid:28)(cid:28)(cid:28) 12 p Tk B k p k − (cid:6) 1 0 [ g ( x k + tp k ) − g ( x k ) ] T p k dt (cid:28)(cid:28)(cid:28)(cid:28) ≤ ( β / 2 ) (cid:8) p k (cid:8) 2 + β 1 (cid:8) p k (cid:8) 2 , ( 4 . 27 ) 4 . 2 . G L O B A L C O N V E R G E N C E 81 where we have used β 1 to denote the Lipschitz constant for g on the set S ( R 0 ) , and assumed that (cid:8) p k (cid:8) ≤ R 0 to ensure that x k and x k + tp k both lie in the set S ( R 0 ) . Suppose for contradiction that there is (cid:9) > 0 and a positive index K such that (cid:8) g k (cid:8) ≥ (cid:9) , for all k ≥ K . ( 4 . 28 ) From ( 4 . 20 ) , we have for k ≥ K that m k ( 0 ) − m k ( p k ) ≥ c 1 (cid:8) g k (cid:8) min (cid:17) (cid:6) k , (cid:8) g k (cid:8) (cid:8) B k (cid:8) (cid:18) ≥ c 1 (cid:9) min (cid:17) (cid:6) k , (cid:9) β (cid:18) . ( 4 . 29 ) Using ( 4 . 29 ) , ( 4 . 27 ) , and the bound ( 4 . 25 ) , we have | ρ k − 1 | ≤ γ 2 (cid:6) 2 k ( β / 2 + β 1 ) c 1 (cid:9) min ( (cid:6) k , (cid:9) / β ) . ( 4 . 30 ) We now derive a bound on the right - hand - side that holds for all sufﬁciently small values of (cid:6) k , that is , for all (cid:6) k ≤ ¯ (cid:6) , where ¯ (cid:6) is deﬁned as follows : ¯ (cid:6) (cid:3) min (cid:17) 1 2 c 1 (cid:9) γ 2 ( β / 2 + β 1 ) , R 0 γ (cid:18) . ( 4 . 31 ) The R 0 / γ term in this deﬁnition ensures that the bound ( 4 . 27 ) is valid ( because (cid:8) p k (cid:8) ≤ γ (cid:6) k ≤ γ ¯ (cid:6) ≤ R 0 ) . Note that since c 1 ≤ 1 and γ ≥ 1 , we have ¯ (cid:6) ≤ (cid:9) / β . The latter condition implies that for all (cid:6) k ∈ [ 0 , ¯ (cid:6) ] , we have min ( (cid:6) k , (cid:9) / β ) (cid:3) (cid:6) k , so from ( 4 . 30 ) and ( 4 . 31 ) , we have | ρ k − 1 | ≤ γ 2 (cid:6) 2 k ( β / 2 + β 1 ) c 1 (cid:9)(cid:6) k (cid:3) γ 2 (cid:6) k ( β / 2 + β 1 ) c 1 (cid:9) ≤ γ 2 ¯ (cid:6) ( β / 2 + β 1 ) c 1 (cid:9) ≤ 1 2 . Therefore , ρ k > 1 4 , and so by the workings of Algorithm 4 . 1 , we have (cid:6) k + 1 ≥ (cid:6) k whenever (cid:6) k falls below the threshold ¯ (cid:6) . It follows that reduction of (cid:6) k (cid:7) by a factor of 1 4 (cid:8) can occur in our algorithm only if (cid:6) k ≥ ¯ (cid:6) , and therefore we conclude that (cid:6) k ≥ min (cid:7) (cid:6) K , ¯ (cid:6) / 4 (cid:8) for all k ≥ K . ( 4 . 32 ) Suppose now that there is an inﬁnite subsequence K such that ρ k ≥ 14 for k ∈ K . For 82 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S k ∈ K and k ≥ K , we have from ( 4 . 29 ) that f ( x k ) − f ( x k + 1 ) (cid:3) f ( x k ) − f ( x k + p k ) ≥ 14 [ m k ( 0 ) − m k ( p k ) ] ≥ 14 c 1 (cid:9) min ( (cid:6) k , (cid:9) / β ) . Since f is bounded below , it follows from this inequality that lim k ∈ K , k →∞ (cid:6) k (cid:3) 0 , contradicting ( 4 . 32 ) . Hence no such inﬁnite subsequence K can exist , and we must have ρ k < 14 for all k sufﬁciently large . In this case , (cid:6) k will eventually be multiplied by 14 at every iteration , and we have lim k →∞ (cid:6) k (cid:3) 0 , which again contradicts ( 4 . 32 ) . Hence , our original assertion ( 4 . 28 ) must be false , giving ( 4 . 26 ) . (cid:1) Our second global convergence result , for the case η > 0 , borrows much of the analysis from the proof above . Our approach here follows that of Schultz , Schnabel , and Byrd [ 279 ] . Theorem 4 . 6 . Let η ∈ (cid:7) 0 , 14 (cid:8) in Algorithm 4 . 1 . Suppose that (cid:8) B k (cid:8) ≤ β for some constant β , that f is bounded below on the level set S ( 4 . 24 ) and Lipschitz continuously differentiable in S ( R 0 ) for some R 0 > 0 , and that all approximate solutions p k of ( 4 . 3 ) satisfy the inequalities ( 4 . 20 ) and ( 4 . 25 ) for some positive constants c 1 and γ . We then have lim k →∞ g k (cid:3) 0 . ( 4 . 33 ) P ROOF . We consider a particular positive index m with g m (cid:9)(cid:3) 0 . Using β 1 again to denote the Lipschitz constant for g on the set S ( R 0 ) , we have (cid:8) g ( x ) − g m (cid:8) ≤ β 1 (cid:8) x − x m (cid:8) , for all x ∈ S ( R 0 ) . We now deﬁne the scalars (cid:9) and R to satisfy (cid:9) (cid:3) 12 (cid:8) g m (cid:8) , R (cid:3) min (cid:17) (cid:9) β 1 , R 0 (cid:18) . Note that the ball B ( x m , R ) (cid:3) { x | (cid:8) x − x m (cid:8) ≤ R } is contained in S ( R 0 ) , so Lipschitz continuity of g holds inside B ( x m , R ) . We have x ∈ B ( x m , R ) ⇒ (cid:8) g ( x ) (cid:8) ≥ (cid:8) g m (cid:8) − (cid:8) g ( x ) − g m (cid:8) ≥ 12 (cid:8) g m (cid:8) (cid:3) (cid:9) . If the entire sequence { x k } k ≥ m stays inside the ball B ( x m , R ) , we would have (cid:8) g k (cid:8) ≥ (cid:9) > 0 4 . 3 . I T E R A T I V E S O L U T I O N O F T H E S U B P R O B L E M 83 for all k ≥ m . The reasoning in the proof of Theorem 4 . 5 can be used to show that this scenario does not occur . Therefore , the sequence { x k } k ≥ m eventually leaves B ( x m , R ) . Let the index l ≥ m be such that x l + 1 is the ﬁrst iterate after x m outside B ( x m , R ) . Since (cid:8) g k (cid:8) ≥ (cid:9) for k (cid:3) m , m + 1 , . . . , l , we can use ( 4 . 29 ) to write f ( x m ) − f ( x l + 1 ) (cid:3) l (cid:3) k (cid:3) m f ( x k ) − f ( x k + 1 ) ≥ (cid:3) l k (cid:3) m , x k (cid:9)(cid:3) x k + 1 η [ m k ( 0 ) − m k ( p k ) ] ≥ (cid:3) l k (cid:3) m , x k (cid:9)(cid:3) x k + 1 η c 1 (cid:9) min (cid:17) (cid:6) k , (cid:9) β (cid:18) , wherewehavelimitedthesumtotheiterations k forwhich x k (cid:9)(cid:3) x k + 1 , thatis , thoseiterations on which a step was actually taken . If (cid:6) k ≤ (cid:9) / β for all k (cid:3) m , m + 1 , . . . , l , we have f ( x m ) − f ( x l + 1 ) ≥ η c 1 (cid:9) l (cid:3) k (cid:3) m , x k (cid:9)(cid:3) x k + 1 (cid:6) k ≥ η c 1 (cid:9) R (cid:3) η c 1 (cid:9) min (cid:17) (cid:9) β 1 , R 0 (cid:18) . ( 4 . 34 ) Otherwise , we have (cid:6) k > (cid:9) / β for some k (cid:3) m , m + 1 , . . . , l , and so f ( x m ) − f ( x l + 1 ) ≥ η c 1 (cid:9) (cid:9) β . ( 4 . 35 ) Since the sequence { f ( x k ) } ∞ k (cid:3) 0 is decreasing and bounded below , we have that f ( x k ) ↓ f ∗ ( 4 . 36 ) for some f ∗ > −∞ . Therefore , using ( 4 . 34 ) and ( 4 . 35 ) , we can write f ( x m ) − f ∗ ≥ f ( x m ) − f ( x l + 1 ) ≥ η c 1 (cid:9) min (cid:17) (cid:9) β , (cid:9) β 1 , R 0 (cid:18) (cid:3) 1 2 η c 1 (cid:8) g m (cid:8) min (cid:17) (cid:8) g m (cid:8) 2 β , (cid:8) g m (cid:8) 2 β 1 , R 0 (cid:18) > 0 . Since f ( x m ) − f ∗ ↓ 0 , we must have g m → 0 , giving the result . (cid:1) 4 . 3 ITERATIVE SOLUTION OF THE SUBPROBLEM In this section , we describe a technique that uses the characterization ( 4 . 6 ) of the subprob - lem solution , applying Newton’s method to ﬁnd the value of λ which matches the given 84 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S trust - region radius (cid:6) in ( 4 . 5 ) . We also prove the key result Theorem 4 . 1 concerning the characterization of solutions of ( 4 . 3 ) . The methods of Section 4 . 1 make no serious attempt to ﬁnd the exact solution of the subproblem ( 4 . 5 ) . They do , however , make some use of the information in the model Hessian B k , and they have advantages of reasonable implementation cost and nice global convergence properties . When the problem is relatively small ( that is , n is not too large ) , it may be worthwhile to exploit the model more fully by looking for a closer approximation to the solution of the subproblem . Inthissection , wedescribeanapproachforﬁndingagoodapproximationatthe cost of a few factorizations of the matrix B ( typically three factorization ) , as compared with a single factorization for the dogleg and two - dimensional subspace minimization methods . This approach is based on the characterization of the exact solution given in Theorem 4 . 1 , together with an ingenious application of Newton’s method in one variable . Essentially , the algorithm tries to identify the value of λ for which ( 4 . 6 ) is satisﬁed by the solution of ( 4 . 5 ) . The characterization of Theorem 4 . 1 suggests an algorithm for ﬁnding the solution p of ( 4 . 7 ) . Either λ (cid:3) 0 satisﬁes ( 4 . 8a ) and ( 4 . 8c ) with (cid:8) p (cid:8) ≤ (cid:6) , or else we deﬁne p ( λ ) (cid:3) − ( B + λ I ) − 1 g for λ sufﬁciently large that B + λ I is positive deﬁnite and seek a value λ > 0 such that (cid:8) p ( λ ) (cid:8) (cid:3) (cid:6) . ( 4 . 37 ) This problem is a one - dimensional root - ﬁnding problem in the variable λ . To see that a value of λ with all the desired properties exists , we appeal to the eigende - composition of B and use it to study the properties of (cid:8) p ( λ ) (cid:8) . Since B is symmetric , there is an orthogonal matrix Q and a diagonal matrix (cid:16) such that B (cid:3) Q (cid:16) Q T , where (cid:16) (cid:3) diag ( λ 1 , λ 2 , . . . , λ n ) , and λ 1 ≤ λ 2 ≤ · · · ≤ λ n are the eigenvalues of B ; see ( A . 16 ) . Clearly , B + λ I (cid:3) Q ( (cid:16) + λ I ) Q T , and for λ (cid:9)(cid:3) λ j , we have p ( λ ) (cid:3) − Q ( (cid:16) + λ I ) − 1 Q T g (cid:3) − n (cid:3) j (cid:3) 1 q Tj g λ j + λ q j , ( 4 . 38 ) where q j denotes the j th column of Q . Therefore , by orthonormality of q 1 , q 2 , . . . , q n , we have (cid:8) p ( λ ) (cid:8) 2 (cid:3) n (cid:3) j (cid:3) 1 (cid:29) q Tj g (cid:30) 2 ( λ j + λ ) 2 . ( 4 . 39 ) 4 . 3 . I T E R A T I V E S O L U T I O N O F T H E S U B P R O B L E M 85 1 | | p | | * 3 2 Figure 4 . 5 (cid:8) p ( λ ) (cid:8) as a function of λ . This expression tells us a lot about (cid:8) p ( λ ) (cid:8) . If λ > − λ 1 , we have λ j + λ > 0 for all j (cid:3) 1 , 2 , . . . , n , and so (cid:8) p ( λ ) (cid:8) is a continuous , nonincreasing function of λ on the interval ( − λ 1 , ∞ ) . In fact , we have that lim λ →∞ (cid:8) p ( λ ) (cid:8) (cid:3) 0 . ( 4 . 40 ) Moreover , we have when q Tj g (cid:9)(cid:3) 0 that lim λ →− λ j (cid:8) p ( λ ) (cid:8) (cid:3) ∞ . ( 4 . 41 ) Figure 4 . 5 plots (cid:8) p ( λ ) (cid:8) against λ in a case in whcih q T 1 g , q T 2 g , and q T 3 g are all nonzero . Note that the properties ( 4 . 40 ) and ( 4 . 41 ) hold and that (cid:8) p ( λ ) (cid:8) is a nonincreasing function of λ on ( − λ 1 , ∞ ) . In particular , as is always the case when q T 1 g (cid:9)(cid:3) 0 , that there is a unique value λ ∗ ∈ ( − λ 1 , ∞ ) such that (cid:8) p ( λ ∗ ) (cid:8) (cid:3) (cid:6) . ( There may be other , smaller values of λ for which (cid:8) p ( λ ) (cid:8) (cid:3) (cid:6) , but these will fail to satisfy ( 4 . 8c ) . ) Wenowsketchaprocedureforidentifyingthe λ ∗ ∈ ( − λ 1 , ∞ ) forwhich (cid:8) p ( λ ∗ ) (cid:8) (cid:3) (cid:6) , which works when q T 1 g (cid:9)(cid:3) 0 . ( We discuss the case of q T 1 g (cid:3) 0 later . ) First , note that when B positive deﬁnite and (cid:8) B − 1 g (cid:8) ≤ (cid:6) , the value λ (cid:3) 0 satisﬁes ( 4 . 8 ) , so the procedure can be terminated immediately with λ ∗ (cid:3) 0 . Otherwise , we could use the root - ﬁnding Newton’s method ( see the Appendix ) to ﬁnd the value of λ > − λ 1 that solves φ 1 ( λ ) (cid:3) (cid:8) p ( λ ) (cid:8) − (cid:6) (cid:3) 0 . ( 4 . 42 ) 86 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S The disadvantage of this approach can be seen by considering the form of (cid:8) p ( λ ) (cid:8) when λ is greater than , but close to , − λ 1 . For such λ , we can approximate φ 1 by a rational function , as follows : φ 1 ( λ ) ≈ C 1 λ + λ 1 + C 2 , where C 1 > 0 and C 2 are constants . Clearly this approximation ( and hence φ 1 ) is highly nonlinear , so the root - ﬁnding Newton’s method will be unreliable or slow . Better results will be obtained if we reformulate the problem ( 4 . 42 ) so that it is nearly linear near the optimal λ . By deﬁning φ 2 ( λ ) (cid:3) 1 (cid:6) − 1 (cid:8) p ( λ ) (cid:8) , it can be shown using ( 4 . 39 ) that for λ slightly greater than − λ 1 , we have φ 2 ( λ ) ≈ 1 (cid:6) − λ + λ 1 C 3 for some C 3 > 0 . Hence , φ 2 is nearly linear near − λ 1 ( see Figure 4 . 6 ) , and the root - ﬁnding 1 | | p | | - - 1 * 3 2 1 Figure 4 . 6 1 / (cid:8) p ( λ ) (cid:8) as a function of λ . 4 . 3 . I T E R A T I V E S O L U T I O N O F T H E S U B P R O B L E M 87 Newton’s method will perform well , provided that it maintains λ > − λ 1 . The root - ﬁnding Newton’s method applied to φ 2 generates a sequence of iterates λ ( (cid:1) ) by setting λ ( (cid:1) + 1 ) (cid:3) λ ( (cid:1) ) − φ 2 (cid:7) λ ( (cid:1) ) (cid:8) φ (cid:14) 2 (cid:7) λ ( (cid:1) ) (cid:8) . ( 4 . 43 ) After some elementary manipulation , this updating formula can be implemented in the following practical way . Algorithm 4 . 3 ( Trust Region Subproblem ) . Given λ ( 0 ) , (cid:6) > 0 : for (cid:1) (cid:3) 0 , 1 , 2 , . . . Factor B + λ ( (cid:1) ) I (cid:3) R T R ; Solve R T Rp (cid:1) (cid:3) − g , R T q (cid:1) (cid:3) p (cid:1) ; Set λ ( (cid:1) + 1 ) (cid:3) λ ( (cid:1) ) + (cid:17) (cid:8) p (cid:1) (cid:8) (cid:8) q (cid:1) (cid:8) (cid:18) 2 (cid:17) (cid:8) p (cid:1) (cid:8) − (cid:6) (cid:6) (cid:18) ; ( 4 . 44 ) end ( for ) . Safeguards must be added to this algorithm to make it practical ; for instance , when λ ( (cid:1) ) < − λ 1 , the Cholesky factorization B + λ ( (cid:1) ) I (cid:3) R T R will not exist . A slightly enhanced version of this algorithm does , however , converge to a solution of ( 4 . 37 ) in most cases . Themainworkineachiterationofthismethodis , ofcourse , theCholeskyfactorization of B + λ ( (cid:1) ) I . Practical versions of this algorithm do not iterate until convergence to the optimal λ is obtained with high accuracy , but are content with an approximate solution that can be obtained in two or three iterations . THE HARD CASE Recall that in the discussion above , we assumed that q T 1 g (cid:9)(cid:3) 0 . In fact , the approach described above can be applied even when the most negative eigenvalue is a multiple eigenvalue ( that is , 0 > λ 1 (cid:3) λ 2 (cid:3) · · · ) , provided that Q T 1 g (cid:9)(cid:3) 0 , where Q 1 is the matrix whose columns span the subspace corresponding to the eigenvalue λ 1 . When this condition does not hold , the situation becomes a little complicated , because the limit ( 4 . 41 ) does not hold for λ j (cid:3) λ 1 and so there may not be a value λ ∈ ( − λ 1 , ∞ ) such that (cid:8) p ( λ ) (cid:8) (cid:3) (cid:6) ( see Figure 4 . 7 ) . Mor ´ e and Sorensen [ 214 ] refer to this case as the hard case . At ﬁrst glance , it is not clear how p and λ can be chosen to satisfy ( 4 . 8 ) in the hard case . Clearly , our root - ﬁnding technique will not work , since there is no solution for λ in the open interval ( − λ 1 , ∞ ) . But Theorem 4 . 1 assures us that the right value of λ lies in the interval [ − λ 1 , ∞ ) , so there is only 88 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S | | p | | ∆ λ λ − − − 3 2 1 λ Figure 4 . 7 The hard case : (cid:8) p ( λ ) (cid:8) < (cid:6) for all λ ∈ ( − λ 1 , ∞ ) . one possibility : λ (cid:3) − λ 1 . To ﬁnd p , it is not enough to delete the terms for which λ j (cid:3) λ 1 from the formula ( 4 . 38 ) and set p (cid:3) (cid:3) j : λ j (cid:9)(cid:3) λ 1 q Tj g λ j + λ q j . Instead , we note that ( B − λ 1 I ) is singular , so there is a vector z such that (cid:8) z (cid:8) (cid:3) 1 and ( B − λ 1 I ) z (cid:3) 0 . In fact , z is an eigenvector of B corresponding to the eigenvalue λ 1 , so by orthogonality of Q we have q Tj z (cid:3) 0 for λ j (cid:9)(cid:3) λ 1 . It follows from this property that if we set p (cid:3) (cid:3) j : λ j (cid:9)(cid:3) λ 1 q Tj g λ j + λ q j + τ z ( 4 . 45 ) for any scalar τ , we have (cid:8) p (cid:8) 2 (cid:3) (cid:3) j : λ j (cid:9)(cid:3) λ 1 (cid:29) q Tj g (cid:30) 2 ( λ j + λ ) 2 + τ 2 , so it is always possible to choose τ to ensure that (cid:8) p (cid:8) (cid:3) (cid:6) . It is easy to check that the conditions ( 4 . 8 ) holds for this choice of p and λ (cid:3) − λ 1 . 4 . 3 . I T E R A T I V E S O L U T I O N O F T H E S U B P R O B L E M 89 PROOF OF THEOREM 4 . 1 We now give a formal proof of Theorem 4 . 1 , the result that characterizes the exact solution of ( 4 . 5 ) . The proof relies on the following technical lemma , which deals with the unconstrained minimizers of quadratics and is particularly interesting in the case where the Hessian is positive semideﬁnite . Lemma 4 . 7 . Let m be the quadratic function deﬁned by m ( p ) (cid:3) g T p + 12 p T Bp , ( 4 . 46 ) where B is any symmetric matrix . Then the following statements are true . ( i ) m attains a minimum if and only if B is positive semideﬁnite and g is in the range of B . If B is positive semideﬁnite , then every p satisfying Bp (cid:3) − g is a global minimizer of m . ( ii ) m has a unique minimizer if and only if B is positive deﬁnite . P ROOF . We prove each of the three claims in turn . ( i ) We start by proving the “if” part . Since g is in the range of B , there is a p with Bp (cid:3) − g . For all w ∈ R n , we have m ( p + w ) (cid:3) g T ( p + w ) + 12 ( p + w ) T B ( p + w ) (cid:3) ( g T p + 12 p T Bp ) + g T w + ( Bp ) T w + 12 w T B w (cid:3) m ( p ) + 12 w T B w ≥ m ( p ) , ( 4 . 47 ) since B is positive semideﬁnite . Hence , p is a minimizer of m . For the “only if” part , let p be a minimizer of m . Since ∇ m ( p ) (cid:3) Bp + g (cid:3) 0 , we have that g is in the range of B . Also , we have ∇ 2 m ( p ) (cid:3) B positive semideﬁnite , giving the result . ( ii ) For the “if” part , the same argument as in ( i ) sufﬁces with the additional point that w T B w > 0 whenever w (cid:9)(cid:3) 0 . For the “only if” part , we proceed as in ( i ) to deduce that B is positive semideﬁnite . If B is not positive deﬁnite , there is a vector w (cid:9)(cid:3) 0 such that B w (cid:3) 0 . Hence , from ( 4 . 47 ) , we have m ( p + w ) (cid:3) m ( p ) , so the minimizer is not unique , giving a contradiction . (cid:1) To illustrate case ( i ) , suppose that B (cid:3) ⎡ ⎢⎣ 1 0 0 0 0 0 0 0 2 ⎤ ⎥⎦ , 90 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S which has eigenvalues 0 , 1 , 2 and is therefore singular . If g is any vector whose second component is zero , then g will be in the range of B , and the quadratic will attain a minimum . But if the second element in g is nonzero , we can decrease m ( · ) indeﬁnitely by moving along the direction ( 0 , − g 2 , 0 ) T . We are now in a position to take account of the trust - region bound (cid:8) p (cid:8) ≤ (cid:6) and hence prove Theorem 4 . 1 . P ROOF . ( Theorem 4 . 1 ) Assume ﬁrst that there is λ ≥ 0 such that the conditions ( 4 . 8 ) are satisﬁed . Lemma 4 . 7 ( i ) implies that p ∗ is a global minimum of the quadratic function ˆ m ( p ) (cid:3) g T p + 12 p T ( B + λ I ) p (cid:3) m ( p ) + λ 2 p T p . ( 4 . 48 ) Since ˆ m ( p ) ≥ ˆ m ( p ∗ ) , we have m ( p ) ≥ m ( p ∗ ) + λ 2 ( ( p ∗ ) T p ∗ − p T p ) . ( 4 . 49 ) Because λ ( (cid:6) − (cid:8) p ∗ (cid:8) ) (cid:3) 0 and therefore λ ( (cid:6) 2 − ( p ∗ ) T p ∗ ) (cid:3) 0 , we have m ( p ) ≥ m ( p ∗ ) + λ 2 ( (cid:6) 2 − p T p ) . Hence , from λ ≥ 0 , we have m ( p ) ≥ m ( p ∗ ) for all p with (cid:8) p (cid:8) ≤ (cid:6) . Therefore , p ∗ is a global minimizer of ( 4 . 7 ) . For the converse , we assume that p ∗ is a global solution of ( 4 . 7 ) and show that there is a λ ≥ 0 that satisﬁes ( 4 . 8 ) . In the case (cid:8) p ∗ (cid:8) < (cid:6) , p ∗ is an unconstrained minimizer of m , and so ∇ m ( p ∗ ) (cid:3) Bp ∗ + g (cid:3) 0 , ∇ 2 m ( p ∗ ) (cid:3) B positive semideﬁnite , and so the properties ( 4 . 8 ) hold for λ (cid:3) 0 . Assume for the remainder of the proof that (cid:8) p ∗ (cid:8) (cid:3) (cid:6) . Then ( 4 . 8b ) is immediately satisﬁed , and p ∗ also solves the constrained problem min m ( p ) subject to (cid:8) p (cid:8) (cid:3) (cid:6) . By applying optimality conditions for constrained optimization to this problem ( see ( 12 . 34 ) ) , we ﬁnd that there is a λ such that the Lagrangian function deﬁned by L ( p , λ ) (cid:3) m ( p ) + λ 2 ( p T p − (cid:6) 2 ) 4 . 3 . I T E R A T I V E S O L U T I O N O F T H E S U B P R O B L E M 91 has a stationary point at p ∗ . By setting ∇ p L ( p ∗ , λ ) to zero , we obtain Bp ∗ + g + λ p ∗ (cid:3) 0 ⇒ ( B + λ I ) p ∗ (cid:3) − g , ( 4 . 50 ) so that ( 4 . 8a ) holds . Since m ( p ) ≥ m ( p ∗ ) for any p with p T p (cid:3) ( p ∗ ) T p ∗ (cid:3) (cid:6) 2 , we have for such vectors p that m ( p ) ≥ m ( p ∗ ) + λ 2 (cid:7) ( p ∗ ) T p ∗ − p T p (cid:8) . If we substitute the expression for g from ( 4 . 50 ) into this expression , we obtain after some rearrangement that 12 ( p − p ∗ ) T ( B + λ I ) ( p − p ∗ ) ≥ 0 . ( 4 . 51 ) Since the set of directions (cid:31) w : w (cid:3) ± p − p ∗ (cid:8) p − p ∗ (cid:8) , for some p with (cid:8) p (cid:8) (cid:3) (cid:6) is dense on the unit sphere , ( 4 . 51 ) sufﬁces to prove ( 4 . 8c ) . It remains to show that λ ≥ 0 . Because ( 4 . 8a ) and ( 4 . 8c ) are satisﬁed by p ∗ , we have fromLemma4 . 7 ( i ) that p ∗ minimizes ˆ m , so ( 4 . 49 ) holds . Supposethatthereareonlynegative values of λ that satisfy ( 4 . 8a ) and ( 4 . 8c ) . Then we have from ( 4 . 49 ) that m ( p ) ≥ m ( p ∗ ) whenever (cid:8) p (cid:8) ≥ (cid:8) p ∗ (cid:8) (cid:3) (cid:6) . Since we already know that p ∗ minimizes m for (cid:8) p (cid:8) ≤ (cid:6) , it follows that m is in fact a global , unconstrained minimizer of m . From Lemma 4 . 7 ( i ) it follows that Bp (cid:3) − g and B is positive semideﬁnite . Therefore conditions ( 4 . 8a ) and ( 4 . 8c ) are satisﬁed by λ (cid:3) 0 , which contradicts our assumption that only negative values of λ can satisfy the conditions . We conclude that λ ≥ 0 , completing the proof . (cid:1) CONVERGENCE OF ALGORITHMS BASED ON NEARLY EXACT SOLUTIONS As we noted in the discussion of Algorithm 4 . 3 , the loop to determine the optimal values of λ and p for the subproblem ( 4 . 5 ) does not iterate until high accuracy is achieved . Instead , it is terminated after two or three iterations with a fairly loose approximation to the true solution . The inexactness in this approximate solution is measured in a different way from the dogleg and subspace minimization algorithms . We can add safeguards to the root - ﬁnding Newton method to ensure that the key assumptions of Theorems 4 . 5 and 4 . 6 are satisﬁed by the approximate solution . Speciﬁcally , we require that m ( 0 ) − m ( p ) ≥ c 1 ( m ( 0 ) − m ( p ∗ ) ) , ( 4 . 52a ) (cid:8) p (cid:8) ≤ γ (cid:6) ( 4 . 52b ) 92 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S ( where p ∗ is the exact solution of ( 4 . 3 ) ) , for some constants c 1 ∈ ( 0 , 1 ] and γ > 0 . The condition ( 4 . 52a ) ensures that the approximate solution achieves a signiﬁcant fraction of the maximum decrease possible in the model function m . ( It is not necessary to know p ∗ ; there are practical termination criteria that imply ( 4 . 52a ) . ) One major difference between ( 4 . 52 ) and the earlier criterion ( 4 . 20 ) is that ( 4 . 52 ) makes better use of the second - order part of m ( · ) , that is , the p T Bp term . This difference is illustrated by the case in which g (cid:3) 0 while B has negative eigenvalues , indicating that the current iterate x k is a saddle point . Here , the right - hand - side of ( 4 . 20 ) is zero ( indeed , the algorithms we described earlier would terminate at such a point ) . The right - hand - side of ( 4 . 52 ) is positive , indicating that decrease in the model function is still possible , so it forces the algorithm to move away from x k . The close attention that near - exact algorithms pay to the second - order term is war - ranted only if this term closely reﬂects the actual behavior of the function f —in fact , the trust - region Newton method , for which B (cid:3) ∇ 2 f ( x ) , is the only case that has been treated in the literature . For purposes of global convergence analysis , the use of the exact Hessian allows us to say more about the limit points of the algorithm than merely that they are stationary points . The following result shows that second - order necessary conditions ( Theorem 2 . 3 ) are satisﬁed at the limit points . Theorem 4 . 8 . Suppose that the assumptions of Theorem 4 . 6 are satisﬁed and in addition that f is twice continuously differentiable in the level set S . Suppose that B k (cid:3) ∇ 2 f ( x k ) for all k , and that the approximate solution p k of ( 4 . 3 ) at each iteration satisﬁes ( 4 . 52 ) for some ﬁxed γ > 0 . Then lim k →∞ (cid:8) g k (cid:8) (cid:3) 0 . If , in addition , the level set S of ( 4 . 24 ) is compact , then either the algorithm terminates at a point x k at which the second - order necessary conditions ( Theorem 2 . 3 ) for a local solution hold , or else { x k } has a limit point x ∗ in S at which the second - order necessary conditions hold . We omit the proof , which can be found in Mor´e and Sorensen [ 214 , Section 4 ] . 4 . 4 LOCAL CONVERGENCE OF TRUST - REGION NEWTON METHODS Since global convergence of trust - region methods that use exact Hessians ∇ 2 f ( x ) is estab - lished above , we turn our attention now to local convergence issues . The key to attaining the fast rate of convergence usually associated with Newton’s method is to show that the trust - region bound eventually does not interfere as we approach a solution . Speciﬁcally , we hope that near the solution , the ( approximate ) solution of the trust - region subproblem is well inside the trust region and becomes closer and closer to the true Newton step . Steps that satisfy the latter property are said to be asymptotically similar to Newton steps . We ﬁrst prove a general result that applies to any algorithm of the form of Algo - rithm 4 . 1 ( see Chapter 4 ) that generates steps that are asymptotically similar to Newton 4 . 4 . L O C A L C O N V E R G E N C E O F T R U S T - R E G I O N N E W T O N M E T H O D S 93 steps whenever the Newton steps easily satisfy the trust - region bound . It shows that the trust - region constraint eventually becomes inactive in algorithms with this property and that superlinear convergence can be attained . The result assumes that the exact Hessian B k (cid:3) ∇ 2 f ( x k ) is used in ( 4 . 3 ) when x k is close to a solution x ∗ that satisﬁes second - order sufﬁcient conditions ( see Theorem 2 . 4 ) . Moreover , it assumes that the algorithm uses an approximate solution p k of ( 4 . 3 ) that achieves a similar decrease in the model function m k as the Cauchy point . Theorem 4 . 9 . Let f be twice Lipschitz continuously differentiable in a neighborhhod of a point x ∗ at which second - order sufﬁcient conditions ( Theorem 2 . 4 ) are satisﬁed . Suppose the sequence { x k } converges to x ∗ and that for all k sufﬁciently large , the trust - region algorithm based on ( 4 . 3 ) with B k (cid:3) ∇ 2 f ( x k ) chooses steps p k that satisfy the Cauchy - point - based model reduction criterion ( 4 . 20 ) and are asymptotically similar to Newton steps p N k whenever (cid:8) p N k (cid:8) ≤ 12 (cid:6) k , that is , (cid:8) p k − p N k (cid:8) (cid:3) o ( (cid:8) p N k (cid:8) ) . ( 4 . 53 ) Then the trust - region bound (cid:6) k becomes inactive for all k sufﬁciently large and the sequence { x k } converges superlinearly to x ∗ . P ROOF . We show that (cid:8) p N k (cid:8) ≤ 12 (cid:6) k and (cid:8) p k (cid:8) ≤ (cid:6) k , for all sufﬁciently large k , so the near - optimal step p k in ( 4 . 53 ) will eventually always be taken . We ﬁrst seek a lower bound on the predicted reduction m k ( 0 ) − m k ( p k ) for all sufﬁciently large k . We assume that k is large enough that the o ( (cid:8) p N k (cid:8) ) term in ( 4 . 53 ) is less than (cid:8) p N k (cid:8) . When (cid:8) p N k (cid:8) ≤ 12 (cid:6) k , we then have that (cid:8) p k (cid:8) ≤ (cid:8) p N k (cid:8) + o ( (cid:8) p N k (cid:8) ) ≤ 2 (cid:8) p N k (cid:8) , while if (cid:8) p N k (cid:8) > 12 (cid:6) k , we have (cid:8) p k (cid:8) ≤ (cid:6) k < 2 (cid:8) p N k (cid:8) . In both cases , then , we have (cid:8) p k (cid:8) ≤ 2 (cid:8) p N k (cid:8) ≤ 2 (cid:23)(cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23)(cid:23) (cid:8) g k (cid:8) , and so (cid:8) g k (cid:8) ≥ 12 (cid:8) p k (cid:8) / (cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23) . We have from the relation ( 4 . 20 ) that m k ( 0 ) − m k ( p k ) ≥ c 1 (cid:8) g k (cid:8) min (cid:24) (cid:6) k , (cid:8) g k (cid:8) (cid:23)(cid:23) ∇ 2 f ( x k ) (cid:23)(cid:23) (cid:25) ≥ c 1 (cid:8) p k (cid:8) 2 (cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23) min (cid:24) (cid:8) p k (cid:8) , (cid:8) p k (cid:8) 2 (cid:23)(cid:23) ∇ 2 f ( x k ) (cid:23)(cid:23) (cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23) (cid:25) (cid:3) c 1 (cid:8) p k (cid:8) 2 4 (cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23) 2 (cid:23)(cid:23) ∇ 2 f ( x k ) (cid:23)(cid:23) . Because x k → x ∗ , we use continuity of ∇ 2 f ( x ) and positive deﬁniteness of ∇ 2 f ( x ∗ ) , to 94 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S deduce that the following bound holds for all k sufﬁciently large : c 1 4 (cid:23)(cid:23) ∇ 2 f ( x k ) − 1 (cid:23)(cid:23) 2 (cid:23)(cid:23) ∇ 2 f ( x k ) (cid:23)(cid:23) ≥ c 1 8 (cid:23)(cid:23) ∇ 2 f ( x ∗ ) − 1 (cid:23)(cid:23) 2 (cid:23)(cid:23) ∇ 2 f ( x ∗ ) (cid:23)(cid:23) def (cid:3) c 3 , where c 3 > 0 . Hence , we hae m k ( 0 ) − m k ( p k ) ≥ c 3 (cid:8) p k (cid:8) 2 ( 4 . 54 ) for all sufﬁciently large k . By Lipschitz continuity of ∇ 2 f ( x ) near x ∗ , and using Taylor’s theorem ( Theorem 2 . 1 ) , we have | ( f ( x k ) − f ( x k + p k ) ) − ( m k ( 0 ) − m k ( p k ) ) | (cid:3) (cid:28)(cid:28)(cid:28)(cid:28) 12 p Tk ∇ 2 f ( x k ) p k − 12 (cid:6) 1 0 p Tk ∇ 2 f ( x k + tp k ) p k dt (cid:28)(cid:28)(cid:28)(cid:28) ≤ L 4 (cid:8) p k (cid:8) 3 , where L > 0 is the Lipschitz constant for ∇ 2 f ( · ) . Hence , by deﬁnition ( 4 . 4 ) of ρ k , we have for sufﬁciently large k that | ρ k − 1 | ≤ (cid:8) p k (cid:8) 3 ( L / 4 ) c 3 (cid:8) p k (cid:8) 2 (cid:3) L 4 c 3 (cid:8) p k (cid:8) ≤ L 4 c 3 (cid:6) k . ( 4 . 55 ) Now , the trust - region radius can be reduced only if ρ k < 14 ( or some other ﬁxed number less than 1 ) , so it is clear from ( 4 . 55 ) that the sequence { (cid:6) k } is bounded away from zero . Since x k → x ∗ , we have (cid:8) p N k (cid:8) → 0 and therefore (cid:8) p k (cid:8) → 0 from ( 4 . 53 ) . Hence , the trust - region bound is inactive for all k sufﬁciently large , and the bound (cid:8) p N k (cid:8) ≤ 12 (cid:6) k is eventually always satisﬁed . To prove superlinear convergence , we use the quadratic convergence of Newton’s method , proved in Theorem 3 . 5 . In particular , we have from ( 3 . 33 ) that (cid:8) x k + p N k − x ∗ (cid:8) (cid:3) o (cid:7) (cid:8) x k − x ∗ (cid:8) 2 (cid:8) , which implies that (cid:8) p N k (cid:8) (cid:3) O ( (cid:8) x k − x ∗ (cid:8) ) . Therefore , using ( 4 . 53 ) , we have (cid:8) x k + p k − x ∗ (cid:8) ≤ (cid:8) x k + p N k − x ∗ (cid:8) + (cid:8) p N k − p k (cid:8) (cid:3) o (cid:7) (cid:8) x k − x ∗ (cid:8) 2 (cid:8) + o ( (cid:8) p N k (cid:8) ) (cid:3) o (cid:7) (cid:8) x k − x ∗ (cid:8) (cid:8) , thus proving superlinear convergence . (cid:1) It is immediate from Theorem 3 . 5 that if p k (cid:3) p N k for all k sufﬁciently large , we have quadratic convergence of { x k } to x ∗ . 4 . 5 . O T H E R E N H A N C E M E N T S 95 Reasonable implementations of the dogleg , subspace minimization , and nearly - exact algorithm of Section 4 . 3 with B k (cid:3) ∇ 2 f ( x k ) eventually use the steps p k (cid:3) p N k under the conditionsofTheorem4 . 9 , andthereforeconvergequadratically . Inthecaseofthedoglegand two - dimensional subspace minimization methods , the exact step p N k is one of the candidates for p k —it lies inside the trust region , along the dogleg path , and inside the two - dimensional subspace . Since under the assumptions of Theorem 4 . 9 , p N k is the unconstrained minimizer of m k for k sufﬁciently large , it is certainly the minimizer in the more restricted domains , so we have p k (cid:3) p N k . For the approach of Section 4 . 3 , if we follow the reasonable strategy of checking whether p N k is a solution of ( 4 . 3 ) prior to embarking on Algorithm 4 . 3 , then eventually we will also have p k (cid:3) p N k also . 4 . 5 OTHER ENHANCEMENTS SCALING As we noted in Chapter 2 , optimization problems are often posed with poor scaling— the objective function f is highly sensitive to small changes in certain components of the vector x and relatively insensitive to changes in other components . Topologically , a symptom of poor scaling is that the minimizer x ∗ lies in a narrow valley , so that the contours of the objective f ( · ) near x ∗ tend towards highly eccentric ellipses . Algorithms that fail to compensate for poor scaling can perform badly ; see Figure 2 . 7 for an illustration of the poor performance of the steepest descent approach . Recalling our deﬁnition of a trust region—a region around the current iterate within which the model m k ( · ) is an adequate representation of the true objective f ( · ) —it is easy to see that a spherical trust region may not be appropriate when f is poorly scaled . Even if the model Hessian B k is exact , the rapid changes in f along certain directions probably will cause m k to be a poor approximation to f along these directions . On the other hand , m k may be a more reliable approximation to f along directions in which f is changing more slowly . Since the shape of our trust region should be such that our conﬁdence in the model is more or less the same at all points on the boundary of the region , we are led naturally to consider elliptical trust regions in which the axes are short in the sensitive directions and longer in the less sensitive directions . Elliptical trust regions can be deﬁned by (cid:8) Dp (cid:8) ≤ (cid:6) , ( 4 . 56 ) where D is a diagonal matrix with positive diagonal elements , yielding the following scaled trust - region subproblem : min p ∈ IR n m k ( p ) def (cid:3) f k + g Tk p + 12 p T B k p s . t . (cid:8) Dp (cid:8) ≤ (cid:6) k . ( 4 . 57 ) 96 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S When f ( x ) is highly sensitive to the value of the i th component x i , we set the corresponding diagonal element d ii of D to be large , while d ii is smaller for less - sensitive components . Information to construct the scaling matrix D may be derived from the second derivatives ∂ 2 f / ∂ x 2 i . We can allow D to change from iteration to iteration ; most of the theory of this chapter will still apply with minor modiﬁcations provided that each d ii stays within some predetermined range [ d lo , d hi ] , where 0 < d lo ≤ d hi < ∞ . Of course , we do not need D to be a precise reﬂection of the scaling of the problem , so it is not necessary to devise elaborate heuristics or to perform extensive computations to get it just right . The following procedure shows how the Cauchy point calculation ( Algorithm 4 . 2 ) changes when we use a scaled trust region , Algorithm 4 . 4 ( Generalized Cauchy Point Calculation ) . Find the vector p S k that solves p S k (cid:3) arg min p ∈ IR n f k + g Tk p s . t . (cid:8) Dp (cid:8) ≤ (cid:6) k ; ( 4 . 58 ) Calculate the scalar τ k > 0 that minimizes m k ( τ p S k ) subject to satisfying the trust - region bound , that is , τ k (cid:3) arg min τ > 0 m k ( τ p S k ) s . t . (cid:8) τ D p S k (cid:8) ≤ (cid:6) k ; ( 4 . 59 ) p C k (cid:3) τ k p S k . For this scaled version , we ﬁnd that p S k (cid:3) − (cid:6) k (cid:8) D − 1 g k (cid:8) D − 2 g k , ( 4 . 60 ) and that the step length τ k is obtained from the following modiﬁcation of ( 4 . 12 ) : τ k (cid:3) ⎧⎪⎨ ⎪⎩ 1 if g Tk D − 2 B k D − 2 g k ≤ 0 min (cid:17) (cid:8) D − 1 g k (cid:8) 3 (cid:6) k g Tk D − 2 B k D − 2 g k , 1 (cid:18) otherwise . ( 4 . 61 ) ( The details are left as an exercise . ) A simpler alternative for adjusting the deﬁnition of the Cauchy point and the various algorithms of this chapter to allow for the elliptical trust region is simply to rescale the variables p in the subproblem ( 4 . 57 ) so that the trust region is spherical in the scaled variables . By deﬁning ˜ p def (cid:3) Dp , 4 . 5 . O T H E R E N H A N C E M E N T S 97 and by substituting into ( 4 . 57 ) , we obtain min ˜ p ∈ IR n ˜ m k ( ˜ p ) def (cid:3) f k + g Tk D − 1 ˜ p + 12 ˜ p T D − 1 B k D − 1 ˜ p s . t . (cid:8) ˜ p (cid:8) ≤ (cid:6) k . The theory and algorithms can now be derived in the usual way by substituting ˜ p for p , D − 1 g k for g k , D − 1 B k D − 1 for B k , and so on . TRUST REGIONS IN OTHER NORMS Trust regions may also be deﬁned in terms of norms other than the Euclidean norm . For instance , we may have (cid:8) p (cid:8) 1 ≤ (cid:6) k or (cid:8) p (cid:8) ∞ ≤ (cid:6) k , or their scaled counterparts (cid:8) Dp (cid:8) 1 ≤ (cid:6) k or (cid:8) Dp (cid:8) ∞ ≤ (cid:6) k , where D is a positive diagonal matrix as before . Norms such as these offer no obvious ad - vantages for small - medium unconstrained problems , but they may be useful for constrained problems . For instance , for the bound - constrained problem min x ∈ IR n f ( x ) , subject to x ≥ 0 , the trust - region subproblem may take the form min p ∈ IR n m k ( p ) (cid:3) f k + g T k p + 12 p T B k p s . t . x k + p ≥ 0 , (cid:8) p (cid:8) ≤ (cid:6) k . ( 4 . 62 ) WhenthetrustregionisdeﬁnedbyaEuclideannorm , thefeasibleregionfor ( 4 . 62 ) consistsof the intersection of a sphere and the nonnegative orthant—an awkward object , geometrically speaking . When the ∞ - norm is used , however , the feasible region is simply the rectangular box deﬁned by x k + p ≥ 0 , p ≥ − (cid:6) k e , p ≤ (cid:6) k e , where e (cid:3) ( 1 , 1 , . . . , 1 ) T , so the solution of the subproblem is easily calculated by using techniques for bound - constrained quadratic programming . For large problems , in which factorization or formation the model Hessian B k is not computationally desirable , the use of a trust region deﬁned by (cid:8) · (cid:8) ∞ will also give rise to a bound - constrained subproblem , which may be more convenient to solve than the standard subproblem ( 4 . 3 ) . To our knowledge , there has not been much research on the relative performance of methods that use trust regions of different shapes on large problems . 98 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S NOTES AND REFERENCES One of the earliest works on trust - region methods is Winﬁeld [ 307 ] . The inﬂuential paper of Powell [ 244 ] proves a result like Theorem 4 . 5 for the case of η (cid:3) 0 , where the algo - rithm takes a step whenever it decreases the function value . Powell uses a weaker assumption than ours on the matrices (cid:8) B (cid:8) , but his analysis is more complicated . Mor´e [ 211 ] summarizes developments in algorithms and software before 1982 , paying particular attention to the importance of using a scaled trust - region norm . Byrd , Schnabel , and Schultz [ 279 ] , [ 54 ] provide a general theory for inexact trust - region methods ; they introduce the idea of two - dimensional subspace minimization and also focus on proper handling of the case of indeﬁnite B to ensure stronger local convergence results than Theorems 4 . 5 and 4 . 6 . Dennis and Schnabel [ 93 ] survey trust - region methods as part of their overview of unconstrained optimization , providing pointers to many important developments in the literature . The monograph of Conn , Gould , and Toint [ 74 ] is an exhaustive treatment of the state of the art in trust - region methods for both unconstrained and constrained optimization . It includes an comprehensive annotated bibliography of the literature in the area . ✐ E X E R C I S E S ✐ 4 . 1 Let f ( x ) (cid:3) 10 ( x 2 − x 21 ) 2 + ( 1 − x 1 ) 2 . At x (cid:3) ( 0 , − 1 ) draw the contour lines of the quadratic model ( 4 . 2 ) assuming that B is the Hessian of f . Draw the family of solutions of ( 4 . 3 ) as the trust region radius varies from (cid:6) (cid:3) 0 to (cid:6) (cid:3) 2 . Repeat this at x (cid:3) ( 0 , 0 . 5 ) . ✐ 4 . 2 Write a program that implements the dogleg method . Choose B k to be the exact Hessian . Apply it to solve Rosenbrock’s function ( 2 . 22 ) . Experiment with the update rule for the trust region by changing the constants in Algorithm 4 . 1 , or by designing your own rules . ✐ 4 . 3 Program the trust - region method based on Algorithm 7 . 2 . Choose B k to be the exact Hessian , and use it to minimize the function min f ( x ) (cid:3) n (cid:3) i (cid:3) 1 (cid:9) ( 1 − x 2 i − 1 ) 2 + 10 ( x 2 i − x 2 2 i − 1 ) 2 (cid:10) with n (cid:3) 10 . Experiment with the starting point and the stopping test for the CG iteration . Repeat the computation with n (cid:3) 50 . Your program should indicate , at every iteration , whether Algorithm 7 . 2 encountered negative curvature , reached the trust - region boundary , or met the stopping test . 4 . 5 . O T H E R E N H A N C E M E N T S 99 ✐ 4 . 4 Theorem 4 . 5 shows that the sequence { (cid:8) g (cid:8) } has an accumulation point at zero . Show that if the iterates x stay in a bounded set B , then there is a limit point x ∞ of the sequence { x k } such that g ( x ∞ ) (cid:3) 0 . ✐ 4 . 5 Show that τ k deﬁned by ( 4 . 12 ) does indeed identify the minimizer of m k along the direction − g k . ✐ 4 . 6 The Cauchy – Schwarz inequality states that for any vectors u and v , we have | u T v | 2 ≤ ( u T u ) ( v T v ) , with equality only when u and v are parallel . When B is positive deﬁnite , use this inequality to show that γ def (cid:3) (cid:8) g (cid:8) 4 ( g T Bg ) ( g T B − 1 g ) ≤ 1 , with equality only if g and Bg ( and B − 1 g ) are parallel . ✐ 4 . 7 When B is positive deﬁnite , the double - dogleg method constructs a path with three line segments from the origin to the full step . The four points that deﬁne the path are • the origin ; • the unconstrained Cauchy step p C (cid:3) − ( g T g ) / ( g T Bg ) g ; • a fraction of the full step ¯ γ p B (cid:3) − ¯ γ B − 1 g , for some ¯ γ ∈ ( γ , 1 ] , where γ is deﬁned in the previous question ; and • the full step p B (cid:3) − B − 1 g . Show that (cid:8) p (cid:8) increases monotonically along this path . ( Note : The double - dogleg method , as discussed in Dennis and Schnabel [ 92 , Section 6 . 4 . 2 ] , was for some time thought to be superior to the standard dogleg method , but later testing has not shown much difference in performance . ) ✐ 4 . 8 Show that ( 4 . 43 ) and ( 4 . 44 ) are equivalent . Hints : Note that d d λ (cid:17) 1 (cid:8) p ( λ ) (cid:8) (cid:18) (cid:3) d d λ (cid:7) (cid:8) p ( λ ) (cid:8) 2 (cid:8) − 1 / 2 (cid:3) − 1 2 (cid:7) (cid:8) p ( λ ) (cid:8) 2 (cid:8) − 3 / 2 d d λ (cid:8) p ( λ ) (cid:8) 2 , d d λ (cid:8) p ( λ ) (cid:8) 2 (cid:3) − 2 n (cid:3) j (cid:3) 1 ( q Tj g ) 2 ( λ j + λ ) 3 100 C H A P T E R 4 . T R U S T - R E G I O N M E T H O D S ( from ( 4 . 39 ) ) , and (cid:8) q (cid:8) 2 (cid:3) (cid:8) R − T p (cid:8) 2 (cid:3) p T ( B + λ I ) − 1 p (cid:3) n (cid:3) j (cid:3) 1 ( q Tj g ) 2 ( λ j + λ ) 3 . ✐ 4 . 9 Derive the solution of the two - dimensional subspace minimization problem in the case where B is positive deﬁnite . ✐ 4 . 10 Show that if B is any symmetric matrix , then there exists λ ≥ 0 such that B + λ I is positive deﬁnite . ✐ 4 . 11 Verify that the deﬁnitions ( 4 . 60 ) for p S k and ( 4 . 61 ) for τ k are valid for the Cauchy point in the case of an elliptical trust region . ( Hint : Using the theory of Chapter 12 , we can show that the solution of ( 4 . 58 ) satisﬁes g k + α D 2 p S k (cid:3) 0 for some scalar α ≥ 0 . ) ✐ 4 . 12 The following example shows that the reduction in the model function m achieved by the two - dimensional minimization strategy can be much smaller than that achieved by the exact solution of ( 4 . 5 ) . In ( 4 . 5 ) , set g (cid:3) (cid:17) − 1 (cid:9) , − 1 , − (cid:9) 2 (cid:18) T , where (cid:9) is a small positive number . Set B (cid:3) diag (cid:17) 1 (cid:9) 3 , 1 , (cid:9) 3 (cid:18) , (cid:6) (cid:3) 0 . 5 . Show that the solution of ( 4 . 5 ) has components (cid:7) O ( (cid:9) ) , 12 + O ( (cid:9) ) , O ( (cid:9) ) (cid:8) T and that the reduction in the model m is 38 + O ( (cid:9) ) . For the two - dimensional minimization strategy , show that the solution is a multiple of B − 1 g and that the reduction in m is O ( (cid:9) ) . This is page 101 Printer : Opaque this C H A P T E R 5 Conjugate Gradient Methods Our interest in conjugate gradient methods is twofold . First , they are among the most useful techniques for solving large linear systems of equations . Second , they can be adapted to solve nonlinear optimization problems . The remarkable properties of both linear and nonlinear conjugate gradient methods will be described in this chapter . The linear conjugate gradient method was proposed by Hestenes and Stiefel in the 1950s as an iterative method for solving linear systems with positive deﬁnite coefﬁcient matrices . It is an alternative to Gaussian elimination that is well suited for solving large problems . The performance of the linear conjugate gradient method is determined by the 102 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S distribution of the eigenvalues of the coefﬁcient matrix . By transforming , or preconditioning , the linear system , we canmake this distributionmore favorable andimprove the convergence of the method signiﬁcantly . Preconditioning plays a crucial role in the design of practical conjugate gradient strategies . Our treatment of the linear conjugate gradient method will highlight those properties of the method that are important in optimization . The ﬁrst nonlinear conjugate gradient method was introduced by Fletcher and Reeves in the 1960s . It is one of the earliest known techniques for solving large - scale nonlinear optimization problems . Over the years , many variants of this original scheme have been proposed , and some are widely used in practice . The key features of these algorithms are that they require no matrix storage and are faster than the steepest descent method . 5 . 1 THE LINEAR CONJUGATE GRADIENT METHOD In this section we derive the linear conjugate gradient method and discuss its essential convergence properties . For simplicity , we drop the qualiﬁer “linear” throughout . The conjugate gradient method is an iterative method for solving a linear system of equations Ax (cid:3) b , ( 5 . 1 ) where A is an n × n symmetric positive deﬁnite matrix . The problem ( 5 . 1 ) can be stated equivalently as the following minimization problem : min φ ( x ) def (cid:3) 12 x T Ax − b T x , ( 5 . 2 ) that is , both ( 5 . 1 ) and ( 5 . 2 ) have the same unique solution . This equivalence will allow us to interpret the conjugate gradient method either as an algorithm for solving linear systems or as a technique for minimizing convex quadratic functions . For future reference , we note that the gradient of φ equals the residual of the linear system , that is , ∇ φ ( x ) (cid:3) Ax − b def (cid:3) r ( x ) , ( 5 . 3 ) so in particular at x (cid:3) x k we have r k (cid:3) Ax k − b . ( 5 . 4 ) CONJUGATE DIRECTION METHODS One of the remarkable properties of the conjugate gradient method is its ability to generate , in a very economical fashion , a set of vectors with a property known as conjugacy . A 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 103 set of nonzero vectors { p 0 , p 1 , . . . , p l } is said to be conjugate with respect to the symmetric positive deﬁnite matrix A if p Ti Ap j (cid:3) 0 , for all i (cid:9)(cid:3) j . ( 5 . 5 ) It is easy to show that any set of vectors satisfying this property is also linearly independent . ( For a geometrical illustration of conjugate directions see Section 9 . 4 . ) The importance of conjugacy lies in the fact that we can minimize φ ( · ) in n steps by successively minimizing it along the individual directions in a conjugate set . To verify this claim , we consider the following conjugate direction method . ( The distinction between the conjugate gradient method and the conjugate direction method will become clear as we proceed . ) Givenastartingpoint x 0 ∈ IR n andasetofconjugatedirections { p 0 , p 1 , . . . , p n − 1 } , let us generate the sequence { x k } by setting x k + 1 (cid:3) x k + α k p k , ( 5 . 6 ) where α k is the one - dimensional minimizer of the quadratic function φ ( · ) along x k + α p k , given explicitly by α k (cid:3) − r Tk p k p Tk Ap k ; ( 5 . 7 ) see ( 3 . 55 ) . We have the following result . Theorem 5 . 1 . For any x 0 ∈ IR n the sequence { x k } generated by the conjugate direction algorithm ( 5 . 6 ) , ( 5 . 7 ) converges to the solution x ∗ of the linear system ( 5 . 1 ) in at most n steps . P ROOF . Since the directions { p i } are linearly independent , they must span the whole space IR n . Hence , we can write the difference between x 0 and the solution x ∗ in the following way : x ∗ − x 0 (cid:3) σ 0 p 0 + σ 1 p 1 + · · · + σ n − 1 p n − 1 , for some choice of scalars σ k . By premultiplying this expression by p Tk A and using the conjugacy property ( 5 . 5 ) , we obtain σ k (cid:3) p Tk A ( x ∗ − x 0 ) p Tk Ap k . ( 5 . 8 ) We now establish the result by showing that these coefﬁcients σ k coincide with the step lengths α k generated by the formula ( 5 . 7 ) . 104 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S If x k is generated by algorithm ( 5 . 6 ) , ( 5 . 7 ) , then we have x k (cid:3) x 0 + α 0 p 0 + α 1 p 1 + · · · + α k − 1 p k − 1 . By premultiplying this expression by p Tk A and using the conjugacy property , we have that p Tk A ( x k − x 0 ) (cid:3) 0 , and therefore p Tk A ( x ∗ − x 0 ) (cid:3) p Tk A ( x ∗ − x k ) (cid:3) p Tk ( b − Ax k ) (cid:3) − p Tk r k . By comparing this relation with ( 5 . 7 ) and ( 5 . 8 ) , we ﬁnd that σ k (cid:3) α k , giving the result . (cid:1) There is a simple interpretation of the properties of conjugate directions . If the matrix A in ( 5 . 2 ) is diagonal , the contours of the function φ ( · ) are ellipses whose axes are aligned with the coordinate directions , as illustrated in Figure 5 . 1 . We can ﬁnd the minimizer of this function by performing one - dimensional minimizations along the coordinate directions . * e 2 x 0 e 1 x 1 . . x Figure 5 . 1 Successive minimizations along the coordinate directions ﬁnd the minimizer of a quadratic with a diagonal Hessian in n iterations . 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 105 e x 1 0 x x 2 3 x x * e 2 1 Figure5 . 2 Successive minimization along coordinate axes does not ﬁnd the solution in n iterations , for a general convex quadratic . e 1 , e 2 , . . . , e n in turn . When A is not diagonal , its contours are still elliptical , but they are usually no longer aligned with the coordinate directions . The strategy of successive minimization along these directions in turn no longer leads to the solution in n iterations ( or eveninaﬁnitenumberofiterations ) . Thisphenomenonisillustratedinthetwo - dimensional exampleofFigure5 . 2Wecan , however , recoverthenicebehaviorofFigure5 . 1ifwetransform theproblemtomake A diagonalandthenminimizealongthecoordinatedirections . Suppose we transform the problem by deﬁning new variables ˆ x as ˆ x (cid:3) S − 1 x , ( 5 . 9 ) where S is the n × n matrix deﬁned by S (cid:3) [ p 0 p 1 · · · p n − 1 ] , where { p 0 , p 2 , . . . , p n − 1 } is the set of conjugate directions with respect to A . The quadratic φ deﬁned by ( 5 . 2 ) now becomes ˆ φ ( ˆ x ) def (cid:3) φ ( S ˆ x ) (cid:3) 12 ˆ x T ( S T AS ) ˆ x − ( S T b ) T ˆ x . By the conjugacy property ( 5 . 5 ) , the matrix S T AS is diagonal , so we can ﬁnd the minimizing value of ˆ φ by performing n one - dimensional minimizations along the coordinate directions 106 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S of ˆ x . Because of the relation ( 5 . 9 ) , however , the i th coordinate direction in ˆ x - space corre - sponds to the direction p i in x - space . Hence , the coordinate search strategy applied to ˆ φ is equivalent to the conjugate direction algorithm ( 5 . 6 ) , ( 5 . 7 ) . We conclude , as in Theorem 5 . 1 , that the conjugate direction algorithm terminates in at most n steps . Returning to Figure 5 . 1 , we note another interesting property : When the Hessian ma - trix is diagonal , each coordinate minimization correctly determines one of the components of the solution x ∗ . In other words , after k one - dimensional minimizations , the quadratic has been minimized on the subspace spanned by e 1 , e 2 , . . . , e k . The following theorem proves this important result for the general case in which the Hessian of the quadratic is not necessarily diagonal . ( Here and later , we use the notation span { p 0 , p 1 , . . . , p k } to denote the set of all linear combinations of the vectors p 0 , p 1 , . . . , p k . ) In proving the result we will make use of the following expression , which is easily veriﬁed from the relations ( 5 . 4 ) and ( 5 . 6 ) : r k + 1 (cid:3) r k + α k Ap k . ( 5 . 10 ) Theorem 5 . 2 ( Expanding Subspace Minimization ) . Let x 0 ∈ IR n be any starting point and suppose that the sequence { x k } is generated by the conjugate direction algorithm ( 5 . 6 ) , ( 5 . 7 ) . Then r Tk p i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k − 1 , ( 5 . 11 ) and x k is the minimizer of φ ( x ) (cid:3) 12 x T Ax − b T x over the set { x | x (cid:3) x 0 + span { p 0 , p 1 , . . . , p k − 1 } } . ( 5 . 12 ) P ROOF . We begin by showing that a point ˜ x minimizes φ over the set ( 5 . 12 ) if and only if r ( ˜ x ) T p i (cid:3) 0 , for each i (cid:3) 0 , 1 , . . . , k − 1 . Let us deﬁne h ( σ ) (cid:3) φ ( x 0 + σ 0 p 0 + · · · + σ k − 1 p k − 1 ) , where σ (cid:3) ( σ 0 , σ 1 , . . . , σ k − 1 ) T . Since h ( σ ) is a strictly convex quadratic , it has a unique minimizer σ ∗ that satisﬁes ∂ h ( σ ∗ ) ∂σ i (cid:3) 0 , i (cid:3) 0 , 1 , . . . , k − 1 . By the chain rule , this equation implies that ∇ φ ( x 0 + σ ∗ 0 p 0 + · · · + σ ∗ k − 1 p k − 1 ) T p i (cid:3) 0 , i (cid:3) 0 , 1 , . . . , k − 1 . By recalling the deﬁnition ( 5 . 3 ) , we have for the minimizer ˜ x (cid:3) x 0 + σ ∗ 0 p 0 + σ ∗ 1 p 2 + · · · + σ ∗ k − 1 p k − 1 on the set ( 5 . 12 ) that r ( ˜ x ) T p i (cid:3) 0 , as claimed . We now use induction to show that x k satisﬁes ( 5 . 11 ) . For the case k (cid:3) 1 , we have from the fact that x 1 (cid:3) x 0 + α 0 p 0 minimizes φ along p 0 that r T 1 p 0 (cid:3) 0 . Let us now make 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 107 the induction hypothesis , namely , that r Tk − 1 p i (cid:3) 0 for i (cid:3) 0 , 1 , . . . , k − 2 . By ( 5 . 10 ) , we have r k (cid:3) r k − 1 + α k − 1 Ap k − 1 , so that p Tk − 1 r k (cid:3) p Tk − 1 r k − 1 + α k − 1 p Tk − 1 Ap k − 1 (cid:3) 0 , by the deﬁnition ( 5 . 7 ) of α k − 1 . Meanwhile , for the other vectors p i , i (cid:3) 0 , 1 , . . . , k − 2 , we have p Ti r k (cid:3) p Ti r k − 1 + α k − 1 p Ti Ap k − 1 (cid:3) 0 , where p Ti r k − 1 (cid:3) 0 because of the induction hypothesis and p Ti Ap k − 1 (cid:3) 0 because of conjugacy of the vectors p i . We have shown that r Tk p i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k − 1 , so the proof is complete . (cid:1) The fact that the current residual r k is orthogonal to all previous search directions , as expressed in ( 5 . 11 ) , is a property that will be used extensively in this chapter . The discussion so far has been general , in that it applies to a conjugate direction method ( 5 . 6 ) , ( 5 . 7 ) based on any choice of the conjugate direction set { p 0 , p 1 , . . . , p n − 1 } . There are many ways to choose the set of conjugate directions . For instance , the eigen - vectors v 1 , v 2 , . . . , v n of A are mutually orthogonal as well as conjugate with respect to A , so these could be used as the vectors { p 0 , p 1 , . . . , p n − 1 } . For large - scale applications , however , computation of the complete set of eigenvectors requires an excessive amount of computation . An alternative approach is to modify the Gram – Schmidt orthogonalization process to produce a set of conjugate directions rather than a set of orthogonal directions . ( This modiﬁcation is easy to produce , since the properties of conjugacy and orthogonality are closely related in spirit . ) However , the Gram – Schmidt approach is also expensive , since it requires us to store the entire direction set . BASIC PROPERTIES OF THE CONJUGATE GRADIENT METHOD The conjugate gradient method is a conjugate direction method with a very special property : In generating its set of conjugate vectors , it can compute a new vector p k by using only the previous vector p k − 1 . It does not need to know all the previous elements p 0 , p 1 , . . . , p k − 2 of the conjugate set ; p k is automatically conjugate to these vectors . This remarkable property implies that the method requires little storage and computation . In the conjugate gradient method , each direction p k is chosen to be a linear combi - nation of the negative residual − r k ( which , by ( 5 . 3 ) , is the steepest descent direction for the 108 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S function φ ) and the previous direction p k − 1 . We write p k (cid:3) − r k + β k p k − 1 , ( 5 . 13 ) where the scalar β k is to be determined by the requirement that p k − 1 and p k must be conjugate with respect to A . By premultiplying ( 5 . 13 ) by p Tk − 1 A and imposing the condition p T k − 1 Ap k (cid:3) 0 , we ﬁnd that β k (cid:3) r Tk Ap k − 1 p Tk − 1 Ap k − 1 . We choose the ﬁrst search direction p 0 to be the steepest descent direction at the initial point x 0 . As in the general conjugate direction method , we perform successive one - dimensional minimizations along each of the search directions . We have thus speciﬁed a complete algorithm , which we express formally as follows : Algorithm 5 . 1 ( CG – Preliminary Version ) . Given x 0 ; Set r 0 ← Ax 0 − b , p 0 ← − r 0 , k ← 0 ; while r k (cid:9)(cid:3) 0 α k ← − r Tk p k p Tk Ap k ; ( 5 . 14a ) x k + 1 ← x k + α k p k ; ( 5 . 14b ) r k + 1 ← Ax k + 1 − b ; ( 5 . 14c ) β k + 1 ← r Tk + 1 Ap k p Tk Ap k ; ( 5 . 14d ) p k + 1 ← − r k + 1 + β k + 1 p k ; ( 5 . 14e ) k ← k + 1 ; ( 5 . 14f ) end ( while ) This version is useful for studying the essential properties of the conjugate gradient method , but we present a more efﬁcient version later . We show ﬁrst that the directions p 0 , p 1 , . . . , p n − 1 are indeed conjugate , which by Theorem 5 . 1 implies termination in n steps . The theorem below establishes this property and two other important properties . First , the residuals r i are mutually orthogonal . Second , each search direction p k and residual r k is contained in the Krylov subspace of degree k for r 0 , deﬁned as K ( r 0 ; k ) def (cid:3) span { r 0 , Ar 0 , . . . , A k r 0 } . ( 5 . 15 ) 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 109 Theorem 5 . 3 . Suppose that the k th iterate generated by the conjugate gradient method is not the solution point x ∗ . The following four properties hold : r Tk r i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k − 1 , ( 5 . 16 ) span { r 0 , r 1 , . . . , r k } (cid:3) span { r 0 , Ar 0 , . . . , A k r 0 } , ( 5 . 17 ) span { p 0 , p 1 , . . . , p k } (cid:3) span { r 0 , Ar 0 , . . . , A k r 0 } , ( 5 . 18 ) p Tk Ap i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k − 1 . ( 5 . 19 ) Therefore , the sequence { x k } converges to x ∗ in at most n steps . P ROOF . The proof is by induction . The expressions ( 5 . 17 ) and ( 5 . 18 ) hold trivially for k (cid:3) 0 , while ( 5 . 19 ) holds by construction for k (cid:3) 1 . Assuming now that these three expressions are true for some k ( the induction hypothesis ) , we show that they continue to hold for k + 1 . To prove ( 5 . 17 ) , we show ﬁrst that the set on the left - hand side is contained in the set on the right - hand side . Because of the induction hypothesis , we have from ( 5 . 17 ) and ( 5 . 18 ) that r k ∈ span { r 0 , Ar 0 , . . . , A k r 0 } , p k ∈ span { r 0 , Ar 0 , . . . , A k r 0 } , while by multiplying the second of these expressions by A , we obtain Ap k ∈ span { Ar 0 , . . . , A k + 1 r 0 } . ( 5 . 20 ) By applying ( 5 . 10 ) , we ﬁnd that r k + 1 ∈ span { r 0 , Ar 0 , . . . , A k + 1 r 0 } . By combining this expression with the induction hypothesis for ( 5 . 17 ) , we conclude that span { r 0 , r 1 , . . . , r k , r k + 1 } ⊂ span { r 0 , Ar 0 , . . . , A k + 1 r 0 } . To prove that the reverse inclusion holds as well , we use the induction hypothesis on ( 5 . 18 ) to deduce that A k + 1 r 0 (cid:3) A ( A k r 0 ) ∈ span { Ap 0 , Ap 1 , . . . , Ap k } . Since by ( 5 . 10 ) we have Ap i (cid:3) ( r i + 1 − r i ) / α i for i (cid:3) 0 , 1 , . . . , k , it follows that A k + 1 r 0 ∈ span { r 0 , r 1 , . . . , r k + 1 } . 110 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S By combining this expression with the induction hypothesis for ( 5 . 17 ) , we ﬁnd that span { r 0 , Ar 0 , . . . , A k + 1 r 0 } ⊂ span { r 0 , r 1 , . . . , r k , r k + 1 } . Therefore , the relation ( 5 . 17 ) continues to hold when k is replaced by k + 1 , as claimed . We show that ( 5 . 18 ) continues to hold when k is replaced by k + 1 by the following argument : span { p 0 , p 1 , . . . , p k , p k + 1 } (cid:3) span { p 0 , p 1 , . . . , p k , r k + 1 } by ( 5 . 14e ) (cid:3) span { r 0 , Ar 0 , . . . , A k r 0 , r k + 1 } by induction hypothesis for ( 5 . 18 ) (cid:3) span { r 0 , r 1 , . . . , r k , r k + 1 } by ( 5 . 17 ) (cid:3) span { r 0 , Ar 0 , . . . , A k + 1 r 0 } by ( 5 . 17 ) for k + 1 . Next , we prove the conjugacy condition ( 5 . 19 ) with k replaced by k + 1 . By multiplying ( 5 . 14e ) by Ap i , i (cid:3) 0 , 1 , . . . , k , we obtain p Tk + 1 Ap i (cid:3) − r Tk + 1 Ap i + β k + 1 p Tk Ap i . ( 5 . 21 ) By the deﬁnition ( 5 . 14d ) of β k , the right - hand - side of ( 5 . 21 ) vanishes when i (cid:3) k . For i ≤ k − 1 we need to collect a number of observations . Note ﬁrst that our induction hypothesis for ( 5 . 19 ) implies that the directions p 0 , p 1 , . . . , p k are conjugate , so we can apply Theorem 5 . 2 to deduce that r Tk + 1 p i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k . ( 5 . 22 ) Second , by repeatedly applying ( 5 . 18 ) , we ﬁnd that for i (cid:3) 0 , 1 , . . . , k − 1 , the following inclusion holds : Ap i ∈ A span { r 0 , Ar 0 , . . . , A i r 0 } (cid:3) span { Ar 0 , A 2 r 0 , . . . , A i + 1 r 0 } ⊂ span { p 0 , p 1 , . . . , p i + 1 } . ( 5 . 23 ) By combining ( 5 . 22 ) and ( 5 . 23 ) , we deduce that r Tk + 1 Ap i (cid:3) 0 , for i (cid:3) 0 , 1 , . . . , k − 1 , so the ﬁrst term in the right - hand - side of ( 5 . 21 ) vanishes for i (cid:3) 0 , 1 , . . . , k − 1 . Be - cause of the induction hypothesis for ( 5 . 19 ) , the second term vanishes as well , and we 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 111 conclude that p Tk + 1 Ap i (cid:3) 0 , i (cid:3) 0 , 1 , . . . , k . Hence , the inductionargument holds for ( 5 . 19 ) also . It follows that the direction set generated by the conjugate gradient method is indeed a conjugate direction set , so Theorem 5 . 1 tells us that the algorithm terminates in at most n iterations . Finally , we prove ( 5 . 16 ) by a noninductive argument . Because the direction set is conjugate , we have from ( 5 . 11 ) that r Tk p i (cid:3) 0 for all i (cid:3) 0 , 1 , . . . , k − 1 and any k (cid:3) 1 , 2 , . . . , n − 1 . By rearranging ( 5 . 14e ) , we ﬁnd that p i (cid:3) − r i + β i p i − 1 , so that r i ∈ span { p i , p i − 1 } for all i (cid:3) 1 , . . . , k − 1 . We conclude that r Tk r i (cid:3) 0 for all i (cid:3) 1 , . . . , k − 1 . To complete the proof , we note that r Tk r 0 (cid:3) − r Tk p 0 (cid:3) 0 , by deﬁnition of p 0 in Algorithm 5 . 1 and by ( 5 . 11 ) . (cid:1) The proof of this theorem relies on the fact that the ﬁrst direction p 0 is the steep - est descent direction − r 0 ; in fact , the result does not hold for other choices of p 0 . Since the gradients r k are mutually orthogonal , the term “conjugate gradient method” is ac - tually a misnomer . It is the search directions , not the gradients , that are conjugate with respect to A . A PRACTICAL FORM OF THE CONJUGATE GRADIENT METHOD We can derive a slightly more economical form of the conjugate gradient method by using the results of Theorems 5 . 2 and 5 . 3 . First , we can use ( 5 . 14e ) and ( 5 . 11 ) to replace the formula ( 5 . 14a ) for α k by α k (cid:3) r Tk r k p Tk Ap k . Second , we have from ( 5 . 10 ) that α k Ap k (cid:3) r k + 1 − r k , so by applying ( 5 . 14e ) and ( 5 . 11 ) once again we can simplify the formula for β k + 1 to β k + 1 (cid:3) r Tk + 1 r k + 1 r Tk r k . By using these formulae together with ( 5 . 10 ) , we obtain the following standard form of the conjugate gradient method . 112 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S Algorithm 5 . 2 ( CG ) . Given x 0 ; Set r 0 ← Ax 0 − b , p 0 ← − r 0 , k ← 0 ; while r k (cid:9)(cid:3) 0 α k ← r Tk r k p Tk Ap k ; ( 5 . 24a ) x k + 1 ← x k + α k p k ; ( 5 . 24b ) r k + 1 ← r k + α k Ap k ; ( 5 . 24c ) β k + 1 ← r Tk + 1 r k + 1 r Tk r k ; ( 5 . 24d ) p k + 1 ← − r k + 1 + β k + 1 p k ; ( 5 . 24e ) k ← k + 1 ; ( 5 . 24f ) end ( while ) At any given point in Algorithm 5 . 2 we never need to know the vectors x , r , and p for more than the last two iterations . Accordingly , implementations of this algorithm overwrite old values of these vectors to save on storage . The major computational tasks to be performed at each step are computation of the matrix – vector product Ap k , calculation of the inner products p Tk ( Ap k ) and r Tk + 1 r k + 1 , and calculation of three vector sums . The inner product and vector sum operations can be performed in a small multiple of n ﬂoating - point operations , while the cost of the matrix – vector product is , of course , dependent on the problem . The CG method is recommended only for large problems ; otherwise , Gaussian elimination or other factorization algorithms such as the singular value decomposition are to be preferred , since they are less sensitive to rounding errors . For large problems , the CG method has the advantage that it does not alter the coefﬁcient matrix and ( in contrast to factorization techniques ) does not produce ﬁll in the arrays holding the matrix . Another key property is that the CG method sometimes approaches the solution quickly , as we discuss next . RATE OF CONVERGENCE We have seen that in exact arithmetic the conjugate gradient method will terminate at the solution in at most n iterations . What is more remarkable is that when the distribution of the eigenvalues of A has certain favorable features , the algorithm will identify the solution in many fewer than n iterations . To explain this property , we begin by viewing the expanding subspace minimization property proved in Theorem 5 . 2 in a slightly different way , using it to show that Algorithm 5 . 2 is optimal in a certain important sense . 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 113 From ( 5 . 24b ) and ( 5 . 18 ) , we have that x k + 1 (cid:3) x 0 + α 0 p 0 + · · · + α k p k (cid:3) x 0 + γ 0 r 0 + γ 1 Ar 0 + · · · + γ k A k r 0 , ( 5 . 25 ) for some constants γ i . We now deﬁne P ∗ k ( · ) to be a polynomial of degree k with coefﬁcients γ 0 , γ 1 , . . . , γ k . Like any polynomial , P ∗ k can take either a scalar or a square matrix as its argument . For the matrix argument A , we have P ∗ k ( A ) (cid:3) γ 0 I + γ 1 A + · · · + γ k A k , which allows us to express ( 5 . 25 ) as follows : x k + 1 (cid:3) x 0 + P ∗ k ( A ) r 0 . ( 5 . 26 ) We now show that among all possible methods whose ﬁrst k steps are restricted to the Krylov subspace K ( r 0 ; k ) given by ( 5 . 15 ) , Algorithm 5 . 2 does the best job of minimizing the distance to the solution after k steps , when this distance is measured by the weighted norm measure (cid:8) · (cid:8) A deﬁned by (cid:8) z (cid:8) 2 A (cid:3) z T Az . ( 5 . 27 ) ( Recall that this norm was used in the analysis of the steepest descent method of Chapter 3 . ) Using this norm and the deﬁnition of φ ( 5 . 2 ) , and the fact that x ∗ minimizes φ , it is easy to show that 12 (cid:8) x − x ∗ (cid:8) 2 A (cid:3) 12 ( x − x ∗ ) T A ( x − x ∗ ) (cid:3) φ ( x ) − φ ( x ∗ ) . ( 5 . 28 ) Theorem 5 . 2 states that x k + 1 minimizes φ , and hence (cid:8) x − x ∗ (cid:8) 2 A , over the set x 0 + span { p 0 , p 1 , . . . , p k } , which by ( 5 . 18 ) is the same as x 0 + span { r 0 , Ar 0 , . . . , A k r 0 } . It follows from ( 5 . 26 ) that the polynomial P ∗ k solves the following problem in which the minimum is taken over the space of all possible polynomials of degree k : min P k (cid:8) x 0 + P k ( A ) r 0 − x ∗ (cid:8) A . ( 5 . 29 ) We exploit this optimality property repeatedly in the remainder of the section . Since r 0 (cid:3) Ax 0 − b (cid:3) Ax 0 − Ax ∗ (cid:3) A ( x 0 − x ∗ ) , we have that x k + 1 − x ∗ (cid:3) x 0 + P ∗ k ( A ) r 0 − x ∗ (cid:3) [ I + P ∗ k ( A ) A ] ( x 0 − x ∗ ) . ( 5 . 30 ) 114 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S Let 0 < λ 1 ≤ λ 2 ≤ · · · ≤ λ n be the eigenvalues of A , and let v 1 , v 2 , . . . , v n be the corresponding orthonormal eigenvectors , so that A (cid:3) n (cid:3) i (cid:3) 1 λ i v i v Ti . Since the eigenvectors span the whole space IR n , we can write x 0 − x ∗ (cid:3) n (cid:3) i (cid:3) 1 ξ i v i , ( 5 . 31 ) for some coefﬁcients ξ i . It is easy to show that any eigenvector of A is also an eigenvector of P k ( A ) for any polynomial P k . For our particular matrix A and its eigenvalues λ i and eigenvectors v i , we have P k ( A ) v i (cid:3) P k ( λ i ) v i , i (cid:3) 1 , 2 , . . . , n . By substituting ( 5 . 31 ) into ( 5 . 30 ) we have x k + 1 − x ∗ (cid:3) n (cid:3) i (cid:3) 1 [ 1 + λ i P ∗ k ( λ i ) ] ξ i v i . By using the fact that (cid:8) z (cid:8) 2 A (cid:3) z T Az (cid:3) (cid:4) ni (cid:3) 1 λ i ( v Ti z ) 2 , we have (cid:8) x k + 1 − x ∗ (cid:8) 2 A (cid:3) n (cid:3) i (cid:3) 1 λ i [ 1 + λ i P ∗ k ( λ i ) ] 2 ξ 2 i . ( 5 . 32 ) Since the polynomial P ∗ k generated by the CG method is optimal with respect to this norm , we have (cid:8) x k + 1 − x ∗ (cid:8) 2 A (cid:3) min P k n (cid:3) i (cid:3) 1 λ i [ 1 + λ i P k ( λ i ) ] 2 ξ 2 i . By extracting the largest of the terms [ 1 + λ i P k ( λ i ) ] 2 from this expression , we obtain that (cid:8) x k + 1 − x ∗ (cid:8) 2 A ≤ min P k max 1 ≤ i ≤ n [ 1 + λ i P k ( λ i ) ] 2 ⎛ ⎝ n (cid:3) j (cid:3) 1 λ j ξ 2 j ⎞ ⎠ (cid:3) min P k max 1 ≤ i ≤ n [ 1 + λ i P k ( λ i ) ] 2 (cid:8) x 0 − x ∗ (cid:8) 2 A , ( 5 . 33 ) where we have used the fact that (cid:8) x 0 − x ∗ (cid:8) 2 A (cid:3) (cid:4) nj (cid:3) 1 λ j ξ 2 j . 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 115 The expression ( 5 . 33 ) allows us to quantify the convergence rate of the CG method by estimating the nonnegative scalar quantity min P k max 1 ≤ i ≤ n [ 1 + λ i P k ( λ i ) ] 2 . ( 5 . 34 ) In other words , we search for a polynomial P k that makes this expression as small as possible . In some practical cases , we can ﬁnd this polynomial explicitly and draw some interesting conclusions about the properties of the CG method . The following result is an example . Theorem 5 . 4 . If A has only r distinct eigenvalues , then the CG iteration will terminate at the solution in at most r iterations . P ROOF . Suppose that the eigenvalues λ 1 , λ 2 , . . . , λ n take on the r distinct values τ 1 < τ 2 < · · · < τ r . We deﬁne a polynomial Q r ( λ ) by Q r ( λ ) (cid:3) ( − 1 ) r τ 1 τ 2 · · · τ r ( λ − τ 1 ) ( λ − τ 2 ) · · · ( λ − τ r ) , and note that Q r ( λ i ) (cid:3) 0 for i (cid:3) 1 , 2 , . . . , n and Q r ( 0 ) (cid:3) 1 . From the latter observation , we deduce that Q r ( λ ) − 1 is a polynomial of degree r with a root at λ (cid:3) 0 , so by polynomial division , the function ¯ P r − 1 deﬁned by ¯ P r − 1 ( λ ) (cid:3) ( Q r ( λ ) − 1 ) / λ is a polynomial of degree r − 1 . By setting k (cid:3) r − 1 in ( 5 . 34 ) , we have 0 ≤ min P r − 1 max 1 ≤ i ≤ n [ 1 + λ i P r − 1 ( λ i ) ] 2 ≤ max 1 ≤ i ≤ n [ 1 + λ i ¯ P r − 1 ( λ i ) ] 2 (cid:3) max 1 ≤ i ≤ n Q 2 r ( λ i ) (cid:3) 0 . Hence , the constant in ( 5 . 34 ) is zero for the value k (cid:3) r − 1 , so we have by substituting into ( 5 . 33 ) that (cid:8) x r − x ∗ (cid:8) 2 A (cid:3) 0 , and therefore x r (cid:3) x ∗ , as claimed . (cid:1) By using similar reasoning , Luenberger [ 195 ] establishes the following estimate , which gives a useful characterization of the behavior of the CG method . Theorem 5 . 5 . If A has eigenvalues λ 1 ≤ λ 2 ≤ · · · ≤ λ n , we have that (cid:8) x k + 1 − x ∗ (cid:8) 2 A ≤ (cid:17) λ n − k − λ 1 λ n − k + λ 1 (cid:18) 2 (cid:8) x 0 − x ∗ (cid:8) 2 A . ( 5 . 35 ) 116 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S λ n−m + 1 λ n−m 1 λ | 0 1 n λ Figure 5 . 3 Two clusters of eigenvalues . Without giving details of the proof , we describe how this result is obtained from ( 5 . 33 ) . One selects a polynomial ¯ P k of degree k such that the polynomial Q k + 1 ( λ ) (cid:3) 1 + λ ¯ P k ( λ ) has roots at the k largest eigenvalues λ n , λ n − 1 , . . . , λ n − k + 1 , as well as at the midpoint between λ 1 and λ n − k . It can be shown that the maximum value attained by Q k + 1 on the remaining eigenvalues λ 1 , λ 2 , . . . , λ n − k is precisely ( λ n − k − λ 1 ) / ( λ n − k + λ 1 ) . We now illustrate how Theorem 5 . 5 can be used to predict the behavior of the CG method on speciﬁc problems . Suppose we have the situation plotted in Figure 5 . 3 , where the eigenvalues of A consist of m large values , with the remaining n − m smaller eigenvalues clustered around 1 . If we deﬁne (cid:9) (cid:3) λ n − m − λ 1 , Theorem 5 . 5 tells us that after m + 1 steps of the conjugate gradient algorithm , we have (cid:8) x m + 1 − x ∗ (cid:8) A ≈ (cid:9) (cid:8) x 0 − x ∗ (cid:8) A . For a small value of (cid:9) , we conclude that the CG iterates will provide a good estimate of the solution after only m + 1 steps . Figure 5 . 4 shows the behavior of CG on a problem of this type , which has ﬁve large eigenvalues with all the smaller eigenvalues clustered between 0 . 95 and 1 . 05 , and compares this behavior with that of CG on a problem in which the eigenvalues satisfy some random distribution . In both cases , we plot the log of φ after each iteration . For the problem with clustered eigenvalues , Theorem 5 . 5 predicts a sharp decrease in the error measure at iteration 6 . Note , however , that this decrease was achieved one iteration earlier , illustrating the fact that Theorem 5 . 5 gives only an upper bound , and that the rate of convergence can be faster . By contrast , we observe in Figure 5 . 4 that for the problem with randomly distributed eigenvalues ( dashed line ) , the convergence rate is slower and more uniform . Figure 5 . 4 illustrates another interesting feature : After one more iteration ( a total of seven ) on the problem with clustered eigenvalues , the error measure drops sharply . An extension of the arguments leading to Theorem 5 . 4 explains this behavior . It is almost true to say that the matrix A has just six distinct eigenvalues : the ﬁve large eigenvalues and 1 . Then we would expect the error measure to be zero after six iterations . Because the eigenvaluesnear1areslightlyspreadout , however , theerrordoesnotbecomeverysmalluntil iteration 7 . 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 117 uniformly distributed eigenvalues log ( | | x - x * | | ) A2 clustered eigenvalues 4 5 6 2 3 1 - 5 - 10 5 0 7 iteration Figure5 . 4 Performance of the conjugate gradient method on ( a ) a problem in which ﬁve of the eigenvalues are large and the remainder are clustered near 1 , and ( b ) a matrix with uniformly distributed eigenvalues . To state this claim more precisely , it is generally true that if the eigenvalues occur in r distinct clusters , the CG iterates will approximately solve the problem in about r steps ( see [ 136 ] ) . This result can be proved by constructing a polynomial ¯ P r − 1 such that ( 1 + λ ¯ P r − 1 ( λ ) ) has zeros inside each of the clusters . This polynomial may not vanish at the eigenvalues λ i , i (cid:3) 1 , 2 , . . . , n , but its value will be small at these points , so the constant deﬁned in ( 5 . 34 ) will be small for k ≥ r − 1 . We illustrate this behavior in Figure 5 . 5 , which shows the performance of CG on a matrix of dimension n (cid:3) 14 that has four clusters of eigenvalues : single eigenvalues at 140 and 120 , a cluster of 10 eigenvalues very close to 10 , with the remaining eigenvalues clustered between 0 . 95 and 1 . 05 . After four iterations , the error has decreased signiﬁcantly . After six iterations , the solution is identiﬁed to good accuracy . Another , more approximate , convergence expression for CG is based on the Euclidean condition number of A , which is deﬁned by κ ( A ) (cid:3) (cid:8) A (cid:8) 2 (cid:8) A − 1 (cid:8) 2 (cid:3) λ n / λ 1 . It can be shown that (cid:8) x k − x ∗ (cid:8) A ≤ 2 (cid:17) √ κ ( A ) − 1 √ κ ( A ) + 1 (cid:18) k (cid:8) x 0 − x ∗ (cid:8) A . ( 5 . 36 ) This bound often gives a large overestimate of the error , but it can be useful in those cases 118 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S log ( | | x - x * | | ) A2 1 2 3 4 6 5 0 5 - 5 - 10 iteration 7 Figure 5 . 5 Performance of the conjugate gradient method on a matrix in which the eigenvalues occur in four distinct clusters . where the only information we have about A is estimates of the extreme eigenvalues λ 1 and λ n . This bound should be compared with that of the steepest descent method given by ( 3 . 29 ) , which is identical in form but which depends on the condition number κ ( A ) , and not on its square root √ κ ( A ) . PRECONDITIONING We can accelerate the conjugate gradient method by transforming the linear system to improve the eigenvalue distribution of A . The key to this process , which is known as preconditioning , is a change of variables from x to ˆ x via a nonsingular matrix C , that is , ˆ x (cid:3) Cx . ( 5 . 37 ) The quadratic φ deﬁned by ( 5 . 2 ) is transformed accordingly to ˆ φ ( ˆ x ) (cid:3) 12 ˆ x T ( C − T AC − 1 ) ˆ x − ( C − T b ) T ˆ x . ( 5 . 38 ) If we use Algorithm 5 . 2 to minimize ˆ φ or , equivalently , to solve the linear system ( C − T AC − 1 ) ˆ x (cid:3) C − T b , then the convergence rate will depend on the eigenvalues of the matrix C − T AC − 1 rather than those of A . Therefore , we aim to choose C such that the eigenvalues of C − T AC − 1 5 . 1 . T H E L I N E A R C O N J U G A T E G R A D I E N T M E T H O D 119 are more favorable for the convergence theory discussed above . We can try to choose C such that the condition number of C − T AC − 1 is much smaller than the original condition number of A , for instance , so that the constant in ( 5 . 36 ) is smaller . We could also try to choose C such that the eigenvalues of C − T AC − 1 are clustered , which by the discussion of the previous section ensures that the number of iterates needed to ﬁnd a good approximate solution is not much larger than the number of clusters . It is not necessary to carry out the transformation ( 5 . 37 ) explicitly . Rather , we can apply Algorithm 5 . 2 to the problem ( 5 . 38 ) , in terms of the variables ˆ x , and then invert the transformations to reexpress all the equations in terms of x . This process of derivation results in Algorithm 5 . 3 ( Preconditioned Conjugate Gradient ) , which we now deﬁne . It happens that Algorithm 5 . 3 does not make use of C explicitly , but rather the matrix M (cid:3) C T C , which is symmetric and positive deﬁnite by construction . Algorithm 5 . 3 ( Preconditioned CG ) . Given x 0 , preconditioner M ; Set r 0 ← Ax 0 − b ; Solve My 0 (cid:3) r 0 for y 0 ; Set p 0 (cid:3) − y 0 , k ← 0 ; while r k (cid:9)(cid:3) 0 α k ← r Tk y k p Tk Ap k ; ( 5 . 39a ) x k + 1 ← x k + α k p k ; ( 5 . 39b ) r k + 1 ← r k + α k Ap k ; ( 5 . 39c ) Solve My k + 1 (cid:3) r k + 1 ; ( 5 . 39d ) β k + 1 ← r Tk + 1 y k + 1 r Tk y k ; ( 5 . 39e ) p k + 1 ← − y k + 1 + β k + 1 p k ; ( 5 . 39f ) k ← k + 1 ; ( 5 . 39g ) end ( while ) If we set M (cid:3) I in Algorithm 5 . 3 , we recover the standard CG method , Algorithm 5 . 2 . The properties of Algorithm 5 . 2 generalize to this case in interesting ways . In particular , the orthogonality property ( 5 . 16 ) of the successive residuals becomes r Ti M − 1 r j (cid:3) 0 for all i (cid:9)(cid:3) j . ( 5 . 40 ) 120 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S In terms of computational effort , the main difference between the preconditioned and unpreconditioned CG methods is the need to solve systems of the form My (cid:3) r ( step ( 5 . 39d ) ) . PRACTICAL PRECONDITIONERS No single preconditioning strategy is “best” for all conceivable types of matrices : The tradeoff between various objectives—effectiveness of M , inexpensive computation and storage of M , inexpensive solution of My (cid:3) r —varies from problem to problem . Good preconditioning strategies have been devised for speciﬁc types of matrices , in particular , those arising from discretizations of partial differential equations ( PDEs ) . Often , the preconditioner is deﬁned in such a way that the system My (cid:3) r amounts to a simpliﬁed version of the original system Ax (cid:3) b . In the case of a PDE , My (cid:3) r could represent a coarser discretization of the underlying continuous problem than Ax (cid:3) b . As in many other areas of optimization and numerical analysis , knowledge about the structure and origin of a problem ( in this case , knowledge that the system Ax (cid:3) b is a ﬁnite - dimensional representation of a PDE ) is the key to devising effective techniques for solving the problem . General - purpose preconditioners have also been proposed , but their success varies greatly from problem to problem . The most important strategies of this type include sym - metricsuccessiveoverrelaxation ( SSOR ) , incompleteCholesky , andbandedpreconditioners . ( See [ 272 ] , [ 136 ] , and [ 72 ] for discussions of these techniques . ) Incomplete Cholesky is prob - ably the most effective in general . The basic idea is simple : We follow the Cholesky procedure , but instead of computing the exact Cholesky factor L that satisﬁes A (cid:3) LL T , we compute an approximate factor ˜ L that is sparser than L . ( Usually , we require ˜ L to be no denser , or not much denser , than the lower triangle of the original matrix A . ) We then have A ≈ ˜ L ˜ L T , and by choosing C (cid:3) ˜ L T , we obtain M (cid:3) ˜ L ˜ L T and C − T AC − 1 (cid:3) ˜ L − 1 A ˜ L − T ≈ I , so the eigenvalue distribution of C − T AC − 1 is favorable . We do not compute M explicitly , but rather store the factor ˜ L and solve the system My (cid:3) r by performing two triangular substitutions with ˜ L . Because the sparsity of ˜ L is similar to that of A , the cost of solving My (cid:3) r is similar to the cost of computing the matrix – vector product Ap . There are several possible pitfalls in the incomplete Cholesky approach . One is that the resulting matrix may not be ( sufﬁciently ) positive deﬁnite , and in this case one may need to increase the values of the diagonal elements to ensure that a value for ˜ L can be found . Numerical instability or breakdown can occur during the incomplete factorization because of the sparsity conditions we impose on the factor ˜ L . This difﬁculty can be remedied by allowing additional ﬁll - in in ˜ L , but the denser factor will be more expensive to compute and to apply at each iteration . 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 121 5 . 2 NONLINEAR CONJUGATE GRADIENT METHODS We have noted that the CG method , Algorithm 5 . 2 , can be viewed as a minimization algorithm for the convex quadratic function φ deﬁned by ( 5 . 2 ) . It is natural to ask whether we can adapt the approach to minimize general convex functions , or even general nonlinear functions f . In fact , as we show in this section , nonlinear variants of the conjugate gradient are well studied and have proved to be quite successful in practice . THE FLETCHER – REEVES METHOD Fletcher and Reeves [ 107 ] showed how to extend the conjugate gradient method to nonlinear functions by making two simple changes in Algorithm 5 . 2 . First , in place of the formula ( 5 . 24a ) for the step length α k ( which minimizes φ along the search direction p k ) , we need to perform a line search that identiﬁes an approximate minimum of the nonlinear function f along p k . Second , the residual r , which is simply the gradient of φ in Algorithm 5 . 2 ( see ( 5 . 3 ) ) , must be replaced by the gradient of the nonlinear objective f . These changes give rise to the following algorithm for nonlinear optimization . Algorithm 5 . 4 ( FR ) . Given x 0 ; Evaluate f 0 (cid:3) f ( x 0 ) , ∇ f 0 (cid:3) ∇ f ( x 0 ) ; Set p 0 ← −∇ f 0 , k ← 0 ; while ∇ f k (cid:9)(cid:3) 0 Compute α k and set x k + 1 (cid:3) x k + α k p k ; Evaluate ∇ f k + 1 ; β FR k + 1 ← ∇ f Tk + 1 ∇ f k + 1 ∇ f Tk ∇ f k ; ( 5 . 41a ) p k + 1 ← −∇ f k + 1 + β FR k + 1 p k ; ( 5 . 41b ) k ← k + 1 ; ( 5 . 41c ) end ( while ) If we choose f to be a strongly convex quadratic and α k to be the exact minimizer , this algorithm reduces to the linear conjugate gradient method , Algorithm 5 . 2 . Algorithm 5 . 4 is appealing for large nonlinear optimization problems because each iteration requires only evaluation of the objective function and its gradient . No matrix operations are required for the step computation , and just a few vectors of storage are required . To make the speciﬁcation of Algorithm 5 . 4 complete , we need to be more precise about the choice of line search parameter α k . Because of the second term in ( 5 . 41b ) , the search direction p k may fail to be a descent direction unless α k satisﬁes certain conditions . 122 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S By taking the inner product of ( 5 . 41b ) ( with k replacing k + 1 ) with the gradient vector ∇ f k , we obtain ∇ f Tk p k (cid:3) −(cid:8)∇ f k (cid:8) 2 + β FR k ∇ f Tk p k − 1 . ( 5 . 42 ) If the line search is exact , so that α k − 1 is a local minimizer of f along the direction p k − 1 , we have that ∇ f Tk p k − 1 (cid:3) 0 . In this case we have from ( 5 . 42 ) that ∇ f Tk p k < 0 , so that p k is indeed a descent direction . If the line search is not exact , however , the second term in ( 5 . 42 ) may dominate the ﬁrst term , and we may have ∇ f Tk p k > 0 , implying that p k is actually a direction of ascent . Fortunately , we can avoid this situation by requiring the step length α k to satisfy the strong Wolfe conditions , which we restate here : f ( x k + α k p k ) ≤ f ( x k ) + c 1 α k ∇ f Tk p k , ( 5 . 43a ) | ∇ f ( x k + α k p k ) T p k | ≤ − c 2 ∇ f Tk p k , ( 5 . 43b ) where 0 < c 1 < c 2 < 12 . ( Note that we impose c 2 < 12 here , in place of the looser condition c 2 < 1 that was used in the earlier statement ( 3 . 7 ) . ) By applying Lemma 5 . 6 below , we can show that condition ( 5 . 43b ) implies that ( 5 . 42 ) is negative , and we conclude that any line search procedure that yields an α k satisfying ( 5 . 43 ) will ensure that all directions p k are descent directions for the function f . THE POLAK – RIBI ` ERE METHOD AND VARIANTS There are many variants of the Fletcher – Reeves method that differ from each other mainly in the choice of the parameter β k . An important variant , proposed by Polak and Ribi ` ere , deﬁnes this parameter as follows : β PR k + 1 (cid:3) ∇ f Tk + 1 ( ∇ f k + 1 − ∇ f k ) (cid:8)∇ f k (cid:8) 2 . ( 5 . 44 ) We refer to the algorithm in which ( 5 . 44 ) replaces ( 5 . 41a ) as Algorithm PR . It is identical to Algorithm FR when f is a strongly convex quadratic function and the line search is exact , since by ( 5 . 16 ) the gradients are mutually orthogonal , and so β PR k + 1 (cid:3) β FR k + 1 . When applied to general nonlinear functions with inexact line searches , however , the behavior of the two algorithms differs markedly . Numerical experience indicates that Algorithm PR tends to be the more robust and efﬁcient of the two . A surprising fact about Algorithm PR is that the strong Wolfe conditions ( 5 . 43 ) do not guarantee that p k is always a descent direction . If we deﬁne the β parameter as β + k + 1 (cid:3) max { β PR k + 1 , 0 } , ( 5 . 45 ) 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 123 giving rise to an algorithm we call Algorithm PR + , then a simple adaptation of the strong Wolfe conditions ensures that the descent property holds . There are many other choices for β k + 1 that coincide with the Fletcher – Reeves formula β FR k + 1 in the case where the objective is quadratic and the line search is exact . The Hestenes – Stiefel formula , which deﬁnes β HS k + 1 (cid:3) ∇ f T k + 1 ( ∇ f k + 1 − ∇ f k ) ( ∇ f k + 1 − ∇ f k ) T p k , ( 5 . 46 ) gives rise to an algorithm ( called Algorithm HS ) that is similar to Algorithm PR , both in terms of its theoretical convergence properties and in its practical performance . Formula ( 5 . 46 ) can be derived by demanding that consecutive search directions be conjugate with respect to the average Hessian over the line segment [ x k , x k + 1 ] , which is deﬁned as ¯ G k ≡ (cid:6) 1 0 [ ∇ 2 f ( x k + τα k p k ) ] d τ . Recalling from Taylor’s theorem ( Theorem 2 . 1 ) that ∇ f k + 1 (cid:3) ∇ f k + α k ¯ G k p k , we see that for any direction of the form p k + 1 (cid:3) −∇ f k + 1 + β k + 1 p k , the condition p Tk + 1 ¯ G k p k (cid:3) 0 requires β k + 1 to be given by ( 5 . 46 ) . Later , we see that it is possible to guarantee global convergence for any parameter β k satisfying the bound | β k | ≤ β FR k , ( 5 . 47 ) for all k ≥ 2 . This fact suggests the following modiﬁcation of the PR method , which has performed well on some applications . For all k ≥ 2 let β k (cid:3) ⎧⎪⎨ ⎪⎩ − β FR k if β PR k < − β FR k β PR k if | β PR k | ≤ β FR k β FR k if β PR k > β FR k . ( 5 . 48 ) The algorithm based on this strategy will be denoted by FR - PR . Other variants of the CG method have recently been proposed . Two choices for β k + 1 that possess attractive theoretical and computational properties are β k + 1 (cid:3) (cid:8)∇ f k + 1 (cid:8) 2 ( ∇ f k + 1 − ∇ f k ) T p k ( 5 . 49 ) ( see [ 85 ] ) and β k + 1 (cid:3) (cid:17) ˆ y k − 2 p k (cid:8) ˆ y k (cid:8) 2 ˆ y Tk p k (cid:18) T ∇ f k + 1 ˆ y Tk p k , with ˆ y k (cid:3) ∇ f k + 1 − ∇ f k ( 5 . 50 ) 124 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S ( see [ 161 ] ) . These two choices guarantee that p k is a descent direction , provided the steplength α k satisﬁes the Wolfe conditions . The CG algorithms based on ( 5 . 49 ) or ( 5 . 50 ) appear to be competitive with the Polak – Ribi ` ere method . QUADRATIC TERMINATION AND RESTARTS Implementations of nonlinear conjugate gradient methods usually preserve their close connections with the linear conjugate gradient method . Usually , a quadratic ( or cubic ) interpolation along the search direction p k is incorporated into the line search procedure ; see Chapter 3 . This feature guarantees that when f is a strictly convex quadratic , the step length α k is chosen to be the exact one - dimensional minimizer , so that the nonlinear conjugate gradient method reduces to the linear method , Algorithm 5 . 2 . Another modiﬁcation that is often used in nonlinear conjugate gradient procedures is to restart the iteration at every n steps by setting β k (cid:3) 0 in ( 5 . 41a ) , that is , by taking a steepest descent step . Restarting serves to periodically refresh the algorithm , erasing old information that may not be beneﬁcial . We can even prove a strong theoretical result about restarting : It leads to n - step quadratic convergence , that is , (cid:8) x k + n − x (cid:8) (cid:3) O (cid:7) (cid:8) x k − x ∗ (cid:8) 2 (cid:8) . ( 5 . 51 ) After a little thought , this result is not so surprising . Consider a function f that is strongly convex quadratic in a neighborhood of the solution , but is nonquadratic everywhere else . Assuming that the algorithm is converging to the solution in question , the iterates will eventually enter the quadratic region . At some point , the algorithm will be restarted in that region , and from that point onward , its behavior will simply be that of the linear conjugate gradient method , Algorithm 5 . 2 . In particular , ﬁnite termination will occur within n steps of the restart . The restart is important , because the ﬁnite - termination property and other appealing properties of Algorithm 5 . 2 hold only when its initial search direction p 0 is equal to the negative gradient . Even if the function f is not exactly quadratic in the region of a solution , Taylor’s theorem ( Theorem 2 . 1 ) implies that it can still be approximated quite closely by a quadratic , provided that it is smooth . Therefore , while we would not expect termination in n steps after the restart , it is not surprising that substantial progress is made toward the solution , as indicated by the expression ( 5 . 51 ) . Though the result ( 5 . 51 ) is interesting from a theoretical viewpoint , it may not be relevant in a practical context , because nonlinear conjugate gradient methods can be recom - mended only for solving problems with large n . Restarts may never occur in such problems because an approximate solution may be located in fewer than n steps . Hence , nonlinear CG method are sometimes implemented without restarts , or else they include strategies for restarting that are based on considerations other than iteration counts . The most popular restart strategy makes use of the observation ( 5 . 16 ) , which is that the gradients are mutually orthogonal when f is a quadratic function . A restart is performed whenever two consecutive 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 125 gradients are far from orthogonal , as measured by the test | ∇ f Tk ∇ f k − 1 | (cid:8)∇ f k (cid:8) 2 ≥ ν , ( 5 . 52 ) where a typical value for the parameter ν is 0 . 1 . We could also think of formula ( 5 . 45 ) as a restarting strategy , because p k + 1 will revert to the steepest descent direction whenever β PR k is negative . In contrast to ( 5 . 52 ) , these restarts are rather infrequent because β PR k is positive most of the time . BEHAVIOR OF THE FLETCHER – REEVES METHOD We now investigate the Fletcher – Reeves algorithm , Algorithm 5 . 4 , a little more closely , proving that it is globally convergent and explaining some of its observed inefﬁciencies . The following result gives conditions on the line search under which all search direc - tions are descent directions . It assumes that the level set L (cid:3) { x : f ( x ) ≤ f ( x 0 ) } is bounded and that f is twice continuously differentiable , so that we have from Lemma 3 . 1 that there exists a step length α k satisfying the strong Wolfe conditions . Lemma 5 . 6 . Suppose that Algorithm 5 . 4 is implemented with a step length α k that satisﬁes the strong Wolfe conditions ( 5 . 43 ) with 0 < c 2 < 12 . Then the method generates descent directions p k that satisfy the following inequalities : − 1 1 − c 2 ≤ ∇ f Tk p k (cid:8)∇ f k (cid:8) 2 ≤ 2 c 2 − 1 1 − c 2 , for all k (cid:3) 0 , 1 , . . . . ( 5 . 53 ) P ROOF . Note ﬁrst that the function t ( ξ ) def (cid:3) ( 2 ξ − 1 ) / ( 1 − ξ ) is monotonically increasing on the interval [ 0 , 12 ] and that t ( 0 ) (cid:3) − 1 and t ( 12 ) (cid:3) 0 . Hence , because of c 2 ∈ ( 0 , 12 ) , we have − 1 < 2 c 2 − 1 1 − c 2 < 0 . ( 5 . 54 ) The descent condition ∇ f T k p k < 0 follows immediately once we establish ( 5 . 53 ) . The proof is by induction . For k (cid:3) 0 , the middle term in ( 5 . 53 ) is − 1 , so by using ( 5 . 54 ) , we see that both inequalities in ( 5 . 53 ) are satisﬁed . Next , assume that ( 5 . 53 ) holds for some k ≥ 1 . From ( 5 . 41b ) and ( 5 . 41a ) we have ∇ f T k + 1 p k + 1 (cid:8)∇ f k + 1 (cid:8) 2 (cid:3) − 1 + β k + 1 ∇ f T k + 1 p k (cid:8)∇ f k + 1 (cid:8) 2 (cid:3) − 1 + ∇ f T k + 1 p k (cid:8)∇ f k (cid:8) 2 . ( 5 . 55 ) 126 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S By using the line search condition ( 5 . 43b ) , we have | ∇ f Tk + 1 p k | ≤ − c 2 ∇ f Tk p k , so by combining with ( 5 . 55 ) and recalling ( 5 . 41a ) , we obtain − 1 + c 2 ∇ f T k p k (cid:8)∇ f k (cid:8) 2 ≤ ∇ f T k + 1 p k + 1 (cid:8)∇ f k + 1 (cid:8) 2 ≤ − 1 − c 2 ∇ f T k p k (cid:8)∇ f k (cid:8) 2 . Substituting for the term ∇ f Tk p k / (cid:8)∇ f k (cid:8) 2 from the left - hand - side of the induction hypothesis ( 5 . 53 ) , we obtain − 1 − c 2 1 − c 2 ≤ ∇ f Tk + 1 p k + 1 (cid:8)∇ f k + 1 (cid:8) 2 ≤ − 1 + c 2 1 − c 2 , which shows that ( 5 . 53 ) holds for k + 1 as well . (cid:1) This result used only the second strong Wolfe condition ( 5 . 43b ) ; the ﬁrst Wolfe condition ( 5 . 43a ) will be needed in the next section to establish global convergence . The bounds on ∇ f Tk p k in ( 5 . 53 ) impose a limit on how fast the norms of the steps (cid:8) p k (cid:8) can grow , and they will play a crucial role in the convergence analysis given below . Lemma 5 . 6 can also be used to explain a weakness of the Fletcher – Reeves method . We will argue that if the method generates a bad direction and a tiny step , then the next direction and next step are also likely to be poor . As in Chapter 3 , we let θ k denote the angle between p k and the steepest descent direction −∇ f k , deﬁned by cos θ k (cid:3) −∇ f T k p k (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) . ( 5 . 56 ) Suppose that p k is a poor search direction , in the sense that it makes an angle of nearly 90 ◦ with −∇ f k , that is , cos θ k ≈ 0 . By multiplying both sides of ( 5 . 53 ) by (cid:8)∇ f k (cid:8) / (cid:8) p k (cid:8) and using ( 5 . 56 ) , we obtain 1 − 2 c 2 1 − c 2 (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) ≤ cos θ k ≤ 1 1 − c 2 (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) , for all k (cid:3) 0 , 1 , . . . . ( 5 . 57 ) From these inequalities , we deduce that cos θ k ≈ 0 if and only if (cid:8)∇ f k (cid:8) (cid:24) (cid:8) p k (cid:8) . Since p k is almost orthogonal to the gradient , it is likely that the step from x k to x k + 1 is tiny , that is , x k + 1 ≈ x k . If so , we have ∇ f k + 1 ≈ ∇ f k , and therefore β FR k + 1 ≈ 1 , ( 5 . 58 ) 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 127 by the deﬁnition ( 5 . 41a ) . By using this approximation together with (cid:8)∇ f k + 1 (cid:8) ≈ (cid:8)∇ f k (cid:8) (cid:24) (cid:8) p k (cid:8) in ( 5 . 41b ) , we conclude that p k + 1 ≈ p k , so the new search direction will improve little ( if at all ) on the previous one . It follows that if the condition cos θ k ≈ 0 holds at some iteration k and if the subsequent step is small , a long sequence of unproductive iterates will follow . The Polak – Ribi ` ere method behaves quite differently in these circumstances . If , as in the previous paragraph , the search direction p k satisﬁes cos θ k ≈ 0 for some k , and if the subsequent step is small , it follows by substituting ∇ f k ≈ ∇ f k + 1 into ( 5 . 44 ) that β PR k + 1 ≈ 0 . From the formula ( 5 . 41b ) , we ﬁnd that the new search direction p k + 1 will be close to the steepest descent direction −∇ f k + 1 , and cos θ k + 1 will be close to 1 . Therefore , Algorithm PR essentially performs a restart after it encounters a bad direction . The same argument can be applied to Algorithms PR + and HS . For the FR - PR variant , deﬁned by ( 5 . 48 ) , we have noted already that β FR k + 1 ≈ 1 , and β PR k + 1 ≈ 0 . The formula ( 5 . 48 ) thus sets β k + 1 (cid:3) β PR k + 1 , as desired . Thus , the modiﬁcation ( 5 . 48 ) seems to avoid the inefﬁciencies of the FR method , while falling back on this method for global convergence . The undesirable behavior of the Fletcher – Reeves method predicted by the arguments given above can be observed in practice . For example , the paper [ 123 ] describes a problem with n (cid:3) 100 in which cos θ k is of order 10 − 2 for hundreds of iterations and the steps (cid:8) x k − x k − 1 (cid:8) are of order 10 − 2 . Algorithm FR requires thousands of iterations to solve this problem , while Algorithm PR requires just 37 iterations . In this example , the Fletcher – Reeves method performs much better if it is periodically restarted along the steepest descent direction , since each restart terminates the cycle of bad steps . In general , Algorithm FR should not be implemented without some kind of restart strategy . GLOBAL CONVERGENCE Unlike the linear conjugate gradient method , whose convergence properties are well understood and which is known to be optimal as described above , nonlinear conjugate gradient methods possess surprising , sometimes bizarre , convergence properties . We now present a few of the main results known for the Fletcher – Reeves and Polak – Ribi ` ere methods using practical line searches . For the purposes of this section , we make the following ( nonrestrictive ) assumptions on the objective function . Assumptions 5 . 1 . ( i ) The level set L : (cid:3) { x | f ( x ) ≤ f ( x 0 ) } is bounded ; ( ii ) In some open neighborhood N of L , the objective function f is Lipschitz continuously differentiable . 128 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S These assumptions imply that there is a constant ¯ γ such that (cid:8)∇ f ( x ) (cid:8) ≤ ¯ γ , for all x ∈ L . ( 5 . 59 ) Our main analytical tool in this section is Zoutendijk’s theorem—Theorem 3 . 2 in Chapter 3 . It states , that under Assumptions 5 . 1 , any line search iteration of the form x k + 1 (cid:3) x k + α k p k , where p k is a descent direction and α k satisﬁes the Wolfe conditions ( 5 . 43 ) gives the limit ∞ (cid:3) k (cid:3) 0 cos 2 θ k (cid:8)∇ f k (cid:8) 2 < ∞ . ( 5 . 60 ) We can use this result to prove global convergence for algorithms that are periodically restarted by setting β k (cid:3) 0 . If k 1 , k 2 , and so on denote the iterations on which restarts occur , we have from ( 5 . 60 ) that (cid:3) k (cid:3) k 1 , k 2 , . . . (cid:8)∇ f k (cid:8) 2 < ∞ . ( 5 . 61 ) If we allow no more than ¯ n iterations between restarts , the sequence { k j } ∞ j (cid:3) 1 is inﬁnite , and from ( 5 . 61 ) we have that lim j →∞ (cid:8)∇ f k j (cid:8) (cid:3) 0 . That is , a subsequence of gradients approaches zero , or equivalently , lim inf k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . ( 5 . 62 ) This result applies equally to restarted versions of all the algorithms discussed in this chapter . Itismoreinteresting , however , tostudytheglobalconvergenceof unrestarted conjugate gradient methods , because for large problems ( say n ≥ 1000 ) we expect to ﬁnd a solution in many fewer than n iterations—the ﬁrst point at which a regular restart would take place . Our study of large sequences of unrestarted conjugate gradient iterations reveals some surprising patterns in their behavior . We can build on Lemma 5 . 6 and Zoutendijk’s result ( 5 . 60 ) to prove a global conver - gence result for the Fletcher – Reeves method . While we cannot show that the limit of the sequence of gradients { ∇ f k } is zero , the following result shows that this sequence is not bounded away from zero . Theorem 5 . 7 ( Al - Baali [ 3 ] ) . Suppose that Assumptions 5 . 1 hold , and that Algorithm 5 . 4 is implemented with a line search that satisﬁes the strong Wolfe conditions ( 5 . 43 ) , with 0 < c 1 < c 2 < 12 . Then lim inf k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . ( 5 . 63 ) 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 129 P ROOF . The proof is by contradiction . It assumes that the opposite of ( 5 . 63 ) holds , that is , there is a constant γ > 0 such that (cid:8)∇ f k (cid:8) ≥ γ , ( 5 . 64 ) for all k sufﬁciently large . By substituting the left inequality of ( 5 . 57 ) into Zoutendijk’s condition ( 5 . 60 ) , we obtain ∞ (cid:3) k (cid:3) 0 (cid:8)∇ f k (cid:8) 4 (cid:8) p k (cid:8) 2 < ∞ . ( 5 . 65 ) By using ( 5 . 43b ) and ( 5 . 53 ) , we obtain that | ∇ f Tk p k − 1 | ≤ − c 2 ∇ f Tk − 1 p k − 1 ≤ c 2 1 − c 2 (cid:8)∇ f k − 1 (cid:8) 2 . ( 5 . 66 ) Thus , from ( 5 . 41b ) and recalling the deﬁnition ( 5 . 41a ) of β FR k we obtain (cid:8) p k (cid:8) 2 ≤ (cid:8)∇ f k (cid:8) 2 + 2 β FR k | ∇ f Tk p k − 1 | + ( β FR k ) 2 (cid:8) p k − 1 (cid:8) 2 ≤ (cid:8)∇ f k (cid:8) 2 + 2 c 2 1 − c 2 β FR k (cid:8)∇ f k − 1 (cid:8) 2 + ( β FR k ) 2 (cid:8) p k − 1 (cid:8) 2 (cid:3) (cid:17) 1 + c 2 1 − c 2 (cid:18) (cid:8)∇ f k (cid:8) 2 + ( β FR k ) 2 (cid:8) p k − 1 (cid:8) 2 . Applying this relation repeatedly , and deﬁning c 3 def (cid:3) ( 1 + c 2 ) / ( 1 − c 2 ) ≥ 1 , we have (cid:8) p k (cid:8) 2 ≤ c 3 (cid:8)∇ f k (cid:8) 2 + ( β FR k ) 2 ( c 3 (cid:8)∇ f k − 1 (cid:8) 2 + ( β FR k − 1 ) 2 ( c 3 (cid:8)∇ f k − 2 (cid:8) 2 + · · · + ( β FR 1 ) 2 (cid:8) p 0 (cid:8) 2 ) ) · · · ) (cid:3) c 3 (cid:8)∇ f k (cid:8) 4 k (cid:3) j (cid:3) 0 (cid:8)∇ f j (cid:8) − 2 , ( 5 . 67 ) where we used the facts that ( β FR k ) 2 ( β FR k − 1 ) 2 · · · ( β FR k − i ) 2 (cid:3) (cid:8)∇ f k (cid:8) 4 (cid:8)∇ f k − i − 1 (cid:8) 4 and p 0 (cid:3) −∇ f 0 . By using the bounds ( 5 . 59 ) and ( 5 . 64 ) in ( 5 . 67 ) , we obtain (cid:8) p k (cid:8) 2 ≤ c 3 ¯ γ 4 γ 2 k , ( 5 . 68 ) 130 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S which implies that ∞ (cid:3) k (cid:3) 1 1 (cid:8) p k (cid:8) 2 ≥ γ 4 ∞ (cid:3) k (cid:3) 1 1 k , ( 5 . 69 ) for some positive constant γ 4 . On the other hand , from ( 5 . 64 ) and ( 5 . 65 ) , we have that ∞ (cid:3) k (cid:3) 1 1 (cid:8) p k (cid:8) 2 < ∞ . ( 5 . 70 ) However , if we combine this inequality with ( 5 . 69 ) , we obtain that (cid:4) ∞ k (cid:3) 1 1 / k < ∞ , which is not true . Hence , ( 5 . 64 ) does not hold , and the claim ( 5 . 63 ) is proved . (cid:1) This global convergence result can be extended to any choice of β k satisfying ( 5 . 47 ) , and in particular to the FR - PR method given by ( 5 . 48 ) . In general , if we can show that there exist constants c 4 , c 5 > 0 such that cos θ k ≥ c 4 (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) , (cid:8)∇ f k (cid:8) (cid:8) p k (cid:8) ≥ c 5 > 0 , k (cid:3) 1 , 2 , . . . , it follows from ( 5 . 60 ) that lim k →∞ (cid:8)∇ f k (cid:8) (cid:3) 0 . In fact , this result can be established for the Polak – Ribi ` ere method under the assumption that f is strongly convex and that an exact line search is used . For general ( nonconvex ) functions , however , is it not possible to prove a result like Theorem 5 . 7 for Algorithm PR . This fact is unexpected , since the Polak – Ribi ` ere method performs better in practice than the Fletcher – Reeves method . The following surprising result shows that the Polak – Ribi ` ere method can cycle inﬁnitely without approaching a solution point , even if an ideal line search is used . ( By “ideal” we mean that line search returns a value α k that is the ﬁrst positive stationary point for the function t ( α ) (cid:3) f ( x k + α p k ) . ) Theorem 5 . 8 . Consider the Polak – Ribi ` ere method method ( 5 . 44 ) with an ideal line search . There exists a twice continuously differentiable objective function f : IR 3 → IR and a starting point x 0 ∈ IR 3 such that the sequence of gradients { (cid:8)∇ f k (cid:8) } is bounded away from zero . The proof of this result , given in [ 253 ] , is quite complex . It demonstrates the existence of the desired objective function without actually constructing this function explicitly . The result is interesting , since the step length assumed in the proof—the ﬁrst stationary point— may be accepted by any of the practical line search algorithms currently in use . The proof 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 131 of Theorem 5 . 8 requires that some consecutive search directions become almost negatives of each other . In the case of ideal line searches , this happens only if β k < 0 , so the analysis suggests Algorithm PR + ( see ( 5 . 45 ) ) , in which we reset β k to zero whenever it becomes negative . We mentioned earlier that a line search strategy based on a slight modiﬁcation of the Wolfe conditions guarantees that all search directions generated by Algorithm PR + are descent directions . Using these facts , it is possible to a prove global convergence result like Theorem 5 . 7 for Algorithm PR + . An attractive property of the formulae ( 5 . 49 ) , ( 5 . 50 ) is that global convergence can be established without introducing any modiﬁcation to a line search based on the Wolfe conditions . NUMERICAL PERFORMANCE Table 5 . 1 illustrates the performance of Algorithms FR , PR , and PR + without restarts . For these tests , the parameters in the strong Wolfe conditions ( 5 . 43 ) were chosen to be c 1 (cid:3) 10 − 4 and c 2 (cid:3) 0 . 1 . The iterations were terminated when (cid:8)∇ f k (cid:8) ∞ < 10 − 5 ( 1 + | f k | ) . If this condition was not satisﬁed after 10 , 000 iterations , we declare failure ( indicated by a ∗ in the table ) . The ﬁnal column , headed “mod , ” indicates the number of iterations of Algorithm PR + forwhichtheadjustment ( 5 . 45 ) wasneededtoensurethat β PR k ≥ 0 . AlgorithmFRonproblem GENROS takes very short steps far from the solution that lead to tiny improvements in the objective function , and convergence was not achieved within the maximum number of iterations . The Polak – Ribi ` ere algorithm , or its variation PR + , are not always more efﬁcient than Algorithm FR , and it has the slight disadvantage of requiring one more vector of storage . Nevertheless , we recommend that users choose Algorithm PR , PR + or FR - PR , or the methods based on ( 5 . 49 ) and ( 5 . 50 ) . Table 5 . 1 Iterations and function / gradient evaluations required by three nonlinear conjugate gradient methods on a set of test problems ; see [ 123 ] Alg FR Alg PR Alg PR + Problem n it / f - g it / f - g it / f - g mod CALCVAR3 200 2808 / 5617 2631 / 5263 2631 / 5263 0 GENROS 500 ∗ 1068 / 2151 1067 / 2149 1 XPOWSING 1000 533 / 1102 212 / 473 97 / 229 3 TRIDIA1 1000 264 / 531 262 / 527 262 / 527 0 MSQRT1 1000 422 / 849 113 / 231 113 / 231 0 XPOWELL 1000 568 / 1175 212 / 473 97 / 229 3 TRIGON 1000 231 / 467 40 / 92 40 / 92 0 132 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S NOTES AND REFERENCES The conjugate gradient method was developed in the 1950s by Hestenes and Stiefel [ 168 ] as an alternative to factorization methods for ﬁnding solutions of symmet - ric positive deﬁnite systems . It was not until some years later , in one of the most important developments in sparse linear algebra , that this method came to be viewed as an iterative method that could give good approximate solutions to systems in many fewer than n steps . Our presentation of the linear conjugate gradient method follows that of Luenberger [ 195 ] . For a history of the development of the conjugate gradient and Lanczos methods see Golub and O’Leary [ 135 ] . Interestingly enough , the nonlinear conjugate gradient method of Fletcher and Reeves [ 107 ] was proposed after the linear conjugate gradient method had fallen out of favor , but several years before it was rediscovered as an iterative method for linear systems . The Polak – Ribi ` ere method was introduced in [ 237 ] , and the example showing that it may fail to converge on nonconvex problems is given by Powell [ 253 ] . Restart procedures are discussed in Powell [ 248 ] . Hager and Zhang [ 161 ] report some of the best computational results obtained to date with a nonlinear CG method . Their implementation is based on formula ( 5 . 50 ) and uses a high - accuracy line search procedure . The results in Table 5 . 1 are taken from Gilbert and Nocedal [ 123 ] . This paper also describes a line search that guarantees that Algorithm PR + always generates descent directions and proves global convergence . Analysis due to Powell [ 245 ] provides further evidence of the inefﬁciency of the Fletcher – Reeves method using exact line searches . He shows that if the iterates enter a region in which the function is the two - dimensional quadratic f ( x ) (cid:3) 12 x T x , then the angle between the gradient ∇ f k and the search direction p k stays constant . Since this angle can be arbitrarily close to 90 ◦ , the Fletcher – Reeves method can be slower than the steepest descent method . The Polak – Ribi ` ere method behaves quite differently in these circumstances : If a very small step is generated , the next search direction tends to the steepest descent direction , as argued above . This feature prevents a sequence of tiny steps . The global convergence of nonlinear conjugate gradient methods has received much attention ; see for example Al - Baali [ 3 ] , Gilbert and Nocedal [ 123 ] , Dai and Yuan [ 85 ] , and Hager and Zhang [ 161 ] . For recent surveys on CG methods see Gould et al . [ 147 ] and Hager and Zhang [ 162 ] . Most of the theory on the rate of convergence of conjugate gradient methods assumes that the line search is exact . Crowder and Wolfe [ 82 ] show that the rate of convergence is linear , and show by constructing an example that Q - superlinear convergence is not achievable . Powell [ 245 ] studies the case in which the conjugate gradient method enters a region where the objective function is quadratic , and shows that either ﬁnite termination occurs or the rate of convergence is linear . Cohen [ 63 ] and Burmeister [ 45 ] prove n - step 5 . 2 . N O N L I N E A R C O N J U G A T E G R A D I E N T M E T H O D S 133 quadratic convergence ( 5 . 51 ) for general objective functions . Ritter [ 265 ] shows that in fact , the rate is superquadratic , that is , (cid:8) x k + n − x ∗ (cid:8) (cid:3) o ( (cid:8) x k − x ∗ (cid:8) 2 ) . Powell [ 251 ] gives a slightly better result and performs numerical tests on small problems to measure the rate observed in practice . He also summarizes rate - of - convergence results for asymptotically exact line searches , such as those obtained by Baptist and Stoer [ 11 ] and Stoer [ 282 ] . Even faster rates of convergence can be established ( see Schuller [ 278 ] , Ritter [ 265 ] ) , under the assumption that the search directions are uniformly linearly independent , but this assumption is hard to verify and does not often occur in practice . Nemirovsky and Yudin [ 225 ] devote some attention to the global efﬁciency of the Fletcher – Reeves and Polak – Ribi ` ere methods with exact line searches . For this purpose they deﬁne a measure of “laboriousness” and an “optimal bound” for it among a certain class of iterations . They show that on strongly convex problems not only do the Fletcher – Reeves and Polak – Ribi ` ere methods fail to attain the optimal bound , but they may also be slower than the steepest descent method . Subsequently , Nesterov [ 225 ] presented an algorithm that attains this optimal bound . It is related to PARTAN , the method of parallel tangents ( see , for example , Luenberger [ 195 ] ) . We feel that this approach is unlikely to be effective in practice , but no conclusive investigation has been carried out , to the best of our knowledge . ✐ E X E R C I S E S ✐ 5 . 1 Implement Algorithm 5 . 2 and use to it solve linear systems in which A is the Hilbert matrix , whose elements are A i , j (cid:3) 1 / ( i + j − 1 ) . Set the right - hand - side to b (cid:3) ( 1 , 1 , . . . , 1 ) T and the initial point to x 0 (cid:3) 0 . Try dimensions n (cid:3) 5 , 8 , 12 , 20 and report the number of iterations required to reduce the residual below 10 − 6 . ✐ 5 . 2 Show that if the nonzero vectors p 0 , p 1 , . . . , p l satisfy ( 5 . 5 ) , where A is symmetric and positive deﬁnite , then these vectors are linearly independent . ( This result implies that A has at most n conjugate directions . ) ✐ 5 . 3 Verify the formula ( 5 . 7 ) . ✐ 5 . 4 Show that if f ( x ) is a strictly convex quadratic , then the function h ( σ ) def (cid:3) f ( x 0 + σ 0 p 0 + · · · + σ k − 1 p k − 1 ) also is a strictly convex quadratic in the variable σ (cid:3) ( σ 0 , σ 1 , . . . , σ k − 1 ) T . ✐ 5 . 5 Verify from the formulae ( 5 . 14 ) that ( 5 . 17 ) and ( 5 . 18 ) hold for k (cid:3) 1 . ✐ 5 . 6 Show that ( 5 . 24d ) is equivalent to ( 5 . 14d ) . 134 C H A P T E R 5 . C O N J U G A T E G R A D I E N T M E T H O D S ✐ 5 . 7 Let { λ i , v i } i (cid:3) 1 , 2 , . . . , n be the eigenpairs of the symmetric matrix A . Show that the eigenvalues and eigenvectors of [ I + P k ( A ) A ] T A [ I + P k ( A ) A ] are λ i [ 1 + λ i P k ( λ i ) ] 2 and v i , respectively . ✐ 5 . 8 Construct matrices with various eigenvalue distributions ( clustered and non - clustered ) and apply the CG method to them . Comment on whether the behavior can be explained from Theorem 5 . 5 . ✐ 5 . 9 Derive Algorithm 5 . 3 by applying the standard CG method in the variables ˆ x and then transforming back into the original variables . ✐ 5 . 10 Verify the modiﬁed conjugacy condition ( 5 . 40 ) . ✐ 5 . 11 Show that when applied to a quadratic function , with exact line searches , both the Polak – Ribi ` ere formula given by ( 5 . 44 ) and the Hestenes – Stiefel formula given by ( 5 . 46 ) reduce to the Fletcher – Reeves formula ( 5 . 41a ) . ✐ 5 . 12 Prove that Lemma 5 . 6 holds for any choice of β k satisfying | β k | ≤ β FR k . This is page 135 Printer : Opaque this C H A P T E R 6 Quasi - Newton Methods In the mid 1950s , W . C . Davidon , a physicist working at Argonne National Laboratory , was using the coordinate descent method ( see Section 9 . 3 ) to perform a long optimization calculation . At that time computers were not very stable , and to Davidon’s frustration , the computer system would always crash before the calculation was ﬁnished . So Davidon decided to ﬁnd a way of accelerating the iteration . The algorithm he developed—the ﬁrst quasi - Newton algorithm—turned out to be one of the most creative ideas in nonlinear optimization . It was soon demonstrated by Fletcher and Powell that the new algorithm was much faster and more reliable than the other existing methods , and this dramatic 136 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S advance transformed nonlinear optimization overnight . During the following twenty years , numerous variants were proposed and hundreds of papers were devoted to their study . An interesting historical irony is that Davidon’s paper [ 87 ] was not accepted for publication ; it remained as a technical report for more than thirty years until it appeared in the ﬁrst issue of the SIAM Journal on Optimization in 1991 [ 88 ] . Quasi - Newton methods , like steepest descent , require only the gradient of the ob - jective function to be supplied at each iterate . By measuring the changes in gradients , they construct a model of the objective function that is good enough to produce superlinear convergence . The improvement over steepest descent is dramatic , especially on difﬁcult problems . Moreover , since second derivatives are not required , quasi - Newton methods are sometimes more efﬁcient than Newton’s method . Today , optimization software libraries contain a variety of quasi - Newton algorithms for solving unconstrained , constrained , and large - scale optimization problems . In this chapter we discuss quasi - Newton methods for small and medium - sized problems , and in Chapter 7 we consider their extension to the large - scale setting . The development of automatic differentiation techniques has made it possible to use Newton’s method without requiring users to supply second derivatives ; see Chapter 8 . Still , automatic differentiation tools may not be applicable in many situations , and it may be much more costly to work with second derivatives in automatic differentia - tion software than with the gradient . For these reasons , quasi - Newton methods remain appealing . 6 . 1 THE BFGS METHOD The most popular quasi - Newton algorithm is the BFGS method , named for its discoverers Broyden , Fletcher , Goldfarb , and Shanno . In this section we derive this algorithm ( and its close relative , the DFP algorithm ) and describe its theoretical properties and practical implementation . We begin the derivation by forming the following quadratic model of the objective function at the current iterate x k : m k ( p ) (cid:3) f k + ∇ f Tk p + 1 2 p T B k p . ( 6 . 1 ) Here B k is an n × n symmetric positive deﬁnite matrix that will be revised or updated at every iteration . Note that the function value and gradient of this model at p (cid:3) 0 match f k and ∇ f k , respectively . The minimizer p k of this convex quadratic model , which we can write explicitly as p k (cid:3) − B − 1 k ∇ f k , ( 6 . 2 ) 6 . 1 . T H E B F G S M E T H O D 137 is used as the search direction , and the new iterate is x k + 1 (cid:3) x k + α k p k , ( 6 . 3 ) where the step length α k is chosen to satisfy the Wolfe conditions ( 3 . 6 ) . This iteration is quite similar to the line search Newton method ; the key difference is that the approximate Hessian B k is used in place of the true Hessian . Instead of computing B k afresh at every iteration , Davidon proposed to update it in a simple manner to account for the curvature measured during the most recent step . Suppose that we have generated a new iterate x k + 1 and wish to construct a new quadratic model , of the form m k + 1 ( p ) (cid:3) f k + 1 + ∇ f Tk + 1 p + 12 p T B k + 1 p . What requirements should we impose on B k + 1 , based on the knowledge gained during the latest step ? One reasonable requirement is that the gradient of m k + 1 should match the gradient of the objective function f at the latest two iterates x k and x k + 1 . Since ∇ m k + 1 ( 0 ) is precisely ∇ f k + 1 , the second of these conditions is satisﬁed automatically . The ﬁrst condition can be written mathematically as ∇ m k + 1 ( − α k p k ) (cid:3) ∇ f k + 1 − α k B k + 1 p k (cid:3) ∇ f k . By rearranging , we obtain B k + 1 α k p k (cid:3) ∇ f k + 1 − ∇ f k . ( 6 . 4 ) To simplify the notation it is useful to deﬁne the vectors s k (cid:3) x k + 1 − x k (cid:3) α k p k , y k (cid:3) ∇ f k + 1 − ∇ f k , ( 6 . 5 ) so that ( 6 . 4 ) becomes B k + 1 s k (cid:3) y k . ( 6 . 6 ) We refer to this formula as the secant equation . Given the displacement s k and the change of gradients y k , the secant equation requires that the symmetric positive deﬁnite matrix B k + 1 map s k into y k . This will be possible only if s k and y k satisfy the curvature condition s Tk y k > 0 , ( 6 . 7 ) as is easily seen by premultiplying ( 6 . 6 ) by s T k . When f is strongly convex , the inequality ( 6 . 7 ) will be satisﬁed for any two points x k and x k + 1 ( see Exercise 6 . 1 ) . However , this condition 138 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S will not always hold for nonconvex functions , and in this case we need to enforce ( 6 . 7 ) explicitly , by imposing restrictions on the line search procedure that chooses the step length α . In fact , the condition ( 6 . 7 ) is guaranteed to hold if we impose the Wolfe ( 3 . 6 ) or strong Wolfe conditions ( 3 . 7 ) on the line search . To verify this claim , we note from ( 6 . 5 ) and ( 3 . 6b ) that ∇ f Tk + 1 s k ≥ c 2 ∇ f Tk s k , and therefore y T k s k ≥ ( c 2 − 1 ) α k ∇ f T k p k . ( 6 . 8 ) Since c 2 < 1 and since p k is a descent direction , the term on the right is positive , and the curvature condition ( 6 . 7 ) holds . When the curvature condition is satisﬁed , the secant equation ( 6 . 6 ) always has a solution B k + 1 . In fact , it admits an inﬁnite number of solutions , since the n ( n + 1 ) / 2 degrees of freedom in a symmetric positive deﬁnite matrix exceed the n conditions imposed by the secant equation . The requirement of positive deﬁniteness imposes n additional inequalities—all principal minors must be positive—but these conditions do not absorb the remaining degrees of freedom . To determine B k + 1 uniquely , we impose the additional condition that among all symmetric matrices satisfying the secant equation , B k + 1 is , in some sense , closest to the current matrix B k . In other words , we solve the problem min B (cid:8) B − B k (cid:8) ( 6 . 9a ) subject to B (cid:3) B T , Bs k (cid:3) y k , ( 6 . 9b ) where s k and y k satisfy ( 6 . 7 ) and B k is symmetric and positive deﬁnite . Different matrix norms can be used in ( 6 . 9a ) , and each norm gives rise to a different quasi - Newton method . A norm that allows easy solution of the minimization problem ( 6 . 9 ) and gives rise to a scale - invariant optimization method is the weighted Frobenius norm (cid:8) A (cid:8) W ≡ (cid:23)(cid:23) W 1 / 2 AW 1 / 2 (cid:23)(cid:23) F , ( 6 . 10 ) where (cid:8) · (cid:8) F is deﬁned by (cid:8) C (cid:8) 2 F (cid:3) (cid:4) ni (cid:3) 1 (cid:4) nj (cid:3) 1 c 2 ij . The weight matrix W can be chosen as any matrix satisfying the relation W y k (cid:3) s k . For concreteness , the reader can assume that W (cid:3) ¯ G − 1 k where ¯ G k is the average Hessian deﬁned by ¯ G k (cid:3) (cid:26)(cid:6) 1 0 ∇ 2 f ( x k + τα k p k ) d τ (cid:27) . ( 6 . 11 ) The property y k (cid:3) ¯ G k α k p k (cid:3) ¯ G k s k ( 6 . 12 ) follows from Taylor’s theorem , Theorem 2 . 1 . With this choice of weighting matrix W , the 6 . 1 . T H E B F G S M E T H O D 139 norm ( 6 . 10 ) is non - dimensional , which is a desirable property , since we do not wish the solution of ( 6 . 9 ) to depend on the units of the problem . With this weighting matrix and this norm , the unique solution of ( 6 . 9 ) is ( DFP ) B k + 1 (cid:3) (cid:7) I − ρ k y k s Tk (cid:8) B k (cid:7) I − ρ k s k y Tk (cid:8) + ρ k y k y Tk , ( 6 . 13 ) with ρ k (cid:3) 1 y Tk s k . ( 6 . 14 ) This formula is called the DFP updating formula , since it is the one originally proposed by Davidon in 1959 , and subsequently studied , implemented , and popularized by Fletcher and Powell . The inverse of B k , which we denote by H k (cid:3) B − 1 k , is useful in the implementation of the method , since it allows the search direction ( 6 . 2 ) to be calculated by means of a simple matrix – vector multiplication . Using the Sherman – Morrison – Woodbury formula ( A . 28 ) , we can derive the following expression for the update of the inverse Hessian approximation H k that corresponds to the DFP update of B k in ( 6 . 13 ) : ( DFP ) H k + 1 (cid:3) H k − H k y k y Tk H k y Tk H k y k + s k s Tk y Tk s k . ( 6 . 15 ) Note that the last two terms in the right - hand - side of ( 6 . 15 ) are rank - one matrices , so that H k undergoesarank - twomodiﬁcation . Itiseasytoseethat ( 6 . 13 ) isalsoarank - twomodiﬁcation of B k . This is the fundamental idea of quasi - Newton updating : Instead of recomputing the approximate Hessians ( or inverse Hessians ) from scratch at every iteration , we apply a simple modiﬁcation that combines the most recently observed information about the objective function with the existing knowledge embedded in our current Hessian approximation . The DFP updating formula is quite effective , but it was soon superseded by the BFGS formula , which is presently considered to be the most effective of all quasi - Newton updating formulae . BFGS updating can be derived by making a simple change in the argument that led to ( 6 . 13 ) . Instead of imposing conditions on the Hessian approximations B k , we impose similar conditions on their inverses H k . The updated approximation H k + 1 must be symmetric and positive deﬁnite , and must satisfy the secant equation ( 6 . 6 ) , now written as H k + 1 y k (cid:3) s k . The condition of closeness to H k is now speciﬁed by the following analogue of ( 6 . 9 ) : min H (cid:8) H − H k (cid:8) ( 6 . 16a ) subject to H (cid:3) H T , Hy k (cid:3) s k . ( 6 . 16b ) 140 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S The norm is again the weighted Frobenius norm described above , where the weight matrix W is now any matrix satisfying Ws k (cid:3) y k . ( For concreteness , we assume again that W is given by the average Hessian ¯ G k deﬁned in ( 6 . 11 ) . ) The unique solution H k + 1 to ( 6 . 16 ) is given by ( BFGS ) H k + 1 (cid:3) ( I − ρ k s k y Tk ) H k ( I − ρ k y k s Tk ) + ρ k s k s Tk , ( 6 . 17 ) with ρ k deﬁned by ( 6 . 14 ) . Just one issue has to be resolved before we can deﬁne a complete BFGS algorithm : How should we choose the initial approximation H 0 ? Unfortunately , there is no magic formula that works well in all cases . We can use speciﬁc information about the problem , for instance by setting it to the inverse of an approximate Hessian calculated by ﬁnite differences at x 0 . Otherwise , we can simply set it to be the identity matrix , or a multiple of the identity matrix , where the multiple is chosen to reﬂect the scaling of the variables . Algorithm 6 . 1 ( BFGS Method ) . Given starting point x 0 , convergence tolerance (cid:9) > 0 , inverse Hessian approximation H 0 ; k ← 0 ; while (cid:8)∇ f k (cid:8) > (cid:9) ; Compute search direction p k (cid:3) − H k ∇ f k ; ( 6 . 18 ) Set x k + 1 (cid:3) x k + α k p k where α k is computed from a line search procedure to satisfy the Wolfe conditions ( 3 . 6 ) ; Deﬁne s k (cid:3) x k + 1 − x k and y k (cid:3) ∇ f k + 1 − ∇ f k ; Compute H k + 1 by means of ( 6 . 17 ) ; k ← k + 1 ; end ( while ) Each iteration can be performed at a cost of O ( n 2 ) arithmetic operations ( plus the cost of function and gradient evaluations ) ; there are no O ( n 3 ) operations such as linear system solves or matrix – matrix operations . The algorithm is robust , and its rate of convergence is superlinear , whichisfastenoughformostpracticalpurposes . EventhoughNewton’smethod converges more rapidly ( that is , quadratically ) , its cost per iteration usually is higher , because of its need for second derivatives and solution of a linear system . We can derive a version of the BFGS algorithm that works with the Hessian approx - imation B k rather than H k . The update formula for B k is obtained by simply applying the Sherman – Morrison – Woodbury formula ( A . 28 ) to ( 6 . 17 ) to obtain ( BFGS ) B k + 1 (cid:3) B k − B k s k s T k B k s Tk B k s k + y k y T k y Tk s k . ( 6 . 19 ) 6 . 1 . T H E B F G S M E T H O D 141 A naive implementation of this variant is not efﬁcient for unconstrained minimization , because it requires the system B k p k (cid:3) −∇ f k to be solved for the step p k , thereby increasing the cost of the step computation to O ( n 3 ) . We discuss later , however , that less expensive implementations of this variant are possible by updating Cholesky factors of B k . PROPERTIES OF THE BFGS METHOD It is usually easy to observe the superlinear rate of convergence of the BFGS method on practical problems . Below , we report the last few iterations of the steepest descent , BFGS , and an inexact Newton method on Rosenbrock’s function ( 2 . 22 ) . The table gives the value of (cid:8) x k − x ∗ (cid:8) . The Wolfe conditions were imposed on the step length in all three methods . From the starting point ( − 1 . 2 , 1 ) , the steepest descent method required 5264 iterations , whereas BFGS and Newton took only 34 and 21 iterations , respectively to reduce the gradient norm to 10 − 5 . steepest BFGS Newton descent 1 . 827e - 04 1 . 70e - 03 3 . 48e - 02 1 . 826e - 04 1 . 17e - 03 1 . 44e - 02 1 . 824e - 04 1 . 34e - 04 1 . 82e - 04 1 . 823e - 04 1 . 01e - 06 1 . 17e - 08 A few points in the derivation of the BFGS and DFP methods merit further discussion . Note that the minimization problem ( 6 . 16 ) that gives rise to the BFGS update formula does not explicitly require the updated Hessian approximation to be positive deﬁnite . It is easy to show , however , that H k + 1 will be positive deﬁnite whenever H k is positive deﬁnite , by using the following argument . First , note from ( 6 . 8 ) that y Tk s k is positive , so that the updating formula ( 6 . 17 ) , ( 6 . 14 ) is well - deﬁned . For any nonzero vector z , we have z T H k + 1 z (cid:3) w T H k w + ρ k ( z T s k ) 2 ≥ 0 , where we have deﬁned w (cid:3) z − ρ k y k ( s Tk z ) . The right hand side can be zero only if s Tk z (cid:3) 0 , but in this case w (cid:3) z (cid:9)(cid:3) 0 , which implies that the ﬁrst term is greater than zero . Therefore , H k + 1 is positive deﬁnite . To make quasi - Newton updating formulae invariant to transformations in the vari - ables ( such as scaling transformations ) , it is necessary for the objectives ( 6 . 9a ) and ( 6 . 16a ) to be invariant under the same transformations . The choice of the weighting matrices W used to deﬁne the norms in ( 6 . 9a ) and ( 6 . 16a ) ensures that this condition holds . Many other choices of the weighting matrix W are possible , each one of them giving a different update formula . However , despite intensive searches , no formula has been found that is signiﬁcantly more effective than BFGS . 142 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S The BFGS method has many interesting properties when applied to quadratic func - tions . We discuss these properties later in the more general context of the Broyden family of updating formulae , of which BFGS is a special case . It is reasonable to ask whether there are situations in which the updating formula such as ( 6 . 17 ) can produce bad results . If at some iteration the matrix H k becomes a poor approx - imation to the true inverse Hessian , is there any hope of correcting it ? For example , when the inner product y Tk s k is tiny ( but positive ) , then it follows from ( 6 . 14 ) , ( 6 . 17 ) that H k + 1 contains very large elements . Is this behavior reasonable ? A related question concerns the rounding errors that occur in ﬁnite - precision implementation of these methods . Can these errors grow to the point of erasing all useful information in the quasi - Newton approximate Hessian ? These questions have been studied analytically and experimentally , and it is now known that the BFGS formula has very effective self - correcting properties . If the matrix H k incorrectly estimates the curvature in the objective function , and if this bad estimate slows down the iteration , then the Hessian approximation will tend to correct itself within a few steps . It is also known that the DFP method is less effective in correcting bad Hessian approx - imations ; this property is believed to be the reason for its poorer practical performance . The self - correcting properties of BFGS hold only when an adequate line search is performed . In particular , the Wolfe line search conditions ensure that the gradients are sampled at points that allow the model ( 6 . 1 ) to capture appropriate curvature information . It is interesting to note that the DFP and BFGS updating formulae are duals of each other , in the sense that one can be obtained from the other by the interchanges s ↔ y , B ↔ H . This symmetry is not surprising , given the manner in which we derived these methods above . IMPLEMENTATION A few details and enhancements need to be added to Algorithm 6 . 1 to produce an efﬁcient implementation . The line search , which should satisfy either the Wolfe conditions ( 3 . 6 ) or the strong Wolfe conditions ( 3 . 7 ) , should always try the step length α k (cid:3) 1 ﬁrst , becausethissteplengthwilleventuallyalwaysbeaccepted ( undercertainconditions ) , thereby producing superlinear convergence of the overall algorithm . Computational observations strongly suggest that it is more economical , in terms of function evaluations , to perform a fairly inaccurate line search . The values c 1 (cid:3) 10 − 4 and c 2 (cid:3) 0 . 9 are commonly used in ( 3 . 6 ) . As mentioned earlier , the initial matrix H 0 often is set to some multiple β I of the identity , but there is no good general strategy for choosing the multiple β . If β is too large , so that the ﬁrst step p 0 (cid:3) − β g 0 is too long , many function evaluations may be required to ﬁnd a suitable value for the step length α 0 . Some software asks the user to prescribe a value δ for the norm of the ﬁrst step , and then set H 0 (cid:3) δ (cid:8) g 0 (cid:8) − 1 I to achieve this norm . A heuristic that is often quite effective is to scale the starting matrix after the ﬁrst step has been computed but before the ﬁrst BFGS update is performed . We change the 6 . 1 . T H E B F G S M E T H O D 143 provisional value H 0 (cid:3) I by setting H 0 ← y Tk s k y Tk y k I , ( 6 . 20 ) before applying the update ( 6 . 14 ) , ( 6 . 17 ) to obtain H 1 . This formula attempts to make the size of H 0 similar to that of ∇ 2 f ( x 0 ) − 1 , in the following sense . Assuming that the average Hessian deﬁned in ( 6 . 11 ) is positive deﬁnite , there exists a square root ¯ G 1 / 2 k satisfying ¯ G k (cid:3) ¯ G 1 / 2 k ¯ G 1 / 2 k ( see Exercise 6 . 6 ) . Therefore , by deﬁning z k (cid:3) ¯ G 1 / 2 k s k and using the relation ( 6 . 12 ) , we have y Tk s k y Tk y k (cid:3) ( ¯ G 1 / 2 k s k ) T ¯ G 1 / 2 k s k ( ¯ G 1 / 2 k s k ) T ¯ G k ¯ G 1 / 2 k s k (cid:3) z Tk z k z Tk ¯ G k z k . ( 6 . 21 ) The reciprocal of ( 6 . 21 ) is an approximation to one of the eigenvalues of ¯ G k , which in turn is close to an eigenvalue of ∇ 2 f ( x k ) . Hence , the quotient ( 6 . 21 ) itself approximates an eigenvalue of ∇ 2 f ( x k ) − 1 . Other scaling factors can be used in ( 6 . 20 ) , but the one presented here appears to be the most successful in practice . In ( 6 . 19 ) we gave an update formula for a BFGS method that works with the Hes - sian approximation B k instead of the the inverse Hessian approximation H k . An efﬁcient implementation of this approach does not store B k explicitly , but rather the Cholesky fac - torization L k D k L Tk of this matrix . A formula that updates the factors L k and D k directly in O ( n 2 ) operations can be derived from ( 6 . 19 ) . Since the linear system B k p k (cid:3) −∇ f k also can be solved in O ( n 2 ) operations ( by performing triangular substitutions with L k and L Tk and a diagonal substitution with D k ) , the total cost is quite similar to the variant described in Algorithm 6 . 1 . A potential advantage of this alternative strategy is that it gives us the option of modifying diagonal elements in the D k factor if they are not sufﬁciently large , to prevent instability when we divide by these elements during the calculation of p k . However , computational experience suggests no real advantages for this variant , and we prefer the simpler strategy of Algorithm 6 . 1 . The performance of the BFGS method can degrade if the line search is not based on the Wolfe conditions . For example , some software implements an Armijo backtracking line search ( see Section 3 . 1 ) : The unit step length α k (cid:3) 1 is tried ﬁrst and is successively decreased until the sufﬁcient decrease condition ( 3 . 6a ) is satisﬁed . For this strategy , there is no guarantee that the curvature condition y Tk s k > 0 ( 6 . 7 ) will be satisﬁed by the chosen step , since a step length greater than 1 may be required to satisfy this condition . To cope with this shortcoming , some implementations simply skip the BFGS update by setting H k + 1 (cid:3) H k when y Tk s k is negative or too close to zero . This approach is not recommended , because the updates may be skipped much too often to allow H k to capture important curvature information for the objective function f . In Chapter 18 we discuss a damped BFGS update that is a more effective strategy for coping with the case where the curvature condition ( 6 . 7 ) is not satisﬁed . 144 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S 6 . 2 THE SR1 METHOD In the BFGS and DFP updating formulae , the updated matrix B k + 1 ( or H k + 1 ) differs from its predecessor B k ( or H k ) by a rank - 2 matrix . In fact , as we now show , there is a simpler rank - 1 update that maintains symmetry of the matrix and allows it to satisfy the secant equation . Unlike the rank - two update formulae , this symmetric - rank - 1 , or SR1 , update does not guarantee that the updated matrix maintains positive deﬁniteness . Good numerical results have been obtained with algorithms based on SR1 , so we derive it here and investigate its properties . The symmetric rank - 1 update has the general form B k + 1 (cid:3) B k + σvv T , where σ is either + 1 or − 1 , and σ and v are chosen so that B k + 1 satisﬁes the secant equation ( 6 . 6 ) , that is , y k (cid:3) B k + 1 s k . By substituting into this equation , we obtain y k (cid:3) B k s k + (cid:9) σv T s k (cid:10) v . ( 6 . 22 ) Since the term in brackets is a scalar , we deduce that v must be a multiple of y k − B k s k , that is , v (cid:3) δ ( y k − B k s k ) for some scalar δ . By substituting this form of v into ( 6 . 22 ) , we obtain ( y k − B k s k ) (cid:3) σδ 2 (cid:9) s Tk ( y k − B k s k ) (cid:10) ( y k − B k s k ) , ( 6 . 23 ) and it is clear that this equation is satisﬁed if ( and only if ) we choose the parameters δ and σ to be σ (cid:3) sign (cid:9) s Tk ( y k − B k s k ) (cid:10) , δ (cid:3) ± (cid:28)(cid:28) s Tk ( y k − B k s k ) (cid:28)(cid:28) − 1 / 2 . Hence , we have shown that the only symmetric rank - 1 updating formula that satisﬁes the secant equation is given by ( SR1 ) B k + 1 (cid:3) B k + ( y k − B k s k ) ( y k − B k s k ) T ( y k − B k s k ) T s k . ( 6 . 24 ) By applying the Sherman – Morrison formula ( A . 27 ) , we obtain the corresponding update formula for the inverse Hessian approximation H k : ( SR1 ) H k + 1 (cid:3) H k + ( s k − H k y k ) ( s k − H k y k ) T ( s k − H k y k ) T y k . ( 6 . 25 ) This derivation is so simple that the SR1 formula has been rediscovered a number of times . It is easy to see that even if B k is positive deﬁnite , B k + 1 may not have the same property . ( The same is , of course , true of H k . ) This observation was considered a major drawback 6 . 2 . T H E S R 1 M E T H O D 145 in the early days of nonlinear optimization when only line search iterations were used . However , with the advent of trust - region methods , the SR1 updating formula has proved to be quite useful , and its ability to generate indeﬁnite Hessian approximations can actually be regarded as one of its chief advantages . The main drawback of SR1 updating is that the denominator in ( 6 . 24 ) or ( 6 . 25 ) can vanish . In fact , even when the objective function is a convex quadratic , there may be steps on which there is no symmetric rank - 1 update that satisﬁes the secant equation . It pays to reexamine the derivation above in the light of this observation . By reasoning in terms of B k ( similar arguments can be applied to H k ) , we see that there are three cases : 1 . If ( y k − B k s k ) T s k (cid:9)(cid:3) 0 , then the arguments above show that there is a unique rank - one updating formula satisfying the secant equation ( 6 . 6 ) , and that it is given by ( 6 . 24 ) . 2 . If y k (cid:3) B k s k , then the only updating formula satisfying the secant equation is simply B k + 1 (cid:3) B k . 3 . If y k (cid:9)(cid:3) B k s k and ( y k − B k s k ) T s k (cid:3) 0 , then ( 6 . 23 ) shows that there is no symmetric rank - one updating formula satisfying the secant equation . The last case clouds an otherwise simple and elegant derivation , and suggests that numerical instabilitiesandevenbreakdownofthemethodcanoccur . Itsuggeststhatrank - oneupdating does not provide enough freedom to develop a matrix with all the desired characteristics , and that a rank - two correction is required . This reasoning leads us back to the BFGS method , in which positive deﬁniteness ( and thus nonsingularity ) of all Hessian approximations is guaranteed . Nevertheless , we are interested in the SR1 formula for the following reasons . ( i ) A simple safeguard seems to adequately prevent the breakdown of the method and the occurrence of numerical instabilities . ( ii ) The matrices generated by the SR1 formula tend to be good approximations to the true Hessian matrix—often better than the BFGS approximations . ( iii ) In quasi - Newton methods for constrained problems , or in methods for partially separable functions ( see Chapters 18 and 7 ) , it may not be possible to impose the curvature condition y Tk s k > 0 , and thus BFGS updating is not recommended . Indeed , in these two settings , indeﬁnite Hessian approximations are desirable insofar as they reﬂect indeﬁniteness in the true Hessian . We now introduce a strategy to prevent the SR1 method from breaking down . It has been observed in practice that SR1 performs well simply by skipping the update if the denominator is small . More speciﬁcally , the update ( 6 . 24 ) is applied only if (cid:28) (cid:28) s Tk ( y k − B k s k ) (cid:28) (cid:28) ≥ r (cid:8) s k (cid:8) (cid:8) y k − B k s k (cid:8) , ( 6 . 26 ) 146 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S where r ∈ ( 0 , 1 ) is a small number , say r (cid:3) 10 − 8 . If ( 6 . 26 ) does not hold , we set B k + 1 (cid:3) B k . Most implementations of the SR1 method use a skipping rule of this kind . Why do we advocate skipping of updates for the SR1 method , when in the previous section we discouraged this strategy in the case of BFGS ? The two cases are quite different . The condition s Tk ( y k − B k s k ) ≈ 0 occurs infrequently , since it requires certain vectors to be aligned in a speciﬁc way . When it does occur , skipping the update appears to have no negative effects on the iteration . This is not surprising , since the skipping condition im - plies that s Tk ¯ Gs k ≈ s Tk B k s k , where ¯ G is the average Hessian over the last step—meaning that the curvature of B k along s k is already correct . In contrast , the curvature condition s Tk y k ≥ 0 required for BFGS updating may easily fail if the line search does not im - pose the Wolfe conditions ( for example , if the step is not long enough ) , and therefore skipping the BFGS update can occur often and can degrade the quality of the Hessian approximation . We now give a formal description of an SR1 method using a trust - region framework , which we prefer over a line search framework because it can accommodate indeﬁnite Hessian approximations more easily . Algorithm 6 . 2 ( SR1 Trust - Region Method ) . Given starting point x 0 , initial Hessian approximation B 0 , trust - region radius (cid:6) 0 , convergence tolerance (cid:9) > 0 , parameters η ∈ ( 0 , 10 − 3 ) and r ∈ ( 0 , 1 ) ; k ← 0 ; while (cid:8)∇ f k (cid:8) > (cid:9) ; Compute s k by solving the subproblem min s ∇ f Tk s + 1 2 s T B k s subject to (cid:8) s (cid:8) ≤ (cid:6) k ; ( 6 . 27 ) Compute y k (cid:3) ∇ f ( x k + s k ) − ∇ f k , ared (cid:3) f k − f ( x k + s k ) ( actual reduction ) pred (cid:3) − (cid:17) ∇ f Tk s k + 1 2 s Tk B k s k (cid:18) ( predicted reduction ) ; if ared / pred > η x k + 1 (cid:3) x k + s k ; else x k + 1 (cid:3) x k ; end ( if ) 6 . 2 . T H E S R 1 M E T H O D 147 if ared / pred > 0 . 75 if (cid:8) s k (cid:8) ≤ 0 . 8 (cid:6) k (cid:6) k + 1 (cid:3) (cid:6) k ; else (cid:6) k + 1 (cid:3) 2 (cid:6) k ; end ( if ) else if 0 . 1 ≤ ared / pred ≤ 0 . 75 (cid:6) k + 1 (cid:3) (cid:6) k ; else (cid:6) k + 1 (cid:3) 0 . 5 (cid:6) k ; end ( if ) if ( 6 . 26 ) holds Use ( 6 . 24 ) to compute B k + 1 ( even if x k + 1 (cid:3) x k ) ; else B k + 1 ← B k ; end ( if ) k ← k + 1 ; end ( while ) This algorithm has the typical form of a trust region method ( cf . Algorithm 4 . 1 ) . For concreteness , we have speciﬁed a particular strategy for updating the trust region radius , but other heuristics can be used instead . To obtain a fast rate of convergence , it is important for the matrix B k to be updated even along a failed direction s k . The fact that the step was poor indicates that B k is an inadequate approximation of the true Hessian in this direction . Unless the quality of the approximation is improved , steps along similar directions could be generated on later iterations , and repeated rejection of such steps could prevent superlinear convergence . PROPERTIES OF SR1 UPDATING One of the main advantages of SR1 updating is its ability to generate good Hessian approximations . We demonstrate this property by ﬁrst examining a quadratic function . For functions of this type , the choice of step length does not affect the update , so to examine the effect of the updates , we can assume for simplicity a uniform step length of 1 , that is , p k (cid:3) − H k ∇ f k , x k + 1 (cid:3) x k + p k . ( 6 . 28 ) It follows that p k (cid:3) s k . Theorem 6 . 1 . Suppose that f : IR n → IR is the strongly convex quadratic function f ( x ) (cid:3) b T x + 12 x T Ax , where A is symmetric positive deﬁnite . Then for any starting point x 0 and any 148 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S symmetric starting matrix H 0 , the iterates { x k } generated by the SR1 method ( 6 . 25 ) , ( 6 . 28 ) converge to the minimizer in at most n steps , provided that ( s k − H k y k ) T y k (cid:9)(cid:3) 0 for all k . Moreover , if n steps are performed , and if the search directions p i are linearly independent , then H n (cid:3) A − 1 . P ROOF . Because of our assumption ( s k − H k y k ) T y k (cid:9)(cid:3) 0 , the SR1 update is always well - deﬁned . We start by showing inductively that H k y j (cid:3) s j , j (cid:3) 0 , 1 , . . . , k − 1 . ( 6 . 29 ) In other words , we claim that the secant equation is satisﬁed not only along the most recent search direction , but along all previous directions . By deﬁnition , the SR1 update satisﬁes the secant equation , so we have H 1 y 0 (cid:3) s 0 . Let us now assume that ( 6 . 29 ) holds for some value k > 1 and show that it holds also for k + 1 . From this assumption , we have from ( 6 . 29 ) that ( s k − H k y k ) T y j (cid:3) s Tk y j − y Tk ( H k y j ) (cid:3) s Tk y j − y Tk s j (cid:3) 0 , all j < k , ( 6 . 30 ) wherethelastequalityfollowsbecause y i (cid:3) As i forthequadraticfunctionweareconsidering here . By using ( 6 . 30 ) and the induction hypothesis ( 6 . 29 ) in ( 6 . 25 ) , we have H k + 1 y j (cid:3) H k y j (cid:3) s j , for all j < k . Since H k + 1 y k (cid:3) s k by the secant equation , we have shown that ( 6 . 29 ) holds when k is replaced by k + 1 . By induction , then , this relation holds for all k . If the algorithm performs n steps and if these steps { s j } are linearly independent , we have s j (cid:3) H n y j (cid:3) H n As j , j (cid:3) 0 , 1 , . . . , n − 1 . It follows that H n A (cid:3) I , that is , H n (cid:3) A − 1 . Therefore , the step taken at x n is the Newton step , and so the next iterate x n + 1 will be the solution , and the algorithm terminates . Consider now the case in which the steps become linearly dependent . Suppose that s k is a linear combination of the previous steps , that is , s k (cid:3) ξ 0 s 0 + · · · + ξ k − 1 s k − 1 , ( 6 . 31 ) for some scalars ξ i . From ( 6 . 31 ) and ( 6 . 29 ) we have that H k y k (cid:3) H k As k (cid:3) ξ 0 H k As 0 + · · · + ξ k − 1 H k As k − 1 6 . 3 . T H E B R O Y D E N C L A S S 149 (cid:3) ξ 0 H k y 0 + · · · + ξ k − 1 H k y k − 1 (cid:3) ξ 0 s 0 + · · · + ξ k − 1 s k − 1 (cid:3) s k . Since y k (cid:3) ∇ f k + 1 − ∇ f k and since s k (cid:3) p k (cid:3) − H k ∇ f k from ( 6 . 28 ) , we have that H k ( ∇ f k + 1 − ∇ f k ) (cid:3) − H k ∇ f k , which , by the nonsingularity of H k , implies that ∇ f k + 1 (cid:3) 0 . Therefore , x k + 1 is the solution point . (cid:1) The relation ( 6 . 29 ) shows that when f is quadratic , the secant equation is satisﬁed along all previous search directions , regardless of how the line search is performed . A result like this can be established for BFGS updating only under the restrictive assumption that the line search is exact , as we show in the next section . For general nonlinear functions , the SR1 update continues to generate good Hessian approximations under certain conditions . Theorem 6 . 2 . Suppose that f is twice continuously differentiable , and that its Hessian is bounded and Lipschitz continuous in a neighborhood of a point x ∗ . Let { x k } be any sequence of iterates such that x k → x ∗ for some x ∗ ∈ IR n . Suppose in addition that the inequality ( 6 . 26 ) holds for all k , for some r ∈ ( 0 , 1 ) , and that the steps s k are uniformly linearly independent . Then the matrices B k generated by the SR1 updating formula satisfy lim k →∞ (cid:8) B k − ∇ 2 f ( x ∗ ) (cid:8) (cid:3) 0 . The term “uniformly linearly independent steps” means , roughly speaking , that the steps do not tend to fall in a subspace of dimension less than n . This assumption is usually , but not always , satisﬁed in practice ( see the Notes and References at the end of this chapter ) . 6 . 3 THE BROYDEN CLASS So far , we have described the BFGS , DFP , and SR1 quasi - Newton updating formulae , but there are many others . Of particular interest is the Broyden class , a family of updates speciﬁed by the following general formula : B k + 1 (cid:3) B k − B k s k s T k B k s Tk B k s k + y k y T k y Tk s k + φ k ( s T k B k s k ) v k v T k , ( 6 . 32 ) 150 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S where φ k is a scalar parameter and v k (cid:3) (cid:26) y k y Tk s k − B k s k s Tk B k s k (cid:27) . ( 6 . 33 ) The BFGS and DFP methods are members of the Broyden class—we recover BFGS by setting φ k (cid:3) 0 and DFP by setting φ k (cid:3) 1 in ( 6 . 32 ) . We can therefore rewrite ( 6 . 32 ) as a “linear combination” of these two methods , that is , B k + 1 (cid:3) ( 1 − φ k ) B BFGS k + 1 + φ k B DFP k + 1 . This relationship indicates that all members of the Broyden class satisfy the secant equation ( 6 . 6 ) , sincetheBGFSandDFPmatricesthemselvessatisfythisequation . Also , sinceBFGSand DFP updating preserve positive deﬁniteness of the Hessian approximations when s Tk y k > 0 , this relation implies that the same property will hold for the Broyden family if 0 ≤ φ k ≤ 1 . Much attention has been given to the so - called restricted Broyden class , which is obtained by restricting φ k to the interval [ 0 , 1 ] . It enjoys the following property when applied to quadratic functions . Since the analysis is independent of the step length , we assume for simplicity that each iteration has the form p k (cid:3) − B − 1 k ∇ f k , x k + 1 (cid:3) x k + p k . ( 6 . 34 ) Theorem 6 . 3 . Suppose that f : IR n → IR is the strongly convex quadratic function f ( x ) (cid:3) b T x + 12 x T Ax , where A is symmetric and positive deﬁnite . Let x 0 be any starting point for the iteration ( 6 . 34 ) and B 0 be any symmetric positive deﬁnite starting matrix , and suppose that the matrices B k are updated by the Broyden formula ( 6 . 32 ) with φ k ∈ [ 0 , 1 ] . Deﬁne λ k 1 ≤ λ k 2 ≤ · · · ≤ λ kn to be the eigenvalues of the matrix A 12 B − 1 k A 12 . ( 6 . 35 ) Then for all k , we have min { λ ki , 1 } ≤ λ k + 1 i ≤ max { λ ki , 1 } , i (cid:3) 1 , 2 , . . . , n . ( 6 . 36 ) Moreover , the property ( 6 . 36 ) does not hold if the Broyden parameter φ k is chosen outside the interval [ 0 , 1 ] . Let us discuss the signiﬁcance of this result . If the eigenvalues λ ki of the matrix ( 6 . 35 ) are all 1 , then the quasi - Newton approximation B k is identical to the Hessian A of the quadratic objective function . This situation is the ideal one , so we should be hoping for these eigenvalues to be as close to 1 as possible . In fact , relation ( 6 . 36 ) tells us that the 6 . 3 . T H E B R O Y D E N C L A S S 151 eigenvalues { λ ki } converge monotonically ( but not strictly monotonically ) to 1 . Suppose , for example , that at iteration k the smallest eigenvalue is λ k 1 (cid:3) 0 . 7 . Then ( 6 . 36 ) tells us that at the next iteration λ k + 1 1 ∈ [ 0 . 7 , 1 ] . We cannot be sure that this eigenvalue has actually moved closer to 1 , but it is reasonable to expect that it has . In contrast , the ﬁrst eigenvalue can become smaller than 0 . 7 if we allow φ k to be outside [ 0 , 1 ] . Signiﬁcantly , the result of Theorem 6 . 3 holds even if the line searches are not exact . Although Theorem 6 . 3 seems to suggest that the best update formulas belong to the restricted Broyden class , the situation is not at all clear . Some analysis and computational testing suggest that algorithms that allow φ k to be negative ( in a strictly controlled manner ) may in fact be superior to the BFGS method . The SR1 formula is a case in point : It is a member of the Broyden class , obtained by setting φ k (cid:3) s Tk y k s Tk y k − s Tk B k s k , but it does not belong to the restricted Broyden class , because this value of φ k may fall outside the interval [ 0 , 1 ] . In the remaining discussion of this section , we determine more precisely the range of values of φ k that preserve positive deﬁniteness . The last term in ( 6 . 32 ) is a rank - one correction , which by the interlacing eigenvalue theorem ( TheoremA . 1 ) increasestheeigenvaluesofthematrixwhen φ k ispositive . Therefore B k + 1 is positive deﬁnite for all φ k ≥ 0 . On the other hand , by Theorem A . 1 the last term in ( 6 . 32 ) decreases the eigenvalues of the matrix when φ k is negative . As we decrease φ k , this matrix eventually becomes singular and then indeﬁnite . A little computation shows that B k + 1 is singular when φ k has the value φ ck (cid:3) 1 1 − µ k , ( 6 . 37 ) where µ k (cid:3) ( y Tk B − 1 k y k ) ( s Tk B k s k ) ( y Tk s k ) 2 . ( 6 . 38 ) By applying the Cauchy – Schwarz inequality ( A . 5 ) to ( 6 . 38 ) , we see that µ k ≥ 1 and therefore φ ck ≤ 0 . Hence , if the initial Hessian approximation B 0 is symmetric and positive deﬁnite , and if s Tk y k > 0 and φ k > φ ck for each k , then all the matrices B k generated by Broyden’s formula ( 6 . 32 ) remain symmetric and positive deﬁnite . When the line search is exact , all methods in the Broyden class with φ k ≥ φ ck generate the same sequence of iterates . This result applies to general nonlinear functions and is based on the observation that when all the line searches are exact , the directions generated by Broyden - class methods differ only in their lengths . The line searches identify the same 152 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S minima along the chosen search direction , though the values of the step lengths may differ because of the different scaling . The Broyden class has several remarkable properties when applied with exact line searches to quadratic functions . We state some of these properties in the next theorem , whose proof is omitted . Theorem 6 . 4 . Suppose that a method in the Broyden class is applied to the strongly convex quadratic function f ( x ) (cid:3) b T x + 12 x T Ax , where x 0 is the starting point and B 0 is any symmetric positive deﬁnite matrix . Assume that α k is the exact step length and that φ k ≥ φ ck for all k , where φ ck is deﬁned by ( 6 . 37 ) . Then the following statements are true . ( i ) The iterates are independent of φ k and converge to the solution in at most n iterations . ( ii ) The secant equation is satisﬁed for all previous search directions , that is , B k s j (cid:3) y j , j (cid:3) k − 1 , k − 2 , . . . , 1 . ( iii ) If the starting matrix is B 0 (cid:3) I , then the iterates are identical to those generated by the conjugate gradient method ( see Chapter 5 ) . In particular , the search directions are conjugate , that is , s Ti As j (cid:3) 0 , for i (cid:9)(cid:3) j . ( iv ) If n iterations are performed , we have B n (cid:3) A . Note that parts ( i ) , ( ii ) , and ( iv ) of this result echo the statement and proof of Theorem 6 . 1 , where similar results were derived for the SR1 update formula . We can generalize Theorem 6 . 4 slightly : It continues to hold if the Hessian approxi - mations remain nonsingular but not necessarily positive deﬁnite . ( Hence , we could allow φ k to be smaller than φ ck , provided that the chosen value did not produce a singular updated matrix . ) We can also generalize point ( iii ) as follows . If the starting matrix B 0 is not the identity matrix , then the Broyden - class method is identical to the preconditioned conjugate gradient method that uses B 0 as preconditioner . We conclude by commenting that results like Theorem 6 . 4 would appear to be of mainly theoretical interest , since the inexact line searches used in practical implementations of Broyden - class methods ( and all other quasi - Newton methods ) cause their performance to differ markedly . Nevertheless , it is worth noting that this type of analysis guided much of the development of quasi - Newton methods . 6 . 4 . C O N V E R G E N C E A N A L Y S I S 153 6 . 4 CONVERGENCE ANALYSIS In this section we present global and local convergence results for practical implementations of the BFGS and SR1 methods . We give more details for BFGS because its analysis is more general and illuminating than that of SR1 . The fact that the Hessian approximations evolve by means of updating formulas makes the analysis of quasi - Newton methods much more complex than that of steepest descent and Newton’s method . Although the BFGS and SR1 methods are known to be remarkably robust in practice , wewillnotbeabletoestablishtrulyglobalconvergenceresultsforgeneralnonlinearobjective functions . Thatis , wecannotprovethattheiteratesofthesequasi - Newtonmethodsapproach a stationary point of the problem from any starting point and any ( suitable ) initial Hessian approximation . In fact , it is not yet known if the algorithms enjoy such properties . In our analysis we will either assume that the objective function is convex or that the iterates satisfy certain properties . On the other hand , there are well known local , superlinear convergence results that are true under reasonable assumptions . Throughout this section we use (cid:8) · (cid:8) to denote the Euclidean vector or matrix norm , and denote the Hessian matrix ∇ 2 f ( x ) by G ( x ) . GLOBAL CONVERGENCE OF THE BFGS METHOD We study the global convergence of the BFGS method , with a practical line search , when applied to a smooth convex function from an arbitrary starting point x 0 and from any initial Hessian approximation B 0 that is symmetric and positive deﬁnite . We state our precise assumptions about the objective function formally , as follows . Assumption 6 . 1 . ( i ) The objective function f is twice continuously differentiable . ( ii ) The level set L (cid:3) { x ∈ IR n | f ( x ) ≤ f ( x 0 ) } is convex , and there exist positive constants m and M such that m (cid:8) z (cid:8) 2 ≤ z T G ( x ) z ≤ M (cid:8) z (cid:8) 2 ( 6 . 39 ) for all z ∈ IR n and x ∈ L . Part ( ii ) of this assumption implies that G ( x ) is positive deﬁnite on L and that f has a unique minimizer x ∗ in L . By using ( 6 . 12 ) and ( 6 . 39 ) we obtain y T k s k s Tk s k (cid:3) s T k ¯ G k s k s Tk s k ≥ m , ( 6 . 40 ) 154 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S where ¯ G k is the average Hessian deﬁned in ( 6 . 11 ) . Assumption 6 . 1 implies that ¯ G k is positive deﬁnite , so its square root is well - deﬁned . Therefore , as in ( 6 . 21 ) , we have by deﬁning z k (cid:3) ¯ G 1 / 2 k s k that y Tk y k y Tk s k (cid:3) s Tk ¯ G 2 k s k s Tk ¯ G k s k (cid:3) z Tk ¯ G k z k z Tk z k ≤ M . ( 6 . 41 ) We are now ready to present the global convergence result for the BFGS method . It does not seem to be possible to establish a bound on the condition number of the Hessian approximations B k , as is done in Section 3 . 2 . Instead , we will introduce two new tools in the analysis , the trace and determinant , to estimate the size of the largest and smallest eigenvalues of the Hessian approximations . The trace of a matrix ( denoted by trace ( · ) ) is the sum of its eigenvalues , while the determinant ( denoted by det ( · ) ) is the product of the eigenvalues ; see the Appendix for a brief discussion of their properties . Theorem 6 . 5 . Let B 0 be any symmetric positive deﬁnite initial matrix , and let x 0 be a starting point for which Assumption 6 . 1 is satisﬁed . Then the sequence { x k } generated by Algorithm 6 . 1 ( with (cid:9) (cid:3) 0 ) converges to the minimizer x ∗ of f . P ROOF . We start by deﬁning m k (cid:3) y Tk s k s Tk s k , M k (cid:3) y Tk y k y Tk s k , ( 6 . 42 ) and note from ( 6 . 40 ) and ( 6 . 41 ) that m k ≥ m , M k ≤ M . ( 6 . 43 ) By computing the trace of the BFGS update ( 6 . 19 ) , we obtain that trace ( B k + 1 ) (cid:3) trace ( B k ) − (cid:8) B k s k (cid:8) 2 s Tk B k s k + (cid:8) y k (cid:8) 2 y Tk s k ( 6 . 44 ) ( see Exercise 6 . 11 ) . We can also show ( Exercise 6 . 10 ) that det ( B k + 1 ) (cid:3) det ( B k ) y T k s k s Tk B k s k . ( 6 . 45 ) We now deﬁne cos θ k (cid:3) s T k B k s k (cid:8) s k (cid:8)(cid:8) B k s k (cid:8) , q k (cid:3) s T k B k s k s Tk s k , ( 6 . 46 ) 6 . 4 . C O N V E R G E N C E A N A L Y S I S 155 so that θ k is the angle between s k and B k s k . We then obtain that (cid:8) B k s k (cid:8) 2 s Tk B k s k (cid:3) (cid:8) B k s k (cid:8) 2 (cid:8) s k (cid:8) 2 ( s Tk B k s k ) 2 s Tk B k s k (cid:8) s k (cid:8) 2 (cid:3) q k cos 2 θ k . ( 6 . 47 ) In addition , we have from ( 6 . 42 ) that det ( B k + 1 ) (cid:3) det ( B k ) y Tk s k s Tk s k s Tk s k s Tk B k s k (cid:3) det ( B k ) m k q k . ( 6 . 48 ) We now combine the trace and determinant by introducing the following function of a positive deﬁnite matrix B : ψ ( B ) (cid:3) trace ( B ) − ln ( det ( B ) ) , ( 6 . 49 ) where ln ( · ) denotes the natural logarithm . It is not difﬁcult to show that ψ ( B ) > 0 ; see Exercise 6 . 9 . By using ( 6 . 42 ) and ( 6 . 44 ) – ( 6 . 49 ) , we have that ψ ( B k + 1 ) (cid:3) trace ( B k ) + M k − q k cos 2 θ k − ln ( det ( B k ) ) − ln m k + ln q k (cid:3) ψ ( B k ) + ( M k − ln m k − 1 ) + (cid:26) 1 − q k cos 2 θ k + ln q k cos 2 θ k (cid:27) + ln cos 2 θ k . ( 6 . 50 ) Now , since the function h ( t ) (cid:3) 1 − t + ln t is nonpositive for all t > 0 ( see Exercise 6 . 8 ) , the term inside the square brackets is nonpositive , and thus from ( 6 . 43 ) and ( 6 . 50 ) we have 0 < ψ ( B k + 1 ) ≤ ψ ( B 0 ) + c ( k + 1 ) + k (cid:3) j (cid:3) 0 ln cos 2 θ j , ( 6 . 51 ) where we can assume the constant c (cid:3) M − ln m − 1 to be positive , without loss of generality . We now relate these expressions to the results given in Section 3 . 2 . Note from the form s k (cid:3) − α k B − 1 k ∇ f k of the quasi - Newton iteration that cos θ k deﬁned by ( 6 . 46 ) is the angle between the steepest descent direction and the search direction , which plays a crucial role in the global convergence theory of Chapter 3 . From ( 3 . 22 ) , ( 3 . 23 ) we know that the sequence (cid:8)∇ f k (cid:8) generated by the line search algorithm is bounded away from zero only if cos θ j → 0 . Let us then proceed by contradiction and assume that cos θ j → 0 . Then there exists k 1 > 0 such that for all j > k 1 , we have ln cos 2 θ j < − 2 c , 156 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S where c is the constant deﬁned above . Using this inequality in ( 6 . 51 ) we ﬁnd the following relations to be true for all k > k 1 : 0 < ψ ( B 0 ) + c ( k + 1 ) + k 1 (cid:3) j (cid:3) 0 ln cos 2 θ j + k (cid:3) j (cid:3) k 1 + 1 ( − 2 c ) (cid:3) ψ ( B 0 ) + k 1 (cid:3) j (cid:3) 0 ln cos 2 θ j + 2 ck 1 + c − ck . However , the right - hand - side is negative for large k , giving a contradiction . Therefore , there exists a subsequence of indices { j k } k (cid:3) 1 , 2 , . . . such that cos θ j k ≥ δ > 0 . By Zoutendijk’s result ( 3 . 14 ) this limit implies that lim inf (cid:8)∇ f k (cid:8) → 0 . Since the problem is strongly convex , the latter limit is enough to prove that x k → x ∗ . (cid:1) Theorem 6 . 5 has been generalized to the entire restricted Broyden class , except for the DFP method . In other words , Theorem 6 . 5 can be shown to hold for all φ k ∈ [ 0 , 1 ) in ( 6 . 32 ) , but the argument seems to break down as φ k approaches 1 because some of the self - correcting properties of the update are weakened considerably . An extension of the analysis just given shows that the rate of convergence of the iterates is linear . In particular , we can show that the sequence (cid:8) x k − x ∗ (cid:8) converges to zero rapidly enough that ∞ (cid:3) k (cid:3) 1 (cid:8) x k − x ∗ (cid:8) < ∞ . ( 6 . 52 ) We will not prove this claim , but rather establish that if ( 6 . 52 ) holds , then the rate of convergence is actually superlinear . SUPERLINEAR CONVERGENCE OF THE BFGS METHOD The analysis of this section makes use of the Dennis and Mor´e characterization ( 3 . 36 ) of superlinear convergence . It applies to general nonlinear—not just convex—objective functions . For the results that follow we need to make an additional assumption . Assumption 6 . 2 . The Hessian matrix G is Lipschitz continuous at x ∗ , that is , (cid:8) G ( x ) − G ( x ∗ ) (cid:8) ≤ L (cid:8) x − x ∗ (cid:8) , for all x near x ∗ , where L is a positive constant . 6 . 4 . C O N V E R G E N C E A N A L Y S I S 157 We start by introducing the quantities ˜ s k (cid:3) G 1 / 2 ∗ s k , ˜ y k (cid:3) G − 1 / 2 ∗ y k , ˜ B k (cid:3) G − 1 / 2 ∗ B k G − 1 / 2 ∗ , where G ∗ (cid:3) G ( x ∗ ) and x ∗ is a minimizer of f . Similarly to ( 6 . 46 ) , we deﬁne cos ˜ θ k (cid:3) ˜ s Tk ˜ B k ˜ s k (cid:8)˜ s k (cid:8)(cid:8) ˜ B k ˜ s k (cid:8) , ˜ q k (cid:3) ˜ s Tk ˜ B k ˜ s k (cid:8)˜ s k (cid:8) 2 , while we echo ( 6 . 42 ) and ( 6 . 43 ) in deﬁning ˜ M k (cid:3) (cid:8) ˜ y k (cid:8) 2 ˜ y Tk ˜ s k , ˜ m k (cid:3) ˜ y Tk ˜ s k ˜ s Tk ˜ s k . By pre - and postmultiplying the BFGS update formula ( 6 . 19 ) by G − 1 / 2 ∗ and grouping terms appropriately , we obtain ˜ B k + 1 (cid:3) ˜ B k − ˜ B k ˜ s k ˜ s Tk ˜ B k ˜ s Tk ˜ B k ˜ s k + ˜ y k ˜ y Tk ˜ y Tk ˜ s k . Since this expression has precisely the same form as the BFGS formula ( 6 . 19 ) , it follows from the argument leading to ( 6 . 50 ) that ψ ( ˜ B k + 1 ) (cid:3) ψ ( ˜ B k ) + ( ˜ M k − ln ˜ m k − 1 ) + (cid:26) 1 − ˜ q k cos 2 ˜ θ k + ln ˜ q k cos 2 ˜ θ k (cid:27) ( 6 . 53 ) + ln cos 2 ˜ θ k . Recalling ( 6 . 12 ) , we have that y k − G ∗ s k (cid:3) ( ¯ G k − G ∗ ) s k , and thus ˜ y k − ˜ s k (cid:3) G − 1 / 2 ∗ ( ¯ G k − G ∗ ) G − 1 / 2 ∗ ˜ s k . By Assumption 6 . 2 , and recalling the deﬁnition ( 6 . 11 ) , we have (cid:8) ˜ y k − ˜ s k (cid:8) ≤ (cid:8) G − 1 / 2 ∗ (cid:8) 2 (cid:8) ˜ s k (cid:8)(cid:8) ¯ G k − G ∗ (cid:8) ≤ (cid:8) G − 1 / 2 ∗ (cid:8) 2 (cid:8)˜ s k (cid:8) L (cid:9) k , where (cid:9) k is deﬁned by (cid:9) k (cid:3) max { (cid:8) x k + 1 − x ∗ (cid:8) , (cid:8) x k − x ∗ (cid:8) } . 158 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S We have thus shown that (cid:8) ˜ y k − ˜ s k (cid:8) (cid:8)˜ s k (cid:8) ≤ ¯ c (cid:9) k , ( 6 . 54 ) for some positive constant ¯ c . This inequality and ( 6 . 52 ) play an important role in superlinear convergence , as we now show . Theorem 6 . 6 . Suppose that f is twice continuously differentiable and that the iterates generated by the BFGS algorithm converge to a minimizer x ∗ at which Assumption 6 . 2 holds . Suppose also that ( 6 . 52 ) holds . Then x k converges to x ∗ at a superlinear rate . P ROOF . From ( 6 . 54 ) , we have from the triangle inequality ( A . 4a ) that (cid:8) ˜ y k (cid:8) − (cid:8)˜ s k (cid:8) ≤ ¯ c (cid:9) k (cid:8)˜ s k (cid:8) , (cid:8)˜ s k (cid:8) − (cid:8) ˜ y k (cid:8) ≤ ¯ c (cid:9) k (cid:8) ˜ s k (cid:8) , so that ( 1 − ¯ c (cid:9) k ) (cid:8)˜ s k (cid:8) ≤ (cid:8) ˜ y k (cid:8) ≤ ( 1 + ¯ c (cid:9) k ) (cid:8)˜ s k (cid:8) . ( 6 . 55 ) By squaring ( 6 . 54 ) and using ( 6 . 55 ) , we obtain ( 1 − ¯ c (cid:9) k ) 2 (cid:8)˜ s k (cid:8) 2 − 2 ˜ y Tk ˜ s k + (cid:8) ˜ s k (cid:8) 2 ≤ (cid:8) ˜ y k (cid:8) 2 − 2 ˜ y Tk ˜ s k + (cid:8) ˜ s k (cid:8) 2 ≤ ¯ c 2 (cid:9) 2 k (cid:8)˜ s k (cid:8) 2 , and therefore 2 ˜ y T k ˜ s k ≥ ( 1 − 2 ¯ c (cid:9) k + ¯ c 2 (cid:9) 2 k + 1 − ¯ c 2 (cid:9) 2 k ) (cid:8)˜ s k (cid:8) 2 (cid:3) 2 ( 1 − ¯ c (cid:9) k ) (cid:8) ˜ s k (cid:8) 2 . It follows from the deﬁnition of ˜ m k that ˜ m k (cid:3) ˜ y Tk ˜ s k (cid:8)˜ s k (cid:8) 2 ≥ 1 − ¯ c (cid:9) k . ( 6 . 56 ) By combining ( 6 . 55 ) and ( 6 . 56 ) , we obtain also that ˜ M k (cid:3) (cid:8) ˜ y k (cid:8) 2 ˜ y T k ˜ s k ≤ 1 + ¯ c (cid:9) k 1 − ¯ c (cid:9) k . ( 6 . 57 ) Since x k → x ∗ , we have that (cid:9) k → 0 , and thus by ( 6 . 57 ) there exists a positive constant c > ¯ c such that the following inequalities hold for all sufﬁciently large k : ˜ M k ≤ 1 + 2 ¯ c 1 − ¯ c (cid:9) k (cid:9) k ≤ 1 + c (cid:9) k . ( 6 . 58 ) 6 . 4 . C O N V E R G E N C E A N A L Y S I S 159 We again make use of the nonpositiveness of the function h ( t ) (cid:3) 1 − t + ln t . Therefore , we have − x 1 − x − ln ( 1 − x ) (cid:3) h (cid:17) 1 1 − x (cid:18) ≤ 0 . Now , for k large enough we can assume that ¯ c (cid:9) k < 12 , and therefore ln ( 1 − ¯ c (cid:9) k ) ≥ −¯ c (cid:9) k 1 − ¯ c (cid:9) k ≥ − 2 ¯ c (cid:9) k . This relation and ( 6 . 56 ) imply that for sufﬁciently large k , we have ln ˜ m k ≥ ln ( 1 − ¯ c (cid:9) k ) ≥ − 2 ¯ c (cid:9) k > − 2 c (cid:9) k . ( 6 . 59 ) We can now deduce from ( 6 . 53 ) , ( 6 . 58 ) , and ( 6 . 59 ) that 0 < ψ ( ˜ B k + 1 ) ≤ ψ ( ˜ B k ) + 3 c (cid:9) k + ln cos 2 ˜ θ k + (cid:26) 1 − ˜ q k cos 2 ˜ θ k + ln ˜ q k cos 2 ˜ θ k (cid:27) . ( 6 . 60 ) By summing this expression and making use of ( 6 . 52 ) we have that ∞ (cid:3) j (cid:3) 0 (cid:24) ln 1 cos 2 ˜ θ j − (cid:1) 1 − ˜ q j cos 2 ˜ θ j + ln ˜ q j cos 2 ˜ θ j (cid:2)(cid:25) ≤ ψ ( ˜ B 0 ) + 3 c ∞ (cid:3) j (cid:3) 0 (cid:9) j < + ∞ . Since the term in the square brackets is nonpositive , and since ln (cid:29) 1 / cos 2 ˜ θ j (cid:30) ≥ 0 for all j , we obtain the two limits lim j →∞ ln 1 cos 2 ˜ θ j (cid:3) 0 , lim j →∞ (cid:24) 1 − ˜ q j cos 2 ˜ θ j + ln ˜ q j cos 2 ˜ θ j (cid:25) (cid:3) 0 , which imply that lim j →∞ cos ˜ θ j (cid:3) 1 , lim j →∞ ˜ q j (cid:3) 1 . ( 6 . 61 ) The essence of the result has now been proven ; we need only to interpret these limits in terms of the Dennis – Mor´e characterization of superlinear convergence . 160 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S Recalling ( 6 . 47 ) , we have (cid:8) G − 1 / 2 ∗ ( B k − G ∗ ) s k (cid:8) 2 (cid:8) G 1 / 2 ∗ s k (cid:8) 2 (cid:3) (cid:8) ( ˜ B k − I ) ˜ s k (cid:8) 2 (cid:8)˜ s k (cid:8) 2 (cid:3) (cid:8) ˜ B k ˜ s k (cid:8) 2 − 2 ˜ s Tk ˜ B k ˜ s k + ˜ s Tk ˜ s k ˜ s T k ˜ s k (cid:3) ˜ q 2 k cos ˜ θ 2 k − 2 ˜ q k + 1 . Since by ( 6 . 61 ) the right - hand - side converges to 0 , we conclude that lim k →∞ (cid:8) ( B k − G ∗ ) s k (cid:8) (cid:8) s k (cid:8) (cid:3) 0 . The limit ( 3 . 36 ) and Theorem 3 . 6 imply that the unit step length α k (cid:3) 1 will satisfy the Wolfe conditions near the solution , and hence that the rate of convergence is superlinear . (cid:1) CONVERGENCE ANALYSIS OF THE SR1 METHOD The convergence properties of the SR1 method are not as well understood as those of the BFGS method . No global results like Theorem 6 . 5 or local superlinear results like The - orem 6 . 6 have been established , except the results for quadratic functions discussed earlier . There is , however , an interesting result for the trust - region SR1 algorithm , Algorithm 6 . 2 . It states that when the objective function has a unique stationary point and the condition ( 6 . 26 ) holds at every step ( so that the SR1 update is never skipped ) and the Hessian ap - proximations B k are bounded above , then the iterates converge to x ∗ at an ( n + 1 ) - step superlinear rate . The result does not require exact solution of the trust - region subproblem ( 6 . 27 ) . We state the result formally as follows . Theorem 6 . 7 . Supposethattheiterates x k aregeneratedbyAlgorithm6 . 2 . Supposealsothatthefollowing conditions hold : ( c1 ) The sequence of iterates does not terminate , but remains in a closed , bounded , convex set D , on which the function f is twice continuously differentiable , and in which f has a unique stationary point x ∗ ; ( c2 ) the Hessian ∇ 2 f ( x ∗ ) is positive deﬁnite , and ∇ 2 f ( x ) is Lipschitz continuous in a neighborhood of x ∗ ; ( c3 ) the sequence of matrices { B k } is bounded in norm ; ( c4 ) condition ( 6 . 26 ) holds at every iteration , where r is some constant in ( 0 , 1 ) . 6 . 4 . C O N V E R G E N C E A N A L Y S I S 161 Then lim k →∞ x k (cid:3) x ∗ , and we have that lim k →∞ (cid:8) x k + n + 1 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) (cid:3) 0 . Note that the BFGS method does not require the boundedness assumption ( c3 ) to hold . As we have mentioned already , the SR1 update does not necessarily maintain positive deﬁniteness of the Hessian approximations B k . In practice , B k may be indeﬁnite at any iteration , which means that the trust region bound may continue to be active for arbitrarily large k . Interestingly , however , it can be shown that the SR1 Hessian approximations tend to be positive deﬁnite most of the time . The precise result is that lim k →∞ number of indices j (cid:3) 1 , 2 , . . . , k for which B j is positive semideﬁnite k (cid:3) 1 , under the assumptions of Theorem 6 . 7 . This result holds regardless of whether the initial Hessian approximation is positive deﬁnite or not . NOTES AND REFERENCES For a comprehensive treatment of quasi - Newton methods see Dennis and Schn - abel [ 92 ] , Dennis and Mor´e [ 91 ] , and Fletcher [ 101 ] . A formula for updating the Cholesky factors of the BFGS matrices is given in Dennis and Schnabel [ 92 ] . Several safeguards and modiﬁcations of the SR1 method have been proposed , but the condition ( 6 . 26 ) is favored in the light of the analysis of Conn , Gould , and Toint [ 71 ] . Computational experiments by Conn , Gould , and Toint [ 70 , 73 ] and Khalfan , Byrd , and Schnabel [ 181 ] , using both line search and trust - region approaches , indicate that the SR1 method appears to be competitive with the BFGS method . The proof of Theorem 6 . 7 is given in Byrd , Khalfan , and Schnabel [ 51 ] . A study of the convergence of BFGS matrices for nonlinear problems can be found in Ge and Powell [ 119 ] and Boggs and Tolle [ 32 ] ; however , the results are not as satisfactory as for SR1 updating . The global convergence of the BFGS method was established by Powell [ 246 ] . This result was extended to the restricted Broyden class , except for DFP , by Byrd , Nocedal , and Yuan [ 53 ] . For a discussion of the self - correcting properties of quasi - Newton methods see Nocedal [ 229 ] . Most of the early analysis of quasi - Newton methods was based on the bounded deterioration principle . This is a tool for the local analysis that quantiﬁes the worst - case behavior of quasi - Newton updating . Assuming that the starting point is sufﬁciently close to the solution x ∗ and that the initial Hessian approximation is sufﬁciently close to ∇ 2 f ( x ∗ ) , one can use the bounded deterioration bounds to prove that the iteration cannot stray away from the solution . This property can then be used to show that the quality of the quasi - Newton approximations is good enough to yield superlinear convergence . For details , see Dennis and Mor´e [ 91 ] or Dennis and Schnabel [ 92 ] . 162 C H A P T E R 6 . Q U A S I - N E W T O N M E T H O D S ✐ E X E R C I S E S ✐ 6 . 1 ( a ) Show that if f is strongly convex , then ( 6 . 7 ) holds for any vectors x k and x k + 1 . ( b ) Give an example of a function of one variable satisfying g ( 0 ) (cid:3) − 1 and g ( 1 ) (cid:3) − 1 4 and show that ( 6 . 7 ) does not hold in this case . ✐ 6 . 2 Show that the second strong Wolfe condition ( 3 . 7b ) implies the curvature condition ( 6 . 7 ) . ✐ 6 . 3 Verify that ( 6 . 19 ) and ( 6 . 17 ) are inverses of each other . ✐ 6 . 4 Use the Sherman – Morrison formula ( A . 27 ) to show that ( 6 . 24 ) is the inverse of ( 6 . 25 ) . ✐ 6 . 5 Prove the statements ( ii ) and ( iii ) given in the paragraph following ( 6 . 25 ) . ✐ 6 . 6 The square root of a matrix A is a matrix A 1 / 2 such that A 1 / 2 A 1 / 2 (cid:3) A . Show that any symmetric positive deﬁnite matrix A has a square root , and that this square root is itself symmetric and positive deﬁnite . ( Hint : Use the factorization A (cid:3) U DU T ( A . 16 ) , where U is orthogonal and D is diagonal with positive diagonal elements . ) ✐ 6 . 7 Use the Cauchy - Schwarz inequality ( A . 5 ) to verify that µ k ≥ 1 , where µ k is deﬁned by ( 6 . 38 ) . ✐ 6 . 8 Deﬁne h ( t ) (cid:3) 1 − t + ln t , and note that h (cid:14) ( t ) (cid:3) − 1 + 1 / t , h (cid:14)(cid:14) ( t ) (cid:3) − 1 / t 2 < 0 , h ( 1 ) (cid:3) 0 , and h (cid:14) ( 1 ) (cid:3) 0 . Show that h ( t ) ≤ 0 for all t > 0 . ✐ 6 . 9 Denote the eigenvalues of the positive deﬁnite matrix B by λ 1 , λ 2 , . . . , λ n , where 0 < λ 1 ≤ λ 2 ≤ · · · ≤ λ n . Show that the ψ function deﬁned in ( 6 . 49 ) can be written as ψ ( B ) (cid:3) n (cid:3) i (cid:3) 1 ( λ i − ln λ i ) . Use this form to show that ψ ( B ) > 0 . ✐ 6 . 10 The object of this exercise is to prove ( 6 . 45 ) . ( a ) Show that det ( I + xy T ) (cid:3) 1 + y T x , where x and y are n - vectors . Hint : Assuming that x (cid:9)(cid:3) 0 , we can ﬁnd vectors w 1 , w 2 , . . . , w n − 1 such that the matrix Q deﬁned by Q (cid:3) [ x , w 1 , w 2 , . . . , w n − 1 ] 6 . 4 . C O N V E R G E N C E A N A L Y S I S 163 is nonsingular and x (cid:3) Qe 1 , where e 1 (cid:3) ( 1 , 0 , 0 , . . . , 0 ) T . If we deﬁne y T Q (cid:3) ( z 1 , z 2 , . . . , z n ) , then z 1 (cid:3) y T Qe 1 (cid:3) y T Q ( Q − 1 x ) (cid:3) y T x , and det ( I + xy T ) (cid:3) det ( Q − 1 ( I + xy T ) Q ) (cid:3) det ( I + e 1 y T Q ) . ( b ) Use a similar technique to prove that det ( I + xy T + u v T ) (cid:3) ( 1 + y T x ) ( 1 + v T u ) − ( x T v ) ( y T u ) . ( c ) Use this relation to establish ( 6 . 45 ) . ✐ 6 . 11 Use the properties of the trace of a symmetric matrix and the formula ( 6 . 19 ) to prove ( 6 . 44 ) . ✐ 6 . 12 Show that if f satisﬁes Assumption 6 . 1 and if the sequence of gradients satisﬁes lim inf (cid:8)∇ f k (cid:8) (cid:3) 0 , then the whole sequence of iterates x converges to the solution x ∗ . This is pag Printer : O C H A P T E R 7 Large - Scale Unconstrained Optimization Many applications give rise to unconstrained optimization problems with thousands or millions of variables . Problems of this size can be solved efﬁciently only if the storage and computational costs of the optimization algorithm can be kept at a tolerable level . A diverse collection of large - scale optimization methods has been developed to achieve this goal , each being particularly effective for certain problem types . Some of these methods are straightforward adaptations of the methods described in Chapters 3 , 4 , and 6 . Other approaches are modiﬁcations of these basic methods that allow approximate steps to be calculated at lower cost in computation and storage . One set of approaches that we have alreadydiscussed—thenonlinearconjugategradientmethodsofSection5 . 2—canbeapplied 7 . 1 . I N E X A C T N E W T O N M E T H O D S 165 to large problems without modiﬁcation , because of its minimal storage demands and its reliance on only ﬁrst - order derivative information . Thelinesearchandtrust - regionNewtonalgorithmsofChapters3and4requirematrix factorizations of the Hessian matrices ∇ 2 f k . In the large - scale case , these factorizations can be carried out using sparse elimination techniques . Such algorithms have received much attention , and high quality software implementations are available . If the computational cost and memory requirements of these sparse factorization methods are affordable for a given application , and if the Hessian matrix can be formed explicitly , Newton methods based on sparse factorizations constitute an effective approach for solving such problems . Often , however , the cost of factoring the Hessian is prohibitive , and it is preferable to compute approximations to the Newton step using iterative linear algebra techniques . Section 7 . 1 discusses inexact Newton methods that use these techniques , in both line search and trust - region frameworks . The resulting algorithms have attractive global convergence properties and may be superlinearly convergent for suitable choices of parameters . They ﬁnd effectivesearchdirectionswhentheHessian ∇ 2 f k isindeﬁnite , andmayevenbeimplemented in a “Hessian - free” manner , without explicit calculation or storage of the Hessian . The Hessian approximations generated by the quasi - Newton approaches of Chapter 6 are usually dense , even when the true Hessian is sparse , and the cost of storing and working with these approximations can be excessive for large n . Section 7 . 2 discusses limited - memory variants of the quasi - Newton approach , which use Hessian approximations that can be stored compactly by using just a few vectors of length n . These methods are fairly robust , inexpensive , and easy to implement , but they do not converge rapidly . Another approach , discussed brieﬂy in Section 7 . 3 , is to deﬁne quasi - Newton approximate Hessians B k that preserve sparsity , for example by mimicking the sparsity pattern of the Hessian . In Section 7 . 4 , we note that objective functions in large problems often possess a structural property known as partial separability , which means they can be decomposed into a sum of simpler functions , each of which depends on only a small subspace of IR n . EffectiveNewtonandquasi - Newtonmethodsthatexploitthispropertyhavebeendeveloped . Such methods usually converge rapidly and are robust , but they require detailed information about the objective function , which can be difﬁcult to obtain in some applications . We conclude the chapter with a discussion of software for large - scale unconstrained optimization problems . 7 . 1 INEXACT NEWTON METHODS Recall from ( 2 . 15 ) that the basic Newton step p N k is obtained by solving the symmetric n × n linear system ∇ 2 f k p N k (cid:3) −∇ f k . ( 7 . 1 ) In this section , we describe techniques for obtaining approximations to p N k that are 166 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N inexpensive to calculate but are good search directions or steps . These approaches are based on solving ( 7 . 1 ) by using the conjugate gradient ( CG ) method ( see Chapter 5 ) or the Lanczos method , with modiﬁcations to handle negative curvature in the Hessian ∇ 2 f k . Both line search and trust - region approaches are described here . We refer to this family of methods by the general name inexact Newton methods . The use of iterative methods for ( 7 . 1 ) spares us from concerns about the expense of a direct factorization of the Hessian ∇ 2 f k and the ﬁll - in that may occur during this process . Further , we can customize the solution strategy to ensure that the rapid convergence properties associated with Newton’s methods are not lost in the inexact version . In addition , as noted below , we can implement these methods in a Hessian - free manner , so that the Hessian ∇ 2 f k need not be calculated or stored explicitly at all . We examine ﬁrst how the inexactness in the step calculation determines the local convergence properties of inexact Newton methods . We then consider line search and trust - region approaches based on using CG ( possibly with preconditioning ) to obtain an approximate solution of ( 7 . 1 ) . Finally , we discuss the use of the Lanczos method for solving ( 7 . 1 ) approximately . LOCAL CONVERGENCE OF INEXACT NEWTON METHODS Most rules for terminating the iterative solver for ( 7 . 1 ) are based on the residual r k (cid:3) ∇ 2 f k p k + ∇ f k , ( 7 . 2 ) where p k is the inexact Newton step . Usually , we terminate the CG iterations when (cid:8) r k (cid:8) ≤ η k (cid:8)∇ f k (cid:8) , ( 7 . 3 ) where the sequence { η k } ( with 0 < η k < 1 for all k ) is called the forcing sequence . We now study how the rate of convergence of inexact Newton methods based on ( 7 . 1 ) – ( 7 . 3 ) is affected by the choice of the forcing sequence . The next two theorems apply not just to Newton – CG procedures but to all inexact Newton methods whose steps satisfy ( 7 . 2 ) and ( 7 . 3 ) . Our ﬁrst result says that local convergence is obtained simply by ensuring that η k is bounded away from 1 . Theorem 7 . 1 . Suppose that ∇ 2 f ( x ) exists and is continuous in a neighborhood of a minimizer x ∗ , with ∇ 2 f ( x ∗ ) is positive deﬁnite . Consider the iteration x k + 1 (cid:3) x k + p k where p k satisﬁes ( 7 . 3 ) , and assume that η k ≤ η for some constant η ∈ [ 0 , 1 ) . Then , if the starting point x 0 is sufﬁciently near x ∗ , the sequence { x k } converges to x ∗ and satisﬁes (cid:8)∇ 2 f ( x ∗ ) ( x k + 1 − x ∗ ) (cid:8) ≤ ˆ η (cid:8)∇ 2 f ( x ∗ ) ( x k − x ∗ ) (cid:8) , ( 7 . 4 ) for some constant ˆ η with η < ˆ η < 1 . 7 . 1 . I N E X A C T N E W T O N M E T H O D S 167 Rather than giving a rigorous proof of this theorem , we present an informal derivation that contains the essence of the argument and motivates the next result . Since the Hessian matrix ∇ 2 f is positive deﬁnite at x ∗ and continuous near x ∗ , there exists a positive constant L such that (cid:8) ( ∇ 2 f k ) − 1 (cid:8) ≤ L for all x k sufﬁciently close to x ∗ . We therefore have from ( 7 . 2 ) that the inexact Newton step satisﬁes (cid:8) p k (cid:8) ≤ L ( (cid:8)∇ f k (cid:8) + (cid:8) r k (cid:8) ) ≤ 2 L (cid:8)∇ f k (cid:8) , where the second inequality follows from ( 7 . 3 ) and η k < 1 . Using this expression together with Taylor’s theorem and the continuity of ∇ 2 f ( x ) , we obtain ∇ f k + 1 (cid:3) ∇ f k + ∇ 2 f k p k + (cid:6) 1 0 [ ∇ f ( x k + tp k ) − ∇ f ( x k ) ] p k dt (cid:3) ∇ f k + ∇ 2 f k p k + o ( (cid:8) p k (cid:8) ) (cid:3) ∇ f k − ( ∇ f k − r k ) + o ( (cid:8)∇ f k (cid:8) ) (cid:3) r k + o ( (cid:8)∇ f k (cid:8) ) . ( 7 . 5 ) Taking norms and recalling ( 7 . 3 ) , we have that (cid:8)∇ f k + 1 (cid:8) ≤ η k (cid:8)∇ f k (cid:8) + o ( (cid:8)∇ f k (cid:8) ) ≤ ( η k + o ( 1 ) ) ) (cid:8)∇ f k (cid:8) . ( 7 . 6 ) When x k is close enough to x ∗ that the o ( 1 ) term in the last estimate is bounded by ( 1 − η ) / 2 , we have (cid:8)∇ f k + 1 (cid:8) ≤ ( η k + ( 1 − η ) / 2 ) (cid:8)∇ f k (cid:8) ≤ 1 + η 2 (cid:8)∇ f k (cid:8) , ( 7 . 7 ) so the gradient norm decreases by a factor of ( 1 + η ) / 2 at this iteration . By choosing the initial point x 0 sufﬁciently close to x ∗ , we can ensure that this rate of decrease occurs at every iteration . To prove ( 7 . 4 ) , we note that under our smoothness assumptions , we have ∇ f k (cid:3) ∇ 2 f ( x ∗ ) ( x k − x ∗ ) + o ( (cid:8) x k − x ∗ (cid:8) ) . Hence it can be shown that for x k close to x ∗ , the gradient ∇ f k differs from the scaled error ∇ 2 f ( x ∗ ) ( x k − x ∗ ) by only a relatively small perturbation . A similar estimate holds at x k + 1 , so ( 7 . 4 ) follows from ( 7 . 7 ) . From ( 7 . 6 ) , we have that (cid:8)∇ f k + 1 (cid:8) (cid:8)∇ f k (cid:8) ≤ η k + o ( 1 ) . ( 7 . 8 ) 168 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N If lim k →∞ η k (cid:3) 0 , we have from this expression that lim k →∞ (cid:8)∇ f k + 1 (cid:8) (cid:8)∇ f k (cid:8) (cid:3) 0 , indicating Q - superlinear convergence of the gradient norms (cid:8)∇ f k (cid:8) to zero . Superlinear convergence of the iterates { x k } to x ∗ can be proved as a consequence . We can obtain quadratic convergence by making the additional assumption that the Hessian ∇ 2 f ( x ) is Lipschitz continuous near x ∗ . In this case , the estimate ( 7 . 5 ) can be tightened to ∇ f k + 1 (cid:3) r k + O (cid:7) (cid:8)∇ f k (cid:8) 2 (cid:8) . By choosing the forcing sequence so that η k (cid:3) O ( (cid:8)∇ f k (cid:8) ) , we have from this expression that (cid:8)∇ f k + 1 (cid:8) (cid:3) O ( (cid:8)∇ f k (cid:8) 2 ) , indicatingQ - quadraticconvergenceofthegradientnormstozero ( andthusalsoQ - quadratic convergence of the iterates x k to x ∗ ) . The last two observations are summarized in the following theorem . Theorem 7 . 2 . Suppose that the conditions of Theorem 7 . 1 hold , and assume that the iterates { x k } generated by the inexact Newton method converge to x ∗ . Then the rate of convergence is superlinear if η k → 0 . If in addition , ∇ 2 f ( x ) is Lipschitz continuous for x near x ∗ and if η k (cid:3) O ( (cid:8)∇ f k (cid:8) ) , then the convergence is quadratic . To obtain superlinear convergence , we can set , for example , η k (cid:3) min (cid:7) 0 . 5 , √(cid:8)∇ f k (cid:8) (cid:8) ; the choice η k (cid:3) min ( 0 . 5 , (cid:8)∇ f k (cid:8) ) would yield quadratic convergence . All the results presented in this section , which are proved by Dembo , Eisenstat , and Steihaug [ 89 ] , are local in nature : They assume that the sequence { x k } eventually enters the near vicinity of the solution x ∗ . They also assume that the unit step length α k (cid:3) 1 is taken and hence that globalization strategies do not interfere with rapid convergence . In the following pages we show that inexact Newton strategies can , in fact , be incorporated in practical line search and trust - region implementations of Newton’s method , yielding algorithms with good local and global convergence properties . We start with a line search approach . LINE SEARCH NEWTON – CG METHOD InthelinesearchNewton – CGmethod , alsoknownasthe truncatedNewtonmethod , we compute the search direction by applying the CG method to the Newton equations ( 7 . 1 ) and 7 . 1 . I N E X A C T N E W T O N M E T H O D S 169 attempt to satisfy a termination test of the form ( 7 . 3 ) . However , the CG method is designed to solve positive deﬁnite systems , and the Hessian ∇ 2 f k may have negative eigenvalues when x k is not close to a solution . Therefore , we terminate the CG iteration as soon as a direction of negative curvature is generated . This adaptation of the CG method produces a search direction p k that is a descent direction . Moreover , the adaptation guarantees that the fast convergence rate of the pure Newton method is preserved , provided that the step length α k (cid:3) 1 is used whenever it satisﬁes the acceptance criteria . We now describe Algorithm 7 . 1 , a line search algorithm that uses a modiﬁcation of Algorithm 5 . 2 as the inner iteration to compute each search direction p k . For purposes of this algorithm , we write the linear system ( 7 . 1 ) in the form B k p (cid:3) −∇ f k , ( 7 . 9 ) where B k represents ∇ 2 f k . For the inner CG iteration , we denote the search directions by d j and the sequence of iterates that it generates by z j . When B k is positive deﬁnite , the inner iteration sequence { z j } will converge to the Newton step p N k that solves ( 7 . 9 ) . At each major iteration , we deﬁne a tolerance (cid:9) k that speciﬁes the required accuracy of the computed solution . For concreteness , we choose the forcing sequence to be η k (cid:3) min ( 0 . 5 , √(cid:8)∇ f k (cid:8) ) to obtain a superlinear convergence rate , but other choices are possible . Algorithm 7 . 1 ( Line Search Newton – CG ) . Given initial point x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Deﬁne tolerance (cid:9) k (cid:3) min ( 0 . 5 , √(cid:8)∇ f k (cid:8) ) (cid:8)∇ f k (cid:8) ; Set z 0 (cid:3) 0 , r 0 (cid:3) ∇ f k , d 0 (cid:3) − r 0 (cid:3) −∇ f k ; for j (cid:3) 0 , 1 , 2 , . . . if d T j B k d j ≤ 0 if j (cid:3) 0 return p k (cid:3) −∇ f k ; else return p k (cid:3) z j ; Set α j (cid:3) r Tj r j / d Tj B k d j ; Set z j + 1 (cid:3) z j + α j d j ; Set r j + 1 (cid:3) r j + α j B k d j ; if (cid:8) r j + 1 (cid:8) < (cid:9) k return p k (cid:3) z j + 1 ; Set β j + 1 (cid:3) r Tj + 1 r j + 1 / r Tj r j ; Set d j + 1 (cid:3) − r j + 1 + β j + 1 d j ; end ( for ) Set x k + 1 (cid:3) x k + α k p k , where α k satisﬁes the Wolfe , Goldstein , or Armijo backtracking conditions ( using α k (cid:3) 1 if possible ) ; end 170 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N The main differences between the inner loop of Algorithm 7 . 1 and Algorithm 5 . 2 are that the speciﬁc starting point z 0 (cid:3) 0 is used ; the use of a positive tolerance (cid:9) k allows the CG iterations to terminate at an inexact solution ; and the negative curvature test d Tj B k d j ≤ 0 ensures that p k is a descent direction for f at x k . If negative curvature is detected on the ﬁrst inner iteration j (cid:3) 0 , the returned direction p k (cid:3) −∇ f k is both a descent direction and a direction of nonpositive curvature for f at x k . We can modify the CG iterations in Algorithm 7 . 1 by introducing preconditioning , in the manner described in Chapter 5 . Algorithm7 . 1iswellsuitedforlargeproblems , butithasaweakness . WhentheHessian ∇ 2 f k is nearly singular , the line search Newton – CG direction can be long and of poor quality , requiring many function evaluations in the line search and giving only a small reduction in the function . To alleviate this difﬁculty , we can try to normalize the Newton step , but good rules for doing so are difﬁcult to determine . They run the risk of undermining the rapid convergence of Newton’s method in the case where the pure Newton step is well scaled . It is preferable to introduce a threshold value into the test d Tj Bd j ≤ 0 , but good choices of the threshold are difﬁcult to determine . The trust - region Newton – CG method described below deals more effectively with this problematic situation and is therefore preferable , in our opinion . The line search Newton – CG method does not require explicit knowledge of the Hessian B k (cid:3) ∇ 2 f k . Rather , it requires only that we can supply Hessian – vector products of the form ∇ 2 f k d for any given vector d . When the user cannot easily supply code to calculate second derivatives , or where the Hessian requires too much storage , the techniques of Chapter 8 ( automatic differentiation and ﬁnite differencing ) can be used to calculate these Hessian – vector products . Methods of this type are known as Hessian - free Newton methods . To illustrate the ﬁnite - differencing technique brieﬂy , we use the approximation ∇ 2 f k d ≈ ∇ f ( x k + hd ) − ∇ f ( x k ) h , ( 7 . 10 ) for some small differencing interval h . It is easy to prove that the accuracy of this approxi - mation is O ( h ) ; appropriate choices of h are discussed in Chapter 8 . The price we pay for bypassing the computation of the Hessian is one new gradient evaluation per CG iteration . TRUST - REGION NEWTON – CG METHOD In Chapter 4 , we discussed approaches for ﬁnding an approximate solution of the trust - region subproblem ( 4 . 3 ) that produce improvements on the Cauchy point . Here we deﬁne a modiﬁed CG algorithm for solving the subproblem with these properties . This algorithm , due to Steihaug [ 281 ] , is speciﬁed below as Algorithm 7 . 2 . A complete algorithm for minimizing f is obtained by using Algorithm 7 . 2 to generate the step p k required by Algorithm 4 . 1 of Chapter 4 , for some choice of tolerance (cid:9) k at each iteration . 7 . 1 . I N E X A C T N E W T O N M E T H O D S 171 We use notation similar to ( 7 . 9 ) to deﬁne the trust - region subproblem for which Steihaug’s method ﬁnds an approximate solution : min p ∈ IR n m k ( p ) def (cid:3) f k + ( ∇ f k ) T p + 12 p T B k p subject to (cid:8) p (cid:8) ≤ (cid:6) k , ( 7 . 11 ) where B k (cid:3) ∇ 2 f k . As in Algorithm 7 . 1 , we use d j to denote the search directions of this modiﬁed CG iteration and z j to denote the sequence of iterates that it generates . Algorithm 7 . 2 ( CG – Steihaug ) . Given tolerance (cid:9) k > 0 ; Set z 0 (cid:3) 0 , r 0 (cid:3) ∇ f k , d 0 (cid:3) − r 0 (cid:3) −∇ f k ; if (cid:8) r 0 (cid:8) < (cid:9) k return p k (cid:3) z 0 (cid:3) 0 ; for j (cid:3) 0 , 1 , 2 , . . . if d Tj B k d j ≤ 0 Find τ such that p k (cid:3) z j + τ d j minimizes m k ( p k ) in ( 4 . 5 ) and satisﬁes (cid:8) p k (cid:8) (cid:3) (cid:6) k ; return p k ; Set α j (cid:3) r Tj r j / d Tj B k d j ; Set z j + 1 (cid:3) z j + α j d j ; if (cid:8) z j + 1 (cid:8) ≥ (cid:6) k Find τ ≥ 0 such that p k (cid:3) z j + τ d j satisﬁes (cid:8) p k (cid:8) (cid:3) (cid:6) k ; return p k ; Set r j + 1 (cid:3) r j + α j B k d j ; if (cid:8) r j + 1 (cid:8) < (cid:9) k return p k (cid:3) z j + 1 ; Set β j + 1 (cid:3) r Tj + 1 r j + 1 / r Tj r j ; Set d j + 1 (cid:3) − r j + 1 + β j + 1 d j ; end ( for ) . The ﬁrst if statement inside the loop stops the method if its current search direction d j is a direction of nonpositive curvature along B k , while the second if statement inside the loop causes termination if z j + 1 violates the trust - region bound . In both cases , the method returnsthestep p k obtainedbyintersectingthecurrentsearchdirectionwiththetrust - region boundary . The choice of the tolerance (cid:9) k at each call to Algorithm 7 . 2 is important in keeping the overall cost of the trust - region Newton – CG method low . Near a well - behaved solution x ∗ , the trust - region bound becomes inactive , and the method reduces to the inexact Newton method analyzed in Theorems 7 . 1 and 7 . 2 . Rapid convergence can be obtained in these circumstances by choosing (cid:9) k in a similar fashion to Algorithm 7 . 1 . 172 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N The essential differences between Algorithm 5 . 2 and the inner loop of Algorithm 7 . 2 are that the latter terminates when it violates the trust - region bound (cid:8) p (cid:8) ≤ (cid:6) , when it encounters a direction of negative curvature in ∇ 2 f k , or when it satisﬁes a convergence tolerance deﬁned by a parameter (cid:9) k . In these respects , Algorithm 7 . 2 is quite similar to the inner loop of Algorithm 7 . 1 . The initialization of z 0 to zero in Algorithm 7 . 2 is a crucial feature of the algorithm . Provided (cid:8)∇ f k (cid:8) 2 ≥ (cid:9) k , Algorithm 7 . 2 terminates at a point p k for which m k ( p k ) ≤ m k ( p C k ) , that is , when the reduction in model function equals or exceeds that of the Cauchy point . To demonstrate this fact , we consider several cases . First , if d T 0 B k d 0 (cid:3) ( ∇ f k ) T B k ∇ f k ≤ 0 , then the condition in the ﬁrst if statement is satisﬁed , and the algorithm returns the Cauchy point p (cid:3) − (cid:6) k ( ∇ f k ) / (cid:8)∇ f k (cid:8) . Otherwise , Algorithm 7 . 2 deﬁnes z 1 as follows : z 1 (cid:3) α 0 d 0 (cid:3) r T 0 r 0 d T 0 B k d 0 d 0 (cid:3) − ( ∇ f k ) T ∇ f k ( ∇ f k ) T B k ∇ f k ∇ f k . If (cid:8) z 1 (cid:8) < (cid:6) k , then z 1 is exactly the Cauchy point . Subsequent steps of Algorithm 7 . 2 ensure that the ﬁnal p k satisﬁes m k ( p k ) ≤ m k ( z 1 ) . When (cid:8) z 1 (cid:8) ≥ (cid:6) k , on the other hand , the second if statement is activated , and Algorithm 7 . 2 terminates at the Cauchy point , proving our claim . This property is important for global convergence : Since each step is at least as good as the Cauchy point in reducing the model m k , Algorithm 7 . 2 is globally convergent . Another crucial property of the method is that each iterate z j is larger in norm than its predecessor . This property is another consequence of the initialization z 0 (cid:3) 0 . Its main implication is that it is acceptable to stop iterating as soon as the trust - region boundary is reached , because no further iterates giving a lower value of the model function m k will lie inside the trust region . We state and prove this property formally in the following theorem , which makes use of the expanding subspace property of the conjugate gradient algorithm , described in Theorem 5 . 2 . Theorem 7 . 3 . The sequence of vectors { z j } generated by Algorithm 7 . 2 satisﬁes 0 (cid:3) (cid:8) z 0 (cid:8) 2 < · · · < (cid:8) z j (cid:8) 2 < (cid:8) z j + 1 (cid:8) 2 < · · · < (cid:8) p k (cid:8) 2 ≤ (cid:6) k . P ROOF . We ﬁrst show that the sequences of vectors generated by Algorithm 7 . 2 satisfy z T j r j (cid:3) 0 for j ≥ 0 and z T j d j > 0 for j ≥ 1 . Algorithm 7 . 2 computes z j + 1 recursively in terms of z j ; but when all the terms of this recursion are written explicitly , we see that z j (cid:3) z 0 + j − 1 (cid:3) i (cid:3) 0 α i d i (cid:3) j − 1 (cid:3) i (cid:3) 0 α i d i , 7 . 1 . I N E X A C T N E W T O N M E T H O D S 173 since z 0 (cid:3) 0 . Multiplying by r j and applying the expanding subspace property of conjugate gradients ( see Theorem 5 . 2 ) , we obtain z Tj r j (cid:3) j − 1 (cid:3) i (cid:3) 0 α i d Ti r j (cid:3) 0 . ( 7 . 12 ) An induction proof establishes the relation z Tj d j > 0 . By applying the expanding subspace property again , we obtain z T 1 d 1 (cid:3) ( α 0 d 0 ) T ( − r 1 + β 1 d 0 ) (cid:3) α 0 β 1 d T 0 d 0 > 0 . We now make the inductive hypothesis that z Tj d j > 0 and deduce that z Tj + 1 d j + 1 > 0 . From ( 7 . 12 ) , we have z Tj + 1 r j + 1 (cid:3) 0 , and therefore z Tj + 1 d j + 1 (cid:3) z Tj + 1 ( − r j + 1 + β j + 1 d j ) (cid:3) β j + 1 z Tj + 1 d j (cid:3) β j + 1 ( z j + α j d j ) T d j (cid:3) β j + 1 z Tj d j + α j β j + 1 d Tj d j . Because of the inductive hypothesis and positivity of β j + 1 and α j , the last expression is positive . We now prove the theorem . If Algorithm 7 . 2 terminates because d Tj B k d j ≤ 0 or (cid:8) z j + 1 (cid:8) 2 ≥ (cid:6) k , then the ﬁnal point p k is chosen to make (cid:8) p k (cid:8) 2 (cid:3) (cid:6) k , which is the largest possible length . To cover all other possibilities in the algorithm , we must show that (cid:8) z j (cid:8) 2 < (cid:8) z j + 1 (cid:8) 2 when z j + 1 (cid:3) z j + α j d j and j ≥ 1 . Observe that (cid:8) z j + 1 (cid:8) 2 2 (cid:3) ( z j + α j d j ) T ( z j + α j d j ) (cid:3) (cid:8) z j (cid:8) 2 2 + 2 α j z Tj d j + α 2 j (cid:8) d j (cid:8) 2 2 . It follows from this expression and our intermediate result that (cid:8) z j (cid:8) 2 < (cid:8) z j + 1 (cid:8) 2 , so our proof is complete . (cid:1) From this theorem we see that Algorithm 7 . 2 sweeps out points z j that move on some interpolating path from z 1 to the ﬁnal solution p k , a path in which every step increases its total distance from the start point . When B k (cid:3) ∇ 2 f k is positive deﬁnite , this path may be compared to the path of the dogleg method : Both methods start by minimizing m k along the negative gradient direction −∇ f k and subsequently progress toward p N k , until the trust - region boundary intervenes . One can show that , when B k (cid:3) ∇ 2 f k is positive deﬁnite , Algorithm 7 . 2 provides a decrease in the model ( 7 . 11 ) that is at least half as good as the optimal decrease [ 320 ] . 174 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N PRECONDITIONING THE TRUST - REGION NEWTON – CG METHOD As discussed in Chapter 5 , preconditioning can be used to accelerate the CG iteration . Preconditioning techniques are based on ﬁnding a nonsingular matrix D such that the eigen - values of D − T ∇ 2 f k D − 1 have a more favorable distribution . By generalizing Theorem 7 . 3 , we can show that the iterates z j generated by a preconditioned variant of Algorithm 7 . 2 will grow monotonically in the weighted norm (cid:8) D · (cid:8) . To be consistent , we should redeﬁne the trust - region subproblem in terms of the same norm , as follows : min p ∈ IR n m k ( p ) def (cid:3) f k + ∇ f kT p + 12 p T B k p subject to (cid:8) Dp (cid:8) ≤ (cid:6) k . ( 7 . 13 ) Making the change of variables ˆ p (cid:3) Dp and deﬁning ˆ g k (cid:3) D − T ∇ f k , ˆ B k (cid:3) D − T ( ∇ 2 f k ) D − 1 , we can write ( 7 . 13 ) as min ˆ p ∈ IR n f k + ˆ g Tk ˆ p + 12 ˆ p T ˆ B k ˆ p subject to (cid:8) ˆ p (cid:8) ≤ (cid:6) , whichhasexactlytheformof ( 7 . 11 ) . WecanapplyAlgorithm7 . 2withoutanymodiﬁcationto this subproblem , which is equivalent to applying a preconditioned version of Algorithm 7 . 2 to the problem ( 7 . 13 ) . Many preconditioners can be used within this framework ; we discuss some of them in Chapter 5 . Of particular interest is incomplete Cholesky factorization , which has proved useful in a wide range of optimization problems . The incomplete Cholesky factorization of a positive deﬁnite matrix B ﬁnds a lower triangular matrix L such that B (cid:3) LL T − R , where the amount of ﬁll - in in L is restricted in some way . ( For instance , it is constrained to have the same sparsity structure as the lower triangular part of B or is allowed to have a number of nonzero entries similar to that in B . ) The matrix R accounts for the inexactness in the approximate factorization . The situation is complicated somewhat by the possible indeﬁniteness of the Hessian ∇ 2 f k ; we must be able to handle this indeﬁniteness as well as maintain the sparsity . The following algorithm combines incomplete Cholesky and a form of modiﬁed Cholesky to deﬁne a preconditioner for the trust - region Newton – CG approach . Algorithm 7 . 3 ( Inexact Modiﬁed Cholesky ) . Compute T (cid:3) diag ( (cid:8) Be 1 (cid:8) , (cid:8) Be 2 (cid:8) , . . . , (cid:8) Be n (cid:8) ) , where e i is the i th coordinate vector ; Set ¯ B ← T − 1 / 2 BT − 1 / 2 ; Set β ← (cid:8) ¯ B (cid:8) ; 7 . 1 . I N E X A C T N E W T O N M E T H O D S 175 ( compute a shift to ensure positive deﬁniteness ) if min i b ii > 0 α 0 ← 0 else α 0 ← β / 2 ; for k (cid:3) 0 , 1 , 2 , . . . Attempt to apply incomplete Cholesky algorithm to obtain LL T (cid:3) ¯ B + α k I ; if the factorization is completed successfully stop and return L ; else α k + 1 ← max ( 2 α k , β / 2 ) ; end ( for ) We can then set the preconditioner to be D (cid:3) L T , where L is the lower triangular matrix output from Algorithm 7 . 3 . A trust - region Newton – CG method using this preconditioner is implemented in the LANCELOT [ 72 ] and TRON [ 192 ] codes . TRUST - REGION NEWTON – LANCZOS METHOD A limitation of Algorithm 7 . 2 is that it accepts any direction of negative curvature , even when this direction gives an insigniﬁcant reduction in the model . Consider , for example , the case where the subproblem ( 7 . 11 ) is min p m ( p ) (cid:3) 10 − 3 p 1 − 10 − 4 p 2 1 − p 2 2 subject to (cid:8) p (cid:8) ≤ 1 , where subscripts indicate elements of the vector p . The steepest descent direction at p (cid:3) 0 is ( − 10 − 3 , 0 ) T , which is a direction of negative curvature for the model . Algorithm 7 . 2 would follow this direction to the boundary of the trust region , yielding a reduction in model function m of about 10 − 3 . A step along e 2 —also a direction of negative curvature—would yield a much greater reduction of 1 . Several remedies have been proposed . We have seen in Chapter 4 that when the Hessian ∇ 2 f k contains negative eigenvalues , the search direction should have a signiﬁcant component along the eigenvector corresponding to the most negative eigenvalue of ∇ 2 f k . This feature would allow the algorithm to move away rapidly from stationary points that are not minimizers . One way to achieve this is to compute a nearly exact solution of the trust - region subproblem ( 7 . 11 ) using the techniques described in Section 4 . 3 . This approach requires the solution of a few linear systems with coefﬁcient matrices of the form 176 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N B k + λ I . Although this approach is perhaps too expensive in the large - scale case , it generates productive search directions in all cases . A more practical alternative is to use the Lanczos method ( see , for example , [ 136 ] ) rather than the CG method to solve the linear system B k p (cid:3) −∇ f k . The Lanczos method can be seen as a generalization of the CG method that is applicable to indeﬁnite systems , and we can use it to continue the CG process while gathering negative curvature information . After j steps , the Lanczos method generates an n × j matrix Q j with orthogonal columns that span the Krylov subspace ( 5 . 15 ) generated by this method . This matrix has the property that Q Tj BQ j (cid:3) T j , where T j is an tridiagonal . We can take advantage of this tridiagonal structure and seek to ﬁnd an approximate solution of the trust - region subproblem in the range of the basis Q j . To do so , we solve the problem min w ∈ IR j f k + e T 1 Q j ( ∇ f k ) e T 1 w + 12 w T T j w subject to (cid:8) w (cid:8) ≤ (cid:6) k , ( 7 . 14 ) where e 1 (cid:3) ( 1 , 0 , 0 , . . . , 0 ) T , and we deﬁne the approximate solution of the trust - region subproblem as p k (cid:3) Q j w . Since T j is tridiagonal , problem ( 7 . 14 ) can be solved by factoring the system T j + λ I and following the ( nearly ) exact approach of Section 4 . 3 . The Lanczos iteration may be terminated , as in the Newton – CG methods , by a test of the form ( 7 . 3 ) . Preconditioning can also be incorporated to accelerate the convergence of the Lanczos iteration . The additional robustness in this trust - region algorithm comes at the cost of a more expensive solution of the subproblem than in the Newton – CG approach . A sophisticated implementation of the Newton – Lanczos approach has been implemented in the GLTR package [ 145 ] . 7 . 2 LIMITED - MEMORY QUASI - NEWTON METHODS Limited - memory quasi - Newton methods are useful for solving large problems whose Hes - sian matrices cannot be computed at a reasonable cost or are not sparse . These methods maintain simple and compact approximations of Hessian matrices : Instead of storing fully dense n × n approximations , they save only a few vectors of length n that represent the approximations implicitly . Despite these modest storage requirements , they often yield an acceptable ( albeit linear ) rate of convergence . Various limited - memory methods have been proposed ; we focus mainly on an algorithm known as L - BFGS , which , as its name suggests , is based on the BFGS updating formula . The main idea of this method is to use curvature information from only the most recent iterations to construct the Hessian approximation . Curvature information from earlier iterations , which is less likely to be relevant to the ac - tual behavior of the Hessian at the current iteration , is discarded in the interest of saving storage . Following our discussion of L - BFGS and its convergence behavior , we discuss its relationship to the nonlinear conjugate gradient methods of Chapter 5 . We then discuss 7 . 2 . L I M I T E D - M E M O R Y Q U A S I - N E W T O N M E T H O D S 177 implementations of limited - memory schemes that make use of a compact representation of approximate Hessian information . These techniques can be applied not only to L - BFGS but also to limited - memory versions of other quasi - Newton procedures such as SR1 . Finally , we discuss quasi - Newton updating schemes that impose a particular sparsity pattern on the approximate Hessian . LIMITED - MEMORY BFGS We begin our description of the L - BFGS method by recalling its parent , the BFGS method , which was described in Algorithm 8 . 1 . Each step of the BFGS method has the form x k + 1 (cid:3) x k − α k H k ∇ f k , ( 7 . 15 ) where α k is the step length and H k is updated at every iteration by means of the formula H k + 1 (cid:3) V Tk H k V k + ρ k s k s Tk ( 7 . 16 ) ( see ( 6 . 17 ) ) , where ρ k (cid:3) 1 y Tk s k , V k (cid:3) I − ρ k y k s Tk , ( 7 . 17 ) and s k (cid:3) x k + 1 − x k , y k (cid:3) ∇ f k + 1 − ∇ f k . ( 7 . 18 ) Since the inverse Hessian approximation H k will generally be dense , the cost of storing and manipulating it is prohibitive when the number of variables is large . To circumvent this problem , we store a modiﬁed version of H k implicitly , by storing a certain number ( say , m ) of the vector pairs { s i , y i } used in the formulas ( 7 . 16 ) – ( 7 . 18 ) . The product H k ∇ f k can be obtained by performing a sequence of inner products and vector summations involving ∇ f k and the pairs { s i , y i } . After the new iterate is computed , the oldest vector pair in the set of pairs { s i , y i } is replaced by the new pair { s k , y k } obtained from the current step ( 7 . 18 ) . In this way , the set of vector pairs includes curvature information from the m most recent iterations . Practical experience has shown that modest values of m ( between 3 and 20 , say ) often produce satisfactory results . We now describe the updating process in a little more detail . At iteration k , the current iterate is x k and the set of vector pairs is given by { s i , y i } for i (cid:3) k − m , . . . , k − 1 . We ﬁrst choose some initial Hessian approximation H 0 k ( in contrast to the standard BFGS iteration , this initial approximation is allowed to vary from iteration to iteration ) and ﬁnd by repeated application of the formula ( 7 . 16 ) that the L - BFGS approximation H k satisﬁes the following 178 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N formula : H k (cid:3) (cid:7) V Tk − 1 · · · V Tk − m (cid:8) H 0 k ( V k − m · · · V k − 1 ) + ρ k − m (cid:7) V Tk − 1 · · · V Tk − m + 1 (cid:8) s k − m s Tk − m ( V k − m + 1 · · · V k − 1 ) + ρ k − m + 1 (cid:7) V Tk − 1 · · · V Tk − m + 2 (cid:8) s k − m + 1 s Tk − m + 1 ( V k − m + 2 · · · V k − 1 ) + · · · + ρ k − 1 s k − 1 s Tk − 1 . ( 7 . 19 ) From this expression we can derive a recursive procedure to compute the product H k ∇ f k efﬁciently . Algorithm 7 . 4 ( L - BFGS two - loop recursion ) . q ← ∇ f k ; for i (cid:3) k − 1 , k − 2 , . . . , k − m α i ← ρ i s Ti q ; q ← q − α i y i ; end ( for ) r ← H 0 k q ; for i (cid:3) k − m , k − m + 1 , . . . , k − 1 β ← ρ i y Ti r ; r ← r + s i ( α i − β ) end ( for ) stop with result H k ∇ f k (cid:3) r . Without considering the multiplication H 0 k q , the two - loop recursion scheme requires 4 mn multiplications ; if H 0 k is diagonal , then n additional multiplications are needed . Apart from being inexpensive , this recursion has the advantage that the multiplication by the initial matrix H 0 k is isolated from the rest of the computations , allowing this matrix to be chosen freely and to vary between iterations . We may even use an implicit choice of H 0 k by deﬁning some initial approximation B 0 k to the Hessian ( not its inverse ) and obtaining r by solving the system B 0 k r (cid:3) q . A method for choosing H 0 k that has proved effective in practice is to set H 0 k (cid:3) γ k I , where γ k (cid:3) s Tk − 1 y k − 1 y Tk − 1 y k − 1 . ( 7 . 20 ) As discussed in Chapter 6 , γ k is the scaling factor that attempts to estimate the size of the true Hessian matrix along the most recent search direction ( see ( 6 . 21 ) ) . This choice helps to ensure that the search direction p k is well scaled , and as a result the step length α k (cid:3) 1 is accepted in most iterations . As discussed in Chapter 6 , it is important that the line search be 7 . 2 . L I M I T E D - M E M O R Y Q U A S I - N E W T O N M E T H O D S 179 based on the Wolfe conditions ( 3 . 6 ) or strong Wolfe conditions ( 3 . 7 ) , so that BFGS updating is stable . The limited - memory BFGS algorithm can be stated formally as follows . Algorithm 7 . 5 ( L - BFGS ) . Choose starting point x 0 , integer m > 0 ; k ← 0 ; repeat Choose H 0 k ( for example , by using ( 7 . 20 ) ) ; Compute p k ← − H k ∇ f k from Algorithm 7 . 4 ; Compute x k + 1 ← x k + α k p k , where α k is chosen to satisfy the Wolfe conditions ; if k > m Discard the vector pair { s k − m , y k − m } from storage ; Compute and save s k ← x k + 1 − x k , y k (cid:3) ∇ f k + 1 − ∇ f k ; k ← k + 1 ; until convergence . The strategy of keeping the m most recent correction pairs { s i , y i } works well in practice ; indeed no other strategy has yet proved to be consistently better . During its ﬁrst m − 1 iterations , Algorithm 7 . 5 is equivalent to the BFGS algorithm of Chapter 6 if the initial matrix H 0 is the same in both methods , and if L - BFGS chooses H 0 k (cid:3) H 0 at each iteration . Table 7 . 1 presents results illustrating the behavior of Algorithm 7 . 5 for various levels of memory m . It gives the number of function and gradient evaluations ( nfg ) and the total CPU time . The test problems are taken from the CUTE collection [ 35 ] , the number of variables is indicated by n , and the termination criterion (cid:8)∇ f k (cid:8) ≤ 10 − 5 is used . The table shows that the algorithm tends to be less robust when m is small . As the amount of storage increases , the number of function evaluations tends to decrease ; but since the cost of each iteration increases with the amount of storage , the best CPU time is often obtained for small values of m . Clearly , the optimal choice of m is problem dependent . Because some rival algorithms are inefﬁcient , Algorithm 7 . 5 is often the approach of choice for large problems in which the true Hessian is not sparse . In particular , a Newton Table 7 . 1 Performance of Algorithm 7 . 5 . L - BFGS L - BFGS L - BFGS L - BFGS Problem n m (cid:3) 3 m (cid:3) 5 m (cid:3) 17 m (cid:3) 29 nfg time nfg time nfg time nfg time DIXMAANL 1500 146 16 . 5 134 17 . 4 120 28 . 2 125 44 . 4 EIGENALS 110 821 21 . 5 569 15 . 7 363 16 . 2 168 12 . 5 FREUROTH 1000 > 999 — > 999 — 69 8 . 1 38 6 . 3 TRIDIA 1000 876 46 . 6 611 41 . 4 531 84 . 6 462 127 . 1 180 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N method in which the exact Hessian is computed and factorized is not practical in such circumstances . The L - BFGS approach may also outperform Hessian - free Newton methods such as Newton – CG approaches , in which Hessian – vector products are calculated by ﬁnite differences or automatic differentiation . The main weakness of the L - BFGS method is that it converges slowly on ill - conditioned problems—speciﬁcally , on problems where the Hessian matrix contains a wide distribution of eigenvalues . On certain applications , the nonlinear conjugate gradient methods discussed in Chapter 5 are competitive with limited - memory quasi - Newton methods . RELATIONSHIP WITH CONJUGATE GRADIENT METHODS Limited - memory methods evolved as an attempt to improve nonlinear conjugate gradient methods , and early implementations resembled conjugate gradient methods more than quasi - Newton methods . The relationship between the two classes is the basis of a memoryless BFGS iteration , which we now outline . We start by considering the Hestenes – Stiefel form of the nonlinear conjugate gradient method ( 5 . 46 ) . Recalling that s k (cid:3) α k p k , we have that the search direction for this method is given by p k + 1 (cid:3) −∇ f k + 1 + ∇ f Tk + 1 y k y Tk p k p k (cid:3) − (cid:17) I − s k y Tk y Tk s k (cid:18) ∇ f k + 1 ≡ − ˆ H k + 1 ∇ f k + 1 . ( 7 . 21 ) This formula resembles a quasi - Newton iteration , but the matrix ˆ H k + 1 is neither symmetric nor positive deﬁnite . We could symmetrize it as ˆ H T k + 1 ˆ H k + 1 , but this matrix does not satisfy the secant equation ˆ H k + 1 y k (cid:3) s k and is , in any case , singular . An iteration matrix that is symmetric , positive deﬁnite , and satisﬁes the secant equation is given by H k + 1 (cid:3) (cid:17) I − s k y Tk y Tk s k (cid:18) (cid:17) I − y k s Tk y Tk s k (cid:18) + s k s Tk y Tk s k . ( 7 . 22 ) ThismatrixisexactlytheoneobtainedbyapplyingasingleBFGSupdate ( 7 . 16 ) totheidentity matrix . Hence , an algorithm whose search direction is given by p k + 1 (cid:3) − H k + 1 ∇ f k + 1 , with H k + 1 deﬁned by ( 7 . 22 ) , can be thought of as a “memoryless” BFGS method , in which the previous Hessian approximation is always reset to the identity matrix before updating it and where only the most recent correction pair ( s k , y k ) is kept at every iteration . Alternatively , we can view the method as a variant of Algorithm 7 . 5 in which m (cid:3) 1 and H 0 k (cid:3) I at each iteration . A more direct connection with conjugate gradient methods can be seen if we consider the memoryless BFGS formula ( 7 . 22 ) in conjunction with an exact line search , for which 7 . 2 . L I M I T E D - M E M O R Y Q U A S I - N E W T O N M E T H O D S 181 ∇ f Tk + 1 p k (cid:3) 0 for all k . We then obtain p k + 1 (cid:3) − H k + 1 ∇ f k + 1 (cid:3) −∇ f k + 1 + ∇ f Tk + 1 y k y Tk p k p k , ( 7 . 23 ) which is none other than the Hestenes – Stiefel conjugate gradient method . Moreover , it is easy to verify that when ∇ f T k + 1 p k (cid:3) 0 , the Hestenes – Stiefel formula reduces to the Polak – Ribi ` ere formula ( 5 . 44 ) . Even though the assumption of exact line searches is unrealistic , it is intriguing that the BFGS formula is related in this way to the Polak – Ribi ` ere and Hestenes – Stiefel methods . GENERAL LIMITED - MEMORY UPDATING Limited - memoryquasi - Newtonapproximationsareusefulinavarietyofoptimization methods . L - BFGS , Algorithm 7 . 5 , is a line search method for unconstrained optimization that ( implicitly ) updates an approximation H k to the inverse of the Hessian matrix . Trust - region methods , on the other hand , require an approximation B k to the Hessian matrix , not to its inverse . We would also like to develop limited - memory methods based on the SR1 formula , which is an attractive alternative to BFGS ; see Chapter 6 . In this section we consider limited - memory updating in a general setting and show that by representing quasi - Newton matrices in a compact ( or outer product ) form , we can derive efﬁcient implementations of all popular quasi - Newton update formulas , and their inverses . These compact representations will also be useful in designing limited - memory methods for constrained optimization , where approximations to the Hessian or reduced Hessian of the Lagrangian are needed ; see Chapter 18 and Chapter 19 . We will consider only limited - memory methods ( such as L - BFGS ) that continuously refresh the correction pairs by removing and adding information at each stage . A different approach saves correction pairs until the available storage is exhausted and then discards all correctionpairs ( exceptperhapsone ) andstartstheprocessanew . Computationalexperience suggests that this second approach is less effective in practice . Throughout this chapter we let B k denote an approximation to a Hessian matrix and H k the approximation to the inverse . In particular , we always have that B − 1 k (cid:3) H k . COMPACT REPRESENTATION OF BFGS UPDATING We now describe an approach to limited - memory updating that is based on repre - senting quasi - Newton matrices in outer - product form . We illustrate it for the case of a BFGS approximation B k to the Hessian . Theorem 7 . 4 . Let B 0 be symmetric and positive deﬁnite , and assume that the k vector pairs { s i , y i } k − 1 i (cid:3) 0 satisfy s Ti y i > 0 . Let B k be obtained by applying k BFGS updates with these vector pairs to B 0 , 182 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N using the formula ( 6 . 19 ) . We then have that B k (cid:3) B 0 − (cid:9) B 0 S k Y k (cid:10) (cid:1) S Tk B 0 S k L k L Tk − D k (cid:2) − 1 (cid:1) S Tk B 0 Y Tk (cid:2) , ( 7 . 24 ) where S k and Y k are the n × k matrices deﬁned by S k (cid:3) [ s 0 , . . . , s k − 1 ] , Y k (cid:3) [ y 0 , . . . , y k − 1 ] , ( 7 . 25 ) while L k and D k are the k × k matrices ( L k ) i , j (cid:3) (cid:21) s Ti − 1 y j − 1 if i > j , 0 otherwise , ( 7 . 26 ) D k (cid:3) diag (cid:9) s T 0 y 0 , . . . , s Tk − 1 y k − 1 (cid:10) . ( 7 . 27 ) This result can be proved by induction . We note that the conditions s Ti y i > 0 , i (cid:3) 0 , 1 , . . . , k − 1 , ensure that the middle matrix in ( 7 . 24 ) is nonsingular , so that this expres - sion is well deﬁned . The utility of this representation becomes apparent when we consider limited - memory updating . As in the L - BFGS algorithm , we keep the m most recent correction pairs { s i , y i } and refresh this set at every iteration by removing the oldest pair and adding a newly generated pair . During the ﬁrst m iterations , the update procedure described in Theorem 7 . 4 can be used without modiﬁcation , except that usually we make the speciﬁc choice B 0 k (cid:3) δ k I for the basic matrix , where δ k (cid:3) 1 / γ k and γ k is deﬁned by ( 7 . 20 ) . At subsequent iterations k > m , the update procedure needs to be modiﬁed slightly to reﬂectthechangingnatureofthesetofvectorpairs { s i , y i } for i (cid:3) k − m , k − m + 1 , . . . , k − 1 . Deﬁning the n × m matrices S k and Y k by S k (cid:3) [ s k − m , . . . , s k − 1 ] , Y k (cid:3) [ y k − m , . . . , y k − 1 ] , ( 7 . 28 ) we ﬁnd that the matrix B k resulting from m updates to the basic matrix B ( k ) 0 (cid:3) δ k I is given by B k (cid:3) δ k I − (cid:9) δ k S k Y k (cid:10) (cid:1) δ k S Tk S k L k L Tk − D k (cid:2) − 1 (cid:1) δ k S Tk Y Tk (cid:2) , ( 7 . 29 ) where L k and D k are now the m × m matrices deﬁned by ( L k ) i , j (cid:3) (cid:21) ( s k − m − 1 + i ) T ( y k − m − 1 + j ) if i > j , 0 otherwise , D k (cid:3) diag (cid:9) s Tk − m y k − m , . . . , s Tk − 1 y k − 1 (cid:10) . 7 . 2 . L I M I T E D - M E M O R Y Q U A S I - N E W T O N M E T H O D S 183 Bk = k I + δ Figure 7 . 1 Compact ( or outer product ) representation of B k in ( 7 . 29 ) . After the new iterate x k + 1 is generated , we obtain S k + 1 by deleting s k − m from S k and adding the new displacement s k , and we update Y k + 1 in a similar fashion . The new matrices L k + 1 and D k + 1 are obtained in an analogous way . Since the middle matrix in ( 7 . 29 ) is small—of dimension 2 m —its factorization re - quires a negligible amount of computation . The key idea behind the compact representation ( 7 . 29 ) is that the corrections to the basic matrix can be expressed as an outer product of two long and narrow matrices— [ δ k S k Y k ] and its transpose—with an intervening multiplication by a small 2 m × 2 m matrix . See Figure 7 . 1 for a graphical illustration . The limited - memory updating procedure of B k requires approximately 2 mn + O ( m 3 ) operations , and matrix – vector products of the form B k v can be performed at a cost of ( 4 m + 1 ) n + O ( m 2 ) multiplications . These operation counts indicate that updating and manipulating the direct limited - memory BFGS matrix B k is quite economical when m is small . This approximation B k can be used in a trust - region method for unconstrained opti - mization or , more signiﬁcantly , in methods for bound - constrained and general - constrained optimization . The program L - BFGS - B [ 322 ] makes extensive use of compact limited - memory approximations to solve large nonlinear optimization problems with bound constraints . In this situation , projections of B k into subspaces deﬁned by the constraint gradients must be calculated repeatedly . Several codes for general - constrained optimization , including KNITRO and IPOPT , make use of the compact limited - memory matrix B k to approximate the Hessian of the Lagrangians ; see Section 19 . 3 We can derive a formula , similar to ( 7 . 24 ) , that provides a compact representation of the inverse BFGS approximation H k ; see [ 52 ] for details . An implementation of the unconstrained L - BFGS algorithm based on this expression requires a similar amount of computation as the algorithm described in the previous section . Compact representations can also be derived for matrices generated by the symmetric rank - one ( SR1 ) formula . If k updates are applied to the symmetric matrix B 0 using the vector pairs { s i , y i } k − 1 i (cid:3) 0 and the SR1 formula ( 6 . 24 ) , the resulting matrix B k can be expressed as B k (cid:3) B 0 + ( Y k − B 0 S k ) ( D k + L k + L Tk − S Tk B 0 S k ) − 1 ( Y k − B 0 S k ) T , ( 7 . 30 ) 184 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N where S k , Y k , D k , and L k are as deﬁned in ( 7 . 25 ) , ( 7 . 26 ) , and ( 7 . 27 ) . Since the SR1 method is self - dual , the inverse formula H k can be obtained simply by replacing B , s , and y by H , y , and s , respectively . Limited - memory SR1 methods can be derived in the same way as the BFGS method . We replace B 0 with the basic matrix B 0 k at the k th iteration , and we redeﬁne S k and Y k to contain the m most recent corrections , as in ( 7 . 28 ) . We note , however , that limited - memory SR1 updating is sometimes not as effective as L - BFGS updating because it may not produce positive deﬁnite approximations near a solution . UNROLLING THE UPDATE The reader may wonder whether limited - memory updating can be implemented in simpler ways . In fact , as we show here , the most obvious implementation of limited - memoryBFGSupdatingisconsiderablymoreexpensivethantheapproachbasedoncompact representations discussed in the previous section . The direct BFGS formula ( 6 . 19 ) can be written as B k + 1 (cid:3) B k − a k a Tk + b k b Tk , ( 7 . 31 ) where the vectors a k and b k are deﬁned by a k (cid:3) B k s k ( s Tk B k s k ) 12 , b k (cid:3) y k ( y Tk s k ) 12 . ( 7 . 32 ) We could continue to save the vector pairs { s i , y i } but use the formula ( 7 . 31 ) to compute matrix – vector products . A limited - memory BFGS method that uses this approach would proceed by deﬁning the basic matrix B 0 k at each iteration and then updating according to the formula B k (cid:3) B 0 k + k − 1 (cid:3) i (cid:3) k − m (cid:9) b i b Ti − a i a Ti (cid:10) . ( 7 . 33 ) The vector pairs { a i , b i } , i (cid:3) k − m , k − m + 1 , . . . , k − 1 , would then be recovered from the stored vector pairs { s i , y i } , i (cid:3) k − m , k − m + 1 , . . . , k − 1 , by the following procedure : Procedure 7 . 6 ( Unrolling the BFGS formula ) . for i (cid:3) k − m , k − m + 1 , . . . , k − 1 b i ← y i / ( y Ti s i ) 1 / 2 ; a i ← B 0 k s i + (cid:4) i − 1 j (cid:3) k − m ) ( b Tj s i ) b j − ( a Tj s i ) a j * ; a i ← a i / ( s Ti a i ) 1 / 2 ; end ( for ) 7 . 3 . S P A R S E Q U A S I - N E W T O N U P D A T E S 185 Note that the vectors a i must be recomputed at each iteration because they all depend on the vector pair { s k − m , y k − m } , which is removed at the end of iteration k . On the other hand , the vectors b i and the inner products b Tj s i can be saved from the previous iteration , so only the new values b k − 1 and b Tj s k − 1 need to be computed at the current iteration . By taking all these computations into account , and assuming that B 0 k (cid:3) I , we ﬁnd that approximately 32 m 2 n operations are needed to determine the limited - memory matrix . The actual computation of the inner product B m v ( for arbitrary v ∈ IR n ) requires 4 mn multiplications . Overall , therefore , this approach is less efﬁcient than the one based on the compact matrix representation described previously . Indeed , while the product B k v costs the same in both cases , updating the representation of the limited - memory matrix by using the compact form requires only 2 mn multiplications , compared to 32 m 2 n multiplications needed when the BFGS formula is unrolled . 7 . 3 SPARSE QUASI - NEWTON UPDATES We now discuss a quasi - Newton approach to large - scale problems that has intuitive appeal : We demand that the quasi - Newton approximations B k have the same ( or similar ) sparsity pattern as the true Hessian . This approach would reduce the storage requirements of the algorithm and perhaps give rise to more accurate Hessian approximations . Suppose that we know which components of the Hessian may be nonzero at some point in the domain of interest . That is , we know the contents of the set (cid:22) deﬁned by (cid:22) def (cid:3) { ( i , j ) | [ ∇ 2 f ( x ) ] ij (cid:9)(cid:3) 0 for some x in the domain of f } . Suppose also that the current Hessian approximation B k mirrors the nonzero structure of the exact Hessian , that is , ( B k ) ij (cid:3) 0 for ( i , j ) / ∈ (cid:22) . In updating B k to B k + 1 , then , we could try to ﬁnd the matrix B k + 1 that satisﬁes the secant condition , has the same sparsity pattern , and is as close as possible to B k . Speciﬁcally , we deﬁne B k + 1 to be the solution of the following quadratic program : min B (cid:8) B − B k (cid:8) 2 F (cid:3) (cid:3) ( i , j ) ∈ (cid:22) [ B ij − ( B k ) ij ] 2 , ( 7 . 34a ) subject to Bs k (cid:3) y k , B (cid:3) B T , and B ij (cid:3) 0 for ( i , j ) / ∈ (cid:22) . ( 7 . 34b ) One can show that the solution B k + 1 of this problem can be obtained by solving an n × n linear system whose sparsity pattern is (cid:22) , the same as the sparsity of the true Hessian . Once B k + 1 has been computed , we can use it , within a trust - region method , to obtain the new iterate x k + 1 . We note that B k + 1 is not guaranteed to be positive deﬁnite . Weomitfurtherdetailsofthisapproachbecauseithasseveraldrawbacks . Theupdating process does not possess scale invariance under linear transformations of the variables and , 186 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N more signiﬁcantly , its practical performance has been disappointing . The fundamental weakness of this approach is that ( 7 . 34a ) is an inadequate model and can produce poor Hessian approximations . An alternative approach is to relax the secant equation , making sure that it is approx - imately satisﬁed along the last few steps rather than requiring it to hold strictly on the latest step . To do so , we deﬁne S k and Y k by ( 7 . 28 ) so that they contain the m most recent difference pairs . We can then deﬁne the new Hessian approximation B k + 1 to be the solution of min B (cid:8) BS k − Y k (cid:8) 2 F subject to B (cid:3) B T and B ij (cid:3) 0 for ( i , j ) / ∈ (cid:22) . This convex optimization problem has a solution , but it is not easy to compute . Moreover , this approach can produce singular or poorly conditioned Hessian approximations . Even though it frequently outperforms methods based on ( 7 . 34a ) , its performance on large problems has not been impressive . 7 . 4 ALGORITHMS FOR PARTIALLY SEPARABLE FUNCTIONS In a separable unconstrained optimization problem , the objective function can be decom - posed into a sum of simpler functions that can be optimized independently . For example , if we have f ( x ) (cid:3) f 1 ( x 1 , x 3 ) + f 2 ( x 2 , x 4 , x 6 ) + f 3 ( x 5 ) , we can ﬁnd the optimal value of x by minimizing each function f i , i (cid:3) 1 , 2 , 3 , indepen - dently , since no variable appears in more than one function . The cost of performing m lower - dimensional optimizations is much less in general than the cost of optimizing an n - dimensional function . In many large problems the objective function f : IR n → IR is not separable , but it can still be written as the sum of simpler functions , known as element functions . Each element function has the property that it is unaffected when we move along a large number of linearly independent directions . If this property holds , we say that f is partially separable . All functions whose Hessians ∇ 2 f are sparse are partially separable , but so are many functions whose Hessian is not sparse . Partial separability allows for economical problem representation , efﬁcient automatic differentiation , and effective quasi - Newton updating . The simplest form of partial separability arises when the objective function can be written as f ( x ) (cid:3) ne (cid:3) i (cid:3) 1 f i ( x ) , ( 7 . 35 ) 7 . 4 . A L G O R I T H M S F O R P A R T I A L L Y S E P A R A B L E F U N C T I O N S 187 where each of the element functions f i depends on only a few components of x . It follows that the gradients ∇ f i and Hessians ∇ 2 f i of each element function contain just a few nonzeros . By differentiating ( 7 . 35 ) , we obtain ∇ f ( x ) (cid:3) ne (cid:3) i (cid:3) 1 ∇ f i ( x ) , ∇ 2 f ( x ) (cid:3) ne (cid:3) i (cid:3) 1 ∇ 2 f i ( x ) . A natural question is whether it is more effective to maintain quasi - Newton approximations to each of the element Hessians ∇ 2 f i ( x ) separately , rather than approximating the entire Hessian ∇ 2 f ( x ) . Wewillshowthattheanswerisafﬁrmative , providedthatthequasi - Newton approximation fully exploits the structure of each element Hessian . We introduce the concept by means of a simple example . Consider the objective function f ( x ) (cid:3) ( x 1 − x 23 ) 2 + ( x 2 − x 24 ) 2 + ( x 3 − x 22 ) 2 + ( x 4 − x 21 ) 2 ( 7 . 36 ) ≡ f 1 ( x ) + f 2 ( x ) + f 3 ( x ) + f 4 ( x ) . The Hessians of the element functions f i are 4 × 4 sparse , singular matrices with 4 nonzero entries . Let us focus on f 1 ; all other element functions have exactly the same form . Even though f 1 is formally a function of all components of x , it depends only on x 1 and x 3 , which we call the element variables for f 1 . We assemble the element variables into a vector that we call x [ 1 ] , that is , x [ 1 ] (cid:3) (cid:1) x 1 x 3 (cid:2) , and note that x [ 1 ] (cid:3) U 1 x with U 1 (cid:3) (cid:1) 1 0 0 0 0 0 1 0 (cid:2) . If we deﬁne the function φ 1 by φ 1 ( z 1 , z 2 ) (cid:3) ( z 1 − z 2 2 ) 2 , then we can write f 1 ( x ) (cid:3) φ 1 ( U 1 x ) . By applying the chain rule to this representation , we obtain ∇ f 1 ( x ) (cid:3) U T 1 ∇ φ 1 ( U 1 x ) , ∇ 2 f 1 ( x ) (cid:3) U T 1 ∇ 2 φ 1 ( U 1 x ) U 1 . ( 7 . 37 ) 188 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N In our case , we have ∇ 2 φ 1 ( U 1 x ) (cid:3) (cid:1) 2 − 4 x 3 − 4 x 3 12 x 23 − 4 x 1 (cid:2) , ∇ 2 f 1 ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎣ 2 0 − 4 x 3 0 0 0 0 0 − 4 x 3 0 12 x 23 − 4 x 1 0 0 0 0 0 ⎤ ⎥⎥⎥⎥⎦ . The matrix U 1 , known as a compactifying matrix , allows us to map the derivative information for the low - dimensional function φ 1 into the derivative informationfor the element function f 1 . Now comes the key idea : Instead of maintaining a quasi - Newton approximation to ∇ 2 f 1 , we maintain a 2 × 2 quasi - Newton approximation B [ 1 ] of ∇ 2 φ 1 and use the relation ( 7 . 37 ) to transform it into a quasi - Newton approximation to ∇ 2 f 1 . To update B [ 1 ] after a typical step from x to x + , we record the information s [ 1 ] (cid:3) x + [ 1 ] − x [ 1 ] , y [ 1 ] (cid:3) ∇ φ 1 ( x + [ 1 ] ) − ∇ φ 1 ( x [ 1 ] ) , ( 7 . 38 ) and use BFGS or SR1 updating to obtain the new approximation B + [ 1 ] . We therefore update small , dense quasi - Newton approximations with the property B [ 1 ] ≈ ∇ 2 φ 1 ( U 1 x ) (cid:3) ∇ 2 φ 1 ( x [ 1 ] ) . ( 7 . 39 ) To obtain an approximation of the element Hessian ∇ 2 f 1 , we use the transformation suggested by the relationship ( 7 . 37 ) ; that is , ∇ 2 f 1 ( x ) ≈ U T 1 B [ 1 ] U 1 . This operation has the effect of mapping the elements of B [ 1 ] to the correct positions in the full n × n Hessian approximation . The previous discussion concerned only the ﬁrst element function f 1 , but we can treat all other functions f i in the same way . The full objective function can now be written as f ( x ) (cid:3) ne (cid:3) i (cid:3) 1 φ i ( U i x ) , ( 7 . 40 ) and we maintain a quasi - Newton approximation B [ i ] for each of the functions φ i . To obtain a complete approximation to the full Hessian ∇ 2 f , we simply sum the element Hessian approximations as follows : B (cid:3) ne (cid:3) i (cid:3) 1 U T i B [ i ] U i . ( 7 . 41 ) 7 . 5 . P E R S P E C T I V E S A N D S O F T W A R E 189 We may use this approximate Hessian in a trust - region algorithm , obtaining an approximate solution p k of the system B k p k (cid:3) −∇ f k . ( 7 . 42 ) We need not assemble B k explicitly but rather use the conjugate gradient approach to solve ( 7 . 42 ) , computing matrix – vector products of the form B k v by performing operations with the matrices U i and B [ i ] . To illustrate the usefulness of this element - by - element updating technique , let us consider a problem of the form ( 7 . 36 ) but this time involving 1000 variables , not just 4 . The functions φ i still depend on only two internal variables , so that each Hessian approximation B [ i ] is a 2 × 2 matrix . After just a few iterations , we will have sampled enough directions s [ i ] to make each B [ i ] an accurate approximation to ∇ 2 φ i . Hence the full quasi - Newton approximation ( 7 . 41 ) will tend to be a very good approximation to ∇ 2 f ( x ) . By contrast , a quasi - Newton method that ignores the partially separable structure of the objective function will attempt to estimate the total average curvature—the sum of the individual curvatures of the element functions—by approximating the 1000 × 1000 Hessian matrix . When the number of variables n is large , many iterations will be required before this quasi - Newton approximation is of good quality . Hence an algorithm of this type ( for example , standard BFGS or L - BFGS ) will require many more iterations than a method based on the partially separable approximate Hessian . It is not always possible to use the BFGS formula to update the partial Hessian B [ i ] , because there is no guarantee that the curvature condition s T [ i ] y [ i ] > 0 will be satisﬁed . That is , even though the full Hessian ∇ 2 f ( x ) is at least positive semideﬁnite at the solution x ∗ , someoftheindividualHessians ∇ 2 φ i ( · ) maybeindeﬁnite . Onewaytoovercomethisobstacle is to apply the SR1 update to each of the element Hessians . This approach has proved effective in the LANCELOT package [ 72 ] , which is designed to take full advantage of partial separability . The main limitations of this quasi - Newton approach are the cost of the step computa - tion ( 7 . 42 ) , which is comparable to the cost of a Newton step , and the difﬁculty of identifying the partially separable structure of a function . The performance of quasi - Newton methods is satisfactory provided that we ﬁnd the ﬁnest partially separable decomposition of the problem ; see [ 72 ] . Furthermore , even when the partially separable structure is known , it may be more efﬁcient to compute a Newton step . For example , the modeling language AMPL automatically detects the partially separable structure of a function f and uses it to compute the Hessian ∇ 2 f ( x ) . 7 . 5 PERSPECTIVES AND SOFTWARE Newton – CG methods have been used successfully to solve large problems in a vari - ety of applications . Many of these implementations are developed by engineers and 190 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N scientists and use problem - speciﬁc preconditioners . Freely available packages include TN / TNBC [ 220 ] and TNPACK [ 275 ] . Software for more general problems , such as LANCELOT [ 72 ] , KNITRO / CG [ 50 ] , and TRON [ 192 ] , employ Newton – CG methods when applied to unconstrained problems . Other packages , such as LOQO [ 294 ] implement Newton meth - ods with a sparse factorization modiﬁed to ensure positive deﬁniteness . GLTR [ 145 ] offers a Newton – Lanczos method . There is insufﬁcient experience to date to say whether the Newton – LanczosmethodissigniﬁcantlybetterinpracticethantheSteihaugstrategygivenin Algorithm 7 . 2 . Software for computing incomplete Cholesky preconditioners includes the ICFS [ 193 ] and MA 57 [ 166 ] packages . A preconditioner for Newton – CG based on limited - memory BFGS approximations is provided in PREQN [ 209 ] . Limited - memory BFGS methods are implemented in LBFGS [ 194 ] and M 1 QN 3 [ 122 ] ; see Gill and Leonard [ 125 ] for a variant that requires less storage and appears to be quite efﬁcient . The compact limited - memory representations of Section 7 . 2 are used in LBFGS - B [ 322 ] , IPOPT [ 301 ] , and KNITRO . The LANCELOT package exploits partial separability . It provides SR1 and BFGS quasi - Newton options as well as a Newton methods . The step computation is obtained by a preconditioned conjugate gradient iteration using trust regions . If f is partially separable , a general afﬁne transformation will not in general preserve the partially separable structure . The quasi - Newton method for partially separable functions described in Section 7 . 4 is not invariant to afﬁne transformations of the variables , but this is not a drawback because the method is invariant under transformations that preserve separability . NOTES AND REFERENCES A complete study of inexact Newton methods is given in [ 74 ] . For a discussion of the Newton – Lanczos method see [ 145 ] . Other iterative methods for the solution of a trust - region problem have been proposed by Hager [ 160 ] , and by Rendl and Wolkowicz [ 263 ] . For further discussion on the L - BFGS method see Nocedal [ 228 ] , Liu and Nocedal [ 194 ] , and Gilbert and Lemar´echal [ 122 ] . The last paper also discusses various ways in which the scaling parameter can be chosen . Algorithm 7 . 4 , the two - loop L - BFGS recursion , constitutesaneconomicalprocedureforcomputingtheproduct H k ∇ f k . Itisbased , however , on the speciﬁc form of the BFGS update formula ( 7 . 16 ) , and recursions of this type have not yet been developed ( and may not exist ) for other members of the Broyden class ( for instance , the SR1 and DFP methods ) . Our discussion of compact representations of limited - memory matrices is based on Byrd , Nocedal , and Schnabel [ 52 ] . Sparse quasi - Newton updates have been studied by Toint [ 288 , 289 ] and Fletcher et al . [ 102 , 104 ] , among others . The concept of partial separability was introduced by Griewank and Toint [ 156 , 155 ] . For an extensive treatment of the subject see Conn , Gould , and Toint [ 72 ] . 7 . 5 . P E R S P E C T I V E S A N D S O F T W A R E 191 ✐ E X E R C I S E S ✐ 7 . 1 Code Algorithm 7 . 5 , and test it on the extended Rosenbrock function f ( x ) (cid:3) n / 2 (cid:3) i (cid:3) 1 (cid:9) α ( x 2 i − x 22 i − 1 ) 2 + ( 1 − x 2 i − 1 ) 2 (cid:10) , where α is a parameter that you can vary ( for example , 1 or 100 ) . The solution is x ∗ (cid:3) ( 1 , 1 , . . . , 1 ) T , f ∗ (cid:3) 0 . Choose the starting point as ( − 1 , − 1 , . . . , − 1 ) T . Observe the behavior of your program for various values of the memory parameter m . ✐ 7 . 2 Show that the matrix ˆ H k + 1 in ( 7 . 21 ) is singular . ✐ 7 . 3 Derive the formula ( 7 . 23 ) under the assumption that line searches are exact . ✐ 7 . 4 Consider limited - memory SR1 updating based on ( 7 . 30 ) . Explain how the storage can be cut in half if the basic matrix B 0 k is kept ﬁxed for all k . ( Hint : Consider the matrix Q k (cid:3) [ q 0 , . . . , q k − 1 ] (cid:3) Y k − B 0 S k . ) ✐ 7 . 5 Write the function deﬁned by f ( x ) (cid:3) x 2 x 3 e x 1 + x 3 − x 4 + ( x 2 x 3 ) 2 + ( x 3 − x 4 ) in the form ( 7 . 40 ) . In particular , give the deﬁnition of each of the compactifying transformations U i . ✐ 7 . 6 Does the approximation B obtained by the partially separable quasi - Newton updating ( 7 . 38 ) , ( 7 . 41 ) satisfy the secant equation Bs (cid:3) y ? ✐ 7 . 7 The minimum surface problem is a classical application of the calculus of vari - ations and can be found in many textbooks . We wish to ﬁnd the surface of minimum area , deﬁned on the unit square , that interpolates a prescribed continuous function on the boundary of the square . In the standard discretization of this problem , the unknowns are the values of the sought - after function z ( x , y ) on a q × q rectangular mesh of points over the unit square . More speciﬁcally , we divide each edge of the square into q intervals of equal length , yielding ( q + 1 ) 2 grid points . We label the grid points as x ( i − 1 ) ( q + 1 ) + 1 , . . . , x i ( q + 1 ) for i (cid:3) 1 , 2 , . . . , q + 1 , so that each value of i generates a line . With each point we associate a variable z i that represents the height of the surface at this point . For the 4 q grid points on the boundary of the unit square , the values of these variables are determined by the given function . The 192 C H A P T E R 7 . L A R G E - S C A L E U N C O N S T R A I N E D O P T I M I Z A T I O N optimization problem is to determine the other ( q + 1 ) 2 − 4 q variables z i so that the total surface area is minimized . A typical subsquare in this partition looks as follows : x j + q + 1 x j + q + 2 x j x j + 1 We denote this square by A j and note that its area is q 2 . The desired function is z ( x , y ) , and we wish to compute its surface over A j . Calculus books show that the area of the surface is given by f j ( x ) ≡ (cid:6) (cid:6) ( x , y ) ∈ A j + 1 + (cid:17) ∂ z ∂ x (cid:18) 2 + (cid:17) ∂ z ∂ y (cid:18) 2 dx dy . Approximate the derivatives by ﬁnite differences , and show that f j has the form f j ( x ) (cid:3) 1 q 2 (cid:26) 1 + q 2 2 [ ( x j − x j + q + 1 ) 2 + ( x j + 1 − x j + q ) 2 ] (cid:27) 12 . ( 7 . 43 ) ✐ 7 . 8 Compute the gradient of the element function ( 7 . 43 ) with respect to the full vector x . Show that it contains at most four nonzeros , and that two of these four nonzero components are negatives of the other two . Compute the Hessian of f j , and show that , among the 16 nonzeros , only three different magnitudes are represented . Also show that this Hessian is singular . This is page 193 Printer : Opaque this C H A P T E R 8 Calculating Derivatives Most algorithms for nonlinear optimization and nonlinear equations require knowledge of derivatives . Sometimes the derivatives are easy to calculate by hand , and it is reasonable to expect the user to provide code to compute them . In other cases , the functions are too complicated , so we look for ways to calculate or approximate the derivatives automatically . A number of interesting approaches are available , of which the most important are probably the following . Finite Differencing . This technique has its roots in Taylor’s theorem ( see Chapter 2 ) . By observing the change in function values in response to small perturbations of the unknowns 194 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S near a given point x , we can estimate the response to inﬁntesimal perturbations , that is , the derivatives . For instance , the partial derivative of a smooth function f : IR n → IR with respect to the i th variable x i can be approximated by the central - difference formula ∂ f ∂ x i ≈ f ( x + (cid:9) e i ) − f ( x − (cid:9) e i ) 2 (cid:9) , where (cid:9) is a small positive scalar and e i is the i th unit vector , that is , the vector whose elements are all 0 except for a 1 in the i th position . Automatic Differentiation . This technique takes the view that the computer code for evaluating the function can be broken down into a composition of elementary arithmetic operations , to which the chain rule ( one of the basic rules of calculus ) can be applied . Some software tools for automatic differentiation ( such as ADIFOR [ 25 ] ) produce new code that calculates both function and derivative values . Other tools ( such as ADOL - C [ 154 ] ) keep a record of the elementary computations that take place while the function evaluation code for a given point x is executing on the computer . This information is processed to produce the derivatives at the same point x . Symbolic Differentiation . In this technique , the algebraic speciﬁcation for the function f is manipulated by symbolic manipulation tools to produce new algebraic expressions for each component of the gradient . Commonly used symbolic manipulation tools can be found in the packages Mathematica [ 311 ] , Maple [ 304 ] , and Macsyma [ 197 ] . In this chapter we discuss the ﬁrst two approaches : ﬁnite differencing and automatic differentiation . The usefulness of derivatives is not restricted to algorithms for optimization . Modelers in areas such as design optimization and economics are often interested in performing post - optimal sensitivity analysis , in which they determine the sensitivity of the optimum to small perturbations in the parameter or constraint values . Derivatives are also important in other areas such as nonlinear differential equations and simulation . 8 . 1 FINITE - DIFFERENCE DERIVATIVE APPROXIMATIONS Finite differencing is an approach to the calculation of approximate derivatives whose motivation ( like that of so many algorithms in optimization ) comes from Taylor’s theorem . Many software packages perform automatic calculation of ﬁnite differences whenever the user is unable or unwilling to supply code to calculate exact derivatives . Although they yield only approximate values for the derivatives , the results are adequate in many situations . Bydeﬁnition , derivativesareameasureofthesensitivityofthefunctiontoinﬁnitesimal changes in the values of the variables . Our approach in this section is to make small , ﬁnite perturbations in the values of x and examine the resulting differences in the function values . 8 . 1 . F I N I T E - D I F F E R E N C E D E R I V A T I V E A P P R O X I M A T I O N S 195 By taking ratios of the function difference to variable difference , we obtain approximations to the derivatives . APPROXIMATING THE GRADIENT An approximation to the gradient vector ∇ f ( x ) can be obtained by evaluating the function f at ( n + 1 ) points and performing some elementary arithmetic . We describe this technique , along with a more accurate variant that requires additional function evaluations . A popular formula for approximating the partial derivative ∂ f / ∂ x i at a given point x is the forward - difference , or one - sided - difference , approximation , deﬁned as ∂ f ∂ x i ( x ) ≈ f ( x + (cid:9) e i ) − f ( x ) (cid:9) . ( 8 . 1 ) The gradient can be built up by simply applying this formula for i (cid:3) 1 , 2 , . . . , n . This process requires evaluation of f at the point x as well as the n perturbed points x + (cid:9) e i , i (cid:3) 1 , 2 , . . . , n : a total of ( n + 1 ) points . The basis for the formula ( 8 . 1 ) is Taylor’s theorem , Theorem 2 . 1 in Chapter 2 . When f is twice continuously differentiable , we have f ( x + p ) (cid:3) f ( x ) + ∇ f ( x ) T p + 12 p T ∇ 2 f ( x + tp ) p , some t ∈ ( 0 , 1 ) ( 8 . 2 ) ( see ( 2 . 6 ) ) . If we choose L to be a bound on the size of (cid:8)∇ 2 f ( · ) (cid:8) in the region of interest , it follows directly from this formula that the last term in this expression is bounded by ( L / 2 ) (cid:8) p (cid:8) 2 , so that (cid:23)(cid:23) f ( x + p ) − f ( x ) − ∇ f ( x ) T p (cid:23)(cid:23) ≤ ( L / 2 ) (cid:8) p (cid:8) 2 . ( 8 . 3 ) We now choose the vector p to be (cid:9) e i , so that it represents a small change in the value of a single component of x ( the i th component ) . For this p , we have that ∇ f ( x ) T p (cid:3) ∇ f ( x ) T e i (cid:3) ∂ f / ∂ x i , so by rearranging ( 8 . 3 ) , we conclude that ∂ f ∂ x i ( x ) (cid:3) f ( x + (cid:9) e i ) − f ( x ) (cid:9) + δ (cid:9) , where | δ (cid:9) | ≤ ( L / 2 ) (cid:9) . ( 8 . 4 ) We derive the forward - difference formula ( 8 . 1 ) by simply ignoring the error term δ (cid:9) in this expression , which becomes smaller and smaller as (cid:9) approaches zero . An important issue in implementing the formula ( 8 . 1 ) is the choice of the parameter (cid:9) . The error expression ( 8 . 4 ) suggests that we should choose (cid:9) as small as possible . Unfor - tunately , this expression ignores the roundoff errors that are introduced when the function f is evaluated on a real computer , in ﬂoating - point arithmetic . From our discussion in the Appendix ( see ( A . 30 ) and ( A . 31 ) ) , we know that the quantity u known as unit roundoff 196 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S is crucial : It is a bound on the relative error that is introduced whenever an arithmetic operation is performed on two ﬂoating - point numbers . ( u is about 1 . 1 × 10 − 16 in double - precision IEEE ﬂoating - point arithmetic . ) The effect of these errors on the ﬁnal computed value of f depends on the way in which f is computed . It could come from an arithmetic formula , or from a differential equation solver , with or without reﬁnement . As a rough estimate , let us assume simply that the relative error in the computed f is bounded by u , so that the computed values of f ( x ) and f ( x + (cid:9) e i ) are related to the exact values in the following way : | comp ( f ( x ) ) − f ( x ) | ≤ u L f , | comp ( f ( x + (cid:9) e i ) ) − f ( x + (cid:9) e i ) | ≤ u L f , where comp ( · ) denotes the computed value , and L f is a bound on the value of | f ( · ) | in the region of interest . If we use these computed values of f in place of the exact values in ( 8 . 4 ) and ( 8 . 1 ) , we obtain an error that is bounded by ( L / 2 ) (cid:9) + 2 u L f / (cid:9) . ( 8 . 5 ) Naturally , we would like to choose (cid:9) to make this error as small as possible ; it is easy to see that the minimizing value is (cid:9) 2 (cid:3) 4 L f u L . If we assume that the problem is well scaled , then the ratio L f / L ( the ratio of function values to second derivative values ) does not exceed a modest size . We can conclude that the following choice of (cid:9) is fairly close to optimal : (cid:9) (cid:3) √ u . ( 8 . 6 ) ( In fact , this value is used in many of the optimization software packages that use ﬁnite differencing as an option for estimating derivatives . ) For this value of (cid:9) , we have from ( 8 . 5 ) that the total error in the forward - difference approximation is fairly close to √ u . A more accurate approximation to the derivative can be obtained by using the central - difference formula , deﬁned as ∂ f ∂ x i ( x ) ≈ f ( x + (cid:9) e i ) − f ( x − (cid:9) e i ) 2 (cid:9) . ( 8 . 7 ) As we show below , this approximation is more accurate than the forward - difference approx - imation ( 8 . 1 ) . It is also about twice as expensive , since we need to evaluate f at the points x and x ± (cid:9) e i , i (cid:3) 1 , 2 , . . . , n : a total of 2 n + 1 points . 8 . 1 . F I N I T E - D I F F E R E N C E D E R I V A T I V E A P P R O X I M A T I O N S 197 The basis for the central difference approximation is again Taylor’s theorem . When the second derivatives of f exist and are Lipschitz continuous , we have from ( 8 . 2 ) that f ( x + p ) (cid:3) f ( x ) + ∇ f ( x ) T p + 12 p T ∇ 2 f ( x + tp ) p for some t ∈ ( 0 , 1 ) (cid:3) f ( x ) + ∇ f ( x ) T p + 12 p T ∇ 2 f ( x ) p + O (cid:7) (cid:8) p (cid:8) 3 (cid:8) . ( 8 . 8 ) By setting p (cid:3) (cid:9) e i and p (cid:3) − (cid:9) e i , respectively , we obtain f ( x + (cid:9) e i ) (cid:3) f ( x ) + (cid:9) ∂ f ∂ x i + 1 2 (cid:9) 2 ∂ 2 f ∂ x 2 i + O (cid:7) (cid:9) 3 (cid:8) , f ( x − (cid:9) e i ) (cid:3) f ( x ) − (cid:9) ∂ f ∂ x i + 1 2 (cid:9) 2 ∂ 2 f ∂ x 2 i + O (cid:7) (cid:9) 3 (cid:8) . ( Note that the ﬁnal error terms in these two expressions are generally not the same , but they are both bounded by some multiple of (cid:9) 3 . ) By subtracting the second equation from the ﬁrst and dividing by 2 (cid:9) , we obtain the expression ∂ f ∂ x i ( x ) (cid:3) f ( x + (cid:9) e i ) − f ( x − (cid:9) e i ) 2 (cid:9) + O (cid:7) (cid:9) 2 (cid:8) . We see from this expression that the error is O (cid:7) (cid:9) 2 (cid:8) , as compared to the O ( (cid:9) ) error in the forward - difference formula ( 8 . 1 ) . However , when we take evaluation error in f into account , the accuracy that can be achieved in practice is less impressive ; the same assumptions that were used to derive ( 8 . 6 ) lead to an optimal choice of (cid:9) of about u 1 / 3 and an error of about u 2 / 3 . In some situations , the extra few digits of accuracy may improve the performance of the algorithm enough to make the extra expense worthwhile . APPROXIMATING A SPARSE JACOBIAN Consider now the case of a vector function r : IR n → IR m , such as the residual vector that we consider in Chapter 10 or the system of nonlinear equations from Chapter 11 . The matrix J ( x ) of ﬁrst derivatives for this function is deﬁned as follows : J ( x ) (cid:3) (cid:26) ∂ r j ∂ x i (cid:27) j (cid:3) 1 , 2 , . . . , m i (cid:3) 1 , 2 , . . . , n (cid:3) ⎡ ⎢⎢⎢⎢⎢⎣ ∇ r 1 ( x ) T ∇ r 2 ( x ) T . . . ∇ r m ( x ) T ⎤ ⎥⎥⎥⎥⎥⎦ , ( 8 . 9 ) where r j , j (cid:3) 1 , 2 , . . . , m are the components of r . The techniques described in the previous 198 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S section can be used to evaluate the full Jacobian J ( x ) one column at a time . When r is twice continuously differentiable , we can use Taylor’s theorem to deduce that (cid:8) r ( x + p ) − r ( x ) − J ( x ) p (cid:8) ≤ ( L / 2 ) (cid:8) p (cid:8) 2 , ( 8 . 10 ) where L is a Lipschitz constant for J in the region of interest . If we require an approximation to the Jacobian – vector product J ( x ) p for a given vector p ( as is the case with inexact Newton methods for nonlinear systems of equations ; see Section 11 . 1 ) , this expression immediately suggests choosing a small nonzero (cid:9) and setting J ( x ) p ≈ r ( x + (cid:9) p ) − r ( x ) (cid:9) , ( 8 . 11 ) an approximation that is accurate to O ( (cid:9) ) . A two - sided approximation can be derived from the formula ( 8 . 7 ) . If an approximation to the full Jacobian J ( x ) is required , we can compute it a column at a time , analogously to ( 8 . 1 ) , by setting set p (cid:3) (cid:9) e i in ( 8 . 10 ) to derive the following estimate of the i th column : ∂ r ∂ x i ( x ) ≈ r ( x + (cid:9) e i ) − r ( x ) (cid:9) . ( 8 . 12 ) A full Jacobian estimate can be obtained at a cost of n + 1 evaluations of the function r . When the Jacobian is sparse , however , we can often obtain the estimate at a much lower cost , sometimes just three or four evaluations of r . The key is to estimate a number of different columns of the Jacobian simultaneously , by judicious choices of the perturbation vector p in ( 8 . 10 ) . We illustrate the technique with a simple example . Consider the function r : IR n → IR n deﬁned by r ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢ ⎢⎣ 2 ( x 3 2 − x 2 1 ) 3 ( x 3 2 − x 2 1 ) + 2 ( x 3 3 − x 2 2 ) 3 ( x 3 3 − x 2 2 ) + 2 ( x 3 4 − x 2 3 ) . . . 3 ( x 3 n − x 2 n − 1 ) ⎤ ⎥⎥⎥⎥⎥⎥⎥ ⎥⎦ . ( 8 . 13 ) Each component of r depends on just two or three components of x , so that each row of the Jacobian contains only two or three nonzero elements . For the case of n (cid:3) 6 , the Jacobian 8 . 1 . F I N I T E - D I F F E R E N C E D E R I V A T I V E A P P R O X I M A T I O N S 199 has the following structure : ⎡ ⎢⎢⎢⎢⎢⎢⎢⎢ ⎢⎣ × × × × × × × × × × × × × × × × ⎤ ⎥⎥⎥⎥⎥⎥⎥⎥ ⎥⎦ , ( 8 . 14 ) where each cross represents a nonzero element , with zeros represented by a blank space . Staying for the moment with the case n (cid:3) 6 , suppose that we wish to compute a ﬁnite - difference approximation to the Jacobian . ( Of course , it is easy to calculate this particular Jacobian by hand , but there are complicated functions with similar structure for which hand calculation is more difﬁcult . ) A perturbation p (cid:3) (cid:9) e 1 to the ﬁrst component of x will affect only the ﬁrst and second components of r . The remaining components will be unchanged , so that the right - hand - side of formula ( 8 . 12 ) will correctly evaluate to zero in the components 3 , 4 , 5 , 6 . It is wasteful , however , to reevaluate these components of r when we know in advance that their values are not affected by the perturbation . Instead , we look for a way to modify the perturbation vector so that it does not have any further effect on components 1 and 2 , but does produce a change in some of the components 3 , 4 , 5 , 6 , which we can then use as the basis of a ﬁnite - difference estimate for some other column of the Jacobian . It is not hard to see that the additional perturbation (cid:9) e 4 has the desired property : It alters the 3rd , 4th , and 5th elements of r , but leaves the 1st and 2nd elements unchanged . The changes in r as a result of the perturbations (cid:9) e 1 and (cid:9) e 4 do not interfere with each other . To express this discussion in mathematical terms , we set p (cid:3) (cid:9) ( e 1 + e 4 ) , and note that r ( x + p ) 1 , 2 (cid:3) r ( x + (cid:9) ( e 1 + e 4 ) ) 1 , 2 (cid:3) r ( x + (cid:9) e 1 ) 1 , 2 ( 8 . 15 ) ( where the notation [ · ] 1 , 2 denotes the subvector consisting of the ﬁrst and second elements ) , while r ( x + p ) 3 , 4 , 5 (cid:3) r ( x + (cid:9) ( e 1 + e 4 ) ) 3 , 4 , 5 (cid:3) r ( x + (cid:9) e 4 ) 3 , 4 , 5 . ( 8 . 16 ) By substituting ( 8 . 15 ) into ( 8 . 10 ) , we obtain r ( x + p ) 1 , 2 (cid:3) r ( x ) 1 , 2 + (cid:9) [ J ( x ) e 1 ] 1 , 2 + O ( (cid:9) 2 ) . 200 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S By rearranging this expression , we obtain the following difference formula for estimating the ( 1 , 1 ) and ( 2 , 1 ) elements of the Jacobian matrix : ⎡ ⎢⎢⎣ ∂ r 1 ∂ x 1 ( x ) ∂ r 2 ∂ x 1 ( x ) ⎤ ⎥⎥⎦ (cid:3) [ J ( x ) e 1 ] 1 , 2 ≈ r ( x + p ) 1 , 2 − r ( x ) 1 , 2 (cid:9) . ( 8 . 17 ) A similar argument shows that the nonzero elements of the fourth column of the Jacobian can be estimated by substituting ( 8 . 16 ) into ( 8 . 10 ) ; we obtain ⎡ ⎢⎢⎢⎢⎢⎢⎣ ∂ r 4 ∂ x 3 ( x ) ∂ r 4 ∂ x 4 ( x ) ∂ r 4 ∂ x 5 ( x ) ⎤ ⎥⎥⎥⎥⎥⎥⎦ (cid:3) [ J ( x ) e 4 ] 3 , 4 , 5 ≈ r ( x + p ) 3 , 4 , 5 − r ( x ) 3 , 4 , 5 (cid:9) . ( 8 . 18 ) To summarize : We have been able to estimate two columns of the Jacobian J ( x ) by evaluating the function r at the single extra point x + (cid:9) ( e 1 + e 4 ) . We can approximate the remainder of J ( x ) in an economical manner as well . Columns 2 and 5 can be approximated by choosing p (cid:3) (cid:9) ( e 2 + e 5 ) , while we can use p (cid:3) (cid:9) ( e 3 + e 6 ) to approximate columns 3 and 6 . In total , we need 3 evaluations of the function r ( after the initial evaluation at x ) to estimate the entire Jacobian matrix . In fact , for any choice of n in ( 8 . 13 ) ( no matter how large ) , three extra evaluations of r are sufﬁcient to approximate the entire Jacobian . The corresponding choices of perturbation vectors p are p (cid:3) (cid:9) ( e 1 + e 4 + e 7 + e 10 + · · · ) , p (cid:3) (cid:9) ( e 2 + e 5 + e 8 + e 11 + · · · ) , p (cid:3) (cid:9) ( e 3 + e 6 + e 9 + e 12 + · · · ) . In the ﬁrst of these vectors , the nonzero components are chosen so that no two of the columns 1 , 4 , 7 , . . . have a nonzero element in the same row . The same property holds for the other two vectors and , in fact , points the way to the criterion that we can apply to general problems to decide on a valid set of perturbation vectors . Algorithms for choosing the perturbation vectors can be expressed conveniently in the language of graphs and graph coloring . For any function r : IR n → IR m , we can construct a column incidence graph G with n nodes by drawing an arc between nodes i and k if there is some component of r that depends on both x i and x k . In other words , the i th and k th columns of the Jacobian J ( x ) each have a nonzero element in some row j , for some j (cid:3) 1 , 2 , . . . , m and some value of x . ( The intersection graph for the function deﬁned in 8 . 1 . F I N I T E - D I F F E R E N C E D E R I V A T I V E A P P R O X I M A T I O N S 201 6 3 1 2 4 5 Figure 8 . 1 Column incidence graph for r ( x ) deﬁned in ( 8 . 13 ) . ( 8 . 13 ) , with n (cid:3) 6 , is shown in Figure 8 . 1 . ) We now assign each node a “color” according to the following rule : Two nodes can have the same color if there is no arc that connects them . Finally , we choose one perturbation vector corresponding to each color : If nodes i 1 , i 2 , . . . , i (cid:1) have the same color , the corresponding p is (cid:9) ( e i 1 + e i 2 + · · · + e i (cid:1) ) . Usually , there are many ways to assign colors to the n nodes in the graph in a way that satisﬁes the required condition . The simplest way is just to assign each node a different color , but since that scheme produces n perturbation vectors , it is usually not the most efﬁcient approach . It is generally very difﬁcult to ﬁnd the coloring scheme that uses the fewest possible colors , but there are simple algorithms that do a good job of ﬁnding a near - optimal coloring at low cost . Curtis , Powell , and Reid [ 83 ] and Coleman and Mor´e [ 68 ] provide descriptions of some methods and performance comparisons . Newsam and Ramsdell [ 227 ] show that by considering a more general class of perturbation vectors p , it is possible to evaluate the full Jacobian using no more than n z evaluations of r ( in addition to the evaluation at the point x ) , where n z is the maximum number of nonzeros in each row of J ( x ) . Forsomefunctions r withwell - studiedstructures ( thosethatarisefromdiscretizations of differential operators , or those that give rise to banded Jacobians , as in the example above ) , optimal coloring schemes are known . For the tridiagonal Jacobian of ( 8 . 14 ) andits associated graph in Figure 8 . 1 , the scheme with three colors is optimal . APPROXIMATING THE HESSIAN In some situations , the user may be able to provide a routine to calculate the gradient ∇ f ( x ) but not the Hessian ∇ 2 f ( x ) . We can obtain the Hessian by applying the techniques described above for the vector function r to the gradient ∇ f . By using the graph coloring techniques discussed above , sparse Hessians often can be approximated in this manner by using considerably fewer than n perturbation vectors . This approach ignores symmetry of the Hessian , and will usually produce a nonsymmetric approximation . We can recover 202 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S symmetry by adding the approximation to its transpose and dividing the result by 2 . Alternative differencing approaches that take symmetry of ∇ 2 f ( x ) explicitly into account are discussed below . Some important algorithms—most notably the Newton – CG methods described in Chapter 7—do not require knowledge of the full Hessian . Instead , each iteration requires us to supply the Hessian – vector product ∇ 2 f ( x ) p , for a given vector p . We can obtain an approximation to this matrix - vector product by appealing once again to Taylor’s theorem . When second derivatives of f exist and are Lipschitz continuous near x , we have ∇ f ( x + (cid:9) p ) (cid:3) ∇ f ( x ) + (cid:9) ∇ 2 f ( x ) p + O ( (cid:9) 2 ) , ( 8 . 19 ) so that ∇ 2 f ( x ) p ≈ ∇ f ( x + (cid:9) p ) − ∇ f ( x ) (cid:9) ( 8 . 20 ) ( see also ( 7 . 10 ) ) . The approximation error is O ( (cid:9) ) , and the cost of obtaining the approxi - mation is a single gradient evaluation at the point x + (cid:9) p . The formula ( 8 . 20 ) corresponds to the forward - difference approximation ( 8 . 1 ) . A central - difference formula like ( 8 . 7 ) can be derived by evaluating ∇ f ( x − (cid:9) p ) as well . For the case in which even gradients are not available , we can use Taylor’s theorem once again to derive formulae for approximating the Hessian that use only function values . The main tool is the formula ( 8 . 8 ) : By substituting the vectors p (cid:3) (cid:9) e i , p (cid:3) (cid:9) e j , and p (cid:3) (cid:9) ( e i + e j ) into this formula and combining the results appropriately , we obtain ∂ 2 f ∂ x i ∂ x j ( x ) (cid:3) f ( x + (cid:9) e i + (cid:9) e j ) − f ( x + (cid:9) e i ) − f ( x + (cid:9) e j ) + f ( x ) (cid:9) 2 + O ( (cid:9) ) . ( 8 . 21 ) If we wished to approximate every element of the Hessian with this formula , then we would need to evaluate f at x + (cid:9) ( e i + e j ) for all possible i and j ( a total of n ( n + 1 ) / 2 points ) as well as at the n points x + (cid:9) e i , i (cid:3) 1 , 2 , . . . , n . If the Hessian is sparse , we can , of course , reduce this operation count by skipping the evaluation whenever we know the element ∂ 2 f / ∂ x i ∂ x j to be zero . APPROXIMATING A SPARSE HESSIAN We noted above that a Hessian approximation can be obtained by applying ﬁnite - difference Jacobian estimation techniques to the gradient ∇ f , treated as a vector function . We now show how symmetry of the Hessian ∇ 2 f can be used to reduce the number of perturbation vectors p needed to obtain a complete approximation , when the Hessian is sparse . The key observation is that , because of symmetry , any estimate of the element [ ∇ 2 f ( x ) ] i , j (cid:3) ∂ 2 f ( x ) / ∂ x i ∂ x j is also an estimate of its symmetric counterpart [ ∇ 2 f ( x ) ] j , i . 8 . 1 . F I N I T E - D I F F E R E N C E D E R I V A T I V E A P P R O X I M A T I O N S 203 We illustrate the point with the simple function f : IR n → IR deﬁned by f ( x ) (cid:3) x 1 n (cid:3) i (cid:3) 1 i 2 x 2 i . ( 8 . 22 ) It is easy to show that the Hessian ∇ 2 f has the “arrowhead” structure depicted below , for the case of n (cid:3) 6 : ⎡ ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣ × × × × × × × × × × × × × × × × ⎤ ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ . ( 8 . 23 ) If we were to construct the intersection graph for the function ∇ f ( analogous to Figure 8 . 1 ) , we would ﬁnd that every node is connected to every other node , for the simple reason that row 1 has a nonzero in every column . According to the rule for coloring the graph , then , we would have to assign a different color to every node , which implies that we would need to evaluate ∇ f at the n + 1 points x and x + (cid:9) e i for i (cid:3) 1 , 2 , . . . , n . We can construct a much more efﬁcient scheme by taking the symmetry into account . Suppose we ﬁrst use the perturbation vector p (cid:3) (cid:9) e 1 to estimate the ﬁrst column of ∇ 2 f ( x ) . Because of symmetry , the same estimates apply to the ﬁrst row of ∇ 2 f . From ( 8 . 23 ) , we see that all that remains is to ﬁnd the diagonal elements ∇ 2 f ( x ) 22 , ∇ 2 f ( x ) 33 , . . . , ∇ 2 f ( x ) 66 . The intersection graph for these remaining elements is completely disconnected , so we can assign them all the same color and choose the corresponding perturbation vector to be p (cid:3) (cid:9) ( e 2 + e 3 + · · · + e 6 ) (cid:3) (cid:9) ( 0 , 1 , 1 , 1 , 1 , 1 ) T . ( 8 . 24 ) Note that the second component of ∇ f is not affected by the perturbations in components 3 , 4 , 5 , 6 of the unknown vector , while the third component of ∇ f is not affected by perturbations in components 2 , 4 , 5 , 6 of x , and so on . As in ( 8 . 15 ) and ( 8 . 16 ) , we have for each component i that ∇ f ( x + p ) i (cid:3) ∇ f ( x + (cid:9) ( e 2 + e 3 + · · · + e 6 ) ) i (cid:3) ∇ f ( x + (cid:9) e i ) i . By applying the forward - difference formula ( 8 . 1 ) to each of these individual components , we then obtain ∂ 2 f ∂ x 2 i ( x ) ≈ ∇ f ( x + (cid:9) e i ) i − ∇ f ( x ) i (cid:9) (cid:3) ∇ f ( x + (cid:9) p ) i − ∇ f ( x ) i (cid:9) , i (cid:3) 2 , 3 , . . . , 6 . 204 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S By exploiting symmetry , we have been able to estimate the entire Hessian by evaluating ∇ f only at x and two other points . Again , graph - coloring techniques can be used to choose the perturbation vectors p economically . We use the adjacency graph in place of the intersection graph described earlier . The adjacency graph has n nodes , with arcs connecting nodes i and k whenever i (cid:9)(cid:3) k and ∂ 2 f ( x ) / ( ∂ x i ∂ x k ) (cid:9)(cid:3) 0 for some x . The requirements on the coloring scheme are a little more complicated than before , however . We require not only that connected nodes have different colors , but also that any path of length 3 through the graph contain at least three colors . In other words , if there exist nodes i 1 , i 2 , i 3 , i 4 in the graph that are connected by arcs ( i 1 , i 2 ) , ( i 2 , i 3 ) , and ( i 3 , i 4 ) , then at least three different colors must be used in coloring these four nodes . See Coleman and Mor´e [ 69 ] for an explanation of this rule and for algorithms to compute valid colorings . The perturbation vectors are constructed as before : Whenever the nodes i 1 , i 2 , . . . , i (cid:1) have the same color , we set the corresponding perturbation vector to be p (cid:3) (cid:9) ( e i 1 + e i 2 + · · · + e i (cid:1) ) . 8 . 2 AUTOMATIC DIFFERENTIATION Automatic differentiation is the generic name for techniques that use the computational representation of a function to produce analytic values for the derivatives . Some techniques produce code for the derivatives at a general point x by manipulating the function code directly . Other techniques keep a record of the computations made during the evaluation of the function at a speciﬁc point x and then review this information to produce a set of derivatives at x . Automatic differentiation techniques are founded on the observation that any func - tion , nomatterhowcomplicated , isevaluatedbyperformingasequenceofsimpleelementary operations involving just one or two arguments at a time . Two - argument operations include addition , multiplication , division , andthe power operation a b . Examples of single - argument operationsincludethetrigonometric , exponential , andlogarithmicfunctions . Anothercom - mon ingredient of the various automatic differentiation tools is their use of the chain rule . This is the well - known rule from elementary calculus that says that if h is a function of the vector y ∈ IR m , which is in turn a function of the vector x ∈ IR n , we can write the derivative of h with respect to x as follows : ∇ x h ( y ( x ) ) (cid:3) m (cid:3) i (cid:3) 1 ∂ h ∂ y i ∇ y i ( x ) . ( 8 . 25 ) See Appendix A for further details . There are two basic modes of automatic differentiation : the forward and reverse modes . The difference between them can be illustrated by a simple example . We work through such 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 205 an example below , and indicate how the techniques can be extended to general functions , including vector functions . AN EXAMPLE Consider the following function of 3 variables : f ( x ) (cid:3) ( x 1 x 2 sin x 3 + e x 1 x 2 ) / x 3 . ( 8 . 26 ) Figure 8 . 2 shows how the evaluation of this function can be broken down into its elementary operations and also indicates the partial ordering associated with these operations . For instance , the multiplication x 1 ∗ x 2 must take place prior to the exponentiation e x 1 x 2 , or else we would obtain the incorrect result ( e x 1 ) x 2 . This graph introduces the intermediate variables x 4 , x 5 , . . . that contain the results of intermediate computations ; they are distinguished from the independent variables x 1 , x 2 , x 3 that appear at the left of the graph . We can express the evaluation of f in arithmetic terms as follows : x 4 (cid:3) x 1 ∗ x 2 , x 5 (cid:3) sin x 3 , x 6 (cid:3) e x 4 , x 7 (cid:3) x 4 ∗ x 5 , x 8 (cid:3) x 6 + x 7 , x 9 (cid:3) x 8 / x 3 . ( 8 . 27 ) The ﬁnal node x 9 in Figure 8 . 2 contains the function value f ( x ) . In the terminology of graph theory , node i is the parent of node j , and node j the child of node i , whenever there is a directed arc from i to j . Any node can be evaluated when the values of all its parents are known , so computation ﬂows through the graph from left to right . Flow of x 8 x 3 5 x x 7 4 x x 6 / exp * + * x 2 9 x x 1 sin Figure 8 . 2 Computational graph for f ( x ) deﬁned in ( 8 . 26 ) . 206 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S computation in this direction is known as a forward sweep . It is important to emphasize that software tools for automatic differentiation do not require the user to break down the code for evaluating the function into its elements , as in ( 8 . 27 ) . Identiﬁcation of intermediate quantitiesandconstructionofthecomputationalgraphiscarriedout , explicitlyorimplicitly , by the software tool itself . THE FORWARD MODE In the forward mode of automatic differentiation , we evaluate and carry forward a directional derivative of each intermediate variable x i in a given direction p ∈ IR n , simultaneously with the evaluation of x i itself . For the three - variable example above , we use the following notation for the directional derivative for p associated with each variable : D p x i def (cid:3) ( ∇ x i ) T p (cid:3) 3 (cid:3) j (cid:3) 1 ∂ x i ∂ x j p j , i (cid:3) 1 , 2 , . . . , 9 , ( 8 . 28 ) where ∇ indicates the gradient with respect to the three independent variables . Our goal is to evaluate D p x 9 , which is the same as the directional derivative ∇ f ( x ) T p . We note immediately that initial values D p x i for the independent variables x i , i (cid:3) 1 , 2 , 3 , are simply the components p 1 , p 2 , p 3 of p . The direction p is referred to as the seed vector . As soon as the value of x i at any node is known , we can ﬁnd the corresponding value of D p x i from the chain rule . For instance , suppose we know the values of x 4 , D p x 4 , x 5 , and D p x 5 , and we are about to calculate x 7 in Figure 8 . 2 . We have that x 7 (cid:3) x 4 x 5 ; that is , x 7 is a function of the two variables x 4 and x 5 , which in turn are functions of x 1 , x 2 , x 3 . By applying the rule ( 8 . 25 ) , we have that ∇ x 7 (cid:3) ∂ x 7 ∂ x 4 ∇ x 4 + ∂ x 7 ∂ x 5 ∇ x 5 (cid:3) x 5 ∇ x 4 + x 4 ∇ x 5 . Bytakingtheinnerproductofbothsidesofthisexpressionwith p andapplyingthedeﬁnition ( 8 . 28 ) , we obtain D p x 7 (cid:3) ∂ x 7 ∂ x 4 D p x 4 + ∂ x 7 ∂ x 5 D p x 5 (cid:3) x 5 D p x 4 + x 4 D p x 5 . ( 8 . 29 ) The directional derivatives D p x i are therefore evaluated side by side with the intermediate results x i , and at the end of the process we obtain D p x 9 (cid:3) D p f (cid:3) ∇ f ( x ) T p . The principle of the forward mode is straightforward enough , but what of its practical implementation and computational requirements ? First , we repeat that the user does not need to construct the computational graph , break the computation down into elementary operations as in ( 8 . 27 ) , or identify intermediate variables . The automatic differentiation software should perform these tasks implicitly and automatically . Nor is it necessary to store 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 207 the information x i and D p x i for every node of the computation graph at once ( which is just as well , since this graph can be very large for complicated functions ) . Once all the children of any node have been evaluated , its associated values x i and D p x i are not needed further and may be overwritten in storage . The key to practical implementation is the side - by - side evaluation of x i and D p x i . The automatic differentiation software associates a scalar D p w with any scalar w that appears in the evaluation code . Whenever w is used in an arithmetic computation , the software performs an associated operation ( based on the chain rule ) with the gradient vector D p w . For instance , if w is combined in a division operation with another value y to produce a new value z , that is , z ← w y , we use w , z , D p w , and D p y to evaluate the directional derivative D p z as follows : D p z ← 1 y D p w − w y 2 D p y . ( 8 . 30 ) Toobtainthecompletegradientvector , wecancarryoutthisproceduresimultaneously for the n seed vectors p (cid:3) e 1 , e 2 , . . . , e n . By the deﬁnition ( 8 . 28 ) , we see that p (cid:3) e j implies that D p f (cid:3) ∂ f / ∂ x j , j (cid:3) 1 , 2 , . . . , n . We note from the example ( 8 . 30 ) that the additional cost of evaluating f and ∇ f ( over the cost of evaluating f alone ) may be signiﬁcant . In this example , the single division operation on w and y needed to calculate z gives rise to approximately 2 n multiplications and n additions in the computation of the gradient elements D e j z , j (cid:3) 1 , 2 , . . . , n . It is difﬁcult to obtain an exact bound on the increase in computation , since the costs of retrieving and storing the data should also be taken into account . The storage requirements may also increase by a factor as large as n , since we now have to store n additional scalars D e j x i , j (cid:3) 1 , 2 , . . . , n , alongside each intermediate variable x i . It is usually possible to make savings by observing that many of these quantities are zero , particularly in the early stages of the computation ( that is , toward the left of the computational graph ) , so sparse data structures can be used to store the vectors D e j x i , j (cid:3) 1 , 2 , . . . , n ( see [ 27 ] ) . The forward mode of automatic differentiation can be implemented by means of a precompiler , which transforms function evaluation code into extended code that evaluates the derivative vectors as well . An alternative approach is to use the operator - overloading facilities available in languages such as C + + to transparently extend the data structures and operations in the manner described above . THE REVERSE MODE The reverse mode of automatic differentiation does not perform function and gradient evaluations concurrently . Instead , after the evaluation of f is complete , it recovers the partial 208 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S derivatives of f with respect to each variable x i —independent and intermediate variables alike—by performing a reverse sweep of the computational graph . At the conclusion of this process , the gradient vector ∇ f can be assembled from the partial derivatives ∂ f / ∂ x i with respect to the independent variables x i , i (cid:3) 1 , 2 , . . . , n . Instead of the gradient vectors D p x i used in the forward mode , the reverse mode associates a scalar variable ¯ x i with each node in the graph ; information about the partial derivative ∂ f / ∂ x i is accumulated in ¯ x i during the reverse sweep . The ¯ x i are sometimes called the adjoint variables , and we initialize their values to zero , with the exception of the rightmost node in the graph ( node N , say ) , for which we set ¯ x N (cid:3) 1 . This choice makes sense because x N contains the ﬁnal function value f , so we have ∂ f / ∂ x N (cid:3) 1 . The reverse sweep makes use of the following observation , which is again based on the chain rule ( 8 . 25 ) : For any node i , the partial derivative ∂ f / ∂ x i can be built up from the partial derivatives ∂ f / ∂ x j corresponding to its child nodes j according to the following formula : ∂ f ∂ x i (cid:3) (cid:3) j a child of i ∂ f ∂ x j ∂ x j ∂ x i . ( 8 . 31 ) For each node i , we add the right - hand - side term in ( 8 . 31 ) to ¯ x i as soon as it becomes known ; that is , we perform the operation ¯ x i + (cid:3) ∂ f ∂ x j ∂ x j ∂ x i . ( 8 . 32 ) ( In this expression and the ones below , we use the arithmetic notation of the programming language C , in which x + (cid:3) a means x ← x + a . ) Once contributions have been received from all the child nodes of i , we have ¯ x i (cid:3) ∂ f / ∂ x i , so we declare node i to be “ﬁnalized . ” At this point , node i is ready to contribute a term to the summation for each of its parent nodes according to the formula ( 8 . 31 ) . The process continues in this fashion until all nodes are ﬁnalized . Note that for derivative evaluation , the ﬂow of computation in the graph is from children to parents—the opposite direction to the computation ﬂow for function evaluation . During the reverse sweep , we work with numerical values , not with formulae or computer code involving the variables x i or the partial derivatives ∂ f / ∂ x i . During the forward sweep—the evaluation of f —we not only calculate the values of each variable x i , but we also calculate and store the numerical values of each partial derivative ∂ x j / ∂ x i . Each of these partial derivatives is associated with a particular arc of the computational graph . The numerical values of ∂ x j / ∂ x i computed during the forward sweep are then used in the formula ( 8 . 32 ) during the reverse sweep . We illustrate the reverse mode for the example function ( 8 . 26 ) . In Figure 8 . 3 we ﬁll in the graph of Figure 8 . 2 for a speciﬁc evaluation point x (cid:3) ( 1 , 2 , π / 2 ) T , indicating the 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 209 p ( 5 , 3 ) = 0 2 2 2 + e / 2 π p ( 9 , 8 ) = 2 / π 4 + 2e / 2 π p ( 9 , 3 ) = ( 84e ) / π 2 2 / p ( 7 , 4 ) = 1 p ( 6 , 4 ) = e p ( 4 , 2 ) = 1 p ( 8 , 6 ) = 1 * + * 1 2 p ( 7 , 5 ) = 2 p ( 8 , 7 ) = 1 p ( 4 , 1 ) = 2 sin exp 2 1 2 e Figure 8 . 3 Computational graph for f ( x ) deﬁned in ( 8 . 26 ) showing numerical values of intermediate values and partial derivatives for the point x (cid:3) ( 1 , 2 , π / 2 ) T . Notation : p ( j , i ) (cid:3) ∂ x j / ∂ x i . numerical values of the intermediate variables x 4 , x 5 , . . . , x 9 associated with each node and the partial derivatives ∂ x j / ∂ x i associated with each arc . As mentioned above , we initialize the reverse sweep by setting all the adjoint variables ¯ x i to zero , except for the rightmost node , for which we have ¯ x 9 (cid:3) 1 . Since f ( x ) (cid:3) x 9 and since node 9 has no children , we have ¯ x 9 (cid:3) ∂ f / ∂ x 9 , and so we can immediately declare node 9 to be ﬁnalized . Node 9 is the child of nodes 3 and 8 , so we use formula ( 8 . 32 ) to update the values of ¯ x 3 and ¯ x 8 as follows : ¯ x 3 + (cid:3) ∂ f ∂ x 9 ∂ x 9 ∂ x 3 (cid:3) − 2 + e 2 ( π / 2 ) 2 (cid:3) − 8 − 4 e 2 π 2 , ( 8 . 33a ) ¯ x 8 + (cid:3) ∂ f ∂ x 9 ∂ x 9 ∂ x 8 (cid:3) 1 π / 2 (cid:3) 2 π . ( 8 . 33b ) Node 3 is not ﬁnalized after this operation ; it still awaits a contribution from its other child , node 5 . On the other hand , node 9 is the only child of node 8 , so we can declare node 8 to be ﬁnalized with the value ∂ f ∂ x 8 (cid:3) 2 / π . We can now update the values of ¯ x i at the two parent nodes of node 8 by applying the formula ( 8 . 32 ) once again ; that is , ¯ x 6 + (cid:3) ∂ f ∂ x 8 ∂ x 8 ∂ x 6 (cid:3) 2 π ; ¯ x 7 + (cid:3) ∂ f ∂ x 8 ∂ x 8 ∂ x 7 (cid:3) 2 π . At this point , nodes 6 and 7 are ﬁnalized , so we can use them to update nodes 4 and 5 . At 210 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S the end of this process , when all nodes are ﬁnalized , nodes 1 , 2 , and 3 contain ⎡ ⎢⎣ ¯ x 1 ¯ x 2 ¯ x 3 ⎤ ⎥⎦ (cid:3) ∇ f ( x ) (cid:3) ⎡ ⎢⎣ ( 4 + 4 e 2 ) / π ( 2 + 2 e 2 ) / π ( − 8 − 4 e 2 ) / π 2 ⎤ ⎥⎦ , and the derivative computation is complete . The main appeal of the reverse mode is that its computational complexity is low for the scalar functions f : IR n → IR discussed here . The extra arithmetic associated with the gradient computation is at most four or ﬁve times the arithmetic needed to evaluate the function alone . Taking the division operation in ( 8 . 33 ) as an example , we see that two multiplications , a division , and an addition are required for ( 8 . 33a ) , while a division and an addition are required for ( 8 . 33b ) . This is about ﬁve times as much work as the single division involving these nodes that was performed during the forward sweep . As we noted above , the forward mode may require up to n times more arithmetic to compute the gradient ∇ f than to compute the function f alone , making it appear uncompetitive with the reverse mode . When we consider vector functions r : IR n → IR m , the relative costs of the forward and reverse modes become more similar as m increases , as we describe in the next section . Anapparentdrawbackofthereversemodeistheneedtostoretheentirecomputational graph , which is needed for the reverse sweep . In principle , storage of this graph is not too dif - ﬁcult to implement . Whenever an elementary operation is performed , we can form and store anewnodecontainingtheintermediateresult , pointerstothe ( oneortwo ) parentnodes , and the partial derivatives associated with these arcs . During the reverse sweep , the nodes can be read in the reverse order to that in which they were written , giving a particularly simple access pattern . The process of forming and writing the graph can be implemented as a straightfor - wardextensiontotheelementaryoperationsviaoperatoroverloading ( asinADOL - C [ 154 ] ) . The reverse sweep / gradient evaluation can be invoked as a simple function call . Unfortunately , the computational graph may require a huge amount of storage . If each node can be stored in 20 bytes , then a function that requires one second of evaluation time on a 100 megaﬂop computer may produce a graph of up to 2 gigabytes in size . The storage requirements can be reduced , at the cost of some extra arithmetic , by performing partial forward and reverse sweeps on pieces of the computational graph , reevaluating portions of the graph as needed rather than storing the whole structure . Descriptions of this approach , sometimesknownas checkpointing , canbefoundinGriewank [ 150 ] andGrimm , Pottier , and Rostaing - Schmidt [ 157 ] . An implementation of checkpointing in the context of variational data assimilation can be found in Restrepo , Leaf , and Griewank [ 264 ] . VECTOR FUNCTIONS AND PARTIAL SEPARABILITY So far , we have looked at automatic differentiation of general scalar - valued functions f : IR n → IR . In nonlinear least - squares problems ( Chapter 10 ) and nonlinear equations 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 211 ( Chapter 11 ) , we have to deal with vector functions r : IR n → IR m with m components r j , j (cid:3) 1 , 2 , . . . , m . The rightmost column of the computational graph then consists of m nodes , none of which has any children , in place of the single node described above . The forward and reverse modes can be adapted in straightforward ways to ﬁnd the Jacobian J ( x ) , the m × n matrix deﬁned in ( 8 . 9 ) . Besides their applications to least - squares and nonlinear - equations problems , auto - matic differentiation of vector functions is a useful technique for dealing with partially separable functions . We recall that partial separability is commonly observed in large - scale optimization , and we saw in Chapter 7 that there exist efﬁcient quasi - Newton procedures for the minimization of objective functions with this property . Since an automatic procedure for detecting the decomposition of a given function f into its partially separable representation was developed recently by Gay [ 118 ] , it has become possible to exploit the efﬁciencies that accrue from this property without asking much information from the user . In the simplest sense , a function f is partially separable if we can express it in the form f ( x ) (cid:3) ne (cid:3) i (cid:3) 1 f i ( x ) , ( 8 . 34 ) where each element function f i ( · ) depends on just a few components of x . If we construct the vector function r from the partially separable components , that is , r ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎣ f 1 ( x ) f 2 ( x ) . . . f ne ( x ) ⎤ ⎥⎥⎥⎥⎥⎦ , it follows from ( 8 . 34 ) that ∇ f ( x ) (cid:3) J ( x ) T e , ( 8 . 35 ) where , as usual , e (cid:3) ( 1 , 1 , . . . , 1 ) T . Because of the partial separability property , most columns of J ( x ) contain just a few nonzeros . This structure makes it possible to calculate J ( x ) efﬁciently by applying graph - coloring techniques , as we discuss below . The gradient ∇ f ( x ) can then be recovered from the formula ( 8 . 35 ) . In constrained optimization , it is often beneﬁcial to evaluate the objective function f andtheconstraintfunctions c i , i ∈ I ∪ E , simultaneously . Bydoingso , wecantakeadvantage of common expressions ( which show up as shared intermediate nodes in the computation graph ) and thus can reduce the total workload . In this case , the vector function r can be 212 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S deﬁned as r ( x ) (cid:3) (cid:1) f ( x ) (cid:9) c j ( x ) (cid:10) j ∈ I ∪ E (cid:2) . An example of shared intermediate nodes was seen in Figure 8 . 2 , where x 4 is shared during the computation of x 6 and x 7 . CALCULATING JACOBIANS OF VECTOR FUNCTIONS The forward mode is the same for vector functions as for scalar functions . Given a seed vector p , we continue to associate quantities D p x i with the node that calculates each intermediate variable x i . At each of the rightmost nodes ( containing r j , j (cid:3) 1 , 2 , . . . , m ) , this variable contains the quantity D p r j (cid:3) ( ∇ r j ) T p , j (cid:3) 1 , 2 , . . . , m . By assembling these m quantities , we obtain J ( x ) p , the product of the Jacobian and our chosen vector p . As in the case of scalar functions ( m (cid:3) 1 ) , we can evaluate the complete Jacobian by setting p (cid:3) e 1 , e 2 , . . . , e n and evaluating the n quantities D e j x i simultaneously . For sparse Jacobians , we can use the coloring techniques outlined above in the context of ﬁnite - difference methods to make more intelligent and economical choices of the seed vectors p . The factor of increase in cost of arithmetic , when compared to a single evaluation of r , is about equal to the number of seed vectors used . The key to applying the reverse mode to a vector function r ( x ) is to choose seed vectors q ∈ IR m and apply the reverse mode to the scalar functions r ( x ) T q . The result of this process is the vector ∇ [ r ( x ) T q ] (cid:3) ∇ ⎡ ⎣ m (cid:3) j (cid:3) 1 q j r j ( x ) ⎤ ⎦ (cid:3) J ( x ) T q . Instead of the Jacobian – vector product that we obtain with the forward mode , the reverse mode yields a Jacobian - transpose – vector product . The technique can be implemented by seeding the variables ¯ x i in the m dependent nodes that contain r 1 , r 2 , . . . , r m , with the components q 1 , q 2 , . . . , q m of the vector q . At the end of the reverse sweep , the node for independent variables x 1 , x 2 , . . . , x n will contain d dx i (cid:9) r ( x ) T q (cid:10) , i (cid:3) 1 , 2 , . . . , n , which are simply the components of J ( x ) T q . As usual , we can obtain the full Jacobian by carrying out the process above for the m unit vectors q (cid:3) e 1 , e 2 , . . . , e m . Alternatively , for sparse Jacobians , we can apply the usual coloring techniques to ﬁnd a smaller number of seed vectors q —the only difference being 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 213 that the graphs and coloring strategies are deﬁned with reference to the transpose J ( x ) T rather than to J ( x ) itself . The factor of increase in the number of arithmetic operations required , in comparison to an evaluation of r alone , is no more than 5 times the number of seed vectors . ( The factor of 5 is the usual overhead from the reverse mode for a scalar function . ) The space required for storage of the computational graph is no greater than in the scalar case . As before , we need only store the graph topology information together with the partial derivative associated with each arc . The forward - and reverse - mode techniques can be combined to cumulatively reveal all the elements of J ( x ) . We can choose a set of seed vectors p for the forward mode to reveal some columns of J , then perform the reverse mode with another set of seed vectors q to reveal the rows that contain the remaining elements . Finally , we note that for some algorithms , we do not need full knowledge of the Jacobian J ( x ) . For instance , iterative methods such as the inexact Newton method for nonlinear equations ( see Section 11 . 1 ) require repeated calculation of J ( x ) p for a succession of vectors p . Each such matrix – vector product can be computed using the forward mode by using a single forward sweep , at a similar cost to evaluation of the function alone . CALCULATING HESSIANS : FORWARD MODE So far , we have described how the forward and reverse modes can be applied to obtain ﬁrst derivatives of scalar and vector functions . We now outline extensions of these techniques to the computation of the Hessian ∇ 2 f of a scalar function f , and evaluation of the Hessian – vector product ∇ 2 f ( x ) p for a given vector p . Recall that the forward mode makes use of the quantities D p x i , each of which stores ( ∇ x i ) T p for each node i in the computational graph and a given vector p . For a given pair of seed vectors p and q ( both in IR n ) we now deﬁne another scalar quantity by D pq x i (cid:3) p T ( ∇ 2 x i ) q , ( 8 . 36 ) for each node i in the computational graph . We can evaluate these quantities during the forward sweep through the graph , alongside the function values x i and the ﬁrst - derivative values D p x i . The initial values of D pq at the independent variable nodes x i , i (cid:3) 1 , 2 . . . , n , will be 0 , since the second derivatives of x i are zero at each of these nodes . When the forward sweep is complete , the value of D pq x i in the rightmost node of the graph will be p T ∇ 2 f ( x ) q . The formulae for transformation of the D pq x i variables during the forward sweep can once again be derived from the chain rule . For instance , if x i is obtained by adding the values at its two parent nodes , x i (cid:3) x j + x k , the corresponding accumulation operations on D p x i and D pq x i are as follows : D p x i (cid:3) D p x j + D p x k , D pq x i (cid:3) D pq x j + D pq x k . ( 8 . 37 ) 214 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S The other binary operations − , × , / are handled similarly . If x i is obtained by applying the unitary transformation L to x j , we have x i (cid:3) L ( x j ) , ( 8 . 38a ) D p x i (cid:3) L (cid:14) ( x j ) ( D p x j ) , ( 8 . 38b ) D pq x i (cid:3) L (cid:14)(cid:14) ( x j ) ( D p x j ) ( D q x j ) + L (cid:14) ( x j ) D pq x j . ( 8 . 38c ) We see in ( 8 . 38c ) that computation of D pq x i can rely on the ﬁrst - derivative quantities D p x i and D q x i , so both these quantities must be accumulated during the forward sweep as well . We could compute a general dense Hessian by choosing the pairs ( p , q ) to be all possible pairs of unit vectors ( e j , e k ) , for j (cid:3) 1 , 2 , . . . , n and k (cid:3) 1 , 2 , . . . , j , a total of n ( n + 1 ) / 2 vector pairs . ( Note that we need only evaluate the lower triangle of ∇ 2 f ( x ) , because of symmetry . ) When we know the sparsity structure of ∇ 2 f ( x ) , we need evaluate D e j e k x i only for the pairs ( e j , e k ) for which the ( j , k ) component of ∇ 2 f ( x ) is possibly nonzero . The total increase factor for the number of arithmetic operations , compared with the amount of arithmetic to evaluate f alone , is a small multiple of 1 + n + N z ( ∇ 2 f ) , where N z ( ∇ 2 f ) is the number of elements of ∇ 2 f that we choose to evaluate . This number reﬂects the evaluation of the quantities x i , D e j x i ( j (cid:3) 1 , 2 , . . . , n ) , and D e j e k x i for the N z ( ∇ 2 f ) vector pairs ( e j , e k ) . The “small multiple” results from the fact that the update operations for D p x i and D pq x i may require a few times more operations than the update operation for x i alone ; see , for example , ( 8 . 38 ) . One storage location per node of the graph is required for each of the 1 + n + N z ( ∇ 2 f ) quantities that are accumulated , but recall that storage of node i can be overwritten once all its children have been evaluated . When we do not need the complete Hessian , but only a matrix – vector product involv - ing the Hessian ( as in the Newton – CG algorithm of Chapter 7 ) , the amount of arithmetic is , of course , smaller . Given a vector q ∈ IR n , we use the techniques above to compute the ﬁrst - derivative quantities D e 1 x i , . . . D e n x i and D q x i , as well as the second - derivative quantities D e 1 q x i , . . . , D e n q x i , during the forward sweep . The ﬁnal node will contain the quantities e Tj (cid:7) ∇ 2 f ( x ) (cid:8) q (cid:3) (cid:9) ∇ 2 f ( x ) q (cid:10) j , j (cid:3) 1 , 2 , . . . , n , which are the components of the vector ∇ 2 f ( x ) q . Since 2 n + 1 quantities in addition to x i are being accumulated during the forward sweep , the increase factor in the number of arithmetic operations increases by a small multiple of 2 n . An alternative technique for evaluating sparse Hessians is based on the forward - mode propagation of ﬁrst and second derivatives of univariate functions . To motivate this 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 215 approach , note that the ( i , j ) element of the Hessian can be expressed as follows : [ ∇ 2 f ( x ) ] ij (cid:3) e Ti ∇ 2 f ( x ) e j ( 8 . 39 ) (cid:3) 1 2 (cid:9) ( e i + e j ) T ∇ 2 f ( x ) ( e i + e j ) − e Ti ∇ 2 f ( x ) e i − e Tj ∇ 2 f ( x ) e j (cid:10) . We can use this interpolation formula to evaluate [ ∇ 2 f ( x ) ] ij , provided that the second derivatives D pp x k , for p (cid:3) e i , p (cid:3) e j , p (cid:3) e i + e j , and all nodes x k , have been evaluated during the forward sweep through the computational graph . In fact , we can evaluate all the nonzero elements of the Hessian , provided that we use the forward mode to evaluate D p x k and D pp x k for a selection of vectors p of the form e i + e j , where i and j are both indices in { 1 , 2 , . . . , n } , possibly with i (cid:3) j . One advantage of this approach is that it is no longer necessary to propagate “cross terms” of the form D pq x k for p (cid:9)(cid:3) q ( see , for example , ( 8 . 37 ) and ( 8 . 38c ) ) . The propagation formulae therefore simplify somewhat . Each D pp x k is a function of x (cid:1) , D p x (cid:1) , and D pp x (cid:1) for all parent nodes (cid:1) of node k . Note , too , that if we deﬁne the univariate function ψ by ψ ( t ) (cid:3) f ( x + tp ) , ( 8 . 40 ) then the values of D p f and D pp f , which emerge at the completion of the forward sweep , are simply the ﬁrst two derivatives of ψ evaluated at t (cid:3) 0 ; that is , D p f (cid:3) p T ∇ f ( x ) (cid:3) ψ (cid:14) ( t ) | t (cid:3) 0 , D pp f (cid:3) p T ∇ 2 f ( x ) p (cid:3) ψ (cid:14)(cid:14) ( t ) | t (cid:3) 0 . Extension of this technique to third , fourth , and higher derivatives is possible . Inter - polation formulae analogous to ( 8 . 39 ) can be used in conjunction with higher derivatives of the univariate functions ψ deﬁned in ( 8 . 40 ) , again for a suitably chosen set of vectors p , where each p is made up of a sum of unit vectors e i . For details , see Bischof , Corliss , and Griewank [ 26 ] . CALCULATING HESSIANS : REVERSE MODE We can also devise schemes based on the reverse mode for calculating Hessian – vector products ∇ 2 f ( x ) q , or the full Hessian ∇ 2 f ( x ) . A scheme for obtaining ∇ 2 f ( x ) q proceeds as follows . We start by using the forward mode to evaluate both f and ∇ f ( x ) T q , by accumulating the two variables x i and D q x i during the forward sweep in the manner described above . We then apply the reverse mode in the normal fashion to the computed function ∇ f ( x ) T q . At the end of the reverse sweep , the nodes i (cid:3) 1 , 2 , . . . , n of the computational graph that correspond to the independent variables will contain ∂ ∂ x i ( ∇ f ( x ) T q ) (cid:3) (cid:9) ∇ 2 f ( x ) q (cid:10) i , i (cid:3) 1 , 2 , . . . , n . 216 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S The number of arithmetic operations required to obtain ∇ 2 f ( x ) q by this procedure increases by only a modest factor , independent of n , over the evaluation of f alone . By the usual analysis for the forward mode , we see that the computation of f and ∇ f ( x ) T q jointly requires a small multiple of the operation count for f alone , while the reverse sweep introduces a further factor of at most 5 . The total increase factor is approximately 12 over the evaluation of f alone . If the entire Hessian ∇ 2 f ( x ) is required , we could apply the procedure just described with q (cid:3) e 1 , e 2 , . . . , e n . This approach would introduce an additional factor of n into the operation count , leading to an increase of at most 12 n over the cost of f alone . Once again , when the Hessian is sparse with known structure , we may be able to use graph - coloring techniques to evaluate this entire matrix using many fewer than n seed vectors . The choices of q are similar to those used for ﬁnite - difference evaluation of the Hessian , described above . The increase in operation count over evaluating f alone is a multiple of up to 12 N c ( ∇ 2 f ) , where N c is the number of seed vectors q used in calculating ∇ 2 f . CURRENT LIMITATIONS The current generation of automatic differentiation tools has proved its worth through successful application to some large and difﬁcult design optimization problems . However , these tools can run into difﬁculties with some commonly used programming constructs and some implementations of computer arithmetic . As an example , if the evaluation of f ( x ) depends on the solution of a partial differential equation ( PDE ) , then the computed value of f may contain truncation error arising from the ﬁnite - difference or the ﬁnite - element technique that is used to solve the PDE numerically . That is , we have ˆ f ( x ) (cid:3) f ( x ) + τ ( x ) , where ˆ f ( · ) is the computed value of f ( · ) and τ ( · ) is the truncation error . Though | τ ( x ) | is usually small , its derivative τ (cid:14) ( x ) may not be , so the error in the computed derivative ˆ f (cid:14) ( x ) is potentially large . ( The ﬁnite - difference approximation techniques discussed in Section 8 . 1 experience the same difﬁculty . ) Similar problems arise when the computer uses piecewise rational functions to approximate trigonometric functions . Another source of potential difﬁculty is the presence of branching in the code to improve the speed or accuracy of function evaluation in certain domains . A pathological example is provided by the linear function f ( x ) (cid:3) x − 1 . If we used the following ( perverse , but valid ) piece of code to evaluate this function , if ( x (cid:3) 1 . 0 ) then f (cid:3) 0 . 0 else f (cid:3) x − 1 . 0 , then by applying automatic differentiation to this procedure we would obtain the derivative value f (cid:14) ( 1 ) (cid:3) 0 . For a discussion of such issues and an approach to dealing with them , see Griewank [ 151 , 152 ] . In conclusion , automatic differentiation should be regarded as a set of increasingly sophisticatedtechniquesthatenhancesoptimizationalgorithms , allowingthemtobeapplied more widely to practical problems involving complicated functions . By providing sensitivity information , it helps the modeler to extract more information from the results of the 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 217 computation . Automatic differentiation should not be regarded as a panacea that absolves the user altogether from the responsibility of thinking about derivative calculations . NOTES AND REFERENCES A comprehensive and authoritative reference on automatic differentiation is the book of Griewank [ 152 ] . The web site www . autodiff . org contains a wealth of current infor - mation about theory , software , and applications . A number of edited collections of papers on automatic differentiation have appeared since 1991 ; see Griewank and Corliss [ 153 ] , Berz et al . [ 20 ] , and B¨ucker et al . [ 40 ] . An historical paper of note is Corliss and Rall [ 78 ] , which includes an extensive bibliography . Software tool development in automatic dif - ferentiation makes use not only of forward and reverse modes but also includes “mixed modes” and “cross - country algorithms” that combine the two approaches ; see for example Naumann [ 222 ] . The ﬁeld of automatic differentiation grew considerably during the 1990s , and and a number of good software tools appeared . These included ADIFOR [ 25 ] and ADIC [ 28 ] , and ADOL - C [ 154 ] . Tools developed in more recent years include TAPENADE , which accepts Fortran code through a web server and returns differentiated code ; TAF , a commercial tool that also performs source - to - source automatic differentiation of Fortran codes ; OpenAD , which works with Fortran , C , and C + + ; and TOMLAB / MAD , which works with MATLAB code . The technique for calculating the gradient of a partially separable function was de - scribed by Bischof et al . [ 24 ] , whereas the computation of the Hessian matrix has been considered by several authors ; see , for example , Gay [ 118 ] . The work of Coleman and Mor´e [ 69 ] on efﬁcient estimation of Hessians was predated by Powell and Toint [ 261 ] , who did not use the language of graph coloring but nevertheless devised highly effective schemes . Software for estimating sparse Hessians and Jacobians is described by Coleman , Garbow , and Mor´e [ 66 , 67 ] . The recent paper of Gebremedhin , Manne , and Pothen [ 120 ] contains a comprehensive discussion of the application of graph coloring to both ﬁnite difference and automatic differentiation techniques . ✐ E X E R C I S E S ✐ 8 . 1 Show that a suitable value for the perturbation (cid:9) in the central - difference formula is (cid:9) (cid:3) u 1 / 3 , and that the accuracy achievable by this formula when the values of f contain roundoff errors of size u is approximately u 2 / 3 . ( Use similar assumptions to the ones used to derive the estimate ( 8 . 6 ) for the forward - difference formula . ) ✐ 8 . 2 Derive a central - difference analogue of the Hessian – vector approximation formula ( 8 . 20 ) . 218 C H A P T E R 8 . C A L C U L A T I N G D E R I V A T I V E S ✐ 8 . 3 Verify the formula ( 8 . 21 ) for approximating an element of the Hessian using only function values . ✐ 8 . 4 Verify that if the Hessian of a function f has nonzero diagonal elements , then its adjacency graph is a subgraph of the intersection graph for ∇ f . In other words , show that any arc in the adjacency graph also belongs to the intersection graph . ✐ 8 . 5 Draw the adjacency graph for the function f deﬁned by ( 8 . 22 ) . Show that the coloring scheme in which node 1 has one color while nodes 2 , 3 , . . . , n have another color is valid . Draw the intersection graph for ∇ f . ✐ 8 . 6 Construct the adjacency graph for the function whose Hessian has the nonzero structure ⎡ ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣ × × × × × × × × × × × × × × × × × × ⎤ ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ , and ﬁnd a valid coloring scheme with just four colors . ✐ 8 . 7 Trace the computations performed in the forward mode for the function f ( x ) in ( 8 . 26 ) , expressing the intermediate derivatives ∇ x i , i (cid:3) 4 , 5 , . . . , 9 in terms of quantities available at their parent nodes and then in terms of the independent variables x 1 , x 2 , x 3 . ✐ 8 . 8 Formula ( 8 . 30 ) showed the gradient operations associated with scalar division . Derive similar formulae for the following operations : ( s , t ) → s + t addition ; t → e t exponentiation ; t → tan ( t ) tangent ; ( s , t ) → s t . ✐ 8 . 9 By calculating the partial derivatives ∂ x j / ∂ x i for the function ( 8 . 26 ) from the expressions ( 8 . 27 ) , verify the numerical values for the arcs in Figure 8 . 3 for the evaluation point x (cid:3) ( 1 , 2 , π / 2 ) T . Work through the remaining details of the reverse sweep process , indicating the order in which the nodes become ﬁnalized . 8 . 2 . A U T O M A T I C D I F F E R E N T I A T I O N 219 ✐ 8 . 10 Using ( 8 . 33 ) as a guide , describe the reverse sweep operations corresponding to the following elementary operations in the forward sweep : x k ← x i x j multiplication ; x k ← cos ( x i ) cosine . In each case , compare the arithmetic workload in the reverse sweep to the workload required for the forward sweep . ✐ 8 . 11 Deﬁne formulae similar to ( 8 . 37 ) for accumulating the ﬁrst derivatives D p x i and the second derivatives D pq x i when x i is obtained from the following three binary operations : x i (cid:3) x j − x k , x i (cid:3) x j x k , and x i (cid:3) x j / x k . ✐ 8 . 12 By using the deﬁnitions ( 8 . 28 ) of D p x i and ( 8 . 36 ) of D pq x i , verify the differentiation formulae ( 8 . 38 ) for the unitary operation x i (cid:3) L ( x j ) . ✐ 8 . 13 Let a ∈ IR n be a ﬁxed vector and deﬁne f as f ( x ) (cid:3) 12 (cid:29) x T x + (cid:7) a T x (cid:8) 2 (cid:30) . Count the number of operations needed to evaluate f , ∇ f , ∇ 2 f , and the Hessian – vector product ∇ 2 f ( x ) p for an arbitrary vector p . This is pag Printer : O C H A P T E R 9 Derivative - Free Optimization Many practical applications require the optimization of functions whose derivatives are not available . Problems of this kind can be solved , in principle , by approximating the gradient ( and possibly the Hessian ) using ﬁnite differences ( see Chapter 8 ) , and using these approximate gradients within the algorithms described in earlier chapters . Even though this ﬁnite - difference approach is effective in some applications , it cannot be regarded a general - purpose technique for derivative - free optimization because the number of function evaluations required can be excessive and the approach can be unreliable in the presence of noise . ( For the purposes of this chapter we deﬁne noise to be inaccuracy in the function evaluation . ) Because of these shortcomings , various algorithms have been developed that 9 . 1 . F I N I T E D I F F E R E N C E S A N D N O I S E 221 do not attempt to approximate the gradient . Rather , they use the function values at a set of sample points to determine a new iterate by some other means . Derivative - free optimization ( DFO ) algorithms differ in the way they use the sampled function values to determine the new iterate . One class of methods constructs a linear or quadratic model of the objective function and deﬁnes the next iterate by seeking to minimize this model inside a trust region . We pay particular attention to these model - based approaches because they are related to the unconstrained minimization methods described in earlier chapters . Other widely used DFO methods include the simplex - reﬂection method of Nelder and Mead , pattern - search methods , conjugate - direction methods , and simulated annealing . In this chapter we brieﬂy discuss these methods , with the exception of simulated annealing , which is a nondeterministic approach and has little in common with the other techniques discussed in this book . Derivative - free optimization methods are not as well developed as gradient - based methods ; current algorithms are effective only for small problems . Although most DFO methods have been adapted to handle simple types of constraints , such as bounds , the efﬁcient treatment of general constraints is still the subject of investigation . Consequently , we limit our discussion to the unconstrained optimization problem min x ∈ IR n f ( x ) . ( 9 . 1 ) Problems in which derivatives are not available arise often in practice . The evaluation of f ( x ) can , for example , be the result of an experimental measurement or a stochastic simulation , with the underlying analytic form of f unknown . Even if the objective function f is known in analytic form , coding its derivatives may be time consuming or impractical . Automatic differentiation tools ( Chapter 8 ) may not be applicable if f ( x ) is provided only in the form of binary computer code . Even when the source code is available , these tools cannot be applied if the code is written in a combination of languages . Methods for derivative - free optimization are often used ( with mixed success ) to minimize problems with nondifferentiable functions or to try to locate the global minimizer of a function . Since we do not treat nonsmooth optimization or global optimization in this book , we will restrict our attention to smooth problems in which f has a continuous derivative . We do , however , discuss the effects of noise in Sections 9 . 1 and 9 . 6 . 9 . 1 FINITE DIFFERENCES AND NOISE As mentioned above , an obvious DFO approach is to estimate the gradient by using ﬁnite differencesandthenemployagradient - basedmethod . Thisapproachissometimessuccessful and should always be considered , but the ﬁnite - difference estimates can be inaccurate when the objective function contains noise . We quantify the effect of noise in this section . Noise can arise in function evaluations for various reasons . If f ( x ) depends on a stochastic simulation , there will be a random error in the evaluated function because of the 222 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N ﬁnite number of trials in the simulation . When a differential equation solver or some other complex numerical procedure is needed to calculate f , small but nonzero error tolerances that are used during the calculations will produce noise in the value of f . In many applications , then , the objective function f has the form f ( x ) (cid:3) h ( x ) + φ ( x ) , ( 9 . 2 ) where h is a smooth function and φ represents the noise . Note that we have written φ to be a function of x but in practice it need not be . For instance , if the evaluation of f depends on a simulation , the value of φ will generally differ at each evaluation , even at the same x . The form ( 9 . 2 ) is , however , useful for illustrating some of the difﬁculties caused by noise in gradient estimates and for developing algorithms for derivative - free optimization . Given a difference interval (cid:9) , recall that the centered ﬁnite - difference approximation ( 8 . 7 ) to the gradient of f at x is deﬁned as follows : ∇ (cid:9) f ( x ) (cid:3) (cid:26) f ( x + (cid:9) e i ) − f ( x − (cid:9) e i ) 2 (cid:9) (cid:27) i (cid:3) 1 , 2 , . . . , n , ( 9 . 3 ) where e i is the i th unit vector ( the vector whose only nonzero element is a 1 in the i th position ) . We wish to relate ∇ (cid:9) f ( x ) to the gradient of the underlying smooth function h ( x ) , as a function of (cid:9) and the noise level . For this purpose we deﬁne the noise level η to be the largest value of φ in a box of edge length 2 (cid:9) centered at x , that is , η ( x ; (cid:9) ) (cid:3) sup (cid:8) z − x (cid:8) ∞ ≤ (cid:9) | φ ( z ) | . ( 9 . 4 ) By applying to the central difference formula ( 9 . 3 ) the argument that led to ( 8 . 5 ) , we can establish the following result . Lemma 9 . 1 . Suppose that ∇ 2 h is Lipschitz continuous in a neighborhood of the box { z | (cid:8) z − x (cid:8) ∞ ≤ (cid:9) } with Lipschitz constant L h . Then we have (cid:8)∇ (cid:9) f ( x ) − ∇ h ( x ) (cid:8) ∞ ≤ L h (cid:9) 2 + η ( x ; (cid:9) ) (cid:9) . ( 9 . 5 ) Thus the error in the approximation ( 9 . 3 ) comes from both the intrinsic ﬁnite difference approximation error ( the O ( (cid:9) 2 ) term ) and the noise ( the η ( x ; (cid:9) ) / (cid:9) term ) . If the noise dominates the difference interval (cid:9) , we cannot expect any accuracy at all in ∇ (cid:9) f ( x ) , so it will only be pure luck if −∇ (cid:9) f ( x ) turns out to be a direction of descent for f . Instead of computing a tight cluster of function values around the current iterate , as required by a ﬁnite - difference approximation to the gradient , it may be preferable to separate these points more widely and use them to construct a model of the objective function . This 9 . 2 . M O D E L - B A S E D M E T H O D S 223 approach , which we consider in the next section and in Section 9 . 6 , may be more robust to the presence of noise . 9 . 2 MODEL - BASED METHODS Some of the most effective algorithms for unconstrained optimization described in the previous chapters compute steps by minimizing a quadratic model of the objective function f . The model is formed by using function and derivative information at the current iterate . When derivatives are not available , we may deﬁne the model m k as the quadratic function that interpolates f at a set of appropriately chosen sample points . Since such a model is usually nonconvex , the model - based methods discussed in this chapter use a trust - region approach to compute the step . Suppose that at the current iterate x k we have a set of sample points Y (cid:3) { y 1 , y 2 , . . . , y q } , with y i ∈ IR n , i (cid:3) 1 , 2 , . . . , q . We assume that x k is an element of this set and that no point in Y has a lower function value than x k . We wish to construct a quadratic model of the form m k ( x k + p ) (cid:3) c + g T p + 12 p T Gp . ( 9 . 6 ) We cannot deﬁne g (cid:3) ∇ f ( x k ) and G (cid:3) ∇ 2 f ( x k ) because these derivatives are not available . Instead , we determine the scalar c , the vector g ∈ R n , and the symmetric matrix G ∈ R n × n by imposing the interpolation conditions m k ( y l ) (cid:3) f ( y l ) , l (cid:3) 1 , 2 , . . . , q . ( 9 . 7 ) Since there are 12 ( n + 1 ) ( n + 2 ) coefﬁcients in the model ( 9 . 6 ) ( that is , the components of c , g , and G , taking into account the symmetry of G ) , the interpolation conditions ( 9 . 7 ) determine m k uniquely only if q (cid:3) 1 2 ( n + 1 ) ( n + 2 ) . ( 9 . 8 ) In this case , ( 9 . 7 ) can be written as a square linear system of equations in the coefﬁcients of the model . If we choose the interpolation points y 1 , y 2 , . . . , y q so that this linear system is nonsingular , the model m k will be uniquely determined . Once m k has been formed , we compute a step p by approximately solving the trust - region subproblem min p m k ( x k + p ) , subject to (cid:8) p (cid:8) 2 ≤ (cid:6) , ( 9 . 9 ) for some trust - region radius (cid:6) > 0 . We can use one of the techniques described in Chapter 4 to solve this subproblem . If x k + p gives a sufﬁcient reduction in the objective function , 224 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N the new iterate is deﬁned as x k + 1 (cid:3) x k + p , the trust region radius (cid:6) is updated , and a new iteration commences . Otherwise the step is rejected , and the interpolation set Y may be improved or the trust region shrunk . To reduce the cost of the algorithm , we update the model m k at every iteration , rather than recomputing it from scratch . In practice , we choose a convenient basis for the space of quadratic polynomials , the most common choices being Lagrange and Newton polynomials . The properties of these bases can be used both to measure appropriateness of the sample set Y and to change this set if necessary . A complete algorithm that treats all these issues effectively is far more complicated than the quasi - Newton methods discussed in Chapter 6 . Consequently , we will provide only a broad outline of model - based DFO methods . As is common in trust - region algorithms , the step - acceptance and trust - region update strategies are based on the ratio between the actual reduction in the function and the reduction predicted by the model , that is , ρ (cid:3) f ( x k ) − f ( x + k ) m k ( x k ) − m k ( x + k ) , ( 9 . 10 ) where x + k denotes the trial point . Throughout this section , the integer q is deﬁned by ( 9 . 8 ) . Algorithm 9 . 1 ( Model - Based Derivative - Free Method ) . Choose an interpolation set Y (cid:3) { y 1 , y 2 , . . . , y q } such that the linear system deﬁned by ( 9 . 7 ) is nonsingular , and select x 0 as a point in this set such that f ( x 0 ) ≤ f ( y i ) for all y i ∈ Y . Choose an initial trust region radius (cid:6) 0 , a constant η ∈ ( 0 , 1 ) , and set k ← 0 . repeat until a convergence test is satisﬁed : Form the quadratic model m k ( x k + p ) that satisﬁes the interpolation conditions ( 9 . 7 ) ; Compute a step p by approximately solving subproblem ( 9 . 9 ) ; Deﬁne the trial point as x + k (cid:3) x k + p ; Compute the ratio ρ deﬁned by ( 9 . 10 ) ; if ρ ≥ η Replace an element of Y by x + k ; Choose (cid:6) k + 1 ≥ (cid:6) k ; Set x k + 1 ← x + k ; Set k ← k + 1 and go to the next iteration ; else if the set Y need not be improved Choose (cid:6) k + 1 < (cid:6) k ; Set x k + 1 ← x k ; Set k ← k + 1 and go to the next iteration ; end ( if ) 9 . 2 . M O D E L - B A S E D M E T H O D S 225 Invoke a geometry - improving procedure to update Y : at least one of the points in Y is replaced by some other point , with the goal of improving the conditioning of ( 9 . 7 ) ; Set (cid:6) k + 1 ← (cid:6) k ; Choose ˆ x as an element in Y with lowest function value ; Set x + k ← ˆ x and recompute ρ by ( 9 . 10 ) ; if ρ ≥ η Set x k + 1 ← x + k ; else Set x k + 1 ← x k ; end ( if ) Set k ← k + 1 ; end ( repeat ) The case of ρ ≥ η , in which we obtain sufﬁcient reduction in the merit function , is the simplest . In this case we always accept the trial point x + k as the new iterate , include x + k in Y , and remove an element from Y . When sufﬁcient reduction is not achieved ( ρ < η ) , we look at two possible causes : inadequacy of the interpolation set Y and a trust region that is too large . The ﬁrst cause can arise when the iterates become restricted to a low - dimensional surface of IR n that does not contain the solution . The algorithm could then be converging to a minimizer in this subset . Behavior such as this can be detected by monitoring the conditioning of the linear system deﬁned by the interpolation conditions ( 9 . 7 ) . If the condition number is too high , we change Y to improve it , typically by replacing one element of Y with a new element so as to move the interpolation system ( 9 . 7 ) as far away from singularity as possible . If Y seems adequate , we simply decrease the trust region radius (cid:6) , as is done in the methods of Chapter 4 . A good initial choice for Y is given by the vertices and the midpoints of the edges of a simplex in IR n . The use of quadratic models limits the size of problems that can be solved in practice . Performing O ( n 2 ) function evaluations just to start the algorithm is onerous , even for moderate values of n ( say , n (cid:3) 50 ) . In addition , the cost of the iteration is high . Even by updating the model m k at every iteration , rather than recomputing it from scratch , the number of operations required to construct m k and compute a step is O ( n 4 ) [ 257 ] . To alleviate these drawbacks , we can replace the quadratic model by a linear model in which the matrix G in ( 9 . 6 ) is set to zero . Since such a model contains only n + 1 parameters , we need to retain only n + 1 interpolation points in the set Y , and the cost of each iteration is O ( n 3 ) . Algorithm 9 . 1 can be applied with little modiﬁcation when the model is linear , but it is not rapidly convergent because linear models cannot represent curvature of the problem . Therefore , some model - based algorithms start with n + 1 initial points and compute steps 226 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N using a linear model , but after q (cid:3) 12 ( n + 1 ) ( n + 2 ) function values become available , they switch to using quadratic models . INTERPOLATION AND POLYNOMIAL BASES We now consider in more detail how to form a model of the objective function using interpolation techniques . We begin by considering a linear model of the form m k ( x k + p ) (cid:3) f ( x k ) + g T p . ( 9 . 11 ) To determine the vector g ∈ IR n , we impose the interpolation conditions m k ( y l ) (cid:3) f ( y l ) , l (cid:3) 1 , 2 , . . . , n , which can be written as ( s l ) T g (cid:3) f ( y l ) − f ( x k ) , l (cid:3) 1 , 2 , . . . , n , ( 9 . 12 ) where s l (cid:3) y l − x k , l (cid:3) 1 , 2 , . . . , n . ( 9 . 13 ) Conditions ( 9 . 12 ) represent a linear system of equations in which the rows of the coefﬁcient matrix are given by the vectors ( s l ) T . It follows that the model ( 9 . 11 ) is determined uniquely by ( 9 . 12 ) if and only if the interpolation points { y 1 , y 2 , . . . , y n } are such that the set { s l : l (cid:3) 1 , 2 , . . . , n } is linearly independent . If this condition holds , the simplex formed by the points x k , y 1 , y 2 , . . . , y n is said to be nondegenerate . Let us now consider how to construct a quadratic model of the form ( 9 . 6 ) , with f (cid:3) f ( x k ) . We rewrite the model as m k ( x k + p ) (cid:3) f ( x k ) + g T p + (cid:3) i < j G ij p i p j + 12 (cid:3) i G ii p 2 i ( 9 . 14 ) def (cid:3) f ( x k ) + ˆ g T ˆ p , ( 9 . 15 ) where we have collected the elements of g and G in the ( q − 1 ) - vector of unknowns ˆ g ≡ (cid:29) g T , { G ij } i < j , , 1 √ 2 G ii - (cid:30) T , ( 9 . 16 ) and where the ( q − 1 ) - vector ˆ p is given by ˆ p ≡ (cid:29) p T , { p i p j } i < j , , 1 √ 2 p 2 i - (cid:30) T . The model ( 9 . 15 ) has the same form as ( 9 . 11 ) , and the determination of the vector of unknown coefﬁcients ˆ g can be done as in the linear case . 9 . 2 . M O D E L - B A S E D M E T H O D S 227 Multivariate quadratic functions can be represented in various ways . The monomial basis ( 9 . 14 ) has the advantage that known structure in the Hessian can be imposed easily by setting appropriate elements in G to zero . Other bases are , however , more convenient when one is developing mechanisms for avoiding singularity of the system ( 9 . 7 ) . We denote by { φ i ( · ) } qi (cid:3) 1 a basis for the linear space of n - dimensional quadratic functions . The function ( 9 . 6 ) can therefore be expressed as m k ( x ) (cid:3) q (cid:3) i (cid:3) 1 α i φ i ( x ) , for some coefﬁcients α i . The interpolation set Y (cid:3) { y 1 , y 2 , . . . , y q } determines the coefﬁcients α i uniquely if the determinant δ ( Y ) def (cid:3) det ⎛ ⎜⎜⎝ φ 1 ( y 1 ) · · · φ 1 ( y q ) . . . . . . φ q ( y 1 ) · · · φ q ( y q ) ⎞ ⎟⎟⎠ ( 9 . 17 ) is nonzero . As model - based algorithms iterate , the determinant δ ( Y ) may approach zero , leading to numerical difﬁculties or even failure . Several algorithms therefore contain a mechanism for keeping the interpolation points well placed . We now describe one of those mechanisms . UPDATING THE INTERPOLATION SET Rather than waiting until the determinant δ ( Y ) becomes smaller than a threshold , we may invoke a geometry - improving procedure whenever a trial point does not provide sufﬁcient decrease in f . The goal in this case is to replace one of the interpolation points so that the determinant ( 9 . 17 ) increases in magnitude . To guide us in this exchange , we use the following property of δ ( Y ) , which we state in terms of Lagrange functions . For every y ∈ Y , we deﬁne the Lagrangian function L ( · , y ) to be a polynomial of degree at most 2 such that L ( y , y ) (cid:3) 1 and L ( ˆ y , y ) (cid:3) 0 for ˆ y (cid:9)(cid:3) y , ˆ y ∈ Y . Suppose that the set Y is updated by removing a point y − and replacing it by some other point y + , to give the new set Y + . One can show that ( after a suitable normalization and given certain conditions [ 256 ] ) | δ ( Y + ) | ≤ | L ( y + , y − ) | | δ ( Y ) | . ( 9 . 18 ) Algorithm 9 . 1 can make good use of this inequality to update the interpolation set . Consider ﬁrst the case in which trial point x + provides sufﬁcient reduction in the objective function ( ρ ≥ η ) . We include x + in Y and remove another point y − from Y . 228 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N Motivated by ( 9 . 18 ) , we select the outgoing point as follows : y − (cid:3) arg max y ∈ Y | L ( x + , y ) | . Next , let us consider the case in which the reduction in f is not sufﬁcient ( ρ < η ) . We ﬁrst determine whether the set Y should be improved , and for this purpose we use the following rule . We consider Y to be adequate at the current iterate x k if for all y i ∈ Y such that (cid:8) x k − y i (cid:8) ≤ (cid:6) we have that | δ ( Y ) | cannot be doubled by replacing one of these interpolation points y i with any point y inside the trust region . If Y is adequate but the reduction in f was not sufﬁcient , we decrease the trust - region radius and begin a new iteration . If Y is inadequate , the geometry - improving mechanism is invoked . We choose a point y − ∈ Y and replace it by some other point y + that is chosen solely with the objective of improving the determinant ( 9 . 17 ) . For every point y i ∈ Y , we deﬁne its potential replacement y ir as y ir (cid:3) arg max (cid:8) y − x k (cid:8)≤ (cid:6) | L ( y , y i ) | . The outgoing point y − is selected as the point for which | L ( y ir , y i ) | is maximized over all indices y i ∈ Y . Implementing these rules efﬁciently in practice is not simple , and one must also consider several possible difﬁculties we have not discussed ; see [ 76 ] . Strategies for improving the position of the interpolation set are the subject of ongoing investigation and new developments are likely in the coming years . A METHOD BASED ON MINIMUM - CHANGE UPDATING We now consider a method that be viewed as an extension of the quasi - Newton approach discussed in Chapter 6 . The method uses quadratic models but requires only O ( n 3 ) operations per iteration , substantially fewer than the O ( n 4 ) operations required by the methods described above . To achieve this economy , the method retains only O ( n ) points for the interpolation conditions ( 9 . 7 ) and absorbs the remaining degrees of freedom in the model ( 9 . 6 ) by requiring that the Hessian of the model change as little as possible from one iteration to the next . This least - change property is one of the key ingredients in quasi - Newton methods , the other ingredient being the requirement that the model interpolate the gradient ∇ f at the two most recent points . The method we describe now combines the least - change property with interpolation of function values . At the k th iteration of the algorithm , a new quadratic model m k + 1 of the form ( 9 . 6 ) is constructed after taking a step from x k to x k + 1 . The coefﬁcients f k + 1 , g k + 1 , G k + 1 of the 9 . 3 . C O O R D I N A T E A N D P A T T E R N - S E A R C H M E T H O D S 229 model m k + 1 are determined as the solution of the problem min f , g , G (cid:8) G − G k (cid:8) 2 F ( 9 . 19a ) subject to G symmetric m ( y l ) (cid:3) f ( y l ) l (cid:3) 1 , 2 , . . . , ˆ q , ( 9 . 19b ) where (cid:8) · (cid:8) F denotes the Frobenius norm ( see ( A . 9 ) ) , G k is the Hessian of the previous model m k , and ˆ q is an integer comparable to n . One can show that the integer ˆ q must be chosen larger than n + 1 to guarantee that G k + 1 is not equal to G k . An appropriate value in practice is ˆ q (cid:3) 2 n + 1 ; for this choice the number of interpolation points is roughly twice that used for linear models . Problem ( 9 . 19 ) is an equality - constrained quadratic program whose KKT conditions can be expressed as a system of equations . Once the model m k + 1 is determined , we compute a new step by solving a trust - region problem of the form ( 9 . 9 ) . In this approach , too , it is necessary to ensure that the geometry of the interpolation set Y is adequate . We therefore impose two minimum requirements . First , the set Y should be such that the equations ( 9 . 19b ) can be satisﬁed for any right - hand side . Second , the points y i should not all lie in a hyperplane . If these two conditions hold , problem ( 9 . 19 ) has a unique solution . A practical algorithm based on the subproblem ( 9 . 19 ) resembles Algorithm 9 . 1 in that it contains procedures both for generating new iterates and for improving the geometry of the set Y . The implementation described in [ 260 ] contains other features to ensure that the interpolation points are well separated and that steps are not too small . A strength of this method is that it requires only O ( n ) interpolation points to start producing productive steps . In practice the method often approaches a solution with fewer than 1 2 ( n + 1 ) ( n + 2 ) function evaluations . However , since this approach has been developed only recently , there is insufﬁcient numerical experience to assess its full potential . 9 . 3 COORDINATE AND PATTERN - SEARCH METHODS Rather than constructing a model of f explicitly based on function values , coordinate search and pattern - search methods look along certain speciﬁed directions from the current iterate for a point with a lower function value . If such a point is found , they step to it and repeat the process , possibly modifying the directions of search for the next iteration . If no satisfactory new point is found , the step length along the current search directions may be adjusted , or new search directions may be generated . We describe ﬁrst a simple approach of this type that has been used often in practice . We then consider a generalized approach that is potentially more efﬁcient and has stronger theoretical properties . 230 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N 0 x 1 x x * Figure 9 . 1 Coordinate search method makes slow progress on this function of two variables . COORDINATE SEARCH METHOD The coordinate search method ( also known as the coordinate descent method or the alternating variables method ) cycles through the n coordinate directions e 1 , e 2 , . . . , e n , obtaining new iterates by performing a line search along each direction in turn . Speciﬁcally , at the ﬁrst iteration , we ﬁx all components of x except the ﬁrst one x 1 and ﬁnd a new value of this component that minimizes ( or at least reduces ) the objective function . On the next iteration , we repeat the process with the second component x 2 , and so on . After n iterations , we return to the ﬁrst variable and repeat the cycle . Though simple and somewhat intuitive , this method can be quite inefﬁcient in practice , as we illustrate in Figure 9 . 1 for a quadratic function in two variables . Note that after a few iterations , neither the vertical ( x 2 ) nor the horizontal ( x 1 ) move makes much progress toward the solution at each iteration . In general , the coordinate search method can iterate inﬁnitely without ever approach - ing a point where the gradient of the objective function vanishes , even when exact line searches are used . ( By contrast , as we showed in Section 3 . 2 , the steepest descent method produces a sequence of iterates { x k } for which (cid:8)∇ f k (cid:8) → 0 , under reasonable assumptions . ) In fact , a cyclic search along any set of linearly independent directions does not guarantee global convergence [ 243 ] . Technically speaking , this difﬁculty arises because the steepest de - scent search direction −∇ f k may become more and more perpendicular to the coordinate search direction . In such circumstances , the Zoutendijk condition ( 3 . 14 ) is satisﬁed because cos θ k approaches zero rapidly , even when ∇ f k does not approach zero . When the coordinate search method does converge to a solution , it often converges much more slowly than the steepest descent method , and the difference between the two approaches tends to increase with the number of variables . However , coordinate search may 9 . 3 . C O O R D I N A T E A N D P A T T E R N - S E A R C H M E T H O D S 231 still be useful because it does not require calculation of the gradient ∇ f k , and the speed of convergence can be quite acceptable if the variables are loosely coupled in the objective function f . Many variants of the coordinate search method have been proposed , some of which allow a global convergence property to be proved . One simple variant is a “back - and - forth” approach in which we search along the sequence of directions e 1 , e 2 , . . . , e n − 1 , e n , e n − 1 , . . . , e 2 , e 1 , e 2 , . . . ( repeats ) . Another approach , suggested by Figure 9 . 1 , is ﬁrst to perform a sequence of coordinate descentstepsandthensearchalongthelinejoiningtheﬁrstandlastpointsinthecycle . Several algorithms , such as that of Hooke and Jeeves , are based on these ideas ; see Fletcher [ 101 ] and Gill , Murray , and Wright [ 130 ] . The pattern - search approach , described next , generalizes coordinate search in that it allows the use of a richer set of search directions at each iteration . PATTERN - SEARCH METHODS We consider pattern - search methods that choose a certain set of search directions at each iterate and evaluate f at a given step length along each of these directions . These candidate points form a “frame , ” or “stencil , ” around the current iterate . If a point with a signiﬁcantly lower function value is found , it is adopted as the new iterate , and the center of the frame is shifted to this new point . Whether shifted or not , the frame may then be altered in some way ( the set of search directions may be changed , or the step length may grow or shrink ) , and the process repeats . For certain methods of this type it is possible to prove global convergence results—typically , that there exists a stationary accumulation point . The presence of noise or other forms of inexactness in the function values may affect the performance of pattern - search algorithms and certainly impacts the convergence theory . Nonsmoothness may also cause undesirable behavior , as can be shown by simple examples , although satisfactory convergence is often observed on nonsmooth problems . To deﬁne pattern - search methods , we introduce some notation . For the current iterate x k , we deﬁne D k to be the set of possible search directions and γ k to be the line search parameter . The frame consists of the points x k + γ k p k , for all p k ∈ D k . When one of the points in the frame yields a signiﬁcant decrease in f , we take the step and may also increase γ k , so as to expand the frame for the next iteration . If none of the points in the frame has a signiﬁcantly better function value than f k , we reduce γ k ( contract the frame ) , set x k + 1 (cid:3) x k , and repeat . In either case , we may change the direction set D k prior to the next iteration , subject to certain restrictions . A more precise description of the algorithm follows . 232 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N Algorithm 9 . 2 ( Pattern - Search ) . Given convergence tolerance γ tol , contraction parameter θ max , sufﬁcient decrease function ρ : [ 0 , ∞ ) → IR with ρ ( t ) an increasing function of t and ρ ( t ) / t → 0 as t ↓ 0 ; Choose initial point x 0 , initial step length γ 0 > γ tol , initial direction set D 0 ; for k (cid:3) 1 , 2 , . . . if γ k ≤ γ tol stop ; if f ( x k + γ k p k ) < f ( x k ) − ρ ( γ k ) for some p k ∈ D k Set x k + 1 ← x k + γ k p k for some such p k ; Set γ k + 1 ← φ k γ k for some φ k ≥ 1 ; ( ∗ increase step length ∗ ) else Set x k + 1 ← x k ; Set γ k + 1 ← θ k γ k , where 0 < θ k ≤ θ max < 1 ; end ( if ) end ( for ) A wise choice of the direction set D k is crucial to the practical behavior of this approach and to the theoretical results that can be proved about it . A key condition is that at least one direction in this set should give a direction of descent for f whenever ∇ f ( x k ) (cid:9)(cid:3) 0 ( that is , whenever x k is not a stationary point ) . To make this condition speciﬁc , we refer to formula ( 3 . 12 ) , where we deﬁned the angle between a possible search direction d and the gradient ∇ f k as follows : cos θ (cid:3) −∇ f Tk p (cid:8)∇ f k (cid:8) (cid:8) p (cid:8) . ( 9 . 20 ) Recall from Theorem 3 . 2 that global convergence of a line - search method to a stationary point of f could be ensured if the search direction d at each iterate x k satisﬁed cos θ ≥ δ , for some constant δ > 0 , and if the line search parameter satisﬁed certain conditions . In the same spirit , we choose D k so that at least one direction p ∈ D k will yield cos θ > δ , regardless of the value of ∇ f k . This condition is as follows : κ ( D k ) def (cid:3) min v ∈ IR n max p ∈ D k v T p (cid:8) v (cid:8)(cid:8) p (cid:8) ≥ δ . ( 9 . 21 ) A second condition on D k is that the lengths of the vectors in this set are all roughly similar , so that the diameter of the frame formed by this set is captured adequately by the step length parameter γ k . Thus , we impose the condition β min ≤ (cid:8) p (cid:8) ≤ β max , for all p ∈ D k , ( 9 . 22 ) for some positive constants β min and β max and all k . If the conditions ( 9 . 21 ) and ( 9 . 22 ) hold , 9 . 3 . C O O R D I N A T E A N D P A T T E R N - S E A R C H M E T H O D S 233 we have for any k that −∇ f Tk p ≥ κ ( D k ) (cid:8)∇ f k (cid:8)(cid:8) p (cid:8) ≥ δβ min (cid:8)∇ f k (cid:8) , for some p ∈ D k . Examples of sets D k that satisfy the properties ( 9 . 21 ) and ( 9 . 22 ) include the coordinate direction set { e 1 , e 2 , . . . , e n , − e 1 , − e 2 , . . . , − e n } , ( 9 . 23 ) and the set of n + 1 vectors deﬁned by p i (cid:3) 1 2 n e − e i , i (cid:3) 1 , 2 , . . . , n ; p n + 1 (cid:3) 1 2 n e , ( 9 . 24 ) where e (cid:3) ( 1 , 1 , . . . , 1 ) T . For n (cid:3) 3 these direction sets are sketched in Figure 9 . 2 . The coordinate descent method described above is similar to the special case of Algorithm 9 . 2 obtained by setting D k (cid:3) { e i , − e i } for some i (cid:3) 1 , 2 , . . . , n at each iteration . Note that for this choice of D k , we have κ ( D k ) (cid:3) 0 for all k . Hence , as noted above , cos θ can be arbitrarily close to zero at each iteration . Often , the directions that satisfy the properties ( 9 . 21 ) and ( 9 . 22 ) form only a subset of the direction set D k , which may contain other directions as well . These additional directions could be chosen heuristically , according to some knowledge of the function f and its scaling , or according to experience on previous iterations . They could also be chosen as linear combinations of the core set of directions ( the ones that ensure δ > 0 ) . Note that Algorithm 9 . 2 does not require us to choose the point x k + γ k p k , p k ∈ D k , with the smallest objective value . Indeed , we may save on function evaluations by not evaluating f at all points in the frame , but rather performing the evaluations one at a time and accepting the ﬁrst candidate point that satisﬁes the sufﬁcient decrease condition . 1 2 3 e 3 2 e 1 e p 3 p 4 1 p p 2 Figure 9 . 2 Generating search sets in IR 3 : coordinate direction set ( left ) and simplex set ( right ) . 234 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N Another important detail in the implementation of Algorithm 9 . 2 is the choice of sufﬁcient decrease function ρ ( t ) . If ρ ( · ) is chosen to be identically zero , then any candidate pointthatproducesadecreasein f isacceptableasanewiterate . AswehaveseeninChapter3 , such a weak condition does not lead to strong global convergence results in general . A more appropriate choice might be ρ ( t ) (cid:3) Mt 3 / 2 , where M is some positive constant . 9 . 4 A CONJUGATE - DIRECTION METHOD We have seen in Chapter 5 that the minimizer of a strictly convex quadratic function f ( x ) (cid:3) 12 x T Ax − b T x ( 9 . 25 ) can be located by performing one - dimensional minimizations along a set of n conjugate directions . These directions were deﬁned in Chapter 5 as a linear combination of gradients . In this section , we show how to construct conjugate directions using only function values , and we therefore devise an algorithm for minimizing ( 9 . 25 ) that requires only function value calculations . Naturally , we also consider an extension of this approach to the case of a nonlinear objective f . We use the parallel subspace property , which we describe ﬁrst for the case n (cid:3) 2 . Consider two parallel lines l 1 ( α ) (cid:3) x 1 + α p and l 2 ( α ) (cid:3) x 2 + α p , where x 1 , x 2 , and p are given vectors in IR 2 and α is the scalar parameter that deﬁnes the lines . We show below that if x ∗ 1 and x ∗ 2 denote the minimizers of f ( x ) along l 1 and l 2 , respectively , then x ∗ 1 − x ∗ 2 is conjugate to p . Hence , if we perform a one - dimensional minimization along the line joining x ∗ 1 and x ∗ 2 , we will reach the minimizer of f , because we have successively minimized along the two conjugate directions p and x ∗ 2 − x ∗ 1 . This process is illustrated in Figure 9 . 3 . This observation suggests the following algorithm for minimizing a two - dimensional quadratic function f . We choose a set of linearly independent directions , say the coordinate directions e 1 and e 2 . From any initial point x 0 , we ﬁrst minimize f along e 2 to obtain the point x 1 . We then perform successive minimizations along e 1 and e 2 , starting from x 1 , to obtain the point z . It follows from the parallel subspace property that z − x 1 is conjugate to e 2 because x 1 and z are minimizers along two lines parallel to e 2 . Thus , if we perform a one - dimensional search from x 1 along the direction z − x 1 , we will locate the minimizer of f . We now state the parallel subspace minimization property in its most general form . Suppose that x 1 , x 2 are two distinct points in IR n and that { p 1 , p 2 , . . . , p l } is a set of linearly independent directions in IR n . Let us deﬁne the two parallel linear varieties S 1 (cid:3) (cid:21) x 1 + l (cid:3) i (cid:3) 1 α i p i | α i ∈ IR , i (cid:3) 1 , 2 , . . . , l (cid:22) , S 2 (cid:3) (cid:21) x 2 + l (cid:3) i (cid:3) 1 α i p i | α i ∈ IR , i (cid:3) 1 , 2 , . . . , l (cid:22) . 9 . 4 . A C O N J U G A T E - D I R E C T I O N M E T H O D 235 2 l 1 x * 1 x * 2 x * l Figure 9 . 3 Geometric construction of conjugate directions . ( The minimizer of f is denoted by x ∗ . ) If we denote the minimizers of f on S 1 and S 2 by x ∗ 1 and x ∗ 2 , respectively , then x ∗ 2 − x ∗ 1 is conjugate to p 1 , p 2 , . . . , p l . It is easy to verify this claim . By the minimization property , we have that ∂ f ( x ∗ 1 + α i p i ) ∂α i (cid:28)(cid:28)(cid:28)(cid:28) α i (cid:3) 0 (cid:3) ∇ f ( x ∗ 1 ) T p i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , l , and similarly for x 2 . Therefore we have from ( 9 . 25 ) that 0 (cid:3) ( ∇ f ( x ∗ 1 ) − ∇ f ( x ∗ 2 ) ) T p i (cid:3) ( Ax ∗ 1 − b − Ax ∗ 2 + b ) T p i (cid:3) ( x ∗ 1 − x ∗ 2 ) T Ap i , i (cid:3) 1 , 2 , . . . , l . ( 9 . 26 ) We now consider the case n (cid:3) 3 and show how the parallel subspace property can be used to generate a set of three conjugate directions . We choose a set of linearly independent directions , say e 1 , e 2 , e 3 . From any starting point x 0 we ﬁrst minimize f along the last direction e 3 to obtain a point x 1 . We then perform three successive one - dimensional minimizations , starting from x 1 , along the directions e 1 , e 2 , e 3 and denote the resulting point by z . Next , we minimize f along the direction p 1 (cid:3) z − x 1 to obtain x 2 . As noted earlier , p 1 (cid:3) z − x 1 is conjugate to e 3 . We note also that x 2 is the minimizer of f on the set S 1 (cid:3) { y + α 1 e 3 + α 2 p 1 | α 1 ∈ IR , α 2 ∈ IR } , where y is the intermediate point obtained after minimizing along e 1 and e 2 . A new iteration now commences . We discard e 1 and deﬁne the new set of search directions as e 2 , e 3 , p 1 . We perform one - dimensional minimizations along e 2 , e 3 , p 1 , starting 236 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N from x 2 , to obtain the point ˆ z . Note that ˆ z can be viewed as the minimizer of f on the set S 2 (cid:3) { ˆ y + α 1 e 3 + α 2 p 1 | α 1 ∈ IR , α 2 ∈ IR } , for some intermediate point ˆ y . Therefore , by applying the parallel subspace minimization property to the sets S 1 and S 2 just deﬁned , we have that p 2 (cid:3) ˆ z − x 2 is conjugate to both e 3 and p 1 . We then minimize f along p 2 to obtain a point x 3 , which is the minimizer of f . This procedure thus generates the conjugate directions e 3 , p 1 , p 2 . We can now state the general algorithm , which consists of an inner and an outer iteration . In the inner iteration , n one - dimensional minimizations are performed along a set of linearly independent directions . Upon completion of the inner iteration , a new conjugate direction is generated , which replaces one of the previously stored search directions . Algorithm 9 . 3 ( DFO Method of Conjugate Directions ) . Choose an initial point x 0 and set p i (cid:3) e i , for i (cid:3) 1 , 2 , . . . , n ; Compute x 1 as the minimizer of f along the line x 0 + α p n ; Set k ← 1 . repeat until a convergence test is satisﬁed Set z 1 ← x k ; for j (cid:3) 1 , 2 , . . . , n Calculate α j so that f ( z j + α j p j ) is minimized ; Set z j + 1 ← z j + α j p j ; end ( for ) Set p j ← p j + 1 for j (cid:3) 1 , 2 , . . . , n − 1 and p n ← z n + 1 − z 1 ; Calculate α n so that f ( z n + 1 + α n p n ) is minimized ; Set x k + 1 ← z n + 1 + α n p n ; Set k ← k + 1 ; end ( repeat ) The line searches can be performed by quadratic interpolation using three function values along each search direction . Since the restriction of ( 9 . 25 ) to a line is a ( strictly convex ) quadratic , the interpolating quadratic matches it exactly , and the one - dimensional minimizer can easily be computed . Note that at the end of ( the outer ) iteration k , the directions p n − k , p n − k + 1 , . . . , p n are conjugate by the property mentioned above . Thus the algorithm terminates at the minimizer of ( 9 . 25 ) after n − 1 iterations , provided none of the conjugate directions is zero . Unfortunately , this possibility cannot be ruled out , and some safeguards described below must be incorporated to improve robustness . In the ( usual ) case that Algorithm 9 . 3 terminates after n − 1 iterations , it will perform O ( n 2 ) function evaluations . Algorithm 9 . 3 can be extended to minimize nonquadratic objective functions . The only change is in the line search , which must be performed approximately , using interpola - tion . Because of the possible nonconvexity , this one - dimensional search must be done with care ; see Brent [ 39 ] for a treatment of this subject . Numerical experience indicates that this 9 . 4 . A C O N J U G A T E - D I R E C T I O N M E T H O D 237 extension of Algorithm 9 . 3 performs adequately for small - dimensional problems but that sometimes the directions { p i } tend to become linearly dependent . Several modiﬁcations of the algorithm have been proposed to guard against this possibility . One such modiﬁcation measures the degree to which the directions { p i } are conjugate . To do so , we deﬁne the scaled directions ˆ p i (cid:3) p i 0 p Ti Ap i , i (cid:3) 1 , 2 , . . . , n . ( 9 . 27 ) One can show [ 239 ] that the quantity | det ( ˆ p 1 , ˆ p 2 , . . . , ˆ p n ) | ( 9 . 28 ) is maximized if and only if the vectors p i are conjugate with respect to A . This result suggests that we should not replace one of the existing search directions in the set { p 1 , p 2 , . . . , p n } by the most recently generated conjugate direction if this action causes the quantity ( 9 . 28 ) to decrease . Procedure 9 . 4 implements this strategy for the case of the quadratic objective function ( 9 . 25 ) . Some algebraic manipulations ( which we do not present here ) show that we can compute the scaled directions ˆ p i without using the Hessian A because the terms p Ti Ap i are available from the line search along p i . Further , only comparisons using computed function values are needed to ensure that ( 9 . 28 ) does not increase . The following pro - cedure is invoked immediately after the execution of the inner iteration ( or for - loop ) of Algorithm 9 . 3 . Procedure 9 . 4 ( Updating of the Set of Directions ) . Find the integer m ∈ { 1 , 2 , . . . , n } such that ψ m (cid:3) f ( x m − 1 ) − f ( x m ) is maximized ; Let f 1 (cid:3) f ( z 1 ) , f 2 (cid:3) f ( z n + 1 ) , and f 3 (cid:3) f ( 2 z n + 1 − z 1 ) ; if f 3 ≥ f 1 or ( f 1 − 2 f 2 + f 3 ) ( f 1 − f 2 − ψ m ) 2 ≥ 1 2 ψ m ( f 1 − f 3 ) 2 Keep the set p 1 , p 2 , . . . , p n unchanged and set x k + 1 ← z n + 1 ; else Set ˆ p ← z n + 1 − z 1 and calculate ˆ α so that f ( z n + 1 + ˆ α ˆ p ) is minimized ; Set x k + 1 ← z n + 1 + α ˆ p ; Remove p m from the set of directions and add ˆ p to this set ; end ( if ) This procedure can be applied to general objective functions by implementing inexact one - dimensional line searches . The resulting conjugate - gradient method has been found to be useful for solving small dimensional problems . 238 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N 9 . 5 NELDER – MEAD METHOD The Nelder – Mead simplex - reﬂection method has been a popular DFO method since its introduction in 1965 [ 223 ] . It takes its name from the fact that at any stage of the algorithm , we keep track of n + 1 points of interest in IR n , whose convex hull forms a simplex . ( The method has nothing to do with the simplex method for linear programming discussed in Chapter 13 . ) Given a simplex S with vertices { z 1 , z 2 , . . . , z n + 1 } , we can deﬁne an as - sociated matrix V ( S ) by taking the n edges along V from one of its vertices ( z 1 , say ) , as follows : V ( S ) (cid:3) [ z 2 − z 1 , z 3 − z 1 , . . . , z n + 1 − z 1 ] . The simplex is said to be nondegenerate or nonsingular if V is a nonsingular matrix . ( For example , a simplex in IR 3 is nondegenerate if its four vertices are not coplanar . ) In a single iteration of the Nelder – Mead algorithm , we seek to remove the vertex with the worst function value and replace it with another point with a better value . The new point is obtained by reﬂecting , expanding , or contracting the simplex along the line joining the worst vertex with the centroid of the remaining vertices . If we cannot ﬁnd a better point in this manner , we retain only the vertex with the best function value , and we shrink the simplex by moving all other vertices toward this value . We specify a single step of the algorithm after some deﬁning some notation . The n + 1 vertices of the current simplex are denoted by { x 1 , x 2 , . . . , x n + 1 } , where we choose the ordering so that f ( x 1 ) ≤ f ( x 2 ) ≤ · · · ≤ f ( x n + 1 ) . The centroid of the best n points is denoted by ¯ x (cid:3) n (cid:3) i (cid:3) 1 x i . Points along the line joining ¯ x and the “worst” vertex x n + 1 are denoted by ¯ x ( t ) (cid:3) ¯ x + t ( x n + 1 − ¯ x ) . Procedure 9 . 5 ( One Step of Nelder – Mead Simplex ) . Compute the reﬂection point ¯ x ( − 1 ) and evaluate f − 1 (cid:3) f ( ¯ x ( − 1 ) ) ; if f ( x 1 ) ≤ f − 1 < f ( x n ) ( ∗ reﬂected point is neither best nor worst in the new simplex ∗ ) replace x n + 1 by ¯ x ( − 1 ) and go to next iteration ; else if f − 1 < f ( x 1 ) 9 . 5 . N E L D E R – M E A D M E T H O D 239 ( ∗ reﬂected point is better than the current best ; try to go farther along this direction ∗ ) Compute the expansion point ¯ x ( − 2 ) and evaluate f − 2 (cid:3) f ( ¯ x ( − 2 ) ) ; if f − 2 < f − 1 replace x n + 1 by x − 2 and go to next iteration ; else replace x n + 1 by x − 1 and go to next iteration ; else if f − 1 ≥ f ( x n ) ( ∗ reﬂected point is still worse than x n ; contract ∗ ) if f ( x n ) ≤ f − 1 < f ( x n + 1 ) ( ∗ try to perform “outside” contraction ∗ ) evaluate f − 1 / 2 (cid:3) ¯ x ( − 1 / 2 ) ; if f − 1 / 2 ≤ f − 1 replace x n + 1 by x − 1 / 2 and go to next iteration ; else ( ∗ try to perform “inside” contraction ∗ ) evaluate f 1 / 2 (cid:3) ¯ x ( 1 / 2 ) ; if f 1 / 2 < f n + 1 replace x n + 1 by x 1 / 2 and go to next iteration ; ( ∗ neither outside nor inside contraction was acceptable ; shrink the simplex toward x 1 ∗ ) replace x i ← ( 1 / 2 ) ( x 1 + x i ) for i (cid:3) 2 , 3 , . . . , n + 1 ; Procedure 9 . 5 is illustrated on a three - dimensional example in Figure 9 . 4 . The worst current vertex is x 3 , and the possible replacement points are ¯ x ( − 1 ) , ¯ x ( − 2 ) , ¯ x ( − 12 ) , ¯ x ( 12 ) . If none of the replacement points proves to be satisfactory , the simplex is shrunk to the smaller triangle indicated by the dotted line , which retains the best vertex x 1 . The scalars t used in deﬁning the candidate points ¯ x ( t ) have been assigned the speciﬁc ( and standard ) values − 1 , − 2 , − 1 2 , and 1 2 in our description above . Different choices are also possible , subject to certain restrictions . Practical performance of the Nelder – Mead algorithm is often reasonable , though stagnation has been observed to occur at nonoptimal points . Restarting can be used when stagnationisdetected ; seeKelley [ 178 ] . Notethatunlesstheﬁnalshrinkagestepisperformed , the average function value 1 n + 1 n + 1 (cid:3) i (cid:3) 1 f ( x i ) ( 9 . 29 ) will decrease at each step . When f is convex , even the shrinkage step is guaranteed not to increase the average function value . 240 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N ( −2 ) 1 x 3 x 2 x x x x ( 1 / 2 ) ( −1 / 2 ) ( −1 ) x Figure 9 . 4 One step of the Nelder – Mead simplex method in IR 3 , showing current simplex ( solid triangle with vertices x 1 , x 2 , x 3 ) , reﬂection point ¯ x ( − 1 ) , expansion point ¯ x ( − 2 ) , inside contraction point ¯ x ( 12 ) , outside contraction point ¯ x ( − 12 ) , and shrunken simplex ( dotted triangle ) . A limited amount of convergence theory has been developed for the Nelder – Mead method in recent years ; see , for example , Kelley [ 179 ] and Lagarias et al . [ 186 ] . 9 . 6 IMPLICIT FILTERING We now describe an algorithm designed for functions whose evaluations are modeled by ( 9 . 2 ) , where h is smooth . This implicit ﬁltering approach is , in its simplest form , a variant of the steepest descent algorithm with line search discussed in Chapter 3 , in which the gradient ∇ f k is replaced by a ﬁnite difference estimate such as ( 9 . 3 ) , with a difference parameter (cid:9) that may not be particularly small . Implicit ﬁltering works best on functions for which the noise level decreases as the iterates approach a solution . This situation may occur when we have control over the noise level , as is the case when f is obtained by solving a differential equation to a user - speciﬁed tolerance , or by running a stochastic simulation for a user - speciﬁed number of trials ( where an increase in the number of trials usually produces a decrease in the noise ) . The implicit ﬁltering algorithm decreases (cid:9) systematically ( but , one hopes , not as rapidly as the decay in error ) so as to maintain reasonable accuracy in ∇ (cid:9) f ( x ) , given the noise level at the current value of x . For each value of (cid:9) , it performs an inner loop that is simply an Armijo line search using the search direction −∇ (cid:9) f ( x ) . If the inner loop is unable to ﬁnd a satisfactory step length after backtracking at least a max times , we return to the outer loop , choose a smaller value of (cid:9) , and repeat . A formal speciﬁcation follows . 9 . 6 . I M P L I C I T F I L T E R I N G 241 Algorithm 9 . 6 ( Implicit Filtering ) . Choose a sequence { (cid:9) k } ↓ 0 , Armijo parameters c and ρ in ( 0 , 1 ) , maximum backtracking parameter a max ; Set k ← 1 , Choose initial point x (cid:3) x 0 ; repeat increment k ← false ; repeat Compute f ( x ) and ∇ (cid:9) k f ( x ) ; if (cid:23)(cid:23) ∇ (cid:9) k f ( x ) (cid:23)(cid:23) ≤ (cid:9) k increment k ← true ; else Find the smallest integer m between 0 and a max such that f (cid:7) x − ρ m ∇ (cid:9) k f ( x ) (cid:8) ≤ f ( x ) − c ρ m (cid:23)(cid:23) ∇ (cid:9) k f ( x ) (cid:23)(cid:23) 2 2 ; if no such m exists increment k ← true ; else x ← x − ρ m ∇ (cid:9) f ( x ) ; until increment k ; x k ← x ; k ← k + 1 ; until a termination test is satisﬁed . Note that the inner loop in Algorithm 9 . 6 is essentially the backtracking line search algorithm—Algorithm 3 . 1 of Chapter 3—with a convergence criterion added to detect whether the minimum appears to have been found to within the accuracy implied by the dif - ference parameter (cid:9) k . If the gradient estimate ∇ (cid:9) k f is small , or if the line search fails to ﬁnd a satisfactory new iterate ( indicating that the gradient approximation ∇ (cid:9) k f ( x ) is insufﬁciently accurate to produce descent in f ) , we decrease the difference parameter to (cid:9) k + 1 and proceed . A basic convergence result for Algorithm 9 . 6 is the following . Theorem 9 . 2 . Suppose that ∇ 2 h is Lipschitz continuous , that Algorithm 9 . 6 generates an inﬁnite sequence of iterates { x k } , and that lim k →∞ (cid:9) 2 k + η ( x k ; (cid:9) k ) (cid:9) k (cid:3) 0 . Suppose , too , that all but a ﬁnite number of inner loops in Algorithm 9 . 6 terminate with (cid:23)(cid:23) ∇ (cid:9) k f ( x k ) (cid:23)(cid:23) ≤ (cid:9) k . Then all limit points of the sequence { x k } are stationary . P ROOF . Using { (cid:9) k } ↓ 0 , we have under our assumptions on inner loop termination that ∇ (cid:9) k f ( x k ) → 0 . By invoking the error bound ( 9 . 5 ) and noting that the right - hand side of this expression is approaching zero , we conclude that ∇ h ( x k ) → 0 . Hence all limit points satisfy ∇ h ( x ) (cid:3) 0 , as claimed . (cid:1) 242 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N More sophisticated versions of implicit ﬁltering methods can be derived by using the gradient estimate ∇ (cid:9) k f to construct quasi - Newton approximate Hessians , and thus generating quasi - Newton search directions instead of the negative - approximate - gradient search direction used in Algorithm 9 . 6 . NOTES AND REFERENCES A classical reference on derivative - free methods is Brent [ 39 ] , which focuses primarily on one - dimensional problems and includes discussion of roundoff errors and global min - imization . Recent surveys on derivative - free methods include Wright [ 314 ] , Powell [ 256 ] , Conn , Scheinberg , and Toint [ 76 ] , and Kolda , Lewis , and Torczon [ 183 ] . The ﬁrst model - based method for derivative - free optimization was proposed by Win - ﬁeld [ 307 ] . It uses quadratic models , which are determined by the interpolation conditions ( 9 . 7 ) , and computes steps by solving a subproblem of the form ( 9 . 9 ) . Practical procedures for improving the geometry of the interpolation points were ﬁrst developed by Powell in the context of model - based methods using linear and quadratic polynomials ; see [ 256 ] for a review of this work . Conn , Scheinberg , and Toint [ 75 ] propose and analyze model - based methods and studytheuseofNewtonfundamentalpolynomials . Methodsthatcombineminimumchange updating and interpolation are discussed by Powell [ 258 , 260 ] . Our presentation of model - based methods in Section 9 . 2 is based on [ 76 , 259 , 258 ] . For a comprehensive discussion of pattern - search methods of the type discussed here , we refer the reader to the review paper of Kolda , Lewis , and Torczon [ 183 ] , and the references therein . The method of conjugate directions given in Algorithm 9 . 3 was proposed by Pow - ell [ 239 ] . For a discussion on the rate of convergence of the coordinate descent method and for more references about this method , see Luenberger [ 195 ] . For further information on implicit ﬁltering , see Kelley [ 179 ] and Choi and Kelley [ 60 ] and the references therein . Software packages that implement model - based methods include COBYLA [ 258 ] , DFO [ 75 ] , UOBYQA [ 257 ] , WEDGE [ 200 ] , and NEWUOA [ 260 ] . The earliest code is COBYLA , which employs linear models . DFO , UOBYQA , and WEDGE use quadratic models , whereas the method based on minimum change updating ( 9 . 19 ) is implemented in NEWUOA . A pattern - search methodisimplementedin APPS [ 171 ] , while DIRECT [ 173 ] isdesignedtoﬁndaglobalsolution . ✐ E X E R C I S E S ✐ 9 . 1 Prove Lemma 9 . 1 . ✐ 9 . 2 ( a ) Verify that the number of interpolation conditions to uniquely determine the coefﬁcients in ( 9 . 6 ) are q (cid:3) 12 ( n + 1 ) ( n + 2 ) . 9 . 6 . I M P L I C I T F I L T E R I N G 243 ( b ) Verify that the number of vertices and midpoints of the edges of a nondegenerate simplex in R n add up to q (cid:3) 12 ( n + 1 ) ( n + 2 ) and can therefore be used as the initial interpolation set in a DFO algorithm . ( c ) How many interpolation conditions would be required to determine the coefﬁcients in ( 9 . 6 ) if the matrix G were identically 0 ? How many if G were diagonal ? How many if G were tridiagonal ? ✐ 9 . 3 Describe conditions on the vectors s l that guarantee that the model ( 9 . 14 ) is uniquely determined . ✐ 9 . 4 Consider the determination of a quadratic function in two variables . ( a ) Show that six points on a line do not determine the quadratic . ( b ) Show that six points in a circle in the plane do not uniquely determine the quadratic . ✐ 9 . 5 Use induction to show that at the end of the outer iteration k of Algorithm 9 . 3 , the directions p n − k , p n − k + 1 , . . . , p n are conjugate . Use this fact to show that if the step lengths α i in Algorithm 9 . 3 are never zero , the iteration terminates at the minimizer of ( 9 . 25 ) after at most n outer iterations . ✐ 9 . 6 Write a program that computes the one - dimensional minimizer of a strictly convex quadratic function f along a direction p using quadratic interpolation . Describe the formulas used in your program . ✐ 9 . 7 Find the quadratic function m ( x 1 , x 2 ) (cid:3) f + g 1 x 1 + g 2 x 2 + 1 2 G 211 x 21 + G 12 x 1 x 2 + 1 2 G 222 x 22 that interpolates the following data : x 0 (cid:3) y 1 (cid:3) ( 0 , 0 ) T , y 2 (cid:3) ( 1 , 0 ) T , y 3 (cid:3) ( 2 , 0 ) T , y 4 (cid:3) ( 1 , 1 ) T , y 5 (cid:3) ( 0 , 2 ) T , y 6 (cid:3) ( 0 , 1 ) T , and f ( y 1 ) (cid:3) 1 , f ( y 2 ) (cid:3) 2 . 0084 , f ( y 3 ) (cid:3) 7 . 0091 , f ( y 4 ) (cid:3) 1 . 0168 , f ( y 5 ) (cid:3) − 0 . 9909 , and f ( y 6 ) (cid:3) − 0 . 9916 . ✐ 9 . 8 Find the value of δ for which the coordinate generating set ( 9 . 23 ) satisﬁes the property ( 9 . 21 ) . ✐ 9 . 9 Show that κ ( D k ) (cid:3) 0 , where κ ( · ) is deﬁned by ( 9 . 21 ) and D k (cid:3) { e i , − e i } for any i (cid:3) 1 , 2 , . . . , n . ✐ 9 . 10 ( Hard ) Prove that the generating set ( 9 . 24 ) satisﬁes the property ( 9 . 21 ) for a certain value δ > 0 , and ﬁnd this value of δ . ✐ 9 . 11 Justify the statement that the average function value at the Nelder – Mead simplex points will decrease over one step if any of the points ¯ x ( − 1 ) , ¯ x ( − 2 ) , ¯ x ( − 12 ) , ¯ x ( 12 ) are adopted as a replacement for x n + 1 . 244 C H A P T E R 9 . D E R I V A T I V E - F R E E O P T I M I Z A T I O N ✐ 9 . 12 Show that if f is a convex function , the shrinkage step in the Nelder – Mead simplex method will not increase the average value of the function over the simplex vertices deﬁned by ( 9 . 29 ) . Show that unless f ( x 1 ) (cid:3) f ( x 2 ) (cid:3) · · · (cid:3) f ( x n + 1 ) , the average value will in fact decrease . ✐ 9 . 13 Suppose for the f deﬁned in ( 9 . 2 ) , we deﬁne the approximate gradient ∇ (cid:9) f ( x ) by the forward - difference formula ∇ (cid:9) f ( x ) (cid:3) (cid:26) f ( x + (cid:9) e i ) − f ( x ) (cid:9) (cid:27) i (cid:3) 1 , 2 , . . . , n , rather than the central - difference formula ( 9 . 3 ) . ( This formula requires only half as many function evaluations but is less accurate . ) For this deﬁnition , prove the following variant of Lemma 9 . 1 : Suppose that ∇ h ( x ) is Lipschitz continuous in a neighborhood of the box { z | z ≥ x , (cid:8) z − x (cid:8) ∞ ≤ (cid:9) } with Lipschitz constant L h . Then we have (cid:8)∇ (cid:9) f ( x ) − ∇ h ( x ) (cid:8) ∞ ≤ L h (cid:9) + η ( x ; (cid:9) ) (cid:9) , where η ( x ; (cid:9) ) is redeﬁned as follows : η ( x ; (cid:9) ) (cid:3) sup z ≥ x , (cid:8) z − x (cid:8) ∞ ≤ (cid:9) | φ ( z ) | . This is page 245 Printer : Opaque this C H A P T E R 10 Least - Squares Problems In least - squares problems , the objective function f has the following special form : f ( x ) (cid:3) 12 m (cid:3) j (cid:3) 1 r 2 j ( x ) , ( 10 . 1 ) where each r j is a smooth function from IR n to IR . We refer to each r j as a residual , and we assume throughout this chapter that m ≥ n . Least - squares problems arise in many areas of applications , and may in fact be the largestsourceofunconstrainedoptimizationproblems . Manywhoformulateaparametrized 246 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S model for a chemical , physical , ﬁnancial , or economic application use a function of the form ( 10 . 1 ) to measure the discrepancy between the model and the observed behavior of the system ( see Example 2 . 1 , for instance ) . By minimizing this function , they select values for the parameters that best match the model to the data . In this chapter we show how to devise efﬁcient , robust minimization algorithms by exploiting the special structure of the function f and its derivatives . Toseewhythespecialformof f oftenmakesleast - squaresproblemseasiertosolvethan general unconstrained minimization problems , we ﬁrst assemble the individual components r j from ( 10 . 1 ) into a residual vector r : IR n → IR m , as follows r ( x ) (cid:3) ( r 1 ( x ) , r 2 ( x ) , . . . , r m ( x ) ) T . ( 10 . 2 ) Using this notation , we can rewrite f as f ( x ) (cid:3) 12 (cid:8) r ( x ) (cid:8) 22 . The derivatives of f ( x ) can be expressed in terms of the Jacobian J ( x ) , which is the m × n matrix of ﬁrst partial derivatives of the residuals , deﬁned by J ( x ) (cid:3) (cid:26) ∂ r j ∂ x i (cid:27) j (cid:3) 1 , 2 , . . . , m i (cid:3) 1 , 2 , . . . , n (cid:3) ⎡ ⎢⎢⎢⎢⎢⎣ ∇ r 1 ( x ) T ∇ r 2 ( x ) T . . . ∇ r m ( x ) T ⎤ ⎥⎥⎥⎥⎥⎦ , ( 10 . 3 ) where each ∇ r j ( x ) , j (cid:3) 1 , 2 , . . . , m is the gradient of r j . The gradient and Hessian of f can then be expressed as follows : ∇ f ( x ) (cid:3) m (cid:3) j (cid:3) 1 r j ( x ) ∇ r j ( x ) (cid:3) J ( x ) T r ( x ) , ( 10 . 4 ) ∇ 2 f ( x ) (cid:3) m (cid:3) j (cid:3) 1 ∇ r j ( x ) ∇ r j ( x ) T + m (cid:3) j (cid:3) 1 r j ( x ) ∇ 2 r j ( x ) (cid:3) J ( x ) T J ( x ) + m (cid:3) j (cid:3) 1 r j ( x ) ∇ 2 r j ( x ) . ( 10 . 5 ) In many applications , the ﬁrst partial derivatives of the residuals and hence the Jacobian matrix J ( x ) are relatively easy or inexpensive to calculate . We can thus obtain the gradient ∇ f ( x ) as written in formula ( 10 . 4 ) . Using J ( x ) , we also can calculate the ﬁrst term J ( x ) T J ( x ) in the Hessian ∇ 2 f ( x ) without evaluating any second derivatives of the functions r j . This availability of part of ∇ 2 f ( x ) “for free” is the distinctive feature of least - squares problems . Moreover , this term J ( x ) T J ( x ) is often more important than the second summation term in ( 10 . 5 ) , either because the residuals r j are close to afﬁne near the solution ( that is , the ∇ 2 r j ( x ) are relatively small ) or because of small residuals ( that 1 0 . 1 . B A C K G R O U N D 247 is , the r j ( x ) are relatively small ) . Most algorithms for nonlinear least - squares exploit these structural properties of the Hessian . The most popular algorithms for minimizing ( 10 . 1 ) ﬁt into the line search and trust - region frameworks described in earlier chapters . They are based on the Newton and quasi - Newton approaches described earlier , with modiﬁcations that exploit the particular structure of f . Section 10 . 1 contains some background on applications . Section 10 . 2 discusses lin - ear least - squares problems , which provide important motivation for algorithms for the nonlinear problem . Section 10 . 3 describes the major algorithms , while Section 10 . 4 brieﬂy describes a variant of least squares known as orthogonal distance regression . Throughout this chapter , we use the notation (cid:8)·(cid:8) to denote the Euclidean norm (cid:8)·(cid:8) 2 , unless a subscript indicates that some other norm is intended . 10 . 1 BACKGROUND We discuss a simple parametrized model and show how least - squares techniques can be used to choose the parameters that best ﬁt the model to the observed data . ❏ E XAMPLE 10 . 1 We would like to study the effect of a certain medication on a patient . We draw blood samples at certain times after the patient takes a dose , and measure the concentration of the medication in each sample , tabulating the time t j and concentration y j for each sample . Based on our previous experience in such experiments , we ﬁnd that the following function φ ( x ; t ) provides a good prediction of the concentration at time t , for appropriate values of the ﬁve - dimensional parameter vector x (cid:3) ( x 1 , x 2 , x 3 , x 4 , x 5 ) : φ ( x ; t ) (cid:3) x 1 + tx 2 + t 2 x 3 + x 4 e − x 5 t . ( 10 . 6 ) We choose the parameter vector x so that this model best agrees with our observation , in some sense . A good way to measure the difference between the predicted model values and the observations is the following least - squares function : 1 2 m (cid:3) j (cid:3) 1 [ φ ( x ; t j ) − y j ] 2 , ( 10 . 7 ) which sums the squares of the discrepancies between predictions and observations at each t j . This function has precisely the form ( 10 . 1 ) if we deﬁne r j ( x ) (cid:3) φ ( x ; t j ) − y j . ( 10 . 8 ) 248 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S t 3 t 4 t 1 t 2 t 5 t 6 t 7 t y Figure 10 . 1 Model ( 10 . 7 ) ( smooth curve ) and the observed measurements , with deviations indicated by vertical dotted lines . Graphically , each term in ( 10 . 7 ) represents the square of the vertical distance between the curve φ ( x ; t ) ( plotted as a function of t ) and the point ( t j , y j ) , for a ﬁxed choice of parameter vector x ; see Figure 10 . 1 . The minimizer x ∗ of the least - squares problem is the parameter vector for which the sum of squares of the lengths of the dotted lines in Figure 10 . 1 is minimized . Having obtained x ∗ , we use φ ( x ∗ ; t ) to estimate the concentration of medication remaining in the patient’s bloodstream at any time t . ❐ This model is an example of what statisticians call a ﬁxed - regressor model . It assumes that the times t j at which the blood samples are drawn are known to high accuracy , while the observations y j may contain more or less random errors due to the limitations of the equipment ( or the lab technician ! ) In general data - ﬁtting problems of the type just described , the ordinate t in the model φ ( x ; t ) could be a vector instead of a scalar . ( In the example above , for instance , t could have two dimensions , with the ﬁrst dimension representing the time since the drug was admistered and the second dimension representing the weight of the patient . We could then use observations for an entire population of patients , not just a single patient , to obtain the “best” parameters for this model . ) The sum - of - squares function ( 10 . 7 ) is not the only way of measuring the discrepancy between the model and the observations . Other common measures include the maximum absolute value max j (cid:3) 1 , 2 , . . . , m | φ ( x ; t j ) − y j | ( 10 . 9 ) 1 0 . 1 . B A C K G R O U N D 249 and the sum of absolute values m (cid:3) j (cid:3) 1 | φ ( x ; t j ) − y j | . ( 10 . 10 ) By using the deﬁnitions of the (cid:1) ∞ and (cid:1) 1 norms , we can rewrite these two measures as f ( x ) (cid:3) (cid:8) r ( x ) (cid:8) ∞ , f ( x ) (cid:3) (cid:8) r ( x ) (cid:8) 1 , ( 10 . 11 ) respectively . As we discuss in Chapter 17 , the problem of minimizing the functions ( 10 . 11 ) can be reformulated a smooth constrained optimization problem . In this chapter we focus only on the (cid:1) 2 - norm formulation ( 10 . 1 ) . In some situations , there are statistical motivations for choosing the least - squares criterion . Changing the no - tation slightly , let the discrepancies between model and observation be denoted by (cid:9) j , that is , (cid:9) j (cid:3) φ ( x ; t j ) − y j . It often is reasonable to assume that the (cid:9) j ’s are independent and identically distributed with a certain variance σ 2 and probability density function g σ ( · ) . ( This assumption will often be true , for instance , when the model accurately reﬂects the actual process , and when the errors made in obtaining the measurements y j do not contain a systematic bias . ) Under this assumption , the likelihood of a particular set of observations y j , j (cid:3) 1 , 2 , . . . , m , given that the actual parameter vector is x , is given by the function p ( y ; x , σ ) (cid:3) m 1 j (cid:3) 1 g σ ( (cid:9) j ) (cid:3) m 1 j (cid:3) 1 g σ ( φ ( x ; t j ) − y j ) . ( 10 . 12 ) Giventheobservations y 1 , y 2 , . . . , y m , the“mostlikely”valueof x isobtainedbymaximizing p ( y ; x , σ ) with respect to x . The resulting value of x is called the maximum likelihood estimate . When we assume that the discrepancies follow a normal distribution , we have g σ ( (cid:9) ) (cid:3) 1 √ 2 πσ 2 exp (cid:17) − (cid:9) 2 2 σ 2 (cid:18) . Substitution in ( 10 . 12 ) yields p ( y ; x , σ ) (cid:3) ( 2 πσ 2 ) − m / 2 exp ⎛ ⎝ − 1 2 σ 2 m (cid:3) j (cid:3) 1 [ φ ( x ; t j ) − y j ] 2 ⎞ ⎠ . 250 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S For any ﬁxed value of the variance σ 2 , it is obvious that p is maximized when the sum of squares ( 10 . 7 ) is minimized . To summarize : When the discrepancies are assumed to be independent and identically distributed with a normal distribution function , the maximum likelihood estimate is obtained by minimizing the sum of squares . The assumptions on (cid:9) j in the previous paragraph are common , but they do not describe the only situation for which the minimizer of the sum of squares makes good statistical sense . Seber and Wild [ 280 ] describe many instances in which minimization of functions like ( 10 . 7 ) , or generalizations of this function such as r ( x ) T Wr ( x ) , where W ∈ IR m × m is symmetric , is the crucial step in obtaining estimates of the parameters x from observed data . 10 . 2 LINEAR LEAST - SQUARES PROBLEMS Many models φ ( x ; t ) in data - ﬁtting problems are linear functions of x . In these cases , the residuals r j ( x ) deﬁned by ( 10 . 8 ) also are linear , and the problem of minimizing ( 10 . 7 ) is called a linear least - squares problem . We can write the residual vector as r ( x ) (cid:3) Jx − y for some matrix J and vector y , both independent of x , so that the objective is f ( x ) (cid:3) 12 (cid:8) Jx − y (cid:8) 2 , ( 10 . 13 ) where y (cid:3) r ( 0 ) . We also have ∇ f ( x ) (cid:3) J T ( Jx − y ) , ∇ 2 f ( x ) (cid:3) J T J . ( Note that the second term in ∇ 2 f ( x ) ( see ( 10 . 5 ) ) disappears , because ∇ 2 r j (cid:3) 0 for all j (cid:3) 1 , 2 , . . . , m . ) It is easy to see that the f ( x ) in ( 10 . 13 ) is convex—a property that does not necessarily hold for the nonlinear problem ( 10 . 1 ) . Theorem 2 . 5 tells us that any point x ∗ for which ∇ f ( x ∗ ) (cid:3) 0 is the global minimizer of f . Therefore , x ∗ must satisfy the following linear system of equations : J T Jx ∗ (cid:3) J T y . ( 10 . 14 ) These are known as the normal equations for ( 10 . 13 ) . We outline brieﬂy three major algorithms for the unconstrained linear least - squares problem . We assume in most of our discussion that m ≥ n and that J has full column rank . 1 0 . 2 . L I N E A R L E A S T - S Q U A R E S P R O B L E M S 251 The ﬁrst and most obvious algorithm is simply to form and solve the system ( 10 . 14 ) by the following three - step procedure : • compute the coefﬁcient matrix J T J and the right - hand - side J T y ; • compute the Cholesky factorization of the symmetric matrix J T J ; • perform two triangular substitutions with the Cholesky factors to recover the solution x ∗ . The Cholesky factorization J T J (cid:3) ¯ R T ¯ R ( 10 . 15 ) ( where ¯ R is an n × n upper triangular with positive diagonal elements ) is guaranteed to exist when m ≥ n and J has rank n . This method is frequently used in practice and is often effective , but it has one signiﬁcant disadvantage , namely , that the condi - tion number of J T J is the square of the condition number of J . Since the relative error in the computed solution of a problem is usually proportional to the condition num - ber , the Cholesky - based method may result in less accurate solutions than those obtained from methods that avoid this squaring of the condition number . When J is ill condi - tioned , the Cholesky factorization process may even break down , since roundoff errors may cause small negative elements to appear on the diagonal during the factorization process . A second approach is based on a QR factorization of the matrix J . Since the Euclidean norm of any vector is not affected by orthogonal transformations , we have (cid:8) Jx − y (cid:8) (cid:3) (cid:8) Q T ( Jx − y ) (cid:8) ( 10 . 16 ) for any m × m orthogonal matrix Q . Suppose we perform a QR factorization with column pivoting on the matrix J ( see ( A . 24 ) ) to obtain J (cid:23) (cid:3) Q (cid:1) R 0 (cid:2) (cid:3) (cid:9) Q 1 Q 2 (cid:10) (cid:1) R 0 (cid:2) (cid:3) Q 1 R , ( 10 . 17 ) where (cid:23) is an n × n permutation matrix ( hence , orthogonal ) ; Q is m × m orthogonal ; Q 1 is the ﬁrst n columns of Q , while Q 2 contains the last m − n columns ; R is n × n upper triangular with positive diagonal elements . 252 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S By combining ( 10 . 16 ) and ( 10 . 17 ) , we obtain (cid:8) Jx − y (cid:8) 22 (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) Q T 1 Q T 2 (cid:2) ( J (cid:23)(cid:23) T x − y ) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 2 (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) R 0 (cid:2) ( (cid:23) T x ) − (cid:1) Q T 1 y Q T 2 y (cid:2)(cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 (cid:3) (cid:23)(cid:23) R ( (cid:23) T x ) − Q T 1 y (cid:23)(cid:23) 2 2 + (cid:23)(cid:23) Q T 2 y (cid:23)(cid:23) 2 . ( 10 . 18 ) No choice of x has any effect on the second term of this last expression , but we can minimize (cid:8) Jx − y (cid:8) by driving the ﬁrst term to zero , that is , by setting x ∗ (cid:3) (cid:23) R − 1 Q T 1 y . ( In practice , we perform a triangular substitution to solve Rz (cid:3) Q T 1 y , then permute the components of z to obtain x ∗ (cid:3) (cid:23) z . ) This QR - based approach does not degrade the conditioning of the problem unnec - essarily . The relative error in the ﬁnal computed solution x ∗ is usually proportional to the condition number of J , not its square , and this method is usually reliable . Some situations , however , call for greater robustness or more information about the sensitivity of the solu - tion to perturbations in the data ( J or y ) . A third approach , based on the singular - value decomposition ( SVD ) of J , can be used in these circumstances . Recall from ( A . 15 ) that the SVD of J is given by J (cid:3) U (cid:1) S 0 (cid:2) V T (cid:3) (cid:9) U 1 U 2 (cid:10) (cid:1) S 0 (cid:2) V T (cid:3) U 1 SV T , ( 10 . 19 ) where U is m × m orthogonal ; U 1 contains the ﬁrst n columns of U , U 2 the last m − n columns ; V is n × n orthogonal ; S is n × n diagonal , with diagonal elements σ 1 ≥ σ 2 ≥ · · · ≥ σ n > 0 . ( Note that J T J (cid:3) V S 2 V T , so that the columns of V are eigenvectors of J T J with eigenvalues σ 2 j , j (cid:3) 1 , 2 , . . . , n . ) By following the same logic that led to ( 10 . 18 ) , we obtain (cid:8) Jx − y (cid:8) 2 (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) S 0 (cid:2) ( V T x ) − (cid:1) U T 1 U T 2 (cid:2) y (cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 (cid:3) (cid:8) S ( V T x ) − U T 1 y (cid:8) 2 + (cid:8) U T 2 y (cid:8) 2 . ( 10 . 20 ) 1 0 . 2 . L I N E A R L E A S T - S Q U A R E S P R O B L E M S 253 Again , the optimum is found by choosing x to make the ﬁrst term equal to zero ; that is , x ∗ (cid:3) V S − 1 U T 1 y . Denoting the i th columns of U and V by u i ∈ IR m and v i ∈ IR n , respectively , we have x ∗ (cid:3) n (cid:3) i (cid:3) 1 u Ti y σ i v i . ( 10 . 21 ) This formula yields useful information about the sensitivity of x ∗ . When σ i is small , x ∗ is particularly sensitive to perturbations in y that affect u Ti y , and also to perturbations in J that affect this same quantity . Such information is particularly useful when J is nearly rank - deﬁcient , that is , when σ n / σ 1 (cid:24) 1 . It is sometimes worth the extra cost of the SVD algorithm to obtain this sensitivity information . All three approaches above have their place . The Cholesky - based algorithm is partic - ularly useful when m (cid:28) n and it is practical to store J T J but not J itself . It can also be less expensive than the alternatives when m (cid:28) n and J is sparse . However , this approach must be modiﬁed when J is rank - deﬁcient or ill conditioned to allow pivoting of the diagonal elements of J T J . The QR approach avoids squaring of the condition number and hence may be more numerically robust . While potentially the most expensive , the SVD approach is the most robust and reliable of all . When J is actually rank - deﬁcient , some of the singular values σ i are exactly zero , and any vector x ∗ of the form x ∗ (cid:3) (cid:3) σ i (cid:9)(cid:3) 0 u Ti y σ i v i + (cid:3) σ i (cid:3) 0 τ i v i ( 10 . 22 ) ( for arbitrary coefﬁcients τ i ) is a minimizer of ( 10 . 20 ) . Frequently , the solution with smallest norm is the most desirable , and we obtain it by setting each τ i (cid:3) 0 in ( 10 . 22 ) . When J has full rank but is ill conditioned , the last few singular values σ n , σ n − 1 , . . . are small relative to σ 1 . The coefﬁcients u Ti y / σ i in ( 10 . 22 ) are particularly sensitive to perturbations in u Ti y when σ i is small , so an approximate solution that is less sentitive to perturbations than the true solution can be obtained by omitting these terms from the summation . When the problem is very large , it may be efﬁcient to use iterative techniques , such as the conjugate gradient method , to solve the normal equations ( 10 . 14 ) . A direct imple - mentation of conjugate gradients ( Algorithm 5 . 2 ) requires one matrix vector multiplication with J T J to be performed at each iteration . This operation can be performed by means of successive multiplications by J and J T ; we need only the ability to perform matrix - vector multiplications with these two matrices to implement this algorithm . Several modiﬁcations of the conjugate gradient approach have been proposed that involve a similar amount of work per iteration ( one matrix - vector multiplication each with J and J T ) but that have superior numerical properties . Some alternatives are described by Paige and Saunders [ 234 ] , 254 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S who propose in particular an algorithm called LSQR which has become the basis of a highly successful code . 10 . 3 ALGORITHMS FOR NONLINEAR LEAST - SQUARES PROBLEMS THE GAUSS – NEWTON METHOD We now describe methods for minimizing the nonlinear objective function ( 10 . 1 ) that exploit the structure in the gradient ∇ f ( 10 . 4 ) and Hessian ∇ 2 f ( 10 . 5 ) . The simplest of these methods—the Gauss – Newton method—can be viewed as a modiﬁed Newton’s method with line search . Instead of solving the standard Newton equations ∇ 2 f ( x k ) p (cid:3) −∇ f ( x k ) , we solve instead the following system to obtain the search direction p GN k : J Tk J k p GN k (cid:3) − J Tk r k . ( 10 . 23 ) This simple modiﬁcation gives a number of advantages over the plain Newton’s method . First , our use of the approximation ∇ 2 f k ≈ J Tk J k ( 10 . 24 ) saves us the trouble of computing the individual residual Hessians ∇ 2 r j , j (cid:3) 1 , 2 , . . . , m , which are needed in the second term in ( 10 . 5 ) . In fact , if we calculated the Jacobian J k in the course of evaluating the gradient ∇ f k (cid:3) J T k r k , the approximation ( 10 . 24 ) does not require any additional derivative evaluations , and the savings in computational time can be quite signiﬁcant in some applications . Second , there are many interesting situations in which the ﬁrst term J T J in ( 10 . 5 ) dominates the second term ( at least close to the solution x ∗ ) , so that J Tk J k is a close approximation to ∇ 2 f k and the convergence rate of Gauss – Newton is similar to that of Newton’s method . The ﬁrst term in ( 10 . 5 ) will be dominant when the norm of each second - order term ( that is , | r j ( x ) | (cid:8)∇ 2 r j ( x ) (cid:8) ) is signiﬁcantly smaller than the eigenvalues of J T J . As mentioned in the introduction , we tend to see this behavior when either the residuals r j are small or when they are nearly afﬁne ( so that the (cid:8)∇ 2 r j (cid:8) are small ) . In practice , many least - squares problems have small residuals at the solution , leading to rapid local convergence of Gauss – Newton . A third advantage of Gauss – Newton is that whenever J k has full rank and the gradient ∇ f k is nonzero , the direction p GN k is a descent direction for f , and therefore a suitable direction for a line search . From ( 10 . 4 ) and ( 10 . 23 ) we have ( p GN k ) T ∇ f k (cid:3) ( p GN k ) T J Tk r k (cid:3) − ( p GN k ) T J Tk J k p GN k (cid:3) −(cid:8) J k p GN k (cid:8) 2 ≤ 0 . ( 10 . 25 ) 1 0 . 3 . A L G O R I T H M S F O R N O N L I N E A R L E A S T - S Q U A R E S P R O B L E M S 255 The ﬁnal inequality is strict unless J k p GN k (cid:3) 0 , in which case we have by ( 10 . 23 ) and full rank of J k that J Tk r k (cid:3) ∇ f k (cid:3) 0 ; that is , x k is a stationary point . Finally , the fourth advantage of Gauss – Newton arises from the similarity between the equations ( 10 . 23 ) and the normal equations ( 10 . 14 ) for the linear least - squares problem . This connection tells us that p GN k is in fact the solution of the linear least - squares problem min p 1 2 (cid:8) J k p + r k (cid:8) 2 . ( 10 . 26 ) Hence , we can ﬁnd the search direction by applying linear least - squares algorithms to the subproblem ( 10 . 26 ) . In fact , if the QR or SVD - based algorithms are used , there is no need to calculate the Hessian approximation J Tk J k in ( 10 . 23 ) explicitly ; we can work directly with the Jacobian J k . The same is true if we use a conjugate - gradient technique to solve ( 10 . 26 ) . For this method we need to perform matrix - vector multiplications with J Tk J k , which can be done by ﬁrst multiplying by J k and then by J Tk . If the number of residuals m is large while the number of variables n is relatively small , it may be unwise to store the Jacobian J explicitly . A preferable strategy may be to calculate the matrix J T J and gradient vector J T r by evaluating r j and ∇ r j successively for j (cid:3) 1 , 2 , . . . , m and performing the accumulations J T J (cid:3) m (cid:3) i (cid:3) 1 ( ∇ r j ) ( ∇ r j ) T , J T r (cid:3) m (cid:3) i (cid:3) 1 r j ( ∇ r j ) . ( 10 . 27 ) The Gauss – Newton steps can then be computed by solving the system ( 10 . 23 ) of normal equations directly . The subproblem ( 10 . 26 ) suggests another motivation for the Gauss – Newton search direction . We can view this equation as being obtained from a linear model for the the vector function r ( x k + p ) ≈ r k + J k p , substituted into the function 12 (cid:8) · (cid:8) 2 . In other words , we use the approximation f ( x k + p ) (cid:3) 12 (cid:8) r ( x k + p ) (cid:8) 2 ≈ 12 (cid:8) J k p + r k (cid:8) 2 , and choose p GN k to be the minimizer of this approximation . Implementations of the Gauss – Newton method usually perform a line search in the direction p GN k , requiring the step length α k to satisfy conditions like those discussed in Chapter 3 , such as the Armijo and Wolfe conditions ; see ( 3 . 4 ) and ( 3 . 6 ) . CONVERGENCE OF THE GAUSS – NEWTON METHOD The theory of Chapter 3 can applied to study the convergence properties of the Gauss – Newton method . We prove a global convergence result under the assumption that the Jacobians J ( x ) have their singular values uniformly bounded away from zero in the 256 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S region of interest ; that is , there is a constant γ > 0 such that (cid:8) J ( x ) z (cid:8) ≥ γ (cid:8) z (cid:8) ( 10 . 28 ) for all x in a neighborhood N of the level set L (cid:3) { x | f ( x ) ≤ f ( x 0 ) } , ( 10 . 29 ) where x 0 is the starting point for the algorithm . We assume here and in the rest of the chapter that L is bounded . Our result is a consequence of Theorem 3 . 2 . Theorem 10 . 1 . Suppose each residual function r j is Lipschitz continuously differentiable in a neigh - borhood N of the bounded level set ( 10 . 29 ) , and that the Jacobians J ( x ) satisfy the uniform full - rank condition ( 10 . 28 ) on N . Then if the iterates x k are generated by the Gauss – Newton method with step lengths α k that satisfy ( 3 . 6 ) , we have lim k →∞ J Tk r k (cid:3) 0 . P ROOF . First , we note that the neighborhood N of the bounded level set L can be chosen small enough that the following properties are satisﬁed for some positive constants L and β : | r j ( x ) | ≤ β and (cid:8)∇ r j ( x ) (cid:8) ≤ β , | r j ( x ) − r j ( ˜ x ) | ≤ L (cid:8) x − ˜ x (cid:8) and (cid:8)∇ r j ( x ) − ∇ r j ( ˜ x ) (cid:8) ≤ L (cid:8) x − ˜ x (cid:8) , for all x , ˜ x ∈ N and all j (cid:3) 1 , 2 , . . . , m . It is easy to deduce that there exists a constant ¯ β > 0 such that (cid:8) J ( x ) T (cid:8) (cid:3) (cid:8) J ( x ) (cid:8) ≤ ¯ β for all x ∈ L . In addition , by applying the results concerning Lipschitz continuity of products and sums ( see for example ( A . 43 ) ) to the gradient ∇ f ( x ) (cid:3) (cid:4) mj (cid:3) 1 r j ( x ) ∇ r j ( x ) , we can show that ∇ f is Lipschitz continuous . Hence , the assumptions of Theorem 3 . 2 are satisﬁed . We check next that the angle θ k between the search direction p GN k and the negative gradient −∇ f k is uniformly bounded away from π / 2 . From ( 3 . 12 ) , ( 10 . 25 ) , and ( 10 . 28 ) , we have for x (cid:3) x k ∈ L and p GN (cid:3) p GN k that cos θ k (cid:3) − ( ∇ f ) T p GN (cid:8) p GN (cid:8)(cid:8)∇ f (cid:8) (cid:3) (cid:8) J p GN (cid:8) 2 (cid:8) p GN (cid:8)(cid:8) J T J p GN (cid:8) ≥ γ 2 (cid:8) p GN (cid:8) 2 ¯ β 2 (cid:8) p GN (cid:8) 2 (cid:3) γ 2 ¯ β 2 > 0 . It follows from ( 3 . 14 ) in Theorem 3 . 2 that ∇ f ( x k ) → 0 , giving the result . (cid:1) If J k is rank - deﬁcient for some k ( so that a condition like ( 10 . 28 ) is not satisﬁed ) , the coefﬁcient matrix in ( 10 . 23 ) is singular . The system ( 10 . 23 ) still has a solution , however , becauseoftheequivalencebetweenthislinearsystemandtheminimizationproblem ( 10 . 26 ) . 1 0 . 3 . A L G O R I T H M S F O R N O N L I N E A R L E A S T - S Q U A R E S P R O B L E M S 257 In fact , there are inﬁnitely many solutions for p GN k in this case ; each of them has the form of ( 10 . 22 ) . However , there is no longer an assurance that cos θ k is uniformly bounded away from zero , so we cannot prove a result like Theorem 10 . 1 . The convergence of Gauss – Newton to a solution x ∗ can be rapid if the leading term J Tk J k dominates the second - order term in the Hessian ( 10 . 5 ) . Suppose that x k is close to x ∗ and that assumption ( 10 . 28 ) is satisﬁed . Then , applying an argument like the Newton’s method analysis ( 3 . 31 ) , ( 3 . 32 ) , ( 3 . 33 ) in Chapter 3 , we have for a unit step in the Gauss – Newton direction that x k + p GN k − x ∗ (cid:3) x k − x ∗ − [ J T J ( x k ) ] − 1 ∇ f ( x k ) (cid:3) [ J T J ( x k ) ] − 1 (cid:9) J T J ( x k ) ( x k − x ∗ ) + ∇ f ( x ∗ ) − ∇ f ( x k ) (cid:10) , where J T J ( x ) is shorthand notation for J ( x ) T J ( x ) . Using H ( x ) to denote the second - order term in ( 10 . 5 ) , we have from ( A . 57 ) that ∇ f ( x k ) − ∇ f ( x ∗ ) (cid:3) (cid:6) 1 0 J T J ( x ∗ + t ( x k − x ∗ ) ) ( x k − x ∗ ) dt + (cid:6) 1 0 H ( x ∗ + t ( x k − x ∗ ) ) ( x k − x ∗ ) dt . A similar argument as in ( 3 . 32 ) , ( 3 . 33 ) , assuming Lipschitz continuity of H ( · ) near x ∗ , shows that (cid:8) x k + p GN k − x ∗ (cid:8) ≤ (cid:6) 1 0 (cid:8) [ J T J ( x k ) ] − 1 H ( x ∗ + t ( x k − x ∗ ) ) (cid:8)(cid:8) x k − x ∗ (cid:8) dt + O ( (cid:8) x k − x ∗ (cid:8) 2 ) ≈ (cid:8) [ J T J ( x ∗ ) ] − 1 H ( x ∗ ) (cid:8) (cid:8) x k − x ∗ (cid:8) + O ( (cid:8) x k − x ∗ (cid:8) 2 ) . ( 10 . 30 ) Hence , if (cid:8) [ J T J ( x ∗ ) ] − 1 H ( x ∗ ) (cid:8) (cid:24) 1 , we can expect a unit step of Gauss – Newton to move us much closer to the solution x ∗ , giving rapid local convergence . When H ( x ∗ ) (cid:3) 0 , the convergence is actually quadratic . When n and m are both large and the Jacobian J ( x ) is sparse , the cost of computing steps exactly by factoring either J k or J Tk J k at each iteration may become quite expensive relative to the cost of function and gradient evaluations . In this case , we can design inexact variants of the Gauss – Newton algorithm that are analogous to the inexact Newton algo - rithms discussed in Chapter 7 . We simply replace the Hessian ∇ 2 f ( x k ) in these methods by its approximation J T k J k . The positive semideﬁniteness of this approximation simpliﬁes the resulting algorithms in several places . 258 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S THE LEVENBERG – MARQUARDT METHOD Recall that the Gauss – Newton method is like Newton’s method with line search , except that we use the convenient and often effective approximation ( 10 . 24 ) for the Hessian . The Levenberg – Marquardt method can be obtained by using the same Hessian approximation , but replacing the line search with a trust - region strategy . The use of a trust region avoids one of the weaknesses of Gauss – Newton , namely , its behavior when the Jacobian J ( x ) is rank - deﬁcient , or nearly so . Since the same Hessian approximations are used in each case , the local convergence properties of the two methods are similar . The Levenberg – Marquardt method can be described and analyzed using the trust - region framework of Chapter 4 . ( In fact , the Levenberg – Marquardt method is sometimes considered to be the progenitor of the trust - region approach for general unconstrained optimization discussed in Chapter 4 . ) For a spherical trust region , the subproblem to be solved at each iteration is min p 12 (cid:8) J k p + r k (cid:8) 2 , subject to (cid:8) p (cid:8) ≤ (cid:6) k , ( 10 . 31 ) where (cid:6) k > 0 is the trust - region radius . In effect , we are choosing the model function m k ( · ) in ( 4 . 3 ) to be m k ( p ) (cid:3) 12 (cid:8) r k (cid:8) 2 + p T J Tk r k + 12 p T J Tk J k p . ( 10 . 32 ) We drop the iteration counter k during the rest of this section and concern ourselves with the subproblem ( 10 . 31 ) . The results of Chapter 4 allow us to characterize the solution of ( 10 . 31 ) in the following way : When the solution p GN of the Gauss – Newton equations ( 10 . 23 ) lies strictly inside the trust region ( that is , (cid:8) p GN (cid:8) < (cid:6) ) , then this step p GN also solves the subproblem ( 10 . 31 ) . Otherwise , there is a λ > 0 such that the solution p (cid:3) p LM of ( 10 . 31 ) satisﬁes (cid:8) p (cid:8) (cid:3) (cid:6) and (cid:7) J T J + λ I (cid:8) p (cid:3) − J T r . ( 10 . 33 ) This claim is veriﬁed in the following lemma , which is a straightforward consequence of Theorem 4 . 1 from Chapter 4 . Lemma 10 . 2 . The vector p LM is a solution of the trust - region subproblem min p (cid:8) Jp + r (cid:8) 2 , subject to (cid:8) p (cid:8) ≤ (cid:6) , if and only if p LM is feasible and there is a scalar λ ≥ 0 such that ( J T J + λ I ) p LM (cid:3) − J T r , ( 10 . 34a ) λ ( (cid:6) − (cid:8) p LM (cid:8) ) (cid:3) 0 . ( 10 . 34b ) 1 0 . 3 . A L G O R I T H M S F O R N O N L I N E A R L E A S T - S Q U A R E S P R O B L E M S 259 P ROOF . In Theorem 4 . 1 , the semideﬁniteness condition ( 4 . 8c ) is satisﬁed automatically , since J T J is positive semideﬁnite and λ ≥ 0 . The two conditions ( 10 . 34a ) and ( 10 . 34b ) follow from ( 4 . 8a ) and ( 4 . 8b ) , respectively . (cid:1) Note that the equations ( 10 . 33 ) are just the normal equations for the following linear least - squares problem : min p 12 (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) J √ λ I (cid:2) p + (cid:1) r 0 (cid:2)(cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 . ( 10 . 35 ) Just as in the Gauss – Newton case , the equivalence between ( 10 . 33 ) and ( 10 . 35 ) gives us a way of solving the subproblem without computing the matrix – matrix product J T J and its Cholesky factorization . IMPLEMENTATION OF THE LEVENBERG – MARQUARDT METHOD To ﬁnd a value of λ that approximately matches the given (cid:6) in Lemma 10 . 2 , we can use the rootﬁnding algorithm described in Chapter 4 . It is easy to safeguard this procedure : The Cholesky factor R is guaranteed to exist whenever the current estimate λ ( (cid:1) ) is positive , since the approximate Hessian B (cid:3) J T J is already positive semideﬁnite . Because of the special structure of B , we do not need to compute the Cholesky factorization of B + λ I from scratch in each iteration of Algorithm 4 . 1 . Rather , we present an efﬁcient technique for ﬁnding the following QR factorization of the coefﬁcient matrix in ( 10 . 35 ) : (cid:1) R λ 0 (cid:2) (cid:3) Q T λ (cid:1) J √ λ I (cid:2) ( 10 . 36 ) ( Q λ orthogonal , R λ upper triangular ) . The upper triangular factor R λ satisﬁes R T λ R λ (cid:3) ( J T J + λ I ) . We can save computer time in the calculation of the factorization ( 10 . 36 ) by using a combination of Householder and Givens transformations . Suppose we use Householder transformations to calculate the QR factorization of J alone as J (cid:3) Q (cid:1) R 0 (cid:2) . ( 10 . 37 ) We then have ⎡ ⎢⎣ R 0 √ λ I ⎤ ⎥⎦ (cid:3) (cid:1) Q T I (cid:2) (cid:1) J √ λ I (cid:2) . ( 10 . 38 ) 260 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S The leftmost matrix in this formula is upper triangular except for the n nonzero terms of the matrix λ I . These can be eliminated by a sequence of n ( n + 1 ) / 2 Givens rotations , in which the diagonal elements of the upper triangular part are used to eliminate the nonzeros of λ I and the ﬁll - in terms that arise in the process . The ﬁrst few steps of this process are as follows : rotate row n of R with row n of √ λ I , to eliminate the ( n , n ) element of √ λ I ; rotate row n − 1 of R with row n − 1 of √ λ I to eliminate the ( n − 1 , n − 1 ) element of the latter matrix . This step introduces ﬁll - in in position ( n − 1 , n ) of √ λ I , which is eliminated by rotating row n of R with row n − 1 of √ λ I , to eliminate the ﬁll - in element at position ( n − 1 , n ) ; rotate row n − 2 of R with row n − 2 of √ λ I , to eliminate the ( n − 2 ) diagonal in the latter matrix . This step introduces ﬁll - in in the ( n − 2 , n − 1 ) and ( n − 2 , n ) positions , which we eliminate by · · · and so on . If we gather all the Givens rotations into a matrix ¯ Q λ , we obtain from ( 10 . 38 ) that ¯ Q T λ ⎡ ⎢⎣ R 0 √ λ I ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ R λ 0 0 ⎤ ⎥⎦ , and hence ( 10 . 36 ) holds with Q λ (cid:3) (cid:1) Q I (cid:2) ¯ Q λ . The advantage of this combined approach is that when the value of λ is changed in the rootﬁnding algorithm , we need only recalculate ¯ Q λ and not the Householder part of the factorization ( 10 . 38 ) . This feature can save a lot of computation in the case of m (cid:28) n , since just O ( n 3 ) operations are required to recalculate ¯ Q λ and R λ for each value of λ , after the initial cost of O ( mn 2 ) operations needed to calculate Q in ( 10 . 37 ) . Least - squares problems are often poorly scaled . Some of the variables could have values of about 10 4 , while other variables could be of order 10 − 6 . If such wide variations are ignored , the algorithms above may encounter numerical difﬁculties or produce solutions of poor quality . One way to reduce the effects of poor scaling is to use an ellipsoidal trust region in place of the spherical trust region deﬁned above . The step is conﬁned to an ellipse in which the lengths of the principal axes are related to the typical values of the corresponding variables . Analytically , the trust - region subproblem becomes min p 12 (cid:8) J k p + r k (cid:8) 2 , subject to (cid:8) D k p (cid:8) ≤ (cid:6) k , ( 10 . 39 ) 1 0 . 3 . A L G O R I T H M S F O R N O N L I N E A R L E A S T - S Q U A R E S P R O B L E M S 261 where D k is a diagonal matrix with positive diagonal entries ( cf . ( 7 . 13 ) ) . Instead of ( 10 . 33 ) , the solution of ( 10 . 39 ) satisﬁes an equation of the form (cid:7) J Tk J k + λ D 2 k (cid:8) p LM k (cid:3) − J Tk r k , ( 10 . 40 ) and , equivalently , solves the linear least - squares problem min p (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) J k √ λ D k (cid:2) p + (cid:1) r k 0 (cid:2)(cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 . ( 10 . 41 ) The diagonals of the scaling matrix D k can change from iteration to iteration , as we gather information about the typical range of values for each component of x . If the variation in these elements is kept within certain bounds , then the convergence theory for the spherical case continues to hold , with minor modiﬁcations . Moreover , the technique described above for calculating R λ needs no modiﬁcation . Seber and Wild [ 280 ] suggest choosing the diagonals of D 2 k to match those of J Tk J k , to make the algorithm invariant under diagonal scaling of the components of x . This approach is analogous to the technique of scaling by diagonal elements of the Hessian , which was described in Section 4 . 5 in the context of trust - region algorithms for unconstrained optimization . For problems in which m and n are large and J ( x ) is sparse , we may prefer to solve ( 10 . 31 ) or ( 10 . 39 ) approximately using the CG - Steihaug algorithm , Algorithm 7 . 2 from Chapter 7 , with J Tk J k replacing the exact Hessian ∇ 2 f k . Positive semideﬁniteness of the matrix J Tk J k makes for some simpliﬁcation of this algorithm , because negative curvature cannot arise . It is not necessary to calculate J Tk J k explicitly to implement Algorithm 7 . 2 ; the matrix - vector products required by the algorithm can be found by forming matrix - vector products with J k and J Tk separately . CONVERGENCE OF THE LEVENBERG – MARQUARDT METHOD It is not necessary to solve the trust - region problem ( 10 . 31 ) exactly in order for the Levenberg – Marquardt method to enjoy global convergence properties . The following convergence result can be obtained as a direct consequence of Theorem 4 . 6 . Theorem 10 . 3 . Let η ∈ (cid:7) 0 , 1 4 (cid:8) in Algorithm 4 . 1 of Chapter 4 , and suppose that the level set L deﬁned in ( 10 . 29 ) is bounded and that the residual functions r j ( · ) , j (cid:3) 1 , 2 , . . . , m are Lipschitz continuously differentiable in a neighborhood N of L . Assume that for each k , the approximate solution p k of ( 10 . 31 ) satisﬁes the inequality m k ( 0 ) − m k ( p k ) ≥ c 1 (cid:8) J T k r k (cid:8) min (cid:17) (cid:6) k , (cid:8) J T k r k (cid:8) (cid:8) J Tk J k (cid:8) (cid:18) , ( 10 . 42 ) 262 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S for some constant c 1 > 0 , and in addition (cid:8) p k (cid:8) ≤ γ (cid:6) k for some constant γ ≥ 1 . We then have that lim k →∞ ∇ f k (cid:3) lim k →∞ J Tk r k (cid:3) 0 . P ROOF . The smoothness assumption on r j ( · ) implies that we can choose a constant M > 0 such that (cid:8) J Tk J k (cid:8) ≤ M for all iterates k . Note too that the objective f is bounded below ( by zero ) . Hence , the assumptions of Theorem 4 . 6 are satisﬁed , and the result follows immediately . (cid:1) As in Chapter 4 , there is no need to calculate the right - hand - side in the inequality ( 10 . 42 ) or to check it explicitly . Instead , we can simply require the decrease given by our approximate solution p k of ( 10 . 31 ) to at least match the decrease given by the Cauchy point , which can be calculated inexpensively in the same way as in Chapter 4 . If we use the iterative CG - Steihaug approach , Algorithm 7 . 2 , the condition ( 10 . 42 ) is satisﬁed automatically for c 1 (cid:3) 1 / 2 , since the Cauchy point is the ﬁrst estimate of p k computed by this approach , while subsequent estimates give smaller values for the model function . The local convergence behavior of Levenberg – Marquardt is similar to the Gauss – Newton method . Near a solution x ∗ at which the ﬁrst term of the Hessian ∇ 2 f ( x ∗ ) ( 10 . 5 ) dominates the second term , the model function in ( 10 . 31 ) , the trust region becomes inactive and the algorithm takes Gauss – Newton steps , giving the rapid local convergence expression ( 10 . 30 ) . METHODS FOR LARGE - RESIDUAL PROBLEMS In large - residual problems , the quadratic model in ( 10 . 31 ) is an inadequate repre - sentation of the function f because the second - order part of the Hessian ∇ 2 f ( x ) is too signiﬁcant to be ignored . In data - ﬁtting problems , the presence of large residuals may indicate that the model is inadequate or that errors have been made in monitoring the observations . Still , the practitioner may need to solve the least - squares problem with the current model and data , to indicate where improvements are needed in the weighting of observations , modeling , or data collection . On large - residual problems , the asymptotic convergence rate of Gauss – Newton and Levenberg – Marquardt algorithms is only linear—slower than the superlinear convergence rate attained by algorithms for general unconstrained problems , such as Newton or quasi - Newton . If the individual Hessians ∇ 2 r j are easy to calculate , it may be better to ignore the structure of the least - squares objective and apply Newton’s method with trust region or line search to the problem of minimizing f . Quasi - Newton methods , which attain a superlin - ear convergence rate without requiring calculation of ∇ 2 r j , are another option . However , the behavior of both Newton and quasi - Newton on early iterations ( before reaching a neighborhoodofthesolution ) maybeinferiortoGauss – NewtonandLevenberg – Marquardt . 1 0 . 3 . A L G O R I T H M S F O R N O N L I N E A R L E A S T - S Q U A R E S P R O B L E M S 263 Of course , we often do not know beforehand whether a problem will turn out to have small or large residuals at the solution . It seems reasonable , therefore , to consider hybrid algorithms , which would behave like Gauss – Newton or Levenberg – Marquardt if the residuals turn out to be small ( and hence take advantage of the cost savings associated with these methods ) but switch to Newton or quasi - Newton steps if the residuals at the solution appear to be large . There are a couple of ways to construct hybrid algorithms . One approach , due to Fletcher and Xu ( see Fletcher [ 101 ] ) , maintains a sequence of positive deﬁnite Hessian ap - proximations B k . If the Gauss – Newton step from x k reduces the function f by a certain ﬁxed amount ( say , a factor of 5 ) , then this step is taken and B k is overwritten by J Tk J k . Otherwise , a direction is computed using B k , and the new point x k + 1 is obtained by per - forming a line search . In either case , a BFGS - like update is applied to B k to obtain a new approximation B k + 1 . In the zero - residual case , the method eventually always takes Gauss – Newton steps ( giving quadratic convergence ) , while it eventually reduces to BFGS in the nonzero - residual case ( giving superlinear convergence ) . Numerical results in Fletcher [ 101 , Tables 6 . 1 . 2 , 6 . 1 . 3 ] show good results for this approach on small - , large - , and zero - residual problems . A second way to combine Gauss – Newton and quasi - Newton ideas is to maintain approximations to just the second - order part of the Hessian . That is , we maintain a sequence of matrices S k that approximate the summation term (cid:4) mj (cid:3) 1 r j ( x k ) ∇ 2 r j ( x k ) in ( 10 . 5 ) , and then use the overall Hessian approximation B k (cid:3) J Tk J k + S k in a trust - region or line search model for calculating the step p k . Updates to S k are devised so that the approximate Hessian B k , or its constituent parts , mimics the behavior of the corresponding exact quantities over the step just taken . The update formula is based on a secant equation , which arises also in the context of unconstrained minimization ( 6 . 6 ) and nonlinear equations ( 11 . 27 ) . In the present instance , there are a number of different ways to deﬁne the secant equation and to specify the other conditions needed for a complete update formula for S k . We describe the algorithm of Dennis , Gay , and Welsch [ 90 ] , which is probably the best - known algorithm in this class because of its implementation in the well - known NL 2 SOL package . In [ 90 ] , the secant equation is motivated in the following way . Ideally , S k + 1 should be a close approximation to the exact second - order term at x (cid:3) x k + 1 ; that is , S k + 1 ≈ m (cid:3) j (cid:3) 1 r j ( x k + 1 ) ∇ 2 r j ( x k + 1 ) . Since we do not want to calculate the individual Hessians ∇ 2 r j in this formula , we could replace each of them with an approximation ( B j ) k + 1 and impose the condition that ( B j ) k + 1 264 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S should mimic the behavior of its exact counterpart ∇ 2 r j over the step just taken ; that is , ( B j ) k + 1 ( x k + 1 − x k ) (cid:3) ∇ r j ( x k + 1 ) − ∇ r j ( x k ) (cid:3) ( row j of J ( x k + 1 ) ) T − ( row j of J ( x k ) ) T . This condition leads to a secant equation on S k + 1 , namely , S k + 1 ( x k + 1 − x k ) (cid:3) m (cid:3) j (cid:3) 1 r j ( x k + 1 ) ( B j ) k + 1 ( x k + 1 − x k ) (cid:3) m (cid:3) j (cid:3) 1 r j ( x k + 1 ) (cid:9) ( row j of J ( x k + 1 ) ) T − ( row j of J ( x k ) ) T (cid:10) (cid:3) J Tk + 1 r k + 1 − J Tk r k + 1 . As usual , this condition does not completely specify the new approximation S k + 1 . Dennis , Gay , and Welsch add requirements that S k + 1 be symmetric and that the difference S k + 1 − S k from the previous estimate S k be minimized in a certain sense , and derive the following update formula : S k + 1 (cid:3) S k + ( y (cid:24) − S k s ) y T + y ( y (cid:24) − S k s ) T y T s − ( y (cid:24) − S k s ) T s ( y T s ) 2 yy T , ( 10 . 43 ) where s (cid:3) x k + 1 − x k , y (cid:3) J Tk + 1 r k + 1 − J Tk r k , y (cid:24) (cid:3) J Tk + 1 r k + 1 − J Tk r k + 1 . Note that ( 10 . 43 ) is a slight variant on the DFP update for unconstrained minimization . It would be identical if y (cid:24) and y were the same . Dennis , Gay , and Welsch use their approximate Hessian J Tk J k + S k in conjunction with a trust - region strategy , but a few more features are needed to enhance its performance . One deﬁciency of its basic update strategy for S k is that this matrix is not guaranteed to vanish as the iterates approach a zero - residual solution , so it can interfere with superlinear convergence . This problem is avoided by scaling S k prior to its update ; we replace S k by τ k S k on the right - hand - side of ( 10 . 43 ) , where τ k (cid:3) min (cid:17) 1 , | s T y (cid:24) | | s T S k s | (cid:18) . 1 0 . 4 . O R T H O G O N A L D I S T A N C E R E G R E S S I O N 265 A ﬁnal modiﬁcation in the overall algorithm is that the S k term is omitted from the Hessian approximation when the resulting Gauss – Newton model produces a sufﬁciently good step . 10 . 4 ORTHOGONAL DISTANCE REGRESSION In Example 10 . 1 we assumed that no errors were made in noting the time at which the blood samples were drawn , so that the differences between the model φ ( x ; t j ) and the observation y j were due to inadequacy in the model or measurement errors in y j . We assumed that any errors in the ordinates—the times t j —are tiny by comparison with the errors in the observations . This assumption often is reasonable , but there are cases where the answer can be seriously distorted if we fail to take possible errors in the ordinates into account . Models that take these errors into account are known in the statistics literature as errors - in - variables models [ 280 , Chapter 10 ] , and the resulting optimization problems are referred to as total least squares in the case of a linear model ( see Golub and Van Loan [ 136 , Chapter 5 ] ) or as orthogonal distance regression in the nonlinear case ( see Boggs , Byrd , and Schnabel [ 30 ] ) . We formulate this problem mathematically by introducing perturbations δ j for the ordinates t j , as well as perturbations (cid:9) j for y j , and seeking the values of these 2 m perturba - tions that minimize the discrepancy between the model and the observations , as measured by a weighted least - squares objective function . To be precise , we relate the quantities t j , y j , δ j , and (cid:9) j by y j (cid:3) φ ( x ; t j + δ j ) + (cid:9) j , j (cid:3) 1 , 2 , . . . , m , ( 10 . 44 ) and deﬁne the minimization problem as min x , δ j , (cid:9) j 12 m (cid:3) j (cid:3) 1 w 2 j (cid:9) 2 j + d 2 j δ 2 j , subject to ( 10 . 44 ) . ( 10 . 45 ) The quantities w i and d i are weights , selected either by the modeler or by some automatic estimate of the relative signiﬁcance of the error terms . It is easy to see how the term “orthogonal distance regression” originates when we graph this problem ; see Figure 10 . 2 . If all the weights w i and d i are equal , then each term in the summation ( 10 . 45 ) is simply the shortest distance between the point ( t j , y j ) and the curve φ ( x ; t ) ( plotted as a function of t ) . The shortest path between each point and the curve is orthogonal to the curve at the point of intersection . Using the constraints ( 10 . 44 ) to eliminate the variables (cid:9) j from ( 10 . 45 ) , we obtain the unconstrained least - squares problem min x , δ F ( x , δ ) (cid:3) 12 m (cid:3) j (cid:3) 1 w 2 j [ y j − φ ( x ; t j + δ j ) ] 2 + d 2 j δ 2 j (cid:3) 12 2 m (cid:3) j (cid:3) 1 r 2 j ( x , δ ) , ( 10 . 46 ) 266 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S t 3 t 4 t 1 t 2 t 5 t 6 t 7 t y Figure 10 . 2 Orthogonal distance regression minimizes the sum of squares of the distance from each point to the curve . where δ (cid:3) ( δ 1 , δ 2 , . . . , δ m ) T and we have deﬁned r j ( x , δ ) (cid:3) (cid:21) w j [ φ ( x ; t j + δ j ) − y j ] , j (cid:3) 1 , 2 , . . . , m , d j − m δ j − m , j (cid:3) m + 1 , . . . , 2 m . ( 10 . 47 ) Note that ( 10 . 46 ) is now a standard least - squares problem with 2 m residuals and m + n unknowns , which we can solve by using the techniques in this chapter . A naive implementa - tion of this strategy may , however , be quite expensive , since the number of parameters ( 2 n ) and the number of observations ( m + n ) may both be much larger than for the original problem . Fortunately , the Jacobian matrix for ( 10 . 46 ) has a special structure that can be ex - ploited in implementing the Gauss – Newton or Levenberg – Marquardt methods . Many of its components are zero ; for instance , we have ∂ r j ∂δ i (cid:3) ∂ [ φ ( t j + δ j ; x ) − y j ] ∂δ i (cid:3) 0 , i , j (cid:3) 1 , 2 , . . . , m , i (cid:9)(cid:3) j , and ∂ r j ∂ x i (cid:3) 0 , j (cid:3) m + 1 , . . . , 2 m , i (cid:3) 1 , 2 , . . . , n . 1 0 . 4 . O R T H O G O N A L D I S T A N C E R E G R E S S I O N 267 Additionally , we have for j (cid:3) 1 , 2 , . . . , m and i (cid:3) 1 , 2 , . . . , m that ∂ r m + j ∂δ i (cid:3) (cid:21) d j if i (cid:3) j , 0 otherwise . Hence , we can partition the Jacobian of the residual function r deﬁned by ( 10 . 47 ) into blocks and write J ( x , δ ) (cid:3) (cid:1) ˆ J V 0 D (cid:2) , ( 10 . 48 ) where V and D are m × m diagonal matrices and ˆ J is the m × n matrix of partial derivatives of the functions w j φ ( t j + δ j ; x ) with respect to x . Boggs , Byrd , and Schnabel [ 30 ] ) apply the Levenberg – Marquardt algorithm to ( 10 . 46 ) and note that block elimination can be used to solve the subproblems ( 10 . 33 ) , ( 10 . 35 ) efﬁciently . Given the partitioning ( 10 . 48 ) , we can partition the step vector p and the residual vector r accordingly as p (cid:3) (cid:1) p x p δ (cid:2) , r (cid:3) (cid:1) ˆ r 1 ˆ r 2 (cid:2) , and write the normal equations ( 10 . 33 ) in the partitioned form (cid:1) ˆ J T ˆ J + λ I ˆ J T V V ˆ J V 2 + D 2 + λ I (cid:2) (cid:1) p x p δ (cid:2) (cid:3) − (cid:1) ˆ J T ˆ r 1 V ˆ r 1 + D ˆ r 2 (cid:2) . ( 10 . 49 ) Since the lower right submatrix V 2 + D 2 + λ I is diagonal , it is easy to eliminate p δ from this system and obtain a smaller n × n system to be solved for p x alone . The total cost of ﬁnding a step is only marginally greater than for the m × n problem arising from the standard least - squares model . NOTES AND REFERENCES Algorithms for linear least squares are discussed comprehensively by Bj¨orck [ 29 ] , who includes detailed error analyses of the different algorithms and software listings . He considers not just the basic problem ( 10 . 13 ) but also the situation in which there are bounds ( for example , x ≥ 0 ) or linear constraints ( for example , Ax ≥ b ) on the variables . Golub and Van Loan [ 136 , Chapter 5 ] survey the state of the art , including discussion of the suitability of the different approaches ( for example , normal equations vs . QR factorization ) for different problem types . A classical reference on linear least - squares is Lawson and Hanson [ 188 ] . 268 C H A P T E R 1 0 . L E A S T - S Q U A R E S P R O B L E M S Very large nonlinear least - squares problems arise in numerous areas of application , such as medical imaging , geophysics , economics , and engineering design . In many instances , both the number of variables n and the number of residuals m is large , but it is also quite common that only m is large . The original description of the Levenberg – Marquardt algorithm [ 190 , 203 ] did not make the connection with the trust - region concept . Rather , it adjusted the value of λ in ( 10 . 33 ) directly , increasing or decreasing it by a certain factor according to whether or not the previous trial step was effective in decreasing f ( · ) . ( The heuristics for adjusting λ were analogous to those used for adjusting the trust - region radius (cid:6) k in Algorithm 4 . 1 . ) Similar convergence results to Theorem 10 . 3 can be proved for algorithms that use this approach ( see , for instance , Osborne [ 231 ] ) , independently of trust - region analysis . The connection with trust regions was ﬁrmly established by Mor´e [ 210 ] . Wright and Holt [ 318 ] present an inexact Levenberg – Marquardt approach for large - scale nonlinear least squares that manipulates the parameter λ directly rather than making use of the connection to trust - region algorithms . This method takes steps ¯ p k that , analogously to ( 7 . 2 ) and ( 7 . 3 ) in Chapter 7 , satisfy the system (cid:23)(cid:23)(cid:7) J Tk J k + λ k I (cid:8) ¯ p k + J Tk r k (cid:23)(cid:23) ≤ η k (cid:8) J Tk r k (cid:8) , for some η k ∈ [ 0 , η ] , where η ∈ ( 0 , 1 ) is a constant and { η k } is a forcing sequence . A ratio of actual to pre - dicted decrease is used to decide whether the step ¯ p k should be taken , and convergence to stationary points can be proved under certain assumptions . The method can be imple - mented efﬁciently by using Algorithm LSQR of Paige and Saunders [ 234 ] to calculate the approximate solution of ( 10 . 35 ) since , for a small marginal cost , this algorithm can compute approximate solutions for a number of different values of λ k simultaneously . Hence , we can compute values of ¯ p k corresponding to a range of values of λ k , and choose the actual step to be the one corresponding to the smallest λ k for which the actual - predicted decrease ratio is satisfactory . Nonlinear least squares software is fairly prevalent because of the high demand for it . Major numerical software libraries such as IMSL , HSL , NAG , and SAS , as well as programming environments such as Mathematica and Matlab , contain robust nonlinear least - squares implementations . Other high quality implmentations include DFNLP , MINPACK , NL 2 SOL , and NLSSOL ; see Mor´e and Wright [ 217 , Chapter 3 ] . The nonlinear programming packages LANCELOT , KNITRO , and SNOPT provide large - scale implementions of the Gauss – Newton and Levenberg – Marquardt methods . The orthogonal distance regression algorithm is implemented by ORDPACK [ 31 ] . All these routines ( which can be accessed through the web ) give the user the option of either supplying Jacobians explicitly or else allowing the code to compute them by ﬁnite differencing . ( In the latter case , the user need only write code to compute the residual vector r ( x ) ; see Chapter 8 . ) Seber and Wild [ 280 , Chapter 15 ] describe some of the important practical issues in selecting software for statistical applications . 1 0 . 4 . O R T H O G O N A L D I S T A N C E R E G R E S S I O N 269 ✐ E X E R C I S E S ✐ 10 . 1 Let J be an m × n matrix with m ≥ n , and let y ∈ IR m be a vector . ( a ) Show that J has full column rank if and only if J T J is nonsingular . ( b ) Show that J has full column rank if and only if J T J is positive deﬁnite . ✐ 10 . 2 Show that the function f ( x ) in ( 10 . 13 ) is convex . ✐ 10 . 3 Show that ( a ) if Q is an orthogonal matrix , then (cid:8) Qx (cid:8) (cid:3) (cid:8) x (cid:8) for any vector x ; ( b ) the matrices ¯ R in ( 10 . 15 ) and R in ( 10 . 17 ) are identical if (cid:23) (cid:3) I , provided that J has full column rank n . ✐ 10 . 4 ( a ) Show that x ∗ deﬁned in ( 10 . 22 ) is a minimizer of ( 10 . 13 ) . ( b ) Find (cid:8) x ∗ (cid:8) and conclude that this norm is minimized when τ i (cid:3) 0 for all i with σ i (cid:3) 0 . ✐ 10 . 5 Suppose that each residual function r j and its gradient are Lipschitz continuous with Lipschitz constant L , that is , (cid:8) r j ( x ) − r j ( ˜ x ) (cid:8) ≤ L (cid:8) x − ˜ x (cid:8) , (cid:8)∇ r j ( x ) − ∇ r j ( ˜ x ) (cid:8) ≤ L (cid:8) x − ˜ x (cid:8) for all j (cid:3) 1 , 2 , . . . , m and all x , ˜ x ∈ D , where D is a compact subset of IR n . Assume also that the r j are bounded on D , that is , there exists M > 0 such that | r j ( x ) | ≤ M for all j (cid:3) 1 , 2 , . . . , m and all x ∈ D . Find Lipschitz constants for the Jacobian J ( 10 . 3 ) and the gradient ∇ f ( 10 . 4 ) over D . ✐ 10 . 6 Express the solution p of ( 10 . 33 ) in terms of the singular - value decomposition of J ( x ) and the scalar λ . Express its squared - norm (cid:8) p (cid:8) 2 in these same terms , and show that lim λ → 0 p (cid:3) (cid:3) σ i (cid:9)(cid:3) 0 u Ti r σ i v i . This is pag Printer : O C H A P T E R 11 Nonlinear Equations In many applications we do not need to optimize an objective function explicitly , but rather to ﬁnd values of the variables in a model that satisfy a number of given relationships . When these relationships take the form of n equalities—the same number of equality conditions as variables in the model—the problem is one of solving a system of nonlinear equations . We write this problem mathematically as r ( x ) (cid:3) 0 , ( 11 . 1 ) C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S 271 where r : IR n → IR n is a vector function , that is , r ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎣ r 1 ( x ) r 2 ( x ) . . . r n ( x ) ⎤ ⎥⎥⎥⎥⎥⎦ . In this chapter , we assume that each function r i : IR n → IR , i (cid:3) 1 , 2 , . . . , n , is smooth . A vector x ∗ for which ( 11 . 1 ) is satisﬁed is called a solution or root of the nonlinear equations . A simple example is the system r ( x ) (cid:3) (cid:1) x 22 − 1 sin x 1 − x 2 (cid:2) (cid:3) 0 , which is a system of n (cid:3) 2 equations with inﬁnitely many solutions , two of which are x ∗ (cid:3) ( 3 π / 2 , − 1 ) T and x ∗ (cid:3) ( π / 2 , 1 ) T . In general , the system ( 11 . 1 ) may have no solutions , a unique solution , or many solutions . The techniques for solving nonlinear equations overlap in their motivation , analysis , and implementation with optimization techniques discussed in earlier chapters . In both optimization and nonlinear equations , Newton’s method lies at the heart of many important algorithms . Features such as line searches , trust regions , and inexact solution of the linear algebra subproblems at each iteration are important in both areas , as are other issues such as derivative evaluation and global convergence . Because some important algorithms for nonlinear equations proceed by minimizing a sum of squares of the equations , that is , min x n (cid:3) i (cid:3) 1 r 2 i ( x ) , there are particularly close connections with the nonlinear least - squares problem discussed in Chapter 10 . The differences are that in nonlinear equations , the number of equations equals the number of variables ( instead of exceeding the number of variables , as is typically the case in Chapter 10 ) , and that we expect all equations to be satisﬁed at the solution , rather than just minimizing the sum of squares . This point is important because the nonlinear equations may represent physical or economic constraints such as conservation laws or consistency principles , which must hold exactly in order for the solution to be meaningful . Many applications require us to solve a sequence of closely related nonlinear systems , as in the following example . 272 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S ❏ E XAMPLE 11 . 1 ( R HEINBOLDT ; SEE [ 212 ] ) An interesting problem in control is to analyze the stability of an aircraft in response to the commands of the pilot . The following is a simpliﬁed model based on force - balance equations , in which gravity terms have been neglected . The equilibrium equations for a particular aircraft are given by a system of 5 equations in 8 unknowns of the form F ( x ) ≡ Ax + φ ( x ) (cid:3) 0 , ( 11 . 2 ) where F : IR 8 → IR 5 , the matrix A is given by A (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎣ − 3 . 933 0 . 107 0 . 126 0 − 9 . 99 0 − 45 . 83 − 7 . 64 0 − 0 . 987 0 − 22 . 95 0 − 28 . 37 0 0 0 . 002 0 − 0 . 235 0 5 . 67 0 − 0 . 921 − 6 . 51 0 1 . 0 0 − 1 . 0 0 − 0 . 168 0 0 0 0 − 1 . 0 0 − 0 . 196 0 − 0 . 0071 0 ⎤ ⎥⎥⎥⎥⎥⎥⎦ , and the nonlinear part is deﬁned by φ ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ − 0 . 727 x 2 x 3 + 8 . 39 x 3 x 4 − 684 . 4 x 4 x 5 + 63 . 5 x 4 x 2 0 . 949 x 1 x 3 + 0 . 173 x 1 x 5 − 0 . 716 x 1 x 2 − 1 . 578 x 1 x 4 + 1 . 132 x 4 x 2 − x 1 x 5 x 1 x 4 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ . The ﬁrst three variables x 1 , x 2 , x 3 , represent the rates of roll , pitch , and yaw , respec - tively , while x 4 is the incremental angle of attack and x 5 the sideslip angle . The last three variables x 6 , x 7 , x 8 are the controls ; they represent the deﬂections of the elevator , aileron , and rudder , respectively . For a given choice of the control variables x 6 , x 7 , x 8 we obtain a system of 5 equations and 5 unknowns . If we wish to study the behavior of the aircraft as the controls are changed , we need to solve a system of nonlinear equations with unknowns x 1 , x 2 , . . . , x 5 for each setting of the controls . ❐ Despite the many similarities between nonlinear equations and unconstrained and least - squares optimization algorithms , there are also some important differences . To ob - tain quadratic convergence in optimization we require second derivatives of the objective function , whereas knowledge of the ﬁrst derivatives is sufﬁcient in nonlinear equations . C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S 273 −3 −2 −1 0 1 2 3 −4 −3 −2 −1 0 1 2 3 4 Figure 11 . 1 The function r ( x ) (cid:3) sin ( 5 x ) − x has three roots . Quasi - Newton methods are perhaps less useful in nonlinear equations than in optimiza - tion . In unconstrained optimization , the objective function is the natural choice of merit function that gauges progress towards the solution , but in nonlinear equations various merit functions can be used , all of which have some drawbacks . Line search and trust - region tech - niques play an equally important role in optimization , but one can argue that trust - region algorithms have certain theoretical advantages in solving nonlinear equations . Some of the difﬁculties that arise in trying to solve nonlinear equations can be illustrated by a simple scalar example ( n (cid:3) 1 ) . Suppose we have r ( x ) (cid:3) sin ( 5 x ) − x , ( 11 . 3 ) as plotted in Figure 11 . 1 . From this ﬁgure we see that there are three solutions of the problem r ( x ) (cid:3) 0 , also known as roots of r , located at zero and approximately ± 0 . 519148 . This situation of multiple solutions is similar to optimization problems where , for example , a function may have more than one local minimum . It is not quite the same , however : In the case of optimization , one of the local minima may have a lower function value than the others ( making it a “better” solution ) , while in nonlinear equations all solutions are equally good from a mathematical viewpoint . ( If the modeler decides that the solution 274 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S found by the algorithm makes no sense on physical grounds , their model may need to be reformulated . ) In this chapter we start by outlining algorithms related to Newton’s method and examining their local convergence properties . Besides Newton’s method itself , these in - clude Broyden’s quasi - Newton method , inexact Newton methods , and tensor methods . We then address global convergence , which is the issue of trying to force convergence to a solution from a remote starting point . Finally , we discuss a class of methods in which an “easy” problem—one to which the solution is well known—is gradually transformed into the problem F ( x ) (cid:3) 0 . In these so - called continuation ( or homotopy ) methods , we track the solution as the problem changes , with the aim of ﬁnishing up at a solution of F ( x ) (cid:3) 0 . Throughout this chapter we make the assumption that the vector function r is con - tinuously differentiable in the region D containing the values of x we are interested in . In other words , the Jacobian J ( x ) ( the matrix of ﬁrst partial derivatives of r ( x ) deﬁned in the Appendix and in ( 10 . 3 ) ) exists and is continuous . We say that x ∗ satisfying r ( x ∗ ) (cid:3) 0 is a degenerate solution if J ( x ∗ ) is singular , and a nondegenerate solution otherwise . 11 . 1 LOCAL ALGORITHMS NEWTON’S METHOD FOR NONLINEAR EQUATIONS Recall from Theorem 2 . 1 that Newton’s method for minimizing f : IR n → IR forms a quadratic model function by taking the ﬁrst three terms of the Taylor series approximation of f around the current iterate x k . The Newton step is the vector that minimizes this model . In the case of nonlinear equations , Newton’s method is derived in a similar way , but with a linear model , one that involves function values and ﬁrst derivatives of the functions r i ( x ) , i (cid:3) 1 , 2 , . . . , m at the current iterate x k . We justify this strategy by referring to the following multidimensional variant of Taylor’s theorem . Theorem 11 . 1 . Suppose that r : IR n → IR n is continuously differentiable in some convex open set D and that x and x + p are vectors in D . We then have that r ( x + p ) (cid:3) r ( x ) + (cid:6) 1 0 J ( x + tp ) p dt . ( 11 . 4 ) We can deﬁne a linear model M k ( p ) of r ( x k + p ) by approximating the second term on the right - hand - side of ( 11 . 4 ) by J ( x ) p , and writing M k ( p ) def (cid:3) r ( x k ) + J ( x k ) p . ( 11 . 5 ) 1 1 . 1 . L O C A L A L G O R I T H M S 275 Newton’s method , in its pure form , chooses the step p k to be the vector for which M k ( p k ) (cid:3) 0 , that is , p k (cid:3) − J ( x k ) − 1 r ( x k ) . We deﬁne it formally as follows . Algorithm 11 . 1 ( Newton’s Method for Nonlinear Equations ) . Choose x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Calculate a solution p k to the Newton equations J ( x k ) p k (cid:3) − r ( x k ) ; ( 11 . 6 ) x k + 1 ← x k + p k ; end ( for ) We use a linear model to derive the Newton step , rather than a quadratic model as in unconstrained optimization , because the linear model normally has a solution and yields an algorithm with rapid convergence properties . In fact , Newton’s method for unconstrained optimization ( see ( 2 . 15 ) ) can be derived by applying Algorithm 11 . 1 to the nonlinear equations ∇ f ( x ) (cid:3) 0 . We see also in Chapter 18 that sequential quadratic programming for equality - constrained optimization can be derived by applying Algorithm 11 . 1 to the nonlinear equations formed by the ﬁrst - order optimality conditions ( 18 . 3 ) for this problem . Another connection is with the Gauss – Newton method for nonlinear least squares ; the formula ( 11 . 6 ) is equivalent to ( 10 . 23 ) in the usual case in which J ( x k ) is nonsingular . When the iterate x k is close to a nondegenerate root x ∗ , Newton’s method converges superlinearly , as we show in Theorem 11 . 2 below . Potential shortcomings of the method include the following . • When the starting point is remote from a solution , Algorithm 11 . 1 can behave erratically . When J ( x k ) is singular , the Newton step may not even be deﬁned . • First - derivative information ( the Jacobian matrix J ) may be difﬁcult to obtain . • It may be too expensive to ﬁnd and calculate the Newton step p k exactly when n is large . • The root x ∗ in question may be degenerate , that is , J ( x ∗ ) may be singular . An example of a degenerate problem is the scalar function r ( x ) (cid:3) x 2 , which has a single degenerate root at x ∗ (cid:3) 0 . Algorithm 11 . 1 , when started from any nonzero x 0 , generates the sequence of iterates x k (cid:3) 1 2 k x 0 , which converges to the solution 0 , but only at a linear rate . As we show later in this chapter , Newton’s method can be modiﬁed and enhanced in various ways to get around most of these problems . The variants we describe form the basis of much of the available software for solving nonlinear equations . 276 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S We summarize the local convergence properties of Algorithm 11 . 1 in the following theorem . For part of this result , we make use of a Lipschitz continuity assumption on the Jacobian , by which we mean that there is a constant β L such that (cid:8) J ( x 0 ) − J ( x 1 ) (cid:8) ≤ β L (cid:8) x 0 − x 1 (cid:8) , ( 11 . 7 ) for all x 0 and x 1 in the domain in question . Theorem 11 . 2 . Suppose that r is continuously differentiable in a convex open set D ⊂ IR n . Let x ∗ ∈ D be a nondegenerate solution of r ( x ) (cid:3) 0 , and let { x k } be the sequence of iterates generated by Algorithm 11 . 1 . Then when x k ∈ D is sufﬁciently close to x ∗ , we have x k + 1 − x ∗ (cid:3) o ( (cid:8) x k − x ∗ (cid:8) ) , ( 11 . 8 ) indicating local Q - superlinear convergence . When r is Lipschitz continuously differentiable near x ∗ , we have for all x k sufﬁciently close to x ∗ that x k + 1 − x ∗ (cid:3) O ( (cid:8) x k − x ∗ (cid:8) 2 ) , ( 11 . 9 ) indicating local Q - quadratic convergence . P ROOF . Since r ( x ∗ ) (cid:3) 0 , we have from Theorem 11 . 1 that r ( x k ) (cid:3) r ( x k ) − r ( x ∗ ) (cid:3) J ( x k ) ( x k − x ∗ ) + w ( x k , x ∗ ) , ( 11 . 10 ) where w ( x k , x ∗ ) (cid:3) (cid:6) 1 0 (cid:9) J ( x k + t ( x ∗ − x k ) ) − J ( x k ) (cid:10) ( x k − x ∗ ) . ( 11 . 11 ) From ( A . 12 ) and continuity of J , we have (cid:8) w ( x k , x ∗ ) (cid:8) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:6) 1 0 [ J ( x ∗ + t ( x ∗ − x k ) ) − J ( x k ) ] ( x k − x ∗ ) dt (cid:23)(cid:23)(cid:23)(cid:23) ≤ (cid:6) 1 0 (cid:8) J ( x ∗ + t ( x ∗ − x k ) ) − J ( x k ) (cid:8) (cid:8) x k − x ∗ (cid:8) dt ( 11 . 12 ) (cid:3) o ( (cid:8) x k − x ∗ (cid:8) ) . Since J ( x ∗ ) is nonsingular , there is a radius δ > 0 and a positive constant β ∗ such that for all x in the ball B ( x ∗ , δ ) deﬁned by B ( x ∗ , δ ) (cid:3) { x | (cid:8) x − x ∗ (cid:8) ≤ δ } , ( 11 . 13 ) 1 1 . 1 . L O C A L A L G O R I T H M S 277 we have that (cid:8) J ( x ) − 1 (cid:8) ≤ β ∗ and x ∈ D . ( 11 . 14 ) Assuming that x k ∈ B ( x ∗ , δ ) , and recalling the deﬁnition ( 11 . 6 ) , we multiply both sides of ( 11 . 10 ) by J ( x k ) − 1 to obtain − p k (cid:3) ( x k − x ∗ ) + (cid:8) J ( x k ) − 1 (cid:8) o ( (cid:8) x k − x ∗ (cid:8) ) , ⇒ x k + p k − x ∗ (cid:3) o ( (cid:8) x k − x ∗ (cid:8) ) , ⇒ x k + 1 − x ∗ (cid:3) o ( (cid:8) x k − x ∗ (cid:8) ) , ( 11 . 15 ) which yields ( 11 . 8 ) . When the Lipschitz continuity assumption ( 11 . 7 ) is satisﬁed , we can obtain a sharper estimate for the remainder term w ( x k , x ∗ ) deﬁned in ( 11 . 11 ) . By using ( 11 . 7 ) in ( 11 . 12 ) , we obtain (cid:8) w ( x k , x ∗ ) (cid:8) (cid:3) O ( (cid:8) x k − x ∗ (cid:8) 2 ) . ( 11 . 16 ) By multiplying ( 11 . 10 ) by J ( x k ) − 1 as above , we obtain − p k − ( x k − x ∗ ) (cid:3) J ( x k ) − 1 w ( x k , x ∗ ) , so the estimate ( 11 . 9 ) follows as in ( 11 . 15 ) . (cid:1) INEXACT NEWTON METHODS Instead of solving ( 11 . 6 ) exactly , inexact Newton methods use search directions p k that satisfy the condition (cid:8) r k + J k p k (cid:8) ≤ η k (cid:8) r k (cid:8) , for some η k ∈ [ 0 , η ] , ( 11 . 17 ) where η ∈ [ 0 , 1 ) is a constant . As in Chapter 7 , we refer to { η k } as the forcing sequence . Different methods make different choices of the forcing sequence , and they use different algorithms for ﬁnding the approximate solutions p k . The general framework for this class of methods can be stated as follows . Framework 11 . 2 ( Inexact Newton for Nonlinear Equations ) . Given η ∈ [ 0 , 1 ) ; Choose x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Choose forcing parameter η k ∈ [ 0 , η ] ; Find a vector p k that satisﬁes ( 11 . 17 ) ; x k + 1 ← x k + p k ; end ( for ) 278 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S The convergence theory for these methods depends only on the condition ( 11 . 17 ) and not on the particular technique used to calculate p k . The most important methods in this class , however , make use of iterative techniques for solving linear systems of the form Jp (cid:3) − r , such as GMRES ( Saad and Schultz [ 273 ] , Walker [ 302 ] ) or other Krylov - space methods . Like the conjugate - gradient algorithm of Chapter 5 ( which is not directly applicable here , since the coefﬁcient matrix J is not symmetric positive deﬁnite ) , these methods typically require us to perform a matrix – vector multiplication of the form Jd for some d at each iteration , and to store a number of work vectors of length n . GMRES requires an additional vector to be stored at each iteration , so must be restarted periodically ( often every 10 or 20 iterations ) to keep memory requirements at a reasonable level . The matrix – vector products Jd can be computed without explicit knowledge of the Jacobian J . A ﬁnite - difference approximation to Jd that requires one evaluation of r ( · ) is given by the formula ( 8 . 11 ) . Calculation of Jd exactly ( at least , to within the limits of ﬁnite - precision arithmetic ) can be performed by using the forward mode of automatic differentiation , at a cost of at most a small multiple of an evaluation of r ( · ) . Details of this procedure are given in Section 8 . 2 . We do not discuss the iterative methods for sparse linear systems here , but refer the interested reader to Kelley [ 177 ] and Saad [ 272 ] for comprehensive descriptions and implementations of the most interesting techniques . We prove a local convergence theorem for the method , similar to Theorem 11 . 2 . Theorem 11 . 3 . Suppose that r is continuously differentiable in a convex open set D ⊂ IR n . Let x ∗ ∈ D be a nondegenerate solution of r ( x ) (cid:3) 0 , and let { x k } be the sequence of iterates generated by the Framework 11 . 2 . Then when x k ∈ D is sufﬁciently close to x ∗ , the following are true : ( i ) If η in ( 11 . 17 ) is sufﬁciently small , the convergence of { x k } to x ∗ is Q - linear . ( ii ) If η k → 0 , the convergence is Q - superlinear . ( iii ) If , in addition , J ( · ) is Lipschitz continuous in a neighborhood of x ∗ and η k (cid:3) O ( (cid:8) r k (cid:8) ) , the convergence is Q - quadratic . P ROOF . We ﬁrst rewrite ( 11 . 17 ) as J ( x k ) p k + r ( x k ) (cid:3) v k , where (cid:8) v k (cid:8) ≤ η k (cid:8) r ( x k ) (cid:8) . ( 11 . 18 ) Since x ∗ is a nondegenerate root , we have as in ( 11 . 14 ) that there is a radius δ > 0 such that (cid:8) J ( x ) − 1 (cid:8) ≤ β ∗ for some constant β ∗ and all x ∈ B ( x ∗ , δ ) . By multiplying both sides of ( 11 . 18 ) by J ( x k ) − 1 and rearranging , we ﬁnd that (cid:23) (cid:23) p k + J ( x k ) − 1 r ( x k ) (cid:23) (cid:23) (cid:3) (cid:23) (cid:23) J ( x k ) − 1 v k (cid:23) (cid:23) ≤ β ∗ η k (cid:8) r ( x k ) (cid:8) . ( 11 . 19 ) 1 1 . 1 . L O C A L A L G O R I T H M S 279 As in ( 11 . 10 ) , we have that r ( x ) (cid:3) J ( x ) ( x − x ∗ ) + w ( x , x ∗ ) , ( 11 . 20 ) where ρ ( x ) def (cid:3) (cid:8) w ( x , x ∗ ) (cid:8) / (cid:8) x − x ∗ (cid:8) → 0 as x → x ∗ . By reducing δ if necessary , we have from this expression that the following bound holds for all x ∈ B ( x ∗ , δ ) : (cid:8) r ( x ) (cid:8) ≤ 2 (cid:8) J ( x ∗ ) (cid:8) (cid:8) x − x ∗ (cid:8) + o ( (cid:8) x − x ∗ (cid:8) ) ≤ 4 (cid:8) J ( x ∗ ) (cid:8) (cid:8) x − x ∗ (cid:8) . ( 11 . 21 ) We now set x (cid:3) x k in ( 11 . 20 ) , and use ( 11 . 19 ) and ( 11 . 21 ) to obtain (cid:8) x k + p k − x ∗ (cid:8) (cid:3) (cid:23)(cid:23) p k + J ( x k ) − 1 ( r ( x k ) − w ( x k , x ∗ ) ) (cid:23)(cid:23) ≤ β ∗ η k (cid:8) r ( x k ) (cid:8) + (cid:8) J ( x k ) − 1 (cid:8)(cid:8) w ( x k , x ∗ ) (cid:8) ≤ (cid:9) 4 (cid:8) J ( x ∗ ) (cid:8) β ∗ η k + β ∗ ρ ( x k ) (cid:10) (cid:8) x k − x ∗ (cid:8) . ( 11 . 22 ) By choosing x k close enough to x ∗ that ρ ( x k ) ≤ 1 / ( 4 β ∗ ) , and choosing η (cid:3) 1 / ( 8 (cid:8) J ( x ∗ ) (cid:8) β ∗ ) , we have that the term in square brackets in ( 11 . 22 ) is at most 1 / 2 . Hence , since x k + 1 (cid:3) x k + p k , this formula indicates Q - linear convergence of { x k } to x ∗ , proving part ( i ) . Part ( ii ) follows immediately from the fact that the term in brackets in ( 11 . 22 ) goes to zero as x k → x ∗ and η k → 0 . For part ( iii ) , we combine the techniques above with the logic of the second part of the proof of Theorem 11 . 2 . Details are left as an exercise . (cid:1) BROYDEN’S METHOD Secant methods , also known as quasi - Newton methods , do not require calculation of the Jacobian J ( x ) . Instead , they construct their own approximation to this matrix , updating it at each iteration so that it mimics the behavior of the true Jacobian J over the step just taken . The approximate Jacobian , which we denote at iteration k by B k , is then used to construct a linear model analogous to ( 11 . 5 ) , namely M k ( p ) (cid:3) r ( x k ) + B k p . ( 11 . 23 ) We obtain the step by setting this model to zero . When B k is nonsingular , we have the following explicit formula ( cf . ( 11 . 6 ) ) : p k (cid:3) − B − 1 k r ( x k ) . ( 11 . 24 ) The requirement that the approximate Jacobian should mimic the behavior of the true Jacobian can be speciﬁed as follows . Let s k denote the step from x k to x k + 1 , and let y k 280 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S be the corresponding change in r , that is , s k (cid:3) x k + 1 − x k , y k (cid:3) r ( x k + 1 ) − r ( x k ) . ( 11 . 25 ) From Theorem 11 . 1 , we have that s k and y k are related by the expression y k (cid:3) (cid:6) 1 0 J ( x k + ts k ) s k dt ≈ J ( x k + 1 ) s k + o ( (cid:8) s k (cid:8) ) . ( 11 . 26 ) We require the updated Jacobian approximation B k + 1 to satisfy the following equation , which is known as the secant equation , y k (cid:3) B k + 1 s k , ( 11 . 27 ) which ensures that B k + 1 and J ( x k + 1 ) have similar behavior along the direction s k . ( Note the similarity with the secant equation ( 6 . 6 ) in quasi - Newton methods for unconstrained optimization ; the motivation is the same in both cases . ) The secant equation does not say anything about how B k + 1 should behave along directions orthogonal to s k . In fact , we can view ( 11 . 27 ) as a system of n linear equations in n 2 unknowns , where the unknowns are the components of B k + 1 , so for n > 1 the equation ( 11 . 27 ) does not determine all the components of B k + 1 uniquely . ( The scalar case of n (cid:3) 1 gives rise to the scalar secant method ; see ( A . 60 ) . ) The most successful practical algorithm is Broyden’s method , for which the update formula is B k + 1 (cid:3) B k + ( y k − B k s k ) s Tk s T k s k . ( 11 . 28 ) The Broyden update makes the smallest possible change to the Jacobian ( as measured by the Euclidean norm (cid:8) B k − B k + 1 (cid:8) 2 ) that is consistent with ( 11 . 27 ) , as we show in the following Lemma . Lemma 11 . 4 ( Dennis and Schnabel [ 92 , Lemma 8 . 1 . 1 ] ) . Among all matrices B satisfying Bs k (cid:3) y k , the matrix B k + 1 deﬁned by ( 11 . 28 ) minimizes the difference (cid:8) B − B k (cid:8) . P ROOF . Let B be any matrix that satisﬁes Bs k (cid:3) y k . By the properties of the Euclidean norm ( see ( A . 10 ) ) and the fact that (cid:8) ss T / s T s (cid:8) (cid:3) 1 for any vector s ( see Exercise 11 . 1 ) , we have (cid:8) B k + 1 − B k (cid:8) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23) ( y k − B k s k ) s Tk s Tk s k (cid:23)(cid:23)(cid:23)(cid:23) (cid:3) (cid:23)(cid:23) (cid:23) (cid:23) ( B − B k ) s k s T k s Tk s k (cid:23)(cid:23) (cid:23) (cid:23) ≤ (cid:8) B − B k (cid:8) (cid:23)(cid:23) (cid:23) (cid:23) s k s T k s Tk s k (cid:23)(cid:23) (cid:23) (cid:23) (cid:3) (cid:8) B − B k (cid:8) . 1 1 . 1 . L O C A L A L G O R I T H M S 281 Hence , we have that B k + 1 ∈ arg min B : y k (cid:3) Bs k (cid:8) B − B k (cid:8) , and the result is proved . (cid:1) In the speciﬁcation of the algorithm below , we allow a line search to be performed along the search direction p k , so that s k (cid:3) α p k for some α > 0 in the formula ( 11 . 25 ) . ( See below for details about line - search methods . ) Algorithm 11 . 3 ( Broyden ) . Choose x 0 and a nonsingular initial Jacobian approximation B 0 ; for k (cid:3) 0 , 1 , 2 , . . . Calculate a solution p k to the linear equations B k p k (cid:3) − r ( x k ) ; ( 11 . 29 ) Choose α k by performing a line search along p k ; x k + 1 ← x k + α k p k ; s k ← x k + 1 − x k ; y k ← r ( x k + 1 ) − r ( x k ) ; Obtain B k + 1 from the formula ( 11 . 28 ) ; end ( for ) Under certain assumptions , Broyden’s method converges superlinearly , that is , (cid:8) x k + 1 − x ∗ (cid:8) (cid:3) o ( (cid:8) x k − x ∗ (cid:8) ) . ( 11 . 30 ) This local convergence rate is fast enough for most practical purposes , though not as fast as the Q - quadratic convergence of Newton’s method . We illustrate the difference between the convergence rates of Newton’s and Broyden’s method with a small example . The function r : IR 2 → IR 2 deﬁned by r ( x ) (cid:3) (cid:1) ( x 1 + 3 ) ( x 3 2 − 7 ) + 18 sin ( x 2 e x 1 − 1 ) (cid:2) ( 11 . 31 ) has a nondegenerate root at x ∗ (cid:3) ( 0 , 1 ) T . We start both methods from the point x 0 (cid:3) ( − 0 . 5 , 1 . 4 ) T , and use the exact Jacobian J ( x 0 ) at this point as the initial Jacobian approximation B 0 . Results are shown in Table 11 . 1 . Newton’s method clearly exhibits Q - quadratic convergence , which is characterized by doubling of the exponent of the error at each iteration . Broyden’s method takes twice as 282 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S Table 11 . 1 Convergence of Iterates in Broyden and Newton Methods (cid:8) x k − x ∗ (cid:8) 2 Iteration k Broyden Newton 0 0 . 64 × 10 0 0 . 64 × 10 0 1 0 . 62 × 10 − 1 0 . 62 × 10 − 1 2 0 . 52 × 10 − 3 0 . 21 × 10 − 3 3 0 . 25 × 10 − 3 0 . 18 × 10 − 7 4 0 . 43 × 10 − 4 0 . 12 × 10 − 15 5 0 . 14 × 10 − 6 6 0 . 57 × 10 − 9 7 0 . 18 × 10 − 11 8 0 . 87 × 10 − 15 Table 11 . 2 Convergence of Function Norms in Broyden and Newton Methods (cid:8) r ( x k ) (cid:8) 2 Iteration k Broyden Newton 0 0 . 74 × 10 1 0 . 74 × 10 1 1 0 . 59 × 10 0 0 . 59 × 10 0 2 0 . 20 × 10 − 2 0 . 23 × 10 − 2 3 0 . 21 × 10 − 2 0 . 16 × 10 − 6 4 0 . 37 × 10 − 3 0 . 22 × 10 − 15 5 0 . 12 × 10 − 5 6 0 . 49 × 10 − 8 7 0 . 15 × 10 − 10 8 0 . 11 × 10 − 18 many iterations as Newton’s , and reduces the error at a rate that accelerates slightly towards the end . The function norms (cid:8) r ( x k ) (cid:8) approach zero at a similar rate to the iteration errors (cid:8) x k − x ∗ (cid:8) . As in ( 11 . 10 ) , we have that r ( x k ) (cid:3) r ( x k ) − r ( x ∗ ) ≈ J ( x ∗ ) ( x k − x ∗ ) , so by nonsingularity of J ( x ∗ ) , the norms of r ( x k ) and ( x k − x ∗ ) are bounded above and below by multiples of each other . For our example problem ( 11 . 31 ) , convergence of the sequence of function norms in the two methods is shown in Table 11 . 2 . The convergence analysis of Broyden’s method is more complicated than that of Newton’s method . We state the following result without proof . Theorem 11 . 5 . Suppose the assumptions of Theorem 11 . 2 hold . Then there are positive constants (cid:9) and δ such that if the starting point x 0 and the starting approximate Jacobian B 0 satisfy (cid:8) x 0 − x ∗ (cid:8) ≤ δ , (cid:8) B 0 − J ( x ∗ ) (cid:8) ≤ (cid:9) , ( 11 . 32 ) 1 1 . 1 . L O C A L A L G O R I T H M S 283 the sequence { x k } generated by Broyden’s method ( 11 . 24 ) , ( 11 . 28 ) is well - deﬁned and converges Q - superlinearly to x ∗ . The second condition in ( 11 . 32 ) —that the initial Jacobian approximation B 0 must be close to the true Jacobian at the solution J ( x ∗ ) —is difﬁcult to guarantee in practice . In contrast to the case of unconstrained minimization , a good choice of B 0 can be crit - ical to the performance of the algorithm . Some implementations of Broyden’s method recommend choosing B 0 to be J ( x 0 ) , or some ﬁnite - difference approximation to this matrix . The Broyden matrix B k will be dense in general , even if the true Jacobian J is sparse . Therefore , when n is large , an implementation of Broyden’s method that stores B k as a full n × n matrix may be inefﬁcient . Instead , we can use limited - memory methods in which B k is stored implicitly in the form of a number of vectors of length n , while the system ( 11 . 29 ) is solved by a technique based on application of the Sherman – Morrison – Woodbury formula ( A . 28 ) . These methods are similar to the ones described in Chapter 7 for large - scale unconstrained optimization . TENSOR METHODS In tensor methods , the linear model M k ( p ) used by Newton’s method ( 11 . 5 ) is aug - mented with an extra term that aims to capture some of the nonlinear , higher - order , behavior of r . By doing so , it achieves more rapid and reliable convergence to degenerate roots , in particular , to roots x ∗ for which the Jacobian J ( x ∗ ) has rank n − 1 or n − 2 . We give a broad outline of the method here , and refer to Schnabel and Frank [ 277 ] for details . We use ˆ M k ( p ) to denote the model function on which tensor methods are based ; this function has the form ˆ M k ( p ) (cid:3) r ( x k ) + J ( x k ) p + 12 T k pp , ( 11 . 33 ) where T k is a tensor deﬁned by n 3 elements ( T k ) ijl whose action on a pair of arbitrary vectors u and v in IR n is deﬁned by ( T k u v ) i (cid:3) n (cid:3) j (cid:3) 1 n (cid:3) l (cid:3) 1 ( T k ) ijl u j v l . If we followed the reasoning behind Newton’s method , we could consider building T k from the second derivatives of r at the point x k , that is , ( T k ) ijl (cid:3) [ ∇ 2 r i ( x k ) ] jl . 284 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S For instance , in the example ( 11 . 31 ) , we have that ( T ( x ) u v ) 1 (cid:3) u T ∇ 2 r 1 ( x ) v (cid:3) u T (cid:1) 0 3 x 22 3 x 22 6 x 2 ( x 1 + 3 ) (cid:2) v (cid:3) 3 x 22 ( u 1 v 2 + u 2 v 1 ) + 6 x 2 ( x 1 + 3 ) u 2 v 2 . However , use of the exact second derivatives is not practical in most instances . If we were to store this information explicitly , about n 3 / 2 memory locations would be needed , about n times the requirements of Newton’s method . Moreover , there may be no vector p for which ˆ M k ( p ) (cid:3) 0 , so the step may not even be deﬁned . Instead , the approach described in [ 277 ] deﬁnes T k in a way that requires little additional storage , but which gives ˆ M k some potentially appealing properties . Speciﬁcally , T k is chosen so that ˆ M k ( p ) interpolates the function r ( x k + p ) at some previous iterates visited by the algorithm . That is , we require that ˆ M k ( x k − j − x k ) (cid:3) r ( x k − j ) , for j (cid:3) 1 , 2 , . . . , q , ( 11 . 34 ) for some integer q > 0 . By substituting from ( 11 . 33 ) , we see that T k must satisfy the condition 12 T k s jk s jk (cid:3) r ( x k − j ) − r ( x k ) − J ( x k ) s jk , where s jk def (cid:3) x k − j − x k , j (cid:3) 1 , 2 , . . . , q . In [ 277 ] it is shown that this condition can be ensured by choosing T k so that its action on arbitrary vectors u and v is T k u v (cid:3) q (cid:3) j (cid:3) 1 a j ( s Tjk u ) ( s Tjk v ) , where a j , j (cid:3) 1 , 2 , . . . , q , are vectors of length n . The number of interpolating points q is typically chosen to be quite modest , usually less than √ n . This T k can be stored in 2 nq locations , which contain the vectors a j and s jk for j (cid:3) 1 , 2 , . . . , q . Note the connection between this idea and Broyden’s method , which also chooses information in the model ( albeit in the ﬁrst - order part of the model ) to interpolate the function value at the previous iterate . This technique can be reﬁned in various ways . The points of interpolation can be chosen to make the collection of directions s jk more linearly independent . There may still not be a vector p for which ˆ M k ( p ) (cid:3) 0 , but we can instead take the step to be the vector that 1 1 . 2 . P R A C T I C A L M E T H O D S 285 minimizes (cid:8) ˆ M k ( p ) (cid:8) 22 , which can be found by using a specialized least - squares technique . There is no assurance that the step obtained in this way is a descent direction for the merit function 12 (cid:8) r ( x ) (cid:8) 2 ( which is discussed in the next section ) , and in this case it can be replaced by the standard Newton direction − J − 1 k r k . 11 . 2 PRACTICAL METHODS We now consider practical variants of the Newton - like methods discussed above , in which line - search and trust - region modiﬁcations to the steps are made in order to ensure better global convergence behavior . MERIT FUNCTIONS As mentioned above , neither Newton’s method ( 11 . 6 ) nor Broyden’s method ( 11 . 24 ) , ( 11 . 28 ) with unit step lengths can be guaranteed to converge to a solution of r ( x ) (cid:3) 0 unless they are started close to that solution . Sometimes , components of the unknown or function vector or the Jacobian will blow up . Another , more exotic , kind of behavior is cycling , where the iterates move between distinct regions of the parameter space without approaching a root . An example is the scalar function r ( x ) (cid:3) − x 5 + x 3 + 4 x , which has ﬁve nondegenerate roots . When started from the point x 0 (cid:3) 1 , Newton’s method produces a sequence of iterates that oscillates between 1 and − 1 ( see Exercise 11 . 3 ) without converging to any of the roots . The Newton and Broyden methods can be made more robust by using line - search and trust - region techniques similar to those described in Chapters 3 and 4 . Before describing these techniques , we need to deﬁne a merit function , which is a scalar - valued function of x that indicates whether a new iterate is better or worse than the current iterate , in the sense of making progress toward a root of r . In unconstrained optimization , the objective function f is itself a natural merit function ; most algorithms for minimizing f require a decrease in f at each iteration . In nonlinear equations , the merit function is obtained by combining the n components of the vector r in some way . The most widely used merit function is the sum of squares , deﬁned by f ( x ) (cid:3) 12 (cid:8) r ( x ) (cid:8) 2 (cid:3) 12 n (cid:3) i (cid:3) 1 r 2 i ( x ) . ( 11 . 35 ) ( The factor 1 / 2 is introduced for convenience . ) Any root x ∗ of r obviously has f ( x ∗ ) (cid:3) 0 , and since f ( x ) ≥ 0 for all x , each root is a minimizer of f . However , local minimizers of f are not roots of r if f is strictly positive at the point in question . Still , the merit function 286 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S −3 −2 −1 0 1 2 3 0 1 2 3 4 5 6 Figure 11 . 2 Plot of 12 [ sin ( 5 x ) − x ] 2 , showing its many local minima . ( 11 . 35 ) has been used successfully in many applications and is implemented in a number of software packages . The merit function for the example ( 11 . 3 ) is plotted in Figure 11 . 2 . It shows three local minima corresponding to the three roots , but there are many other local minima ( for example , those at around ± 1 . 53053 ) . Local minima like these that are not roots of f satisfy an interesting property . Since ∇ f ( x ∗ ) (cid:3) J ( x ∗ ) T r ( x ∗ ) (cid:3) 0 , ( 11 . 36 ) we can have r ( x ∗ ) (cid:9)(cid:3) 0 only if J ( x ∗ ) is singular . Since local minima for the sum - of - squares merit function may be points of attraction for the algorithms described in this section , global convergence results for the algorithms discussed here are less satisfactory than for similar algorithms applied to unconstrained optimization . Other merit functions are also used in practice . One such is the (cid:1) 1 norm merit function deﬁned by f 1 ( x ) (cid:3) (cid:8) r ( x ) (cid:8) 1 (cid:3) m (cid:3) i (cid:3) 1 | r i ( x ) | . This function is studied in Chapters 17 and 18 in the context of algorithms for constrained optimization . 1 1 . 2 . P R A C T I C A L M E T H O D S 287 LINE SEARCH METHODS We can obtain algorithms with global convergence properties by applying the line - search approach of Chapter 3 to the sum - of - squares merit function f ( x ) (cid:3) 12 (cid:8) r ( x ) (cid:8) 2 . When it is well deﬁned , the Newton step J ( x k ) p k (cid:3) − r ( x k ) ( 11 . 37 ) is a descent direction for f ( · ) whenever r k (cid:9)(cid:3) 0 , since p Tk ∇ f ( x k ) (cid:3) − p Tk J Tk r k (cid:3) −(cid:8) r k (cid:8) 2 < 0 . ( 11 . 38 ) Step lengths α k are chosen by one of the procedures of Chapter 3 , and the iterates are deﬁned by the formula x k + 1 (cid:3) x k + α k p k , k (cid:3) 0 , 1 , 2 , . . . . ( 11 . 39 ) For the case of line searches that choose α k to satisfy the Wolfe conditions ( 3 . 6 ) , we have the following convergence result , which follows directly from Theorem 3 . 2 . Theorem 11 . 6 . Suppose that J ( x ) is Lipschitz continuous in a neighborhood D of the level set L (cid:3) { x : f ( x ) ≤ f ( x 0 ) } , and that (cid:8) J ( x ) (cid:8) and (cid:8) r ( x ) (cid:8) are bounded above on D . Suppose that a line - search algorithm ( 11 . 39 ) is applied to f , where the search directions p k satisfy p Tk ∇ f k < 0 while the step lengths α k satisfy the Wolfe conditions ( 3 . 6 ) . Then we have that the Zoutendijk condition holds , that is , (cid:3) k ≥ 0 cos 2 θ k (cid:8) J T k r k (cid:8) 2 < ∞ , where cos θ k (cid:3) − p Tk ∇ f ( x k ) (cid:8) p k (cid:8)(cid:8)∇ f ( x k ) (cid:8) . ( 11 . 40 ) We omit the proof , which veriﬁes that ∇ f is Lipschitz continuous on D and that f is bounded below ( by 0 ) on D , and then applies Theorem 3 . 2 . Provided that the sequence of iterates satisﬁes cos θ k ≥ δ , for some δ ∈ ( 0 , 1 ) and all k sufﬁciently large , ( 11 . 41 ) Theorem 11 . 6 guarantees that J Tk r k → 0 , meaning that the iterates approach stationarity of the merit function f . Moreover , if we know that (cid:8) J ( x k ) − 1 (cid:8) is bounded then we must have r k → 0 . 288 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S We now investigate the values of cos θ k for the directions generated by the Newton and inexact Newton methods . From ( 11 . 40 ) and ( 11 . 38 ) , we have for the exact Newton step ( 11 . 6 ) that cos θ k (cid:3) − p Tk ∇ f ( x k ) (cid:8) p k (cid:8)(cid:8)∇ f ( x k ) (cid:8) (cid:3) (cid:8) r k (cid:8) 2 (cid:8) J − 1 k r k (cid:8)(cid:8) J Tk r k (cid:8) ≥ 1 (cid:8) J Tk (cid:8)(cid:8) J − 1 k (cid:8) (cid:3) 1 κ ( J k ) . ( 11 . 42 ) When p k is an inexact Newton direction—that is , one that satisﬁes the condition ( 11 . 17 ) —we have that (cid:8) r k + J k p k (cid:8) 2 ≤ η 2 k (cid:8) r k (cid:8) 2 ⇒ 2 p Tk J Tk r k + (cid:8) r k (cid:8) 2 + (cid:8) J k p k (cid:8) 2 ≤ η 2 (cid:8) r k (cid:8) 2 ⇒ p Tk ∇ f k (cid:3) p Tk J Tk r k ≤ [ ( η 2 − 1 ) / 2 ] (cid:8) r k (cid:8) 2 . Meanwhile , (cid:8) p k (cid:8) ≤ (cid:8) J − 1 k (cid:8) [ (cid:8) r k + J k p k (cid:8) + (cid:8) r k (cid:8) ] ≤ (cid:8) J − 1 k (cid:8) ( η + 1 ) (cid:8) r k (cid:8) , and (cid:8)∇ f k (cid:8) (cid:3) (cid:8) J Tk r k (cid:8) ≤ (cid:8) J k (cid:8)(cid:8) r k (cid:8) . By combining these estimates , we obtain cos θ k (cid:3) − p Tk ∇ f k (cid:8) p k (cid:8)(cid:8)∇ f k (cid:8) ≥ 1 − η 2 2 (cid:8) J k (cid:8)(cid:8) J − 1 k (cid:8) ( 1 + η ) ≥ 1 − η 2 κ ( J k ) . We conclude that a bound of the form ( 11 . 41 ) is satisﬁed both for the exact and inexact Newton methods , provided that the condition number κ ( J k ) is bounded . When κ ( J k ) is large , however , this lower bound is close to zero , and use of the Newton direction may cause poor performance of the algorithm . In fact , the following example shows that condition cos θ k can converge to zero , causing the algorithm to fail . This example highlights a fundamental weakness of the line - search approach . ❏ E XAMPLE 11 . 2 ( P OWELL [ 241 ] ) Consider the problem of ﬁnding a solution of the nonlinear system r ( x ) (cid:3) ⎡ ⎣ x 1 10 x 1 ( x 1 + 0 . 1 ) + 2 x 2 2 ⎤ ⎦ , ( 11 . 43 ) 1 1 . 2 . P R A C T I C A L M E T H O D S 289 withuniquesolution x ∗ (cid:3) 0 . WetrytosolvethisproblemusingtheNewtoniteration ( 11 . 37 ) , ( 11 . 39 ) where α k is chosen to minimize f along p k . It is proved in [ 241 ] that , starting from the point ( 3 , 1 ) T , the iterates converge to ( 1 . 8016 , 0 ) T ( to four digits of accuracy ) . However , this point is not a solution of ( 11 . 43 ) . In fact , it is not even a stationary point of f , and a step from this point in the direction −∇ f will produce a decrease in both components of r . To verify these claims , note that the Jacobian of r , which is J ( x ) (cid:3) ⎡ ⎣ 1 0 1 ( x 1 + 0 . 1 ) 2 4 x 2 ⎤ ⎦ , is singular at all x for which x 2 (cid:3) 0 . For such points , we have ∇ f ( x ) (cid:3) ⎡ ⎣ x 1 + 10 x 1 ( x 1 + 0 . 1 ) 3 0 ⎤ ⎦ , so that the gradient points in the direction of the positive x 1 axis whenever x 1 > 0 . The point ( 1 . 8016 , 0 ) T is therefore not a stationary point of f . For this example , a calculation shows that the Newton step generated from an iterate that is close to ( but not quite on ) the x 1 axis tends to be parallel to the x 2 axis , making it nearly orthogonal to the gradient ∇ f ( x ) . That is , cos θ k for the Newton direction may be arbitrarily close to zero . ❐ In this example , a Newton method with exact line searches is attracted to a point of no interest at which the Jacobian is singular . Since systems of nonlinear equations often contain singular points , this behavior gives cause for concern . To prevent this undesirable behavior and ensure that ( 11 . 41 ) holds , we may have to modify the Newton direction . One possibility is to add some multiple λ k I of the identity to J Tk J k , and deﬁne the step p k to be p k (cid:3) − ( J Tk J k + λ k I ) − 1 J Tk r k . ( 11 . 44 ) For any λ k > 0 the matrix in parentheses is nonsingular , and if λ k is bounded away from zero , a condition of the form ( 11 . 41 ) is satisﬁed . Therefore , some practical algorithms choose λ k adaptively to ensure that the matrix in ( 11 . 44 ) does not approach singularity . This approach is analogous to the classical Levenberg - Marquardt algorithm discussed in Chapter 10 . To implement it without forming J Tk J k explicitly and performing trial Cholesky factorizations of the matrices ( J T k J k + λ I ) , we can use the technique ( 10 . 36 ) illustrated earlier for the least - squares case . This technique uses the fact that the Cholesky factor of ( J Tk J k + λ I ) is 290 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S identical to R T , where R is the upper triangular factor from the QR factorization of the matrix (cid:1) J k √ λ I (cid:2) . ( 11 . 45 ) A combination of Householder and Givens transformations can be used , as for ( 10 . 36 ) , and the savings noted in the discussion following ( 10 . 36 ) continue to hold if we need to perform this calculation for several candidate values of λ k . The drawback of this Levenberg - Marquardt approach is that it is difﬁcult to choose λ k . If too large , we can destroy the fast rate of convergence of Newton’s method . ( Note that p k approaches a multiple of − J Tk r k as λ k ↑ ∞ , so the step becomes small and tends to point in the steepest - descent direction for f . ) If λ k is too small , the algorithm can be inefﬁcient in the presence of Jacobian singularities . A more satisfactory approach is to follow the trust - region approach described below , which chooses λ k indirectly . We conclude by specifying an algorithm based on Newton - like steps and line searches that regularizes the step calculations where necessary . Several details are deliberately left vague ; we refer the reader to the papers cited above for details . Algorithm 11 . 4 ( Line Search Newton - like Method ) . Given c 1 , c 2 with 0 < c 1 < c 2 < 12 ; Choose x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Calculate a Newton - like step from ( 11 . 6 ) ( regularizing with ( 11 . 44 ) if J k appears to be near - singular ) , or ( 11 . 17 ) or ( 11 . 24 ) ; if α (cid:3) 1 satisﬁes the Wolfe conditions ( 3 . 6 ) Set α k (cid:3) 1 ; else Perform a line search to ﬁnd α k > 0 that satisﬁes ( 3 . 6 ) ; end ( if ) x k + 1 ← x k + α k p k ; end ( for ) TRUST - REGION METHODS The most widely used trust - region methods for nonlinear equations simply ap - ply Algorithm 4 . 1 from Chapter 4 to the merit function f ( x ) (cid:3) 12 (cid:8) r ( x ) (cid:8) 22 , using B k (cid:3) J ( x k ) T J ( x k ) as the approximate Hessian in the model function m k ( p ) , which is deﬁned as follows : m k ( p ) (cid:3) 12 (cid:8) r k + J k p (cid:8) 22 (cid:3) f k + p T J Tk r k + 12 p T J Tk J k p k . 1 1 . 2 . P R A C T I C A L M E T H O D S 291 The step p k is generated by ﬁnding an approximate solution of the subproblem min p m k ( p ) , subject to (cid:8) p (cid:8) ≤ (cid:6) k , ( 11 . 46 ) where (cid:6) k is the radius of the trust region . The ratio ρ k of actual to predicted reduction ( see ( 4 . 4 ) ) , which plays a critical role in many trust - region algorithms , is therefore ρ k (cid:3) (cid:8) r ( x k ) (cid:8) 2 − (cid:8) r ( x k + p k ) (cid:8) 2 (cid:8) r ( x k ) (cid:8) 2 − (cid:8) r ( x k ) + J ( x k ) p k (cid:8) 2 . ( 11 . 47 ) We can state the trust - region framework that results from this model as follows . Algorithm 11 . 5 ( Trust - Region Method for Nonlinear Equations ) . Given ¯ (cid:6) > 0 , (cid:6) 0 ∈ ( 0 , ¯ (cid:6) ) , and η ∈ (cid:9) 0 , 14 (cid:8) : for k (cid:3) 0 , 1 , 2 , . . . Calculate p k as an ( approximate ) solution of ( 11 . 46 ) ; Evaluate ρ k from ( 11 . 47 ) ; if ρ k < 14 (cid:6) k + 1 (cid:3) 14 (cid:8) p k (cid:8) ; else if ρ k > 34 and (cid:8) p k (cid:8) (cid:3) (cid:6) k (cid:6) k + 1 (cid:3) min ( 2 (cid:6) k , ¯ (cid:6) ) ; else (cid:6) k + 1 (cid:3) (cid:6) k ; end ( if ) end ( if ) if ρ k > η x k + 1 (cid:3) x k + p k ; else x k + 1 (cid:3) x k ; end ( if ) end ( for ) . The dogleg method is a special case of the trust - region algorithm , Algorithm 4 . 1 , that constructs an approximate solution to ( 11 . 46 ) based on the Cauchy point p C k and the unconstrained minimizer of m k . The Cauchy point is p C k (cid:3) − τ k ( (cid:6) k / (cid:8) J Tk r k (cid:8) ) J Tk r k , ( 11 . 48 ) where τ k (cid:3) min 2 1 , (cid:8) J Tk r k (cid:8) 3 / ( (cid:6) k r Tk J k ( J Tk J k ) J Tk r k ) 3 ; ( 11 . 49 ) 292 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S By comparing with the general deﬁnition ( 4 . 11 ) , ( 4 . 12 ) we see that it is not necessary to consider the case of an indeﬁnite Hessian approximation in m k ( p ) , since the model Hessian J Tk J k that we use is positive semideﬁnite . The unconstrained minimizer of m k ( p ) is unique when J k is nonsingular . In this case , we denote it by p J k and write p J k (cid:3) − ( J Tk J k ) − 1 ( J Tk r k ) (cid:3) − J − 1 k r k . The selection of p k in the dogleg method proceeds as follows . Procedure 11 . 6 ( Dogleg ) . Calculate p C k ; if (cid:8) p C k (cid:8) (cid:3) (cid:6) k p k ← p C k ; else Calculate p J k ; p k ← p C k + τ ( p J k − p C k ) , where τ is the largest value in [ 0 , 1 ] such that (cid:8) p k (cid:8) ≤ (cid:6) k ; end ( if ) . Lemma 4 . 2 shows that when J k is nonsingular , the vector p k chosen above is the minimizer of m k along the piecewise linear path that leads from the origin to the Cauchy point and then to the unconstrained minimizer p J k . Hence , the reduction in model function at least matches the reduction obtained by the Cauchy point , which can be estimated by specializing the bound ( 4 . 20 ) to the least - squares case by writing m k ( 0 ) − m k ( p k ) ≥ c 1 (cid:8) J Tk r k (cid:8) min (cid:17) (cid:6) k , (cid:8) J Tk r k (cid:8) (cid:8) J Tk J k (cid:8) (cid:18) , ( 11 . 50 ) where c 1 is some positive constant . From Theorem 4 . 1 , we know that the exact solution of ( 11 . 46 ) has the form p k (cid:3) − ( J Tk J k + λ k I ) − 1 J Tk r k , ( 11 . 51 ) forsome λ k ≥ 0 , andthat λ k (cid:3) 0iftheunconstrainedsolution p J k satisﬁes (cid:8) p J k (cid:8) ≤ (cid:6) k . ( Note that ( 11 . 51 ) is identical to the formula ( 10 . 34a ) from Chapter 10 . In fact , the Levenberg – Marquardt approach for nonlinear equations is a special case of the same algorithm for nonlinearleast - squaresproblems . ) TheLevenberg – Marquardtalgorithmusesthetechniques of Section 4 . 3 to search for the value of λ k that satisﬁes ( 11 . 51 ) . The procedure described in the “exact” trust - region algorithm , Algorithm 4 . 3 , is based on Cholesky factorizations , but as in Chapter 10 , we can replace these by specialized algorithms to compute the QR factorization of the matrix ( 11 . 45 ) . Even if the exact λ k corresponding to the solution of ( 11 . 46 ) is not found , the p k calculated from ( 11 . 51 ) will still yield global convergence if it 1 1 . 2 . P R A C T I C A L M E T H O D S 293 satisﬁes the condition ( 11 . 50 ) for some value of c 1 , together with (cid:8) p k (cid:8) ≤ γ (cid:6) k , for some constant γ ≥ 1 . ( 11 . 52 ) The dogleg method requires just one linear system to be solved per iteration , whereas methods that search for the exact solution of ( 11 . 46 ) require several such systems to be solved . As in Chapter 4 , there is a tradeoff to be made between the amount of effort to spend on each iteration and the total number of function and derivative evaluations required . We can also consider alternative trust - region approaches that are based on different merit functions and different deﬁnitions of the trust region . An algorithm based on the (cid:1) 1 merit function with an (cid:1) ∞ - norm trust region gives rise to subproblems of the form min p (cid:8) J k p + r k (cid:8) 1 subject to (cid:8) p (cid:8) ∞ ≤ (cid:6) , ( 11 . 53 ) which can be formulated and solved using linear programming techniques . This approach is closely related to the S (cid:1) 1 QP and SLQP approaches for nonlinear programming discussed in Section 18 . 5 . Global convergence results of Algorithm 11 . 5 when the steps p k satisfy ( 11 . 50 ) and ( 11 . 52 ) are given in the following theorem , which can be proved by referring directly to Theorems 4 . 5 and 4 . 6 . The ﬁrst result is for η (cid:3) 0 , in which the algorithm accepts all steps that produce a decrease in the merit function f k , while the second ( stronger ) result requires a strictly positive choice of η . Theorem 11 . 7 . Suppose that J ( x ) is Lipschitz continuous and that (cid:8) J ( x ) (cid:8) is bounded above in a neighborhood D of the level set L (cid:3) { x : f ( x ) ≤ f ( x 0 ) } . Suppose in addition that all approximate solutions of ( 11 . 46 ) satisfy the bounds ( 11 . 50 ) and ( 11 . 52 ) . Then if η (cid:3) 0 in Algorithm 11 . 5 , we have that lim inf k →∞ (cid:8) J Tk r k (cid:8) (cid:3) 0 , while if η ∈ (cid:7) 0 , 14 (cid:8) , we have lim k →∞ (cid:8) J Tk r k (cid:8) (cid:3) 0 . We turn now to local convergence of the trust - region algorithm for the case in which the subproblem ( 11 . 46 ) is solved exactly . We assume that the sequence { x k } converges to a nondegenerate solution x ∗ of the nonlinear equations r ( x ) (cid:3) 0 . The signiﬁcance of this result is that the algorithmic enhancements needed for global convergence do not , in well - designed algorithms , interfere with the fast local convergence properties described in Section 11 . 1 . 294 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S Theorem 11 . 8 . Suppose that the sequence { x k } generated by Algorithm 11 . 5 converges to a nondegenerate solution x ∗ of the problem r ( x ) (cid:3) 0 . Suppose also that J ( x ) is Lipschitz continuous in an open neighborhood D of x ∗ and that the trust - region subproblem ( 11 . 46 ) is solved exactly for all sufﬁciently large k . Then the sequence { x k } converges quadratically to x ∗ . P ROOF . We prove this result by showing that there is an index K such that the trust - region radius is not reduced further after iteration K ; that is , (cid:6) k ≥ (cid:6) K for all k ≥ K . We then show that the algorithm eventually takes the pure Newton step at every iteration , so that quadratic convergence follows from Theorem 11 . 2 . Let p k denote the exact solution of ( 11 . 46 ) . Note ﬁrst that p k will simply be the uncon - strainedNewtonstep − J − 1 k r k wheneverthisstepsatisﬁesthetrust - regionbound . Otherwise , we have (cid:8) J − 1 k r k (cid:8) > (cid:6) k , while the solution p k satisﬁes (cid:8) p k (cid:8) ≤ (cid:6) k . In either case , we have (cid:8) p k (cid:8) ≤ (cid:8) J − 1 k r k (cid:8) . ( 11 . 54 ) We consider the ratio ρ k of actual to predicted reduction deﬁned by ( 11 . 47 ) . We have directly from the deﬁnition that | 1 − ρ k | ≤ (cid:28)(cid:28) (cid:8) r k + J k p k (cid:8) 2 − (cid:8) r ( x k + p k ) (cid:8) 2 (cid:28)(cid:28) (cid:8) r ( x k ) (cid:8) 2 − (cid:8) r ( x k ) + J ( x k ) p k (cid:8) 2 . ( 11 . 55 ) From Theorem 11 . 1 , we have for the second term in the numerator that (cid:8) r ( x k + p k ) (cid:8) 2 (cid:3) (cid:8) [ r ( x k ) + J ( x k ) p k ] + w ( x k , x k + p k ) (cid:8) 2 , ( 11 . 56 ) where w ( · , · ) is deﬁned as in ( 11 . 11 ) . Because of Lipschitz continuity of J with Lipschitz constant β L ( 11 . 7 ) , we have (cid:8) w ( x k , x k + p k ) (cid:8) ≤ (cid:6) 1 0 (cid:8) J ( x k + tp k ) − J ( x k ) (cid:8)(cid:8) p k (cid:8) dt ≤ (cid:6) 1 0 β L (cid:8) p k (cid:8) 2 dt (cid:3) ( β L / 2 ) (cid:8) p k (cid:8) 2 , so that using ( 11 . 56 ) and the fact that (cid:8) r k + J k p k (cid:8) ≤ (cid:8) r k (cid:8) (cid:3) f ( x k ) 1 / 2 ( since p k is the solution of ( 11 . 46 ) ) , we can bound the numerator as follows : (cid:28)(cid:28) (cid:8) r k + J k p k (cid:8) 2 − (cid:8) r ( x k + p k ) (cid:8) 2 (cid:28)(cid:28) ≤ 2 (cid:8) r k + J k p k (cid:8)(cid:8) w ( x k , x k + p k ) (cid:8) + (cid:8) w ( x k , x k + p k ) (cid:8) 2 ≤ f ( x k ) 1 / 2 β L (cid:8) p k (cid:8) 2 + ( β L / 2 ) 2 (cid:8) p k (cid:8) 4 ≤ (cid:9) ( x k ) (cid:8) p k (cid:8) 2 , ( 11 . 57 ) 1 1 . 2 . P R A C T I C A L M E T H O D S 295 where we deﬁne (cid:9) ( x k ) (cid:3) f ( x k ) 1 / 2 β L + ( β L / 2 ) 2 (cid:8) p k (cid:8) 2 . Since x k → x ∗ by assumption , it follows that f ( x k ) → 0 and (cid:8) r k (cid:8) → 0 . Because x ∗ is a nondegenerate root , we have as in ( 11 . 14 ) that (cid:8) J ( x k ) − 1 (cid:8) ≤ β ∗ for all k sufﬁciently large , so from ( 11 . 54 ) , we have (cid:8) p k (cid:8) ≤ (cid:8) J − 1 k r k (cid:8) ≤ β ∗ (cid:8) r k (cid:8) → 0 . ( 11 . 58 ) Hence , (cid:9) ( x k ) → 0 . Turning now to the denominator of ( 11 . 55 ) , we deﬁne ¯ p k to be a step of the same length as the solution p k in the Newton direction − J − 1 k r k , that is , ¯ p k (cid:3) − (cid:8) p k (cid:8) (cid:8) J − 1 k r k (cid:8) J − 1 k r k . Since ¯ p k is feasible for ( 11 . 46 ) , and since p k is optimal for this subproblem , we have (cid:8) r k (cid:8) 2 − (cid:8) r k + J k p k (cid:8) 2 ≥ (cid:8) r k (cid:8) 2 − (cid:23)(cid:23)(cid:23)(cid:23) r k − (cid:8) p k (cid:8) (cid:8) J − 1 k r k (cid:8) r k (cid:23)(cid:23)(cid:23)(cid:23) 2 (cid:3) 2 (cid:8) p k (cid:8) (cid:8) J − 1 k r k (cid:8)(cid:8) r k (cid:8) 2 − (cid:8) p k (cid:8) 2 (cid:8) J − 1 k r k (cid:8) 2 (cid:8) r k (cid:8) 2 ≥ (cid:8) p k (cid:8) (cid:8) J − 1 k r k (cid:8)(cid:8) r k (cid:8) 2 , where for the last inequality we have used ( 11 . 54 ) . By using ( 11 . 58 ) again , we have from this bound that (cid:8) r k (cid:8) 2 − (cid:8) r k + J k p k (cid:8) 2 ≥ (cid:8) p k (cid:8) (cid:8) J − 1 k r k (cid:8)(cid:8) r k (cid:8) 2 ≥ 1 β ∗ (cid:8) p k (cid:8)(cid:8) r k (cid:8) . ( 11 . 59 ) By substituting ( 11 . 57 ) and ( 11 . 59 ) into ( 11 . 55 ) , and then applying ( 11 . 58 ) again , we have | 1 − ρ k | ≤ β ∗ (cid:9) ( x k ) (cid:8) p k (cid:8) 2 (cid:8) p k (cid:8)(cid:8) r k (cid:8) ≤ ( β ∗ ) 2 (cid:9) ( x k ) → 0 . ( 11 . 60 ) Therefore , for all k sufﬁciently large , we have ρ k > 14 , and so the trust region radius (cid:6) k will not be increased beyond this point . As claimed , there is an index K such that (cid:6) k ≥ (cid:6) K , for all k ≥ K . 296 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S Since (cid:8) J − 1 k r k (cid:8) ≤ β ∗ (cid:8) r k (cid:8) → 0 , the Newton step − J − 1 k r k will eventually be smaller than (cid:6) K ( and hence (cid:6) k ) , so it will eventually always be accepted as the solution of ( 11 . 46 ) . The result now follows from Theorem 11 . 2 . (cid:1) We can replace the assumption that x k → x ∗ with an assumption that the nonde - generate solution x ∗ is just one of the limit points of the sequence . ( In fact , this condition implies that x k → x ∗ ; see Exercise 11 . 9 . ) 11 . 3 CONTINUATION / HOMOTOPY METHODS MOTIVATION We mentioned above that Newton - based methods all suffer from one shortcoming : Unless J ( x ) is nonsingular in the region of interest—a condition that often cannot be guaranteed—they are in danger of converging to a local minimum of the merit function rather that is not a solution of the nonlinear system . Continuation methods , which we outline in this section , are more likely to converge to a solution of r ( x ) (cid:3) 0 in difﬁcult cases . Their underlying motivation is simple to describe : Rather than dealing with the original problem r ( x ) (cid:3) 0 directly , we set up an “easy” system of equations for which the solution is obvious . We then gradually transform the easy system into the original system r ( x ) , and follow the solution as it moves from the solution of the easy problem to the solution of the original problem . One simple way to deﬁne the so - called homotopy map H ( x , λ ) is as follows : H ( x , λ ) (cid:3) λ r ( x ) + ( 1 − λ ) ( x − a ) , ( 11 . 61 ) where λ is a scalar parameter and a ∈ IR n is a ﬁxed vector . When λ (cid:3) 0 , ( 11 . 61 ) deﬁnes the artiﬁcial , easy problem H ( x , 0 ) (cid:3) x − a , whose solution is obviously x (cid:3) a . When λ (cid:3) 1 , we have H ( x , 1 ) (cid:3) r ( x ) , the original system of equations . To solve r ( x ) (cid:3) 0 , consider the following algorithm : First , set λ (cid:3) 0 in ( 11 . 61 ) and set x (cid:3) a . Then , increase λ from 0 to 1 in small increments , and for each value of λ , calculate the solution of the system H ( x , λ ) (cid:3) 0 . The ﬁnal value of x corresponding to λ (cid:3) 1 will solve the original problem r ( x ) (cid:3) 0 . This naive approach sounds plausible , and Figure 11 . 3 illustrates a situation in which it would be successful . In this ﬁgure , there is a unique solution x of the system H ( x , λ ) (cid:3) 0 for each value of λ in the range [ 0 , 1 ] . The trajectory of points ( x , λ ) for which H ( x , λ ) (cid:3) 0 is called the zero path . Unfortunately , however , the approach often fails , as illustrated in Figure 11 . 4 . Here , the algorithm follows the lower branch of the curve from λ (cid:3) 0 to λ (cid:3) λ T , but it then loses the trail unless it is lucky enough to jump to the top branch of the path . The value λ T is 1 1 . 3 . C O N T I N U A T I O N / H O M O T O P Y M E T H O D S 297 0 λ 1 x Figure 11 . 3 Plot of a zero path : Trajectory of points ( x , λ ) with H ( x , λ ) (cid:3) 0 . 1 T ( x , ) . λ . 0 λ x λ Figure 11 . 4 Zero path with turning points . The path joining ( a , 0 ) to ( x ∗ , 1 ) cannot be followed by increasing λ monotonically from 0 to 1 . known as a turning point , since at this point we can follow the path smoothly only if we no longer insist on increasing λ at every step . In fact , practical continuation methods work by doing exactly as Figure 11 . 4 suggests , that is , they follow the zero path explicitly , even if this means allowing λ to decrease from time to time . PRACTICAL CONTINUATION METHODS In one practical technique , we model the zero path by allowing both x and λ to be functions of an independent variable s that represents arc length along the path . That is , 298 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S ( x ( s ) , λ ( s ) ) is the point that we arrive at by traveling a distance s along the path from the initial point ( x ( 0 ) , λ ( 0 ) ) (cid:3) ( a , 0 ) . Because we have that H ( x ( s ) , λ ( s ) ) (cid:3) 0 , for all s ≥ 0 , we can take the total derivative of this expression with respect to s to obtain ∂ ∂ x H ( x , λ ) ˙ x + ∂ ∂λ H ( x , λ ) ˙ λ (cid:3) 0 , where ( ˙ x , ˙ λ ) (cid:3) (cid:17) dx ds , d λ ds (cid:18) . ( 11 . 62 ) The vector ( ˙ x ( s ) , ˙ λ ( s ) ) is the tangent vector to the zero path , as we illustrate in Figure 11 . 4 . From ( 11 . 62 ) , we see that it lies in the null space of the n × ( n + 1 ) matrix (cid:26) ∂ ∂ x H ( x , λ ) ∂ ∂λ H ( x , λ ) (cid:27) . ( 11 . 63 ) When this matrix has full rank , its null space has dimension 1 , so to complete the deﬁnition of ( ˙ x , ˙ λ ) in this case , we need to assign it a length and direction . The length is ﬁxed by imposing the normalization condition (cid:8)˙ x ( s ) (cid:8) 2 + | ˙ λ ( s ) | 2 (cid:3) 1 , for all s , ( 11 . 64 ) which ensures that s is the true arc length along the path from ( 0 , a ) to ( x ( s ) , λ ( s ) ) . We need to choose the sign to ensure that we keep moving forward along the zero path . A heuristic that works well is to choose the sign so that the tangent vector ( ˙ x , ˙ λ ) at the current value of s makes an angle of less than π / 2 with the tangent point at the previous value of s . We can outline the complete procedure for computing ( ˙ x , ˙ λ ) as follows : Procedure 11 . 7 ( Tangent Vector Calculation ) . Compute a vector in the null space of ( 11 . 63 ) by performing a QR factorization with column pivoting , Q T (cid:26) ∂ ∂ x H ( x , λ ) ∂ ∂λ H ( x , λ ) (cid:27) (cid:23) (cid:3) (cid:9) R w (cid:10) , where Q is n × n orthogonal , R is n × n upper triangular , (cid:23) is an ( n + 1 ) × ( n + 1 ) permutation matrix , and w ∈ IR n . Set v (cid:3) (cid:23) (cid:1) R − 1 w − 1 (cid:2) ; 1 1 . 3 . C O N T I N U A T I O N / H O M O T O P Y M E T H O D S 299 Set ( ˙ x , ˙ λ ) (cid:3) ± v / (cid:8) v (cid:8) 2 , where the sign is chosen to satisfy the angle criterion mentioned above . Details of the QR factorization procedure are given in the Appendix . Since we can obtain the tangent at any given point ( x , λ ) and since we know the initial point ( x ( 0 ) , λ ( 0 ) ) (cid:3) ( a , 0 ) , we can trace the zero path by calling a standard initial - value ﬁrst - order ordinary differential equation solver , terminating the algorithm when it ﬁnds a value of s for which λ ( s ) (cid:3) 1 . A second approach for following the zero path is quite similar to the one just described , except that it takes an algebraic viewpoint instead of a differential - equations viewpoint . Given a current point ( x , λ ) , we compute the tangent vector ( ˙ x , ˙ λ ) as above , and take a small step ( of length (cid:9) , say ) along this direction to produce a “predictor” point ( x P , λ P ) ; that is , ( x P , λ P ) (cid:3) ( x , λ ) + (cid:9) ( ˙ x , ˙ λ ) . Usually , this new point will not lie exactly on the zero path , so we apply some “corrector” iterations to bring it back to the path , thereby identifying a new iterate ( x + , λ + ) that satisﬁes H ( x + , λ + ) (cid:3) 0 . ( This process is illustrated in Figure 11 . 5 . ) During the corrections , we choose a component of the predictor step ( x P , λ P ) —one of the components that has been changing most rapidly during the past few steps—and hold this component ﬁxed during the correction process . If the index of this component is i , and if we use a pure Newton corrector process ( often adequate , since ( x P , λ P ) is usually quite close to the target point λ λ + + ( x , ) P P λ x ( x , ) λ ( x , ) Figure 11 . 5 The algebraic predictor – corrector procedure , using λ as the ﬁxed variable in the correction process . 300 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S ( x + , λ + ) ) , the steps will have the form ⎡ ⎣ ∂ H ∂ x ∂ H ∂λ e i ⎤ ⎦ (cid:1) δ x δλ (cid:2) (cid:3) (cid:1) − H 0 (cid:2) , where the quantities ∂ H / ∂ x , ∂ H / ∂λ , and H are evaluated at the latest point of the corrector process . The last row of this system serves to ﬁx the i th component of ( δ x , δλ ) at zero ; the vector e i ∈ IR n + 1 is a vector with n + 1 components containing all zeros , except for a 1 in the location i that corresponds to the ﬁxed component . Note that in Figure 11 . 5 the λ component is chosen to be ﬁxed on the current iteration . On the following iteration , it may be more appropriate to choose x as the ﬁxed component , as we reach the turning point in λ . The two variants on path - following described above are able to follow curves like those depicted in Figure 11 . 4 to a solution of the nonlinear system . They rely , however , on the n × ( n + 1 ) matrix in ( 11 . 63 ) having full rank for all ( x , λ ) along the path , so that the tangent vector is well - deﬁned . The following result shows that full rank is guaranteed under certain assumptions . Theorem 11 . 9 ( Watson [ 305 ] ) . Suppose that r is twice continuously differentiable . Then for almost all vectors a ∈ IR n , there is a zero path emanating from ( 0 , a ) along which the n × ( n + 1 ) matrix ( 11 . 63 ) has full rank . If this path is bounded for λ ∈ [ 0 , 1 ) , then it has an accumulation point ( ¯ x , 1 ) such that r ( ¯ x ) (cid:3) 0 . Furthermore , if the Jacobian J ( ¯ x ) is nonsingular , the zero path between ( a , 0 ) and ( ¯ x , 1 ) has ﬁnite arc length . The theorem assures us that unless we are unfortunate in the choice of a , the algorithms described above can be applied to obtain a path that either diverges or else leads to a point ¯ x that is a solution of the original nonlinear system if J ( ¯ x ) is nonsingular . More detailed convergence results can be found in Watson [ 305 ] and the references therein . We conclude with an example to show that divergence of the zero path—the less desirable outcome of Theorem 11 . 9—can happen even for innocent - looking problems . ❏ E XAMPLE 11 . 3 Consider the system r ( x ) (cid:3) x 2 − 1 , for which there are two nondegenerate solutions + 1 and − 1 . Suppose we choose a (cid:3) − 2 and attempt to apply a continuation method to the function H ( x , λ ) (cid:3) λ ( x 2 − 1 ) + ( 1 − λ ) ( x + 2 ) (cid:3) λ x 2 + ( 1 − λ ) x + ( 2 − 3 λ ) , ( 11 . 65 ) obtained by substituting into ( 11 . 61 ) . The zero paths for this function are plotted in Figure 11 . 6 . As can be seen from that diagram , there is no zero path that joins ( − 2 , 0 ) 1 1 . 3 . C O N T I N U A T I O N / H O M O T O P Y M E T H O D S 301 0 0 . 2 0 . 4 0 . 6 0 . 8 1 −12 −10 −8 −6 −4 −2 0 2 lambda x Figure11 . 6 Zeropathsfortheexampleinwhich H ( x , λ ) (cid:3) λ ( x 2 − 1 ) + ( 1 − λ ) ( x + 2 ) . There is no continuous zero path from λ (cid:3) 0 to λ (cid:3) 1 . to either ( 1 , 1 ) or ( − 1 , 1 ) , so the continuation methods fail on this example . We can ﬁnd the values of λ for which no solution exists by using the formula for a quadratic root to obtain x (cid:3) − ( 1 − λ ) ± (cid:5) ( 1 − λ ) 2 − 4 λ ( 2 − 3 λ ) 2 λ . Now , whentheterminthesquarerootisnegative , thecorrespondingvaluesof x arecomplex , that is , there are no real roots x . It is easy to verify that such is the case when λ ∈ (cid:24) 5 − 2 √ 3 13 , 5 + 2 √ 3 13 (cid:25) ≈ ( 0 . 118 , 0 . 651 ) . Note that the zero path starting from ( − 2 , 0 ) becomes unbounded , which is one of the possible outcomes of Theorem 11 . 9 . ❐ This example indicates that continuation methods may fail to produce a solution even to a fairly simple system of nonlinear equations . However , it is generally true that they are more reliable than the merit - function methods described earlier in the chapter . The extra robustness comes at a price , since continuation methods typically require signiﬁcantly more computational effort than the merit - function methods . 302 C H A P T E R 1 1 . N O N L I N E A R E Q U A T I O N S NOTES AND REFERENCES Nonlinear differential equations and integral equations are a rich source of nonlinear equations . Whenformulatedasﬁnite - dimensionalnonlinearequations , theunknownvector x is a discrete approximation to the ( inﬁnite - dimensional ) solution . In other applications , the vector x is intrinsically ﬁnite - dimensional ; it may represent the quantities of materials to be transported between pairs of cities in a distribution network , for instance . In all cases , the equations r i enforce consistency , conservation , and optimality principles in the model . Mor´e [ 212 ] and Averick et al . [ 10 ] discuss a number of interesting practical applications . For analysis of the convergence of Broyden’s method , including proofs of Theo - rem 11 . 5 , see Dennis and Schnabel [ 92 , Chapter 8 ] and Kelley [ 177 , Chapter 6 ] . Details on a limited - memory implementation of Broyden’s method are given by Kelley [ 177 , Section 7 . 3 ] . Example 11 . 2 and the algorithm described by Powell [ 241 ] have been inﬂuential beyond the ﬁeld of nonlinear equations . The example shows that a line - search method may not be able to achieve sufﬁcient decrease , whereas the Cauchy step in the trust - region approach is designed to guarantee that this condition holds and hence that reasonable convergence properties are guaranteed . The dogleg algorithm proposed in [ 241 ] can be viewed as one of the ﬁrst modern trust - region methods . ✐ E X E R C I S E S ✐ 11 . 1 Show that for any vector s ∈ IR n , we have (cid:23)(cid:23)(cid:23)(cid:23) ss T s T s (cid:23)(cid:23)(cid:23)(cid:23) (cid:3) 1 , where (cid:8) · (cid:8) denotes the Euclidean matrix norm . ✐ 11 . 2 Consider the function r : IR → IR deﬁned by r ( x ) (cid:3) x q , where q is an integer greater than 2 . Note that x ∗ (cid:3) 0 is the sole root of this function and that it is degenerate . Show that Newton’s method converges Q - linearly , and ﬁnd the value of the convergence ratio r in ( A . 34 ) . ✐ 11 . 3 Show that Newton’s method applied to the function r ( x ) (cid:3) − x 5 + x 3 + 4 x starting from x 0 (cid:3) 1 produces the cyclic behavior described in the text . Find the roots of this function , and check that they are nondegenerate . ✐ 11 . 4 For the scalar function r ( x ) (cid:3) sin ( 5 x ) − x , show that the sum - of - squares merit function has inﬁnitely many local minima , and ﬁnd a general formula for such points . ✐ 11 . 5 When r : IR n → IR n , show that the function φ ( λ ) (cid:3) (cid:23) (cid:23) ( J T J + λ I ) − 1 J T r (cid:23) (cid:23) 1 1 . 3 . C O N T I N U A T I O N / H O M O T O P Y M E T H O D S 303 is monotonically decreasing in λ unless J T r (cid:3) 0 . ( Hint : Use the singular - value decomposition of J . ) ✐ 11 . 6 Prove part ( iii ) of Theorem 11 . 3 . ✐ 11 . 7 Consider a line - search Newton method in which the step length α k is chosen to be the exact minimizer of the merit function f ( · ) ; that is , α k (cid:3) arg min α f ( x k − α J − 1 k r k ) . Show that if J ( x ) is nonsingular at the solution x ∗ , then α k → 1 as x k → x ∗ . ✐ 11 . 8 Let J ∈ IR n × m and r ∈ IR n and suppose that J J T r (cid:3) 0 . Show that J T r (cid:3) 0 . ( Hint : This doesn’t even take one line ! ) ✐ 11 . 9 Suppose we replace the assumption of x k → x ∗ in Theorem 11 . 8 by an assump - tion that the nondegenerate solution x ∗ is a limit point of x ∗ . By adding some logic to the proof of this result , show that in fact x ∗ is the only possible limit point of the sequence . ( Hint : Show that (cid:8) J − 1 k + 1 r k + 1 (cid:8) ≤ 12 (cid:8) J − 1 k r k (cid:8) for all k sufﬁciently large , and hence that for any constant (cid:9) > 0 , the sequence { x k } satisﬁes (cid:8) x k − x ∗ (cid:8) ≤ (cid:9) for all k sufﬁciently large . ) ✐ 11 . 10 Consider the following modiﬁcation of our example of failure of continuation methods : r ( x ) (cid:3) x 2 − 1 , a (cid:3) 12 . Show that for this example there is a zero path for H ( x , λ ) (cid:3) λ ( x 2 − 1 ) + ( 1 − λ ) ( x − a ) that connects ( 12 , 0 ) to ( 1 , 1 ) , so that continuation methods should work for this choice of starting point . This is pag Printer : O C H A P T E R 12 Theory of Constrained Optimization The second part of this book is about minimizing functions subject to constraints on the variables . A general formulation for these problems is min x ∈ IR n f ( x ) subject to (cid:21) c i ( x ) (cid:3) 0 , i ∈ E , c i ( x ) ≥ 0 , i ∈ I , ( 12 . 1 ) where f and the functions c i are all smooth , real - valued functions on a subset of IR n , and I and E are two ﬁnite sets of indices . As before , we call f the objective function , while c i , C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N 305 i ∈ E are the equality constraints and c i , i ∈ I are the inequality constraints . We deﬁne the feasible set (cid:22) to be the set of points x that satisfy the constraints ; that is , (cid:22) (cid:3) { x | c i ( x ) (cid:3) 0 , i ∈ E ; c i ( x ) ≥ 0 , i ∈ I } , ( 12 . 2 ) so that we can rewrite ( 12 . 1 ) more compactly as min x ∈ (cid:22) f ( x ) . ( 12 . 3 ) In this chapter we derive mathematical characterizations of the solutions of ( 12 . 3 ) . As in the unconstrained case , we discuss optimality conditions of two types . Necessary condi - tionsareconditionsthatmustbesatisﬁedbyanysolutionpoint ( undercertainassumptions ) . Sufﬁcient conditions are those that , if satisﬁed at a certain point x ∗ , guarantee that x ∗ is in fact a solution . For the unconstrained optimization problem of Chapter 2 , the optimality conditions were as follows : Necessary conditions : Local unconstrained minimizers have ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) positive semideﬁnite . Sufﬁcient conditions : Any point x ∗ at which ∇ f ( x ∗ ) (cid:3) 0 and ∇ 2 f ( x ∗ ) is positive deﬁnite is a strong local minimizer of f . In this chapter , we derive analogous conditions to characterize the solutions of constrained optimization problems . LOCAL AND GLOBAL SOLUTIONS We have seen already that global solutions are difﬁcult to ﬁnd even when there are no constraints . The situation may be improved when we add constraints , since the feasible set might exclude many of the local minima and it may be comparatively easy to pick the global minimum from those that remain . However , constraints can also make things more difﬁcult . As an example , consider the problem min ( x 2 + 100 ) 2 + 0 . 01 x 2 1 , subject to x 2 − cos x 1 ≥ 0 , ( 12 . 4 ) illustrated in Figure 12 . 1 . Without the constraint , the problem has the unique solution ( 0 , − 100 ) T . With the constraint , there are local solutions near the points x ( k ) (cid:3) ( k π , − 1 ) T , for k (cid:3) ± 1 , ± 3 , ± 5 , . . . . Deﬁnitions of the different types of local solutions are simple extensions of the corre - sponding deﬁnitions for the unconstrained case , except that now we restrict consideration to the feasible points in the neighborhood of x ∗ . We have the following deﬁnition . 306 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N ( 1 ) x ( 2 ) x ( 3 ) x ( 4 ) x ( 5 ) x feasible region contours of f Figure 12 . 1 Constrained problem with many isolated local solutions . A vector x ∗ is a local solution of the problem ( 12 . 3 ) if x ∗ ∈ (cid:22) and there is a neighborhood N of x ∗ such that f ( x ) ≥ f ( x ∗ ) for x ∈ N ∩ (cid:22) . Similarly , we can make the following deﬁnitions : Avector x ∗ isa strictlocalsolution ( alsocalleda stronglocalsolution ) if x ∗ ∈ (cid:22) andthere is a neighborhood N of x ∗ such that f ( x ) > f ( x ∗ ) for all x ∈ N ∩ (cid:22) with x (cid:9)(cid:3) x ∗ . A point x ∗ is an isolated local solution if x ∗ ∈ (cid:22) and there is a neighborhood N of x ∗ such that x ∗ is the only local solution in N ∩ (cid:22) . Note that isolated local solutions are strict , but that the reverse is not true ( see Exercise 12 . 2 ) . SMOOTHNESS Smoothness of objective functions and constraints is an important issue in character - izing solutions , just as in the unconstrained case . It ensures that the objective function and the constraints all behave in a reasonably predictable way and therefore allows algorithms to make good choices for search directions . We saw in Chapter 2 that graphs of nonsmooth functions contain “kinks " or “jumps” where the smoothness breaks down . If we plot the feasible region for any given constrained optimization problem , we usually observe many kinks and sharp edges . Does this mean that the constraint functions that describe these regions are nonsmooth ? The answer is often no , because the nonsmooth boundaries can often be described by a collection of smooth constraint functions . Figure 12 . 2 shows a diamond - shaped feasible region in IR 2 that could be described by the single nonsmooth constraint (cid:8) x (cid:8) 1 (cid:3) | x 1 | + | x 2 | ≤ 1 . ( 12 . 5 ) It can also be described by the following set of smooth ( in fact , linear ) constraints : x 1 + x 2 ≤ 1 , x 1 − x 2 ≤ 1 , − x 1 + x 2 ≤ 1 , − x 1 − x 2 ≤ 1 . ( 12 . 6 ) Each of the four constraints represents one edge of the feasible polytope . In general , the con - straint functions are chosen so that each one represents a smooth piece of the boundary of (cid:22) . 1 2 . 1 . E X A M P L E S 307 Figure 12 . 2 A feasible region with a nonsmooth boundary can be described by smooth constraints . Nonsmooth , unconstrained optimization problems can sometimes be reformulated as smooth constrained problems . An example is the unconstrained minimization of a function f ( x ) (cid:3) max ( x 2 , x ) , ( 12 . 7 ) which has kinks at x (cid:3) 0 and x (cid:3) 1 , and the solution at x ∗ (cid:3) 0 . We obtain a smooth , constrained formulation of this problem by adding an artiﬁcial variable t and writing min t s . t . t ≥ x , t ≥ x 2 . ( 12 . 8 ) Reformulation techniques such as ( 12 . 6 ) and ( 12 . 8 ) are used often in cases where f is a maximum of a collection of functions or when f is a 1 - norm or ∞ - norm of a vector function . In the examples above we expressed inequality constraints in a slightly different way from the form c i ( x ) ≥ 0 that appears in the deﬁnition ( 12 . 1 ) . However , any collection of inequality constraints with ≥ and ≤ and nonzero right - hand - sides can be expressed in the form c i ( x ) ≥ 0 by simple rearrangement of the inequality . 12 . 1 EXAMPLES To introduce the basic principles behind the characterization of solutions of constrained optimization problems , we work through three simple examples . The discussion here is informal ; the ideas introduced will be made rigorous in the sections that follow . We start by noting one important item of terminology that recurs throughout the rest of the book . 308 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N Deﬁnition 12 . 1 . The active set A ( x ) at any feasible x consists of the equality constraint indices from E together with the indices of the inequality constraints i for which c i ( x ) (cid:3) 0 ; that is , A ( x ) (cid:3) E ∪ { i ∈ I | c i ( x ) (cid:3) 0 } . At a feasible point x , the inequality constraint i ∈ I is said to be active if c i ( x ) (cid:3) 0 and inactive if the strict inequality c i ( x ) > 0 is satisﬁed . A SINGLE EQUALITY CONSTRAINT ❏ E XAMPLE 12 . 1 Our ﬁrst example is a two - variable problem with a single equality constraint : min x 1 + x 2 s . t . x 21 + x 22 − 2 (cid:3) 0 ( 12 . 9 ) ( see Figure 12 . 3 ) . In the language of ( 12 . 1 ) , we have f ( x ) (cid:3) x 1 + x 2 , I (cid:3) ∅ , E (cid:3) { 1 } , and c 1 ( x ) (cid:3) x 21 + x 22 − 2 . We can see by inspection that the feasible set for this problem is the circle of radius √ 2 centered at the origin—just the boundary of this circle , not its interior . The solution x ∗ is obviously ( − 1 , − 1 ) T . From any other point on the circle , it is easy to ﬁnd a way to move that stays feasible ( that is , remains on the circle ) while decreasing f . For instance , from the point x (cid:3) ( √ 2 , 0 ) T any move in the clockwise direction around the circle has the desired effect . ∆ ∆ ∆ ∆ ∆ ∆ ∆ 1 x * x 2 f f x 1 f f c 1 c 1 c Figure 12 . 3 Problem ( 12 . 9 ) , showing constraint and function gradients at various feasible points . 1 2 . 1 . E X A M P L E S 309 We also see from Figure 12 . 3 that at the solution x ∗ , the constraint normal ∇ c 1 ( x ∗ ) is parallel to ∇ f ( x ∗ ) . That is , there is a scalar λ ∗ 1 ( in this case λ ∗ 1 (cid:3) − 1 / 2 ) such that ∇ f ( x ∗ ) (cid:3) λ ∗ 1 ∇ c 1 ( x ∗ ) . ( 12 . 10 ) ❐ We can derive ( 12 . 10 ) by examining ﬁrst - order Taylor series approximations to the objective and constraint functions . To retain feasibility with respect to the function c 1 ( x ) (cid:3) 0 , we require any small ( but nonzero ) step s to satisfy that c 1 ( x + s ) (cid:3) 0 ; that is , 0 (cid:3) c 1 ( x + s ) ≈ c 1 ( x ) + ∇ c 1 ( x ) T s (cid:3) ∇ c 1 ( x ) T s . ( 12 . 11 ) Hence , the step s retains feasibility with respect to c 1 , to ﬁrst order , when it satisﬁes ∇ c 1 ( x ) T s (cid:3) 0 . ( 12 . 12 ) Similarly , if we want s to produce a decrease in f , we would have so that 0 > f ( x + s ) − f ( x ) ≈ ∇ f ( x ) T s , or , to ﬁrst order , ∇ f ( x ) T s < 0 . ( 12 . 13 ) Existence of a small step s that satisﬁes both ( 12 . 12 ) and ( 12 . 13 ) strongly suggests existence of a direction d ( where the size of d is not small ; we could have d ≈ s / (cid:8) s (cid:8) to ensure that the norm of d is close to 1 ) with the same properties , namely ∇ c 1 ( x ) T d (cid:3) 0 and ∇ f ( x ) T d < 0 . ( 12 . 14 ) If , on the other hand , there is no direction d with the properties ( 12 . 14 ) , then is it likely that we cannot ﬁnd a small step s with the properties ( 12 . 12 ) and ( 12 . 13 ) . In this case , x ∗ would appear to be a local minimizer . By drawing a picture , the reader can check that the only way that a d satisfying ( 12 . 14 ) does not exist is if ∇ f ( x ) and ∇ c 1 ( x ) are parallel , that is , if the condition ∇ f ( x ) (cid:3) λ 1 ∇ c 1 ( x ) holds at x , for some scalar λ 1 . If in fact ∇ f ( x ) and ∇ c 1 ( x ) are not parallel , we can set ¯ d (cid:3) − (cid:17) I − ∇ c 1 ( x ) ∇ c 1 ( x ) T (cid:8)∇ c 1 ( x ) (cid:8) 2 (cid:18) ∇ f ( x ) ; d (cid:3) ¯ d (cid:8) ¯ d (cid:8) . ( 12 . 15 ) It is easy to verify that this d satisﬁes ( 12 . 14 ) . 310 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N By introducing the Lagrangian function L ( x , λ 1 ) (cid:3) f ( x ) − λ 1 c 1 ( x ) , ( 12 . 16 ) and noting that ∇ x L ( x , λ 1 ) (cid:3) ∇ f ( x ) − λ 1 ∇ c 1 ( x ) , we can state the condition ( 12 . 10 ) equivalently as follows : At the solution x ∗ , there is a scalar λ ∗ 1 such that ∇ x L ( x ∗ , λ ∗ 1 ) (cid:3) 0 . ( 12 . 17 ) This observation suggests that we can search for solutions of the equality - constrained problem ( 12 . 9 ) by seeking stationary points of the Lagrangian function . The scalar quantity λ 1 in ( 12 . 16 ) is called a Lagrange multiplier for the constraint c 1 ( x ) (cid:3) 0 . Though the condition ( 12 . 10 ) ( equivalently , ( 12 . 17 ) ) appears to be necessary for an optimal solution of the problem ( 12 . 9 ) , it is clearly not sufﬁcient . For instance , in Example 12 . 1 , condition ( 12 . 10 ) is satisﬁed at the point x (cid:3) ( 1 , 1 ) T ( with λ 1 (cid:3) 12 ) , but this point is obviously not a solution—in fact , it maximizes the function f on the circle . Moreover , in the case of equality - constrained problems , we cannot turn the condition ( 12 . 10 ) into a sufﬁcient condition simply by placing some restriction on the sign of λ 1 . To see this , consider replacing the constraint x 21 + x 22 − 2 (cid:3) 0 by its negative 2 − x 21 − x 22 (cid:3) 0 in Example 12 . 1 . The solution of the problem is not affected , but the value of λ ∗ 1 that satisﬁes the condition ( 12 . 10 ) changes from λ ∗ 1 (cid:3) − 12 to λ ∗ 1 (cid:3) 12 . A SINGLE INEQUALITY CONSTRAINT ❏ E XAMPLE 12 . 2 This is a slight modiﬁcation of Example 12 . 1 , in which the equality constraint is replaced by an inequality . Consider min x 1 + x 2 s . t . 2 − x 2 1 − x 2 2 ≥ 0 , ( 12 . 18 ) for which the feasible region consists of the circle of problem ( 12 . 9 ) and its interior ( see Figure 12 . 4 ) . Note that the constraint normal ∇ c 1 points toward the interior of the feasible region at each point on the boundary of the circle . By inspection , we see that the solution is still ( − 1 , − 1 ) T and that the condition ( 12 . 10 ) holds for the value λ ∗ 1 (cid:3) 12 . However , this inequality - constrained problem differs from the equality - constrained problem ( 12 . 9 ) of Example 12 . 1 in that the sign of the Lagrange multiplier plays a signiﬁcant role , as we now argue . ❐ 1 2 . 1 . E X A M P L E S 311 As before , we conjecture that a given feasible point x is not optimal if we can ﬁnd a small step s that both retains feasibility and decreases the objective function f to ﬁrst order . The main difference between problems ( 12 . 9 ) and ( 12 . 18 ) comes in the handling of the feasibility condition . As in ( 12 . 13 ) , the step s improves the objective function , to ﬁrst order , if ∇ f ( x ) T s < 0 . Meanwhile , s retains feasibility if 0 ≤ c 1 ( x + s ) ≈ c 1 ( x ) + ∇ c 1 ( x ) T s , so , to ﬁrst order , feasibility is retained if c 1 ( x ) + ∇ c 1 ( x ) T s ≥ 0 . ( 12 . 19 ) In determining whether a step s exists that satisﬁes both ( 12 . 13 ) and ( 12 . 19 ) , we consider the following two cases , which are illustrated in Figure 12 . 4 . Case I : Consider ﬁrst the case in which x lies strictly inside the circle , so that the strict inequality c 1 ( x ) > 0 holds . In this case , any step vector s satisﬁes the condition ( 12 . 19 ) , provided only that its length is sufﬁciently small . In fact , whenever ∇ f ( x ) (cid:9)(cid:3) 0 , we can obtain a step s that satisﬁes both ( 12 . 13 ) and ( 12 . 19 ) by setting s (cid:3) − α ∇ f ( x ) , 1 ∆ s f ∆ s x ∆ c x f Figure 12 . 4 Improvement directions s from two feasible points x for the problem ( 12 . 18 ) at which the constraint is active and inactive , respectively . 312 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N for any positive scalar α sufﬁciently small . However , this deﬁnition does not give a step s with the required properties when ∇ f ( x ) (cid:3) 0 , ( 12 . 20 ) Case II : Consider now the case in which x lies on the boundary of the circle , so that c 1 ( x ) (cid:3) 0 . The conditions ( 12 . 13 ) and ( 12 . 19 ) therefore become ∇ f ( x ) T s < 0 , ∇ c 1 ( x ) T s ≥ 0 . The ﬁrst of these conditions deﬁnes an open half - space , while the second deﬁnes a closed half - space , as illustrated in Figure 12 . 5 . It is clear from this ﬁgure that the intersection of these two regions is empty only when ∇ f ( x ) and ∇ c 1 ( x ) point in the same direction , that is , when ∇ f ( x ) (cid:3) λ 1 ∇ c 1 ( x ) , for some λ 1 ≥ 0 . ( 12 . 21 ) Note that the sign of the multiplier is signiﬁcant here . If ( 12 . 10 ) were satisﬁed with a negative value of λ 1 , then ∇ f ( x ) and ∇ c 1 ( x ) would point in opposite directions , and we see from Figure 12 . 5 that the set of directions that satisfy both ( 12 . 13 ) and ( 12 . 19 ) would make up an entire open half - plane . ∆ 1 ∆ Anydirection , to first order d c f in this cone is a good search Figure 12 . 5 A direction d that satisﬁes both ( 12 . 13 ) and ( 12 . 19 ) lies in the intersection of a closed half - plane and an open half - plane . 1 2 . 1 . E X A M P L E S 313 The optimality conditions for both cases I and II can again be summarized neatly with reference to the Lagrangian function L deﬁned in ( 12 . 16 ) . When no ﬁrst - order feasible descent direction exists at some point x ∗ , we have that ∇ x L ( x ∗ , λ ∗ 1 ) (cid:3) 0 , for some λ ∗ 1 ≥ 0 , ( 12 . 22 ) where we also require that λ ∗ 1 c 1 ( x ∗ ) (cid:3) 0 . ( 12 . 23 ) Condition ( 12 . 23 ) is known as a complementarity condition ; it implies that the Lagrange multiplier λ 1 can be strictly positive only when the corresponding constraint c 1 is active . Conditions of this type play a central role in constrained optimization , as we see in the sections that follow . In case I , we have that c 1 ( x ∗ ) > 0 , so ( 12 . 23 ) requires that λ ∗ 1 (cid:3) 0 . Hence , ( 12 . 22 ) reduces to ∇ f ( x ∗ ) (cid:3) 0 , as required by ( 12 . 20 ) . In case II , ( 12 . 23 ) allows λ ∗ 1 to take on a nonnegative value , so ( 12 . 22 ) becomes equivalent to ( 12 . 21 ) . TWO INEQUALITY CONSTRAINTS ❏ E XAMPLE 12 . 3 Suppose we add an extra constraint to the problem ( 12 . 18 ) to obtain min x 1 + x 2 s . t . 2 − x 21 − x 22 ≥ 0 , x 2 ≥ 0 , ( 12 . 24 ) for which the feasible region is the half - disk illustrated in Figure 12 . 6 . It is easy to see that the solution lies at ( −√ 2 , 0 ) T , a point at which both constraints are active . By repeating the arguments for the previous examples , we would expect a direction d of ﬁrst - order feasible descent to satisfy ∇ c i ( x ) T d ≥ 0 , i ∈ I (cid:3) { 1 , 2 } , ∇ f ( x ) T d < 0 . ( 12 . 25 ) However , it is clear from Figure 12 . 6 that no such direction can exist when x (cid:3) ( −√ 2 , 0 ) T . The conditions ∇ c i ( x ) T d ≥ 0 , i (cid:3) 1 , 2 , are both satisﬁed only if d lies in the quadrant deﬁned by ∇ c 1 ( x ) and ∇ c 2 ( x ) , but it is clear by inspection that all vectors d in this quadrant satisfy ∇ f ( x ) T d ≥ 0 . Let us see how the Lagrangian and its derivatives behave for the problem ( 12 . 24 ) and the solution point ( −√ 2 , 0 ) T . First , we include an additional term λ i c i ( x ) in the Lagrangian for each additional constraint , so the deﬁnition of L becomes L ( x , λ ) (cid:3) f ( x ) − λ 1 c 1 ( x ) − λ 2 c 2 ( x ) , 314 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N ∆ ∆ ∆ 1 2 c f c Figure 12 . 6 Problem ( 12 . 24 ) , illustrating the gradients of the active constraints and objective at the solution . where λ (cid:3) ( λ 1 , λ 2 ) T is the vector of Lagrange multipliers . The extension of condition ( 12 . 22 ) to this case is ∇ x L ( x ∗ , λ ∗ ) (cid:3) 0 , for some λ ∗ ≥ 0 , ( 12 . 26 ) where the inequality λ ∗ ≥ 0 means that all components of λ ∗ are required to be nonnegative . By applying the complementarity condition ( 12 . 23 ) to both inequality constraints , we obtain λ ∗ 1 c 1 ( x ∗ ) (cid:3) 0 , λ ∗ 2 c 2 ( x ∗ ) (cid:3) 0 . ( 12 . 27 ) When x ∗ (cid:3) ( −√ 2 , 0 ) T , we have ∇ f ( x ∗ ) (cid:3) (cid:1) 1 1 (cid:2) , ∇ c 1 ( x ∗ ) (cid:3) (cid:1) 2 √ 2 0 (cid:2) , ∇ c 2 ( x ∗ ) (cid:3) (cid:1) 0 1 (cid:2) , so that it is easy to verify that ∇ x L ( x ∗ , λ ∗ ) (cid:3) 0 when we select λ ∗ as follows : λ ∗ (cid:3) (cid:1) 1 / ( 2 √ 2 ) 1 (cid:2) . Note that both components of λ ∗ are positive , so that ( 12 . 26 ) is satisﬁed . We consider now some other feasible points that are not solutions of ( 12 . 24 ) , and examine the properties of the Lagrangian and its gradient at these points . For the point x (cid:3) ( √ 2 , 0 ) T , we again have that both constraints are active ( see Figure 12 . 7 ) . However , it s easy to identify vectors d that satisﬁes ( 12 . 25 ) : d (cid:3) ( − 1 , 0 ) T is one such vector ( there are many others ) . For this value of x it is easy to verify that the condition ∇ x L ( x , λ ) (cid:3) 0 is satisﬁed only when λ (cid:3) ( − 1 / ( 2 √ 2 ) , 1 ) T . Note that the ﬁrst component λ 1 is negative , so that the conditions ( 12 . 26 ) are not satisﬁed at this point . Finally , we consider the point x (cid:3) ( 1 , 0 ) T , at which only the second constraint c 2 is active . Since any small step s away from this point will continue to satisfy c 1 ( x + s ) > 0 , we need to consider only the behavior of c 2 and f in determining whether s is indeed a feasible 1 2 . 2 . T A N G E N T C O N E A N D C O N S T R A I N T Q U A L I F I C A T I O N S 315 ∆ ∆ ∆ f c 2 1 c Figure 12 . 7 Problem ( 12 . 24 ) , illustrating the gradients of the active constraints and objective at a nonoptimal point . descent step . Using the same reasoning as in the earlier examples , we ﬁnd that the direction of feasible descent d must satisfy ∇ c 2 ( x ) T d ≥ 0 , ∇ f ( x ) T d < 0 . ( 12 . 28 ) By noting that ∇ f ( x ) (cid:3) (cid:1) 1 1 (cid:2) , ∇ c 2 ( x ) (cid:3) (cid:1) 0 1 (cid:2) , it is easy to verify that the vector d (cid:3) (cid:7) − 12 , 14 (cid:8) T satisﬁes ( 12 . 28 ) and is therefore a descent direction . To show that optimality conditions ( 12 . 26 ) and ( 12 . 27 ) fail , we note ﬁrst from ( 12 . 27 ) that since c 1 ( x ) > 0 , we must have λ 1 (cid:3) 0 . Therefore , in trying to satisfy ∇ x L ( x , λ ) (cid:3) 0 , we are left to search for a value λ 2 such that ∇ f ( x ) − λ 2 ∇ c 2 ( x ) (cid:3) 0 . No such λ 2 exists , and thus this point fails to satisfy the optimality conditions . ❐ 12 . 2 TANGENT CONE AND CONSTRAINT QUALIFICATIONS In this section we deﬁne the tangent cone T (cid:22) ( x ∗ ) to the closed convex set (cid:22) at a point x ∗ ∈ (cid:22) , and also the set F ( x ∗ ) of ﬁrst - order feasible directions at x ∗ . We also discuss constraint qualiﬁcations . In the previous section , we determined whether or not it was possible to take a feasible descent step away from a given feasible point x by examining the ﬁrst derivatives of f and the constraint functions c i . We used the ﬁrst - order Taylor series expansion of these functions about x to form an approximate problem in which both objective and constraints are linear . This approach makes sense , however , only when the linearized approximation captures the essential geometric features of the feasible set near the point x in question . If , near x , the linearization is fundamentally different from the 316 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N feasible set ( for instance , it is an entire plane , while the feasible set is a single point ) then we cannot expect the linear approximation to yield useful information about the original problem . Hence , we need to make assumptions about the nature of the constraints c i that are active at x to ensure that the linearized approximation is similar to the feasible set , near x . Constraint qualiﬁcations are assumptions that ensure similarity of the constraint set (cid:22) and its linearized approximation , in a neighborhood of x ∗ . Given a feasible point x , we call { z k } a feasible sequence approaching x if z k ∈ (cid:22) for all k sufﬁciently large and z k → x . Later , we characterize a local solution of ( 12 . 1 ) as a point x at which all feasible sequences approaching x have the property that f ( z k ) ≥ f ( x ) for all k sufﬁciently large , and we will derive practical , veriﬁable conditions under which this property holds . We lay the groundwork in this section by characterizing the directions in which we can step away from x while remaining feasible . A tangent is a limiting direction of a feasible sequence . Deﬁnition 12 . 2 . The vector d is said to be a tangent ( or tangent vector ) to (cid:22) at a point x if there are a feasible sequence { z k } approaching x and a sequence of positive scalars { t k } with t k → 0 such that lim k →∞ z k − x t k (cid:3) d . ( 12 . 29 ) The set of all tangents to (cid:22) at x ∗ is called the tangent cone and is denoted by T (cid:22) ( x ∗ ) . It is easy to see that the tangent cone is indeed a cone , according to the deﬁnition ( A . 36 ) . If d is a tangent vector with corresponding sequences { z k } and { t k } , then by replacing each t k by α − 1 t k , for any α > 0 , we ﬁnd that α d ∈ T (cid:22) ( x ∗ ) also . We obtain that 0 ∈ T (cid:22) ( x ) by setting z k ≡ x in the deﬁnition of feasible sequence . We turn now to the linearized feasible direction set , which we deﬁne as follows . Deﬁnition 12 . 3 . Given a feasible point x and the active constraint set A ( x ) of Deﬁnition 12 . 1 , the set of linearized feasible directions F ( x ) is F ( x ) (cid:3) (cid:21) d (cid:28)(cid:28) d T ∇ c i ( x ) (cid:3) 0 , for all i ∈ E , d T ∇ c i ( x ) ≥ 0 , for all i ∈ A ( x ) ∩ I (cid:22) . As with the tangent cone , it is easy to verify that F ( x ) is a cone , according to the deﬁnition ( A . 36 ) . It is important to note that the deﬁnition of tangent cone does not rely on the algebraic speciﬁcation of the set (cid:22) , only on its geometry . The linearized feasible direction set does , however , depend on the deﬁnition of the constraint functions c i , i ∈ E ∪ I . 1 2 . 2 . T A N G E N T C O N E A N D C O N S T R A I N T Q U A L I F I C A T I O N S 317 d c 1 _ feasible sequence tangent z f k Figure 12 . 8 Constraint normal , objective gradient , and feasible sequence for problem ( 12 . 9 ) . We illustrate the tangent cone and the linearized feasible direction set by revisiting Examples 12 . 1 and 12 . 2 . ❏ E XAMPLE 12 . 4 ( E XAMPLE 12 . 1 , R EVISITED ) Figure 12 . 8 shows the problem ( 12 . 9 ) , the equality - constrained problem in which the feasible set is a circle of radius √ 2 , near the nonoptimal point x (cid:3) ( −√ 2 , 0 ) T . The ﬁgure also shows a feasible sequence approaching x . This sequence could be deﬁned analytically by the formula z k (cid:3) (cid:1) − (cid:5) 2 − 1 / k 2 − 1 / k (cid:2) . ( 12 . 30 ) By choosing t k (cid:3) (cid:8) z k − x (cid:8) , we ﬁnd that d (cid:3) ( 0 , − 1 ) T is a tangent . Note that the objective function f ( x ) (cid:3) x 1 + x 2 increases as we move along the sequence ( 12 . 30 ) ; in fact , we have f ( z k + 1 ) > f ( z k ) for all k (cid:3) 2 , 3 , . . . . It follows that f ( z k ) < f ( x ) for k (cid:3) 2 , 3 , . . . , so x cannot be a solution of ( 12 . 9 ) . Another feasible sequence is one that approaches x (cid:3) ( −√ 2 , 0 ) T from the opposite direction . Its elements are deﬁned by z k (cid:3) (cid:1) − (cid:5) 2 − 1 / k 2 1 / k (cid:2) . It is easy to show that f decreases along this sequence and that the tangents corresponding to this sequence are d (cid:3) ( 0 , α ) T . In summary , the tangent cone at x (cid:3) ( −√ 2 , 0 ) T is { ( 0 , d 2 ) T | d 2 ∈ IR } . 318 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N For the deﬁnition ( 12 . 9 ) of this set , and Deﬁnition 12 . 3 , we have that d (cid:3) ( d 1 , d 2 ) T ∈ F ( x ) if 0 (cid:3) ∇ c 1 ( x ) T d (cid:3) (cid:1) 2 x 1 2 x 2 (cid:2) T (cid:1) d 1 d 2 (cid:2) (cid:3) − 2 √ 2 d 1 . Therefore , we obtain F ( x ) (cid:3) { ( 0 , d 2 ) T | d 2 ∈ IR } . In this case , we have T (cid:22) ( x ) (cid:3) F ( x ) . Suppose that the feasible set is deﬁned instead by the formula (cid:22) (cid:3) { x | c 1 ( x ) (cid:3) 0 } , where c 1 ( x ) (cid:3) ( x 21 + x 22 − 2 ) 2 (cid:3) 0 . ( 12 . 31 ) ( Note that (cid:22) is the same , but its algebraic speciﬁcation has changed . ) The vector d belongs to the linearized feasible set if 0 (cid:3) ∇ c 1 ( x ) T d (cid:3) (cid:1) 4 ( x 21 + x 22 − 2 ) x 1 4 ( x 21 + x 22 − 2 ) x 2 (cid:2) T (cid:1) d 1 d 2 (cid:2) (cid:3) (cid:1) 0 0 (cid:2) T (cid:1) d 1 d 2 (cid:2) , which is true for all ( d 1 , d 2 ) T . Hence , we have F ( x ) (cid:3) IR 2 , so for this algebraic speciﬁcation of (cid:22) , the tangent cone and linearized feasible sets differ . ❐ ❏ E XAMPLE 12 . 5 ( E XAMPLE 12 . 2 , R EVISITED ) We now reconsider problem ( 12 . 18 ) in Example 12 . 2 . The solution x (cid:3) ( − 1 , − 1 ) T is the same as in the equality - constrained case , but there is a much more extensive collection of feasible sequences that converge to any given feasible point ( see Figure 12 . 9 ) . 2 x 1 x Figure 12 . 9 Feasible sequences converging to a particular feasible point for the region deﬁned by x 21 + x 22 ≤ 2 . 1 2 . 2 . T A N G E N T C O N E A N D C O N S T R A I N T Q U A L I F I C A T I O N S 319 From the point x (cid:3) ( −√ 2 , 0 ) T , the various feasible sequences deﬁned above for the equality - constrained problem are still feasible for ( 12 . 18 ) . There are also inﬁnitely many feasible sequences that converge to x (cid:3) ( −√ 2 , 0 ) T along a straight line from the interior of the circle . These sequences have the form z k (cid:3) ( −√ 2 , 0 ) T + ( 1 / k ) w , where w is any vector whose ﬁrst component is positive ( w 1 > 0 ) . The point z k is feasible provided that (cid:8) z k (cid:8) ≤ √ 2 , that is , ( −√ 2 + w 1 / k ) 2 + ( w 2 / k ) 2 ≤ 2 , which is true when k ≥ ( w 21 + w 22 ) / ( 2 √ 2 w 1 ) . In addition to these straight - line feasible sequences , we can also deﬁne an inﬁnite variety of sequences that approach ( −√ 2 , 0 ) T along a curve from the interior of the circle . To summarize , the tangent cone to this set at ( −√ 2 , 0 ) T is { ( w 1 , w 2 ) T | w 1 ≥ 0 } . For the deﬁnition ( 12 . 18 ) of this feasible set , we have from Deﬁnition 12 . 3 that d ∈ F ( x ) if 0 ≤ ∇ c 1 ( x ) T d (cid:3) (cid:1) − 2 x 1 − 2 x 2 (cid:2) T (cid:1) d 1 d 2 (cid:2) (cid:3) 2 √ 2 d 1 . Hence , we obtain F ( x ) (cid:3) T (cid:22) ( x ) for this particular algebraic speciﬁcation of the feasible set . ❐ Constraint qualiﬁcations are conditions under which the linearized feasible set F ( x ) is similar to the tangent cone T (cid:22) ( x ) . In fact , most constraint qualiﬁcations ensure that these two sets are identical . As mentioned earlier , these conditions ensure that the F ( x ) , which is constructed by linearizing the algebraic description of the set (cid:22) at x , captures the essential geometric features of the set (cid:22) in the vicinity of x , as represented by T (cid:22) ( x ) . Revisiting Example 12 . 4 , we see that both T (cid:22) ( x ) and F ( x ) consist of the vertical axis , which is qualitatively similar to the set (cid:22) − { x } in the neighborhood of x . As a further example , consider the constraints c 1 ( x ) (cid:3) 1 − x 21 − ( x 2 − 1 ) 2 ≥ 0 , c 2 ( x ) (cid:3) − x 2 ≥ 0 , ( 12 . 32 ) for which the feasible set is the single point (cid:22) (cid:3) { ( 0 , 0 ) T } ( see Figure 12 . 10 ) . For this point x (cid:3) ( 0 , 0 ) T , it is obvious that that tangent cone is T (cid:22) ( x ) (cid:3) { ( 0 , 0 ) T } , since all feasible sequences approaching x must have z k (cid:3) x (cid:3) ( 0 , 0 ) T for all k sufﬁciently large . Moreover , it is easy to show that linearized approximation to the feasible set F ( x ) is F ( x ∗ ) (cid:3) { ( d 1 , 0 ) T | d 1 ∈ IR } , 320 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N Figure 12 . 10 Problem ( 12 . 32 ) , for which the feasible set is the single point of intersection between circle and line . that is , the entire horizontal axis . In this case , the linearized feasible direction set does not capture the geometry of the feasible set , so constraint qualiﬁcations are not satisﬁed . The constraint qualiﬁcation most often used in the design of algorithms is the subject of the next deﬁnition . Deﬁnition 12 . 4 ( LICQ ) . Given the point x and the active set A ( x ) deﬁned in Deﬁnition 12 . 1 , we say that the linear independence constraint qualiﬁcation ( LICQ ) holds if the set of active constraint gradients { ∇ c i ( x ) , i ∈ A ( x ) } is linearly independent . Note that this condition is not satisﬁed for the examples ( 12 . 32 ) and ( 12 . 31 ) . In general , if LICQ holds , none of the active constraint gradients can be zero . We mention other constraint qualiﬁcations in Section 12 . 6 . 12 . 3 FIRST - ORDER OPTIMALITY CONDITIONS In this section , we state ﬁrst - order necessary conditions for x ∗ to be a local minimizer and show how these conditions are satisﬁed on a small example . The proof of the result is presented in subsequent sections . Asapreliminarytostatingthenecessaryconditions , wedeﬁnetheLagrangianfunction for the general problem ( 12 . 1 ) . L ( x , λ ) (cid:3) f ( x ) − (cid:3) i ∈ E ∪ I λ i c i ( x ) . ( 12 . 33 ) ( We had previously deﬁned special cases of this function for the examples of Section 12 . 1 . ) 1 2 . 3 . F I R S T - O R D E R O P T I M A L I T Y C O N D I T I O N S 321 The necessary conditions deﬁned in the following theorem are called ﬁrst - order con - ditions because they are concerned with properties of the gradients ( ﬁrst - derivative vectors ) of the objective and constraint functions . These conditions are the foundation for many of the algorithms described in the remaining chapters of the book . Theorem 12 . 1 ( First - Order Necessary Conditions ) . Suppose that x ∗ is a local solution of ( 12 . 1 ) , that the functions f and c i in ( 12 . 1 ) are continuously differentiable , and that the LICQ holds at x ∗ . Then there is a Lagrange multiplier vector λ ∗ , with components λ ∗ i , i ∈ E ∪ I , such that the following conditions are satisﬁed at ( x ∗ , λ ∗ ) ∇ x L ( x ∗ , λ ∗ ) (cid:3) 0 , ( 12 . 34a ) c i ( x ∗ ) (cid:3) 0 , for all i ∈ E , ( 12 . 34b ) c i ( x ∗ ) ≥ 0 , for all i ∈ I , ( 12 . 34c ) λ ∗ i ≥ 0 , for all i ∈ I , ( 12 . 34d ) λ ∗ i c i ( x ∗ ) (cid:3) 0 , for all i ∈ E ∪ I . ( 12 . 34e ) The conditions ( 12 . 34 ) are often known as the Karush – Kuhn – Tucker conditions , or KKT conditions for short . The conditions ( 12 . 34e ) are complementarity conditions ; they imply that either constraint i is active or λ ∗ i (cid:3) 0 , or possibly both . In particular , the Lagrange multipliers corresponding to inactive inequality constraints are zero , we can omit the terms for indices i / ∈ A ( x ∗ ) from ( 12 . 34a ) and rewrite this condition as 0 (cid:3) ∇ x L ( x ∗ , λ ∗ ) (cid:3) ∇ f ( x ∗ ) − (cid:3) i ∈ A ( x ∗ ) λ ∗ i ∇ c i ( x ∗ ) . ( 12 . 35 ) A special case of complementarity is important and deserves its own deﬁnition . Deﬁnition 12 . 5 ( Strict Complementarity ) . Given a local solution x ∗ of ( 12 . 1 ) and a vector λ ∗ satisfying ( 12 . 34 ) , we say that the strict complementarity condition holds if exactly one of λ ∗ i and c i ( x ∗ ) is zero for each index i ∈ I . In other words , we have that λ ∗ i > 0 for each i ∈ I ∩ A ( x ∗ ) . Satisfaction of the strict complementarity property usually makes it easier for algorithms to determine the active set A ( x ∗ ) and converge rapidly to the solution x ∗ . For a given problem ( 12 . 1 ) and solution point x ∗ , there may be many vectors λ ∗ for which the conditions ( 12 . 34 ) are satisﬁed . When the LICQ holds , however , the optimal λ ∗ is unique ( see Exercise 12 . 17 ) . The proof of Theorem 12 . 1 is quite complex , but it is important to our understanding of constrained optimization , so we present it in the next section . First , we illustrate the KKT conditions with another example . 322 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N x 2 x 1 Figure 12 . 11 Inequality - constrained problem ( 12 . 36 ) with solution at ( 1 , 0 ) T . ❏ E XAMPLE 12 . 6 Consider the feasible region illustrated in Figure 12 . 2 and described by the four constraints ( 12 . 6 ) . By restating the constraints in the standard form of ( 12 . 1 ) and including an objective function , the problem becomes min x (cid:17) x 1 − 3 2 (cid:18) 2 + (cid:17) x 2 − 1 2 (cid:18) 4 s . t . ⎡ ⎢⎢⎢⎢⎣ 1 − x 1 − x 2 1 − x 1 + x 2 1 + x 1 − x 2 1 + x 1 + x 2 ⎤ ⎥⎥⎥⎥⎦ ≥ 0 . ( 12 . 36 ) It is fairly clear from Figure 12 . 11 that the solution is x ∗ (cid:3) ( 1 , 0 ) T . The ﬁrst and second constraints in ( 12 . 36 ) are active at this point . Denoting them by c 1 and c 2 ( and the inactive constraints by c 3 and c 4 ) , we have ∇ f ( x ∗ ) (cid:3) ⎡ ⎣ − 1 − 1 2 ⎤ ⎦ , ∇ c 1 ( x ∗ ) (cid:3) (cid:1) − 1 − 1 (cid:2) , ∇ c 2 ( x ∗ ) (cid:3) (cid:1) − 1 1 (cid:2) . Therefore , the KKT conditions ( 12 . 34a ) – ( 12 . 34e ) are satisﬁed when we set λ ∗ (cid:3) (cid:7) 34 , 14 , 0 , 0 (cid:8) T . ❐ 1 2 . 4 . F I R S T - O R D E R O P T I M A L I T Y C O N D I T I O N S : P R O O F 323 12 . 4 FIRST - ORDER OPTIMALITY CONDITIONS : PROOF We now develop a proof of Theorem 12 . 1 . A number of key subsidiary results are required , so the development is quite long . However , a complete treatment is worthwhile , since these results are so fundamental to the ﬁeld of optimization . RELATING THE TANGENT CONE AND THE FIRST - ORDER FEASIBLE DIRECTION SET The following key result uses a constraint qualiﬁcation ( LICQ ) to relate the tangent cone of Deﬁnition 12 . 2 to the set F of ﬁrst - order feasible directions of Deﬁnition 12 . 3 . In the proof below and in later results , we use the notation A ( x ∗ ) to represent the matrix whose rows are the active constraint gradients at the optimal point , that is , A ( x ∗ ) T (cid:3) [ ∇ c i ( x ∗ ) ] i ∈ A ( x ∗ ) , ( 12 . 37 ) where the active set A ( x ∗ ) is deﬁned as in Deﬁnition 12 . 1 . Lemma 12 . 2 . Let x ∗ be a feasible point . The following two statements are true . ( i ) T (cid:22) ( x ∗ ) ⊂ F ( x ∗ ) . ( ii ) If the LICQ condition is satisﬁed at x ∗ , then F ( x ∗ ) (cid:3) T (cid:22) ( x ∗ ) . P ROOF . Without loss of generality , let us assume that all the constraints c i ( · ) , i (cid:3) 1 , 2 , . . . , m , areactiveat x ∗ . ( Wecanarriveatthisconvenientorderingbysimplydroppingall inactive constraints—which are irrelevant in some neighborhood of x ∗ —and renumbering the active constraints that remain . ) To prove ( i ) , let { z k } and { t k } be the sequences for which ( 12 . 29 ) is satisﬁed , that is , lim k →∞ z k − x ∗ t k (cid:3) d . ( Note in particular that t k > 0 for all k . ) From this deﬁnition , we have that z k (cid:3) x ∗ + t k d + o ( t k ) . ( 12 . 38 ) By taking i ∈ E and using Taylor’s theorem , we have that 0 (cid:3) 1 t k c i ( z k ) (cid:3) 1 t k (cid:9) c i ( x ∗ ) + t k ∇ c i ( x ∗ ) T d + o ( t k ) (cid:10) (cid:3) ∇ c i ( x ∗ ) T d + o ( t k ) t k . 324 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N By taking the limit as k → ∞ , the last term in this expression vanishes , and we have ∇ c i ( x ∗ ) T d (cid:3) 0 , as required . For the active inequality constraints i ∈ A ( x ∗ ) ∩ I , we have similarly that 0 ≤ 1 t k c i ( z k ) (cid:3) 1 t k (cid:9) c i ( x ∗ ) + t k ∇ c i ( x ∗ ) T d + o ( t k ) (cid:10) (cid:3) ∇ c i ( x ∗ ) T d + o ( t k ) t k . Hence , by a similar limiting argument , we have that ∇ c i ( x ∗ ) T d ≥ 0 , as required . For ( ii ) , we use the implicit function theorem ( see the Appendix or Lang [ 187 , p . 131 ] for a statement of this result ) . First , since the LICQ holds , we have from Deﬁnition 12 . 4 that the m × n matrix A ( x ∗ ) of active constraint gradients has full row rank m . Let Z be a matrix whose columns are a basis for the null space of A ( x ∗ ) ; that is , Z ∈ IR n × ( n − m ) , Z has full column rank , A ( x ∗ ) Z (cid:3) 0 . ( 12 . 39 ) ( See the related discussion in Chapter 16 . ) Choose d ∈ F ( x ∗ ) arbitrarily , and suppose that { t k } ∞ k (cid:3) 0 is any sequence of positive scalars such lim k →∞ t k (cid:3) 0 . Deﬁne the parametrized system of equations R : IR n × IR → IR n by R ( z , t ) (cid:3) (cid:1) c ( z ) − t A ( x ∗ ) d Z T ( z − x ∗ − td ) (cid:2) (cid:3) (cid:1) 0 0 (cid:2) . ( 12 . 40 ) We claim that the solutions z (cid:3) z k of this system for small t (cid:3) t k > 0 give a feasible sequence that approaches x ∗ and satisﬁes the deﬁnition ( 12 . 29 ) . At t (cid:3) 0 , z (cid:3) x ∗ , and the Jacobian of R at this point is ∇ z R ( x ∗ , 0 ) (cid:3) (cid:1) A ( x ∗ ) Z T (cid:2) , ( 12 . 41 ) which is nonsingular by construction of Z . Hence , according to the implicit function theorem , the system ( 12 . 40 ) has a unique solution z k for all values of t k sufﬁciently small . Moreover , we have from ( 12 . 40 ) and Deﬁnition 12 . 3 that i ∈ E ⇒ c i ( z k ) (cid:3) t k ∇ c i ( x ∗ ) T d (cid:3) 0 , ( 12 . 42a ) i ∈ A ( x ∗ ) ∩ I ⇒ c i ( z k ) (cid:3) t k ∇ c i ( x ∗ ) T d ≥ 0 , ( 12 . 42b ) so that z k is indeed feasible . 1 2 . 4 . F I R S T - O R D E R O P T I M A L I T Y C O N D I T I O N S : P R O O F 325 It remains to verify that ( 12 . 29 ) holds for this choice of { z k } . Using the fact that R ( z k , t k ) (cid:3) 0 for all k together with Taylor’s theorem , we ﬁnd that 0 (cid:3) R ( z k , t k ) (cid:3) (cid:1) c ( z k ) − t k A ( x ∗ ) d Z T ( z k − x ∗ − t k d ) (cid:2) (cid:3) (cid:1) A ( x ∗ ) ( z k − x ∗ ) + o ( (cid:8) z k − x ∗ (cid:8) ) − t k A ( x ∗ ) d Z T ( z k − x ∗ − t k d ) (cid:2) (cid:3) (cid:1) A ( x ∗ ) Z T (cid:2) ( z k − x ∗ − t k d ) + o ( (cid:8) z k − x ∗ (cid:8) ) . By dividing this expression by t k and using nonsingularity of the coefﬁcient matrix in the ﬁrst term , we obtain z k − x ∗ t k (cid:3) d + o (cid:17) (cid:8) z k − x ∗ (cid:8) t k (cid:18) , from which it follows that ( 12 . 29 ) is satisﬁed ( for x (cid:3) x ∗ ) . Hence , d ∈ T (cid:22) ( x ∗ ) for an arbitrary d ∈ F ( x ∗ ) , so the proof of ( ii ) is complete . (cid:1) A FUNDAMENTAL NECESSARY CONDITION Asmentionedabove , alocalsolutionof ( 12 . 1 ) isapoint x atwhichallfeasiblesequences have the property that f ( z k ) ≥ f ( x ) for all k sufﬁciently large . The following result shows that if such a sequence exists , then its limiting directions must make a nonnegative inner product with the objective function gradient . Theorem 12 . 3 . If x ∗ is a local solution of ( 12 . 1 ) , then we have ∇ f ( x ∗ ) T d ≥ 0 , for all d ∈ T (cid:22) ( x ∗ ) . ( 12 . 43 ) P ROOF . Suppose for contradiction that there is a tangent d for which ∇ f ( x ∗ ) T d < 0 . Let { z k } and { t k } be the sequences satisfying Deﬁnition 12 . 2 for this d . We have that f ( z k ) (cid:3) f ( x ∗ ) + ( z k − x ∗ ) T ∇ f ( x ∗ ) + o ( (cid:8) z k − x ∗ (cid:8) ) (cid:3) f ( x ∗ ) + t k d T ∇ f ( x ∗ ) + o ( t k ) , 326 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N Figure 12 . 12 Problem ( 12 . 44 ) , showing various limiting directions of feasible sequences at the point ( 0 , 0 ) T . where the second line follows from ( 12 . 38 ) . Since d T ∇ f ( x ∗ ) < 0 , the remainder term is eventually dominated by the ﬁrst - order term , that is , f ( z k ) < f ( x ∗ ) + 12 t k d T ∇ f ( x ∗ ) , for all k sufﬁciently large . Hence , given any open neighborhood of x ∗ , we can choose k sufﬁciently large that z k lies within this neighborhood and has a lower value of the objective f . Therefore , x ∗ is not a local solution . (cid:1) The converse of this result is not necessarily true . That is , we may have ∇ f ( x ∗ ) T d ≥ 0 for all d ∈ T (cid:22) ( x ∗ ) , yet x ∗ is not a local minimizer . An example is the following problem in two unknowns , illustrated in Figure 12 . 12 min x 2 subject to x 2 ≥ − x 21 . ( 12 . 44 ) This problem is actually unbounded , but let us examine its behavior at x ∗ (cid:3) ( 0 , 0 ) T . It is not difﬁcult to show that all limiting directions d of feasible sequences must have d 2 ≥ 0 , so that ∇ f ( x ∗ ) T d (cid:3) d 2 ≥ 0 . However , x ∗ is clearly not a local minimizer ; the point ( α , − α 2 ) T for α > 0 has a smaller function value than x ∗ , and can be brought arbitrarily close to x ∗ by setting α sufﬁciently small . FARKAS’ LEMMA The most important step in proving Theorem 12 . 1 is a classical theorem of the alternative known as Farkas’ Lemma . This lemma considers a cone K deﬁned as follows : K (cid:3) { By + C w | y ≥ 0 } , ( 12 . 45 ) 1 2 . 4 . F I R S T - O R D E R O P T I M A L I T Y C O N D I T I O N S : P R O O F 327 b 2 b 1 b 3 b 2 b 1 b 3 g g d Figure 12 . 13 Farkas’ Lemma : Either g ∈ K ( left ) or there is a separating hyperplane ( right ) . where B and C are matrices of dimension n × m and n × p , respectively , and y and w are vectors of appropriate dimensions . Given a vector g ∈ IR n , Farkas’ Lemma states that one ( and only one ) of two alternatives is true . Either g ∈ K , or else there is a vector d ∈ IR n such that g T d < 0 , B T d ≥ 0 , C T d (cid:3) 0 . ( 12 . 46 ) The two cases are illustrated in Figure 12 . 13 for the case of B with three columns , C null , and n (cid:3) 2 . Note that in the second case , the vector d deﬁnes a separating hyperplane , which is a plane in IR n that separates the vector g from the cone K . Lemma 12 . 4 ( Farkas ) . Let the cone K be deﬁned as in ( 12 . 45 ) . Given any vector g ∈ IR n , we have either that g ∈ K or that there exists d ∈ IR n satisfying ( 12 . 46 ) , but not both . P ROOF . We show ﬁrst that the two alternatives cannot hold simultaneously . If g ∈ K , there exist vectors y ≥ 0 and w such that g (cid:3) By + C w . If there also exists a d with the property ( 12 . 46 ) , we have by taking inner products that 0 > d T g (cid:3) d T By + d T C w (cid:3) ( B T d ) T y + ( C T d ) T w ≥ 0 , where the ﬁnal inequality follows from C T d (cid:3) 0 , B T d ≥ 0 , and y ≥ 0 . Hence , we cannot have both alternatives holding at once . We now show that one of the alternatives holds . To be precise , we show how to construct d with the properties ( 12 . 46 ) in the case that g / ∈ K . For this part of the proof , we need to use the property that K is a closed set—a fact that is intuitively obvious but not trivial to prove ( see Lemma 12 . 15 in the Notes and References below ) . Let ˆ s be the vector 328 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N in K that is closest to g in the sense of the Euclidean norm . Because K is closed , ˆ s is well deﬁned and is given by the solution of the following optimization problem : min (cid:8) s − g (cid:8) 22 subject to s ∈ K . ( 12 . 47 ) Since ˆ s ∈ K , we have from the fact that K is a cone that α ˆ s ∈ K for all scalars α ≥ 0 . Since (cid:8) α ˆ s − g (cid:8) 22 is minimized by α (cid:3) 1 , we have by simple calculus that d d α (cid:8) α ˆ s − g (cid:8) 22 (cid:28)(cid:28)(cid:28)(cid:28) α (cid:3) 1 (cid:3) 0 ⇒ (cid:7) − 2 ˆ s T g + 2 t ˆ s T ˆ s (cid:8)(cid:28)(cid:28) α (cid:3) 1 (cid:3) 0 ⇒ ˆ s T ( ˆ s − g ) (cid:3) 0 . ( 12 . 48 ) Now , let s be any other vector in K . Since K is convex , we have by the minimizing property of ˆ s that (cid:8)ˆ s + θ ( s − ˆ s ) − g (cid:8) 22 ≥ (cid:8)ˆ s − g (cid:8) 22 for all θ ∈ [ 0 , 1 ] , and hence 2 θ ( s − ˆ s ) T ( ˆ s − g ) + θ 2 (cid:8) s − ˆ s (cid:8) 22 ≥ 0 . By dividing this expression by θ and taking the limit as θ ↓ 0 , we have ( s − ˆ s ) T ( ˆ s − g ) ≥ 0 . Therefore , because of ( 12 . 48 ) , s T ( ˆ s − g ) ≥ 0 , for all s ∈ K . ( 12 . 49 ) We claim now that the vector d (cid:3) ˆ s − g satisﬁes the conditions ( 12 . 46 ) . Note that d (cid:9)(cid:3) 0 because g / ∈ K . We have from ( 12 . 48 ) that d T g (cid:3) d T ( ˆ s − d ) (cid:3) ( ˆ s − g ) T ˆ s − d T d (cid:3) −(cid:8) d (cid:8) 2 2 < 0 , so that d satisﬁes the ﬁrst property in ( 12 . 46 ) . From ( 12 . 49 ) , we have that d T s ≥ 0 for all s ∈ K , so that d T ( By + C w ) ≥ 0 for all y ≥ 0 and all w . By ﬁxing y (cid:3) 0 we have that ( C T d ) T w ≥ 0 for all w , which is true only if C T d (cid:3) 0 . By ﬁxing w (cid:3) 0 , we have that ( B T d ) T y ≥ 0 for all y ≥ 0 , which is true only if B T d ≥ 0 . Hence , d also satisﬁes the second and third properties in ( 12 . 46 ) and our proof is complete . (cid:1) 1 2 . 4 . F I R S T - O R D E R O P T I M A L I T Y C O N D I T I O N S : P R O O F 329 By applying Lemma 12 . 4 to the cone N deﬁned by N (cid:3) ⎧⎨ ⎩ (cid:3) i ∈ A ( x ∗ ) λ i ∇ c i ( x ∗ ) , λ i ≥ 0 for i ∈ A ( x ∗ ) ∩ I ⎫⎬ ⎭ , ( 12 . 50 ) and setting g (cid:3) ∇ f ( x ∗ ) , we have that either ∇ f ( x ∗ ) (cid:3) (cid:3) i ∈ A ( x ∗ ) λ i ∇ c i ( x ∗ ) (cid:3) A ( x ∗ ) T λ ∗ , λ i ≥ 0 for i ∈ A ( x ∗ ) ∩ I , ( 12 . 51 ) or else there is a direction d such that d T ∇ f ( x ∗ ) < 0 and d ∈ F ( x ∗ ) . PROOF OF THEOREM 12 . 1 Lemmas 12 . 2 and 12 . 4 can be combined to give the KKT conditions described in Theorem 12 . 1 . We work through the ﬁnal steps of the proof here . Suppose that x ∗ ∈ IR n is a feasible point at which the LICQ holds . The theorem claims that if x ∗ is a local solution for ( 12 . 1 ) , then there is a vector λ ∗ ∈ IR m that satisﬁes the conditions ( 12 . 34 ) . We show ﬁrst that there are multipliers λ i , i ∈ A ( x ∗ ) , such that ( 12 . 51 ) is satisﬁed . Theorem 12 . 3 tells us that d T ∇ f ( x ∗ ) ≥ 0 for all tangent vectors d ∈ T (cid:22) ( x ∗ ) . From Lemma 12 . 2 , since LICQ holds , we have that T (cid:22) ( x ∗ ) (cid:3) F ( x ∗ ) . By putting these two statementstogether , weﬁndthat d T ∇ f ( x ∗ ) ≥ 0forall d ∈ F ( x ∗ ) . Hence , fromLemma12 . 4 , there is a vector λ for which ( 12 . 51 ) holds , as claimed . We now deﬁne the vector λ ∗ by λ ∗ i (cid:3) (cid:21) λ i , i ∈ A ( x ∗ ) , 0 , i ∈ I \ A ( x ∗ ) , ( 12 . 52 ) and show that this choice of λ ∗ , together with our local solution x ∗ , satisﬁes the conditions ( 12 . 34 ) . We check these conditions in turn . • The condition ( 12 . 34a ) follows immediately from ( 12 . 51 ) and the deﬁnitions ( 12 . 33 ) of the Lagrangian function and ( 12 . 52 ) of λ ∗ . • Since x ∗ is feasible , the conditions ( 12 . 34b ) and ( 12 . 34c ) are satisﬁed . • We have from ( 12 . 51 ) that λ ∗ i ≥ 0 for i ∈ A ( x ∗ ) ∩ I , while from ( 12 . 52 ) , λ ∗ i (cid:3) 0 for i ∈ I \ A ( x ∗ ) . Hence , λ ∗ i ≥ 0 for i ∈ I , so that ( 12 . 34d ) holds . • We have for i ∈ A ( x ∗ ) ∩ I that c i ( x ∗ ) (cid:3) 0 , while for i ∈ I \ A ( x ∗ ) , we have λ ∗ i (cid:3) 0 . Hence λ ∗ i c i ( x ∗ ) (cid:3) 0 for i ∈ I , so that ( 12 . 34e ) is satisﬁed as well . The proof is complete . 330 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N 12 . 5 SECOND - ORDER CONDITIONS So far , we have described ﬁrst - order conditions—the KKT conditions—which tell us how the ﬁrst derivatives of f and the active constraints c i are related to each other at a solution x ∗ . When these conditions are satisﬁed , a move along any vector w from F ( x ∗ ) either increases the ﬁrst - order approximation to the objective function ( that is , w T ∇ f ( x ∗ ) > 0 ) , or else keeps this value the same ( that is , w T ∇ f ( x ∗ ) (cid:3) 0 ) . What role do the second derivatives of f and the constraints c i play in optimality conditions ? We see in this section that second derivatives play a “tiebreaking” role . For the directions w ∈ F ( x ∗ ) for which w T ∇ f ( x ∗ ) (cid:3) 0 , we cannot determine from ﬁrst derivative information alone whether a move along this direction will increase or decrease the objective function f . Second - order conditions examine the second derivative terms in the Taylor series expansions of f and c i , to see whether this extra information resolves the issue of increase or decrease in f . Essentially , the second - order conditions concern the curvature of the Lagrangian function in the “undecided” directions—the directions w ∈ F ( x ∗ ) for which w T ∇ f ( x ∗ ) (cid:3) 0 . Since we are discussing second derivatives , stronger smoothness assumptions are needed here than in the previous sections . For the purpose of this section , f and c i , i ∈ E ∪ I , are all assumed to be twice continuously differentiable . Given F ( x ∗ ) from Deﬁnition 12 . 3 and some Lagrange multiplier vector λ ∗ satisfying the KKT conditions ( 12 . 34 ) , we deﬁne the critical cone C ( x ∗ , λ ∗ ) as follows : C ( x ∗ , λ ∗ ) (cid:3) { w ∈ F ( x ∗ ) | ∇ c i ( x ∗ ) T w (cid:3) 0 , all i ∈ A ( x ∗ ) ∩ I with λ ∗ i > 0 } . Equivalently , w ∈ C ( x ∗ , λ ∗ ) ⇔ ⎧⎪⎨ ⎪⎩ ∇ c i ( x ∗ ) T w (cid:3) 0 , for all i ∈ E , ∇ c i ( x ∗ ) T w (cid:3) 0 , for all i ∈ A ( x ∗ ) ∩ I with λ ∗ i > 0 , ∇ c i ( x ∗ ) T w ≥ 0 , for all i ∈ A ( x ∗ ) ∩ I with λ ∗ i (cid:3) 0 . ( 12 . 53 ) The critical cone contains those directions w that would tend to “adhere” to the active inequality constraints even when we were to make small changes to the objective ( those indices i ∈ I for which the Lagrange multiplier component λ ∗ i is positive ) , as well as to the equality constraints . From the deﬁnition ( 12 . 53 ) and the fact that λ ∗ i (cid:3) 0 for all inactive components i ∈ I \ A ( x ∗ ) , it follows immediately that w ∈ C ( x ∗ , λ ∗ ) ⇒ λ ∗ i ∇ c i ( x ∗ ) T w (cid:3) 0 for all i ∈ E ∪ I . ( 12 . 54 ) Hence , from the ﬁrst KKT condition ( 12 . 34a ) and the deﬁnition ( 12 . 33 ) of the Lagrangian function , we have that w ∈ C ( x ∗ , λ ∗ ) ⇒ w T ∇ f ( x ∗ ) (cid:3) (cid:3) i ∈ E ∪ I λ ∗ i w T ∇ c i ( x ∗ ) (cid:3) 0 . ( 12 . 55 ) 1 2 . 5 . S E C O N D - O R D E R C O N D I T I O N S 331 1 2 x ∆ f − F x C Figure 12 . 14 Problem ( 12 . 56 ) , showing F ( x ∗ ) and C ( x ∗ , λ ∗ ) . Hence the critical cone C ( x ∗ , λ ∗ ) contains directions from F ( x ∗ ) for which it is not clear from ﬁrst derivative information alone whether f will increase or decrease . ❏ E XAMPLE 12 . 7 Consider the problem min x 1 subject to x 2 ≥ 0 , 1 − ( x 1 − 1 ) 2 − x 2 2 ≥ 0 , ( 12 . 56 ) illustrated in Figure 12 . 14 . It is not difﬁcult to see that the solution is x ∗ (cid:3) ( 0 , 0 ) T , with active set A ( x ∗ ) (cid:3) { 1 , 2 } and a unique optimal Lagrange multiplier λ ∗ (cid:3) ( 0 , 0 . 5 ) T . Since the gradients of the active constraints at x ∗ are ( 0 , 1 ) T and ( 2 , 0 ) T , respectively , the LICQ holds , so the optimal multiplier is unique . The linearized feasible set is then F ( x ∗ ) (cid:3) { d | d ≥ 0 } , while the critical cone is C ( x ∗ , λ ∗ ) (cid:3) { ( 0 , w 2 ) T | w 2 ≥ 0 } . ❐ 332 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N The ﬁrst theorem deﬁnes a necessary condition involving the second derivatives : If x ∗ is a local solution , then the Hessian of the Lagrangian has nonnegative curvature along critical directions ( that is , the directions in C ( x ∗ , λ ∗ ) ) . Theorem 12 . 5 ( Second - Order Necessary Conditions ) . Suppose that x ∗ is a local solution of ( 12 . 1 ) and that the LICQ condition is satisﬁed . Let λ ∗ be the Lagrange multiplier vector for which the KKT conditions ( 12 . 34 ) are satisﬁed . Then w T ∇ 2 xx L ( x ∗ , λ ∗ ) w ≥ 0 , for all w ∈ C ( x ∗ , λ ∗ ) . ( 12 . 57 ) P ROOF . Since x ∗ is a local solution , all feasible sequences { z k } approaching x ∗ must have f ( z k ) ≥ f ( x ∗ ) for all k sufﬁciently large . Our approach in this proof is to construct a feasible sequence whose limiting direction is w and show that the property f ( z k ) ≥ f ( x ∗ ) implies that ( 12 . 57 ) holds . Since w ∈ C ( x ∗ , λ ∗ ) ⊂ F ( x ∗ ) , we can use the technique in the proof of Lemma 12 . 2 to choose a sequence { t k } of positive scalars and to construct a feasible sequence { z k } approaching x ∗ such that lim k →∞ z k − x ∗ t k (cid:3) w , ( 12 . 58 ) which we can write also as ( 12 . 58 ) that z k − x ∗ (cid:3) t k w + o ( t k ) . ( 12 . 59 ) Because of the construction technique for { z k } , we have from formula ( 12 . 42 ) that c i ( z k ) (cid:3) t k ∇ c i ( x ∗ ) T w , for all i ∈ A ( x ∗ ) ( 12 . 60 ) From ( 12 . 33 ) , ( 12 . 60 ) , and ( 12 . 54 ) , we have L ( z k , λ ∗ ) (cid:3) f ( z k ) − (cid:3) i ∈ E ∪ I λ ∗ i c i ( z k ) (cid:3) f ( z k ) − t k (cid:3) i ∈ A ( x ∗ ) λ ∗ i ∇ c i ( x ∗ ) T w (cid:3) f ( z k ) , ( 12 . 61 ) On the other hand , we can perform a Taylor series expansion to obtain an estimate of L ( z k , λ ∗ ) near x ∗ . By using Taylor’s theorem expression ( 2 . 6 ) and continuity of the Hessians ∇ 2 f and ∇ 2 c i , i ∈ E ∪ I , we obtain L ( z k , λ ∗ ) (cid:3) L ( x ∗ , λ ∗ ) + ( z k − x ∗ ) T ∇ x L ( x ∗ , λ ∗ ) ( 12 . 62 ) + 12 ( z k − x ∗ ) T ∇ 2 xx L ( x ∗ , λ ∗ ) ( z k − x ∗ ) + o ( (cid:8) z k − x ∗ (cid:8) 2 ) . 1 2 . 5 . S E C O N D - O R D E R C O N D I T I O N S 333 By the complementarity conditions ( 12 . 34e ) , we have L ( x ∗ , λ ∗ ) (cid:3) f ( x ∗ ) . From ( 12 . 34a ) , the second term on the right - hand side is zero . Hence , using ( 12 . 59 ) , we can rewrite ( 12 . 62 ) as L ( z k , λ ∗ ) (cid:3) f ( x ∗ ) + 12 t 2 k w T ∇ 2 xx L ( x ∗ , λ ∗ ) + o ( t 2 k ) . ( 12 . 63 ) By substituting into ( 12 . 63 ) , we obtain f ( z k ) (cid:3) f ( x ∗ ) + 12 t 2 k w T ∇ 2 xx L ( x ∗ , λ ∗ ) w + o ( t 2 k ) . ( 12 . 64 ) If w T ∇ 2 xx L ( x ∗ , λ ∗ ) w < 0 , then ( 12 . 64 ) would imply that f ( z k ) < f ( x ∗ ) for all k sufﬁciently large , contradicting the fact that x ∗ is a local solution . Hence , the condition ( 12 . 57 ) must hold , as claimed . (cid:1) Sufﬁcient conditions are conditions on f and c i , i ∈ E ∪ I , that ensure that x ∗ is a local solution of the problem ( 12 . 1 ) . ( They take the opposite tack to necessary conditions , which assume that x ∗ is a local solution and deduce properties of f and c i , for the active indices i . ) The second - order sufﬁcient condition stated in the next theorem looks very much like the necessary condition just discussed , but it differs in that the constraint qualiﬁcation is not required , and the inequality in ( 12 . 57 ) is replaced by a strict inequality . Theorem 12 . 6 ( Second - Order Sufﬁcient Conditions ) . Suppose that for some feasible point x ∗ ∈ IR n there is a Lagrange multiplier vector λ ∗ such that the KKT conditions ( 12 . 34 ) are satisﬁed . Suppose also that w T ∇ 2 xx L ( x ∗ , λ ∗ ) w > 0 , for all w ∈ C ( x ∗ , λ ∗ ) , w (cid:9)(cid:3) 0 . ( 12 . 65 ) Then x ∗ is a strict local solution for ( 12 . 1 ) . P ROOF . First , note that the set ¯ C (cid:3) { d ∈ C ( x ∗ , λ ∗ ) | (cid:8) d (cid:8) (cid:3) 1 } is a compact subset of C ( x ∗ , λ ∗ ) , so by ( 12 . 65 ) , the minimizer of d T ∇ 2 xx L ( x ∗ , λ ∗ ) d over this set is a strictly positive number , say σ . Since C ( x ∗ , λ ∗ ) is a cone , we have that ( w / (cid:8) w (cid:8) ) ∈ ¯ C if and only if w ∈ C ( x ∗ , λ ∗ ) , w (cid:9)(cid:3) 0 . Therefore , condition ( 12 . 65 ) by w T ∇ 2 xx L ( x ∗ , λ ∗ ) w ≥ σ (cid:8) w (cid:8) 2 , for all w ∈ C ( x ∗ , λ ∗ ) , ( 12 . 66 ) for σ > 0 deﬁned as above . ( Note that this inequality holds trivially for w (cid:3) 0 . ) We prove the result by showing that every feasible sequence { z k } approaching x ∗ has f ( z k ) ≥ f ( x ∗ ) + ( σ / 4 ) (cid:8) z k − x ∗ (cid:8) 2 , for all k sufﬁciently large . Suppose for contradiction that this is not the case , and that there is a sequence { z k } approaching x ∗ with f ( z k ) < f ( x ∗ ) + ( σ / 4 ) (cid:8) z k − x ∗ (cid:8) 2 , for all k sufﬁciently large . ( 12 . 67 ) 334 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N By taking a subsequence if necessary , we can identify a limiting direction d such that lim k →∞ z k − x ∗ (cid:8) z k − x ∗ (cid:8) (cid:3) d . ( 12 . 68 ) We have from Lemma 12 . 2 ( i ) and Deﬁnition 12 . 3 that d ∈ F ( x ∗ ) . From ( 12 . 33 ) and the facts that λ ∗ i ≥ 0 and c i ( z k ) ≥ 0 for i ∈ I and c i ( z k ) (cid:3) 0 for i ∈ E , we have that L ( z k , λ ∗ ) (cid:3) f ( z k ) − (cid:3) i ∈ A ( x ∗ ) λ ∗ i c i ( z k ) ≤ f ( z k ) , ( 12 . 69 ) while the Taylor series approximation ( 12 . 63 ) from the proof of Theorem 12 . 5 continues to hold . If d were not in C ( x ∗ , λ ∗ ) , we could identify some index j ∈ A ( x ∗ ) ∩ I such that the strict positivity condition λ ∗ j ∇ c j ( x ∗ ) T d > 0 ( 12 . 70 ) is satisﬁed , while for the remaining indices i ∈ A ( x ∗ ) , we have λ ∗ i ∇ c i ( x ∗ ) T d ≥ 0 . From Taylor’s theorem and ( 12 . 68 ) , we have for this particular value of j that λ ∗ j c j ( z k ) (cid:3) λ ∗ j c j ( x ∗ ) + λ ∗ j ∇ c j ( x ∗ ) T ( z k − x ∗ ) + o ( (cid:8) z k − x ∗ (cid:8) ) (cid:3) (cid:8) z k − x ∗ (cid:8) λ ∗ j ∇ c j ( x ∗ ) T d + o ( (cid:8) z k − x ∗ (cid:8) ) . Hence , from ( 12 . 69 ) , we have that L ( z k , λ ∗ ) (cid:3) f ( z k ) − (cid:3) i ∈ A ( x ∗ ) λ ∗ i c i ( z k ) ≤ f ( z k ) − λ ∗ j c j ( z k ) ≤ f ( z k ) − (cid:8) z k − x ∗ (cid:8) λ ∗ j ∇ c j ( x ∗ ) T d + o ( (cid:8) z k − x ∗ (cid:8) ) . ( 12 . 71 ) From the Taylor series estimate ( 12 . 63 ) , we have meanwhile that L ( z k , λ ∗ ) (cid:3) f ( x ∗ ) + O ( (cid:8) z k − x ∗ (cid:8) 2 ) , and by combining with ( 12 . 71 ) , we obtain f ( z k ) ≥ f ( x ∗ ) + (cid:8) z k − x ∗ (cid:8) λ ∗ j ∇ c j ( x ∗ ) T d + o ( (cid:8) z k − x ∗ (cid:8) ) . 1 2 . 5 . S E C O N D - O R D E R C O N D I T I O N S 335 Because of ( 12 . 70 ) , this inequality is incompatible with ( 12 . 67 ) . We conclude that d ∈ C ( x ∗ , λ ∗ ) , and hence d T ∇ 2 xx L ( x ∗ , λ ∗ ) d ≥ σ . By combining the Taylor series estimate ( 12 . 63 ) with ( 12 . 69 ) and using ( 12 . 68 ) , we obtain f ( z k ) ≥ f ( x ∗ ) + 12 ( z k − x ∗ ) T ∇ 2 xx L ( x ∗ , λ ∗ ) ( z k − x ∗ ) + o ( (cid:8) z k − x ∗ (cid:8) 2 ) (cid:3) f ( x ∗ ) + 12 d T ∇ 2 xx L ( x ∗ , λ ∗ ) d (cid:8) z k − x ∗ (cid:8) 2 + o ( (cid:8) z k − x ∗ (cid:8) 2 ) ≥ f ( x ∗ ) + ( σ / 2 ) (cid:8) z k − x ∗ (cid:8) 2 + o ( (cid:8) z k − x ∗ (cid:8) 2 ) . This inequality yields the contradiction to ( 12 . 67 ) . We conclude that every feasible sequence { z k } approaching x ∗ must satisfy f ( z k ) ≥ f ( x ∗ ) + ( σ / 4 ) (cid:8) z k − x ∗ (cid:8) 2 , for all k sufﬁciently large , so x ∗ is a strict local solution . (cid:1) ❏ E XAMPLE 12 . 8 ( E XAMPLE 12 . 2 , O NE M ORE T IME ) We now return to Example 12 . 2 to check the second - order conditions for problem ( 12 . 18 ) . In this problem we have f ( x ) (cid:3) x 1 + x 2 , c 1 ( x ) (cid:3) 2 − x 21 − x 22 , E (cid:3) ∅ , and I (cid:3) { 1 } . The Lagrangian is L ( x , λ ) (cid:3) ( x 1 + x 2 ) − λ 1 ( 2 − x 21 − x 22 ) , and it is easy to show that the KKT conditions ( 12 . 34 ) are satisﬁed by x ∗ (cid:3) ( − 1 , − 1 ) T , with λ ∗ 1 (cid:3) 12 . The Lagrangian Hessian at this point is ∇ 2 xx L ( x ∗ , λ ∗ ) (cid:3) (cid:1) 2 λ ∗ 1 0 0 2 λ ∗ 1 (cid:2) (cid:3) (cid:1) 1 0 0 1 (cid:2) . This matrix is positive deﬁnite , so it certainly satisﬁes the conditions of Theorem 12 . 6 . We conclude that x ∗ (cid:3) ( − 1 , − 1 ) T is a strict local solution for ( 12 . 18 ) . ( In fact , it is the global solution of this problem , since , as we note later , this problem is a convex programming problem . ) ❐ ❏ E XAMPLE 12 . 9 For a more complex example , consider the problem min − 0 . 1 ( x 1 − 4 ) 2 + x 22 s . t . x 21 + x 22 − 1 ≥ 0 , ( 12 . 72 ) 336 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N in which we seek to minimize a nonconvex function over the exterior of the unit circle . Obviously , the objective function is not bounded below on the feasible region , since we can take the feasible sequence (cid:1) 10 0 (cid:2) , (cid:1) 20 0 (cid:2) , (cid:1) 30 0 (cid:2) , (cid:1) 40 0 (cid:2) , and note that f ( x ) approaches −∞ along this sequence . Therefore , no global solution exists , but it may still be possible to identify a strict local solution on the boundary of the constraint . We search for such a solution by using the KKT conditions ( 12 . 34 ) and the second - order conditions of Theorem 12 . 6 . By deﬁning the Lagrangian for ( 12 . 72 ) in the usual way , it is easy to verify that ∇ x L ( x , λ ) (cid:3) (cid:1) − 0 . 2 ( x 1 − 4 ) − 2 λ 1 x 1 2 x 2 − 2 λ 1 x 2 (cid:2) , ( 12 . 73a ) ∇ 2 xx L ( x , λ ) (cid:3) (cid:1) − 0 . 2 − 2 λ 1 0 0 2 − 2 λ 1 (cid:2) . ( 12 . 73b ) The point x ∗ (cid:3) ( 1 , 0 ) T satisﬁes the KKT conditions with λ ∗ 1 (cid:3) 0 . 3 and the active set A ( x ∗ ) (cid:3) { 1 } . To check that the second - order sufﬁcient conditions are satisﬁed at this point , we note that ∇ c 1 ( x ∗ ) (cid:3) (cid:1) 2 0 (cid:2) , so that the set C deﬁned in ( 12 . 53 ) is simply C ( x ∗ , λ ∗ ) (cid:3) { ( 0 , w 2 ) T | w 2 ∈ IR } . Now , by substituting x ∗ and λ ∗ into ( 12 . 73b ) , we have for any w ∈ C ( x ∗ , λ ∗ ) with w (cid:9)(cid:3) 0 that w 2 (cid:9)(cid:3) 0 and thus w T ∇ 2 xx L ( x ∗ , λ ∗ ) w (cid:3) (cid:1) 0 w 2 (cid:2) T (cid:1) − 0 . 4 0 0 1 . 4 (cid:2) (cid:1) 0 w 2 (cid:2) (cid:3) 1 . 4 w 2 2 > 0 . Hence , the second - order sufﬁcient conditions are satisﬁed , and we conclude from Theorem 12 . 6 that ( 1 , 0 ) T is a strict local solution for ( 12 . 72 ) . ❐ 1 2 . 5 . S E C O N D - O R D E R C O N D I T I O N S 337 SECOND - ORDER CONDITIONS AND PROJECTED HESSIANS The second - order conditions are sometimes stated in a form that is slightly weaker but easier to verify than ( 12 . 57 ) and ( 12 . 65 ) . This form uses a two - sided projection of the Lagrangian Hessian ∇ 2 xx L ( x ∗ , λ ∗ ) onto subspaces that are related to C ( x ∗ , λ ∗ ) . The simplest case is obtained when the multiplier λ ∗ that satisﬁes the KKT conditions ( 12 . 34 ) is unique ( as happens , for example , when the LICQ condition holds ) and strict complementarity holds . In this case , the deﬁnition ( 12 . 53 ) of C ( x ∗ , λ ∗ ) reduces to C ( x ∗ , λ ∗ ) (cid:3) Null (cid:9) ∇ c i ( x ∗ ) T (cid:10) i ∈ A ( x ∗ ) (cid:3) Null A ( x ∗ ) , where A ( x ∗ ) is deﬁned as in ( 12 . 37 ) . In other words , C ( x ∗ , λ ∗ ) is the null space of the matrix whose rows are the active constraint gradients at x ∗ . As in ( 12 . 39 ) , we can deﬁne the matrix Z with full column rank whose columns span the space C ( x ∗ , λ ∗ ) ; that is , C ( x ∗ , λ ∗ ) (cid:3) { Zu | u ∈ IR | A ( x ∗ ) | } . Hence , the condition ( 12 . 57 ) in Theorem 12 . 5 can be restated as u T Z T ∇ 2 xx L ( x ∗ , λ ∗ ) Zu ≥ 0 for all u , or , more succinctly , Z T ∇ 2 xx L ( x ∗ , λ ∗ ) Z is positive semideﬁnite . Similarly , the condition ( 12 . 65 ) in Theorem 12 . 6 can be restated as Z T ∇ 2 xx L ( x ∗ , λ ∗ ) Z is positive deﬁnite . As we show next , Z can be computed numerically , so that the positive ( semi ) deﬁniteness conditions can actually be checked by forming these matrices and ﬁnding their eigenvalues . One way to compute the matrix Z is to apply a QR factorization to the matrix of active constraint gradients whose null space we seek . In the simplest case above ( in which the multiplier λ ∗ is unique and strictly complementary holds ) , we deﬁne A ( x ∗ ) as in ( 12 . 37 ) and write the QR factorization of its transpose as A ( x ∗ ) T (cid:3) Q (cid:1) R 0 (cid:2) (cid:3) (cid:9) Q 1 Q 2 (cid:10) (cid:1) R 0 (cid:2) (cid:3) Q 1 R , ( 12 . 74 ) where R is a square upper triangular matrix and Q is n × n orthogonal . If R is nonsingular , we can set Z (cid:3) Q 2 . If R is singular ( indicating that the active constraint gradients are linearly dependent ) , a slight enhancement of this procedure that makes use of column pivoting during the QR procedure can be used to identify Z . 338 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N 12 . 6 OTHER CONSTRAINT QUALIFICATIONS We now reconsider constraint qualiﬁcations , the conditions discussed in Sections 12 . 2 and 12 . 4 that ensure that the linearized approximation to the feasible set (cid:22) captures the essential shape of (cid:22) in a neighborhood of x ∗ . One situation in which the linearized feasible direction set F ( x ∗ ) is obviously an adequate representation of the actual feasible set occurs when all the active constraints are already linear ; that is , c i ( x ) (cid:3) a Ti x + b i , ( 12 . 75 ) for some a i ∈ IR n and b i ∈ IR . It is not difﬁcult to prove a version of Lemma 12 . 2 for this situation . Lemma 12 . 7 . Suppose that at some x ∗ ∈ (cid:22) , all active constraints c i ( · ) , i ∈ A ( x ∗ ) , are linear functions . Then F ( x ∗ ) (cid:3) T (cid:22) ( x ∗ ) . P ROOF . WehavefromLemma12 . 2 ( i ) that T (cid:22) ( x ∗ ) ⊂ F ( x ∗ ) . Toprovethat F ( x ∗ ) ⊂ T (cid:22) ( x ∗ ) , we choose an arbitrary w ∈ F ( x ∗ ) and show that w ∈ T (cid:22) ( x ∗ ) . By Deﬁnition 12 . 3 and the form ( 12 . 75 ) of the constraints , we have F ( x ∗ ) (cid:3) (cid:21) d (cid:28)(cid:28) a Ti d (cid:3) 0 , for all i ∈ E , a Ti d ≥ 0 , for all i ∈ A ( x ) ∩ I (cid:22) . First , note that there is a positive scalar ¯ t such that the inactive constraint remain inactive at x ∗ + t w , for all t ∈ [ 0 , ¯ t ] , that is , c i ( x ∗ + t w ) > 0 , for all i ∈ I \ A ( x ∗ ) and all t ∈ [ 0 , ¯ t ] . Now deﬁne the sequence z k by z k (cid:3) x ∗ + ( ¯ t / k ) w , k (cid:3) 1 , 2 , . . . . Since a T i w ≥ 0 for all i ∈ I ∩ A ( x ∗ ) , we have c i ( z k ) (cid:3) c i ( z k ) − c i ( x ∗ ) (cid:3) a Ti ( z k − x ∗ ) (cid:3) ¯ t k a Ti w ≥ 0 , for all i ∈ I ∩ A ( x ∗ ) , so that z k is feasible with respect to the active inequality constraints c i , i ∈ I ∩ A ( x ∗ ) . By the choice of ¯ t , we ﬁnd that z k is also feasible with respect to the inactive inequality constraints 1 2 . 6 . O T H E R C O N S T R A I N T Q U A L I F I C A T I O N S 339 i ∈ I \ A ( x ∗ ) , and it is easy to show that c i ( z k ) (cid:3) 0 for the equality constraints i ∈ E . Hence , z k is feasible for each k (cid:3) 1 , 2 , . . . . In addition , we have that z k − x ∗ ( ¯ t / k ) (cid:3) ( ¯ t / k ) w ( ¯ t / k ) (cid:3) w , so that indeed w is the limiting direction of { z k } . Hence , w ∈ T (cid:22) ( x ∗ ) , and the proof is complete . (cid:1) We conclude from this result that the condition that all active constraints be linear is another possible constraint qualiﬁcation . It is neither weaker nor stronger than the LICQ condition , that is , there are situations in which one condition is satisﬁed but not the other ( see Exercise 12 . 12 ) . Another useful generalization of the LICQ is the Mangasarian – Fromovitz constraint qualiﬁcation ( MFCQ ) . Deﬁnition 12 . 6 ( MFCQ ) . We say that the Mangasarian – Fromovitz constraint qualiﬁcation ( MFCQ ) holds if there exists a vector w ∈ IR n such that ∇ c i ( x ∗ ) T w > 0 , for all i ∈ A ( x ∗ ) ∩ I , ∇ c i ( x ∗ ) T w (cid:3) 0 , for all i ∈ E , and the set of equality constraint gradients { ∇ c i ( x ∗ ) , i ∈ E } is linearly independent . Note the strict inequality involving the active inequality constraints . The MFCQ is a weaker condition than LICQ . If LICQ is satisﬁed , then the system of equalities deﬁned by ∇ c i ( x ∗ ) T w (cid:3) 1 , for all i ∈ A ( x ∗ ) ∩ I , ∇ c i ( x ∗ ) T w (cid:3) 0 , for all i ∈ E , has a solution w , by full rank of the active constraint gradients . Hence , we can choose the w of Deﬁnition 12 . 6 to be precisely this vector . On the other hand , it is easy to construct examples in which the MFCQ is satisﬁed but the LICQ is not ; see Exercise 12 . 13 . It is possible to prove a version of the ﬁrst - order necessary condition result ( Theo - rem 12 . 1 ) in which MFCQ replaces LICQ in the assumptions . MFCQ gives rise to the nice property that it is equivalent to boundedness of the set of Lagrange multiplier vectors λ ∗ for which the KKT conditions ( 12 . 34 ) are satisﬁed . ( In the case of LICQ , this set consists of a unique vector λ ∗ , and so is trivially bounded . ) Note that constraint qualiﬁcations are sufﬁcient conditions for the linear approxima - tion to be adequate , not necessary conditions . For instance , consider the set deﬁned by x 2 ≥ − x 21 and x 2 ≤ x 21 and the feasible point x ∗ (cid:3) ( 0 , 0 ) T . None of the constraint qualiﬁcations 340 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N we have discussed are satisﬁed , but the linear approximation F ( x ∗ ) (cid:3) { ( w 1 , 0 ) T | w 1 ∈ IR } accurately reﬂects the geometry of the feasible set near x ∗ . 12 . 7 A GEOMETRIC VIEWPOINT Finally , we mention an alternative ﬁrst - order optimality condition that depends only on the geometry of the feasible set (cid:22) and not on its particular algebraic description in terms of the constraint functions c i , i ∈ E ∪ I . In geometric terms , our problem ( 12 . 1 ) can be stated as min f ( x ) subject to x ∈ (cid:22) , ( 12 . 76 ) where (cid:22) is the feasible set . To prove a “geometric” ﬁrst - order condition , we need to deﬁne the normal cone to the set (cid:22) at a feasible point x . Deﬁnition 12 . 7 . The normal cone to the set (cid:22) at the point x ∈ (cid:22) is deﬁned as N (cid:22) ( x ) (cid:3) { v | v T w ≤ 0 for all w ∈ T (cid:22) ( x ) } , ( 12 . 77 ) where T (cid:22) ( x ) is the tangent cone of Deﬁnition 12 . 2 . Each vector v ∈ N (cid:22) ( x ) is said to be a normal vector . Geometrically , each normal vector v makes an angle of at least π / 2 with every tangent vector . The ﬁrst - order necessary condition for ( 12 . 76 ) is delightfully simple . Theorem 12 . 8 . Suppose that x ∗ is a local minimizer of f in (cid:22) . Then − ∇ f ( x ∗ ) ∈ N (cid:22) ( x ∗ ) . ( 12 . 78 ) P ROOF . Given any d ∈ T (cid:22) ( x ∗ ) , we have for the sequences { t k } and { z k } in Deﬁnition 12 . 2 that z k ∈ (cid:22) , z k (cid:3) x ∗ + t k d + o ( t k ) , for all k . ( 12 . 79 ) Since x ∗ is a local solution , we must have f ( z k ) ≥ f ( x ∗ ) 1 2 . 8 . L A G R A N G E M U L T I P L I E R S A N D S E N S I T I V I T Y 341 for all k sufﬁciently large . Hence , since f is continuously differentiable , we have from Taylor’s theorem ( 2 . 4 ) that f ( z k ) − f ( x ∗ ) (cid:3) t k ∇ f ( x ∗ ) T d + o ( t k ) ≥ 0 . By dividing by t k and taking limits as k → ∞ , we have ∇ f ( x ∗ ) T d ≥ 0 . Recall that d was an arbitrary member of T (cid:22) ( x ∗ ) , so we have −∇ f ( x ∗ ) T d ≤ 0 for all d ∈ T (cid:22) ( x ∗ ) . We conclude from Deﬁnition 12 . 7 that −∇ f ( x ∗ ) ∈ N (cid:22) ( x ∗ ) . (cid:1) This result suggests a close relationship between N (cid:22) ( x ∗ ) and the conic combination of active constraint gradients given by ( 12 . 50 ) . When the linear independence constraint qualiﬁcation holds , identical ( to within a change of sign ) . Lemma 12 . 9 . Suppose that the LICQ assumption ( Deﬁnition 12 . 4 ) holds at x ∗ . Then t the normal cone N (cid:22) ( x ∗ ) is simply − N , where N is the set deﬁned in ( 12 . 50 ) . P ROOF . The proof follows from Farkas’ Lemma ( Lemma 12 . 4 ) and Deﬁnition 12 . 7 of N (cid:22) ( x ∗ ) . From Lemma 12 . 4 , we have that g ∈ N ⇒ g T d ≥ 0 for all d ∈ F ( x ∗ ) . Since we have F ( x ∗ ) (cid:3) T (cid:22) ( x ∗ ) from Lemma 12 . 2 , it follows by switching the sign of this expression that g ∈ − N ⇒ g T d ≤ 0 for all d ∈ T (cid:22) ( x ∗ ) . We conclude from Deﬁnition 12 . 7 that N (cid:22) ( x ∗ ) (cid:3) − N , as claimed . (cid:1) 12 . 8 LAGRANGE MULTIPLIERS AND SENSITIVITY The importance of Lagrange multipliers in optimality theory should be clear , but what of their intuitive signiﬁcance ? We show in this section that each Lagrange multiplier λ ∗ i tells us something about the sensitivity of the optimal objective value f ( x ∗ ) to the presence of the constraint c i . To put it another way , λ ∗ i indicates how hard f is “pushing” or “pulling” the solution x ∗ against the particular constraint c i . We illustrate this point with some informal analysis . When we choose an inactive constraint i / ∈ A ( x ∗ ) such that c i ( x ∗ ) > 0 , the solution x ∗ and function value f ( x ∗ ) are 342 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N indifferent to whether this constraint is present or not . If we perturb c i by a tiny amount , it will still be inactive and x ∗ will still be a local solution of the optimization problem . Since λ ∗ i (cid:3) 0 from ( 12 . 34e ) , the Lagrange multiplier indicates accurately that constraint i is not signiﬁcant . Supposeinsteadthatconstraint i isactive , andletusperturbtheright - hand - sideofthis constraint a little , requiring , say , that c i ( x ) ≥ − (cid:9) (cid:8)∇ c i ( x ∗ ) (cid:8) instead of c i ( x ) ≥ 0 . Suppose that (cid:9) is sufﬁciently small that the perturbed solution x ∗ ( (cid:9) ) still has the same set of active constraints , and that the Lagrange multipliers are not much affected by the perturbation . ( These conditions can be made more rigorous with the help of strict complementarity and second - order conditions . ) We then ﬁnd that − (cid:9) (cid:8)∇ c i ( x ∗ ) (cid:8) (cid:3) c i ( x ∗ ( (cid:9) ) ) − c i ( x ∗ ) ≈ ( x ∗ ( (cid:9) ) − x ∗ ) T ∇ c i ( x ∗ ) , 0 (cid:3) c j ( x ∗ ( (cid:9) ) ) − c j ( x ∗ ) ≈ ( x ∗ ( (cid:9) ) − x ∗ ) T ∇ c j ( x ∗ ) , for all j ∈ A ( x ∗ ) with j (cid:9)(cid:3) i . The value of f ( x ∗ ( (cid:9) ) ) , meanwhile , can be estimated with the help of ( 12 . 34a ) . We have f ( x ∗ ( (cid:9) ) ) − f ( x ∗ ) ≈ ( x ∗ ( (cid:9) ) − x ∗ ) T ∇ f ( x ∗ ) (cid:3) (cid:3) j ∈ A ( x ∗ ) λ ∗ j ( x ∗ ( (cid:9) ) − x ∗ ) T ∇ c j ( x ∗ ) ≈ − (cid:9) (cid:8)∇ c i ( x ∗ ) (cid:8) λ ∗ i . By taking limits , we see that the family of solutions x ∗ ( (cid:9) ) satisﬁes d f ( x ∗ ( (cid:9) ) ) d (cid:9) (cid:3) − λ ∗ i (cid:8)∇ c i ( x ∗ ) (cid:8) . ( 12 . 80 ) A sensitivity analysis of this problem would conclude that if λ ∗ i (cid:8)∇ c i ( x ∗ ) (cid:8) is large , then the optimal value is sensitive to the placement of the i th constraint , while if this quantity is small , the dependence is not too strong . If λ ∗ i is exactly zero for some active constraint , small perturbations to c i in some directions will hardly affect the optimal objective value at all ; the change is zero , to ﬁrst order . This discussion motivates the deﬁnition below , which classiﬁes constraints according to whether or not their corresponding Lagrange multiplier is zero . Deﬁnition 12 . 8 . Let x ∗ be a solution of the problem ( 12 . 1 ) , and suppose that the KKT conditions ( 12 . 34 ) are satisﬁed . We say that an inequality constraint c i is strongly active or binding if i ∈ A ( x ∗ ) and λ ∗ i > 0 for some Lagrange multiplier λ ∗ satisfying ( 12 . 34 ) . We say that c i is weakly active if i ∈ A ( x ∗ ) and λ ∗ i (cid:3) 0 for all λ ∗ satisfying ( 12 . 34 ) . Note that the analysis above is independent of scaling of the individual constraints . For instance , we might change the formulation of the problem by replacing some active 1 2 . 9 . D U A L I T Y 343 constraint c i by 10 c i . The new problem will actually be equivalent ( that is , it has the same feasible set and same solution ) , but the optimal multiplier λ ∗ i corresponding to c i will be replaced by λ ∗ i / 10 . However , since (cid:8)∇ c i ( x ∗ ) (cid:8) is replaced by 10 (cid:8)∇ c i ( x ∗ ) (cid:8) , the product λ ∗ i (cid:8)∇ c i ( x ∗ ) (cid:8) does not change . If , on the other hand , we replace the objective function f by 10 f , the multipliers λ ∗ i in ( 12 . 34 ) all will need to be replaced by 10 λ ∗ i . Hence in ( 12 . 80 ) we see that the sensitivity of f to perturbations has increased by a factor of 10 , which is exactly what we would expect . 12 . 9 DUALITY In this section we present some elements of the duality theory for nonlinear program - ming . This theory is used to motivate and develop some important algorithms , including the augmented Lagrangian algorithms of Chapter 17 . In its full generality , duality theory ranges beyond nonlinear programming to provide important insight into the ﬁelds of con - vex nonsmooth optimization and even discrete optimization . Its specialization to linear programming proved central to the development of that area ; see Chapter 13 . ( We note that the discussion of linear programming duality in Section 13 . 1 can be read without consulting this section ﬁrst . ) Duality theory shows how we can construct an alternative problem from the functions and data that deﬁne the original optimization problem . This alternative “dual” problem is related to the original problem ( which is sometimes referred to in this context as the “primal” for purposes of contrast ) in fascinating ways . In some cases , the dual problem is easier to solve computationally than the original problem . In other cases , the dual can be used to obtain easily a lower bound on the optimal value of the objective for the primal problem . As remarked above , the dual has also been used to design algorithms for solving the primal problem . Our results in this section are mostly restricted to the special case of ( 12 . 1 ) in which there are no equality constraints and the objective f and the negatives of the inequality constraints − c i are all convex functions . For simplicity we assume that there are m inequality constraints labelled 1 , 2 , . . . , m and rewrite ( 12 . 1 ) as follows : min x ∈ IR n f ( x ) subject to c i ( x ) ≥ 0 , i (cid:3) 1 , 2 , . . . , m . If we assemble the constraints into a vector function c ( x ) def (cid:3) ( c 1 ( x ) , c 2 ( x ) , . . . , c m ( x ) ) T , we can write the problem as min x ∈ IR n f ( x ) subject to c ( x ) ≥ 0 , ( 12 . 81 ) 344 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N for which the Lagrangian function ( 12 . 16 ) with Lagrange multiplier vector λ ∈ IR m is L ( x , λ ) (cid:3) f ( x ) − λ T c ( x ) . We deﬁne the dual objective function q : IR n → IR as follows : q ( λ ) def (cid:3) inf x L ( x , λ ) . ( 12 . 82 ) In many problems , this inﬁmum is −∞ for some values of λ . We deﬁne the domain of q as the set of λ values for which q is ﬁnite , that is , D def (cid:3) { λ | q ( λ ) > −∞ } . ( 12 . 83 ) Note that calculation of the inﬁmum in ( 12 . 82 ) requires ﬁnding the global minimizer of the function L ( · , λ ) for the given λ which , as we have noted in Chapter 2 , may be extremely difﬁcult in practice . However , when f and − c i are convex functions and λ ≥ 0 ( the case in which we are most interested ) , the function L ( · , λ ) is also convex . In this situation , all local minimizers are global minimizers ( as we verify in Exercise 12 . 4 ) , so computation of q ( λ ) becomes a more practical proposition . The dual problem to ( 12 . 81 ) is deﬁned as follows : max λ ∈ IR n q ( λ ) subject to λ ≥ 0 . ( 12 . 84 ) ❏ E XAMPLE 12 . 10 Consider the problem min ( x 1 , x 2 ) 0 . 5 ( x 2 1 + x 2 2 ) subject to x 1 − 1 ≥ 0 . ( 12 . 85 ) The Lagrangian is L ( x 1 , x 2 , λ 1 ) (cid:3) 0 . 5 ( x 2 1 + x 2 2 ) − λ 1 ( x 1 − 1 ) . If we hold λ 1 ﬁxed , this is a convex function of ( x 1 , x 2 ) T . Therefore , the inﬁmum with respect to ( x 1 , x 2 ) T is achieved when the partial derivatives with respect to x 1 and x 2 are zero , that is , x 1 − λ 1 (cid:3) 0 , x 2 (cid:3) 0 . 1 2 . 9 . D U A L I T Y 345 By substituting these inﬁmal values into L ( x 1 , x 2 , λ 1 ) we obtain the dual objective ( 12 . 82 ) : q ( λ 1 ) (cid:3) 0 . 5 ( λ 21 + 0 ) − λ 1 ( λ 1 − 1 ) (cid:3) − 0 . 5 λ 21 + λ 1 . Hence , the dual problem ( 12 . 84 ) is max λ 1 ≥ 0 − 0 . 5 λ 2 1 + λ 1 , ( 12 . 86 ) which clearly has the solution λ 1 (cid:3) 1 . ❐ In the remainder of this section , we show how the dual problem is related to ( 12 . 81 ) . Our ﬁrst result concerns concavity of q . Theorem 12 . 10 . The function q deﬁned by ( 12 . 82 ) is concave and its domain D is convex . P ROOF . For any λ 0 and λ 1 in IR m , any x ∈ IR n , and any α ∈ [ 0 , 1 ] , we have L ( x , ( 1 − α ) λ 0 + αλ 1 ) (cid:3) ( 1 − α ) L ( x , λ 0 ) + α L ( x , λ 1 ) . By taking the inﬁmum of both sides in this expression , using the deﬁnition ( 12 . 82 ) , and using the results that the inﬁmum of a sum is greater than or equal to the sum of inﬁmums , we obtain q ( ( 1 − α ) λ 0 + αλ 1 ) ≥ ( 1 − α ) q ( λ 0 ) + α q ( λ 1 ) , conﬁrming concavity of q . If both λ 0 and λ 1 belong to D , this inequality implies that q ( ( 1 − α ) λ 0 + αλ 1 ) ≥ −∞ also , and therefore ( 1 − α ) λ 0 + αλ 1 ∈ D , verifying convexity of D . (cid:1) The optimal value of the dual problem ( 12 . 84 ) gives a lower bound on the optimal objective value for the primal problem ( 12 . 81 ) . This observation is a consequence of the following weak duality result . Theorem 12 . 11 ( Weak Duality ) . For any ¯ x feasible for ( 12 . 81 ) and any ¯ λ ≥ 0 , we have q ( ¯ λ ) ≤ f ( ¯ x ) . P ROOF . q ( ¯ λ ) (cid:3) inf x f ( x ) − ¯ λ T c ( x ) ≤ f ( ¯ x ) − ¯ λ T c ( ¯ x ) ≤ f ( ¯ x ) , where the ﬁnal inequality follows from ¯ λ ≥ 0 and c ( ¯ x ) ≥ 0 . (cid:1) 346 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N For the remaining results , we note that the KKT conditions ( 12 . 34 ) specialized to ( 12 . 81 ) are as follows : ∇ f ( ¯ x ) − ∇ c ( ¯ x ) ¯ λ (cid:3) 0 , ( 12 . 87a ) c ( ¯ x ) ≥ 0 , ( 12 . 87b ) ¯ λ ≥ 0 , ( 12 . 87c ) ¯ λ i c i ( ¯ x ) (cid:3) 0 , i (cid:3) 1 , 2 , . . . , m , ( 12 . 87d ) where ∇ c ( x ) is the n × m matrix deﬁned by ∇ c ( x ) (cid:3) [ ∇ c 1 ( x ) , ∇ c 2 ( x ) , . . . , ∇ c m ( x ) ] . The next result shows that optimal Lagrange multipliers for ( 12 . 81 ) are solutions of the dual problem ( 12 . 84 ) under certain conditions . It is essentially due to Wolfe [ 309 ] . Theorem 12 . 12 . Suppose that ¯ x is a solution of ( 12 . 81 ) and that f and − c i , i (cid:3) 1 , 2 , . . . , m are convex functions on IR n that are differentiable at ¯ x . Then any ¯ λ for which ( ¯ x , ¯ λ ) satisﬁes the KKT conditions ( 12 . 87 ) is a solution of ( 12 . 84 ) . P ROOF . Suppose that ( ¯ x , ¯ λ ) satisﬁes ( 12 . 87 ) . We have from ¯ λ ≥ 0 that L ( · , ¯ λ ) is a convex and differentiable function . Hence , for any x , we have L ( x , ¯ λ ) ≥ L ( ¯ x , ¯ λ ) + ∇ x L ( ¯ x , ¯ λ ) T ( x − ¯ x ) (cid:3) L ( ¯ x , ¯ λ ) , where the last equality follows from ( 12 . 87a ) . Therefore , we have q ( ¯ λ ) (cid:3) inf x L ( x , ¯ λ ) (cid:3) L ( ¯ x , ¯ λ ) (cid:3) f ( ¯ x ) − ¯ λ T c ( ¯ x ) (cid:3) f ( ¯ x ) , where the last equality follows from ( 12 . 87d ) . Since from Theorem 12 . 11 , we have q ( λ ) ≤ f ( ¯ x ) for all λ ≥ 0 it follows immediately from q ( ¯ λ ) (cid:3) f ( ¯ x ) that ¯ λ is a solution of ( 12 . 84 ) . (cid:1) Note that if the functions are continuously differentiable and a constraint qualiﬁcation such as LICQ holds at ¯ x , then an optimal Lagrange multiplier is guaranteed to exist , by Theorem 12 . 1 . In Example 12 . 10 , we see that λ 1 (cid:3) 1 is both an optimal Lagrange multiplier for the problem ( 12 . 85 ) and a solution of ( 12 . 86 ) . Note too that the optimal objective for both problems is 0 . 5 . We prove a partial converse of Theorem 12 . 12 , which shows that solutions to the dual problem ( 12 . 84 ) can sometimes be used to derive solutions to the original problem ( 12 . 81 ) . The essential condition is strict convexity of the function L ( · , ˆ λ ) for a certain value ˆ λ . We note that this condition holds if either f is strictly convex ( as is the case in Example 12 . 10 ) or if c i is strictly convex for some i (cid:3) 1 , 2 , . . . , m with ˆ λ i > 0 . 1 2 . 9 . D U A L I T Y 347 Theorem 12 . 13 . Suppose that f and − c i , i (cid:3) 1 , 2 , . . . , m are convex and continuously differentiable on IR n . Suppose that ¯ x is a solution of ( 12 . 81 ) at which LICQ holds . Suppose that ˆ λ solves ( 12 . 84 ) and that the inﬁmum in inf x L ( x , ˆ λ ) is attained at ˆ x . Assume further than L ( · , ˆ λ ) is a strictly convex function . Then ¯ x (cid:3) ˆ x ( that is , ˆ x is the unique solution of ( 12 . 81 ) ) , and f ( ¯ x ) (cid:3) L ( ˆ x , ˆ λ ) . P ROOF . Assume for contradiction that ¯ x (cid:9)(cid:3) ˆ x . From Theorem 12 . 1 , because of the LICQ assumption , there exists ¯ λ satisfying ( 12 . 87 ) . Hence , from Theorem 12 . 12 , we have that ¯ λ also solves ( 12 . 84 ) , so that L ( ¯ x , ¯ λ ) (cid:3) q ( ¯ λ ) (cid:3) q ( ˆ λ ) (cid:3) L ( ˆ x , ˆ λ ) . Because ˆ x (cid:3) arg min x L ( x , ˆ λ ) , we have from Theorem 2 . 2 that ∇ x L ( ˆ x , ˆ λ ) (cid:3) 0 . Moreover , by strict convexity of L ( · , ˆ λ ) , it follows that L ( ¯ x , ˆ λ ) − L ( ˆ x , ˆ λ ) > ∇ x L ( ˆ x , ˆ λ ) T ( ¯ x − ˆ x ) (cid:3) 0 . Hence , we have L ( ¯ x , ˆ λ ) > L ( ˆ x , ˆ λ ) (cid:3) L ( ¯ x , ¯ λ ) , so in particular we have −ˆ λ T c ( ¯ x ) > −¯ λ T c ( ¯ x ) (cid:3) 0 , where the ﬁnal equality follows from ( 12 . 87d ) . Since ˆ λ ≥ 0 and c ( ¯ x ) ≥ 0 , this yields the contradiction , and we conclude that ˆ x (cid:3) ¯ x , as claimed . (cid:1) In Example 12 . 10 , at the dual solution λ 1 (cid:3) 1 , the inﬁmum of L ( x 1 , x 2 , λ 1 ) is achieved at ( x 1 , x 2 ) (cid:3) ( 1 , 0 ) T , which is the solution of the original problem ( 12 . 85 ) . An slightly different form of duality that is convenient for computations , known as the Wolfe dual [ 309 ] , can be stated as follows : max x , λ L ( x , λ ) ( 12 . 88a ) subject to ∇ x L ( x , λ ) (cid:3) 0 , λ ≥ 0 . ( 12 . 88b ) The following results explains the relationship of the Wolfe dual to ( 12 . 81 ) . Theorem 12 . 14 . Suppose that f and − c i , i (cid:3) 1 , 2 , . . . , m are convex and continuously differentiable on IR n . Suppose that ( ¯ x , ¯ λ ) is a solution pair of ( 12 . 81 ) at which LICQ holds . Then ( ¯ x , ¯ λ ) solves the problem ( 12 . 88 ) . 348 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N P ROOF . From the KKT conditions ( 12 . 87 ) we have that ( ¯ x , ¯ λ ) satisﬁes ( 12 . 88b ) , and that L ( ¯ x , ¯ λ ) (cid:3) f ( ¯ x ) . Therefore for any pair ( x , λ ) that satisﬁes ( 12 . 88b ) we have that L ( ¯ x , ¯ λ ) (cid:3) f ( ¯ x ) ≥ f ( ¯ x ) − λ T c ( ¯ x ) (cid:3) L ( ¯ x , λ ) ≥ L ( x , λ ) + ∇ x L ( x , λ ) T ( ¯ x − x ) (cid:3) L ( x , λ ) , where the second inequality follows from the convexity of L ( · , λ ) . We have therefore shown that ( ¯ x , ¯ λ ) maximizes L over the constraints ( 12 . 88b ) , and hence solves ( 12 . 88 ) . (cid:1) ❏ E XAMPLE 12 . 11 ( L INEAR P ROGRAMMING ) An important special case of ( 12 . 81 ) is the linear programming problem min c T x subject to Ax − b ≥ 0 , ( 12 . 89 ) for which the dual objective is q ( λ ) (cid:3) inf x (cid:9) c T x − λ T ( Ax − b ) (cid:10) (cid:3) inf x (cid:9) ( c − A T λ ) T x + b T λ (cid:10) . If c − A T λ (cid:9)(cid:3) 0 , the inﬁmum is clearly −∞ ( we can set x to be a large negative multiple of − ( c − A T λ ) to make q arbitrarily large and negative ) . When c − A T λ (cid:3) 0 , on the other hand , the dual objective is simply b T λ . In maximizing q , we can exclude λ for which c − A T λ (cid:9)(cid:3) 0 from consideration ( the maximum obviously cannot be attained at a point λ for which q ( λ ) (cid:3) −∞ ) . Hence , we can write the dual problem ( 12 . 84 ) as follows : max λ b T λ subject to A T λ (cid:3) c , λ ≥ 0 . ( 12 . 90 ) The Wolfe dual of ( 12 . 89 ) can be written as max λ c T x − λ T ( Ax − b ) subject to A T λ (cid:3) c , λ ≥ 0 , and by substituting the constraint A T λ − c (cid:3) 0 into the objective we obtain ( 12 . 90 ) again . For some matrices A , the dual problem ( 12 . 90 ) may be computationally easier to solve than the original problem ( 12 . 89 ) . We discuss the possibilities further in Chapter 13 . ❐ 1 2 . 9 . D U A L I T Y 349 ❏ E XAMPLE 12 . 12 ( C ONVEX Q UADRATIC P ROGRAMMING ) Consider min 1 2 x T Gx + c T x subject to Ax − b ≥ 0 , ( 12 . 91 ) where G is a symmetric positive deﬁnite matrix . The dual objective for this problem is q ( λ ) (cid:3) inf x L ( x , λ ) (cid:3) inf x 1 2 x T Gx + c T x − λ T ( Ax − b ) . ( 12 . 92 ) Since G is positive deﬁnite , since L ( · , λ ) is a strictly convex quadratic function , the inﬁmum is achieved when ∇ x L ( x , λ ) (cid:3) 0 , that is , Gx + c − A T λ (cid:3) 0 . ( 12 . 93 ) Hence , we can substitute for x in the inﬁmum expression and write the dual objective explicitly as follows : q ( λ ) (cid:3) − 1 2 ( A T λ − c ) T G − 1 ( A T λ − c ) T + b T λ . Alternatively , we can write the Wolfe dual form ( 12 . 88 ) by retaining x as a variable and including the constraint ( 12 . 93 ) explicitly in the dual problem , to obtain max ( λ , x ) 1 2 x T Gx + c T x − λ T ( Ax − b ) ( 12 . 94 ) subject to Gx + c − A T λ (cid:3) 0 , λ ≥ 0 . To make it clearer that the objective is concave , we can use the constraint to substitute ( c − A T λ ) T x (cid:3) − x T Gx in the objective , and rewrite the dual formulation as follows : max ( λ , x ) − 1 2 x T Gx + λ T b , subject to Gx + c − A T λ (cid:3) 0 , λ ≥ 0 . ( 12 . 95 ) ❐ Note that the Wolfe dual form requires only positive semideﬁniteness of G . NOTES AND REFERENCES The theory of constrained optimization is discussed in many books on numerical optimization . The discussion in Fletcher [ 101 , Chapter 9 ] is similar to ours , though a little 350 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N terser , and includes additional material on duality . Bertsekas [ 19 , Chapter 3 ] emphasizes the role of duality and discusses sensitivity of the solution with respect to the active constraints in some detail . The classic treatment of Mangasarian [ 198 ] is particularly notable for its thorough description of constraint qualiﬁcations . It also has an extensive discussion of theorems of the alternative [ 198 , Chapter 2 ] , placing Farkas’ Lemma ﬁrmly in the context of other related results . The KKT conditions were described in a 1951 paper of Kuhn and Tucker [ 185 ] , though they were derived earlier ( and independently ) in an unpublished 1939 master’s thesis of W . Karush . Lagrange multipliers and optimality conditions for general problems ( including nonsmooth problems ) are described in the deep and wide - ranging article of Rockafellar [ 270 ] . Duality theory for nonlinear programming is described in the books of Rockafel - lar [ 198 ] and Bertsekas [ 19 ] ; the latter treatment is particularly extensive and general . The material in Section 12 . 9 is adapted from these sources . We return to our claim that the set N deﬁned by N (cid:3) { By + Ct | y ≥ 0 } , ( where B and C are matrices of dimension n × m and n × p , respectively , and y and t are vectors of appropriate dimensions ; see ( 12 . 45 ) ) is a closed set . This fact is needed in the proof of Lemma 12 . 4 to ensure that the solution of the projection subproblem ( 12 . 47 ) is well - deﬁned . The following technical result is well known ; the proof given below is due to R . Byrd . Lemma 12 . 15 . The set N is closed . P ROOF . By splitting t into positive and negative parts , it is easy to see that N (cid:3) ⎧⎪⎨ ⎪⎩ (cid:9) B C − C (cid:10) ⎡ ⎢⎣ y t + t − ⎤ ⎥⎦ (cid:28)(cid:28)(cid:28)(cid:28)(cid:28)(cid:28)(cid:28) ⎡ ⎢⎣ y t + t − ⎤ ⎥⎦ ≥ 0 ⎫⎪⎬ ⎪⎭ . Hence , we can assume without loss of generality that N has the form N (cid:3) { By | y ≥ 0 } . Suppose that B has dimensions n × m . First , we show that for any s ∈ N , we can write s (cid:3) B I y I with y I ≥ 0 , where I ⊂ { 1 , 2 , . . . , m } , B I is the column submatrix of B indexed by I with full column rank , and I has minimum cardinality . To prove this claim , we assume for contradiction that K ⊂ { 1 , 2 , . . . , m } is an index set with minimal cardinality such that s (cid:3) B K y K , y K ≥ 0 , yet 1 2 . 9 . D U A L I T Y 351 the columns of B K are linearly dependent . Since K is minimal , y K has no zero components . We then have a nonzero vector w such that B K w (cid:3) 0 . Since s (cid:3) B K ( y K + τw ) for any τ , we can increase or decrease τ from 0 until one or more components of y K + τw become zero , while the other components remain positive . We deﬁne ¯ K by removing the indices from K that correspond to zero components of y K + τw , and deﬁne ¯ y ¯ K to be the vector of strictly positive components of y K + τw . We then have that s (cid:3) B ¯ K ¯ y ¯ K and ¯ y ¯ K ≥ 0 , contradicting our assumption that K was the set of minimal cardinality with this property . Now let { s k } be a sequence with s k ∈ N for all k and s k → s . We prove the lemma by showing that s ∈ N . By the claim of the previous paragraph , for all k we can write s k (cid:3) B I k y kI k with y kI k ≥ 0 , I k is minimal , and the columns of B I k are linearly independent . Since there only ﬁnitely many possible choices of index set I k , at least one index set occurs inﬁnitely often in the sequence . By choosing such an index set I , we can take a subsequence if necessary and assume without loss of generality that I k ≡ I for all k . We then have that s k (cid:3) A I y kI with y kI ≥ 0 and A I has full column rank . Because of the latter property , we have that A TI A I is invertible , so that y kI is deﬁned uniquely as follows : y kI (cid:3) ( A TI A I ) − 1 A TI s k , k (cid:3) 0 , 1 , 2 , . . . . By taking limits and using s k → s , we have that y kI → y I def (cid:3) ( A TI A I ) − 1 A TI s , and moreover y I ≥ 0 , since y kI ≥ 0 for all k . Hence we can write s (cid:3) B I y I with y I ≥ 0 , and therefore s ∈ N . (cid:1) ✐ E X E R C I S E S ✐ 12 . 1 The following example from [ 268 ] with a single variable x ∈ IR and a single equality constraint shows that strict local solutions are not necessarily isolated . Consider min x x 2 subject to c ( x ) (cid:3) 0 , where c ( x ) (cid:3) (cid:21) x 6 sin ( 1 / x ) (cid:3) 0 if x (cid:9)(cid:3) 0 0 if x (cid:3) 0 . ( 12 . 96 ) ( a ) Show that the constraint function is twice continuously differentiable at all x ( including at x (cid:3) 0 ) and that the feasible points are x (cid:3) 0 and x (cid:3) 1 / ( k π ) for all nonzero integers k . ( b ) Verify that each feasible point except x (cid:3) 0 is an isolated local solution by showing that there is a neighborhood N around each such point within which it is the only feasible point . 352 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N ( c ) Verify that x (cid:3) 0 is a global solution and a strict local solution , but not an isolated local solution ✐ 12 . 2 Is an isolated local solution necessarily a strict local solution ? Explain . ✐ 12 . 3 Does problem ( 12 . 4 ) have a ﬁnite or inﬁnite number of local solutions ? Use the ﬁrst - order optimality conditions ( 12 . 34 ) to justify your answer . ✐ 12 . 4 If f is convex and the feasible region (cid:22) is convex , show that local solutions of the problem ( 12 . 3 ) are also global solutions . Show that the set of global solutions is convex . ( Hint : See Theorem 2 . 5 . ) ✐ 12 . 5 Let v : IR n → IR m be a smooth vector function and consider the unconstrained optimization problems of minimizing f ( x ) where f ( x ) (cid:3) (cid:8) v ( x ) (cid:8) ∞ , f ( x ) (cid:3) max i (cid:3) 1 , 2 , . . . , m v i ( x ) . Reformulate these ( generally nonsmooth ) problems as smooth constrained optimization problems . ✐ 12 . 6 Can you perform a smooth reformulation as in the previous question when f is deﬁned by f ( x ) (cid:3) min i (cid:3) 1 , 2 , . . . , m f i ( x ) ? ( N . B . “min” not “max . ” ) Why or why not ? ✐ 12 . 7 Show that the vector deﬁned by ( 12 . 15 ) satisﬁes ( 12 . 14 ) when the ﬁrst - order optimality condition ( 12 . 10 ) is not satisﬁed . ✐ 12 . 8 Verify that for the sequence { z k } deﬁned by ( 12 . 30 ) , the function f ( x ) (cid:3) x 1 + x 2 satisﬁes f ( z k + 1 ) > f ( z k ) for k (cid:3) 2 , 3 , . . . . ( Hint : Consider the trajectory z ( s ) (cid:3) ( − (cid:5) 2 − 1 / s 2 , − 1 / s ) T and show that the function h ( s ) def (cid:3) f ( z ( s ) ) has h (cid:14) ( s ) > 0 for all s ≥ 2 . ) ✐ 12 . 9 Consider the problem ( 12 . 9 ) . Specify two feasible sequences that approach the maximizing point ( 1 , 1 ) T , and show that neither sequence is a decreasing sequence for f . ✐ 12 . 10 Verify that neither the LICQ nor the MFCQ holds for the constraint set deﬁned by ( 12 . 32 ) at x ∗ (cid:3) ( 0 , 0 ) T . ✐ 12 . 11 Consider the feasible set (cid:22) in IR 2 deﬁned by x 2 ≥ 0 , x 2 ≤ x 21 . ( a ) For x ∗ (cid:3) ( 0 , 0 ) T , write down T (cid:22) ( x ∗ ) and F ( x ∗ ) . ( b ) Is LICQ satisﬁed at x ∗ ? Is MFCQ satisﬁed ? 1 2 . 9 . D U A L I T Y 353 ( c ) If the objective function is f ( x ) (cid:3) − x 2 , verify that that KKT conditions ( 12 . 34 ) are satisﬁed at x ∗ . ( d ) Find a feasible sequence { z k } approaching x ∗ with f ( z k ) < f ( x ∗ ) for all k . ✐ 12 . 12 It is trivial to construct an example of a feasible set and a feasible point x ∗ at which the LICQ is satisﬁed but the constraints are nonlinear . Give an example of the reverse situation , that is , where the active constraints are linear but the LICQ is not satisﬁed . ✐ 12 . 13 Show that for the feasible region deﬁned by ( x 1 − 1 ) 2 + ( x 2 − 1 ) 2 ≤ 2 , ( x 1 − 1 ) 2 + ( x 2 + 1 ) 2 ≤ 2 , x 1 ≥ 0 , the MFCQ is satisﬁed at x ∗ (cid:3) ( 0 , 0 ) T but the LICQ is not satisﬁed . ✐ 12 . 14 Consider the half space deﬁned by H (cid:3) { x ∈ IR n | a T x + α ≥ 0 } where a ∈ IR n and α ∈ IR are given . Formulate and solve the optimization problem for ﬁnding the point x in H that has the smallest Euclidean norm . ✐ 12 . 15 Consider the following modiﬁcation of ( 12 . 36 ) , where t is a parameter to be ﬁxed prior to solving the problem : min x (cid:17) x 1 − 3 2 (cid:18) 2 + ( x 2 − t ) 4 s . t . ⎡ ⎢⎢⎢⎢⎣ 1 − x 1 − x 2 1 − x 1 + x 2 1 + x 1 − x 2 1 + x 1 + x 2 ⎤ ⎥⎥⎥⎥⎦ ≥ 0 . ( 12 . 97 ) ( a ) For what values of t does the point x ∗ (cid:3) ( 1 , 0 ) T satisfy the KKT conditions ? ( b ) Show that when t (cid:3) 1 , only the ﬁrst constraint is active at the solution , and ﬁnd the solution . ✐ 12 . 16 ( Fletcher [ 101 ] ) Solve the problem min x x 1 + x 2 subject to x 2 1 + x 2 2 (cid:3) 1 by eliminating the variable x 2 . Show that the choice of sign for a square root operation during the elimination process is critical ; the “wrong” choice leads to an incorrect answer . ✐ 12 . 17 Prove that when the KKT conditions ( 12 . 34 ) and the LICQ are satisﬁed at a point x ∗ , the Lagrange multiplier λ ∗ in ( 12 . 34 ) is unique . 354 C H A P T E R 1 2 . T H E O R Y O F C O N S T R A I N E D O P T I M I Z A T I O N ✐ 12 . 18 Consider the problem of ﬁnding the point on the parabola y (cid:3) 15 ( x − 1 ) 2 that is closest to ( x , y ) (cid:3) ( 1 , 2 ) , in the Euclidean norm sense . We can formulate this problem as min f ( x , y ) (cid:3) ( x − 1 ) 2 + ( y − 2 ) 2 subject to ( x − 1 ) 2 (cid:3) 5 y . ( a ) Find all the KKT points for this problem . Is the LICQ satisﬁed ? ( b ) Which of these points are solutions ? ( c ) By directly substituting the constraint into the objective function and eliminating the variable x , we obtain an unconstrained optimization problem . Show that the solutions of this problem cannot be solutions of the original problem . ✐ 12 . 19 Consider the problem min x ∈ IR 2 f ( x ) (cid:3) − 2 x 1 + x 2 subject to (cid:21) ( 1 − x 1 ) 3 − x 2 ≥ 0 x 2 + 0 . 25 x 21 − 1 ≥ 0 . The optimal solution is x ∗ (cid:3) ( 0 , 1 ) T , where both constraints are active . ( a ) Do the LICQ hold at this point ? ( b ) Are the KKT conditions satisﬁed ? ( c ) Write down the sets F ( x ∗ ) and C ( x ∗ , λ ∗ ) . ( d ) Are the second - order necessary conditions satisﬁed ? Are the second - order sufﬁcient conditions satisﬁed ? ✐ 12 . 20 Find the minima of the function f ( x ) (cid:3) x 1 x 2 on the unit circle x 2 1 + x 2 2 (cid:3) 1 . Illustrate this problem geometrically . ✐ 12 . 21 Find the maxima of f ( x ) (cid:3) x 1 x 2 over the unit disk deﬁned by the inequality constraint 1 − x 2 1 − x 2 2 ≥ 0 . ✐ 12 . 22 Show that for ( 12 . 1 ) , the feasible set (cid:22) is convex if c i , i ∈ E are linear functions and − c i , i ∈ I are convex functions . This is page 355 Printer : Opaque this C H A P T E R 13 Linear Programming : The Simplex Method Dantzig’s development of the simplex method in the late 1940s marks the start of the modern era in optimization . This method made it possible for economists to formulate large models and analyze them in a systematic and efﬁcient way . Dantzig’s discovery coincided with the development of the ﬁrst electronic computers , and the simplex method became one of the earliest important applications of this new and revolutionary technology . From those days to the present , computer implementations of the simplex method have been continually improved and reﬁned . They have beneﬁted particularly from interactions with numerical analysis , a branch of mathematics that also came into its own with the appearance of electronic computers , and have now reached a high level of sophistication . 356 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D Today , linear programming and the simplex method continue to hold sway as the most widely used of all optimization tools . Since 1950 , generations of workers in management , economics , ﬁnance , and engineering have been trained in the techniques of formulating linear models and solving them with simplex - based software . Often , the situations they model are actually nonlinear , but linear programming is appealing because of the advanced state of the software , guaranteed convergence to a global minimum , and the fact that uncertainty in the model makes a linear model more appropriate than an overly complex nonlinear model . Nonlinear programming may replace linear programming as the method of choice in some applications as the nonlinear software improves , and a new class of methods known as interior - point methods ( see Chapter 14 ) has proved to be faster for some linear programming problems , but the continued importance of the simplex method is assured for the foreseeable future . LINEAR PROGRAMMING Linear programs have a linear objective function and linear constraints , which may include both equalities and inequalities . The feasible set is a polytope , a convex , connected set with ﬂat , polygonal faces . The contours of the objective function are planar . Figure 13 . 1 depicts a linear program in two - dimensional space , in which the contours of the objective function are indicated by dotted lines . The solution in this case is unique—a single vertex . A simple reorientation of the polytope or the objective gradient c could however make the solution non - unique ; the optimal value c T x could take on the same value over an entire edge . In higher dimensions , the set of optimal points can be a single vertex , an edge or face , or even the entire feasible set . The problem has no solution if the feasible set is empty ( the infeasible case ) or if the objective function is unbounded below on the feasible region ( the unbounded case ) . Linear programs are usually stated and analyzed in the following standard form : min c T x , subject to Ax (cid:3) b , x ≥ 0 , ( 13 . 1 ) where c and x are vectors in IR n , b is a vector in IR m , and A is an m × n matrix . Simple devices can be used to transform any linear program to this form . For instance , given the problem min c T x , subject to Ax ≤ b ( without any bounds on x ) , we can convert the inequality constraints to equalities by introducing a vector of slack variables z and writing min c T x , subject to Ax + z (cid:3) b , z ≥ 0 . ( 13 . 2 ) This form is still not quite standard , since not all the variables are constrained to be C H A P T E R 1 3 . T H E S I M P L E X M E T H O D 357 x optimal point feasible polytope * c Figure 13 . 1 A linear program in two dimensions with solution at x ∗ . nonnegative . We deal with this by splitting x into its nonnegative and nonpositive parts , x (cid:3) x + − x − , where x + (cid:3) max ( x , 0 ) ≥ 0 and x − (cid:3) max ( − x , 0 ) ≥ 0 . The problem ( 13 . 2 ) can now be written as min ⎡ ⎢⎣ c − c 0 ⎤ ⎥⎦ T ⎡ ⎢⎣ x + x − z ⎤ ⎥⎦ , s . t . (cid:9) A − A I (cid:10) ⎡ ⎢⎣ x + x − z ⎤ ⎥⎦ (cid:3) b , ⎡ ⎢⎣ x + x − z ⎤ ⎥⎦ ≥ 0 , which clearly has the same form as ( 13 . 1 ) . Inequalityconstraintsoftheform x ≤ u or Ax ≥ b alwayscanbeconvertedtoequality constraints by adding or subtracting slack variables to make up the difference between the left - and right - hand sides . Hence , x ≤ u ⇔ x + w (cid:3) u , w ≥ 0 , Ax ≥ b ⇔ Ax − y (cid:3) b , y ≥ 0 . ( When we subtract the variables from the left hand side , as in the second case , they are sometimes known as surplus variables . ) We can also convert a “maximize” objective max c T x into the “minimize” form of ( 13 . 1 ) by simply negating c to obtain : min ( − c ) T x . We say that the linear program ( 13 . 1 ) is infeasible if the feasible set is empty . We say that the problem ( 13 . 1 ) is unbounded if the objective function is unbounded below on the feasible region , that is , there is a sequence of points x k feasible for ( 13 . 1 ) such that c T x k ↓ −∞ . ( Of course , unbounded problems have no solution ) . 358 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D Many linear programs arise from models of transshipment and distribution networks . These problems have additional structure in their constraints ; special - purpose simplex algo - rithmsthatexploitthisstructurearehighlyefﬁcient . Wedonotdiscusssuchproblemsfurther in this book , except to note that the subject is important and complex , and that a number of ﬁne texts on the topic are available ( see , for example , Ahuja , Magnanti , and Orlin [ 1 ] ) . For the standard formulation ( 13 . 1 ) , we will assume throughout that m < n . Other - wise , the system Ax (cid:3) b contains redundant rows , or is infeasible , or deﬁnes a unique point . When m ≥ n , factorizations such as the QR or LU factorization ( see Appendix A ) can be used to transform the system Ax (cid:3) b to one with a coefﬁcient matrix of full row rank . 13 . 1 OPTIMALITY AND DUALITY OPTIMALITY CONDITIONS Optimality conditions for the problem ( 13 . 1 ) can be derived from the theory of Chapter12 . Onlytheﬁrst - orderconditions—theKarush – Kuhn – Tucker ( KKT ) conditions— are needed . Convexity of the problem ensures that these conditions are sufﬁcient for a global minimum . We do not need to refer to the second - order conditions from Chapter 12 , which are not informative in any case because the Hessian of the Lagrangian for ( 13 . 1 ) is zero . The theory we developed in Chapter 12 make derivation of optimality and duality results for linear programming much easier than in other treatments , where this theory is developed more or less from scratch . The KKT conditions follow from Theorem 12 . 1 . As stated in Chapter 12 , this theorem requires linear independence of the active constraint gradients ( LICQ ) . However , as we noted in Section 12 . 6 , the result continues to hold for dependent constraints provided they are linear , as is the case here . We partition the Lagrange multipliers for the problem ( 13 . 1 ) into two vectors λ and s , where λ ∈ IR m is the multiplier vector for the equality constraints Ax (cid:3) b , while s ∈ IR n is the multiplier vector for the bound constraints x ≥ 0 . Using the deﬁnition ( 12 . 33 ) , we can write the Lagrangian function for ( 13 . 1 ) as L ( x , λ , s ) (cid:3) c T x − λ T ( Ax − b ) − s T x . ( 13 . 3 ) Applying Theorem 12 . 1 , we ﬁnd that the ﬁrst - order necessary conditions for x ∗ to be a solution of ( 13 . 1 ) are that there exist vectors λ and s such that A T λ + s (cid:3) c , ( 13 . 4a ) Ax (cid:3) b , ( 13 . 4b ) x ≥ 0 , ( 13 . 4c ) s ≥ 0 , ( 13 . 4d ) x i s i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , n . ( 13 . 4e ) 1 3 . 1 . O P T I M A L I T Y A N D D U A L I T Y 359 The complementarity condition ( 13 . 4e ) , which essentially says that at least one of the components x i and s i must be zero for each i (cid:3) 1 , 2 , . . . , n , is often written in the alternative form x T s (cid:3) 0 . Because of the nonnegativity conditions ( 13 . 4c ) , ( 13 . 4d ) , the two forms are identical . Let ( x ∗ , λ ∗ , s ∗ ) denote a vector triple that satisﬁes ( 13 . 4 ) . By combining the three equalities ( 13 . 4a ) , ( 13 . 4d ) , and ( 13 . 4e ) , we ﬁnd that c T x ∗ (cid:3) ( A T λ ∗ + s ∗ ) T x ∗ (cid:3) ( Ax ∗ ) T λ ∗ (cid:3) b T λ ∗ . ( 13 . 5 ) As we shall see in a moment , b T λ is the objective function for the dual problem to ( 13 . 1 ) , so ( 13 . 5 ) indicates that the primal and dual objectives are equal for vector triples ( x , λ , s ) that satisfy ( 13 . 4 ) . It is easy to show directly that the conditions ( 13 . 4 ) are sufﬁcient for x ∗ to be a global solution of ( 13 . 1 ) . Let ¯ x be any other feasible point , so that A ¯ x (cid:3) b and ¯ x ≥ 0 . Then c T ¯ x (cid:3) ( A λ ∗ + s ∗ ) T ¯ x (cid:3) b T λ ∗ + ¯ x T s ∗ ≥ b T λ ∗ (cid:3) c T x ∗ . ( 13 . 6 ) We have used ( 13 . 4 ) and ( 13 . 5 ) here ; the inequality relation follows trivially from ¯ x ≥ 0 and s ∗ ≥ 0 . The inequality ( 13 . 6 ) tells us that no other feasible point can have a lower objective value than c T x ∗ . We can say more : The feasible point ¯ x is optimal if and only if ¯ x T s ∗ (cid:3) 0 , since otherwise the inequality in ( 13 . 6 ) is strict . In other words , when s ∗ i > 0 , then we must have ¯ x i (cid:3) 0 for all solutions ¯ x of ( 13 . 1 ) . THE DUAL PROBLEM Given the data c , b , and A , which deﬁnes the problem ( 13 . 1 ) , we can deﬁne another , closely related , problem as follows : max b T λ , subject to A T λ ≤ c . ( 13 . 7 ) This problem is called the dual problem for ( 13 . 1 ) . In contrast , ( 13 . 1 ) is often referred to as the primal . We can restate ( 13 . 7 ) in a slightly different form by introducing a vector of dual slack variables s , and writing max b T λ , subject to A T λ + s (cid:3) c , s ≥ 0 . ( 13 . 8 ) The variables ( λ , s ) in this problem are sometimes jointly referred to collectively as dual variables . 360 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D The primal and dual problems present two different viewpoints on the same data . Their close relationship becomes evident when we write down the KKT conditions for ( 13 . 7 ) . Let us ﬁrst restate ( 13 . 7 ) in the form min − b T λ subject to c − A T λ ≥ 0 , to ﬁt the formulation ( 12 . 1 ) from Chapter 12 . By using x ∈ IR n to denote the Lagrange multipliers for the constraints A T λ ≤ c , we see that the Lagrangian function is ¯ L ( λ , x ) (cid:3) − b T λ − x T ( c − A T λ ) . Using Theorem 12 . 1 again , we ﬁnd the ﬁrst - order necessary conditions for λ to be optimal for ( 13 . 7 ) to be that there exists x such that Ax (cid:3) b , ( 13 . 9a ) A T λ ≤ c , ( 13 . 9b ) x ≥ 0 , ( 13 . 9c ) x i ( c − A T λ ) i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , n . ( 13 . 9d ) Deﬁning s (cid:3) c − A T λ ( as in ( 13 . 8 ) ) , we ﬁnd that the conditions ( 13 . 9 ) and ( 13 . 4 ) are identical ! TheoptimalLagrangemultipliers λ intheprimalproblemaretheoptimalvariables in the dual problem , while the optimal Lagrange multipliers x in the dual problem are the optimal variables in the primal problem . Analogously to ( 13 . 6 ) , we can show that ( 13 . 9 ) are in fact sufﬁcient conditions for a solution of the dual problem ( 13 . 7 ) . Given x ∗ and λ ∗ satisfying these conditions ( so that the triple ( x , λ , s ) (cid:3) ( x ∗ , λ ∗ , c − A T λ ∗ ) satisﬁes ( 13 . 4 ) ) , we have for any other dual feasible point ¯ λ ( with A T ¯ λ ≤ c ) that b T ¯ λ (cid:3) ( x ∗ ) T A T ¯ λ (cid:3) ( x ∗ ) T ( A T ¯ λ − c ) + c T x ∗ ≤ c T x ∗ because A T ¯ λ − c ≤ 0 and x ∗ ≥ 0 (cid:3) b T λ ∗ from ( 13 . 5 ) . Hence λ ∗ achieves the maximum of the dual objective b T λ over the dual feasible region A T λ ≤ c , so it solves the dual problem ( 13 . 7 ) . The primal – dual relationship is symmetric ; by taking the dual of the dual problem ( 13 . 7 ) , we recover the primal problem ( 13 . 1 ) . We leave the proof of this claim as an exercise . Given a feasible vector x for the primal ( satisfying Ax (cid:3) b and x ≥ 0 ) and a feasible point ( λ , s ) for the dual ( satisfying A T λ + s (cid:3) c , s ≥ 0 ) , we have as in ( 13 . 6 ) that c T x − b T λ (cid:3) ( c − A T λ ) T x (cid:3) s T x ≥ 0 . ( 13 . 10 ) 1 3 . 1 . O P T I M A L I T Y A N D D U A L I T Y 361 Therefore we have c T x ≥ b T λ ( that is , the dual objective is a lower bound on the primal objective ) when both the primal and dual variables are feasible—a result known as weak duality . Thefollowing strongduality resultisfundamentaltothetheoryoflinearprogramming . Theorem 13 . 1 ( Strong Duality ) . ( i ) If either problem ( 13 . 1 ) or ( 13 . 7 ) has a ( ﬁnite ) solution , then so does the other , and the objective values are equal . ( ii ) If either problem ( 13 . 1 ) or ( 13 . 7 ) is unbounded , then the other problem is infeasible . P ROOF . For ( i ) , suppose that ( 13 . 1 ) has a ﬁnite optimal solution x ∗ . It follows from The - orem 12 . 1 that there are vectors λ ∗ and s ∗ such that ( x ∗ , λ ∗ , s ∗ ) satisﬁes ( 13 . 4 ) . We noted above that ( 13 . 4 ) and ( 13 . 9 ) are equivalent , and that ( 13 . 9 ) are sufﬁcient conditions for λ ∗ to be a solution of the dual problem ( 13 . 7 ) . Moreover , it follows from ( 13 . 5 ) that c T x ∗ (cid:3) b T λ ∗ , as claimed . A symmetric argument holds if we start by assuming that the dual problem ( 13 . 7 ) has a solution . To prove ( ii ) , suppose that the primal is unbounded , that is , there is a sequence of points x k , k (cid:3) 1 , 2 , 3 , . . . such that c T x k ↓ −∞ , Ax k (cid:3) b , x k ≥ 0 . Suppose too that the dual ( 13 . 7 ) is feasible , that is , there exists a vector ¯ λ such that A T ¯ λ ≤ c . From the latter inequality together with x k ≥ 0 , we have that ¯ λ T Ax k ≤ c T x k , and therefore ¯ λ T b (cid:3) ¯ λ T Ax k ≤ c T x k ↓ −∞ , yielding a contradiction . Hence , the dual must be infeasible . A similar argument can be used to show that unboundedness of the dual implies infeasibility of the primal . (cid:1) As we showed in the discussion following Theorem 12 . 1 , the multiplier values λ and s for ( 13 . 1 ) indicate the sensitivity of the optimal objective value to perturbations in the constraints . In fact , the process of ﬁnding ( λ , s ) for a given optimal x is often called sensitivity analysis . Considering the case of perturbations to the vector b ( the right - hand side in ( 13 . 1 ) and objective gradient in ( 13 . 7 ) ) , we can make an informal argument to illustrate the sensitivity . Suppose that this small change produces small perturbations in the primal and dual solutions , and that the vectors (cid:6) s and (cid:6) x have zeros in the same locations as s and x , respectively . Since x and s are complementary ( see ( 13 . 4e ) ) it follows that 0 (cid:3) x T s (cid:3) x T (cid:6) s (cid:3) ( (cid:6) x ) T s (cid:3) ( (cid:6) x ) T (cid:6) s . 362 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D We have from Theorem 13 . 1 that the optimal objectives of the primal and dual problems are equal , for both the original and perturbed problems , so c T x (cid:3) b T λ , c T ( x + (cid:6) x ) (cid:3) ( b + (cid:6) b ) T ( λ + (cid:6)λ ) . Moreover , by feasibility of the perturbed solutions in the perturbed problems , we have A ( x + (cid:6) x ) (cid:3) b + (cid:6) b , A T (cid:6)λ (cid:3) − (cid:6) s . Hence , the change in optimal objective due to the perturbation is as follows : c T (cid:6) x (cid:3) ( b + (cid:6) b ) T ( λ + (cid:6)λ ) − b T λ (cid:3) ( b + (cid:6) b ) T (cid:6)λ + ( (cid:6) b ) T λ (cid:3) ( x + (cid:6) x ) T A T (cid:6)λ + ( (cid:6) b ) T λ (cid:3) ( x + (cid:6) x ) T (cid:6) s + ( (cid:6) b ) T λ (cid:3) ( (cid:6) b ) T λ . In particular , if (cid:6) b (cid:3) (cid:9) e j , where e j is the j th unit vector in IR m , we have for all (cid:9) sufﬁciently small that c T (cid:6) x (cid:3) (cid:9)λ j . ( 13 . 11 ) That is , the change in optimal objective is λ j times the size of the perturbation to b j , if the perturbation is small . 13 . 2 GEOMETRY OF THE FEASIBLE SET BASES AND BASIC FEASIBLE POINTS We assume for the remainder of the chapter that The matrix A in ( 13 . 1 ) has full row rank . ( 13 . 12 ) In practice , a preprocessing phase is applied to the user - supplied data to remove some redundancies from the given constraints and eliminate some of the variables . Reformulation by adding slack , surplus , and artiﬁcial variables can also result in A satisfying the property ( 13 . 12 ) . Each iterate generated by the simplex method is a basic feasible point of ( 13 . 1 ) . A vector x is a basic feasible point if it is feasible and if there exists a subset B of the index set { 1 , 2 , . . . , n } such that 1 3 . 2 . G E O M E T R Y O F T H E F E A S I B L E S E T 363 • B contains exactly m indices ; • i / ∈ B ⇒ x i (cid:3) 0 ( that is , the bound x i ≥ 0 can be inactive only if i ∈ B ) ; • The m × m matrix B deﬁned by B (cid:3) [ A i ] i ∈ B ( 13 . 13 ) is nonsingular , where A i is the i th column of A . A set B satisfying these properties is called a basis for the problem ( 13 . 1 ) . The corresponding matrix B is called the basis matrix . The simplex method’s strategy of examining only basic feasible points will converge to a solution of ( 13 . 1 ) only if ( a ) the problem has basic feasible points ; and ( b ) at least one such point is a basic optimal point , that is , a solution of ( 13 . 1 ) that is also a basic feasible point . Happily , both ( a ) and ( b ) are true under reasonable assumptions , as the following result ( sometimes known as the fundamental theorem of linear programming ) shows . Theorem 13 . 2 . ( i ) If ( 13 . 1 ) has a nonempty feasible region , then there is at least one basic feasible point ; ( ii ) If ( 13 . 1 ) has solutions , then at least one such solution is a basic optimal point . ( iii ) If ( 13 . 1 ) is feasible and bounded , then it has an optimal solution . P ROOF . Among all feasible vectors x , choose one with the minimal number of nonzero components , and denote this number by p . Without loss of generality , assume that the nonzeros are x 1 , x 2 , . . . , x p , so we have p (cid:3) i (cid:3) 1 A i x i (cid:3) b . Suppose ﬁrst that the columns A 1 , A 2 , . . . , A p are linearly dependent . Then we can express one of them ( A p , say ) in terms of the others , and write A p (cid:3) p − 1 (cid:3) i (cid:3) 1 A i z i , ( 13 . 14 ) 364 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D for some scalars z 1 , z 2 , . . . , z p − 1 . It is easy to check that the vector x ( (cid:9) ) (cid:3) x + (cid:9) ( z 1 , z 2 , . . . , z p − 1 , − 1 , 0 , 0 , . . . , 0 ) T (cid:3) x + (cid:9) z ( 13 . 15 ) satisﬁes Ax ( (cid:9) ) (cid:3) b for any scalar (cid:9) . In addition , since x i > 0 for i (cid:3) 1 , 2 , . . . , p , we also have x i ( (cid:9) ) > 0 for the same indices i (cid:3) 1 , 2 , . . . , p and all (cid:9) sufﬁciently small in magnitude . However , there is a value ¯ (cid:9) ∈ ( 0 , x p ] such that x i ( ¯ (cid:9) ) (cid:3) 0 for some i (cid:3) 1 , 2 , . . . , p . Hence , x ( ¯ (cid:9) ) is feasible and has at most p − 1 nonzero components , contradicting our choice of p as the minimal number of nonzeros . Therefore , columns A 1 , A 2 , . . . , A p must be linearly independent , and so p ≤ m . If p (cid:3) m , we are done , since then x is a basic feasible point and B is simply { 1 , 2 , . . . , m } . Otherwise p < m and , because A has full row rank , we can choose m − p columns from among A p + 1 , A p + 2 , . . . , A n tobuildupasetof m linearlyindependentvectors . Weconstruct B by adding the corresponding indices to { 1 , 2 , . . . , p } . The proof of ( i ) is complete . The proof of ( ii ) is quite similar . Let x ∗ be a solution with a minimal number of nonzero components p , and assume again that x ∗ 1 , x ∗ 2 , . . . , x ∗ p are the nonzeros . If the columns A 1 , A 2 , . . . , A p are linearly dependent , we deﬁne x ∗ ( (cid:9) ) (cid:3) x ∗ + (cid:9) z , where z is chosen exactly as in ( 13 . 14 ) , ( 13 . 15 ) . It is easy to check that x ∗ ( (cid:9) ) will be feasible for all (cid:9) sufﬁciently small , both positive and negative . Hence , since x ∗ is optimal , we must have c T ( x ∗ + (cid:9) z ) ≥ c T x ∗ ⇒ (cid:9) c T z ≥ 0 forall (cid:9) sufﬁcientlysmall ( positiveandnegative ) . Therefore , c T z (cid:3) 0andso c T x ∗ ( (cid:9) ) (cid:3) c T x ∗ for all (cid:9) . The same logic as in the proof of ( i ) can be applied to ﬁnd ¯ (cid:9) > 0 such that x ∗ ( ¯ (cid:9) ) is feasible and optimal , with at most p − 1 nonzero components . This contradicts our choice of p as the minimal number of nonzeros , so the columns A 1 , A 2 , . . . , A p must be linearly independent . We can now apply the same reasoning as above to conclude that x ∗ is already a basic feasible point and therefore a basic optimal point . The ﬁnal statement ( iii ) is a consequence of ﬁnite termination of the simplex method . We comment on the latter property in the next section . (cid:1) The terminology we use here is not quite standard , as the following table shows : our terminology terminology used elsewhere basic feasible point basic feasible solution basic optimal point optimal basic feasible solution The standard terms arose because “solution” and “feasible solution” were originally used as synonyms for “feasible point . ” However , as the discipline of optimization developed , 1 3 . 2 . G E O M E T R Y O F T H E F E A S I B L E S E T 365 * * * * * * * * * * Figure 13 . 2 Vertices of a three - dimensional polytope ( indicated by ∗ ) . the word “solution” took on a more speciﬁc and intuitive meaning ( as in “solution to the problem” ) . We maintain consistency with the rest of the book by following this more modern usage . VERTICES OF THE FEASIBLE POLYTOPE The feasible set deﬁned by the linear constraints is a polytope , and the vertices of this polytope are the points that do not lie on a straight line between two other points in the set . Geometrically , they are easily recognizable ; see Figure 13 . 2 . Algebraically , the vertices are exactly the basic feasible points deﬁned above . We therefore have an important relationship between the algebraic and geometric viewpoints and a useful aid to understanding how the simplex method works . Theorem 13 . 3 . All basic feasible points for ( 13 . 1 ) are vertices of the feasible polytope { x | Ax (cid:3) b , x ≥ 0 } , and vice versa . P ROOF . Let x be a basic feasible point and assume without loss of generality that B (cid:3) { 1 , 2 , . . . , m } . The matrix B (cid:3) [ A i ] i (cid:3) 1 , 2 , . . . , m is therefore nonsingular , and x m + 1 (cid:3) x m + 2 (cid:3) · · · (cid:3) x n (cid:3) 0 . ( 13 . 16 ) Suppose that x lies on a straight line between two other feasible points y and z . Then we can ﬁnd α ∈ ( 0 , 1 ) such that x (cid:3) α y + ( 1 − α ) z . Because of ( 13 . 16 ) and the fact that α and 1 − α are both positive , we must have y i (cid:3) z i (cid:3) 0 for i (cid:3) m + 1 , m + 2 , . . . , n . Writing x B (cid:3) ( x 1 , x 2 , . . . , x m ) T and deﬁning y B and z B likewise , we have from Ax (cid:3) Ay (cid:3) Az (cid:3) b 366 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D that Bx B (cid:3) By B (cid:3) Bz B (cid:3) b , and so , by nonsingularity of B , we have x B (cid:3) y B (cid:3) z B . Therefore , x (cid:3) y (cid:3) z , contradicting our assertion that y and z are two feasible points other than x . Therefore , x is a vertex . Conversely , let x be a vertex of the feasible polytope , and suppose that the nonzero components of x are x 1 , x 2 , . . . , x p . If the corresponding columns A 1 , A 2 , . . . , A p are linearly dependent , then we can construct the vector x ( (cid:9) ) (cid:3) x + (cid:9) z as in ( 13 . 15 ) . Since x ( (cid:9) ) is feasible for all (cid:9) with sufﬁciently small magnitude , we can deﬁne ˆ (cid:9) > 0 such that x ( ˆ (cid:9) ) and x ( −ˆ (cid:9) ) are both feasible . Since x (cid:3) x ( 0 ) obviously lies on a straight line between these two points , it cannot be a vertex . Hence our assertion that A 1 , A 2 , . . . , A p are linearly dependent must be incorrect , so these columns must be linearly independent and p ≤ m . If p < m , and since A has full row rank , we can add m − p indices to { 1 , 2 , . . . , p } to form a basis B , for which x is the corresponding basic feasible point . This completes our proof . (cid:1) We conclude this discussion of the geometry of the feasible set with a deﬁnition of degeneracy . This term has a variety of meanings in optimization , as we discuss in Chapter 16 . For the purposes of this chapter , we use the following deﬁnition . Deﬁnition 13 . 1 ( Degeneracy ) . A basis B is said to be degenerate if x i (cid:3) 0 for some i ∈ B , where x is the basic feasible solution corresponding to B . A linear program ( 13 . 1 ) is said to be degenerate if it has at least one degenerate basis . 13 . 3 THE SIMPLEX METHOD OUTLINE In this section we give a detailed description of the simplex method for ( 13 . 1 ) . There are actually a number of variants the simplex method ; the one described here is sometimes known as the revised simplex method . ( We will describe an alternative known as the dual simplex method in Section 13 . 6 . ) As we described above , all iterates of the simplex method are basic feasible points for ( 13 . 1 ) and therefore vertices of the feasible polytope . Most steps consist of a move from one vertex to an adjacent one for which the basis B differs in exactly one component . On most steps ( but not all ) , the value of the primal objective function c T x is decreased . Another type of step occurs when the problem is unbounded : The step is an edge along which the objective function is reduced , and along which we can move inﬁnitely far without ever reaching a vertex . 1 3 . 3 . T H E S I M P L E X M E T H O D 367 The major issue at each simplex iteration is to decide which index to remove from the basis B . Unless the step is a direction of unboundedness , a single index must be removed from B and replaced by another from outside B . We can gain some insight into how this decision is made by looking again at the KKT conditions ( 13 . 4 ) . From B and ( 13 . 4 ) , we can derive values for not just the primal variable x but also the dual variables ( λ , s ) , as we now show . First , deﬁne the nonbasic index set N as the complement of B , that is , N (cid:3) { 1 , 2 , . . . , n } \ B . ( 13 . 17 ) Justas B isthebasicmatrix , whosecolumnsare A i for i ∈ B , weuse N todenotethenonbasic matrix N (cid:3) [ A i ] i ∈ N . We also partition the n - element vectors x , s , and c according to the index sets B and N , using the notation x B (cid:3) [ x i ] i ∈ B , x N (cid:3) [ x i ] i ∈ N , s B (cid:3) [ s i ] i ∈ B , s N (cid:3) [ s i ] i ∈ N , c B (cid:3) [ c i ] i ∈ B , c N (cid:3) [ c i ] i ∈ N . From the KKT condition ( 13 . 4b ) , we have that Ax (cid:3) Bx B + Nx N (cid:3) b . The primal variable x for this simplex iterate is deﬁned as x B (cid:3) B − 1 b , x N (cid:3) 0 . ( 13 . 18 ) Since we are dealing only with basic feasible points , we know that B is nonsingular and that x B ≥ 0 , so this choice of x satisﬁes two of the KKT conditions : the equality constraints ( 13 . 4b ) and the nonnegativity condition ( 13 . 4c ) . We choose s to satisfy the complementarity condition ( 13 . 4e ) by setting s B (cid:3) 0 . The remaining components λ and s N can be found by partitioning this condition into c B and c N components and using s B (cid:3) 0 to obtain B T λ (cid:3) c B , N T λ + s N (cid:3) c N . ( 13 . 19 ) Since B is square and nonsingular , the ﬁrst equation uniquely deﬁnes λ as λ (cid:3) B − T c B . ( 13 . 20 ) The second equation in ( 13 . 19 ) implies a value for s N : s N (cid:3) c N − N T λ (cid:3) c N − ( B − 1 N ) T c B . ( 13 . 21 ) 368 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D Computation of the vector s N is often referred to as pricing . The components of s N are often called the reduced costs of the nonbasic variables x N . The only KKT condition that we have not enforced explicitly is the nonnegativity condition s ≥ 0 . The basic components s B certainly satisfy this condition , by our choice s B (cid:3) 0 . If the vector s N deﬁned by ( 13 . 21 ) also satisﬁes s N ≥ 0 , we have found an optimal vector triple ( x , λ , s ) , so the algorithm can terminate and declare success . Usually , however , one or more of the components of s N are negative . The new index to enter the basis B —the entering index —is chosen to be one of the indices q ∈ N for which s q < 0 . As we show below , the objective c T x will decrease when we allow x q to become positive if and only if ( i ) s q < 0 and ( ii ) it is possible to increase x q away from zero while maintaining feasibility of x . Our procedure for altering B and changing x and s can be described accordingly as follows : • allow x q to increase from zero during the next step ; • ﬁx all other components of x N at zero , and ﬁgure out the effect of increasing x q on the current basic vector x B , given that we want to stay feasible with respect to the equality constraints Ax (cid:3) b ; • keep increasing x q until one of the components of x B ( x p , say ) is driven to zero , or determining that no such component exists ( the unbounded case ) ; • remove index p ( known as the leaving index ) from B and replace it with the entering index q . This process of selecting entering and leaving indices , and performing the algebraic operations necessary to keep track of the values of the variables x , λ , and s , is sometimes known as pivoting . We now formalize the pivoting procedure in algebraic terms . Since both the new iterate x + and the current iterate x should satisfy Ax (cid:3) b , and since x N (cid:3) 0 and x + i (cid:3) 0 for i ∈ N \ { q } , we have Ax + (cid:3) Bx + B + A q x + q (cid:3) Bx B (cid:3) Ax . By multiplying this expression by B − 1 and rearranging , we obtain x + B (cid:3) x B − B − 1 A q x + q . ( 13 . 22 ) Geometrically speaking , ( 13 . 22 ) is usually a move along an edge of the feasible polytope that decreases c T x . We continue to move along this edge until a new vertex is encountered . At this vertex , a new constraint x p ≥ 0 must have become active , that is , one of the components x p , p ∈ B , has decreased to zero . We then remove this index p from the basis B and replace it by q . 1 3 . 3 . T H E S I M P L E X M E T H O D 369 We now show how the step deﬁned by ( 13 . 22 ) affects the value of c T x . From ( 13 . 22 ) , we have c T x + (cid:3) c T B x + B + c q x + q (cid:3) c T B x B − c T B B − 1 A q x + q + c q x + q . ( 13 . 23 ) From ( 13 . 20 ) we have c T B B − 1 (cid:3) λ T , while from the second equation in ( 13 . 19 ) , since q ∈ N , we have A Tq λ (cid:3) c q − s q . Therefore , c T B B − 1 A q x + q (cid:3) λ T A q x + q (cid:3) ( c q − s q ) x + q , so by substituting in ( 13 . 23 ) we obtain c T x + (cid:3) c T B x B − ( c q − s q ) x + q + c q x + q (cid:3) c T x + s q x + q . ( 13 . 24 ) Since q was chosen to have s q < 0 , it follows that the step ( 13 . 22 ) produces a decrease in the primal objective function c T x whenever x + q > 0 . It is possible that we can increase x + q to ∞ without ever encountering a new vertex . In other words , the constraint x + B (cid:3) x B − B − 1 A q x + q ≥ 0 holds for all positive values of x + q . When this happens , the linear program is unbounded ; the simplex method has identiﬁed a ray that lies entirely within the feasible polytope along which the objective c T x decreases to −∞ . Figure 13 . 3 shows a path traversed by the simplex method for a problem in IR 2 . In this example , the optimal vertex x ∗ is found in three steps . If the basis B is nondegenerate ( see Deﬁnition 13 . 1 ) , then we are guaranteed that x + q > 0 , so we can be assured of a strict decrease in the objective function c T x at this step . If simplex path 1 0 2 3 c Figure 13 . 3 Simplex iterates for a two - dimensional problem . 370 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D the problem ( 13 . 1 ) is nondegenerate , we can ensure a decrease in c T x at every step , and can therefore prove the following result concerning termination of the simplex method . Theorem 13 . 4 . Provided that the linear program ( 13 . 1 ) is nondegenerate and bounded , the simplex method terminates at a basic optimal point . P ROOF . The simplex method cannot visit the same basic feasible point x at two different iterations , because it attains a strict decrease at each iteration . Since the number of possible bases B is ﬁnite ( there are only a ﬁnite number of ways to choose a subset of m indices from { 1 , 2 , . . . , n } ) , and since each basis deﬁnes a single basic feasible point , there are only a ﬁnite number of basic feasible points . Hence , the number of iterations is ﬁnite . Moreover , since the method is always able to take a step away from a nonoptimal basic feasible point , and since the problem is not unbounded , the method must terminate at a basic optimal point . (cid:1) This result gives us a proof of Theorem 13 . 2 ( iii ) in the case in which the linear program is nondegenerate . The proof of ﬁnite termination is considerably more complex when nondegeneracy of ( 13 . 1 ) is not assumed , as we discuss at the end of Section 13 . 5 . A SINGLE STEP OF THE METHOD We have covered most of the mechanics of taking a single step of the simplex method . To make subsequent discussions easier to follow , we summarize our description . Procedure 13 . 1 ( One Step of Simplex ) . Given B , N , x B (cid:3) B − 1 b ≥ 0 , x N (cid:3) 0 ; Solve B T λ (cid:3) c B for λ , Compute s N (cid:3) c N − N T λ ; ( ∗ pricing ∗ ) if s N ≥ 0 stop ; ( ∗ optimal point found ∗ ) Select q ∈ N with s q < 0 as the entering index ; Solve Bd (cid:3) A q for d ; if d ≤ 0 stop ; ( ∗ problem is unbounded ∗ ) Calculate x + q (cid:3) min i | d i > 0 ( x B ) i / d i , and use p to denote the minimizing i ; Update x + B (cid:3) x B − dx + q , x + N (cid:3) ( 0 , . . . , 0 , x + q , 0 , . . . , 0 ) T ; Change B by adding q and removing the basic variable corresponding to column p of B . We illustrate this procedure with a simple example . 1 3 . 3 . T H E S I M P L E X M E T H O D 371 ❏ E XAMPLE 13 . 1 Consider the problem min − 4 x 1 − 2 x 2 subject to x 1 + x 2 + x 3 (cid:3) 5 , 2 x 1 + ( 1 / 2 ) x 2 + x 4 (cid:3) 8 , x ≥ 0 . Suppose we start with the basis B (cid:3) { 3 , 4 } , for which we have x B (cid:3) (cid:1) x 3 x 4 (cid:2) (cid:3) (cid:1) 5 8 (cid:2) , λ (cid:3) (cid:1) 0 0 (cid:2) , s N (cid:3) (cid:1) s 1 s 2 (cid:2) (cid:3) (cid:1) − 3 − 2 (cid:2) , and an objective value of c T x (cid:3) 0 . Since both elements of s N are negative , we could choose either 1 or 2 to be the entering variable . Suppose we choose q (cid:3) 1 . We obtain d (cid:3) ( 1 , 2 ) T , so we cannot ( yet ) conclude that the problem is unbounded . By performing the ratio calculation , we ﬁnd that p (cid:3) 2 ( corresponding to the index 4 ) and x + 1 (cid:3) 4 . We update the basic and nonbasic index sets to B (cid:3) { 3 , 1 } and N (cid:3) { 4 , 2 } , and move to the next iteration . At the second iteration , we have x B (cid:3) (cid:1) x 3 x 1 (cid:2) (cid:3) (cid:1) 1 4 (cid:2) , λ (cid:3) (cid:1) 0 − 3 / 2 (cid:2) , s N (cid:3) (cid:1) s 4 s 2 (cid:2) (cid:3) (cid:1) 3 / 2 − 5 / 4 (cid:2) , with an objective value of − 12 . We see that s N has one negative component , corresponding to the index q (cid:3) 2 , so we select this index to enter the basis . We obtain d (cid:3) ( 3 / 2 , − 1 / 2 ) T , so again we do not detect unboundedness . Continuing , we ﬁnd that the maximum value of x + 2 is 4 / 3 , and that p (cid:3) 1 , which indicates that index 3 will leave the basis B . We update the index sets to B (cid:3) { 2 , 1 } and N (cid:3) { 4 , 3 } and continue . At the start of the third iteration , we have x B (cid:3) (cid:1) x 2 x 1 (cid:2) (cid:3) (cid:1) 4 / 3 11 / 3 (cid:2) , λ (cid:3) (cid:1) − 5 / 3 − 2 / 3 (cid:2) , s N (cid:3) (cid:1) s 4 s 3 (cid:2) (cid:3) (cid:1) 7 / 3 5 / 3 (cid:2) , with an objective value of c T x (cid:3) − 41 / 3 . We see that s N ≥ 0 , so the optimality test is satisﬁed , and we terminate . ❐ We need to ﬂesh out Procedure 13 . 1 with speciﬁcs of three important aspects of the implementation : 372 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D • Linear algebra issues—maintaining an LU factorization of B that can be used to solve for λ and d . • Selection of the entering index q from among the negative components of s N . ( In general , there are many such components . ) • Handling of degenerate bases and degenerate steps , in which it is not possible to choose a positive value of x + q without violating feasibility . Proper handling of these issues is crucial to the efﬁciency of a simplex implementation . We give some details in the next three sections . 13 . 4 LINEAR ALGEBRA IN THE SIMPLEX METHOD We have to solve two linear systems involving the matrix B at each step ; namely , B T λ (cid:3) c B , Bd (cid:3) A q . ( 13 . 25 ) We never calculate the inverse basis matrix B − 1 explicitly just to solve these systems . Instead , we calculate or maintain some factorization of B —usually an LU factorization—and use triangular substitutions with the factors to recover λ and d . It is less expensive to update the factorization than to calculate it afresh at each iteration because the basis matrix B changes by just a single column between iterations . The standard factorization / updating procedures start with an LU factorization of B at the ﬁrst iteration of the simplex algorithm . Since in practical applications B is large and sparse , its rows and columns are rearranged during the factorization to maintain both numerical stability and sparsity of the L and U factors . One successful pivot strategy that trades off between these two aims was proposed by Markowitz in 1957 [ 202 ] ; it is still used as the basis of many practical sparse LU algorithms . Other considerations may also enter into our choice of row and column reordering of B . For example , it may help to improve the efﬁciency of the updating procedure if as many as possible of the leading columns of U con - tain just a single nonzero , on the diagonal . Many heuristics have been devised for choosing row and column permutations that produce this and other desirable structural features . Let us assume for simplicity that row and column permutations are already incorporated in B , so that we write the initial LU factorization as LU (cid:3) B , ( 13 . 26 ) ( L is unit lower triangular , U is upper triangular ) . The system Bd (cid:3) A q can then be solved by the following two - step procedure : L ¯ d (cid:3) A q , Ud (cid:3) ¯ d . ( 13 . 27 ) 1 3 . 4 . L I N E A R A L G E B R A I N T H E S I M P L E X M E T H O D 373 p column Figure 13 . 4 Left : L − 1 B + , which is upper triangular except for the column occupied by A p . Right : After cyclic row and column permutation P 1 , the non – upper triangular part of P 1 L − 1 B + P T 1 appears in the last row . Similarly , the system B T λ (cid:3) c B is solved by performing the following two triangular substitutions : U T ¯ λ (cid:3) c B , L T λ (cid:3) ¯ λ . We now discuss a procedure for updating the factors L and U after one step of the simplex method , when the index p is removed from the basis B and replaced by the index q . The corresponding change to the basis matrix B is that the column B p is removed from B and replaced by A q . We call the resulting matrix B + and note that if we rewrite ( 13 . 26 ) as U (cid:3) L − 1 B , the modiﬁed matrix L − 1 B + will be upper triangular except in column p . That is , L − 1 B + has the form shown on the left in Figure 13 . 4 . Wenowperformacyclicpermutationthatmovescolumn p tothelastcolumnposition m and moves columns p + 1 , p + 2 , . . . , m one position to the left to make room for it . If we apply the same permutation to rows p through m , the net effect is to move the non - upper triangular part to the last row of the matrix , as shown in Figure 13 . 4 . If we denote the permutation matrix by P 1 , the matrix illustrated at right in Figure 13 . 4 is P 1 L − 1 B + P T 1 . Finally , we perform sparse Gaussian elimination on the matrix P 1 L − 1 B + P T 1 to restore upper triangular form . That is , we ﬁnd L 1 and U 1 ( lower and upper triangular , respectively ) such that P 1 L − 1 B + P T 1 (cid:3) L 1 U 1 . ( 13 . 28 ) It is easy to show that L 1 and U 1 have a simple form . The lower triangular matrix L 1 differs from the identity only in the last row , while U 1 is identical to P 1 L − 1 B + P T 1 except that the ( m , m ) element is changed and the off - diagonal elements in the last row are eliminated . 374 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D We give details of this process for the case of m (cid:3) 5 . Using the notation L − 1 B (cid:3) U (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢ ⎣ u 11 u 12 u 13 u 14 u 15 u 22 u 23 u 24 u 25 u 33 u 34 u 35 u 44 u 45 u 55 ⎤ ⎥⎥⎥⎥⎥⎥⎥ ⎦ , L − 1 A q (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢ ⎣ w 1 w 2 w 3 w 4 w 5 ⎤ ⎥⎥⎥⎥⎥⎥⎥ ⎦ , and supposing that p (cid:3) 2 ( so that the second column is replaced by L − 1 A q ) , we have L − 1 B + (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ u 11 w 1 u 13 u 14 u 15 w 2 u 23 u 24 u 25 w 3 u 33 u 34 u 35 w 4 u 44 u 45 w 5 u 55 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ . After the cyclic permutation P 1 , we have P 1 L − 1 B + P 1 T (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ u 11 u 13 u 14 u 15 w 1 u 33 u 34 u 35 w 3 u 44 u 45 w 4 u 55 w 5 u 23 u 24 u 25 w 2 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ . ( 13 . 29 ) The factors L 1 and U 1 are now as follows : L 1 (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ 1 1 1 1 0 l 52 l 53 l 54 1 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ , U 1 (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ u 11 u 13 u 14 u 15 w 1 u 33 u 34 u 35 w 3 u 44 u 45 w 4 u 55 w 5 ˆ w 2 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ , ( 13 . 30 ) for certain values of l 52 , l 53 , l 54 , and ˆ w 2 ( see Exercise 13 . 10 ) . The result of this updating process is the factorization ( 13 . 28 ) , which we can rewrite as follows : B + (cid:3) L + U + , where L + (cid:3) L P T 1 L 1 , U + (cid:3) U 1 P 1 . ( 13 . 31 ) 1 3 . 5 . O T H E R I M P O R T A N T D E T A I L S 375 There is no need to calculate L + and U + explicitly . Rather , the nonzero elements in L 1 and the last column of U 1 , and the permutation information in P 1 , can be stored in compact form , so that triangular substitutions involving L + and U + can be performed by applying a number of permutations and sparse triangular substitutions involving these factors . The factorization updates from subsequent simplex steps are stored and applied in a similar fashion . The procedure we have just outlined is due to Forrest and Tomlin [ 110 ] . It is quite efﬁcient , becauseitrequiresthestorageoflittledataateachupdateanddoesnotrequiremuch movement of data in memory . Its major disadvantage is possible numerical instability . Large elements in the factors of a matrix are a sure indicator of instability , and the multipliers in the L 1 factor ( l 52 in ( 13 . 30 ) , for example ) may be very large . An earlier scheme of Bartels and Golub [ 12 ] allowed swapping of rows to avoid these problems . For instance , if | u 33 | < | u 23 | in ( 13 . 29 ) , we could swap rows 2 and 5 to ensure that the subsequent multiplier l 52 in the L 1 factor does not exceed 1 in magnitude . This improved stability comes at a price : The lower right corner of the upper triangular factor may become more dense during each update . Although the update information for each iteration ( the permutation matrices and the sparse triangular factors ) can often be stored in a highly compact form , the total amount of space may build up to unreasonable levels after many such updates have been performed . As the number of updates builds up , so does the time needed to solve for the vectors d and λ in Procedure 13 . 1 . If an unstable updating procedure is used , numerical errors may also come into play , blocking further progress by the simplex algorithm . For all these reasons , most simplex implementations periodically calculate a fresh LU factorization of the current basis matrix B and discard the accumulated updates . The new factorization uses the same permutation strategies that we apply to the very ﬁrst factorization , which balance the requirements of stability , sparsity , and structure . 13 . 5 OTHER IMPORTANT DETAILS PRICING AND SELECTION OF THE ENTERING INDEX There are usually many negative components of s N at each step . How do we choose one of these to become the index that enters the basis ? Ideally , we would like to choose the sequence of entering indices q that gets us to the solution x ∗ in the fewest possible steps , but we rarely have the global perspective needed to implement this strategy . Instead , we use more shortsighted but practical strategies that obtain a signiﬁcant decrease in c T x on just the present iteration . There is usually a tradeoff between the effort spent on ﬁnding a good entering index and the amount of decrease in c T x resulting from this choice . Different pivot strategies resolve this tradeoff in different ways . Dantzig’s original selection rule is one of the simplest . It chooses q such that s q is the most negative component of s N (cid:3) N T λ . This rule , which is motivated by ( 13 . 24 ) , gives the maximum improvement in c T x per unit increase in the entering variable x q . A large 376 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D reduction in c T x is not guaranteed , however . It could be that we can increase x + q only a tiny amount from zero ( or not at all ) before reaching the next vertex . Calculation of the entire vector s N from ( 13 . 21 ) requires a multiplication by N T , which can be expensive when the matrix N is very large . Partial pricing strategies calculate only a subvector of s N and make the choice of entering variable from among the negative entries in this subvector . To give all the indices in N a chance to enter the basis , these strategies cycle through the nonbasic elements , periodically changing the subvector of s N they evaluate so that no nonbasic index is ignored for too long . Neither of these strategies guarantees that we can make a substantial move along the chosen edge before reaching a new vertex . Multiple pricing strategies are more thorough : For a small subset of indices q ∈ N , they evaluate s q and , if s q < 0 , the maximum value of x + q that maintains feasibility of x + and the consequent change s q x + q in the objective function ( see ( 13 . 24 ) ) . Calculation of x + q requires evaluation of d (cid:3) B − 1 A q as in Procedure 13 . 1 , which is not cheap . Subsequent iterations deal with this same index subset until we reach an iteration at which all s q are nonnegative for q in the subset . At this point , the full vector s N is computed , a new subset of nonbasic indices is chosen , and the cycle begins again . This approach has the advantage that the columns of the matrix N outside the current subset of priced components need not be accessed at all , so memory access in the implementation is quite localized . Naturally , it is possible to devise heuristics that combine partial and multiple pricing in various imaginative ways . A sophisticated rule known as steepest edge chooses the “most downhill” direction from among all the candidates—the one that produces the largest decrease in c T x per unit distance moved along the edge . ( By contrast , Dantzig’s rule maximizes the decrease in c T x per unit change in x + q , which is not the same thing , as a small change in x + q can correspond to a large distance moved along the edge . ) During the pivoting step , the overall change in x is x + (cid:3) (cid:1) x + B x + N (cid:2) (cid:3) (cid:1) x B x N (cid:2) + (cid:1) − B − 1 A q e q (cid:2) x + q (cid:3) x + η q x + q , ( 13 . 32 ) where e q is the unit vector with a 1 in the position corresponding to the index q ∈ N and zeros elsewhere , and the vector η q is deﬁned as η q (cid:3) (cid:1) − B − 1 A q e q (cid:2) (cid:3) (cid:1) − d e q (cid:2) ; ( 13 . 33 ) see ( 13 . 25 ) . The change in c T x per unit step along η q is given by c T η q (cid:8) η q (cid:8) . ( 13 . 34 ) The steepest - edge rule chooses q ∈ N to minimize this quantity . 1 3 . 5 . O T H E R I M P O R T A N T D E T A I L S 377 If we had to compute each η i by solving Bd (cid:3) A i for each i ∈ N , the steepest - edge strategy would be prohibitively expensive . Goldfarb and Reid [ 134 ] showed that the measure ( 13 . 34 ) of edge steepness for all indices i ∈ N can , in fact , be updated quite economically at each iteration . We outline their steepest - edge procedure by showing how each c T η i and (cid:8) η i (cid:8) can be updated at the current iteration . First , note that we already know the numerator c T η i in ( 13 . 34 ) without calculating η i , because by taking the inner product of ( 13 . 32 ) with c and using ( 13 . 24 ) , we have that c T η i (cid:3) s i . To investigate the change in denominator (cid:8) η i (cid:8) at this step , we deﬁne γ i (cid:3) (cid:8) η i (cid:8) 2 , where this quantity is deﬁned before and after the update as follows : γ i (cid:3) (cid:8) η i (cid:8) 2 (cid:3) (cid:8) B − 1 A i (cid:8) 2 + 1 , ( 13 . 35a ) γ + i (cid:3) (cid:8) η + i (cid:8) 2 (cid:3) (cid:8) ( B + ) − 1 A i (cid:8) 2 + 1 . ( 13 . 35b ) Assume without loss of generality that the entering column A q replaces the ﬁrst column of the basis matrix B ( that is , p (cid:3) 1 ) , and that this column corresponds to the index t . We can then express the update to B as follows : B + (cid:3) B + ( A q − A t ) e T 1 (cid:3) B + ( A q − Be 1 ) e T 1 , ( 13 . 36 ) where e 1 (cid:3) ( 1 , 0 , 0 , . . . , 0 ) T . By applying the Sherman – Morrison formula ( A . 27 ) to the rank - one update formula in ( 13 . 36 ) , we obtain ( B + ) − 1 (cid:3) B − 1 − ( B − 1 A q − e 1 ) e T 1 B − 1 1 + e T 1 ( B − 1 A q − e 1 ) (cid:3) B − 1 − ( d − e 1 ) e T 1 B − 1 e T 1 d , where again we have used the fact that d (cid:3) B − 1 A q ( see ( 13 . 25 ) ) . Therefore , we have that ( B + ) − 1 A i (cid:3) B − 1 A i − e T 1 B − 1 A i e T 1 d ( d − e 1 ) . By substituting for ( B + ) − 1 A i in ( 13 . 35 ) and performing some simple manipulation , we obtain γ + i (cid:3) γ i − 2 (cid:17) e T 1 B − 1 A i e T 1 d (cid:18) A Ti B − T d + (cid:17) e T 1 B − 1 A i e T 1 d (cid:18) 2 γ q . ( 13 . 37 ) Once we solve the following two linear systems to obtain ˆ d and r : B T ˆ d (cid:3) d , B T r (cid:3) e 1 . ( 13 . 38 ) 378 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D The formula ( 13 . 37 ) then becomes γ + i (cid:3) γ i − 2 (cid:17) r T A i r T A q (cid:18) ˆ d T A i + (cid:17) r T A i r T A q (cid:18) 2 γ q . ( 13 . 39 ) Hence , the entire set of γ i values , for i ∈ N with i (cid:9)(cid:3) q , can be calculated by solving the two systems ( 13 . 38 ) and then evaluating the inner products r T A i and ˆ d T A i , for each i . The steepest - edge strategy does not guarantee that we can take a long step before reaching another vertex , but it has proved to be highly effective in practice . STARTING THE SIMPLEX METHOD The simplex method requires a basic feasible starting point x and a corresponding initial basis B ⊂ { 1 , 2 , . . . , n } with | B | (cid:3) m such that the basis matrix B deﬁned by ( 13 . 13 ) is nonsingular and x B (cid:3) B − 1 b ≥ 0 and x N (cid:3) 0 . The problem of ﬁnding this initial point and basis may itself be nontrivial—in fact , its difﬁculty is equivalent to that of actually solving a linear program . We describe here the two - phase approach that is commonly used to deal with this difﬁculty in practical implementations . In Phase I of this approach we set up an auxiliary linear program based on the data of ( 13 . 1 ) , and solve it with the simplex method . The Phase - I problem is designed so that an initial basis and initial basic feasible point is trivial to ﬁnd , and so that its solution gives a basic feasible initial point for the second phase . In Phase II , a second linear program similar to the original problem ( 13 . 1 ) is solved , with the Phase - I solution as a starting point . The solution of the original problem ( 13 . 1 ) can be extracted easily from the solution of the Phase - II problem . In Phase I we introduce artiﬁcial variables z into ( 13 . 1 ) and redeﬁne the objective function to be the sum of these artiﬁcial variables , as follows : min e T z , subject to Ax + Ez (cid:3) b , ( x , z ) ≥ 0 , ( 13 . 40 ) where z ∈ IR m , e (cid:3) ( 1 , 1 , . . . , 1 ) T , and E is a diagonal matrix whose diagonal elements are E jj (cid:3) + 1 if b j ≥ 0 , E jj (cid:3) − 1 if b j < 0 . It is easy to see that the point ( x , z ) deﬁned by x (cid:3) 0 , z j (cid:3) | b j | , j (cid:3) 1 , 2 , . . . , m , ( 13 . 41 ) is a basic feasible point for ( 13 . 40 ) . Obviously , this point satisﬁes the constraints in ( 13 . 40 ) , while the initial basis matrix B is simply the diagonal matrix E , which is clearly nonsingular . At any feasible point for ( 13 . 40 ) , the artiﬁcial variables z represent the amounts by which the constraints Ax (cid:3) b are violated by the x component . The objective function is 1 3 . 5 . O T H E R I M P O R T A N T D E T A I L S 379 simply the sum of these violations , so by minimizing this sum we are forcing x to become feasible for the original problem ( 13 . 1 ) . It is not difﬁcult to see that the Phase - I problem ( 13 . 40 ) has an optimal objective value of zero if and only if the original problem ( 13 . 1 ) is feasible , by using the following argument : If there exists a vector ( ˜ x , ˜ z ) that is feasible for ( 13 . 40 ) such that e T ˜ z (cid:3) 0 , we must have ˜ z (cid:3) 0 , and therefore A ˜ x (cid:3) b and ˜ x ≥ 0 , so ˜ x is feasible for ( 13 . 1 ) . Conversely , if ˜ x is feasible for ( 13 . 1 ) , then the point ( ˜ x , 0 ) is feasible for ( 13 . 40 ) with an objective value of 0 . Since the objective in ( 13 . 40 ) is obviously nonnegative at all feasible points , then ( ˜ x , 0 ) must be optimal for ( 13 . 40 ) , verifying our claim . In Phase I , we apply the simplex method to ( 13 . 40 ) from the initial point ( 13 . 41 ) . This linear program cannot be unbounded , because its objective function is bounded below by 0 , so the simplex method will terminate at an optimal point ( assuming that it does not cycle ; see below ) . If the objective e T z is positive at this solution , we conclude by the argument above that the original problem ( 13 . 1 ) is infeasible . Otherwise , the simplex method identiﬁes a point ( ˜ x , ˜ z ) with e T ˜ z (cid:3) 0 , which is also a basic feasible point for the following Phase - II problem : min c T x subject to Ax + z (cid:3) b , x ≥ 0 , 0 ≥ z ≥ 0 . ( 13 . 42 ) Note that this problem differs from ( 13 . 40 ) in that the objective function is replaced by the original objective c T x , while upper bounds of 0 have been imposed on z . In fact , ( 13 . 42 ) is equivalent to ( 13 . 1 ) , because any solution ( and indeed any feasible point ) must have z (cid:3) 0 . We need to retain the artiﬁcial variables z in Phase II , however , since some components of z may still be present in the optimal basis from Phase I that we are using as the initial basis for ( 13 . 42 ) , though of course the values ˜ z j of these components must be zero . In fact , we can modify ( 13 . 42 ) to include only those components of z that are present in the optimal basis for ( 13 . 40 ) . The problem ( 13 . 42 ) is not quite in standard form because of the two - sided bounds on z . However , it is easy to modify the simplex method described above to handle upper and lower bounds on the variables ( we omit the details ) . We can customize the simplex algorithm slightly by deleting each component of z from the problem ( 13 . 42 ) as soon as it is swapped out of the basis . This strategy ensures that components of z do not repeatedly enter and leave the basis , thereby avoiding unnecessary simplex iterations . If ( x ∗ , z ∗ ) is a basic solution of ( 13 . 42 ) , it must have z ∗ (cid:3) 0 , and so x ∗ is a solution of ( 13 . 1 ) . In fact , x ∗ is a basic feasible point for ( 13 . 1 ) , though this claim is not completely obvious because the ﬁnal basis B for the Phase - II problem may still contain components of z ∗ , making it unsuitable as an optimal basis for ( 13 . 1 ) . Since A has full row rank , however , we can construct an optimal basis for ( 13 . 1 ) in a postprocessing phase : Extract from B any components of z that are present , and replace them with nonbasic components of x in a way that maintains nonsingularity of the submatrix B deﬁned by ( 13 . 13 ) . A ﬁnal point to note is that in many problems we do not need to add a complete set of m artiﬁcial variables to form the Phase - I problem . This observation is particularly relevant when slack and surplus variables have already been added to the problem formulation , as 380 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D in ( 13 . 2 ) , to obtain a linear program with inequality constraints in standard form ( 13 . 1 ) . Some of these slack / surplus variables can play the roles of artiﬁcial variables , making it unnecessary to include such variables explicitly . We illustrate this point with the following example . ❏ E XAMPLE 13 . 2 Consider the inequality - constrained linear program deﬁned by min 3 x 1 + x 2 + x 3 subject to 2 x 1 + x 2 + x 3 ≤ 2 , x 1 − x 2 − x 3 ≤ − 1 , x ≥ 0 . By adding slack variables to both inequality constraints , we obtain the following equivalent problem in standard form : min 3 x 1 + x 2 + x 3 subject to 2 x 1 + x 2 + x 3 + x 4 (cid:3) 2 , x 1 − x 2 − x 3 + x 5 (cid:3) − 1 , x ≥ 0 . By inspection , it is easy to see that the vector x (cid:3) ( 0 , 0 , 0 , 2 , 0 ) is feasible with respect to the ﬁrst linear constraint and the lower bound x ≥ 0 , though it does not satisfy the second constraint . Hence , in forming the Phase - I problem , we add just a single artiﬁcial variable z 2 to the second constraint and obtain min z 2 subject to ( 13 . 43 ) 2 x 1 + x 2 + x 3 + x 4 (cid:3) 2 , ( 13 . 44 ) x 1 − x 2 − x 3 + x 5 − z 2 (cid:3) − 1 , ( 13 . 45 ) ( x , z 2 ) ≥ 0 . ( 13 . 46 ) It is easy to see that the vector ( x , z 2 ) (cid:3) ( ( 0 , 0 , 0 , 2 , 0 ) , 1 ) is feasible with respect to ( 13 . 43 ) . In fact , it is a basic feasible point , since the corresponding basis matrix B is B (cid:3) (cid:1) 1 0 0 − 1 (cid:2) , whichisclearlynonsingular . Inthisexample , thevariable x 4 playstheroleofartiﬁcialvariable for the ﬁrst constraint . There was no need to add an explicit artiﬁcial variable z 1 . ❐ 1 3 . 5 . O T H E R I M P O R T A N T D E T A I L S 381 DEGENERATE STEPS AND CYCLING As noted above , the simplex method may encounter situations in which for the entering index q , we cannot set x + q any greater than zero in ( 13 . 22 ) without violating the nonnegativity condition x + ≥ 0 . By referring to Procedure 13 . 1 , we see that these situations arise when there is i with ( x B ) i (cid:3) 0 and d i < 0 , where d is deﬁned by ( 13 . 25 ) . Steps of this type are called degenerate steps . On such steps , the components of x do not change and , therefore , the objective function c T x does not decrease . However , the steps may still be useful because they change the basis B ( by replacing one index ) , and the updated B may be closer to the optimal basis . In other words , the degenerate step may be laying the groundwork for reductions in c T x on later steps . Sometimes , however , a phenomenon known as cycling can occur . After a number of successive degenerate steps , we may return to an earlier basis B . If we continue to apply the algorithm from this point using the same rules for selecting entering and leaving indices , we will repeat the same cycle ad inﬁnitum , never converging . Cycling was once thought to be a rare phenomenon , but in recent times it has been observed frequently in the large linear programs that arise as relaxations of integer pro - gramming problems . Since integer programs are an important source of linear programs , practical simplex codes usually incorporate a cycling avoidance strategy . In the remainder of this section , we describe a perturbation strategy and its close relative , the lexicographic strategy . Suppose that a degenerate basis is encountered at some simplex iteration , at which the basis is ˆ B and the basis matrix is ˆ B , say . We consider a modiﬁed linear program in which we add a small perturbation to the right - hand side of the constraints in ( 13 . 1 ) , as follows : b ( (cid:9) ) (cid:3) b + ˆ B ⎡ ⎢⎢⎢⎢⎢⎣ (cid:9) (cid:9) 2 . . . (cid:9) m ⎤ ⎥⎥⎥⎥⎥⎦ , where (cid:9) is a very small positive number . This perturbation in b induces a perturbation in the components of the basic solution vector ; we have x ˆ B ( (cid:9) ) (cid:3) x ˆ B + ⎡ ⎢⎢⎢⎢⎢⎣ (cid:9) (cid:9) 2 . . . (cid:9) m ⎤ ⎥⎥⎥⎥⎥⎦ . ( 13 . 47 ) 382 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D Retaining the perturbation for subsequent iterations , we see that subsequent basic solutions have the form x B ( (cid:9) ) (cid:3) x B + B − 1 ˆ B ⎡ ⎢⎢⎢⎢⎢ ⎣ (cid:9) (cid:9) 2 . . . (cid:9) m ⎤ ⎥⎥⎥⎥⎥ ⎦ (cid:3) x B + m (cid:3) k (cid:3) 1 ( B − 1 ˆ B ) · k (cid:9) k , ( 13 . 48 ) where ( B − 1 ˆ B ) · k denotes the k th column of B − 1 ˆ B and x B represents the basic solution for the unperturbed right - hand side b . From ( 13 . 47 ) , we have that for all (cid:9) sufﬁciently small ( but positive ) , ( x ˆ B ( (cid:9) ) ) i > 0 for all i . Hence , the basis is nondegenerate for the perturbed problem , and we can perform a step of the simplex method that produces a nonzero ( but tiny ) decrease in the objective . Indeed , if we retain the perturbation over all subsequent iterations , and provided that the initial choice of (cid:9) was small enough , we claim that all subsequent bases visited by the algorithm are nondegenerate . We prove this claim by contradiction , by assuming that there is some basis matrix B such that ( x B ( (cid:9) ) ) i (cid:3) 0 for some i and all (cid:9) sufﬁciently small . From ( 13 . 48 ) , we see that this can happen only when ( x B ) i (cid:3) 0 and ( B − 1 ¯ B ) ik (cid:3) 0 for k (cid:3) 1 , 2 , . . . , m . The latter relation implies that the i th row of B − 1 ¯ B is zero , which cannot occur , because both B and ¯ B are nonsingular . We conclude that , provided the initial choice of (cid:9) is sufﬁciently small to ensure nondegeneracy of all subsequent bases , no basis is visited more than once by the simplex method and therefore , by the same logic as in the proof of Theorem 13 . 4 , the method terminates ﬁnitely at a solution of the perturbed problem . The perturbation can be removed in a postprocessing phase , by resetting x B (cid:3) B − 1 b for the ﬁnal basis B and the original right - hand side b . The question remains of how to choose (cid:9) small enough at the point at which the original degenerate basis ˆ B is encountered . The lexicographic strategy ﬁnesses this issue by not making an explicit choice of (cid:9) , but rather keeping track of the dependence of each basic variable on each power of (cid:9) . When it comes to selecting the leaving variable , it chooses the index p that minimizes ( x B ( (cid:9) ) ) i / d i over all variables in the basis , for all sufﬁciently small (cid:9) . ( The choice of p is uniquely deﬁned by this procedure , as we can show by an argument similar to the one above concerning nondenegeracy of each basis . ) We can extend the pivot procedure slightly to update the dependence of each basic variable on the powers of (cid:9) at each iteration , including the variable x q that has just entered the basis . 13 . 6 THE DUAL SIMPLEX METHOD Herewedescribeanothervariantofthesimplexmethodthatisusefulinavarietyofsituations and is often faster on many practical problems than the variant described above . This dual 1 3 . 6 . T H E D U A L S I M P L E X M E T H O D 383 simplex method uses many of the same concepts and methodology described above , such as the splitting of the matrix A into column submatrices B and N and the generation of iterates ( x , λ , s ) that satisfy the complementarity condition x T s (cid:3) 0 . The method of Section 13 . 3 starts with a feasible x ( with x B ≥ 0 and x N (cid:3) 0 ) and a corresponding dual iterate ( λ , s ) for which s B (cid:3) 0 but s N is not necessarily nonnegative . After making systematic column interchanges between B and N , it ﬁnally reaches a feasible dual point ( λ , s ) at which s N ≥ 0 , thus yielding a solution of both the primal problem ( 13 . 1 ) and the dual ( 13 . 8 ) . By contrast , the dual simplex method starts with a point ( λ , s ) feasible for ( 13 . 8 ) , at which s N ≥ 0 and s B (cid:3) 0 , and a corresponding primal feasible point x for which x N (cid:3) 0 but x B is not necessarily nonnegative . By making systematic column interchanges between B and N , it ﬁnally reaches a feasible primal point x for which x B ≥ 0 , signifying optimality . Note that although the matrix B used in this algorithm is a nonsingular column submatrix of A , it is no longer correct to refer to it as a basis matrix , since it does not satisfy the feasibility condition x B (cid:3) B − 1 b ≥ 0 . We now describe a single step of this method in a similar fashion to Section 13 . 3 , though the details are a little more complicated here . As mentioned above , we commence each step with submatrices B and N of A , and corresponding sets B and N . The primal and dual variables corresponding to these sets are deﬁned as follows ( cf . ( 13 . 18 ) , ( 13 . 20 ) , and ( 13 . 21 ) ) : x B (cid:3) B − 1 b , x N (cid:3) 0 , ( 13 . 49a ) λ (cid:3) B − T c B , ( 13 . 49b ) s B (cid:3) c B − B T λ (cid:3) 0 , s N (cid:3) c N − N T λ ≥ 0 , ( 13 . 49c ) If x B ≥ 0 , the current point ( x , λ , s ) satisﬁes the optimality conditions ( 13 . 4 ) , and we are done . Otherwise , we select a leaving index q ∈ B such that x q < 0 . Our aim is to move x q to zero ( thereby ensuring that nonnegativity holds for this component ) , while allowing s q to increase away from zero . We will also identify an entering index r ∈ N , such that s r becomes zero on this step while x r increases away from zero . Hence , the index q will move from B to N , while r will move from N to B . How do we choose r , and how are x , λ , and s changed on this step ? The description below provides the answer . We use ( x + , λ + , s + ) to denote the updated values of our variables , after this step is taken . First , let e q the vector of length m that contains all zeros except for a 1 in the position occupied by index q in the set B . Since we increase s q away from zero while ﬁxing the remaining components of s B at zero , the updated value s + B will have the form s + B (cid:3) s B + α e q ( 13 . 50 ) for some positive scalar α to be determined . We write the corresponding update to λ as λ + (cid:3) λ + αv , ( 13 . 51 ) 384 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D for some vector v . In fact , since s + B and λ + must satisfy the ﬁrst equation in ( 13 . 49c ) , we must have s + B (cid:3) c B − B T λ + ⇒ s B + α e q (cid:3) c B − B T ( λ + αv ) ⇒ e q (cid:3) − B T v , ( 13 . 52 ) which is a system of equations that we can solve to obtain v . To see how the dual objective value b T λ changes as a result of this step , we use ( 13 . 52 ) and the fact that x q (cid:3) x T B e q to obtain b T λ + (cid:3) b T λ + α b T v (cid:3) b T λ − α b T B − T e q from ( 13 . 52 ) (cid:3) b T λ − α x T B e q from ( 13 . 49a ) (cid:3) b T λ − α x q by deﬁnition of e q . Since x q < 0 and since our aim is to maximize the dual objective , we would like to choose α as large as possible . The upper bound on α is provided by the constraint s + N ≥ 0 . Similarly to ( 13 . 49c ) , we have s + N (cid:3) c N − N T λ + (cid:3) s N − α N T v (cid:3) s N − αw , where we have deﬁned w (cid:3) N T v (cid:3) − N T B − T e q . The largest α for which s + N ≥ 0 is given by the formula α (cid:3) min j ∈ N , w j > 0 s j w j . We deﬁne the entering index r to be the index at which the minimum in this expression is achieved . Note that s + r (cid:3) 0 and w r (cid:3) A Tr v > 0 , ( 13 . 53 ) where , as usual , A r denotes the r th column of A . Having now identiﬁed how λ and s are updated on this step , we need to ﬁgure out how x changes . For the leaving index q , we need to set x + q (cid:3) 0 , while for the entering index r we can allow x + r to be nonzero . We denote the direction of change for x B to be the vector 1 3 . 7 . P R E S O L V I N G 385 d , deﬁned by the following linear system : Bd (cid:3) (cid:3) i ∈ B A i d i (cid:3) A r . ( 13 . 54 ) Since from ( 13 . 49a ) , we have (cid:3) i ∈ B A i x i (cid:3) b , we have that (cid:3) i ∈ B A i ( x i − γ d i ) + A r γ (cid:3) b , ( 13 . 55 ) for any scalar γ . To ensure that x + q (cid:3) 0 , we set γ (cid:3) x q d q , ( 13 . 56 ) which is well deﬁned only if d q is nonzero . In fact , we have that d q < 0 , since d q (cid:3) d T e q (cid:3) A Tr B − T e q (cid:3) − A Tr v (cid:3) − w r < 0 , where we have used the deﬁnition of e q along with ( 13 . 54 ) , ( 13 . 52 ) , and ( 13 . 53 ) to derive these relationships . Since x q < 0 , it follows from ( 13 . 56 ) that γ > 0 . Following ( 13 . 55 ) we can deﬁne the updated vector x + as follows : x + i (cid:3) ⎧ ⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎩ x i − γ d i , for i ∈ B with i (cid:9)(cid:3) q , 0 , for i (cid:3) q , 0 , for i ∈ N with i (cid:9)(cid:3) r , γ , for i (cid:3) r . 13 . 7 PRESOLVING Presolving ( also known as preprocessing ) is carried out in practical linear programming codes to reduce the size of the user - deﬁned linear programming problem before passing it to the solver . A variety of techniques—some obvious , some ingenious—are used to eliminate certain variables , constraints , and bounds from the problem . Often the reduction in problem size is quite dramatic , and the linear programming algorithm takes much less time when applied to the presolved problem than when applied to the original problem . Presolving is 386 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D beneﬁcial regardless of what algorithm is used to solve the linear program ; it is used both in simplex and interior - point codes . Infeasibility may also be detected by the presolver , eliminating the need to call the linear programming algorithm at all . We mention just a few of the more straightforward preprocessing techniques here , referring the interested reader to Andersen and Andersen [ 4 ] for a more comprehensive list . For the purpose of this discussion , we assume that the linear program is formulated with both lower and upper bounds on x , that is , min c T x , subject to Ax (cid:3) b , l ≤ x ≤ u , ( 13 . 57 ) where some components l i of the lower bound vector may be −∞ and some upper bounds u i may be + ∞ . Consider ﬁrst a row singleton , which happens when one of the equality constraints involves just one of the variables . Speciﬁcally , if constraint k involves only variable j ( that is , A kj (cid:9)(cid:3) 0 , but A ki (cid:3) 0 for all i (cid:9)(cid:3) j ) , we can immediately set x j (cid:3) b k / A kj and eliminate x j from the problem . Note that if this value of x j violates its bounds ( that is , x j < l j or x j > u j ) , we can declare the problem to be infeasible , and terminate . Another obvious technique is the free column singleton , in which there is a variable x j that occurs in only one of the equality constraints , and is free ( that is , its lower bound is −∞ and its upper bound is + ∞ ) . In this case , we have for some k that A kj (cid:9)(cid:3) 0 while A lj (cid:3) 0 for all l (cid:9)(cid:3) k . Here we can simply use constraint k to eliminate x j from the problem , setting x j (cid:3) b k − (cid:4) p (cid:9)(cid:3) j A kp x p A kj . Once the values of x p for p (cid:9)(cid:3) j have been obtained by solving a reduced linear program , we can substitute into this formula to recover x j prior to returning the result to the user . This substitution does not require us to modify any other constraints , but it will change the cost vector c in general , whenever c j (cid:9)(cid:3) 0 . We will need to make the replacement c p ← c p − c j A kp / A kj , for all p (cid:9)(cid:3) j . In this case , we can also determine the dual variable associated with constraint k . Since x j is a free variable , there is no dual slack associated with it , so the j th dual constraint becomes m (cid:3) l (cid:3) 1 A lj λ l (cid:3) c j ⇒ A kj λ k (cid:3) c j , from which we deduce that λ k (cid:3) c j / A kj . Perhaps the simplest preprocessing check is for the presence of zero rows and columns in A . If A ki (cid:3) 0 for all i (cid:3) 1 , 2 , . . . , n , then provided that the right - hand side is also zero ( b k (cid:3) 0 ) , we can simply delete this row from the problem and set the corresponding 1 3 . 7 . P R E S O L V I N G 387 Lagrange multiplier λ k to an arbitrary value . For a zero column—say , A kj (cid:3) 0 for all k (cid:3) 1 , 2 , . . . , m —we can determing the optimal value of x j by inspecting its cost coefﬁcient c j and its bounds l j and u j . If c j < 0 , we set x j (cid:3) u j to minimize the product c j x j . ( We are free to do so because x j is not restricted by any of the equality constraints . ) If c j < 0 and u j (cid:3) + ∞ , then the problem is unbounded . Similarly , if c j > 0 , we set x j (cid:3) l j , or else declare unboundedness if l j (cid:3) −∞ . A somewhat more subtle presolving technique is to check for forcing or dominated constraints . Rather than give a general speciﬁcation , we illustrate this case with a simple example . Suppose that one of the equality constraints is as follows : 5 x 1 − x 4 + 2 x 5 (cid:3) 10 , where the variables in question have the following bounds : 0 ≤ x 1 ≤ 1 , − 1 ≤ x 4 ≤ 5 , 0 ≤ x 5 ≤ 2 . It is not hard to see that the equality constraint can only be satisﬁed if x 1 and x 5 are at their upper bounds and x 4 is at its lower bound . Any other feasible values of these variables would result in the left - hand side of the equality constraint being strictly less than 10 . Hence , we can set x 1 (cid:3) 1 , x 4 (cid:3) − 1 , x 5 (cid:3) 2 and eliminate these variables , and the equality constraint , from the problem . We use a similar example to illustrate dominated constraints . Suppose that we have the following constraint involving three variables : 2 x 2 + x 6 − 3 x 7 (cid:3) 8 , where the variables in question have the following bounds : − 10 ≤ x 2 ≤ 10 , 0 ≤ x 6 ≤ 1 , 0 ≤ x 7 ≤ 2 . By rearranging the constraint and using the bounds on x 6 and x 7 , we ﬁnd that x 2 (cid:3) 4 − ( 1 / 2 ) x 6 + ( 3 / 2 ) x 7 ≤ 4 − 0 + ( 3 / 2 ) 2 (cid:3) 7 . and similarly , using the opposite bounds on x 6 and x 7 we obtain x 2 ≥ 7 / 2 . We conclude that the stated bounds of − 10 and 10 on x 2 are redundant , since x 2 is implicitly conﬁned to an even smaller interval by the combination of the equality constraint and the bounds on x 6 and x 7 . Hence , we can drop the bounds on x 2 from the formulation and treat it as a free variable . Presolving techniques are applied recursively , because the elimination of certain vari - ablesorconstraintsmaycreatesituationsthatallowfurthereliminations . Asatrivialexample , 388 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D suppose that the following two equality constraints are present in the problem : 3 x 2 (cid:3) 6 , x 2 + 4 x 5 (cid:3) 10 . The ﬁrst of these constraints is a row singleton , which we can use to set x 2 (cid:3) 2 and eliminate this variable and constraint . After substitution , the second constraint becomes 4 x 5 (cid:3) 10 − x 2 (cid:3) 8 , which is again a row singleton . We can therefore set x 5 (cid:3) 2 and eliminate this variable and constraint as well . Relatively little information about presolving techniques has appeared in the liter - ature , in part because they have commercial value as an important component of linear programming software . 13 . 8 WHERE DOES THE SIMPLEX METHOD FIT ? In linear programming , as in all optimization problems in which inequality constraints are present , the fundamental task of the algorithm is to determine which of these constraints are active at the solution ( see Deﬁnition 12 . 1 and which are inactive . The simplex method belongs to a general class of algorithms for constrained optimization known as active set methods , which explicitly maintain estimates of the active and inactive index sets that are updated at each step of the algorithm . ( At each iteration , the basis B is our current estimate of the inactive set , that is , the set of indices i for which we suspect that x i > 0 at the solution of the linear program . ) Like most active set methods , the simplex method makes only modest changes to these index sets at each step ; a single index is exchanged between B into N . Active set algorithms for quadratic programming , bound - constrained optimization , and nonlinear programming use the same basic strategy as simplex of making an explicit estimate of the active set and taking a step toward the solution of a reduced problem in which theconstraintsinthisestimatedactivesetaresatisﬁedasequalities . Whennonlinearityenters the problem , many of the features that make the simplex method so effective no longer apply . For example , it is no longer true in general that at least n − m of the bounds x ≥ 0 are active at the solution , and the specialized linear algebra techniques described in Section 13 . 5 no longer apply . Nevertheless , the simplex method is rightly viewed as the antecedent of the active set class of methods for constrained optimization . One undesirable feature of the simplex method attracted attention from its earliest days . Thoughhighlyefﬁcientonalmostallpracticalproblems ( themethodgenerallyrequires at most 2 m to 3 m iterations , where m is the row dimension of the constraint matrix in ( 13 . 1 ) ) , there are pathological problems on which the algorithm performs very poorly . Klee and Minty [ 182 ] presented an n - dimensional problem whose feasible polytope has 2 n vertices , for which the simplex method visits every single vertex before reaching the optimal point ! This example veriﬁed that the complexity of the simplex method is exponential ; 1 3 . 8 . W H E R E D O E S T H E S I M P L E X M E T H O D F I T ? 389 roughly speaking , its running time may be an exponential function of the dimension of the problem . For many years , theoreticians searched for a linear programming algorithm that has polynomial complexity , that is , an algorithm in which the running time is bounded by a polynomial function of the amount of storage required to deﬁne the problem . In the late 1970s , Khachiyan [ 180 ] described an ellipsoid method that indeed has polynomial complexity but turned out to be impractical . In the mid - 1980s , Karmarkar [ 175 ] described a polynomial algorithm that approaches the solution through the interior of the feasible polytope rather than working its way around the boundary as the simplex method does . Karmarkar’s announcement marked the start of intense research in the ﬁeld of interior - point methods , which are the subject of the next chapter . NOTES AND REFERENCES The standard reference for the simplex method is Dantzig’s book [ 86 ] . Later excellent texts include Chv´atal [ 61 ] and Vanderbei [ 293 ] . Further information on steepest - edge pivoting can be found in Goldfarb and Reid [ 134 ] and Goldfarb and Forrest [ 133 ] . An alternative procedure for performing the Phase - I calculation of an initial basis was described by Wolfe [ 310 ] . This technique does not require artiﬁcial variables to be introduced in the problem formulation , but rather starts at any point x that satisﬁes Ax (cid:3) b with at most m nonzero components in x . ( Note that we do not require the basic part x B to consist of all positive components . ) Phase I then consists in solving the problem min x (cid:3) x i < 0 − x i subject to Ax (cid:3) b , and terminating when an objective value of 0 is attained . This problem is not a linear program—its objective is only piecewise linear—but it can be solved by the simplex method nonetheless . The key is to redeﬁne the cost vector f at each iteration x such that f i (cid:3) − 1 for x i < 0 and f i (cid:3) 0 otherwise . ✐ E X E R C I S E S ✐ 13 . 1 Convert the following linear program to standard form : max x , y c T x + d T y subject to A 1 x (cid:3) b 1 , A 2 x + B 2 y ≤ b 2 , l ≤ y ≤ u , where there are no explicit bounds on x . ✐ 13 . 2 Verify that the dual of ( 13 . 8 ) is the original primal problem ( 13 . 1 ) . 390 C H A P T E R 1 3 . T H E S I M P L E X M E T H O D ✐ 13 . 3 Complete the proof of Theorem 13 . 1 by showing that if the dual ( 13 . 7 ) is unbounded above , the primal ( 13 . 1 ) must be infeasible . ✐ 13 . 4 Theorem 13 . 1 does not exclude the possibility that both primal and dual are infeasible . Give a simple linear program for which such is the case . ✐ 13 . 5 Show that the dual of the linear program min c T x subject to Ax ≥ b , x ≥ 0 , is max b T λ subject to A T λ ≤ c , λ ≥ 0 . ✐ 13 . 6 Show that when m ≤ n and the rows of A are linearly dependent in ( 13 . 1 ) , then the matrix B in ( 13 . 13 ) is singular , and therefore there are no basic feasible points . ✐ 13 . 7 Consider the overdetermined linear system Ax (cid:3) b with m rows and n columns ( m > n ) . When we apply Gaussian elimination with complete pivoting to A , we obtain P AQ (cid:3) L (cid:1) U 11 U 12 0 0 (cid:2) , where P and Q are permutation matrices , L is m × m lower triangular , U 11 is ¯ m × ¯ m upper triangular and nonsingular , U 12 is ¯ m × ( n − ¯ m ) , and ¯ m ≤ n is the rank of A . ( a ) Show that the system Ax (cid:3) b is feasible if the last m − ¯ m components of L − 1 Pb are zero , and infeasible otherwise . ( b ) When ¯ m (cid:3) n , ﬁnd the unique solution of Ax (cid:3) b . ( c ) Show that the reduced system formed from the ﬁrst ¯ m rows of P A and the ﬁrst ¯ m components of Pb is equivalent to Ax (cid:3) b ( i . e . , a solution of one system also solves the other ) . ✐ 13 . 8 Verify formula ( 13 . 37 ) . ✐ 13 . 9 Consider the following linear program : min − 5 x 1 − x 2 subject to x 1 + x 2 ≤ 5 , 2 x 1 + ( 1 / 2 ) x 2 ≤ 8 , x ≥ 0 . 1 3 . 8 . W H E R E D O E S T H E S I M P L E X M E T H O D F I T ? 391 ( a ) Add slack variables x 3 and x 4 to convert this problem to standard form . ( b ) Using Procedure 13 . 1 , solve this problem using the simplex method , showing at each step the basis and the vectors λ , s N , and x B , and the value of the objective function . ( The initial choice of B for which x B ≥ 0 should be obvious once you have added the slacks in part ( a ) . ) ✐ 13 . 10 Calculate the values of l 52 , l 53 , l 54 , and ˆ w 2 in ( 13 . 30 ) , by equating the last row of L 1 U 1 to the last row of the matrix in ( 13 . 29 ) . ✐ 13 . 11 By extending the procedure ( 13 . 27 ) appropriately , show how the factorization ( 13 . 31 ) can be used to solve linear systems with coefﬁcient matrix B + efﬁciently . This is pag Printer : O C H A P T E R 14 Linear Programming : Interior - Point Methods In the 1980s it was discovered that many large linear programs could be solved efﬁciently by using formulations and algorithms from nonlinear programming and nonlinear equations . One characteristic of these methods was that they required all iterates to satisfy the inequality constraints in the problem strictly , so they became known as interior - point methods . By the early 1990s , a subclass of interior - point methods known as primal - dual methods had distinguished themselves as the most efﬁcient practical approaches , and proved to be strong competitors to the simplex method on large problems . These methods are the focus of this chapter . 1 4 . 1 . P R I M A L - D U A L M E T H O D S 393 Interior - point methods arose from the search for algorithms with better theoretical propertiesthanthesimplexmethod . AswementionedinChapter13 , thesimplexmethodcan be inefﬁcient on certain pathological problems . Roughly speaking , the time required to solve a linear program may be exponential in the size of the problem , as measured by the number of unknowns and the amount of storage needed for the problem data . For almost all practical problems , the simplex method is much more efﬁcient than this bound would suggest , but its poor worst - case complexity motivated the development of new algorithms with better guaranteed performance . The ﬁrst such method was the ellipsoid method , proposed by Khachiyan [ 180 ] , which ﬁnds a solution in time that is at worst polynomial in the problem size . Unfortunately , this method approaches its worst - case bound on all problems and is not competitive with the simplex method in practice . Karmarkar’s projective algorithm [ 175 ] , announced in 1984 , also has the polynomial complexity property , but it came with the added attraction of good practical behavior . The initial claims of excellent performance on large linear programs were never fully borne out , but the announcement prompted a great deal of research activity which gave rise to many new methods . All are related to Karmarkar’s original algorithm , and to the log - barrier approach described in Chapter 19 , but many of the approaches can be motivated and analyzed independently of the earlier methods . Interior - pointmethodssharecommonfeaturesthatdistinguishthemfromthesimplex method . Each interior - point iteration is expensive to compute and can make signiﬁcant progress towards the solution , while the simplex method usually requires a larger number of inexpensive iterations . Geometrically speaking , the simplex method works its way around the boundary of the feasible polytope , testing a sequence of vertices in turn until it ﬁnds the optimal one . Interior - point methods approach the boundary of the feasible set only in the limit . They may approach the solution either from the interior or the exterior of the feasible region , but they never actually lie on the boundary of this region . In this chapter , we outline some of the basic ideas behind primal - dual interior - point methods , including the relationship to Newton’s method and homotopy methods and the concept of the central path . We sketch the important methods in this class , and give a com - prehensive convergence analysis of a particular interior - point method known as a long - step path - following method . We describe in some detail a practical predictor - corrector algorithm proposed by Mehrotra , which is the basis of much of the current generation of software . 14 . 1 PRIMAL - DUAL METHODS OUTLINE We consider the linear programming problem in standard form ; that is , min c T x , subject to Ax (cid:3) b , x ≥ 0 , ( 14 . 1 ) where c and x are vectors in IR n , b is a vector in IR m , and A is an m × n matrix with full row 394 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S rank . ( As in Chapter 13 , we can preprocess the problem to remove dependent rows from A if necessary . ) The dual problem for ( 14 . 1 ) is max b T λ , subject to A T λ + s (cid:3) c , s ≥ 0 , ( 14 . 2 ) where λ is a vector in IR m and s is a vector in IR n . As shown in Chapter 13 , solutions of ( 14 . 1 ) , ( 14 . 2 ) are characterized by the Karush – Kuhn – Tucker conditions ( 13 . 4 ) , which we restate here as follows : A T λ + s (cid:3) c , ( 14 . 3a ) Ax (cid:3) b , ( 14 . 3b ) x i s i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , n , ( 14 . 3c ) ( x , s ) ≥ 0 . ( 14 . 3d ) Primal - dual methods ﬁnd solutions ( x ∗ , λ ∗ , s ∗ ) of this system by applying variants of Newton’s method to the three equalities in ( 14 . 3 ) and modifying the search directions and step lengths so that the inequalities ( x , s ) ≥ 0 are satisﬁed strictly at every iteration . The equations ( 14 . 3a ) , ( 14 . 3b ) , ( 14 . 3c ) are linear or only mildly nonlinear and so are not difﬁcult to solve by themselves . However , the problem becomes much more difﬁcult when we add the nonnegativity requirement ( 14 . 3d ) , which gives rise to all the complications in the design and analysis of interior - point methods . To derive primal - dual interior - point methods we restate the optimality conditions ( 14 . 3 ) in a slightly different form by means of a mapping F from IR 2 n + m to IR 2 n + m : F ( x , λ , s ) (cid:3) ⎡ ⎢⎣ A T λ + s − c Ax − b X Se ⎤ ⎥⎦ (cid:3) 0 , ( 14 . 4a ) ( x , s ) ≥ 0 , ( 14 . 4b ) where X (cid:3) diag ( x 1 , x 2 , . . . , x n ) , S (cid:3) diag ( s 1 , s 2 , . . . , s n ) , ( 14 . 5 ) and e (cid:3) ( 1 , 1 , . . . , 1 ) T . Primal - dual methods generate iterates ( x k , λ k , s k ) that satisfy the bounds ( 14 . 4b ) strictly , that is , x k > 0 and s k > 0 . This property is the origin of the term interior - point . By respecting these bounds , the methods avoid spurious solutions , that is , points that satisfy F ( x , λ , s ) (cid:3) 0 but not ( x , s ) ≥ 0 . Spurious solutions abound , and do not provide useful information about solutions of ( 14 . 1 ) or ( 14 . 2 ) , so it makes sense to exclude them altogether from the region of search . Like most iterative algorithms in optimization , primal - dual interior - point methods have two basic ingredients : a procedure for determining the step and a measure of the 1 4 . 1 . P R I M A L - D U A L M E T H O D S 395 desirability of each point in the search space . An important component of the measure of desirability is the average value of the pairwise products x i s i , i (cid:3) 1 , 2 , . . . , n , which are all positive when x > 0 and s > 0 . This quantity is known as the duality measure and is deﬁned as follows : µ (cid:3) 1 n n (cid:3) i (cid:3) 1 x i s i (cid:3) x T s n . ( 14 . 6 ) The procedure for determining the search direction has its origins in Newton’s method for the nonlinear equations ( 14 . 4a ) . Newton’s method forms a linear model for F around the current point and obtains the search direction ( (cid:6) x , (cid:6)λ , (cid:6) s ) by solving the following system of linear equations : J ( x , λ , s ) ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) − F ( x , λ , s ) , where J is the Jacobian of F . ( See Chapter 11 for a detailed discussion of Newton’s method for nonlinear systems . ) If we use the notation r c and r b for the ﬁrst two block rows in F , that is , r b (cid:3) Ax − b , r c (cid:3) A T λ + s − c , ( 14 . 7 ) we can write the Newton equations as follows : ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r c − r b − X Se ⎤ ⎥⎦ . ( 14 . 8 ) Usually , a full step along this direction would violate the bound ( x , s ) ≥ 0 , so we perform a line search along the Newton direction and deﬁne the new iterate as ( x , λ , s ) + α ( (cid:6) x , (cid:6)λ , (cid:6) s ) , for some line search parameter α ∈ ( 0 , 1 ] . We often can take only a small step along this direction ( α (cid:24) 1 ) before violating the condition ( x , s ) > 0 . Hence , the pure Newton direction ( 14 . 8 ) , sometimes known as the afﬁne scaling direction , often does not allow us to make much progress toward a solution . Most primal - dual methods use a less aggressive Newton direction , one that does not aim directly for a solution of ( 14 . 3a ) , ( 14 . 3b ) , ( 14 . 3c ) but rather for a point whose pairwise products x i s i are reduced to a lower average value—not all the way to zero . Speciﬁcally , we 396 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S take a Newton step toward the a point for which x i s i (cid:3) σµ , where µ is the current duality measure and σ ∈ [ 0 , 1 ] is the reduction factor that we wish to achieve in the duality measure on this step . The modiﬁed step equation is then ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r c − r b − X Se + σµ e ⎤ ⎥⎦ . ( 14 . 9 ) We call σ the centering parameter , for reasons to be discussed below . When σ > 0 , it usually is possible to take a longer step α along the direction deﬁned by ( 14 . 16 ) before violating the bounds ( x , s ) ≥ 0 . At this point , we have speciﬁed most of the elements of a path - following primal - dual interior - point method . The general framework for such methods is as follows . Framework 14 . 1 ( Primal - Dual Path - Following ) . Given ( x 0 , λ 0 , s 0 ) with ( x 0 , s 0 ) > 0 ; for k (cid:3) 0 , 1 , 2 , . . . Choose σ k ∈ [ 0 , 1 ] and solve ⎡ ⎢⎣ 0 A T I A 0 0 S k 0 X k ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x k (cid:6)λ k (cid:6) s k ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r kc − r kb − X k S k e + σ k µ k e ⎤ ⎥⎦ , ( 14 . 10 ) where µ k (cid:3) ( x k ) T s k / n ; Set ( x k + 1 , λ k + 1 , s k + 1 ) (cid:3) ( x k , λ k , s k ) + α k ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) , ( 14 . 11 ) choosing α k so that ( x k + 1 , s k + 1 ) > 0 . end ( for ) . Thechoicesofcenteringparameter σ k andsteplength α k arecrucialtotheperformance of the method . Techniques for controlling these parameters , directly and indirectly , give rise to a wide variety of methods with diverse properties . Although software for implementing interior - point methods does not usually start from a point ( x 0 , λ 0 , s 0 ) that is feasible with respect to the linear equations ( 14 . 3a ) and ( 14 . 3b ) , most of the historical development of theory and algorithms assumed that these conditions are satisﬁed . In the remainder of this section , we discuss this feasible case , showing that a comprehensive convergence analysis can be presented in just a few pages , using only basic mathematical tools and concepts . Analysis of the infeasible case follows the 1 4 . 1 . P R I M A L - D U A L M E T H O D S 397 same principles , but is considerably more complicated in the details , so we do not present it here . In Section 14 . 2 , however , we describe a complete practical algorithm that does not require starting from a feasible initial point . To begin our discussion and analysis of feasible interior - point methods , we introduce the concept of the central path , and then describe neighborhoods of this path . THE CENTRAL PATH The primal - dual feasible set F and strictly feasible set F o are deﬁned as follows : F (cid:3) { ( x , λ , s ) | Ax (cid:3) b , A T λ + s (cid:3) c , ( x , s ) ≥ 0 } , ( 14 . 12a ) F o (cid:3) { ( x , λ , s ) | Ax (cid:3) b , A T λ + s (cid:3) c , ( x , s ) > 0 } . ( 14 . 12b ) The central path C is an arc of strictly feasible points that plays a vital role in primal - dual algorithms . It is parametrized by a scalar τ > 0 , and each point ( x τ , λ τ , s τ ) ∈ C satisﬁes the following equations : A T λ + s (cid:3) c , ( 14 . 13a ) Ax (cid:3) b , ( 14 . 13b ) x i s i (cid:3) τ , i (cid:3) 1 , 2 , . . . , n , ( 14 . 13c ) ( x , s ) > 0 . ( 14 . 13d ) These conditions differ from the KKT conditions only in the term τ on the right - hand side of ( 14 . 13c ) . Instead of the complementarity condition ( 14 . 3c ) , we require that the pairwise products x i s i have the same ( positive ) value for all indices i . From ( 14 . 13 ) , we can deﬁne the central path as C (cid:3) { ( x τ , λ τ , s τ ) | τ > 0 } . It can be shown that ( x τ , λ τ , s τ ) is deﬁned uniquely for each τ > 0 if and only if F o is nonempty . The conditions ( 14 . 13 ) are also the optimality conditions for a logarithmic - barrier formulation of the problem ( 14 . 1 ) . By introducing log - barrier terms for the nonnegativity constraints , with barrier parameter τ > 0 , we obtain min c T x − τ n (cid:3) i (cid:3) 1 ln x i , subject to Ax (cid:3) b . ( 14 . 14 ) 398 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S The KKT conditions ( 12 . 34 ) for this problem , with Lagrange multiplier λ for the equality constraint , are as follows : c i − τ x i − A T · i λ , i (cid:3) 1 , 2 , . . . , n , Ax (cid:3) b . Since the objective in ( 14 . 14 ) is strictly convex , these conditions are sufﬁcient as well as necessary for optimality . We recover ( 14 . 13 ) by deﬁning s i (cid:3) τ / x i , i (cid:3) 1 , 2 , . . . , n . Another way of deﬁning C is to use the mapping F deﬁned in ( 14 . 4 ) and write F ( x τ , λ τ , s τ ) (cid:3) ⎡ ⎢⎣ 0 0 τ e ⎤ ⎥⎦ , ( x τ , s τ ) > 0 . ( 14 . 15 ) The equations ( 14 . 13 ) approximate ( 14 . 3 ) more and more closely as τ goes to zero . If C converges to anything as τ ↓ 0 , it must converge to a primal - dual solution of the linear program . The central path thus guides us to a solution along a route that maintains positivity of the x and s components and decreases the pairwise products x i s i , i (cid:3) 1 , 2 , . . . , n to zero at the same rate . Most primal - dual algorithms take Newton steps toward points on C for which τ > 0 , rather than pure Newton steps for F . Since these steps are biased toward the interior of the nonnegative orthant deﬁned by ( x , s ) ≥ 0 , it usually is possible to take longer steps along them than along the pure Newton ( afﬁne scaling ) steps , before violating the positivity condition . In the feasible case of ( x , λ , s ) ∈ F , we have r b (cid:3) 0 and r c (cid:3) 0 , so the search direction satisﬁes a special case of ( 14 . 8 ) , that is , ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ 0 0 − X Se + σµ e ⎤ ⎥⎦ , ( 14 . 16 ) where µ is the duality measure deﬁned by ( 14 . 6 ) and σ ∈ [ 0 , 1 ] is the centering pa - rameter . When σ (cid:3) 1 , the equations ( 14 . 16 ) deﬁne a centering direction , a Newton step toward the point ( x µ , λ µ , s µ ) ∈ C , at which all the pairwise products x i s i are identical to the current average value of µ . Centering directions are usually biased strongly toward the interior of the nonnegative orthant and make little , if any , progress in reducing the duality measure µ . However , by moving closer to C , they set the scene for a substantial reduction in µ on the next iteration . At the other extreme , the value σ (cid:3) 0 gives the standard Newton ( afﬁne scaling ) step . Many algorithms use intermediate values of σ from 1 4 . 1 . P R I M A L - D U A L M E T H O D S 399 the open interval ( 0 , 1 ) to trade off between the twin goals of reducing µ and improving centrality . CENTRAL PATH NEIGHBORHOODS AND PATH - FOLLOWING METHODS Path - following algorithms explicitly restrict the iterates to a neighborhood of the central path C and follow C to a solution of the linear program . By preventing the iterates from coming too close to the boundary of the nonnegative orthant , they ensure that it is possible to take a nontrivial step along each search direction . Mopreover , by forcing the duality measure µ k to zero as k → ∞ , we ensure that the iterates ( x k , λ k , s k ) come closer and closer to satisfying the KKT conditions ( 14 . 3 ) . The two most interesting neighborhoods of C are N 2 ( θ ) (cid:3) { ( x , λ , s ) ∈ F o | (cid:8) X Se − µ e (cid:8) 2 ≤ θµ } , ( 14 . 17 ) for some θ ∈ [ 0 , 1 ) , and N −∞ ( γ ) (cid:3) { ( x , λ , s ) ∈ F o | x i s i ≥ γ µ all i (cid:3) 1 , 2 , . . . , n } , ( 14 . 18 ) for some γ ∈ ( 0 , 1 ] . ( Typical values of the parameters are θ (cid:3) 0 . 5 and γ (cid:3) 10 − 3 . ) If a point lies in N −∞ ( γ ) , each pairwise product x i s i must be at least some small multiple γ of their average value µ . This requirement is actually quite modest , and we can make N −∞ ( γ ) encompass most of the feasible region F by choosing γ close to zero . The N 2 ( θ ) neighborhood is more restrictive , since certain points in F o do not belong to N 2 ( θ ) no matter how close θ is chosen to its upper bound of 1 . By keeping all iterates inside one or other of these neighborhoods , path - following methodsreduceallthepairwiseproducts x i s i tozeroatmoreorlessthesamerate . Figure14 . 1 shows the projection of the central path C onto the primal variables for a typical problem , along with a typical neighborhood N . Path - following methods are akin to homotopy methods for general nonlinear equa - tions , which also deﬁne a path to be followed to the solution . Traditional homotopy methods stay in a tight tubular neighborhood of their path , making incremental changes to the pa - rameter and chasing the homotopy path all the way to a solution . For primal - dual methods , this neighborhood is horn - shaped rather than tubular , and it tends to be broad and loose for larger values of the duality measure µ . It narrows as µ → 0 , however , because of the positivity requirement ( x , s ) > 0 . The algorithm we specify below , a special case of Framework 14 . 1 , is known as a long - step path - following algorithm . This algorithm can make rapid progress because of its use of the wide neighborhood N −∞ ( γ ) , for γ close to zero . It depends on two parameters σ min and σ max , which are lower and upper bounds on the centering parameter σ k . The search direction is , as usual , obtained by solving ( 14 . 10 ) , and we choose the step length α k to be as large as possible , subject to the requirement that we stay inside N −∞ ( γ ) . 400 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S C central path neighborhood Figure 14 . 1 Central path , projected into space of primal variables x , showing a typical neighborhood N . Here and in later analysis , we use the notation ( x k ( α ) , λ k ( α ) , s k ( α ) ) def (cid:3) ( x k , λ k , s k ) + α ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) , ( 14 . 19a ) µ k ( α ) def (cid:3) x k ( α ) T s k ( α ) / n . ( 14 . 19b ) Algorithm 14 . 2 ( Long - Step Path - Following ) . Given γ , σ min , σ max with γ ∈ ( 0 , 1 ) , 0 < σ min ≤ σ max < 1 , and ( x 0 , λ 0 , s 0 ) ∈ N −∞ ( γ ) ; for k (cid:3) 0 , 1 , 2 , . . . Choose σ k ∈ [ σ min , σ max ] ; Solve ( 14 . 10 ) to obtain ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) ; Choose α k as the largest value of α in [ 0 , 1 ] such that ( x k ( α ) , λ k ( α ) , s k ( α ) ) ∈ N −∞ ( γ ) ; ( 14 . 20 ) Set ( x k + 1 , λ k + 1 , s k + 1 ) (cid:3) ( x k ( α k ) , λ k ( α k ) , s k ( α k ) ) ; end ( for ) . Typical behavior of the algorithm is illustrated in Figure 14 . 2 for the case of n (cid:3) 2 . The horizontal and vertical axes in this ﬁgure represent the pairwise products x 1 s 1 and x 2 s 2 , so the central path C is the line emanating from the origin at an angle of 45 ◦ . ( A point at the origin of this illustration is a primal - dual solution if it also satisﬁes the feasibility conditions 1 4 . 1 . P R I M A L - D U A L M E T H O D S 401 x 2 s 2 x 1 s 1 iterates 0 1 2 3 central path C N boundary of neighborhood Figure 14 . 2 Iterates of Algorithm 14 . 2 , plotted in ( xs ) space . ( 14 . 3a ) , ( 14 . 3b ) , and ( 14 . 3d ) . ) In the unusual geometry of Figure 14 . 2 , the search directions ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) transform to curves rather than straight lines . As Figure 14 . 2 shows ( and the analysis conﬁrms ) , the lower bound σ min on the centering parameter ensures that each search direction starts out by moving away from the boundary of N −∞ ( γ ) and into the relative interior of this neighborhood . That is , small steps along the search direction improve the centrality . Larger values of α take us outside the neighborhood again , since the error in approximating the nonlinear system ( 14 . 15 ) by the linear step equations ( 14 . 16 ) becomes more pronounced as α increases . Still , we are guaranteed that a certain minimum step can be taken before we reach the boundary of N −∞ ( γ ) , as we show in the analysis below . The analysis of Algorithm 14 . 2 appears in the next few pages . With judicious choices of σ k , this algorithm is fairly efﬁcient in practice . With a few more modiﬁcations , it becomes the basis of a truly competitive method , as we discuss in Section 14 . 2 . Our aim in the analysis below is to show that given some small tolerance (cid:9) > 0 , the algorithm requires O ( n | log (cid:9) | ) iterations to reduce the duality measure by a factor of (cid:9) , that is , to identify a point ( x k , λ k , s k ) for which µ k ≤ (cid:9)µ 0 . For small (cid:9) , the point ( x k , λ k , s k ) satisﬁes the primal - dual optimality conditions except for perturbations of about (cid:9) in the right - hand side of ( 14 . 3c ) , so it is usually very close to a primal - dual solution of the original linear program . The O ( n | log (cid:9) | ) estimate is a worst - case bound on the number of iterations required ; on practical problems , the number of iterations required appears 402 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S to increase only slightly ( if at all ) as n increases . The simplex method may require 2 n iterations to solve a problem with n variables , though in practice it usually requires a modest multiple of m iterations , where m is the row dimension of the constraint matrix A in ( 14 . 1 ) . As is typical for interior - point methods , the analysis builds from a purely techni - cal lemma to a powerful theorem in just a few pages . We start with the technical result ( Lemma 14 . 1 ) and use it to derive a bound on the vector of pairwise products (cid:6) x i (cid:6) s i , i (cid:3) 1 , 2 , . . . , n ( Lemma 14 . 2 ) . Theorem 14 . 3 ﬁnds a lower bound on the step length α k and a corresponding estimate of the reduction in µ on iteration k . Finally , Theorem 14 . 4 proves that O ( n | log (cid:9) | ) iterations are required to identify a point for which µ k < (cid:9) , for a given tolerance (cid:9) ∈ ( 0 , 1 ) . Lemma 14 . 1 . Let u and v be any two vectors in IR n with u T v ≥ 0 . Then (cid:8) UV e (cid:8) 2 ≤ 2 − 3 / 2 (cid:8) u + v (cid:8) 22 , where U (cid:3) diag ( u 1 , u 2 , . . . , u n ) , V (cid:3) diag ( v 1 , v 2 , . . . , v n ) . P ROOF . ( When the subscript is omitted from (cid:8) · (cid:8) , we mean (cid:8) · (cid:8) 2 , as is our convention throughout the book . ) First , note that for any two scalars α and β with αβ ≥ 0 , we have from the algebraic - geometric mean inequality that (cid:5) | αβ | ≤ 1 2 | α + β | . ( 14 . 21 ) Since u T v ≥ 0 , we have 0 ≤ u T v (cid:3) (cid:3) u i v i ≥ 0 u i v i + (cid:3) u i v i < 0 u i v i (cid:3) (cid:3) i ∈ P | u i v i | − (cid:3) i ∈ M | u i v i | , ( 14 . 22 ) where we partitioned the index set { 1 , 2 , . . . , n } as P (cid:3) { i | u i v i ≥ 0 } , M (cid:3) { i | u i v i < 0 } . 1 4 . 1 . P R I M A L - D U A L M E T H O D S 403 Now , (cid:8) UV e (cid:8) (cid:3) (cid:7) (cid:8) [ u i v i ] i ∈ P (cid:8) 2 + (cid:8) [ u i v i ] i ∈ M (cid:8) 2 (cid:8) 1 / 2 ≤ (cid:7) (cid:8) [ u i v i ] i ∈ P (cid:8) 21 + (cid:8) [ u i v i ] i ∈ M (cid:8) 21 (cid:8) 1 / 2 since (cid:8) · (cid:8) 2 ≤ (cid:8) · (cid:8) 1 ≤ (cid:7) 2 (cid:8) [ u i v i ] i ∈ P (cid:8) 21 (cid:8) 1 / 2 from ( 14 . 22 ) ≤ √ 2 (cid:23)(cid:23)(cid:23) (cid:23) (cid:26) 1 4 ( u i + v i ) 2 (cid:27) i ∈ P (cid:23)(cid:23)(cid:23) (cid:23) 1 from ( 14 . 21 ) (cid:3) 2 − 3 / 2 (cid:3) i ∈ P ( u i + v i ) 2 ≤ 2 − 3 / 2 n (cid:3) i (cid:3) 1 ( u i + v i ) 2 ≤ 2 − 3 / 2 (cid:8) u + v (cid:8) 2 , completing the proof . (cid:1) For the next result , we omit the iteration counter k from ( 14 . 10 ) , and deﬁne the diagonal matrices (cid:6) X and (cid:6) S similarly to ( 14 . 5 ) , as follows : (cid:6) X (cid:3) diag ( (cid:6) x 1 , (cid:6) x 2 , . . . , (cid:6) x n ) , (cid:6) S (cid:3) diag ( (cid:6) s 1 , (cid:6) s 2 , . . . , (cid:6) s n ) . . Lemma 14 . 2 . If ( x , λ , s ) ∈ N −∞ ( γ ) , then (cid:8) (cid:6) X (cid:6) Se (cid:8) ≤ 2 − 3 / 2 ( 1 + 1 / γ ) n µ . P ROOF . It is easy to show using ( 14 . 10 ) that (cid:6) x T (cid:6) s (cid:3) 0 . ( 14 . 23 ) By multiplying the last block row in ( 14 . 10 ) by ( X S ) − 1 / 2 and using the deﬁnition D (cid:3) X 1 / 2 S − 1 / 2 , we obtain D − 1 (cid:6) x + D (cid:6) s (cid:3) ( X S ) − 1 / 2 ( − X Se + σµ e ) . ( 14 . 24 ) Because ( D − 1 (cid:6) x ) T ( D (cid:6) s ) (cid:3) (cid:6) x T (cid:6) s (cid:3) 0 , we can apply Lemma 14 . 1 with u (cid:3) D − 1 (cid:6) x and v (cid:3) D (cid:6) s to obtain (cid:8) (cid:6) X (cid:6) Se (cid:8) (cid:3) (cid:8) ( D − 1 (cid:6) X ) ( D (cid:6) S ) e (cid:8) ≤ 2 − 3 / 2 (cid:8) D − 1 (cid:6) x + D (cid:6) s (cid:8) 2 from Lemma 14 . 1 (cid:3) 2 − 3 / 2 (cid:8) ( X S ) − 1 / 2 ( − X Se + σµ e ) (cid:8) 2 from ( 14 . 24 ) . Expanding the squared Euclidean norm and using such relationships as x T s (cid:3) n µ and 404 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S e T e (cid:3) n , we obtain (cid:8) (cid:6) X (cid:6) Se (cid:8) ≤ 2 − 3 / 2 (cid:1) x T s − 2 σµ e T e + σ 2 µ 2 n (cid:3) i (cid:3) 1 1 x i s i (cid:2) ≤ 2 − 3 / 2 (cid:26) x T s − 2 σµ e T e + σ 2 µ 2 n γ µ (cid:27) since x i s i ≥ γ µ ≤ 2 − 3 / 2 (cid:26) 1 − 2 σ + σ 2 γ (cid:27) n µ ≤ 2 − 3 / 2 ( 1 + 1 / γ ) n µ , as claimed . (cid:1) Theorem 14 . 3 . Given the parameters γ , σ min , and σ max in Algorithm 14 . 2 , there is a constant δ independent of n such that µ k + 1 ≤ (cid:17) 1 − δ n (cid:18) µ k , ( 14 . 25 ) for all k ≥ 0 . P ROOF . We start by proving that (cid:7) x k ( α ) , λ k ( α ) , s k ( α ) (cid:8) ∈ N −∞ ( γ ) for all α ∈ (cid:26) 0 , 2 3 / 2 γ 1 − γ 1 + γ σ k n (cid:27) , ( 14 . 26 ) where (cid:7) x k ( α ) , λ k ( α ) , s k ( α ) (cid:8) is deﬁned as in ( 14 . 19 ) . It follows that the step length α k is at least as long as the upper bound of this interval , that is , α k ≥ 2 3 / 2 σ k n γ 1 − γ 1 + γ . ( 14 . 27 ) For any i (cid:3) 1 , 2 , . . . , n , we have from Lemma 14 . 2 that | (cid:6) x ki (cid:6) s ki | ≤ (cid:8) (cid:6) X k (cid:6) S k e (cid:8) 2 ≤ 2 − 3 / 2 ( 1 + 1 / γ ) n µ k . ( 14 . 28 ) Using ( 14 . 10 ) , we have from x ki s ki ≥ γ µ k and ( 14 . 28 ) that x ki ( α ) s ki ( α ) (cid:3) (cid:7) x ki + α(cid:6) x ki (cid:8) (cid:7) s ki + α(cid:6) s ki (cid:8) (cid:3) x ki s ki + α (cid:7) x ki (cid:6) s ki + s ki (cid:6) x ki (cid:8) + α 2 (cid:6) x ki (cid:6) s ki ≥ x k i s k i ( 1 − α ) + ασ k µ k − α 2 | (cid:6) x k i (cid:6) s k i | ≥ γ ( 1 − α ) µ k + ασ k µ k − α 2 2 − 3 / 2 ( 1 + 1 / γ ) n µ k . 1 4 . 1 . P R I M A L - D U A L M E T H O D S 405 By summing the n components of the equation S k (cid:6) x k + X k (cid:6) s k (cid:3) − X k S k e + σ k µ k e ( the third block row from ( 14 . 10 ) ) , and using ( 14 . 23 ) and the deﬁnition of µ k and µ k ( α ) ( see ( 14 . 19 ) ) , we obtain µ k ( α ) (cid:3) ( 1 − α ( 1 − σ k ) ) µ k . From these last two formulas , we can see that the proximity condition x ki ( α ) s ki ( α ) ≥ γ µ k ( α ) is satisﬁed , provided that γ ( 1 − α ) µ k + ασ k µ k − α 2 2 − 3 / 2 ( 1 + 1 / γ ) n µ k ≥ γ ( 1 − α + ασ k ) µ k . Rearranging this expression , we obtain ασ k µ k ( 1 − γ ) ≥ α 2 2 − 3 / 2 n µ k ( 1 + 1 / γ ) , which is true if α ≤ 2 3 / 2 n σ k γ 1 − γ 1 + γ . We have proved that (cid:7) x k ( α ) , λ k ( α ) , s k ( α ) (cid:8) satisﬁes the proximity condition for N −∞ ( γ ) when α lies in the range stated in ( 14 . 26 ) . It is not difﬁcult to show that (cid:7) x k ( α ) , λ k ( α ) , s k ( α ) (cid:8) ∈ F o for all α in the given range . Hence , we have proved ( 14 . 26 ) and therefore ( 14 . 27 ) . We complete the proof of the theorem by estimating the reduction in µ on the k th step . Because of ( 14 . 23 ) , ( 14 . 27 ) , and the last block row of ( 14 . 16 ) , we have µ k + 1 (cid:3) x k ( α k ) T s k ( α k ) / n (cid:3) (cid:9) ( x k ) T s k + α k (cid:7) ( x k ) T (cid:6) s k + ( s k ) T (cid:6) x k (cid:8) + α 2 k ( (cid:6) x k ) T (cid:6) s k (cid:10) / n (cid:3) µ k + α k (cid:7) − ( x k ) T s k / n + σ k µ k (cid:8) (cid:3) ( 1 − α k ( 1 − σ k ) ) µ k ≤ (cid:17) 1 − 2 3 / 2 n γ 1 − γ 1 + γ σ k ( 1 − σ k ) (cid:18) µ k . ( 14 . 29 ) Now , the function σ ( 1 − σ ) is a concave quadratic function of σ , so on any given interval it attains its minimum value at one of the endpoints . Hence , we have σ k ( 1 − σ k ) ≥ min { σ min ( 1 − σ min ) , σ max ( 1 − σ max ) } , for all σ k ∈ [ σ min , σ max ] . 406 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S The proof is completed by substituting this estimate into ( 14 . 29 ) and setting δ (cid:3) 2 3 / 2 γ 1 − γ 1 + γ min { σ min ( 1 − σ min ) , σ max ( 1 − σ max ) } . (cid:1) We conclude with a result that a reduction of a factor of (cid:9) in the duality measure µ can be obtained in O ( n log 1 / (cid:9) ) iterations . Theorem 14 . 4 . Given (cid:9) ∈ ( 0 , 1 ) and γ ∈ ( 0 , 1 ) , suppose the starting point in Algorithm 14 . 2 satisﬁes ( x 0 , λ 0 , s 0 ) ∈ N −∞ ( γ ) . Then there is an index K with K (cid:3) O ( n log 1 / (cid:9) ) such that µ k ≤ (cid:9)µ 0 , for all k ≥ K . P ROOF . By taking logarithms of both sides in ( 14 . 25 ) , we obtain log µ k + 1 ≤ log (cid:17) 1 − δ n (cid:18) + log µ k . By applying this formula repeatedly , we have log µ k ≤ k log (cid:17) 1 − δ n (cid:18) + log µ 0 . The following well - known estimate for the log function , log ( 1 + β ) ≤ β , for all β > − 1 , implies that log ( µ k / µ 0 ) ≤ k (cid:17) − δ n (cid:18) . Therefore , the condition µ k / µ 0 ≤ (cid:9) is satisﬁed if we have k (cid:17) − δ n (cid:18) ≤ log (cid:9) . This inequality holds for all k that satisfy k ≥ K def (cid:3) n δ log 1 (cid:9) (cid:3) n δ | log (cid:9) | , so the proof is complete . (cid:1) 1 4 . 2 . P R A C T I C A L P R I M A L - D U A L A L G O R I T H M S 407 14 . 2 PRACTICAL PRIMAL - DUAL ALGORITHMS Practical implementations of interior - point algorithms follow the spirit of the previous section , in that strict positivity of x k and s k is maintained throughout and each step is a Newton - like step involving a centering component . However , most implementations work with an infeasible starting point and infeasible iterations . Several aspects of “theoretical” algorithmsaretypicallyignored , whileseveralenhancementsareaddedthathaveasigniﬁcant effect on practical performance . In this section , we describe the algorithmic enhancements that are found in a typical implementation of an infeasible - interior - point method , and present the resulting method as Algorithm 14 . 3 . Many of the techniques of this section are described in the paper of Mehrotra [ 207 ] , which can be consulted for further details . CORRECTOR AND CENTERING STEPS A key feature of practical algorithms is their use of corrector steps that compensate for the linearization error made by the Newton ( afﬁne - scaling ) step in modeling the equation x i s i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , n ( see ( 14 . 3c ) ) . Consider the afﬁne - scaling direction ( (cid:6) x , (cid:6)λ , (cid:6) s ) deﬁned by ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x aff (cid:6)λ aff (cid:6) s aff ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r c − r b − X Se ⎤ ⎥⎦ , ( 14 . 30 ) ( where r b and r c are deﬁned in ( 14 . 7 ) ) . If we take a full step in this direction , we obtain ( x i + (cid:6) x aff i ) ( s i + (cid:6) s aff i ) (cid:3) x i s i + x i (cid:6) s aff i + s i (cid:6) x aff i + (cid:6) x aff i (cid:6) s aff i (cid:3) (cid:6) x aff i (cid:6) s aff i . That is , the updated value of x i s i is (cid:6) x aff i (cid:6) s aff i rather than the ideal value 0 . We can solve the following system to obtain a step ( (cid:6) x cor , (cid:6)λ cor , (cid:6) s cor ) that attempts to correct for this deviation from the ideal : ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x cor (cid:6)λ cor (cid:6) s cor ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ 0 0 − (cid:6) X aff (cid:6) S aff e ⎤ ⎥⎦ . ( 14 . 31 ) In many cases , the combined step ( (cid:6) x aff , (cid:6)λ aff , (cid:6) s aff ) + ( (cid:6) x cor , (cid:6)λ cor , (cid:6) s cor ) does a better job of reducing the duality measure than does the afﬁne - scaling step alone . Like theoretical algorithms such as the one analysed in Section 14 . 1 , practical algo - rithms make use of centering steps , with an adaptive choice of the centering parameter σ k . The afﬁne - scaling step can be used as the basis of a successful heuristic for choosing σ k . 408 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S Roughly speaking , if the afﬁne - scaling step ( multiplied by a steplength to maintain non - negativity of x and s ) reduces the duality measure signiﬁcantly , there is not much need for centering , so a smaller value of σ k is appropriate . Conversely , if not much progress can be made along this direction before reaching the boundary of the nonnegative orthant , a larger value of σ k will ensure that the next iterate is more centered , so a longer step will be possible from this next point . Speciﬁcally , this scheme calculates the maximum allowable steplengths along the afﬁne - scaling direction ( 14 . 30 ) as follows : α priaff def (cid:3) min (cid:24) 1 , min i : (cid:6) x aff i < 0 − x i (cid:6) x aff i (cid:25) , ( 14 . 32a ) α dualaff def (cid:3) min (cid:24) 1 , min i : (cid:6) s aff i < 0 − s i (cid:6) s aff i (cid:25) , ( 14 . 32b ) and then deﬁnes µ aff to be the value of µ that would be obtained by using these steplengths , that is , µ aff (cid:3) ( x + α priaff (cid:6) x aff ) T ( s + α dualaff (cid:6) s aff ) / n . ( 14 . 33 ) The centering parameter σ is chosen according to the following heuristic ( which does not have a solid analytical justiﬁcation , but appears to work well in practice ) : σ (cid:3) (cid:17) µ aff µ (cid:18) 3 . ( 14 . 34 ) To summarize , computation of the search direction requires the solution of two linear systems . First , the system ( 14 . 30 ) is solved to obtain the afﬁne - scaling direction , also known as the predictor step . This step is used to deﬁne the right - hand side for the corrector step ( see ( 14 . 31 ) ) and to calculate the centering parameter from ( 14 . 33 ) , ( 14 . 34 ) . Second , the search direction is calculated by solving ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r c − r b − X Se − (cid:6) X aff (cid:6) S aff e + σµ e ⎤ ⎥⎦ . ( 14 . 35 ) Note that the predictor , corrector , and centering contributions have been aggregated on the right - hand side of this system . The coefﬁcient matrix in both linear systems ( 14 . 30 ) and ( 14 . 35 ) is the same . Thus , the factorization of the matrix needs to be computed only once , and the marginal cost of solving the second system is relatively small . 1 4 . 2 . P R A C T I C A L P R I M A L - D U A L A L G O R I T H M S 409 STEP LENGTHS Practical implementations typically do not enforce membership of the central path neighborhoods N 2 and N −∞ deﬁned in the previous section . Rather , they calculate the maximum steplengths that can be taken in the x and s variables ( separately ) without violating nonnegativity , then take a steplength of slightly less than this maximum ( but no greater than 1 ) . Given an iterate ( x k , λ k , s k ) with ( x k , s k ) > 0 , and a step ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) , it is easy to show that the quantities α pri k , max and α dual k , max deﬁned as follows : α pri k , max def (cid:3) min i : (cid:6) x ki < 0 − x ki (cid:6) x ki , α dual k , max def (cid:3) min i : (cid:6) s ki < 0 − s ki (cid:6) s ki , ( 14 . 36 ) are the largest values of α for which x k + α(cid:6) x k ≥ 0 and s k + α(cid:6) s k ≥ 0 , respectively . ( Note that these formulae are similar to the ratio test used in the simplex method to determine the index that enters the basis . ) Practical algorithms then choose the steplengths to lie in the open intervals deﬁned by these maxima , that is , α pri k ∈ ( 0 , α pri k , max ) , α dual k ∈ ( 0 , α dual k , max ) , and then obtain a new iterate by setting x k + 1 (cid:3) x k + α pri k (cid:6) x k , ( λ k + 1 , s k + 1 ) (cid:3) ( λ k , s k ) + α dual k ( (cid:6)λ k , (cid:6) s k ) . If the step ( (cid:6) x k , (cid:6)λ k , (cid:6) s k ) rectiﬁes the infeasibility in the KKT conditions ( 14 . 3a ) and ( 14 . 3b ) , that is , A (cid:6) x k (cid:3) − r kb (cid:3) − ( Ax k − b ) , A T (cid:6)λ k + (cid:6) s k (cid:3) − r kc (cid:3) − ( A T λ k + s k − c ) , it is easy to show that the infeasibilities at the new iterate satisfy r k + 1 b (cid:3) (cid:7) 1 − α pri k (cid:8) r kb , r k + 1 c (cid:3) (cid:7) 1 − α dual k (cid:8) r kc . ( 14 . 37 ) The following formula is used to calculate steplengths in many practical implementations α pri k (cid:3) min ( 1 , η k α pri k , max ) , α dual k (cid:3) min ( 1 , η k α dual k , max ) , ( 14 . 38 ) where η k ∈ [ 0 . 9 , 1 . 0 ) is chosen so that η k → 1 as the iterates approach the primal - dual solution , to accelerate the asymptotic convergence . 410 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S STARTING POINT Choice of starting point is an important practical issue with a signiﬁcant effect on the robustness of the algorithm . A poor choice ( x 0 , λ 0 , s 0 ) satisfying only the minimal conditions x 0 > 0 and s 0 > 0 often leads to failure of convergence . We describe here a heuristic that ﬁnds a starting point that satisﬁes the equality constraints in the primal and dual problems reasonably well , while maintaining positivity of the x and s components and avoiding excessively large values of these components . First , we ﬁnd a vector ˜ x of minimum norm satisfying the primal constraint Ax (cid:3) b , and a vector ( ˜ λ , ˜ s ) satisfy the dual constraint A T λ + s (cid:3) c such that ˜ s has minimum norm . That is , we solve the problems min x 12 x T x subject to Ax (cid:3) b , ( 14 . 39a ) min ( λ , s ) 12 s T s subject to A T λ + s (cid:3) c . ( 14 . 39b ) It is not difﬁcult to show that ˜ x and ( ˜ λ , ˜ s ) can be written explicitly as follows : ˜ x (cid:3) A T ( AA T ) − 1 b , ˜ λ (cid:3) ( AA T ) − 1 Ac , ˜ s (cid:3) c − A T ˜ λ . ( 14 . 40 ) In general , ˜ x and ˜ s will have nonpositive components , so are not suitable for use as a starting point . We deﬁne δ x (cid:3) max ( − ( 3 / 2 ) min i ˜ x i , 0 ) , δ s (cid:3) max ( − ( 3 / 2 ) min i ˜ s i , 0 ) , and adjust the x and s vectors as follows : ˆ x (cid:3) ˜ x + δ x e , ˆ s (cid:3) ˜ s + δ s e , where , as usual , e (cid:3) ( 1 , 1 , . . . , 1 ) T . Clearly , we have ˆ x ≥ 0 and ˆ s ≥ 0 . To ensure that the components of x 0 and s 0 are not too close to zero and not too dissimilar , we add two more scalars deﬁned as follows : ˆ δ x (cid:3) 1 2 ˆ x T ˆ s e T ˆ s , ˆ δ s (cid:3) 1 2 ˆ x T ˆ s e T ˆ x ( Note that ˆ δ x is the average size of the components of ˆ x , weighted by the corresponding components of ˆ s ; similarly for ˆ δ s . ) Finally , we deﬁne the starting point as follows : x 0 (cid:3) ˆ x + ˆ δ x e , λ 0 (cid:3) ˜ λ , s 0 (cid:3) ˆ s + ˆ δ s e . The computational cost of ﬁnding ( x 0 , λ 0 , s 0 ) by this scheme is about the same as one step of the primal - dual method . 1 4 . 2 . P R A C T I C A L P R I M A L - D U A L A L G O R I T H M S 411 In some cases , we have prior knowledge about the solution , possibly in the form of a solution to a similar linear program . The use of such “warm - start” information in constructing a starting point is discussed in Section 14 . 4 . A PRACTICAL ALGORITHM We now give a formal speciﬁcation of a practical algorithm . Algorithm 14 . 3 ( Predictor - Corrector Algorithm ( Mehrotra [ 207 ] ) ) . Calculate ( x 0 , λ 0 , s 0 ) as described above ; for k (cid:3) 0 , 1 , 2 , . . . Set ( x , λ , s ) (cid:3) ( x k , λ k , s k ) and solve ( 14 . 30 ) for ( (cid:6) x aff , (cid:6)λ aff , (cid:6) s aff ) ; Calculate α priaff , α dualaff , and µ aff as in ( 14 . 32 ) and ( 14 . 33 ) ; Set centering parameter to σ (cid:3) ( µ aff / µ ) 3 ; Solve ( 14 . 35 ) for ( (cid:6) x , (cid:6)λ , (cid:6) s ) ; Calculate α pri k and α dual k from ( 14 . 38 ) ; Set x k + 1 (cid:3) x k + α pri k (cid:6) x , ( λ k + 1 , s k + 1 ) (cid:3) ( λ k , s k ) + α dual k ( (cid:6)λ , (cid:6) s ) ; end ( for ) . No convergence theory is available for Mehrotra’s algorithm , at least in the form in which it is described above . In fact , there are examples for which the algorithm diverges . Simple safeguards could be incorporated into the method to force it into the convergence framework of existing methods or to improve its robustness , but many practical codes do not implement these safeguards , because failures are rare . When presented with a linear program that is infeasible or unbounded , the algorithm above typically diverges , with the infeasibilities r kb and r kc and / or the duality measure µ k going to ∞ . Since the symptoms of infeasibility and unboundedness are fairly easy to recognize , interior - point codes contain heuristics to detect and report these conditions . More rigorous approaches for detecting infeasibility and unboundedness make use of the homogeneous self - dual formulation ; see Wright [ 316 , Chapter 9 ] and the references therein for a discussion . A more recent approach that applies directly to infeasible - interior - point methods is described by Todd [ 286 ] . SOLVING THE LINEAR SYSTEMS Most of the computational effort in primal - dual methods is taken up in solving linear systems such as ( 14 . 9 ) , ( 14 . 30 ) , and ( 14 . 35 ) . The coefﬁcient matrix in these systems is usually large and sparse , since the constraint matrix A is itself large and sparse in most applications . 412 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S The special structure in the step equations allows us to reformulate them as systems with more compact symmetric coefﬁcient matrices , which are easier and cheaper to factor than the original sparse form . We apply the reformulation procedures to the following general form of the linear system : ⎡ ⎢⎣ 0 A T I A 0 0 S 0 X ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6)λ (cid:6) s ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r c − r b − r xs ⎤ ⎥⎦ . ( 14 . 41 ) Since x and s are strictly positive , the diagonal matrices X and S are nonsingular . We can eliminate (cid:6) s and add − X − 1 times the third equation in this system to the ﬁrst equation to obtain (cid:1) − D − 2 A T A 0 (cid:2) (cid:1) (cid:6) x (cid:6)λ (cid:2) (cid:3) (cid:1) − r c + X − 1 r xs − r b (cid:2) , ( 14 . 42a ) (cid:6) s (cid:3) − X − 1 r xs − X − 1 S (cid:6) x , ( 14 . 42b ) where we have introduced the notation D (cid:3) S − 1 / 2 X 1 / 2 . ( 14 . 43 ) This form of the step equations usually is known as the augmented system . We can go further and eliminate (cid:6) x and add AD 2 times the ﬁrst equation to the second equation in ( 14 . 42a ) to obtain AD 2 A T (cid:6)λ (cid:3) − r b − AX S − 1 r c + AS − 1 r xs ( 14 . 44a ) (cid:6) s (cid:3) − r c − A T (cid:6)λ , ( 14 . 44b ) (cid:6) x (cid:3) − S − 1 r xs − X S − 1 (cid:6) s , ( 14 . 44c ) where the expressions for (cid:6) s and (cid:6) s are obtained from the original system ( 14 . 41 ) . The form ( 14 . 44a ) often is called the normal - equations form , because the system ( 14 . 44a ) can be viewed as the normal equations ( 10 . 14 ) for a certain linear least - squares problem with coefﬁcient matrix DA T . Mostimplementationsofprimal - dualmethodsarebasedonformulationslike ( 14 . 44 ) . They use direct sparse Cholesky algorithms to factor the matrix AD 2 A T , and then perform triangular solves with the resulting sparse factors to obtain the step (cid:6)λ from ( 14 . 44a ) . The steps (cid:6) s and (cid:6) x are recovered from ( 14 . 44b ) and ( 14 . 44c ) . General - purpose sparse Cholesky software can be applied to AD 2 A T , but modiﬁcations are needed because AD 2 A T may be ill - conditioned or singular . ( Ill conditioning of this system is often observed during 1 4 . 3 . O T H E R P R I M A L - D U A L A L G O R I T H M S A N D E X T E N S I O N S 413 the ﬁnal stages of a primal - dual algorithm , when the elements of the diagonal weighting matrix D 2 take on both huge and tiny values . ) The Cholesky technique may encounter diagonal elements that are very small , zero or ( because of roundoff error ) slightly negative . One approach for handling this eventuality is to skip a step of the factorization , setting the component of (cid:6)λ that corresponds to the faulty diagonal element to zero . We refer to Wright [ 317 ] for details of this and other approaches . A disadvantage of the normal - equations formulation is that if A contains any dense columns , the entire matrix AD 2 A T is also dense . Hence , practical software identiﬁes dense and nearly - dense columns , excludes them from the matrix product AD 2 A T , and performs the Cholesky factorization of the resulting sparse matrix . Then , a device such as a Sherman - Morrison - Woodbury update is applied to account for the excluded columns . We refer the reader to Wright [ 316 , Chapter 11 ] for further details . The formulation ( 14 . 42 ) has received less attention than ( 14 . 44 ) , mainly because algorithms and software for factoring sparse symmetric indeﬁnite matrices are more com - plicated , slower , and less prevalent than sparse Cholesky algorithms . Nevertheless , the formulation ( 14 . 42 ) is cleaner and more ﬂexible than ( 14 . 44 ) in a number of respects . It normally avoids the ﬁll - in caused by dense columns in A in the matrix product AD 2 A T . Moreover , it allows free variables ( components of x with no explicit lower or upper bounds ) to be handled directly in the formulation . ( The normal equations form must resort to var - ious artiﬁcial devices to express such variables , otherwise it is not possible to perform the block elimination that leads to the system ( 14 . 44a ) . ) 14 . 3 OTHER PRIMAL - DUAL ALGORITHMS AND EXTENSIONS OTHER PATH - FOLLOWING METHODS Framework 14 . 1 is the basis of a number of other algorithms of the path - following variety . They are less important from a practical viewpoint , but we mention them here because of their elegance and their strong theoretical properties . Some path - following methods choose conservative values for the centering parameter σ ( that is , σ only slightly less than 1 ) so that unit steps ( that is , a steplength of α (cid:3) 1 ) can be taken along the resulting direction from ( 14 . 16 ) without leaving the chosen neighborhood . These methods , which are known as short - step path - following methods , make only slow progress toward the solution because they require the iterates to stay inside a restrictive N 2 neighborhood ( 14 . 17 ) . From a theoretical point of view , however , they have the advantage of better complexity . ( A result similar to Theorem 14 . 4 holds with n replaced by n 1 / 2 in the complexity estimate . ) Better results are obtained with the predictor - corrector method , due to Mizuno , Todd , and Ye [ 208 ] , which uses two N 2 neighborhoods , nested one inside the other . ( Despite the similar terminology , this algorithm is quite distinct from Algorithm 14 . 3 of Section 14 . 2 . ) Every second step of this method is a predictor step , which starts in the inner neighborhood 414 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S and moves along the afﬁne - scaling direction ( computed by setting σ (cid:3) 0 in ( 14 . 16 ) ) to the boundary of the outer neighborhood . The gap between neighborhood boundaries is wide enough to allow this step to make signiﬁcant progress in reducing µ . Alternating with the predictor steps are corrector steps ( computed with σ (cid:3) 1 and α (cid:3) 1 ) , which take the next iterate back inside the inner neighborhood in preparation for the next predictor step . The predictor - corrector algorithm produces a sequence of duality measures µ k that converge superlinearly to zero , in contrast to the linear convergence that characterizes most methods . POTENTIAL - REDUCTION METHODS Potential - reduction methods take steps of the same form as path - following methods , but they do not explicitly follow the central path C and can be motivated independently of it . They use a logarithmic potential function to measure the worth of each point in F o and aim to achieve a certain ﬁxed reduction in this function at each iteration . The primal - dual potential function , which we denote generically by (cid:25) , usually has two important properties : (cid:25) → ∞ if x i s i → 0 for some i , while µ (cid:3) x T s / n (cid:9)→ 0 , ( 14 . 45a ) (cid:25) → −∞ if and only if ( x , λ , s ) → (cid:22) . ( 14 . 45b ) The ﬁrst property ( 14 . 45a ) prevents any one of the pairwise products x i s i from approaching zero independently of the others , and therefore keeps the iterates away from the boundary of the nonnegative orthant . The second property ( 14 . 45b ) relates (cid:25) to the solution set (cid:22) . If our algorithm forces (cid:25) to −∞ , then ( 14 . 45b ) ensures that the sequence approaches the solution set . An interesting primal - dual potential function is deﬁned by (cid:25) ρ ( x , s ) (cid:3) ρ log x T s − n (cid:3) i (cid:3) 1 log x i s i , ( 14 . 46 ) for some parameter ρ > n ( see Tanabe [ 283 ] and Todd and Ye [ 287 ] ) . Like all algorithms based on Framework 14 . 1 , potential - reduction algorithms obtain their search directions by solving ( 14 . 10 ) , for some σ k ∈ ( 0 , 1 ) , and they take steps of length α k along these directions . For instance , the step length α k may be chosen to approximately minimize (cid:25) ρ along the computed direction . By ﬁxing σ k (cid:3) n / ( n + √ n ) for all k , one can guarantee constant reduction in (cid:25) ρ at every iteration . Hence , (cid:25) ρ will approach −∞ , forcing convergence . Adaptive and heuristic choices of σ k and α k are also covered by the theory , provided that they at least match the reduction in (cid:25) ρ obtained from the conservative theoretical values of these parameters . 1 4 . 3 . O T H E R P R I M A L - D U A L A L G O R I T H M S A N D E X T E N S I O N S 415 EXTENSIONS Primal - dual methods for linear programming can be extended to wider classes of problems . There are simple extensions of the algorithm to the monotone linear comple - mentarity problem ( LCP ) and convex quadratic programming problems for which the convergence and polynomial complexity properties of the linear programming algorithms are retained . The monotone LCP is the problem of ﬁnding vectors x and s in IR n that satisfy the following conditions : s (cid:3) Mx + q , ( x , s ) ≥ 0 , x T s (cid:3) 0 , ( 14 . 47 ) where M is a positive semideﬁnite n × n matrix and q ∈ IR n . The similarity between ( 14 . 47 ) and the KKT conditions ( 14 . 3 ) is obvious : The last two conditions in ( 14 . 47 ) correspond to ( 14 . 3d ) and ( 14 . 3c ) , respectively , while the condition s (cid:3) Mx + q is similar to the equations ( 14 . 3a ) and ( 14 . 3b ) . For practical instances of the problem ( 14 . 47 ) , see Cottle , Pang , and Stone [ 80 ] . Interior - point methods for monotone LCP have a close correspondence to algorithms for linear programming . The duality measure ( 14 . 6 ) is redeﬁned to be the complementarity measure ( with the same deﬁnition µ (cid:3) x T s / n ) , and the conditions that must be satisﬁed by the solution can be stated similarly to ( 14 . 4 ) as follows : (cid:1) Mx + q − s X Se (cid:2) (cid:3) 0 , ( x , s ) ≥ 0 . The general formula for a path - following step is deﬁned analogously to ( 14 . 9 ) as follows : (cid:1) M − I S X (cid:2) (cid:1) (cid:6) x (cid:6) s (cid:2) (cid:3) (cid:1) − ( Mx + q − s ) − X Se + σµ e (cid:2) , where σ ∈ [ 0 , 1 ] . Using these and similar adaptations , an extension of the practical method of Section 14 . 2 can also be derived . Extensions to convex quadratic programs are discussed in Section 16 . 6 . Their adaptation to nonlinear programming problems is the subject of Chapter 19 . Interior - point methods are highly effective in solving semideﬁnite programming prob - lems , a class of problems involving symmetric matrix variables that are constrained to be positive semideﬁnite . Semideﬁnite programming , which has been the topic of concentrated research since the early 1990s , has applications in many areas , including control theory and combinatorial optimization . Further information on this increasingly important topic can be found in the survey papers of Todd [ 285 ] and Vandenberghe and Boyd [ 292 ] and the books of Nesterov and Nemirovskii [ 226 ] , Boyd et al . [ 37 ] , and Boyd and Vandenberghe [ 38 ] . 416 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S 14 . 4 PERSPECTIVES AND SOFTWARE The appearance of interior - point methods in the 1980s presented the ﬁrst serious challenge to the dominance of the simplex method as a practical means of solving linear programming problems . Byabout1990 , interior - pointcodeshademergedthatincorporatedthetechniques described in Section 14 . 2 and that were superior on many large problems to the simplex codes available at that time . The years that followed saw signiﬁcant improvements in simplex software , evidenced by the appearance of packages such as CPLEX and XPRESS - MP . These improvements were due to algorthmic advances such as steepest - edge pivoting ( see Goldfarb and Forrest [ 133 ] ) and improved pricing heuristics , and also to close attention to the nuts and bolts of efﬁcient implementation . The efﬁciency of interior - point codes also continued to improve , through improvements in the linear algebra for solving the step equations and through the use of higher - order correctors in the step calculation ( see Gondzio [ 138 ] ) . During this period , a number of good interior - point codes became freely available ( such as PCx [ 84 ] , HOPDM [ 137 ] , BPMPD , and LIPSOL [ 321 ] ) and found their way into many applications . In general , simplex codes are faster on problems of small - medium dimensions , while interior - point codes are competitive and often faster on large problems . However , this rule is certainly not hard - and - fast ; it depends strongly on the structure of the particular application . Interior - point methods are generally not able to take full advantage of prior knowledge about the solution , such as an estimate of the solution itself or an estimate of the optimal basis . Hence , interior - point methods are less useful than simplex approaches in situations in which “warm - start” information is readily available . One situation of this type involves branch - and - bound algorithms for solving integer programs , where each node in the branch - and - bound tree requires the solution of a linear program that differs only slightly from one already solved in the parent node . In other situations , we may wish to solve a sequence of linear programs in which the data is perturbed slightly to investigate sensitivity of the solutions to various perturbations , or in which we approximate a non - linear optimization problem by a sequence of linear programs . Yıldırım and Wright [ 319 ] describe how a given point ( such as an approximate solution ) can be modiﬁed to obtain a starting point that is theoretically valid , in that it allows complexity results to be proved that depend on the quality of the given point . In practice , however , these techniques can be expected to provide only a modest improvement in algorithmic performance ( perhaps a factor of between 2 and 5 ) over a “cold” starting point such as the one described in Section 14 . 2 . Interior - point software has the advantage that it is easy to program , relative to the simplex method . The most complex operation is the solution of the large linear systems at each iteration to compute the step ; software to perform this linear algebra operation is readily available . The interior - point code LIPSOL [ 321 ] is written entirely in the Matlab language , apart from a small amount of FORTRAN code that interfaces to the linear algebra software . The code PCx [ 84 ] is written in C , but also is easy for the interested user to comprehend and modify . It is even possible for a non - expert in optimization to write an 1 4 . 4 . P E R S P E C T I V E S A N D S O F T W A R E 417 efﬁcient interior - point implementation from scratch that is customized to their particular application . NOTES AND REFERENCES For more details on the material of this chapter , see the book by Wright [ 316 ] . As noted in the text , Karmarkar’s method arose from a search for linear programming algorithms with better worst - case behavior than the simplex method . The ﬁrst algorithm with polynomial complexity , Khachiyan’s ellipsoid algorithm [ 180 ] , was a computational disappointment . In contrast , the execution times required by Karmarkar’s method were not too much greater than simplex codes at the time of its introduction , particularly for large linear programs . Karmarkar’s is a primal algorithm ; that is , it is described , moti - vated , and implemented purely in terms of the primal problem ( 14 . 1 ) without reference to the dual . At each iteration , Karmarkar’s algorithm performs a projective transforma - tion on the primal feasible set that maps the current iterate x k to the center of the set and takes a step in the feasible steepest descent direction for the transformed space . Progress toward optimality is measured by a logarithmic potential function . Descrip - tions of the algorithm can be found in Karmarkar’s original paper [ 175 ] and in Fletcher [ 101 , Section 8 . 7 ] . Karmarkar’s method falls outside the scope of this chapter , and in any case , its practi - cal performance does not appear to match the most efﬁcient primal - dual methods . The algorithms we discussed in this chapter have polynomial complexity , like Karmarkar’s method . Many of the algorithmic ideas that have been examined since 1984 actually had their genesis in three works that preceded Karmarkar’s paper . The ﬁrst of these is the book of Fiacco and McCormick [ 98 ] on logarithmic barrier functions ( originally proposed by Frisch [ 115 ] ) , which proves existence of the central path , among many other results . Further analysis of the central path was carried out by McLinden [ 205 ] , in the context of nonlinear complementarity problems . Finally , there is Dikin’s paper [ 94 ] , in which an interior - point method known as primal afﬁne - scaling was originally proposed . The outburst of research on primal - dual methods , which culminated in the efﬁcient software packages available today , dates to the seminal paper of Megiddo [ 206 ] . Todd gives an excellent survey of potential reduction methods in [ 284 ] . He relates the primal - dual potential reduction method mentioned above to pure primal potential reduction methods , including Karmarkar’s original algorithm , and discusses extensions to special classes of nonlinear problems . For an introduction to complexity theory and its relationship to optimization , see the book by Vavasis [ 297 ] . Andersen et al . [ 6 ] cover many of the practical issues relating to implementation of interior - point methods . In particular , they describe an alternative scheme for choosing the initial point , for the case in which upper bounds are also present on the variables . 418 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S ✐ E X E R C I S E S ✐ 14 . 1 This exercise illustrates the fact that the bounds ( x , s ) ≥ 0 are essential in relating solutions of the system ( 14 . 4a ) to solutions of the linear program ( 14 . 1 ) and its dual . Consider the following linear program in IR 2 : min x 1 , subject to x 1 + x 2 (cid:3) 1 , ( x 1 , x 2 ) ≥ 0 . Show that the primal - dual solution is x ∗ (cid:3) (cid:24) 0 1 (cid:25) , λ ∗ (cid:3) 0 , s ∗ (cid:3) (cid:24) 1 0 (cid:25) . Also verify that the system F ( x , λ , s ) (cid:3) 0 has the spurious solution x (cid:3) (cid:24) 1 0 (cid:25) , λ (cid:3) 1 , s (cid:3) (cid:24) 0 − 1 (cid:25) , which has no relation to the solution of the linear program . ✐ 14 . 2 ( i ) Show that N 2 ( θ 1 ) ⊂ N 2 ( θ 2 ) when 0 ≤ θ 1 < θ 2 < 1 and that N −∞ ( γ 1 ) ⊂ N −∞ ( γ 2 ) for 0 < γ 2 ≤ γ 1 ≤ 1 . ( ii ) Show that N 2 ( θ ) ⊂ N −∞ ( γ ) if γ ≤ 1 − θ . ✐ 14 . 3 Given an arbitrary point ( x , λ , s ) ∈ F o , ﬁnd the range of γ values for which ( x , λ , s ) ∈ N −∞ ( γ ) . ( The range depends on x and s . ) ✐ 14 . 4 For n (cid:3) 2 , ﬁnd a point ( x , s ) > 0 for which the condition (cid:8) X Se − µ e (cid:8) 2 ≤ θµ is not satisﬁed for any θ ∈ [ 0 , 1 ) . ✐ 14 . 5 Prove that the neighborhoods N −∞ ( 1 ) ( see ( 14 . 18 ) ) and N 2 ( 0 ) ( see ( 14 . 17 ) ) coincide with the central path C . ✐ 14 . 6 In the long - step path - following method ( Algorithm 14 . 2 ) , give a procedure for calculating the maximum value of α such that ( 14 . 20 ) is satisﬁed . ✐ 14 . 7 Show that (cid:25) ρ deﬁned by ( 14 . 46 ) has the property ( 14 . 45a ) . ✐ 14 . 8 Prove that the coefﬁcient matrix in ( 14 . 16 ) is nonsingular if and only if A has full row rank . 1 4 . 4 . P E R S P E C T I V E S A N D S O F T W A R E 419 ✐ 14 . 9 Given ( (cid:6) x , (cid:6)λ , (cid:6) s ) satisfying ( 14 . 10 ) , prove ( 14 . 23 ) . ✐ 14 . 10 Given an iterate ( x k , λ k , s k ) with ( x k , s k ) > 0 , show that the quantities α primax and α dualmax deﬁned by ( 14 . 36 ) are the largest values of α such that x k + α(cid:6) x k ≥ 0 and s k + α(cid:6) s k ≥ 0 , respectively . ✐ 14 . 11 Verify ( 14 . 37 ) . ✐ 14 . 12 Given that X and S are diagonal with positive diagonal elements , show that the coefﬁcient matrix in ( 14 . 44a ) is symmetric and positive deﬁnite if and only if A has full row rank . Does this result continue to hold if we replace D by a diagonal matrix in which exactly m of the diagonal elements are positive and the remainder are zero ? ( Here m is the number of rows of A . ) ✐ 14 . 13 Given a point ( x , λ , s ) with ( x , s ) > 0 , consider the trajectory H deﬁned by F (cid:29) ˆ x ( τ ) , ˆ λ ( τ ) , ˆ s ( τ ) (cid:30) (cid:3) ⎡ ⎢⎣ ( 1 − τ ) ( A T λ + s − c ) ( 1 − τ ) ( Ax − b ) ( 1 − τ ) X Se ⎤ ⎥⎦ , ( ˆ x ( τ ) , ˆ s ( τ ) ) ≥ 0 , for τ ∈ [ 0 , 1 ] , and note that (cid:29) ˆ x ( 0 ) , ˆ λ ( 0 ) , ˆ s ( 0 ) (cid:30) (cid:3) ( x , λ , s ) , while the limit of (cid:29) ˆ x ( τ ) , ˆ λ ( τ ) , ˆ s ( τ ) (cid:30) as τ ↑ 1 will lie in the primal - dual solution set of the linear pro - gram . Find equations for the ﬁrst , second , and third derivatives of H with respect to τ at τ (cid:3) 0 . Hence , write down a Taylor series approximation to H near the point ( x , λ , s ) . ✐ 14 . 14 Consider the following linear program , which contains “free variables” denoted by y : min c T x + d T y , subject to A 1 x + A 2 y (cid:3) b , x ≥ 0 . By introducing Lagrange multipliers λ for the equality constraints and s for the bounds x ≥ 0 , write down optimality conditions for this problem in an analogous fashion to ( 14 . 3 ) . Following ( 14 . 4 ) and ( 14 . 16 ) , use these conditions to derive the general step equations for a primal - dual interior - point method . Express these equations in augmented system form analogously to ( 14 . 42 ) and explain why it is not possible to reduce further to a formulation like ( 14 . 44 ) in which the coefﬁcient matrix is symmetric positive deﬁnite . ✐ 14 . 15 Program Algorithm 14 . 3 in Matlab . Choose η (cid:3) 0 . 99 uniformly in ( 14 . 38 ) . Test your code on a linear programming problem ( 14 . 1 ) generated by choosing A randomly , 420 C H A P T E R 1 4 . I N T E R I O R - P O I N T M E T H O D S and then setting x , s , b , and c as follows : x i (cid:3) (cid:21) random positive number i (cid:3) 1 , 2 , . . . , m , 0 i (cid:3) m + 1 , m + 2 , . . . , n , s i (cid:3) (cid:21) random positive number i (cid:3) m + 1 , m + 2 , . . . , n 0 i (cid:3) 1 , 2 , . . . , m , λ (cid:3) random vector , c (cid:3) A T λ + s , b (cid:3) Ax . Choose the starting point ( x 0 , λ 0 , s 0 ) with the components of x 0 and s 0 set to large positive values . ✐ 14 . 17 Show that the solutions of the problems ( 14 . 39 ) are given explicitly by ( 14 . 40 ) . This is page 421 Printer : Opaque this C H A P T E R 15 Fundamentals of Algorithms for Nonlinear Constrained Optimization In this chapter , we begin our discussion of algorithms for solving the general constrained optimization problem min x ∈ IR n f ( x ) subject to c i ( x ) (cid:3) 0 , i ∈ E , c i ( x ) ≥ 0 , i ∈ I , ( 15 . 1 ) where the objective function f and the constraint functions c i are all smooth , real - valued functions on a subset of IR n , and I and E are ﬁnite index sets of inequality and equality constraints , respectively . In Chapter 12 , we used this general statement of the problem 422 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S to derive optimality conditions that characterize its solutions . This theory is useful for motivating the various algorithms discussed in the remainder of the book , which differ from each other in fundamental ways but are all iterative in nature . They generate a sequence of estimates of the solution x ∗ that , we hope , tend toward a solution . In some cases , they also generate a sequence of guesses for the Lagrange multipliers associated with the constraints . As in the chapters on unconstrained optimization , we study only algorithms for ﬁnding local solutions of ( 15 . 1 ) ; the problem of ﬁnding a global solution is outside the scope of this book . We note that this chapter is not concerned with individual algorithms themselves , but rather with fundamental concepts and building blocks that are common to more than one algorithm . After reading Sections 15 . 1 and 15 . 2 , the reader may wish to glance at the material in Sections 15 . 3 , 15 . 4 , 15 . 5 , and 15 . 6 , and return to these sections as needed during study of subsequent chapters . 15 . 1 CATEGORIZING OPTIMIZATION ALGORITHMS We now catalog the algorithmic approaches presented in the rest of the book . No standard taxonomy exists for nonlinear optimization algorithms ; in the remaining chapters we have grouped the various approaches as follows . I . In Chapter 16 we study algorithms for solving quadratic programming problems . We consider this category separately because of its intrinsic importance , because its particular characteristics can be exploited by efﬁcient algorithms , and because quadratic programming subproblems need to be solved by sequential quadratic programming methods and certain interior - point methods for nonlinear programming . We discuss active set , interior - point , and gradient projection methods . II . In Chapter 17 we discuss penalty and augmented Lagrangian methods . By combining the objective function and constraints into a penalty function , we can attack problem ( 15 . 1 ) by solving a sequence of unconstrained problems . For example , if only equality constraints are present in ( 15 . 1 ) , we can deﬁne the quadratic penalty function as f ( x ) + µ 2 (cid:3) i ∈ E c 2 i ( x ) , ( 15 . 2 ) where µ > 0 is referred to as a penalty parameter . We minimize this unconstrained function , for a series of increasing values of µ , until the solution of the constrained optimization problem is identiﬁed to sufﬁcient accuracy . Ifweusean exact penaltyfunction , itmaybepossibletoﬁndalocalsolutionof ( 15 . 1 ) by solving a single unconstrained optimization problem . For the equality - constrained problem , 1 5 . 1 . C A T E G O R I Z I N G O P T I M I Z A T I O N A L G O R I T H M S 423 the function deﬁned by f ( x ) + µ (cid:3) i ∈ E | c i ( x ) | , is usually an exact penalty function , for a sufﬁciently large value of µ > 0 . Although they often are nondifferentiable , exact penalty functions can be minimized by solving a sequence of smooth subproblems . In augmented Lagrangian methods , we deﬁne a function that combines the properties of the Lagrangian function ( 12 . 33 ) and the quadratic penalty function ( 15 . 2 ) . This so - called augmented Lagrangian function has the following form for equality - constrained problems : L A ( x , λ ; µ ) (cid:3) f ( x ) − (cid:3) i ∈ E λ i c i ( x ) + µ 2 (cid:3) i ∈ E c 2 i ( x ) . Methods based on this function ﬁx λ to some estimate of the optimal Lagrange multiplier vector and ﬁx µ to some positive value , then ﬁnd a value of x that approximately minimizes L A ( · , λ ; µ ) . At this new x - iterate , λ and µ may be updated ; then the process is repeated . This approach avoids certain drawbacks associated with the minimization of the quadratic penalty function ( 15 . 2 ) . III . In Chapter 18 we describe sequential quadratic programming ( SQP ) methods , which model ( 15 . 1 ) by a quadratic programming subproblem at each iterate and deﬁne the search direction to be the solution of this subproblem . In the basic SQP method , we deﬁne the search direction p k at the iterate ( x k , λ k ) to be the solution of min p 12 p T ∇ 2 xx L ( x k , λ k ) p + ∇ f ( x k ) T p ( 15 . 3a ) subject to ∇ c i ( x k ) T p + c i ( x k ) (cid:3) 0 , i ∈ E , ( 15 . 3b ) ∇ c i ( x k ) T p + c i ( x k ) ≥ 0 , i ∈ I , ( 15 . 3c ) where L is the Lagrangian function deﬁned in ( 12 . 33 ) . The objective in this subproblem is an approximation to the change in the Lagrangian function in moving from x k to x k + p , while the constraints are linearizations of the constraints in ( 15 . 1 ) . A trust - region constraint may be added to ( 15 . 3 ) to control the length and quality of the step , and quasi - Newton approximate Hessians can be used in place of ∇ 2 xx L ( x k , λ k ) . In a variant called sequential linear - quadratic programming , the step p k is computed in two stages . First , we solve a linear program that is deﬁned by omitting the ﬁrst ( quadratic ) term from the objective ( 15 . 3a ) and adding a trust - region constraint to ( 15 . 3 ) . Next , we obtain the step p k by solving an equality - constrained subproblem in which the constraints active at the solution of the linear program are imposed as equalities , while all other constraints are ignored . IV . In Chapter 19 we study interior - point methods for nonlinear programming . These meth - ods can be viewed as extensions of the primal - dual interior - point methods for linear 424 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S programming discussed in Chapter 14 . We can also view them as barrier methods that generate steps by solving the problem min x , s f ( x ) − µ m (cid:3) i (cid:3) 1 log s i ( 15 . 4a ) subject to c i ( x ) (cid:3) 0 , i ∈ E , ( 15 . 4b ) c i ( x ) − s i (cid:3) 0 , i ∈ I , ( 15 . 4c ) for some positive value of the barrier parameter µ , where the variables s i > 0 are slacks . Interior - point methods constitute the newest class of methods for nonlinear programming and have already proved to be formidable competitors of sequential quadratic programming methods . ThealgorithmsincategoriesI , III , andIVmakeuseofeliminationtechniques , inwhich the constraints are used to eliminate some of the degrees of freedom in the problem . As a background to those algorithms , we discuss elimination in Section 15 . 3 . In later sections we discuss merit functions and ﬁlters , which are important mechanisms for promoting convergence of nonlinear programming algorithms from remote starting points . 15 . 2 THE COMBINATORIAL DIFFICULTY OF INEQUALITY - CONSTRAINED PROBLEMS One of the main challenges in solving nonlinear programming problems lies in dealing with inequality constraints—in particular , in deciding which of these constraints are active at the solution and which are not . One approach , which is the essence of active - set methods , starts by making a guess of the optimal active set A ∗ , that is , the set of constraints that are satisﬁed as equalities at a solution . We call our guess the working set and denote it by W . We then solve a problem in which the constraints in the working set are imposed as equalities and the constraints not in W are ignored . We then check to see if there is a choice of Lagrange multipliers such that the solution x ∗ obtained for this W satisﬁes the KKT conditions ( 12 . 34 ) . If so , we accept x ∗ as a local solution of ( 15 . 1 ) . Otherwise , we make a different choice of W and repeat the process . This approach is based on the observation that , in general , it is much simpler to solve equality - constrained problems than to solve nonlinear programs . The number of choices for working set W may be very large—up to 2 | I | , where | I | is the number of inequality constraints . We arrive at this estimate by observing that we can make one of two choices for each i ∈ I : to include it in W or leave it out . Since the number of possible working sets grows exponentially with the number of inequalities—a phenomenon which we refer to as the combinatorial difﬁculty of nonlinear programming—we cannot hope to design a practical algorithm by considering all possible choices for W . 1 5 . 2 . T H E C O M B I N A T O R I A L D I F F I C U L T Y O F I N E Q U A L I T Y - C O N S T R A I N E D P R O B L E M S 425 The following example suggests that even for a small number of inequality constraints , determination of the optimal active set is not a simple task . ❏ E XAMPLE 15 . 1 Consider the problem min x , y f ( x , y ) def (cid:3) 12 ( x − 2 ) 2 + 12 ( y − 12 ) 2 ( 15 . 5 ) subject to ( x + 1 ) − 1 − y − 14 ≥ 0 , x ≥ 0 , y ≥ 0 . We label the constraints , in order , with the indices 1 through 3 . Figure 15 . 1 illustrates the contours of the objective function ( dashed circles ) . The feasible region is the region enclosed by the curve and the two axes . We see that only the ﬁrst constraint is active at the solution , which is ( x ∗ , y ∗ ) T (cid:3) ( 1 . 953 , 0 . 089 ) T . Let us now apply the working - set approach described above to ( 15 . 5 ) , considering all 2 3 (cid:3) 8 possible choices of W . We consider ﬁrst the possibility that no constraints are active at the solution , that is , W (cid:3) ∅ . Since ∇ f (cid:3) ( x − 2 , y − 1 / 2 ) T , we see that the unconstrained minimum of f lies outside the feasible region . Hence , the optimal active set cannot be empty . There are seven further possibilities . First , all three constraints could be active ( that is , W (cid:3) { 1 , 2 , 3 } ) . A glance at Figure 15 . 1 shows that this does not happen for our problem ; the three constraints do not share a common point of intersection . Three further possibilities are obtained by making a single constraint active ( that is , W (cid:3) { 1 } , W (cid:3) { 2 } , and W (cid:3) { 3 } ) , x ( x , y ) * y ( 2 , 0 . 5 ) * Figure 15 . 1 Graphical illustration of problem ( 15 . 5 ) . 426 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S while the ﬁnal three possibilities are obtained by making exactly two constraints active ( that is , W (cid:3) { 1 , 2 } , W (cid:3) { 1 , 3 } , and W (cid:3) { 2 , 3 } ) . We consider three of these cases in detail . - W (cid:3) { 2 } ; that is , only the constraint x (cid:3) 0 is active . If we minimize f enforcing only this constraint , we obtain the point ( 0 , 1 / 2 ) T . A check of the KKT conditions ( 12 . 34 ) shows that no matter how we choose the Lagrange multipliers , we cannot satisfy all these conditions at ( 0 , 1 / 2 ) T . ( We must have λ 1 (cid:3) λ 3 (cid:3) 0 to satisfy ( 12 . 34e ) , which implies that we must set λ 2 (cid:3) − 2 to satisfy ( 12 . 34a ) ; but this value of λ 2 violates the condition ( 12 . 34d ) . ) - W (cid:3) { 1 , 3 } , which yields the single feasible point ( 3 , 0 ) T . Since constraint 2 is inactive at this point , we have λ 2 (cid:3) 0 , so by solving ( 12 . 34a ) for the other Lagrange multipliers , we obtain λ 1 (cid:3) − 16 and λ 3 (cid:3) − 16 . 5 . These values are negative , so they violate ( 12 . 34d ) , and x (cid:3) ( 3 , 0 ) T cannot be a solution of ( 15 . 1 ) . - W (cid:3) { 1 } . Solving the equality - constrained problem in which the ﬁrst constraint is active , we obtain ( x , y ) T (cid:3) ( 1 . 953 , 0 . 089 ) T with Lagrange multiplier λ 1 (cid:3) 0 . 411 . It is easy to see that by setting λ 2 (cid:3) λ 3 (cid:3) 0 , the remaining KKT conditions ( 12 . 34 ) are satisﬁed , so we conclude that this is a KKT point . Furthermore , it is easy to show that the second - order sufﬁcient conditions are satisﬁed , as the Hessian of the Lagrangian is positive deﬁnite . ❐ Even for this small example , we see that it is exhausting to consider all possible choices for W . Figure 15 . 1 suggests , however , that some choices of W can be eliminated from consideration if we make use of knowledge of the functions that deﬁne the problem , and their derivatives . In fact , the active set methods described in Chapter 16 use this kind of information to make a series of educated guesses for the working set , avoiding choices of W that obviously will not lead to a solution of ( 15 . 1 ) . A different approach is followed by interior - point ( or barrier ) methods discussed in Chapter 19 . These methods generate iterates that stay away from the boundary of the feasible region deﬁned by the inequality constraints . As the solution of the nonlinear program is approached , the barrier effects are weakened to permit an increasingly accurate estimate of the solution . In this manner , interior - point methods avoid the combinatorial difﬁculty of nonlinear programming . 15 . 3 ELIMINATION OF VARIABLES When dealing with constrained optimization problems , it is natural to try to use the con - straints to eliminate some of the variables from the problem , to obtain a simpler problem with fewer degrees of freedom . Elimination techniques must be used with care , however , as they may alter the problem or introduce ill conditioning . 1 5 . 3 . E L I M I N A T I O N O F V A R I A B L E S 427 x + y = 2 2 4 x + y = 1 2 2 = ( x - 1 ) 2 y 3 ( 1 , 0 ) y x Figure 15 . 2 The danger of nonlinear elimination . We begin with an example in which it is safe and convenient to eliminate variables . In the problem min f ( x ) (cid:3) f ( x 1 , x 2 , x 3 , x 4 ) subject to x 1 + x 23 − x 4 x 3 (cid:3) 0 , − x 2 + x 4 + x 23 (cid:3) 0 , there is no risk in setting x 1 (cid:3) x 4 x 3 − x 23 , x 2 (cid:3) x 4 + x 23 , to obtain a function of two variables h ( x 3 , x 4 ) (cid:3) f ( x 4 x 3 − x 2 3 , x 4 + x 2 3 , x 3 , x 4 ) , which we can minimize using the unconstrained optimization techniques described in earlier chapters . The dangers of nonlinear elimination are illustrated in the following example . ❏ E XAMPLE 15 . 2 ( F LETCHER [ 101 ] ) Consider the problem min x 2 + y 2 subject to ( x − 1 ) 3 (cid:3) y 2 . The contours of the objective function and the constraints are illustrated in Figure 15 . 2 , which shows that the solution is ( x , y ) (cid:3) ( 1 , 0 ) . 428 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S We attempt to solve this problem by eliminating y . By doing so , we obtain h ( x ) (cid:3) x 2 + ( x − 1 ) 3 . Clearly , h ( x ) → −∞ as x → −∞ . By blindly applying this transformation we may conclude that the problem is unbounded , but this view ignores the fact that the con - straint ( x − 1 ) 3 (cid:3) y 2 implicitly imposes the bound x ≥ 1 that is active at the solution . Hence , if we wish to eliminate y , we should explicitly introduce the bound x ≥ 1 into the problem . ❐ This example shows that the use of nonlinear equations to eliminate variables may result in errors that can be difﬁcult to trace . For this reason , nonlinear elimination is not used by most optimization algorithms . Instead , many algorithms linearize the constraints and apply elimination techniques to the simpliﬁed problem . We now describe systematic procedures for performing variable elimination using linear constraints . SIMPLE ELIMINATION USING LINEAR CONSTRAINTS We consider the minimization of a nonlinear function subject to a set of linear equality constraints , min f ( x ) subject to Ax (cid:3) b , ( 15 . 6 ) where A is an m × n matrix with m ≤ n . Suppose for simplicity that A has full row rank . ( If such is not the case , we ﬁnd either that the problem is inconsistent or that some of the constraints are redundant and can be deleted without affecting the solution of the problem . ) Under this assumption , we can ﬁnd a subset of m columns of A that is linearly independent . If we gather these columns into an m × m matrix B and deﬁne an n × n permutation matrix P that swaps these columns to the ﬁrst m column positions in A , we can write AP (cid:3) [ B | N ] , ( 15 . 7 ) where N denotes the n − m remaining columns of A . ( The notation here is consistent with that of Chapter 13 , where we discussed similar concepts in the context of linear programming . ) We deﬁne the subvectors x B ∈ IR m and x N ∈ IR n − m as follows : (cid:1) x B x N (cid:2) (cid:3) P T x , ( 15 . 8 ) 1 5 . 3 . E L I M I N A T I O N O F V A R I A B L E S 429 and call x B the basic variables and B the basis matrix . Noting that P P T (cid:3) I , we can rewrite the constraint Ax (cid:3) b as b (cid:3) Ax (cid:3) AP ( P T x ) (cid:3) Bx B + Nx N . By rearranging this formula , we deduce that the basic variables can be expressed as follows : x B (cid:3) B − 1 b − B − 1 Nx N . ( 15 . 9 ) We can therefore compute a feasible point for the constraints Ax (cid:3) b by choosing any value of x N and then setting x B according to the formula ( 15 . 9 ) . The problem ( 15 . 6 ) is therefore equivalent to the unconstrained problem min x N h ( x N ) def (cid:3) f (cid:24) P (cid:1) B − 1 b − B − 1 Nx N x N (cid:2)(cid:25) . ( 15 . 10 ) We refer to the substitution in ( 15 . 9 ) as simple elimination of variables . This discussion shows that a nonlinear optimization problem with linear equality constraints is , from a mathematical point of view , the same as an unconstrained problem . ❏ E XAMPLE 15 . 3 Consider the problem min sin ( x 1 + x 2 ) + x 23 + 1 3 ( x 4 + x 45 + x 6 / 2 ) ( 15 . 11a ) subject to 8 x 1 − 6 x 2 + x 3 + 9 x 4 + 4 x 5 (cid:3) 6 3 x 1 + 2 x 2 − x 4 + 6 x 5 + 4 x 6 (cid:3) − 4 . ( 15 . 11b ) By deﬁning the permutation matrix P so as to reorder the components of x as x T (cid:3) ( x 3 , x 6 , x 1 , x 2 , x 4 , x 5 ) T , we ﬁnd that the coefﬁcient matrix AP is AP (cid:3) (cid:1) 1 0 8 − 6 9 4 0 4 3 2 − 1 6 (cid:2) . The basis matrix B is diagonal and therefore easy to invert . We obtain from ( 15 . 9 ) that (cid:1) x 3 x 6 (cid:2) (cid:3) − ⎡ ⎣ 8 − 6 9 4 3 4 1 2 − 1 4 3 2 ⎤ ⎦ ⎡ ⎢⎢⎢⎢⎣ x 1 x 2 x 4 x 5 ⎤ ⎥⎥⎥⎥⎦ + (cid:1) 6 − 1 (cid:2) . ( 15 . 12 ) 430 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S By substituting for x 3 and x 6 in ( 15 . 11a ) , the problem becomes min x 1 , x 2 , x 4 , x 5 sin ( x 1 + x 2 ) + ( 8 x 1 − 6 x 2 + 9 x 4 + 4 x 5 − 6 ) 2 ( 15 . 13 ) + 1 3 ( x 4 + x 45 − [ ( 1 / 2 ) + ( 3 / 8 ) x 1 + ( 1 / 4 ) x 2 − ( 1 / 8 ) x 4 + ( 3 / 4 ) x 5 ] ) . We could have chosen two other columns of the coefﬁcient matrix A ( that is , two variables other than x 3 and x 6 ) as the basis for elimination in the system ( 15 . 11b ) , but the matrix B − 1 N would not have been so simple . ❐ A set of m independent columns can be selected , in general , by means of Gaussian elimination . In the parlance of linear algebra , we can compute the row echelon form of the matrix and choose the pivot columns as the columns of the basis B . Ideally , we would like B to be easy to factor and well conditioned . A technique that suits these purposes is a sparse Gaussian elimination approach that attempts to preserve sparsity while keeping rounding errors under control . A well - known implementation of this algorithm is MA48 from the HSL library [ 96 ] . As we discuss below , however , there is no guarantee that the Gaussian elimination process will identify the best choice of basis matrix . There is an interesting interpretation of the simple elimination - of - variables approach that we have just described . To simplify the notation , we will assume from now on that the coefﬁcient matrix is already given to us so that the basic columns appear in the ﬁrst m positions , that is , P (cid:3) I . From ( 15 . 8 ) and ( 15 . 9 ) we see that any feasible point x for the linear constraints in ( 15 . 6 ) can be written as (cid:1) x B x N (cid:2) (cid:3) x (cid:3) Yb + Zx N , ( 15 . 14 ) where Y (cid:3) (cid:1) B − 1 0 (cid:2) , Z (cid:3) (cid:1) − B − 1 N I (cid:2) . ( 15 . 15 ) Note that Z has n − m linearly independent columns ( because of the presence of the identity matrix in the lower block ) and that it satisﬁes AZ (cid:3) 0 . Therefore , Z is a basis for the null space of A . In addition , the columns of Y and the columns of Z form a linearly independent set . We note also from ( 15 . 15 ) , ( 15 . 7 ) that Yb is a particular solution of the linear constraints Ax (cid:3) b . In other words , the simple elimination technique expresses feasible points as the sum of a particular solution of Ax (cid:3) b ( the ﬁrst term in ( 15 . 14 ) ) plus a displacement along the 1 5 . 3 . E L I M I N A T I O N O F V A R I A B L E S 431 x 2 x 1 x = b A coordinate relaxation step Figure 15 . 3 Simple elimination , showing the coordinate relaxation step obtained by choosing the basis to be the ﬁrst column of A . null space of the constraints ( the second term in ( 15 . 14 ) ) . The relations ( 15 . 14 ) , ( 15 . 15 ) indicate that the particular Yb solution is obtained by holding n − m components of x at zero while relaxing the other m components ( the ones in x B ) until they reach the constraints . The particular solution Yb is sometimes known as the coordinate relaxation step . In Figure 15 . 3 , we see the coordinate relaxation step Yb obtained by choosing the basis matrix B to be the ﬁrst column of A . If we were to choose B to be the second column of A , the coordinate relaxation step would lie along the x 2 axis . Simple elimination is inexpensive but can give rise to numerical instabilities . If the feasible set in Figure 15 . 3 consisted of a line that was almost parallel to the x 1 axis , the coordinate relaxation along this axis would be very large in magnitude . We would then be computing x as the difference of very large vectors , giving rise to numerical cancellation . In that situation it would be preferable to choose a particular solution along the x 2 axis , that is , to select a different basis . Selection of the best basis is , therefore , not a straightfor - ward task in general . To overcome the dangers of an excessively large coordinate relaxation step , we could deﬁne the particular solution Yb as the minimum - norm step to the con - straints . This approach is a special case of more general elimination strategies , which we now describe . GENERAL REDUCTION STRATEGIES FOR LINEAR CONSTRAINTS To generalize ( 15 . 14 ) and ( 15 . 15 ) , we choose matrices Y ∈ IR n × m and Z ∈ IR n × ( n − m ) with the following properties : [ Y | Z ] ∈ IR n × n is nonsingular , AZ (cid:3) 0 . ( 15 . 16 ) 432 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S These properties indicate that , as in ( 15 . 15 ) , the columns of Z are a basis for the null space of A . Since A has full row rank , so does A [ Y | Z ] (cid:3) [ AY | 0 ] , so it follows that the m × m matrix AY is nonsingular . We now express any solution of the linear constraints Ax (cid:3) b as x (cid:3) Y x Y + Zx Z , ( 15 . 17 ) for some vectors x Y ∈ IR m and x Z ∈ IR n − m . By substituting ( 15 . 17 ) into the constraints Ax (cid:3) b , we obtain Ax (cid:3) ( AY ) x Y (cid:3) b ; hence by nonsingularity of AY , x Y can be written explicitly as x Y (cid:3) ( AY ) − 1 b . ( 15 . 18 ) By substituting this expression into ( 15 . 17 ) , we conclude that any vector x of the form x (cid:3) Y ( AY ) − 1 b + Zx Z ( 15 . 19 ) satisﬁes the constraints Ax (cid:3) b for any choice of x Z ∈ IR n − m . Therefore , the problem ( 15 . 6 ) can be restated equivalently as the following unconstrained problem min x Z f ( Y ( AY ) − 1 b + Zx Z ) . ( 15 . 20 ) Ideally , we would like to choose Y in such a way that the matrix AY is as well conditioned as possible , since it needs to be factorized to give the particular solution Y ( AY ) − 1 b . We can do this by computing Y and Z by means of a QR factorization of A T , which has the form A T (cid:23) (cid:3) (cid:9) Q 1 Q 2 (cid:10) (cid:1) R 0 (cid:2) , ( 15 . 21 ) where (cid:9) Q 1 Q 2 (cid:10) is orthogonal . The submatrices Q 1 and Q 2 have orthonormal columns and are of dimension n × m and n × ( n − m ) , while R is m × m upper triangular and nonsingular and (cid:23) is an m × m permutation matrix . ( See the discussion following ( A . 24 ) in the Appendix for further details . ) We now deﬁne Y (cid:3) Q 1 , Z (cid:3) Q 2 , ( 15 . 22 ) so that the columns of Y and Z form an orthonormal basis of IR n . If we expand ( 15 . 21 ) and do a little rearrangement , we obtain AY (cid:3) (cid:23) R T , AZ (cid:3) 0 . 1 5 . 3 . E L I M I N A T I O N O F V A R I A B L E S 433 Therefore , Y and Z have the desired properties , and the condition number of AY is the same as that of R , which in turn is the same as that of A itself . From ( 15 . 19 ) we see that any solution of Ax (cid:3) b can be expressed as x (cid:3) Q 1 R − T (cid:23) T b + Q 2 x Z , for some vector x Z . The computation R − T (cid:23) T b can be carried out inexpensively , at the cost of a single triangular substitution . A simple computation shows that the particular solution Q 1 R − T (cid:23) T b can also be written as A T ( AA T ) − 1 b . This vector is the solution of the following problem : min (cid:8) x (cid:8) 2 subject to Ax (cid:3) b ; that is , it is the minimum - norm solution of Ax (cid:3) b . See Figure 15 . 5 for an illustration of this step . Elimination via the orthogonal basis ( 15 . 22 ) is ideal from the point of view of numer - ical stability . The main cost associated with this reduction strategy is in computing the QR factorization ( 15 . 21 ) . Unfortunately , for problems in which A is large and sparse , a sparse QR factorization can be much more costly to compute than the sparse Gaussian elimina - tion strategy used in simple elimination . Therefore , other elimination strategies have been developed that seek a compromise between these two techniques ; see Exercise 15 . 7 . x 2 x 3 x 1 Zx Yx Z Y Ax = b Figure 15 . 4 General elimination : Case in which A ∈ IR 1 × 3 , showing the particular solution and a step in the null space of A . 434 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S x 2 x 1 x = b A A ] [ T A T A - 1 b Figure 15 . 5 The minimum - norm step . EFFECT OF INEQUALITY CONSTRAINTS Elimination of variables is not always beneﬁcial if inequality constraints are present alongside the equalities . For instance , if problem ( 15 . 11 ) had the additional constraint x ≥ 0 , then after eliminating the variables x 3 and x 6 , we would be left with the problem of minimizing the function in ( 15 . 13 ) subject to the constraints ( x 1 , x 2 , x 4 , x 5 ) ≥ 0 , 8 x 1 − 6 x 2 + 9 x 4 + 4 x 5 ≤ 6 , ( 3 / 4 ) x 1 + ( 1 / 2 ) x 2 − ( 1 / 4 ) x 4 + ( 3 / 2 ) x 5 ≤ − 1 . Hence , the cost of eliminating the equality constraints ( 15 . 11b ) is to make the inequalities more complicated than the simple bounds x ≥ 0 . For many algorithms , this transformation will not yield any beneﬁt . If , however , problem ( 15 . 11 ) included the general inequality constraint 3 x 1 + 2 x 3 ≥ 1 , the elimination ( 15 . 12 ) would transform the problem into one of minimizing the function in ( 15 . 13 ) subject to the inequality constraint − 13 x 1 + 12 x 2 − 18 x 4 − 8 x 5 ≥ − 11 . ( 15 . 23 ) In this case , the inequality constraint would not become much more complicated af - ter elimination of the equality constraints , so it is probably worthwhile to perform the elimination . 1 5 . 4 . M E R I T F U N C T I O N S A N D F I L T E R S 435 15 . 4 MERIT FUNCTIONS AND FILTERS Suppose that an algorithm for solving the nonlinear programming problem ( 15 . 1 ) generates astepthatreducestheobjectivefunctionbutincreasestheviolationoftheconstraints . Should we accept this step ? This question is not easy to answer . We must look for a way to balance the twin ( often competing ) goals of reducing the objective function and satisfying the constraints . Merit functions and ﬁlters are two approaches for achieving this balance . In a typical constrained optimization algorithm , a step p will be accepted only if it leads to a sufﬁcient reduction in the merit function φ or if it is acceptable to the ﬁlter . These concepts are explained in the rest of the section . MERIT FUNCTIONS In unconstrained optimization , the objective function f is the natural choice for the merit function . All the unconstrained optimization methods described in this book require that f be decreased at each step ( or at least within a certain number of iterations ) . In feasible methods for constrained optimization in which the starting point and all subsequent iterates satisfy all the constraints in the problem , the objective function is still an appropriate merit function . On the other hand , algorithms that allow iterates to violate the constraints require some means to assess the quality of the steps and iterates . The merit function in this case combines the objective with measures of constraint violation . A popular choice of merit function for the nonlinear programming problem ( 15 . 1 ) is the (cid:1) 1 penalty function deﬁned by φ 1 ( x ; µ ) (cid:3) f ( x ) + µ (cid:3) i ∈ E | c i ( x ) | + µ (cid:3) i ∈ I [ c i ( x ) ] − , ( 15 . 24 ) where we use the notation [ z ] − (cid:3) max { 0 , − z } . The positive scalar µ is the penalty parameter , whichdeterminestheweightthatweassigntoconstraintsatisfactionrelativetominimization of the objective . The (cid:1) 1 merit function φ 1 is not differentiable because of the presence of the absolute value and [ · ] − functions , but it has the important property of being exact . Deﬁnition 15 . 1 ( Exact Merit Function ) . A merit function φ ( x ; µ ) is exact if there is a positive scalar µ ∗ such that for any µ > µ ∗ , any local solution of the nonlinear programming problem ( 15 . 1 ) is a local minimizer of φ ( x ; µ ) . We show in Theorem 17 . 3 that , under certain assumptions , the (cid:1) 1 merit function φ 1 ( x ; µ ) is exact and that the threshold value µ ∗ is given by µ ∗ (cid:3) max { | λ ∗ i | , i ∈ E ∪ I } , 436 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S where the λ ∗ i denote the Lagrange multipliers associated with an optimal solution x ∗ . Since the optimal Lagrange multipliers are , however , not known in advance , algorithms based on the (cid:1) 1 merit function contain rules for adjusting the penalty parameter whenever there is reason to believe that it is not large enough ( or is excessively large ) . These rules depend on the choice of optimization algorithm and are discussed in the next chapters . Another useful merit function is the exact (cid:1) 2 function , which for equality - constrained problems takes the form φ 2 ( x ; µ ) (cid:3) f ( x ) + µ (cid:8) c ( x ) (cid:8) 2 . ( 15 . 25 ) This function is nondifferentiable because the 2 - norm term is not squared ; its derivative is not deﬁned at x for which c ( x ) (cid:3) 0 . Some merit functions are both smooth and exact . To ensure that both properties hold , we must include additional terms in the merit function . For equality - constrained problems , Fletcher’s augmented Lagrangian is given by φ F ( x ; µ ) (cid:3) f ( x ) − λ ( x ) T c ( x ) + 12 µ (cid:3) i ∈ E c i ( x ) 2 , ( 15 . 26 ) where µ > 0 is the penalty parameter and λ ( x ) (cid:3) [ A ( x ) A ( x ) T ] − 1 A ( x ) ∇ f ( x ) . ( 15 . 27 ) ( Here A ( x ) denotes the Jacobian of c ( x ) . ) Although this merit function has some interesting theoretical properties , it has practical limitations , including the expense of solving for λ ( x ) in ( 15 . 27 ) . A quite different merit function is the ( standard ) augmented Lagrangian in x and λ , which for equality - constrained problems has the form L A ( x , λ ; µ ) (cid:3) f ( x ) − λ T c ( x ) + 12 µ (cid:8) c ( x ) (cid:8) 2 2 . ( 15 . 28 ) We assess the acceptability of a trial point ( x + , λ + ) by comparing the value of L A ( x + , λ + ; µ ) with the value at the current iterate , ( x , λ ) . Strictly speaking , L A is not a merit function in the sense that a solution ( x ∗ , λ ∗ ) of the nonlinear programming problem is not in general a minimizer of L A ( x , λ ; µ ) but only a stationary point . Although some sequential quadratic programming methods use L A successfully as a merit function by adaptively modifying µ and λ , we will not consider its use as a merit function further . Instead , we will focus primarily on the nonsmooth exact penalty functions φ 1 and φ 2 . A trial step x + (cid:3) x + α p generated by a line search algorithm will be accepted if it produces a sufﬁcient decrease in the merit function φ ( x ; µ ) . One way to deﬁne this concept is analogous to the condition ( 3 . 4 ) used in unconstrained optimization , where the amount 1 5 . 4 . M E R I T F U N C T I O N S A N D F I L T E R S 437 of decrease is not too small relative to the predicted change in the function over the step . The (cid:1) 1 and (cid:1) 2 merit functions are not differentiable , but they have a directional derivative . ( See ( A . 51 ) for background on directional derivatives . ) We write the directional derivative of φ ( x ; µ ) in the direction p as D ( φ ( x ; µ ) ; p ) . In a line search method , the sufﬁcient decrease condition requires the steplength parameter α > 0 to be small enough that the inequality φ ( x + α p ; µ ) ≤ φ ( x ; µ ) + ηα D ( φ ( x ; µ ) ; p ) , ( 15 . 29 ) is satisﬁed for some η ∈ ( 0 , 1 ) . Trust - region methods typically use a quadratic model q ( p ) to estimate the value of the merit function φ after a step p ; see Section 18 . 5 . The sufﬁcient decrease condition can be stated in terms of a decrease in this model , as follows φ ( x + p ; µ ) ≤ φ ( x ; µ ) − η ( q ( 0 ) − q ( p ) ) , ( 15 . 30 ) for some η ∈ ( 0 , 1 ) . ( The ﬁnal term in ( 15 . 30 ) is positive , because the step p is computed to decrease the model q . ) FILTERS Filter techniques are step acceptance mechanisms based on ideas from multiobjective optimization . Our derivation starts with the observation that nonlinear programming has two goals : minimization of the objective function and the satisfaction of the constraints . If we deﬁne a measure of infeasibility as h ( x ) (cid:3) (cid:3) i ∈ E | c i ( x ) | + (cid:3) i ∈ I [ c i ( x ) ] − , ( 15 . 31 ) we can write these two goals as min x f ( x ) and min x h ( x ) . ( 15 . 32 ) Unlike merit functions , which combine both problems into a single minimization prob - lem , ﬁlter methods keep the two goals in ( 15 . 32 ) separate . Filter methods accept a trial step x + as a new iterate if the pair ( f ( x + ) , h ( x + ) ) is not dominated by a previous pair ( f l , h l ) (cid:3) ( f ( x l ) , h ( x l ) ) generated by the algorithm . These concepts are deﬁned as follows . 438 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S f ( x ) h ( x ) i i ( f , h ) ( f k k , h ) Figure 15 . 6 Graphical illustration of a ﬁlter with four pairs . Deﬁnition 15 . 2 . ( a ) A pair ( f k , h k ) is said to dominate another pair ( f l , h l ) if both f k ≤ f l and h k ≤ h l . ( b ) A ﬁlter is a list of pairs ( f l , h l ) such that no pair dominates any other . ( c ) An iterate x k is said to be acceptable to the ﬁlter if ( f k , h k ) is not dominated by any pair in the ﬁlter . When an iterate x k is acceptable to the ﬁlter , we ( normally ) add ( f k , h k ) to the ﬁlter and remove any pairs that are dominated by ( f k , h k ) . Figure 15 . 6 shows a ﬁlter where each pair ( f l , h l ) in the ﬁlter is represented as a black dot . Every point in the ﬁlter creates an ( inﬁnite ) rectangular region , and their union deﬁnes the set of pairs not acceptable to the ﬁlter . More speciﬁcally , a trial point x + is acceptable to the ﬁlter if ( f + , h + ) lies below or to the left of the solid line in Figure 15 . 6 . To compare the ﬁlter and merit function approaches , we plot in Figure 15 . 7 the contour line of the set of pairs ( f , h ) such that f + µ h (cid:3) f k + µ h k , where x k is the current iterate . The region to the left of this line corresponds to the set of pairs that reduce the merit function φ ( x ; µ ) (cid:3) f ( x ) + µ h ( x ) ; clearly this set is quite different from the set of points acceptable to the ﬁlter . If a trial step x + (cid:3) x k + α k p k generated by a line search method gives a pair ( f + , h + ) that is acceptable to the ﬁlter , we set x k + 1 (cid:3) x + ; otherwise , a backtracking line search is performed . In a trust - region method , if the step is not acceptable to the ﬁlter , the trust region is reduced , and a new step is computed . Several enhancements to this ﬁlter technique are needed to obtain global convergence and good practical performance . We need to ensure , ﬁrst of all , that we do not accept a point whose ( f , h ) pair is very close to the current pair ( f k , h k ) or to another pair in the ﬁlter . We 1 5 . 4 . M E R I T F U N C T I O N S A N D F I L T E R S 439 h ( x ) f ( x ) merit function isovalue of i i ( f , h ) ( f k k , h ) Figure 15 . 7 Comparing the ﬁlter and merit function techniques . do so by modifying the acceptability criterion and imposing a sufﬁcient decrease condition . A trial iterate x + is acceptable to the ﬁlter if , for all pairs ( f j , h j ) in the ﬁlter , we have that f ( x + ) ≤ f j − β h j or h ( x + ) ≤ h j − β h j , ( 15 . 33 ) for β ∈ ( 0 , 1 ) . Although this condition is effective in practice using , say β (cid:3) 10 − 5 , for purposes of analysis it may be advantageous to replace the ﬁrst inequality by f ( x + ) ≤ f j − β h + . A second enhancement addresses some problematic aspects of the ﬁlter mechanism . Under certain circumstances , the search directions generated by line search methods may require arbitrarily small steplengths α k to be acceptable to the ﬁlter . This phenomenon can cause the algorithm to stall and fail . To guard against this situation , if the backtracking line search generates a steplength that is smaller than a given threshold α min , the algorithm switches to a feasibility restoration phase , which we describe below . Similarly , in a trust - region method , if a sequence of trial steps is rejected by the ﬁlter , the trust - region radius may be decreased so much that the trust - region subproblem becomes infeasible ( see Section 18 . 5 ) . In this case , too , the feasibility restoration phase is invoked . ( Other mechanisms could be employed to handle this situation , but as we discuss below , the feasibility restoration phase can help the algorithm achieve other useful goals . ) The feasibility restoration phase aims exclusively to reduce the constraint violation , that is , to ﬁnd an approximate solution to the problem min x h ( x ) . 440 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S Although h ( x ) deﬁned by ( 15 . 31 ) is not smooth , we show in Chapter 17 how to minimize it using a smooth constrained optimization subproblem . This phase terminates at an iterate that has a sufﬁciently small value of h and is compatible with the ﬁlter . We now present a framework for ﬁlter methods that assumes that iterates are generated by a trust - region method ; see Section 18 . 5 for a discussion of trust - region methods for constrained optimization . Algorithm 15 . 1 ( General Filter Method ) . Choose a starting point x 0 and an initial trust - region radius (cid:6) 0 ; Set k ← 0 ; repeat until a convergence test is satisﬁed if the step - generation subproblem is infeasible Compute x k + 1 using the feasibility restoration phase ; else Compute a trial iterate x + (cid:3) x k + p k ; if ( f + , h + ) is acceptable to the ﬁlter Set x k + 1 (cid:3) x + and add ( f k + 1 , h k + 1 ) to the ﬁlter ; Choose (cid:6) k + 1 such that (cid:6) k + 1 ≥ (cid:6) k ; Remove all pairs from the ﬁlter that are dominated by ( f k + 1 , h k + 1 ) ; else Reject the step , set x k + 1 (cid:3) x k ; Choose (cid:6) k + 1 < (cid:6) k ; end if end if k ← k + 1 ; end repeat Other enhancements of this simple ﬁlter framework are used in practice ; they depend on the choice of algorithm and will be discussed in subsequent chapters . 15 . 5 THE MARATOS EFFECT Some algorithms based on merit functions or ﬁlters may fail to converge rapidly because they reject steps that make good progress toward a solution . This undesirable phenomenon is often called the Maratos effect , because it was ﬁrst observed by Maratos [ 199 ] . It is illustrated by the following example , in which steps p k , which would yield quadratic convergence if accepted , cause an increase both in the objective function value and the constraint violation . 1 5 . 5 . T H E M A R A T O S E F F E C T 441 θ f x + x = 1 12 22 constraint x + p k k k x x * contours of Figure 15 . 8 Maratos Effect : Example 15 . 4 . Note that the constraint is no longer satisﬁed after the step from x k to x k + p k , and the objective value has increased . ❏ E XAMPLE 15 . 4 ( P OWELL [ 255 ] ) Consider the problem min f ( x 1 , x 2 ) (cid:3) 2 ( x 21 + x 22 − 1 ) − x 1 , subject to x 21 + x 22 − 1 (cid:3) 0 . ( 15 . 34 ) One can verify ( see Figure 15 . 8 ) that the optimal solution is x ∗ (cid:3) ( 1 , 0 ) T , that the corresponding Lagrange multiplier is λ ∗ (cid:3) 3 2 , and that ∇ 2 xx L ( x ∗ , λ ∗ ) (cid:3) I . Let us consider an iterate x k of the form x k (cid:3) ( cos θ , sin θ ) T , which is feasible for any value of θ . Suppose that our algorithm computes the following step : p k (cid:3) (cid:24) sin 2 θ − sin θ cos θ (cid:25) , ( 15 . 35 ) which yields a trial point x k + p k (cid:3) (cid:24) cos θ + sin 2 θ sin θ ( 1 − cos θ ) (cid:25) . By using elementary trigonometric identities , we have that (cid:8) x k + p k − x ∗ (cid:8) 2 (cid:3) 2 sin 2 ( θ / 2 ) , (cid:8) x k − x ∗ (cid:8) 2 (cid:3) 2 | sin ( θ / 2 ) | , 442 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S and therefore (cid:8) x k + p k − x ∗ (cid:8) 2 (cid:8) x k − x ∗ (cid:8) 22 (cid:3) 1 2 . Hence , this step approaches the solution at a rate consistent with Q - quadratic convergence . However , we have that f ( x k + p k ) (cid:3) sin 2 θ − cos θ > − cos θ (cid:3) f ( x k ) , c ( x k + p k ) (cid:3) sin 2 θ > c ( x k ) (cid:3) 0 , so that , as can be seen in Figure 15 . 8 , both the objective function value and the constraint violation increase over this step . This behavior occurs for any nonzero value of θ , even if the initial point is arbitrarily close to the solution . ❐ On the example above , any algorithm that requires reduction of a merit function of the form φ ( x ; µ ) (cid:3) f ( x ) + µ h ( c ( x ) ) , where h ( · ) is a nonnegative function satisfying h ( 0 ) (cid:3) 0 , will reject the good step ( 15 . 35 ) . ( Examples of such merit functions include the φ 1 and φ 2 penalty functions . ) The step ( 15 . 35 ) will also be rejected by the ﬁlter mechanism described above because the pair ( f ( x k + p k ) , h ( x k + p k ) ) is dominated by ( f k , h k ) . Therefore , all these approaches will suffer from the Maratos effect . If no remedial measures are taken , the Maratos effect can slow optimization meth - ods by interfering with good steps away from the solution and by preventing superlinear convergence . Strategies for avoiding the Maratos effect include the following . 1 . We can use a merit function that does not suffer from the Maratos effect . An example is Fletcher’s augmented Lagrangian function ( 15 . 26 ) . 2 . We can use a second - order correction in which we add to p k a step ˆ p k , which is computed at c ( x k + p k ) and which decreases the constraint violation . 3 . We can allow the merit function φ to increase on certain iterations ; that is , we can use a nonmonotone strategy . We discuss the last two approaches in the next section . 1 5 . 6 . S E C O N D - O R D E R C O R R E C T I O N A N D N O N M O N O T O N E T E C H N I Q U E S 443 15 . 6 SECOND - ORDER CORRECTION AND NONMONOTONE TECHNIQUES By adding a correction term that decreases the constraint violation , various algorithms are able to overcome the difﬁculties associated with the Maratos effect . We describe this technique with respect to the equality - constrained problem , in which the constraint is c ( x ) (cid:3) 0 , where c : IR n → IR | E | . Given a step p k , the second - order correction step ˆ p k is deﬁned to be ˆ p k (cid:3) − A Tk ( A k A Tk ) − 1 c ( x k + p k ) , ( 15 . 36 ) where A k (cid:3) A ( x k ) is the Jacobian of c at x k . Note that ˆ p k has the property that it satisﬁes a linearization of the constraint c at the point x k + p k , that is , A k ˆ p k + c ( x k + p k ) (cid:3) 0 . In fact , ˆ p k is the minimum - norm solution of this equation . ( A different interpretation of the second - order correction is given in Section 18 . 3 . ) The effect of the correction step ˆ p k is to decrease the quantity (cid:8) c ( x ) (cid:8) to the order of (cid:8) x k − x ∗ (cid:8) 3 , provided the primary step p k satisﬁes A k p k + c ( x k ) (cid:3) 0 . This estimate indicates that the step from from x k to x k + p k + ˆ p k will decrease the merit function , at least near the solution . The cost of this enhancement includes the additional evaluation of the constraint function c at x k + p k and the linear algebra required to calculate the step ˆ p k from ( 15 . 36 ) . We now describe an algorithm that uses a merit function together with a line - search strategy and a second - order correction step . We assume that the search direction p k and the penalty parameter µ k are computed so that p k is a descent direction for the merit function , that is , D ( φ ( x k ; µ ) ; p k ) < 0 . In Chapters 18 and 19 , we discuss how to accomplish these goals . The key feature of the algorithm is that , if the full step α k (cid:3) 1 does not produce satisfactory descent in the merit function , we try the second - order correction step before backtracking along the original direction p k . Algorithm 15 . 2 ( Generic Algorithm with Second - Order Correction ) . Choose parameters η ∈ ( 0 , 0 . 5 ) and τ 1 , τ 2 with 0 < τ 1 < τ 2 < 1 ; Choose initial point x 0 ; set k ← 0 ; repeat until a convergence test is satisﬁed : Compute a search direction p k ; Set α k ← 1 , newpoint ← false ; while newpoint = false if φ ( x k + α k p k ; µ ) ≤ φ ( x k ; µ ) + ηα k D ( φ ( x k ; µ ) ; p k ) Set x k + 1 ← x k + α k p k ; Set newpoint ← true ; 444 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S else if α k (cid:3) 1 Compute ˆ p k from ( 15 . 36 ) ; if φ ( x k + p k + ˆ p k ; µ ) ≤ φ ( x k ; µ ) + η D ( φ ( x k ; µ ) ; p k ) Set x k + 1 ← x k + p k + ˆ p k ; Set newpoint ← true ; else Choose new α k in [ τ 1 α k , τ 2 α k ] ; end else Choose new α k in [ τ 1 α k , τ 2 α k ] ; end end while end repeat In this algorithm , the full second - order correction step ˆ p k is discarded if does not produce a reduction in the merit function . We do not backtrack along the direction p k + ˆ p k because it is not guaranteed to be a descent direction for the merit func - tion . A variation of this algorithm applies the second - order correction step only if the sufﬁcient decrease condition ( 15 . 29 ) is violated as a result of an increase in the norm of the constraints . The second - order correction strategy is effective in practice . The cost of performing theextraconstraintfunctionevaluationandanadditionalbacksolvein ( 15 . 36 ) isoutweighed by added robustness and efﬁciency . NONMONOTONE ( WATCHDOG ) STRATEGY The inefﬁciencies caused by the Maratos effect can also be avoided by occasionally accepting steps that increase the merit function ; such steps are called relaxed steps . There is a limit to our tolerance , however . If a sufﬁcient reduction of the merit function has not been obtained within a certain number of iterates of the relaxed step ( ˆ t iterates , say ) , then we return to the iterate before the relaxed step and perform a normal iteration , using a line search or some other technique to force a reduction in the merit function . In contrast with the second - order correction , which aims only to improve satisfaction of the constraints , this nonmonotone strategy always takes regular steps p k of the algorithm that aim both for improved feasibility and optimality . The hope is that any increase in the merit function over a single step will be temporary , and that subsequent steps will more than compensate for it . We now describe a particular instance of the nonmonotone approach called the watchdog strategy . We set ˆ t (cid:3) 1 , so that we allow the merit function to increase on just a single step before insisting on a sufﬁcient decrease in the merit function . As above , we focus our discussion on a line search algorithm that uses a nonsmooth merit function φ . We assume that the penalty parameter µ is not changed until a successful cycle has been 1 5 . 6 . S E C O N D - O R D E R C O R R E C T I O N A N D N O N M O N O T O N E T E C H N I Q U E S 445 completed . To simplify the notation , we omit the dependence of φ on µ and write the merit function as φ ( x ) and the directional derivative as D ( φ ( x ) ; p k ) . Algorithm 15 . 3 ( Watchdog ) . Choose a constant η ∈ ( 0 , 0 . 5 ) and an initial point x 0 ; Set k ← 0 , S ← { 0 } ; repeat until a termination test is satisﬁed Compute a step p k ; Set x k + 1 ← x k + p k ; if φ ( x k + 1 ) ≤ φ ( x k ) + η D ( φ ( x k ) ; p k ) k ← k + 1 , S ← S ∪ { k } ; else Compute a search direction p k + 1 from x k + 1 ; Find α k + 1 such that φ ( x k + 2 ) ≤ φ ( x k + 1 ) + ηα k + 1 D ( φ ( x k + 1 ) ; p k + 1 ) ; Set x k + 2 ← x k + 1 + α k + 1 p k + 1 ; if φ ( x k + 1 ) ≤ φ ( x k ) or φ ( x k + 2 ) ≤ φ ( x k ) + η D ( φ ( x k ) ; p k ) k ← k + 2 , S ← S ∪ { k } ; else if φ ( x k + 2 ) > φ ( x k ) ( * return to x k and search along p k * ) Find α k such that φ ( x k + 3 ) ≤ φ ( x k ) + ηα k D ( φ ( x k ) ; p k ) ; Compute x k + 3 (cid:3) x k + α k p k ; k ← k + 3 , S ← S ∪ { k } ; else Compute a direction p k + 2 from x k + 2 ; Find α k + 2 such that φ ( x k + 3 ) ≤ φ ( x k + 2 ) + ηα k + 2 D ( φ ( x k + 2 ) ; p k + 2 ) ; Set x k + 3 ← x k + 2 + α k + 2 p k + 2 ; k ← k + 3 , S ← S ∪ { k } ; end end end ( repeat ) The set S is not required by the algorithm and is introduced only to identify the iterates for which a sufﬁcient merit function reduction was obtained . Note that at least a third of the iterates have their indices in S . By using this fact , one can show that various constrained optimization methods that use the watchdog technique are globally convergent . One can also show that for all sufﬁciently large k , the step length is α k (cid:3) 1 and the convergence rate is superlinear . In practice , it may be advantageous to allow increases in the merit function for more than one iteration . Values of ˆ t such as 5 or 8 are typical . As this discussion indicates , care - ful implementations of the watchdog technique have a certain degree of complexity , but 446 C H A P T E R 1 5 . F U N D A M E N T A L S O F C O N S T R A I N E D A L G O R I T H M S the added complexity is worthwhile because the approach has good practical performance . A potential advantage of the watchdog technique over the second - order correction strat - egy is that it may require fewer evaluations of the constraint functions . In the best case , most of the steps will be full steps , and there will rarely be a need to return to an earlier point . NOTES AND REFERENCES Techniques for eliminating linear constraints are described , for example , in Fletcher [ 101 ] and Gill , Murray , and Wright [ 131 ] . For a thorough discussion of merit functions see Boggs and Tolle [ 33 ] and Conn , Gould , and Toint [ 74 ] . Some of the earliest references on nonmonotone methods include Grippo , Lampariello and Lucidi [ 158 ] , and Chamberlain et al [ 57 ] ; see [ 74 ] for a review of nonmonotone techniques and an extensive list of references . The concept of a ﬁlter was introduced by Fletcher and Leyffer [ 105 ] ; our discussion of ﬁlters is based on that paper . Second - order correction steps are motivated and discussed in Fletcher [ 101 ] . ✐ E X E R C I S E S ✐ 15 . 1 In Example 15 . 1 , consider these three choices of the working set : W (cid:3) { 3 } , W (cid:3) { 1 , 2 } , W (cid:3) { 2 , 3 } . Show that none of these working sets are the optimal active set for ( 15 . 5 ) . ✐ 15 . 2 For the problem in Example 15 . 3 , perform simple elimination of the variables x 2 and x 5 to obtain an unconstrained problem in the remaining variables x 1 , x 3 , x 4 , and x 6 . Similarly to ( 15 . 12 ) , express the eliminated variables explicitly in terms of the retained variables . ✐ 15 . 3 Do the following problems have solutions ? Explain . min x 1 + x 2 subject to x 21 + x 22 (cid:3) 2 , 0 ≤ x 1 ≤ 1 , 0 ≤ x 2 ≤ 1 ; min x 1 + x 2 subject to x 21 + x 22 ≤ 1 , x 1 + x 2 (cid:3) 3 ; min x 1 x 2 subject to x 1 + x 2 (cid:3) 2 . ✐ 15 . 4 Show that if in Example 15 . 2 we eliminate x in terms of y , then the correct solution of the problem is obtained by performing unconstrained minimization . ✐ 15 . 5 Show that the basis matrices ( 15 . 15 ) are linearly independent . ✐ 15 . 6 Show that the particular solution Q 1 R − T (cid:23) T b of Ax (cid:3) b is identical to A T ( AA T ) − 1 b . 1 5 . 6 . S E C O N D - O R D E R C O R R E C T I O N A N D N O N M O N O T O N E T E C H N I Q U E S 447 ✐ 15 . 7 In this exercise we compute basis matrices that attempt to compromise between the orthonormal basis ( 15 . 22 ) and simple elimination ( 15 . 15 ) . We assume that the basis matrix is given by the ﬁrst m columns of A , so that P (cid:3) I in ( 15 . 7 ) , and deﬁne Y (cid:3) (cid:1) I ( B − 1 N ) T (cid:2) , Z (cid:3) (cid:1) − B − 1 N I (cid:2) . ( 15 . 37 ) ( a ) Show that the columns of Y and Z are no longer of norm 1 and that the relations AZ (cid:3) 0 and Y T Z (cid:3) 0 hold . Therefore , the columns of Y and Z form a linearly independent set , showing that ( 15 . 37 ) is a valid choice of the basis matrices . ( b ) Show that the particular solution Y ( AY ) − 1 b deﬁned by this choice of Y is , as in the orthogonal factorization approach , the minimum - norm solution of Ax (cid:3) b . More speciﬁcally , show that Y ( AY ) − 1 (cid:3) A T ( AA T ) − 1 . It follows that the matrix Y ( AY ) − 1 is independent of the choice of basis matrix B in ( 15 . 7 ) , and its conditioning is determined by that of A alone . ( Note , however , that the matrix Z still depends explicitly on B , so a careful choice of B is needed to ensure well conditioning in this part of the computation . ) ✐ 15 . 8 Verify that by adding the inequality constraint 3 x 1 + 2 x 3 ≥ 1 to the problem ( 15 . 11 ) , the elimination ( 15 . 12 ) transforms the problem into one of minimizing the function ( 15 . 13 ) subject to the inequality constraint ( 15 . 23 ) . This is pag Printer : O C H A P T E R 16 Quadratic Programming An optimization problem with a quadratic objective function and linear constraints is called a quadratic program . Problems of this type are important in their own right , and they also arise as subproblems in methods for general constrained optimization , such as sequential quadratic programming ( Chapter 18 ) , augmented Lagrangian methods ( Chapter 17 ) , and interior - point methods ( Chapter 19 ) . C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G 449 The general quadratic program ( QP ) can be stated as min x q ( x ) (cid:3) 12 x T Gx + x T c ( 16 . 1a ) subject to a Ti x (cid:3) b i , i ∈ E , ( 16 . 1b ) a Ti x ≥ b i , i ∈ I , ( 16 . 1c ) where G is a symmetric n × n matrix , E and I are ﬁnite sets of indices , and c , x , and { a i } , i ∈ E ∪ I , are vectors in IR n . Quadratic programs can always be solved ( or shown to be infeasible ) in a ﬁnite amount of computation , but the effort required to ﬁnd a solution depends strongly on the characteristics of the objective function and the number of inequality constraints . If the Hessian matrix G is positive semideﬁnite , we say that ( 16 . 1 ) is a convex QP , and in this case the problem is often similar in difﬁculty to a linear program . ( Strictly convex QPs are those in which G is positive deﬁnite . ) Nonconvex QPs , in which G is an indeﬁnite matrix , can be more challenging because they can have several stationary points and local minima . In this chapter we focus primarily on convex quadratic programs . We start by considering an interesting application of quadratic programming . ❏ E XAMPLE 16 . 1 ( P ORTFOLIO O PTIMIZATION ) Every investor knows that there is a tradeoff between risk and return : To increase the expected return on investment , an investor must be willing to tolerate greater risks . Portfolio theory studies how to model this tradeoff given a collection of n possible investments with returns r i , i (cid:3) 1 , 2 , . . . , n . The returns r i are usually not known in advance and are often assumed to be random variables that follow a normal distribution . We can characterize these variables by their expected value µ i (cid:3) E [ r i ] and their variance σ 2 i (cid:3) E [ ( r i − µ i ) 2 ] . The variance measures the ﬂuctuations of the variable r i about its mean , so that larger values of σ i indicate riskier investments . The returns are not in general independent , and we can deﬁne correlations between pairs of returns as follows : ρ ij (cid:3) E [ ( r i − µ i ) ( r j − µ j ) ] σ i σ j , for i , j (cid:3) 1 , 2 , . . . , n . The correlation measures the tendency of the return on investments i and j to move in the same direction . Two investments whose returns tend to rise and fall together have a positive correlation ; the nearer ρ ij is to 1 , the more closely the two investments track each other . Investments whose returns tend to move in opposite directions have a negative correlation . An investor constructs a portfolio by putting a fraction x i of the available funds into investment i , for i (cid:3) 1 , 2 , . . . , n . Assuming that all available funds are invested and that short - selling is not allowed , the constraints are (cid:4) ni (cid:3) 1 x i (cid:3) 1 and x ≥ 0 . The return on the 450 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G portfolio is given by R (cid:3) n (cid:3) i (cid:3) 1 x i r i . ( 16 . 2 ) To measure the desirability of the portfolio , we need to obtain measures of its expected return and variance . The expected return is simply E [ R ] (cid:3) E (cid:1) n (cid:3) i (cid:3) 1 x i r i (cid:2) (cid:3) n (cid:3) i (cid:3) 1 x i E [ r i ] (cid:3) x T µ , while the variance is given by Var [ R ] (cid:3) E [ ( R − E [ R ] ) 2 ] (cid:3) n (cid:3) i (cid:3) 1 n (cid:3) j (cid:3) 1 x i x j σ i σ j ρ ij (cid:3) x T Gx , where the n × n symmetric positive semideﬁnite matrix G deﬁned by G ij (cid:3) ρ ij σ i σ j is called the covariance matrix . Ideally , we would like to ﬁnd a portfolio for which the expected return x T µ is large while the variance x T Gx is small . In the model proposed by Markowitz [ 201 ] , we combine these two aims into a single objective function with the aid of a “risk tolerance parameter” denoted by κ , and we solve the following problem to ﬁnd the optimal portfolio : max x T µ − κ x T Gx , subject to n (cid:3) i (cid:3) 1 x i (cid:3) 1 , x ≥ 0 . The value chosen for the nonnegative parameter κ depends on the preferences of the individual investor . Conservative investors , who place more emphasis on minimizing risk in their portfolio , would choose a large value of κ to increase the weight of the variance measure in the objective function . More daring investors , who are prepared to take on more risk in the hope of a higher expected return , would choose a smaller value of κ . The difﬁculty in applying this portfolio optimization technique to real - life investing lies in deﬁning the expected returns , variances , and correlations for the investments in question . Financial professionals often combine historical data with their own insights and expectations to produce values of these quantities . ❐ 1 6 . 1 . E Q U A L I T Y - C O N S T R A I N E D Q U A D R A T I C P R O G R A M S 451 16 . 1 EQUALITY - CONSTRAINED QUADRATIC PROGRAMS We begin our discussion of algorithms for quadratic programming by considering the case in which only equality constraints are present . Techniques for this special case are applicable also to problems with inequality constraints since , as we see later in this chapter , some algorithms for general QP require the solution of an equality - constrained QP at each iteration . PROPERTIES OF EQUALITY - CONSTRAINED QPs For simplicity , we write the equality constraints in matrix form and state the equality - constrained QP as follows : min x q ( x ) def (cid:3) 12 x T Gx + x T c ( 16 . 3a ) subject to Ax (cid:3) b , ( 16 . 3b ) where A is the m × n Jacobian of constraints ( with m ≤ n ) whose rows are a Ti , i ∈ E and b is the vector in IR m whose components are b i , i ∈ E . For the present , we assume that A has full row rank ( rank m ) so that the constraints ( 16 . 3b ) are consistent . ( In Section 16 . 8 we discuss the case in which A is rank deﬁcient . ) The ﬁrst - order necessary conditions for x ∗ to be a solution of ( 16 . 3 ) state that there is a vector λ ∗ such that the following system of equations is satisﬁed : (cid:1) G − A T A 0 (cid:2) (cid:1) x ∗ λ ∗ (cid:2) (cid:3) (cid:1) − c b (cid:2) . ( 16 . 4 ) Theseconditionsareaconsequenceofthegeneralresultforﬁrst - orderoptimalityconditions , Theorem 12 . 1 . As in Chapter 12 , we call λ ∗ the vector of Lagrange multipliers . The system ( 16 . 4 ) can be rewritten in a form that is useful for computation by expressing x ∗ as x ∗ (cid:3) x + p , where x is some estimate of the solution and p is the desired step . By introducing this notation and rearranging the equations , we obtain (cid:1) G A T A 0 (cid:2) (cid:1) − p λ ∗ (cid:2) (cid:3) (cid:1) g h (cid:2) , ( 16 . 5 ) where h (cid:3) Ax − b , g (cid:3) c + Gx , p (cid:3) x ∗ − x . ( 16 . 6 ) The matrix in ( 16 . 5 ) is called the Karush – Kuhn – Tucker ( KKT ) matrix , and the fol - lowing result gives conditions under which it is nonsingular . As in Chapter 15 , we use Z to 452 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G denote the n × ( n − m ) matrix whose columns are a basis for the null space of A . That is , Z has full rank and satisﬁes AZ (cid:3) 0 . Lemma 16 . 1 . Let A have full row rank , and assume that the reduced - Hessian matrix Z T GZ is positive deﬁnite . Then the KKT matrix K (cid:3) (cid:1) G A T A 0 (cid:2) ( 16 . 7 ) is nonsingular , and hence there is a unique vector pair ( x ∗ , λ ∗ ) satisfying ( 16 . 4 ) . P ROOF . Suppose there are vectors w and v such that (cid:1) G A T A 0 (cid:2) (cid:1) w v (cid:2) (cid:3) 0 . ( 16 . 8 ) Since A w (cid:3) 0 , we have from ( 16 . 8 ) that 0 (cid:3) (cid:1) w v (cid:2) T (cid:1) G A T A 0 (cid:2) (cid:1) w v (cid:2) (cid:3) w T G w . Since w lies in the null space of A , it can be written as w (cid:3) Zu for some vector u ∈ IR n − m . Therefore , we have 0 (cid:3) w T G w (cid:3) u T Z T GZu , which by positive deﬁniteness of Z T GZ implies that u (cid:3) 0 . Therefore , w (cid:3) 0 , and by ( 16 . 8 ) , A T v (cid:3) 0 . Full row rank of A then implies that v (cid:3) 0 . We conclude that equation ( 16 . 8 ) is satisﬁed only if w (cid:3) 0 and v (cid:3) 0 , so the matrix is nonsingular , as claimed . (cid:1) ❏ E XAMPLE 16 . 2 Consider the quadratic programming problem min q ( x ) (cid:3) 3 x 21 + 2 x 1 x 2 + x 1 x 3 + 2 . 5 x 22 + 2 x 2 x 3 + 2 x 23 − 8 x 1 − 3 x 2 − 3 x 3 , subject to x 1 + x 3 (cid:3) 3 , x 2 + x 3 (cid:3) 0 . ( 16 . 9 ) 1 6 . 1 . E Q U A L I T Y - C O N S T R A I N E D Q U A D R A T I C P R O G R A M S 453 We can write this problem in the form ( 16 . 3 ) by deﬁning G (cid:3) ⎡ ⎢⎣ 6 2 1 2 5 2 1 2 4 ⎤ ⎥⎦ , c (cid:3) ⎡ ⎢⎣ − 8 − 3 − 3 ⎤ ⎥⎦ , A (cid:3) (cid:1) 1 0 1 0 1 1 (cid:2) , b (cid:3) (cid:1) 3 0 (cid:2) . The solution x ∗ and optimal Lagrange multiplier vector λ ∗ are given by x ∗ (cid:3) ( 2 , − 1 , 1 ) T , λ ∗ (cid:3) ( 3 , − 2 ) T . In this example , the matrix G is positive deﬁnite , and the null - space basis matrix can be deﬁned as in ( 15 . 15 ) , giving Z (cid:3) ( − 1 , − 1 , 1 ) T . ( 16 . 10 ) ❐ We have seen that when the conditions of Lemma 16 . 1 are satisﬁed , there is a unique vector pair ( x ∗ , λ ∗ ) that satisﬁes the ﬁrst - order necessary conditions for ( 16 . 3 ) . In fact , the second - order sufﬁcient conditions ( see Theorem 12 . 6 ) are also satisﬁed at ( x ∗ , λ ∗ ) , so x ∗ is a strict local minimizer of ( 16 . 3 ) . In fact , we can use a direct argument to show that x ∗ is a global solution of ( 16 . 3 ) . Theorem 16 . 2 . Let A have full row rank and assume that the reduced - Hessian matrix Z T GZ is positive deﬁnite . Then the vector x ∗ satisfying ( 16 . 4 ) is the unique global solution of ( 16 . 3 ) . P ROOF . Let x be any other feasible point ( satisfying Ax (cid:3) b ) , and as before , let p denote the difference x ∗ − x . Since Ax ∗ (cid:3) Ax (cid:3) b , we have that Ap (cid:3) 0 . By substituting into the objective function ( 16 . 3a ) , we obtain q ( x ) (cid:3) 12 ( x ∗ − p ) T G ( x ∗ − p ) + c T ( x ∗ − p ) (cid:3) 12 p T Gp − p T Gx ∗ − c T p + q ( x ∗ ) . ( 16 . 11 ) From ( 16 . 4 ) we have that Gx ∗ (cid:3) − c + A T λ ∗ , so from Ap (cid:3) 0 we have that p T Gx ∗ (cid:3) p T ( − c + A T λ ∗ ) (cid:3) − p T c . By substituting this relation into ( 16 . 11 ) , we obtain q ( x ) (cid:3) 12 p T Gp + q ( x ∗ ) . 454 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G Since p lies in the null space of A , we can write p (cid:3) Zu for some vector u ∈ IR n − m , so that q ( x ) (cid:3) 12 u T Z T GZu + q ( x ∗ ) . By positive deﬁniteness of Z T GZ , we conclude that q ( x ) > q ( x ∗ ) except when u (cid:3) 0 , that is , when x (cid:3) x ∗ . Therefore , x ∗ is the unique global solution of ( 16 . 3 ) . (cid:1) When the reduced Hessian matrix Z T GZ is positive semideﬁnite with zero eigenval - ues , the vector x ∗ satisfying ( 16 . 4 ) is a local minimizer but not a strict local minimizer . If the reduced Hessian has negative eigenvalues , then x ∗ is only a stationary point , not a local minimizer . 16 . 2 DIRECT SOLUTION OF THE KKT SYSTEM In this section we discuss efﬁcient methods for solving the KKT system ( 16 . 5 ) . The ﬁrst important observation is that if m ≥ 1 , the KKT matrix is always indeﬁnite . We deﬁne the inertia of a symmetric matrix K to be the scalar triple that indicates the numbers n + , n − , and n 0 of positive , negative , and zero eigenvalues , respectively , that is , inertia ( K ) (cid:3) ( n + , n − , n 0 ) . The following result characterizes the inertia of the KKT matrix . Theorem 16 . 3 . Let K be deﬁned by ( 16 . 7 ) , and suppose that A has rank m . Then inertia ( K ) (cid:3) inertia ( Z T GZ ) + ( m , m , 0 ) . Therefore , if Z T GZ is positive deﬁnite , inertia ( K ) (cid:3) ( n , m , 0 ) . The proof of this result is given in [ 111 ] , for example . Note that the assumptions of this theorem are satisﬁed by Example 16 . 2 . Hence , if we construct the 5 × 5 matrix K using the data of this example , we obtain inertia ( K ) (cid:3) ( 3 , 2 , 0 ) . KnowingthattheKKTsystemisindeﬁnite , wenowdescribethemaindirecttechniques used to solve ( 16 . 5 ) . FACTORING THE FULL KKT SYSTEM One option for solving ( 16 . 5 ) is to perform a triangular factorization on the full KKT matrix and then perform backward and forward substitution with the triangular factors . Because of indeﬁniteness , we cannot use the Cholesky factorization . We could use Gaussian 1 6 . 2 . D I R E C T S O L U T I O N O F T H E K K T S Y S T E M 455 elimination with partial pivoting ( or a sparse variant thereof ) to obtain the L and U factors , but this approach has the disadvantage that it ignores the symmetry . The most effective strategy in this case is to use a symmetric indeﬁnite factorization , which we have discussed in Chapter 3 and the Appendix . For a general symmetric matrix K , this factorization has the form P T K P (cid:3) L BL T , ( 16 . 12 ) where P is a permutation matrix , L is unit lower triangular , and B is block - diagonal with either 1 × 1 or 2 × 2 blocks . The symmetric permutations deﬁned by the matrix P are introduced for numerical stability of the computation and , in the case of large sparse K , for maintaining sparsity . The computational cost of the symmetric indeﬁnite factorization ( 16 . 12 ) is typically about half the cost of sparse Gaussian elimination . To solve ( 16 . 5 ) , we ﬁrst compute the factorization ( 16 . 12 ) of the coefﬁcient matrix . We then perform the following sequence of operations to arrive at the solution : solve Lz (cid:3) P T (cid:1) g h (cid:2) to obtain z ; solve B ˆ z (cid:3) z to obtain ˆ y ; solve L T ¯ z (cid:3) ˆ z to obtain ¯ z ; set (cid:1) − p λ ∗ (cid:2) (cid:3) P ¯ z . Since multiplications with the permutation matrices P and P T can be performed by simply rearranging vector components , they are inexpensive . Solution of the system B ˆ z (cid:3) z entails solving a number of small 1 × 1 and 2 × 2 systems , so the number of operations is a small multiple of the system dimension ( m + n ) , again inexpensive . Triangular substitutions with L and L T are more costly . Their precise cost depends on the amount of sparsity , but is usually signiﬁcantly less than the cost of performing the factorization ( 16 . 12 ) . This approach of factoring the full ( n + m ) × ( n + m ) KKT matrix ( 16 . 7 ) is quite effective on many problems . It may be expensive , however , when the heuristics for choosing the permutation matrix P are not able to maintain sparsity in the L factor , so that L becomes much more dense than the original coefﬁcient matrix . SCHUR - COMPLEMENT METHOD Assuming that G is positive deﬁnite , we can multiply the ﬁrst equation in ( 16 . 5 ) by AG − 1 and then subtract the second equation to obtain a linear system in the vector λ ∗ alone : ( AG − 1 A T ) λ ∗ (cid:3) ( AG − 1 g − h ) . ( 16 . 13 ) 456 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G We solve this symmetric positive deﬁnite system for λ ∗ and then recover p from the ﬁrst equation in ( 16 . 5 ) by solving Gp (cid:3) A T λ ∗ − g . ( 16 . 14 ) This approach requires us to perform operations with G − 1 , as well as to compute the factorization of the m × m matrix AG − 1 A T . Therefore , it is most useful when : • G is well conditioned and easy to invert ( for instance , when G is diagonal or block - diagonal ) ; or • G − 1 is known explicitly through a quasi - Newton updating formula ; or • the number of equality constraints m is small , so that the number of backsolves needed to form the matrix AG − 1 A T is not too large . The name “Schur - Complement method” derives from the fact that , by applying block Gaussian elimination to ( 16 . 7 ) using G as the pivot , we obtain the block upper triangular system (cid:1) G A T 0 − AG − 1 A T (cid:2) . ( 16 . 15 ) In linear algebra terminology , the matrix AG − 1 A T is the Schur complement of G in the matrix K of ( 16 . 7 ) . By applying this block elimination technique to the system ( 16 . 5 ) , and performing a block backsolve , we obtain ( 16 . 13 ) , ( 16 . 14 ) . We can use an approach like the Schur - complement method to derive an explicit inverse formula for the KKT matrix in ( 16 . 5 ) . This formula is (cid:1) G A T A 0 (cid:2) − 1 (cid:3) (cid:1) C E E T F (cid:2) , ( 16 . 16 ) with C (cid:3) G − 1 − G − 1 A T ( AG − 1 A T ) − 1 AG − 1 , E (cid:3) G − 1 A T ( AG − 1 A T ) − 1 , F (cid:3) − ( AG − 1 A T ) − 1 . The solution of ( 16 . 5 ) can be obtained by multiplying its right - hand side by this inverse matrix . If we take advantage of common expressions , and group the terms appropriately , we recover the approach ( 16 . 13 ) , ( 16 . 14 ) . 1 6 . 2 . D I R E C T S O L U T I O N O F T H E K K T S Y S T E M 457 NULL - SPACE METHOD The null - space method does not require nonsingularity of G and therefore has wider applicability than the Schur - complement method . It assumes only that the conditions of Lemma 16 . 1 hold , namely , that A has full row rank and that Z T GZ is positive deﬁnite . However , it requires knowledge of the null - space basis matrix Z . Like the Schur - complement method , it exploits the block structure in the KKT system to decouple ( 16 . 5 ) into two smaller systems . Suppose that we partition the vector p in ( 16 . 5 ) into two components , as follows : p (cid:3) Y p Y + Zp Z , ( 16 . 17 ) where Z is the n × ( n − m ) null - space matrix , Y is any n × m matrix such that [ Y | Z ] is nonsingular , p Y is an m - vector , and p Z is an ( n − m ) - vector . The matrices Y and Z were discussed in Section 15 . 3 , where Figure 15 . 4 shows that Y x Y is a particular solution of Ax (cid:3) b , while Zx Z is a displacement along these constraints . By substituting p into the second equation of ( 16 . 5 ) and recalling that AZ (cid:3) 0 , we obtain ( AY ) p Y (cid:3) − h . ( 16 . 18 ) Since A has rank m and [ Y | Z ] is n × n nonsingular , the product A [ Y | Z ] (cid:3) [ AY | 0 ] has rank m . Therefore , AY is a nonsingular m × m matrix , and p Y is well determined by the equations ( 16 . 18 ) . Meanwhile , we can substitute ( 16 . 17 ) into the ﬁrst equation of ( 16 . 5 ) to obtain − GY p Y − GZp Z + A T λ ∗ (cid:3) g and multiply by Z T to obtain ( Z T GZ ) p Z (cid:3) − Z T GY p Y − Z T g . ( 16 . 19 ) This system can be solved by performing a Cholesky factorization of the reduced - Hessian matrix Z T GZ to determine p Z . We therefore can compute the total step p (cid:3) Y p Y + Zp Z . To obtain the Lagrange multiplier , we multiply the ﬁrst block row in ( 16 . 5 ) by Y T to obtain the linear system ( AY ) T λ ∗ (cid:3) Y T ( g + Gp ) , ( 16 . 20 ) which can be solved for λ ∗ . 458 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G ❏ E XAMPLE 16 . 3 Consider the problem ( 16 . 9 ) given in Example 16 . 2 . We can choose Y (cid:3) ⎡ ⎢ ⎣ 2 / 3 − 1 / 3 − 1 / 3 2 / 3 1 / 3 1 / 3 ⎤ ⎥ ⎦ and set Z as in ( 16 . 10 ) . Note that AY (cid:3) I . Suppose we have x (cid:3) ( 0 , 0 , 0 ) T in ( 16 . 6 ) . Then h (cid:3) Ax − b (cid:3) − b , g (cid:3) c + Gx (cid:3) c (cid:3) ⎡ ⎢⎣ − 8 − 3 − 3 ⎤ ⎥⎦ . Simple calculation shows that p Y (cid:3) (cid:1) 3 0 (cid:2) , p Z (cid:3) (cid:9) 0 (cid:10) , so that p (cid:3) x ∗ − x (cid:3) Y p Y + Zp Z (cid:3) ⎡ ⎢⎣ 2 − 1 1 ⎤ ⎥⎦ . After recovering λ ∗ from ( 16 . 20 ) , we conclude that x ∗ (cid:3) ⎡ ⎢⎣ 2 − 1 1 ⎤ ⎥⎦ , λ ∗ (cid:3) (cid:1) 3 − 2 (cid:2) . ❐ The null - space approach can be very effective when the number of degrees of freedom n − m is small . Its main limitation lies in the need for the null - space matrix Z which , as we have seen in Chapter 15 , can be expensive to compute in some large problems . The matrix Z is not uniquely deﬁned and , if it is poorly chosen , the reduced system ( 16 . 19 ) may become ill conditioned . If we choose Z to have orthonormal columns , as is normally done in software for small and medium - sized problems , then the conditioning of Z T GZ is at least as good as that of G itself . When A is large and sparse , however , an orthonormal Z is expensive to 1 6 . 3 . I T E R A T I V E S O L U T I O N O F T H E K K T S Y S T E M 459 compute , so for practical reasons we are often forced to use one of the less reliable choices of Z described in Chapter 15 . It is difﬁcult to give hard and fast rules about the relative effectiveness of null - space and Schur - complement methods , because factors such as ﬁll - in during computation of Z vary signiﬁcantly even among problems of the same dimension . In general , we can recommend the Schur - complement method if G is positive deﬁnite and AG − 1 A T can be computed relatively cheaply ( because G is easy to invert or because m is small relative to n ) . Otherwise , the null - space method is often preferable , in particular when it is much more expensive to compute factors of G than to compute the null - space matrix Z and the factors of Z T GZ . 16 . 3 ITERATIVE SOLUTION OF THE KKT SYSTEM An alternative to the direct factorization techniques discussed in the previous section is to use an iterative method to solve the KKT system ( 16 . 5 ) . Iterative methods are suitable for solving very large systems and often lend themselves well to parallelization . The conjugate gradient ( CG ) method is not recommended for solving the full system ( 16 . 5 ) as written , because it can be unstable on systems that are not positive deﬁnite . Better options are Krylov methods for general linear or symmetric indeﬁnite systems . Candidates include the GMRES , QMR , and LSQR methods ; see the Notes and References at the end of the chapter . Other iterative methods can be derived from the null - space approach by applying the conjugate gradient method to the reduced system ( 16 . 19 ) . Methods of this type are key to the algorithms of Chapters 18 and 19 , and are discussed in the remainder of this section . We assume throughout that Z T GZ is positive deﬁnite . CG APPLIED TO THE REDUCED SYSTEM We begin our discussion of iterative null - space methods by deriving the underlying equations in the notation of the equality - constrained QP ( 16 . 3 ) . Expressing the solution of the quadratic program ( 16 . 3 ) as x ∗ (cid:3) Y x Y + Zx Z , ( 16 . 21 ) for some vectors x Z ∈ IR n − m , x Y ∈ IR m , the constraints Ax (cid:3) b yield AY x Y (cid:3) b , ( 16 . 22 ) which determines the vector x Y . In Chapter 15 , various practical choices of Y are described , some of which allow ( 16 . 22 ) to be solved economically . Substituting ( 16 . 21 ) into ( 16 . 3 ) , we see that x Z solves the unconstrained reduced problem min x Z 12 x Z T Z T GZx Z + x Z T c Z , 460 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G where c Z (cid:3) Z T GY x Y + Z T c . ( 16 . 23 ) The solution x Z satisﬁes the linear system Z T GZx Z (cid:3) − c Z . ( 16 . 24 ) Since Z T GZ is positive deﬁnite , we can apply the CG method to this linear system and substitute x Z into ( 16 . 21 ) to obtain a solution of ( 16 . 3 ) . As discussed in Chapter 5 , preconditioning can improve the rate of convergence of the CG iteration , so we assume that a preconditioner W ZZ is given . The preconditioned CG method ( Algorithm 5 . 3 ) applied to the ( n − m ) - dimensional reduced system ( 16 . 24 ) is as follows . ( We denote the steps produced by the CG iteration by d Z . ) Algorithm 16 . 1 ( Preconditioned CG for Reduced Systems ) . Choose an initial point x Z ; Compute r Z (cid:3) Z T GZx Z + c Z , g Z (cid:3) W ZZ − 1 r Z , and d Z (cid:3) − g Z ; repeat α ← r Z T g Z / d Z T Z T GZd Z ; ( 16 . 25a ) x Z ← x Z + α d Z ; ( 16 . 25b ) r Z + ← r Z + α Z T GZd Z ; ( 16 . 25c ) g Z + ← W ZZ − 1 r Z + ; ( 16 . 25d ) β ← ( r Z + ) T g Z + / r Z T g Z ; ( 16 . 25e ) d Z ← − g Z + + β d Z ; ( 16 . 25f ) g Z ← g Z + ; r Z ← r Z + ; ( 16 . 25g ) until a termination test is satisﬁed . This iteration may be terminated when , for example , r Z T W ZZ − 1 r Z is sufﬁciently small . In this approach , it is not necessary to form the reduced Hessian Z T GZ explicitly because the CG method requires only that we compute matrix - vector products involving this matrix . In fact , it is not even necessary to form Z explicitly as long as we are able to compute products of Z and Z T with arbitrary vectors . For some choices of Z , these products are much cheaper to compute than Z itself , as we have seen in Chapter 15 . The preconditioner W ZZ is a symmetric , positive deﬁnite matrix of dimension n − m , which might be chosen to cluster the eigenvalues of W ZZ − 1 / 2 ( Z T GZ ) W ZZ − 1 / 2 and to reduce the span between the smallest and largest eigenvalues . An ideal choice of preconditioner is one for which W ZZ − 1 / 2 ( Z T GZ ) W ZZ − 1 / 2 (cid:3) I , that is , W ZZ (cid:3) Z T GZ . Motivated by this ideal , we consider preconditioners of the form W ZZ (cid:3) Z T H Z , ( 16 . 26 ) 1 6 . 3 . I T E R A T I V E S O L U T I O N O F T H E K K T S Y S T E M 461 where H is a symmetric matrix such that Z T H Z is positive deﬁnite . Some choices of H are discussed below . Preconditioners of the form ( 16 . 26 ) allow us to apply the CG method in n - dimensional space , as we discuss next . THE PROJECTED CG METHOD It is possible to design a modiﬁcation of the Algorithm 16 . 1 that avoids operating with the null - space basis Z , provided we use a preconditioner of the form ( 16 . 26 ) and a particular solution of the equation Ax (cid:3) b . This approach works implicitly with an orthogonal matrix Z and is not affected by ill conditioning in A or by a poor choice of Z . After the solution x Z of ( 16 . 24 ) has been computed by using Algorithm 16 . 1 , it must be multiplied by Z and substituted in ( 16 . 21 ) to give the solution of the quadratic program ( 16 . 3 ) . Alternatively , we may rewrite Algorithm 16 . 1 to work directly with the vector x (cid:3) Zx Z + Y x Y , where the Y x Y term is ﬁxed at the start and the x Z term is updated ( implicitly ) within each iteration . To specify this form of the CG algorithm , we introduce the n - vectors x , r , g , and d , which satisfy x (cid:3) Zx Z + Y x Y , Z T r (cid:3) r Z , g (cid:3) Zg Z , and d (cid:3) Zd Z , respectively . We also deﬁne the scaled n × n projection matrix P as follows : P (cid:3) Z ( Z T H Z ) − 1 Z T , ( 16 . 27 ) where H is the preconditioning matrix from ( 16 . 26 ) . The CG iteration in n - dimensional space can be speciﬁed as follows . Algorithm 16 . 2 ( Projected CG Method ) . Choose an initial point x satisfying Ax (cid:3) b ; Compute r (cid:3) Gx + c , g (cid:3) Pr , and d (cid:3) − g ; repeat α ← r T g / d T Gd ; ( 16 . 28a ) x ← x + α d ; ( 16 . 28b ) r + ← r + α Gd ; ( 16 . 28c ) g + ← Pr + ; ( 16 . 28d ) β ← ( r + ) T g + / r T g ; ( 16 . 28e ) d ← − g + + β d ; ( 16 . 28f ) g ← g + ; r ← r + ; ( 16 . 28g ) until a convergence test is satisﬁed . 462 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G A practical stop test is to terminate when r T g (cid:3) r T Pr is smaller than a prescribed tolerance . Note that the vector g + , which we call the preconditioned residual , has been deﬁned to be in the null space of A . As a result , in exact arithmetic , all the search directions d generated by Algorithm 16 . 2 also lie in the null space of A , and thus the iterates x all satisfy Ax (cid:3) b . It is not difﬁcult to verify ( see Exercise 16 . 14 ) that the iteration is well deﬁned if Z T GZ and Z T H Z are positive deﬁnite . The reader can also verify that the iterates x generated by Algorithm 16 . 2 are related to the iterates x Z of Algorithm 16 . 1 via ( 16 . 21 ) . Two simple choices of the preconditioning matrix H are H (cid:3) diag ( | G ii | ) and H (cid:3) I . In some applications , it is effective to deﬁne H as a block diagonal submatrix of G . Algorithm 16 . 2 makes use of the null - space basis Z only through the operator ( 16 . 27 ) . It is possible , however , to compute Pr without knowing a representation of the null - space basis Z . For simplicity , we ﬁrst consider the case in which H (cid:3) I , so that P is the orthogonal projection operator onto the null space of A . We use P I to denote this special case of P , that is , P I (cid:3) Z ( Z T Z ) − 1 Z T . ( 16 . 29 ) The computation of the preconditioned residual g + (cid:3) P I r + in ( 16 . 28d ) can be performed in two ways . The ﬁrst is to express P I by the equivalent formula P I (cid:3) I − A T ( AA T ) − 1 A ( 16 . 30 ) and thus compute g + (cid:3) P I r + . We can then write g + (cid:3) r + − A T v + , where v + is the solution of the system AA T v + (cid:3) Ar + . ( 16 . 31 ) This approach for computing the projection g + (cid:3) P I r + is called the normal equa - tions approach ; the system ( 16 . 31 ) can be solved by using a Cholesky factorization of AA T . The second approach is to express the projection ( 16 . 28d ) as the solution of the augmented system (cid:1) I A T A 0 (cid:2) (cid:1) g + v + (cid:2) (cid:3) (cid:1) r + 0 (cid:2) , ( 16 . 32 ) which can be solved by means of a symmetric indeﬁnite factorization , as discussed earlier . We call this approach the augmented system approach . 1 6 . 4 . I N E Q U A L I T Y - C O N S T R A I N E D P R O B L E M S 463 Wesupposenowthatthepreconditioninghasthegeneralformof ( 16 . 27 ) and ( 16 . 28d ) . When H is nonsingular , we can compute g + as follows : g + (cid:3) Pr + , where P (cid:3) H − 1 (cid:7) I − A T ( AH − 1 A T ) − 1 AH − 1 (cid:8) . ( 16 . 33 ) Otherwise , when z T Hz (cid:9)(cid:3) 0 for all nonzero z with Az (cid:3) 0 , we can ﬁnd g + as the solution of the system (cid:1) H A T A 0 (cid:2) (cid:1) g + v + (cid:2) (cid:3) (cid:1) r + 0 (cid:2) . ( 16 . 34 ) While ( 16 . 33 ) is unappealing when H − 1 does not have a simple form , ( 16 . 34 ) is a useful generalization of ( 16 . 32 ) . A “perfect” preconditioner is obtained by taking H (cid:3) G , but other choices for H are also possible , provided that Z T H Z is positive deﬁnite . The matrix in ( 16 . 34 ) is often called a constraint preconditioner . None of these procedures for computing the projection makes use of a null - space basis Z ; only the factorization of matrices involving A is required . Signiﬁcantly , all these forms allow us to compute an initial point satisfying Ax (cid:3) b . The operator g + (cid:3) P I r + relies on a factorization of AA T from which we can compute x (cid:3) A T ( AA T ) − 1 b , while factorizations of the system matrices in ( 16 . 32 ) and ( 16 . 34 ) allow us to ﬁnd a suitable x by solving (cid:1) I A T A 0 (cid:2) (cid:1) x y (cid:2) (cid:3) (cid:1) 0 b (cid:2) or (cid:1) H A T A 0 (cid:2) (cid:1) x y (cid:2) (cid:3) (cid:1) 0 b (cid:2) . Therefore we can compute an initial point for Algorithm 16 . 2 at the cost of one backsolve , using the factorization of the system needed to perform the projection operators . We point out that these approaches for computing g + can give rise to signiﬁ - cant round - off errors , so the use of iterative reﬁnement is recommended to improve accuracy . 16 . 4 INEQUALITY - CONSTRAINED PROBLEMS In the remainder of the chapter we discuss several classes of algorithms for solving convex quadratic programs that contain both inequality and equality constraints . Active - set methods have been widely used since the 1970s and are effective for small - and medium - sized problems . They allow for efﬁcient detectionof unboundedness andinfeasibility andtypically return an accurate estimate of the optimal active set . Interior - point methods are more recent , having become popular in the 1990s . They are well suited for large problems but may not be the most effective when a series of related QPs must be solved . We also study a special 464 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G type of active - set methods called a gradient projection method , which is most effective when the only constraints in the problem are bounds on the variables . OPTIMALITY CONDITIONS FOR INEQUALITY - CONSTRAINED PROBLEMS Webeginourdiscussionwithabriefreviewoftheoptimalityconditionsforinequality - constrained quadratic programming , then discuss some of the less obvious properties of the solutions . Theorem 12 . 1 can be applied to ( 16 . 1 ) by noting that the Lagrangian for this problem is L ( x , λ ) (cid:3) 12 x T Gx + x T c − (cid:3) i ∈ I ∪ E λ i ( a Ti x − b i ) . ( 16 . 35 ) As in Deﬁnition 12 . 1 , the active set A ( x ∗ ) consists of the indices of the constraints for which equality holds at x ∗ : A ( x ∗ ) (cid:3) 2 i ∈ E ∪ I | a Ti x ∗ (cid:3) b i 3 . ( 16 . 36 ) By specializing the KKT conditions ( 12 . 34 ) to this problem , we ﬁnd that any solution x ∗ of ( 16 . 1 ) satisﬁes the following ﬁrst - order conditions , for some Lagrange multipliers λ ∗ i , i ∈ A ( x ∗ ) : Gx ∗ + c − (cid:3) i ∈ A ( x ∗ ) λ ∗ i a i (cid:3) 0 , ( 16 . 37a ) a Ti x ∗ (cid:3) b i , for all i ∈ A ( x ∗ ) , ( 16 . 37b ) a Ti x ∗ ≥ b i , for all i ∈ I \ A ( x ∗ ) , ( 16 . 37c ) λ ∗ i ≥ 0 , for all i ∈ I ∩ A ( x ∗ ) . ( 16 . 37d ) A technical point : In Theorem 12 . 1 we assumed that the linear independence con - straint qualiﬁcation ( LICQ ) was satisﬁed . As mentioned in Section 12 . 6 , this theorem still holds if we replace LICQ by other constraint qualiﬁcations , such as linearity of the con - straints , which is certainly satisﬁed for quadratic programming . Hence , in the optimality conditions for quadratic programming given above , we need not assume that the active constraints are linearly independent at the solution . For convex QP , when G is positive semideﬁnite , the conditions ( 16 . 37 ) are in fact sufﬁcient for x ∗ to be a global solution , as we now prove . Theorem 16 . 4 . If x ∗ satisﬁestheconditions ( 16 . 37 ) forsome λ ∗ i , i ∈ A ( x ∗ ) , and G ispositivesemideﬁnite , then x ∗ is a global solution of ( 16 . 1 ) . 1 6 . 4 . I N E Q U A L I T Y - C O N S T R A I N E D P R O B L E M S 465 P ROOF . If x is any other feasible point for ( 16 . 1 ) , we have that a Ti x (cid:3) b i for all i ∈ E and a Ti x ≥ b i for all i ∈ A ( x ∗ ) ∩ I . Hence , a Ti ( x − x ∗ ) (cid:3) 0 for all i ∈ E and a Ti ( x − x ∗ ) ≥ 0 for all i ∈ A ( x ∗ ) ∩ I . Using these relationships , together with ( 16 . 37a ) and ( 16 . 37d ) , we have that ( x − x ∗ ) T ( Gx ∗ + c ) (cid:3) (cid:3) i ∈ E λ ∗ i a Ti ( x − x ∗ ) + (cid:3) i ∈ A ( x ∗ ) ∩ I λ ∗ i a Ti ( x − x ∗ ) ≥ 0 . ( 16 . 38 ) By elementary manipulation , we ﬁnd that q ( x ) (cid:3) q ( x ∗ ) + ( x − x ∗ ) T ( Gx ∗ + c ) + 12 ( x − x ∗ ) T G ( x − x ∗ ) ≥ q ( x ∗ ) + 12 ( x − x ∗ ) T G ( x − x ∗ ) ≥ q ( x ∗ ) , where the ﬁrst inequality follows from ( 16 . 38 ) and the second inequality follows from positive semideﬁniteness of G . We have shown that q ( x ) ≥ q ( x ∗ ) for any feasible x , so x ∗ is a global solution . (cid:1) By a trivial modiﬁcation of this proof , we see that x ∗ is actually the unique global solution when G is positive deﬁnite . We can also apply the theory from Section 12 . 5 to derive second - order optimality conditions for ( 16 . 1 ) . Second - order sufﬁcient conditions for x ∗ to be a local minimizer are satisﬁed if Z T GZ is positive deﬁnite , where Z is deﬁned to be a null - space basis matrix for the active constraint Jacobian matrix , which is the matrix whose rows are a Ti for all i ∈ A ( x ∗ ) . In this case , x ∗ is a strict local solution , according to Theorem 12 . 6 . When G is not positive deﬁnite , the general problem ( 16 . 1 ) may have more than one strict local solution . As mentioned above , such problems are called “nonconvex QPs” or “indeﬁnite QPs , ” and they cause some complications for algorithms . Examples of indeﬁnite QPs are illustrated in Figure 16 . 1 . On the left we have plotted the feasible region and the contours of a quadratic objective q ( x ) in which G has one positive and one negative eigenvalue . We have indicated by + or − that the function tends toward plus or minus inﬁnity in that direction . Note that x ∗∗ is a local maximizer , x ∗ a local minimizer , and the center of the box is a stationary point . The picture on the right in Figure 16 . 1 , in which both eigenvalues of G are negative , shows a global maximizer at ˜ x and local minimizers at x ∗ and x ∗∗ . DEGENERACY A second property that causes difﬁculties for some algorithms is degeneracy . Con - fusingly , this term has been given a variety of meanings . It refers to situations in which 466 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G x * x * * x ~ x feasibleregion + + x * * x * - - Figure 16 . 1 Nonconvex quadratic programs . x * x * Figure 16 . 2 Degenerate solutions of quadratic programs . ( a ) the active constraint gradients a i , i ∈ A ( x ∗ ) , are linearly dependent at the solution x ∗ , and / or ( b ) the strict complementarity condition of Deﬁnition 12 . 5 fails to hold , that is , there is some index i ∈ A ( x ∗ ) such that all Lagrange multipliers satisfying ( 16 . 37 ) have λ ∗ i (cid:3) 0 . ( Such constraints are weakly active according to Deﬁnition 12 . 8 . ) Two examples of degeneracy are shown in Figure 16 . 2 . In the left - hand picture , there is a single active constraint at the solution x ∗ , which is also an unconstrained minimizer of the objective function . In the notation of ( 16 . 37a ) , we have that Gx ∗ + c (cid:3) 0 , so that 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 467 the lone Lagrange multiplier must be zero . In the right - hand picture , three constraints are active at the solution x ∗ . Since each of the three constraint gradients is a vector in IR 2 , they must be linearly dependent . Lack of strict complementarity is also illustrated by the problem min x 21 + ( x 2 + 1 ) 2 subject to x ≥ 0 , which has a solution at x ∗ (cid:3) 0 at which both constraints are active . Strict complementarity does not hold at x ∗ because the Lagrange multiplier associated with the active constraint x 1 ≥ 0 is zero . Degeneracy can cause problems for algorithms for two main reasons . First , linear dependence of the active constraint gradients can cause numerical difﬁculties in the step computation because certain matrices that we need to factor become rank deﬁcient . Second , when the problem contains weakly active constraints , it is difﬁcult for the algorithm to determine whether these constraints are active at the solution . In the case of active - set methods and gradient projection methods ( described below ) , this indecisiveness can cause the algorithm to zigzag as the iterates move on and off the weakly active constraints on successive iterations . Safeguards must be used to prevent such behavior . 16 . 5 ACTIVE - SET METHODS FOR CONVEX QPs We now describe active - set methods for solving quadratic programs of the form ( 16 . 1 ) containing equality and inequality constraints . We consider only the convex case , in which the matrix G in ( 16 . 1a ) is positive semideﬁnite . The case in which G is an indeﬁnite matrix raises complications in the algorithms and is outside the scope of this book . We refer to Gould [ 147 ] for a discussion of nonconvex QPs . If the contents of the optimal active set ( 16 . 36 ) were known in advance , we could ﬁnd the solution x ∗ by applying one of the techniques for equality - constrained QP of Sections 16 . 2 and 16 . 3 to the problem min x q ( x ) (cid:3) 12 x T Gx + x T c subject to a Ti x (cid:3) b i , i ∈ A ( x ∗ ) . Of course , we usually do not have prior knowledge of A ( x ∗ ) and , as we now see , de - termination of this set is the main challenge facing algorithms for inequality - constrained QP . We have already encountered an active - set approach for linear programming in Chap - ter 13 , namely , the simplex method . In essence , the simplex method starts by making a guess of the optimal active set , then repeatedly uses gradient and Lagrange multiplier information to drop one index from the current estimate of A ( x ∗ ) and add a new index , until optimality 468 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G is detected . Active - set methods for QP differ from the simplex method in that the iterates ( and the solution x ∗ ) are not necessarily vertices of the feasible region . Active - set methods for QP come in three varieties : primal , dual , and primal - dual . We restrict our discussion to primal methods , which generate iterates that remain feasible with respect to the primal problem ( 16 . 1 ) while steadily decreasing the objective function q ( x ) . Primal active - set methods ﬁnd a step from one iterate to the next by solving a quadratic subproblem in which some of the inequality constraints ( 16 . 1c ) , and all the equality con - straints ( 16 . 1b ) , are imposed as equalities . This subset is referred to as the working set and is denoted at the k th iterate x k by W k . An important requirement we impose on W k is that the gradients a i of the constraints in the working set be linearly independent , even when the full set of active constraints at that point has linearly dependent gradients . Given an iterate x k and the working set W k , we ﬁrst check whether x k minimizes the quadratic q in the subspace deﬁned by the working set . If not , we compute a step p by solving an equality - constrained QP subproblem in which the constraints corresponding to the working set W k are regarded as equalities and all other constraints are temporarily disregarded . To express this subproblem in terms of the step p , we deﬁne p (cid:3) x − x k , g k (cid:3) Gx k + c . By substituting for x into the objective function ( 16 . 1a ) , we ﬁnd that q ( x ) (cid:3) q ( x k + p ) (cid:3) 12 p T Gp + g Tk p + ρ k , where ρ k (cid:3) 12 x Tk Gx k + c T x k is independent of p . Since we can drop ρ k from the objective without changing the solution of the problem , we can write the QP subproblem to be solved at the k th iteration as follows : min p 1 2 p T Gp + g Tk p ( 16 . 39a ) subject to a Ti p (cid:3) 0 , i ∈ W k . ( 16 . 39b ) We denote the solution of this subproblem by p k . Note that for each i ∈ W k , the value of a Ti x does not change as we move along p k , since we have a Ti ( x k + α p k ) (cid:3) a Ti x k (cid:3) b i for all α . Since the constraints in W k were satisﬁed at x k , they are also satisﬁed at x k + α p k , for any value of α . Since G is positive deﬁnite , the solution of ( 16 . 39 ) can be computed by any of the techniques described in Section 16 . 2 . Supposing for the moment that the optimal p k from ( 16 . 39 ) is nonzero , we need to decide how far to move along this direction . If x k + p k is feasible with respect to all the constraints , we set x k + 1 (cid:3) x k + p k . Otherwise , we set x k + 1 (cid:3) x k + α k p k , ( 16 . 40 ) 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 469 where the step - length parameter α k is chosen to be the largest value in the range [ 0 , 1 ] for which all constraints are satisﬁed . We can derive an explicit deﬁnition of α k by considering what happens to the constraints i / ∈ W k , since the constraints i ∈ W k will certainly be satisﬁed regardless of the choice of α k . If a Ti p k ≥ 0 for some i / ∈ W k , then for all α k ≥ 0 we have a Ti ( x k + α k p k ) ≥ a Ti x k ≥ b i . Hence , constraint i will be satisﬁed for all nonnegative choices of the step - length parameter . Whenever a Ti p k < 0 for some i / ∈ W k , however , we have that a Ti ( x k + α k p k ) ≥ b i only if α k ≤ b i − a Ti x k a Ti p k . To maximize the decrease in q , we want α k to be as large as possible in [ 0 , 1 ] subject to retaining feasibility , so we obtain the following deﬁnition : α k def (cid:3) min (cid:24) 1 , min i / ∈ W k , a Ti p k < 0 b i − a Ti x k a Ti p k (cid:25) . ( 16 . 41 ) We call the constraints i for which the minimum in ( 16 . 41 ) is achieved the blocking con - straints . ( If α k (cid:3) 1 and no new constraints are active at x k + α k p k , then there are no blocking constraints on this iteration . ) Note that it is quite possible for α k to be zero , because we could have a Ti p k < 0 for some constraint i that is active at x k but not a member of the current working set W k . If α k < 1 , that is , the step along p k was blocked by some constraint not in W k , a new working set W k + 1 is constructed by adding one of the blocking constraints to W k . We continue to iterate in this manner , adding constraints to the working set until we reach a point ˆ x that minimizes the quadratic objective function over its current working set ˆ W . It is easy to recognize such a point because the subproblem ( 16 . 39 ) has solution p (cid:3) 0 . Since p (cid:3) 0 satisﬁes the optimality conditions ( 16 . 5 ) for ( 16 . 39 ) , we have that (cid:3) i ∈ ˆ W a i ˆ λ i (cid:3) g (cid:3) G ˆ x + c , ( 16 . 42 ) for some Lagrange multipliers ˆ λ i , i ∈ ˆ W . It follows that ˆ x and ˆ λ satisfy the ﬁrst KKT condition ( 16 . 37a ) , if we deﬁne the multipliers corresponding to the inequality constraints that are not in the working set to be zero . Because of the control imposed on the step length , ˆ x is also feasible with respect to all the constraints , so the second and third KKT conditions ( 16 . 37b ) and ( 16 . 37c ) are satisﬁed at this point . We now examine the signs of the multipliers corresponding to the inequality con - straints in the working set , that is , the indices i ∈ ˆ W ∩ I . If these multipliers are all nonnegative , the fourth KKT condition ( 16 . 37d ) is also satisﬁed , so we conclude that ˆ x is a KKT point for the original problem ( 16 . 1 ) . In fact , since G is positive semideﬁnite , we have 470 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G from Theorem 16 . 4 that ˆ x is a global solution of ( 16 . 1 ) . ( As noted after Theorem 16 . 4 , ˆ x is a strict local minimizer and the unique global solution if G is positive deﬁnite . ) If , on the other hand , one or more of the multipliers ˆ λ j , j ∈ ˆ W ∩ I , is negative , the condition ( 16 . 37d ) is not satisﬁed and the objective function q ( · ) may be decreased by dropping one of these constraints , as shown in Section 12 . 3 . Thus , we remove an index j corresponding to one of the negative multipliers from the working set and solve a new subproblem ( 16 . 39 ) for the new step . We show in the following theorem that this strategy produces a direction p at the next iteration that is feasible with respect to the dropped constraint . We continue to assume that the constraint gradients a i for i in the working set are linearly independent . After the algorithm has been fully stated , we discuss how this property can be maintained . Theorem 16 . 5 . Suppose that the point ˆ x satisﬁes ﬁrst - order conditions for the equality - constrained subproblem with working set ˆ W ; that is , equation ( 16 . 42 ) is satisﬁed along with a Ti ˆ x (cid:3) b i for all i ∈ ˆ W . Suppose , too , that the constraint gradients a i , i ∈ ˆ W , are linearly independent and that there is an index j ∈ ˆ W such that ˆ λ j < 0 . Let p be the solution obtained by dropping the constraint j and solving the following subproblem : min p 12 p T Gp + ( G ˆ x + c ) T p , ( 16 . 43a ) subject to a Ti p (cid:3) 0 , for all i ∈ ˆ W with i (cid:9)(cid:3) j . ( 16 . 43b ) Then p is a feasible direction for constraint j , that is , a Tj p ≥ 0 . Moreover , if p satisﬁes second - order sufﬁcient conditions for ( 16 . 43 ) , then we have that a Tj p > 0 , and that p is a descent direction for q ( · ) . P ROOF . Since p solves ( 16 . 43 ) , we have from the results of Section 16 . 1 that there are multipliers ˜ λ i , for all i ∈ ˆ W with i (cid:9)(cid:3) j , such that (cid:3) i ∈ ˆ W , i (cid:9)(cid:3) j ˜ λ i a i (cid:3) Gp + ( G ˆ x + c ) . ( 16 . 44 ) In addition , we have by second - order necessary conditions that if Z is a null - space basis vector for the matrix (cid:9) a Ti (cid:10) i ∈ ˆ W , i (cid:9)(cid:3) j , then Z T GZ is positive semideﬁnite . Clearly , p has the form p (cid:3) Zp Z for some vector p Z , so it follows that p T Gp ≥ 0 . 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 471 We have made the assumption that ˆ x and ˆ W satisfy the relation ( 16 . 42 ) . By subtracting ( 16 . 42 ) from ( 16 . 44 ) , we obtain (cid:3) i ∈ ˆ W , i (cid:9)(cid:3) j ( ˜ λ i − ˆ λ i ) a i − ˆ λ j a j (cid:3) Gp . ( 16 . 45 ) By taking inner products of both sides with p and using the fact that a Ti p (cid:3) 0 for all i ∈ ˆ W with i (cid:9)(cid:3) j , we have that − ˆ λ j a Tj p (cid:3) p T Gp . ( 16 . 46 ) Since p T Gp ≥ 0 and ˆ λ j < 0 by assumption , it follows that a Tj p ≥ 0 . If the second - order sufﬁcient conditions of Section 12 . 5 are satisﬁed , we have that Z T GZ deﬁned above is positive deﬁnite . From ( 16 . 46 ) , we can have a Tj p (cid:3) 0 only if p T Gp (cid:3) p T Z Z T GZp Z (cid:3) 0 , which happens only if p Z (cid:3) 0 and p (cid:3) 0 . But if p (cid:3) 0 , then by substituting into ( 16 . 45 ) and using linear independence of a i for i ∈ ˆ W , we must have that ˆ λ j (cid:3) 0 , which contradicts our choice of j . We conclude that p T Gp > 0 in ( 16 . 46 ) , and therefore a Tj p > 0 whenever p satisﬁes the second - order sufﬁcient conditions for ( 16 . 43 ) . The claim that p is a descent direction for q ( · ) is proved in Theorem 16 . 6 below . (cid:1) While any index j for which ˆ λ j < 0 usually will yield a direction p along which the algorithm can make progress , the most negative multiplier is often chosen in practice ( and in the algorithm speciﬁed below ) . This choice is motivated by the sensitivity analysis given in Chapter 12 , which shows that the rate of decrease in the objective function when one constraint is removed is proportional to the magnitude of the Lagrange multiplier for that constraint . As in linear programming , however , the step along the resulting direction may be short ( as when it is blocked by a new constraint ) , so the amount of decrease in q is not guaranteed to be greater than for other possible choices of j . We conclude with a result that shows that whenever p k obtained from ( 16 . 39 ) is nonzero and satisﬁes second - order sufﬁcient optimality conditions for the current working set , it is a direction of strict descent for q ( · ) . Theorem 16 . 6 . Suppose that the solution p k of ( 16 . 39 ) is nonzero and satisﬁes the second - order sufﬁcient conditions for optimality for that problem . Then the function q ( · ) is strictly decreasing along the direction p k . P ROOF . Since p k satisﬁes the second - order conditions , that is , Z T GZ is positive deﬁnite for the matrix Z whose columns are a basis of the null space of the constraints ( 16 . 39b ) , we have by applying Theorem 16 . 2 to ( 16 . 39 ) that p k is the unique global solution of ( 16 . 39 ) . Since p (cid:3) 0 is also a feasible point for ( 16 . 39 ) , its objective value in ( 16 . 39a ) must be larger 472 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G than that of p k , so we have 12 p Tk Gp k + g Tk p k < 0 . Since p Tk Gp k ≥ 0 by convexity , this inequality implies that g Tk p k < 0 . Therefore , we have q ( x k + α k p k ) (cid:3) q ( x k ) + α g T k p k + 1 2 α 2 p T k Gp k < q ( x k ) , for all α > 0 sufﬁciently small . (cid:1) When G is positive deﬁnite—the strictly convex case—the second - order sufﬁcient conditions are satisﬁed for all feasible subproblems of the form ( 16 . 39 ) . Hence , it follows from the result above that we obtain a strict decrease in q ( · ) whenever p k (cid:9)(cid:3) 0 . This fact is signiﬁcant when we discuss ﬁnite termination of the algorithm . SPECIFICATION OF THE ACTIVE - SET METHOD FOR CONVEX QP Having described the active - set algorithm for convex QP , we now present the following formal speciﬁcation . We assume that the objective function q is bounded in the feasible set ( 16 . 1b ) , ( 16 . 1c ) . Algorithm 16 . 3 ( Active - Set Method for Convex QP ) . Compute a feasible starting point x 0 ; Set W 0 to be a subset of the active constraints at x 0 ; for k (cid:3) 0 , 1 , 2 , . . . Solve ( 16 . 39 ) to ﬁnd p k ; if p k (cid:3) 0 Compute Lagrange multipliers ˆ λ i that satisfy ( 16 . 42 ) , with ˆ W (cid:3) W k ; if ˆ λ i ≥ 0 for all i ∈ W k ∩ I stop with solution x ∗ (cid:3) x k ; else j ← arg min j ∈ W k ∩ I ˆ λ j ; x k + 1 ← x k ; W k + 1 ← W k \ { j } ; else ( * p k (cid:9)(cid:3) 0 * ) Compute α k from ( 16 . 41 ) ; x k + 1 ← x k + α k p k ; if there are blocking constraints Obtain W k + 1 by adding one of the blocking constraints to W k ; else W k + 1 ← W k ; end ( for ) 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 473 Various techniques can be used to determine an initial feasible point . One such is to use the “Phase I” approach for linear programming described in Chapter 13 . Though no signiﬁcant modiﬁcations are needed to generalize this method from linear program - ming to quadratic programming , we describe a variant here that allows the user to supply an initial estimate ˜ x of the vector x . This estimate need not be feasible , but a good choice based on knowledge of the QP may reduce the work needed in the Phase I step . Given ˜ x , we deﬁne the following feasibility linear program : min ( x , z ) e T z subject to a Ti x + γ i z i (cid:3) b i , i ∈ E , a Ti x + γ i z i ≥ b i , i ∈ I , z ≥ 0 , where e (cid:3) ( 1 , 1 , . . . , 1 ) T , γ i (cid:3) − sign ( a Ti ˜ x − b i ) for i ∈ E , and γ i (cid:3) 1 for i ∈ I . A feasible initial point for this problem is then x (cid:3) ˜ x , z i (cid:3) | a Ti ˜ x − b i | ( i ∈ E ) , z i (cid:3) max ( b i − a Ti ˜ x , 0 ) ( i ∈ I ) . It is easy to verify that if ˜ x is feasible for the original problem ( 16 . 1 ) , then ( ˜ x , 0 ) is optimal for the feasibility subproblem . In general , if the original problem has feasible points , then the optimal objective value in the subproblem is zero , and any solution of the subproblem yields a feasible point for the original problem . The initial working set W 0 for Algorithm 16 . 3 can be found by taking a linearly independent subset of the active constraints at the solution of the feasibility problem . An alternative approach is a penalty ( or “big M ” ) method , which does away with the “Phase I” and instead includes a measure of infeasibility in the objective that is guaranteed to be zero at the solution . That is , we introduce a scalar artiﬁcial variable η into ( 16 . 1 ) to measure the constraint violation , and we solve the problem min ( x , η ) 12 x T Gx + x T c + M η , subject to ( a Ti x − b i ) ≤ η , i ∈ E , − ( a Ti x − b i ) ≤ η , i ∈ E , ( 16 . 47 ) b i − a Ti x ≤ η , i ∈ I , 0 ≤ η , for some large positive value of M . It can be shown by applying the theory of exact penalty functions ( see Chapter 17 ) that whenever there exist feasible points for the original problem ( 16 . 1 ) , then for all M sufﬁciently large , the solution of ( 16 . 47 ) will have η (cid:3) 0 , with an x component that is a solution for ( 16 . 1 ) . 474 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G Our strategy is to use some heuristic to choose a value of M and solve ( 16 . 47 ) by the usual means . If the solution we obtain has a positive value of η , we increase M and try again . Note that a feasible point is easy to obtain for the subproblem ( 16 . 47 ) : We set x (cid:3) ˜ x ( where , as before , ˜ x is the user - supplied initial guess ) and choose η large enough that all the constraints in ( 16 . 47 ) are satisﬁed . This approach is , in fact , an exact penalty method using the (cid:1) ∞ norm ; see Chapter 17 . A variant of ( 16 . 47 ) that penalizes the (cid:1) 1 norm of the constraint violation rather than the (cid:1) ∞ norm is as follows : min ( x , s , t , v ) 12 x T Gx + x T c + Me T E ( s + t ) + Me T I v subject to a Ti x − b i + s i − t i (cid:3) 0 , i ∈ E , a Ti x − b i + v i ≥ 0 , i ∈ I , ( 16 . 48 ) s ≥ 0 , t ≥ 0 , v ≥ 0 . Here , e E is the vector ( 1 , 1 , . . . , 1 ) T of length | E | ; similarly for e I . The slack variables s i , t i , and v i soak up any infeasibility in the constraints . In the following example we use subscripts on the vectors x and p to denote their components , and we use superscripts to indicate the iteration index . For example , x 1 denotes the ﬁrst component , while x 4 denotes the fourth iterate of the vector x . x 1 x , x 2 3 x , x 0 1 x 2 x 4 ( 2 , 0 ) ( 2 , 2 ) x 5 ( 4 , 1 ) ( 0 , 1 ) Figure 16 . 3 Iterates of the active - set method . 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 475 ❏ E XAMPLE 16 . 4 We apply Algorithm 16 . 3 to the following simple 2 - dimensional problem illustrated in Figure 16 . 3 . min x q ( x ) (cid:3) ( x 1 − 1 ) 2 + ( x 2 − 2 . 5 ) 2 ( 16 . 49a ) subject to x 1 − 2 x 2 + 2 ≥ 0 , ( 16 . 49b ) − x 1 − 2 x 2 + 6 ≥ 0 , ( 16 . 49c ) − x 1 + 2 x 2 + 2 ≥ 0 , ( 16 . 49d ) x 1 ≥ 0 , ( 16 . 49e ) x 2 ≥ 0 . ( 16 . 49f ) We refer the constraints , in order , by indices 1 through 5 . For this problem it is easy to determine a feasible initial point ; say x 0 (cid:3) ( 2 , 0 ) T . Constraints 3 and 5 are active at this point , and we set W 0 (cid:3) { 3 , 5 } . ( Note that we could just as validly have chosen W 0 (cid:3) { 5 } or W 0 (cid:3) { 3 } or even W (cid:3) ∅ ; each choice would lead the algorithm to perform somewhat differently . ) Since x 0 lies on a vertex of the feasible region , it is obviously a minimizer of the objective function q with respect to the working set W 0 ; that is , the solution of ( 16 . 39 ) with k (cid:3) 0 is p (cid:3) 0 . We can then use ( 16 . 42 ) to ﬁnd the multipliers ˆ λ 3 and ˆ λ 5 associated with the active constraints . Substitution of the data from our problem into ( 16 . 42 ) yields (cid:1) − 1 2 (cid:2) ˆ λ 3 + (cid:1) 0 1 (cid:2) ˆ λ 5 (cid:3) (cid:1) 2 − 5 (cid:2) , which has the solution ( ˆ λ 3 , ˆ λ 5 ) (cid:3) ( − 2 , − 1 ) . We now remove constraint 3 from the working set , because it has the most negative multiplier , and set W 1 (cid:3) { 5 } . We begin iteration 1 by ﬁnding the solution of ( 16 . 39 ) for k (cid:3) 1 , which is p 1 (cid:3) ( − 1 , 0 ) T . The step - length formula ( 16 . 41 ) yields α 1 (cid:3) 1 , and the new iterate is x 2 (cid:3) ( 1 , 0 ) T . There are no blocking constraints , so that W 2 (cid:3) W 1 (cid:3) { 5 } , and we ﬁnd at the start of iteration 2 that the solution of ( 16 . 39 ) is p 2 (cid:3) 0 . From ( 16 . 42 ) we deduce that the Lagrange multiplier for the lone working constraint is ˆ λ 5 (cid:3) − 5 , so we drop 5 from the working set to obtain W 3 (cid:3) ∅ . Iteration 3 starts by solving the unconstrained problem , to obtain the solution p 3 (cid:3) ( 0 , 2 . 5 ) T . The formula ( 16 . 41 ) yields a step length of α 3 (cid:3) 0 . 6 and a new iterate x 4 (cid:3) ( 1 , 1 . 5 ) T . There is a single blocking constraint ( constraint 1 ) , so we obtain W 4 (cid:3) { 1 } . The solution of ( 16 . 39 ) for k (cid:3) 4 is then p 4 (cid:3) ( 0 . 4 , 0 . 2 ) T , and the new step length is 1 . There are no blocking constraints on this step , so the next working set is unchanged : W 5 (cid:3) { 1 } . The new iterate is x 5 (cid:3) ( 1 . 4 , 1 . 7 ) T . 476 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G Finally , we solve ( 16 . 39 ) for k (cid:3) 5 to obtain a solution p 5 (cid:3) 0 . The formula ( 16 . 42 ) yields a multiplier ˆ λ 1 (cid:3) 0 . 8 , so we have found the solution . We set x ∗ (cid:3) ( 1 . 4 , 1 . 7 ) T and terminate . ❐ FURTHER REMARKS ON THE ACTIVE - SET METHOD We noted above that there is ﬂexibility in the choice of the initial working set and that each initial choice leads to a different iteration sequence . When the initial active constraints have independent gradients , as above , we can include them all in W 0 . Alternatively , we can select a subset . For instance , if in the example above we have chosen W 0 (cid:3) { 3 } , the ﬁrst iterate would have yielded p 0 (cid:3) ( 0 . 2 , 0 . 1 ) T and a new iterate of x 1 (cid:3) ( 2 . 2 , 0 . 1 ) T . If we had chosen W 0 (cid:3) { 5 } , we would have moved immediately to the new iterate x 1 (cid:3) ( 1 , 0 ) T , without ﬁrst performing the operation of dropping the index 3 , as is done in the example . If we had selected W 0 (cid:3) ∅ , we would have obtained p 1 (cid:3) ( − 1 , 2 . 5 ) T , α 1 (cid:3) 23 , a new iterate of x 1 (cid:3) ( 43 , 53 ) T , and a new working set of W 1 (cid:3) { 1 } . The solution x ∗ would have been found on the next iteration . Even if the initial working set W 0 coincides with the initial active set , the sets W k and A ( x k ) may differ at later iterations . For instance , when a particular step encounters more than one blocking constraint , just one of them is added to the working set , so the identiﬁcation between W k and A ( x k ) is broken . Moreover , subsequent iterates differ in general according to what choice is made . We require the constraint gradients in W 0 to be linearly independent , and our strategy for modifying the working set ensures that this same property holds for all subsequent workingsets W k . Whenweencounterablockingconstraintonaparticularstep , itsconstraint normal cannot be a linear combination of the normals a i in the current working set ( see Exercise 16 . 18 ) . Hence , linear independence is maintained after the blocking constraint is added to the working set . On the other hand , deletion of an index from the working set cannot introduce linear dependence . The strategy of removing the constraint corresponding to the most negative Lagrange multiplier often works well in practice but has the disadvantage that it is susceptible to the scaling of the constraints . ( By multiplying constraint i by some factor β > 0 we do not change the geometry of the optimization problem , but we introduce a scaling of 1 / β to the corresponding multiplier λ i . ) Choice of the most negative multiplier is analogous to Dantzig’s original pivot rule for the simplex method in linear programming ( see Chapter 13 ) and , as we noted there , strategies that are less sensitive to scaling often give better results . We do not discuss this advanced topic further . We note that the strategy of adding or deleting at most one constraint at each iteration of the Algorithm 16 . 3 places a natural lower bound on the number of iterations needed to reach optimality . Suppose , for instance , that we have a problem in which m inequality constraints are active at the solution x ∗ but that we start from a point x 0 that is strictly 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 477 feasible with respect to all the inequality constraints . In this case , the algorithm will need at least m iterations to move from x 0 to x ∗ . Even more iterations will be required if the algorithm adds some constraint j to the working set at some iteration , only to remove it at a later step . FINITE TERMINATION OF ACTIVE - SET ALGORITHM ON STRICTLY CONVEX QPs It is not difﬁcult to show that , under certain assumptions , Algorithm 16 . 3 converges for strictly convex QPs , that is , it identiﬁes the solution x ∗ in a ﬁnite number of iterations . This claim is certainly true if we assume that the method always takes a nonzero step length α k whenever the direction p k computed from ( 16 . 39 ) is nonzero . Our argument proceeds as follows : • If the solution of ( 16 . 39 ) is p k (cid:3) 0 , the current point x k is the unique global minimizer of q ( · ) for the working set W k ; see Theorem 16 . 6 . If it is not the solution of the original problem ( 16 . 1 ) ( that is , at least one of the Lagrange multipliers is negative ) , Theorems 16 . 5 and 16 . 6 together show that the step p k + 1 computed after a constraint is dropped will be a strict decrease direction for q ( · ) . Therefore , because of our assumption α k > 0 , we have that the value of q is lower than q ( x k ) at all subsequent iterations . It follows that the algorithm can never return to the working set W k , because subsequent iterates have values of q that are lower than the global minimizer for this working set . • The algorithm encounters an iterate k for which p k (cid:3) 0 solves ( 16 . 39 ) at least on every n th iteration . To demonstrate this claim , we note that for any k at which p k (cid:9)(cid:3) 0 , either we have α k (cid:3) 1 ( in which case we reach the minimizer of q on the current working set W k , so that the next iteration will yield p k + 1 (cid:3) 0 ) , or else a constraint is added to the working set W k . If the latter situation occurs repeatedly , then after at most n iterations the working set will contain n indices , which correspond to n linearly independent vectors . The solution of ( 16 . 39 ) will then be p k (cid:3) 0 , since only the zero vector will satisfy the constraints ( 16 . 39b ) . • Taken together , the two statements above indicate that the algorithm ﬁnds the global minimum of q on its current working set periodically ( at least once every n iterations ) and that , having done so , it never visits this particular working set again . It follows that , since there are only a ﬁnite number of possible working sets , the algorithm cannot iterate forever . Eventually , it encounters a minimizer for a current working set that satisﬁes optimality conditions for ( 16 . 1 ) , and it terminates with a solution . The assumption that we can always take a nonzero step along a nonzero descent direction p k calculated from ( 16 . 39 ) guarantees that the algorithm does not undergo cycling . This term refers to the situation in which a sequence of consecutive iterations results in no movementiniterate x , whiletheworkingset W k undergoesdeletionsandadditionsofindices 478 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G and eventually repeats itself . That is , for some integers k and l ≥ 1 , we have that x k (cid:3) x k + l and W k (cid:3) W k + l . At each iterate in the cycle , a constraint is dropped ( as in Theorem 16 . 5 ) , but a new constraint i / ∈ W k is encountered immediately without any movement along the computed direction p . Procedures for handling degeneracy and cycling in quadratic programming are similar to those for linear programming discussed in Chapter 13 ; we do not discuss them here . Most QP implementations simply ignore the possibility of cycling . UPDATING FACTORIZATIONS We have seen that the step computation in the active - set method given in Al - gorithm 16 . 3 requires the solution of the equality - constrained subproblem ( 16 . 39 ) . As mentioned at the beginning of this chapter , this computation amounts to solving the KKT system ( 16 . 5 ) . Since the working set can change by just one index at every iteration , the KKT matrix differs in at most one row and one column from the previous iteration’s KKT matrix . Indeed , G remains ﬁxed , whereas the matrix A of constraint gradients corresponding to the current working set may change through addition and / or deletion of a single row . It follows from this observation that we can compute the matrix factors needed to solve ( 16 . 39 ) at the current iteration by updating the factors computed at the previous iteration , rather than recomputing them from scratch . These updating techniques are crucial to the efﬁciency of active - set methods . We limit our discussion to the case in which the step is computed with the null - space method ( 16 . 17 ) – ( 16 . 20 ) . Suppose that A has m linearly independent rows and assume that the bases Y and Z are deﬁned by means of a QR factorization of A ( see Section 15 . 3 for details ) . Thus A T (cid:23) (cid:3) Q (cid:1) R 0 (cid:2) (cid:3) (cid:9) Q 1 Q 2 (cid:10) (cid:1) R 0 (cid:2) ( 16 . 50 ) ( see ( 15 . 21 ) ) , where (cid:23) is a permutation matrix ; R is square , upper triangular and nonsingu - lar ; Q (cid:3) (cid:9) Q 1 Q 2 (cid:10) is n × n orthogonal ; and Q 1 and R both have m columns while Q 2 has n − m columns . As noted in Chapter 15 , we can choose Z to be simply the orthonormal matrix Q 2 . Suppose that one constraint is added to the working set at the next iteration , so that the new constraint matrix is ¯ A T (cid:3) (cid:9) A T a (cid:10) , where a is a column vector of length n such that ¯ A T retains full column rank . As we now show , there is an economical way to update the Q and R factors in ( 16 . 50 ) to obtain new factors ( and hence a new null - space basis matrix ¯ Z , with n − m − 1 columns ) for the expanded matrix ¯ A . Note ﬁrst that , since Q 1 Q T 1 + Q 2 Q T 2 (cid:3) I , we have ¯ A T (cid:1) (cid:23) 0 0 1 (cid:2) (cid:3) (cid:9) A T (cid:23) a (cid:10) (cid:3) Q (cid:1) R Q T 1 a 0 Q T 2 a (cid:2) . ( 16 . 51 ) 1 6 . 5 . A C T I V E - S E T M E T H O D S F O R C O N V E X Q P S 479 We can now deﬁne an orthogonal matrix ˆ Q that transforms the vector Q T 2 a to a vector in which all elements except the ﬁrst are zero . That is , we have ˆ Q ( Q T 2 a ) (cid:3) (cid:1) γ 0 (cid:2) , where γ is a scalar . ( Since ˆ Q is orthogonal , we have (cid:8) Q T 2 a (cid:8) (cid:3) | γ | . ) From ( 16 . 51 ) we now have ¯ A T (cid:1) (cid:23) 0 0 1 (cid:2) (cid:3) Q ⎡ ⎢⎣ R Q T 1 a 0 ˆ Q T (cid:1) γ 0 (cid:2) ⎤ ⎥⎦ (cid:3) Q (cid:1) I 0 0 ˆ Q T (cid:2) ⎡ ⎢⎣ R Q T 1 a 0 γ 0 0 ⎤ ⎥⎦ . This factorization has the form ¯ A T ¯ (cid:23) (cid:3) ¯ Q (cid:1) ¯ R 0 (cid:2) , where ¯ (cid:23) (cid:3) (cid:1) (cid:23) 0 0 1 (cid:2) , ¯ Q (cid:3) Q (cid:1) I 0 0 ˆ Q T (cid:2) (cid:3) ) Q 1 Q 2 ˆ Q T * , ¯ R (cid:3) (cid:1) R Q T 1 a 0 γ (cid:2) . We can therefore choose ¯ Z to be the last n − m − 1 columns of Q 2 ˆ Q T . If we know Z explicitly and need an explicit representation of ¯ Z , we need to account for the cost of obtaining ˆ Q and the cost of forming the product Q 2 ˆ Q T (cid:3) Z ˆ Q T . Because of the special structure of ˆ Q , this cost is of order n ( n − m ) , compared to the cost of computing ( 16 . 50 ) from scratch , which is of order n 2 m . The updating strategy is less expensive , especially when the null space is small ( that is , when n − m (cid:24) n ) . An updating technique can also be designed for the case in which a row is removed from A . This operation has the effect of deleting a column from R in ( 16 . 50 ) , thus disturbing the upper triangular property of this matrix by introducing a number of nonzeros on the diagonal immediately below the main diagonal of the matrix . Upper triangularity can be restored by applying a sequence of plane rotations . These rotations introduce a number of inexpensive transformations into the ﬁrst m columns of Q , and the updated null - space matrix is obtained by selecting the last n − m + 1 columns from this matrix after the transformations are complete . The new null - space basis in this case has the form ¯ Z (cid:3) (cid:9) ¯ z Z (cid:10) , ( 16 . 52 ) that is , the current matrix Z is augmented by a single column . The total cost of this operation varies with the location of the removed column in A but is in general cheaper 480 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G than recomputing a QR factorization from scratch . For details of these procedures , see Gill et al . [ 124 , Section 5 ] . We now consider the reduced Hessian . Because of the special form of ( 16 . 39 ) , we have h (cid:3) 0 in ( 16 . 5 ) , and the step p Y given in ( 16 . 18 ) is zero . Thus from ( 16 . 19 ) , the null - space component p Z is the solution of ( Z T GZ ) p Z (cid:3) − Z T g . ( 16 . 53 ) We can sometimes ﬁnd ways of updating the factorization of the reduced Hessian Z T GZ after Z has changed . Suppose that we have the Cholesky factorization of the current reduced Hessian , written as Z T GZ (cid:3) LL T , and that at the next step Z changes as in ( 16 . 52 ) , gaining a column after deletion of a constraint . A series of inexpensive , elementary operations can be used to transform the Cholesky factor L into the new factor ¯ L for the new reduced Hessian ¯ Z T G ¯ Z . A variety of other simpliﬁcations are possible . For example , as discussed in Sec - tion 16 . 7 , we can update the reduced gradient Z T g at the same time as we update Z to ¯ Z . 16 . 6 INTERIOR - POINT METHODS The interior - point approach can be applied to convex quadratic programs through a simple extension of the linear - programming algorithms described in Chapter 14 . The resulting primal - dualalgorithmsareeasytodescribeandarequiteefﬁcientonmanytypesofproblems . Extensions of interior - point methods to nonconvex problems are discussed in Chapter 19 . For simplicity , we restrict our attention to convex quadratic programs with inequality constraints , which we write as follows : min x q ( x ) (cid:3) 12 x T Gx + x T c ( 16 . 54a ) subject to Ax ≥ b , ( 16 . 54b ) where G issymmetricandpositivesemideﬁniteandwherethe m × n matrix A andright - hand side b are deﬁned by A (cid:3) [ a i ] i ∈ I , b (cid:3) [ b i ] i ∈ I , I (cid:3) { 1 , 2 , . . . , m } . ( If equality constraints are also present , they can be accommodated with simple extensions to the approaches described below . ) Rewriting the KKT conditions ( 16 . 37 ) in this notation , 1 6 . 6 . I N T E R I O R - P O I N T M E T H O D S 481 we obtain Gx − A T λ + c (cid:3) 0 , Ax − b ≥ 0 , ( Ax − b ) i λ i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , m , λ ≥ 0 . By introducing the slack vector y ≥ 0 , we can rewrite these conditions as Gx − A T λ + c (cid:3) 0 , ( 16 . 55a ) Ax − y − b (cid:3) 0 , ( 16 . 55b ) y i λ i (cid:3) 0 , i (cid:3) 1 , 2 , . . . , m , ( 16 . 55c ) ( y , λ ) ≥ 0 . ( 16 . 55d ) Since we assume that G is positive semideﬁnite , these KKT conditions are not only necessary but also sufﬁcient ( see Theorem 16 . 4 ) , so we can solve the convex quadratic program ( 16 . 54 ) by ﬁnding solutions of the system ( 16 . 55 ) . Given a current iterate ( x , y , λ ) that satisﬁes ( y , λ ) > 0 , we can deﬁne a complementarity measure µ by µ (cid:3) y T λ m . ( 16 . 56 ) As in Chapter 14 , we derive path - following , primal - dual methods by considering the perturbed KKT conditions given by F ( x , y , λ ; σµ ) (cid:3) ⎡ ⎢⎣ Gx − A T λ + c Ax − y − b Y (cid:16) e − σµ e ⎤ ⎥⎦ (cid:3) 0 , ( 16 . 57 ) where Y (cid:3) diag ( y 1 , y 2 , . . . , y m ) , (cid:16) (cid:3) diag ( λ 1 , λ 2 , . . . , λ m ) , e (cid:3) ( 1 , 1 , . . . , 1 ) T , and σ ∈ [ 0 , 1 ] . The solutions of ( 16 . 57 ) for all positive values of σ and µ deﬁne the central path , which is a trajectory that leads to the solution of the quadratic program as σµ tends to zero . By ﬁxing µ and applying Newton’s method to ( 16 . 57 ) , we obtain the linear system ⎡ ⎢⎣ G 0 − A T A − I 0 0 (cid:16) Y ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6) y (cid:6)λ ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r d − r p − (cid:16) Y e + σµ e ⎤ ⎥⎦ , ( 16 . 58 ) 482 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G where r d (cid:3) Gx − A T λ + c , r p (cid:3) Ax − y − b . ( 16 . 59 ) We obtain the next iterate by setting ( x + , y + , λ + ) (cid:3) ( x , y , λ ) + α ( (cid:6) x , (cid:6) y , (cid:6)λ ) , ( 16 . 60 ) where α is chosen to retain the inequality ( y + , λ + ) > 0 and possibly to satisfy various other conditions . In the rest of the chapter we discuss several enhancements of this primal - dual iteration that make it effective in practice . SOLVING THE PRIMAL - DUAL SYSTEM The major computational operation in the interior - point method is the solution of the system ( 16 . 58 ) . The coefﬁcient matrix in this system can be much more costly to factor than the matrix ( 14 . 9 ) arising in linear programming because of the presence of the Hessian matrix G . It is therefore important to exploit the structure of ( 16 . 58 ) by choosing a suitable direct factorization algorithm , or by choosing an appropriate preconditioner for an iterative solver . As in Chapter 14 , the system ( 16 . 58 ) may be restated in more compact forms . The “augmented system” form is (cid:1) G − A T A (cid:16) − 1 Y (cid:2) (cid:1) (cid:6) x (cid:6)λ (cid:2) (cid:3) (cid:1) − r d − r p + ( − y + σµ(cid:16) − 1 e ) (cid:2) . ( 16 . 61 ) After a simple transformation to symmetric form , a symmetric indeﬁnite factorization scheme can be applied to the coefﬁcient matrix in this system . The “normal equations” form ( 14 . 44a ) is ( G + A T Y − 1 (cid:16) A ) (cid:6) x (cid:3) − r d + A T Y − 1 (cid:16) [ − r p − y + σµ(cid:16) − 1 e ] , ( 16 . 62 ) which can be solved by means of a modiﬁed Cholesky algorithm . This approach is effective if the term A T ( Y − 1 (cid:16) ) A is not too dense compared with G , and it has the advantage of being much smaller than ( 16 . 61 ) if there are many inequality constraints . The projected CG method of Algorithm 16 . 2 can also be effective for solving the primal - dual system . We can rewrite ( 16 . 58 ) in the form ⎡ ⎢⎣ G 0 − A T 0 Y − 1 (cid:16) I A − I 0 ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6) y (cid:6)λ ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r d − (cid:16) e + σµ Y − 1 e − r p ⎤ ⎥⎦ , ( 16 . 63 ) 1 6 . 6 . I N T E R I O R - P O I N T M E T H O D S 483 and observe that these are the optimality conditions for an equality - constrained convex quadratic program of the form ( 16 . 3 ) , in which the variable is ( (cid:6) x , (cid:6) y ) . Hence , we can make appropriate substitutions and solve this system using Algorithm 16 . 2 . This approach may be useful for problems in which the direct factorization cannot be performed due to excessive memory demands . The projected CG method does not require that the matrix G be formed or factored ; it requires only matrix - vector products . STEP LENGTH SELECTION We mentioned in Chapter 14 that interior - point methods for linear programming are more efﬁcient if different step lengths α pri , α dual are used for the primal and dual variables . Equation ( 14 . 37 ) indicates that the greatest reduction in the residuals r b and r c is obtained by choosing the largest admissible primal and dual step lengths . The situation is different in quadratic programming . Suppose that we deﬁne the new iterate as ( x + , y + ) (cid:3) ( x , y ) + α pri ( (cid:6) x , (cid:6) y ) , λ + (cid:3) λ + α dual (cid:6)λ , ( 16 . 64 ) where α pri and α dual are step lengths that ensure the positivity of ( y + , λ + ) . By using ( 16 . 58 ) and ( 16 . 59 ) , we see that the new residuals satisfy the following relations : r + p (cid:3) ( 1 − α pri ) r p , ( 16 . 65a ) r + d (cid:3) ( 1 − α dual ) r d + ( α pri − α dual ) G (cid:6) x . ( 16 . 65b ) If α pri (cid:3) α dual (cid:3) α then both residuals decrease linearly for all α ∈ ( 0 , 1 ) . For different step lengths , however , the dual residual r + d may increase for certain choices of α pri , α dual , possibly causing divergence of the interior - point iteration . One option is to use equal step lengths , as in ( 16 . 60 ) , and to set α (cid:3) min ( α pri τ , α dual τ ) , where α pri τ (cid:3) max { α ∈ ( 0 , 1 ] : y + α(cid:6) y ≥ ( 1 − τ ) y } , ( 16 . 66a ) α dual τ (cid:3) max { α ∈ ( 0 , 1 ] : λ + α(cid:6)λ ≥ ( 1 − τ ) λ } ; ( 16 . 66b ) the parameter τ ∈ ( 0 , 1 ) controls how far we back off from the maximum step for which the conditions y + α(cid:6) y ≥ 0 and λ + α(cid:6)λ ≥ 0 are satisﬁed . Numerical experience has shown , however , that using different step lengths in the primal and dual variables often leads to faster convergence . One way to choose unequal step lengths is to select ( α pri , α dual ) so as to ( approximately ) minimize the optimality measure (cid:8) Gx + − A T λ + + c (cid:8) 22 + (cid:8) Ax + − y + − b (cid:8) 22 + ( y + ) T z + , subject to 0 ≤ α pri ≤ α pri τ and 0 ≤ α dual ≤ α dual τ , where x + , y + , λ + are deﬁned as a function of the step lengths through ( 16 . 64 ) . 484 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G A PRACTICAL PRIMAL - DUAL METHOD The most popular interior - point method for convex QP is based on Mehrotra’s predictor - corrector , originally developed for linear programming ( see Section 14 . 2 ) . The extension to quadratic programming is straightforward , as we now show . First , we compute an afﬁne scaling step ( (cid:6) x aff , (cid:6) y aff , (cid:6)λ aff ) by setting σ (cid:3) 0 in ( 16 . 58 ) . We improve upon this step by computing a corrector step , which is deﬁned following the same reasoning that leads to ( 14 . 31 ) . Next , we compute the centering parameter σ using ( 14 . 34 ) . The total step is obtained by solving the following system ( cf . ( 14 . 35 ) ) : ⎡ ⎢⎣ G 0 − A T A − I 0 0 (cid:16) Y ⎤ ⎥⎦ ⎡ ⎢⎣ (cid:6) x (cid:6) y (cid:6)λ ⎤ ⎥⎦ (cid:3) ⎡ ⎢⎣ − r d − r p − (cid:16) Y e − (cid:6)(cid:16) aff (cid:6) Y aff e + σµ e ⎤ ⎥⎦ . ( 16 . 67 ) We now specify the algorithm . For simplicity , we will assume in our description that equal step lengths are used in the primal and dual variables though , as noted above , unequal step lengths can give slightly faster convergence . Algorithm 16 . 4 ( Predictor - Corrector Algorithm for QP ) . Compute ( x 0 , y 0 , λ 0 ) with ( y 0 , λ 0 ) > 0 ; for k (cid:3) 0 , 1 , 2 , . . . Set ( x , y , λ ) (cid:3) ( x k , y k , λ k ) and solve ( 16 . 58 ) with σ (cid:3) 0 for ( (cid:6) x aff , (cid:6) y aff , (cid:6)λ aff ) ; Calculate µ (cid:3) y T λ / m ; Calculate ˆ α aff (cid:3) max { α ∈ ( 0 , 1 ] | ( y , λ ) + α ( (cid:6) y aff , (cid:6)λ aff ) ≥ 0 } ; Calculate µ aff (cid:3) ( y + ˆ α aff (cid:6) y aff ) T ( λ + ˆ α aff (cid:6)λ aff ) / m ; Set centering parameter to σ (cid:3) ( µ aff / µ ) 3 ; Solve ( 16 . 67 ) for ( (cid:6) x , (cid:6) y , (cid:6)λ ) ; Choose τ k ∈ ( 0 , 1 ) and set ˆ α (cid:3) min ( α pri τ k , α dual τ k ) ( see ( 16 . 66 ) ) ; Set ( x k + 1 , y k + 1 , λ k + 1 ) (cid:3) ( x k , y k , λ k ) + ˆ α ( (cid:6) x , (cid:6) y , (cid:6)λ ) ; end ( for ) We can choose τ k to approach 1 as the iterates approach the solution , to accelerate the convergence . As for linear programming , efﬁciency and robustness of this approach is greatly enhanced if we choose a good starting point . This selection can be done in several ways . The following simple heuristic accepts an initial point ( ¯ x , ¯ y , ¯ λ ) from the user and moves it far enough away from the boundary of the region ( y , λ ) ≥ 0 to permit the algorithm to take long steps on early iterations . First , we compute the afﬁne scaling step ( (cid:6) x aff , (cid:6) y aff , (cid:6)λ aff ) 1 6 . 7 . T H E G R A D I E N T P R O J E C T I O N M E T H O D 485 from the user - supplied initial point ( ¯ x , ¯ y , ¯ λ ) , then set y 0 (cid:3) max ( 1 , | ¯ y + (cid:6) y aff | ) , λ 0 (cid:3) max ( 1 , | ¯ λ + (cid:6)λ aff | ) , x 0 (cid:3) ¯ x , where the max and absolute values are applied component - wise . We conclude this section by contrasting some of the properties of active - set and interior - point methods for convex quadratic programming . Active - set methods generally require a large number of steps in which each search direction is relatively inexpensive to compute , while interior - point methods take a smaller number of more expensive steps . Active - set methods are more complicated to implement , particularly if the procedures for updating matrix factorizations try to take advantage of sparsity or structure in G and A . By contrast , the nonzero structure of the matrix to be factored at each interior - point iteration remains the same at all iterations ( though the numerical values change ) , so standard sparse factorization software can be used to obtain the steps . For particular sparsity structures ( for example , bandedness in the matrices A and G ) , efﬁcient customized solvers for the linear system arising at each interior - point iteration can be devised . For very large problems , interior - point methods are often more efﬁcient . However , when an estimate of the solution is available ( a “warm start” ) , the active - set approach may converge rapidly in just a few iterations , particularly if the initial value of x is feasible . Interior - point methods are less able to exploit a warm start , though research efforts to improve their performance in this regard are ongoing . 16 . 7 THE GRADIENT PROJECTION METHOD In the active - set method described in Section 16 . 5 , the active set and working set change slowly , usually by a single index at each iteration . This method may thus require many iterations to converge on large - scale problems . For instance , if the starting point x 0 has no active constraints , while 200 constraints are active at the ( nondegenerate ) solution , then at least 200 iterations of the active - set method will be required to reach the solution . The gradient projection method allows the active set to change rapidly from iteration to iteration . It is most efﬁcient when the constraints are simple in form—in particular , when there are only bounds on the variables . Accordingly , we restrict our attention to the following bound - constrained problem : min x q ( x ) (cid:3) 1 2 x T Gx + x T c ( 16 . 68a ) subject to l ≤ x ≤ u , ( 16 . 68b ) where G is symmetric and l and u are vectors of lower and upper bounds on the components of x . We do not make any positive deﬁniteness assumptions on G in this section , because the gradient projection approach can be applied to both convex and nonconvex problems . The 486 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G feasible region deﬁned by ( 16 . 68b ) is sometimes called a “box” because of its rectangular shape . Some components of x may lack an upper or a lower bound ; we handle these cases formally by setting the appropriate components of l and u to −∞ and + ∞ , respectively . Each iteration of the gradient projection algorithm consists of two stages . In the ﬁrst stage , we search along the steepest descent direction from the current point x , that is , the direction − g , where g (cid:3) Gx + c ; see ( 16 . 6 ) . Whenever a bound is encountered , the search direction is “bent” so that it stays feasible . We search along the resulting piecewise - linear path and locate the ﬁrst local minimizer of q , which we denote by x c and refer to as the Cauchy point , by analogy with our terminology of Chapter 4 . The working set is now deﬁned to be the set of bound constraints that are active at the Cauchy point , denoted by A ( x c ) . In the second stage of each gradient projection iteration , we explore the face of the feasible box on which the Cauchy point lies by solving a subproblem in which the active components x i for i ∈ A ( x c ) are ﬁxed at the values x ci . We describe the gradient projection method in detail in the rest of this section . Our convention in this section is to denote the iteration number by a superscript ( that is , x k ) and use subscripts to denote the elements of a vector . CAUCHY POINT COMPUTATION We now derive an explicit expression for the piecewise - linear path obtained by pro - jecting the steepest descent direction onto the feasible box , and outline the search procedure for identifying the ﬁrst local minimum of q along this path . The projection of an arbitrary point x onto the feasible region ( 16 . 68b ) is deﬁned as follows . The i th component is given by P ( x , l , u ) i (cid:3) ⎧⎪⎪⎨ ⎪⎪⎩ l i if x i < l i , x i if x i ∈ [ l i , u i ] , u i if x i > u i . ( 16 . 69 ) ( We assume , without loss of generality , that l i < u i for all i . ) The piecewise - linear path x ( t ) starting at the reference point x and obtained by projecting the steepest descent direction at x onto the feasible region ( 16 . 68b ) is thus given by x ( t ) (cid:3) P ( x − tg , l , u ) , ( 16 . 70 ) where g (cid:3) Gx + c ; see Figure 16 . 4 . TheCauchypoint x c , isdeﬁnedastheﬁrstlocalminimizeroftheunivariate , piecewise - quadratic function q ( x ( t ) ) , for t ≥ 0 . This minimizer is obtained by examining each of the line segments that make up x ( t ) . To perform this search , we need to determine the values of t at which the kinks in x ( t ) , or breakpoints , occur . We ﬁrst identify the values of t for which each component reaches its bound along the chosen direction − g . These values ¯ t i are given 1 6 . 7 . T H E G R A D I E N T P R O J E C T I O N M E T H O D 487 x−tg 2 x ( t ) 3 1 x ( t ) x x ( t ) Figure 16 . 4 The piecewise - linear path x ( t ) , for an example in IR 3 . by the following explicit formulae : ¯ t i (cid:3) ⎧⎪⎨ ⎪⎩ ( x i − u i ) / g i if g i < 0 and u i < + ∞ , ( x i − l i ) / g i if g i > 0 and l i > −∞ , ∞ otherwise . ( 16 . 71 ) The components of x ( t ) for any t are therefore x i ( t ) (cid:3) (cid:21) x i − tg i if t ≤ ¯ t i , x i − ¯ t i g i otherwise . To search for the ﬁrst local minimizer along P ( x − tg , l , u ) , we eliminate the duplicate values and zero values of ¯ t i from the set { ¯ t 1 , ¯ t 2 , . . . , ¯ t n } , to obtain a sorted , reduced set of breakpoints { t 1 , t 2 , . . . , t l } with 0 < t 1 < t 2 < · · · . We now examine the intervals [ 0 , t 1 ] , [ t 1 , t 2 ] , [ t 2 , t 3 ] , . . . in turn . Suppose we have examined up to t j − 1 and have not yet found a local minimizer . For the interval [ t j − 1 , t j ] , we have that x ( t ) (cid:3) x ( t j − 1 ) + ( (cid:6) t ) p j − 1 , where (cid:6) t (cid:3) t − t j − 1 ∈ [ 0 , t j − t j − 1 ] , 488 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G and p j − 1 i (cid:3) (cid:21) − g i if t j − 1 < ¯ t i , 0 otherwise . ( 16 . 72 ) We can then write the quadratic ( 16 . 68a ) on the line segment [ x ( t j − 1 ) , x ( t j ) ] as follows : q ( x ( t ) ) (cid:3) c T ( x ( t j − 1 ) + ( (cid:6) t ) p j − 1 ) + 12 ( x ( t j − 1 ) + ( (cid:6) t ) p j − 1 ) T G ( x ( t j − 1 ) + ( (cid:6) t ) p j − 1 ) . Expanding and grouping the coefﬁcients of 1 , (cid:6) t , and ( (cid:6) t ) 2 , we ﬁnd that q ( x ( t ) ) (cid:3) f j − 1 + f (cid:14) j − 1 (cid:6) t + 12 f (cid:14)(cid:14) j − 1 ( (cid:6) t ) 2 , (cid:6) t ∈ [ 0 , t j − t j − 1 ] , ( 16 . 73 ) where the coefﬁcients f j − 1 , f (cid:14) j − 1 , and f (cid:14)(cid:14) j − 1 are deﬁned by f j − 1 def (cid:3) c T x ( t j − 1 ) + 12 x ( t j − 1 ) T Gx ( t j − 1 ) , f (cid:14) j − 1 def (cid:3) c T p j − 1 + x ( t j − 1 ) T Gp j − 1 , f (cid:14)(cid:14) j − 1 def (cid:3) ( p j − 1 ) T Gp j − 1 . Differentiating ( 16 . 73 ) with respect to (cid:6) t and equating to zero , we obtain (cid:6) t ∗ (cid:3) − f (cid:14) j − 1 / f (cid:14)(cid:14) j − 1 . The following cases can occur . ( i ) If f (cid:14) j − 1 > 0 there is a local minimizer of q ( x ( t ) ) at t (cid:3) t j − 1 ; else ( ii ) (cid:6) t ∗ ∈ [ 0 , t j − t j − 1 ) there is a minimizer at t (cid:3) t j − 1 + (cid:6) t ∗ ; ( iii ) in all other cases we move on to the next interval [ t j , t j + 1 ] and continue the search . For the next search interval , we need to calculate the new direction p j from ( 16 . 72 ) , and we use this new value to calculate f j , f (cid:14) j , and f (cid:14)(cid:14) j . Since p j differs from p j − 1 typically in just one component , computational savings can be made by updating these coefﬁcients rather than computing them from scratch . SUBSPACE MINIMIZATION After the Cauchy point x c has been computed , the components of x c that are at their lower or upper bounds deﬁne the active set A ( x c ) (cid:3) { i | x ci (cid:3) l i or x ci (cid:3) u i } . In the second stage of the gradient projection iteration , we approximately solve the QP obtained by ﬁxing the components x i for i ∈ A ( x c ) at the values x ci . The remaining 1 6 . 7 . T H E G R A D I E N T P R O J E C T I O N M E T H O D 489 components are determined from the subproblem min x q ( x ) (cid:3) 12 x T Gx + x T c ( 16 . 74a ) subject to x i (cid:3) x ci , i ∈ A ( x c ) , ( 16 . 74b ) l i ≤ x i ≤ u i , i / ∈ A ( x c ) . ( 16 . 74c ) It is not necessary to solve this problem exactly . Nor is it desirable in the large - dimensional case , because the subproblem may be almost as difﬁcult as the original problem ( 16 . 68 ) . In fact , to obtain global convergence of the gradient projection procedure , we require only that the approximate solution x + of ( 16 . 74 ) is feasible with respect to ( 16 . 68b ) and has an objective function value no worse than that of x c , that is , q ( x + ) ≤ q ( x c ) . A strategy that is intermediate between choosing x + (cid:3) x c as the approximate solution ( on the one hand ) and solving ( 16 . 74 ) exactly ( on the other hand ) is to compute an approximate solution of ( 16 . 74 ) by using the conjugate gradient iteration described in Algorithm 16 . 1 or Algorithm 16 . 2 . Note that for the equality constraints ( 16 . 74b ) , the Jacobian A and the null - space basis matrix Z have particularly simple forms . We could therefore apply conjugate gradient to the problem ( 16 . 74a ) , ( 16 . 74b ) and terminate as soon as a bound l ≤ x ≤ u is encountered . Alternatively , we could continue to iterate , temporarily ignoring the bounds and projecting the solution back onto the box constraints . The negative - curvature case can be handled as in Algorithm 7 . 2 , the method for approximately solving possibly indeﬁnite trust - region subproblems in unconstrained optimization . We summarize the gradient projection algorithm for quadratic programming as follows . Algorithm 16 . 5 ( Gradient Projection Method for QP ) . Compute a feasible starting point x 0 ; for k (cid:3) 0 , 1 , 2 , . . . if x k satisﬁes the KKT conditions for ( 16 . 68 ) stop with solution x ∗ (cid:3) x k ; Set x (cid:3) x k and ﬁnd the Cauchy point x c ; Find an approximate solution x + of ( 16 . 74 ) such that q ( x + ) ≤ q ( x c ) and x + is feasible ; x k + 1 ← x + ; end ( for ) If the algorithm approaches a solution x ∗ at which the Lagrange multipliers associated with all the active bounds are nonzero ( that is , strict complementarity holds ) , the active sets A ( x c ) generated by the gradient projection algorithm are equal to the optimal active set for all k sufﬁciently large . That is , constraint indices do not repeatedly enter and leave the active set on successive iterations . When the problem is degenerate , the active set may not settle down at its optimal value . Various devices have been proposed to prevent this undesirable behavior from taking place . 490 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G While gradient projection methods can be applied in principle to problems with gen - eral linear constraints , signiﬁcant computation may be required to perform the projection onto the feasible set in such cases . For example , if the constraint set is deﬁned as a Ti x ≥ b i , i ∈ I , we must solve the following convex quadratic program to compute the projection of a given point ¯ x onto this set : max x (cid:8) x − ¯ x (cid:8) 2 subject to a T i x ≥ b i for all i ∈ I . The expense of solving this “projection subproblem” may approach the cost of solving the original quadratic program , so it is usually not economical to apply gradient projection to this case . When we use duality to replace a strictly convex quadratic program with its dual ( see Example 12 . 12 ) , the gradient projection method may be useful in solving the bound - constrained dual problem , which is formulated in terms of the Lagrange multipliers λ as follows : max λ ˜ q ( λ ) (cid:3) − 1 2 ( A T λ − c ) T G − 1 ( A T λ − c ) T + b T λ , subject to λ ≥ 0 . ( Note that the dual is conventionally written as a maximization problem ; we can equivalently minimize −˜ q ( λ ) and note that this transformed problem is convex . ) This approach is most useful when G has a simple form , for example , a diagonal or block - diagonal matrix . 16 . 8 PERSPECTIVES AND SOFTWARE Active - set methods for convex quadratic programming are implemented in QPOPT [ 126 ] , VE 09 [ 142 ] , BQPD [ 103 ] , and QPA [ 148 ] . Several commercial interior - point solvers for QP are available , including CPLEX [ 172 ] , XPRESS - MP [ 159 ] and MOSEK [ 5 ] . The code QPB [ 146 ] uses a two - phase interior - point method that can handle convex and nonconvex problems . OOPS [ 139 ] and OOQP [ 121 ] are object - oriented interior - point codes that allow the user to customize the linear algebra techniques to the particular structure of the data for an application . Some nonlinear programming interior - point packages , such as LOQO [ 294 ] and KNITRO [ 46 ] , are also effective for convex and nonconvex quadratic programming . The numerical comparison of active - set and interior - point methods for convex quadratic programming reported in [ 149 ] indicates that interior - point methods are gener - ally much faster on large problems . If a warm start is required , however , active - set methods may be generally preferable . Although considerable research has been focused on improving the warm - start capabilities of interior - point methods , the full potential of such techniques is now yet known . Wehaveassumedinthischapterthatallequality - constrainedquadraticprogramshave linearly independent constraints , that is , the m × n constraint Jacobian matrix A has rank m . 1 6 . 8 . P E R S P E C T I V E S A N D S O F T W A R E 491 Ifredundantconstraintsarepresent , theycanbedetectedbyformingaSVDorrank - revealing QR factorization of A T , and then removed from the formulation . When A is larger , sparse Gaussian elimination techniques can be applied to A T instead , but they are less reliable . The KNITRO and OOPS software packages provide the option of solving the primal - dual equations ( 16 . 63 ) by means of the projected CG iteration of Algorithm 16 . 2 . We have not considered active - set methods for the case in which the Hessian matrix G is indeﬁnite because these methods can be quite complicated to describe and it is not well understood how to adapt them to the large dimensional case . We make some comments here on the principal techniques . Algorithm 16 . 3 , the active - set method for convex QP , can be adapted to this indeﬁnite case by modifying the computation of the search direction and step length in certain situations . To explain the need for the modiﬁcation , we consider the computation of a step by a null - space method , that is , p (cid:3) Zp Z , where p Z is given by ( 16 . 53 ) . If the reduced Hessian Z T GZ ispositivedeﬁnite , thenthisstep p pointstotheminimizerofthesubproblem ( 16 . 39 ) , andthelogicoftheiterationneednotbechanged . If Z T GZ hasnegativeeigenvalues , however , p points only to a saddle point of ( 16 . 39 ) and is therefore not always a suitable step . Instead , we seek an alternative direction s Z that is a direction of negative curvature for Z T GZ . We then have that q ( x + α Zs Z ) → −∞ as α → ∞ . ( 16 . 75 ) Additionally , we change the sign of s Z if necessary to ensure that Zs Z is a non - ascent direction for q at the current point x , that is , ∇ q ( x ) T Zs Z ≤ 0 . By moving along the direction Zs Z , we will encounter a constraint that can be added to the working set for the next iteration . ( If we don’t ﬁnd such a constraint , the problem is unbounded . ) If the reduced Hessian for the new working set is not positive deﬁnite , we repeat this process until enough constraints have been added to make the reduced Hessian positive deﬁnite . A difﬁculty with this general approach , however , is that if we allow the reduced Hessian to have several negative eigenvalues , it is difﬁcult to make these methods efﬁcient when the reduced Hessian changes from one working set to the next . Inertia controlling methods are a practical class of algorithms for indeﬁnite QP that never allow the reduced Hessian to have more than one negative eigenvalue . As in the convex case , there is a preliminary phase in which a feasible starting point x 0 is found . We place the additional demand on x 0 that it be either a vertex ( in which case the reduced Hessian is the null matrix ) or a constrained stationary point at which the reduced Hessian is positive deﬁnite . At each iteration , the algorithm will either add or remove a constraint from the working set . If a constraint is added , the reduced Hessian is of smaller dimension and must remain positive deﬁnite or be the null matrix . Therefore , an indeﬁnite reduced Hessian can arise only when one of the constraints is removed from the working set , which happens only when the current point is a minimizer with respect to the current working set . In this case , we will choose the new search direction to be a direction of negative curvature for the reduced Hessian . 492 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G Various algorithms for indeﬁnite QP differ in the way that indeﬁniteness is detected , in the computation of the negative curvature direction , and in the handling of the working set ; see Fletcher [ 99 ] and Gill and Murray [ 126 ] . NOTES AND REFERENCES The problem of determining whether a feasible point for a nonconvex QP ( 16 . 1 ) is a global minimizer is NP - hard ( Murty and Kabadi [ 219 ] ) ; so is the problem of determining whether a given point is a local minimizer ( Vavasis [ 296 , Theorem 5 . 1 ] ) . Various algorithms for convex QP with polynomial convexity are discussed in Nesterov and Nemirovskii [ 226 ] . The portfolio optimization problem was formulated by Markowitz [ 201 ] . For a discussion on the QMR , LSQR , and GMRES methods see , for example , [ 136 , 272 , 290 ] . The idea of using the projection ( 16 . 30 ) in the CG method dates back to at least Polyak [ 238 ] . The alternative ( 16 . 34 ) , and its special case ( 16 . 32 ) , are proposed in Coleman [ 64 ] . Although it can give rise to substantial rounding errors , they can be corrected by iterative reﬁnement ; see Gould et al . [ 143 ] . More recent studies on preconditioning of the projected CG method include Keller et al . [ 176 ] and Lukˇsan and Vlˇcek [ 196 ] . For further discussion on the gradient projection method see , for example , Conn , Gould , and Toint [ 70 ] and Burke and Mor´e [ 44 ] . In some areas of application , the KKT matrix ( 16 . 7 ) not only is sparse but also contains special structure . For instance , the quadratic programs that arise in many control problems have banded matrices G and A ( see Wright [ 315 ] ) , which can be exploited by interior - point methods via a suitable symmetric reordering of K . When active - set methods are applied to this problem , however , the advantages of bandedness and sparsity are lost after just a few updates of the factorization . Further details of interior - point methods for convex quadratic programming can be found in Wright [ 316 ] and Vanderbei [ 293 ] . The ﬁrst inertia - controlling method for indeﬁnite quadratic programming was proposed by Fletcher [ 99 ] . See also Gill et al . [ 129 ] and Gould [ 142 ] for a discussion of methods for general quadratic programming . ✐ E X E R C I S E S ✐ 16 . 1 ( a ) Solve the following quadratic program and illustrate it geometrically . min f ( x ) (cid:3) 2 x 1 + 3 x 2 + 4 x 21 + 2 x 1 x 2 + x 22 , subject to x 1 − x 2 ≥ 0 , x 1 + x 2 ≤ 4 , x 1 ≤ 3 . ( b ) If the objective function is redeﬁned as q ( x ) (cid:3) − f ( x ) , does the problem have a ﬁnite minimum ? Are there local minimizers ? 1 6 . 8 . P E R S P E C T I V E S A N D S O F T W A R E 493 ✐ 16 . 2 The problem of ﬁnding the shortest distance from a point x 0 to the hyperplane { x | Ax (cid:3) b } , where A has full row rank , can be formulated as the quadratic program min 12 ( x − x 0 ) T ( x − x 0 ) subject to Ax (cid:3) b . Show that the optimal multiplier is λ ∗ (cid:3) ( AA T ) − 1 ( b − Ax 0 ) and that the solution is x ∗ (cid:3) x 0 + A T ( AA T ) − 1 ( b − Ax 0 ) . Show that in the special case in which A is a row vector , the shortest distance from x 0 to the solution set of Ax (cid:3) b is | b − Ax 0 | / (cid:8) A (cid:8) 2 . ✐ 16 . 3 Use Theorem 12 . 1 to verify that the ﬁrst - order necessary conditions for ( 16 . 3 ) are given by ( 16 . 4 ) . ✐ 16 . 4 Suppose that G is positive semideﬁnite in ( 16 . 1 ) and that x ∗ satisﬁes the KKT conditions ( 16 . 37 ) for some λ ∗ i , i ∈ A ( x ∗ ) . Suppose in addition that second - order sufﬁcient conditions are satisﬁed , that is , Z T GZ is positive deﬁnite where the columns of Z span the null space of the active constraint Jacobian matrix . Show that x ∗ is in fact the unique global solution for ( 16 . 1 ) , that is , q ( x ) > q ( x ∗ ) for all feasible x with x (cid:9)(cid:3) x ∗ . ✐ 16 . 5 Verify that the inverse of the KKT matrix is given by ( 16 . 16 ) . ✐ 16 . 6 Use Theorem 12 . 6 to show that if the conditions of Lemma 16 . 1 hold , then the second - order sufﬁcient conditions for ( 16 . 3 ) are satisﬁed by the vector pair ( x ∗ , λ ∗ ) that satisﬁes ( 16 . 4 ) . ✐ 16 . 7 Consider ( 16 . 3 ) and suppose that the projected Hessian matrix Z T GZ has a negative eigenvalue ; that is , u T Z T GZu < 0 for some vector u . Show that if there exists any vector pair ( x ∗ , λ ∗ ) that satisﬁes ( 16 . 4 ) , then the point x ∗ is only a stationary point of ( 16 . 3 ) and not a local minimizer . ( Hint : Consider the function q ( x ∗ + α Zu ) for α (cid:9)(cid:3) 0 , and use an expansion like that in the proof of Theorem 16 . 2 . ) ✐ 16 . 8 By using the QR factorization and a permutation matrix , show that for a full - rank m × n matrix A ( with m < n ) one can ﬁnd an orthogonal matrix Q and an m × m upper triangular matrix ˆ U such that AQ (cid:3) ) 0 ˆ U * . ( Hint : Start by applying the standard QR factorization to A T . ) ✐ 16 . 9 Verify that the ﬁrst - order conditions for optimality of ( 16 . 1 ) are equivalent to ( 16 . 37 ) when we make use of the active - set deﬁnition ( 16 . 36 ) . 494 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G ✐ 16 . 10 For each of the alternative choices of initial working set W 0 in the example ( 16 . 49 ) ( that is , W 0 (cid:3) { 3 } , W 0 (cid:3) { 5 } , and W 0 (cid:3) ∅ ) work through the ﬁrst two iterations of Algorithm 16 . 3 . ✐ 16 . 11 Program Algorithm 16 . 3 , and use it to solve the problem min x 2 1 + 2 x 2 2 − 2 x 1 − 6 x 2 − 2 x 1 x 2 subject to 12 x 1 + 12 x 2 ≤ 1 , − x 1 + 2 x 2 ≤ 2 , x 1 , x 2 ≥ 0 . Choose three initial starting points : one in the interior of the feasible region , one at a vertex , and one at a non - vertex point on the boundary of the feasible region . ✐ 16 . 12 Show that the operator P deﬁned by ( 16 . 27 ) is independent of the choice of null - space basis Z . ( Hint : First show that any null - space basis Z can be written as Z (cid:3) QB where Q is an orthogonal basis and B is a nonsingular matrix . ) ✐ 16 . 13 ( a ) Show that the the computation of the preconditioned residual g + in ( 16 . 28d ) can be performed with ( 16 . 29 ) or ( 16 . 30 ) . ( b ) Show that we can also perform this computation by solving the system ( 16 . 32 ) . ( c ) Verify ( 16 . 33 ) . ✐ 16 . 14 ( a ) Show that if Z T GZ is positive deﬁnite , then the denominator in ( 16 . 28a ) is nonzero . ( b ) Show that if Z T r (cid:3) r Z (cid:9)(cid:3) 0 and Z T H Z is positive deﬁnite , then the denominator in ( 16 . 28e ) is nonzero . ✐ 16 . 15 Consider problem ( 16 . 3 ) , and assume that A has full row rank and that Z is a basis for the null space of A . Prove that there are no ﬁnite solutions if Z T GZ has negative eigenvalues . ✐ 16 . 16 ( a ) Assume that A (cid:9)(cid:3) 0 . Show that the KKT matrix ( 16 . 7 ) is indeﬁnite . ( b ) Prove that if the KKT matrix ( 16 . 7 ) is nonsingular , then A must have full rank . ✐ 16 . 17 Consider the quadratic program max 6 x 1 + 4 x 2 − 13 − x 21 − x 22 , subject to x 1 + x 2 ≤ 3 , x 1 ≥ 0 , x 2 ≥ 0 . ( 16 . 76 ) 1 6 . 8 . P E R S P E C T I V E S A N D S O F T W A R E 495 First solve it graphically , and then use your program implementing the active - set method given in Algorithm 16 . 3 . ✐ 16 . 18 Using ( 16 . 39 ) and ( 16 . 41 ) , explain brieﬂy why the gradient of each blocking constraint cannot be a linear combination of the constraint gradients in the current working set W k . ✐ 16 . 19 Let W be an n × n symmetric matrix , and suppose that Z is of dimension n × t . Suppose that Z T W Z is positive deﬁnite and that ¯ Z is obtained by removing a column from Z . Show that ¯ Z T W ¯ Z is positive deﬁnite . ✐ 16 . 20 Find a null - space basis matrix Z for the equality - constrained problem deﬁned by ( 16 . 74a ) , ( 16 . 74b ) . ✐ 16 . 21 Write down KKT conditions for the following convex quadratic program with mixed equality and inequality constraints : min q ( x ) (cid:3) 12 x T Gx + x T c subject to Ax ≥ b , ¯ Ax (cid:3) ¯ b , where G is symmetric and positive semideﬁnite . Use these conditions to derive an analogue of the generic primal - dual step ( 16 . 58 ) for this problem . ✐ 16 . 22 Explain why for a bound - constrained problems the number of possible active sets is at most 3 n . ✐ 16 . 23 ( a ) Show that the primal - dual system ( 16 . 58 ) can be solved using the augmented system ( 16 . 61 ) or the normal equations ( 16 . 62 ) . Describe in detail how all the components ( (cid:6) x , (cid:6) y , (cid:6)λ ) are computed . ( b ) Verify ( 16 . 65 ) . ✐ 16 . 24 Program Algorithm 16 . 4 and use it to solve problem ( 16 . 76 ) . Set all initial variables to be the vector e (cid:3) ( 1 , 1 , . . . , 1 ) T . ✐ 16 . 25 Let ¯ x ∈ R n be given , and let x ∗ be the solution of the projection problem min (cid:8) x − ¯ x (cid:8) 2 subject to l ≤ x ≤ u . ( 16 . 77 ) For simplicity , assume that −∞ < l i < u i < ∞ for all i (cid:3) 1 , 2 , . . . , n . Show that the solution of this problem coincides with the projection formula given by ( 16 . 69 ) that is , show that x ∗ (cid:3) P ( ¯ x , l , u ) . ( Hint : Note that the problem is separable . ) 496 C H A P T E R 1 6 . Q U A D R A T I C P R O G R A M M I N G ✐ 16 . 26 Consider the bound - constrained quadratic problem ( 16 . 68 ) with G (cid:3) (cid:1) 4 1 1 2 (cid:2) , c (cid:3) (cid:1) − 1 1 (cid:2) , l (cid:3) (cid:1) 0 0 (cid:2) , and u (cid:3) (cid:1) 5 3 (cid:2) . ( 16 . 78 ) Suppose x 0 (cid:3) ( 0 , 2 ) T . Find ¯ t 1 , ¯ t 2 , t 1 , t 2 , p 1 , p 2 and x ( t 1 ) , x ( t 2 ) . Find the minimizer of q ( x ( t ) ) . ✐ 16 . 27 Consider the search for the one dimensional minimizer of the function q ( x ( t ) ) deﬁned by ( 16 . 73 ) . There are 9 possible cases since f , f (cid:14) , f (cid:14)(cid:14) can each be positive , negative , or zero . For each case , determine the location of the minimizer . Verify that the rules described in Section 16 . 7 hold . This is page 497 Printer : Opaque this C H A P T E R 17 Penalty and Augmented Lagrangian Methods Some important methods for constrained optimization replace the original problem by a sequence of subproblems in which the constraints are represented by terms added to the objective . In this chapter we describe three approaches of this type . The quadratic penalty method adds a multiple of the square of the violation of each constraint to the objective . Because of its simplicity and intuitive appeal , this approach is used often in practice , al - though it has some important disadvantages . In nonsmooth exact penalty methods , a single unconstrained problem ( rather than a sequence ) takes the place of the original constrained problem . Using these penalty functions , we can often ﬁnd a solution by performing a single 498 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S unconstrained minimization , but the nonsmoothness may create complications . A popular function of this type is the (cid:1) 1 penalty function . A different kind of exact penalty approach is the method of multipliers or augmented Lagrangian method , in which explicit Lagrange multiplier estimates are used to avoid the ill - conditioning that is inherent in the quadratic penalty function . A somewhat related approach is used in the log - barrier method , in which logarithmic terms prevent feasible iterates from moving too close to the boundary of the feasible re - gion . This approach forms part of the foundation for interior - point methods for nonlinear programming and we discuss it further in Chapter 19 . 17 . 1 THE QUADRATIC PENALTY METHOD MOTIVATION Let us consider replacing a constrained optimization problem by a single function consisting of - the original objective of the constrained optimization problem , plus - one additional term for each constraint , which is positive when the current point x violates that constraint and zero otherwise . Most approaches deﬁne a sequence of such penalty functions , in which the penalty terms for the constraint violations are multiplied by a positive coefﬁcient . By making this coefﬁcient larger , we penalize constraint violations more severely , thereby forcing the minimizer of the penalty function closer to the feasible region for the constrained problem . The simplest penalty function of this type is the quadratic penalty function , in which the penalty terms are the squares of the constraint violations . We describe this approach ﬁrst in the context of the equality - constrained problem min x f ( x ) subject to c i ( x ) (cid:3) 0 , i ∈ E , ( 17 . 1 ) which is a special case of ( 12 . 1 ) . The quadratic penalty function Q ( x ; µ ) for this formulation is Q ( x ; µ ) def (cid:3) f ( x ) + µ 2 (cid:3) i ∈ E c 2 i ( x ) , ( 17 . 2 ) where µ > 0 is the penalty parameter . By driving µ to ∞ , we penalize the constraint violations with increasing severity . It makes good intuitive sense to consider a sequence of values { µ k } with µ k ↑ ∞ as k → ∞ , and to seek the approximate minimizer x k of Q ( x ; µ k ) for each k . Because the penalty terms in ( 17 . 2 ) are smooth , we can use techniques from 1 7 . 1 . T H E Q U A D R A T I C P E N A L T Y M E T H O D 499 unconstrained optimization to search for x k . In searching for x k , we can use the minimizers x k − 1 , x k − 2 , etc . , of Q ( · ; µ ) for smaller values of µ to construct an initial guess . For suitable choices of the sequence { µ k } and the initial guesses , just a few steps of unconstrained minimization may be needed for each µ k . ❏ E XAMPLE 17 . 1 Consider the problem ( 12 . 9 ) from Chapter 12 , that is , min x 1 + x 2 subject to x 21 + x 22 − 2 (cid:3) 0 , ( 17 . 3 ) for which the solution is ( − 1 , − 1 ) T and the quadratic penalty function is Q ( x ; µ ) (cid:3) x 1 + x 2 + µ 2 (cid:7) x 21 + x 22 − 2 (cid:8) 2 . ( 17 . 4 ) We plot the contours of this function in Figures 17 . 1 and 17 . 2 . In Figure 17 . 1 we have µ (cid:3) 1 , and we observe a minimizer of Q near the point ( − 1 . 1 , − 1 . 1 ) T . ( There is also a local maximizer near x (cid:3) ( 0 . 3 , 0 . 3 ) T . ) In Figure 17 . 2 we have µ (cid:3) 10 , so points that do not lie on the feasible circle deﬁned by x 21 + x 22 (cid:3) 2 suffer a much greater penalty than in the ﬁrst ﬁgure—the “trough” of low values of Q is clearly evident . The minimizer in this ﬁgure is much closer to the solution ( − 1 , − 1 ) T of the problem ( 17 . 3 ) . A local maximum lies near ( 0 , 0 ) T , and Q goes rapidly to ∞ outside the circle x 21 + x 22 (cid:3) 2 . ❐ −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 Figure 17 . 1 Contours of Q ( x ; µ ) from ( 17 . 4 ) for µ (cid:3) 1 , contour spacing 0 . 5 . 500 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 Figure 17 . 2 Contours of Q ( x ; µ ) from ( 17 . 4 ) for µ (cid:3) 10 , contour spacing 2 . The situation is not always so benign as in Example 17 . 1 . For a given value of the penalty parameter µ , the penalty function may be unbounded below even if the original constrained problem has a unique solution . Consider for example min − 5 x 21 + x 22 subject to x 1 (cid:3) 1 , ( 17 . 5 ) whose solution is ( 1 , 0 ) T . The penalty function is unbounded for any µ < 10 . For such values of µ , the iterates generated by an unconstrained minimization method would usually diverge . This deﬁciency is , unfortunately , common to all the penalty functions discussed in this chapter . For the general constrained optimization problem min x f ( x ) subject to c i ( x ) (cid:3) 0 , i ∈ E , c i ( x ) ≥ 0 , i ∈ I , ( 17 . 6 ) which contains inequality constraints as well as equality constraints , we can deﬁne the quadratic penalty function as Q ( x ; µ ) def (cid:3) f ( x ) + µ 2 (cid:3) i ∈ E c 2 i ( x ) + µ 2 (cid:3) i ∈ I (cid:7) [ c i ( x ) ] − (cid:8) 2 , ( 17 . 7 ) where [ y ] − denotes max ( − y , 0 ) . In this case , Q may be less smooth than the objective and constraint functions . For instance , if one of the inequality constraints is x 1 ≥ 0 , then the function min ( 0 , x 1 ) 2 has a discontinuous second derivative , so that Q is no longer twice continuously differentiable . 1 7 . 1 . T H E Q U A D R A T I C P E N A L T Y M E T H O D 501 ALGORITHMIC FRAMEWORK A general framework for algorithms based on the quadratic penalty function ( 17 . 2 ) can be speciﬁed as follows . Framework 17 . 1 ( Quadratic Penalty Method ) . Given µ 0 > 0 , a nonnegative sequence { τ k } with τ k → 0 , and a starting point x s 0 ; for k (cid:3) 0 , 1 , 2 , . . . Find an approximate minimizer x k of Q ( · ; µ k ) , starting at x sk , and terminating when (cid:8)∇ x Q ( x ; µ k ) (cid:8) ≤ τ k ; if ﬁnal convergence test satisﬁed stop with approximate solution x k ; end ( if ) Choose new penalty parameter µ k + 1 > µ k ; Choose new starting point x sk + 1 ; end ( for ) The parameter sequence { µ k } can be chosen adaptively , based on the difﬁculty of minimizing the penalty function at each iteration . When minimization of Q ( x ; µ k ) proves to be expensive for some k , we choose µ k + 1 to be only modestly larger than µ k ; for instance µ k + 1 (cid:3) 1 . 5 µ k . If we ﬁnd the approximate minimizer of Q ( x ; µ k ) cheaply , we could try a more ambitious increase , for instance µ k + 1 (cid:3) 10 µ k . The convergence theory for Frame - work 17 . 1 allows wide latitude in the choice of nonnegative tolerances τ k ; it requires only that τ k → 0 , to ensure that the minimization is carried out more accurately as the iterations progress . There is no guarantee that the stop test (cid:8)∇ x Q ( x ; µ k ) (cid:8) ≤ τ k will be satisﬁed be - cause , as discussed above , the iterates may move away from the feasible region when the penalty parameter is not large enough . A practical implementation must include safe - guards that increase the penalty parameter ( and possibly restore the initial point ) when the constraint violation is not decreasing rapidly enough , or when the iterates appear to be diverging . When only equality constraints are present , Q ( x ; µ k ) is smooth , so the algorithms for unconstrainedminimizationdescribedintheﬁrstchaptersofthebookcanbeusedtoidentify theapproximatesolution x k . However , theminimizationof Q ( x ; µ k ) becomesmoredifﬁcult to perform as µ k becomes large , unless we use special techniques to calculate the search directions . For one thing , the Hessian ∇ 2 xx Q ( x ; µ k ) becomes arbitrarily ill conditioned near the minimizer . This property alone is enough to make many unconstrained minimization algorithms such as quasi - Newton and conjugate gradient perform poorly . Newton’s method , ontheotherhand , isnotsensitivetoillconditioningoftheHessian , butit , too , mayencounter difﬁculties for large µ k for two other reasons . First , ill conditioning of ∇ 2 xx Q ( x ; µ k ) might be expected to cause numerical problems when we solve the linear equations to calculate the Newton step . We discuss this issue below , and show that these effects are not severe and 502 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S that a reformulation of the Newton equations is possible . Second , even when x is close to the minimizer of Q ( · ; µ k ) , the quadratic Taylor series approximation to Q ( x ; µ k ) about x is a reasonable approximation of the true function only in a small neighborhood of x . This property can be seen in Figure 17 . 2 , where the contours of Q near the minimizer have a “banana” shape , rather than the elliptical shape that characterizes quadratic functions . Since Newton’s method is based on the quadratic model , the steps that it generates may not make rapid progress toward the minimizer of Q ( x ; µ k ) . This difﬁculty can be lessened by a judicious choice of the starting point x sk + 1 , or by setting x sk + 1 (cid:3) x k and choosing µ k + 1 to be only modestly larger than µ k . CONVERGENCE OF THE QUADRATIC PENALTY METHOD We describe some convergence properties of the quadratic penalty method in the following two theorems . We restrict our attention to the equality - constrained problem ( 17 . 1 ) , for which the quadratic penalty function is deﬁned by ( 17 . 2 ) . For the ﬁrst result we assume that the penalty function Q ( x ; µ k ) has a ( ﬁnite ) minimizer for each value of µ k . Theorem 17 . 1 . Suppose that each x k is the exact global minimizer of Q ( x ; µ k ) deﬁned by ( 17 . 2 ) in Framework 17 . 1 above , and that µ k ↑ ∞ . Then every limit point x ∗ of the sequence { x k } is a global solution of the problem ( 17 . 1 ) . P ROOF . Let ¯ x be a global solution of ( 17 . 1 ) , that is , f ( ¯ x ) ≤ f ( x ) for all x with c i ( x ) (cid:3) 0 , i ∈ E . Since x k minimizes Q ( · ; µ k ) for each k , we have that Q ( x k ; µ k ) ≤ Q ( ¯ x ; µ k ) , which leads to the inequality f ( x k ) + µ k 2 (cid:3) i ∈ E c 2 i ( x k ) ≤ f ( ¯ x ) + µ k 2 (cid:3) i ∈ E c 2 i ( ¯ x ) (cid:3) f ( ¯ x ) . ( 17 . 8 ) By rearranging this expression , we obtain (cid:3) i ∈ E c 2 i ( x k ) ≤ 2 µ k [ f ( ¯ x ) − f ( x k ) ] . ( 17 . 9 ) Suppose that x ∗ is a limit point of { x k } , so that there is an inﬁnite subsequence K such that lim k ∈ K x k (cid:3) x ∗ . 1 7 . 1 . T H E Q U A D R A T I C P E N A L T Y M E T H O D 503 By taking the limit as k → ∞ , k ∈ K , on both sides of ( 17 . 9 ) , we obtain (cid:3) i ∈ E c 2 i ( x ∗ ) (cid:3) lim k ∈ K (cid:3) i ∈ E c 2 i ( x k ) ≤ lim k ∈ K 2 µ k [ f ( ¯ x ) − f ( x k ) ] (cid:3) 0 , where the last equality follows from µ k ↑ ∞ . Therefore , we have that c i ( x ∗ ) (cid:3) 0 for all i ∈ E , so that x ∗ is feasible . Moreover , by taking the limit as k → ∞ for k ∈ K in ( 17 . 8 ) , we have by nonnegativity of µ k and of each c i ( x k ) 2 that f ( x ∗ ) ≤ f ( x ∗ ) + lim k ∈ K µ k 2 (cid:3) i ∈ E c 2 i ( x k ) ≤ f ( ¯ x ) . Since x ∗ is a feasible point whose objective value is no larger than that of the global solution ¯ x , we conclude that x ∗ , too , is a global solution , as claimed . (cid:1) Since this result requires us to ﬁnd the global minimizer for each subproblem , this desirable property of convergence to the global solution of ( 17 . 1 ) cannot be attained in general . The next result concerns convergence properties of the sequence { x k } when we allow inexact ( but increasingly accurate ) minimizations of Q ( · ; µ k ) . In contrast to Theorem 17 . 1 , it shows that the sequence may be attracted to infeasible points , or to any KKT point ( that is , a point satisfying ﬁrst - order necessary conditions ; see ( 12 . 34 ) ) , rather than to a minimizer . It also shows that the quantities µ k c i ( x k ) may be used as estimates of the Lagrange multipliers λ ∗ i in certain circumstances . This observation is important for the analysis of augmented Lagrangian methods in Section 17 . 3 . To establish the result we will make the ( optimistic ) assumption that the stop test (cid:8)∇ x Q ( x ; µ k ) (cid:8) ≤ τ k is satisﬁed for all k . Theorem 17 . 2 . Suppose that the tolerances and penalty parameters in Framework 17 . 1 satisfy τ k → 0 and µ k ↑ ∞ . Then if a limit point x ∗ of the sequence { x k } is infeasible , it is a stationary point of the function (cid:8) c ( x ) (cid:8) 2 . On the other hand , if a limit point x ∗ is feasible and the constraint gradients ∇ c i ( x ∗ ) are linearly independent , then x ∗ is a KKT point for the problem ( 17 . 1 ) . For such points , we have for any inﬁnite subsequence K such that lim k ∈ K x k (cid:3) x ∗ that lim k ∈ K − µ k c i ( x k ) (cid:3) λ ∗ i , for all i ∈ E , ( 17 . 10 ) where λ ∗ is the multiplier vector that satisﬁes the KKT conditions ( 12 . 34 ) for the equality - constrained problem ( 17 . 1 ) . P ROOF . By differentiating Q ( x ; µ k ) in ( 17 . 2 ) , we obtain ∇ x Q ( x k ; µ k ) (cid:3) ∇ f ( x k ) + (cid:3) i ∈ E µ k c i ( x k ) ∇ c i ( x k ) , ( 17 . 11 ) 504 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S so from the termination criterion for Framework 17 . 1 , we have that (cid:23)(cid:23)(cid:23)(cid:23)(cid:23) ∇ f ( x k ) + (cid:3) i ∈ E µ k c i ( x k ) ∇ c i ( x k ) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23) ≤ τ k . ( 17 . 12 ) By rearranging this expression ( and in particular using the inequality (cid:8) a (cid:8)−(cid:8) b (cid:8) ≤ (cid:8) a + b (cid:8) ) , we obtain (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:3) i ∈ E c i ( x k ) ∇ c i ( x k ) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23) ≤ 1 µ k [ τ k + (cid:8)∇ f ( x k ) (cid:8) ] . ( 17 . 13 ) Let x ∗ be a limit point of the sequence of iterates . Then there is a subsequence K such that lim k ∈ K x k (cid:3) x ∗ . When we take limits as k → ∞ for k ∈ K , the bracketed term on the right - hand - side approaches (cid:8)∇ f ( x ∗ ) (cid:8) , so because µ k ↑ ∞ , the right - hand - side approaches zero . From the corresponding limit on the left - hand - side , we obtain (cid:3) i ∈ E c i ( x ∗ ) ∇ c i ( x ∗ ) (cid:3) 0 . ( 17 . 14 ) We can have c i ( x ∗ ) (cid:9)(cid:3) 0 ( if the constraint gradients ∇ c i ( x ∗ ) are dependent ) , but in this case ( 17 . 14 ) implies that x ∗ is a stationary point of the function (cid:8) c ( x ) (cid:8) 2 . If , on the other hand , the constraint gradients ∇ c i ( x ∗ ) are linearly independent at a limit point x ∗ , we have from ( 17 . 14 ) that c i ( x ∗ ) (cid:3) 0 for all i ∈ E , so x ∗ is feasible . Hence , the second KKT condition ( 12 . 34b ) is satisﬁed . We need to check the ﬁrst KKT condition ( 12 . 34a ) as well , and to show that the limit ( 17 . 10 ) holds . By using A ( x ) to denote the matrix of constraint gradients ( also known as the Jacobian ) , that is , A ( x ) T (cid:3) [ ∇ c i ( x ) ] i ∈ E , ( 17 . 15 ) and λ k to denote the vector − µ k c ( x k ) , we have as in ( 17 . 12 ) that A ( x k ) T λ k (cid:3) ∇ f ( x k ) − ∇ x Q ( x k ; µ k ) , (cid:8)∇ x Q ( x k ; µ k ) (cid:8) ≤ τ k . ( 17 . 16 ) For all k ∈ K sufﬁciently large , the matrix A ( x k ) has full row rank , so that A ( x k ) A ( x k ) T is nonsingular . By multiplying ( 17 . 16 ) by A ( x k ) and rearranging , we have that λ k (cid:3) (cid:9) A ( x k ) A ( x k ) T (cid:10) − 1 A ( x k ) [ ∇ f ( x k ) − ∇ x Q ( x k ; µ k ) ] . Hence by taking the limit as k ∈ K goes to ∞ , we ﬁnd that lim k ∈ K λ k (cid:3) λ ∗ (cid:3) (cid:9) A ( x ∗ ) A ( x ∗ ) T (cid:10) − 1 A ( x ∗ ) ∇ f ( x ∗ ) . 1 7 . 1 . T H E Q U A D R A T I C P E N A L T Y M E T H O D 505 By taking limits in ( 17 . 12 ) , we conclude that ∇ f ( x ∗ ) − A ( x ∗ ) T λ ∗ (cid:3) 0 , ( 17 . 17 ) so that λ ∗ satisﬁes the ﬁrst KKT condition ( 12 . 34a ) for ( 17 . 1 ) . Hence , x ∗ is a KKT point for ( 17 . 1 ) , with unique Lagrange multiplier vector λ ∗ . (cid:1) It is reassuring that , if a limit point x ∗ is not feasible , it is at least a stationary point for the function (cid:8) c ( x ) (cid:8) 2 . Newton - type algorithms can always be attracted to infeasible points of this type . ( We see the same effect in Chapter 11 , in our discussion of methods for nonlinear equations that use the sum - of - squares merit function (cid:8) r ( x ) (cid:8) 2 . ) Such methods cannot be guaranteed to ﬁnd a root , and can be attracted to a stationary point or minimizer of the merit function . In the case in which the nonlinear program ( 17 . 1 ) is infeasible , we often observe convergence of the quadratic - penalty method to stationary points or minimizers of (cid:8) c ( x ) (cid:8) 2 . ILL CONDITIONING AND REFORMULATIONS We now examine the nature of the ill conditioning in the Hessian ∇ 2 xx Q ( x ; µ k ) . An understanding of the properties of this matrix , and the similar Hessians that arise in other penalty and barrier methods , is essential in choosing effective algorithms for the minimization problem and for the linear algebra calculations at each iteration . The Hessian is given by the formula ∇ 2 xx Q ( x ; µ k ) (cid:3) ∇ 2 f ( x ) + (cid:3) i ∈ E µ k c i ( x ) ∇ 2 c i ( x ) + µ k A ( x ) T A ( x ) , ( 17 . 18 ) where we have used the deﬁnition ( 17 . 15 ) of A ( x ) . When x is close to the minimizer of Q ( · ; µ k ) and the conditions of Theorem 17 . 2 are satisﬁed , we have from ( 17 . 10 ) that the sum of the ﬁrst two terms on the right - hand - side of ( 17 . 18 ) is approximately equal to the Hessian of the Lagrangian function deﬁned in ( 12 . 33 ) . To be speciﬁc , we have ∇ 2 xx Q ( x ; µ k ) ≈ ∇ 2 xx L ( x , λ ∗ ) + µ k A ( x ) T A ( x ) , ( 17 . 19 ) when x is close to the minimizer of Q ( · ; µ k ) . We see from this expression that ∇ 2 xx Q ( x ; µ k ) is approximately equal to the sum of - a matrix whose elements are independent of µ k ( the Lagrangian term ) , and - a matrix of rank | E | whose nonzero eigenvalues are of order µ k ( the second term on the right - hand side of ( 17 . 19 ) ) . The number of constraints | E | is usually smaller than n . In this case , the last term in ( 17 . 19 ) is singular . The overall matrix has some of its eigenvalues approaching a constant , while others 506 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S are of order µ k . Since µ k is approaching ∞ , the increasing ill conditioning of ∇ 2 xx Q ( x ; µ k ) is apparent . One consequence of the ill conditioning is possible inaccuracy in the calculation of the Newton step for Q ( x ; µ k ) , which is obtained by solving the following system : ∇ 2 xx Q ( x ; µ k ) p (cid:3) −∇ x Q ( x ; µ k ) . ( 17 . 20 ) Ingeneral , thepoorconditioningofthissystemwillleadtosigniﬁcanterrorsinthecomputed value of p , regardless of the computational technique used to solve ( 17 . 20 ) . For the same reason , iterative methods can be expected to perform poorly unless accompanied by a preconditioning strategy that removes the systematic ill conditioning . There is an alternative formulation of the equations ( 17 . 20 ) that avoids the ill condi - tioning due to the ﬁnal term in ( 17 . 18 ) . By introducing a new variable vector ζ deﬁned by ζ (cid:3) µ A ( x ) p , we see that the vector p that solves ( 17 . 20 ) also satisﬁes the following system : ⎡ ⎣ ∇ 2 f ( x ) + (cid:3) i ∈ E µ k c i ( x ) ∇ 2 c i ( x ) A ( x ) T A ( x ) − ( 1 / µ k ) I ⎤ ⎦ (cid:1) p ζ (cid:2) (cid:3) (cid:1) −∇ x Q ( x ; µ k ) 0 (cid:2) . ( 17 . 21 ) When x is not too far from the solution x ∗ , the coefﬁcient matrix in this system does not have large singular values ( of order µ k ) , so the system ( 17 . 21 ) can be viewed as a well conditioned reformulation of ( 17 . 20 ) . We note , however , that neither system may yield a good search direction p because the coefﬁcients µ k c i ( x ) in the summation term of the upper left block of ( 17 . 21 ) may be poor approximations to the Lagrange multipliers − λ ∗ i , even when x is quite close to the minimizer x k of Q ( x ; µ k ) . This fact may cause the quadratic model on which p is based to be an inadequate model of Q ( · ; µ k ) , so the Newton step may be intrinsically an unsuitable search direction . We discussed possible remedies for this difﬁculty above , in our comments following Framework 17 . 1 . To compute the step via ( 17 . 21 ) involves the solution of a linear system of dimension n + | E | rather than the system of dimension n given by ( 17 . 19 ) . A similar system must be solved to calculate the sequential quadratic programming ( SQP ) step ( 18 . 6 ) , which is derived in Chapter 18 . In fact , when µ k is large , ( 17 . 21 ) can be viewed as a regularization of the SQP step ( 18 . 6 ) in which the term − ( 1 / µ k ) I helps to ensure that the iteration matrix is nonsingular even when the Jacobian A ( x ) is rank deﬁcient . On the other hand , when µ k is small , ( 17 . 21 ) showsthatthestepcomputedbythequadraticpenaltymethoddoesnotclosely satisfy the linearization of the constraints . This situation is undesirable because the steps may not make signiﬁcant progress toward the feasible region , resulting in inefﬁcient global behavior . Moreover , if { µ k } does not approach ∞ rapidly enough , we lose the possibility of a superlinear rate that occurs when the linearization is exact ; see Chapter 18 . 1 7 . 2 . N O N S M O O T H P E N A L T Y F U N C T I O N S 507 To conclude , the formulation ( 17 . 21 ) allows us to view the quadratic penalty method either as the application of unconstrained minimization to the penalty function Q ( · ; µ k ) or as a variation on the SQP methods discussed in Chapter 18 . 17 . 2 NONSMOOTH PENALTY FUNCTIONS Some penalty functions are exact , which means that , for certain choices of their penalty parameters , a single minimization with respect to x can yield the exact solution of the non - linear programming problem . This property is desirable because it makes the performance of penalty methods less dependent on the strategy for updating the penalty parameter . The quadratic penalty function of Section 17 . 1 is not exact because its minimizer is generally not the same as the solution of the nonlinear program for any positive value of µ . In this section we discuss nonsmooth exact penalty functions , which have proved to be useful in a number of practical contexts . A popular nonsmooth penalty function for the general nonlinear programming problem ( 17 . 6 ) is the (cid:1) 1 penalty function deﬁned by φ 1 ( x ; µ ) (cid:3) f ( x ) + µ (cid:3) i ∈ E | c i ( x ) | + µ (cid:3) i ∈ I [ c i ( x ) ] − , ( 17 . 22 ) where we use again the notation [ y ] − (cid:3) max { 0 , − y } . Its name derives from the fact that the penalty term is µ times the (cid:1) 1 norm of the constraint violation . Note that φ 1 ( x ; µ ) is not differentiable at some x , because of the presence of the absolute value and [ · ] − functions . The following result establishes the exactness of the (cid:1) 1 penalty function . For a proof see [ 165 , Theorem 4 . 4 ] . Theorem 17 . 3 . Suppose that x ∗ is a strict local solution of the nonlinear programming problem ( 17 . 6 ) at which the ﬁrst - order necessary conditions of Theorem 12 . 1 are satisﬁed , with Lagrange multipliers λ ∗ i , i ∈ E ∪ I . Then x ∗ is a local minimizer of φ 1 ( x ; µ ) for all µ > µ ∗ , where µ ∗ (cid:3) (cid:8) λ ∗ (cid:8) ∞ (cid:3) max i ∈ E ∪ I | λ ∗ i | . ( 17 . 23 ) If , in addition , the second - order sufﬁcient conditions of Theorem 12 . 6 hold and µ > µ ∗ , then x ∗ is a strict local minimizer of φ 1 ( x ; µ ) . Loosely speaking , at a solution of the nonlinear program x ∗ , any move into the infeasible region is penalized sharply enough that it produces an increase in the penalty function to a value greater than φ 1 ( x ∗ ; µ ) (cid:3) f ( x ∗ ) , thereby forcing the minimizer of φ 1 ( · ; µ ) to lie at x ∗ . 508 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S ❏ E XAMPLE 17 . 2 Consider the following problem in one variable : min x subject to x ≥ 1 , ( 17 . 24 ) whose solution is x ∗ (cid:3) 1 . We have that φ 1 ( x ; µ ) (cid:3) x + µ [ x − 1 ] − (cid:3) (cid:21) ( 1 − µ ) x + µ if x ≤ 1 , x if x > 1 . ( 17 . 25 ) As can be seen in Figure 17 . 3 , the penalty function has a minimizer at x ∗ (cid:3) 1 when µ > 1 , but is a monotone increasing function when µ < 1 . ❐ Since penalty methods work by minimizing the penalty function directly , we need to characterize stationary points of φ 1 . Even though φ 1 is not differentiable , it has a directional derivative D ( φ 1 ( x ; µ ) ; p ) along any direction ; see ( A . 51 ) and the example following this deﬁnition . Deﬁnition 17 . 1 . A point ˆ x ∈ R n is a stationary point for the penalty function φ 1 ( x ; µ ) if D ( φ 1 ( ˆ x ; µ ) ; p ) ≥ 0 , ( 17 . 26 ) x x 1 x = 1 x = 1 x Φ ( ; µ ) x 1 Φ ( ; µ ) Figure 17 . 3 Penalty function for problem ( 17 . 24 ) with µ > 1 ( left ) and µ < 1 ( right ) . 1 7 . 2 . N O N S M O O T H P E N A L T Y F U N C T I O N S 509 for all p ∈ R n . Similarly , ˆ x is a stationary point of the measure of infeasibility h ( x ) (cid:3) (cid:3) i ∈ E | c i ( x ) | + (cid:3) i ∈ I [ c i ( x ) ] − ( 17 . 27 ) if D ( h ( ˆ x ) ; p ) ≥ 0 for all p ∈ R n . If a point is infeasible for ( 17 . 6 ) but stationary with respect to the infeasibility measure h , we say that it is an infeasible stationary point . For the function in Example 17 . 2 , we have for x ∗ (cid:3) 1 that D ( φ 1 ( x ∗ ; µ ) ; p ) (cid:3) (cid:21) p if p ≥ 0 ( 1 − µ ) p if p < 0 ; it follows that when µ > 1 , we have D ( φ 1 ( x ∗ ; µ ) ; p ) ≥ 0 for all p ∈ IR . The following result complements Theorem 17 . 3 by showing that stationary points of φ 1 ( x ; µ ) correspond to KKT points of the constrained optimization problem ( 17 . 6 ) under certain assumptions . Theorem 17 . 4 . Suppose that ˆ x is a stationary point of the penalty function φ 1 ( x ; µ ) for all µ greater than a certain threshold ˆ µ > 0 . Then , if ˆ x is feasible for the nonlinear program ( 17 . 6 ) , it satisﬁes the KKT conditions ( 12 . 34 ) for ( 17 . 6 ) . Is ˆ x is not feasible for ( 17 . 6 ) , it is an infeasible stationary point . P ROOF . Suppose ﬁrst that ˆ x is feasible . We have from ( A . 51 ) and the deﬁnition ( 17 . 22 ) of φ 1 that D ( φ 1 ( ˆ x ; µ ) ; p ) (cid:3) ∇ f ( ˆ x ) T p + µ (cid:3) i ∈ E (cid:28)(cid:28) ∇ c i ( ˆ x ) T p (cid:28)(cid:28) + µ (cid:3) i ∈ I ∩ A ( ˆ x ) (cid:9) ∇ c i ( ˆ x ) T p (cid:10) − , ( 17 . 28 ) where the active set A ( ˆ x ) is deﬁned in Deﬁnition 12 . 1 . ( We leave veriﬁcation of ( 17 . 28 ) as an exercise . ) Consider any direction p in the linearized feasible direction set F ( ˆ x ) of Deﬁnition 12 . 3 . By the properties of F ( ˆ x ) , we have (cid:28)(cid:28) ∇ c i ( ˆ x ) T p (cid:28)(cid:28) + (cid:3) i ∈ I ∩ A ( ˆ x ) (cid:9) ∇ c i ( ˆ x ) T p (cid:10) − (cid:3) 0 , so that by the stationarity assumption on φ 1 ( ˆ x ; µ ) , we have 0 ≤ D ( φ 1 ( ˆ x ; µ ) ; p ) (cid:3) ∇ f ( ˆ x ) T p , for all p ∈ F ( ˆ x ) . 510 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 Figure 17 . 4 Contours of φ 1 ( x ; µ ) from ( 17 . 3 ) for µ (cid:3) 2 , contour spacing 0 . 5 . We can now apply Farkas’ Lemma ( Lemma 12 . 4 ) to deduce that ∇ f ( ˆ x ) (cid:3) (cid:3) i ∈ A ( ˆ x ) ˆ λ i ∇ c i ( ˆ x ) , for some coefﬁcients ˆ λ i with ˆ λ i ≥ 0 for all i ∈ I ∩ A ( ˆ x ) . As we noted earlier ( see Theorem 12 . 1 and ( 12 . 35 ) ) , this expression implies that the KKT conditions ( 12 . 34 ) hold , as claimed . We leave the second part of the proof ( concerning infeasible ˆ x ) as an exercise . (cid:1) ❏ E XAMPLE 17 . 3 Consider again problem ( 17 . 3 ) , for which the (cid:1) 1 penalty function is φ 1 ( x ; µ ) (cid:3) x 1 + x 2 + µ (cid:28)(cid:28) x 2 1 + x 2 2 − 2 (cid:28)(cid:28) . ( 17 . 29 ) Figure 17 . 4 plots the function φ 1 ( x ; 2 ) , whose minimizer is the solution x ∗ (cid:3) ( − 1 , − 1 ) T of ( 17 . 3 ) . In fact , following Theorem 17 . 3 , we ﬁnd that for all µ > | λ ∗ | (cid:3) 0 . 5 , the minimizer of φ 1 ( x ; µ ) coincides with x ∗ . The sharp corners on the contours indicate nonsmoothness along the boundary of the circle deﬁned by x 21 + x 22 (cid:3) 2 . ❐ 1 7 . 2 . N O N S M O O T H P E N A L T Y F U N C T I O N S 511 These results provide the motivation for an algorithmic framework based on the (cid:1) 1 penalty function , which we now present . Framework 17 . 2 ( Classical (cid:1) 1 Penalty Method ) . Given µ 0 > 0 , tolerance τ > 0 , starting point x s 0 ; for k (cid:3) 0 , 1 , 2 , . . . Find an approximate minimizer x k of φ 1 ( x ; µ k ) , starting at x sk ; if h ( x k ) ≤ τ stop with approximate solution x k ; end ( if ) Choose new penalty parameter µ k + 1 > µ k ; Choose new starting point x sk + 1 ; end ( for ) Theminimizationof φ 1 ( x ; µ k ) ismadedifﬁcultbythenonsmoothnessofthefunction . Nevertheless , as we discuss below , it is well understood how to compute minimization steps using a smooth model of φ 1 ( x ; µ k ) , in a way that resembles SQP methods . The simplest scheme for updating the penalty parameter µ k is to increase it by a constant multiple ( say 5 or 10 ) , if the current value produces a minimizer that is not feasible to within the tolerance τ . This scheme sometimes works well in practice , but can also be inefﬁcient . If the initial penalty parameter µ 0 is too small , many cycles of Framework 17 . 2 may be needed to determine an appropriate value . In addition , the iterates may move away from the solution x ∗ in these initial cycles , in which case the minimization of φ 1 ( x ; µ k ) should be terminated early and x s k should possibly be reset to a previous iterate . If , on the other hand , µ k is excessively large , the penalty function will be difﬁcult to minimize , possibly requiring a large number of iterations . We return to the issue of selecting the penalty parameter below . A PRACTICAL (cid:1) 1 PENALTY METHOD As noted already , φ 1 ( x ; µ ) is nonsmooth—its gradient is not deﬁned at any x for which c i ( x ) (cid:3) 0 for some i ∈ E ∪ I . Rather than using techniques for nondifferen - tiable optimization , such as bundle methods [ 170 ] , we prefer techniques that take account of the special nature of the nondifferentiabilities in this function . As in the algorithms for unconstrained optimization discussed in the ﬁrst part of this book , we obtain a step toward the minimizer of φ 1 ( x ; µ ) by forming a simpliﬁed model of this function and seeking the minimizer of this model . Here , the model can be deﬁned by linearizing the constraints c i and replacing the nonlinear programming objective f by a quadratic 512 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S function , as follows : q ( p ; µ ) (cid:3) f ( x ) + ∇ f ( x ) T p + 12 p T W p + µ (cid:3) i ∈ E | c i ( x ) + ∇ c i ( x ) T p | + µ (cid:3) i ∈ I [ c i ( x ) + ∇ c i ( x ) T p ] − , ( 17 . 30 ) where W is a symmetric matrix which usually contains second derivative information about f and c i , i ∈ E ∪ I . The model q ( p ; µ ) is not smooth , but we can formulate the problem of minimizing q as a smooth quadratic programming problem by introducing artiﬁcial variables r i , s i , and t i , as follows : min p , r , s , t f ( x ) + 12 p T W p + ∇ f ( x ) T p + µ (cid:3) i ∈ E ( r i + s i ) + µ (cid:3) i ∈ I t i subject to ∇ c i ( x ) T p + c i ( x ) (cid:3) r i − s i , i ∈ E ∇ c i ( x ) T p + c i ( x ) ≥ − t i , i ∈ I ( 17 . 31 ) r , s , t ≥ 0 . This subproblem can be solved with a standard quadratic programming solver . Even after addition of a “box - shaped” trust region constraint of the form (cid:8) p (cid:8) ∞ ≤ (cid:6) , it remains a quadratic program . This approach to minimizing φ 1 is closely related to sequential quadratic programming ( SQP ) and will be discussed further in Chapter 18 . The strategy for choosing and updating the penalty parameter µ k is crucial to the practical success of the iteration . We mentioned that a simple ( but not always effective ) approach is to choose an initial value and increase it repeatedly until feasibility is attained . In some variants of the approach , the penalty parameter is chosen at every iteration so that µ k > (cid:8) λ k (cid:8) ∞ , where λ k is an estimate of the Lagrange multipliers computed at x k . We base this strategy on Theorem 17 . 2 , which suggests that in a neighborhood of a solution x ∗ , a good choice would be to set µ k modestly larger than (cid:8) λ ∗ (cid:8) ∞ . This strategy is not always successful , as the multiplier estimates may be inaccurate and may in any case not provide a good appropriate value of µ k far from the solution . The difﬁculties of choosing appropriate values of µ k caused nonsmooth penalty methods to fall out of favor during the 1990s and stimulated the development of ﬁlter methods , which do not require the choice of a penalty parameter ( see Section 15 . 4 ) . In recent years , however , there has been a resurgence of interest in penalty methods , in part because of their ability to handle degenerate problems . New approaches for updating the penalty parameter appear to have largely overcome the difﬁculties associated with choosing µ k , at least for some particular implementations ( see Algorithm 18 . 5 ) . Careful consideration should also be given to the choice of starting point x sk + 1 for the minimization of φ 1 ( x ; µ k + 1 ) . If the penalty parameter µ k for the present cycle is appropriate , in the sense that the algorithm made progress toward feasibility , then we can set x sk + 1 to be 1 7 . 2 . N O N S M O O T H P E N A L T Y F U N C T I O N S 513 the minimizer x k of φ 1 ( x ; µ k ) obtained on this cycle . Otherwise , we may want to restore the initial point from an earlier cycle . A GENERAL CLASS OF NONSMOOTH PENALTY METHODS Exact nonsmooth penalty functions can be deﬁned in terms of norms other than the (cid:1) 1 norm . We can write φ ( x ; µ ) (cid:3) f ( x ) + µ (cid:8) c E ( x ) (cid:8) + µ (cid:8) [ c I ( x ) ] − (cid:8) , ( 17 . 32 ) where (cid:8) · (cid:8) is any vector norm , and all the equality and inequality constraints have been grouped in the vector functions c E and c I , respectively . Framework 17 . 2 applies to any of these penalty functions ; we simply redeﬁne the measure of infeasibility as h ( x ) (cid:3) (cid:8) c E ( x ) (cid:8) + (cid:8) [ c I ( x ) ] − (cid:8) . The most common norms used in practice are the (cid:1) 1 , (cid:1) ∞ and (cid:1) 2 ( not squared ) . It is easy to ﬁnd a reformulation similar to ( 17 . 31 ) for the (cid:1) ∞ norm . The theoretical properties described for the (cid:1) 1 function extend to the general class ( 17 . 32 ) . In Theorem 17 . 3 , we replace the inequality ( 17 . 23 ) by µ ∗ (cid:3) (cid:8) λ ∗ (cid:8) D , ( 17 . 33 ) where (cid:8) · (cid:8) D is the dual norm of (cid:8) · (cid:8) , deﬁned in ( A . 6 ) . Theorem 17 . 4 applies without modiﬁcation . We show now that penalty functions of the type considered so far in this chapter must be nonsmooth to be exact . For simplicity , we restrict our attention to the case when there is a single equality constraint c 1 ( x ) (cid:3) 0 , and consider a penalty function of the form φ ( x ; µ ) (cid:3) f ( x ) + µ h ( c 1 ( x ) ) , ( 17 . 34 ) where h : IR → IR is a function satisfying the properties h ( y ) ≥ 0 for all y ∈ IR and h ( 0 ) (cid:3) 0 . Suppose for contradiction that h is continuously differentiable . Since h has a minimizer at zero , we have from Theorem 2 . 2 that ∇ h ( 0 ) (cid:3) 0 . If x ∗ is a local solution of the problem ( 17 . 6 ) , we have c 1 ( x ∗ ) (cid:3) 0 and therefore ∇ h ( c 1 ( x ∗ ) ) (cid:3) 0 . If x ∗ is a local minimizer of φ ( x ; µ ) , we therefore have 0 (cid:3) ∇ φ ( x ∗ ; µ ) (cid:3) ∇ f ( x ∗ ) + µ ∇ c 1 ( x ∗ ) ∇ h ( c 1 ( x ∗ ) ) (cid:3) ∇ f ( x ∗ ) . However , itisnotgenerallytruethatthegradientof f vanishesatthesolutionofa constrained optimization problem , so our original assumption that h is continuously differentiable must be incorrect , and φ ( · ; µ ) cannot be smooth . Nonsmoothpenaltyfunctionsarealsousedas meritfunctions inmethodsthatcompute steps by some other mechanism . For further details see the general discussion of Section 15 . 4 and the concrete implementations given in Chapters 18 and 19 . 514 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S 17 . 3 AUGMENTED LAGRANGIAN METHOD : EQUALITY CONSTRAINTS Wenowdiscussanapproachknownasthe methodofmultipliers orthe augmentedLagrangian method . This algorithm is related to the quadratic penalty algorithm of Section 17 . 1 , but it reduces the possibility of ill conditioning by introducing explicit Lagrange multiplier estimates into the function to be minimized , which is known as the augmented Lagrangian function . In contrast to the penalty functions discussed in Section 17 . 2 , the augmented Lagrangian function largely preserves smoothness , and implementations can be constructed from standard software for unconstrained or bound - constrained optimization . In this section we use superscripts ( usually k and k + 1 ) on the Lagrange multiplier estimates to denote iteration index , and subscripts ( usually i ) to denote the component indices of the vector λ . For all other variables we use subscripts for the iteration index , as usual . MOTIVATION AND ALGORITHMIC FRAMEWORK We consider ﬁrst the equality - constrained problem ( 17 . 1 ) . The quadratic penalty function Q ( x ; µ ) deﬁned by ( 17 . 2 ) penalizes constraint violations by squaring the infeasi - bilities and scaling them by µ / 2 . As we see from Theorem 17 . 2 , however , the approximate minimizers x k of Q ( x ; µ k ) do not quite satisfy the feasibility conditions c i ( x ) (cid:3) 0 , i ∈ E . Instead , they are perturbed ( see ( 17 . 10 ) ) so that c i ( x k ) ≈ − λ ∗ i / µ k , for all i ∈ E . ( 17 . 35 ) To be sure , we have c i ( x k ) → 0 as µ k ↑ ∞ , but one may ask whether we can alter the function Q ( x ; µ k ) to avoid this systematic perturbation—that is , to make the approximate minimizers more nearly satisfy the equality constraints c i ( x ) (cid:3) 0 , even for moderate values of µ k . The augmented Lagrangian function L A ( x , λ ; µ ) achieves this goal by including an explicitestimateoftheLagrangemultipliers λ , basedontheestimate ( 17 . 35 ) , intheobjective . From the deﬁnition L A ( x , λ ; µ ) def (cid:3) f ( x ) − (cid:3) i ∈ E λ i c i ( x ) + µ 2 (cid:3) i ∈ E c 2 i ( x ) , ( 17 . 36 ) we see that the augmented Lagrangian differs from the ( standard ) Lagrangian ( 12 . 33 ) for ( 17 . 1 ) by the presence of the squared terms , while it differs from the quadratic penalty function ( 17 . 2 ) in the presence of the summation term involving λ . In this sense , it is a combination of the Lagrangian function and the quadratic penalty function . We now design an algorithm that ﬁxes the penalty parameter µ to some value µ k > 0 at its k th iteration ( as in Frameworks 17 . 1 and 17 . 2 ) , ﬁxes λ at the current estimate λ k , and 1 7 . 3 . A U G M E N T E D L A G R A N G I A N M E T H O D : E Q U A L I T Y C O N S T R A I N T S 515 performs minimization with respect to x . Using x k to denote the approximate minimizer of L A ( x , λ k ; µ k ) , we have by the optimality conditions for unconstrained minimization ( Theorem 2 . 2 ) that 0 ≈ ∇ x L A ( x k , λ k ; µ k ) (cid:3) ∇ f ( x k ) − (cid:3) i ∈ E [ λ ki − µ k c i ( x k ) ] ∇ c i ( x k ) . ( 17 . 37 ) By comparing with the optimality condition ( 17 . 17 ) for ( 17 . 1 ) , we can deduce that λ ∗ i ≈ λ ki − µ k c i ( x k ) , for all i ∈ E . ( 17 . 38 ) By rearranging this expression , we have that c i ( x k ) ≈ − 1 µ k ( λ ∗ i − λ ki ) , for all i ∈ E , so we conclude that if λ k is close to the optimal multiplier vector λ ∗ , the infeasibility in x k will be much smaller than ( 1 / µ k ) , rather than being proportional to ( 1 / µ k ) as in ( 17 . 35 ) . The relation ( 17 . 38 ) immediately suggests a formula for improving our current estimate λ k of the Lagrange multiplier vector , using the approximate minimizer x k just calculated : We can set λ k + 1 i (cid:3) λ ki − µ k c i ( x k ) , for all i ∈ E . ( 17 . 39 ) This discussion motivates the following algorithmic framework . Framework 17 . 3 ( Augmented Lagrangian Method - Equality Constraints ) . Given µ 0 > 0 , tolerance τ 0 > 0 , starting points x s 0 and λ 0 ; for k (cid:3) 0 , 1 , 2 , . . . Find an approximate minimizer x k of L A ( · , λ k ; µ k ) , starting at x sk , and terminating when (cid:8)∇ x L A ( x k , λ k ; µ k ) (cid:8) ≤ τ k ; if a convergence test for ( 17 . 1 ) is satisﬁed stop with approximate solution x k ; end ( if ) Update Lagrange multipliers using ( 17 . 39 ) to obtain λ k + 1 ; Choose new penalty parameter µ k + 1 ≥ µ k ; Set starting point for the next iteration to x s k + 1 (cid:3) x k ; Select tolerance τ k + 1 ; end ( for ) We show below that convergence of this method can be assured without increasing µ indeﬁnitely . Ill conditioning is therefore less of a problem than in Framework 17 . 1 , so the choice of starting point x sk + 1 in Framework 17 . 3 is less critical . ( In Framework 17 . 3 we 516 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 −1 . 5 −1 −0 . 5 0 0 . 5 1 1 . 5 Figure17 . 5 Contours of L A ( x , λ ; µ ) from ( 17 . 40 ) for λ (cid:3) − 0 . 4 and µ (cid:3) 1 , contour spacing 0 . 5 . simply start the search at iteration k + 1 from the previous approximate minimizer x k . ) The tolerance τ k could be chosen to depend on the infeasibility (cid:4) i ∈ E | c ( x k ) | , and the penalty parameter µ may be increased if the reduction in this infeasibility measure is insufﬁcient at the present iteration . ❏ E XAMPLE 17 . 4 Consider again problem ( 17 . 3 ) , for which the augmented Lagrangian is L A ( x , λ ; µ ) (cid:3) x 1 + x 2 − λ ( x 2 1 + x 2 2 − 2 ) + µ 2 ( x 2 1 + x 2 2 − 2 ) 2 . ( 17 . 40 ) The solution of ( 17 . 3 ) is x ∗ (cid:3) ( − 1 , − 1 ) T and the optimal Lagrange multiplier is λ ∗ (cid:3) − 0 . 5 . Suppose that at iterate k we have µ k (cid:3) 1 ( as in Figure 17 . 1 ) , while the current multiplier estimate is λ k (cid:3) − 0 . 4 . Figure 17 . 5 plots the function L A ( x , − 0 . 4 ; 1 ) . Note that the spacing of the contours indicates that the conditioning of this problem is similar to that of the quadratic penalty function Q ( x ; 1 ) illustrated in Figure 17 . 1 . However , the minimizing value of x k ≈ ( − 1 . 02 , − 1 . 02 ) T is much closer to the solution x ∗ (cid:3) ( − 1 , − 1 ) T than is the minimizing value of Q ( x ; 1 ) , which is approximately ( − 1 . 1 , − 1 . 1 ) T . This example shows that the inclusion of the Lagrange multiplier term in the function L A ( x , λ ; µ ) can result in a signiﬁcant improvement over the quadratic penalty method , as a way to reformulate the constrained optimization problem ( 17 . 1 ) . ❐ 1 7 . 3 . A U G M E N T E D L A G R A N G I A N M E T H O D : E Q U A L I T Y C O N S T R A I N T S 517 PROPERTIES OF THE AUGMENTED LAGRANGIAN We now prove two results that justify the use of the augmented Lagrangian function and the method of multipliers for equality - constrained problems . The ﬁrst result validates the approach of Framework 17 . 3 by showing that when we have knowledge of the exact Lagrange multiplier vector λ ∗ , the solution x ∗ of ( 17 . 1 ) is a strict minimizer of L A ( x , λ ∗ ; µ ) for all µ sufﬁciently large . Although we do not know λ ∗ exactly in practice , the result and its proof suggest that we can obtain a good estimate of x ∗ by minimizing L A ( x , λ ; µ ) even when µ is not particularly large , provided that λ is a reasonably good estimate of λ ∗ . Theorem 17 . 5 . Let x ∗ be a local solution of ( 17 . 1 ) at which the LICQ is satisﬁed ( that is , the gradients ∇ c i ( x ∗ ) , i ∈ E , are linearly independent vectors ) , and the second - order sufﬁcient conditions speciﬁed in Theorem 12 . 6 are satisﬁed for λ (cid:3) λ ∗ . Then there is a threshold value ¯ µ such that for all µ ≥ ¯ µ , x ∗ is a strict local minimizer of L A ( x , λ ∗ ; µ ) . P ROOF . We prove the result by showing that x ∗ satisﬁes the second - order sufﬁcient condi - tions to be a strict local minimizer of L A ( x , λ ∗ ; µ ) ( see Theorem 2 . 4 ) for all µ sufﬁciently large ; that is , ∇ x L A ( x ∗ , λ ∗ ; µ ) (cid:3) 0 , ∇ 2 xx L A ( x ∗ , λ ∗ ; µ ) positive deﬁnite . ( 17 . 41 ) Because x ∗ is a local solution for ( 17 . 1 ) at which LICQ is satisﬁed , we can apply Theorem 12 . 1 to deduce that ∇ x L ( x ∗ , λ ∗ ) (cid:3) 0 and c i ( x ∗ ) (cid:3) 0 for all i ∈ E , so that ∇ x L A ( x ∗ , λ ∗ ; µ ) (cid:3) ∇ f ( x ∗ ) − (cid:3) i ∈ E [ λ ∗ i − µ c i ( x ∗ ) ] ∇ c i ( x ∗ ) (cid:3) ∇ f ( x ∗ ) − (cid:3) i ∈ E λ ∗ i ∇ c i ( x ∗ ) (cid:3) ∇ x L ( x ∗ , λ ∗ ) (cid:3) 0 , verifying the ﬁrst part of ( 17 . 41 ) , independently of µ . For the second part of ( 17 . 41 ) , we deﬁne A to be the constraint gradient matrix in ( 17 . 15 ) evaluated at x ∗ , and write ∇ 2 xx L A ( x ∗ , λ ∗ ; µ ) (cid:3) ∇ 2 xx L ( x ∗ , λ ∗ ) + µ A T A . If the claim in ( 17 . 41 ) were not true , then for each integer k ≥ 1 , we could choose a vector w k with (cid:8) w k (cid:8) (cid:3) 1 such that 0 ≥ w Tk ∇ 2 xx L A ( x ∗ , λ ∗ ; k ) w k (cid:3) w Tk ∇ 2 xx L ( x ∗ , λ ∗ ) w k + k (cid:8) A w k (cid:8) 22 , ( 17 . 42 ) 518 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S and therefore (cid:8) A w k (cid:8) 22 ≤ − ( 1 / k ) w Tk ∇ 2 xx L ( x ∗ , λ ∗ ) w k → 0 , as k → ∞ . ( 17 . 43 ) Since the vectors { w k } lie in a compact set ( the surface of the unit sphere ) , they have an accumulation point w . The limit ( 17 . 43 ) implies that A w (cid:3) 0 . Moreover , by rearranging ( 17 . 42 ) , we have that w Tk ∇ 2 xx L ( x ∗ , λ ∗ ) w k ≤ − k (cid:8) A w k (cid:8) 22 ≤ 0 , so by taking limits we have w T ∇ 2 xx L ( x ∗ , λ ∗ ) w ≤ 0 . However , this inequality contradicts the second - order conditions in Theorem 12 . 6 which , when applied to ( 17 . 1 ) , state that we must have w T ∇ 2 xx L ( x ∗ , λ ∗ ) w > 0 for all nonzero vectors w with A w (cid:3) 0 . Hence , the second part of ( 17 . 41 ) holds for all µ sufﬁciently large . (cid:1) The second result , given by Bertsekas [ 19 , Proposition 4 . 2 . 3 ] , describes the more realistic situation of λ (cid:9)(cid:3) λ ∗ . It gives conditions under which there is a minimizer of L A ( x , λ ; µ ) that lies close to x ∗ and gives error bounds on both x k and the updated multiplier estimate λ k + 1 obtained from solving the subproblem at iteration k . Theorem 17 . 6 . Suppose that the assumptions of Theorem 17 . 5 are satisﬁed at x ∗ and λ ∗ and let ¯ µ be chosen as in that theorem . Then there exist positive scalars δ , (cid:9) , and M such that the following claims hold : ( a ) For all λ k and µ k satisfying (cid:8) λ k − λ ∗ (cid:8) ≤ µ k δ , µ k ≥ ¯ µ , ( 17 . 44 ) the problem min x L A ( x , λ k ; µ k ) subject to (cid:8) x − x ∗ (cid:8) ≤ (cid:9) has a unique solution x k . Moreover , we have (cid:8) x k − x ∗ (cid:8) ≤ M (cid:8) λ k − λ ∗ (cid:8) / µ k . ( 17 . 45 ) ( b ) For all λ k and µ k that satisfy ( 17 . 44 ) , we have (cid:8) λ k + 1 − λ ∗ (cid:8) ≤ M (cid:8) λ k − λ ∗ (cid:8) / µ k , ( 17 . 46 ) where λ k + 1 is given by the formula ( 17 . 39 ) . 1 7 . 4 . P R A C T I C A L A U G M E N T E D L A G R A N G I A N M E T H O D S 519 ( c ) For all λ k and µ k that satisfy ( 17 . 44 ) , the matrix ∇ 2 xx L A ( x k , λ k ; µ k ) is positive deﬁnite and the constraint gradients ∇ c i ( x k ) , i ∈ E , are linearly independent . This theorem illustrates some salient properties of the augmented Lagrangian ap - proach . The bound ( 17 . 45 ) shows that x k will be close to x ∗ if λ k is accurate or if the penalty parameter µ k is large . Hence , this approach gives us two ways of improving the accuracy of x k , whereas the quadratic penalty approach gives us only one option : increasing µ k . The bound ( 17 . 46 ) states that , locally , we can ensure an improvement in the accuracy of the multipliers by choosing a sufﬁciently large value of µ k . The ﬁnal observation of the theorem shows that second - order sufﬁcient conditions for unconstrained minimization ( see Theo - rem 2 . 4 ) are also satisﬁed for the k th subproblem under the given conditions , so one can expect good performance by applying standard unconstrained minimization techniques . 17 . 4 PRACTICAL AUGMENTED LAGRANGIAN METHODS In this section we discuss practical augmented Lagrangian procedures , in particular , proce - dures for handling inequality constraints . We discuss three approaches based , respectively , on bound - constrained , linearly constrained , and unconstrained formulations . The ﬁrst two are the basis of the successful nonlinear programming codes LANCELOT [ 72 ] and MINOS [ 218 ] . BOUND - CONSTRAINED FORMULATION Given the general nonlinear program ( 17 . 6 ) , we can convert it to a problem with equality constraints and bound constraints by introducing slack variables s i and replacing the general inequalities c i ( x ) ≥ 0 , i ∈ I , by c i ( x ) − s i (cid:3) 0 , s i ≥ 0 , for all i ∈ I . ( 17 . 47 ) Bound constraints , l ≤ x ≤ u , need not be transformed . By reformulating in this way , we can write the nonlinear program as follows : min x ∈ IR n f ( x ) subject to c i ( x ) (cid:3) 0 , i (cid:3) 1 , 2 , . . . , m , l ≤ x ≤ u . ( 17 . 48 ) ( The slacks s i have been incorporated into the vector x and the constraint functions c i have been redeﬁned accordingly . We have numbered the constraints consecutively with i (cid:3) 1 , 2 , . . . , m and in the discussion below we gather them into the vector function c : IR n → IR m . ) Some of the components of the lower bound vector l may be set to −∞ , signifying that there is no lower bound on the components of x in question ; similarly for u . 520 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S The bound - constrained Lagrangian ( BCL ) approach incorporates only the equality constraints from ( 17 . 48 ) into the augmented Lagrangian , that is , L A ( x , λ ; µ ) (cid:3) f ( x ) − m (cid:3) i (cid:3) 1 λ i c i ( x ) + µ 2 m (cid:3) i (cid:3) 1 c 2 i ( x ) . ( 17 . 49 ) The bound constraints are enforced explicitly in the subproblem , which has the form min x L A ( x , λ ; µ ) subject to l ≤ x ≤ u . ( 17 . 50 ) After this problem has been solved approximately , the multipliers λ and the penalty parameter µ are updated and the process is repeated . An efﬁcient technique for solving the nonlinear program with bound constraints ( 17 . 50 ) ( for ﬁxed µ and λ ) is the ( nonlinear ) gradient projection method discussed in Section 18 . 6 . By specializing the KKT conditions ( 12 . 34 ) to the problem ( 17 . 50 ) , we ﬁnd that the ﬁrst - order necessary condition for x to be a solution of ( 17 . 50 ) is that x − P ( x − ∇ x L A ( x , λ ; µ ) , l , u ) (cid:3) 0 , ( 17 . 51 ) where P ( g , l , u ) is the projection of the vector g ∈ IR n onto the rectangular box [ l , u ] deﬁned as follows P ( g , l , u ) i (cid:3) ⎧⎪⎨ ⎪⎩ l i if g i ≤ l i , g i if g i ∈ ( l i , u i ) , u i if g i ≥ u i , for all i (cid:3) 1 , 2 , . . . , n . ( 17 . 52 ) We are now ready to describe the algorithm implemented in the LANCELOT software package . Algorithm 17 . 4 ( Bound - Constrained Lagrangian Method ) . Choose an initial point x 0 and initial multipliers λ 0 ; Choose convergence tolerances η ∗ and ω ∗ ; Set µ 0 (cid:3) 10 , ω 0 (cid:3) 1 / µ 0 , and η 0 (cid:3) 1 / µ 0 . 1 0 ; for k (cid:3) 0 , 1 , 2 , . . . Find an approximate solution x k of the subproblem ( 17 . 50 ) such that (cid:23)(cid:23) x k − P (cid:7) x k − ∇ x L A ( x k , λ k ; µ k ) , l , u (cid:8) (cid:23)(cid:23) ≤ ω k ; if (cid:8) c ( x k ) (cid:8) ≤ η k ( ∗ test for convergence ∗ ) if (cid:8) c ( x k ) (cid:8) ≤ η ∗ and (cid:23)(cid:23) x k − P (cid:7) x k − ∇ x L A ( x k , λ k ; µ k ) , l , u (cid:8)(cid:23)(cid:23) ≤ ω ∗ stop with approximate solution x k ; 1 7 . 4 . P R A C T I C A L A U G M E N T E D L A G R A N G I A N M E T H O D S 521 end ( if ) ( ∗ update multipliers , tighten tolerances ∗ ) λ k + 1 (cid:3) λ k − µ k c ( x k ) ; µ k + 1 (cid:3) µ k ; η k + 1 (cid:3) η k / µ 0 . 9 k + 1 ; ω k + 1 (cid:3) ω k / µ k + 1 ; else ( ∗ increase penalty parameter , tighten tolerances ∗ ) λ k + 1 (cid:3) λ k ; µ k + 1 (cid:3) 100 µ k ; η k + 1 (cid:3) 1 / µ 0 . 1 k + 1 ; ω k + 1 (cid:3) 1 / µ k + 1 ; end ( if ) end ( for ) The main branch in the algorithm occurs after problem ( 17 . 50 ) has been solved approximately , when the algorithm tests to see if the constraints have decreased sufﬁciently , as measured by the condition (cid:8) c ( x k ) (cid:8) ≤ η k . ( 17 . 53 ) If this condition holds , the penalty parameter is not changed for the next iteration because the current value of µ k is producing an acceptable level of constraint violation . The Lagrange multiplier estimates are updated according to the formula ( 17 . 39 ) and the tolerances ω k and η k are tightened in advance of the next iteration . If , on the other hand , ( 17 . 53 ) does not hold , then we increase the penalty parameter to ensure that the next subproblem will place more emphasis on decreasing the constraint violations . The Lagrange multiplier estimates are not updated in this case ; the focus is on improving feasibility . The constants 0 . 1 , 0 . 9 , and 100 appearing in Algorithm 17 . 4 are to some extent arbi - trary ; other values can be used without compromising theoretical convergence properties . LANCELOT uses the gradient projection method with trust regions ( see ( 18 . 61 ) ) to solve the bound - constrained nonlinear subproblem ( 17 . 50 ) . In this context , the gradient projection method constructs a quadratic model of the augmented Lagrangian L A and computes a step d by approximately solving the trust region problem min d 12 d T (cid:9) ∇ 2 xx L ( x k , λ k ) + µ k A T k A k (cid:10) d + ∇ x L A ( x k , λ k ; µ k ) T d ( 17 . 54 ) subject to l ≤ x k + d ≤ u , (cid:8) d (cid:8) ∞ ≤ (cid:6) , where A k (cid:3) A ( x k ) and (cid:6) is a trust region radius . ( We can formulate the trust - region constraint by means of the bounds − (cid:6) e ≤ d ≤ (cid:6) e , where e (cid:3) ( 1 , 1 , . . . , 1 ) T . ) Each iteration of the algorithm for solving this subproblem proceeds in two stages . First , a 522 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S projected gradient line search is performed to determine which components of d should be set at one of their bounds . Second , a conjugate gradient iteration minimizes ( 17 . 54 ) with respect to the free components of d —those not at one of their bounds . Importantly , this algorithm does not require the factorizations of a KKT matrix or of the constraint Jacobian A k . The conjugate gradient iteration only requires matrix - vector products , a feature that makes LANCELOT suitable for large problems . The Hessian of the Lagrangian ∇ 2 xx L ( x k , λ k ) in ( 17 . 54 ) can be replaced by a quasi - Newton approximation based on the BFGS or SR1 updating formulas . LANCELOT is designed to take advantage of partially separable structure in the objective function and constraints , either in the evaluation of the Hessian of the Lagrangian or in the quasi - Newton updates ( see Section 7 . 4 ) . LINEARLY CONSTRAINED FORMULATION Theprincipalideabehind linearlyconstrainedLagrangian ( LCL ) methodsistogenerate a step by minimizing the Lagrangian ( or augmented Lagrangian ) subject to linearizations of the constraints . If we use the formulation ( 17 . 48 ) of the nonlinear programming problem , the subproblem used in the LCL approach takes the form min x F k ( x ) ( 17 . 55a ) subject to c ( x k ) + A k ( x − x k ) (cid:3) 0 , l ≤ x ≤ u . ( 17 . 55b ) There are several possible choices for F k ( x ) . Early LCL methods deﬁned F k ( x ) (cid:3) f ( x ) − m (cid:3) i (cid:3) 1 λ ki ¯ c ki ( x ) , ( 17 . 56 ) where λ k is the current Lagrange multiplier estimate and ¯ c ki ( x ) is the difference between c i ( x ) and its linearization at x k , that is , ¯ c ki ( x ) (cid:3) c i ( x ) − c i ( x k ) − ∇ c i ( x k ) T ( x − x k ) . ( 17 . 57 ) One can show that as x k converges to a solution x ∗ , the Lagrange multiplier associated with the equality constraint in ( 17 . 55b ) converges to the optimal multiplier . Therefore , one can set λ k in ( 17 . 56 ) to be the Lagrange multiplier for the equality constraint in ( 17 . 55b ) from the previous iteration . Current LCL methods deﬁne F k to be the augmented Lagrangian function F k ( x ) (cid:3) f ( x ) − m (cid:3) i (cid:3) 1 λ k i ¯ c k i ( x ) + µ 2 m (cid:3) i (cid:3) 1 [ ¯ c k i ( x ) ] 2 . ( 17 . 58 ) 1 7 . 4 . P R A C T I C A L A U G M E N T E D L A G R A N G I A N M E T H O D S 523 This deﬁnition of F k appears to yield more reliable convergence from remote starting points than does ( 17 . 56 ) , in practice . There is a notable similarity between ( 17 . 58 ) and the augmented Lagrangian ( 17 . 36 ) , the difference being that the original constraints c i ( x ) have been replaced by the functions ¯ c ki ( x ) , which capture only the “second - order and above” terms of c i . The subproblem ( 17 . 55 ) differs from the augmented Lagrangian subproblem in that the new x is required to satisfy exactly a linearization of the equality constraints , while the linear part of each constraint is factored out of the objective via the use of ¯ c ki in place of c i . A procedure similar to the one in Algorithm 17 . 4 can be used for updating the penalty parameter µ and for adjusting the tolerances that govern the accuracy of the solution of the subproblem . Since ¯ c ki ( x ) has zero gradient at x (cid:3) x k , we have that ∇ F k ( x k ) (cid:3) ∇ f ( x k ) , where F k is deﬁned by either ( 17 . 56 ) or ( 17 . 58 ) . We can also show that the Hessian of F k is closely related to the Hessians of the Lagrangian or augmented Lagrangian functions for ( 17 . 1 ) . Because of these properties , the subproblem ( 17 . 55 ) is similar to the SQP subproblems described in Chapter 18 , with the quadratic objective in SQP being replaced by a nonlinear objective in LCL . Thewellknowncode MINOS [ 218 ] usesthenonlinearmodelfunction ( 17 . 58 ) andsolves the subproblem via a reduced gradient method that employs quasi - Newton approximations to the reduced Hessian of F k . A fairly accurate solution of the subproblem is computed in MINOS to try to ensure that the Lagrange multiplier estimates for the equality constraint in ( 17 . 55b ) ( subsequently used in ( 17 . 58 ) ) are of good quality . As a result , MINOS typically requires more evaluations of the objective f andconstraint functions c i ( andtheir gradients ) in total than SQP methods or interior - point methods . The total number of subproblems ( 17 . 55 ) that are solved in the course of the algorithm is , however , sometimes smaller than in other approaches . UNCONSTRAINED FORMULATION We can obtain an unconstrained form of the augmented Lagrangian subproblem for inequality - constrained problems by using a derivation based on the proximal point approach . Supposing for simplicity that the problem has no equality constraints ( E (cid:3) ∅ ) , we can write the problem ( 17 . 6 ) equivalently as an unconstrained optimization problem : min x ∈ IR n F ( x ) , ( 17 . 59 ) where F ( x ) (cid:3) max λ ≥ 0 (cid:21) f ( x ) − (cid:3) i ∈ I λ i c i ( x ) (cid:22) (cid:3) (cid:21) f ( x ) if x is feasible , ∞ otherwise . ( 17 . 60 ) To verify these expressions for F , consider ﬁrst the case of x infeasible , that is , c i ( x ) < 0 for some i . We can then choose λ i arbitrarily large and positive while setting λ j (cid:3) 0 for all 524 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S j (cid:9)(cid:3) i , to verify that F ( x ) is inﬁnite in this case . If x is feasible , we have c i ( x ) ≥ 0 for all i ∈ I , so the maximum is attained at λ (cid:3) 0 , and F ( x ) (cid:3) f ( x ) in this case . By combining ( 17 . 59 ) with ( 17 . 60 ) , we have min x ∈ IR n F ( x ) (cid:3) min x feasible f ( x ) , ( 17 . 61 ) which is simply the original inequality - constrained problem . It is not practical to minimize F directly , however , since this function is not smooth—it jumps from a ﬁnite value to an inﬁnite value as x crosses the boundary of the feasible set . We can make this approach more practical by replacing F by a smooth approximation ˆ F ( x ; λ k , µ k ) which depends on the penalty parameter µ k and Lagrange multiplier estimate λ k . This approximation is deﬁned as follows : ˆ F ( x ; λ k , µ k ) (cid:3) max λ ≥ 0 (cid:21) f ( x ) − (cid:3) i ∈ I λ i c i ( x ) − 1 2 µ k (cid:3) i ∈ I (cid:7) λ i − λ ki (cid:8) 2 (cid:22) . ( 17 . 62 ) The ﬁnal term in this expression applies a penalty for any move of λ away from the previous estimate λ k ; it encourages the new maximizer λ to stay proximal to the previous estimate λ k . Since ( 17 . 62 ) represents a bound - constrained quadratic problem in λ , separable in the individual components λ i , we can perform the maximization explicitly , to obtain λ i (cid:3) (cid:21) 0 if − c i ( x ) + λ ki / µ k ≤ 0 ; λ ki − µ k c i ( x ) otherwise . ( 17 . 63 ) By substituting these values in ( 17 . 62 ) , we ﬁnd that ˆ F ( x ; λ k , µ k ) (cid:3) f ( x ) + (cid:3) i ∈ I ψ ( c i ( x ) , λ ki ; µ k ) , ( 17 . 64 ) where the function ψ of three scalar arguments is deﬁned as follows : ψ ( t , σ ; µ ) def (cid:3) ⎧⎪⎨ ⎪⎩ − σ t + µ 2 t 2 if t − σ / µ ≤ 0 , − 1 2 µσ 2 otherwise , ( 17 . 65 ) Hence , we can obtain the new iterate x k by minimizing ˆ F ( x ; λ k , µ k ) with respect to x , and use the formula ( 17 . 63 ) to obtain the updated Lagrange multiplier estimates λ k + 1 . By comparing with Framework 17 . 3 , we see that F plays the role of L A and that the scheme just described extends the augmented Lagrangian methods for equality constraints neatly to the inequality - constrained case . Unlike the bound - constrained and linearly constrained formulations , however , this unconstrained formulation is not the basis of any widely used software packages , so its practical properties have not been tested . 1 7 . 5 . P E R S P E C T I V E S A N D S O F T W A R E 525 17 . 5 PERSPECTIVES AND SOFTWARE The quadratic penalty approach is often used by practitioners when the number of con - straints is small . In fact , minimization of Q ( x ; µ ) is sometimes performed for just one large value of µ . Unless µ is chosen wisely ( with the beneﬁt of experience with the underlying application ) , the resulting solution may not be very accurate . Since the main software pack - ages for constrained optimization do not implement a quadratic penalty approach , little attention has been paid to techniques for updating the penalty parameter , adjusting the tolerances τ k , and choosing the starting points x sk for each iteration . ( See Gould [ 141 ] for a discussion of these issues . ) Despite the intuitive appeal and simplicity of the quadratic penalty method of Frame - work 17 . 1 , the augmented Lagrangian method of Sections 17 . 3 and 17 . 4 is generally preferred . The subproblems are in general no more difﬁcult to solve , and the introduc - tion of multiplier estimates reduces the likelihood that large values of µ will be needed to obtain good feasibility and accuracy , thereby avoiding ill conditioning of the subproblem . Thequadraticpenaltyapproachremains , however , animportantmechanismforregularizing other algorithms such as sequential quadratic programming ( SQP ) methods , as we mention at the end of Section 17 . 1 . A general - purpose (cid:1) 1 penalty method was developed by Fletcher in the 1980’s . It is known as the S (cid:1) 1 QP method because it has features in common with SQP methods . More recently , an (cid:1) 1 penalty method that uses linear programming subproblems has been implemented as part of the KNITRO [ 46 ] software package . These two methods are discussed in Section 18 . 5 . The (cid:1) 1 penalty function has received signiﬁcant attention in recent years . It has been successfully used to treat difﬁcult problems , such as mathematical programs with complementarity constraints ( MPCCs ) , in which the constraints do not satisfy standard constraint qualiﬁcations [ 274 ] . By including these problematic constraints as a penalty term , ratherthanlinearizingthemexactly , andtreatingtheremainingconstraintsusingother techniques such as SQP or interior - point , it is possible to extend the range of applicability of these other approaches . See [ 8 ] for an active - set method and [ 16 , 191 ] for interior - point methods for MPCCs . The SNOPT software package uses an (cid:1) 1 penalty approach within an SQP method as a safeguard strategy in case the quadratic model appears to be infeasible or unbounded or to have unbounded multipliers . Augmented Lagrangian methods have been popular for many years because , in part , of their simplicity . The MINOS and LANCELOT packages rank among the best implemen - tations of augmented Lagrangian methods . Both are suitable for large - scale nonlinear programming problems . At a general level , the linearly constrained Lagrangian ( LCL ) of MINOS and the bound - constrained Lagrangian ( BCL ) method of LANCELOT have im - portant features in common . They differ signiﬁcantly , however , in the formulation of the step - computation subproblems and in the techniques used to solve these subproblems . MINOS follows a reduced - space approach to handle linearized constraints and employs a ( dense ) quasi - Newton approximation to the Hessian of the Lagrangian . As a result , MINOS 526 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S is most successful for problems with relatively few degrees of freedom . LANCELOT , on the other hand , is more effective when there are relatively few constraints . As indicated in Sec - tion 17 . 4 , LANCELOT does not require a factorization of the constraint Jacobian matrix A , again enhancing its suitability for very large problems , and provides a variety of Hessian ap - proximationoptionsandpreconditioners . The PENNON softwarepackage [ 184 ] isbasedonan augmented Lagrangian approach and has the advantage of permitting semi - deﬁnite matrix constraints . A weakness of both the bound - constrained and unconstrained Lagrangian methods is that they complicate constraints by squaring them in ( 17 . 49 ) ; progress in feasibility is only achieved through the minimization of the augmented Lagrangian . In contrast , the LCL formulation ( 17 . 55 ) promotes steady progress toward feasibility by performing a Newton - like step on the constraints . Not surprisingly , numerical experience has shown an advantage of MINOS over LANCELOT for problems with linear constraints . Smooth exact penalty functions have been constructed from the augmented La - grangian functions of Section 17 . 3 , but these are considerably more complicated . As an example , we mention the function of Fletcher for equality - constrained problems , deﬁned as follows : φ F ( x ; µ ) (cid:3) f ( x ) − λ ( x ) T c ( x ) + µ 2 (cid:3) i ∈ E c i ( x ) 2 . ( 17 . 66 ) The Lagrange multiplier estimates λ ( x ) are deﬁned explicitly in terms of x via the least - squares estimate , deﬁned as λ ( x ) (cid:3) [ A ( x ) A ( x ) T ] − 1 A ( x ) ∇ f ( x ) . ( 17 . 67 ) The function φ F is differentiable and exact , though the threshold value µ ∗ deﬁning the exactness property is not as easy to specify as for the nonsmooth (cid:1) 1 penalty function . Drawbacks of the penalty function φ F include the cost of evaluating λ ( x ) via ( 17 . 67 ) , the fact that λ ( x ) is not uniquely deﬁned when A ( x ) does not have full rank , and the observation that estimates of λ may be poor when A ( x ) is nearly singular . NOTES AND REFERENCES The quadratic penalty function was ﬁrst proposed by Courant [ 81 ] . Gould [ 140 ] addresses the issue of stable determination of the Newton step for Q ( x ; µ k ) . His formula ( 2 . 2 ) differs from our formula ( 17 . 20 ) in the right - hand - side , but both systems give rise to the same p component . TheaugmentedLagrangianmethodwasproposedbyHestenes [ 167 ] andPowell [ 240 ] . In the early days it was known as the “method of multipliers . ” A key reference in this area is Bertsekas [ 18 ] . Chapters 1 – 3 of that book contain a thorough motivation of the method that outlines its connections to other approaches . Other introductory discussions 1 7 . 5 . P E R S P E C T I V E S A N D S O F T W A R E 527 are given by Fletcher [ 101 , Section 12 . 2 ] , and Polak [ 236 , Section 2 . 8 ] . The extension to inequality constraints in the unconstrained formulation was described by Rockafellar [ 269 ] and Powell [ 243 ] . Linearly constrained Lagrangian methods were proposed by Robinson [ 266 ] and Rosen and Kreuser [ 271 ] . The MINOS implementation is due to Murtagh and Saunders [ 218 ] and the LANCELOT implementation due to Conn , Gould and Toint [ 72 ] . We have followed Friedlander and Saunders [ 114 ] in our use of the terms “linearly constrained Lagrangian” and “bound - constrained Lagrangian . ” ✐ E X E R C I S E S ✐ 17 . 1 ( a ) Write an equality - constrained problem which has a local solution and for which the quadratic penalty function Q is unbounded for any value of the penalty parameter . ( b ) Write a problem with a single inequality constraint that has the same unboundedness property . ✐ 17 . 2 Draw the contour lines of the quadratic penalty function Q for problem ( 17 . 5 ) corresponding to µ (cid:3) 1 . Find the stationary points of Q . ✐ 17 . 3 Minimize the quadratic penalty function for problem ( 17 . 3 ) for µ k (cid:3) 1 , 10 , 100 , 1000 using an unconstrained minimization algorithm . Set τ k (cid:3) 1 / µ k in Frame - work 17 . 1 , and choose the starting point x sk + 1 for each minimization to be the solution for the previous value of the penalty parameter . Report the approximate solution of each penalty function . ✐ 17 . 4 For z ∈ IR , show that the function min ( 0 , z ) 2 has a discontinuous second deriva - tive at z (cid:3) 0 . ( It follows that quadratic penalty function ( 17 . 7 ) may not have continuous second derivatives even when f and c i , i ∈ E ∪ I , in ( 17 . 6 ) are all twice continuously differentiable . ) ✐ 17 . 5 Write a quadratic program similar to ( 17 . 31 ) for the case when the norm in ( 17 . 32 ) is the inﬁnity norm . ✐ 17 . 6 Suppose that a nonlinear program has a minimizer x ∗ with Lagrange multiplier vector λ ∗ . One can show ( Fletcher [ 101 , Theorem 14 . 3 . 2 ] ) that the function φ 1 ( x ; µ ) does not have a local minimizer at x ∗ unless µ > (cid:8) λ ∗ (cid:8) ∞ . Verify that this observation holds for Example 17 . 1 . ✐ 17 . 7 Verify ( 17 . 28 ) . ✐ 17 . 8 Prove the second part of Theorem 17 . 4 . That is , if ˆ x is a stationary point of φ 1 ( x ; µ ) for all µ sufﬁciently large , but ˆ x is infeasible for problem ( 17 . 6 ) , then ˆ x is 528 C H A P T E R 1 7 . P E N A L T Y A N D A U G M E N T E D L A G R A N G I A N M E T H O D S an infeasible stationary point . ( Hint : Use the fact that D ( φ 1 ( ˆ x ; µ ) ; p ) (cid:3) ∇ f ( ˆ x ) T p + µ D ( h ( ˆ x ) ; p ) , where h is deﬁned in ( 17 . 27 ) . ) ✐ 17 . 9 Verify that the KKT conditions for the bound - constrained problem min x ∈ IR n φ ( x ) subject to l ≤ x ≤ u are equivalent to the compactly stated condition x − P ( x − ∇ φ ( x ) , l , u ) (cid:3) 0 , where the projection operator P onto the rectangular box [ l , u ] is deﬁned in ( 17 . 52 ) . ✐ 17 . 10 CalculatethegradientandHessianoftheLCLobjectivefunctions F k ( x ) deﬁned by ( 17 . 56 ) and ( 17 . 58 ) . Evaluate these quantities at x (cid:3) x k . ✐ 17 . 11 Show that the function ψ ( t , σ ; µ ) deﬁned in ( 17 . 65 ) has a discontinuity in its second derivative with respect to t when t (cid:3) σ / µ . Assuming that c i : IR n → IR is twice continuously differentiable , write down the second partial derivative matrix of ψ ( c i ( x ) , λ i ; µ ) with respect to x for the two cases c i ( x ) < λ i / µ and c i ( x ) ≥ a λ i / µ . ✐ 17 . 12 Verify that the multipliers λ i , i ∈ I deﬁned in ( 17 . 63 ) are indeed those that attain the maximum in ( 17 . 62 ) , and that the equality ( 17 . 64 ) holds . Hint : Use the fact that KKT conditions for the problem max φ ( x ) subject to x ≥ 0 indicate that at a stationary point , we either have x i (cid:3) 0 and [ ∇ φ ( x ) ] i ≤ 0 , or x i > 0 and [ ∇ φ ( x ) ] i (cid:3) 0 . This is page 529 Printer : Opaque this C H A P T E R 18 Sequential Quadratic Programming One of the most effective methods for nonlinearly constrained optimization generates steps by solving quadratic subproblems . This sequential quadratic programming ( SQP ) approach can be used both in line search and trust - region frameworks , and is appropriate for small or large problems . Unlike linearly constrained Lagrangian methods ( Chapter 17 ) , which are effective when most of the constraints are linear , SQP methods show their strength when solving problems with signiﬁcant nonlinearities in the constraints . All the methods considered in this chapter are active - set methods ; a more descriptive title for this chapter would perhaps be “Active - Set Methods for Nonlinear Programming . ” 530 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G In Chapter 14 we study interior - point methods for nonlinear programming , a competing approach for handling inequality - constrained problems . There are two types of active - set SQP methods . In the IQP approach , a general inequality - constrained quadratic program is solved at each iteration , with the twin goals of computing a step and generating an estimate of the optimal active set . EQP methods decouple these computations . They ﬁrst compute an estimate of the optimal active set , then solve an equality - constrained quadratic program to ﬁnd the step . In this chapter we study both IQP and EQP methods . Our development of SQP methods proceeds in two stages . First , we consider local methods that motivate the SQP approach and allow us to introduce the step computation techniques in a simple setting . Second , we consider practical line search and trust - region methods that achieve convergence from remote starting points . Throughout the chapter we give consideration to the algorithmic demands of solving large problems . 18 . 1 LOCAL SQP METHOD We begin by considering the equality - constrained problem min f ( x ) ( 18 . 1a ) subject to c ( x ) (cid:3) 0 , ( 18 . 1b ) where f : IR n → IR and c : IR n → IR m are smooth functions . The idea behind the SQP approach is to model ( 18 . 1 ) at the current iterate x k by a quadratic programming subproblem , then use the minimizer of this subproblem to deﬁne a new iterate x k + 1 . The challenge is to design the quadratic subproblem so that it yields a good step for the nonlinear optimization problem . Perhaps the simplest derivation of SQP methods , which we present now , views them as an application of Newton’s method to the KKT optimality conditions for ( 18 . 1 ) . From ( 12 . 33 ) , we know that the Lagrangian function for this problem is L ( x , λ ) (cid:3) f ( x ) − λ T c ( x ) . We use A ( x ) to denote the Jacobian matrix of the constraints , that is , A ( x ) T (cid:3) [ ∇ c 1 ( x ) , ∇ c 2 ( x ) , . . . , ∇ c m ( x ) ] , ( 18 . 2 ) where c i ( x ) is the i th component of the vector c ( x ) . The ﬁrst - order ( KKT ) conditions ( 12 . 34 ) of the equality - constrained problem ( 18 . 1 ) can be written as a system of n + m equations in the n + m unknowns x and λ : F ( x , λ ) (cid:3) (cid:1) ∇ f ( x ) − A ( x ) T λ c ( x ) (cid:2) (cid:3) 0 . ( 18 . 3 ) Any solution ( x ∗ , λ ∗ ) of the equality - constrained problem ( 18 . 1 ) for which A ( x ∗ ) has full 1 8 . 1 . L O C A L S Q P M E T H O D 531 rank satisﬁes ( 18 . 3 ) . One approach that suggests itself is to solve the nonlinear equations ( 18 . 3 ) by using Newton’s method , as described in Chapter 11 . The Jacobian of ( 18 . 3 ) with respect to x and λ is given by F (cid:14) ( x , λ ) (cid:3) (cid:1) ∇ 2 xx L ( x , λ ) − A ( x ) T A ( x ) 0 (cid:2) . ( 18 . 4 ) The Newton step from the iterate ( x k , λ k ) is thus given by (cid:1) x k + 1 λ k + 1 (cid:2) (cid:3) (cid:1) x k λ k (cid:2) + (cid:1) p k p λ (cid:2) , ( 18 . 5 ) where p k and p λ solve the Newton – KKT system (cid:1) ∇ 2 xx L k − A Tk A k 0 (cid:2) (cid:1) p k p λ (cid:2) (cid:3) (cid:1) −∇ f k + A Tk λ k − c k (cid:2) . ( 18 . 6 ) This Newton iteration is well deﬁned when the KKT matrix in ( 18 . 6 ) is nonsingular . We saw in Chapter 16 that this matrix is nonsingular if the following assumption holds at ( x , λ ) (cid:3) ( x k , λ k ) . Assumptions 18 . 1 . ( a ) The constraint Jacobian A ( x ) has full row rank ; ( b ) The matrix ∇ 2 xx L ( x , λ ) is positive deﬁnite on the tangent space of the constraints , that is , d T ∇ 2 xx L ( x , λ ) d > 0 for all d (cid:9)(cid:3) 0 such that A ( x ) d (cid:3) 0 . The ﬁrst assumption is the linear independence constraint qualiﬁcation discussed in Chapter 12 ( see Deﬁnition 12 . 4 ) , which we assume throughout this chapter . The second condition holds whenever ( x , λ ) is close to the optimum ( x ∗ , λ ∗ ) and the second - order suf - ﬁcient condition is satisﬁed at the solution ( see Theorem 12 . 6 ) . The Newton iteration ( 18 . 5 ) , ( 18 . 6 ) can be shown to be quadratically convergent under these assumptions ( see Theo - rem 18 . 4 ) and constitutes an excellent algorithm for solving equality - constrained problems , provided that the starting point is close enough to x ∗ . SQP FRAMEWORK There is an alternative way to view the iteration ( 18 . 5 ) , ( 18 . 6 ) . Suppose that at the iterate ( x k , λ k ) we model problem ( 18 . 1 ) using the quadratic program min p f k + ∇ f Tk p + 12 p T ∇ 2 xx L k p ( 18 . 7a ) subject to A k p + c k (cid:3) 0 . ( 18 . 7b ) 532 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G If Assumptions 18 . 1 hold , this problem has a unique solution ( p k , l k ) that satisﬁes ∇ 2 xx L k p k + ∇ f k − A Tk l k (cid:3) 0 , ( 18 . 8a ) A k p k + c k (cid:3) 0 . ( 18 . 8b ) The vectors p k and l k can be identiﬁed with the solution of the Newton equations ( 18 . 6 ) . If we subtract A Tk λ k from both sides of the ﬁrst equation in ( 18 . 6 ) , we obtain (cid:1) ∇ 2 xx L k − A Tk A k 0 (cid:2) (cid:1) p k λ k + 1 (cid:2) (cid:3) (cid:1) −∇ f k − c k (cid:2) . ( 18 . 9 ) Hence , by nonsingularity of the coefﬁcient matrix , we have that λ k + 1 (cid:3) l k and that p k solves ( 18 . 7 ) and ( 18 . 6 ) . The new iterate ( x k + 1 , λ k + 1 ) can therefore be deﬁned either as the solution of the quadratic program ( 18 . 7 ) or as the iterate generated by Newton’s method ( 18 . 5 ) , ( 18 . 6 ) applied to the optimality conditions of the problem . Both viewpoints are useful . The Newton point of view facilitates the analysis , whereas the SQP framework enables us to derive practical algorithms and to extend the technique to the inequality - constrained case . We now state the SQP method in its simplest form . Algorithm 18 . 1 ( Local SQP Algorithm for solving ( 18 . 1 ) ) . Choose an initial pair ( x 0 , λ 0 ) ; set k ← 0 ; repeat until a convergence test is satisﬁed Evaluate f k , ∇ f k , ∇ 2 xx L k , c k , and A k ; Solve ( 18 . 7 ) to obtain p k and l k ; Set x k + 1 ← x k + p k and λ k + 1 ← l k ; end ( repeat ) We note in passing that , in the objective ( 18 . 7a ) of the quadratic program , we could replace the linear term ∇ f Tk p by ∇ x L ( x k , λ k ) T p , since the constraint ( 18 . 7b ) makes the two choices equivalent . In this case , ( 18 . 7a ) is a quadratic approximation of the Lagrangian function . This fact provides a motivation for our choice of the quadratic model ( 18 . 7 ) : We ﬁrst replace the nonlinear program ( 18 . 1 ) by the problem of minimizing the Lagrangian subject to the equality constraints ( 18 . 1b ) , then make a quadratic approximation to the Lagrangian and a linear approximation to the constraints to obtain ( 18 . 7 ) . INEQUALITY CONSTRAINTS The SQP framework can be extended easily to the general nonlinear programming problem min f ( x ) ( 18 . 10a ) 1 8 . 2 . P R E V I E W O F P R A C T I C A L S Q P M E T H O D S 533 subject to c i ( x ) (cid:3) 0 , i ∈ E , ( 18 . 10b ) c i ( x ) ≥ 0 , i ∈ I . ( 18 . 10c ) To model this problem we now linearize both the inequality and equality constraints to obtain min p f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p ( 18 . 11a ) subject to ∇ c i ( x k ) T p + c i ( x k ) (cid:3) 0 , i ∈ E , ( 18 . 11b ) ∇ c i ( x k ) T p + c i ( x k ) ≥ 0 , i ∈ I . ( 18 . 11c ) We can use one of the algorithms for quadratic programming described in Chapter 16 to solve this problem . The new iterate is given by ( x k + p k , λ k + 1 ) where p k and λ k + 1 are the solution and the corresponding Lagrange multiplier of ( 18 . 11 ) . A local SQP method for ( 18 . 10 ) is thus given by Algorithm 18 . 1 with the modiﬁcation that the step is computed from ( 18 . 11 ) . In this IQP approach the set of active constraints A k at the solution of ( 18 . 11 ) constitutes our guess of the active set at the solution of the nonlinear program . If the SQP method is able to correctly identify this optimal active set ( and not change its guess at a subsequent iteration ) then it will act like a Newton method for equality - constrained optimization and will converge rapidly . The following result gives conditions under which this desirable behavior takes place . Recall that strict complementarity is said to hold at a solution pair ( x ∗ , λ ∗ ) if there is no index i ∈ I such that λ ∗ i (cid:3) c i ( x ∗ ) (cid:3) 0 . Theorem 18 . 1 ( Robinson [ 267 ] ) . Suppose that x ∗ is a local solution of ( 18 . 10 ) at which the KKT conditions are satis - ﬁed for some λ ∗ . Suppose , too , that the linear independence constraint qualiﬁcation ( LICQ ) ( Deﬁnition 12 . 4 ) , the strict complementarity condition ( Deﬁnition 12 . 5 ) , and the second - order sufﬁcient conditions ( Theorem 12 . 6 ) hold at ( x ∗ , λ ∗ ) . Then if ( x k , λ k ) is sufﬁciently close to ( x ∗ , λ ∗ ) , there is a local solution of the subproblem ( 18 . 11 ) whose active set A k is the same as the active set A ( x ∗ ) of the nonlinear program ( 18 . 10 ) at x ∗ . It is also remarkable that , far from the solution , the SQP approach is usually able to improve the estimate of the active set and guide the iterates toward a solution ; see Section 18 . 7 . 18 . 2 PREVIEW OF PRACTICAL SQP METHODS IQP AND EQP There are two ways of designing SQP methods for solving the general nonlinear programming problem ( 18 . 10 ) . The ﬁrst is the approach just described , which solves at 534 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G every iteration the quadratic subprogram ( 18 . 11 ) , taking the active set at the solution of this subproblem as a guess of the optimal active set . This approach is referred to as the IQP ( inequality - constrained QP ) approach ; it has proved to be quite successful in practice . Its main drawback is the expense of solving the general quadratic program ( 18 . 11 ) , which can be high when the problem is large . As the iterates of the SQP method converge to the solution , however , solving the quadratic subproblem becomes economical if we use information from the previous iteration to make a good guess of the optimal solution of the current subproblem . This warm - start strategy is described below . The second approach selects a subset of constraints at each iteration to be the so - called working set , and solves only equality - constrained subproblems of the form ( 18 . 7 ) , where the constraints in the working sets are imposed as equalities and all other constraints are ignored . The working set is updated at every iteration by rules based on Lagrange multiplier estimates , or by solving an auxiliary subproblem . This EQP ( equality - constrained QP ) approach has the advantage that the equality - constrained quadratic subproblems are less expensive to solve than ( 18 . 11 ) in the large - scale case . An example of an EQP method is the sequential linear - quadratic programming ( SLQP ) method discussed in Section 18 . 5 . This approach constructs a linear program by omitting the quadratic term p T ∇ 2 xx L k p from ( 18 . 11a ) and adding a trust - region constraint (cid:8) p (cid:8) ∞ ≤ (cid:6) k to the subproblem . The active set of the resulting linear programming sub - problem is taken to be the working set for the current iteration . The method then ﬁxes the constraints in the working set and solves an equality - constrained quadratic program ( with the term p T ∇ 2 xx L k p reinserted ) to obtain the SQP step . Another successful EQP method is the gradient projection method described in Section 16 . 7 in the context of bound con - strained quadratic programs . In this method , the working set is determined by minimizing a quadratic model along the path obtained by projecting the steepest descent direction onto the feasible region . ENFORCING CONVERGENCE To be practical , an SQP method must be able to converge from remote starting points and on nonconvex problems . We now outline how the local SQP strategy can be adapted to meet these goals . We begin by drawing an analogy with unconstrained optimization . In its simplest form , the Newton iteration for minimizing a function f takes a step to the minimizer of the quadratic model m k ( p ) (cid:3) f k + ∇ f Tk p + 12 p T ∇ 2 f k p . This framework is useful near the solution , where the Hessian ∇ 2 f ( x k ) is normally positive deﬁnite and the quadratic model has a well deﬁned minimizer . When x k is not close to the solution , however , the model function m k may not be convex . Trust - region methods ensure that the new iterate is always well deﬁned and useful by restricting the candidate step p k 1 8 . 3 . A L G O R I T H M I C D E V E L O P M E N T 535 to some neighborhood of the origin . Line search methods modify the Hessian in m k ( p ) to make it positive deﬁnite ( possibly replacing it by a quasi - Newton approximation B k ) , to ensure that p k is a descent direction for the objective function f . Similar strategies are used to globalize SQP methods . If ∇ 2 xx L k is positive deﬁnite on the tangent space of the active constraints , the quadratic subproblem ( 18 . 7 ) has a unique solution . When ∇ 2 xx L k does not have this property , line search methods either replace it by a positive deﬁnite approximation B k or modify ∇ 2 xx L k directly during the process of matrix factorization . In all these cases , the subproblem ( 18 . 7 ) becomes well deﬁned , but the modiﬁcations may introduce unwanted distortions in the model . Trust - region SQP methods add a constraint to the subproblem , limiting the step to a region within which the model ( 18 . 7 ) is considered reliable . These methods are able to handle indeﬁnite Hessians ∇ 2 xx L k . The inclusion of the trust region may , however , cause the subproblem to become infeasible , and the procedures for handling this situation complicate the algorithms and increase their computational cost . Due to these tradeoffs , neither of the two SQP approaches—line search or trust - region—is currently regarded as clearly superior to the other . ThetechniqueusedtoacceptorrejectstepsalsoimpactstheefﬁciencyofSQPmethods . In unconstrained optimization , the merit function is simply the objective f , and it remains ﬁxed throughout the minimization procedure . For constrained problems , we use devices such as a merit function or a ﬁlter ( see Section 15 . 4 ) . The parameters or entries used in these devices must be updated in a way that is compatible with the step produced by the SQP method . 18 . 3 ALGORITHMIC DEVELOPMENT Inthissectionweexpandontheideasoftheprevioussectionanddescribevariousingredients needed to produce practical SQP algorithms . We focus on techniques for ensuring that the subproblems are always feasible , on alternative choices for the Hessian of the quadratic model , and on step - acceptance mechanisms . HANDLING INCONSISTENT LINEARIZATIONS A possible difﬁculty with SQP methods is that the linearizations ( 18 . 11b ) , ( 18 . 11c ) of the nonlinear constraints may give rise to an infeasible subproblem . Consider , for example , the case in which n (cid:3) 1 and the constraints are x ≤ 1 and x 2 ≥ 4 . When we linearize these constraints at x k (cid:3) 1 , we obtain the inequalities − p ≥ 0 and 2 p − 3 ≥ 0 , which are inconsistent . 536 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G To overcome this difﬁculty , we can reformulate the nonlinear program ( 18 . 10 ) as the (cid:1) 1 penalty problem min x , v , w , t f ( x ) + µ (cid:3) i ∈ E ( v i + w i ) + µ (cid:3) i ∈ I t i ( 18 . 12a ) subject to c i ( x ) (cid:3) v i − w i , i ∈ E , ( 18 . 12b ) c i ( x ) ≥ − t i , i ∈ I , ( 18 . 12c ) v , w , t ≥ 0 , ( 18 . 12d ) for some positive choice of the penalty parameter µ . The quadratic subproblem ( 18 . 11 ) associated with ( 18 . 12 ) is always feasible . As discussed in Chapter 17 , if the nonlinear problem ( 18 . 10 ) has a solution x ∗ that satisﬁes certain regularity assumptions , and if the penalty parameter µ is sufﬁciently large , then x ∗ ( along with v ∗ i (cid:3) w ∗ i (cid:3) 0 , i ∈ E and t ∗ i (cid:3) 0 , i ∈ I ) is a solution of the penalty problem ( 18 . 12 ) . If , on the other hand , there is no feasible solution to the nonlinear problem and µ is large enough , then the penalty problem ( 18 . 12 ) usually determines a stationary point of the infeasibility measure . The choice of µ has been discussed in Chapter 17 and is considered again in Section 18 . 5 . The SNOPT software package [ 127 ] uses the formulation ( 18 . 12 ) , which is sometimes called the elastic mode , to deal with inconsistencies of the linearized constraints . Other procedures for relaxing the constraints are presented in Section 18 . 5 in the context of trust - region methods . FULL QUASI - NEWTON APPROXIMATIONS The Hessian of the Lagrangian ∇ 2 xx L ( x k , λ k ) is made up of second derivatives of the objective function and constraints . In some applications , this information is not easy to compute , so it is useful to consider replacing the Hessian ∇ 2 xx L ( x k , λ k ) in ( 18 . 11a ) by a quasi - Newton approximation . Since the BFGS and SR1 formulae have proved to be successful in the context of unconstrained optimization , we can employ them here as well . The update for B k that results from the step from iterate k to iterate k + 1 makes use of the vectors s k and y k deﬁned as follows : s k (cid:3) x k + 1 − x k , y k (cid:3) ∇ x L ( x k + 1 , λ k + 1 ) − ∇ x L ( x k , λ k + 1 ) . ( 18 . 13 ) We compute the new approximation B k + 1 using the BFGS or SR1 formulae given , respec - tively , by ( 6 . 19 ) and ( 6 . 24 ) . We can view this process as the application of quasi - Newton updating to the case in which the objective function is given by the Lagrangian L ( x , λ ) ( with λ ﬁxed ) . This viewpoint immediately reveals the strengths and weaknesses of this approach . If ∇ 2 xx L is positive deﬁnite in the region where the minimization takes place , then BFGS quasi - Newton approximations B k will reﬂect some of the curvature information of the problem , and the iteration will converge robustly and rapidly , just as in the unconstrained BFGS method . If , however , ∇ 2 xx L contains negative eigenvalues , then the BFGS approach 1 8 . 3 . A L G O R I T H M I C D E V E L O P M E N T 537 of approximating it with a positive deﬁnite matrix may be problematic . BFGS updating requires that s k and y k satisfy the curvature condition s Tk y k > 0 , which may not hold when s k and y k are deﬁned by ( 18 . 13 ) , even when the iterates are close to the solution . To overcome this difﬁculty , we could skip the BFGS update if the condition s Tk y k ≥ θ s Tk B k s k ( 18 . 14 ) is not satisﬁed , where θ is a positive parameter ( 10 − 2 , say ) . This strategy may , on occasion , yield poor performance or even failure , so it cannot be regarded as adequate for general - purpose algorithms . A more effective modiﬁcation ensures that the update is always well deﬁned by modifying the deﬁnition of y k . Procedure 18 . 2 ( Damped BFGS Updating ) . Given : symmetric and positive deﬁnite matrix B k ; Deﬁne s k and y k as in ( 18 . 13 ) and set r k (cid:3) θ k y k + ( 1 − θ k ) B k s k , where the scalar θ k is deﬁned as θ k (cid:3) (cid:21) 1 if s Tk y k ≥ 0 . 2 s Tk B k s k , ( 0 . 8 s Tk B k s k ) / ( s Tk B k s k − s Tk y k ) if s Tk y k < 0 . 2 s Tk B k s k ; ( 18 . 15 ) Update B k as follows : B k + 1 (cid:3) B k − B k s k s Tk B k s Tk B k s k + r k r Tk s Tk r k . ( 18 . 16 ) The formula ( 18 . 16 ) is simply the standard BFGS update formula , with y k replaced by r k . It guarantees that B k + 1 is positive deﬁnite , since it is easy to show that when θ k (cid:9)(cid:3) 1 we have s Tk r k (cid:3) 0 . 2 s Tk B k s k > 0 . ( 18 . 17 ) To gain more insight into this strategy , note that the choice θ k (cid:3) 0 gives B k + 1 (cid:3) B k , while θ k (cid:3) 1 gives the ( possibly indeﬁnite ) matrix produced by the unmodiﬁed BFGS update . A value θ k ∈ ( 0 , 1 ) thus produces a matrix that interpolates the current approximation B k and the one produced by the unmodiﬁed BFGS formula . The choice of θ k ensures that the new approximation stays close enough to the current approximation B k to ensure positive deﬁniteness . 538 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G Damped BFGS updating often works well but it , too , can behave poorly on difﬁcult problems . It still fails to address the underlying problem that the Lagrangian Hessian may not be positive deﬁnite . For this reason , SR1 updating may be more appropriate , and is indeed a good choice for trust - region SQP methods . An SR1 approximation to the Hessian of the Lagrangian is obtained by applying formula ( 6 . 24 ) with s k and y k deﬁned by ( 18 . 13 ) , using the safeguards described in Chapter 6 . Line search methods cannot , however , accept indeﬁnite Hessian approximations and would therefore need to modify the SR1 formula , possibly by adding a sufﬁciently large multiple of the identity matrix ; see the discussion around ( 19 . 25 ) . All quasi - Newton approximations B k discussed above are dense n × n matrices that can be expensive to store and manipulate in the large - scale case . Limited - memory updating is useful in this context and is often implemented in software packages . ( See ( 19 . 29 ) for an implementation of limited - memory BFGS in a constrained optimization algorithm . ) REDUCED - HESSIAN QUASI - NEWTON APPROXIMATIONS When we examine the KKT system ( 18 . 9 ) for the equality - constrained problem ( 18 . 1 ) , we see that the part of the step p k in the range space of A Tk is completely determined by the second block row A k p k (cid:3) − c k . The Lagrangian Hessian ∇ 2 xx L k affects only the part of p k in the orthogonal subspace , namely , the null space of A k . It is reasonable , therefore , to consider quasi - Newton methods that ﬁnd approximations to only that part of ∇ 2 xx L k that affects the component of p k in the null space of A k . In this section , we consider quasi - Newton methods based on these reduced - Hessian approximations . Our focus is on equality - constrained problems in this section , as existing SQP methods for the full problem ( 18 . 10 ) use reduced - Hessian approaches only after an equality - constrained subproblem has been generated . To derive reduced - Hessian methods , we consider solution of the step equations ( 18 . 9 ) by means of the null space approach of Section 16 . 2 . In that section , we deﬁned matrices Y k and Z k whose columns span the range space of A Tk and the null space of A k , respectively . By writing p k (cid:3) Y k p Y + Z k p Z , ( 18 . 18 ) and substituting into ( 18 . 9 ) , we obtain the following system to be solved for p Y and p Z : ( A k Y k ) p Y (cid:3) − c k , ( 18 . 19a ) (cid:7) Z Tk ∇ 2 xx L k Z k (cid:8) p Z (cid:3) − Z Tk ∇ 2 xx L k Y k p Y − Z Tk ∇ f k . ( 18 . 19b ) From the ﬁrst block of equations in ( 18 . 9 ) we see that the Lagrange multipliers λ k + 1 , which are sometimes called QP multipliers , can be obtained by solving ( A k Y k ) T λ k + 1 (cid:3) Y Tk ( ∇ f k + ∇ 2 xx L k p k ) . ( 18 . 20 ) 1 8 . 3 . A L G O R I T H M I C D E V E L O P M E N T 539 We can avoid computation of the Hessian ∇ 2 xx L k by introducing several approx - imations in the null - space approach . First , we delete the term involving p k from the right - hand - side of ( 18 . 20 ) , thereby decoupling the computations of p k and λ k + 1 and elimi - nating the need for ∇ 2 xx L k in this term . This simpliﬁcation can be justiﬁed by observing that p k converges to zero as we approach the solution , whereas ∇ f k normally does not . There - fore , the multipliers computed in this manner will be good estimates of the QP multipliers near the solution . More speciﬁcally , if we choose Y k (cid:3) A Tk ( which is a valid choice for Y k when A k has full row rank ; see ( 15 . 16 ) ) , we obtain ˆ λ k + 1 (cid:3) ( A k A Tk ) − 1 A k ∇ f k . ( 18 . 21 ) These are called the least - squares multipliers because they can also be derived by solving the problem min λ (cid:8)∇ x L ( x k , λ ) (cid:8) 22 (cid:3) (cid:23)(cid:23) ∇ f k − A Tk λ (cid:23)(cid:23) 2 2 . ( 18 . 22 ) This observation shows that the least - squares multipliers are useful even when the current iterateisfarfromthesolution , becausetheyseektosatisfytheﬁrst - orderoptimalitycondition in ( 18 . 3 ) as closely as possible . Conceptually , the use of least - squares multipliers transforms the SQP method from a primal - dual iteration in x and λ to a purely primal iteration in the x variable alone . Our second simpliﬁcation of the null - space approach is to remove the cross term Z Tk ∇ 2 xx L k Y k p Y in ( 18 . 19b ) , thereby yielding the simpler system ( Z Tk ∇ 2 xx L k Z k ) p Z (cid:3) − Z Tk ∇ f k . ( 18 . 23 ) This approach has the advantage that it needs to approximate only the matrix Z Tk ∇ 2 xx L k Z k , not the ( n − m ) × m cross - term matrix Z Tk ∇ 2 xx L k Y k , which is a relatively large matrix when m (cid:28) n − m . Dropping the cross term is justiﬁed when Z Tk ∇ 2 xx L k Z k is replaced by a quasi - Newton approximation because the normal component p Y usually converges to zero faster than the tangential component p Z , thereby making ( 18 . 23 ) a good approximation of ( 18 . 19b ) . HavingdispensedwiththepartialHessian Z Tk ∇ 2 xx L k Y k , wediscusshowtoapproximate the remaining part Z Tk ∇ 2 xx L k Z k . Suppose we have just taken a step α k p k (cid:3) x k + 1 − x k (cid:3) α k Z k p Z + α k Y k p Y . By Taylor’s theorem , writing ∇ 2 xx L k + 1 (cid:3) ∇ 2 xx L ( x k + 1 , λ k + 1 ) , we have ∇ 2 xx L k + 1 α k p k ≈ ∇ x L ( x k + α k p k , λ k + 1 ) − ∇ x L ( x k , λ k + 1 ) . By premultiplying by Z Tk , we have Z T k ∇ 2 xx L k + 1 Z k α k p Z ( 18 . 24 ) ≈ − Z Tk ∇ 2 xx L k + 1 Y k α k p Y + Z Tk [ ∇ x L ( x k + α k p k , λ k + 1 ) − ∇ x L ( x k , λ k + 1 ) ] . 540 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G If we drop the cross term Z Tk ∇ 2 xx L k + 1 Y k α k p Y ( using the rationale discussed earlier ) , we see that the secant equation for M k can be deﬁned by M k + 1 s k (cid:3) y k , ( 18 . 25 ) where s k and y k are given by s k (cid:3) α k p Z , y k (cid:3) Z Tk [ ∇ x L ( x k + α k p k , λ k + 1 ) − ∇ x L ( x k , λ k + 1 ) ] . ( 18 . 26 ) We then apply the BFGS or SR1 formulae , using these deﬁnitions for the correction vectors s k and y k , to deﬁne the new approximation M k + 1 . An advantage of this reduced - Hessian approach , compared to full - Hessian quasi - Newton approximations , is that the reduced Hessian is much more likely to be positive deﬁnite , even when the current iterate is some distance from the solution . When using the BFGS formula , the safeguarding mechanism discussed above will be required less often in line search implementations . MERIT FUNCTIONS SQP methods often use a merit function to decide whether a trial step should be accepted . In line search methods , the merit function controls the size of the step ; in trust - region methods it determines whether the step is accepted or rejected and whether the trust - region radius should be adjusted . A variety of merit functions have been used in SQP methods , including nonsmooth penalty functions and augmented Lagrangians . We limit our discussion to exact , nonsmooth merit functions typiﬁed by the (cid:1) 1 merit function discussed in Chapters 15 and 17 . For the purpose of step computation and evaluation of a merit function , inequality constraints c ( x ) ≥ 0 are often converted to the form ¯ c ( x , s ) (cid:3) c ( x ) − s (cid:3) 0 , where s ≥ 0 is a vector of slacks . ( The condition s ≥ 0 is typically not monitored by the merit function . ) Therefore , in the discussion that follows we assume that all constraints are in the form of equalities , and we focus our attention on problem ( 18 . 1 ) . The (cid:1) 1 merit function for ( 18 . 1 ) takes the form φ 1 ( x ; µ ) (cid:3) f ( x ) + µ (cid:8) c ( x ) (cid:8) 1 . ( 18 . 27 ) In a line search method , a step α k p k will be accepted if the following sufﬁcient decrease condition holds : φ 1 ( x k + α k p k ; µ k ) ≤ φ 1 ( x k , µ k ) + ηα k D ( φ 1 ( x k ; µ ) ; p k ) , η ∈ ( 0 , 1 ) , ( 18 . 28 ) 1 8 . 3 . A L G O R I T H M I C D E V E L O P M E N T 541 where D ( φ 1 ( x k ; µ ) ; p k ) denotes the directional derivative of φ 1 in the direction p k . This requirement is analogous to the Armijo condition ( 3 . 4 ) for unconstrained optimization provided that p k is a descent direction , that is , D ( φ 1 ( x k ; µ ) ; p k ) < 0 . This descent condition holdsifthepenaltyparameter µ ischosensufﬁcientlylarge , asweshowinthefollowingresult . Theorem 18 . 2 . Let p k and λ k + 1 be generated by the SQP iteration ( 18 . 9 ) . Then the directional derivative of φ 1 in the direction p k satisﬁes D ( φ 1 ( x k ; µ ) ; p k ) (cid:3) ∇ f Tk p k − µ (cid:8) c k (cid:8) 1 . ( 18 . 29 ) Moreover , we have that D ( φ 1 ( x k ; µ ) ; p k ) ≤ − p Tk ∇ 2 xx L k p k − ( µ − (cid:8) λ k + 1 (cid:8) ∞ ) (cid:8) c k (cid:8) 1 . ( 18 . 30 ) P ROOF . By applying Taylor’s theorem ( see ( 2 . 5 ) ) to f and c i , i (cid:3) 1 , 2 , . . . , m , we obtain φ 1 ( x k + α p ; µ ) − φ 1 ( x k ; µ ) (cid:3) f ( x k + α p ) − f k + µ (cid:8) c ( x k + α p ) (cid:8) 1 − µ (cid:8) c k (cid:8) 1 ≤ α ∇ f Tk p + γ α 2 (cid:8) p (cid:8) 2 + µ (cid:8) c k + α A k p (cid:8) 1 − µ (cid:8) c k (cid:8) 1 , where the positive constant γ bounds the second - derivative terms in f and c . If p (cid:3) p k is given by ( 18 . 9 ) , we have that A k p k (cid:3) − c k , so for α ≤ 1 we have that φ 1 ( x k + α p k ; µ ) − φ 1 ( x k ; µ ) ≤ α [ ∇ f Tk p k − µ (cid:8) c k (cid:8) 1 ] + α 2 γ (cid:8) p k (cid:8) 2 . By arguing similarly , we also obtain the following lower bound : φ 1 ( x k + α p k ; µ ) − φ 1 ( x k ; µ ) ≥ α [ ∇ f Tk p k − µ (cid:8) c k (cid:8) 1 ] − α 2 γ (cid:8) p k (cid:8) 2 . Taking limits , we conclude that the directional derivative of φ 1 in the direction p k is given by D ( φ 1 ( x k ; µ ) ; p k ) (cid:3) ∇ f Tk p k − µ (cid:8) c k (cid:8) 1 , ( 18 . 31 ) which proves ( 18 . 29 ) . The fact that p k satisﬁes the ﬁrst equation in ( 18 . 9 ) implies that D ( φ 1 ( x k ; µ ) ; p k ) (cid:3) − p Tk ∇ 2 xx L k p k + p Tk A Tk λ k + 1 − µ (cid:8) c k (cid:8) 1 . From the second equation in ( 18 . 9 ) , we can replace the term p T k A T k λ k + 1 in this expression by − c Tk λ k + 1 . By making this substitution in the expression above and invoking the inequality − c Tk λ k + 1 ≤ (cid:8) c k (cid:8) 1 (cid:8) λ k + 1 (cid:8) ∞ , we obtain ( 18 . 30 ) . (cid:1) 542 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G It follows from ( 18 . 30 ) that p k will be a descent direction for φ 1 if p k (cid:9)(cid:3) 0 , ∇ 2 xx L k is positive deﬁnite and µ > (cid:8) λ k + 1 (cid:8) ∞ . ( 18 . 32 ) ( A more detailed analysis shows that this assumption on ∇ 2 xx L k can be relaxed ; we need only the reduced Hessian Z T k ∇ 2 xx L k Z k to be positive deﬁnite . ) One strategy for choosing the new value of the penalty parameter µ in φ 1 ( x ; µ ) at every iteration is to increase the previous value , if necessary , so as to satisfy ( 18 . 32 ) , with some margin . It has been observed , however , that this strategy may select inappropriate values of µ and often interferes with the progress of the iteration . An alternative approach , based on ( 18 . 29 ) , is to require that the directional derivative be sufﬁciently negative in the sense that D ( φ 1 ( x k ; µ ) ; p k ) (cid:3) ∇ f Tk p k − µ (cid:8) c k (cid:8) 1 ≤ − ρµ (cid:8) c k (cid:8) 1 , for some ρ ∈ ( 0 , 1 ) . This inequality holds if µ ≥ ∇ f Tk p k ( 1 − ρ ) (cid:8) c k (cid:8) 1 . ( 18 . 33 ) This choice is not dependent on the Lagrange multipliers and performs adequately in practice . A more effective strategy for choosing µ , which is appropriate both in the line search and trust - region contexts , considers the effect of the step on a model of the merit function . We deﬁne a ( piecewise ) quadratic model of φ 1 by q µ ( p ) (cid:3) f k + ∇ f Tk p + σ 2 p T ∇ 2 xx L k p + µ m ( p ) , ( 18 . 34 ) where m ( p ) (cid:3) (cid:8) c k + A k p (cid:8) 1 , and σ is a parameter to be deﬁned below . After computing a step p k , we choose the penalty parameter µ large enough that q µ ( 0 ) − q µ ( p k ) ≥ ρµ [ m ( 0 ) − m ( p k ) ] , ( 18 . 35 ) for some parameter ρ ∈ ( 0 , 1 ) . It follows from ( 18 . 34 ) and ( 18 . 7b ) that inequality ( 18 . 35 ) is satisﬁed for µ ≥ ∇ f Tk p k + ( σ / 2 ) p Tk ∇ 2 xx L k p k ( 1 − ρ ) (cid:8) c k (cid:8) 1 . ( 18 . 36 ) If the value of µ from the previous iteration of the SQP method satisﬁes ( 18 . 36 ) , it is left unchanged . Otherwise , µ is increased so that it satisﬁes this inequality with some margin . 1 8 . 3 . A L G O R I T H M I C D E V E L O P M E N T 543 The constant σ is used to handle the case in which the Hessian ∇ 2 xx L k is not positive deﬁnite . We deﬁne σ as σ (cid:3) (cid:21) 1 if p Tk ∇ 2 xx L k p k > 0 , 0 otherwise . ( 18 . 37 ) It is easy to verify that , if µ satisﬁes ( 18 . 36 ) , this choice of σ ensures that D ( φ 1 ( x k ; µ ) ; p k ) ≤ − ρµ (cid:8) c k (cid:8) 1 , so that p k is a descent direction for the merit function φ 1 . This conclusion is not always valid if σ (cid:3) 1 and p Tk ∇ 2 xx L k p k < 0 . By comparing ( 18 . 33 ) and ( 18 . 36 ) we see that , when σ > 0 , the strategy based on ( 18 . 35 ) selects a larger penalty parameter , thus placing more weight on the reduction of the constraints . This property is advantageous if the step p k decreases the constraints but increases the objective , for in this case the step has a better chance of being accepted by the merit function . SECOND - ORDER CORRECTION In Chapter 15 , we showed by means of Example 15 . 4 that many merit functions can impede progress of an optimization algorithm , a phenomenon known as the Maratos effect . We now show that the step analyzed in that example is , in fact , produced by an SQP method . ❏ E XAMPLE 18 . 1 ( E XAMPLE 15 . 4 , R EVISITED ) Consider problem ( 15 . 34 ) . At the iterate x k (cid:3) ( cos θ , sin θ ) T , let us compute a search direction p k by solving the SQP subproblem ( 18 . 7 ) with ∇ 2 xx L k replaced by ∇ 2 xx L ( x ∗ , λ ∗ ) (cid:3) I . Since f k (cid:3) − cos θ , ∇ f k (cid:3) (cid:1) 4 cos θ − 1 4 sin θ (cid:2) , A Tk (cid:3) (cid:1) 2 cos θ 2 sin θ (cid:2) , the quadratic subproblem ( 18 . 7 ) takes the form min p ( 4 cos θ − 1 ) p 1 + 4 sin θ p 2 + 1 2 p 2 1 + 1 2 p 2 2 subject to p 2 + cot θ p 1 (cid:3) 0 . By solving this subproblem , we obtain the direction p k (cid:3) (cid:1) sin 2 θ − sin θ cos θ (cid:2) , ( 18 . 38 ) which coincides with ( 15 . 35 ) . ❐ 544 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G We mentioned in Section 15 . 4 that the difﬁculties associated with the Maratos effect can be overcome by means of a second - order correction . There are various ways of applying this technique ; we describe one possible implementation next . Suppose that the SQP method has computed a step p k from ( 18 . 11 ) . If this step yields an increase in the merit function φ 1 , a possible cause is that our linear approximations to the constraints are not sufﬁciently accurate . To overcome this deﬁciency , we could re - solve ( 18 . 11 ) with the linear terms c i ( x k ) + ∇ c i ( x k ) T p replaced by quadratic approximations , c i ( x k ) + ∇ c i ( x k ) T p + 12 p T ∇ 2 c i ( x k ) p . ( 18 . 39 ) However , even if the Hessians of the constraints are individually available , the resulting quadratically constrained subproblem may be too difﬁcult to solve . Instead , we evaluate the constraint values at the new point x k + p k and make use of the following approximations . By Taylor’s theorem , we have c i ( x k + p k ) ≈ c i ( x k ) + ∇ c i ( x k ) T p k + 12 p Tk ∇ 2 c i ( x k ) p k . ( 18 . 40 ) Assuming that the ( still unknown ) second - order step p will not be too different from p k , we can approximate the last term in ( 18 . 39 ) as follows : p T ∇ 2 c i ( x k ) p (cid:3) p Tk ∇ 2 c i ( x k ) p k . ( 18 . 41 ) By making this substitution in ( 18 . 39 ) and using ( 18 . 40 ) , we obtain the second - order correction subproblem min p ∇ f T k p + 12 p T ∇ 2 xx L k p subject to ∇ c i ( x k ) T p + d i (cid:3) 0 , i ∈ E , ∇ c i ( x k ) T p + d i ≥ 0 , i ∈ I , where d i (cid:3) c i ( x k + p k ) − ∇ c i ( x k ) T p k , i ∈ E ∪ I . The second - order correction step requires evaluation of the constraints c i ( x k + p k ) for i ∈ E ∪ I , and therefore it is preferable not to apply it every time the merit function increases . One strategy is to use it only if the increase in the merit function is accompanied by an increase in the constraint norm . It can be shown that when the step p k is generated by the SQP method ( 18 . 11 ) then , near a solution satisfying second - order sufﬁcient conditions , the algorithm above takes either the full step p k or the corrected step p k + ˆ p k . The merit function does not interfere with the iteration , so superlinear convergence is attained , as in the local algorithm . 1 8 . 4 . A P R A C T I C A L L I N E S E A R C H S Q P M E T H O D 545 18 . 4 A PRACTICAL LINE SEARCH SQP METHOD From the discussion in the previous section , we can see that there is a wide variety of line search SQP methods that differ in the way the Hessian approximation is computed , in the step acceptance mechanism , and in other algorithmic features . We now incorporate some of these ideas into a concrete , practical SQP algorithm for solving the nonlinear programming problem ( 18 . 10 ) . To keep the description simple , we will not include a mechanism such as ( 18 . 12 ) to ensure the feasibility of the subproblem , or a second - order correction step . Rather , the search direction is obtained simply by solving the subproblem ( 18 . 11 ) . We also assume that the quadratic program ( 18 . 11 ) is convex , so that we can solve it by means of the active - set method for quadratic programming ( Algorithm 16 . 3 ) described in Chapter 16 . Algorithm 18 . 3 ( Line Search SQP Algorithm ) . Choose parameters η ∈ ( 0 , 0 . 5 ) , τ ∈ ( 0 , 1 ) , and an initial pair ( x 0 , λ 0 ) ; Evaluate f 0 , ∇ f 0 , c 0 , A 0 ; If a quasi - Newton approximation is used , choose an initial n × n symmetric positive deﬁnite Hessian approximation B 0 , otherwise compute ∇ 2 xx L 0 ; repeat until a convergence test is satisﬁed Compute p k by solving ( 18 . 11 ) ; let ˆ λ be the corresponding multiplier ; Set p λ ← ˆ λ − λ k ; Choose µ k to satisfy ( 18 . 36 ) with σ (cid:3) 1 ; Set α k ← 1 ; while φ 1 ( x k + α k p k ; µ k ) > φ 1 ( x k ; µ k ) + ηα k D 1 ( φ ( x k ; µ k ) p k ) Reset α k ← τ α α k for some τ α ∈ ( 0 , τ ] ; end ( while ) Set x k + 1 ← x k + α k p k and λ k + 1 ← λ k + α k p λ ; Evaluate f k + 1 , ∇ f k + 1 , c k + 1 , A k + 1 , ( and possibly ∇ 2 xx L k + 1 ) ; If a quasi - Newton approximation is used , set s k ← α k p k and y k ← ∇ x L ( x k + 1 , λ k + 1 ) − ∇ x L ( x k , λ k + 1 ) , and obtain B k + 1 by updating B k using a quasi - Newton formula ; end ( repeat ) We can achieve signiﬁcant savings in the solution of the quadratic subproblem by warm - start procedures . For example , we can initialize the working set for each QP subproblem to be the ﬁnal active set from the previous SQP iteration . We have not given particulars of the quasi - Newton approximation in Algorithm 18 . 3 . We could use , for example , a limited - memory BFGS approach that is suitable for large - scale problems . If we use an exact Hessian ∇ 2 xx L k , we assume that it is modiﬁed as necessary to be positive deﬁnite on the null space of the equality constraints . Instead of a merit function , we could employ a ﬁlter ( see Section 15 . 4 ) in the inner “while” loop to determine the steplength α k . As discussed in Section 15 . 4 , a feasibility restoration phase is invoked if a trial steplength generated by the backtracking line search is 546 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G smaller than a given threshold . Regardless of whether a merit function or ﬁlter are used , a mechanism such as second - order correction can be incorporated to overcome the Maratos effect . 18 . 5 TRUST - REGION SQP METHODS Trust - region SQP methods have several attractive properties . Among them are the facts that they do not require the Hessian matrix ∇ 2 xx L k in ( 18 . 11 ) to be positive deﬁnite , they control the quality of the steps even in the presence of Hessian and Jacobian singularities , and they provide a mechanism for enforcing global convergence . Some implementations follow an IQP approach and solve an inequality - constrained subproblem , while others follow an EQP approach . The simplest way to formulate a trust - region SQP method is to add a trust - region constraint to subproblem ( 18 . 11 ) , as follows : min p f k + ∇ f Tk p + 12 p T ∇ 2 xx L k p ( 18 . 43a ) subject to ∇ c i ( x k ) T p + c i ( x k ) (cid:3) 0 , i ∈ E , ( 18 . 43b ) ∇ c i ( x k ) T p + c i ( x k ) ≥ 0 , i ∈ I , ( 18 . 43c ) (cid:8) p (cid:8) ≤ (cid:6) k . ( 18 . 43d ) Even if the constraints ( 18 . 43b ) , ( 18 . 43c ) are compatible , this problem may not always have a solution because of the trust - region constraint ( 18 . 43d ) . We illustrate this fact in Figure 18 . 1 for a problem that contains only one equality constraint whose linearization is represented by the solid line . In this example , any step p that satisﬁes the linearized constraint must lie outside the trust region , which is indicated by the circle of radius (cid:6) k . As we see from this example , a consistent system of equalities and inequalities may not have a solution if we restrict the norm of the solution . To resolve the possible conﬂict between the linear constraints ( 18 . 43b ) , ( 18 . 43c ) and the trust - region constraint ( 18 . 43d ) , it is not appropriate simply to increase (cid:6) k until the set of steps p satisfying the linear constraints intersects the trust region . This approach would defeat the purpose of using the trust region in the ﬁrst place as a way to deﬁne a region within which we trust the model ( 18 . 43a ) – ( 18 . 43c ) to accurately reﬂect the behavior of the objective and constraint functions . Analytically , it would harm the convergence properties of the algorithm . A more appropriate viewpoint is that there is no reason to satisfy the linearized constraints exactly at every step ; rather , we should aim to improve the feasibility of these constraints at each step and to satisfy them exactly only if the trust - region constraint permits it . This point of view is the basis of the three classes of methods discussed in this section : relaxation methods , penalty methods , and ﬁlter methods . 1 8 . 5 . T R U S T - R E G I O N S Q P M E T H O D S 547 1 p ∆ k p 2 c + p A k k = 0 Figure 18 . 1 Inconsistent constraints in trust - region model . A RELAXATION METHOD FOR EQUALITY - CONSTRAINED OPTIMIZATION We describe this method in the context of the equality - constrained optimization problem ( 18 . 1 ) ; its extension to general nonlinear programs is deferred to Chapter 19 because it makes use of interior - point techniques . ( Active - set extensions of the relaxation approach have been proposed , but have not been fully explored . ) At the iterate x k , we compute the SQP step by solving the subproblem min p f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p ( 18 . 44a ) subject to A k p + c k (cid:3) r k , ( 18 . 44b ) (cid:8) p (cid:8) 2 ≤ (cid:6) k . ( 18 . 44c ) The choice of the relaxation vector r k requires careful consideration , as it impacts the efﬁciency of the method . Our goal is to choose r k as the smallest vector such that ( 18 . 44b ) , ( 18 . 44c ) are consistent for some reduced value of trust - region radius (cid:6) k . To do so , we ﬁrst solve the subproblem min v (cid:8) A k v + c k (cid:8) 22 ( 18 . 45a ) subject to (cid:8) v (cid:8) 2 ≤ 0 . 8 (cid:6) k . ( 18 . 45b ) Denoting the solution of this subproblem by v k , we deﬁne r k (cid:3) A k v k + c k . ( 18 . 46 ) 548 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G We now compute the step p k by solving ( 18 . 44 ) , deﬁne the new iterate x k + 1 (cid:3) x k + p k , and obtain new multiplier estimates λ k + 1 using the least squares formula ( 18 . 21 ) . Note that the constraints ( 18 . 44b ) , ( 18 . 44c ) are consistent because they are satisﬁed by the vector p (cid:3) v k . At ﬁrst glance , this approach appears to be impractical because problems ( 18 . 44 ) and ( 18 . 45 ) are not particularly easy to solve , especially when ∇ 2 xx L k is indeﬁnite . Fortu - nately , we can design efﬁcient procedures for computing useful inexact solutions of these problems . We solve the auxiliary subproblem ( 18 . 45 ) by the dogleg method described in Chap - ter 4 . This method requires a Cauchy step p U , which is the minimizer of the objective ( 18 . 45a ) along the direction − A Tk c k , and a “Newton step” p B , which is the unconstrained minimizer of ( 18 . 45a ) . Since the Hessian in ( 18 . 45a ) is singular , there are inﬁnitely many possible choices of p B , all of which satisfy A k p B + c k (cid:3) 0 . We choose the one with smallest Euclidean norm by setting p B (cid:3) − A Tk [ A k A Tk ] − 1 c k . We now take v k to be the minimizer of ( 18 . 45a ) along the path deﬁned by p U , p B , and the formula ( 4 . 16 ) . The preferred technique for computing an approximate solution p k of ( 18 . 44 ) is the projected conjugate gradient method of Algorithm 16 . 2 . We apply this algorithm to the equality - constrained quadratic program ( 18 . 44a ) – ( 18 . 44b ) , monitoring satisfaction of the trust - region constraint ( 18 . 44c ) and stopping if the boundary of this region is reached or if negative curvature is detected ; see Section 7 . 1 . Algorithm 16 . 2 requires a feasible starting point , which may be chosen as v k . A merit function that ﬁts well with this approach is the nonsmooth (cid:1) 2 function φ 2 ( x ; µ ) (cid:3) f ( x ) + µ (cid:8) c ( x ) (cid:8) 2 . We model it by means of the function q µ ( p ) (cid:3) f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p + µ m ( p ) , ( 18 . 47 ) where m ( p ) (cid:3) (cid:8) c k + A k p (cid:8) 2 , ( see ( 18 . 34 ) ) . We choose the penalty parameter large enough that inequality ( 18 . 35 ) is satisﬁed . To judge the acceptability of a step p k , we monitor the ratio ρ k (cid:3) ared k pred k (cid:3) φ 2 ( x k , µ ) − φ 2 ( x k + p k , µ ) q µ ( 0 ) − q µ ( p k ) . ( 18 . 48 ) We can now give a description of this trust - region SQP method for the equality - constrained optimization problem ( 18 . 1 ) . 1 8 . 5 . T R U S T - R E G I O N S Q P M E T H O D S 549 Algorithm 18 . 4 ( Byrd – Omojokun Trust - Region SQP Method ) . Choose constants (cid:9) > 0 and η , γ ∈ ( 0 , 1 ) ; Choose starting point x 0 , initial trust region (cid:6) 0 > 0 ; for k (cid:3) 0 , 1 , 2 , . . . Compute f k , c k , ∇ f k , A k ; Compute multiplier estimates ˆ λ k by ( 18 . 21 ) ; if (cid:8)∇ f k − A Tk ˆ λ k (cid:8) ∞ < (cid:9) and (cid:8) c k (cid:8) ∞ < (cid:9) stop with approximate solution x k ; Solve normal subproblem ( 18 . 45 ) for v k and compute r k from ( 18 . 46 ) ; Compute ∇ 2 xx L k or a quasi - Newton approximation ; Compute p k by applying the projected CG method to ( 18 . 44 ) ; Choose µ k to satisfy ( 18 . 35 ) ; Compute ρ k (cid:3) ared k / pred k ; if ρ k > η Set x k + 1 (cid:3) x k + p k ; Choose (cid:6) k + 1 to satisfy (cid:6) k + 1 ≥ (cid:6) k ; else Set x k + 1 (cid:3) x k ; Choose (cid:6) k + 1 to satisfy (cid:6) k + 1 ≤ γ (cid:8) p k (cid:8) ; end ( for ) . A second - order correction can be added to avoid the Maratos effect . Beyond the cost of evaluating the objective function f and constraints c , the main costs of this algorithm lie in the projected CG iteration , which requires products of the Hessian ∇ 2 xx L k with vectors , and in the factorization and backsolves with the projection matrix ( 16 . 32 ) ; see Section 16 . 3 . S (cid:1) 1 QP ( SEQUENTIAL (cid:1) 1 QUADRATIC PROGRAMMING ) In this approach we move the linearized constraints ( 18 . 43b ) , ( 18 . 43c ) into the ob - jective of the quadratic program , in the form of an (cid:1) 1 penalty term , to obtain the following subproblem : min p q µ ( p ) def (cid:3) f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p + µ (cid:3) i ∈ E | c i ( x k ) + ∇ c i ( x k ) T p | + µ (cid:3) i ∈ I [ c i ( x k ) + ∇ c i ( x k ) T p ] − ( 18 . 49 ) subject to (cid:8) p (cid:8) ∞ ≤ (cid:6) k , 550 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G for some penalty parameter µ , where we use the notation [ y ] − (cid:3) max { 0 , − y } . Introducing slack variables v , w , t , we can reformulate this problem as follows : min p , v , w , t f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p + µ (cid:3) i ∈ E ( v i + w i ) + µ (cid:3) i ∈ I t i ( 18 . 50a ) s . t . ∇ c i ( x k ) T p + c i ( x k ) (cid:3) v i − w i , i ∈ E , ( 18 . 50b ) ∇ c i ( x k ) T p + c i ( x k ) ≥ − t i , i ∈ I , ( 18 . 50c ) v , w , t ≥ 0 , ( 18 . 50d ) (cid:8) p (cid:8) ∞ ≤ (cid:6) k . ( 18 . 50e ) This formulation is simply a linearization of the elastic - mode formulation ( 18 . 12 ) with the addition of a trust - region constraint . The constraints of this problem are always consistent . Since the trust region has been deﬁned using the (cid:1) ∞ norm , ( 18 . 50 ) is a smooth quadratic program that can be solved by means of a quadratic programming algorithm . Warm - start strategies can signiﬁcantly reduce the solution time of ( 18 . 50 ) and are invariably used in practical implementations . It is natural to use the (cid:1) 1 merit function φ 1 ( x ; µ ) (cid:3) f ( x ) + µ (cid:3) i ∈ E | c i ( x ) | + µ (cid:3) i ∈ I [ c i ( x ) ] − ( 18 . 51 ) to determine step acceptance . In fact , the function q µ deﬁned in ( 18 . 49 ) can be viewed as a model of φ 1 ( x , µ ) at x k in which we approximate each constraint function c i by its linearization , and replace f by a quadratic function whose curvature term includes information from both objective and constraints . After computing the step p k from ( 18 . 50 ) , we determine the ratio ρ k via ( 18 . 48 ) , using the merit function φ 1 and deﬁning q µ by ( 18 . 49 ) . The step is accepted or rejected according to standard trust - region rules , as implemented in Algorithm 18 . 4 . A second - order correction step can be added to prevent the occurence of the Maratos effect . The S (cid:1) 1 QP approach has several attractive properties . Not only does the formula - tion ( 18 . 49 ) overcome the possible inconsistency among the linearized constraints , but it also ensures that the trust - region constraint can always be satisﬁed . Further , the ma - trix ∇ 2 xx L k can be used without modiﬁcation in subproblem ( 18 . 50 ) or else can be replaced by a quasi - Newton approximation . There is no requirement for it to be positive deﬁnite . This choice of the penalty parameter µ plays an important role in the efﬁciency of this method . Unlike the SQP methods described above , which use a penalty function only to determine the acceptability of a trial point , the step p k of the S (cid:1) 1 QP algorithm depends on µ . Values of µ that are too small can lead the algorithm away from the solution ( Section 17 . 2 ) , while excessively large values can result in slow progress . To obtain good 1 8 . 5 . T R U S T - R E G I O N S Q P M E T H O D S 551 practical performance over a range of applications , the value of µ must be chosen carefully at each iteration ; see Algorithm 18 . 5 below . SEQUENTIAL LINEAR - QUADRATIC PROGRAMMING ( SLQP ) The SQP methods discussed above require the solution of a general ( inequality - constrained ) quadratic problem at each iteration . The cost of solving this subproblem imposes a limit on the size of problems that can be solved in practice . In addition , the incorporation of ( indeﬁnite ) second derivative information in SQP methods has proved to be difﬁcult [ 147 ] . The sequential linear - quadratic programming ( SLQP ) method attempts to overcome these concerns by computing the step in two stages , each of which scales well with the number of variables . First , a linear program ( LP ) is solved to identify a working set W . Second , there is an equality - constrained quadratic programming ( EQP ) phase in which the constraints in the working set W are imposed as equalities . The total step of the algorithm is a combination of the steps obtained in the linear programming and equality - constrained phases , as we now discuss . In the LP phase , we would like to solve the problem min p f k + ∇ f Tk p ( 18 . 52a ) subject to c i ( x k ) + ∇ c i ( x k ) T p (cid:3) 0 , i ∈ E , ( 18 . 52b ) c i ( x k ) + ∇ c i ( x k ) T p ≥ 0 , i ∈ I , ( 18 . 52c ) (cid:8) p (cid:8) ∞ ≤ (cid:6) LP k , ( 18 . 52d ) which differs from the standard SQP subproblem ( 18 . 43 ) only in that the second - order term in the objective has been omitted and that an (cid:1) ∞ norm is used to deﬁne the trust region . Since the constraints of ( 18 . 52 ) may be inconsistent , we solve instead the (cid:1) 1 penalty reformulation of ( 18 . 52 ) deﬁned by min p l µ ( p ) def (cid:3) f k + ∇ f Tk p + µ (cid:3) i ∈ E | c i ( x k ) + ∇ c i ( x k ) T p | + µ (cid:3) i ∈ I [ c i ( x k ) + ∇ c i ( x k ) T p ] − ( 18 . 53a ) subject to (cid:8) p (cid:8) ∞ ≤ (cid:6) LP k . ( 18 . 53b ) Byintroducingslackvariablesasin ( 18 . 50 ) , wecanreformulate ( 18 . 53 ) asanLP . Thesolution of ( 18 . 53 ) , which we denote by p LP , is computed by the simplex method ( Chapter 13 ) . From this solution we obtain the following explicit estimate of the optimal active set : A k ( p LP ) (cid:3) { i ∈ E | c i ( x k ) + ∇ c i ( x k ) T p LP (cid:3) 0 } ∪ { i ∈ I | c i ( x k ) + ∇ c i ( x k ) T p LP (cid:3) 0 } . 552 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G Likewise , we deﬁne the set V k of violated constraints as V k ( p LP ) (cid:3) { i ∈ E | c i ( x k ) + ∇ c i ( x k ) T p LP (cid:9)(cid:3) 0 } ∪ { i ∈ I | c i ( x k ) + ∇ c i ( x k ) T p LP < 0 } . We deﬁne the working set W k as some linearly independent subset of the active set A k ( p LP ) . To ensure that the algorithm makes progress on the penalty function φ 1 , we deﬁne the Cauchy step , p C (cid:3) α LP p LP , ( 18 . 54 ) where α LP ∈ ( 0 , 1 ] is a steplength that provides sufﬁcient decrease in the model q µ deﬁned in ( 18 . 49 ) . Given the working set W k , we now solve an equality - constrained quadratic program ( EQP ) treating the constraints in W k as equalities and ignoring all others . We thus obtain the subproblem min p f k + 12 p T ∇ 2 xx L k p + ⎛ ⎝ ∇ f k + µ k (cid:3) i ∈ V k γ i ∇ c i ( x k ) ⎞ ⎠ T p ( 18 . 55a ) subject to c i ( x k ) + ∇ c i ( x k ) T p (cid:3) 0 , i ∈ E ∩ W k , ( 18 . 55b ) c i ( x k ) + ∇ c i ( x k ) T p (cid:3) 0 , i ∈ I ∩ W k , ( 18 . 55c ) (cid:8) p (cid:8) 2 ≤ (cid:6) k , ( 18 . 55d ) where γ i is the algebraic sign of the i - th violated constraint . Note that the trust region ( 18 . 55d ) is spherical , and that (cid:6) k is distinct from the trust - region radius (cid:6) LP k used in ( 18 . 53b ) . Problem ( 18 . 55 ) is solved for the vector p Q by applying the projected conjugated gradient procedure of Algorithm 16 . 2 , handling the trust - region constraint by Steihaug’s strategy ( Algorithm 7 . 2 ) . The total step p k of the SLQP method is given by p k (cid:3) p C + α Q ( p Q − p C ) , where α Q ∈ [ 0 , 1 ] is a steplength that approximately minimizes the model q µ deﬁned in ( 18 . 49 ) . The trust - region radius (cid:6) k for the EQP phase is updated using standard trust - region update strategies . The choice of radius (cid:6) LP k + 1 for the LP phase is more delicate , since it inﬂuences our guess of the optimal active set . The value of (cid:6) LP k + 1 should be set to be a little larger than the total step p k , subject to some other restrictions [ 49 ] . The multiplier estimates λ k used in the Hessian ∇ 2 xx L k are least squares estimates ( 18 . 21 ) using the working set W k , and modiﬁed so that λ i ≥ 0 for i ∈ I . An appealing feature of the SLQP algorithm is that established techniques for solving large - scale versions of the LP and EQP subproblems are readily available . High quality LP 1 8 . 5 . T R U S T - R E G I O N S Q P M E T H O D S 553 software is capable of solving problems with very large numbers of variables and constraints , while the solution of the EQP subproblem can be performed efﬁciently using the projected conjugate gradient method . A TECHNIQUE FOR UPDATING THE PENALTY PARAMETER We have mentioned that penalty methods such as S (cid:1) 1 QP and SLQP can be sensitive to the choice of the penalty parameter µ . We now discuss a procedure for choosing µ that has proved to be effective in practice and is supported by global convergence guarantees . The goal is to choose µ small enough to avoid an unnecessary imbalance in the merit function , but large enough to cause the step to make sufﬁcient progress in linearized feasibility at each iteration . We present this procedure in the context of the S (cid:1) 1 QP method and then describe its extension to the SLQP approach . We deﬁne a piecewise linear model of constraint violation at a point x k by m k ( p ) (cid:3) (cid:3) i ∈ E | c i ( x k ) + ∇ c i ( x k ) T p | + (cid:3) i ∈ I [ c i ( x k ) + ∇ c i ( x k ) T p ) ] − , ( 18 . 56 ) so that the objective of the SQP subproblem ( 18 . 49 ) can be written as q µ ( p ) (cid:3) f k + ∇ f Tk p + 1 2 p T ∇ 2 xx L k p + µ m k ( p ) . ( 18 . 57 ) We begin by solving the QP subproblem ( 18 . 49 ) ( or equivalently , ( 18 . 50 ) ) using the previous value µ k − 1 of the penalty parameter . If the constraints ( 18 . 50b ) , ( 18 . 50c ) are satisﬁed with the slack variables v i , w i , t i all equal to zero ( that is , m k ( p k ) (cid:3) 0 ) , then the current value of µ is adequate , and we set µ k (cid:3) µ k − 1 . This is the felicitous case in which we can achieve linearized feasibility with a step p k that is no longer in norm than the trust - region radius . If m k ( p ) > 0 , on the other hand , it may be appropriate to increase the penalty parameter . The question is : by how much ? To obtain a reference value , we re - solve the QP ( 18 . 49 ) using an “inﬁnite” value of µ , by which we mean that the objective function in ( 18 . 49 ) is replaced by m k ( p ) . After computing the new step , which we denote by p ∞ , two outcomes are possible . If m k ( p ∞ ) (cid:3) 0 , meaning that the linearized constraints are feasible within the trust region , we choose µ k > µ k − 1 such that m k ( p k ) (cid:3) 0 . Otherwise , if m k ( p ∞ ) > 0 , we choose µ k ≥ µ k − 1 such that the reduction in m k caused by the step p k is at least a fraction of the ( optimal ) reduction given by p ∞ . The selection of µ k > µ k − 1 is achieved in all cases by successively increasing the current trial value of µ ( by a factor of 10 , say ) and re - solving the quadratic program ( 18 . 49 ) . To describe this strategy more precisely , we write the solution of the QP problem ( 18 . 49 ) as p ( µ ) to stress its dependence on the penalty parameter . Likewise , p ∞ denotes the minimizer of m k ( p ) subject to the trust - region constraint ( 18 . 50e ) . The following algorithm describes the selection of the penalty parameter µ k and the computation of the S (cid:1) 1 QP step p k . 554 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G Algorithm 18 . 5 ( Penalty Update and Step Computation ) . Initial data : x k , µ k − 1 > 0 , (cid:6) k > 0 , and parameters (cid:9) 1 , (cid:9) 2 ∈ ( 0 , 1 ) . Solve the subproblem ( 18 . 50 ) with µ (cid:3) µ k − 1 to obtain p ( µ k − 1 ) ; if m k ( p ( µ k − 1 ) ) (cid:3) 0 Set µ + ← µ k − 1 ; else Compute p ∞ ; if m k ( p ∞ ) (cid:3) 0 Find µ + > µ k − 1 such that m k ( p ( µ + ) ) (cid:3) 0 ; else Find µ + ≥ µ k − 1 such that m k ( 0 ) − m k ( p ( µ + ) ) ≥ (cid:9) 1 [ m k ( 0 ) − m k ( p ∞ ) ] ; end ( if ) end ( if ) Increase µ + if necessary to satisfy q µ + ( 0 ) − q µ + ( p ( µ + ) ) ≥ (cid:9) 2 µ + [ m k ( 0 ) − m k ( p ( µ + ) ) ] ; Set µ k ← µ + and p k ← p ( µ + ) . ( Note that the inequality in the penultimate line is the same as condition ( 18 . 35 ) . ) Although Algorithm 18 . 5 requires the solution of some additional quadratic programs , we hope to reduce the total number of iterations ( and the total number of QP solves ) by identifying an appropriate penalty parameter value more quickly than rules based on feasibility monitoring ( see Framework 17 . 2 ) . Numerical experience indicates that these savings occur when an adaptation of Al - gorithm 18 . 5 is used in the SLQP method . This adaptation is obtained simply by setting ∇ 2 xx L k (cid:3) 0 in the deﬁnition ( 18 . 49 ) of q µ and applying Algorithm 18 . 5 to determine µ and to compute the LP step p LP . The extra LP solves required by Algorithm 18 . 5 in this case are typically inexpensive , requiring relatively few simplex iterations , because we can use warm - start information from LPs solved earlier , with different values of the penalty parameter . 18 . 6 NONLINEAR GRADIENT PROJECTION In Section 16 . 7 , we discussed the gradient projection method for bound constrained quadratic programming . It is not difﬁcult to extend this method to the problem min f ( x ) subject to l ≤ x ≤ u , ( 18 . 58 ) where f is a nonlinear function and l and u are vectors of lower and upper bounds , respectively . 1 8 . 6 . N O N L I N E A R G R A D I E N T P R O J E C T I O N 555 We begin by describing a line search approach . At the current iterate x k , we form the quadratic model q k ( x ) (cid:3) f k + ∇ f Tk ( x − x k ) + 12 ( x − x k ) T B k ( x − x k ) , ( 18 . 59 ) where B k is a positive deﬁnite approximation to ∇ 2 f ( x k ) . We then use the gradient projec - tion method for quadratic programming ( Algorithm 16 . 5 ) to ﬁnd an approximate solution ˆ x of the subproblem min q k ( x ) subject to l ≤ x ≤ u . ( 18 . 60 ) The search direction is deﬁned as p k (cid:3) ˆ x − x k and the new iterate is given by x k + 1 (cid:3) x k + α k p k , where the steplength α k is chosen to satisfy f ( x k + α k p k ) ≤ f ( x k ) + ηα k ∇ f Tk p k for some parameter η ∈ ( 0 , 1 ) . To see that the search direction p k is indeed a descent direction for the objective function , we use the properties of Algorithm 16 . 5 , as discussed in Section 16 . 7 . Recall that this method searches along a piecewise linear path—the projected steepest descent path—for the Cauchy point x c , which minimizes q k along this path . It then identiﬁes the components of x that are at their bounds and holds these components constant while performing an unconstrained minimization of q k over the remaining components to obtain the approximate solution ˆ x of the subproblem ( 18 . 60 ) . The Cauchy point x c satisﬁes q k ( x c ) < q k ( x k ) if the projected gradient is nonzero . Since Algorithm 16 . 5 produces a subproblem solution ˆ x with q k ( ˆ x ) ≤ q k ( x c ) , we have f k (cid:3) q k ( x k ) > q k ( x c ) ≥ q k ( ˆ x ) (cid:3) f k + ∇ f Tk p k + 1 2 p Tk B k p k . This inequality implies that ∇ f Tk p k < 0 , since B k is assumed to be positive deﬁnite . We now consider a trust - region gradient projection method for solving ( 18 . 58 ) . We begin by forming the quadratic model ( 18 . 59 ) , but since there is no requirement for q k to be convex , we can deﬁne B k to be the Hessian ∇ 2 f ( x k ) or a quasi - Newton approximation obtained from the BFGS or SR1 formulas . The step p k is obtained by solving the subproblem min q k ( x ) subject to { l ≤ x ≤ u , (cid:8) x − x k (cid:8) ∞ ≤ (cid:6) k } , ( 18 . 61 ) for some (cid:6) k > 0 . This problem can be posed as a bound - constrained quadratic program as follows : min q k ( x ) subject to max ( l , x k − (cid:6) k e ) ≤ x ≤ min ( u , x k + (cid:6) k e ) , 556 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G where e (cid:3) ( 1 , 1 , . . . , 1 ) T . Algorithm 16 . 5 can be used to solve this subproblem . The step p k is accepted or rejected following standard trust - region strategies , and the radius (cid:6) k is updated according to the agreement between the change in f and the change in q k produced by the step p k ; see Chapter 4 . The two gradient projection methods just outlined require solution of an inequality - constrained quadratic subproblem at each iteration , and so are formally IQP methods . They can , however , beviewedalsoasEQPmethodsbecauseoftheiruseofAlgorithm16 . 5insolving the subproblem . This algorithm ﬁrst identiﬁes a working set ( by ﬁnding the Cauchy point ) and then solves an equality - constrained subproblem ( by ﬁxing the working - set constraints at their bounds ) . For large problems , it is efﬁcient to perform the subpace minimization ( 16 . 74 ) by using the conjugate gradient method . A preconditioner is sometimes needed to make this approach practical ; the most popular choice is the incomplete ( and modiﬁed ) Cholesky factorization outlined in Algorithm 7 . 3 . The gradient projection approach can be extended in principle to more general ( linear or convex ) constraints . Practical implementations are however limited to the bound con - strained problem ( 18 . 58 ) because of the high cost of computing projections onto general constraint sets . 18 . 7 CONVERGENCE ANALYSIS Numerical experience has shown that the SQP and SLQP methods discussed in this chapter often converge to a solution from remote starting points . Hence , there has been considerable interest in understanding what drives the iterates toward a solution and what can cause the algorithms to fail . These global convergence studies have been valuable in improving the design and implementation of algorithms . Some early results make strong assumptions , such as boundedness of multipliers , well posedness of the subproblem ( 18 . 11 ) , and regularity of constraint Jacobians . More recent studies relax many of these assumptions with the goal of understanding both the successful and unsuccessful outcomes of the iteration . We now state a classical global convergence result that gives conditions under which a standard SQP algorithm always identiﬁes a KKT point of the nonlinear program . Consider an SQP method that computes a search direction p k by solving the quadratic program ( 18 . 11 ) . We assume that the Hessian ∇ 2 xx L k is replaced in ( 18 . 11a ) by some symmetric and positive deﬁnite approximation B k . The new iterate is deﬁned as x k + 1 + α k p k , where α k is computed by a backtracking line search , starting from the unit steplength , and terminating when φ 1 ( x k + α k p k ; µ ) ≤ φ 1 ( x k ; µ ) − ηα k ( q µ ( 0 ) − q µ ( p k ) ) , where η ∈ ( 0 , 1 ) , with φ 1 deﬁned as in ( 18 . 51 ) and q µ deﬁned as in ( 18 . 49 ) . To establish the convergence result , we assume that each quadratic program ( 18 . 11 ) is feasible and 1 8 . 7 . C O N V E R G E N C E A N A L Y S I S 557 determines a bounded solution p k . We also assume that the penalty parameter µ is ﬁxed for all k and sufﬁciently large . Theorem 18 . 3 . SupposethattheSQPalgorithmjustdescribedisappliedtothenonlinearprogram ( 18 . 10 ) . Suppose that the sequences { x k } and { x k + p k } are contained in a closed , bounded , convex region of IR n in which f and c i have continuous ﬁrst derivatives . Suppose that the matrices B k and multipliers are bounded and that µ satisﬁes µ ≥ (cid:8) λ k (cid:8) ∞ + ρ for all k , where ρ is a positive constant . Then all limit points of the sequence { x k } are KKT points of the nonlinear program ( 18 . 10 ) . The conclusions of the theorem are quite satisfactory , but the assumptions are some - what restrictive . For example , the condition that the sequence { x k + p k } stays within in a bounded set rules out the case in which the Hessians B k or constraint Jacobians become ill conditioned . Global convergence results that are established under more realistic condi - tions are surveyed by Conn , Gould , and Toint [ 74 ] . An example of a result of this type is Theorem 19 . 2 . Although this theorem is established for a nonlinear interior - point method , similar results can be established for trust - region SQP methods . RATE OF CONVERGENCE We now derive conditions that guarantee the local convergence of SQP methods , as well as conditions that ensure a superlinear rate of convergence . For simplicity , we limit our discussion to Algorithm 18 . 1 for equality - constrained optimization , and consider both exact Hessian and quasi - Newton versions . The results presented here can be applied to algorithms for inequality - constrained problems once the active set has settled at its ﬁnal optimal value ( see Theorem 18 . 1 ) . We begin by listing a set of assumptions on the problem that will be useful in this section . Assumptions 18 . 2 . The point x ∗ is a local solution of problem ( 18 . 1 ) at which the following conditions hold . ( a ) The functions f and c are twice differentiable in a neighborhood of x ∗ with Lipschitz continuous second derivatives . ( b ) The linear independence constraint qualiﬁcation ( Deﬁnition 12 . 4 ) holds at x ∗ . This con - dition implies that the KKT conditions ( 12 . 34 ) are satisﬁed for some vector of multipliers λ ∗ . ( c ) The second - order sufﬁcient conditions ( Theorem 12 . 6 ) hold at ( x ∗ , λ ∗ ) . We consider ﬁrst an SQP method that uses exact second derivatives . 558 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G Theorem 18 . 4 . Suppose that Assumptions 18 . 2 hold . Then , if ( x 0 , λ 0 ) is sufﬁciently close to ( x ∗ , λ ∗ ) , the pairs ( x k , λ k ) generated by Algorithm 18 . 1 converge quadratically to ( x ∗ , λ ∗ ) . The proof follows directly from Theorem 11 . 2 , since we know that Algorithm 18 . 1 is equivalent to Newton’s method applied to the nonlinear system F ( x , λ ) (cid:3) 0 , where F is deﬁned by ( 18 . 3 ) . We turn now to quasi - Newton variants of Algorithm 18 . 1 , in which the Lagrangian Hessian ∇ 2 xx L ( x k , λ k ) is replaced by a quasi - Newton approximation B k . We discussed in Sec - tion 18 . 3 algorithms that used approximations to the full Hessian , and also reduced - Hessian methods that maintained approximations to the projected Hessian Z Tk ∇ 2 xx L ( x k , λ k ) Z k . As in the earlier discussion , we take Z k to be the n × ( n − m ) matrix whose columns span the null space of A k , assuming in addition that the columns of Z k are orthornormal ; see ( 15 . 22 ) . If we multiply the ﬁrst block row of the KKT system ( 18 . 9 ) by Z k , we obtain Z Tk ∇ 2 xx L k p k (cid:3) − Z Tk ∇ f k . ( 18 . 62 ) This equation , together with the second block row A k p k (cid:3) − c k of ( 18 . 9 ) , is sufﬁcient to determine fully the value of p k when x k and λ k are not too far from their optimal values . In other words , only the projection of the Hessian Z Tk ∇ 2 xx L k is signiﬁcant ; the remainder of ∇ 2 xx L k ( its projection onto the range space of A Tk ) does not play a role in determinining p k . By multiplying ( 18 . 62 ) by Z k , and deﬁning the following matrix P k , which projects onto the null space of A k : P k (cid:3) I − A Tk (cid:9) A k A Tk (cid:10) − 1 A k (cid:3) Z k Z Tk , we can rewrite ( 18 . 62 ) equivalently as follows : P k ∇ 2 xx L k p k (cid:3) − P k ∇ f k . The discussion above , together with Theorem 18 . 4 , suggests that a quasi - Newton method willbelocallyconvergentifthequasi - Newtonmatrix B k ischosensothat P k B k isareasonable approximationof P k ∇ 2 xx L k , andthatitwillbesuperlinearlyconvergentif P k B k approximates P k ∇ 2 xx L k well . To make the second statement more precise , we present a result that can be viewed as an extension of characterization of superlinear convergence ( Theorem 3 . 6 ) to the equality - constrained case . In the following discussion , ∇ 2 xx L ∗ denotes ∇ 2 xx L ( x ∗ , λ ∗ ) . Theorem 18 . 5 . Suppose that Assumptions 18 . 2 hold and that the iterates x k generated by Algorithm 18 . 1 with quasi - Newton approximate Hessians B k converge to x ∗ . Then x k converges superlinearly if and only if the Hessian approximation B k satisﬁes lim k →∞ (cid:8) P k ( B k − ∇ 2 xx L ∗ ) ( x k + 1 − x k ) (cid:8) (cid:8) x k + 1 − x k (cid:8) (cid:3) 0 . ( 18 . 63 ) 1 8 . 7 . C O N V E R G E N C E A N A L Y S I S 559 We can apply this result to the quasi - Newton updating schemes discussed earlier in this chapter , beginning with the full BFGS approximation based on ( 18 . 13 ) . To guarantee that the BFGS approximation is always well deﬁned , we make the ( strong ) assumption that the Hessian of the Lagrangian is positive deﬁnite at the solution . Theorem 18 . 6 . Suppose that Assumptions 18 . 2 hold . Assume also that ∇ 2 xx L ∗ and B 0 are symmetric and positive deﬁnite . If (cid:8) x 0 − x ∗ (cid:8) and (cid:8) B 0 −∇ 2 xx L ∗ (cid:8) are sufﬁciently small , the iterates x k generated by Algorithm 18 . 1 with BFGS Hessian approximations B k deﬁned by ( 18 . 13 ) and ( 18 . 16 ) ( with r k (cid:3) s k ) satisfy the limit ( 18 . 63 ) . Therefore , the iterates x k converge superlinearly to x ∗ . For the damped BFGS updating strategy given in Procedure 18 . 2 , we can show that the rate of convergence is R - superlinear ( not the usual Q - superlinear rate ; see the Appendix ) . We now consider reduced - Hessian SQP methods that update an approximation M k to Z Tk ∇ 2 xx L k Z k . From the deﬁnition of P k , we see that Z k M k Z Tk can be considered as an approximation to the two - sided projection P k ∇ 2 xx L k P k . Since reduced - Hessian methods do not approximate the one - sided projection P k ∇ 2 xx L k , we cannot expect ( 18 . 63 ) to hold . For these methods , we can state a condition for superlinear convergence by writing ( 18 . 63 ) as lim k →∞ (cid:26) P k ( B k − ∇ 2 xx L ∗ ) P k ( x k + 1 − x k ) (cid:8) x k + 1 − x k (cid:8) + P k ( B k − ∇ 2 xx L ∗ ) ( I − P k ) ( x k + 1 − x k ) (cid:8) x k + 1 − x k (cid:8) (cid:27) (cid:3) 0 , ( 18 . 64 ) and deﬁning B k (cid:3) Z k M k Z Tk . The following result shows that it is necessary only for the ﬁrst term in ( 18 . 64 ) to go to zero to obtain a weaker form of superlinear convergence , namely , two - step superlinear convergence . Theorem 18 . 7 . Suppose that Assumption 18 . 2 ( a ) holds and that the matrices B k are bounded . Assume also that the iterates x k generated by Algorithm 18 . 1 with approximate Hessians B k converge to x ∗ , and that lim k →∞ (cid:8) P k ( B k − ∇ 2 xx L ∗ ) P k ( x k + 1 − x k ) (cid:8) (cid:8) x k + 1 − x k (cid:8) (cid:3) 0 . ( 18 . 65 ) Then the sequence { x k } converges to x ∗ two - step superlinearly , that is , lim k →∞ (cid:8) x k + 2 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) (cid:3) 0 . In a reduced - Hessian method that uses BFGS updating , the iteration is x k + 1 (cid:3) x k + Y k p Y + Z k p Z , where p Y and p Z are given by ( 18 . 19a ) , ( 18 . 23 ) ( with ( Z T k ∇ 2 xx L k Z k ) replaced by M k ) . The reduced - Hessian approximation M k is updated by the BFGS formula using 560 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G the correction vectors ( 18 . 26 ) , and the initial approximation M 0 is symmetric and positive deﬁnite . If we make the assumption that the null space bases Z k used to deﬁne the correction vectors ( 18 . 26 ) vary smoothly , then we can apply Theorem 18 . 7 to show that x k converges two - step superlinearly . 18 . 8 PERSPECTIVES AND SOFTWARE SQP methods are most efﬁcient if the number of active constraints is nearly as large as the number of variables , that is , if the number of free variables is relatively small . They require few evaluations of the functions , in comparison with augmented Lagrangian methods , and can be more robust on badly scaled problems than the nonlinear interior - point methods described in the next chapter . It is not known at present whether the IQP or EQP approach will prove to be more effective for large problems . Current reasearch focuses on widening the class of problems that can be solved with SQP and SLQP approaches . Two established SQP software packages are SNOPT [ 128 ] and FILTERSQP [ 105 ] . The former code follows a line search approach , while the latter implements a trust - region strategy using a ﬁlter for step acceptance . The SLQP approach of Section 18 . 5 is implemented in KNITRO / ACTIVE [ 49 ] . Allthreepackagesincludemechanismstoensurethatthesubproblems are always feasible and to guard against rank - deﬁcient constraint Jacobians . SNOPT uses the penalty ( or elastic ) mode ( 18 . 12 ) , which is invoked if the SQP subproblem is infeasible or if the Lagrange multiplier estimates become very large in norm . FILTERSQP includes a feasibility restoration phase that , in addition to promoting convergence , provides rapid identiﬁcation of convergence to infeasible points . KNITRO / ACTIVE implements a penalty method using the update strategy of Algorithm 18 . 5 . There is no established implementation of the S (cid:1) 1 QP approach , but prototype imple - mentations have shown promise . The CONOPT [ 9 ] package implements a generalized reduced gradient method as well as an SQP method . Quasi - Newton approximations to the Hessian of the Lagrangian ∇ 2 xx L k are often used in practice . BFGS updating is generally less effective for constrained problems than in the unconstrained case because of the requirement of maintaining a positive deﬁnite approximation to an underlying matrix that often does not have this property . Nevertheless , the BFGS and limited - memory BFGS approximations implemented in SNOPT and KNITRO perform adequately in practice . KNITRO also offers an SR1 option that may be more effective than the BFGS option , but the question of how best to implement full quasi - Newton approx - imations for constrained optimization requires further investigation . The RSQP package [ 13 ] implements an SQP method that maintains a quasi - Newton approximation to the reduced Hessian . The Maratos effect , if left unattended , can signiﬁcantly slow optimization algorithms thatusenonsmoothmeritfunctionsorﬁlters . However , selectiveapplicationofsecond - order correction steps adequately resolves the difﬁculties in practice . 1 8 . 8 . P E R S P E C T I V E S A N D S O F T W A R E 561 Trust - region implementations of the gradient projection method include TRON [ 192 ] and LANCELOT [ 72 ] . Both codes use a conjugate gradient iteration to perform the subspace minimization and apply an incomplete Cholesky preconditioner . Gradient projection meth - ods in which the Hessian approximation is deﬁned by limited - memory BFGS updating are implemented in LBFGS - B [ 322 ] and BLMVM [ 17 ] . The properties of limited - memory BFGS matrices can be exploited to perform the projected gradient search and subpace minimiza - tion efﬁciently . SPG [ 23 ] implements the gradient projection method using a nonmonotone line search . NOTES AND REFERENCES SQP methods were ﬁrst proposed in 1963 by Wilson [ 306 ] and were developed in the 1970s by Garcia - Palomares and Mangasarian [ 117 ] , Han [ 163 , 164 ] , and Powell [ 247 , 250 , 249 ] , among others . Trust - region variants are studied by Vardi [ 295 ] , Celis , Dennis , and Tapia [ 56 ] , and Byrd , Schnabel , and Shultz [ 55 ] . See Boggs and Tolle [ 33 ] and Gould , Orban , and Toint [ 147 ] for literature surveys . The SLQP approach was proposed by Fletcher and Sainz de la Maza [ 108 ] and was further developed by Chin and Fletcher [ 59 ] and Byrd et al . [ 49 ] . The latter paper discusses how to update the LP trust region and many other details of implementation . The technique for updating the penalty parameter implemented in Algorithm 18 . 5 is discussed in [ 49 , 47 ] . The S (cid:1) 1 QP method was proposed by Fletcher ; see [ 101 ] for a complete discussion of this method . Some analysis shows that several—but not all—of the good properties of BFGS updat - ing are preserved by damped BFGS updating . Numerical experiments exposing the weakness of the approach are reported by Powell [ 254 ] . Second - order correction strategies were pro - posed by Coleman and Conn [ 65 ] , Fletcher [ 100 ] , Gabay [ 116 ] , and Mayne and Polak [ 204 ] . The watchdog technique was proposed by Chamberlain et al . [ 57 ] and other nonmonotone strategies are described by Bonnans et al . [ 36 ] . For a comprehensive discussion of second - order correction and nonmonotone techniques , see the book by Conn , Gould , and Toint [ 74 ] . Two ﬁlter SQP algorithms are described by Fletcher and Leyffer [ 105 ] and Fletcher , Leyffer , and Toint [ 106 ] . It is not yet known whether the ﬁlter strategy has advantages over merit functions . Both approaches are undergoing development and improved imple - mentations can be expected in the future . Theorem 18 . 3 is proved by Powell [ 252 ] and Theorem 18 . 5 by Boggs , Tolle , and Wang [ 34 ] . ✐ E X E R C I S E S ✐ 18 . 1 Show that in the quadratic program ( 18 . 7 ) we can replace the linear term ∇ f T k p by ∇ x L ( x k , λ k ) T p without changing the solution . 562 C H A P T E R 1 8 . S E Q U E N T I A L Q U A D R A T I C P R O G R A M M I N G ✐ 18 . 2 Prove Theorem 18 . 4 . ✐ 18 . 3 Write a program that implements Algorithm 18 . 1 . Use it to solve the problem min e x 1 x 2 x 3 x 4 x 5 − 12 ( x 31 + x 32 + 1 ) 2 ( 18 . 66 ) subject to x 21 + x 22 + x 23 + x 24 + x 25 − 10 (cid:3) 0 , ( 18 . 67 ) x 2 x 3 − 5 x 4 x 5 (cid:3) 0 , ( 18 . 68 ) x 31 + x 32 + 1 (cid:3) 0 . ( 18 . 69 ) Use the starting point x 0 (cid:3) ( − 1 . 71 , 1 . 59 , 1 . 82 , − 0 . 763 , − 0 . 763 ) T . The solution is x ∗ (cid:3) ( − 1 . 8 , 1 . 7 , 1 . 9 , − 0 . 8 , − 0 . 8 ) T . ✐ 18 . 4 Show that the damped BFGS updating satisﬁes ( 18 . 17 ) . ✐ 18 . 5 Consider the constraint x 21 + x 22 (cid:3) 1 . Write the linearized constraints ( 18 . 7b ) at the following points : ( 0 , 0 ) T , ( 0 , 1 ) T , ( 0 . 1 , 0 . 02 ) T , − ( 0 . 1 , 0 . 02 ) T . ✐ 18 . 6 Prove Theorem 18 . 2 for the case in which the merit function is given by φ ( x ; µ ) (cid:3) f ( x ) + µ (cid:8) c ( x ) (cid:8) q , where q > 0 . Use this lemma to show that the condition that ensures descent is given by µ > (cid:8) λ k + 1 (cid:8) r , where r > 0 satisﬁes r − 1 + q − 1 (cid:3) 1 . ✐ 18 . 7 Write a program that implements the reduced - Hessian method given by ( 18 . 18 ) , ( 18 . 19a ) , ( 18 . 21 ) , ( 18 . 23 ) . Use your program to solve the problem given in Exercise 18 . 3 . ✐ 18 . 8 Show that the constraints ( 18 . 50b ) – ( 18 . 50e ) are always consistent . ✐ 18 . 9 Show that the feasibility problem ( 18 . 45a ) – ( 18 . 45b ) always has a solution v k lying in the range space of A T k . Hint : First show that if the trust - region constraint ( 18 . 45b ) is active , v k lies in the range space of A T k . Next , show that if the trust region is inactive , the minimum - norm solution of ( 18 . 45a ) lies in the range space of A Tk . This is page 563 Printer : Opaque this C H A P T E R 19 Interior - Point Methods for Nonlinear Programming Interior - point ( or barrier ) methods have proved to be as successful for nonlinear optimiza - tionasforlinearprogramming , andtogetherwithactive - setSQPmethods , theyarecurrently considered the most powerful algorithms for large - scale nonlinear programming . Some of the key ideas , such as primal - dual steps , carry over directly from the linear programming case , but several important new challenges arise . These include the treatment of noncon - vexity , the strategy for updating the barrier parameter in the presence of nonlinearities , and the need to ensure progress toward the solution . In this chapter we describe two classes of interior - point methods that have proved effective in practice . 564 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S The methods in the ﬁrst class can be viewed as direct extensions of interior - point methods for linear and quadratic programming . They use line searches to enforce conver - gence and employ direct linear algebra ( that is , matrix factorizations ) to compute steps . The methods in the second class use a quadratic model to deﬁne the step and incorporate a trust - region constraint to provide stability . These two approaches , which coincide asymptotically , have similarities with line search and trust - region SQP methods . Barrier methods for nonlinear optimization were developed in the 1960s but fell out of favor for almost two decades . The success of interior - point methods for linear programming stimulated renewed interest in them for the nonlinear case . By the late 1990s , a new genera - tion of methods and software for nonlinear programming had emerged . Numerical experi - ence indicates that interior - point methods are often faster than active - set SQP methods on large problems , particularly when the number of free variables is large . They may not yet be as robust , but signiﬁcant advances are still being made in their design and implementation . The terms “interior - point methods” and “barrier methods” are now used interchangeably . In Chapters 14 and 16 we discussed interior - point methods for linear and quadratic programming . It is not essential that the reader study those chapters before reading this one , although doing so will give a better perspective . The ﬁrst part of this chapter assumes famil - iarity primarily with the KKT conditions and Newton’s method , and the second part of the chapter relies on concepts from sequential quadratic programming presented in Chapter 18 . The problem under consideration in this chapter is written as follows : min x , s f ( x ) ( 19 . 1a ) subject to c E ( x ) (cid:3) 0 , ( 19 . 1b ) c I ( x ) − s (cid:3) 0 , ( 19 . 1c ) s ≥ 0 . ( 19 . 1d ) The vector c I ( x ) is formed from the scalar functions c i ( x ) , i ∈ I , and similarly for c E ( x ) . Note that we have transformed the inequalities c I ( x ) ≥ 0 into equalities by the introduction of a vector s of slack variables . We use l to denote the number of equality constraints ( that is , the dimension of the vector c E ) and m to denote the number of inequality constraints ( the dimension of c I ) . 19 . 1 TWO INTERPRETATIONS Interior - point methods can be seen as continuation methods or as barrier methods . We discuss both derivations , starting with the continuation approach . The KKT conditions ( 12 . 1 ) for the nonlinear program ( 19 . 1 ) can be written as ∇ f ( x ) − A E T ( x ) y − A I T ( x ) z (cid:3) 0 , ( 19 . 2a ) Sz − µ e (cid:3) 0 , ( 19 . 2b ) 1 9 . 1 . T W O I N T E R P R E T A T I O N S 565 c E ( x ) (cid:3) 0 , ( 19 . 2c ) c I ( x ) − s (cid:3) 0 , ( 19 . 2d ) with µ (cid:3) 0 , together with s ≥ 0 , z ≥ 0 . ( 19 . 3 ) Here A E ( x ) and A I ( x ) are the Jacobian matrices of the functions c E and c I , respectively , and y and z are their Lagrange multipliers . We deﬁne S and Z to be the diagonal matrices whose diagonal entries are given by the vectors s and z , respectively , and let e (cid:3) ( 1 , 1 , . . . , 1 ) T . Equation ( 19 . 2b ) , with µ (cid:3) 0 , and the bounds ( 19 . 3 ) introduce into the problem the combinatorial aspect of determining the optimal active set , illustrated in Example 15 . 1 . We circumvent this difﬁculty by letting µ be strictly positive , thus forcing the variables s and z to take positive values . The homotopy ( or continuation ) approach consists of ( approximately ) solving the perturbed KKT conditions ( 19 . 2 ) for a sequence of positive parameters { µ k } that converges to zero , while maintaining s , z > 0 . The hope is that , in the limit , we will obtain a point that satisﬁes the KKT conditions for the nonlinear program ( 19 . 1 ) . Furthermore , by requiring the iterates to decrease a merit function ( or to be acceptable to a ﬁlter ) , the iteration is likely to converge to a minimizer , not simply a KKT point . The homotopy approach is justiﬁed locally . In a neighborhood of a solution ( x ∗ , s ∗ , y ∗ , z ∗ ) that satisﬁes the linear independence constraint qualiﬁcation ( LICQ ) ( Deﬁ - nition 12 . 4 ) , the strict complementarity condition ( Deﬁnition 12 . 5 ) , and the second - order sufﬁcient conditions ( Theorem 12 . 6 ) , we have that for all sufﬁciently small positive values of µ , the system ( 19 . 2 ) has a locally unique solution , which we denote by ( x ( µ ) , s ( µ ) , y ( µ ) , z ( µ ) ) . The trajectory described by these points is called the primal - dual central path , and it converges to ( x ∗ , s ∗ , y ∗ , z ∗ ) as µ → 0 . The second derivation of interior - point methods associates with ( 19 . 1 ) the barrier problem min x , s f ( x ) − µ m (cid:3) i (cid:3) 1 log s i ( 19 . 4a ) subject to c E ( x ) (cid:3) 0 , ( 19 . 4b ) c I ( x ) − s (cid:3) 0 , ( 19 . 4c ) where µ is a positive parameter and log ( · ) denotes the natural logarithm function . One need not include the inequality s ≥ 0 in ( 19 . 4 ) because minimization of the barrier term − µ (cid:4) mi (cid:3) 1 log s i in ( 19 . 4a ) prevents the components of s from becoming too close to zero . ( Recall that ( − log t ) → ∞ as t ↓ 0 . ) Problem ( 19 . 4 ) also avoids the combinatorial aspect of nonlinear programs , but its solution does not coincide with that of ( 19 . 1 ) for µ > 0 . The barrier approach consists of ﬁnding ( approximate ) solutions of the barrier problem ( 19 . 4 ) for a sequence of positive barrier parameters { µ k } that converges to zero . 566 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S To compare the homotopy and barrier approaches , we write the KKT conditions for ( 19 . 4 ) as follows : ∇ f ( x ) − A E T ( x ) y − A I T ( x ) z (cid:3) 0 , ( 19 . 5a ) − µ S − 1 e + z (cid:3) 0 , ( 19 . 5b ) c E ( x ) (cid:3) 0 , ( 19 . 5c ) c I ( x ) − s (cid:3) 0 . ( 19 . 5d ) Note that they differ from ( 19 . 2 ) only inthe secondequation , which becomes quite nonlinear near the solution as s → 0 . It is advantageous for Newton’s method to transform the rational equation ( 19 . 5b ) into a quadratic equation . We do so by multiplying this equation by S , a procedure that does not change the solution of ( 19 . 5 ) because the diagonal elements of S are positive . After this transformation , the KKT conditions for the barrier problem coincide with the perturbed KKT system ( 19 . 2 ) . The term “interior point” derives from the fact that early barrier methods [ 98 ] did not use slacks and assumed that the initial point x 0 is feasible with respect to the inequality constraints c i ( x ) ≥ 0 , i ∈ I . These methods used the barrier function f ( x ) − µ (cid:3) i ∈ I log c i ( x ) to prevent the iterates from leaving the feasible region deﬁned by the inequalities . ( We discuss this barrier function further in Section 19 . 6 . ) Most modern interior - point methods are infeasible ( they can start from any initial point x 0 ) and remain interior only with respect to the constraints s ≥ 0 , z ≥ 0 . However , they can be designed so that once they generate a feasible iterate , all subsequent iterates remain feasible with respect to the inequalities . In the next sections we will see that the homotopy and barrier interpretations are both useful . The homotopy view gives rise to the deﬁnition of the primal - dual direction , whereas the barrier view is vital in the design of globally convergent iterations . 19 . 2 A BASIC INTERIOR - POINT ALGORITHM Applying Newton’s method to the nonlinear system ( 19 . 2 ) , in the variables x , s , y , z , we obtain ⎡ ⎢⎢⎢⎢⎣ ∇ 2 xx L 0 − A E T ( x ) − A I T ( x ) 0 Z 0 S A E ( x ) 0 0 0 A I ( x ) − I 0 0 ⎤ ⎥⎥⎥⎥⎦ ⎡ ⎢⎢⎢⎢⎣ p x p s p y p z ⎤ ⎥⎥⎥⎥⎦ (cid:3) − ⎡ ⎢⎢⎢⎢⎣ ∇ f ( x ) − A E T ( x ) y − A I T ( x ) z Sz − µ e c E ( x ) c I ( x ) − s ⎤ ⎥⎥⎥⎥⎦ , ( 19 . 6 ) 1 9 . 2 . A B A S I C I N T E R I O R - P O I N T A L G O R I T H M 567 where L denotes the Lagrangian for ( 19 . 1a ) – ( 19 . 1c ) : L ( x , s , y , z ) (cid:3) f ( x ) − y T c E ( x ) − z T ( c I ( x ) − s ) . ( 19 . 7 ) The system ( 19 . 6 ) is called the primal - dual system ( in contrast with the primal system discussed in Section 19 . 3 ) . After the step p (cid:3) ( p x , p s , p y , p z ) has been determined , we compute the new iterate ( x + , s + , y + , z + ) as x + (cid:3) x + α max s p x , s + (cid:3) s + α max s p s , ( 19 . 8a ) y + (cid:3) y + α max z p y , z + (cid:3) z + α max z p z , ( 19 . 8b ) where α max s (cid:3) max { α ∈ ( 0 , 1 ] : s + α p s ≥ ( 1 − τ ) s } , ( 19 . 9a ) α max z (cid:3) max { α ∈ ( 0 , 1 ] : z + α p z ≥ ( 1 − τ ) z } , ( 19 . 9b ) with τ ∈ ( 0 , 1 ) . ( A typical value of τ is 0 . 995 . ) The condition ( 19 . 9 ) , called the fraction to the boundary rule , prevents the variables s and z from approaching their lower bounds of 0 too quickly . This simple iteration provides the basis of modern interior - point methods , though various modiﬁcations are needed to cope with nonconvexities and nonlinearities . The other major ingredient is the procedure for choosing the sequence of parameters { µ k } , which from now on we will call the barrier parameters . In the approach studied by Fiacco and McCormick [ 98 ] , the barrier parameter µ is held ﬁxed for a series of iterations until the KKT conditions ( 19 . 2 ) are satisﬁed to some accuracy . An alternative approach is to update the barrier parameter at each iteration . Both approaches have their merits and are discussed in Section 19 . 3 . The primal - dual matrix in ( 19 . 6 ) remains nonsingular as the iteration converges to a solution that satisﬁes the second - order sufﬁciency conditions and strict complementarity . More speciﬁcally , if x ∗ is a solution point for which strict complementarity holds , then for every index i either s i or z i remains bounded away from zero as the iterates approach x ∗ , ensuring that the second block row of the primal - dual matrix ( 19 . 6 ) has full row rank . Therefore , the interior - point approach does not , in itself , give rise to ill conditioning or singularity . This fact allows us to establish a fast ( superlinear ) rate of convergence ; see Section 19 . 8 . We summarize the discussion by describing a concrete implementation of this basic interior - point method . We use the following error function , which is based on the perturbed KKT system ( 19 . 2 ) : E ( x , s , y , z ; µ ) (cid:3) max 2 (cid:8)∇ f ( x ) − A E ( x ) T y − A I ( x ) T z (cid:8) , (cid:8) Sz − µ e (cid:8) , (cid:8) c E ( x ) (cid:8) , (cid:8) c I ( x ) − s (cid:8) } , ( 19 . 10 ) for some vector norm (cid:8) · (cid:8) . 568 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S Algorithm 19 . 1 ( Basic Interior - Point Algorithm ) . Choose x 0 and s 0 > 0 , and compute initial values for the multipliers y 0 and z 0 > 0 . Select an initial barrier parameter µ 0 > 0 and parameters σ , τ ∈ ( 0 , 1 ) . Set k ← 0 . repeat until a stopping test for the nonlinear program ( 19 . 1 ) is satisﬁed repeat until E ( x k , s k , y k , z k ; µ k ) ≤ µ k Solve ( 19 . 6 ) to obtain the search direction p (cid:3) ( p x , p s , p y , p z ) ; Compute α max s , α max z using ( 19 . 9 ) ; Compute ( x k + 1 , s k + 1 , y k + 1 , z k + 1 ) using ( 19 . 8 ) ; Set µ k + 1 ← µ k and k ← k + 1 ; end Choose µ k ∈ ( 0 , σµ k ) ; end An algorithm that updates the barrier parameter µ k at every iteration is easily obtained from Algorithm 19 . 1 by removing the requirement that the KKT conditions be satisﬁed for each µ k ( the inner “repeat” loop ) and by using a dynamic rule for updating µ k in the penultimate line . The following theorem provides a theoretical foundation for interior - point methods that compute only approximate solutions of the barrier problem . Theorem 19 . 1 . Suppose that Algorithm 19 . 1 generates an inﬁnite sequence of iterates { x k } and that { µ k } → 0 ( that is , that the algorithm does not loop inﬁnitely in the inner “repeat” statement ) . Suppose that f and c are continuously differentiable functions . Then all limit points ˆ x of { x k } are feasible . Furthermore , if any limit point ˆ x of { x k } satisﬁes the linear independence constraint qualiﬁcation ( LICQ ) , then the ﬁrst - order optimality conditions of the problem ( 19 . 1 ) hold at ˆ x . P ROOF . For simplicity , we prove the result for the case in which the nonlinear program ( 19 . 1 ) contains only inequality constraints , leaving the extension of the result as an exercise . For ease of notation , we denote the inequality constraints c I by c . Let ˆ x be a limit point of the sequence { x k } , and let { x k l } be a convergent subsequence , namely , { x k l } → ˆ x . Since µ k → 0 , the error E given by ( 19 . 10 ) converges to zero , so we have ( c k l − s k l ) → 0 . By continuity of c , this fact implies that ˆ c def (cid:3) c ( ˆ x ) ≥ 0 ( that is , ˆ x is feasible ) and s k l → ˆ s (cid:3) ˆ c . Now suppose that the linear independence constraint qualiﬁcation holds at ˆ x , and consider the set of active indices A (cid:3) { i : ˆ c i (cid:3) 0 } . 1 9 . 3 . A L G O R I T H M I C D E V E L O P M E N T 569 For i (cid:9)∈ A , we have ˆ c i > 0 and ˆ s i > 0 , and thus by the complementarity condition ( 19 . 2b ) , we have that [ z k l ] i → 0 . From this fact and ∇ f k l − A Tk l z k l → 0 , we deduce that ∇ f k l − (cid:3) i ∈ A [ z k l ] i ∇ c i ( x k l ) → 0 . ( 19 . 11 ) By the constraint qualiﬁcation hypothesis , the vectors { ∇ ˆ c i : i ∈ A } are linearly indepen - dent . Hence , by ( 19 . 11 ) and continuity of ∇ f ( · ) and ∇ c ( i ) ( · ) , i ∈ A , the positive sequence { z k l } converges to some value ˆ z ≥ 0 . Taking the limit in ( 19 . 11 ) , we have that ∇ f ( ˆ x ) (cid:3) (cid:3) i ∈ A ˆ z i ∇ c i ( ˆ x ) . We also have that ˆ c T ˆ z (cid:3) 0 , completing the proof . (cid:1) Practical interior - point algorithms fall into two categories . The ﬁrst builds on Algo - rithm 19 . 1 , adding a line search and features to control the rate of decrease in the slacks s and multipliers z , and introducing modiﬁcations in the primal - dual sytem when negative curva - ture is encountered . The second category of algorithms , presented in Section 19 . 5 , computes steps by minimizing a quadratic model of ( 19 . 4 ) , subject to a trust - region constraint . The two approaches share many features described in the next section . 19 . 3 ALGORITHMIC DEVELOPMENT We now discuss a series of modiﬁcations and extensions of Algorithm 19 . 1 that enable it to solve nonconvex nonlinear problems , starting from any initial estimate . Often , the primal - dual system ( 19 . 6 ) is rewritten in the symmetric form ⎡ ⎢⎢⎢⎢⎣ ∇ 2 xx L 0 A E T ( x ) A I T ( x ) 0 (cid:28) 0 − I A E ( x ) 0 0 0 A I ( x ) − I 0 0 ⎤ ⎥⎥⎥⎥⎦ ⎡ ⎢⎢⎢⎢⎣ p x p s − p y − p z ⎤ ⎥⎥⎥⎥⎦ (cid:3) − ⎡ ⎢⎢⎢⎢⎣ ∇ f ( x ) − A E T ( x ) y − A I T ( x ) z z − µ S − 1 e c E ( x ) c I ( x ) − s ⎤ ⎥⎥⎥⎥⎦ , ( 19 . 12 ) where (cid:28) (cid:3) S − 1 Z . ( 19 . 13 ) This formulation permits the use of a symmetric linear equations solver , which reduces the computational work of each iteration . 570 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S PRIMAL VS . PRIMAL - DUAL SYSTEM If we apply Newton’s method directly to the optimality conditions ( 19 . 5 ) of the barrier problem ( instead of transforming to ( 19 . 5b ) ﬁrst ) and then symmetrize the iteration matrix , we obtain the system ( 19 . 12 ) but with (cid:28) given by (cid:28) (cid:3) µ S − 2 . ( 19 . 14 ) This is often called the primal system , in contrast with the primal - dual system arising from ( 19 . 13 ) . ( This nomenclature owes more to the historical development of interior - point methods than to the concept of primal - dual iterations . ) Whereas in the primal - dual choice ( 19 . 13 ) the vector z can be seen as a general multiplier estimate , the primal term ( 19 . 14 ) is obtained by making the speciﬁc selection Z (cid:3) µ S − 1 ; we return to this choice of multipliers in Section 19 . 6 . Even though the systems ( 19 . 2 ) and ( 19 . 5 ) are equivalent , Newton’s method applied to them will generally produce different iterates , and there are reasons for preferring the primal - dual system . Note that ( 19 . 2b ) has the advantage that its derivatives are bounded as any slack variables approach zero ; such is not the case with ( 19 . 5b ) . Moreover , analysis of the primal step as well as computational experience has shown that , under some circumstances , the primal step ( 19 . 12 ) , ( 19 . 14 ) tends to produce poor steps that violate the bounds s > 0 and z > 0 signiﬁcantly , resulting in slow progress ; see Section 19 . 6 . SOLVING THE PRIMAL - DUAL SYSTEM Apart from the cost of evaluating the problem functions and their derivatives , the work of the interior - point iteration is dominated by the solution of the primal - dual system ( 19 . 12 ) , ( 19 . 13 ) . An efﬁcient linear solver , using either sparse factorization or iterative techniques , is therefore essential for fast solution of large problems . The symmetric matrix in ( 19 . 12 ) has the familiar form of a KKT matrix ( cf . ( 16 . 7 ) , ( 18 . 6 ) ) , and the linear system can be solved by the approaches described in Chapter 16 . We can ﬁrst reduce the system by eliminating p s using the second equation in ( 19 . 6 ) , giving ⎡ ⎢⎣ ∇ 2 xx L A E T ( x ) A I T ( x ) A E ( x ) 0 0 A I ( x ) 0 − (cid:28) − 1 ⎤ ⎥⎦ ⎡ ⎢⎣ p x − p y − p z ⎤ ⎥⎦ (cid:3) − ⎡ ⎢⎣ ∇ f ( x ) − A E T ( x ) y − A I T ( x ) z c E ( x ) c I ( x ) − µ Z − 1 e ⎤ ⎥⎦ . ( 19 . 15 ) This system can be factored by using a symmetric indeﬁnite factorization ; see ( 16 . 12 ) . If we denote the coefﬁcient matrix in ( 19 . 15 ) by K , this factorization computes P T K P (cid:3) L BL T , where L is lower triangular and B is block diagonal , with blocks of size 1 × 1 or 2 × 2 . P is a matrix of row and column permutations that seeks a compromise between the goals of preserving sparsity and ensuring numerical stability ; see ( 3 . 51 ) and the discussion that follows . 1 9 . 3 . A L G O R I T H M I C D E V E L O P M E N T 571 The system ( 19 . 15 ) can be reduced further by eliminating p z using the last equation , to obtain the condensed coefﬁcient matrix (cid:1) ∇ 2 xx L + A I T (cid:28) A I A E T ( x ) A E ( x ) 0 (cid:2) , ( 19 . 16 ) which is much smaller than ( 19 . 12 ) when the number of inequality constraints is large . Although signiﬁcant ﬁll - in can arise from the term A I T (cid:28) A I , it is tolerable in many applica - tions . A particularly favorable case , in which A I T (cid:28) A I is diagonal , arises when the inequality constraints are simple bounds . The primal - dual system in any of the symmetric forms ( 19 . 12 ) , ( 19 . 15 ) , ( 19 . 16 ) is ill conditioned because , by ( 19 . 13 ) , some of the elements of (cid:28) diverge to ∞ , while others converge to zero as µ → 0 . Nevertheless , because of the special form in which this ill conditioning arises , the direction computed by a stable direct factorization method is usually accurate . Damaging errors result only when the slacks s or multipliers z become very close to zero ( or when the Hessian ∇ 2 xx L or the Jacobian matrix A E is almost rank deﬁcient ) . For this reason , direct factorization techniques are considered the most reliable techniques for computing steps in interior - point methods . Iterative linear algebra techniques can also be used for the step computation . Ill con - ditioning is a grave concern in this context , and preconditioners that cluster the eigenvalues of (cid:28) must be used . Fortunately , such preconditioners are easy to construct . For example , let us introduce the change of variables ˜ p s (cid:3) S − 1 p s in the system ( 19 . 12 ) , and multiply the second equation in ( 19 . 12 ) by S , transforming the term (cid:28) into S (cid:28) S . As µ → 0 ( and assuming that SZ ≈ µ I ) we have from ( 19 . 13 ) that all the elements of S (cid:28) S cluster around µ I . Other scalings can be used as well . The change of variables ˜ p s (cid:3) (cid:28) 1 / 2 p s provides the perfect preconditioner , while ˜ p s (cid:3) √ µ S − 1 p s transforms (cid:28) to S (cid:28) S / µ , which converges to I as µ → 0 . We can apply an iterative method to one of the symmetric indeﬁnite systems ( 19 . 12 ) , ( 19 . 15 ) , or ( 19 . 16 ) . The conjugate gradient method is not appropriate ( except as explained below ) because it is designed for positive deﬁnite systems , but we can use GMRES , QMR , or LSQR ( see [ 136 ] ) . In addition to employing preconditioning that re - moves the ill conditioning caused by the barrier approach , as discussed above , we need to deal with possible ill conditioning caused by the Hessian ∇ 2 xx L or the Jacobian matri - ces A E and A I . General - purpose preconditioners are difﬁcult to ﬁnd in this context , and the success of an iterative method hinges on the use of problem - speciﬁc or structured preconditioners . An effective alternative is to use a null - space approach to solve the primal - dual system and apply the CG method in the ( positive deﬁnite ) reduced space . As explained in Sec - tion 16 . 3 , we can do this by applying the projected CG iteration of Algorithm 16 . 2 using a so - called constraint preconditioner . In the context of the system ( 19 . 12 ) the preconditioner 572 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S has the form ⎡ ⎢⎢⎢⎢⎣ G 0 A E T ( x ) A I T ( x ) 0 T 0 − I A E ( x ) 0 0 0 A I ( x ) − I 0 0 ⎤ ⎥⎥⎥⎥⎦ , ( 19 . 17 ) where G is a sparse matrix that is positive deﬁnite on the null space of the constraints and T is a diagonal matrix that equals or approximates (cid:28) . This preconditioner keeps the Jacobian information of A E and A I intact and thereby removes any ill conditioning present in these matrices . UPDATING THE BARRIER PARAMETER The sequence of barrier parameters { µ k } must converge to zero so that , in the limit , we recover the solution of the nonlinear programming problem ( 19 . 1 ) . If µ k is decreased too slowly , a large number of iterations will be required for convergence ; but if it is decreased too quickly , some of the slacks s or multipliers z may approach zero prematurely , slowing progress of the iteration . We now describe several techniques for updating µ k that have proved to be effective in practice . The strategy implemented in Algorithm 19 . 1 , which we call the Fiacco – McCormick approach , ﬁxes the barrier parameter until the perturbed KKT conditions ( 19 . 2 ) are satisﬁed to some accuracy . Then the barrier parameter is decreased by the rule µ k + 1 (cid:3) σ k µ k , with σ k ∈ ( 0 , 1 ) . ( 19 . 18 ) Some early implementations of interior - point methods chose σ k to be a constant ( for exam - ple , σ k (cid:3) 0 . 2 ) . It is , however , preferable to let σ k take on two or more values ( for example , 0 . 2 and 0 . 1 ) , choosing smaller values when the most recent iterations make signiﬁcant progress toward the solution . Furthermore , by letting σ k → 0 near the solution , and letting the parameter τ in ( 19 . 9 ) converge to 1 , a superlinear rate of convergence can be obtained . TheFiacco – McCormickapproachworkswellonmanyproblems , butitcanbesensitive to the choice of the initial point , the initial barrier parameter value , and the scaling of the problem . Adaptive strategies for updating the barrier parameter are more robust in difﬁcult situations . These strategies , unlike the Fiacco – McCormick approach , vary µ at every it - eration depending on the progress of the algorithm . Most such strategies are based on complementarity , as in the linear programming case ( see Framework 14 . 1 ) , and have the form µ k + 1 (cid:3) σ k s T k z k m , ( 19 . 19 ) 1 9 . 3 . A L G O R I T H M I C D E V E L O P M E N T 573 which allows µ k to reﬂect the scale of the problem . One choice of σ k , implemented in the LOQO package [ 294 ] , is based on the deviation of the smallest complementarity product [ s k ] i [ z k ] i from the average : σ k (cid:3) 0 . 1 min (cid:17) 0 . 051 − ξ k ξ k , 2 (cid:18) 3 , where ξ k (cid:3) min i [ s k ] i [ z k ] i ( s k ) T z k / m . ( 19 . 20 ) Here [ s k ] i denotes the i th component of the iterate s k , and similarly for [ z k ] i . When ξ k ≈ 1 ( all the individual products are near to their average ) , the barrier parameter is decreased aggressively . Predictor or probing strategies ( see Section 14 . 2 ) can also be used to determine the parameter σ k in ( 19 . 19 ) . We calculate a predictor ( afﬁne scaling ) direction ( (cid:6) x aff , (cid:6) s aff , (cid:6) y aff , (cid:6) z aff ) by setting µ (cid:3) 0 in ( 19 . 12 ) . We probe this direction by ﬁnding α aff p and α aff d to be the longest step lengths that can be taken along the afﬁne scaling direction before violating the nonnegativity conditions ( s , z ) ≥ 0 . Explicit formulas for these step lengths are given by ( 19 . 9 ) with τ (cid:3) 1 . We then deﬁne µ aff to be the value of complementarity along the ( shortened ) afﬁne scaling step , that is , µ aff (cid:3) ( s k + α aff s (cid:6) s aff ) T ( z k + α aff z (cid:6) z aff ) / m , ( 19 . 21 ) and deﬁne σ k as follows : σ k (cid:3) (cid:17) µ aff s Tk z k / m (cid:18) 3 . ( 19 . 22 ) This heuristic choice of σ k was proposed for linear programming problems ( see ( 14 . 34 ) ) and also works well for nonlinear programs . HANDLING NONCONVEXITY AND SINGULARITY The direction deﬁned by the primal - dual system ( 19 . 12 ) is not always productive because it seeks to locate only KKT points ; it can move toward a maximizer or other stationary points . In Chapter 18 we have seen that the Newton step ( 18 . 9 ) for the equality - constrained problem ( 18 . 1 ) can be guaranteed to be a descent direction for a large class of merit functions—and to be a productive direction for a ﬁlter—if the Hessian W is positive deﬁnite on the tangent space of the constraints . The reason is that , in this case , the step can be interpreted as the minimization of a convex model in the reduced space obtained by eliminating the linearized constraints . 574 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S For the primal - dual system ( 19 . 12 ) , the step p is a descent direction if the matrix (cid:1) ∇ 2 xx L 0 0 (cid:28) (cid:2) ( 19 . 23 ) is positive deﬁnite on the null space of the constraint matrix (cid:1) A E ( x ) 0 A I ( x ) − I (cid:2) . Lemma 16 . 3 states that this positive deﬁniteness condition holds if the inertia of the primal - dual matrix in ( 19 . 12 ) is given by ( n + m , l + m , 0 ) , ( 19 . 24 ) in other words , if this matrix has exactly n + m positive , l + m negative , and no zero eigenvalues . ( Recall that l and m denote the number of equality and inequality constraints , respectively . ) As discussed in Section 3 . 4 , the inertia can be obtained from the symmetric - indeﬁnite factorization of ( 19 . 12 ) . If the primal - dual matrix does not have the desired inertia , we can modify it as follows . Note that the diagonal matrix (cid:28) is positive deﬁnite by construction but ∇ 2 xx L can be indeﬁnite . Therefore , we can replace the latter matrix by ∇ 2 xx L + δ I , where δ > 0 is sufﬁciently large to ensure that the inertia is given by ( 19 . 24 ) . The size of this modiﬁcation is not known beforehand , but we can try successively larger values of δ until the desired inertia is obtained . We must also guard against singularity of the primal - dual matrix caused by the rank deﬁciency of A E ( the matrix [ A I − I ] always has full rank ) . We do so by including a regularization parameter γ ≥ 0 , in addition to the modiﬁcation term δ I , and work with the modiﬁed primal - dual matrix ⎡ ⎢⎢⎢⎢⎣ ∇ 2 xx L + δ I 0 A E ( x ) T A I ( x ) T 0 (cid:28) 0 − I A E ( x ) 0 − γ I 0 A I ( x ) − I 0 0 ⎤ ⎥⎥⎥⎥⎦ . ( 19 . 25 ) A procedure for selecting γ and δ is given in Algorithm B . 1 in Appendix B . It is invoked at every iteration of the interior - point method to enforce the inertia condition ( 19 . 24 ) and to guarantee nonsingularity . Other matrix modiﬁcations to ensure positive deﬁniteness have been discussed in Chapter 3 in the context of unconstrained minimization . 1 9 . 3 . A L G O R I T H M I C D E V E L O P M E N T 575 STEP ACCEPTANCE : MERIT FUNCTIONS AND FILTERS The role of the merit function or ﬁlter is to determine whether a step is productive and should be accepted . Since interior - point methods can be seen as methods for solv - ing the barrier problem ( 19 . 4 ) , it is appropriate to deﬁne the merit function φ or ﬁlter in terms of barrier functions . We may use , for example , an exact merit function of the form φ ν ( x , s ) (cid:3) f ( x ) − µ m (cid:3) i (cid:3) 1 log s i + ν (cid:8) c E ( x ) (cid:8) + ν (cid:8) c I ( x ) − s (cid:8) , ( 19 . 26 ) where the norm is chosen , say , to be the (cid:1) 1 or the (cid:1) 2 norm ( unsquared ) . The penalty parameter ν > 0 can be updated by using the strategies described in Chapter 18 . In a line search method , after the step p has been computed and the maximum step lengths ( 19 . 9 ) have been determined , we perform a backtracking line search that computes the step lengths α s ∈ ( 0 , α max s ] , α z ∈ ( 0 , α max z ] , ( 19 . 27 ) providing sufﬁcient decrease of the merit function or ensuring acceptability by the ﬁlter . The new iterate is then deﬁned as x + (cid:3) x + α s p x , s + (cid:3) s + α s p s , ( 19 . 28a ) y + (cid:3) y + α z p y , z + (cid:3) z + α z p z . ( 19 . 28b ) When deﬁning a ﬁlter ( see Section 15 . 4 ) the pairs of the ﬁlter are formed , on the one hand , by the values of the barrier function f ( x ) − µ (cid:4) m i (cid:3) 1 log s i and , on the other hand , by the constraint violations (cid:8) ( c E ( x ) , c I ( x ) − s ) (cid:8) . A step will be accepted if it is not dominated by any element in the ﬁlter . Under certain circumstances , if the step is not accepted by the ﬁlter , instead of reducing the step length α s in ( 19 . 8a ) , a feasibility restoration phase is invoked ; see the Notes and References at the end of the chapter . QUASI - NEWTON APPROXIMATIONS A quasi - Newton version of the primal - dual step is obtained by replacing ∇ 2 xx L in ( 19 . 12 ) by a quasi - Newton approximation B . We can use the BFGS ( 6 . 19 ) or SR1 ( 6 . 24 ) updateformulasdescribedinChapter6todeﬁne B , orwecanfollowalimited - memoryBFGS approach ( seeChapter7 ) . ItisimportanttoapproximatetheHessianoftheLagrangianofthe nonlinear program , not the Hessian of the barrier function , which is highly ill conditioned and changes rapidly . The correction pairs used by the quasi - Newton updating formula are denoted here by ( (cid:6) x , (cid:6) l ) , replacing the notation ( s , y ) of Chapter 6 . After computing a step from ( x , s , y , z ) 576 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S to ( x + , s + , y + , z + ) , we deﬁne (cid:6) l (cid:3) ∇ x L ( x + , s + , y + , z + ) − ∇ x L ( x , s + , y + , z + ) , (cid:6) x (cid:3) x + − x . To ensure that the BFGS method generates a positive deﬁnite matrix , one can skip or damp the update ; see ( 18 . 14 ) and ( 18 . 15 ) . SR1 updating must be safeguarded to avoid unboundedness , as discussed in Section 6 . 2 , and may also need to be modiﬁed so that the inertia of the primal - dual matrix is given by ( 19 . 24 ) . This modiﬁcation can be performed by means of Algorithm B . 1 . The quasi - Newton matrices B generated in this manner are dense n × n matrices . For largeproblems , limited - memoryupdatingisdesirable . Oneoptionistoimplementalimited - memory BFGS method by using the compact representations described in Section 7 . 2 . Here B has the form B (cid:3) ξ I + W MW T , ( 19 . 29 ) where ξ > 0 is a scaling factor , W is an n × 2 ˆ m matrix , M is a 2 ˆ m × 2 ˆ m symmet - ric and nonsingular matrix , and ˆ m denotes the number of correction pairs saved in the limited - memory updating procedure . The matrices W and M are formed by using the vec - tors { (cid:6) l k } and { (cid:6) x k } accumulated in the last ˆ m iterations . Since the limited - memory matrix B is positive deﬁnite , and assuming A E has full rank , the primal - dual matrix is nonsingular , and we can compute the solution to ( 19 . 12 ) by inverting the coefﬁcient matrix using the Sherman – Morrison – Woodbury formula ( see Exercise 19 . 14 ) . FEASIBLE INTERIOR - POINT METHODS In many applications , it is desirable for all of the iterates generated by an optimization algorithm to be feasible with respect to some or all of the inequality constraints . For example , theobjectivefunctionmaybedeﬁnedonlywhensomeoftheconstraintsaresatisﬁed , making this feature essential . Interior - point methods provide a natural framework for deriving feasible algorithms . If the current iterate x satisﬁes c I ( x ) > 0 , then it is easy to adapt the primal - dual iteration ( 19 . 12 ) so that feasibility is preserved . After computing the step p , we let x + (cid:3) x + p x , redeﬁne the slacks as s + ← c I ( x + ) , ( 19 . 30 ) and test whether the point ( x + , s + ) is acceptable for the merit function φ . If so , we deﬁne this point to be the new iterate ; otherwise we reject the step p and compute a new , shorter trial step . In a line search algorithm we backtrack , and in a trust - region method we compute a new step with a reduced trust - region bound . This strategy is justiﬁed by the fact that if at a trial point we have that c i ( x + ) ≤ 0 for some inequality constraint , the value of the merit 1 9 . 4 . A L I N E S E A R C H I N T E R I O R - P O I N T M E T H O D 577 function is + ∞ , and we reject the trial point . We will also reject steps x + p x that are too close to the boundary of the feasible region because such steps increase the barrier term − µ (cid:4) i ∈ I log ( s i ) in the merit function ( 19 . 26 ) . Making the substitution ( 19 . 30 ) has the effect of replacing log ( s i ) with log ( c i ( x ) ) in the merit function , a technique reminiscent of the classical primal log - barrier approach discussed in Section 19 . 6 . 19 . 4 A LINE SEARCH INTERIOR - POINT METHOD We now give a more detailed description of a line search interior - point method . We denote by D φ ( x , s ; p ) the directional derivative of the merit function φ ν at ( x , s ) in the direction p . The stopping conditions are based on the error function ( 19 . 10 ) . Algorithm 19 . 2 ( Line Search Interior - Point Algorithm ) . Choose x 0 and s 0 > 0 , and compute initial values for the multipliers y 0 and z 0 > 0 . If a quasi - Newton approach is used , choose an n × n symmetric and positive deﬁnite initial matrix B 0 . Selectaninitialbarrierparameter µ > 0 , parameters η , σ ∈ ( 0 , 1 ) , andtolerances (cid:9) µ and (cid:9) TOL . Set k ← 0 . repeat until E ( x k , s k , y k , z k ; 0 ) ≤ (cid:9) TOL repeat until E ( x k , s k , y k , z k ; µ ) ≤ (cid:9) µ Compute the primal - dual direction p (cid:3) ( p x , p s , p y , p z ) from ( 19 . 12 ) , where the coefﬁcient matrix is modiﬁed as in ( 19 . 25 ) , if necessary ; Compute α max s , α max z using ( 19 . 9 ) ; Set p w (cid:3) ( p x , p s ) ; Compute step lengths α s , α z satisfying both ( 19 . 27 ) and φ ν ( x k + α s p x , s k + α s p s ) ≤ φ ν ( x k , s k ) + ηα s D φ ν ( x k , s k ; p w ) ; Compute ( x k + 1 , s k + 1 , y k + 1 , z k + 1 ) using ( 19 . 28 ) ; if a quasi - Newton approach is used update the approximation B k ; Set k ← k + 1 ; end Set µ ← σµ and update (cid:9) µ ; end The barrier tolerance can be deﬁned , for example , as (cid:9) µ (cid:3) µ , as in Algorithm 19 . 1 . An adaptive strategy that updates the barrier parameter µ at every step is easily implemented in this framework . If the merit function can cause the Maratos effect ( see Section 15 . 4 ) , a second - order correction or a nonmonotone strategy should be implemented . An al - ternative to using a merit function is to employ a ﬁlter mechanism to perform the line search . 578 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S We will see in Section 19 . 7 that Algorithm 19 . 2 must be safeguarded to ensure global convergence . 19 . 5 A TRUST - REGION INTERIOR - POINT METHOD We now consider an interior - point method that uses trust regions to promote convergence . As in the unconstrained case , the trust - region formulation allows great freedom in the choice of the Hessian and provides a mechanism for coping with Jacobian and Hessian singularities . The price to pay for this ﬂexibility is a more complex iteration than in the line search approach . The interior - point method described below is asymptotically equivalent to the line search method discussed in Section 19 . 4 , but differs signiﬁcantly in two respects . First , it is not fully a primal - dual method in the sense that it ﬁrst computes a step in the variables ( x , s ) and then updates the estimates for the multipliers , as opposed to the approach of Algorithm 19 . 1 , in which primal and dual variables are computed simultaneously . Second , the trust - region method uses a scaling of the variables that discourages moves toward the boundary of the feasible region . This causes the algorithm to generate steps that can be different from , and enjoy more favorable convergence properties than , those produced by a line search method . We ﬁrst describe a trust - region algorithm for ﬁnding approximate solutions of a ﬁxed barrier problem . We then present a complete interior - point method in which the barrier parameter is driven to zero . AN ALGORITHM FOR SOLVING THE BARRIER PROBLEM The barrier problem ( 19 . 4 ) is an equality - constrained optimization problem and can be solved by using a sequential quadratic programming method with trust regions . A straightforward application of SQP techniques to the barrier problem leads , however , to inefﬁcient steps that tend to violate the positivity of the slack variables and are frequently cut short by the trust - region constraint . To overcome this problem , we design an SQP method tailored to the structure of barrier problems . At the iterate ( x , s ) , and for a given barrier parameter µ , we ﬁrst compute Lagrange multiplier estimates ( y , z ) and then compute a step p (cid:3) ( p x , p s ) that approximately solves the subproblem min p x , p s ∇ f T p x + 1 2 p Tx ∇ 2 xx L p x − µ e T S − 1 p s + 1 2 p Ts (cid:28) p s ( 19 . 31a ) subject to A E ( x ) p x + c E ( x ) (cid:3) r E , ( 19 . 31b ) A I ( x ) p x − p s + ( c I ( x ) − s ) (cid:3) r I , ( 19 . 31c ) (cid:8) ( p x , S − 1 p s ) (cid:8) 2 ≤ (cid:6) , ( 19 . 31d ) p s ≥ − τ s . ( 19 . 31e ) 1 9 . 5 . A T R U S T - R E G I O N I N T E R I O R - P O I N T M E T H O D 579 Here (cid:28) is the primal - dual matrix ( 19 . 13 ) , and the scalar τ ∈ ( 0 , 1 ) is chosen close to 1 ( for example , 0 . 995 ) . The inequality ( 19 . 31e ) plays the same role as the fraction to the boundary rule ( 19 . 9 ) . Ideally , we would like to set r (cid:3) ( r E , r I ) (cid:3) 0 , but since this can cause the constraints ( 19 . 31b ) – ( 19 . 31d ) to be incompatible or to give a step p that makes little progress toward feasibility , we choose the parameter r by an auxiliary computation , as in Algorithm 18 . 4 . We motivate the choice of the objective ( 19 . 31a ) by noting that the ﬁrst - order optimal - ity conditions of ( 19 . 31a ) – ( 19 . 31c ) are given by ( 19 . 2 ) ( with the second block of equations scaled by S − 1 ) . Thus the step computed from the subproblem ( 19 . 31 ) is related to the primal - dual line search step in the same way as the SQP and Newton – Lagrange steps of Section 18 . 1 . The trust - region constraint ( 19 . 31d ) guarantees that the problem ( 19 . 31 ) has a ﬁnite solution even when ∇ 2 xx L ( x , s , y , z ) is not positive deﬁnite , and therefore this Hessian need never be modiﬁed . In addition , the trust - region formulation ensures that adequate progress is made at every iteration . To justify the scaling S − 1 used in ( 19 . 31d ) , we note that the shape of the trust region must take into account the requirement that the slacks not approach zero prematurely . The scaling S − 1 serves this purpose because it restricts those components i of the step vector p s for which s i is close to its lower bound of zero . As we see below , it also plays an important role in the choice of the relaxation vectors r E and r I . We outline this SQP trust - region approach as follows . The stopping condition is deﬁned in terms of the error function E given by ( 19 . 10 ) , and the merit function φ ν can be deﬁned as in ( 19 . 26 ) using the 2 - norm , (cid:8) · (cid:8) 2 . Algorithm 19 . 3 ( Trust - Region Algorithm for Barrier Problems ) . Input parameters : µ > 0 , x 0 , s 0 > 0 , (cid:9) µ , and (cid:6) 0 > 0 . Compute Lagrange multiplier estimates y 0 and z 0 > 0 . Set k ← 0 . repeat until E ( x k , s k , y k , z k ; µ ) ≤ (cid:9) µ Compute p (cid:3) ( p x , p s ) by approximately solving ( 19 . 31 ) . if p provides sufﬁcient decrease in the merit function φ ν Set x k + 1 ← x k + p x , s k + 1 ← s k + p s ; Compute new multiplier estimates y k + 1 , z k + 1 > 0 and set (cid:6) k + 1 ≥ (cid:6) k ; else Deﬁne x k + 1 ← x k , s k + 1 ← s k , and set (cid:6) k + 1 < (cid:6) k ; end Set k ← k + 1 ; end ( repeat ) Algorithm 19 . 3 is applied for a ﬁxed value of the barrier parameter µ . A complete interior - point algorithm driven by a sequence { µ k } → 0 is described below . First , we discuss how to ﬁnd an approximate solution of the subproblem ( 19 . 31 ) , along with Lagrange multiplier estimates ( y k + 1 , z k + 1 ) . 580 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S STEP COMPUTATION The subproblem ( 19 . 31a ) – ( 19 . 31e ) is difﬁcult to minimize exactly because of the presence of the nonlinear constraint ( 19 . 31d ) and the bounds ( 19 . 31e ) . An important observation is that we can compute useful inexact solutions , at moderate cost . Since this approachscalesupwellwiththenumberofvariablesandconstraints , itprovidesaframework for developing practical interior - point methods for large - scale optimization . The ﬁrst step in the solution process is to make a change of variables that transforms the trust - region constraint ( 19 . 31d ) into a ball . By deﬁning ˜ p (cid:3) (cid:1) p x ˜ p s (cid:2) (cid:3) (cid:1) p x S − 1 p s (cid:2) , ( 19 . 32 ) we can write problem ( 19 . 31 ) as min p x , ˜ p s ∇ f T p x + 1 2 p Tx ∇ 2 xx L p x − µ e T ˜ p s + 1 2 ˜ p Ts S (cid:28) S ˜ p s ( 19 . 33a ) subject to A E ( x ) p x + c E ( x ) (cid:3) r E , ( 19 . 33b ) A I ( x ) p x − S ˜ p s + ( c I ( x ) − s ) (cid:3) r I , ( 19 . 33c ) (cid:8) ( p x , ˜ p s ) (cid:8) 2 ≤ (cid:6) , ( 19 . 33d ) ˜ p s ≥ − τ e . ( 19 . 33e ) To compute the vectors r E and r I , we proceed as in Section 18 . 5 and formulate the following normal subproblem in the variable v (cid:3) ( v x , v s ) : min v (cid:8) A E ( x ) v x + c E ( x ) (cid:8) 2 2 + (cid:8) A I ( x ) v x − S v s + ( c I ( x ) − s ) (cid:8) 2 2 ( 19 . 34a ) subject to (cid:8) ( v x , v s ) (cid:8) 2 ≤ 0 . 8 (cid:6) , ( 19 . 34b ) v s ≥ − ( τ / 2 ) e . ( 19 . 34c ) If we ignore ( 19 . 34c ) , this problem has the standard form of a trust - region problem , and we can compute an approximate solution by using the techniques discussed in Chapter 4 , such as the dogleg method . If the solution violates the bounds ( 19 . 34c ) , we can backtrack so that these bounds are satisﬁed . Having solved ( 19 . 34 ) , we deﬁne the vectors r E and r I in ( 19 . 33b ) – ( 19 . 33c ) to be the residuals in the normal step computation , namely , r E (cid:3) A E ( x ) v x + c E ( x ) , r I (cid:3) A I ( x ) v x − S v s + ( c I ( x ) − s ) . ( 19 . 35 ) Wearenowreadytocomputeanapproximatesolution ˜ d ofthesubproblem ( 19 . 33 ) . By ( 19 . 35 ) , the vector v is a particular solution of the linear constraints ( 19 . 33b ) – ( 19 . 33c ) . We 1 9 . 5 . A T R U S T - R E G I O N I N T E R I O R - P O I N T M E T H O D 581 can then solve the equality - constrained quadratic program ( 19 . 33a ) – ( 19 . 33c ) by using the projected conjugate gradient iteration given in Algorithm 16 . 2 . We terminate the projected CG iteration by Steihaug’s rules : During the solution by CG we monitor the satisfaction of the trust - region constraint ( 19 . 33d ) and stop if the boundary of this region is reached , if negative curvature is detected , or if an approximate solution is obtained . If the solution given by the projected CG iteration does not satisfy the bounds ( 19 . 33e ) , we backtrack so that they are satisﬁed . After the step ( p x , ˜ p s ) has been computed , we recover p from ( 19 . 32 ) . As discussed in Section 16 . 3 , every iteration of the projected CG iteration requires the solution of a linear system in order to perform the projection operation . For the quadratic program ( 19 . 33a ) – ( 19 . 33c ) this projection matrix is given by (cid:1) I ˆ A T ˆ A 0 (cid:2) , with ˆ A (cid:3) (cid:1) A E ( x ) 0 A I ( x ) − S (cid:2) . ( 19 . 36 ) Thus , although this trust - region approach still requires the solution of an augmented system , the matrix ( 19 . 36 ) is simpler than the primal - dual matrix ( 19 . 12 ) . In particular , the Hessian ∇ 2 xx L need never be factored because the CG approach requires only products of this matrix with vectors . We mentioned in Section 19 . 3 that the term S (cid:28) S in ( 19 . 33a ) has a much tighter distribution of eigenvalues than (cid:28) . Therefore the CG method will normally not be adversely affected by ill conditioning and is a viable approach for solving the quadratic program ( 19 . 33a ) – ( 19 . 33c ) . LAGRANGE MULTIPLIERS ESTIMATES AND STEP ACCEPTANCE At an iterate ( x , s ) , we choose ( y , z ) to be the least - squares multipliers ( see ( 18 . 21 ) ) corresponding to ( 19 . 33a ) – ( 19 . 33c ) . We obtain the formula (cid:1) y z (cid:2) (cid:3) (cid:29) ˆ A ˆ A T (cid:30) − 1 ˆ A (cid:1) ∇ f ( x ) − µ e (cid:2) , ( 19 . 37 ) where ˆ A is given by ( 19 . 36 ) The multiplier estimates z obtained in this manner may not always be positive ; to enforce positivity , we may redeﬁne them as z i ← min ( 10 − 3 , µ / s i ) , i (cid:3) 1 , 2 , . . . , m . ( 19 . 38 ) The quantity µ / s i is called the i th primal multiplier estimate because if all components of z were deﬁned by ( 19 . 38 ) , then (cid:28) would reduce to the primal choice , ( 19 . 14 ) . As is standard in trust - region methods , the step p is accepted if ared ( p ) ≥ η pred ( p ) , ( 19 . 39 ) 582 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S where ared ( p ) (cid:3) φ ν ( x , s ) − φ ν ( x + p x , s + p s ) ( 19 . 40 ) and where η is a constant in ( 0 , 1 ) ( say , η (cid:3) 10 − 8 ) . The predicted reduction is deﬁned as pred ( p ) (cid:3) q ν ( 0 ) − q ν ( p ) , ( 19 . 41 ) where q ν is deﬁned as q ν ( p ) (cid:3) ∇ f T p x + 1 2 p Tx ∇ 2 xx L p x − µ e T S − 1 p s + 1 2 p Ts (cid:28) p s + ν m ( p ) , and m ( p ) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:23)(cid:1) A E ( x ) p x + c E ( x ) A I ( x ) p x − p s + c I ( x ) − s (cid:2)(cid:23)(cid:23)(cid:23)(cid:23)(cid:23) 2 . To determine an appropriate value of the penalty parameter ν , we require that ν be large enough that pred ( p ) ≥ ρν ( m ( 0 ) − m ( p ) ) , ( 19 . 42 ) for some parameter ρ ∈ ( 0 , 1 ) . This is the same as condition ( 18 . 35 ) used in Section 18 . 5 , and the value of ν can be computed by the procedure described in that section . DESCRIPTION OF A TRUST - REGION INTERIOR - POINT METHOD We now present a more detailed description of the trust - region interior - point algo - rithm for solving the nonlinear programming problem ( 19 . 1 ) . For concreteness we follow theFiacco – McCormickstrategyforupdatingthebarrierparameter . Thestoppingconditions are stated , once more , in terms of the error function E deﬁned by ( 19 . 10 ) . In a quasi - Newton approach , the Hessian ∇ 2 xx L is replaced by a symmetric approximation . Algorithm 19 . 4 ( Trust - Region Interior - Point Algorithm ) . Choose a value for the parameters η > 0 , τ ∈ ( 0 , 1 ) , σ ∈ ( 0 , 1 ) , and ζ ∈ ( 0 , 1 ) , and select the stopping tolerances (cid:9) µ and (cid:9) TOL . If a quasi - Newton approach is used , select an n × n symmetric initial matrix B 0 . Choose initial values for µ > 0 , x 0 , s 0 > 0 , and (cid:6) 0 . Set k ← 0 . repeat until E ( x k , s k , y k , z k ; 0 ) ≤ (cid:9) TOL repeat until E ( x k , s k , y k , z k ; µ ) ≤ (cid:9) µ Compute Lagrange multipliers from ( 19 . 37 ) – ( 19 . 38 ) ; 1 9 . 6 . T H E P R I M A L L O G - B A R R I E R M E T H O D 583 Compute ∇ 2 xx L ( x k , s k , y k , z k ) or upate a quasi - Newton approximation B k , and deﬁne (cid:28) k by ( 19 . 13 ) ; Compute the normal step v k (cid:3) ( v x , v s ) ; Compute ˜ p k by applying the projected CG method to ( 19 . 33 ) ; Obtain the total step p k from ( 19 . 32 ) ; Update ν k to satisfy ( 19 . 42 ) ; Compute pred k ( p k ) by ( 19 . 41 ) and ared k ( p k ) by ( 19 . 40 ) ; if ared k ( p k ) ≥ η pred k ( p k ) Set x k + 1 ← x k + p x , s k + 1 ← s k + p s ; Choose (cid:6) k + 1 ≥ (cid:6) k ; else set x k + 1 (cid:3) x k , s k + 1 (cid:3) s k ; and choose (cid:6) k + 1 < (cid:6) k ; endif Set k ← k + 1 ; end Set µ ← σµ and update (cid:9) µ ; end The merit function ( 19 . 26 ) can reject steps that make good progress toward a solution : the Maratos effect discussed in Chapter 18 . This deﬁciency can be overcome by selective application of a second - order correction step ; see Section 15 . 4 . Algorithm 19 . 4 can easily be modiﬁed to implement an adaptive barrier update strategy . The barrier stop tolerance can be deﬁned as (cid:9) µ (cid:3) µ . Algorithm 19 . 4 is the basis of the KNITRO / CG method [ 50 ] , which implements both exact Hessian and quasi - Newton options . 19 . 6 THE PRIMAL LOG - BARRIER METHOD Prior to the introduction of primal - dual interior methods , barrier methods worked in the space of primal variables x . As in the quadratic penalty function approach of Chapter 17 , the goal was to solve nonlinear programming problems by unconstrained minimization applied to a parametric sequence of functions . Primal barrier methods are more easily described in the context of inequality - constrained problems of the form min x f ( x ) subject to c ( x ) ≥ 0 . ( 19 . 43 ) The log - barrier function is deﬁned by P ( x ; µ ) (cid:3) f ( x ) − µ (cid:3) i ∈ I log c i ( x ) , ( 19 . 44 ) 584 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S where µ > 0 . One can show that the minimizers of P ( x ; µ ) , which we denote by x ( µ ) , approach a solution of ( 19 . 43 ) as µ ↓ 0 , under certain conditions ; see , for example , [ 111 ] . The trajectory C p deﬁned by C p def (cid:3) { x ( µ ) | µ > 0 } ( 19 . 45 ) is often referred to as the primal central path . Since the minimizer x ( µ ) of P ( x ; µ ) lies in the strictly feasible set { x | c ( x ) > 0 } ( where no constraints are active ) , we can in principle search for it by using any of the uncon - strained minimization algorithms described in the ﬁrst part of this book . These methods need to be modiﬁed , as explained in the discussion following equation ( 19 . 30 ) , so that they reject steps that leave the feasible region or are too close to the constraint boundaries . One way to obtain an estimate of the Lagrange multipliers is based on differentiating P to obtain ∇ x P ( x ; µ ) (cid:3) ∇ f ( x ) − (cid:3) i ∈ I µ c i ( x ) ∇ c i ( x ) . ( 19 . 46 ) When x is close to the minimizer x ( µ ) and µ is small , we see from Theorem 12 . 1 that the optimal Lagrange multipliers z ∗ i , i ∈ I , can be estimated as follows : z ∗ i ≈ µ / c i ( x ) , i ∈ I . ( 19 . 47 ) A general framework for algorithms based on the primal log - barrier function ( 19 . 44 ) can be speciﬁed as follows . Framework 19 . 5 ( Unconstrained Primal Barrier Method ) . Given µ 0 > 0 , a sequence { τ k } with τ k → 0 , and a starting point x s 0 ; for k (cid:3) 0 , 1 , 2 , . . . Find an approximate minimizer x k of P ( · ; µ k ) , starting at x sk , and terminating when (cid:8)∇ P ( x k ; µ k ) (cid:8) ≤ τ k ; Compute Lagrange multipliers z k by ( 19 . 47 ) ; if ﬁnal convergence test satisﬁed stop with approximate solution x k ; Choose new penalty parameter µ k + 1 < µ k ; Choose new starting point x sk + 1 ; end ( for ) The primal barrier approach was ﬁrst proposed by Frisch [ 115 ] in the 1950s and was analyzed and popularized by Fiacco and McCormick [ 98 ] in the late 1960s . It fell out of favor after the introduction of SQP methods and has not regained its popularity because it suffers from several drawbacks compared to primal - dual interior - point methods . The most 1 9 . 6 . T H E P R I M A L L O G - B A R R I E R M E T H O D 585 important drawback is that the minimizer x ( µ ) becomes more and more difﬁcult to ﬁnd as µ ↓ 0 because of the nonlinearity of the function P ( x ; µ ) ❏ E XAMPLE 19 . 1 Consider the problem min ( x 1 + 0 . 5 ) 2 + ( x 2 − 0 . 5 ) 2 subject to x 1 ∈ [ 0 , 1 ] , x 2 ∈ [ 0 , 1 ] , ( 19 . 48 ) for which the primal barrier function is P ( x ; µ ) (cid:3) ( x 1 + 0 . 5 ) 2 + ( x 2 − 0 . 5 ) 2 ( 19 . 49 ) − µ (cid:9) log x 1 + log ( 1 − x 1 ) + log x 2 + log ( 1 − x 2 ) (cid:10) . Contours of this function for the value µ (cid:3) 0 . 01 are plotted in Figure 19 . 1 . The elongated nature of the contours indicates bad scaling , which causes poor performance of unconstrained optimization methods such as quasi - Newton , steepest descent , and con - jugate gradient . Newton’s method is insensitive to the poor scaling , but the nonelliptical property—the contours in Figure 19 . 1 are almost straight along the left edge while being circular along the right edge—indicates that the quadratic approximation on which New - ton’s method is based does not capture well the behavior of the barrier function . Hence , Newton’s method , too , may not show rapid convergence to the minimizer of ( 19 . 49 ) except in a small neighborhood of this point . ❐ 0 . 05 0 . 1 0 . 15 0 . 2 0 . 25 0 . 35 0 . 4 0 . 45 0 . 5 0 . 55 0 . 6 0 . 65 Figure 19 . 1 Contours of P ( x ; µ ) from ( 19 . 49 ) for µ (cid:3) 0 . 01 586 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S To lessen this nonlinearity , we can proceed as in ( 17 . 21 ) and introduce additional variables . Deﬁning z i (cid:3) µ / c i ( x ) , we rewrite the stationarity condition ( 19 . 46 ) as ∇ f ( x ) − (cid:3) i ∈ I z i ∇ c i ( x ) (cid:3) 0 , ( 19 . 50a ) C ( x ) z − µ e (cid:3) 0 , ( 19 . 50b ) where C ( x ) (cid:3) diag ( c 1 ( x ) , c 2 ( x ) , . . . , c m ( x ) ) . Note that this system is equivalent to the perturbed KKT conditions ( 19 . 2 ) for problem ( 19 . 43 ) if , in addition , we introduce slacks as in ( 19 . 2d ) . Finally , if we apply Newton’s method in the variables ( x , s , z ) and temporarily ignore the bounds s , z ≥ 0 , we arrive at the primal - dual formulation . Thus , with hindsight , we can transform the primal log - barrier approach into the primal - dual line search approach of Section 19 . 4 or into the trust - region algorithm of Section 19 . 5 . Other drawbacks of the classical primal barrier approach are that it requires a feasible initial point , which can be difﬁcult to ﬁnd in many cases , and that the incorporation of equality constraints in a primal function is problematic . ( A formulation in which the equality constraints are replaced by quadratic penalties suffers from the shortcomings of quadratic penalty functions discussed in Section 17 . 1 . ) The shortcomings of the primal barrier approach were attributed for many years to the ill conditioning of the Hessian of the barrier function P . Note that ∇ 2 xx P ( x ; µ ) (cid:3) ∇ 2 f ( x ) − (cid:3) i ∈ I µ c i ( x ) ∇ 2 c i ( x ) + (cid:3) i ∈ I µ c 2 i ( x ) ∇ c i ( x ) ∇ c i ( x ) T . ( 19 . 51 ) By substituting ( 19 . 47 ) into ( 19 . 51 ) and using the deﬁnition ( 12 . 33 ) of the Lagrangian L ( x , z ) , we ﬁnd that ∇ 2 xx P ( x ; µ ) ≈ ∇ 2 xx L ( x , z ∗ ) + (cid:3) i ∈ I 1 µ ( z ∗ i ) 2 ∇ c i ( x ) ∇ c i ( x ) T . ( 19 . 52 ) NotethesimilarityofthisexpressiontotheHessianofthequadraticpenaltyfunction ( 17 . 19 ) . Analysis of the matrix ∇ 2 xx P ( x ; µ ) shows that it becomes increasingly ill conditioned near the minimizer x ( µ ) , as µ approaches zero . This ill conditioning will be detrimental to the performance of the steepest descent , conjugate gradient , or quasi - Newton methods . It is therefore correct to identify ill condi - tioning as a source of the difﬁculties of unconstrained primal barrier functions that use these unconstrained methods . Newton’s method is , however , not affected by ill conditioning , but its performance is still not satisfactory . As explained above , it is the high nonlinearity of the primal barrier function P that poses signiﬁcant difﬁculties to Newton’s method . 1 9 . 7 . G L O B A L C O N V E R G E N C E P R O P E R T I E S 587 19 . 7 GLOBAL CONVERGENCE PROPERTIES Wenowstudysomeglobalconvergencepropertiesoftheprimal - dualinterior - pointmethods describedinSections19 . 4and19 . 5 . Theorem19 . 1providesthestartingpointfortheanalysis . It gives conditions under which limit points of the iterates generated by the interior - point methods are KKT points for the nonlinear problem . Theorem 19 . 1 relies on the assumption that the perturbed KKT conditions ( 19 . 2 ) can be satisﬁed ( to a certain accuracy ) for every value of µ k . In this section we study conditions under which this assumption holds , that is , conditions that guarantee that our algorithms can ﬁnd stationary points of the barrier problem ( 19 . 4 ) . We begin with a surprising observation . Whereas the line search primal - dual ap - proach is the basis of globally convergent interior - point algorithms for linear and quadratic programming , it is not guaranteed to be successful for nonlinear programming , even for nondegenerate problems . FAILURE OF THE LINE SEARCH APPROACH We have seen in Chapter 11 that line search Newton iterations for nonlinear equations can fail when the Jacobian loses rank . We now discuss a different kind of failure speciﬁc to interior - pointmethods . Itiscausedbythelackofcoordinationbetweenthestepcomputation and the imposition of the bounds . ❏ E XAMPLE 19 . 2 ( W ¨ ACHTER AND B IEGLER [ 299 ] ) Consider the problem min x ( 19 . 53a ) subject to c 1 ( x ) − s def (cid:3) x 2 − s 1 − 1 (cid:3) 0 , ( 19 . 53b ) c 2 ( x ) − s def (cid:3) x − s 2 − 12 (cid:3) 0 , ( 19 . 53c ) s 1 ≥ 0 , s 2 ≥ 0 . ( 19 . 53d ) Note that the Jacobian of the equality constraints ( 19 . 53b ) – ( 19 . 53c ) with respect to ( x , s ) has full rank everywhere . Let us apply a line search interior - point method of the form ( 19 . 6 ) – ( 19 . 9 ) , starting from an initial point x ( 0 ) such that ( s ( 0 ) 1 , s ( 0 ) 2 ) > 0 , and c 1 ( x ( 0 ) ) − s ( 0 ) ≥ 0 . ( In this example , we use superscripts to denote iteration indices . ) Figure 19 . 2 illustrates the feasible region ( the dotted segment of the parabola ) and the initial point , all projected onto the x - s 1 plane . The primal - dual step , which satisﬁes the linearization of the constraints ( 19 . 53b ) – ( 19 . 53c ) , leads from x ( 0 ) to the tangent to the parabola . Here p 1 and p 2 are examples of possible steps satisfying the linearization of ( 19 . 53b ) – ( 19 . 53c ) . The new iterate x ( 1 ) therefore lies between x ( 0 ) and this tangent , but since s 1 must remain positive , x ( 1 ) will 588 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S x s 1 feasible region ( x ( 0 ) , s 1 ( 0 ) ) p 1 p 2 Figure 19 . 2 Problem ( 19 . 53 ) projected onto the x - s 1 plane . lie above the horizontal axis . Thus , from any starting point above the x - axis and to the left of the parabola , namely , in the region { ( x , s 1 , s 2 ) : x 2 − s 1 − 1 ≥ 0 , s 1 ≥ 0 } , ( 19 . 54 ) the new iterate will remain in this region . The argument can now be repeated to show that the iterates { x ( k ) } never leave the region ( 19 . 54 ) and therefore never become feasible . This convergence failure affects any method that generates directions that satisfy the linearization of the constraints ( 19 . 53b ) – ( 19 . 53c ) and that enforces the bounds ( 19 . 53d ) by the fraction to the boundary rule ( 19 . 8 ) . The merit function can only restrict the step length further and is therefore incapable of resolving the difﬁculties . The strategy for updating µ is also irrelevant because the argument given above makes use only of the linearizations of the constraints . ❐ These difﬁculties can be observed when practical line - search codes are applied to the problem ( 19 . 53 ) . For a wide range of starting points in the region ( 19 . 54 ) , the interior - point iteration converges to points of the form ( − β , 0 , 0 ) , with β > 0 . In other words , the iterates can converge to an infeasible , non - optimal point on the boundary of the set { ( x 1 , s 1 , s 2 ) : s 1 ≥ 0 , s 2 ≥ 0 } , a situation that barrier methods are supposed to prevent . Furthermore , such limit points are not stationary for a feasibility measure ( see Deﬁnition 17 . 1 ) . 1 9 . 7 . G L O B A L C O N V E R G E N C E P R O P E R T I E S 589 Failures of this type are rare in practice , but they highlight a theoretical deﬁciency of the algorithmic class ( 19 . 6 ) – ( 19 . 9 ) that may manifest itself more often as inefﬁcient behavior than as outright convergence failure . MODIFIED LINE SEARCH METHODS To remedy this problem , as well as the inefﬁciencies caused by Hessian and constraint Jacobian singularities , we must modify the search direction of the line search interior - point iteration in some circumstances . One option is to use penalizations of the constraints [ 147 ] . Such penalty - barrier methods have been investigated only recently and mature implementations have not yet emerged . An approach that has been successful in practice is to monitor the step lengths α s , α z in ( 19 . 28 ) ; if they are smaller than a given threshold , then we replace the primal - dual step by a step that guarantees progress in feasibility and , preferably , improvement in optimality , too . In a ﬁlter method , when the step lengths are very small , we can invoke the feasibility restoration phase ( see Section 15 . 4 ) , which is designed to generate a new iterate that reduces the infeasibility . A different approach , which assumes that a trust - region algorithm is at hand , is to replace the primal - dual step by a trust - region step , such as that produced by Algorithm 19 . 4 . Safeguarding the primal - dual step when the step lengths are very small is justiﬁed theoretically because , when line search iterations converge to non - stationary points , the step lengths α s , α z converge to zero . From a practical perspective , however , this strategy is not totally satisfactory because it attempts to react when bad steps are generated , rather than trying to prevent them . It also requires the choice of a heuristic to determine when a step length is too small . As we discuss next , the trust - region approach always generates productive steps and needs no safeguarding . GLOBAL CONVERGENCE OF THE TRUST - REGION APPROACH The interior - point trust - region method speciﬁed in Algorithm 19 . 4 has favorable global convergence properties , which we now discuss . For simplicity , we present the analysis in the context of inequality - constrained problems of the form ( 19 . 43 ) . We ﬁrst study the solution of the barrier problem ( 19 . 4 ) for a ﬁxed value of µ , and then consider the complete algorithm . Intheresultthatfollows , B k denotestheHessian ∇ 2 xx L k oraquasi - Newtonapproxima - tion to it . We use the measure of infeasibility h ( x ) (cid:3) (cid:8) [ c ( x ) ] − (cid:8) , where [ y ] (cid:3) max { 0 , − y } . This measure vanishes if and only if x is feasible for problem ( 19 . 43 ) . Note that h ( x ) 2 is differentiable and its gradient is ∇ [ h ( x ) 2 ] (cid:3) 2 A ( x ) c ( x ) − . 590 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S We say that a sequence { x k } is asymptotically feasible if c ( x k ) − → 0 . To apply Algorithm 19 . 4 to a ﬁxed barrier problem , we dispense with the outer “repeat” loop . Theorem 19 . 2 . Suppose that Algorithm 19 . 4 is applied to the barrier problem ( 19 . 4 ) , that is , µ is ﬁxed and the inner “repeat” loop is executed with (cid:9) µ (cid:3) 0 . Suppose that the sequence { f k } is bounded below and the sequences { ∇ f k } , { c k } , { A k } , and { B k } are bounded . Then one of the following three situations occurs : ( i ) The sequence { x k } is not asymptotically feasible . In this case , the iterates approach sta - tionarity of the measure of infeasibility h ( x ) (cid:3) (cid:8) c ( x ) − (cid:8) , meaning that A k c − k → 0 , and the penalty parameters ν k tend to inﬁnity . ( ii ) The sequence { x k } is asymptotically feasible , but the sequence { ( c k , A k ) } has a limit point ( ¯ γ , ¯ A ) failing the linear independence constraint qualiﬁcation . In this situation also , the penalty parameters ν k tend to inﬁnity . ( iii ) The sequence { x k } is asymptotically feasible , and all limit points of the sequence { ( c k , A k ) } satisfy the linear independence constraint qualiﬁcation . In this case , the penalty parameter ν k is constant and c k > 0 for all large indices k , and the stationarity conditions of problem ( 19 . 4 ) are satisﬁed in the limit . This theorem is proved in [ 48 ] , where it is assumed , for simplicity , that (cid:28) is given by the primal choice ( 19 . 14 ) . The theorem accounts for two situations in which the KKT conditions may not be satisﬁed in the limit , both of which are of interest . Outcome ( i ) is a case in which , in the limit , there is no direction that improves feasibility to ﬁrst order . This outcome cannot be ruled out because ﬁnding a feasible point is a problem that a local method cannot always solve without a good starting point . ( Note that we do not assume that the constraint Jacobian A k has full rank . ) In considering outcome ( ii ) , we must keep in mind that in some cases the solution to problem ( 19 . 43 ) is a point where the linear independence constraint qualiﬁcation fails and that is not a KKT point . Outcome ( iii ) is the most desirable outcome and can be monitored in practice by observing , for example , the behavior of the penalty parameter ν k . We now study the complete interior - point method given in Algorithm 19 . 4 applied to the nonlinear programming problem ( 19 . 43 ) . By combining Theorems 19 . 1 and 19 . 2 we see that the following outcomes can occur : • For some barrier parameter µ generated by the algorithm , either the inequality (cid:8) c k − s k (cid:8) ≤ (cid:9) µ is never satisﬁed , in which case the stationarity condition for minimizing h ( x ) is satisﬁed in the limit , or else ( c k − s k ) → 0 , in which case the sequence { ( c k , A k ) } has a limit point ( ¯ c , ¯ A ) failing the linear independence constraint qualiﬁcation ; • At each outer iteration of Algorithm 19 . 4 the inner stop test E ( x k , s k , y k , z k ; µ ) ≤ (cid:9) µ is satisﬁed . Then all limit points of the iteration sequence are feasible . Furthermore , 1 9 . 8 . S U P E R L I N E A R C O N V E R G E N C E 591 if any limit point ˆ x satisﬁes the linear independence constraint qualiﬁcation , the ﬁrst - order necessary conditions for problem ( 19 . 43 ) hold at ˆ x . 19 . 8 SUPERLINEAR CONVERGENCE We can implement primal - dual interior - point methods so that they converge quickly near the solution . All is needed is that we carefully control the decrease in the barrier parameter µ and the inner convergence tolerance (cid:9) µ , and let the parameter τ in ( 19 . 9 ) converge to 1 sufﬁciently rapidly . We now describe strategies for updating these parameters in the context of the line search iteration discussed in Section 19 . 4 ; these strategies extend easily to the trust - region method of Section 19 . 5 . In the discussion that follows , we assume that the merit function or ﬁlter is inactive . This assumption is realistic because with a careful implementation ( which may include second - order correction steps or other features ) , we can ensure that , near a solution , all the steps generated by the primal - dual method are acceptable to the merit function or ﬁlter . We denote the primal - dual iterates by v (cid:3) ( x , s , y , z ) ( 19 . 55 ) and deﬁne the full primal - dual step ( without backtracking ) by v + (cid:3) v + p , ( 19 . 56 ) where p is the solution of ( 19 . 12 ) . To establish local convergence results , we assume that the iterates converge to a solution point satisfying certain regularity assumptions . Assumptions 19 . 1 . ( a ) v ∗ is a solution of the nonlinear program ( 19 . 1 ) for which the ﬁrst - order KKT conditions are satisﬁed . ( b ) The Hessian matrices ∇ 2 f ( x ) and ∇ 2 c i ( x ) , i ∈ E ∪ I , are locally Lipschitz continuous at v ∗ . ( c ) The linear independence constraint qualiﬁcation ( LICQ ) ( Deﬁnition 12 . 4 ) , the strict complementarity condition ( Deﬁnition 12 . 5 ) , and the second - order sufﬁcient conditions ( Theorem 12 . 6 ) hold at v ∗ . We assume that v is an iterate at which the inner stop test E ( v , µ ) ≤ (cid:9) µ is satisﬁed , so that the barrier parameter is decreased from µ to µ + . We now study how to control the parameters in Algorithm 19 . 2 so that the following three properties hold in a neighborhood of v ∗ : 592 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S 1 . The iterate v + satisﬁes the fraction to the boundary rule ( 19 . 9 ) , that is , α max s (cid:3) α max z (cid:3) 1 . 2 . The inner stop test is satisﬁed at v + , that is , E ( v + ; µ + ) ≤ (cid:9) µ + . 3 . The sequence of iterates ( 19 . 56 ) converge superlinearly to v ∗ . We can achieve these three goals by letting (cid:9) µ (cid:3) θµ and (cid:9) µ + (cid:3) θµ + , ( 19 . 57 ) for θ > 0 , and setting the other parameters as follows : µ + (cid:3) µ 1 + δ , δ ∈ ( 0 , 1 ) ; τ (cid:3) 1 − µ β , β > δ . ( 19 . 58 ) There are other practical ways of controlling the parameters of the algorithm . For example , we may prefer to determine the change in µ from the reduction achieved in the KKT conditions of the nonlinear program , as measured by the function E . The three results mentioned above can be established if the convergence tolerance (cid:9) µ is deﬁned as in ( 19 . 57 ) and if we replace µ by E ( v ; 0 ) in the right - hand sides of the deﬁnitions ( 19 . 58 ) of µ + and τ . There is a limit to how fast we can decrease µ and still be able to satisfy the inner stop test after just one iteration ( condition 2 ) . One can show that there is no point in decreasing µ at a faster than quadratic rate , since the overall convergence cannot be faster than quadratic . Not suprising , if τ is constant and µ + (cid:3) σµ , with σ ∈ ( 0 , 1 ) , then the interior - point algorithm is only linearly convergent . Although it is desirable to implement interior - point methods so that they achieve a superlinear rate of convergence , this rate is typically observed only in the last few iterations in practice . 19 . 9 PERSPECTIVES AND SOFTWARE Software packages that implement nonlinear interior - point methods are widely available . Line search implementations include LOQO [ 294 ] , KNITRO / DIRECT [ 303 ] , IPOPT [ 301 ] , and BARNLP [ 21 ] , and for convex problems , MOSEK [ 5 ] . The trust - region algorithm discussed in Section 19 . 5 has been implemented in KNITRO / CG [ 50 ] . These interior - point packages have proved to be strong competitors of the leading active - set and augmented Lagrangian pack - ages , such as MINOS [ 218 ] , SNOPT [ 128 ] , LANCELOT [ 72 ] , FILTERSQP [ 105 ] , and KNITRO / ACTIVE [ 49 ] . At present , interior - point and active - set methods appear to be the most promising approaches , while augmented Lagrangian methods seem to be less efﬁcient . The KNITRO package provides crossover from interior - point to active - set modes [ 46 ] . Interior - point methods show their strength in large - scale applications , where they often ( but not always ) outperform active - set methods . In interior - point methods , the linear 1 9 . 9 . P E R S P E C T I V E S A N D S O F T W A R E 593 system to be solved at every iteration has the same block structure , so effort can be focused on exploiting this structure . Both direct factorization techniques and projected CG methods are available , allowing the user to solve many types of applications efﬁciently . On the other hand , interior - point methods , unlike active - set methods , consider all the constraints at each iteration , even if they are irrelevant to the solution . As a result , the cost of the primal - dual iteration can be excessive in some applications . One of the main weaknesses of interior - point methods is their sensitivity to the choice oftheinitialpoint , thescalingoftheproblem , andtheupdatestrategyforthebarrierparame - ter µ . If the iterates approach the boundary of the feasible region prematurely , interior - point methods may have difﬁculty escaping it , and convergence can be slow . The availability of adaptive strategies for updating µ is , however , beginning to lessen this sensitivity , and more robust implementations can be expected in the coming years . Although the description of the line search algorithm in Section 19 . 4 is fairly complete , various details of implementation ( such as second - order corrections , iterative reﬁnement , and resetting of parameters ) are needed to obtain a robust code . Our description of the trust - region method of Algorithm 19 . 4 leaves some important details unspeciﬁed , particularly concerningtheprocedureforcomputingapproximatesolutionsofthenormalandtangential subproblems ; see [ 50 ] for further discussion . The KNITRO / CG implementation of this trust - region algorithm uses a projected CG iteration in the computation of the step , which allows the method to work even when only Hessian – vector products are available , not the Hessian itself . Filters and merit functions have each been used to globalize interior - point methods . Although some studies have shown that merit functions restrict the progress of the iteration unduly [ 298 ] , recent developments in penalty update procedures ( see Chapter 18 ) have altered the picture , and it is currently unclear whether ﬁlter globalization approaches are preferable . NOTES AND REFERENCES The development of modern nonlinear interior - point methods was inﬂuenced by the success of interior - point methods for linear and quadratic programming . The concept of primal - dual steps arises from the homotopy formulation given in Section 19 . 1 , which is an extension of the systems ( 14 . 13 ) and ( 16 . 57 ) for linear and quadratic programming . Although the primal barrier methods of Section 19 . 6 predate primal - dual methods by at least 15 years , they played a limited role in their development . There is a vast literature on nonlinear interior - point methods . We refer the reader to the surveys by Forsgren , Gill , and Wright [ 111 ] and Gould , Orban , and Toint [ 147 ] for a comprehensive list of references . The latter paper also compares and contrasts interior - point methods with other nonlinear optimization methods . For an analysis of interior - point methods that use ﬁlter globalization see , for example , Ulbrich , Ulbrich , and Vicente [ 291 ] and W¨achter and Biegler [ 300 ] . The book by Conn , Gould , and Toint [ 74 ] gives a thorough presentation of several interior - point methods . 594 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S Primal barrier methods were originally proposed by Frisch [ 115 ] and were analyzed in an authoritative book by Fiacco and McCormick [ 98 ] . The term “interior - point method” and the concept of the primal central path C p appear to have originated in this book . Nesterov and Nemirovskii [ 226 ] propose and analyze several families of barrier methods and establish polynomial - time complexity results for very general classes of problems such as semideﬁnite and second - order cone programming . For a discussion of the history of barrier function methods , see Nash [ 221 ] . ✐ E X E R C I S E S ✐ 19 . 1 Consider the nonlinear program min f ( x ) subject to c E ( x ) (cid:3) 0 , c I ( x ) ≥ 0 . ( 19 . 59 ) ( a ) Write down the KKT conditions of ( 19 . 1 ) and ( 19 . 59 ) , and establish a one - to - one correspondence between KKT points of these problems ( despite the different numbers of variables and multipliers ) . ( b ) The multipliers z correspond to the equality constraints ( 19 . 1c ) and should therefore be unsigned . Nonetheless , argue that ( 19 . 2 ) with µ (cid:3) 0 together with ( 19 . 3 ) can be seen as the KKT conditions of problem ( 19 . 1 ) . Moreover , argue that the multipliers z in ( 19 . 2 ) can be seen as the multipliers of the inequalities c I in ( 19 . 59 ) . ( c ) Suppose ¯ x is feasible for ( 19 . 59 ) . Show that LICQ holds at ¯ x for ( 19 . 59 ) if and only if LICQ holds at ( ¯ x , ¯ s ) for ( 19 . 1 ) , with ¯ s (cid:3) c I ( ¯ x ) . ( d ) Repeat part ( c ) assuming that the MFCQ condition holds ( see Deﬁnition 12 . 6 ) instead of LICQ . ✐ 19 . 2 This question concerns Algorithm 19 . 1 . ( a ) Extend the proof of Theorem 19 . 1 to the general nonlinear program ( 19 . 1 ) . ( b ) Show that the theorem still holds if the condition E ( x k , s k , y k , z k ) ≤ µ k is replaced by E ( x k , s k , y k , z k ) ≤ (cid:9) µ k , for any sequence (cid:9) µ k that converges to 0 as µ k → 0 . ( c ) Suppose that in Algorithm 19 . 1 the new iterate ( x k + 1 , s k + 1 , y k + 1 , z k + 1 ) is obtained by any means . What conditions are required on this iterate so that Theorem 19 . 1 holds ? ✐ 19 . 3 Consider the nonlinear system of equations ( 11 . 1 ) . Show that Newton’s method ( 11 . 6 ) is invariant to scalings of the equations . More precisely , show that the Newton step p does not change if each component of r is multiplied by a nonzero constant . 1 9 . 9 . P E R S P E C T I V E S A N D S O F T W A R E 595 ✐ 19 . 4 Consider the system x 1 + x 2 − 2 (cid:3) 0 , x 1 x 2 − 2 x 22 + 1 (cid:3) 0 . Find all the solutions to this system . Show that if the ﬁrst equation is multiplied by x 2 , the solutions do not change but the Newton step taken from ( 1 , − 1 ) will not be the same as that for the original system . ✐ 19 . 5 Let ( x , s , y , z ) be a primal - dual solution that satisﬁes the LICQ and strict complementarity conditions . ( a ) Give conditions on ∇ 2 xx c L ( x , s , y , z ) thatensure that the primal - dual matrix in ( 19 . 6 ) is nonsingular . ( b ) Show that some diagonal elements of (cid:28) tend to inﬁnity and others tend to zero when µ → 0 . Can you characterize each case ? Consider the cases in which (cid:28) is deﬁned by ( 19 . 13 ) and ( 19 . 14 ) . ( c ) Argue that the matrix in ( 19 . 6 ) is not ill conditioned under the assumptions of this problem . ✐ 19 . 6 ( a ) Introduce the change of variables ˜ p s (cid:3) S − 1 p s in ( 19 . 12 ) , and show that the ( 2 , 2 ) block of the primal - dual matrix has a cluster of eigenvalues around 0 when µ → 0 . ( b ) Analyze the eigenvalue distribution of the ( 2 , 2 ) block if the change of variables is given by ˜ p s (cid:3) (cid:28) 1 / 2 p s or ˜ p s (cid:3) √ µ S − 1 p s . ( c ) Let γ > 0 be the smallest eigenvalue of ∇ 2 xx c L . Describe a change of variables for which all the eigenvalues of the ( 2 , 2 ) block converge to γ as µ → 0 . ✐ 19 . 7 Program the simple interior - point method Algorithm 19 . 1 and apply it to the problem ( 18 . 69 ) . Use the same starting point as in that problem . Try different values for the parameter σ . ✐ 19 . 8 ( a ) Compute the minimum - norm solution of the system of equations deﬁned by ( 19 . 35 ) . ( This system deﬁnes the Newton component in the dogleg method used to ﬁnd an ap - proximate solution to ( 19 . 34 ) . ) Show that the computation of the Newton component can use the factorization of the augmented matrix deﬁned in ( 19 . 36 ) . ( b ) Compute the unconstrained minimizer of the quadratic in ( 19 . 34a ) along the steepest descent direction , starting from v (cid:3) 0 . ( This minimizer deﬁnes the Cauchy component in the dogleg method used to ﬁnd an approximate solution to ( 19 . 34 ) . ) 596 C H A P T E R 1 9 . N O N L I N E A R I N T E R I O R M E T H O D S ( c ) The dogleg step is a combination of the Newton and Cauchy steps from parts ( a ) and ( b ) . Show that the dogleg step is in the range space of ˆ A T . ✐ 19 . 9 ( a ) If the normal subproblem ( 19 . 34a ) – ( 19 . 34c ) is solved by using the dogleg method , show that the solution v is in the range space of matrix ˆ A T deﬁned in ( 19 . 36 ) . ( b ) After the normal step v is obtained , we deﬁne the residual vectors r E and r I as in ( 19 . 35 ) and w (cid:3) ˜ p − v . Show that ( 19 . 33 ) becomes a quadratic program with circular trust - region constraint and bound constraint in the variables w . ( c ) Show that the solution w of the problem derived in part ( b ) is orthogonal to the normal step v , that is , that w T v (cid:3) 0 . ✐ 19 . 10 Verify that the least - squares multiplier formula ( 18 . 21 ) corresponding to ( 19 . 33a ) – ( 19 . 33c ) is given by ( 19 . 37 ) . ✐ 19 . 11 ( a ) Write the primal - dual system ( 19 . 6 ) for problem ( 19 . 53 ) , considering s 1 , s 2 as slacks and denoting the multipliers of ( 19 . 53b ) , ( 19 . 53c ) by z 1 , z 2 . ( You should get a system of ﬁve equations with ﬁve unknowns . ) Show that the matrix of the system is singular at any iterate of the form ( x , 0 , 0 ) . ( b ) Show that if the starting point in Example ( 19 . 53 ) lies in the region ( 19 . 54 ) , the interior - point step leads to a point on the tangent line to the parabola , as illustrated in Figure 19 . 2 . ( More speciﬁcally , show that the tangent line never lies to the left of the parabola . ) ( c ) Let x ( 0 ) (cid:3) − 2 , s ( 0 ) 1 (cid:3) 1 , s ( 0 ) 2 (cid:3) 1 , let z ( 0 ) 1 (cid:3) z ( 0 ) 2 (cid:3) 1 , and let µ (cid:3) 0 . Compute the full Newton step based on the system in part ( a ) . Truncate , if necessary , to satisfy a fraction to the boundary rule with τ (cid:3) 1 . Verify that the new iterate is still in the region ( 19 . 54 ) . ( d ) Let us the consider the behavior of an SQP method . For the initial point in ( c ) , show that the linearized constraints of problem ( 18 . 56 ) ( don’t forget the constraints s 1 ≥ 0 , s 2 ≥ 0 ) areinconsistent . Therefore , theSQPsubproblem ( 18 . 11 ) isinconsistent , and a relaxation of the constraint of the SQP subproblem must be performed . ✐ 19 . 12 Consider the following problem in a single variable x : min x subject to x ≥ 0 , 1 − x ≥ 0 . ( a ) Write the primal barrier function P ( x ; µ ) associated with this problem . ( b ) Plot the barrier function for different values of µ . 1 9 . 9 . P E R S P E C T I V E S A N D S O F T W A R E 597 ( c ) Characterize the minimizers of the barrier function as a function of µ and consider the limit as µ goes to 0 . ✐ 19 . 13 Consider the scalar minimization problem min x 1 1 + x 2 , subject to x ≥ 1 . Write down P ( x ; µ ) for this problem , and show that P ( x ; µ ) is unbounded below for any positive value of µ . ( See Powell [ 242 ] and M . Wright [ 313 ] . ) ✐ 19 . 14 The goal of this exercise is to describe an efﬁcient implementation of the limited - memory BFGS version of the interior - point method using the compact representation ( 19 . 29 ) . First we decompose the primal - dual matrix as ⎡ ⎢⎢⎢⎢⎣ ξ I 0 A E T A I T 0 (cid:28) 0 I A E 0 0 0 A I I 0 0 ⎤ ⎥⎥⎥⎥⎦ + ⎡ ⎢⎢⎢⎢⎣ W 0 0 0 ⎤ ⎥⎥⎥⎥⎦ (cid:9) MW T 0 0 0 (cid:10) . ( 19 . 60 ) Use the Sherman – Morrison – Woodbury formula to express the inverse ( 19 . 60 ) . Then show that the primal - dual step ( 19 . 12 ) requires the solution of systems of the form C v (cid:3) b , where C is the left matrix in ( 19 . 60 ) and v and b are certain vectors . This is pag Printer : O A P P E N D I X A Background Material A . 1 ELEMENTS OF LINEAR ALGEBRA VECTORS AND MATRICES In this book we work exclusively with vectors and matrices whose components are real numbers . Vectors are usually denoted by lowercase roman characters , and matrices by uppercase roman characters . The space of real vectors of length n is denoted by IR n , while the space of real m × n matrices is denoted by IR m × n . A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 599 Given a vector x ∈ IR n , we use x i to denote its i th component . We invariably assume that x is a column vector , that is , x (cid:3) ⎡ ⎢⎢⎢⎢⎢ ⎣ x 1 x 2 . . . x n ⎤ ⎥⎥⎥⎥⎥ ⎦ . The transpose of x , denoted by x T is the row vector x T (cid:3) (cid:9) x 1 x 2 · · · x n (cid:10) , and is often also written with parentheses as x (cid:3) ( x 1 , x 2 , . . . , x n ) . We write x ≥ 0 to indicate componentwise nonnegativity , that is , x i ≥ 0 for all i (cid:3) 1 , 2 , . . . , n , while x > 0 indicates that x i > 0 for all i (cid:3) 1 , 2 , . . . , n . Given x ∈ IR n and y ∈ IR n , the standard inner product is x T y (cid:3) (cid:4) ni (cid:3) 1 x i y i . Given a matrix A ∈ IR m × n , we specify its components by double subscripts as A ij , for i (cid:3) 1 , 2 , . . . , m and j (cid:3) 1 , 2 , . . . , n . The transpose of A , denoted by A T , is the n × m matrix whose components are A ji . The matrix A is said to be square if m (cid:3) n . A square matrix is symmetric if A (cid:3) A T . A square matrix A is positive deﬁnite if there is a positive scalar α such that x T Ax ≥ α x T x , for all x ∈ IR n . ( A . 1 ) It is positive semideﬁnite if x T Ax ≥ 0 , for all x ∈ IR n . We can recognize that a symmetric matrix is positive deﬁnite by computing its eigenvalues and verifying that they are all positive , or by performing a Cholesky factorization . Both techniques are discussed further in later sections . The diagonal of the matrix A ∈ IR m × n consists of the elements A ii , for i (cid:3) 1 , 2 , . . . min ( m , n ) . The matrix A ∈ IR m × n is lower triangular if A ij (cid:3) 0 whenever i < j ; that is , all elements above the diagonal are zero . It is upper triangular if A ij (cid:3) 0 whenever i > j ; that is , all elements below the diagonal are zero . A is diagonal if A ij (cid:3) 0 whenever i (cid:9)(cid:3) j . The identity matrix , denoted by I , is the square diagonal matrix whose diagonal elements are all 1 . A square n × n matrix A is nonsingular if for any vector b ∈ IR n , there exists x ∈ IR n such that Ax (cid:3) b . For nonsingular matrices A , there exists a unique n × n matrix B such that AB (cid:3) B A (cid:3) I . We denote B by A − 1 and call it the inverse of A . It is not hard to show that the inverse of A T is the transpose of A − 1 . A square matrix Q is orthogonal if it has the property that QQ T (cid:3) Q T Q (cid:3) I . In other words , the inverse of an orthogonal matrix is its transpose . 600 A P P E N D I X A . B A C K G R O U N D M A T E R I A L NORMS For a vector x ∈ IR n , we deﬁne the following norms : (cid:8) x (cid:8) 1 def (cid:3) n (cid:3) i (cid:3) 1 | x i | , ( A . 2a ) (cid:8) x (cid:8) 2 def (cid:3) (cid:24) n (cid:3) i (cid:3) 1 x 2 i (cid:25) 1 / 2 (cid:3) ( x T x ) 1 / 2 , ( A . 2b ) (cid:8) x (cid:8) ∞ def (cid:3) max i (cid:3) 1 , . . . , n | x i | . ( A . 2c ) The norm (cid:8) · (cid:8) 2 is often called the Euclidean norm . We sometimes refer to (cid:8) · (cid:8) 1 as the (cid:1) 1 norm and to (cid:8) · (cid:8) ∞ as the (cid:1) ∞ norm . All these norms measure the length of the vector in some sense , and they are equivalent in the sense that each one is bounded above and below by a multiple of the other . To be precise , we have for all x ∈ IR n that (cid:8) x (cid:8) ∞ ≤ (cid:8) x (cid:8) 2 ≤ √ n (cid:8) x (cid:8) ∞ , (cid:8) x (cid:8) ∞ ≤ (cid:8) x (cid:8) 1 ≤ n (cid:8) x (cid:8) ∞ , ( A . 3 ) and so on . In general , a norm is any mapping (cid:8) · (cid:8) from IR n to the nonnegative real numbers that satisﬁes the following properties : (cid:8) x + z (cid:8) ≤ (cid:8) x (cid:8) + (cid:8) z (cid:8) , for all x , z ∈ IR n ; ( A . 4a ) (cid:8) x (cid:8) (cid:3) 0 ⇒ x (cid:3) 0 ; ( A . 4b ) (cid:8) α x (cid:8) (cid:3) | α | (cid:8) x (cid:8) , for all α ∈ IR and x ∈ IR n . ( A . 4c ) Equality holds in ( A . 4a ) if and only if one of the vectors x and z is a nonnegative scalar multiple of the other . Another interesting property that holds for the Euclidean norm (cid:8) · (cid:8) (cid:3) (cid:8) · (cid:8) 2 is the Cauchy – Schwarz inequality , which states that (cid:28)(cid:28) x T z (cid:28)(cid:28) ≤ (cid:8) x (cid:8) (cid:8) z (cid:8) , ( A . 5 ) with equality if and only if one of these vectors is a nonnegative multiple of the other . We can prove this result as follows : 0 ≤ (cid:8) α x + z (cid:8) 2 (cid:3) α 2 (cid:8) x (cid:8) 2 + 2 α x T z + (cid:8) z (cid:8) 2 . The right - hand - side is a convex function of α , and it satisﬁes the required nonnegativity property only if there exist fewer than 2 distinct real roots , that is , ( 2 x T z ) 2 ≤ 4 (cid:8) x (cid:8) 2 (cid:8) z (cid:8) 2 , A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 601 proving ( A . 5 ) . Equality occurs when the quadratic α has exactly one real root ( that is , | x T z | (cid:3) (cid:8) x (cid:8) (cid:8) z (cid:8) ) and when α x + z (cid:3) 0 for some α , as claimed . Any norm (cid:8) · (cid:8) has a dual norm (cid:8) · (cid:8) D deﬁned by (cid:8) x (cid:8) D (cid:3) max (cid:8) y (cid:8)(cid:3) 1 x T y . ( A . 6 ) It is easy to show that the norms (cid:8) · (cid:8) 1 and (cid:8) · (cid:8) ∞ are duals of each other , and that the Euclidean norm is its own dual . We can derive deﬁnitions for certain matrix norms from these vector norm deﬁni - tions . If we let (cid:8) · (cid:8) be generic notation for the three norms listed in ( A . 2 ) , we deﬁne the corresponding matrix norm as (cid:8) A (cid:8) def (cid:3) sup x (cid:9)(cid:3) 0 (cid:8) Ax (cid:8) (cid:8) x (cid:8) . ( A . 7 ) The matrix norms deﬁned in this way are said to be consistent with the vector norms ( A . 2 ) . Explicit formulae for these norms are as follows : (cid:8) A (cid:8) 1 (cid:3) max j (cid:3) 1 , . . . , n m (cid:3) i (cid:3) 1 | A ij | , ( A . 8a ) (cid:8) A (cid:8) 2 (cid:3) largest eigenvalue of ( A T A ) 1 / 2 , ( A . 8b ) (cid:8) A (cid:8) ∞ (cid:3) max i (cid:3) 1 , . . . , m n (cid:3) j (cid:3) 1 | A ij | . ( A . 8c ) The Frobenius norm (cid:8) A (cid:8) F of the matrix A is deﬁned by (cid:8) A (cid:8) F (cid:3) ⎛ ⎝ m (cid:3) i (cid:3) 1 n (cid:3) j (cid:3) 1 A 2 ij ⎞ ⎠ 1 / 2 . ( A . 9 ) This norm is useful for many purposes , but it is not consistent with any vector norm . Once again , these various matrix norms are equivalent with each other in a sense similar to ( A . 3 ) . For the Euclidean norm (cid:8) · (cid:8) (cid:3) (cid:8) · (cid:8) 2 , the following property holds : (cid:8) AB (cid:8) ≤ (cid:8) A (cid:8) (cid:8) B (cid:8) , ( A . 10 ) for all matrices A and B with consistent dimensions . The condition number of a nonsingular matrix is deﬁned as κ ( A ) (cid:3) (cid:8) A (cid:8) (cid:8) A − 1 (cid:8) , ( A . 11 ) 602 A P P E N D I X A . B A C K G R O U N D M A T E R I A L where any matrix norm can be used in the deﬁnition . Different norms can by the use of a subscript— κ 1 ( · ) , κ 2 ( · ) , and κ ∞ ( · ) , respectively—with κ denoting κ 2 by default . Norms also have a meaning for scalar , vector , and matrix - valued functions that are deﬁned on a particular domain . In these cases , we can deﬁne Hilbert spaces of functions for which the inner product and norm are deﬁned in terms of an integral over the domain . We omit details , since all the development of this book takes place in the space IR n , though many of the algorithms can be extended to more general Hilbert spaces . However , we mention for purposes of the analysis of Newton - like methods that the following inequality holds for functions of the type that we consider in this book : (cid:23)(cid:23)(cid:23)(cid:23)(cid:6) b a F ( t ) (cid:23)(cid:23)(cid:23)(cid:23) ≤ (cid:6) b a (cid:8) F ( t ) (cid:8) dt , ( A . 12 ) where F is a continuous scalar - , vector - , or matrix - valued function on the interval [ a , b ] . SUBSPACES Given the Euclidean space IR n , the subset S ⊂ IR n is a subspace of IR n if the following property holds : If x and y are any two elements of S , then α x + β y ∈ S , for all α , β ∈ IR . For instance , S is a subspace of IR 2 if it consists of ( i ) the whole space IR n ; ( ii ) any line passing through the origin ; ( iii ) the origin alone ; or ( iv ) the empty set . Given any set of vectors a i ∈ IR n , i (cid:3) 1 , 2 , . . . , m , the set S (cid:3) 2 w ∈ IR n | a Ti w (cid:3) 0 , i (cid:3) 1 , 2 , . . . , m 3 ( A . 13 ) is a subspace . However , the set 2 w ∈ IR n | a Ti w ≥ 0 , i (cid:3) 1 , 2 , . . . , m 3 ( A . 14 ) is not in general a subspace . For example , if we have n (cid:3) 2 , m (cid:3) 1 , and a 1 (cid:3) ( 1 , 0 ) T , this set would consist of all vectors ( w 1 , w 2 ) T with w 1 ≥ 0 , but then given two vectors x (cid:3) ( 1 , 0 ) T and y (cid:3) ( 2 , 3 ) in this set , it is easy to choose multiples α and β such that α x + β y has a negative ﬁrst component , and so lies outside the set . Sets of the forms ( A . 13 ) and ( A . 14 ) arise in the discussion of second - order optimality conditions for constrained optimization . A set of vectors { s 1 , s 2 , . . . , s m } in IR n is called a linearly independent set if there are no real numbers α 1 , α 2 , . . . , α m such that α 1 s 2 + α 2 s 2 + · · · + α m s m (cid:3) 0 , A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 603 unless we make the trivial choice α 1 (cid:3) α 2 (cid:3) · · · (cid:3) α m (cid:3) 0 . Another way to deﬁne linear independence is to say that none of the vectors s 1 , s 2 , . . . , s m can be written as a linear combination of the other vectors in this set . If in fact we have s i ∈ S for all i (cid:3) 1 , 2 , . . . , m , we say that { s 1 , s 2 , . . . , s m } is a spanning set for S if any vector s ∈ S can be written as s (cid:3) α 1 s 2 + α 2 s 2 + · · · + α m s m , for some particular choice of the coefﬁcients α 1 , α 2 , . . . , α m . If the vectors s 1 , s 2 , . . . , s m are both linearly independent and a spanning set for S , we call them a basis of S . In this case , m ( the number of elements in the basis ) is referred to as the dimension of S , and denoted by dim ( S ) . Note that there are many ways to choose a basis of S in general , but that all bases contain the same number of vectors . If A is any real matrix , the null space is the subspace Null ( A ) (cid:3) { w | A w (cid:3) 0 } , while the range space is Range ( A ) (cid:3) { w | w (cid:3) A v for some vector v } . The fundamental theorem of linear algebra states that Null ( A ) ⊕ Range ( A T ) (cid:3) IR n , where n is the number of columns in A . ( Here , “ ⊕ ” denotes the direct sum of two sets : A ⊕ B (cid:3) { x + y | x ∈ A , y ∈ B } . ) When A is square ( n × n ) and nonsingular , we have Null A (cid:3) Null A T (cid:3) { 0 } and Range A (cid:3) Range A T (cid:3) IR n . In this case , the columns of A form a basis of IR n , as do the columns of A T . EIGENVALUES , EIGENVECTORS , AND THE SINGULAR - VALUE DECOMPOSITION A scalar value λ is an eigenvalue of the n × n matrix A if there is a nonzero vector q such that Aq (cid:3) λ q . The vector q is called an eigenvector of A . The matrix A is nonsingular if none of its eigenvalues are zero . The eigenvalues of symmetric matrices are all real numbers , while nonsymmetric matrices may have imaginary eigenvalues . If the matrix is positive deﬁnite as well as symmetric , its eigenvalues are all positive real numbers . 604 A P P E N D I X A . B A C K G R O U N D M A T E R I A L All matrices A ( not necessarily square ) can be decomposed as a product of three matrices with special properties . When A ∈ IR m × n with m > n , ( that is , A has more rows than columns ) , this singular - value decomposition ( SVD ) has the form A (cid:3) U (cid:1) S 0 (cid:2) V T , ( A . 15 ) where U and V are orthogonal matrices of dimension m × m and n × n , respectively , and S is an n × n diagonal matrix with diagonal elements σ i , i (cid:3) 1 , 2 , . . . , n , that satisfy σ 1 ≥ σ 2 ≥ · · · ≥ σ n ≥ 0 . These diagonal values are called the singular values of A . We can deﬁne the condition number ( A . 11 ) of the m × n ( possibly nonsquare ) matrix A to be σ 1 / σ n . ( This deﬁnition is identical to κ 2 ( A ) when A happens to be square and nonsingular . ) When m ≤ n ( the number of columns is at least equal to the number of rows ) , the SVD has the form A (cid:3) U (cid:9) S 0 (cid:10) V T , where again U and V are orthogonal of dimension m × m and n × n , respectively , while S is m × m diagonal with nonnegative diagonal elements σ 1 ≥ σ 2 ≥ · · · ≥ σ m . When A is symmetric , its n real eigenvalues λ 1 , λ 2 , . . . , λ n and their associated eigenvectors q 1 , q 2 , . . . , q n can be used to write a spectral decomposition of A as follows : A (cid:3) n (cid:3) i (cid:3) 1 λ i q i q Ti . This decomposition can be restated in matrix form by deﬁning (cid:16) (cid:3) diag ( λ 1 , λ 2 , · · · , λ n ) , Q (cid:3) [ q 1 | q 2 | . . . | q n ] , and writing A (cid:3) Q (cid:16) Q T . ( A . 16 ) In fact , when A is positive deﬁnite as well as symmetric , this decomposition is identical to the singular - value decomposition ( A . 15 ) , where we deﬁne U (cid:3) V (cid:3) Q and S (cid:3) (cid:16) . Note that the singular values σ i and the eigenvalues λ i coincide in this case . A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 605 In the case of the Euclidean norm ( A . 8b ) , we have for symmetric positive deﬁnite matrices A that the singular values and eigenvalues of A coincide , and that (cid:8) A (cid:8) (cid:3) σ 1 ( A ) (cid:3) largest eigenvalue of A , (cid:8) A − 1 (cid:8) (cid:3) σ n ( A ) − 1 (cid:3) inverse of smallest eigenvalue of A . Hence , we have for all x ∈ IR n that σ n ( A ) (cid:8) x (cid:8) 2 (cid:3) (cid:8) x (cid:8) 2 / (cid:8) A − 1 (cid:8) ≤ x T Ax ≤ (cid:8) A (cid:8)(cid:8) x (cid:8) 2 (cid:3) σ 1 ( A ) (cid:8) x (cid:8) 2 . For an orthogonal matrix Q , we have for the Euclidean norm that (cid:8) Qx (cid:8) (cid:3) (cid:8) x (cid:8) , and that all the singular values of this matrix are equal to 1 . DETERMINANT AND TRACE The trace of an n × n matrix A is deﬁned by trace ( A ) (cid:3) n (cid:3) i (cid:3) 1 A ii . ( A . 17 ) If the eigenvalues of A are denoted by λ 1 , λ 2 , . . . , λ n , it can be shown that trace ( A ) (cid:3) n (cid:3) i (cid:3) 1 λ i , ( A . 18 ) that is , the trace of the matrix is the sum of its eigenvalues . The determinant of an n × n matrix A , denoted by det A , is the product of its eigenvalues ; that is , det A (cid:3) n 1 i (cid:3) 1 λ i . ( A . 19 ) The determinant has several appealing ( and revealing ) properties . For instance , det A (cid:3) 0 if and only if A is singular ; det AB (cid:3) ( det A ) ( det B ) ; det A − 1 (cid:3) 1 / det A . 606 A P P E N D I X A . B A C K G R O U N D M A T E R I A L Recall that any orthogonal matrix A has the property that QQ T (cid:3) Q T Q (cid:3) I , so that Q − 1 (cid:3) Q T . It follows from the property of the determinant that det Q (cid:3) det Q T (cid:3) ± 1 . The properties above are used in the analysis of Chapter 6 . MATRIX FACTORIZATIONS : CHOLESKY , LU , QR Matrix factorizations are important both in the design of algorithms and in their analysis . One such factorization is the singular - value decomposition deﬁned above in ( A . 15 ) . Here we deﬁne the other important factorizations . All the factorization algorithms described below make use of permutation matrices . Suppose that we wish to exchange the ﬁrst and fourth rows of a matrix A . We can perform this operation by premultiplying A by a permutation matrix P , which is constructed by interchanging the ﬁrst and fourth rows of an identity matrix that contains the same number of rows as A . Suppose , for example , that A is a 5 × 5 matrix . The appropriate choice of P would be P (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎣ 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 ⎤ ⎥⎥⎥⎥⎥⎥⎥⎦ . A similar technique is used to to ﬁnd a permutation matrix P that exchanges columns of a matrix . The LU factorization of a matrix A ∈ IR n × n is deﬁned as P A (cid:3) LU , ( A . 20 ) where P is an n × n permutation matrix ( that is , it is obtained by rearranging the rows of the n × n identity matrix ) , L is unit lower triangular ( that is , lower triangular with diagonal elements equal to 1 , and U is upper triangular . This factorization can be used to solve a linear system of the form Ax (cid:3) b efﬁciently by the following three - step process : form ˜ b (cid:3) Pb by permuting the elements of b ; solve Lz (cid:3) ˜ b by performing triangular forward - substitution , to obtain the vector z ; A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 607 solve Ux (cid:3) z by performing triangular back - substitution , to obtain the solution vector x . The factorization ( A . 20 ) can be found by using Gaussian elimination with row partial pivoting , an algorithm that requires approximately 2 n 3 / 3 ﬂoating - point operations when A is dense . Standard software that implements this algorithm ( notably , LAPACK [ 7 ] ) is readily available . The method can be stated as follows . Algorithm A . 1 ( Gaussian Elimination with Row Partial Pivoting ) . Given A ∈ IR n × n ; Set P ← I , L ← 0 ; for i (cid:3) 1 , 2 , . . . , n ﬁnd the index j ∈ { i , i + 1 , . . . , n } such that | A ji | (cid:3) max k (cid:3) i , i + 1 , . . . , n | A ki | ; if A ij (cid:3) 0 stop ; ( ∗ matrix A is singular ∗ ) if i (cid:9)(cid:3) j swap rows i and j of matrices A and L ; ( ∗ elimination step ∗ ) L ii ← 1 ; for k (cid:3) i + 1 , i + 2 , . . . , n L ki ← A ki / A ii ; for l (cid:3) i + 1 , i + 2 , . . . , n A kl ← A kl − L ki A il ; end ( for ) end ( if ) end ( for ) U ← upper triangular part of A . Variants of the basic algorithm allow for rearrangement of the columns as well as the rows during the factorization , but these do not add to the practical stability properties of the algorithm . Column pivoting may , however , improve the performance of Gaussian elimination when the matrix A is sparse . by ensuring that the factors L and U are also reasonably sparse . Gaussian elimination can be applied also to the case in which A is not square . When A is m × n , with m > n , the standard row pivoting algorithm produces a factorization of the form ( A . 20 ) , where L ∈ IR m × n is unit lower triangular and U ∈ IR n × n is upper triangular . When m < n , we can ﬁnd an LU factorization of A T rather than A , that is , we obtain P A T (cid:3) (cid:1) L 1 L 2 (cid:2) U , ( A . 21 ) where L 1 is m × m ( square ) unit lower triangular , U is m × m upper triangular , and L 2 is a general ( n − m ) × m matrix . If A has full row rank , we can use this factorization to calculate 608 A P P E N D I X A . B A C K G R O U N D M A T E R I A L its null space explicitly as the space spanned by the columns of the matrix M (cid:3) P T (cid:1) L − T 1 L T 2 − I (cid:2) U − T . ( A . 22 ) It is easy to check that M has dimensions n × ( n − m ) and that AM (cid:3) 0 . When A ∈ IR n × n is symmetric positive deﬁnite , it is possible to compute a similar but more specialized factorization at about half the cost—about n 3 / 3 operations . This factorization , known as the Cholesky factorization , produces a matrix L such that A (cid:3) LL T . ( A . 23 ) ( If we require L to have positive diagonal elements , it is uniquely deﬁned by this formula . ) The algorithm can be speciﬁed as follows . Algorithm A . 2 ( Cholesky Factorization ) . Given A ∈ IR n × n symmetric positive deﬁnite ; for i (cid:3) 1 , 2 , . . . , n ; L ii ← √ A ii ; for j (cid:3) i + 1 , i + 2 , . . . , n L ji ← A ji / L ii ; for k (cid:3) i + 1 , i + 2 , . . . , j A jk ← A jk − L ji L ki ; end ( for ) end ( for ) end ( for ) Note that this algorithm references only the lower triangular elements of A ; in fact , it is only necessary to store these elements in any case , since by symmetry they are simply duplicated in the upper triangular positions . Unlike the case of Gaussian elimination , the Cholesky algorithm can produce a valid factorization of a symmetric positive deﬁnite matrix without swapping any rows or columns . However , symmetric permutation ( that is , reordering the rows and columns in the same way ) can be used to improve the sparsity of the factor L . In this case , the algorithm produces a permutation of the form P T AP (cid:3) LL T for some permutation matrix P . The Cholesky factorization can be used to compute solutions of the system Ax (cid:3) b by performing triangular forward - and back - substitutions with L and L T , respectively , as in the case of L and U factors produced by Gaussian elimination . A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 609 The Cholesky factorization can also be used to verify positive deﬁniteness of a sym - metric matrix A . If Algorithm A . 2 runs to completion with all L ii values well deﬁned and positive , then A is positive deﬁnite . Another useful factorization of rectangular matrices A ∈ IR m × n has the form AP (cid:3) QR , ( A . 24 ) where P is an n × n permutation matrix , A is m × m orthogonal , and R is m × n upper triangular . In the case of a square matrix m (cid:3) n , this factorization can be used to compute solutions of linear systems of the form Ax (cid:3) b via the following procedure : set ˜ b (cid:3) Q T b ; solve Rz (cid:3) ˜ b for z by performing back - substitution ; set x (cid:3) P T z by rearranging the elements of x . Foradensematrix A , thecostofcomputingtheQRfactorizationisabout4 m 2 n / 3operations . In the case of a square matrix , the operation count is about twice as high as for an LU factorization via Gaussian elimination . Moreover , it is more difﬁcult to maintain sparsity in a QR factorization than in an LU factorization . Algorithms to perform QR factorization are almost as simple as algorithms for Gaus - sian elimination and for Cholesky factorization . The most widely used algorithms work by applying a sequence of special orthogonal matrices to A , known either as Householder transformations or Givens rotations , depending on the algorithm . We omit the details , and refer instead to Golub and Van Loan [ 136 , Chapter 5 ] for a complete description . In the case of a rectangular matrix A with m < n , we can use the QR factorization of A T to ﬁnd a matrix whose columns span the null space of A . To be speciﬁc , we write A T P (cid:3) QR (cid:3) (cid:9) Q 1 Q 2 (cid:10) R , where Q 1 consists of the ﬁrst m columns of Q , and Q 2 contains the last n − m columns . It is easy to show that columns of the matrix Q 2 span the null space of A . This procedure yields a more satisfactory basis matrix for the null space than the Gaussian elimination procedure ( A . 22 ) , because the columns of Q 2 are orthogonal to each other and have unit length . It may be more expensive to compute , however , particularly in the case in which A is sparse . When A has full column rank , we can make an identiﬁcation between the R factor in ( A . 24 ) and the Cholesky factorization . By multiplying the formula ( A . 24 ) by its transpose , 610 A P P E N D I X A . B A C K G R O U N D M A T E R I A L we obtain P T A T AP (cid:3) R T Q T QR (cid:3) R T R , andbycomparisonwith ( A . 23 ) , weseethat R T issimplytheCholeskyfactorofthesymmetric positive deﬁnite matrix P T A T AP . Recalling that L is uniquely deﬁned when we restrict its diagonal elements to be positive , this observation implies that R is also uniquely deﬁned for a given choice of permutation matrix P , provided that we enforce positiveness of the diagonals of R . Note , too , that since we can rearrange ( A . 24 ) to read AP R − 1 (cid:3) Q , we can conclude that Q is also uniquely deﬁned under these conditions . Note that by deﬁnition of the Euclidean norm and the property ( A . 10 ) , and the fact that the Euclidean norms of the matrices P and Q in ( A . 24 ) are both 1 , we have that (cid:8) A (cid:8) (cid:3) (cid:8) QRP T (cid:8) ≤ (cid:8) Q (cid:8) (cid:8) R (cid:8) (cid:8) P T (cid:8) (cid:3) (cid:8) R (cid:8) , while (cid:8) R (cid:8) (cid:3) (cid:8) Q T AP (cid:8) ≤ (cid:8) Q T (cid:8) (cid:8) A (cid:8) (cid:8) P (cid:8) (cid:3) (cid:8) A (cid:8) . We conclude from these two inequalities that (cid:8) A (cid:8) (cid:3) (cid:8) R (cid:8) . When A is square , we have by a similar argument that (cid:8) A − 1 (cid:8) (cid:3) (cid:8) R − 1 (cid:8) . Hence the Euclidean - norm condition number of A can be estimated by substituting R for A in the expression ( A . 11 ) . This observation is signiﬁcant because various techniques are available for estimating the condition number of triangular matrices R ; see Golub and Van Loan [ 136 , pp . 128 – 130 ] for a discussion . SYMMETRIC INDEFINITE FACTORIZATION When matrix A is symmetric but indeﬁnite , Algorithm A . 2 will break down by trying to take the square root of a negative number . We can however produce a factorization , similar to the Cholesky factorization , of the form P AP T (cid:3) L BL T , ( A . 25 ) where L is unit lower triangular , B is a block diagonal matrix with blocks of dimension 1 or 2 , and P is a permutation matrix . The ﬁrst step of this symmetric indeﬁnite factorization proceeds as follows . We identify a submatrix E of A that is suitable to be used as a pivot block . The precise criteria that can be used to choose E are described below , but we note here that E is either a single diagonal element of A ( a 1 × 1 pivot block ) , or else the 2 × 2 block consisting of two diagonal elements of A ( say , a ii and a jj ) along with the corresponding off - diagonal elements ( that is , a ij and a ji ) . In either case , E must be nonsingular . We then A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 611 ﬁnd a permutation matrix P 1 that makes E a leading principal submatrix of A , that is , P 1 AP 1 (cid:3) (cid:1) E C T C H (cid:2) , ( A . 26 ) and then perform a block factorization on this rearranged matrix , using E as the pivot block , to obtain P 1 AP T 1 (cid:3) (cid:1) I 0 C E − 1 I (cid:2) (cid:1) E 0 0 H − C E − 1 C T (cid:2) (cid:1) I E − 1 C T 0 I (cid:2) . The next step of the factorization consists in applying exactly the same process to H − C E − 1 C T , known as the remaining matrix or the Schur complement , which has dimension either ( n − 1 ) × ( n − 1 ) or ( n − 2 ) × ( n − 2 ) . We now apply the same procedure recursively , terminating with the factorization ( A . 25 ) . Here P is deﬁned as a product of the permutation matrices from each step of the factorization , and B contains the pivot blocks E on its diagonal . The symmetric indeﬁnite factorization requires approximately n 3 / 3 ﬂoating - point operations—the same as the cost of the Cholesky factorization of a positive deﬁnite matrix— but to this count we must add the cost of identifying suitable pivot blocks E and of performing the permutations , which can be considerable . There are various strategies for determining the pivot blocks , which have an important effect on both the cost of the factorization and its numerical properties . Ideally , our strategy for choosing E at each step of the factorization procedure should be inexpensive , should lead to at most modest growth in the elements of the remaining matrix at each step of the factorization , and should avoid excessive ﬁll - in ( that is , L should not be too much more dense than A ) . A well - known strategy , due to Bunch and Parlett [ 43 ] , searches the whole remaining matrix and identiﬁes the largest - magnitude diagonal and largest - magnitude off - diagonal elements , denoting their respective magnitudes by ξ dia and ξ off . If the diagonal element whose magnitude is ξ dia is selected to be a 1 × 1 pivot block , the element growth in the remaining matrix is bounded by the ratio ξ dia / ξ off . If this growth rate is acceptable , we choose this diagonal element to be the pivot block . Otherwise , we select the off - diagonal element whose magnitude is ξ off ( a ij , say ) , and choose E to be the 2 × 2 submatrix that includes this element , that is , E (cid:3) (cid:1) a ii a ij a ij a jj (cid:2) . This pivoting strategy of Bunch and Parlett is numerically stable and guarantees to yield a matrix L whose maximum element is bounded by 2 . 781 . Its drawback is that the evaluation of ξ dia and ξ off at each iteration requires many comparisons between ﬂoating - point numbers 612 A P P E N D I X A . B A C K G R O U N D M A T E R I A L to be performed : O ( n 3 ) in total during the overall factorization . Since each comparison costs roughly the same as an arithmetic operation , this overhead is not insigniﬁcant . The more economical pivoting strategy of Bunch and Kaufman [ 42 ] searches at most two columns of the working matrix at each stage and requires just O ( n 2 ) comparisons in total . Its rationale and details are somewhat tricky , and we refer the interested reader to the original paper [ 42 ] or to Golub and Van Loan [ 136 , Section 4 . 4 ] for details . Unfortunately , this algorithm can give rise to arbitrarily large elements in the lower triangular factor L , making it unsuitable for use with a modiﬁed Cholesky strategy . The bounded Bunch – Kaufman strategy is essentially a compromise between the Bunch – Parlett and Bunch – Kaufman strategies . It monitors the sizes of elements in L , ac - cepting the ( inexpensive ) Bunch – Kaufman choice of pivot block when it yields only modest element growth , but searching further for an acceptable pivot when this growth is excessive . Its total cost is usually similar to that of Bunch – Kaufman , but in the worst case it can approach the cost of Bunch – Parlett . So far , we have ignored the effect of the choice of pivot block E on the sparsity of the ﬁnal L factor . This consideration is important when the matrix to be factored is large and sparse , since it greatly affects both the CPU time and the amount of storage required by the algorithm . Algorithms that modify the strategies above to take account of sparsity have been proposed by Duff et al . [ 97 ] , Duff and Reid [ 95 ] , and Fourer and Mehrotra [ 113 ] . SHERMAN – MORRISON – WOODBURY FORMULA If the square nonsingular matrix A undergoes a rank - one update to become ¯ A (cid:3) A + ab T , where a , b ∈ IR n , then if ¯ A is nonsingular , we have ¯ A − 1 (cid:3) A − 1 − A − 1 ab T A − 1 1 + b T A − 1 a . ( A . 27 ) It is easy to verify this formula : Simply multiply the deﬁnitions of ¯ A and ¯ A − 1 together and check that they produce the identity . This formula can be extended to higher - rank updates . Let U and V be matrices in IR n × p for some p between 1 and n . If we deﬁne ˆ A (cid:3) A + UV T , then ˆ A is nonsingular if and only if ( I + V T A − 1 U ) is nonsingular , and in this case we have ˆ A − 1 (cid:3) A − 1 − A − 1 U ( I + V T A − 1 U ) − 1 V T A − 1 . ( A . 28 ) A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 613 We can use this formula to solve linear systems of the form ¯ Ax (cid:3) d . Since x (cid:3) ˆ A − 1 d (cid:3) A − 1 d − A − 1 U ( I + V T A − 1 U ) − 1 V T A − 1 d , we see that x can be found by solving p + 1 linear systems with the matrix A ( to obtain A − 1 d and A − 1 U ) , inverting the p × p matrix I + V T A − 1 U , and performing some elementary matrix algebra . Inversion of the p × p matrix I + V T A − 1 U is inexpensive when p (cid:24) n . INTERLACING EIGENVALUE THEOREM The following result is proved for example in Golub and Van Loan [ 136 , Theorem 8 . 1 . 8 ] . Theorem A . 1 ( Interlacing Eigenvalue Theorem ) . Let A ∈ IR n × n be a symmetric matrix with eigenvalues λ 1 , λ 2 , . . . , λ n satisfying λ 1 ≥ λ 2 ≥ · · · ≥ λ n , and let z ∈ IR n be a vector with (cid:8) z (cid:8) (cid:3) 1 , and α ∈ IR be a scalar . Then if we denote the eigenvalues of A + α zz T by ξ 1 , ξ 2 , . . . , ξ n ( in decreasing order ) , we have for α > 0 that ξ 1 ≥ λ 1 ≥ ξ 2 ≥ λ 2 ≥ ξ 3 ≥ · · · ≥ ξ n ≥ λ n , with n (cid:3) i (cid:3) 1 ξ i − λ i (cid:3) α . ( A . 29 ) If α < 0 , we have that λ 1 ≥ ξ 1 ≥ λ 2 ≥ ξ 2 ≥ λ 3 ≥ · · · ≥ λ n ≥ ξ n , where the relationship ( A . 29 ) is again satisﬁed . Informally stated , the eigenvalues of the modiﬁed matrix “interlace” the eigenvalues of the originalmatrix , withnonnegativeadjustmentsifthecoefﬁcient α ispositive , andnonpositive adjustments if α is negative . The total magnitude of the adjustments equals α , whose magnitude is identical to the Euclidean norm (cid:8) α zz T (cid:8) 2 of the modiﬁcation . ERROR ANALYSIS AND FLOATING - POINT ARITHMETIC In most of this book our algorithms and analysis deal with real numbers . Modern digital computers , however , cannot store or compute with general real numbers . Instead , 614 A P P E N D I X A . B A C K G R O U N D M A T E R I A L they work with a subset known as ﬂoating - point numbers . Any quantities that are stored on the computer , whether they are read directly from a ﬁle or program or arise as the intermediate result of a computation , must be approximated by a ﬂoating - point number . In general , then , the numbers that are produced by practical computation differ from those that would be produced if the arithmetic were exact . Of course , we try to perform our computations in such a way that these differences are as tiny as possible . Discussion of errors requires us to distinguish between absolute error and relative error . If x is some exact quantity ( scalar , vector , matrix ) and ˜ x is its approximate value , the absolute error is the norm of the difference , namely , (cid:8) x − ˜ x (cid:8) . ( In general , any of the norms ( A . 2a ) , ( A . 2b ) , and ( A . 2c ) can be used in this deﬁnition . ) The relative error is the ratio of the absolute error to the size of the exact quantity , that is , (cid:8) x − ˜ x (cid:8) (cid:8) x (cid:8) . When this ratio is signiﬁcantly less than one , we can replace the denominator by the size of the approximate quantity—that is , (cid:8)˜ x (cid:8) —without affecting its value very much . Mostcomputationsassociatedwithoptimizationalgorithmsareperformedindouble - precision arithmetic . Double - precision numbers are stored in words of length 64 bits . Most of these bits ( say t ) are devoted to storing the fractional part , while the remainder encode the exponent e and other information , such as the sign of the number , or an indication of whether it is zero or “undeﬁned . ” Typically , the fractional part has the form . d 1 d 2 . . . d t , where each d i , i (cid:3) 1 , 2 , . . . , t , is either zero or one . ( In some systems d 1 is implicitly assumed to be 1 and is not stored . ) The value of the ﬂoating - point number is then t (cid:3) i (cid:3) 1 d i 2 − i × 2 e . The value 2 − t − 1 is known as unit roundoff and is denoted by u . Any real number whose absolute value lies in the range [ 2 L , 2 U ] ( where L and U are lower and upper bounds on the value of the exponent e ) can be approximated to within a relative accuracy of u by a ﬂoating - point number , that is , ﬂ ( x ) (cid:3) x ( 1 + (cid:9) ) , where | (cid:9) | ≤ u , ( A . 30 ) where ﬂ ( · ) denotes ﬂoating - point approximation . The value of u for double - precision IEEE arithmetic is about 1 . 1 × 10 − 16 . In other words , if the real number x and its ﬂoating - point approximation are both written as base - 10 numbers ( the usual fashion ) , they agree to at least 15 digits . A . 1 . E L E M E N T S O F L I N E A R A L G E B R A 615 For further information on ﬂoating - point computations , see Overton [ 233 ] , Golub and Van Loan [ 136 , Section 2 . 4 ] , and Higham [ 169 ] . When an arithmetic operation is performed with one or two ﬂoating - point numbers , the result must also be stored as a ﬂoating - point number . This process introduces a small roundoff error , whose size can be quantiﬁed in terms of the size of the arguments . If x and y are two ﬂoating - point numbers , we have that | ﬂ ( x ∗ y ) − x ∗ y | ≤ u | x ∗ y | , ( A . 31 ) where ∗ denotes any of the operations + , − , × , ÷ . Although the error in a single ﬂoating - point operation appears benign , more signiﬁ - cant errors may occur when the arguments x and y are ﬂoating - point approximations of two real numbers , or when a sequence of computations are performed in succession . Suppose , for instance , that x and y are large real numbers whose values are very similar . When we store them in a computer , we approximate them with ﬂoating - point numbers ﬂ ( x ) and ﬂ ( y ) that satisfy ﬂ ( x ) (cid:3) x + (cid:9) x , ﬂ ( y ) (cid:3) y + (cid:9) y , where | (cid:9) x | ≤ u | x | , | (cid:9) y | ≤ u | y | . If we take the difference of the two stored numbers , we obtain a ﬁnal result ﬂ ( ﬂ ( x ) − ﬂ ( y ) ) that satisﬁes ﬂ ( ﬂ ( x ) − ﬂ ( y ) ) (cid:3) ( ﬂ ( x ) − ﬂ ( y ) ) ( 1 + (cid:9) xy ) , where | (cid:9) xy | ≤ u . By combining these expressions , we ﬁnd that the difference between this result and the true value x − y may be as large as (cid:9) x + (cid:9) y + (cid:9) xy , which is bounded by u ( | x | + | y | + | x − y | ) . Hence , since x and y are large and close together , the relative error is approximately 2 u | x | / | x − y | , which may be quite large , since | x | (cid:28) | x − y | . This phenomenon is known as cancellation . It can also be explained ( less formally ) by noting that if both x and y are accurate to k digits , and if they agree in the ﬁrst ¯ k digits , then their difference will contain only about k − ¯ k signiﬁcant digits—the ﬁrst ¯ k digits cancel each other out . This observation is the reason for the well - known adage of numerical computing—that one should avoid taking the difference of two similar numbers if at all possible . 616 A P P E N D I X A . B A C K G R O U N D M A T E R I A L CONDITIONING AND STABILITY Conditioning and stability are two terms that are used frequently in connection with numerical computations . Unfortunately , their meaning sometimes varies from author to author , but the general deﬁnitions below are widely accepted , and we adhere to them in this book . Conditioning is a property of the numerical problem at hand ( whether it is a linear algebra problem , an optimization problem , a differential equations problem , or whatever ) . A problem is said to be well conditioned if its solution is not affected greatly by small perturbations to the data that deﬁne the problem . Otherwise , it is said to be ill conditioned . A simple example is given by the following 2 × 2 system of linear equations : (cid:1) 1 2 1 1 (cid:2) (cid:1) x 1 x 2 (cid:2) (cid:3) (cid:1) 3 2 (cid:2) . By computing the inverse of the coefﬁcient matrix , we ﬁnd that the solution is simply (cid:1) x 1 x 2 (cid:2) (cid:3) (cid:1) − 1 2 1 − 1 (cid:2) (cid:1) 3 2 (cid:2) (cid:3) (cid:1) 1 1 (cid:2) . If we replace the ﬁrst right - hand - side element by 3 . 00001 , the solution becomes ( x 1 , x 2 ) T (cid:3) ( 0 . 99999 , 1 . 00001 ) T , which is only slightly different from its exact value ( 1 , 1 ) T . We would note similar insensitivity if we were to perturb the other elements of the right - hand - side or elements of the coefﬁcient matrix . We conclude that this problem is well conditioned . On the other hand , the problem (cid:1) 1 . 00001 1 1 1 (cid:2) (cid:1) x 1 x 2 (cid:2) (cid:3) (cid:1) 2 . 00001 2 (cid:2) is ill conditioned . Its exact solution is x (cid:3) ( 1 , 1 ) T , but if we change the ﬁrst element of the right - hand - side from 2 . 00001 to 2 , the solution would change drastically to x (cid:3) ( 0 , 2 ) T . For general square linear systems Ax (cid:3) b where A ∈ IR n × n , the condition number of the matrix ( deﬁned in ( A . 11 ) ) can be used to quantify the conditioning . Speciﬁcally , if we perturb A to ˜ A and b to ˜ b and take ˜ x to be the solution of the perturbed system ˜ A ˜ x (cid:3) ˜ b , it can be shown that (cid:8) x − ˜ x (cid:8) (cid:8) x (cid:8) ≈ κ ( A ) (cid:1) (cid:8) A − ˜ A (cid:8) (cid:8) A (cid:8) + (cid:8) b − ˜ b (cid:8) (cid:8) b (cid:8) (cid:2) ( see , for instance , Golub and Van Loan [ 136 , Section 2 . 7 ] ) . Hence , a large condition number κ ( A ) indicates that the problem Ax (cid:3) b is ill conditioned , while a modest value indicates well conditioning . A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 617 Note that the concept of conditioning has nothing to do with the particular algorithm that is used to solve the problem , only with the numerical problem itself . Stability , on the other hand , is a property of the algorithm . An algorithm is stable if it is guaranteed to produce accurate answers to all well - conditioned problems in its class , even when ﬂoating - point arithmetic is used . As an example , consider again the linear equations Ax (cid:3) b . We can show that Algorithm A . 1 , in combination with triangular substitution , yields a computed solution ˜ x whose relative error is approximately (cid:8) x − ˜ x (cid:8) (cid:8) x (cid:8) ≈ κ ( A ) growth ( A ) (cid:8) A (cid:8) u , ( A . 32 ) where growth ( A ) is the size of the largest element that arises in A during execution of Algorithm A . 1 . In the worst case , we can show that growth ( A ) / (cid:8) A (cid:8) may be around 2 n − 1 , which indicates that Algorithm A . 1 is an unstable algorithm , since even for modest n ( say , n (cid:3) 200 ) , the right - hand - side of ( A . 32 ) may be large even when κ ( A ) is modest . In practice , however , large growth factors are rarely observed , so we conclude that Algorithm A . 1 is stable for all practical purposes . Gaussian elimination without pivoting , on the other hand , is deﬁnitely unstable . If we omit the possible exchange of rows in Algorithm A . 1 , the algorithm will fail to produce a factorization even of some well - conditioned matrices , such as A (cid:3) (cid:1) 0 1 1 2 (cid:2) . For systems Ax (cid:3) b in which A is symmetric positive deﬁnite , the Cholesky fac - torization in combination with triangular substitution constitutes a stable algorithm for producing a solution x . A . 2 ELEMENTS OF ANALYSIS , GEOMETRY , TOPOLOGY SEQUENCES Suppose that { x k } is a sequence of points belonging to IR n . We say that a sequence { x k } converges to some point x , written lim k →∞ x k (cid:3) x , if for any (cid:9) > 0 , there is an index K such that (cid:8) x k − x (cid:8) ≤ (cid:9) , for all k ≥ K . For example , the sequence { x k } deﬁned by x k (cid:3) ( 1 − 2 − k , 1 / k 2 ) T converges to ( 1 , 0 ) T . 618 A P P E N D I X A . B A C K G R O U N D M A T E R I A L Given a index set S ⊂ { 1 , 2 , 3 , . . . } , we can deﬁne a subsequence of { t k } corresponding to S , and denote it by { t k } k ∈ S . We say that ˆ x ∈ IR n is an accumulation point or limit point for { x k } if there is an inﬁnite set of indices k 1 , k 2 , k 3 , . . . such that the subsequence { x k i } i (cid:3) 1 , 2 , 3 , . . . converges to ˆ x ; that is , lim i →∞ x k i (cid:3) ˆ x . Alternatively , we say that for any (cid:9) > 0 and all positive integers K , we have (cid:8) x k − x (cid:8) ≤ (cid:9) , for some k ≥ K . An example is given by the sequence (cid:1) 1 1 (cid:2) , (cid:1) 1 / 2 1 / 2 (cid:2) , (cid:1) 1 1 (cid:2) , (cid:1) 1 / 4 1 / 4 (cid:2) , (cid:1) 1 1 (cid:2) , (cid:1) 1 / 8 1 / 8 (cid:2) , . . . , ( A . 33 ) which has exactly two limit points : ˆ x (cid:3) ( 0 , 0 ) T and ˆ x (cid:3) ( 1 , 1 ) T . A sequence can even have an inﬁnite number of limit points . An example is the sequence x k (cid:3) sin k , for which every point in the interval [ − 1 , 1 ] is a limit point . A sequence converges if and only if it has exactly one limit point . A sequence is said to be a Cauchy sequence if for any (cid:9) > 0 , there exists an integer K such that (cid:8) x k − x l (cid:8) ≤ (cid:9) for all indices k ≥ K and l ≥ K . A sequence converges if and only if it is a Cauchy sequence . We now consider scalar sequences { t k } , that is , t k ∈ IR for all k . This sequence is said to be bounded above if there exists a scalar u such that t k ≤ u for all k , and bounded below if there is a scalar v with t k ≥ v for all k . The sequence { t k } is said to be nondecreasing if t k + 1 ≥ t k for all k , and nonincreasing if t k + 1 ≤ t k for all k . If { t k } is nondecreasing and bounded above , then it converges , that is , lim k →∞ t k (cid:3) t for some scalar t . Similarly , if { t k } is nonincreasing and bounded below , it converges . We deﬁne the supremum of the scalar sequence { t k } as the smallest real number u such that t k ≤ u for all k (cid:3) 1 , 2 , 3 , . . . , and denote it by sup { t k } . The inﬁmum , denoted by inf { t k } , is the largest real number v such that v ≤ t k for all k (cid:3) 1 , 2 , 3 , . . . . We can now deﬁne the sequence of suprema as { u i } , where u i def (cid:3) sup { t k | k ≥ i } . Clearly , { u i } is a nonincreasing sequence . If bounded below , it converges to a ﬁnite number ¯ u , which we call the “lim sup” of { t k } , denoted by lim sup t k . Similarly , we can denote the sequence of inﬁma by { v i } , where v i def (cid:3) inf { t k | k ≥ i } , A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 619 which is nondecreasing . If { v i } is bounded above , it converges to a point ¯ v which we call the “lim inf” of { t k } , denoted by lim inf t k . As an example , the sequence 1 , 12 , 1 , 14 , 1 , 18 , . . . has a lim inf of 0 and a lim sup of 1 . RATES OF CONVERGENCE One of the key measures of performance of an algorithm is its rate of convergence . Here , we deﬁne the terminology associated with different types of convergence . Let { x k } be a sequence in IR n that converges to x ∗ . We say that the convergence is Q - linear if there is a constant r ∈ ( 0 , 1 ) such that (cid:8) x k + 1 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) ≤ r , for all k sufﬁciently large . ( A . 34 ) This means that the distance to the solution x ∗ decreases at each iteration by at least a constant factor bounded away from 1 . For example , the sequence 1 + ( 0 . 5 ) k converges Q - linearly to 1 , with rate r (cid:3) 0 . 5 . The preﬁx “Q” stands for “quotient , ” because this type of convergence is deﬁned in terms of the quotient of successive errors . The convergence is said to be Q - superlinear if lim k →∞ (cid:8) x k + 1 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) (cid:3) 0 . For example , the sequence 1 + k − k converges superlinearly to 1 . ( Prove this statement ! ) Q - quadratic convergence , an even more rapid convergence rate , is obtained if (cid:8) x k + 1 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) 2 ≤ M , for all k sufﬁciently large , where M is a positive constant , not necessarily less than 1 . An example is the sequence 1 + ( 0 . 5 ) 2 k . Thespeedofconvergencedependson r and ( moreweakly ) on M , whosevaluesdepend not only on the algorithm but also on the properties of the particular problem . Regardless of these values , however , a quadratically convergent sequence will always eventually converge faster than a linearly convergent sequence . Obviously , any sequence that converges Q - quadratically also converges Q - super - linearly , and any sequence that converges Q - superlinearly also converges Q - linearly . We can also deﬁne higher rates of convergence ( cubic , quartic , and so on ) , but these are less interesting in practical terms . In general , we say that the Q - order of convergence is p ( with p > 1 ) if there is a positive constant M such that (cid:8) x k + 1 − x ∗ (cid:8) (cid:8) x k − x ∗ (cid:8) p ≤ M , for all k sufﬁciently large . 620 A P P E N D I X A . B A C K G R O U N D M A T E R I A L Quasi - Newton methods for unconstrained optimization typically converge Q - superlinearly , whereas Newton’s method converges Q - quadratically under appropriate assumptions . In contrast , steepest descent algorithms converge only at a Q - linear rate , and when the problem is ill - conditioned the convergence constant r in ( A . 34 ) is close to 1 . In the book , we omit the letter Q and simply talk about superlinear convergence , quadratic convergence , and so on . A slightly weaker form of convergence , characterized by the preﬁx “R” ( for “root” ) , is concerned with the overall rate of decrease in the error , rather than the decrease over each individual step of the algorithm . We say that convergence is R - linear if there is a sequence of nonnegative scalars { ν k } such that (cid:8) x k − x ∗ (cid:8) ≤ ν k for all k , and { ν k } converges Q - linearly to zero . The sequence { (cid:8) x k − x ∗ (cid:8) } is said to be dominated by { ν k } . For instance , the sequence x k (cid:3) (cid:21) 1 + ( 0 . 5 ) k , k even , 1 , k odd , ( A . 35 ) ( the ﬁrst few iterates are 2 , 1 , 1 . 25 , 1 , 1 . 03125 , 1 , . . . ) converges R - linearly to 1 , because we have ( 1 + ( 0 . 5 ) k ) − 1 | (cid:3) ( 0 . ) k , and the sequence { ( 0 . 5 ) k } converges Q - linearly to zero . Likewise , we say that { x k } converges R - superlinearly to x ∗ if { (cid:8) x k − x ∗ (cid:8) } is dominated by a sequence of scalars converging Q - superlinearly to zero , and { x k } converges R - quadratically to x ∗ if { (cid:8) x k − x ∗ (cid:8) } is dominated by a sequence converging Q - quadratically to zero . Note that in the R - linear sequence ( A . 35 ) , the error actually increases at every second iteration ! Such behavior occurs even in sequences whose R - rate of convergence is arbitrarily high , but it cannot occur for Q - linear sequences , which insist on a decrease at every step k , for k sufﬁciently large . For an extensive discussion of convergence rates see Ortega and Rheinboldt [ 230 ] . TOPOLOGY OF THE EUCLIDEAN SPACE IR n The set F is bounded if there is some real number M > 0 such that (cid:8) x (cid:8) ≤ M , for all x ∈ F . A subset F ⊂ IR n is open if for every x ∈ F , we can ﬁnd a positive number (cid:9) > 0 such that the ball of radius (cid:9) around x is contained in F ; that is , { y ∈ IR n | (cid:8) y − x (cid:8) ≤ (cid:9) } ⊂ F . The set F is closed if for all possible sequences of points { x k } in F , all limit points of { x k } are elements of F . For instance , the set F (cid:3) ( 0 , 1 ) ∪ ( 2 , 10 ) is an open subset of IR , while A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 621 F (cid:3) [ 0 , 1 ] ∪ [ 2 , 5 ] is a closed subset of IR . The set F (cid:3) ( 0 , 1 ] is a subset of IR that is neither open nor closed . The interior of a set F , denoted by int F , is the largest open set contained in F . The closure of F , denoted by cl F , is the smallest closed set containing F . In other words , we have x ∈ cl F if lim k →∞ x k (cid:3) x for some sequence { x k } of points in F . If F (cid:3) ( − 1 , 1 ] ∪ [ 2 , 4 ) , then cl F (cid:3) [ − 1 , 1 ] ∪ [ 2 , 4 ] , int F (cid:3) ( − 1 , 1 ) ∪ ( 2 , 4 ) . Note that if F is open , then int F (cid:3) F , while if F is closed , then cl F (cid:3) F . We note the following facts about open and closed sets . The union of ﬁnitely many closed sets is closed , while any intersection of closed sets is closed . The intersection of ﬁnitely many open sets is open , while any union of open sets is open . The set F is compact if every sequence { x k } of points in F has at least one limit point , and all such limit points are in F . ( This deﬁnition is equivalent to the more formal one involving covers of F . ) The following is a central result in topology : F ∈ IR n is closed and bounded ⇒ F is compact . Given a point x ∈ IR n , we call N ∈ IR n a neighborhood of x if it is an open set containing x . An especially useful neighborhood is the open ball of radius (cid:9) around x , which is denoted by IB ( x , (cid:9) ) ; that is , IB ( x , (cid:9) ) (cid:3) { y | (cid:8) y − x (cid:8) < (cid:9) } . Given a set F ⊂ IR n , we say that N is a neighborhood of F if there is (cid:9) > 0 such that ∪ x ∈ F IB ( x , (cid:9) ) ⊂ N . CONVEX SETS IN IR n A convex combination of a ﬁnite set of vectors { x 1 , x 2 , . . . , x m } in IR m is any vector x of the form x (cid:3) m (cid:3) i (cid:3) 1 α i x i , where m (cid:3) i (cid:3) 1 α i (cid:3) 1 , and α i ≥ 0 for all i (cid:3) 1 , 2 , . . . , m . The convex hull of { x 1 , x 2 , . . . , x m } is the set of all convex combinations of these vectors . A cone is a set F with the property that for all x ∈ F we have x ∈ F ⇒ α x ∈ F , for all α > 0 . ( A . 36 ) 622 A P P E N D I X A . B A C K G R O U N D M A T E R I A L For instance , the set F ⊂ IR 2 deﬁned by { ( x 1 , x 2 ) T | x 1 > 0 , x 2 ≥ 0 } is a cone in IR 2 . Note that cones are not necessarily convex . For example , the set { ( x 1 , x 2 ) T | x 1 ≥ 0 or x 2 ≥ 0 } , which encompasses three quarters of the two - dimensional plane , is a cone . The cone generated by { x 1 , x 2 , . . . , x m } is the set of all vectors x of the form x (cid:3) m (cid:3) i (cid:3) 1 α i x i , where α i ≥ 0 for all i (cid:3) 1 , 2 , . . . , m . Note that all cones of this form are convex . Finally , we deﬁne the afﬁne hull and relative interior of a set . An afﬁne set in IR n is a the set of all vectors { x } ⊕ S , where x ∈ IR n and S is a subspace of IR n . Given F ⊂ IR n , the afﬁne hull of F ( denoted by aff F ) is the smallest afﬁne set containing F . For instance , when F is the “ice - cream cone” deﬁned in three dimensions as (cid:22) (cid:3) (cid:31) x ∈ IR 3 | x 3 ≥ 2 0 x 21 + x 22 ( A . 37 ) ( see Figure A . 1 ) , we have aff F (cid:3) IR 3 . If F is the set of two isolated points F (cid:3) { ( 1 , 0 , 0 ) T , ( 0 , 2 , 0 ) T } , we have aff F (cid:3) { ( 1 , 0 , 0 ) T + α ( − 1 , 2 , 0 ) T | for all α ∈ IR } . x x x 1 2 3 Figure A . 1 “Ice - cream cone” set . A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 623 The relative interior ri F of the set F is its interior relative to aff F . If x ∈ F , then x ∈ ri F if there is an (cid:9) > 0 such that ( x + (cid:9) B ) ∩ aff F ⊂ F . Referring again to the ice - cream cone ( A . 37 ) , we have that ri F (cid:3) (cid:31) x ∈ IR 3 (cid:28)(cid:28)(cid:28)(cid:28) x 3 > 2 0 x 21 + x 22 . For the set of two isolated points F (cid:3) { ( 1 , 0 , 0 ) T , ( 0 , 2 , 0 ) T } , we have ri F (cid:3) ∅ . For the set F deﬁned by F def (cid:3) { x ∈ IR 3 | x 1 ∈ [ 0 , 1 ] , x 2 ∈ [ 0 , 1 ] , x 3 (cid:3) 0 } , we have that aff F (cid:3) IR × IR × { 0 } , ri F (cid:3) { x ∈ IR 3 | x 1 ∈ ( 0 , 1 ) , x 2 ∈ ( 0 , 1 ) , x 3 (cid:3) 0 } . CONTINUITY AND LIMITS Let f be a function that maps some domain D ⊂ IR n to the space IR m . For some point x 0 ∈ cl D , we write lim x → x 0 f ( x ) (cid:3) f 0 ( A . 38 ) ( spoken “the limit of f ( x ) as x approaches x 0 is f 0 ” ) if for all (cid:9) > 0 , there is a value δ > 0 such that (cid:8) x − x 0 (cid:8) < δ and x ∈ D ⇒ (cid:8) f ( x ) − f 0 (cid:8) < (cid:9) . We say that f is continuous at x 0 if x 0 ∈ D and the expression ( A . 38 ) holds with f 0 (cid:3) f ( x 0 ) . We say that f is continuous on its domain D if f is continuous for all x 0 ∈ D . An example is provided by the function f ( x ) (cid:3) (cid:21) − x if x ∈ [ − 1 , 1 ] , x (cid:9)(cid:3) 0 , 5 for all other x ∈ [ − 10 , 10 ] . ( A . 39 ) This function is deﬁned on the domain [ − 10 , 10 ] and is continuous at all points of the domain except the points x (cid:3) 0 , x (cid:3) 1 , and x (cid:3) − 1 . At x (cid:3) 0 , the expression ( A . 38 ) holds with f 0 (cid:3) 0 , but the function is not continuous at this point because f 0 (cid:9)(cid:3) f ( 0 ) (cid:3) 5 . At 624 A P P E N D I X A . B A C K G R O U N D M A T E R I A L x (cid:3) − 1 , the limit ( A . 38 ) is not deﬁned , because the function values in the neighborhood of this point are close to both 5 and − 1 , depending on whether x is slightly smaller or slightly larger than − 1 . Hence , the function is certainly not continuous at this point . The same comments apply to the point x (cid:3) 1 . In the special case of n (cid:3) 1 ( that is , the argument of f is a real scalar ) , we can also deﬁne the one - sided limit . Given x 0 ∈ cl D , We write lim x ↓ x 0 f ( x ) (cid:3) f 0 ( A . 40 ) ( spoken “the limit of f ( x ) as x approaches x 0 from above is f 0 ” ) if for all (cid:9) > 0 , there is a value δ > 0 such that x 0 < x < x 0 + δ and x ∈ D ⇒ (cid:8) f ( x ) − f 0 (cid:8) < (cid:9) . Similarly , we write lim x ↑ x 0 f ( x ) (cid:3) f 0 ( A . 41 ) ( spoken “the limit of f ( x ) as x approaches x 0 from below is f 0 ” ) if for all (cid:9) > 0 , there is a value δ > 0 such that x 0 − δ < x < x 0 and x ∈ D ⇒ (cid:8) f ( x ) − f 0 (cid:8) < (cid:9) . For the function deﬁned in ( A . 39 ) , we have that lim x ↓ 1 f ( x ) (cid:3) 5 , lim x ↑ 1 f ( x ) (cid:3) 1 . Considering again the general case of f : D → IR m where D ⊂ IR n for general m and n . The function f is said to be Lipschitz continuous on some set N ⊂ D if there is a constant L > 0 such that (cid:8) f ( x 1 ) − f ( x 0 ) (cid:8) ≤ L (cid:8) x 1 − x 0 (cid:8) , for all x 0 , x 1 ∈ N . ( A . 42 ) ( L is called the Lipschitz constant . ) The function f is locally Lipschitz continuous at a point ¯ x ∈ int D if there is some neighborhood N of ¯ x with N ⊂ D such that the property ( A . 42 ) holds for some L > 0 . If g and h are two functions mapping D ⊂ IR n to IR m , Lipschitz continuous on a set N ⊂ D , their sum g + h is also Lipschitz continuous , with Lipschitz constant equal to the sum of the Lipschitz constants for g and h individually . If g and h are two functions mapping D ⊂ IR n to IR , the product gh is Lipschitz continuous on a set N ⊂ D if both g and h are Lipschitz continuous on N and both are bounded on N ( that is , there is M > 0 A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 625 such that | g ( x ) | ≤ M and | h ( x ) | ≤ M for all x ∈ N ) . We prove this claim via a sequence of elementary inequalities , for arbitrary x 0 , x 1 ∈ N : | g ( x 0 ) h ( x 0 ) − g ( x 1 ) h ( x 1 ) | ≤ | g ( x 0 ) h ( x 0 ) − g ( x 1 ) h ( x 0 ) | + | g ( x 1 ) h ( x 0 ) − g ( x 1 ) h ( x 1 ) | (cid:3) | h ( x 0 ) | | g ( x 0 ) − g ( x 1 ) | + | g ( x 1 ) | | h ( x 0 ) − h ( x 1 ) | ≤ 2 ML (cid:8) x 0 − x 1 (cid:8) , ( A . 43 ) where L is an upper bound on the Lipschitz constant for both g and h . DERIVATIVES Let φ : IR → IR be a real - valued function of a real variable ( sometimes known as a univariate function ) . The ﬁrst derivative φ (cid:14) ( α ) is deﬁned by d φ d α (cid:3) φ (cid:14) ( α ) def (cid:3) lim (cid:9) → 0 φ ( α + (cid:9) ) − φ ( α ) (cid:9) . ( A . 44 ) The second derivative is obtained by substituting φ by φ (cid:14) in this same formula ; that is , d 2 φ d α 2 (cid:3) φ (cid:14)(cid:14) ( α ) def (cid:3) lim (cid:9) → 0 φ (cid:14) ( α + (cid:9) ) − φ (cid:14) ( α ) (cid:9) . ( A . 45 ) Suppose now that α in turn depends on another quantity β ( we denote this dependence by writing α (cid:3) α ( β ) ) . We can use the chain rule to calculate the derivative of φ with respect to β : d φ ( α ( β ) ) d β (cid:3) d φ d α d α d β (cid:3) φ (cid:14) ( α ) α (cid:14) ( β ) . ( A . 46 ) Consider now the function f : IR n → IR , which is a real - valued function of n independent variables . We typically gather the variables into a vector x (cid:3) ( x 1 , x 2 , . . . , x n ) T . We say that f is differentiable at x if there exists a vector g ∈ IR n such that lim y → 0 f ( x + y ) − f ( x ) − g T y (cid:8) y (cid:8) (cid:3) 0 , ( A . 47 ) where (cid:8) · (cid:8) is any vector norm of y . ( This type of differentiability is known as Frechet differentiability . ) If g satisfying ( A . 47 ) exists , we call it the gradient of f at x , and denote it 626 A P P E N D I X A . B A C K G R O U N D M A T E R I A L by ∇ f ( x ) , written componentwise as ∇ f ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎣ ∂ f ∂ x 1 . . . ∂ f ∂ x n ⎤ ⎥⎥⎥⎥⎥⎦ . ( A . 48 ) Here , ∂ f / ∂ x i represents the partial derivative of f with respect to x i . By setting y (cid:3) (cid:9) e i in ( A . 47 ) , where e i is the vector in IR n consisting all all zeros , except for a 1 in position i , we obtain ∂ f ∂ x i def (cid:3) lim (cid:9) → 0 f ( x 1 , . . . , x i − 1 , x i + (cid:9) , x i + 1 , . . . , x n ) − f ( x 1 , . . . , x i − 1 , x i , x i + 1 , . . . , x n ) (cid:9) (cid:3) f ( x + (cid:9) e i ) − f ( x ) (cid:9) . A gradient with respect to only a subset of the unknowns can be expressed by means of a subscript on the symbol ∇ . Thus for the function of two vector variables f ( z , t ) , we use ∇ z f ( z , t ) to denote the gradient with respect to z ( holding t constant ) . The matrix of second partial derivatives of f is known as the Hessian , and is deﬁned as ∇ 2 f ( x ) (cid:3) ⎡ ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣ ∂ 2 f ∂ x 21 ∂ 2 f ∂ x 1 ∂ x 2 · · · ∂ 2 f ∂ x 1 ∂ x n ∂ 2 f ∂ x 2 ∂ x 1 ∂ 2 f ∂ x 2 2 · · · ∂ 2 f ∂ x 2 ∂ x n . . . . . . . . . ∂ 2 f ∂ x n ∂ x 1 ∂ 2 f ∂ x n ∂ x 2 · · · ∂ 2 f ∂ x 2 n ⎤ ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ . We say that f is differentiable on a domain D if ∇ f ( x ) exists for all x ∈ D , and continuously differentiable if ∇ f ( x ) is a continuous functions of x . Similarly , f is twice differentiable on D if ∇ 2 f ( x ) exists for all x ∈ D and twice continuously differentiable if ∇ 2 f ( x ) is continuous on D . Note that when f is twice continuously differentiable , the Hessian is a symmetric matrix , since ∂ 2 f ∂ x i ∂ x j (cid:3) ∂ 2 f ∂ x j ∂ x i , for all i , j (cid:3) 1 , 2 , . . . , n . When f is a vector valued function that is f : IR n → IR m ( See Chapters 10 and 11 ) , we deﬁne ∇ f ( x ) to be the n × m matrix whose i th column is ∇ f i ( x ) , that is , the gradient of A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 627 f i with respect to x . Often , for notational convenience , we prefer to work with the transpose of his matrix , which has dimensions m × n . This matrix is called the Jacobian and is often denoted by J ( x ) . Speciﬁcally , the ( i , j ) element of J ( x ) is ∂ f i ( x ) / ∂ x j . When the vector x in turn depends on another vector t ( that is , x (cid:3) x ( t ) ) , we can extend the chain rule ( A . 46 ) for the univariate function . Deﬁning h ( t ) (cid:3) f ( x ( t ) ) , ( A . 49 ) we have ∇ h ( t ) (cid:3) n (cid:3) i (cid:3) 1 ∂ f ∂ x i ∇ x i ( t ) (cid:3) ∇ x ( t ) ∇ f ( x ( t ) ) . ( A . 50 ) ❏ E XAMPLE A . 1 Let f : IR 2 → IR be deﬁned by f ( x 1 , x 2 ) (cid:3) x 21 + x 1 x 2 , where x 1 (cid:3) sin t 1 + t 22 and x 2 (cid:3) ( t 1 + t 2 ) 2 . Deﬁning h ( t ) as in ( A . 49 ) , the chain rule ( A . 50 ) yields ∇ h ( t ) (cid:3) n (cid:3) i (cid:3) 1 ∂ f ∂ x i ∇ x i ( t ) (cid:3) ( 2 x 1 + x 2 ) (cid:1) cos t 1 2 t 2 (cid:2) + x 1 (cid:1) 2 ( t 1 + t 2 ) 2 ( t 1 + t 2 ) (cid:2) (cid:3) (cid:7) 2 (cid:7) sin t 1 + t 2 2 (cid:8) + ( t 1 + t 2 ) 2 (cid:8) (cid:1) cos t 1 2 t 2 (cid:2) + (cid:7) sin t 1 + t 2 2 (cid:8) (cid:1) 2 ( t 1 + t 2 ) 2 ( t 1 + t 2 ) (cid:2) . If , on the other hand , we substitute directly for x into the deﬁnition of f , we obtain h ( t ) (cid:3) f ( x ( t ) ) (cid:3) (cid:7) sin t 1 + t 2 2 (cid:8) 2 + (cid:7) sin t 1 + t 2 2 (cid:8) ( t 1 + t 2 ) 2 . The reader should verify that the gradient of this expression is identical to the one obtained above by applying the chain rule . ❐ Special cases of the chain rule can be derived when x ( t ) in ( A . 50 ) is a linear function of t , say x ( t ) (cid:3) Ct . We then have ∇ x ( t ) (cid:3) C T , so that ∇ h ( t ) (cid:3) C T ∇ f ( Ct ) . 628 A P P E N D I X A . B A C K G R O U N D M A T E R I A L In the case in which f is a scalar function , we can differentiate twice using the chain rule to obtain ∇ 2 h ( t ) (cid:3) C T ∇ 2 f ( Ct ) C . ( The proof of this statement is left as an exercise . ) DIRECTIONAL DERIVATIVES The directional derivative of a function f : IR n → IR in the direction p is given by D ( f ( x ) ; p ) def (cid:3) lim (cid:9) → 0 f ( x + (cid:9) p ) − f ( x ) (cid:9) . ( A . 51 ) The directional derivative may be well deﬁned even when f is not continuously differen - tiable ; in fact , it is most useful in such situations . Consider for instance the (cid:1) 1 norm function f ( x ) (cid:3) (cid:8) x (cid:8) 1 . We have from the deﬁnition ( A . 51 ) that D ( (cid:8) x (cid:8) 1 ; p ) (cid:3) lim (cid:9) → 0 (cid:8) x + (cid:9) p (cid:8) 1 − (cid:8) x (cid:8) 1 (cid:9) (cid:3) lim (cid:9) → 0 (cid:4) ni (cid:3) 1 | x i + (cid:9) p i | − (cid:4) ni (cid:3) 1 | x i | (cid:9) . If x i > 0 , we have | x i + (cid:9) p i | (cid:3) | x i | + (cid:9) p i for all (cid:9) sufﬁciently small . If x i < 0 , we have | x i + (cid:9) p i | (cid:3) | x i | − (cid:9) p i , while if x i (cid:3) 0 , we have | x i + (cid:9) p i | (cid:3) (cid:9) | p i | . Therefore , we have D ( (cid:8) x (cid:8) 1 ; p ) (cid:3) (cid:3) i | x i < 0 − p i + (cid:3) i | x i > 0 p i + (cid:3) i | x i (cid:3) 0 | p i | , so the directional derivative of this function exists for any x and p . The ﬁrst derivative ∇ f ( x ) does not exist , however , whenever any of the components of x are zero . When f is in fact continuously differentiable in a neighborhood of x , we have D ( f ( x ) ; p ) (cid:3) ∇ f ( x ) T p . To verify this formula , we deﬁne the function φ ( α ) (cid:3) f ( x + α p ) (cid:3) f ( y ( α ) ) , ( A . 52 ) where y ( α ) (cid:3) x + α p . Note that lim (cid:9) → 0 f ( x + (cid:9) p ) − f ( x ) (cid:9) (cid:3) lim (cid:9) → 0 φ ( (cid:9) ) − φ ( 0 ) (cid:9) (cid:3) φ (cid:14) ( 0 ) . A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 629 By applying the chain rule ( A . 50 ) to f ( y ( α ) ) , we obtain φ (cid:14) ( α ) (cid:3) n (cid:3) i (cid:3) 1 ∂ f ( y ( α ) ) ∂ y i ∇ y i ( α ) ( A . 53 ) (cid:3) n (cid:3) i (cid:3) 1 ∂ f ( y ( α ) ) ∂ y i p i (cid:3) ∇ f ( y ( α ) ) T p (cid:3) ∇ f ( x + α p ) T p . We obtain ( A . 51 ) by setting α (cid:3) 0 and comparing the last two expressions . MEAN VALUE THEOREM We now recall the mean value theorem for univariate functions . Given a continuously differentiable function φ : IR → IR and two real numbers α 0 and α 1 that satisfy α 1 > α 0 , we have that φ ( α 1 ) (cid:3) φ ( α 0 ) + φ (cid:14) ( ξ ) ( α 1 − α 0 ) ( A . 54 ) for some ξ ∈ ( α 0 , α 1 ) . An extension of this result to a multivariate function f : IR n → IR is that for any vector p we have f ( x + p ) (cid:3) f ( x ) + ∇ f ( x + α p ) T p , ( A . 55 ) for some α ∈ ( 0 , 1 ) . ( This result can be proved by deﬁning φ ( α ) (cid:3) f ( x + α p ) , α 0 (cid:3) 0 , and α 1 (cid:3) 1 and applying the chain rule , as above . ) ❏ E XAMPLE A . 2 Consider f : IR 2 → IR deﬁned by f ( x ) (cid:3) x 31 + 3 x 1 x 2 2 , and let x (cid:3) ( 0 , 0 ) T and p (cid:3) ( 1 , 2 ) T . It is easy to verify that f ( x ) (cid:3) 0 and f ( x + p ) (cid:3) 13 . Since ∇ f ( x + α p ) (cid:3) (cid:1) 3 ( x 1 + α p 1 ) 2 + 3 ( x 2 + α p 2 ) 2 6 ( x 1 + α p 1 ) ( x 2 + α p 2 ) (cid:2) (cid:3) (cid:1) 15 α 2 12 α 2 (cid:2) , we have that ∇ f ( x + α p ) T p (cid:3) 39 α 2 . Hence the relation ( A . 55 ) holds when we set α (cid:3) 1 / √ 13 , which lies in the open interval ( 0 , 1 ) , as claimed . ❐ 630 A P P E N D I X A . B A C K G R O U N D M A T E R I A L An alternative expression to ( A . 55 ) can be stated for twice differentiable functions : We have f ( x + p ) (cid:3) f ( x ) + ∇ f ( x ) T p + 1 2 p T ∇ 2 f ( x + α p ) T p , ( A . 56 ) for some α ∈ ( 0 , 1 ) . In fact , this expression is one form of Taylor’s theorem , Theorem 2 . 1 in Chapter 2 , to which we refer throughout the book . The extension of ( A . 55 ) to a vector - valued function r : IR n → IR m for m > 1 is not immediate . There is in general no scalar α such that the natural extension of ( A . 55 ) is satisﬁed . However , the following result is often a useful analog . As in ( 10 . 3 ) , we denote the Jacobian of r ( x ) , by J ( x ) , where J ( x ) is the m × n matrix whose ( j , i ) entry is ∂ r j / ∂ x i , for j (cid:3) 1 , 2 , . . . , m and i (cid:3) 1 , 2 , . . . , n , and asssume that J ( x ) is deﬁned and continuous on the domain of interest . Given x and p , we then have r ( x + p ) − r ( x ) (cid:3) (cid:6) 1 0 J ( x + α p ) p d α . ( A . 57 ) When p is sufﬁciently small in norm , we can approximate the right - hand side of this expression adequately by J ( x ) p , that is , r ( x + p ) − r ( x ) ≈ J ( x ) p . If J is Lipschitz continuous in the vicinity of x and x + p with Lipschitz constant L , we can use ( A . 12 ) to estimate the error in this approximation as follows : (cid:8) r ( x + p ) − r ( x ) − J ( x ) p (cid:8) (cid:3) (cid:23)(cid:23)(cid:23)(cid:23)(cid:6) 1 0 [ J ( x + α p ) − J ( x ) ] p d α (cid:23)(cid:23)(cid:23)(cid:23) ≤ (cid:6) 1 0 (cid:8) J ( x + α p ) − J ( x ) (cid:8) (cid:8) p (cid:8) d α ≤ (cid:6) 1 0 L α (cid:8) p (cid:8) 2 d α (cid:3) 12 L (cid:8) p (cid:8) 2 . IMPLICIT FUNCTION THEOREM The implicit function theorem lies behind a number of important results in local convergence theory of optimization algorithms and in the characterization of optimality ( seeChapter12 ) . OurstatementofthisresultisbasedonLang [ 187 , p . 131 ] andBertsekas [ 19 , Proposition A . 25 ] . A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 631 Theorem A . 2 ( Implicit Function Theorem ) . Let h : IR n × IR m → IR n be a function such that ( i ) h ( z ∗ , 0 ) (cid:3) 0 for some z ∗ ∈ IR n , ( ii ) the function h ( · , · ) is continuously differentiable in some neighborhood of ( z ∗ , 0 ) , and ( iii ) ∇ z h ( z , t ) is nonsingular at the point ( z , t ) (cid:3) ( z ∗ , 0 ) . Then there exist open sets N z ⊂ IR n and N t ⊂ IR m containing z ∗ and 0 , respectively , and a continuous function z : N t → N z such that z ∗ (cid:3) z ( 0 ) and h ( z ( t ) , t ) (cid:3) 0 for all t ∈ N t . Further , z ( t ) is uniquely deﬁned . Finally , if h is p times continuously differentiable with respect to both its arguments for some p > 0 , then z ( t ) is also p times continuously differentiable with respect to t , and we have ∇ z ( t ) (cid:3) −∇ t h ( z ( t ) , t ) [ ∇ z h ( z ( t ) , t ) ] − 1 for all t ∈ N t . This theorem is frequently applied to parametrized systems of linear equations , in which z is obtained as the solution of M ( t ) z (cid:3) g ( t ) , where M ( · ) ∈ IR n × n has M ( 0 ) nonsingular , and g ( · ) ∈ IR n . To apply the theorem , we deﬁne h ( z , t ) (cid:3) M ( t ) z − g ( t ) . If M ( · ) and g ( · ) are continuously differentiable in some neighborhood of 0 , the theorem implies that z ( t ) (cid:3) M ( t ) − 1 g ( t ) is a continuous function of t in some neighborhood of 0 . ORDER NOTATION In much of our analysis we are concerned with how the members of a sequence behave eventually , that is , when we get far enough along in the sequence . For instance , we might ask whether the elements of the sequence are bounded , or whether they are similar in size to the elements of a corresponding sequence , or whether they are decreasing and , if so , how rapidly . Order notation is useful shorthand to use when questions like these are being examined . It saves us deﬁning many constants that clutter up the argument and the analysis . We will use three varieties of order notation : O ( · ) , o ( · ) , and (cid:22) ( · ) . Given two nonnegative inﬁnite sequences of scalars { η k } and { ν k } , we write η k (cid:3) O ( ν k ) 632 A P P E N D I X A . B A C K G R O U N D M A T E R I A L if there is a positive constant C such that | η k | ≤ C | ν k | for all k sufﬁciently large . We write η k (cid:3) o ( ν k ) if the sequence of ratios { η k / ν k } approaches zero , that is , lim k →∞ η k ν k (cid:3) 0 . Finally , we write η k (cid:3) (cid:22) ( ν k ) if there are two constants C 0 and C 1 with 0 < C 0 ≤ C 1 < ∞ such that C 0 | ν k | ≤ | η k | ≤ C 1 | ν k | , that is , the corresponding elements of both sequences stay in the same ballpark for all k . This deﬁnition is equivalent to saying that η k (cid:3) O ( ν k ) and ν k (cid:3) O ( η k ) . The same notation is often used in the context of quantities that depend continuously on each other as well . For instance , if η ( · ) is a function that maps IR to IR , we write η ( ν ) (cid:3) O ( ν ) if there is a constant C such that | η ( ν ) | ≤ C | ν | for all ν ∈ IR . ( Typically , we are interested only in values of ν that are either very large or very close to zero ; this should be clear from the context . Similarly , we use η ( ν ) (cid:3) o ( ν ) ( A . 58 ) to indicate that the ratio η ( ν ) / ν approaches zero either as ν → 0 or ν → ∞ . ( Again , the precise meaning should be clear from the context . ) As a slight variant on the deﬁnitions above , we write η k (cid:3) O ( 1 ) to indicate that there is a constant C such that | η k | ≤ C for all k , while η k (cid:3) o ( 1 ) A . 2 . E L E M E N T S O F A N A L Y S I S , G E O M E T R Y , T O P O L O G Y 633 indicates that lim k →∞ η k (cid:3) 0 . We sometimes use vector and matrix quantities as arguments , and in these cases the deﬁnitions above are intended to apply to the norms of these quantities . For instance , if f : IR n → IR n , we write f ( x ) (cid:3) O ( (cid:8) x (cid:8) ) if there is a constant C > 0 such that (cid:8) f ( x ) (cid:8) ≤ C (cid:8) x (cid:8) for all x in the domain of f . Typically , as above , we are interested only in some subdomain of f , usually a small neighborhood of 0 . As before , the precise meaning should be clear from the context . ROOT - FINDING FOR SCALAR EQUATIONS In Chapter 11 we discussed methods for ﬁnding solutions of nonlinear systems of equations F ( x ) (cid:3) 0 , where F : IR n → IR n . Here we discuss brieﬂy the case of scalar equations ( n (cid:3) 1 ) , for which the algorithm is easy to illustrate . Scalar root - ﬁnding is needed in the trust - region algorithms of Chapter 4 , for instance . Of course , the general theorems of Chapter 11 can be applied to derive rigorous convergence results for this special case . The basic step of Newton’s method ( Algorithm Newton of Chapter 11 ) in the scalar case is simply p k (cid:3) − F ( x k ) / F (cid:14) ( x k ) , x k + 1 ← x k + p k ( A . 59 ) ( cf . ( 11 . 6 ) ) . Graphically , such a step involves taking the tangent to the graph of F at the point x k and taking the next iterate to be the intersection of this tangent with the x axis ( see Figure A . 2 ) . Clearly , if the function F is nearly linear , the tangent will be quite a good approximation to F itself , so the Newton iterate will be quite close to the true root of F . x k x k + 1 x k F ( ) tangent Figure A . 2 One step of Newton’s method for a scalar equation . 634 A P P E N D I X A . B A C K G R O U N D M A T E R I A L x k x k + 1 x k + 2 secant Figure A . 3 One step of the secant method for a scalar equation . ThesecantmethodforscalarequationscanbeviewedasthespecializationofBroyden’s method to the case of n (cid:3) 1 . The issues are simpler in this case , however , since the secant equation ( 11 . 27 ) completely determines the value of the 1 × 1 approximate Hessian B k . That is , we do not need to apply extra conditions to ensure that B k is fully determined . By combining ( 11 . 24 ) with ( 11 . 27 ) , we ﬁnd that the secant method for the case of n (cid:3) 1 is deﬁned by B k (cid:3) ( F ( x k ) − F ( x k − 1 ) ) / ( x k − x k − 1 ) , ( A . 60a ) p k (cid:3) − F ( x k ) / B k , x k + 1 (cid:3) x k + p k . ( A . 60b ) By illustrating this algorithm , we see the origin of the term “secant . ” B k approximates the slope of the function at x k by taking the secant through the points ( x k − 1 , F ( x k − 1 ) and ( x k , F ( x k ) ) , and x k + 1 is obtained by ﬁnding the intersection of this secant with the x axis . The method is illustrated in Figure A . 3 . This is page 635 Printer : Opaque this A P P E N D I X B A Regularization Procedure The following algorithm chooses parameters δ , γ that guarantee that the regularized primal - dual matrix ( 19 . 25 ) is nonsingular and satisﬁes the inertia condition ( 19 . 24 ) . The algorithm assumes that , at the beginning of the interior - point iteration , δ old has been initialized to zero . Algorithm B . 1 ( Inertia Correction and Regularization ) . Given the current barrier parameter µ , constants η > 0 and β < 1 , and the perturbation δ old used in the previous interior - point iteration . 636 A P P E N D I X B . A R E G U L A R I Z A T I O N P R O C E D U R E Factor ( 19 . 25 ) with δ (cid:3) γ (cid:3) 0 . if ( 19 . 25 ) is nonsingular and its inertia is ( n + m , l + m , 0 ) compute the primal - dual step ; stop ; if ( 19 . 25 ) has zero eigenvalues set γ ← 10 − 8 ηµ β ; if δ old (cid:3) 0 set δ ← 10 − 4 ; else set δ ← δ old / 2 ; repeat Factor the modiﬁed matrix ( 19 . 25 ) ; if the inertia is ( n + m , l + m , 0 ) Set δ old ← δ ; Compute the primal - dual step ( 19 . 12 ) using the coefﬁcient matrix ( 19 . 25 ) ; stop ; else Set δ ← 10 δ ; end ( repeat ) This algorithm has been adapted from a more elaborate procedure described by W¨achter and Biegler [ 301 ] . All constants used in the algorithm are arbitrary ; we have pro - vided typical choices . The algorithm aims to avoid unnecessarily large modiﬁcations δ I of ∇ 2 xx L while trying to minimize the number of matrix factorizations . Excessive modiﬁcations degrade the performance of the algorithm because they erase the second derivative informa - tion contained in ∇ 2 xx L , and cause the step to take on steepest - descent like characteristics . The ﬁrst trial value ( δ (cid:3) δ old / 2 ) is based on the previous modiﬁcation δ old because the minimum perturbation δ required to achieve the desired inertia will often not vary much from one interior - point iteration to the next . TheheuristicsimplementedinAlgorithmB . 1provideanalternativetothoseemployed in Algorithm 7 . 3 , which were presented in the context of unconstrained optimization . We emphasize , however , that all of these are indeed heuristics and may not always provide adequate safeguards . This is page 637 Printer : Opaque this References [ 1 ] R . K . A HUJA , T . L . M AGNANTI , AND J . B . O RLIN , Network Flows : Theory , Algorithms , and Applications , Prentice - Hall , Englewood Cliffs , N . J . , 1993 . [ 2 ] H . A KAIKE , On a successive transformation of probability distribution and its application to the analysis of the optimum gradient method , Annals of the Institute of Statistical Mathematics , 11 ( 1959 ) , pp . 1 – 17 . [ 3 ] M . A L - B AALI , Descent property and global convergence of the Fletcher - Reeves method with inexact line search , I . M . A . Journal on Numerical Analysis , 5 ( 1985 ) , pp . 121 – 124 . [ 4 ] E . D . A NDERSEN AND K . D . A NDERSEN , Presolving in linear programming , Mathematical Programming , 71 ( 1995 ) , pp . 221 – 245 . [ 5 ] , The MOSEK interior point optimizer for linear programming : an implementation of the homogeneous algorithm , in High Performance Optimization , T . T . H . Frenk , K . Roos and S . Zhang , eds . , Kluwer Academic Publishers , 2000 , pp . 197 – 232 . [ 6 ] E . D . A NDERSEN , J . G ONDZIO , C . M´ ESZ ´ AROS , AND X . X U , Implementation of interior - point methods for large scale linear programming , in Interior Point Methods in Mathematical Programming , T . Terlaky , ed . , Kluwer , 1996 , ch . 6 , pp . 189 – 252 . [ 7 ] E . A NDERSON , Z . B AI , C . B ISCHOF , J . D EMMEL , J . D ONGARRA , J . D U C ROZ , A . G REENBAUM , S . H AM - MARLING , A . M C K ENNEY , S . O STROUCHOV , AND D . S ORENSEN , LAPACK User’s Guide , SIAM , Philadelphia , 1992 . 638 R E F E R E N C E S [ 8 ] M . A NITESCU , On solving mathematical programs with complementarity constraints as nonlinear programs , SIAM Journal on Optimization , 15 ( 2005 ) , pp . 1203 – 1236 . [ 9 ] ARKI C ONSULTING AND D EVELOPMENT A / S , CONOPT version 3 , 2004 . [ 10 ] B . M . A VERICK , R . G . C ARTER , J . J . M OR ´ E , AND G . X UE , The MINPACK - 2 test problem collection , Preprint MCS – P153 – 0692 , Argonne National Laboratory , 1992 . [ 11 ] P . B APTIST AND J . S TOER , On the relation between quadratic termination and convergence properties of minimization algorithms , Part II : Applications , Numerische Mathematik , 28 ( 1977 ) , pp . 367 – 392 . [ 12 ] R . H . B ARTELS AND G . H . G OLUB , The simplex method of linear programming using LU decomposition , Communications of the ACM , 12 ( 1969 ) , pp . 266 – 268 . [ 13 ] R . B ARTLETT AND L . B IEGLER , rSQP + + : An object - oriented framework for successive quadratic programming , in Large - Scale PDE - Constrained Optimization , L . T . Biegler , O . Ghat - tas , M . Heinkenschloss , and B . van Bloemen Waanders , eds . , vol . 30 , New York , 2003 , Springer - Verlag , pp . 316 – 330 . Lecture Notes in Computational Science and Engineering . [ 14 ] M . B AZARAA , H . S HERALI , AND C . S HETTY , Nonlinear Programming , Theory and Applications . , John Wiley & Sons , New York , second ed . , 1993 . [ 15 ] A . B EN - T AL AND A . N EMIROVSKI , Lectures on Modern Convex Optimization : Analysis , Algorithms , and Engineering Applications , MPS - SIAM Series on Optimization , SIAM , 2001 . [ 16 ] H . Y . B ENSON , A . S EN , D . F . S HANNO , AND R . J . V ANDERBEI , Interior - point algorithms , penalty methods and equilibrium problems , Technical Report ORFE - 03 - 02 , Operations Research and Financial Engineering , Princeton University , 2003 . [ 17 ] S . B ENSON AND J . M OR ´ E , A limited - memory variable - metric algorithm for bound constrained minimization , Numerical Analysis Report P909 - 0901 , ANL , Argonne , IL , USA , 2001 . [ 18 ] D . P . B ERTSEKAS , Constrained Optimization and Lagrange Multiplier Methods , Academic Press , New York , 1982 . [ 19 ] , Nonlinear Programming , Athena Scientiﬁc , Belmont , MA , second ed . , 1999 . [ 20 ] M . B ERZ , C . B ISCHOF , C . F . C ORLISS , AND A . G RIEWANK , eds . , Computational Differentiation : Techniques , Applications , and Tools , SIAM Publications , Philadelphia , PA , 1996 . [ 21 ] J . B ETTS , S . K . E LDERSVELD , P . D . F RANK , AND J . G . L EWIS , An interior - point nonlinear programming algorithm for large scale optimization , Technical report MCT TECH - 003 , Mathematics and Computing Technology , The Boeing Company , P . O . Box 3707 , Seattle , WA 98124 - 2207 , 2000 . [ 22 ] J . R . B IRGE AND F . L OUVEAUX , Introduction to Stochastic Programming , Springer - Verlag , New York , 1997 . [ 23 ] E . G . B IRGIN , J . M . M ARTINEZ , AND M . R AYDAN , Algorithm813 : SPGsoftwareforconvex - constrained optimization , ACM Transactions on Mathematical Software , 27 ( 2001 ) , pp . 340 – 349 . [ 24 ] C . B ISCHOF , A . B OUARICHA , P . K HADEMI , AND J . J . M OR ´ E , Computing gradients in large - scale optimization using automatic differentiation , INFORMS Journal on Computing , 9 ( 1997 ) , pp . 185 – 194 . [ 25 ] C . B ISCHOF , A . C ARLE , P . K HADEMI , AND A . M AUER , ADIFOR 2 . 0 : Automatic differentiation of FORTRAN 77 programs , IEEE Computational Science & Engineering , 3 ( 1996 ) , pp . 18 – 32 . [ 26 ] C . B ISCHOF , G . C ORLISS , AND A . G RIEWANK , Structuredsecond - andhigher - orderderivativesthrough univariate Taylor series , Optimization Methods and Software , 2 ( 1993 ) , pp . 211 – 232 . [ 27 ] C . B ISCHOF , P . K HADEMI , A . B OUARICHA , AND A . C ARLE , EfﬁcientcomputationofgradientsandJaco - bians by transparent exploitation of sparsity in automatic differentiation , Optimization Methods and Software , 7 ( 1996 ) , pp . 1 – 39 . R E F E R E N C E S 639 [ 28 ] C . B ISCHOF , L . R OH , AND A . M AUER , ADIC : AnextensibleautomaticdifferentiationtoolforANSI - C , Software—Practice and Experience , 27 ( 1997 ) , pp . 1427 – 1456 . [ 29 ] ˚A . B J ¨ ORCK , Numerical Methods for Least Squares Problems , SIAM Publications , Philadelphia , PA , 1996 . [ 30 ] P . T . B OGGS , R . H . B YRD , AND R . B . S CHNABEL , A stable and efﬁcient algorithm for nonlinear orthogonal distance regression , SIAM Journal on Scientiﬁc and Statistical Computing , 8 ( 1987 ) , pp . 1052 – 1078 . [ 31 ] P . T . B OGGS , J . R . D ONALDSON , R . H . B YRD , AND R . B . S CHNABEL , ODRPACK—Softwareforweighted orthogonaldistanceregression , ACMTransactionsonMathematicalSoftware , 15 ( 1981 ) , pp . 348 – 364 . [ 32 ] P . T . B OGGS AND J . W . T OLLE , Convergence properties of a class of rank - two updates , SIAM Journal on Optimization , 4 ( 1994 ) , pp . 262 – 287 . [ 33 ] , Sequential quadratic programming , Acta Numerica , 4 ( 1996 ) , pp . 1 – 51 . [ 34 ] P . T . B OGGS , J . W . T OLLE , AND P . W ANG , On the local convergence of quasi - Newton methods for constrained optimization , SIAM Journal on Control and Optimization , 20 ( 1982 ) , pp . 161 – 171 . [ 35 ] I . B ONGARTZ , A . R . C ONN , N . I . M . G OULD , AND P . L . T OINT , CUTE : Constrainedandunconstrained testing environment , Research Report , IBM T . J . Watson Research Center , Yorktown Heights , NY , 1993 . [ 36 ] J . F . B ONNANS , E . R . P ANIER , A . L . T ITS , AND J . L . Z HOU , Avoiding the Maratos effect by means of a nonmonotone line search . II . Inequality constrained problems — feasible iterates , SIAM Journal on Numerical Analysis , 29 ( 1992 ) , pp . 1187 – 1202 . [ 37 ] S . B OYD , L . E L G HAOUI , E . F ERON , AND V . B ALAKRISHNAN , Linear Matrix Inequalities in Systems and Control Theory , SIAM Publications , Phildelphia , 1994 . [ 38 ] S . B OYD AND L . V ANDENBERGHE , Convex Optimization , Cambridge University Press , Cambridge , 2003 . [ 39 ] R . P . B RENT , Algorithms for minimization without derivatives , Prentice Hall , Englewood Cliffs , NJ , 1973 . [ 40 ] H . M . B¨ UCKER , G . F . C ORLISS , P . D . H OVLAND , U . N AUMANN , AND B . N ORRIS , eds . , AutomaticDiffer - entiation : Applications , Theory , and Implementations , vol . 50 of Lecture Notes in Computational Science and Engineering , Springer , New York , 2005 . [ 41 ] R . B ULIRSCH AND J . S TOER , Introduction to Numerical Analysis , Springer - Verlag , New York , 1980 . [ 42 ] J . R . B UNCH AND L . K AUFMAN , Some stable methods for calculating inertia and solving symmetric linear systems , Mathematics of Computation , 31 ( 1977 ) , pp . 163 – 179 . [ 43 ] J . R . B UNCH AND B . N . P ARLETT , Direct methods for solving symmetric indeﬁnite systems of linear equations , SIAM Journal on Numerical Analysis , 8 ( 1971 ) , pp . 639 – 655 . [ 44 ] J . V . B URKE AND J . J . M OR ´ E , Exposing constraints , SIAM Journal on Optimization , 4 ( 1994 ) , pp . 573 – 595 . [ 45 ] W . B URMEISTER , Die konvergenzordnung des Fletcher - Powell algorithmus , Zeitschrift f¨ur Angewandte Mathematik und Mechanik , 53 ( 1973 ) , pp . 693 – 699 . [ 46 ] R . B YRD , J . N OCEDAL , AND R . W ALTZ , Knitro : An integrated package for nonlinear optimization , Technical Report 18 , Optimization Technology Center , Evanston , IL , June 2005 . [ 47 ] R . B YRD , J . N OCEDAL , AND R . A . W ALTZ , Steering exact penalty methods , Technical Report OTC 2004 / 07 , Optimization Technology Center , Northwestern University , Evanston , IL , USA , April 2004 . [ 48 ] R . H . B YRD , J . - C . G ILBERT , AND J . N OCEDAL , Atrustregionmethodbasedoninteriorpointtechniques for nonlinear programming , Mathematical Programming , 89 ( 2000 ) , pp . 149 – 185 . 640 R E F E R E N C E S [ 49 ] R . H . B YRD , N . I . M . G OULD , J . N OCEDAL , AND R . A . W ALTZ , Analgorithmfornonlinearoptimization using linear programming and equality constrained subproblems , Mathematical Programming , Series B , 100 ( 2004 ) , pp . 27 – 48 . [ 50 ] R . H . B YRD , M . E . H RIBAR , AND J . N OCEDAL , An interior point method for large scale nonlinear programming , SIAM Journal on Optimization , 9 ( 1999 ) , pp . 877 – 900 . [ 51 ] R . H . B YRD , H . F . K HALFAN , AND R . B . S CHNABEL , Analysis of a symmetric rank - one trust region method , SIAM Journal on Optimization , 6 ( 1996 ) , pp . 1025 – 1039 . [ 52 ] R . H . B YRD , J . N OCEDAL , AND R . B . S CHNABEL , Representations of quasi - Newton matrices and their use in limited - memory methods , Mathematical Programming , Series A , 63 ( 1994 ) , pp . 129 – 156 . [ 53 ] R . H . B YRD , J . N OCEDAL , AND Y . Y UAN , Global convergence of a class of quasi - Newton methods on convex problems , SIAM Journal on Numerical Analysis , 24 ( 1987 ) , pp . 1171 – 1190 . [ 54 ] R . H . B YRD , R . B . S CHNABEL , AND G . A . S CHULTZ , Approximate solution of the trust regions prob - lem by minimization over two - dimensional subspaces , Mathematical Programming , 40 ( 1988 ) , pp . 247 – 263 . [ 55 ] R . H . B YRD , R . B . S CHNABEL , AND G . A . S HULTZ , Atrustregionalgorithmfornonlinearlyconstrained optimization , SIAM Journal on Numerical Analysis , 24 ( 1987 ) , pp . 1152 – 1170 . [ 56 ] M . R . C ELIS , J . E . D ENNIS , AND R . A . T APIA , Atrustregionstrategyfornonlinearequalityconstrained optimization , in Numerical Optimization , P . T . Boggs , R . H . Byrd , and R . B . Schnabel , eds . , SIAM , 1985 , pp . 71 – 82 . [ 57 ] R . C HAMBERLAIN , C . L EMARECHAL , H . C . P EDERSEN , AND M . J . D . P OWELL , The watchdog technique for forcing convergence in algorithms for constrained optimization , Mathematical Programming , 16 ( 1982 ) , pp . 1 – 17 . [ 58 ] S . H . C HENG AND N . J . H IGHAM , A modiﬁed Cholesky algorithm based on a symmetric indeﬁnite factorization , SIAM Journal of Matrix Analysis and Applications , 19 ( 1998 ) , pp . 1097 – 1100 . [ 59 ] C . M . C HIN AND R . F LETCHER , On the global convergence of an SLP - ﬁlter algorithm that takes EQP steps , Mathematical Programming , Series A , 96 ( 2003 ) , pp . 161 – 177 . [ 60 ] T . D . C HOI AND C . T . K ELLEY , Superlinear convergence and implicit ﬁltering , SIAM Journal on Optimization , 10 ( 2000 ) , pp . 1149 – 1162 . [ 61 ] V . C HV ´ ATAL , Linear Programming , W . H . Freeman and Company , New York , 1983 . [ 62 ] F . H . C LARKE , Optimization and Nonsmooth Analysis , John Wiley & Sons , New York , 1983 ( Reprinted by SIAM Publications , 1990 ) . [ 63 ] A . C OHEN , Rate of convergence of several conjugate gradient algorithms , SIAM Journal on Numerical Analysis , 9 ( 1972 ) , pp . 248 – 259 . [ 64 ] T . F . C OLEMAN , Linearly constrained optimization and projected preconditioned conjugate gradi - ents , in Proceedings of the Fifth SIAM Conference on Applied Linear Algebra , J . Lewis , ed . , Philadelphia , USA , 1994 , SIAM , pp . 118 – 122 . [ 65 ] T . F . C OLEMAN AND A . R . C ONN , Non - linear programming via an exact penalty - function : Asymptotic analysis , Mathematical Programming , 24 ( 1982 ) , pp . 123 – 136 . [ 66 ] T . F . C OLEMAN , B . G ARBOW , AND J . J . M OR ´ E , Software for estimating sparse Jacobian matrices , ACM Transactions on Mathematical Software , 10 ( 1984 ) , pp . 329 – 345 . [ 67 ] , Software for estimating sparse Hessian matrices , ACM Transactions on Mathematical Software , 11 ( 1985 ) , pp . 363 – 377 . [ 68 ] T . F . C OLEMAN AND J . J . M OR ´ E , Estimation of sparse Jacobian matrices and graph coloring problems , SIAM Journal on Numerical Analysis , 20 ( 1983 ) , pp . 187 – 209 . [ 69 ] , Estimation of sparse Hessian matrices and graph coloring problems , Mathematical Programming , 28 ( 1984 ) , pp . 243 – 270 . R E F E R E N C E S 641 [ 70 ] A . R . C ONN , N . I . M . G OULD , AND P . L . T OINT , Testingaclassofalgorithmsforsolvingminimization problems with simple bounds on the variables , Mathematics of Computation , 50 ( 1988 ) , pp . 399 – 430 . [ 71 ] , Convergence of quasi - Newton matrices generated by the symmetric rank one update , Mathematical Programming , 50 ( 1991 ) , pp . 177 – 195 . [ 72 ] , LANCELOT : a FORTRAN package for large - scale nonlinear optimization ( Release A ) , no . 17 in Springer Series in Computational Mathematics , Springer - Verlag , New York , 1992 . [ 73 ] , Numerical experiments with the LANCELOT package ( Release A ) for large - scale nonlinear optimization , Report 92 / 16 , Department of Mathematics , University of Namur , Belgium , 1992 . [ 74 ] A . R . C ONN , N . I . M . G OULD , AND P . L . T OINT , Trust - Region Methods , MPS - SIAM Series on Optimization , SIAM , 2000 . [ 75 ] A . R . C ONN , K . S CHEINBERG , AND P . L . T OINT , On the convergence of derivative - free methods for unconstrained optimization , in Approximation Theory and Optimization : Tributes to M . J . D . Powell , A . Iserles and M . Buhmann , eds . , Cambridge University Press , Cambridge , UK , 1997 , pp . 83 – 108 . [ 76 ] , Recent progress in unconstrained nonlinear optimization without derivatives , Mathemat - ical Programming , Series B , 79 ( 1997 ) , pp . 397 – 414 . [ 77 ] W . J . C OOK , W . H . C UNNINGHAM , W . R . P ULLEYBLANK , AND A . S CHRIJVER , Combinatorial Optimization , John Wiley & Sons , New York , 1997 . [ 78 ] B . F . C ORLISS AND L . B . R ALL , An introduction to automatic differentiation , in Computational Differentiation : Techniques , Applications , and Tools , M . Berz , C . Bischof , G . F . Corliss , and A . Griewank , eds . , SIAM Publications , Philadelphia , PA , 1996 , ch . 1 . [ 79 ] T . H . C ORMEN , C . E . L EISSERSON , AND R . L . R IVEST , Introduction to Algorithms , MIT Press , 1990 . [ 80 ] R . W . C OTTLE , J . - S . P ANG , AND R . E . S TONE , The Linear Complementarity Problem , Academic Press , San Diego , 1992 . [ 81 ] R . C OURANT , Variational methods for the solution of problems with equilibrium and vibration , Bulletin of the American Mathematical Society , 49 ( 1943 ) , pp . 1 – 23 . [ 82 ] H . P . C ROWDER AND P . W OLFE , Linear convergence of the conjugate gradient method , IBM Journal of Research and Development , 16 ( 1972 ) , pp . 431 – 433 . [ 83 ] A . C URTIS , M . J . D . P OWELL , AND J . R EID , On the estimation of sparse Jacobian matrices , Journal of the Institute of Mathematics and its Applications , 13 ( 1974 ) , pp . 117 – 120 . [ 84 ] J . C ZYZYK , S . M EHROTRA , M . W AGNER , AND S . J . W RIGHT , PCx : An interior - point code for linear programming , Optimization Methods and Software , 11 / 12 ( 1999 ) , pp . 397 – 430 . [ 85 ] Y . D AI AND Y . Y UAN , A nonlinear conjugate gradient method with a strong global convergence property , SIAM Journal on Optimization , 10 ( 1999 ) , pp . 177 – 182 . [ 86 ] G . B . D ANTZIG , Linear Programming and Extensions , Princeton University Press , Princeton , NJ , 1963 . [ 87 ] W . C . D AVIDON , Variablemetricmethodforminimization , TechnicalReportANL – 5990 ( revised ) , Argonne National Laboratory , Argonne , IL , 1959 . [ 88 ] , Variable metric method for minimization , SIAM Journal on Optimization , 1 ( 1991 ) , pp . 1 – 17 . [ 89 ] R . S . D EMBO , S . C . E ISENSTAT , AND T . S TEIHAUG , Inexact Newton methods , SIAM Journal on Numerical Analysis , 19 ( 1982 ) , pp . 400 – 408 . [ 90 ] J . E . D ENNIS , D . M . G AY , AND R . E . W ELSCH , Algorithm 573 — NL2SOL , An adaptive nonlinear least - squares algorithm , ACM Transactions on Mathematical Software , 7 ( 1981 ) , pp . 348 – 368 . 642 R E F E R E N C E S [ 91 ] J . E . D ENNIS AND J . J . M OR ´ E , Quasi - Newton methods , motivation and theory , SIAM Review , 19 ( 1977 ) , pp . 46 – 89 . [ 92 ] J . E . D ENNIS AND R . B . S CHNABEL , Numerical Methods for Unconstrained Optimization and Non - linear Equations , Prentice - Hall , Englewood Cliffs , NJ , 1983 . Reprinted by SIAM Publications , 1993 . [ 93 ] J . E . D ENNIS AND R . B . S CHNABEL , A view of unconstrained optimization , in Optimization , vol . 1 of Handbooks in Operations Research and Management , Elsevier Science Publishers , Amsterdam , The Netherlands , 1989 , pp . 1 – 72 . [ 94 ] I . I . D IKIN , Iterative solution of problems of linear and quadratic programming , Soviet Mathematics - Doklady , 8 ( 1967 ) , pp . 674 – 675 . [ 95 ] I . S . D UFF AND J . K . R EID , The multifrontal solution of indeﬁnite sparse symmetric linear equations , ACM Transactions on Mathematical Software , 9 ( 1983 ) , pp . 302 – 325 . [ 96 ] I . S . D UFF AND J . K . R EID , The design of MA48 : A code for the direct solution of sparse unsymmetric linear systems of equations , ACM Transactions on Mathematical Software , 22 ( 1996 ) , pp . 187 – 226 . [ 97 ] I . S . D UFF , J . K . R EID , N . M UNKSGAARD , AND H . B . N EILSEN , Directsolutionofsetsoflinearequations whose matrix is sparse symmetric and indeﬁnite , Journal of the Institute of Mathematics and its Applications , 23 ( 1979 ) , pp . 235 – 250 . [ 98 ] A . V . F IACCO AND G . P . M C C ORMICK , Nonlinear Programming : Sequential Unconstrained Mini - mizationTechniques , JohnWiley & Sons , NewYork , N . Y . , 1968 . ReprintedbySIAMPublications , 1990 . [ 99 ] R . F LETCHER , Ageneralquadraticprogrammingalgorithm , JournaloftheInstituteofMathematics and its Applications , 7 ( 1971 ) , pp . 76 – 91 . [ 100 ] , Second order corrections for non - differentiable optimization , in Numerical Analysis , D . Grifﬁths , ed . , Springer Verlag , 1982 , pp . 85 – 114 . Proceedings Dundee 1981 . [ 101 ] , Practical Methods of Optimization , John Wiley & Sons , New York , second ed . , 1987 . [ 102 ] , An optimal positive deﬁnite update for sparse Hessian matrices , SIAM Journal on Optimization , 5 ( 1995 ) , pp . 192 – 218 . [ 103 ] , Stable reduced hessian updates for indeﬁnite quadratic programming , Mathematical Programming , 87 ( 2000 ) , pp . 251 – 264 . [ 104 ] R . F LETCHER , A . G ROTHEY , AND S . L EYFFER , ComputingsparseHessianandJacobianapproximations with optimal hereditary properties , technical report , Department of Mathematics , University of Dundee , 1996 . [ 105 ] R . F LETCHER AND S . L EYFFER , Nonlinear programming without a penalty function , Mathematical Programming , Series A , 91 ( 2002 ) , pp . 239 – 269 . [ 106 ] R . F LETCHER , S . L EYFFER , AND P . L . T OINT , On the global convergence of an SLP - ﬁlter algorithm , Numerical Analysis Report NA / 183 , Dundee University , Dundee , Scotland , UK , 1999 . [ 107 ] R . F LETCHERAND C . M . R EEVES , Functionminimizationbyconjugategradients , ComputerJournal , 7 ( 1964 ) , pp . 149 – 154 . [ 108 ] R . F LETCHER AND E . S AINZ DE LA M AZA , Nonlinear programming and nonsmooth optimization by successive linear programming , Mathematical Programming , 43 ( 1989 ) , pp . 235 – 256 . [ 109 ] C . F LOUDAS AND P . P ARDALOS , eds . , Recent Advances in Global Optimization , Princeton University Press , Princeton , NJ , 1992 . [ 110 ] J . J . H . F ORREST AND J . A . T OMLIN , Updated triangular factors of the basis to maintain sparsity in the product form simplex method , Mathematical Programming , 2 ( 1972 ) , pp . 263 – 278 . R E F E R E N C E S 643 [ 111 ] A . F ORSGREN , P . E . G ILL , AND M . H . W RIGHT , Interior methods for nonlinear optimization , SIAM Review , 44 ( 2003 ) , pp . 525 – 597 . [ 112 ] R . F OURER , D . M . G AY , AND B . W . K ERNIGHAN , AMPL : A Modeling Language for Mathematical Programming , The Scientiﬁc Press , South San Francisco , CA , 1993 . [ 113 ] R . F OURER AND S . M EHROTRA , Solving symmetric indeﬁnite systems in an interior - point method for linear programming , Mathematical Programming , 62 ( 1993 ) , pp . 15 – 39 . [ 114 ] M . P . F RIEDLANDER AND M . A . S AUNDERS , A globally convergent linearly constrained Lagrangian method for nonlinear optimization , SIAM Journal on Optimization , 15 ( 2005 ) , pp . 863 – 897 . [ 115 ] K . R . F RISCH , The logarithmic potential method of convex programming , Technical Report , University Institute of Economics , Oslo , Norway , 1955 . [ 116 ] D . G ABAY , Reduced quasi - Newton methods with feasibility improvement for nonlinearly constrained optimization , Mathematical Programming Studies , 16 ( 1982 ) , pp . 18 – 44 . [ 117 ] U . M . G ARCIA - P ALOMARES AND O . L . M ANGASARIAN , Superlinearly convergent quasi - Newton meth - ods for nonlinearly constrained optimization problems , Mathematical Programming , 11 ( 1976 ) , pp . 1 – 13 . [ 118 ] D . M . G AY , More AD of nonlinear AMPL models : computing Hessian information and exploiting partial separability , in Computational Differentiation : Techniques , Applications , and Tools , M . Berz , C . Bischof , G . F . Corliss , and A . Griewank , eds . , SIAM Publications , Philadelphia , PA , 1996 , pp . 173 – 184 . [ 119 ] R . - P . G E AND M . J . D . P OWELL , The convergence of variable metric matrices in unconstrained optimization , Mathematical Programming , 27 ( 1983 ) , pp . 123 – 143 . [ 120 ] A . H . G EBREMEDHIN , F . M ANNE , AND A . P OTHEN , What color is your Jacobian ? Graph coloring for computing derivatives , SIAM Review , 47 ( 2005 ) , pp . 629 – 705 . [ 121 ] E . M . G ERTZ AND S . J . W RIGHT , Object - oriented software for quadratic programming , ACM Transactions on Mathematical Software , 29 ( 2003 ) , pp . 58 – 81 . [ 122 ] J . G ILBERT AND C . L EMAR ´ ECHAL , Some numerical experiments with variable - storage quasi - Newton algorithms , Mathematical Programming , Series B , 45 ( 1989 ) , pp . 407 – 435 . [ 123 ] J . G ILBERT AND J . N OCEDAL , Global convergence properties of conjugate gradient methods for optimization , SIAM Journal on Optimization , 2 ( 1992 ) , pp . 21 – 42 . [ 124 ] P . E . G ILL , G . H . G OLUB , W . M URRAY , AND M . A . S AUNDERS , Methods for modifying matrix factorizations , Mathematics of Computation , 28 ( 1974 ) , pp . 505 – 535 . [ 125 ] P . E . G ILL AND M . W . L EONARD , Limited - memory reduced - Hessian methods for unconstrained optimization , SIAM Journal on Optimization , 14 ( 2003 ) , pp . 380 – 401 . [ 126 ] P . E . G ILL AND W . M URRAY , Numerically stable methods for quadratic programming , Mathematical Programming , 14 ( 1978 ) , pp . 349 – 372 . [ 127 ] P . E . G ILL , W . M URRAY , AND M . A . S AUNDERS , User’s guide for SNOPT ( Version 5 . 3 ) : A FOR - TRAN package for large - scale nonlinear programming , Technical Report NA 97 - 4 , Department of Mathematics , University of California , San Diego , 1997 . [ 128 ] , SNOPT : An SQP algorithm for large - scale constrained optimization , SIAM Journal on Optimization , 12 ( 2002 ) , pp . 979 – 1006 . [ 129 ] P . E . G ILL , W . M URRAY , M . A . S AUNDERS , AND M . H . W RIGHT , User’s guide for SOL / QPSOL , Technical Report SOL84 – 6 , Department of Operations Research , Stanford University , Stanford , California , 1984 . [ 130 ] P . E . G ILL , W . M URRAY , AND M . H . W RIGHT , Practical Optimization , Academic Press , 1981 . [ 131 ] , Numerical Linear Algebra and Optimization , Vol . 1 , Addison Wesley , Redwood City , California , 1991 . 644 R E F E R E N C E S [ 132 ] D . G OLDFARB , Curvilinear path steplength algorithms for minimization which use directions of negative curvature , Mathematical Programming , 18 ( 1980 ) , pp . 31 – 40 . [ 133 ] D . G OLDFARB AND J . F ORREST , Steepest edge simplex algorithms for linear programming , Mathematical Programming , 57 ( 1992 ) , pp . 341 – 374 . [ 134 ] D . G OLDFARB AND J . K . R EID , A practicable steepest - edge simplex algorithm , Mathematical Programming , 12 ( 1977 ) , pp . 361 – 373 . [ 135 ] G . G OLUB AND D . O’L EARY , Some history of the conjugate gradient methods and the Lanczos algorithms : 1948 – 1976 , SIAM Review , 31 ( 1989 ) , pp . 50 – 100 . [ 136 ] G . H . G OLUB AND C . F . V AN L OAN , Matrix Computations , The Johns Hopkins University Press , Baltimore , third ed . , 1996 . [ 137 ] J . G ONDZIO , HOPDM ( version2 . 12 ) : AfastLPsolverbasedonaprimal - dualinteriorpointmethod , European Journal of Operations Research , 85 ( 1995 ) , pp . 221 – 225 . [ 138 ] , Multiple centrality corrections in a primal - dual method for linear programming , Computational Optimization and Applications , 6 ( 1996 ) , pp . 137 – 156 . [ 139 ] J . G ONDZIO AND A . G ROTHEY , Parallel interior point solver for structured quadratic programs : Applicationtoﬁnancialplanningproblems , TechnicalReportMS - 03 - 001 , SchoolofMathematics , University of Edinburgh , Scotland , 2003 . [ 140 ] N . I . M . G OULD , Ontheaccuratedeterminationofsearchdirectionsforsimpledifferentiablepenalty functions , I . M . A . Journal on Numerical Analysis , 6 ( 1986 ) , pp . 357 – 372 . [ 141 ] , On the convergence of a sequential penalty function method for constrained minimization , SIAM Journal on Numerical Analysis , 26 ( 1989 ) , pp . 107 – 128 . [ 142 ] , An algorithm for large scale quadratic programming , I . M . A . Journal on Numerical Analysis , 11 ( 1991 ) , pp . 299 – 324 . [ 143 ] N . I . M . G OULD , M . E . H RIBAR , AND J . N OCEDAL , On the solution of equality constrained quadratic problems arising in optimization , SIAM Journal on Scientiﬁc Computing , 23 ( 2001 ) , pp . 1375 – 1394 . [ 144 ] N . I . M . G OULD , S . L EYFFER , AND P . L . T OINT , A multidimensional ﬁlter algorithm for nonlinear equations and nonlinear least squares , SIAM Journal on Optimization , 15 ( 2004 ) , pp . 17 – 38 . [ 145 ] N . I . M . G OULD , S . L UCIDI , M . R OMA , AND P . L . T OINT , Solving the trust - region subproblem using the Lanczos method . SIAM Journal on Optimization , 9 ( 1999 ) , pp . 504 – 525 . [ 146 ] N . I . M . G OULD , D . O RBAN , AND P . L . T OINT , GALAHAD —a library of thread - safe Fortran 90 packages for large - scale nonlinear optimization , ACM Transactions on Mathematical Software , 29 ( 2003 ) , pp . 353 – 372 . [ 147 ] N . I . M . G OULD , D . O RBAN , AND P . L . T OINT , Numerical methods for large - scale nonlinear optimization , Acta Numerica , 14 ( 2005 ) , pp . 299 – 361 . [ 148 ] N . I . M . G OULD AND P . L . T OINT , An iterative working - set method for large - scale non - convex quadratic programming , Applied Numerical Mathematics , 43 ( 2002 ) , pp . 109 – 128 . [ 149 ] , Numerical methods for large - scale non - convex quadratic programming , in Trends in Industrial and Applied Mathematics , A . H . Siddiqi and M . Koˇcvara , eds . , Dordrecht , The Netherlands , 2002 , Kluwer Academic Publishers , pp . 149 – 179 . [ 150 ] A . G RIEWANK , Achieving logarithmic growth of temporal and spatial complexity in reverse automatic differentiation , Optimization Methods and Software , 1 ( 1992 ) , pp . 35 – 54 . [ 151 ] , Automatic directional differentiation of nonsmooth composite functions , in Seventh French - German Conference on Optimization , 1994 . [ 152 ] A . G RIEWANK , Evaluating Derivatives : Principles and Techniques of Automatic Differentiation , vol . 19 of Frontiers in Applied Mathematics , SIAM , 2000 . R E F E R E N C E S 645 [ 153 ] A . G RIEWANK AND G . F . C ORLISS , eds . , Automatic Differentition of Algorithms , SIAM Publications , Philadelphia , Penn . , 1991 . [ 154 ] A . G RIEWANK , D . J UEDES , AND J . U TKE , ADOL - C , A package for the automatic differentiation of algorithms written in C / C + + , ACM Transactions on Mathematical Software , 22 ( 1996 ) , pp . 131 – 167 . [ 155 ] A . G RIEWANK AND P . L . T OINT , Local convergence analysis of partitioned quasi - Newton updates , Numerische Mathematik , 39 ( 1982 ) , pp . 429 – 448 . [ 156 ] , Partitioned variable metric updates for large structured optimization problems , Numerische Mathematik , 39 ( 1982 ) , pp . 119 – 137 . [ 157 ] J . G RIMM , L . P OTTIER , AND N . R OSTAING - S CHMIDT , Optimaltimeandminimumspacetimeproduct for reversing a certain class of programs , in Computational Differentiation , Techniques , Appli - cations , and Tools , M . Berz , C . Bischof , G . Corliss , and A . Griewank , eds . , SIAM , Philadelphia , 1996 , pp . 95 – 106 . [ 158 ] L . G RIPPO , F . L AMPARIELLO , AND S . L UCIDI , A nonmonotone line search technique for Newton’s method , SIAM Journal on Numerical Analysis , 23 ( 1986 ) , pp . 707 – 716 . [ 159 ] C . G U ´ ERET , C . P RINS , AND M . S EVAUX , Applications of optimization with Xpress - MP , Dash Optimization , 2002 . [ 160 ] W . W . H AGER , Minimizing a quadratic over a sphere , SIAM Journal on Optimization , 12 ( 2001 ) , pp . 188 – 208 . [ 161 ] W . W . H AGER AND H . Z HANG , A new conjugate gradient method with guaranteed descent and an efﬁcient line search , SIAM Journal on Optimization , 16 ( 2005 ) , pp . 170 – 192 . [ 162 ] , A survey of nonlinear conjugate gradient methods . To appear in the Paciﬁc Journal of Optimization , 2005 . [ 163 ] S . P . H AN , Superlinearly convergent variable metric algorithms for general nonlinear programming problems , Mathematical Programming , 11 ( 1976 ) , pp . 263 – 282 . [ 164 ] , Agloballyconvergentmethodfornonlinearprogramming , JournalofOptimizationTheory and Applications , 22 ( 1977 ) , pp . 297 – 309 . [ 165 ] S . P . H AN AND O . L . M ANGASARIAN , Exact penalty functions in nonlinear programming , Mathematical Programming , 17 ( 1979 ) , pp . 251 – 269 . [ 166 ] H ARWELL S UBROUTINE L IBRARY , Acatalogueofsubroutines ( release13 ) , AEREHarwellLaboratory , Harwell , Oxfordshire , England , 1998 . [ 167 ] M . R . H ESTENES , Multiplier and gradient methods , Journal of Optimization Theory and Applications , 4 ( 1969 ) , pp . 303 – 320 . [ 168 ] M . R . H ESTENES AND E . S TIEFEL , Methods of conjugate gradients for solving linear systems , Journal of Research of the National Bureau of Standards , 49 ( 1952 ) , pp . 409 – 436 . [ 169 ] N . J . H IGHAM , Accuracy and Stability of Numerical Algorithms , SIAM Publications , Philadelphia , 1996 . [ 170 ] J . - B . H IRIART - U RRUTY AND C . L EMARECHAL , Convex Analysis and Minimization Algorithms , Springer - Verlag , Berlin , New York , 1993 . [ 171 ] P . H OUGH , T . K OLDA , AND V . T ORCZON , Asynchronous parallel pattern search for nonlinear optimization , SIAM Journal on Optimization , 23 ( 2001 ) , pp . 134 – 156 . [ 172 ] ILOG CPLEX 8 . 0 , User’s Manual , ILOG SA , Gentilly , France , 2002 . [ 173 ] D . J ONES , C . P ERTTUNEN , AND B . S TUCKMAN , Lipschitzian optimization without the Lipschitz constant , Journal of Optimization Theory and Applications , 79 ( 1993 ) , pp . 157 – 181 . [ 174 ] P . K ALL AND S . W . W ALLACE , Stochastic Programming , John Wiley & Sons , New York , 1994 . 646 R E F E R E N C E S [ 175 ] N . K ARMARKAR , A new polynomial - time algorithm for linear programming , Combinatorics , 4 ( 1984 ) , pp . 373 – 395 . [ 176 ] C . K ELLER , N . I . M . G OULD , AND A . J . W ATHEN , Constraint preconditioning for indeﬁnite linear systems , SIAM Journal on Matrix Analysis and Applications , 21 ( 2000 ) , pp . 1300 – 1317 . [ 177 ] C . T . K ELLEY , Iterative Methods for Linear and Nonlinear Equations , SIAM Publications , Philadelphia , PA , 1995 . [ 178 ] C . T . K ELLEY , Detection and remediation of stagnation in the Nelder - Mead algorithm using a sufﬁcient decrease condition , SIAM Journal on Optimization , 10 ( 1999 ) , pp . 43 – 55 . [ 179 ] , Iterative Methods for Optimization , no . 18 in Frontiers in Applied Mathematics , SIAM Publications , Philadelphia , PA , 1999 . [ 180 ] L . G . K HACHIYAN , A polynomial algorithm in linear programming , Soviet Mathematics Doklady , 20 ( 1979 ) , pp . 191 – 194 . [ 181 ] H . F . K HALFAN , R . H . B YRD , AND R . B . S CHNABEL , A theoretical and experimental study of the symmetric rank one update , SIAM Journal on Optimization , 3 ( 1993 ) , pp . 1 – 24 . [ 182 ] V . K LEE AND G . J . M INTY , How good is the simplex algorithm ? in Inequalities , O . Shisha , ed . , Academic Press , New York , 1972 , pp . 159 – 175 . [ 183 ] T . G . K OLDA , R . M . L EWIS , AND V . T ORCZON , Optimization by direct search : New perspectives on some classical and modern methods , SIAM Review , 45 ( 2003 ) , pp . 385 – 482 . [ 184 ] M . K O ˇ CVARA AND M . S TINGL , PENNON , a code for nonconvex nonlinear and semideﬁnite programming , Optimization Methods and Software , 18 ( 2003 ) , pp . 317 – 333 . [ 185 ] H . W . K UHN AND A . W . T UCKER , Nonlinear programming , in Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability , J . Neyman , ed . , Berkeley , CA , 1951 , University of California Press , pp . 481 – 492 . [ 186 ] J . W . L AGARIAS , J . A . R EEDS , M . H . W RIGHT , AND P . E . W RIGHT , Convergence properties of the Nelder - Mead simplex algorithm in low dimensions , SIAM Journal on Optimization , 9 ( 1998 ) , pp . 112 – 147 . [ 187 ] S . L ANG , Real Analysis , Addison - Wesley , Reading , MA , second ed . , 1983 . [ 188 ] C . L . L AWSONAND R . J . H ANSON , SolvingLeastSquaresProblems , Prentice - Hall , EnglewoodCliffs , NJ , 1974 . [ 189 ] C . L EMAR ´ ECHAL , A view of line searches , in Optimization and Optimal Control , W . Oettli and J . Stoer , eds . , no . 30 in Lecture Notes in Control and Information Science , Springer - Verlag , 1981 , pp . 59 – 78 . [ 190 ] K . L EVENBERG , A method for the solution of certain non - linear problems in least squares , Quarterly of Applied Mathematics , 2 ( 1944 ) , pp . 164 – 168 . [ 191 ] S . L EYFFER , G . L OPEZ - C ALVA , AND J . N OCEDAL , Interior methods for mathematical programs with complementarityconstraints , technicalreport8 , OptimizationTechnologyCenter , Northwestern University , Evanston , IL , 2004 . [ 192 ] C . L IN AND J . M OR ´ E , Newton’s method for large bound - constrained optimization problems , SIAM Journal on Optimization , 9 ( 1999 ) , pp . 1100 – 1127 . [ 193 ] C . L IN AND J . J . M OR ´ E , Incomplete Cholesky factorizations with limited memory , SIAM Journal on Scientiﬁc Computing , 21 ( 1999 ) , pp . 24 – 45 . [ 194 ] D . C . L IU AND J . N OCEDAL , On the limited - memory BFGS method for large scale optimization , Mathematical Programming , 45 ( 1989 ) , pp . 503 – 528 . [ 195 ] D . L UENBERGER , Introduction to Linear and Nonlinear Programming , Addison Wesley , second ed . , 1984 . R E F E R E N C E S 647 [ 196 ] L . L UK ˇ SAN AND J . V L ˇ CEK , Indeﬁnitely preconditioned inexact Newton method for large sparse equal - ity constrained nonlinear programming problems , Numerical Linear Algebra with Applications , 5 ( 1998 ) , pp . 219 – 247 . [ 197 ] Macsyma User’s Guide , second ed . , 1996 . [ 198 ] O . L . M ANGASARIAN , Nonlinear Programming , McGraw - Hill , New York , 1969 . Reprinted by SIAM Publications , 1995 . [ 199 ] N . M ARATOS , Exact penalty function algorithms for ﬁnite dimensional and control optimization problems , PhD thesis , University of London , 1978 . [ 200 ] M . M ARAZZI AND J . N OCEDAL , Wedge trust region methods for derivative free optimization , Mathematical Programming , Series A , 91 ( 2002 ) , pp . 289 – 305 . [ 201 ] H . M . M ARKOWITZ , Portfolio selection , Journal of Finance , 8 ( 1952 ) , pp . 77 – 91 . [ 202 ] , Theeliminationformoftheinverseanditsapplicationtolinearprogramming , Management Science , 3 ( 1957 ) , pp . 255 – 269 . [ 203 ] D . W . M ARQUARDT , An algorithm for least squares estimation of non - linear parameters , SIAM Journal , 11 ( 1963 ) , pp . 431 – 441 . [ 204 ] D . Q . M AYNE AND E . P OLAK , A superlinearly convergent algorithm for constrained optimization problems , Mathematical Programming Studies , 16 ( 1982 ) , pp . 45 – 61 . [ 205 ] L . M C L INDEN , An analogue of Moreau’s proximation theorem , with applications to the nonlinear complementarity problem , Paciﬁc Journal of Mathematics , 88 ( 1980 ) , pp . 101 – 161 . [ 206 ] N . M EGIDDO , Pathways to the optimal set in linear programming , in Progress in Mathematical Programming : Interior - Point and Related Methods , N . Megiddo , ed . , Springer - Verlag , New York , NY , 1989 , ch . 8 , pp . 131 – 158 . [ 207 ] S . M EHROTRA , On the implementation of a primal - dual interior point method , SIAM Journal on Optimization , 2 ( 1992 ) , pp . 575 – 601 . [ 208 ] S . M IZUNO , M . T ODD , AND Y . Y E , On adaptive step primal - dual interior - point algorithms for linear programming , Mathematics of Operations Research , 18 ( 1993 ) , pp . 964 – 981 . [ 209 ] J . L . M ORALES AND J . N OCEDAL , Automatic preconditioning by limited memory quasi - newton updating , SIAM Journal on Optimization , 10 ( 2000 ) , pp . 1079 – 1096 . [ 210 ] J . J . M OR ´ E , The Levenberg - Marquardt algorithm : Implementation and theory , in Lecture Notes in Mathematics , No . 630 – NumericalAnalysis , G . Watson , ed . , Springer - Verlag , 1978 , pp . 105 – 116 . [ 211 ] , Recent developments in algorithms and software for trust region methods , in Mathematical Programming : The State of the Art , Springer - Verlag , Berlin , 1983 , pp . 258 – 287 . [ 212 ] , A collection of nonlinear model problems , in Computational Solution of Nonlinear Systems of Equations , vol . 26 of Lectures in Applied Mathematics , American Mathematical Society , Providence , RI , 1990 , pp . 723 – 762 . [ 213 ] J . J . M OR ´ E AND D . C . S ORENSEN , On the use of directions of negative curvature in a modiﬁed Newton method , Mathematical Programming , 16 ( 1979 ) , pp . 1 – 20 . [ 214 ] , Computing a trust region step , SIAM Journal on Scientiﬁc and Statistical Computing , 4 ( 1983 ) , pp . 553 – 572 . [ 215 ] , Newton’s method , in Studies in Numerical Analysis , vol . 24 of MAA Studies in Mathematics , The Mathematical Association of America , 1984 , pp . 29 – 82 . [ 216 ] J . J . M OR ´ E AND D . J . T HUENTE , Line search algorithms with guaranteed sufﬁcient decrease , ACM Transactions on Mathematical Software , 20 ( 1994 ) , pp . 286 – 307 . [ 217 ] J . J . M OR ´ E AND S . J . W RIGHT , Optimization Software Guide , SIAM Publications , Philadelphia , 1993 . 648 R E F E R E N C E S [ 218 ] B . A . M URTAGH AND M . A . S AUNDERS , MINOS 5 . 1 User’s guide , Technical Report SOL - 83 - 20R , Stanford University , 1987 . [ 219 ] K . G . M URTY AND S . N . K ABADI , Some NP - complete problems in quadratic and nonlinear programming , Mathematical Programming , 19 ( 1987 ) , pp . 200 – 212 . [ 220 ] S . G . N ASH , Newton - type minimization via the Lanczos method , SIAM Journal on Numerical Analysis , 21 ( 1984 ) , pp . 553 – 572 . [ 221 ] , SUMT ( Revisited ) , Operations Research , 46 ( 1998 ) , pp . 763 – 775 . [ 222 ] U . N AUMANN , Optimal accumulation of Jacobian matrices by elimination methods on the dual computational graph , Mathematical Programming , 99 ( 2004 ) , pp . 399 – 421 . [ 223 ] J . A . N ELDER AND R . M EAD , A simplex method for function minimization , The Computer Journal , 8 ( 1965 ) , pp . 308 – 313 . [ 224 ] G . L . N EMHAUSER AND L . A . W OLSEY , Integer and Combinatorial Optimization , John Wiley & Sons , New York , 1988 . [ 225 ] A . S . N EMIROVSKII AND D . B . Y UDIN , Problem complexity and method efﬁciency , John Wiley & Sons , New York , 1983 . [ 226 ] Y . E . N ESTEROVAND A . S . N EMIROVSKII , InteriorPointPolynomialMethodsinConvexProgramming , SIAM Publications , Philadelphia , 1994 . [ 227 ] G . N . N EWSAM AND J . D . R AMSDELL , Estimation of sparse Jacobian matrices , SIAM Journal on Algebraic and Discrete Methods , 4 ( 1983 ) , pp . 404 – 418 . [ 228 ] J . N OCEDAL , Updatingquasi - Newtonmatriceswithlimitedstorage , MathematicsofComputation , 35 ( 1980 ) , pp . 773 – 782 . [ 229 ] , Theory of algorithms for unconstrained optimization , Acta Numerica , 1 ( 1992 ) , pp . 199 – 242 . [ 230 ] J . M . O RTEGA AND W . C . R HEINBOLDT , Iterative solution of nonlinear equations in several variables , Academic Press , New York and London , 1970 . [ 231 ] M . R . O SBORNE , Nonlinear least squares—the Levenberg algorithm revisited , Journal of the Australian Mathematical Society , Series B , 19 ( 1976 ) , pp . 343 – 357 . [ 232 ] , Finite Algorithms in Optimization and Data Analysis , John Wiley & Sons , New York , 1985 . [ 233 ] M . L . O VERTON , Numerical Computing with IEEE Floating Point Arithmetic , SIAM , Philadelphia , PA , 2001 . [ 234 ] C . C . P AIGE AND M . A . S AUNDERS , LSQR : An algorithm for sparse linear equations and sparse least squares , ACM Transactions on Mathematical Software , 8 ( 1982 ) , pp . 43 – 71 . [ 235 ] C . H . P APADIMITRIOUAND K . S TEIGLITZ , CombinatorialOptimization : AlgorithmsandComplexity , Prentice Hall , Englewood Cliffs , NJ , 1982 . [ 236 ] E . P OLAK , Optimization : Algorithms and Consistent Approximations , no . 124 in Applied Mathematical Sciences , Springer , 1997 . [ 237 ] E . P OLAK AND G . R IBI ` ERE , Note sur la convergence de m´ethodes de directions conjugu´ees , Revue Franc¸aise d’Informatique et de Recherche Op´erationnelle , 16 ( 1969 ) , pp . 35 – 43 . [ 238 ] B . T . P OLYAK , The conjugate gradient method in extremal problems , U . S . S . R . Computational Mathematics and Mathematical Physics , 9 ( 1969 ) , pp . 94 – 112 . [ 239 ] M . J . D . P OWELL , An efﬁcient method for ﬁnding the minimum of a function of several variables without calculating derivatives , Computer Journal , 91 ( 1964 ) , pp . 155 – 162 . [ 240 ] , A method for nonlinear constraints in minimization problems , in Optimization , R . Fletcher , ed . , Academic Press , New York , NY , 1969 , pp . 283 – 298 . R E F E R E N C E S 649 [ 241 ] , A hybrid method for nonlinear equations , in Numerical Methods for Nonlinear Algebraic Equations , P . Rabinowitz , ed . , Gordon & Breach , London , 1970 , pp . 87 – 114 . [ 242 ] , Problems related to unconstrained optimization , in Numerical Methods for Uncon - strained Optimization , W . Murray , ed . , Academic Press , 1972 , pp . 29 – 55 . [ 243 ] , On search directions for minimization algorithms , Mathematical Programming , 4 ( 1973 ) , pp . 193 – 201 . [ 244 ] , Convergence properties of a class of minimization algorithms , in Nonlinear Programming 2 , O . L . Mangasarian , R . R . Meyer , and S . M . Robinson , eds . , Academic Press , New York , 1975 , pp . 1 – 27 . [ 245 ] , Some convergence properties of the conjugate gradient method , Mathematical Programming , 11 ( 1976 ) , pp . 42 – 49 . [ 246 ] , Someglobalconvergencepropertiesofavariablemetricalgorithmforminimizationwithout exact line searches , in Nonlinear Programming , SIAM - AMS Proceedings , Vol . IX , R . W . Cottle and C . E . Lemke , eds . , SIAM Publications , 1976 , pp . 53 – 72 . [ 247 ] , A fast algorithm for nonlinearly constrained optimization calculations , in Numerical Analysis Dundee 1977 , G . A . Watson , ed . , Springer Verlag , Berlin , 1977 , pp . 144 – 157 . [ 248 ] , Restart procedures for the conjugate gradient method , Mathematical Programming , 12 ( 1977 ) , pp . 241 – 254 . [ 249 ] , Algorithms for nonlinear constraints that use Lagrangian functions , Mathematical Programming , 14 ( 1978 ) , pp . 224 – 248 . [ 250 ] , The convergence of variable metric methods for nonlinearly constrained optimization calculations , in Nonlinear Programming 3 , Academic Press , New York and London , 1978 , pp . 27 – 63 . [ 251 ] , On the rate of convergence of variable metric algorithms for unconstrained optimization , Technical Report DAMTP 1983 / NA7 , Department of Applied Mathematics and Theoretical Physics , Cambridge University , 1983 . [ 252 ] , Variable metric methods for constrained optimization , in Mathematical Programming : The State of the Art , Bonn , 1982 , Springer - Verlag , Berlin , 1983 , pp . 288 – 311 . [ 253 ] , Nonconvex minimization calculations and the conjugate gradient method , Lecture Notes in Mathematics , 1066 ( 1984 ) , pp . 122 – 141 . [ 254 ] , The performance of two subroutines for constrained optimization on some difﬁcult test problems , in Numerical Optimization , P . T . Boggs , R . H . Byrd , and R . B . Schnabel , eds . , SIAM Publications , Philadelphia , 1984 . [ 255 ] , Convergencepropertiesof algorithms fornonlinear optimization , SIAMReview , 28 ( 1986 ) , pp . 487 – 500 . [ 256 ] , Direct search algorithms for optimization calculations , Acta Numerica , 7 ( 1998 ) , pp . 287 – 336 . [ 257 ] , UOBYQA : unconstrained optimization by quadratic approximation , Mathematical Programming , Series B , 92 ( 2002 ) , pp . 555 – 582 . [ 258 ] , On trust - region methods for unconstrained minimization without derivatives , Mathemat - ical Programming , 97 ( 2003 ) , pp . 605 – 623 . [ 259 ] , Least Frobenius norm updating of quadratic models that satisfy interpolation conditions , Mathematical Programming , 100 ( 2004 ) , pp . 183 – 215 . [ 260 ] , The NEWUOA software for unconstrained optimization without derivatives , Numerical Analysis Report DAMPT 2004 / NA05 , University of Cambridge , Cambridge , UK , 2004 . 650 R E F E R E N C E S [ 261 ] M . J . D . P OWELL AND P . L . T OINT , On the estimation of sparse Hessian matrices , SIAM Journal on Numerical Analysis , 16 ( 1979 ) , pp . 1060 – 1074 . [ 262 ] R . L . R ARDIN , Optimization in Operations Research , Prentice Hall , Englewood Cliffs , NJ , 1998 . [ 263 ] F . R ENDL AND H . W OLKOWICZ , A semideﬁnite framework for trust region subproblems with applications to large scale minimization , Mathematical Programming , 77 ( 1997 ) , pp . 273 – 299 . [ 264 ] J . M . R ESTREPO , G . K . L EAF , AND A . G RIEWANK , Circumventing storage limitations in variational data assimilation studies , SIAM Journal on Scientiﬁc Computing , 19 ( 1998 ) , pp . 1586 – 1605 . [ 265 ] K . R ITTER , Ontherateofsuperlinearconvergenceofaclassofvariablemetricmethods , Numerische Mathematik , 35 ( 1980 ) , pp . 293 – 313 . [ 266 ] S . M . R OBINSON , A quadratically convergent algorithm for general nonlinear programming problems , Mathematical Programming , 3 ( 1972 ) , pp . 145 – 156 . [ 267 ] , Perturbed Kuhn - Tucker points and rates of convergence for a class of nonlinear - programming algorithms , Mathematical Programming , 7 ( 1974 ) , pp . 1 – 16 . [ 268 ] , Generalized equations and their solutions . Part II : Applications to nonlinear programming , Mathematical Programming Study , 19 ( 1982 ) , pp . 200 – 221 . [ 269 ] R . T . R OCKAFELLAR , The multiplier method of Hestenes and Powell applied to convex programming , Journal of Optimization Theory and Applications , 12 ( 1973 ) , pp . 555 – 562 . [ 270 ] , Lagrange multipliers and optimality , SIAM Review , 35 ( 1993 ) , pp . 183 – 238 . [ 271 ] J . B . R OSENAND J . K REUSER , Agradientprojectionalgorithmfornonlinearconstraints , inNumerical Methods for Non - Linear Optimization , F . A . Lootsma , ed . , Academic Press , London and New York , 1972 , pp . 297 – 300 . [ 272 ] , Iterative Methods for Sparse Linear Systems , SIAM Publications , Philadelphia , PA , second ed . , 2003 . [ 273 ] Y . S AAD AND M . S CHULTZ , GMRES : A generalized minimal residual algorithm for solving non - symmetric linear systems , SIAM Journal on Scientiﬁc and Statistical Computing , 7 ( 1986 ) , pp . 856 – 869 . [ 274 ] H . S CHEEL AND S . S CHOLTES , Mathematical programs with complementarity constraints : Stationarity , optimality and sensitivity , Mathematics of Operations Research , 25 ( 2000 ) , pp . 1 – 22 . [ 275 ] T . S CHLICK , ModiﬁedCholeskyfactorizationsforsparsepreconditioners , SIAMJournalonScientiﬁc Computing , 14 ( 1993 ) , pp . 424 – 445 . [ 276 ] R . B . S CHNABEL AND E . E SKOW , A new modiﬁed Cholesky factorization , SIAM Journal on Scientiﬁc Computing , 11 ( 1991 ) , pp . 1136 – 1158 . [ 277 ] R . B . S CHNABEL AND P . D . F RANK , Tensor methods for nonlinear equations , SIAM Journal on Numerical Analysis , 21 ( 1984 ) , pp . 815 – 843 . [ 278 ] G . S CHULLER , On the order of convergence of certain quasi - Newton methods , Numerische Mathematik , 23 ( 1974 ) , pp . 181 – 192 . [ 279 ] G . A . S CHULTZ , R . B . S CHNABEL , AND R . H . B YRD , A family of trust - region - based algorithms for unconstrained minimization with strong global convergence properties , SIAM Journal on Numerical Analysis , 22 ( 1985 ) , pp . 47 – 67 . [ 280 ] G . A . F . S EBER AND C . J . W ILD , Nonlinear Regression , John Wiley & Sons , New York , 1989 . [ 281 ] T . S TEIHAUG , The conjugate gradient method and trust regions in large scale optimization , SIAM Journal on Numerical Analysis , 20 ( 1983 ) , pp . 626 – 637 . [ 282 ] J . S TOER , On the relation between quadratic termination and convergence properties of minimization algorithms . Part I : Theory , Numerische Mathematik , 28 ( 1977 ) , pp . 343 – 366 . R E F E R E N C E S 651 [ 283 ] K . T ANABE , Centered Newton method for mathematical programming , in System Modeling and Optimization : Proceedings of the 13th IFIP conference , vol . 113 of Lecture Notes in Control and Information Systems , Berlin , 1988 , Springer - Verlag , pp . 197 – 206 . [ 284 ] M . J . T ODD , Potential reduction methods in mathematical programming , Mathematical Programming , Series B , 76 ( 1997 ) , pp . 3 – 45 . [ 285 ] , Semideﬁnite optimization , Acta Numerica , 10 ( 2001 ) , pp . 515 – 560 . [ 286 ] , Detecting infeasibility in infeasible - interior - point methods for optimization , in Founda - tions of Computational Mathematics , Minneapolis , 2002 , F . Cucker , R . DeVore , P . Olver , and E . Suli , eds . , Cambridge University Press , Cambridge , 2004 , pp . 157 – 192 . [ 287 ] M . J . T ODD AND Y . Y E , A centered projective algorithm for linear programming , Mathematics of Operations Research , 15 ( 1990 ) , pp . 508 – 529 . [ 288 ] P . L . T OINT , On sparse and symmetric matrix updating subject to a linear equation , Mathematics of Computation , 31 ( 1977 ) , pp . 954 – 961 . [ 289 ] , Towards an efﬁcient sparsity exploiting Newton method for minimization , in Sparse Matrices and Their Uses , Academic Press , New York , 1981 , pp . 57 – 87 . [ 290 ] L . T REFETHEN AND D . B AU , Numerical Linear Algebra , SIAM , Philadelphia , PA , 1997 . [ 291 ] M . U LBRICH , S . U LBRICH , AND L . N . V ICENTE , A globally convergence primal - dual interior - point ﬁlter method for nonlinear programming , Mathematical Programming , Series B , 100 ( 2004 ) , pp . 379 – 410 . [ 292 ] L . V ANDENBERGHE AND S . B OYD , Semideﬁnite programming , SIAM Review , 38 ( 1996 ) , pp . 49 – 95 . [ 293 ] R . J . V ANDERBEI , Linear Programming : Foundations and Extensions , Springer Verlag , New York , second ed . , 2001 . [ 294 ] R . J . V ANDERBEI AND D . F . S HANNO , An interior point algorithm for nonconvex nonlinear programming , Computational Optimization and Applications , 13 ( 1999 ) , pp . 231 – 252 . [ 295 ] A . V ARDI , A trust region algorithm for equality constrained minimization : convergence properties and implementation , SIAM Journal of Numerical Analysis , 22 ( 1985 ) , pp . 575 – 591 . [ 296 ] S . A . V AVASIS , Quadratic programming is NP , Information Processing Letters , 36 ( 1990 ) , pp . 73 – 77 . [ 297 ] , Nonlinear Optimization , Oxford University Press , New York and Oxford , 1991 . [ 298 ] A . W¨ ACHTER , An interior point algorithm for large - scale nonlinear optimization with applications in process engineering , PhD thesis , Department of Chemical Engineering , Carnegie Mellon University , Pittsburgh , PA , USA , 2002 . [ 299 ] A . W¨ ACHTER AND L . T . B IEGLER , Failure of global convergence for a class of interior point methods for nonlinear programming , Mathematical Programming , 88 ( 2000 ) , pp . 565 – 574 . [ 300 ] , Line search ﬁlter methods for nonlinear programming : Motivation and global convergence , SIAM Journal on Optimization , 16 ( 2005 ) , pp . 1 – 31 . [ 301 ] , On the implementation of an interior - point ﬁlter line - search algorithm for large - scale nonlinear programming , Mathematical Programming , 106 ( 2006 ) , pp . 25 – 57 . [ 302 ] H . W ALKER , Implementation of the GMRES method using Householder transformations , SIAM Journal on Scientiﬁc and Statistical Computing , 9 ( 1989 ) , pp . 815 – 825 . [ 303 ] R . A . W ALTZ , J . L . M ORALES , J . N OCEDAL , AND D . O RBAN , An interior algorithm for nonlinear optimization that combines line search and trust region steps , Tech . Rep . 2003 - 6 , Optimization Technology Center , Northwestern University , Evanston , IL , USA , June 2003 . [ 304 ] W ATERLOO M APLE S OFTWARE , I NC , Maple V software package , 1994 . 652 R E F E R E N C E S [ 305 ] L . T . W ATSON , Numerical linear algebra aspects of globally convergent homotopy methods , SIAM Review , 28 ( 1986 ) , pp . 529 – 545 . [ 306 ] R . B . W ILSON , A simplicial algorithm for concave programming , PhD thesis , Graduate School of Business Administration , Harvard University , 1963 . [ 307 ] D . W INFIELD , Function and functional optimization by interpolation in data tables , PhD thesis , Harvard University , Cambridge , USA , 1969 . [ 308 ] W . L . W INSTON , Operations Research , Wadsworth Publishing Co . , third ed . , 1997 . [ 309 ] P . W OLFE , A duality theorem for nonlinear programming , Quarterly of Applied Mathematics , 19 ( 1961 ) , pp . 239 – 244 . [ 310 ] , The composite simplex algorithm , SIAM Review , 7 ( 1965 ) , pp . 42 – 54 . [ 311 ] S . W OLFRAM , The Mathematica Book , Cambridge University Press and Wolfram Media , Inc . , third ed . , 1996 . [ 312 ] L . A . W OLSEY , Integer Programming , Wiley – Interscience Series in Discrete Mathematics and Optimization , John Wiley & Sons , New York , NY , 1998 . [ 313 ] M . H . W RIGHT , Interiormethodsforconstrainedoptimization , inActaNumerica1992 , Cambridge University Press , Cambridge , 1992 , pp . 341 – 407 . [ 314 ] , Direct search methods : Once scorned , now respectable , in Numerical Analysis 1995 ( Pro - ceedings of the 1995 Dundee Biennial Conference in Numerical Analysis ) , Addison Wesley Longman , 1996 , pp . 191 – 208 . [ 315 ] S . J . W RIGHT , Applying new optimization algorithms to model predictive control , in Chemical Process Control - V , J . C . Kantor , ed . , CACHE , 1997 . [ 316 ] , Primal - Dual Interior - Point Methods , SIAM Publications , Philadelphia , PA , 1997 . [ 317 ] , Modiﬁed Cholesky factorizations in interior - point algorithms for linear programming , SIAM Journal on Optimization , 9 ( 1999 ) , pp . 1159 – 1191 . [ 318 ] S . J . W RIGHT AND J . N . H OLT , An inexact Levenberg - Marquardt method for large sparse nonlinear least squares problems , Journal of the Australian Mathematical Society , Series B , 26 ( 1985 ) , pp . 387 – 403 . [ 319 ] E . A . Y ILDIRIM AND S . J . W RIGHT , Warm - start strategies in interior - point methods for linear programming , SIAM Journal on Optimization , 12 ( 2002 ) , pp . 782 – 810 . [ 320 ] Y . Y UAN , On the truncated conjugate - gradient method , Mathematical Programming , Series A , 87 ( 2000 ) , pp . 561 – 573 . [ 321 ] Y . Z HANG , Solving large - scale linear programs with interior - point methods under the Matlab environment , Optimization Methods and Software , 10 ( 1998 ) , pp . 1 – 31 . [ 322 ] C . Z HU , R . H . B YRD , P . L U , AND J . N OCEDAL , Algorithm 778 : L - BFGS - B , FORTRAN subroutines for large scale bound constrained optimization , ACM Transactions on Mathematical Software , 23 ( 1997 ) , pp . 550 – 560 . This is page 653 Printer : Opaque this Index A ccumulation point , see Limit point Active set , 308 , 323 , 336 , 342 Afﬁne scaling direction , 395 , 398 , 414 method , 417 Alternating variables method , see also Coordinate search method , 104 , 230 Angle test , 41 Applications design optimization , 1 ﬁnance , 7 portfolio optimization , 1 , 449 – 450 , 492 transportation , 4 Armijo line search , see Line search , Armijo Augmented Lagrangian function , 423 as merit function , 436 deﬁnition , 514 exactness of , 517 – 518 example , 516 Augmented Lagrangian method , 422 , 498 , 514 – 526 convergence , 518 – 519 framework for , 515 implementation , 519 – 523 LANCELOT , 175 , 519 – 522 motivation , 514 – 515 Automatic differentiation , 170 , 194 adjoint variables , 208 , 209 and graph - coloring algorithms , 212 , 216 – 218 checkpointing , 210 common expressions , 211 computational graph , 205 – 206 , 208 , 210 , 211 , 213 , 215 654 I N D E X Automatic ( cont . ) computational requirements , 206 – 207 , 210 , 214 , 216 , 219 forward mode , 206 – 207 , 278 forward sweep , 206 , 208 , 210 , 213 – 215 , 219 foundations in elementary arithmetic , 194 , 204 Hessian calculation forward mode , 213 – 215 interpolation formulae , 214 – 215 reverse mode , 215 – 216 intermediate variables , 205 – 209 , 211 , 212 , 218 Jacobian calculation , 210 – 213 forward mode , 212 reverse mode , 212 – 213 limitations of , 216 – 217 reverse mode , 207 – 210 reverse sweep , 208 – 210 , 218 seed vectors , 206 , 207 , 212 , 213 , 216 software , 194 , 210 , 217 B acktracking , 37 , 240 Barrier functions , 566 , 583 Barrier method , 563 – 566 primal , 583 Basic variables , 429 Basis matrix , 429 – 431 BFGS method , 24 , 29 , 136 – 143 damping , 537 implementation , 142 – 143 properties , 141 – 142 , 161 self - correction , 142 skipping , 143 , 537 Bound - constrained optimization , 97 , 485 – 490 BQPD , 490 Broyden class , see Quasi - Newton method , Broyden class Broyden’s method , 273 , 274 , 284 , 285 , 302 , 634 derivation of , 279 – 281 limited - memory variants , 283 rate of convergence , 281 – 283 statement of algorithm , 281 Byrd – Omojokun method , 547 , 579 C alculus of variations , 9 Cancellation error , see Floating - point arithmetic , cancellation Cauchy point , 71 – 73 , 76 , 77 , 93 , 100 , 170 , 172 , 262 , 486 calculation of , 71 – 72 , 96 for nonlinear equations , 291 – 292 role in global convergence , 77 – 79 Cauchy sequence , 618 Cauchy – Schwarz inequality , 75 , 99 , 151 , 600 Central path , 397 – 399 , 417 for nonlinear problems , 565 , 584 , 594 neighborhoods of , 399 – 401 , 403 , 406 , 413 Chain rule , 29 , 194 , 204 , 206 – 208 , 213 , 625 , 627 , 629 Cholesky factorization , 87 , 141 , 143 , 161 , 251 , 259 , 289 , 292 , 454 , 599 , 608 – 609 , 617 incomplete , 174 modiﬁed , 48 , 51 – 54 , 63 , 64 , 76 bounded modiﬁed factorization property , 48 sparse , 412 – 413 stability of , 53 , 617 Classiﬁcation of algorithms , 422 Combinatorial difﬁculty , 424 Complementarity condition , 70 , 313 , 321 , 333 , 397 strict , 321 , 337 , 342 , 533 , 565 , 591 Complementarity problems linear ( LCP ) , 415 nonlinear ( NCP ) , 417 Complexity of algorithms , 388 – 389 , 393 , 406 , 415 , 417 Conditioning , see also Matrix , condition number , 426 , 430 – 432 , 616 – 617 ill conditioned , 29 , 502 , 514 , 586 , 616 well conditioned , 616 Cone , 621 Cone of feasible directions , see Tangent cone Conjugacy , 25 , 102 Conjugate direction method , 103 I N D E X 655 expanding subspace minimization , 106 , 172 , 173 termination of , 103 Conjugate gradient method , 71 , 101 – 132 , 166 , 170 – 173 , 253 , 278 n - step quadratic convergence , 133 clustering of eigenvalues , 116 effect of condition number , 117 expanding subspace minimization , 112 Fletcher – Reeves , see Fletcher – Reeves method for reduced system , 459 – 461 global convergence , 40 Hestenes – Stiefel , 123 Krylov subspace , 113 modiﬁed for indeﬁniteness , 169 – 170 nonlinear , 25 , 121 – 131 numerical performance , 131 optimal polynomial , 113 optimal process , 112 Polak – Ribi ` ere , see Polak – Ribi ` ere method practical version , 111 preconditioned , 118 – 119 , 170 , 460 projected , 461 – 463 , 548 , 571 , 581 , 593 rate of convergence , 112 relation to limited - memory , 180 restarts , 124 superlinear convergence , 132 superquadratic , 133 termination , 115 , 124 Constrained optimization , 6 nonlinear , 4 , 6 , 211 , 293 , 356 , 421 , 498 , 500 Constraint qualiﬁcations , 315 – 320 , 333 , 338 – 340 , 350 linear independence ( LICQ ) , 320 , 321 , 323 , 339 , 341 , 358 , 464 , 503 , 517 , 533 , 557 , 565 , 591 Mangasarian – Fromovitz ( MFCQ ) , 339 – 340 Constraints , 2 , 307 bounds , 434 , 519 , 520 equality , 305 inequality , 305 Continuation methods for nonlinear equations , 274 , 303 application to KKT conditions for nonlinear optimization , 565 convergence of , 300 – 301 formulation as initial - value ODE , 297 – 299 motivation , 296 – 297 predictor – corrector method , 299 – 300 zero path , 296 – 301 , 303 divergence of , 300 – 301 tangent , 297 – 300 turning point , 296 , 297 , 300 Convergence , rate of , 619 – 620 n - step quadratic , 133 linear , 262 , 619 , 620 quadratic , 23 , 29 , 49 , 168 , 257 , 619 , 620 sublinear , 29 superlinear , 23 , 29 , 73 , 132 , 140 , 142 , 160 , 161 , 168 , 262 – 265 , 414 , 619 , 620 superquadratic , 133 Convex combination , 621 Convex hull , 621 Convex programming , 7 , 8 , 335 Convexity , 7 – 8 of functions , 8 , 16 – 17 , 28 , 250 of sets , 8 , 28 , 352 strict , 8 Coordinate descent method , see Alternating variables method , 233 Coordinate relaxation step , 431 Coordinate search method , 135 , 230 – 231 CPLEX , 490 Critical cone , 330 D ata - ﬁtting problems , 11 – 12 , 248 Degeneracy , 465 of basis , 366 , 369 , 372 , 382 of linear program , 366 Dennis and Mor´e characterization , 47 Descent direction , 21 , 29 , 30 DFP method , 139 Differential equations ordinary , 299 partial , 216 , 302 Direct sum , 603 Directional derivative , 206 , 207 , 437 , 628 – 629 Discrete optimization , 5 – 6 656 I N D E X Dual slack variables , 359 Dual variables , see also Lagrange multipliers , 359 Duality , 350 in linear programming , 359 – 362 in nonlinear programming , 343 – 349 weak , 345 , 361 E igenvalues , 84 , 252 , 337 , 599 , 603 , 613 negative , 77 , 92 of symmetric matrix , 604 Eigenvectors , 84 , 252 , 603 Element function , 186 Elimination of variables , 424 linear equality constraints , 428 – 433 nonlinear , 426 – 428 when inequality constraints are present , 434 Ellipsoid algorithm , 389 , 393 , 417 Error absolute , 614 relative , 196 , 251 , 252 , 614 , 617 truncation , 216 Errors - in - variables models , 265 F easibility restoration , 439 – 440 Feasible sequences , 316 – 325 , 332 – 333 , 336 limiting directions of , 316 – 325 , 329 , 333 Feasible set , 3 , 305 , 306 , 338 geometric properties of , 340 – 341 primal , 358 primal - dual , 397 , 399 , 405 , 414 Filter method , 437 – 440 Filters , 424 , 437 – 440 , 575 , 589 for interior - point methods , 575 Finite differencing , 170 , 193 – 204 , 216 , 268 , 278 and graph - coloring algorithms , 202 – 204 and noise , 221 central - difference formula , 194 , 196 – 197 , 202 , 217 forward - difference formula , 195 , 196 , 202 , 217 gradient approximation , 195 – 197 graph - coloring algorithms and , 200 – 201 Hessian approximation , 201 – 204 Jacobian approximation , 197 – 201 , 283 First - order feasible descent direction , 310 – 315 First - order optimality conditions , see also Karush – Kuhn – Tucker ( KKT ) conditions , 90 , 275 , 307 – 329 , 340 , 352 derivation of , 315 – 329 examples , 308 – 315 , 317 – 319 , 321 – 322 fundamental principle of , 325 – 326 unconstrained optimization , 14 – 15 , 513 Fixed - regressor model , 248 Fletcher – Reeves method , 102 , 121 – 131 convergence of , 125 numerical performance , 131 Floating - point arithmetic , 216 , 614 – 615 , 617 cancellation , 431 , 615 double - precision , 614 roundoff error , 195 , 217 , 251 , 615 unit roundoff , 196 , 217 , 614 Floating - point numbers , 614 exponent , 614 fractional part , 614 Forcing sequence , see Newton’s method , inexact , forcing sequence Function continuous , 623 – 624 continuously differentiable , 626 , 631 derivatives of , 625 – 630 differentiable , 626 Lipschitz continuous , 624 , 630 locally Lipschitz continuous , 624 one - sided limit , 624 univariate , 625 Functions smooth , 10 , 14 , 306 – 307 , 330 Fundamental theorem of algebra , 603 G auss – Newton method , 254 – 258 , 263 , 266 , 275 connection to linear least squares , 255 line search in , 254 performance on large - residual problems , 262 Gaussian elimination , 51 , 430 , 455 , 609 sparse , 430 , 433 stability of , 617 with row partial pivoting , 607 , 617 I N D E X 657 Global convergence , 77 – 92 , 261 , 274 Global minimizer , 12 – 13 , 16 , 17 , 502 , 503 Global optimization , 6 – 8 , 422 Global solution , see also Global minimizer , 6 , 69 – 70 , 89 – 91 , 305 , 335 , 352 GMRES , 278 , 459 , 492 , 571 Goldstein condition , 36 , 48 Gradient , 625 generalized , 18 Gradient projection method , 464 , 485 – 490 , 492 , 521 Group partial separability , see Partially separable function , group partially separable H essian , 14 , 19 , 20 , 23 , 26 , 626 average , 138 , 140 Homotopy map , 296 Homotopy methods , see Continuation methods for nonlinear equations I mplicit ﬁltering , 240 – 242 Implicit function theorem , 324 , 630 – 631 Inexact Newton method , see Newton’s method , inexact Infeasibility measure , 437 Inner product , 599 Integer programming , 5 , 416 branch - and - bound algorithm , 6 Integral equations , 302 Interior - point methods , see Primal - dual interior - point methods nonlinear , see Nonlinear interior - point method Interlacing eigenvalue theorem , 613 Interpolation conditions , 223 Invariant subspace , see Partially separable optimization , invariant subspace Iterative reﬁnement , 463 J acobian , 246 , 254 , 256 , 269 , 274 , 324 , 395 , 504 , 627 , 630 K armarkar’s algorithm , 389 , 393 , 417 Karush – Kuhn – Tucker ( KKT ) conditions , 330 , 332 , 333 , 335 – 337 , 339 , 350 , 354 , 503 , 517 , 520 , 528 for general constrained problem , 321 for linear programming , 358 – 360 , 367 , 368 , 394 – 415 for linear programming , 394 KNITRO , 490 , 525 , 583 , 592 Krylov subspace , 108 method , 459 L - BFGS algorithm , 177 – 180 , 183 Lagrange multipliers , 310 , 330 , 333 , 337 , 339 , 341 – 343 , 353 , 358 , 360 , 419 , 422 estimates of , 503 , 514 , 515 , 518 , 521 , 522 , 584 Lagrangian function , 90 , 310 , 313 , 320 , 329 , 330 , 336 for linear program , 358 , 360 Hessian of , 330 , 332 , 333 , 335 , 337 , 358 LANCELOT , 520 , 525 , 592 Lanczos method , 77 , 166 , 175 – 176 LAPACK , 607 Least - squares multipliers , 581 Least - squares problems , linear , 250 – 254 normal equations , 250 – 251 , 255 , 259 , 412 sensitivity of solutions , 252 solution via QR factorization , 251 – 252 solution via SVD , 252 – 253 Least - squares problems , nonlinear , 12 , 210 applications of , 246 – 248 Dennis – Gay – Welsch algorithm , 263 – 265 Fletcher – Xu algorithm , 263 large - residual problems , 262 – 265 large - scale problems , 257 scaling of , 260 – 261 software for , 263 , 268 statistical justiﬁcation of , 249 – 250 structure , 247 , 254 Least - squares problems , total , 265 Level set , 92 , 261 Levenberg – Marquardt method , 258 – 262 , 266 , 289 as trust - region method , 258 – 259 , 292 for nonlinear equations , 292 implementation via orthogonal transformations , 259 – 260 inexact , 268 658 I N D E X Levenberg – Marquardt ( cont . ) local convergence of , 262 performance on large - residual problems , 262 lim inf , lim sup , 618 – 619 Limit point , 28 , 79 , 92 , 99 , 502 , 503 , 618 , 620 Limited - memory method , 25 , 176 – 185 , 190 compact representation , 181 – 184 for interior - point method , 575 , 597 L - BFGS , 176 – 180 , 538 memoryless BFGS method , 180 performance of , 179 relation to CG , 180 scaling , 178 SR1 , 183 two - loop recursion , 178 Line search , see also Step length selection Armijo , 33 , 48 , 240 backtracking , 37 curvature condition , 33 Goldstein , 36 inexact , 31 Newton’s method with , 22 – 23 quasi - Newton methods with , 23 – 25 search directions , 20 – 25 strong Wolfe conditions , see Wolfe conditions , strong sufﬁcient decrease , 33 Wolfe conditions , see Wolfe conditions Line search method , 19 – 20 , 30 – 48 , 66 , 67 , 71 , 230 – 231 , 247 for nonlinear equations , 271 , 285 , 287 – 290 global convergence of , 287 – 288 poor performance of , 288 – 289 Linear programming , 4 , 6 , 7 , 9 , 293 artiﬁcial variables , 362 , 378 – 380 basic feasible points , 362 – 366 basis B , 362 – 368 , 378 basis matrix , 363 dual problem , 359 – 362 feasible polytope , 356 vertices of , 365 – 366 fundamental theorem of , 363 – 364 infeasible , 356 , 357 nonbasic matrix , 367 primal solution set , 356 slack and surplus variables , 356 , 357 , 362 , 379 , 380 splitting variables , 357 standard form , 356 – 357 unbounded , 356 , 357 , 369 warm start , 410 , 416 Linearly constrained Lagrangian methods , 522 – 523 , 527 MINOS , 523 , 527 Linearly dependent , 337 Linearly independent , 339 , 503 , 504 , 517 , 519 , 602 Lipschitz continuity , see also Function , Lipschitz continuous , 80 , 93 , 256 , 257 , 261 , 269 , 276 – 278 , 287 , 294 Local minimizer , 12 , 14 , 273 isolated , 13 , 28 strict , 13 , 14 , 16 , 28 , 517 weak , 12 Local solution , see also Local minimizer , 6 , 305 – 306 , 316 , 325 , 329 , 332 , 340 , 342 , 352 , 513 isolated , 306 strict , 306 , 333 , 335 , 336 strong , 306 Log - barrier function , 417 , 597 deﬁnition , 583 – 584 difﬁculty of minimizing , 584 – 585 example , 586 ill conditioned Hessian of , 586 Log - barrier method , 498 , 584 LOQO , 490 , 592 LSQR method , 254 , 268 , 459 , 492 , 571 LU factorization , 606 – 608 M aratos effect , 440 – 446 , 543 , 550 example of , 440 , 543 remedies , 442 Matlab , 416 Matrix condition number , 251 , 601 – 602 , 604 , 610 , 616 determinant , 154 , 605 – 606 diagonal , 252 , 412 , 429 , 599 full - rank , 298 , 300 , 504 , 609 identity , 599 I N D E X 659 indeﬁnite , 76 inertia , 55 , 454 lower triangular , 599 , 606 , 607 modiﬁcation , 574 nonsingular , 325 , 337 , 601 , 612 null space , 298 , 324 , 337 , 430 , 432 , 603 , 608 , 609 orthogonal , 251 , 252 , 337 , 432 , 599 , 604 , 609 permutation , 251 , 429 , 606 positive deﬁnite , 15 , 16 , 23 , 28 , 68 , 76 , 337 , 599 , 603 , 609 positive semideﬁnite , 8 , 15 , 70 , 415 , 599 projection , 462 range space , 430 , 603 rank - deﬁcient , 253 rank - one , 24 rank - two , 24 singular , 337 sparse , 411 , 413 , 607 Cholesky factorization , 413 symmetric , 24 , 68 , 412 , 599 , 603 symmetric indeﬁnite , 413 symmetric positive deﬁnite , 608 trace , 154 , 605 transpose , 599 upper triangular , 251 , 337 , 599 , 606 , 607 , 609 Maximum likelihood estimate , 249 Mean value theorem , 629 – 630 Merit function , see also Penalty function , 435 – 437 , 446 (cid:1) 1 , 293 , 435 – 436 , 513 , 540 – 543 , 550 choice of parameter , 543 exact , 435 – 436 deﬁnition of , 435 nonsmoothness of , 513 Fletcher’s augmented Lagrangian , 436 , 540 for feasible methods , 435 for nonlinear equations , 273 , 285 – 287 , 289 , 290 , 293 , 296 , 301 – 303 , 505 for SQP , 540 – 543 Merit functions , 424 , 575 Method of multipliers , see Augmented Lagrangian method MINOS , see also Linearly constrained Lagrangian methods , 523 , 525 , 592 Model - based methods for derivative - free optimization , 223 – 229 minimum Frobenius change , 228 Modeling , 2 , 9 , 11 , 247 – 249 Monomial basis , 227 MOSEK , 490 Multiobjective optimization , 437 N egative curvature direction , 49 , 50 , 63 , 76 , 169 – 172 , 175 , 489 , 491 Neighborhood , 13 , 14 , 28 , 256 , 621 Network optimization , 358 Newton’s method , 25 , 247 , 254 , 257 , 263 for log - barrier function , 585 for nonlinear equations , 271 , 274 – 277 , 281 , 283 , 285 , 287 – 290 , 294 , 296 , 299 , 302 cycling , 285 inexact , 277 – 279 , 288 for quadratic penalty function , 501 , 506 global convergence , 40 Hessian - free , 165 , 170 in one variable , 84 – 87 , 91 , 633 inexact , 165 – 168 , 171 , 213 forcing sequence , 166 – 169 , 171 , 277 large scale LANCELOT , 175 line search method , 49 TRON , 175 modiﬁed , 48 – 49 adding a multiple of I , 51 eigenvalue modiﬁcation , 49 – 51 Newton – CG , 202 line search , 168 – 170 preconditioned , 174 – 175 trust - region , 170 – 175 Newton – Lanczos , 175 – 176 , 190 rate of convergence , 44 , 76 , 92 , 166 – 168 , 275 – 277 , 281 – 282 , 620 scale invariance , 27 Noise in function evaluation , 221 – 222 Nondifferentiable optimization , 511 Nonlinear equations , 197 , 210 , 213 , 633 degenerate solution , 274 , 275 , 283 , 302 examples of , 271 – 272 , 288 – 289 , 300 – 301 660 I N D E X Nonlinear ( cont . ) merit function , see Merit function , for nonlinear equations multiple solutions , 273 – 274 nondegenerate solution , 274 quasi - Newton methods , see Broyden’s method relationship to least squares , 271 – 272 , 275 , 292 – 293 , 302 relationship to optimization , 271 relationship to primal - dual interior - point methods , 395 solution , 271 statement of problem , 270 – 271 Nonlinear interior - point method , 423 , 563 – 593 barrier formulation , 565 feasible version , 576 global convergence , 589 homotopy formulation , 565 superlinear convergence , 591 trust - region approach , 578 Nonlinear least - squares , see Least - squares problems , nonlinear Nonlinear programming , see Constrained optimization , nonlinear Nonmonotone strategy , 18 , 444 – 446 relaxed steps , 444 Nonnegative orthant , 97 Nonsmooth functions , 6 , 17 – 18 , 306 , 307 , 352 Nonsmooth penalty function , see Penalty function , nonsmooth Norm dual , 601 Euclidean , 25 , 51 , 251 , 280 , 302 , 600 , 601 , 605 , 610 Frobenius , 50 , 138 , 140 , 601 matrix , 601 – 602 vector , 600 – 601 Normal cone , 340 – 341 Normal distribution , 249 Normal subproblem , 580 Null space , see Matrix , null space Numerical analysis , 355 O bjective function , 2 , 10 , 304 One - dimensional minimization , 19 , 56 OOPS , 490 OOQP , 490 Optimality conditions , see also First - order optimality conditions , Second - order optimality conditions , 2 , 9 , 305 for unconstrained local minimizer , 14 – 17 Order notation , 631 – 633 Orthogonal distance regression , 265 – 267 contrast with least squares , 265 – 266 structure , 266 – 267 Orthogonal transformations , 251 , 259 – 260 Givens , 259 , 609 Householder , 259 , 609 P artially separable function , 25 , 186 – 189 , 211 automatic detection , 211 deﬁnition , 211 Partially separable optimization , 165 BFGS , 189 compactifying matrix , 188 element variables , 187 quasi - Newton method , 188 SR1 , 189 Penalty function , see also Merit function , 498 (cid:1) 1 , 507 – 513 exact , 422 – 423 , 507 – 513 nonsmooth , 497 , 507 – 513 quadratic , see also Quadratic penalty method , 422 , 498 – 507 , 525 – 527 , 586 difﬁculty of minimizing , 501 – 502 Hessian of , 505 – 506 relationship to augmented Lagrangian , 514 unbounded , 500 Penalty parameter , 435 , 436 , 498 , 500 , 501 , 507 , 514 , 521 , 525 update , 511 , 512 PENNON , 526 Pivoting , 251 , 617 Polak – Ribi ` ere method , 122 convergence of , 130 Polak – Ribi ` ere method numerical performance , 131 I N D E X 661 Polynomial bases , 226 monomials , 227 Portfolio optimization , see Applications , portfolio optimization Preconditioners , 118 – 120 banded , 120 constraint , 463 for constrained problems , 462 for primal - dual system , 571 for reduced system , 460 incomplete Cholesky , 120 SSOR , 120 Preprocessing , see Presolving Presolving , 385 – 388 Primal interior - point method , 570 Primal - dual interior - point methods , 389 , 597 centering parameter , 396 , 398 , 401 , 413 complexity of , 393 , 406 , 415 contrasts with simplex method , 356 , 393 convex quadratic programs , 415 corrector step , 414 duality measure , 395 , 398 infeasibility detection , 411 linear algebra issues , 411 – 413 Mehrotra’s predictor - corrector algorithm , 393 , 407 – 411 path - following algorithms , 399 – 414 long - step , 399 – 406 predictor - corrector ( Mizuno – Todd – Ye ) algorithm , 413 short - step , 413 potential function , 414 Tanabe – Todd – Ye , 414 potential - reduction algorithms , 414 predictor step , 413 quadratic programming , 480 – 485 relationship to Newton’s method , 394 , 395 starting point , 410 – 411 Primal - dual system , 567 Probability density function , 249 Projected conjugate gradient method , see Conjugate gradient method , projected Projected Hessian , 558 two - sided , 559 Proximal point method , 523 Q MR method , 459 , 492 , 571 QPA , 490 QPOPT , 490 QR factorization , 251 , 259 , 290 , 292 , 298 , 337 , 432 , 433 , 609 – 610 cost of , 609 relationship to Cholesky factorization , 610 Quadratic penalty method , see also Penalty function , quadratic , 497 , 501 – 502 , 514 convergence of , 502 – 507 Quadratic programming , 422 , 448 – 492 active - set methods , 467 – 480 big M method , 473 blocking constraint , 469 convex , 449 cycling , 477 duality , 349 , 490 indeﬁnite , 449 , 467 , 491 – 492 inertia controlling methods , 491 , 492 initial working set , 476 interior - point method , 480 – 485 nonconvex , see Quadraticprogramming , indeﬁnite null - space method , 457 – 459 optimal active set , 467 optimality conditions , 464 phase I , 473 Schur - complement method , 455 – 456 software , 490 strictly convex , 349 , 449 , 472 , 477 – 478 termination , 477 – 478 updating factorizations , 478 working set , 468 – 478 Quasi - Newton approximate Hessian , 23 , 24 , 73 , 242 , 634 Quasi - Newton method , 25 , 165 , 247 , 263 , 501 , 585 BFGS , see BFGS method , 263 bounded deterioration , 161 Broyden class , 149 – 152 curvature condition , 137 662 I N D E X Quasi - Newton ( cont . ) DFP , see DFP method , 190 , 264 for interior - point method , 575 for nonlinear equations , see Broyden’s method for partially separable functions , 25 global convergence , 40 large - scale , 165 – 189 limited memory , see Limited memory method rate of convergence , 46 , 620 secant equation , 24 , 137 , 139 , 263 – 264 , 280 , 634 sparse , see Sparse quasi - Newton method R ange space , see Matrix , range space Regularization , 574 Residuals , 11 , 245 , 262 – 265 , 269 preconditioned , 462 vector of , 18 , 197 , 246 Restoration phase , 439 Robust optimization , 7 Root , see Nonlinear equations , solution Rootﬁnding algorithm , see also Newton’s method , in one variable , 259 , 260 , 633 for trust - region subproblem , 84 – 87 Rosenbrock function extended , 191 Roundoff error , see Floating - point arithmetic , roundoff error Row echelon form , 430 S (cid:1) 1 QP method , 293 , 549 Saddle point , 28 , 92 Scale invariance , 27 , 138 , 141 of Newton’s method , see Newton’s method , scale invariance Scaling , 26 – 27 , 95 – 97 , 342 – 343 , 585 example of poor scaling , 26 – 27 matrix , 96 Schur complement , 456 , 611 Secant method , see also Quasi - Newton method , 280 , 633 , 634 Second - order correction , 442 – 444 , 550 Second - order optimality conditions , 330 – 337 , 342 , 602 for unconstrained optimization , 15 – 16 necessary , 92 , 331 sufﬁcient , 333 – 336 , 517 , 557 Semideﬁnite programming , 415 Sensitivity , 252 , 616 Sensitivity analysis , 2 , 194 , 341 – 343 , 350 , 361 Separable function , 186 Separating hyperplane , 327 Sequential linear - quadratic programming ( SLQP ) , 293 , 423 , 534 Sequential quadratic programming , 423 , 512 , 523 , 529 – 560 Byrd – Omojokun method , 547 derivation , 530 – 533 full quasi - Newton Hessian , 536 identiﬁcation of optimal active set , 533 IQP vs . EQP , 533 KKT system , 275 least - squares multipliers , 539 line search algorithm , 545 local algorithm , 532 Newton – KKT system , 531 null - space , 538 QP multipliers , 538 rate of convergence , 557 – 560 reduced - Hessian approximation , 538 – 540 relaxation constraints , 547 S (cid:1) 1 QP method , see S (cid:1) 1 QP method step computation , 545 trust - region method , 546 – 549 warm start , 545 Set afﬁne , 622 afﬁne hull of , 622 bounded , 620 closed , 620 closure of , 621 compact , 621 interior of , 621 open , 620 relative interior of , 622 , 623 Sherman – Morrison – Woodbury formula , 139 , 140 , 144 , 162 , 283 , 377 , 612 – 613 Simplex method as active - set method , 388 I N D E X 663 basis B , 365 complexity of , 388 – 389 cycling , 381 – 382 lexicographic strategy , 382 perturbation strategy , 381 – 382 degenerate steps , 372 , 381 description of single iteration , 366 – 372 discovery of , 355 dual simplex , 366 , 382 – 385 entering index , 368 , 370 , 372 , 375 – 378 ﬁnite termination of , 368 – 370 initialization , 378 – 380 leaving index , 368 , 370 linear algebra issues , 372 – 375 Phase I / Phase II , 378 – 380 pivoting , 368 pricing , 368 , 370 , 375 – 376 multiple , 376 partial , 376 reduced costs , 368 revised , 366 steepest - edge rule , 376 – 378 Simulated annealing , 221 Singular values , 255 , 604 Singular - value decomposition ( SVD ) , 252 , 269 , 303 , 603 – 604 Slack variables , see also Linear programming , slack / surplus variables , 424 , 519 SNOPT , 536 , 592 Software BQPD , 490 CPLEX , 490 for quadratic programming , 490 IPOPT , 183 , 592 KNITRO , 183 , 490 , 525 , 592 L - BFGS - B , 183 LANCELOT , 520 , 525 , 592 LOQO , 490 , 592 MINOS , 523 , 525 , 592 MOSEK , 490 OOPS , 490 OOQP , 490 PENNON , 526 QPA , 490 QPOPT , 490 SNOPT , 592 TRON , 175 VE09 , 490 XPRESS - MP , 490 Sparse quasi - Newton method , 185 – 186 , 190 SR1 method , 24 , 144 , 161 algorithm , 146 for constrained problems , 538 , 540 limited - memory version , 177 , 181 , 183 properties , 147 safeguarding , 145 skipping , 145 , 160 Stability , 616 – 617 Starting point , 18 Stationary point , 15 , 28 , 289 , 436 , 505 Steepest descent direction , 20 , 21 , 71 , 74 Steepest descent method , 21 , 25 – 27 , 31 , 73 , 95 , 585 rate of convergence , 42 , 44 , 620 Step length , 19 , 30 unit , 23 , 29 Step length selection , see also Line search , 56 – 62 bracketing phase , 57 cubic interpolation , 59 for Wolfe conditions , 60 initial step length , 59 interpolation in , 57 selection phase , 57 Stochastic optimization , 7 Stochastic simulation , 221 Strict complementarity , see Complementarity condition , strict Subgradient , 17 Subspace , 602 basis , 430 , 603 orthonormal , 432 dimension , 603 spanning set , 603 Sufﬁcient reduction , 71 , 73 , 79 Sum of absolute values , 249 Sum of squares , see Least - squares problems , nonlinear Symbolic differentiation , 194 Symmetric indeﬁnite factorization , 455 , 570 , 610 – 612 Bunch – Kaufman , 612 664 I N D E X Symmetric ( cont . ) Bunch – Parlett , 611 modiﬁed , 54 – 56 , 63 sparse , 612 Symmetric rank - one update , see SR1 method T angent , 315 – 325 Tangent cone , 319 , 340 – 341 Taylor series , 15 , 22 , 28 , 29 , 67 , 274 , 309 , 330 , 332 , 334 , 502 Taylor’s theorem , 15 , 21 – 23 , 80 , 123 , 138 , 167 , 193 – 195 , 197 , 198 , 202 , 274 , 280 , 294 , 323 , 325 , 332 , 334 , 341 , 630 statement of , 14 Tensor methods , 274 derivation , 283 – 284 Termination criterion , 92 Triangular substitution , 433 , 606 , 609 , 617 Truncated Newton method , see Newton’s method , Newton - CG , line - search Trust region boundary , 69 , 75 , 95 , 171 – 173 box - shaped , 19 , 293 choice of size for , 67 , 81 elliptical , 19 , 67 , 95 , 96 , 100 radius , 20 , 26 , 68 , 69 , 73 , 258 , 294 spherical , 95 , 258 Trust - region method , 19 – 20 , 69 , 77 , 79 , 80 , 82 , 87 , 91 , 247 , 258 , 633 contrast with line search method , 20 , 66 – 67 dogleg method , 71 , 73 – 77 , 79 , 84 , 91 , 95 , 99 , 173 , 291 – 293 , 548 double - dogleg method , 99 for derivative - free optimization , 225 for nonlinear equations , 271 , 273 , 285 , 290 – 296 global convergence of , 292 – 293 local convergence of , 293 – 296 global convergence , 71 , 73 , 76 – 92 , 172 local convergence , 92 – 95 Newton variant , 26 , 68 , 92 software , 98 Steihaug’s approach , 77 , 170 – 173 , 489 strategy for adjusting radius , 69 subproblem , 19 , 25 – 26 , 68 , 69 , 72 , 73 , 76 , 77 , 91 , 95 – 97 , 258 approximate solution of , 68 , 71 exact solution of , 71 , 77 , 79 , 83 – 92 hard case , 87 – 88 nearly exact solution of , 95 , 292 – 293 two - dimensional subspace minimization , 71 , 76 – 77 , 79 , 84 , 95 , 98 , 100 U nconstrained optimization , 6 , 352 , 427 , 432 , 499 , 501 of barrier function , 584 Unit ball , 91 Unit roundoff , see Floating - point arithmetic , unit roundoff V ariablemetricmethod , see Quasi - Newton method Variable storage method , see Limited memory method VE09 , 490 W atchdog technique , 444 – 446 Weakly active constraints , 342 Wolfe conditions , 33 – 36 , 48 , 78 , 131 , 137 , 138 , 140 – 143 , 146 , 160 , 179 , 255 , 287 , 290 scale invariance of , 36 strong , 34 , 35 , 122 , 125 , 126 , 128 , 131 , 138 , 142 , 162 , 179 X PRESS - MP , 490 Z outendijk condition , 38 – 41 , 128 , 156 , 287