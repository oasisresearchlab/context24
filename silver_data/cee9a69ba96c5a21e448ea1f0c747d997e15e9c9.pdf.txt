FIXED - EFFECTS NEGATIVE BINOMIAL REGRESSION MODELS Paul D . Allison * Richard Waterman ∗ 2 ABSTRACT This paper demonstrates that the conditional negative binomial model for panel data , proposed by Hausman , Hall and Griliches ( 1984 ) , is not a true fixed - effects method . This method—which has been implemented in both Stata and LIMDEP—does not , in fact , control for all stable covariates . Three alternative methods are explored . A negative multinomial model yields the same estimator as the conditional Poisson estimator and , hence , does not provide any additional leverage for dealing with overdispersion . On the other hand , a simulation study yields good results from applying an unconditional negative binomial regression estimator with dummy variables to represent the fixed effects . There is no evidence for any incidental parameters bias in the coefficients , and downward bias in the standard error estimates can be easily and effectively corrected using the deviance statistic . Finally , an approximate conditional method is found to perform at about the same level as the unconditional estimator . 3 1 . INTRODUCTION A major attraction of panel data is the ability to control for all stable covariates , without actually including them in a regression equation . In general , this is accomplished by using only within - individual variation to estimate the parameters , and then averaging the estimates over individuals . Regression models for accomplishing this are often called fixed - effects models . Fixed - effects models have been developed for a variety of different data types and models , including linear models for quantitative data ( Mundlak 1961 ) , logistic regression models for categorical data ( Chamberlain 1980 ) , Cox regression models for event history data ( Yamaguchi 1986 , Allison 1996 ) , and Poisson regression models for count data ( Palmgren 1981 ) . Here we consider some alternative fixed - effects models for count data . First , we show that the fixed - effects negative binomial model proposed by Hausman , Hall and Griliches ( 1984 ) ( hereafter HHG ) is not a true fixed - effects method . Next we consider a negative multinomial model , which leads back to the estimator for the fixed - effects Poisson model . We then use simulated data to compare an unconditional negative binomial estimator with the fixed - effects Poisson estimator . The negative binomial estimator does not appear to suffer from any “incidental parameters” bias , and is generally superior to the Poisson estimator . Finally , we investigate an approximate conditional likelihood method for the negative binomial model . Its performance on the simulated data is roughly comparable to that of the unconditional negative binomial estimator . 2 . THE FIXED - EFFECTS POISSON MODEL The fixed - effects Poisson regression model for panel data has been described in detail by Cameron and Trivedi ( 1998 ) . The dependent variable y it varies over individuals ( i = 1 , … , n ) and 4 over time ( t = 1 , … , T i ) . It is assumed to have a Poisson distribution with parameter µ it which , in turn , depends on a vector of exogenous variables x it according to the loglinear function it i it x β δ µ + = ln ( 1 ) where δ i is the “fixed - effect” . One way to estimate this model is to do conventional Poisson regression by maximum likelihood , including dummy variables for all individuals ( less one ) to directly estimate the fixed effects . An alternative method is conditional maximum likelihood , conditioning on the count total ∑ t it y for each individual . For the Poisson model , this yields a conditional likelihood that is proportional to ∏∏ ∑           i t it s is it y ) exp ( ) exp ( x x β β ( 2 ) which is equivalent to the likelihood function for a multinomial logit model for grouped data . Note that conditioning has eliminated the δ i parameters from the likelihood function . For logistic regression models , it is well known that estimation of fixed - effects models by the inclusion of dummy variables yields inconsistent estimates of β ( Hsiao 1986 ) due to the “incidental parameters” problem ( Kalbfleisch and Sprott 1970 ) while conditional estimation does not suffer from this problem . For Poisson regression , on the other hand , these two estimation methods—unconditional maximization of the likelihood and conditional likelihood—always yield identical estimates for β and the associated covariance matrix ( Cameron and Trivedi 1998 ) . Hence , the choice of method should be dictated by computational convenience . The fixed - effects Poisson regression model allows for unrestricted heterogeneity across individuals but , for a given individual , there is still the restriction that the mean of each count must equal its variance : 5 it it it y y E µ = = ) var ( ) ( ( 3 ) In many data sets , however , there may be additional heterogeneity not accounted for by the model . As an example , let’s consider the patent data analyzed by HHG and reanalyzed by Cameron and Trivedi ( 1998 ) . The data consist of 346 firms with yearly data on number of patents from 1975 to 1979 . Thus , y it is the number of patents for firm i in year t . This variable ranged from 0 to 515 with a mean of 35 and a standard deviation of 71 . A little over half of the firm years had patent counts of five or less . The regressor variables include the logarithm of research and development expenditures in the current year and in each of the previous five years . All the fitted models also include four dummy variables corresponding to years 1976 to 1979 . To analyze the data , we created a separate observation for each firm year , for a total of 1730 working observations . We then estimated a fixed - effects Poisson regression model by conventional Poisson regression software 1 , with 345 dummy variables to estimate the fixed effects . Results for the research and development variables are shown in the first two columns of Table 1 . These numbers differ somewhat from those in Cameron and Trivedi ( 1998 ) , but are identical to the corrected results reported in their web site ( http : / / www . econ . ucdavis . edu / faculty / cameron / ) . [ TABLE 1 ABOUT HERE ] A potential problem with these results is that there is still some evidence of overdispersion in the data . The ratio of the deviance to the degrees of freedom is 2 . 04 ( deviance = 2807 with 1374 d . f . ) and the ratio of the Pearson goodness - of - fit chi - square to the degrees of freedom is 1 . 97 ( deviance = 2709 with 1374 d . f . ) . For a good fitting model , these measures should be close to 1 . Substantial departures from this ratio could indicate a problem 6 with the model specification , and also suggest that the estimated standard errors may be downwardly biased . 3 . THE HHG NEGATIVE BINOMIAL MODEL HHG deal with the problem of overdispersion by assuming that y it has a negative binomial distribution , which can be regarded as a generalization of the Poisson distribution with an additional parameter allowing the variance to exceed the mean . There are several different ways to parameterize the negative binomial distribution , and the choice can be consequential for regression models . In the HHG model , the negative binomial mass function can be written as ( ) ( ) ( ) it i it i i it it it it i it it y y y y f λ θ θ θ λ λ θ λ   +   + + Γ Γ + Γ = 1 1 1 1 ) , | ( ( 4 ) where Γ is the gamma function . The parameter θ i is assumed to be constant over time for each individual while λ it depends on covariates by the function it it x β λ = ln . ( 5 ) The decision to decompose λ it as a function of the covariates is somewhat surprising , since λ is usually regarded as an overdispersion parameter . That’s because ( 4 ) becomes the Poisson mass function as λ →∞ . The mean and variance of y it are given by it i i it it i it y y E λθ θ λθ ) 1 ( ) var ( ) ( + = = ( 6 ) Under this model , the ratio of the variance to the mean is 1 + θ i which can vary across individuals but , as already noted , is constant over time . 7 HHG further assume that for a given individual i , the y it are independent over time . These assumptions imply that ∑ t it y also has a negative binomial distribution with parameters θ i and ∑ t it λ . Conditioning on these total counts , the likelihood function for a single individual is given by ( ) ( ) ∏ ∑ ∑ ∑ ∑ + Γ Γ + Γ   + Γ   Γ   + Γ t it it it it t it t it t it t it y y y y ) 1 ( 1 λ λ λ λ ( 7 ) thereby eliminating the θ i parameters . The likelihood for the entire sample is obtained by multiplying together all the individual terms like ( 7 ) . This likelihood may be maximized with respect to the β parameters using conventional numerical methods . In fact , the method has been implemented in at least two commercial statistical packages , Stata ( www . stata . com ) and LIMDEP ( www . limdep . com ) . In the middle two columns of Table 1 , we report results of applying this method to the patent data 2 , using the same covariates as Cameron and Trivedi ( 1998 ) . The numbers reported here are the same as the corrected numbers given in their web site . Note that the coefficients are similar in magnitude to those for the conditional Poisson method , but the estimated standard errors are appreciably larger because the model allows for overdispersion Unfortunately , this negative binomial model and its conditional likelihood does not really fit the bill as a fixed - effects method . The basic problem is that the θ i parameters that are conditioned out of the likelihood function do not correspond to different intercepts in the loglinear decomposition of λ it . HHG’s rationale is that if we write θ i = exp ( δ i ) , equations ( 5 ) and ( 6 ) imply that ) . ( ) 1 ( ) var ( ) exp ( ) ( it it it i it y E e y x y E i δ β δ + = + = 8 Therefore , it appears that this model does allow for an arbitrary intercept δ i for each individual . The problem with this approach is that the δ i ’s play a different role than x it . Specifically , changes in x it affect the mean directly , and affect the variance only indirectly through the mean . But changes in δ i affect the variance both indirectly , through the mean , and directly . If we regard δ i as representing the effects of omitted explanatory variables , then there is no compelling reason why these variables should have a different kind of effect from that of x it . To put it another way , suppose we begin with equations ( 6 ) and specify ) exp ( i it i it z γ β δ λ + + = x where δ i is an individual - specific intercept and z i is a vector of time - invariant covariates . Then conditioning on the total count for each individual does not eliminate δ i or γ z i from the likelihood function . Symptomatic of this problem is that using HHG’s conditional likelihood in ( 7 ) , one can estimate regression models with both an intercept and time - invariant covariates , something that is usually not possible with conditional fixed - effects models . The last two columns of Table 1 show results for estimating the conditional negative binomial model with an intercept and two time - invariant covariates . 3 Both the intercept and one of the two covariates are statistically significant at beyond the . 01 level . 4 . A NEGATIVE MULTINOMIAL MODEL We now consider an alternative parameterization of the negative binomial model that is a more natural generalization of the Poisson model . The mass function for a single y it is given by ( ) ( ) ( ) i i it i it i it it it i it i i it it y y y y f λ λ µ λ λ µ µ λ λ λ µ   +   + + Γ Γ + Γ = 1 ) , | ( ( 8 ) with mean and variance functions 9 ( ) i it it it it it y y E λ µ µ µ / 1 ) var ( ) ( + = = ( 9 ) Note that the mean is allowed to vary with time , but the overdispersion parameter λ i is assumed to be constant for each individual . To model dependence on covariates , we let it i it x β δ µ + = ln . ( 10 ) Cameron and Trivedi ( 1998 ) refer to this as an NB2 model , to distinguish it from the previous NB1 model . If we assume ( along with HHG ) that the event counts are independent across time for each individual , then this model is not tractable for deriving a conditional likelihood . That’s because ∑ t it y does not itself have a negative binomial distribution , so it’s awkward to condition on it . More technically , under this specification , there is no complete sufficient statistic for the δ i ’s that is a function of the data alone . As an alternative approach , let’s assume that the y it have a negative multinomial distribution , a well - known multivariate generalization of the negative binomial distribution ( Johnson and Kotz 1969 ) . For a single individual , the joint mass function is given by ∏ ∑ ∑ ∑   +   + Γ   + Γ = t it t it i it i t it i i iT i i t it i iT i i iT i y y y y y y f µ λ µ λ µ λ λ λ λ µ µ λ ! ! . . . ) ( ) , . . . , , | , . . . , ( 1 1 1 ( 11 ) with µ it specified as in ( 10 ) . 4 This multivariate distribution has the property that the marginal distribution of each y it is negative binomial as defined in ( 8 ) . Furthermore , the sum ∑ t it y has a negative binomial distribution with parameters ∑ t it µ and λ i . Unlike the HHG model , this one does not assume that event counts in different time intervals are independent for a given individual . In fact , the correlation ( Johnson and Kotz 1969 ) between y it and y is ( s ≠ t ) is       +       + = i is is i it it is it y y λ µ µ λ µ µ ρ ) , ( ( 12 ) 10 To derive a fixed effects estimator for β , we can condition the joint mass function on the total ∑ t it y , which yields ∏ ∑ ∏ ∑ ∑ ∑   ∝     + Γ =   t it s is it t it t it it t it iT i t it iT i y y y y y y y y f ) exp ( ) exp ( 1 ! ! . . . , . . . , 1 1 x x β β µ µ ( 13 ) Thus , conditioning gives us a distribution that doesn’t depend on the parameter λ i but is proportional to the conditional likelihood for the Poisson model in equation ( 2 ) . In other words , the fixed - effects negative multinomial model leads to the same conditional estimator of β as the fixed - effects Poisson model . 5 So it seems that the negative multinomial approach doesn’t accomplish anything with respect to overdispersion . To understand this , recall that the negative binomial distribution can be generated by compounding a Poisson random variable with a gamma random variable . The negative multinomial can be generated by compounding a set of independent Poisson random variables with a single gamma random variable . Thus , the overdispersion in the negative multinomial can be thought of as arising from a single random variable that is common to all the event counts for a given individual ( which is why the correlation in ( 12 ) is not zero ) . Conditioning on the total count for each individual removes all the unobserved heterogeneity , both that arising from the δ i fixed - effects and the unobserved heterogeneity that is intrinsic to the negative multinomial distribution . 11 5 . CONVENTIONAL APPROACHES TO OVERDISPERSION We have seen that the HHG method doesn’t condition out the fixed - effects , while the negative multinomial method conditions out too much to be useful . What’s left ? A relatively simple approach is to estimate the β coefficients under the fixed - effects Poisson model , but adjust the standard errors upward for overdispersion . A commonly - used adjustment is to multiply the standard errors by the square root of the ratio of the goodness - of - fit chi - square to the degrees of freedom . ( Either Pearson’s chi - square or the deviance could be used . ) The first two columns of Table 2 show the Poisson coefficients and adjusted standard errors for the patent data . The coefficients are the same as those in Table 1 . The standard errors were obtained by multiplying the standard errors in Table 1 by 1 . 404 , the square root of Pearson’s chi - square divided by the degrees of freedom . [ TABLE 2 ABOUT HERE ] An alternative approach is to estimate an unconditional negative binomial model . That is , to specify a conventional NB2 regression model , with dummy variables to estimate the fixed - effects . Results of doing that for the patent data are shown in the last two columns of Table 2 . 6 The coefficients are similar to those obtained with a Poisson specification , but the negative binomial standard errors are notably larger than the Poisson standard errors , even though the latter are already adjusted for overdispersion . There are two potential problems with the unconditional negative binomial method . First , since there is a potential incidental parameters problem , it is questionable whether the coefficient estimates are consistent . As yet , there is no proof of this one way or the other . Second , in the case of large sample sizes , it may be computationally impractical to estimate coefficients for large numbers of dummy variables . Greene ( 2001 ) has shown that the 12 computational problem can be readily overcome for this and many other non - linear fixed - effects models , although conventional software would have to be modified to implement his methods . To investigate the performance of the unconditional negative binomial estimator and the fixed - effects Poisson estimator , we generated simulated data under the following model . For 100 individuals ( i = 1 , … , 100 ) and two time periods ( t = 1 , 2 ) , let y it have a negative binomial distribution with conditional mean µ it and overdispersion parameter λ ( constant over individuals and time ) . Assume that y i 1 and y i 2 are independent , conditional on µ it . Restricting the panel to only two time periods produces conditions most likely to yield evidence of bias due to the incidental parameters problem . Using samples of only 100 cases facilitates the use of conventional software to estimate the unconditional models ( by including 99 dummies ) . The conditional mean is specified as ) exp ( i it it z x γ β η µ + = where x it and z i have standard normal distributions with correlation ρ . The variable z i will be treated as unobserved . It can be interpreted as representing all the stable , unobserved characteristics of individual i that have some effect on y it . Conditional on z i , the observed variables x i 1 and x i 2 are uncorrelated . Unconditionally , their correlation is ρ 2 . As a baseline model , we set β = 1 , γ = 1 , λ = 1 , and ρ = 0 . For these parameter values , we generated data for 500 samples , each of size 100 . ( With two observations per case , the working sample size was 200 ) . For each sample , we estimated β using a conventional negative binomial regression program with x as the predictor , along with 99 dummy variables to capture the fixed effects . We then estimated β via a fixed - effects Poisson regression model , with an overdispersion correction for the standard errors . ( Standard errors were multiplied by the square root of the ratio of the Pearson chi - square goodness - of - fit statistic to its degrees of freedom ) . 13 This process was replicated over a range of plausible values for each parameter , with other parameters held at their baseline values . For each set of parameter values , Table 3 gives the mean of the coefficient estimates , standard error ( standard deviation across the repeated samples ) , root mean squared error , and proportion of times that the nominal 95 percent confidence intervals contained the true value . For ease of comparison , the baseline model is replicated within each subpanel of Table 3 . These baseline estimates were made from new random draws in each subpanel , which should provide some feel for the sampling variability of these estimates . One potential problem that occurred with the negative binomial estimator was that , for many of the samples , the estimate for the overdispersion parameter λ did not converge . The number of nonconvergent samples is shown in Table 3 . For the baseline model , this happened in about 20 percent of the samples . For other models , the percentage of convergent samples ranged from zero for true λ = 50 to 100 for true λ = . 2 . Nonconvergence for λ did not seem to affect the estimates for β , however . For all models with appreciable numbers of nonconvergent samples , we compared the means and standard errors of β for the convergent and nonconvergent samples . In no case was there a statistically significant difference , so the results in Table 3 are based on all samples combined . The general conclusions to be drawn from Table 3 are these : • There is little evidence for incidental parameters bias . Both the negative binomial and Poisson estimates appear to be approximately unbiased under all conditions , although the negative binomial estimates are always a bit too low . • Root mean squared errors are appreciably lower for the negative binomial estimator , except when λ = 50 when the negative binomial distribution is very close to a Poisson distribution . 14 • Both estimators have confidence intervals that are too small , yielding coverage rates that are often considerably lower than the nominal 95 percent level . The Poisson estimator is much worse in this regard , especially for some of the more extreme parameter values . Although not obvious from the table , these reduced coverage rates stem from standard error estimates that are generally too small . Now for the details . Variation in λ is crucial for comparing the negative binomial with the Poisson because it controls the degree of overdispersion . More specifically , as λ→∞ , the negative binomial converges to the Poisson . Interestingly , both estimators do better in both RMSE and CI coverage when λ is large rather than small , although the degradation in performance with decreasing λ is more rapid for the Poisson estimator . The parameter γ controls the variance of the stable , unobserved heterogeneity . The performance of the negative binomial estimator is hardly affected at all by changes in γ . But for the Poisson , increases in γ produce both substantial increases in RMSE and major decreases in CI coverage . Variations in the true value of β also show little impact on the performance of the negative binomial estimator . For the Poisson estimator , the CI coverage remains fairly stable with variations in β , but there is some evidence for an increase in the RMSE as β gets larger . The parameter η is a scale factor that affects both the mean and variance of the counts . For these models , η = 1 produces a mean of about 3 . 8 while η = 8 yields a mean of 23 . This is potentially important because when the mean is small , large proportions of the sample will have a count of 0 and it becomes increasingly difficult to discriminate between a Poisson distribution and a negative binomial distribution . In Table 3 , we see that for η = 1 , the Poisson estimator actually does a little better than the negative binomial estimator in CI coverage , although its 15 RMSE is still about 30 percent larger . As η gets larger , the coverage rate for the Poisson estimator deteriorates , while remaining stable for the negative binomial estimator . [ TABLE 3 ABOUT HERE ] Finally , we examine the impact of ρ , the correlation between the observed variable x and the source of unobserved heterogeneity . When ρ = 0 , as with all the models examined thus far , we satisfy the assumptions of a random effects model and could , presumably , do better using a random - effects negative binomial or Poisson estimator . When ρ ≠ 0 , random - effects estimators are likely to be biased , while fixed - effects estimators should remove that bias . Table 3 shows that both the negative binomial and Poisson estimators do a good job of avoiding bias in the estimate of β . However , with increasing ρ , the performance of the negative binomial estimator remains stable , while the Poisson estimator deteriorates substantially in both RMSE and CI coverage . In sum , the message of Table 3 is that , under the specified model , the unconditional fixed - effects negative binomial estimator is virtually always a better choice than the fixed - effects Poisson estimator . But it is still troubling that the negative binomial estimator is accompanied by underestimates of the standard errors , leading to insufficient coverage of confidence intervals . It is natural to ask whether there is some way to adjust the standard errors upward . Table 4 shows the consequences of multiplying the standard errors by the square root of the ratio of the deviance to its degrees of freedom 7 , where the deviance is defined as { } ∑∑ + + + − = i t it it it it it it y y y y D ) ] / ( ) log [ ( ) ( ) / log ( λ µ λ λ µ . ( 14 ) With this correction , confidence intervals have close to their nominal coverage for all parameter values considered in the simulation . Somewhat surprisingly , standard error correction using the Pearson chi - square goodness - of - fit statistic did not produce any noticeable improvement over the 16 conventional model - based standard error estimates ( results not shown ) . Also , use of the deviance - based correction did not improve the confidence interval coverage for the Poisson estimator . [ TABLE 4 ABOUT HERE ] 6 . AN APPROXIMATE CONDITIONAL ESTIMATOR Previously we remarked that conditional inference is not feasible for the NB2 model ( with event counts independent over time for each individual ) because there is no complete , sufficient statistic for the incidental parameters that is a function of the data alone . However , Waterman and Lindsay ( 1996a ) , following the work of Small and McLeish ( 1989 ) have introduced an approximate method that mimics the beneficial properties of conditional inference , even in situations where a straightforward conditioning approach fails . This methodology is termed the projected score method . In conventional maximum likelihood estimation , the log - likelihood is differentiated to produce the score function . This function is then set equal to zero , and the solutions to this equation are the MLE ' s . The projected score method brings the score function itself to the center of attention , and engineers a version of the score function that has properties equivalent to the conditional score function if it existed ; the desirable property is that among all estimating functions that are insensitive to the incidental parameters , it provides the maximal information . Here are some details of the method . Let β be a vector of parameters of interest and let δ be a vector of nuisance ( incidental ) parameters . Let U 0 ( β , δ ) be the conventional score function , that is , the first derivative of the log - likelihood function with respect to β . Let U ∞ ( β , δ ) denote the optimal estimating function , which is defined as follows . We restrict attention to all square , integrable functions g ( β , δ ) that satisfy the strong unbiasedness condition , 17 { } 0 ) , ( 0 0 = δ β g E for all true values of δ , and for any values of β 0 and δ 0 . This condition implies that the estimating function is insensitive to the values of the nuisance parameters , which is what we desire in a conditional method . Among functions that satisfy this condition , the optimal estimating equation is the one whose solution has lowest asymptotic variance . This function exists whenever certain regularity conditions are satisfied ( Waterman and Lindsay 1996a ) . When a complete sufficient statistic exists , this optimal estimating function is identical to the score function for the conditional likelihood . It can be shown ( Waterman and Linday 1996a ) that the optimal estimating function U ∞ can be expressed as an infinite series . Consider a single individual i with nuisance parameters δ i . Define V α = f f / ) ( α where f is the density function and f ( α ) is the α ’th derivative of f with respect to δ i . Then , we have for individual i ∑ ∞ = ∞ − = 1 0 ) , ( ) , ( α α α ρ δβ δβ V U U where the ρ a are coefficients that depend on the parameters but not the data . We approximate U by the first r terms of this series : ∑ = − = r r V U U 1 0 ) , ( ) , ( α α α ρ δβ δβ Clearly one could construct an entire sequence of approximations to the optimal estimating function , but the hope is that the first approximation , denoted as the U 2 estimating function is close enough for practical purposes . Waterman & Lindsay ( 1996b ) show a number of examples for which this is the case . The way in which these approximate score functions are engineered to be close to the optimal one is identical to the way a least squares line is engineered 18 to be close to the data . That is a regression approach is used to obtain estimated values of ρ a , but here the objects of interest are functions rather than data points . This achieved by taking a set of derivatives of the score functions , their cross products and then finding expectations , so that the mathematical operations are differentiation and expectation . The effort in accomplishing this is minimized by using symbolic software , such as Mathematica or Maple , which can derive the functions with relatively modest input from the analyst . Once the projected score function has been obtained , the ML solutions can be obtained using standard software packages . Using the U 2 approximation , we applied the projected score method to the NB2 model , which was the basis for the simulation study of the previous section . ( Mathematica and R programs for accomplishing this are available from the authors ) . Simulation results are displayed in Table 5 . Comparing the projected scores estimates in Table 5 with the unconditional estimates in Tables 3 and 4 , we find noticeably less bias in the projected score estimates for every condition . On the other hand , the standard errors for the projected score estimates are somewhat larger than those for the unconditional estimates in every case but one . Combining these results into the root mean squared errors , we find that the unconditional method does better in 13 out of the 21 conditions . With respect to confidence interval coverage , the projected score method is always appreciably better than the unconditional method using the uncorrected standard errors ( Table 3 ) . But when the unconditional estimates are corrected by the deviance ( Table 4 ) , the resulting confidence interval coverage is always closer to the nominal level than the coverage of the projected score method . [ TABLE 5 ABOUT HERE ] 19 In sum , it does not appear that the projected score method based on the U 2 approximation offers any substantial advantage over the unconditional method with corrected standard errors , at least with respect to estimating β , the regression coefficients . However , the projected score method was much better at estimating λ , the overdispersion parameter . The number of convergence failures was far lower using the projected score method . Furthermore , if we restrict our attention to samples in which the estimate of λ converged , the unconditional estimates of λ had substantially greater upward bias than the projected score estimates ( not shown in the tables ) . In principle , the projected score method could be improved by using more terms in the approximation . 7 . CONCLUSION The negative binomial model of Hausman , Hall and Griliches ( 1984 ) and its associated conditional likelihood estimator does not accomplish what is usually desired in a fixed - effects method , the control of all stable covariates . That’s because the model is based on a regression decomposition of the overdispersion parameter rather than the usual regression decomposition of the mean . Symptomatic of the problem is that programs that implement the conditional estimator have no difficulty estimating an intercept or coefficients for time - invariant covariates . A good alternative is to do conventional negative binomial regression with direct estimation of the fixed effects rather than conditioning them out of the likelihood . Greene ( 2001 ) has demonstrated the computational feasibility of this approach , even with large sample sizes . Simulation results strongly suggest that this estimation method does not suffer from incidental parameters bias , and has much better sampling properties that the fixed - effects Poisson estimator . Bias in standard error estimates can be virtually eliminated by using a correction factor based on the deviance . 20 The approximate conditional score method is another attractive alternative . The approximation used here showed slightly less bias in the coefficient estimates but slightly more sampling variability than the unconditional estimator . This performance could be improved still further by using a higher - order approximation . Furthermore , estimation of the overdispersion parameter was much better with the approximate conditional method than with the unconditional method . REFERENCES Allison , Paul D . 1996 . “Fixed Effects Partial Likelihood for Repeated Events . ” Sociological Methods & Research 25 : 207 - 222 . Cameron , A . Colin and Pravin K . Trivedi . 1998 . Regression Analysis of Count Data . Cambridge , UK : Cambridge University Press . Chamberlain , Gary A . 1980 . “Analysis of Covariance with Qualitative Data . ” Review of Economic Studies 47 : 225 - 238 . Guo , Guang . 1996 . “Negative Multinomial Regression Models for Clustered Event Counts . ” Pp . 113 - 132 in Adrian E . Raftery ( ed . ) , Sociological Methodology 1996 . Washington , DC : American Sociological Association . Greene , William . 2001 . “Estimating Econometric Models with Fixed Effects . ” Unpublished paper available at http : / / www . stern . nyu . edu / ~ wgreene . Hausman , Jerry , Bronwyn H . Hall and Zvi Griliches . 1984 . “Econometric Models for Count Data with an Application to the Patents - R & D Relationship . ” Econometrica 52 : 909 - 938 . Hsiao , C . 1986 . Analysis of Panel Data . Cambridge , UK : Cambridge University Press . Johnson , Norman L . and Samuel Kotz . 1969 . Discrete Distributions . New York , Wiley . 21 Kalbfleisch , John D . And David A . Sprott . 1970 . “Applications of Likelihood Methods to Models Involving Large Numbers of Parameters” ( with discussion ) . Journal of the Royal Statistical Society Series B , 32 : 175 - 208 . Palmgren , Juni . 1981 . “The Fisher Information Matrix for Log - Linear Models Arguing Conditionally in the Observed Explanatory Variables . ” Biometrika 68 : 563 - 566 . Small , C . G . and D . L . McLeish . 1989 . “ Projection as a Method for Increasing Sensitivity and Eliminating Nuisance Parameters . ” Biometrika 76 : 693 - 703 . Waterman Richard P . and Bruce G . Lindsay . 1996a . “Projected Score Methods for Approximating Conditional Scores . ” Biometrika 83 : 1 - 13 . _ _ _ _ _ _ _ _ _ _ _ . 1996b . “A Simple and Accurate Method for Approximate Conditional Inference Applied to Exponential Family Models . ” Journal of the Royal Statistical Society Series B , 58 : 177 - 188 Yamaguchi , Kazuo . 1986 . “Alternative Approaches to Unobserved Heterogeneity in the Analysis of Repeated Events . ” Pp . 213 - 49 in Sociological Methodology 1986 , edited by Nancy Brandon Tuma . Washington , DC : American Sociological Association . 22 TABLE 1 Conditional Regression Models for Number of Patents Conditional Poisson Conditional Negative Binomial Coefficient Standard Error Coefficient Standard Error Coefficient Standard Error LogRD - 0 . 322 . 046 . 363 . 085 . 272 . 071 LogRD - 1 - . 087 . 049 . 156 . 099 - . 098 . 077 LogRD - 2 . 079 . 045 . 174 . 090 . 032 . 071 LogRD - 3 . 001 . 041 . 015 . 083 - . 020 . 066 LogRD - 4 - . 005 . 038 . 029 . 076 . 016 . 063 LogRD - 5 . 003 . 032 . 136 . 062 - . 010 . 053 Log SIZE . 207 . 078 SCIENCE . 018 . 198 Intercept 1 . 660 . 343 23 TABLE 2 Regression Models with Overdispersion Corrections Fixed - Effects Poisson Unconditional Negative Binomial Coefficient Adjusted Standard Error Coefficient Standard Error LogRD - 0 . 322 . 064 . 356 . 093 LogRD - 1 - . 087 . 068 . 021 . 102 LogRD - 2 . 079 . 063 . 007 . 096 LogRD - 3 . 001 . 058 . 008 . 089 LogRD - 4 - . 005 . 053 . 117 . 081 LogRD - 5 . 003 . 045 . 011 . 067 24 TABLE 3 Simulation Results for Negative Binomial and Poisson Models Negative Binomial Poisson Model β SE RMSE 95 % CI Coverage Non - Conv . β SE RMSE 95 % CI Coverage λ = . 2 . 978 . 326 . 327 . 854 0 1 . 045 . 458 . 460 . 724 λ = . 5 . 966 . 191 . 194 . 854 3 1 . 011 . 278 . 278 . 746 λ = 1 ( base ) . 982 . 145 . 146 . 826 156 1 . 018 . 202 . 203 . 778 λ = 10 . 995 . 063 . 063 . 902 500 1 . 005 . 078 . 078 . 866 λ = 50 . 996 . 052 . 052 . 952 500 1 . 002 . 053 . 053 . 928 γ = 0 . 966 . 124 . 129 . 846 327 1 . 003 . 144 . 144 . 900 γ = . 5 . 966 . 139 . 143 . 819 281 1 . 005 . 169 . 169 . 850 γ = 1 ( base ) . 974 . 138 . 140 . 838 140 1 . 016 . 202 . 203 . 782 γ = 1 . 5 . 967 . 142 . 146 . 860 53 . 999 . 281 . 281 . 640 β = 0 . 008 . 116 . 116 . 872 1 . 006 . 163 . 163 . 730 β = . 5 . 474 . 124 . 126 . 850 25 . 490 . 164 . 164 . 794 β = 1 ( base ) . 978 . 131 . 132 . 866 144 1 . 014 . 194 . 194 . 800 β = 1 . 5 1 . 454 . 151 . 158 . 806 261 1 . 513 . 279 . 279 . 726 η = 1 . 978 . 167 . 168 . 836 452 1 . 025 . 221 . 222 . 860 η = 2 . 974 . 137 . 139 . 870 353 1 . 008 . 189 . 189 . 836 η = 4 ( base ) . 968 . 139 . 142 . 844 152 1 . 009 . 211 . 211 . 758 η = 6 . 972 . 125 . 128 . 850 60 1 . 004 . 202 . 202 . 752 η = 8 . 977 . 131 . 133 . 840 19 1 . 006 . 209 . 209 . 760 ρ = 0 ( base ) . 959 . 140 . 146 . 822 139 . 989 . 197 . 197 . 780 ρ = . 50 . 972 . 160 . 162 . 846 38 1 . 011 . 311 . 311 . 646 ρ = . 75 . 978 . 204 . 205 . 872 6 1 . 016 . 451 . 451 . 588 25 TABLE 4 Confidence Interval Coverage for Negative Binomial Model With Deviance Overdispersion Correction . Model 95 % CI Coverage Model 95 % CI Coverage λ = . 2 . 982 β = 0 . 960 λ = . 5 . 972 β = . 5 . 972 λ = 1 ( baseline ) . 956 β = 1 ( baseline ) . 948 λ = 10 . 956 β = 1 . 5 . 940 λ = 50 . 956 η = 1 . 954 γ = 0 . 966 η = 2 . 964 γ = . 5 . 956 η = 4 ( baseline ) . 956 γ = 1 ( baseline ) . 960 η = 6 . 968 γ = 1 . 5 . 952 η = 8 . 952 ρ = 0 ( baseline ) . 962 ρ = . 50 . 964 ρ = . 75 . 950 26 TABLE 5 Simulation Results for Projected Score Method Projected Score Negative Binomial Model β SE RMSE 95 % CI Coverage Non - Convg . λ = . 2 . 994 . 336 . 336 . 929 22 λ = . 5 . 993 . 211 . 211 . 916 7 λ = 1 ( baseline ) . 988 . 139 . 139 . 934 1 λ = 10 1 . 002 . 069 . 069 . 919 7 λ = 50 1 . 001 . 053 . 053 . 933 65 γ = 0 . 995 . 136 . 136 . 932 0 γ = . 5 . 997 . 141 . 141 . 924 0 γ = 1 ( baseline ) . 996 . 140 . 140 . 944 0 γ = 1 . 5 1 . 003 . 143 . 143 . 927 4 β = 0 . 005 . 125 . 125 . 940 0 β = . 5 . 504 . 133 . 133 . 936 1 β = 1 ( baseline ) 1 . 004 . 140 . 140 . 936 0 β = 1 . 5 1 . 493 . 155 . 155 . 934 2 η = 1 1 . 004 . 178 . 178 . 930 0 η = 2 1 . 008 . 164 . 164 . 932 1 η = 4 ( baseline ) . 989 . 141 . 142 . 920 0 η = 6 1 . 000 . 136 . 136 . 914 1 η = 8 1 . 002 . 132 . 132 . 934 0 ρ = 0 ( baseline ) . 993 . 140 . 140 . 924 0 ρ = . 50 . 996 . 141 . 141 . 920 0 ρ = . 75 1 . 007 . 136 . 136 . 948 0 27 NOTES ∗ University of Pennsylvania . 1 We used the GENMOD procedure in SAS . 2 To estimate the model , we used the NLMIXED procedure in SAS . This required the specification of the log - likelihood for a single individual . 3 SIZE is the firm book value in 1972 . SCIENCE is an indicator variable equal to 1 if the firm is in the science sector . 4 This distribution is the same as the one described by Cameron and Trivedi ( 1998 , p . 288 ) as a Poisson random effects model with gamma distributed random effects . 5 See Guo ( 1996 ) for an application of the negative multinomial model in a random - effects setting . 6 Estimates were obtained with SAS PROC GENMOD . 7 With SAS PROC GENMOD , this correction can be implemented with the DSCALE option on the MODEL statement .