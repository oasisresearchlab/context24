INFORMATION TO USERS This manuscript has been reproduced from the microfilm master . UMI films the text directly from the original or copy submitted . Thus , some thesis and dissertation copies are in typewriter face , while others may be from any type of computer printer . The quality of this reproduction is dependent upon the quality of the copy submitted . Broken or indistinct print , colored or poor quality illustrations and photographs , print bleedthrough , substandard margins , and improper alignment can adversely affect reproduction . In the unlikely event that the author did not send UMI a complete manuscript and there are missing pages , these will be noted . Also , if unauthorized copyright material had to be removed , a note will indicate the deletion . Oversize materials ( e . g . , maps , drawings , charts ) are reproduced by sectioning the original , beginning at the upper left - hand corner and continuing from left to right in equal sections with small overlaps . Each original is also photographed in one exposure and is included in reduced form at the back of the book . Photographs included in the original manuscript have been reproduced xerographically in this copy . Higher quality 6 " x 9 " black and white photographic prints are available for any photographs or illustrations appearing in this copy for an additional charge . Contact UMI directly to order . University Microfilms International A Bell & Howell Information Company 300 North Zeeb Road . Ann Arbor , Ml 48106 - 1346 USA 313 / 761 - 4700 800 / 521 - 0600 Order Number 9427700 A survey to investigate teacher awareness of alternative assessment of students in mathematics Drury , John H . , Ph . D . The Ohio State University , 1994 Copyright ©1994 by Drury , John H . All rights reserved . 300 N . Zeeb Rd . Ann Arbor , M I 48106 A SURVEY TO INVESTIGATE TEACHER AWARENESS OF ALTERNATIVE ASSESSMENT OF STUDENTS IN MATHEMATICS DISSERTATION Presented in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy in the Graduate School of The Ohio State University By John H . Drury , B . A . , M . A . * * * * * The Ohio State University 1994 Dissertation Committee : Approved by M . N . Suydam P . A . Brosnan V ) . JL ^ rtL o - w c ’Advisor 0 D . L . Bainer College of Education Copyright by John H . Drury 1994 ACKNOWLEDGEMENTS " We believe in you , now show us what John Drury can do . " P . A . Brosnan ( 1991 ) " John , you have done a very thorough and comprehensive job . You make an excellent argument for portfolios . " J . Cruz ( 1991 ) " You have put in an outstanding effort and made me proud . Great work . " A . D’Costa ( 1991 ) " Good job . Interesting remarks in responding to questions . " S . Heck ( 1989 ) " Here are some books on evaluation that I think you will find useful . Good luck . " J . Higgins ( 1990 ) " Congratulations , you passed your generals exam and now you have the opportunity to write a dissertation . " M . Suydam ( 1991 ) " Thank you . " J . Drury ( 1994 ) A special thanks : to Dr . Bainer , who served in place of Dr . Cruz ; to Tim Goodwin , a super statistician ; to Dr . Brosnan , for ideas ; to Dr . Suydam , for continued guidance ; and to my very best friend and helpmate - Romaine . VITA October 3 , 1938 . . . . . . . . . . . . . . . . . . . . . . . . Born - Columbus , Ohio 1960 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B . A . , Ohio Wesleyan University , Delaware , Ohio 1970 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . M . A . Education , The Ohio State University , Columbus , Ohio 1960 - 1978 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Mathematics Teacher , The Columbus Public Schools , Columbus , Ohio 1974 - 1988 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Lecturer , Department of Mathematics , The Ohio State University , Columbus , Ohio 1979 - 1988 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Instructor , Department of Mathematics , Columbus State Community College , Columbus , Ohio 1989 - 1992 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Graduate Teaching Associate , Department of Mathematics , The Ohio State University , Columbus , Ohio 1992 - 1994 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Assistant Professor of Mathematics , Department of Developmental Studies , Savannah State College , Savannah , Georgia FIELDS OF STUDY Major Field : Education Studies in Mathematics Education with Drs . M . Suydam , P . Brosnan , A . Osborne , J . Higgins , and R . Shumway Studies in Teacher Education with Drs . J . Cruz and D . Cruickshank i v TABLE OF CONTENTS ACKNOWLEDGMENTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii V I T A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii LIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . viii CHAPTER PAGE I . PROBLEM DEFINITION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Need for Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Problem Statem ent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Theoretical M odel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 Definition of T e rm s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 Overview of the Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 II . REVIEW OF THE LITERATURE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 Historical Perspective and Purpose . . . . 15 Preservice and Inservice Programs . . . . 17 Standards of Assessm ent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Cognitive M o d e l . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Alternative Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Future O utlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 v III . METHOD AND PROCEDURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 Instrumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 Data Collection S itu atio n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Survey Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 A n a ly s is . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 Pilot S tu d y . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 IV . RESEARCH RESULTS AND ANALYSIS . . . . . . . . . . . . . . . . . . 60 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 Demographic Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 Statistical Analyses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 P A R T I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 PART I I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 PART I I I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 PART I V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86 PART V . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 Interviews . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 V . CONCLUSIONS AND RECOMMENDATIONS 118 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 Recommendations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 Suggestions for Future Research . . . . . . . . . . . . . . . . . . . 130 v i APPENDICES A . Pilot Instruments : OSU Survey ( A ) and ( B ) . . . . . . . . . . . . . . . . . 134 B . Survey Instrument and Interview O utline . . . . . . . . . . . . . . . . . . 147 C . Assessment Survey Data and Comments . . . . . . . . . . . . . . . . . . . 157 BIBLIOGRAPHY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 LIST OF TABLES TABLE PAGE 1 . Results of the Survey Instrument Distribution and C o lle ctio n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 2 . Frequency Distribution for Portfolio - Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3 . Results of the Content Analysis for Portfolio - Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4 . Results of Demographics for the Survey Instrum ent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 5 . PART I of the Survey Instrument : Results of Teacher Grade Level K - 2 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64 6 . PART I of the Survey Instrument : Results of Teacher Grade Level 3 - 5 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 7 . PART I of the Survey Instrument : Results of Teacher Grade Level 6 - 8 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 8 . PART I of the Survey Instrument : Results of Teacher Grade Level 9 - 12 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 vi i i 9 . PART I of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 10 . PART II of the Survey Instrument : Results of Teacher Grade Level K - 2 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 11 . PART II of the Survey Instrument : Results of Teacher Grade Level 3 - 5 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 12 . PART II of the Survey Instrument : Results of Teacher Grade Level 6 - 8 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 13 . PART II of the Survey Instrument : Results of Teacher Grade Level 9 - 12 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 14 . PART II of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 15 . PART III of the Survey Instrument : Results of Teacher Grade Level K - 2 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 16 . PART III of the Survey Instrument : Results of Teacher Grade Level 3 - 5 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 17 . PART III of the Survey Instrument : Results of Teacher Grade Level 6 - 8 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 i x 18 . PART III of the Survey Instrument : Results of Teacher Grade Level 9 - 12 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83 19 . PART III of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 20 . PART IV of the Survey Instrument : Results of Teacher Grade Level K - 2 by Selection . . . . . . . . . . . . . . . . . . . . . . . 86 21 . PART IV of the Survey Instrument : Results of Teacher Grade Level 3 - 5 by Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . 91 22 . PART IV of the Survey Instrument : Results of Teacher Grade Level 6 - 8 by Selection . . . . . . . . . . . . . . . . . . . . . . . 96 23 . PART IV of the Survey Instrument : Results of Teacher Grade Level 9 - 12 by Selection . . . . . . . . . . . . . . . . . . . . 100 24 . PART IV of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 25 . PART V of the Survey Instrument : Results of Teacher Grade Level K - 2 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106 26 . PART V of the Survey Instrument : Results of Teacher Grade Level 3 - 5 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 27 . PART V of the Survey Instrument : Results of Teacher Grade Level 6 - 8 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 x 28 . PART V of the Survey Instrument : Results of Teacher Grade Level 9 - 12 by Frequency of Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 29 . PART V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110 30 . PART l - V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Re - scaled Scores of Teacher Grade Level G roups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112 31 . PART l - V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between All Scaled Scores of Teacher Grade Level G roups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 CHAPTER I PROBLEM DEFINITION Introduction Can a survey instrument be designed to provide data to investigate teacher awareness of alternative assessment of students in mathematics ? Would a scaling technique and psychometric measurement reveal differences in teacher awareness of alternative assessment by grade level ? How familiar are classroom teachers with alternative assessment practices and are teachers using alternative assessment techniques to evaluate student performance ? An important trend that may shape the way we evaluate student performance is alternative assessment . Few educational movements have caught the attention of educators as quickly and as forcefully as alternative assessment , as a more direct measure of student performance . This movement has been defined as , " everything that a multiple - choice test is not " ( Worthen , 1993 , p . 445 ) . If more was known about the teachers ' awareness of alternative assessment practices , this information would help initiate , design , and direct alternative assessment techniques , strategies , and practices . The data on teacher awareness of alternative assessment could provide a clearer picture of current 1 2 evaluation practices . This information could modify a course of study on assessment , develop objectives for an inservice or preservice program , or improve national standards on assessment . Need for Study Compelling arguments , informed opinion , and research data of mathematics education experts favoring alternative forms of mathematical assessment are currently surfacing in the mathematics education literature ( Berlak , Newmann , Adams , Archbald , Burgess , Raven , & Romberg , 1992 ; Brandt , 1992 ; Cooney & Hirsch , 1990 ; Fennema , Carpenter , & Lamon , 1991 ; Gifford & O ' Connor , 1992 ; Grouws , 1992 ; Kamii , 1990 ; Kulm , 1991 ; National Commission on Testing and Public Policy , 1990 ; Perrone , 1991 ; Romberg , 1992 ; Stiggins & Conklin , 1992 ) . However , there are few actual research studies that will adequately support a major shift in the assessment of student mathematical achievement from a traditional mode ( e . g . , true - false , short answer , multiple - choice quizzes and tests ) to an alternative assessment mode ( e . g . , projects , performance - based testing , portfolios ) . Before accepting the enormous task of justifying an assessment system , more must be known and understood about the component parts of the system . The focal point of this study is to identify the scope of alternative assessment awareness of classroom teachers . 3 It is important to provide substantive data on teacher awareness of assessment methodology because : ( 1 ) there is a paucity of research studies in mathematics education pertaining to teacher awareness of alternative assessment ; ( 2 ) there is little information contained in the mathematics education literature about teacher awareness of assessment practices as it relates to student achievement ; and ( 3 ) the newness of the evaluation standards that are being used as a benchmark to judge teacher awareness of student assessment precludes an in - depth analysis—specifically longitudinal studies . A careful search of Dissertation Abstracts International ( 1985 - 1992 ) using appropriate descriptors failed to reveal any significant studies of similar purpose or intent . In fact , more than half of the seventeen reviewed abstracts on alternative assessment dealt with types of remediation , supplemental learning , under - achievement , and reinforcement . A content analysis of alternative assessment in mathematics was performed using materials referenced in the ERIC CD - ROM ( 1976 - 1992 ) , a machine - readable form of ERIC database and the equivalent of the indexes Current Index to Journals in Education ( CUE ) and Resources in Education ( RIE ) . These analyses further support the contention that substantive data do not exist on teacher awareness of assessment practices as it relates to student achievement . As was mentioned for the dissertation search , a similar fifty percent of the one hundred 4 twenty - six reviewed abstracts on alternative assessment were directed toward special education , learning disabilities , and other types of remedial needs . In 1989 , the National Council of Teachers of Mathematics ( NCTM ) published a document that contained a chapter on evaluation standards and in 1993 , a working draft of NCTM ' s Assessment Standards for School Mathematics ( Draft , 1993 ) . The NCTM ' s Curriculum and Evaluation Standards for School Mathematics offers fourteen standards on evaluation and a vision of alternatives in student assessment to accomplish the formidable tasks of : making student assessment integral to instruction , following a balanced view of instruction and curriculum in judging program quality , providing a wide variety of assessment methods , and assessing all aspects of mathematical awareness and the implied connections ( NCTM , 1989 , p . 109 ) . Representatives from the American Federation of Teachers , the National Council of Measurement in Education , and the National Education Association met in 1990 and produced a document called Standards for Teacher Competence in Educational Assessment of Students . These seven standards were intended to guide the preservice and inservice preparation of educators , the accreditation of programs , and the certification of all educators ( the National Council of Measurement in Education , 1991 , p . 1 ) . The idea of national standards for what students learn and how they are assessed has recently emerged as one of the most important issues for improving education in this country ( O ' Neil , 1993 ) . Since many of these standards were recently written and with more soon to follow , there is a need to adequately justify their implied intent and their application into the 21st century . Problem Statement The problem is the lack of substantive data that accurately describes teacher awareness of alternative assessment of student achievement in mathematics . According to the literature in mathematics education , there is widespread interest in alternative assessment . This current trend seems to flourish amid subtle warnings from educational experts and others about pitfalls and setbacks that might occur , primarily due to the lack of data on successful alternative assessment practices . This research study provides data that will inform mathematics educators about teacher awareness in alternative assessment of students in mathematics . The data will result from a descriptive survey that addresses the classroom teachers ' understanding of educational assessment standards and mathematics evaluation standards , as these standards apply to alternative assessment . The basic instrument of the descriptive survey is a five - part questionnaire and an interview outline incorporating a full range of assessment techniques , practices , and nomenclature , with special emphasis on " alternative " assessment . 6 Research Questions The research questions integral to this study include : Q1 Can a survey instrument be designed to provide data to investigate teacher awareness of alternative assessment of students in mathematics ? Q2 Would a scaling technique and psychometric measurement reveal differences in teacher awareness of alternative assessment by grade level ? Q3 How familiar are classroom teachers with alternative assessment practices and are teachers using alternative assessment techniques to evaluate student performance ? O bjectives The following objectives directed this descriptive research : To compile a comprehensive set of educational evaluation and mathematics assessment standards • To develop a valid survey instrument to measure teacher awareness of alternative assessment practices based on the standards • To develop a scaling technique to be applied to each of the completed survey instruments To administer the survey to four select groups of kindergarten through twelfth - grade teachers • To compare the four teacher grade level groups using a chi - square test 7 Hypothesis There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . Ho : There is no significant difference in the scores . H a : There is a significant difference in the scores . Theoretical Model The theoretical modeling for this study involves two different paradigms . They are : ( 1 ) the Performance - Test Paradigm or " testing " model ( National Commission on Testing and Public Policy , 1990 , p . 8 ) : ( 2 ) the Contextual Paradigm or " learning " model ( Berlak et al . , 1992 ) . The Performance - Test Paradigm follows the normal testing strategy of assuming that high scores on a given test predict actual high performance on a targeted skill and low scores suggest a low performance skill . The Performance - Test paradigm includes two additional cells : A ) those who can perform satisfactorily , but fall below the cut - off score of the test ; and B ) those who cannot perform satisfactorily , but score above the cut­ off score of the test . Performance - Test Paradigm . A four - cell matrix to describe the outcomes includes : ( 1 ) high score - high skill ( 2 ) low score - high skill ( 3 ) low s c o r e - l o w skill ( 4 ) high score - low skill 8 This four - cell outline provided the rationale for directing the scaling of the survey instrument in determining the extent to which the depth of awareness of assessment practices for the surveyed inservice teachers can be categorized . The Performance - Test Paradigm was used as a benchmark for the scaling of each part of the survey instrument . In this general sense of a testing model , the teachers will be " graded " . Berlak et al . ( 1992 ) explain that the Contextual Paradigm is an improved alternative to the psychometric paradigm . The contextual model is based on the premise that a plurality of meanings , differences , and contradictions in perspectives are inevitable in a multicultural world ( Berlak et al . , 1992 , p . 4 ) . Gardner ( 1985b ) argues that everyone possesses at least seven intelligences , most of which have been overlooked in our testing society , and that each person ' s blend of competences produce a unique cognitive profile . Gardner ( 1985b , p . 128 - 9 ) uses Piaget ' s portrait of logical - mathematical thought , as did Kamii ( 1990 ) , to promote the notion of contextualization within the structure of the cognitive science model . Contextualization exemplifies the underlying philosophy for a learning model . This type of learning model provides the basis for authentic assessment . Madaus and Kellaghan ( 1993 ) emphasize authenticity in assessment as the driving force that will eventually reform testing . Authenticity , as a goal of the assessment practices of inservice teachers , is a fundamental theme in this study . 9 Assumptions The assumptions relating to this study include : A1 Teacher awareness of alternative assessment practices can be assessed . A2 Teachers of mathematics should have some degree of familiarity with the content and implementation of the NCTM Standards . A3 The lack of research data on teacher awareness of assessment practices would suggest that much of the information on alternative assessment is based on personal opinion , attitude , and bias . A4 Although the Standards represent the collective experience and expert opinion of leading mathematics educators and teacher educators , the actual application , use , and content knowledge of the Standards has not been carefully documented . A 5 Teacher awareness of assessment practices will have an impact on classroom instruction . A 6 Preservice and inservice programs are a primary source in preparing teachers in all facets of student assessment . A 7 Teachers affect change . A8 Contextual and psychometric paradigms are accepted models that contain the appropriate elements for assessment . A9 Assessment is integral to instruction . A10 Providing a wider variety of assessment methods enhances the quality of the evaluation . 10 Definition of Terms Terms used in this study are defined in the alphabetized glossary below : Alternative assessment : The types of assessment most commonly listed in the literature as an alternative to traditional testing methodology are projects , performance - based tests , and portfolios ( Costa , 1989 ; Shepard , 1989 ; Stenmark , 1991 ) . All references speak of a direct examination of student performance on significant tasks as the focal point of alternative assessment . Assessment : The term assessment refers to the objective and accurate measurement of performance in relationship to the construct of the interest area ( Andrews & Barnes , 1990 , p . 572 ) . Assessment denotes a broad array of devices designed to show what a person knows or can do ( National Commission on Testing and Public Policy , 1990 , p . 3 ) . Authentic assessment : Authentic assessment is an ongoing appraisal of student performance on tasks in a real setting that focuses on understanding . Madaus and Kellaghan ( 1993 ) draw into this definition references to higher - order skills and students ' thinking process . Authentic testing : Authenticity is defined as a standard - setting rather than standardized testing situation that asks students to write , speak , listen , create , do original research , analyze , pose and solve problems ( Wiggins , 1992 , p . 85 ) . 11 Cognitive science : Two mutually exclusive learning disciplines are frequently compared in the current mathematics literature : psychometric / measurement and cognitive science . The psychometric view is motivated by the philosophical contents of behaviorism that attempts to show a correlation between patterns of performance and student attributes . With the cognitive science approach , achievement is studied as an individual ' s behavior in and of itself , according to Gifford and O ' Connor ( 1992 ) . Schoenfeld ( 1987 ) and Crosswhite ( 1987 ) describe cognitive science in computer metaphors : memory content and schemata ; propositional , procedural , and imagery representations ; and information processing . Cognitive science is about the reflective capacity of the individual in learning new concepts , as interpreted by Nesher and Kilpatrick ( 1990 ) . Contextualized academic performance : The focus is on student outcomes as a result of an interdisciplinary approach based on real problem solving . Context - oriented curriculum places value on multiple representations and mathematical connections ( Cooney & Hirsch , 1990 ) . Evaluation : Evaluation is subjective and reflects the placing of value upon the measurement . In general terms , student assessment is a type of evaluation of student achievement ( Andrews & Barnes , 1990 , p . 572 ) . Two differing types of evaluation are usually presented in the assessment literature ; formative evaluation or process evaluation and summative 1 2 evaluation or product evaluation ( p . 670 ) . Three distinct categories are frequently listed in the literature - teacher evaluation , student evaluation , and program evaluation . Holistic Scoring : Holistic scoring produces one score for the task or work to be graded . This single score ( i . e . , usually a point scale of 0 to 4 ) is awarded as a representation of the total thought process of the examinee ( Charles , Lester , & O ' Daffer , 1987 ) . A compilation of holistically scored sections is often used in a more complex setting called analytic scoring ( Kroll , Masingila , & Mau , 1992 ) . Performance tasks : The essential tasks within the context of a performance - based test are tasks that : are authentic and meaningful to the examinee , provide a valid sample that is an apt generalization of overall performance , include standards of performance that are genuine benchmarks of achievement , provide a direct measure of real performance , and can be assessed in a way so that the results can be shared with and satisfy all stakeholders ( Brandt , 1992 ) . Portfolios : The portfolio is an informal assessment technique that is a compilation of the students ' work samples that could include a math journal , lab book , math log , essays , drawings , computer printouts , graphs , and charts ( Stenmark , 1990 ) . The analysis of the portfolio is usually in a holistic and analytic context ( Wolf , 1989 ) . 13 Test : A test is a set of questions or situations designed to permit an inference about what an examinee knows in an area of interest . The term standardized test means that all examinees are given identical directions , time limits , and questions ( National Commission on Testing and Public Policy , 1990 , p . 2 ) . Cronbach defines test " as a systematic procedure for observing behavior and describing it with the aid of numerical scales of fixed categories " ( Webb , 1992 , p . 663 ) . Overview of the Study In this introductory chapter , the need for the study and problem statement were given . For this descriptive survey , the theoretical models that provided the underpinnings were presented , the relevant terms were defined , and the objectives that guided the research were listed . Chapter II contained a review of the related literature on the purpose and history of student assessment , student assessment in preservice and inservice programs , assessment standards , the cognitive science model for assessment , and alternative assessment techniques . Forecasts for the future in student assessment were given . Chapter III presented the details of the descriptive study . The components that directed this research include : a comprehensive set of educational evaluation and mathematics assessment standards ; the creation and modification of a valid 14 survey instrument to measure teacher awareness of alternative assessment practices based on the standards ; the development of a scaling technique to be applied to each of the completed survey instruments ; the administering of the questionnaire to a group of kindergarten through twelfth - grade teachers ; the rating of the collected questionnaires ; the conducting of a series of interviews ; and the description of the process of analyzing the rated questionnaires . In Chapter IV , a chi - square test was used to determine the differences between the scores from the four groups of teachers ( e . g . , high school , middle school , elementary , and primary ) . The results of the demographic questions that preceded the five - part survey , the statistical analyses for all five sections of the survey , and a summary of the interviews were reported . The results of the chi - square tests in determining levels of significance ( i . e . , tail - end values and percentile values ) were stated . A summary of the hypothesis concluded the chapter . Chapter V reported the conclusions , recommendations , and suggestions for future research . The conclusions and recommendations contained in this chapter summarized the data and examined the implications of the findings that direct alternative assessment strategies for mathematics instruction . The chapter concluded with suggestions for future research on the investigation of teacher awareness of alternative assessment of students in mathematics . CHAPTER II REVIEW OF THE LITERATURE Introduction This descriptive study investigated teacher awareness in alternative assessment of student achievement in mathematics . The primary concern was the awareness of assessment - student assessment . The literature pertaining to the assessment of students in mathematics can be categorized as follows : ( 1 ) a historical perspective and the purpose of student assessment ; ( 2 ) the focus of student assessment in preservice and inservice programs ; ( 3 ) the standards , criterion , and " expert opinion " for student assessment ; ( 4 ) a model for alternative assessment - - the cognitive sciences ; ( 5 ) alternative assessment ; ( 6 ) prescriptions , predictions , and forecasts for the future in student assessment . Historical Perspective and Purpose The origins of student assessment begin with intelligence and achievement testing from the mid - 1800 ' s to the early part the twentieth century ( Aiken , 1979 ; Binet , 1975 ; Karier , 1972 ; Spring , 1990 ) . Kilpatrick ( 1992 ) gives a comprehensive overview of the testing - measurement movement beginning in the 1850s through the 1920s . The names of J . M . Rice , E . L . Thorndike , D . E . Smith , and 1 5 1 6 C . W . Stone are mentioned as the contributors to the early development of testing standards ( 1992 , p . 14 - 16 ) . The period from the 1920s to the late 1940s was a continuation of the testing movement by the behaviorists and the associationists ( Brown et al . , 1990 ; Jones , 1970 ; NCTM , 1970 ; ) . A wide variety of testing strategies were used in the period of the 1950s and 1960s and a change from behaviorism to various forms of structuralism and cognitivism was beginning ( Brown et al . , 1990 ; Clarke et al . , 1990 ; Jones , 1970 ) . The development of alternative assessment methods and strategies occurred in the early 1970s ( Brown et al . , 1990 ; Clarke et al . , 1990 ; Wolf , 1991 ) . The purposes of student assessment , as outlined by Webb ( 1992 , p . 663 ) , were : to provide the teacher with evidence and feedback on what students know and are able to do ; to express what is valued regarding what students are to know , do , or believe ; to provide information to decision makers ; and to provide information on the effectiveness of the educational system as a whole . Webb identifies five features that provided a framework for the discussion of assessment and a reflection on the form of assessment ( 1993 , p . 3 ) . Those features were : the assessment situation , the response or display of awareness , the interpretation of the student ' s response , the assigning of meaning to the interpretation , and reporting or recording of the results . These purposes were reflected in the preservice and inservice programs in formal and informal ways ( Webb & Coxford , 1993 ) . 1 7 Preservice and Inservice Programs There is a long history of concern among mathematics educators about student assessment . An issue is the discrepancies that exist between the various college programs in this country in the preservice preparation of teachers in student assessment and the inservice teacher practices of student assessment ( Ewell , 1991 ; Farr & Griffin , 1973 ) . The components of this issue are teacher preparation in student assessment , appropriate assessment techniques in current use by classroom teachers , and " standards " for teacher awareness in the educational assessment of students in mathematics . The focus of the contemporary model . ( Cooney & Hirsch , 1990 ; Romberg , 1991 ) for student assessment has been on achievement and performance ( NCTM , 1989 , 1993 ; NRC , 1989 ; Wolf et al . , 1991 ) . The trend appears to be toward a comprehensive assessment involving more of the learning traits of the student and closely tied to instruction ( Cobb , Wood , Yackel , Nicholls , Wheatley , Trigatti , & Perlwitz , 1991 ; NCTM , 1989 , 1991 , 1993 ; NRC , 1989 ; NSF , 1991 ) . A continuous , dynamic ( Capione & Brown , 1987 ; Litz , 1987 ) , and often informal process ( Muir & Wells , 1983 ; Roeder , 1972 , 1973 ) of student assessment characterizes many of the assessment methods that are taught in preservice programs ( Brown et al . , 1990 ; Gullickson , 1986 , 1985 ; Howe et al . , 1990 ; Kamii , 1990 ; Lester & Kroll , 1990 ; NCTM , 1989 , 1993 ; Wise et al . 18 1991 ) . Student assessment strategies , methods , and techniques primarily involve testing for many inservice teachers ( Borg , 1986 ; Gifford & O ' Connor , 1992 ; Goslin , 1967 ; Medina & Neill , 1990 ; Stiggins & Conklin , 1992 ) . There is evidence of more varieties of assessment and better tests ( Haertel , 1991 ; Wiggins , 1989 ) . There is ample information available to adequately describe the course content on appropriate assessment strategies and techniques currently being taught in the colleges and universities in this country ( Payne , 1982 ) , but there are few comprehensive studies that adequately research what is actually being taught throughout the country . There are currently a respected number of preservice models for assessment programs ( Galluzzo & Craig , 1 , 990 ) . Much of the preservice curriculum on assessment practices is reflected in the course materials and content , and parallels the philosophy , goals , and objectives of the national standards in assessment ( Grouws , 1992 ) . Many mathematics educators in higher education embrace an " alternative " assessment approach ( e . g . , journals , performance - based testing , portfolios , projects , open - ended questions , essays ) of evaluating student achievement and a growing number of faculty teach this process to the preservice teachers ( Haertel , 1991 ) . The data would suggest that more and better information on the content of college courses with respect to student assessment is needed in this country . 1 9 Studies show that the inservice teachers rely on testing ( e . g . , short - answer , multiple - choice , true - false , matching ) as the primary method of assessing students ( Haertel , 1991 ; Wolf et al . , 1991 ) . A mismatch between assessment and instruction ( i . e . , if students learn in a cooperative setting , they are often tested individually ) is usually created by the over - reliance on testing ( Mitchell , 1992 ) . Studies on testing practices show the " authentic " test to be a better " fit " with the curriculum ( Stiggins & Conklin , 1992 ; Wiggins , 1989 , 1992 ) . Authenticity is a standard - setting rather than standardized testing situation that reflects a realistic , valued focus . Alternative assessment , as an authentic measure of student achievement , is not being practiced by inservice teachers , whereas , many preservice programs stress many forms of alternative assessment ( Stiggins & Conklin , 1992 ) . To better understand these discrepancies between preservice and inservice approaches to assessment , knowing how well classroom teachers are applying the standards for assessment of students in mathematics is essential . These standards for assessment and evaluation used in this study are the National Standards of Teacher Competence in Educational Assessment of Students ( NCME , 1991 ) and the Evaluation Standards ( NCTM , 1989 ) . The standards represent the collective experience , expert opinion , and research data from leading mathematics educators and teacher educators . Both sets of standards de - value testing in favor of alternative assessment . 20 According to Worthen and Spandel ( 1991 ) , group testing narrowly defines student performance . Worthen and Spandel offer seven criticisms of standardized testing . They state that standardized achievement tests : do not promote student learning : are poor predictors of performance : are a misrepresentation of content in a school ' s curriculum : dictate or restrict what is taught : categorize and label students : are racially , culturally , and socially biased ; and only measure superficial knowledge ( 1991 ) . A more comprehensive method of evaluation is needed . There are more appropriate methods of analyzing student performance and achievement than the assignment of a single score from a standardized test . Choosing the appropriate assessment technique to properly evaluate students is a difficult task with so little substantive information ( research based ) about these alternative assessment methods . Testing is surviving for good reason . Generally , testing is efficient , cost - effective , and politically favored ( i . e . , justifiable as the personal preference of the tester ) . Decision - makers and stakeholders need all of these test characteristics in deciding how to allocate opportunities and distribute resources among individuals , institutions , and programs . A popular phase in assessment literature is " Levels of Aggregation " - referring to a compilation of materials that usually reflects achievement levels as determined by testing . This information on the aggregated levels often goes beyond the classroom and is used for 21 accountability , management decision making , and policy formation ( Webb , 1992 ) . Brown , Cooney , & Jones ( 1990 ) describe inservice teachers ' resistance to change and inservice teachers ' reversion to the teaching styles of their own teachers as legendary ( p . 649 ) . Many mathematics education experts contend that improving the method of evaluating student achievement and performance will have an impact on future learning and understanding ( Gifford & O ' Connor , 1992 ; Grouws , 1992 ) . Standards of Assessment The argument for assessment standards is similar to the argument for learning models ( i . e . , models that illustrate a structure for learning ) . Models and standards provide an agreed - upon benchmark from which to compare ideas . The assessment standards include : National Assessment of Educational Progress ( NAEP , 1989 ; NAGB , 1991 ) ; educational assessment standards ( NCME , 1990 ) ; mathematics evaluation standards ( NCTM , 1989 , 1991 , 1993 ) ; and expert opinion ( Gay , 1987 ; Nitko , 1983 ; NCTPP , 1990 ; NRC , 1990 ) . A national study is currently being concluded on assessment . This general survey , based on the National Standards of Teacher Competence in Educational Assessment of Students , should provide information on teacher awareness in assessment . To date , there are few published studies on assessment awareness of 22 teachers in specific subject areas . The newness of the National Standards ( NCEM , 1990 ) and the apparent lack of subject - specific standards might account for this void . The subject - specific standards in the developmental stages are as follows : the National Council for the Social Studies plan for a completed set of standards by late 1993 , the National Council of Teachers of English predict a final standards document in late 1994 or 1995 , the National Council of Teachers of Mathematics forecast assessment standards for 1995 ( Working Draft , 1993 ) , the National Science Educations Standards are expected in late 1994 , a National Oversight Committee for Standards in the Arts expect a final document in 1994 ( O ' Neil , 1993 ) . According to O ' Neil ( 1993 ) , a national assessment system should be developed to connect these standards . The assessment system would contain two components - - the National Assessment of Educational Progress ( NAEP ) and the National Education Goals Panel . The National Assessment of Educational Progress provides large - scale sampling for the assessment of American students . The goals for NAEP are established by the National Assessment Governing Board . This Board defines levels of academic achievement . These levels of achievement are measured by test items . The NAEP would provide the sampling function to the assessment system . The National Education Goals Panel is expected to form a new group called the National Education Standards and Assessment Council . The national legislation 23 required for this new commission is expected in 1994 . The National Education Standards and Assessment Council would establish guidelines to certify content and student performance standards . Another national organization that will have an impact on assessment is the National Commission on Testing and Public Policy . The National Commission on Testing and Public Policy was initiated in 1987 to investigate alternative assessment strategies and take a critical look at standardized testing . Their specific recommendations on testing are : ( 1 ) policies and practices in testing must be reoriented for all students ; ( 2 ) over­ reliance on multiple - choice tests needs to be redirected toward alternative assessment ; ( 3 ) test scores should be used only to differentiate on the basis of characteristics relevant to opportunities being allocated ; ( 4 ) the more scores disproportionately deny opportunities to minorities , the greater the need to measure relevant characteristics ; ( 5 ) tests should not be used alone to make important decisions ; ( 6 ) better assessment strategies are needed to hold social institutions accountable ; ( 7 ) testing must be subjected to greater public accountability ; ( 8 ) research and development programs need to be expanded to create and use alternative assessment . Testing has been and continues to be the single most important issue in assessment ( Wiggins , 1989 , 1992 ) . 24 Mathematics educators are demanding a more rigorous set of guidelines for standardized testing ( Romberg , 1992a , 1992b ) . Mitchell ( 1992 ) states that multiple - choice tests have dominated American educational evaluation for thirty years and " terrorized it in the 1980s " ( p . vii ) . She contends that the proliferation of testing sends a clear message to all stakeholders that educational evaluation places a high value on rote memorization and " the single correct answer " . A critical short - coming of testing is the mis - information describing students . There are students that understand the material but fail the test , and those that pass with little or no understanding ( NCTPP , 1990 ) . Shepard ( 1989 ) contends that the more we attempt to raise test scores , the more we distort instruction . She pointed out several indicators of knowledge that should be assessed in testing that include : coherence of knowledge , principled problem solving , knowledge use , automized skills , and metacognitive or self - regulatory skills ( 1989 , p . 7 ) . These indicators are generally lacking from many testing instrum ents . Brandt ( 1992 , p . 22 ) stated that current and future possibilities in establishing standards for testing should include : expanding existing tests and data - gathering instruments : analyzing and packaging existing test information more innovatively ; adapting and legitimizing evaluation schemes and instruments used in other fields : and breaking new ground ( e . g . , 25 computer testing , tying evaluation to learning , student - created tests , climate tests , and input from the community ) . Wiggins ( 1993 ) stated that a well - designed assessment instrument is an important source of information , but should be used in a supporting role in decision making and not as a decision maker . Students should know their mission and the standards in advance , not just their task . Demanding and getting quality means framing standards in terms of the work that we undertake and value . Standards , not standardization , evoke quality student work and offer consistency and quality control ( Wiggins , 1989 , 1992 ) . A framework was developed at Wisconsin ' s Center on Organization and Restructuring of Schools in an attempt to answer the complex question of what types of instruction engage students in using their minds well . Newmann and Wehlage , Directors of the Wisconsin Center , have provided five standards for authentic instruction : ( 1 ) higher - order thinking ; ( 2 ) depth of knowledge ; ( 3 ) connectedness to the world beyond the classroom ; ( 4 ) substantive conversation ; ( 5 ) social support for student achievement . They contend that previous research indicates that teaching for thinking , problem solving , and understanding has a more positive effect on student achievement than traditional teaching . They conclude that authentic . instruction requires authentic assessment . 26 Cognitive Model Hiebert and Carpenter ( 1992 ) said that " One of the most pressing problems in education is the development of procedures for assessing higher - order thinking " ( p . 89 ) . They build their case around the need to better assess the students ' processing of connections with respect to : symbols and symbolic procedures , symbolic procedures and informal problem - solving procedures , within symbolic systems , and developing new symbolic systems . This entire process focuses on the teacher as the catalyst for student success . This single objective could be a kind of advance organizer for NCTM ' s general goals for all students which are to : value mathematics , have confidence to do mathematics , become a mathematical problem solver , learn to communicate and reason mathematically ( NCTM , 1989 , p . 4 ) . Recognizing critical thinking as a fundamental educational ideal draws it into curricular formation , policymaking , and instructional strategies ( Crosswhite , 1989 ; Fennema , 1991 ; Schoenfeld , 1987 ; Siegel , 1988 ) . Cognitive science is making significant strides in helping to understand how the mind works ( Capione , Brown , & Connell , 1989 ; Gardner , 1985 ; ICMI , 1990 ; Schoenfeld , 1987 ) . The observations by cognitive scientists suggest that no single doctrine can explain successful mathematics instruction ( Charles & Silver , 1989 ; Gardner ; 1985 ; Garofalo & Lester , 1985 ; ICMI , 1990 ; Schoenfeld , 1987 ) . 27 Albert Einstein had the following caveat posted on the wall in his office : " Not everything that counts can be counted and not everything that can be counted counts " ( Herman , Aschbacher , & Winters , 1992 , p . v ) . Einstein ' s saying would suggest that the psychometric - measurement theory that has been used so faithfully the past four decades needs to be revised to be more inclusive for the new assessment strategies . Herman et al . ( 1992 ) claim that assessment has become the nation ' s educational reform agenda . Schoenfeld ( 1992 ) cautions that model building is difficult due to the variability of the human condition . In his critique of Ohlsson , Ernst , and Rees ( 1992 ) , he warns of the dilemma of developing a model that is not flexib ! e - - too " fixed " ( 1992 , p . 472 ) . Ohlsson et al . build their argument around a cognitive science oriented model that includes memory , central cognition , procedural knowledge , and cognitive architecture . This type of cognitive modeling is typical of the current trend to define a learning paradigm for assessment in mathematics education ( Berlak et al . , 1992 ; Gifford et al . , 1992 ; Schoenfeld , 1987 ) . Herman et al . ( 1992 , p . 14 ) discusses " ' mental models ' , ' knowledge structures ' , and ' schema ' . " They conclude that today ' s cognitive perspective suggests that learning is reflective , constructive , and self - regulated . 28 Alternative Assessment The California Mathematics Council ( 1989 ) published a booklet on mathematics assessment alternatives , edited by Stenmark , that was one of the first comprehensive approaches to the " new " assessment techniques . The document provided an overview of effective assessment methods , many of which were already in place throughout the country , that represented significant changes in the way teachers assess students . Alternative assessment techniques according to Stenmark ( 1991 ) focus on— • student thinking and documented progress ; • constant informal assessment of students ; • allowing students to be part of the process ; • connecting classroom work to external evaluation ; • an interdependence between instruction and assessment ; • a close bond between process and product . Stenmark notes an important by - product of alternative assessment for teachers and students . Teachers begin to view almost any activity as another setting for an assessment and students become more reflective and assume a greater responsibility for judging their own products and strategies ( 1991 , p . 4 ) . 29 Educational assessment experts cite three subgroups for alternative assessm ent - portfolios ( Stenmark , 1990 , 1991 ; Wolf , 1989 ) , projects . ( Resnick et al . , 1991 ; Shepard , 1989 ; Wolf , 1989 ; Wolf et al . , 1991 ) , and performance - based tasks ( NRC , 1989 ; Resnick et al . , 1991 ; Shepard , 1989 ; Wolf et al . , 1991 ) . There is a wide variance between the experts in the components that form each subgroup ( Webb & Briars , 1990 ) . A repeating theme in the assessment literature on portfolios , projects , and performance - based tasks is the inherent need to integrate instruction and assessment . According to Webb ( 1992 , p . 677 ) , that embodies four components : 1 ) The teacher must define expectations for learning and understand content knowledge ; 2 ) The teacher needs be sensitive to the process that students use to learn , their stages of development , and the process that facilitates learning ; 3 ) The teacher should be aware of the students ' thought processes ; and 4 ) Assessment is used to make informal decisions throughout instruction to monitor student understanding . Portfolios , projects , and performance - based tasks are considered the major components of alternative assessment . The goals are to : provide reflective activities , develop independent problem solvers , and show students that learning is a long - term endeavor ( Wolf , 1989 ) . Some experts argue that portfolios document employability skills . Students in school today are likely 30 to change jobs as least seven times in their lifetime ( Brandt , 1992 ) . To demonstrate their value to future employers , these students need to learn to discover , document , and develop their skills , awareness , and know - how . The documentation is the portfolio , but the discovery and development are inherent to assessment and instruction . Portfolios have developed some important characteristics in students . Wolf ( 1989 ) states that students tend to collect a more diverse body of finished work , assume a greater degree of responsibility for their work , and are more reflective of what they are doing . Features of mathematical projects , according to Brandt ( 1992 ) , could include : blurring the lines between curriculum and instruction ; embedding assessment in meaningful , real - world activities ; using measures that are " intelligence - fair " ; emphasizing students ' strengths ; and attending to the stylistic dimensions of performance . Wiggins ( 1989 ) views performance testing as a kind of authentic testing situation . He has built an elaborate taxonomy for the authentic test . The group headings are : Structure and logistics , Intellectual design features , Grading and scoring standards , and Fairness and equity ( 1989 , p . 45 ) . These characteristics of authentic tests attempt to present a view of reality and allow for testing of a common core learning structure . 31 Future Outlook Teaching and assessing for higher - order thinking in mathematics is the focus and challenge for the next decade ( Kulm , 1990 ; Peterson , 1988 ; Porter , 1989 ; Silver & Kilpatrick , 1989 ; Stiggins et al . , 1989 ) . The bonding of assessment and instruction is a fundamental goal that will receive increasing attention well into the next century ( Campione et al . , 1987 , 1989 ; Crosswhite , 1987 ; Ewell , 1991 ; Garofalo & Lester , 1985 ; Martinez & Lipson , 1989 ; Webb & Briars , 1990 ) and assessment needs to be expanded to match the students ' " exhibits of learning " ( Perrone , 1991 ) . According to Kulm ( 1991 , pp . 2 - 3 ) , we need to be able to construct mathematical frameworks , categorize fundamental higher - order thinking processes in mathematics , and specify the mathematical thinking processes and abilities expected of students . Some experts , concerned about the troubled state of mathematics education in America ' s public schools , cite statistics from federal studies that show : nearly half of all of this country ' s twelfth graders can not perform eighth - grade mathematics ; more than 40 percent of the mathematics teachers did not major in mathematics nor are certified to teach it ; and less than one - third of the inservice teachers have taken any college course work in testing , measurement , or assessment / evaluation ( Association for Supervision and Curriculum Development , 1992 ; Haertel , 1991 ) . Some mathematics experts suggest that these statistics are skewed . 32 Others claim that the results of the studies are valid and further charge that poorly prepared mathematics teachers produce poorly educated students ( Martinez & Lipson , 1989 ) . There is ample evidence to show a united concern at the local , state , and national levels to improve mathematics achievement through educational reform . Many mathematics educators tie the reform movement to needed changes in assessment as it relates to instruction ( Grouws , 1992 ) . The mathematics education experts concede that a major obstacle to the implementation of the Standards is student assessment ( Peterson , 1988 ) . They further charge that the teachers continue to use standardized tests that emphasize 19th century arithmetic skills and that the assessment / instruction mismatch impedes quality instruction ( Porter , 1989 ; Silver & Kilpatrick , 1989 ) . According to Perrone ( 1991 ) , an integrated curriculum that stresses continuities rather than divisions is not possible without a compatible assessment process . Because performance testing is not well developed at this time , standardized testing will be given continued support by local , state , and national educators because it is well known and not because it is efficient at determining achievement levels in students . The predictions tend to highlight major change in standardized testing toward a performance assessment design . Wiggins ( 1992 ) reframed the design format as follows : assessment tasks should be authentic , meaningful , and worth 33 mastering ; valid generalizations about overall performance can be made ; scoring criteria should be valid ; performance standards should be genuine benchmarks ; the context of problems should be rich , realistic , and enticing ; the tasks should be validated and reliable ; and assessment results should satisfy all customers ( 1992 , p . 27 ) . According to Resnick ( Resnick & Resnick , 1992 ; Wiggins , 1992 ) , design performances are integral to higher - order thinking and should be nonalgorithmic and complex . Wiggins agrees that the performance tasks should involve considerable work such that the total path is not visible from a single vantage point , the applications yield multiple solutions , nuanced judgments are possible , the process is self - regulatory , and the structures are in apparent disorder ( 1992 , p . 29 ) . Standardized tests will still be around , but they will no longer be on center stage . The results of studies by Kamii ( 1990 ) on the harmful effects of the memorization of algorithms on primary mathematics students has shown the destructive force of most standard tests . She contends , based on her research , that multiple - choice , right - wrong items or the rote learning of isolated rules and procedures assess memorization more than understanding , integrated processes and connections ( 1990 ) . Kamii is a proponent of the principles of constructivism and insists that students be assessed in a much different way than testing , such as , alternative assessment . 34 Glasser ( 1992 ) states that we should never test for memorized facts or rote retention . He contends that we should test for written and oral opinion of data and problem solving ( p . 237 ) . He further predicts that future testing situations will allow students to use other sources for reference ( i . e . , notes , books , and other materials ) and the students will have an opportunity to rework the areas of mis - understanding with teacher assistance . Most states have mandated testing in mathematics ( i . e . , 46 of 50 states in 1991 ) at some grade level . This large - scale testing is more prevalent now than at any previous time . These kinds of activities set the tone for a testing environment that has a powerful influence on how we teach and learn . Romberg ( 1992b ) contends that most mathematics classroom practices in assessment are characterized by paper - and - pencil exercises from the texts as homework , quizzes , and tests . He concludes that such activities do not foster exploration , curiosity , or excitement ( 1992 , p . 24 ) . Romberg predicts that a new vision of school mathematics is based on three related concerns : 1 ) students should have an opportunity to learn more mathematics ; 2 ) mathematical knowledge should reflect current trends ; 3 ) research information should be implemented that describes better learning and teaching strategies . All three of these components share a common catylst - authentic mathematical assessment . Romberg characterized the " old " 35 system as : age - graded classrooms ; tracking at an early age ; licensure of general teachers ; competence at pencil - and - paper arithmetic ; and general mathematics as a terminal course for non - coilege - bound students ( 1992 ) . Authentic assessment in mathematics can redirect , change , and possibly eliminate most of these characteristics . A new concept of standardized testing will evolve that will have the capacity to adequately measure students as performing thinkers , problem solvers , and inquirers . Alternative assessment of student achievement in mathematics , still in the first decade of development , is bonding well with the integration of instruction and evaluation , higher - order and critical thinking , and evaluation / assessment standards in mathematics . The primary objective in the assessment of student performance appears to be moving away from the building of awareness and routine skills to a renewed interest in the assessment of student understanding of mathematics ( Brandt , 1993 ; NCTM , 1993 ) . CHAPTER III METHOD AND PROCEDURES Introduction An outline of the components that directed this research includes : the compilation of a comprehensive set of educational evaluation and mathematics assessment standards , the creation and modification of a valid survey instrument to measure teacher awareness of alternative assessment practices based on the standards , the development of a scaling technique to assess each of the completed survey instruments , the distribution and collection of the questionnaire to a select group of kindergarten through twelfth - grade teachers , the rating of the collected questionnaires , the interviews , and the analysis process . Design The design for this research study to investigate teacher awareness of assessment practices was a chronology of components . The components are Instrumentation , Data Collection Situation , Analysis , and Pilot Study . Instrumentation involved the compilation and synthesis of a comprehensive set of educational evaluation and mathematics assessment standards . These standards were subsequently used in 36 37 the creation of a valid survey instrument to measure teacher awareness of alternative assessment practices . The Data Collection Situation describes the sample population , as well as the distribution , administration , and collection of the questionnaire to a select group of kindergarten through twelfth - grade teachers . The Analysis section outlines : the development of a scaling technique that was applied to each of the completed survey instruments , the rating of the collected questionnaires , and a description of the process in analyzing the rated questionnaires . The Pilot Study provided preliminary results that were used to modify the survey instrument and direct the analysis of the data . Instrum entation The instrumentation process for this descriptive study was to : ( 1 ) use the NCME ( 1991 ) Standards for Teacher Competence in Educational Assessment of Students and the NCTM ( 1989 ) Evaluation Standards as a benchmark for the items in the questionnaire to investigate teacher awareness ; ( 2 ) apply the principles for research surveys to the development of this descriptive survey ( Ary , Jacobs , & Razavieh , 1990 ; Fowler , 1990 ; Gay , 1987 ; Minium , 1978 ; Nitko , 1983 ; Scheaffer , Mendenhall , & Ott , 1990 ; Siegel , 1956 ; Thorndike , Cunningham , Thorndike , & Hagen , 1991 ) ; ( 3 ) develop a questionnaire containing a wide array of item formats , create a sufficient number of probing items to 38 gauge teacher understanding of student assessment , and select questions on teacher demographics ( Cooney , 1992 ; Fowler , 1988 ; Higgins , Kasten , & Suydam , 1979 ) . Standards . The ideological basis for the survey instrument is founded in the Standards ( e . g . , the NCTM ' s Evaluation Standards and the NCME ' s Educational Assessment Standards ) . The National Council of Teachers of Mathematics ( 1989 ) in their publication , Curriculum and Evaluation Standards for School Mathematics , categorized the fourteen Evaluation Standards into three groups : General Assessment - 3 , Student Assessment - 7 , and Program Evaluation - 4 . A summary outline of the seven Student Assessment Standards includes specific reference to teachers being able to assess the students ' ability to : Integrate all aspects of mathematical knowledge • Solve problems • Communicate mathematically • Reason mathematically • Understand mathematical concepts Understand mathematical procedures • Develop a mathematical disposition The National Council on Measurement in Education ( 1991 ) published Standards for Teacher Competence in Educational Assessment of Students . The standards were developed by the American Association of Colleges for Teacher Education , the 39 American Federation of Teachers , the National Education Association , and the National Council on Measurement in Education . These various associations ' representatives pooled their collective experience , knowledge , and expertise in formulating standards for assessment competencies . The scope of the teacher ' s responsibilities for student assessment are defined in terms of the following : activities prior to instruction ; activities during instruction ; activities after the appropriate instructional segment ; activities associated with a teacher ' s involvement in decision - making , curriculum , and program evaluation ( 1991 ) . An outline summary of the seven standards follows : • Choosing assessment methods appropriate for instruction Developing assessment techniques that are suitable • Administering , scoring , and interpreting results • Using results when making decisions about students • Developing valid pupil grading procedures • Communicating assessment results to students • Recognizing unethical , illegal , and inappropriate assessment Survey Principles . According to Payne and Likert , the principle components of surveys are sampling , question design , and interviewing ( Fowler , 1990 ) . This survey meets the randomness requirement of the sampling component and provides information that is not available from any other source - - the primary function of sampling . For question design , attention was 40 given to question validity , pretesting , and pilot work ( Gay , 1987 ; Minium , 1978 ; Nitko , 1983 ) . The interview process maintained interviewer consistency , since all interviews were conducted by the same interviewer ( Ary , Jacobs , & Razavieh , 1990 ; Scheaffer , Mendenhall , & Ott , 1990 ) . Questionnaire Development . The body of the questionnaire ( i . e . , the five sets of questions , PART l - V in Appendix B ) was developed from a two - part survey that was done at The Ohio State University , in early 1992 . The OSU Survey , contained in Appendix A , consisted of : ( A ) a thirty - five item multiple - choice test on all types of assessment practices ; and ( B ) a series of seven open - ended questions on various assessment techniques and practices . Each of the thirty - five multiple - choice questions in Part A was keyed to a standard in the NCTM documents ( NCTM , 1989 ; NCTM , 1991 ) . Additionally , the items were paired with a given assessment standard extracted from NCME ' s Standards ( NCME , 1990 ) . This type of structure allowed for seven clusters and each cluster had five items . A diverse set of test item formats ( e . g . , correct - answer , best answer , multiple - response , incomplete statement , negative response , combined response ) for the multiple - choice questions was chosen so that each of the seven national assessment standards could be represented in a variety of ways . Part B also used the seven NCME National Standards , but a single open - ended question was fashioned to explore the teachers ' awareness of assessment practices for each standard . 41 Both surveys included a set of demographic questions . These questions proved useful in the development of the ten demographic questions actually used in the research survey . Twenty - five graduate students in mathematics , statistics , and mathematics education at The Ohio State University , upon request , volunteered to complete Part A of the survey in February , 1992 ( Appendix A ) . Part B was administered upon request to thirteen doctoral students in mathematics education at The Ohio State University in March , 1992 ( Appendix A ) . Both parts of the OSU Survey were critical to the development of the survey instrument that was subsequently used in the pilot study and finally in the actual research survey . The Instrument . The assessment instrument ( Appendix B ) was a survey questionnaire in three sections . Sections one and two were demographic questions and the five - part questionnaire , respectively , and were administered to the sample population directly , as a fill - in questionnaire . The third section , the interview outline , was applied to a smaller random selection of the given sample and was done in an interview mode . The ten demographic questions of section one asked for information on : gender , number of years of teaching experience and number of years of teaching mathematics , number of students in the class ( es ) and number of students in the school , grade level taught , type of college degree , accessibility to the NCTM Standards , and college work in assessment . 42 PART I - In this section of the survey , the teachers selected the level of importance they would assign to a given assessment practice for the purpose of evaluation . The subjective continuum five - category scale used was ( 1 ) - not important to ( 5 ) - very important . Of the ten purposes of evaluation that were listed , five were more closely allied with the alternative assessment mode and five allied with the traditional testing mode . Purposes from the alternative assessment mode were to : provide feedback ; check ability to reason ; monitor progress over time ; organize thinking ; and identify misconceptions . The remaining purposes were from the traditional mode . They were to : find out what students do not know ; satisfy an administrative directive ; verify computational skills ; keep students on task ; and compare performance to others . PART II - There were ten multiple - choice questions in this part of the questionnaire . Almost all questions dealt with alternative assessment and incorporated a full range of assessment techniques , practices , and nomenclature . The respondents were asked to choose the best answer for each item from the listing ( A , B , C , or D ) . PART III - Respondents on this section were to mark their level of understanding of ten alternative methods of assessment ( i . e . , the subjective continuum five - category scale , ( 1 ) - not sure to ( 5 ) - very familiar ) that included : recorded informal observations , structured interview plans , math journals , student attitude 43 inventories , holistic scoring techniques , performance assessment tasks , open - ended questions , student reports using self - assessment data , mathematics portfolios , and math projects . PART IV - A series of open - ended questions dealing with the three most common components of alternative assessment tasks - - portfolios , projects , and performance tasks - comprise this part of the survey . Teachers were asked to describe , outline , or list appropriate items for portfolios , projects , and performance tasks . PART V - This part was a percentage breakdown that illustrates how the teacher determines grades . The information requested describes what portion of the students ' grade was determined by homework , quizzes , classwork , projects , portfolios , performance - based tasks , class participation , chapter tests , final exam , lab work , notebook , or other . The last section was an interview outline for the respondents . Each of the selected respondents was asked two questions on each of the following : student evaluation , teacher evaluation , and program evaluation . The student evaluation questions asked for the respondents ' view of alternative assessment and their students ' view of alternative assessment . Questions for teacher evaluation focused on self - evaluation . The program evaluation questions examined alternative assessment as it applies to the current mathematics curriculum . The questions were open - ended and investigated teacher awareness of 44 assessment practices . The interviews occurred immediately after the original survey was administered . Data Collection Situation This descriptive research involved collecting data in order to answer questions concerning the present status of student assessment as practiced by teachers ( K - 12 ) in the Franklin County area . Four teacher groups were identified as : high school ( grades 9 - 12 ) ; middle school ( grades 6 - 8 ) ; intermediate ( grades 3 - 5 ) ; and primary ( grades K - 2 ) . To report the nature of student assessment , as it was practiced by inservice teachers in public schools , was the primary focus of the survey . The questionnaires were distributed to two school districts within the Franklin County area and collected in approximately two months ' time . The questionnaire took approximately 15 - 20 minutes to complete by each teacher and was administered to a group or an individual , depending on the circumstance . The targeted grade level groups and number of respondents surveyed were : mathematics teachers in the high schools ( 30 - 36 ) ; and mathematics teachers in the middle schools ( 30 - 36 ) , intermediate grade teachers ( 30 - 36 ) , and primary grade teachers ( 30 - 36 ) in the selected districts . Completed questionnaires from 120 - 144 teachers were expected . The teachers that actually participated in the research survey represented the Columbus Public School District and the 45 Upper Arlington School District . The sample from Columbus included 3 high schools , 5 middle schools , and 6 elementary schools . The Upper Arlington sample consisted of 1 high school , 2 middle schools , and 2 elementary schools . There were fifteen teachers involved in the distribution of approximately 200 questionnaires of the 225 questionnaires that were printed . The number of questionnaires that were distributed and collected , along with the percent of return , were listed by teacher grade level group in Table 1 . Table 1 Results of the Survey Instrument Distribution and Collection Teacher Grade Level : K - 2 3 - 5 6 - 8 9 - 12 Total Distributed 60 60 40 40 200 Completed 29 29 34 34 126 Percent 48 % 48 % 85 % 85 % 63 % Since several surveys were marked by teachers that taught a 2nd - grade / 3rd - grade split class , it was possible to equalize the two teacher grade level groups ( i . e . , K - 2 and 3 - 5 ) . A similar situation involved teachers ' groups 6 - 8 and 9 - 12 . 46 Franklin County was chosen as the geographical region for the sample because of the accessibility of the survey population . There is a preponderance of institutions of higher learning in the area . Many of the survey respondents received their undergraduate and graduate degrees from these schools . The schools with educational inservice programs include : The Ohio State University ; Franklin University ; Capital University ; Ohio Dominican College ; and Otterbein College . Survey Limitations The survey limitations for this study involved reliability , validity , and generalizability . The sample size was sufficiently large to support the chi - square test , but the power of the statistic could be increased by a larger sample . A test for the reliability of scores of teachers ( i . e . , the extent to which a second determination of the same measure would agree with the first ) was not performed . Reliability was to some extent controlled by the strict application of a predetermined scale to judge the holistic scores for each part of the survey for all respondents , since only one person , the researcher , did the scoring . Validity is special to the purpose for which the instrument is being used . The survey instrument for this study focused on teacher awareness of alternative assessment practices . The content of the survey was deemed appropriate by the doctoral 47 students involved in the OSU - Surveys A and B . The generalizability or the representativeness of findings refers to external validity . Population external validity of this study is restricted to the metropolitan area of Columbus , Ohio . Specifically , the Columbus Public Schools and the Upper Arlington School System were involved in the sample . There were twelve coordinators that represented the respective school districts . These coordinators distributed and collected the questionnaires . The respondents were chosen by these coordinators and this selection process restricted the sample of respondents . A nalysis The Analysis was done in three phases : ( 1 ) a content analysis ; ( 2 ) the rating methodology ; and ( 3 ) the analyses of the data . The first phase was an investigation of alternative assessment using a content analysis . In the second phase , the OSU survey instrument rating and the actual survey - instrument rating were done . A scaling technique was developed to rate the OSU survey instruments and this technique was later modified to apply to each of the completed survey questionnaires . The third phase consisted of the actual scoring of the collected questionnaires and was closely followed by an analysis of the results . Content Analysis . A content analysis of alternative assessment was done using materials referenced in the ERIC CD - ROM ( 1966 - 1992 ) . These analyses illustrated the impact of 48 alternative assessment on the literature and gave credence to the contention that supportive data do not exist on teacher awareness of assessment practices as it relates to student achievement . Approximately half of the 126 reviewed abstracts on portfolio - assessment were directed toward special education , learning disabilities , and other types of remedial needs . In a follow - up check in late 1993 of the articles and papers pertaining to alternative assessment contained in ERIC , a similar situation existed . Alternative assessment is a relatively new term that has come into common use in the last few years . To trace the origins of " alternative " assessment led directly to portfolio - assessm ent . A content analysis was used as the research technique for the objective , systematic , and quantitative description of the impact of portfolio - assessment in the educational literature from the mid - 1960s through the early 1990s . In seeking a reasonable number of references , the selection was made on the basis of the intersection of the two sets , portfolio and assessment . A cross - reference matrix comparing the number of articles and papers containing reference to portfolio - assessment in a temporal sequence is listed in Table 2 . The primary database was divided into three files from : 1966 to 1975 , 1976 to 1982 , and 1983 to 1992 . All materials are referenced in ERIC CD - ROM , a machine - readable form of the ERIC 49 database . The database is the equivalent of the indexes Current Index to Journals in Education ( CUE ) and Resources in Education ( RIE ) . Table 2 Frequency Distribution for Portfolio - Assessment Time Descriptors ; Total A . 1966 - 1975 Portfolio ( 61 ) and Assessment ( 6 , 484 ) = 2 B . 1976 - 1982 Portfolio ( 127 ) and Assessment ( 18 , 417 ) = 58 C . 1983 - 1992 Portfolio ( 180 ) and Assessment ( 19 , 444 ) = 68 Experts in content analysis agree that the analyst must specify in precise terms the classification headings and sub­ headings for the purpose of providing evidence to show the impact of a given topic in the literature . Hence , portfolio - assessment was judged in relationship to other classification headings that are contained in titles and abstracts of educational literature for this quantitative procedure according to ERIC . The search was initiated using the descriptors portfolio and assessment . The classification headings included : Assessment , Career , Education , Evaluation , Learning , and Portfolios . These headings were listed under the rubric of Descriptors / Abstract and were 50 determined on the basis of frequency of appearance : in the descriptors , within the title of the search item , and in the body of the abstract of the search item . The choice of sub - headings ( e . g . , Assessment : Informal , Measurement , Tests , Self ) would be more difficult to defend on the basis of frequency alone . Admittedly , some subjectivity is a necessary condition of content analysis . To develop the body of the table , a routine pattern of checking the abstract , descriptors , and title of the search item was done . An actual count was made of the number of times the headings were used and the sub - headings were appropriate . Any statistical inference was difficult in the absence of similar analyses . However , the original intent of providing a description of the impact of portfolio - assessment was met . The two references in file 1966 - 1975 listed in Table 2 were deleted from Table 3 . Both references involved competency based education in vocational programs and were not suited to the sub­ heading criteria . Table 3 is a frequency distribution comparing the sub - heading classifications using the information from the 58 references in file 1976 - 1982 and the 68 references in file 1983 - 1992 . 51 Table 3 Results of the Content Analysis for Portfolio - Assessm ent DESCRIPTORS / ABSTRACT 1976 - 1982 1983 - 1992 ‘ Assessment : Inform al 4 11 - Measurement 6 13 Tests 9 12 S elf 0 15 Career : Training 10 5 Interview s 9 5 Special needs 10 17 Education : Adult - Vocational 19 16 Elem . - Secondary 10 27 Higher 23 21 52 Table 3 ( continued ) , Table 3 Results of the Content Analysis for Portfolio - Assessm ent DESCRIPTORS / ABSTRACT 1976 - 1982 1983 - 1992 Evaluation : S elf 4 0 Student 12 18 Teacher 7 13 Program 10 3 Learning : Experiential 13 8 P rior 17 12 Lifelong 8 21 ‘ P ortfolios : Background 23 21 Materials 25 21 53 The following general observations seem logically justified by the frequency chart of Table 3 : • Assessm ent . The most recent file 1983 - 1992 uses the word " assessment " more frequently . This parallels the current claim by experts in assessment , that " assessment " has been more clearly defined and widely used in the last decade . • Career . There was greater emphasis on the assessment of training and portfolios in job interviews in the late 1970s . Some educators viewed this as a fad in assessment . • Education . Portfolio assessment was more prevalent in the literature in adult / higher education than in elementary / secondary education in the 1970s . The reverse was true in the 1980s . • Evaluation . Alternative assessments of programs has been de - emphasized in the literature . Program evaluation was emphasized . • Learning . The notion of the assessment of learning as a lifelong experience seems to have greater importance to current researchers than the assessment of prior learning . • Portfolios . Portfolio assessment has been around for nearly two decades . The focal point of portfolios is self . An overall comparison between the file 1976 - 1982 and file 1983 - 1992 , with respect to the self component , revealed a major shift from self - evaluation in the 1970s to self - assessment in the 1980s to a self - directed assessment that could be interpreted as performance - based assessment for the early 1990s . 54 Rating Methodology . For Part A of the OSU survey ( see Appendix A ) , a 35 - item multiple - choice test on all types of assessment practices , a panel of experts provided two scoring patterns . One solution set used a weighted answers method . Each of the four responses to an item was graded 1 , 2 , 3 , or 4 ( i . e . , 1 - least likely to 4 - most likely ) . The other grading scheme was a dichotomous scoring technique ( i . e . , 1 - correct response and 0 - incorrect response ) . An item analysis of the test compared : arithmetic means , using the weighted answer method : and an item difficulty index , for the items scored dichotomously . The item difficulty index is the quotient of the number of correct responses on a given item , as compared to the total number of respondents . The ten multiple - choice items receiving the highest mean and index scores from the graduate student sample were categorized as . " traditional testing " questions . The results clearly showed that the higher mean and index scores related to the items that had a numerical or measurement orientation and the lower scores associated with test items that dealt with doctrine and ideology . A modification of the scoring technique from Part A of the OSU Survey was used to score PART I and II of the actual survey . In Part B of the OSU Survey ( Appendix A ) , the wide array of answers was analyzed by item and a list of descriptors was gleaned from the responses for each question . These descriptors 55 were used in the analytic scoring of a major portion of the survey instrument ( i . e . , Part III , Part IV , and Part V ) of this study . The survey instrument used in the pilot study and the actual teacher survey utilized an analytic scoring technique . As soon as the surveys were completed , the questionnaires were judged according to predetermined criteria . All scoring used a scale of 1 , 2 , or 3 , defined as : ( 1 ) Basic - in awareness of alternative assessment practices ( 2 ) Proficient - in awareness of alternative assessment practices ( 3 ) Advanced - in awareness of alternative assessment practices Each of the five sections ( i . e . . PART 1 - V1 was scored the same wav using this scheme . Note that , because of the nature of the selected sample of teachers , a no response ( 0 ) was deemed inappropriate . The range of the total score on the survey for each respondent using this analytic scoring method was 5 - 15 . A raters ' score sheet of a 3 x 5 matrix with 1 , 2 , and 3 listed with each part of the survey was used . The criteria for scoring the five sections follows : PART I Of the ten purposes of evaluation listed , five purposes had a traditional testing orientation and five had a alternative assessment orientation . The difference in mean scores for each set of five determined the assigned score . A ( 1 ) was assigned a negative difference , a ( 2 ) assigned a positive difference , and a ( 3 ) for a significant positive difference . 56 PARTII The ten multiple - choice items were graded dichotomously ( right or wrong ) against a key . Each questionnaire was assigned a score of 1 , 2 , or 3 : fewest correct answers - 1 ; more correct answers - 2 ; most correct answers - 3 . PART III A total of the selected number - choices of the respondents was the graded score . The range of the graded scores was 10 - 50 . The assigned scores of 1 , 2 , or 3 implied : lower total - II middle total - 2 ; and higher total - 3 . PART IV A ( 1 ) was awarded to the open - ended questions if the general orientation was more directed toward what the students do not know as viewed by quizzes and testing , computational skills , or a limited number of selections . A score of ( 2 ) was assigned to a wider selection and increased variety of assessment items , a mention of calculators and other manipulatives , and the implied use of cooperative learning techniques . Finally , a ( 3 ) was assigned for a sense of the appropriate uses of portfolios , projects , and performance based tasks . PART V In this part on percentage in grade determination , the higher number of choices dictated the higher assigned value . If the focus was only testing and quizzes - 1 , for an expanded selection - 2 , and the expanded selection with interesting others - 3 . For the interviews , a scheme similar to that used in PARTS III and IV was followed . A check list of descriptors was used in the interview process to aid in assigning scores to the interviewees . 57 Data Analysis . The results from the graded questionnaires were used in a chi - square test . The chi - square test was applied to all parts of the survey and this comparison included the four teacher grade level groups ( i . e . , high school , middle school , intermediate , and primary ) . The chi - square statistic provided a measure of the discrepancy between the expected and obtained frequencies in the distribution . The value of chi - square depends on the number of discrepancies involved in the calculation and is accounted for by the degrees of freedom ( df ) . The chi - square test is best viewed conceptually as a test about proportion and determines whether the sample is in accord with what has been hypothesized to be true of the population . The chi - square statistic depends on categorical data without reference to mean scores . The chi - square test measures the differences of the expected and obtained scores within the distribution of scaled scores in the study . The categories of the chi - square tables were mutually exclusive , each score appeared in one and only one of the categories in each table , and the scores were measured as frequencies . Pilot Study The pilot study was conducted in May , 1993 . A total of thirty questionnaires was distributed to teachers in all four teacher groups in five schools in the Columbus Public Schools in Franklin County . The thirty questionnaires were delivered to two 58 high schools ( 6 teachers in each ) , a middle school ( 6 ) , and an elementary school - grades K - 2 ( 6 ) and grades 3 - 5 ( 6 ) . Nineteen questionnaires were returned : high schools ( 5 and 4 , respectively ) ; middle school ( 6 ) ; and elementary ( grades K - 2 ( 2 ) and grades 3 - 5 ( 2 ) ) . A cursory examination of the questionnaires revealed that the questionnaires were done thoroughly and the involved teachers completed the task with serious intent . The surveys , after they were rated , yielded the quality of information that was expected ; but there was an insufficient number of surveys for a chi - square test . Summary Teacher demographics , the first part of the questionnaire , was followed by question items to determine the level of teacher awareness on assessment techniques , practices , and nomenclature . The first section included ten demographic questions from the teachers in the Franklin County area who completed the questionnaire ( e . g . , gender , years of teaching and teaching mathematics , degree held , grade level taught , availability of standards documents , preservice assessment course work ) . Section two was the body of the questionnaire containing five sets of questions . The five sets were : a ten - item attitudinal survey on the level of importance to assessment practices for the purposes of evaluation ; a ten - item multiple - 59 choice test on alternative assessment ; a ten - item attitudinal survey indicating the teachers ' level of understanding of various methods of assessment ; three open - ended questions on mathematics portfolios , projects , and performance tasks ; and a brief questionnaire asking teachers for a percentage breakdown on how their students ' grades are determined ( e . g . , quizzes , tests , exams , portfolios , projects , and performance tasks ) . Section three was an interview outline that focused on the teachers ' opinions on student evaluation , teacher evaluation , and program evaluation . The analysis was done in three phases : a content analysis ; the rating methodology ; and the analyses of the final data . The assessment of the teacher survey was done by an analytic scoring technique involving a holistic score on each of five sections , the body of the questionnaire . An interview with a sampling of respondents was the concluding section of the survey . This comparison included the four teacher grade level groups ( i . e . , high school , middle school , intermediate , and primary ) . A chi - square statistic was used in the analysis of the graded questionnaires . CHAPTER IV RESEARCH RESULTS AND ANALYSIS Introd uctio n This chapter contains the results of the demographic questions , the data of response of the five - part survey , and the statistical analyses ( i . e . , the mean scores and chi - square values ) for all five sections of the survey and the last tables of the analyses included a composite of all parts . The chi - square tests in determining levels of significance ( i . e . , tail - end values and percentile values ) were stated . Summary remarks follow the table of values . A summary of the interviews was given and a general summary concludes the chapter . Demographic Results The ten demographic questions of the first section of the survey asked for information on : gender , number of years of teaching experience and number of years of teaching mathematics , number of students in the class ( es ) and number of students in the school , grade level taught , type of college degree , accessibility to the NCTM Standards , and college work in assessment . The format for the items of Table 4 is the same as the survey instrument ; but the first item ( 00 ) represents the districts of the respondents . 60 61 Table 4 Results of Demographics for the Survey Instrument Grade Level Groups : K - 2 3 - 5 6 - 8 9 - 12 Total Percent 0 0 Teaching district : Columbus 22 25 23 22 92 73 % Upper Arlington 7 4 1 1 1 2 34 27 % 01 Gender : Female 29 25 21 1 5 90 71 % Male 0 4 1 3 1 9 36 29 % 02 Years teaching experience : 0 - 10 1 0 1 2 1 1 5 38 30 % 11 - 20 1 2 9 13 1 2 46 37 % 21 - 31 7 8 1 0 1 7 42 33 % 03 Years teaching mathematics : 0 - 10 11 1 3 14 6 44 35 % 11 - 20 1 2 1 0 1 8 1 2 52 41 % 21 - 31 6 6 2 1 6 30 24 % 04 Grade level ( s ) : 29 29 34 34 126 100 % 05 Highest college degree : BA / BS 1 3 1 1 1 6 1 1 51 40 % MA / MS 1 6 1 8 1 8 23 75 60 % Table 4 ( continued ) , Table 4 62 Grade Level Groups : K - 2 3 - 5 6 - 8 9 - 12 Total Perc 06 School attendance : 250 - 499 1 3 18 1 0 32 25 % 500 - 749 15 1 1 23 1 50 40 % 750 - 999 1 0 8 8 1 7 13 % 1000 - 1250 0 0 2 25 27 22 % 07 Class size or average : 6 - 23 1 0 8 1 2 4 34 27 % 24 - 25 15 1 3 1 3 1 5 56 44 % 26 - 36 4 8 9 1 5 36 29 % 08 Access to NCTM Standards : yes 14 18 24 29 85 67 % no 15 1 1 1 0 5 41 33 % 09 Access to any evaluation standards : yes 1 2 1 7 1 9 21 69 55 % no 1 7 1 2 1 5 1 3 57 45 % 1 0 College courses in evaluation : None 8 3 3 8 22 17 % Part of one 4 7 1 0 1 0 31 25 % One course 9 9 1 0 7 35 28 % 2 or more 8 1 0 1 1 9 38 30 % 63 Statistical Analyses The completed teacher survey instruments were rated using an analytic scoring technique . The questionnaires were judged according to a predetermined criteria . All scaled scoring for each PART of the survey used a scale of 1 , 2 , or 3 : 1 - Basic in awareness of alternative assessment practices 2 - Proficient in awareness of alternative assessment practices 3 - Advanced in awareness of alternative assessment practices Each of the five sections ( i . e . , PART l - V ) was scored the same way . The range of the total scores for all parts on the survey for each respondent using this analytic scoring method was 5 - 15 . A Chi - Square Test was used to determine the level of significance , tail end value , and percentile value for all contingency tables for the hypothesis : Ho : There is no significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . H a : There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 64 Table 5 PART I of the Survey Instrument : Results for Teacher Grade Level K - 2 by Frequency of Selection for 29 Respondents PART I Indicate the level of importance to your assessment practices for the following purposes of evaluation : ( not important ) 1 2 3 4 5 ( very important ) 1 2 3 4 5 01 Find out what students do not know 2 3 0 5 18 02 Provide students with feedback 0 1 1 6 21 03 Check students ' ability to reason 0 1 1 8 18 04 Satisfy an administrative directive 2 5 11 6 5 05 Verify students ' computational skills 0 3 1 12 13 06 To keep students on task 4 5 2 7 11 07 Monitor student progress over time 0 0 1 8 20 08 Compare student performance to others 8 5 10 4 2 09 Help students organize their thinking 1 1 0 10 17 1 0 Identify students ' misconceptions 0 1 2 6 20 65 Table 6 PART I of the Survey Instrument : Results for Teacher Grade Level 3 - 5 by Frequency of Selection for 29 Respondents PART I Indicate the level of importance to your assessment practices for the following purposes of evaluation : ( not important ) 1 2 3 4 5 ( very important ) 1 2 3 4 5 01 Find out what students do not know 0 0 1 6 20 02 Provide students with feedback 1 0 0 5 21 03 Check students ' ability to reason 0 1 0 13 13 04 Satisfy an administrative directive 6 7 4 7 3 05 Verify students ' computational skills 1 2 4 12 8 06 To keep students on task 5 2 3 10 7 07 Monitor student progress over time 0 1 0 5 21 08 Compare student performance to others 6 5 10 4 2 09 Help students organize their thinking 0 2 1 10 14 10 Identify students ' misconceptions 0 0 4 5 18 6 6 Table 7 PART I of the Survey Instrument : Results for Teacher Grade Level 6 - 8 by Frequency of Selection for 34 Respondents PART I Indicate the level of importance to your assessment practices for the following purposes of evaluation : ( not important ) 1 2 3 4 5 ( very important ) 1 2 3 4 5 01 Find out what students do not know 1 1 7 10 14 02 Provide students with feedback 0 1 1 13 18 03 Check students ' ability to reason 0 1 5 11 16 04 Satisfy an administrative directive 6 8 11 3 5 05 Verify students ' computational skills 2 2 9 6 14 06 To keep students on task 5 6 5 13 4 07 Monitor student progress over time 0 1 1 15 16 08 Compare student performance to others 4 8 14 5 2 09 Help students organize their thinking 0 4 2 9 18 10 Identify students ' misconceptions 0 4 7 11 11 67 Table 8 PART I of the Survey Instrument : Results for Teacher Grade Level 9 - 12 by Frequency of Selection for 34 Respondents PART I indicate the level of importance to your assessment practices for the following purposes of evaluation : ( not important ) 1 2 3 4 5 ( very important ) 1 2 3 4 5 01 Find out what students do not know 1 4 11 6 12 02 Provide students with feedback 0 0 0 11 23 03 Check students ' ability to reason 0 0 4 10 20 04 Satisfy an administrative directive 11 6 11 3 3 05 Verify students ' computational skills 0 3 15 13 3 06 To keep students on task 5 2 17 7 3 07 Monitor student progress over time 0 0 4 18 12 08 Compare student performance to others 7 13 5 6 3 09 Help students organize their thinking 1 1 6 16 10 1 0 Identify students ' misconceptions 1 1 9 15 8 PART I . Of the ten purposes of evaluation listed , five purposes had a traditional testing orientation and five had a alternative assessment orientation . The difference in the sum of scores for each set of five determined the assigned score of 1 , 2 , or 3 ( i . e . , 1 = 3 or less , 2 = 4 through 8 , 3 = 9 or more ) . Table 9 PART I of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 1 2 13 4 29 1 . 72 3 - 5 12 1 1 6 29 1 . 79 6 - 8 1 5 1 5 4 34 1 . 68 9 - 12 9 1 7 8 34 1 . 97 Calculated Chi - Square = 3 . 95 , df = 6 The value of Chi - Square was less than the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 683 , and PV = . 317 . There is no significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 69 PART I . For this part , the teacher selected the level of importance they would assign to a given assessment practice for the purpose of evaluation . Of the ten purposes of evaluation that were listed , the five more closely allied with the alternative assessment mode were to : provide feedback , check ability to reason , monitor progress over time , organize thinking , and identify misconceptions . The five allied with the traditional testing mode were to : find out what students do not know , satisfy an administrative directive , verify computational skills , keep students on task , and compare performance to others . There were four assessment practices , of the ten listed , that were marked " more important " ( i . e . , total of 4 - 5 range ) by all teacher grade level groups and the four practices were from the alternative assessment mode . The four practices were to provide feedback , check ability to reason , monitor progress over time , and organize thinking . The three assessment practices that were marked " less important " ( i . e . , total of 1 - 2 range ) by all teacher groups were to satisfy an administrative directive , keep students on task , and compare performance to others . These three practices were from the traditional mode . The chi - square test revealed no significant differences in the scaled scores between the teacher groups . The range between mean scores was the smallest of . all the parts and the mean scores were the lowest of all parts . 70 Table 10 PART II of the Survey Instrument : Results for Teacher Grade Level K - 2 by Frequency of Selection for 29 Respondents PART II Please choose the best answer : 01 Alternative assessment is best characterized by : 5 A . informal testing . 12 _ _ B . projects and portfolios . 4 C . higher order thinking skills . _ J _ _ D . cooperative learning . 02 A mathematics essay question - 19 A . is a reasonable selection for assessment . _ 3— B . is a good selection for a language / arts class , not math . 2 C . takes too much time to grade . 5 D . works best as an enrichment activity . 03 Assessing students ' mathematical disposition suggests : _ 3 _ _ A . looking at the ways students approach tasks . 1 B . checking student willingness to explore . _ _ 1 - - - - C . monitoring students ' appreciation of the value of math . 24 D . all of the above . 04 Calculators , computers , and manipulatives are appropriate for the assessment process . 21 _ _ _ A . Statement is definitely TRUE . 8 B . Statement is probably TRUE . 0 C . Statement is probably FALSE . _ Q _ _ D . Statement is definitely FALSE . 71 Table 10 ( continued ) , 05 The assessment of student knowledge in mathematics is the responsibility of the : a ) teacher ; b ) student . 4 A . ( a ) only . 0 B . ( b ) only . 2A _ _ C . ( a ) & ( b ) . _ 1 _ _ D . Neither ( a ) nor ( b ) . 0 6 Multiple sources of information are necessary in choosing mathematical tasks that - 3 A . identify what students do not know . 4 B . allow for a wide variety of tests . 23 _ _ C . present the same math concept in different ways . 0 D . focus on a specific set of mathematical skills . 0 7 Holistic scoring : 10 A . produces several scores . 2 B . is an ambiguous term . 9 C . correlates test reliability with content validity . 7 D . produces one single score . 0 8 Performance - based tasks emphasize - - 4 A . Accountability . 6 B . Accuracy . 13 C . Authenticity . 6 D . Analysis . 0 9 Alternative assessment should not : 0 A . allow for individual growth . 29 B . rank - order students . 0 C . monitor learning over time . 0 D . recognize a range of learning styles . 1 0 The assessment of ability to communicate mathematics should include : 1 ) the use of computers and calculators ; 2 ) writing about mathematics ; 3 ) discussing mathematical ideas . _ 0 _ _ A . ( 1 ) & ( 2 ) . _ 0 _ _ B . ( 3 ) only . 0 C . none of the above . 23 _ _ _ D . all of the above . 72 Table 11 PART II of the Survey Instrument : Results for Teacher Grade Level 3 - 5 by Frequency of Selection for 29 Respondents PART II Please choose the best answer : 01 Alternative assessment is best characterized by : 4 A . informal testing . 14 B . projects and portfolios . 8 C . higher order thinking skills . 2 D . cooperative learning . 02 A mathematics essay question - - 22 A . is a reasonable selection for assessment . 0 B . is a good selection for a language / arts class , not math . 3 C . takes too much time to grade . 4 D . works best as an enrichment activity . 03 Assessing students ' mathematical disposition suggests : 5 A . looking at the ways students approach tasks . 5 B . checking student willingness to explore . 0 C . monitoring students ' appreciation of the value of math . 1 9 D . all of the above . 04 Calculators , computers , and manipulatives are appropriate for the assessment process . 2 3 _ _ A . Statement is definitely TRUE . 5 B . Statement is probably TRUE . _ 1 _ _ C . Statement is probably FALSE . 0 D . Statement is definitely FALSE . 73 Table 11 ( continued ) , 05 The assessment of student knowledge in mathematics is the responsibility of the : a ) teacher ; b ) student . 1 A . ( a ) only . _ 1 _ _ B . ( b ) only . £5 _ _ C . ( a ) & ( b ) . 2 D . Neither ( a ) nor ( b ) . 06 Multiple sources of information are necessary in choosing mathematical tasks that - - 4 A . identify what students do not know . 4 B . allow for a wide variety of tests . 12 _ _ C . present the same math concept in different ways . 2 D . focus on a specific set of mathematical skills . 07 Holistic scoring : 6 A . produces several scores . 3 B . is an ambiguous term . 7 C . correlates test reliability with content validity . 11 _ _ D . produces one single score . 0 8 Performance - based tasks emphasize - - 6 A . Accountability . 7 B . Accuracy . 5 C . Authenticity . 10 D . Analysis . 0 9 Alternative assessment should not : 0 A . allow for individual growth . 28 B . rank - order students . _ 1 _ _ C . monitor learning over time . 0 D . recognize a range of learning styles . 1 0 The assessment of ability to communicate mathematics should include : 1 ) the use of computers and calculators ; 2 ) writing about mathematics ; 3 ) discussing mathematical ideas . _ 0 _ _ A . ( 1 ) & ( 2 ) . _ 0 _ _ _ B . ( 3 ) only . _ 1 _ _ C . none of the above . 28 D . all of the above . 74 Table 12 PART II of the Survey Instrument : Results for Teacher Grade Level 6 - 8 by Frequency of Selection for 34 Respondents PART II Please choose the best answer : 01 Alternative assessment is best characterized by : 7 A . informal testing . JJ _ _ B . projects and portfolios . 9 C . higher order thinking skills . 3 D . cooperative learning . 02 A mathematics essay question - - 20 A . is a reasonable selection for assessment . 5 B . is a good selection for a language / arts class , not math . 3 C . takes too much time to grade . 3 D . works best as an enrichment activity . 03 Assessing students ' mathematical disposition suggests : 3 A . looking at the ways students approach tasks . 7 B . checking student willingness to explore . 0 C . monitoring students ' appreciation of the value of math . 24 D . all of the above . 04 Calculators , computers , and manipulatives are appropriate for the assessment process . 26 _ _ A . Statement is definitely TRUE . 7 B . Statement is probably TRUE . _ J _ _ C . Statement is probably FALSE . _ _ Q _ _ D . Statement is definitely FALSE . 75 Table 12 ( continued ) , 0 5 The assessment of student knowledge in mathematics is the responsibility of the : a ) teacher ; b ) student . 8 A . ( a ) only . 0 B . ( b ) only . 2J _ _ _ C . ( a ) & ( b ) . 5 D . Neither ( a ) nor ( b ) . 0 6 Multiple sources of information are necessary in choosing mathematical tasks that - - 5 A . identify what students do not know . 7 B . allow for a wide variety of tests . 16 _ _ C . present the same math concept in different ways . _ J _ _ _ D . focus on a specific set of mathematical skills . 0 7 Holistic scoring : 7 A . produces several scores . 5 B . is an ambiguous term . 12 C . correlates test reliability with content validity . 7 D . produces one single score . 0 8 Performance - based tasks emphasize - - 10 A . Accountability . 10 B . Accuracy . 5 C . A uthenticity . 4 D . Analysis . 0 9 Alternative assessment should not : _ J _ _ A . allow for individual growth . 24 B . rank - order students . 4 C . monitor learning over time . 3 D . recognize a range of learning styles . 1 0 The assessment of ability to communicate mathematics should include : 1 ) the use of computers and calculators ; 2 ) writing about mathematics ; 3 ) discussing mathematical ideas . _ 0 _ _ A . ( 1 ) & ( 2 ) . _ 5 _ _ _ B . ( 3 ) only . 0 C . none of the above . 29 D . all of the above . 76 Table 13 PART II of the Survey Instrument : Results for Teacher Grade Level 9 - 12 by Frequency of Selection for 34 Respondents PART II Please choose the best answer : 01 Alternative assessment is best characterized by : 6 A . informal testing . 13 B . projects and portfolios . 8 C . higher order thinking skills . 5 D . cooperative learning . 02 A mathematics essay question - - 28 A . is a reasonable selection for assessment . _ 1 _ _ B . is a good selection for a language / arts class , not math . 0 C . takes too much time to grade . 4 D . works best as an enrichment activity . 03 Assessing students ' mathematical disposition suggests : 3 A . looking at the ways students approach tasks . 1 0 B . checking student willingness to explore . 0 C . monitoring students ' appreciation of the value of math . 20 D . all of the above . 04 Calculators , computers , and manipulatives are appropriate for the assessment process . 23 A . Statement is definitely TRUE . 9 B . Statement is probably TRUE . _ J _ _ C . Statement is probably FALSE . 0 D . Statement is definitely FALSE . 77 Table 13 ( continued ) , 0 5 The assessment of student knowledge in mathematics is the responsibility of the : a ) teacher ; b ) student . 3 A . ( a ) only . _ 1 _ _ B . ( b ) only . 22 _ _ C . ( a ) & ( b ) . 6 D . Neither ( a ) nor ( b ) . 06 Multiple sources of information are necessary in choosing mathematical tasks that - - 4 A . identify what students do not know . 8 B . allow for a wide variety of tests . 22 _ _ C . present the same math concept in different ways . 2 D . focus on a specific set of mathematical skills . 07 Holistic scoring : 6 A . produces several scores . 8 B . is an ambiguous term . 8 C . correlates test reliability with content validity . 1 0 D . produces one single score . 0 8 Performance - based tasks emphasize - - 15 A . Accountability . 9 B . Accuracy . 6 C . Authenticity . 4 D . Analysis . 0 9 Alternative assessment should not : 0 A . allow for individual growth . 3J _ _ _ B . rank - order students . 2 C . monitor learning over time . _ 1 _ _ _ D . recognize a range of learning styles . 1 0 The assessment of ability to communicate mathematics should include : 1 ) the use of computers and calculators ; 2 ) writing about mathematics ; 3 ) discussing mathematical ideas . _ J _ _ A . ( 1 ) & ( 2 ) . _ 0 _ _ _ B . ( 3 ) only . 0 C . none of the above . 33 D . all of the above . 78 PARTII . The ten multiple - choice items were graded dichotomously ( right or wrong ) against a key . Each questionnaire was assigned a score of 1 , 2 , or 3 : 1 - for six or less correct answers ; 2 - for seven correct answers ; 3 - for eight or more correct answers . Table 14 PART II of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 7 6 16 29 2 . 31 3 - 5 9 7 13 29 2 . 14 ' 6 - 8 18 10 6 34 1 . 65 9 - 12 10 10 14 34 2 . 12 Calculated Chi - Square = 11 . 43 , df = 6 The value of Chi - Square was less than the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 076 , and PV = . 924 . There is no significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 79 PART II . There were ten multiple - choice questions in this part of the questionnaire . Most all questions dealt with alternative assessment and incorporated a full range of assessment techniques , practices , and nomenclature . In item 01 , projects and portfolios , as the characteristics of alternative assessment was the " best " ( i . e . , most frequent ) choice for all groups . There were no clear second choices for items 02 , 03 , 04 , 05 , 06 , 09 , and 10 among all groups , but all first choices with the highest frequency among the groups agreed with expert opinion . For item 07 , only groups 3 - 5 and 9 - 12 agreed with the experts in defining holistic scoring as a single score event . Only the K - 2 Group marked authenticity as the focus of performance - based tasks . Two groups chose accountability and one group picked analysis most frequent . The chi - square test again revealed no significant differences in scores between the teacher groups , but the range between means scores was similar to the range values of the remaining parts of the survey . The testing format used in PART II may have had an impact on the results . 80 Table 15 PART III of the Survey Instrument : Results for Teacher Grade Level K - 2 by Frequency of Selection for 29 Respondents PART III Indicate your level of understanding for the following methods of assessment : ( not sure ) 1 2 3 4 5 ( very familiar ) 1 2 3 4 5 01 Recorded informal observations 0 3 3 11 12 02 Structured interview plan 10 5 6 5 3 03 Math journals 2 4 3 11 9 04 Student attitude inventories 6 4 7 8 4 05 Holistic scoring techniques 9 5 4 3 8 06 Performance assessment tasks 2 2 6 11 8 07 Open - ended questions 0 0 7 9 13 08 Reports using self - assessment data 5 7 11 0 6 09 Mathematics portfolios 4 4 5 6 10 1 0 Math projects 2 2 7 7 11 81 Table 16 PART III of the Survey Instrument : Results for Teacher Grade Level 3 - 5 by Frequency of Selection for 29 Respondents PART III Indicate your level of understanding for the following methods of assessment : ( not sure ) 1 2 3 4 5 ( very familiar ) 1 2 3 4 5 01 Recorded informal observations 2 5 2 10 10 02 Structured interview plan 6 6 6 8 3 03 Math journals 2 3 2 14 8 04 Student attitude inventories 3 7 3 8 8 05 Holistic scoring techniques 5 7 5 5 7 06 Performance assessment tasks 1 1 8 8 11 07 Open - ended questions 0 2 3 12 12 08 Reports using self - assessment data 6 5 8 6 4 09 Mathematics portfolios 2 2 9 11 5 1 0 Math projects 2 1 7 12 7 82 Table 17 PART III of the Survey Instrument : Results for Teacher Grade Level 6 - 8 by Frequency of Selection for 34 Respondents PART III Indicate your level of understanding for the following methods of assessment : ( not sure ) 1 2 3 4 5 ( very familiar ) 1 2 3 4 5 01 Recorded informal observations 7 7 5 5 10 02 Structured interview plan 10 9 6 6 3 03 Math journals 1 6 9 11 7 04 Student attitude inventories 8 8 6 6 6 05 Holistic scoring techniques 10 6 10 5 2 06 Performance assessment tasks 4 5 7 9 9 07 Open - ended questions 2 4 5 11 12 08 Reports using self - assessment data 7 8 9 4 6 09 Mathematics portfolios 4 8 8 8 6 1 0 Math projects 1 4 8 14 7 83 Table 18 PART III of the Survey Instrument : Results for Teacher Grade Level 9 - 12 by Frequency of Selection for 34 Respondents PART III Indicate your level of understanding for the following methods of assessment : ( not sure ) 1 2 3 4 5 ( very familiar ) 1 2 3 4 5 01 Recorded informal observations 4 5 11 11 3 02 Structured interview plan 6 14 7 3 3 03 Math journals 0 3 17 10 4 04 Student attitude inventories 6 12 7 5 4 05 Holistic scoring techniques 13 6 7 4 4 06 Performance assessment tasks 5 2 7 14 6 07 Open - ended questions 1 0 5 14 14 08 Reports using self - assessment data 10 9 9 3 3 09 Mathematics portfolios 7 6 9 9 3 1 0 Math projects 0 2 3 22 7 84 PART HI . A total of the selected number - choices of the respondents was the graded score . The range of the graded scores was 10 - 50 . The assigned scores of 1 , 2 , or 3 implied : 1 - a graded score in the 20 ' s ; 2 - a graded score in the 30 ' s ; 3 - a graded score in the 40 ' s . Table 19 PART III of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 8 1 4 7 29 1 . 97 3 - 5 9 8 1 2 29 2 . 10 6 - 8 1 8 7 9 34 1 . 74 9 - 12 1 9 1 1 4 34 1 . 56 Calculated Chi - Square = 14 . 11 , df = 6 The value of Chi - Square exceeded the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 028 , and PV = . 972 . There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 85 PART 111 . Respondents on this section were to mark their level of understanding of ten alternative methods of assessment that included : recorded informal observations , structured interview plans , math journals , student attitude inventories , holistic scoring techniques , performance assessment tasks , open - ended questions , student reports using self - assessment data , mathematics portfolios , and math projects . All teacher grade level groups indicated that they were " more familiar " ( i . e . , total of 4 - 5 range ) with recorded informal observations , math journals , performance assessment tasks , open - ended questions , and math projects . A " less sure " ( i . e . , total of 1 - 2 range ) was recorded for all groups for structured interview plans , holistic scoring techniques , and student reports using self - assessment data . The means of the scaled scores for PART III were similar for the primary and intermediate teacher groups and similar for the middle school and high school groups . This pattern would persist through the remaining parts of the survey with the primary and intermediate teachers scoring higher than the other two groups . The chi - square test underscored these differences between the groups . 8 6 Table 20 PART IV of the Survey Instrument : Results for Teacher Grade Level K - 2 by Selection for 29 Respondents PART IV In the space provided , list your answers to the following questions . 01 What " stuff " could be included in a math portfolio . math journals , performance assessment tests , homework examples : chapter test scores , cumulative test scores , work samples : math facts 1 - 12 , simple addition , subtraction , even / odd numbers , greater than / less than , identify coins ; projects with graphs and surveys , math journals , manipulatives , exploration , math interviews , tests with area , webs ; recorded observations , children ' s writing , samples explaining process , photos of children at work ; journal entries , tests , math writings , homework , pre­ post tests : student selected journaling , standard scores , projects , taped interviews ; speed tests , problem solving , interests ; random pages , random tests , random story pages ; pattern work , math tests , measurement activities , graph work ; surveys , graphs , sketches or other work of manipulatives , math journals , problem solving , sketches and notes ; student generated story problems , computation results , math journal ; math journals , projects , performance task results , formative test scores , summative tests , individual assessments by teacher - informally ; work showing child ' s thinking , math projects , math journal ; graphs , surveys , computation worksheets , story problems , homemade tangrams ; computation papers , math inventories , examples from 87 Table 20 ( continued ) , " hands on " math books , weighing , surveys , measuring , observation notes ; math logs ( journals ) , projects , papers showing understanding of concepts , self assessments , observational logs , interviews ; photos of projects , writing of projects , problem solving , testing information , new ideas ; problem solving work written about , computational skill measurements , project work , math journals ; projects , journals , problem solving activities , photos of work going on , interviews , self assessments ; math journals , projects , graphs , computational problems ; computation pages , surveys , descriptions using math concepts , journal questions and answers , records of weighing activities ; problem solving tasks , semi - concrete recordings , recording of their thoughts , surveys , graphs , computation work , how they use mathematical language ; class work samples , tapes of student talking about his project , teacher ' s anecdotal notes , skills checklists ( regularly updated ) , list of math related literature student has read ; tests and quizzes , class and individual projects , math journals , homework , things chosen by teacher and or student showing where he / she is - any improvement , " hard " copy from manipulative activity ( i . e . patterns made using pegboard ) ; everything they do related to mathematics especially the integration of other subject areas - example writing and illustrating story problems about castles and medieval life or measuring the length of the class guinea pig , exploring patterns of seashells or painting Chinese numerals , logs , journals , lab books include weighing , measuring , surveying , geometric exploration , patterning , money , etc . ; math drawing , center work , calculations , journal books written and illustrated by student ; teacher observations , math journals , teacher assessments . ( no response 1 ) 8 8 Table 20 ( continued ) , 02 Name three mathematical projects appropriate for your students . money - a store and many items to sell and buy , time - time keepers with activities pertaining to that time ; graphing - various things , people ; number families , 2 add , 2 subtract , for each using linker cubes give another name - 2 red plus 3 blue for 5 ; doubles - fold paper in half make dots with paint on one side - make up math sentence ; roll dice to make problems ; use clay to identify shapes - cylinder , sphere , cube ; Aims projects ( graphing , surveying , sorting , categorizing ) ; thanksgiving soup contributions - graph , pumpkin seeds , measuring pumpkins and comparing ; Dino sort - sorting , labeling , counting , graphing , comparing ; activities related to real materials - sand and water , building with blocks , unifix cubes , pattern blocks , surveys and graphs ; running a class store , not familiar enough with math projects ; structure planning and construction - have to think about this ; calendar , graphing , measurement ; counting projects , comparisons , time , measurement ; I guess . . . . a hands on task of using blocks or something to show a task using centers from the math book in small groups , write a number sentence after reading a problem and solve it ; patterning activities ( using different materials ) , graphing ( literature , favorite characters , weather ) , addition collages with beans ; patterning activities , pattern block walls , surveys and graphs related to our study , store - pricing items , buying and selling , making change ; use manipulatives to add or subtract , computer - add and subtract , orally tell stories , draw pictures or use manipulatives to analyze ; measure familiar objects using units ( i . e . paper clips , pipe cleaners ) , bring in favorite toy bear ( graph , tally , size , color , stuffed , plastic , etc . ) , make - up and perform in small groups - number problems ; design a house using graph paper , determine area for each room and entire house - make a model , design a game that teaches young children how to add - try it out , bring in favorite recipe - double or triple it - make a cookbook - cook some dishes and invite guests ; graphing 89 Table 20 ( continued ) , birthdays , sorting M & Ms , playing with money ; making patterns with pattern blocks , taking a class survey - make predictions - take survey then record findings , weighing common objects in room - compare ; tangrams ( explore geometric shapes and spaces ) , estimating ( number of M & Ms in a jar ) , graphing ( birthdays , answers to social studies questions , favorites . . . ) ; using drama to do a story problem , write 10 fractions about your family , using coins to show 6 ways to make 85 cents ; creating our own math problem situations for others to solve , geometry study with manipulatives and recorded findings , a study of patterns that include number patterns ; make a gingerbread village - involve geometry and measurement , read Time To - Bruce McMillian - record what they do during day - every hour , etc . , what can you do in a minute ( sing Row Your Boat - how many times ) ; illustrate math problems , figure out a problem to solve - how to go about it and accompanying writing , take a survey - make a graph , write results ; creating lego structures with symmetry . weighing various manipulatives , measuring dinosaurs with adding machine tape ; dividing food into parts - do we have enough ? 24 cookies into 2 kids - 3 kids - 4 kids , etc . , money - store - price items - sell - make change , measuring with non - traditional materials - peanuts - toothpicks ; sorting tasks , patterns - completing patterns started and creating own , simple projects using real money ( coins ) ; use of manipulatives - unifix cubes - pattern blocks - geoboards - attribute shapes - pegs and pegboards - etc . , make designs using pattern blocks then transfer design to paper , write a math story on the computer using small toys or puppets to act it out ; sand and water - explore volume using different sized containers to fill , surveying - take " special interest " surveys - matching one to one - finding difference - record findings , measuring - weighing - estimating ( always ) compare results - record - example ( it took 25 blocks to measure the length of the book , how many groups of ten can you make ? which was more - your guess or your findings ; design a pattern according to their level , make number equations ; use manipulatives to make number sentences , math journals , patterning . ( no response 0 ) 90 Table 20 ( continued ) , 03 Briefly outline a mathematical performance task . ones and tens - handle objects and move from one column to the other , story problems , students are given task that require steps for its completion ; student is to successfully make a transaction with money - making change ; draw circle - place 1 red block inside - place 2 yellow blocks outside - place 3 blue blocks at top ; using connecting blocks do simple addition or subtraction problems ; page of addition problems done in a time - frame ; unsure ; tell story - show how to add - take away - write a number sentence and solution ; give student a number sentence card ( add or subtract ) make up a story that represents it ; provide students with a menu - they have $ 4 . 50 - they figure out what they can choose for dinner and what change they will get back ; find a penny - nickel - dime - quarter in this pile of money ; given a color or shape pattern can the child reproduce same pattern - then can they make a pattern like the first one but change the colors or shapes ; using a calculator - after introduction and playtime - have children find answers to 2 digit addition and subtraction problems ; using appropriate place value blocks and appropriate chart show 1 , 542 ; don ' t know - perhaps a age - appropriate problem solving situation scored by holistic means ; make a different attribute chain ; I have 3 turkey feather colors - if each turkey has 3 feathers how many different looking turkeys could I make - supply turkey patterns and colored paper ; child will recognize coins , pennies , nickels , dimes and make change up to 20 cents ; not sure , everything above is what I call a performance task ; given a set number of objects and a set number of people , the child can divide the objects equally among the people ; sort a pile of junk into common groups , explain why - describe common and different characteristics , attributes ; make a Venn diagram - sort things like buttons , attribute blocks or just a variety of items - according to size , color , shape , texture or other attributes ; 1 - 1 correspondence - child would count 1 - 20 using manipulatives ; 1 - 1 correspondence while counting , estimating . ( no response 4 ) 91 Table 21 PART IV of the Survey Instrument : Results for Teacher Grade Level 3 - 5 by Selection for 29 Respondents PART IV In the space provided , list your answers to the following questions . 01 What " stuff " could be included in a math portfolio . basic arithmetic , word problem stories , make up problem stories , newspaper ads to make up problems , math puzzles , brainteasers ; ideas , experiments , good and bad , tests ( all kinds ) , data concerning the difference of 4 learning - teaching styles ; math log ( journal ) entries , observations from performance assessment , tests , self - assessments ; projects , journals , problem solving notebook , list of math games played , computational worksheets ; math journals , teacher observation , student projects i . e . games - architecture activity - student writing ; chapter tests , evaluation of concepts , notes about participation in class , notes on projects done ; informal assessments , journals , logs , formative test results , performance task results , some projects ; photographs of projects , tape recorded conference information , data collection , projects themselves ; journal writings , math logs , assessment tests , performance tasks , informal observations ; graphs , surveys , manipulative answer sheets , photos , videos , tests with actual computation ; projects , group work , photos of kids at work ( project ) , chapter tests , work student has self - initiated ; math projects - photos , math writing , performance assessments , student created problems , student ' s perception ; projects , essays about how to - do something , self assessment , informal observations , objective tests ; student samples , assessment , projects ; examples of mathematical reasoning , math dictionaries , problem solving 92 Table 21 ( continued ) , " books " , formative assessments , journals ( student evaluation ) ; math journal , tests , classwork , homework , " math center " activities ; math journal , test scores , evaluations , computer skills and interests , worksheets ; worksheets , project summaries , logs of graph work , homework ( with family ) ( newspaper searches ) ; projects , fact practice , beginning and ending assessment , journal entries ; times tables , a calculator challenge , questions , geometry shapes ; math journals , assessments , tests , work ; student projects , video of student performing tasks , holistic testing , journal entries , problem solving samples ; math journal entries , problem solving activities from classroom , computation papers , graphing / surveying activities completed ; recorded informal observations , self - assessment data , student attitude surveys , problem - solving type data , responses to course of study objectives ; projects , sample work , tests , math log , problem solving samples , informal observations ; projects , writing samples , anecdotal records , formal / informal assessments , extension activities , cooperative group projects . ( no response 2 ) 02 Name three mathematical projects appropriate for your students . build a pyramid using geometric knowledge , math journal - writing about math in your everyday life , tangrams ; 6 month stock project - using scale drawings , diagrams and geometry , design projects ; bridge building ( design , buy materials , build ) , scale house building , " mini society " ( job , salary , income , expenses ) ; volume study - volume of solid objects using displacement , percentages / fractional equivalent - percentage analysis state by state with pie graphs , one hundreds charts , pentominoe study - geometry unit ; study / exploring geometry in the world - use of measurement - manipulating space , problem solving activities that require logical thinking , reasoning and working through problems over a period of time - no one correct answer , projects involving money - decimals , percentages , prices and how used in the world ( sales , stockmarket , temperature , etc . ) ; architecture project - design an architectural feature , room or floor plan to scale - 93 Table 21 ( continued ) , provide drawings and measurements ( social studies , language arts integration ) , art project - grid off a picture / portrait then grid a larger paper to scale and reproduce using the grid as a guide , create your own board game of math riddles or word problems ; working with a partner and a recording sheet find numbers in the classroom - write where you find them and what they mean ; place value project with 2 or 3 players , 10 cards numbered 0 - 9 and a game board ; using a calculator and chart with start , finish and wipe out columns , find which number can you subtract from start numbers to get finish numbers on calculator ; plan one activity appropriate for a math fair using measurement ; write a " pop - up " word problem book based on a trip to the grocery store ; in groups of three , collect birthday data from classmates , display results on a pictograph , circle graph , line graph or bar graph ; pumpkin caper - weighing , measuring , comparing circumference , seed numbers , ability to float of pumpkins - from Aims ; Toothpick bridges , excellent fun ; graphing project ; geoboards , multi - cubes , computer ; survey other students and graph results ; read the sales or advertisement section of the newspaper , make and solve 3 story problems ; eat vanilla wafer cookies to show whole , quarter , half moons , label new , crescent , half also ; budgeting for a family ; working with organic and geometric shapes ; surveying and graphing , drawing conclusions ; cooperative groups - with these objects create a model that has moveable parts and does a particular job ; determine how Napier ' s rods work and solve these problems ; use a catalogue to spend $ 53 . 00 , spend as close to this amount as possible ; give an amount of money and event , choose how to spend exactly the amount ; writing own story problems ; write a survey , collect information , tally and create a graph ; hands - on activities , Aim ' s materials ; Math Everyday Counts ; run a " flower shop " and analyze results ; house building and decorating ; geometry dictionaries ; calculator activities ; making graphs ; using manipulatives ( i . e . making change ) ; planning a " party " , earning money , shopping , portion control , calculating change ; furnishing a room with paint , wallcovering or flooring , measuring and finding costs ; cooking - multiplying amounts ( fractions ) of ingredients , measuring and following directions ; enlarging USA map and painting it on playground , graphing , cost ; cooking refreshments for 94 Table 21 ( continued ) , parent program ( recipe doubling / tripling ) , shopping ; string art ( geometry ) ; brainstorming steps in graphing , following these steps and producing a final product ; free exploration with sorting and then journal ; play games involving a concept and then write about their strategy ; a grocery , store with empty boxes , prices , play money , problem sheet ( cooperative learning ) ; assignment - interview people in the school as to color choice , make a graph of results ; measure heights of everyone in the class and make a graph ; surveys / graphs ; Christmas shopping with $ 50 . 00 , who can get the most for their money ; explain winning positions in the game of Nim , analyze winning move proving why it is so ; fill in a 0 - 100 chart looking at palindromic numbers in terms of how many steps and the pattern of their palindromic partners ; how many unique triangles of area 2 square units can you identify on a 10x10 geoboard ; given a problem solving activity , kids would give solution , draw picture to explain solution , write about it ; finding and relating shapes and patterns in nature , school , home - recording and writing about it ; planning a party , meal , etc . , estimating and finding costs ; write and illustrate a mathematical problem ; make a probability task ( on same level of spinning wheel ) using incongruent fractional pieces ; survey a group of individuals , graph findings ; creating an orienteering course for others to follow ; mapping the classroom and school using measurement and scale ; averaging using a package of chocolate chip cookies ( how many chips in the average cookie ) ; pictographing using literature in cooperative groups based on questions comparing number of pictures with emphasis on more or less ; tangrams using Chinese literature Grandfather James Story and student questions . ( no response 2 ) 03 Briefly outline a mathematical performance task . follow directions to arrive at a mathematical solution ; use fraction pieces to demonstrate and explain the problem 3 2 / 3 + 2 2 / 3 , observe the students as they do do this noting trial and error , successes and methods ; if a pool is twice as long as it is wide and its total perimeter is 84 meters , what is the width and length of the pool , show how you figured out this problem ; Mr . B . wanted to 95 Table 21 ( continued ) , put a fence around his yard , he had 24 sections of fence to use , show the possible ways he could build his fence and the fence design that is best , write and explain why you chose this fence design ; patterns , provide students with manipulatives to create patterns ( i . e . using triangles to build larger triangles and discovering the pattern for doing so ; adding three or more addends , first add the ones , regroup ? add the tens , regroup ? add the hundreds , regroup ? check the sum ; mentally add strings of numbers using groups of ten ; teaching tenths and hundredths using M & Ms count them out into groups of tens , then tell how many out of each group of ten is a particular color , example 3 / 10 or . 3 , graph results ; ( A ) objective stated - build a solid to match a given solid using cubes ( B ) student activity - student would be shown a solid made of cubes , student would then build a solid to match the other solid using his / her own cubes , student would write about the solid or build another solid ( C ) performance task should be evaluated as yes / no for mastery ; using tricks cereal , paper and pencil a student will group cereal to depict 3x5 = ? using a calculator to figure simple interest or percentages ; use toy money to show $ 3 . 24 several ways , share with a partner , use a calculator to check your amounts , write about two of your options ; demonstrate probability by using playing cards ; not sure . . . language arts 8th grade was my area the past ten years ; use fraction pieces to demonstrate for me 1 1 / 4 - 3 / 4 = ? students will be able to make change up to $ 1 . 00 for items costing $ 1 . 00 or less by counting back ; I have attached the 4th grade performance tasks from the alternative tests our school is using ; give a box of coins / bills to the student , show several ways of making change for $ 5 . 00 ( if spent $ 3 . 27 ) ; the child is given the problem , materials , time limit ; with tangrams use any four pieces , create as many different rectangles as possible ; given 3 dice , the child can roll them and can write the largest or smallest 3 digit number ; students will be able to identify groups of ten using manipulatives , counting , grouping - place value of ones / tens . ( no response 7 ) 96 Table 22 PART IV of the Survey Instrument : Results for Teacher Grade Level 6 - 8 by Selection for 34 Respondents PART IV In the space provided , list your answers to the following questions . 01 What " stuff " could be included in a math portfolio . student work ( assignments ) , notes , tests / quizzes , journals , projects ; tests , notes , assignments , assessments ; standardized tests , projects ; homework , seatwork , assessments ; samples of homework , tests , problem solving , critical thinking , decision making ; projects , graphs , charts ; homework papers , geometric drawing , student solution to problems , student test , student quiz , notes on classwork ; notes , projects , manipulatives , test results , assessments ; homework samples , formative tests , journal entries , math projects ; anything the student deems important ; sample work , definitions , math lab work ; anything you or your student decides ; daily work , math journals , problem solving strategies , assessments - informal and formal , interest inventories , self evaluations , teacher evaluations ; tests , journal entries , essay questions , written projects , evaluation of student performance , CBE results ; timings , writing about math , mental math practice ; papers representative of class work mastered , group projects , computer discs / games used , classroom tests , standardized test results ; chapter test , CBE , CWT , math worksheets , work from textbook ; work samples student notes , 97 Table 22 ( continued ) , teacher notes ; problem solving techniques applied to a real life situation ; practical math experiences - i . e . shopping list , expenditures , work done in class , mathematical experiences , newspaper articles relating to math ; math papers students are proud of , reflections upon their work , attitude surveys , projects , teacher selected work , reports ; computational skills , test results , math writing , word problems ; math journals , notes taken , projects completed , test scores ; examples - quizzes , homework , journals writings , examples of problem solving , group project work , individual projects ; writing answers - problem solving techniques , steps on reasoning used to arrive at a solution . ( no response 8 ) 02 Name three mathematical projects appropriate for your students . lab work - discovering pi ; geometric constructions ; discover heights of objects ( trees , buildings ) ; using similar triangles ; make geometric shapes , record statistical data of observed results ; string art , designing buildings , construction of buildings according to specific skills ; projects are difficult in algebra ; scale drawings and model house construction ; group problem solving dittos , Ohio Math League group problem solving ; reports on famous mathematicians ; surveys - put in graph format ; report on mathematical person or topic ; student design or model to test some mathematical concept ; solve a complex problem involving multiple steps ; 3 dimensional geometric figures ; map making - scale ; posters , research of mathematical men or women ; art related projects , string art , construction ; I feel any mathematical project ( any project ) can be adapted to mathematics and if we organized and planned could be used adapted to all students ; report on a famous mathematician ; devising a number scale based on a different scale than 10 ; a shopping expedition or stock market purchases ; collect data or survey , present a point of view , support 98 Table 22 ( continued ) , with graphs ; sell metric system of measurement to your community ; open shelter food drive , coordinate food , transportation , jobs ; constructing castles , homes or artifacts that are done to scale , student designed teaching units - example nine units on geometry , measurement , etc . , taking a particular unit or topic in math and making designing games - to help learn / practice concepts ; researching something like Pascal ' s Triangle or Fibonacci and sharing findings - making visuals for the class ; statistics project , students create a survey , handout , tally , do oral presentation with visual graphs ; graph project , students collect various types of graphs - line , circle , etc . , mount , tell how the graph is used and what kind of graph it is ; have students collect data , choose type of graph best for information , be able to present information to class ; study ancient numeration system and report ; research life of a mathematician and portray him / her , take a survey and produce statistical graphs , tables , charts ; students surveyed students ( favorite TV show , class ) and create circle graphs for hall bulletin board ; cut out tangram pattern pieces , find as many of the 13 polygons as possible ; ask students to write their own advertisements and specify the number of days they should run ; have students list all the factors for numbers 2 - 36 , name all numbers with an odd number of factors and tell what they have in common ; problem solving ; geometry ; probability ; figuring perimeter and area of a room ; track a " checkbook " account ; using newspaper ads to shop ; graphing compiled data , surveys or opinion polls , living expenditures ; halving or doubling a recipe and making food ; the measuring and making of any product ; gathering data for making charts and graphs ; making and performing an " arithmeskit " ; designing a room , use geometry and a budget ; write , present , and solve a word problem ; design a math game , include rules and answers ; drawing and building a castle to scale for a Shakespeare study ; learning how to use an areateering compass , integrated with map reading in social studies ; exploring the school for geometric shapes ; team - cooperative solving real world problems ; research history - background of topic ; parent / community involvement in " math " work . ( no response 10 ) 99 Table 22 ( continued ) , 03 Briefly outline a mathematical performance task . find area and volume of objects using the real numbers ; add fractions , like denominators first , denominators that are multiples , relatively prime denominators , mixed numbers ; individualized by student and teacher ; learning to use and read rulers , measurement activities drawing and measuring using rulers ; describe how to change a mixed number to a fraction , demonstrate with manipulatives ; any kind of a problem that requires the student to plan a strategy , make a guess / estimate , carry through with calculation and be able to explain the process involved in solving the problem ; activities that would allow students to show they understand mathematical concepts such as algebra , lab used to show how to factor an equation , colored counters to show computation with positive and negative numbers - using the TI - 82 to graph equations ; a test on multiplication computation ; assign a math task , assess it ; find the volume , area and perimeter of a student ' s locker ; given a problem done incorrectly , students write about or orally explain what was done wrong and show what must be done to correct it ; given a road map , students tally mileage to a specific destination and estimate time to reach it ; not sure - the teacher might ask the student to - do a problem ( multiply mixed numbers ) and then evaluate how the student performed ; free response to a " situation " , several possible reasoning solutions possible , more than correct answer required for credit . ( no response 21 ) 1 0 0 Table 23 PART IV of the Survey Instrument : Results for Teacher Grade Level 9 - 12 by Selection for 34 Respondents PART IV In the space provided , list your answers to the following questions . 01 What " stuff " could be included in a math portfolio . date , work , likes and dislikes about class , error sheets ; no idea ; basic concepts , history of those who developed the concepts , special problems i . e . " how many piano tuners are there in Chicago " ; detailed work on present topics or practical applications , explorations of present topics ; homework completed , illustrations of math concepts , tests / quizzes , student compiled set of applications , a bit of history on the concept , a student ' s summary of concept , again I am unfamiliar with this topic , the above items are off the top of my head ; standardized tests , projects , journals , group projects , essays , individual projects ; project , opinion question ; anything to - do with math ; articles ; checklist of concepts , grades , teacher analysis of student ; homework , returned tests , quizzes , projects ; projects , tests , awards , examples of real applications from books , journals or own experiences ; class notes , questions that come up doing homework , homework / test pages , paragraphs regarding specific topics ; computation ability , spacial reasoning , essays ; my favorite problem , test and homework , my proof - not like the book , demonstrate a problem solving technique , math in an occupation , math contest results ; homework , tests and quizzes , essays , projects , journal entries ; all homework , all tests , reports ; homework papers , projects , tests and quizzes , notes from class , self evaluations ; a " good " test , a graded homework assignment , response to math essay questions , peer graded quiz , 101 Table 23 ( continued ) , student written explanation of a concept discussed in class ; own research , notes on major topics , own definitions , future questions to explore ; projects , essays , outlines , summaries , special assignments , model homework ; co - op learning activities , journal entries , interviews , open - ended questions , awards , research projects ; graded tests and quizzes , student pre and post , written impressions of what should be / was in course , written summaries of major topics ; notes , homework , quizzes and tests ; homework , tests , quizzes , projects , notes , extra credit ; writing journals , " scrap " paper , pictures representing feelings , math problems that were significant to the student , steps of a solution , tests - traditional and essay and open ended questions , print - outs . ( no response 8 ) 02 Name three math projects appropriate for your students . biographical information on famous mathematicians emphasizing different cultures ; report on something ( pyramids , people ) ; engineering / designing better Pepsi can ; statistical study of area of interest ; research historic mathematicians - presentations ; history of mathematicians and their work ; keep a journal of how you use math in daily life or on special occasions ; do a project related to a topic i . e . probability and statistics ; do your own Harris Poll , % of people cheating on their income tax - how to handle touchy questions and get honest results ; experiments in mathematical physics ; computer applications ; data collection and analysis , investigate statistical topics in relation to data collected ; investigate and present historical math topics ( for example using an abacus , can it be used to find square roots ) ; collect examples of occurrences of the conic sections in the world around us , perhaps make models of such applications ; have students write essay on mathematical usages in " real world " ; do a geometric construction ; do a statistical analysis of the classes ' grades ; graphing on a computer , a linear system ; quad formula ; pt slope formula ; box plots ; statistical story based on peer group ; pepsi can modeling problem ; keep realistic budget ; book report ; biography of mathematicians ; research of mathematical concept ; collect data and model mathematically to predict future values 1 0 2 Table 23 ( continued ) , ( example , population ) ; predict distances and heights using similar figures ; compile a collection of examples ( pictures , problems , applications ) of certain mathematical concepts ; family finance - income , wages , interest , budgetry ; house and room design - area , volume , measurement ; ecology - amount of waste , cost of recycling ; graphics , current events , probability projects ; poster contest ; math in the newspaper ; make a new pepsi can ; constructing " 3D " geometrical figures ; proving Pythagorean theorem in different ways ; designing an " object " ( house , storage task , etc . ) complete with all numeric details ; confirmation or rebuttal of publicized data of a mathematical nature ; using " real " data collected from reliable sources to develop opinions and / or projections ; collect data on class and use statistical graphs and quantities to characterize the class ; use graphing software to explore how changing constants in a family of equations affects the graph ; use trig to determine height of objects which can ' t be measured directly ; sub problem a one week project ; exploring fractions ; collect and analyze data on a topic ; investigate relationship of logarithm and the slide rule ; determine the effects of b in y = ax 2 + bx + c ; devise a computer simulation for tossing in dice ; presentation of real - life application of math being studied ; develop materials that would help others learn a concept ; write a limited response question and collect data and do as advanced analysis of data as possible for level of kids ; estimate the height of 2 to the power of 100 sheets of paper in a stack , explain estimate , demonstrate ( with visual aids ) magnitude of height ; find a person who uses mathematics ( beyond arithmetic ) in their daily work and interview and report ; poster ; report ; oral presentation ; I like to use cooperative learning groups for many application sections in the book ; I like to use problem of the week for extra credit to sharpen their problem solving techniques ; for trig section in algebra 2 , I am going to have them find heights of various objects by using their shadows , a nice spring project ; bridge building , paper written on bridges , constructing plans for building a house ; create a hypercard stack that illustrates a particular objective ( adding like terms ) , how to find the area of a polygon ; research a famous mathematician , write a report , present a summary , create a bulletin board or poster ; research the rain 103 Table 23 ( continued ) , forest destruction , use a spread sheet to calculate the date when rain forests no longer exist , write a mathematical question . ( no response 7 ) 03 Briefly outline a mathematical performance task . speculate that it is a specific hands - on task related to a particular math topic that a student is to demonstrate his / her capability toward ; given a candy bar have students find volume , surface area of wrapper and determine mass , they could also figure cost per unit ; any quiz , test , paper ; a bunch of jargon , could it be a problem solving exercise or maybe simply testing ones maturity - beats me ; getting freshmen to - do their homework ; solve a geometric problem , draw figure , mark what " is given " on figure , write down the " given " another " to prove " , analyze proof , write proof ; the ability to start with raw data ( or a roughly defined project ) and put together a cohesive and complete picture of the results of their work ; students research data relating two variables say per capita cigarette consumption to lung cancer and attempt to find an equation which could be used to model the relationship between the variables ; give a problem in words , work on it over several days , may include a class trip ( class period ) to the library , multiple parts , several possible methods to solve possibly different results based upon assumptions made ; given a set of data , select the best model that fits the data , defend your choice ; have students describe the relationship of the graphs of two linear equations , expand to discuss other relationships and the graphs that represent them ; given two points ( x , y ) , integer coefficient ( x ) less than or equal to 10 , ( y ) less than or equal to 10 , the student will reproduce the equation of the line through the given points in y = mx + b form ; figuring interest on a car loan and what the monthly payments would be ; given a procedure for a particular skill , I ' d use my cooperative learning groups to decide on a solution for a problem ( problem solving ) ; a task which measures the student ' s knowledge , this task could involve an oral discussion , written test , creating a spread sheet , showing a solution to a question or exploring someone else ' s solution . ( no response 18 ) 104 PART IV . Scores were asigned as follows : ( 1 ) for responses including quizzes and testing , computational skills , or a limited selection ; ( 2 ) for to a wider selection and increased variety of assessment items ; and ( 3 ) for a sense of the appropriate uses of portfolios , projects , and performance - based tasks . Table 24 PART IV of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 5 9 1 5 29 2 . 34 3 - 5 4 7 18 29 2 . 48 6 - 8 13 1 2 9 34 1 . 88 9 - 12 1 5 10 9 34 1 . 82 Calculated Chi - Square = 15 . 48 , df = 6 The value of Chi - Square exceeded the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 017 , and PV = . 983 . There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 105 PART IV . A series of open - ended questions dealing with the three most common components of alternative assessment— portfolios , projects , and performance tasks - comprise this part of the survey . Teachers were asked to describe , outline , or list appropriate items for portfolios , projects , and performance tasks . A characterization of descriptive phrases used by the teachers in discussing portfolios , projects , and performance tasks would be difficult . There were major differences between all groups , but there were distinct similarities between groups K - 2 and 3 - 5 and between the groups 6 - 8 and 9 - 12 . There were a number of descriptors or attributes that would tend to identify the primary and intermediate groups and , likewise , the middle school and high school groups . The K - 5 teachers tended toward a more alternative assessment mode with descriptors or attributes such as : center work , student choices , variety of choice , cooperative learning , explorations , learning centers , real life projects , manipulatives , and loosely structured projects and performance tasks . The 6 - 12 teachers tended toward a traditional mode with descriptors or attributes such as : tests , testing , quizzes , exams , text problems , timed activities , teacher choices , and highly structured projects and performance tasks . 106 Table 25 PART V of the Survey Instrument : Results for Teacher Grade Level K - 2 by Frequency of Selection for 29 Respondents PART V About what percent of each of the following do you use in determining the grade for each student at the end of the grading period ? ( 7 ) 10 - 20 % Homework ( 7 ) 10 - 20 % Quizzes ( 21 ) 10 - 60 % Classwork ( 21 ) 10 - 30 % Class participation ( 18 ) 5 - 35 % Class projects ( 12 ) 20 - 70 % Chapter tests ( 3 ) 10 - 20 % Final exam ( 18 ) 5 - 80 % Performance tasks ( 4 ) 5 - 50 % Lab work ( 9 ) 10 - 50 % P ortfolios ( 6 ) 5 - 10 % Notebook ( 4 ) 10 - 20 % Other - describe : _ _ _ 107 Table 26 PART V of the Survey Instrument : Results for Teacher Grade Level 3 - 5 by Frequency of Selection for 29 Respondents PART V About what percent of each of the following do you use in determining the grade for each student at the end of the grading period ? ( 20 ) 5 - . 3 . 0 % Homework ( 13 ) 10 - 20 % Quizzes ( 25 ) 5 - 70 % Classwork ( 25 ) 5 - 40 % Class participation ( 16 ) 5 - 20 % Class projects ( 17 ) 5 - 50 % Chapter tests ( 10 ) 10 - 30 % Final exam ( 12 ) 5 - 20 % Performance tasks ( 3 ) 10 % Lab work ( 7 ) 10 - 70 % P ortfolios ( 9 ) 5 - 25 % Notebook ( 5 ) 10 - 30 % Other - describe : 108 Table 27 PART V of the Survey Instrument : Results for Teacher Grade Level 6 - 8 by Frequency of Selection for 34 Respondents PART V About what percent of each of the following do you use in determining the grade for each student at the end of the grading period ? ( 31 ) 5 - 50 % Homework ( 28 ) § i _ 50 _ 2k Quizzes ( 19 ) 5 - 50 _ % Classwork ( 15 ) 5 - 15 % Class participation ( 8 ) 5 - 20 % Class projects ( 25 ) 10 - 75 % Chapter tests ( 9 ) 5 - 25 % Final exam ( 3 ) 5 - 10 % Performance tasks ( 4 ) 5 - 20 % Lab work ( 1 ) 10 % P ortfolios ( 12 ) 5 - 15 % Notebook ( 4 ) 10 - 40 % Other - describe : 109 Table 28 PART V of the Survey Instrument : Results for Teacher Grade Level 9 - 12 by Frequency of Selection for 34 Respondents PART V About what percent of each of the following do you use in determining the grade for each student at the end of the grading period ? ( 34 ) 5 - 50 % Homework ( 30 ) 10 - 80 % Quizzes ( 20 ) 5 - 25 % Classwork ( 16 ) 5 - 10 % Class participation ( 9 ) 5 - 10 % Class projects ( 30 ) 10 - 70 % Chapter tests ( 15 ) 5 - 25 % Final exam ( 5 ) 5 - 20 % Performance tasks ( 2 ) 15 % Lab work ( 1 ) 15 % P ortfolios ( 14 ) 5 - 20 % Notebook ( 3 ) 5 - 20 % Other - describe : 1 1 0 PART V . In this part on percentage in grade determination , the higher number of choices dictated the higher assigned value . If the focus was only testing and quizzes - 1 , for an expanded selection - 2 , and the expanded selection with interesting others - 3 . Table 29 PART V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 7 1 3 9 29 2 . 07 3 - 5 1 1 1 2 6 29 1 . 83 6 - 8 22 8 4 34 1 . 47 9 - 12 25 6 3 34 1 . 35 Calculated Chi - Square = 20 . 28 , df = 6 The value of Chi - Square exceeded the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 002 , and PV = . 998 . There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 111 PART V . This part was a percentage breakdown that illustrates how the teacher determines grades . The information requested describes what portion of the students ' grade is determined by homework , quizzes , classwork , projects , portfolios , performance - based tasks , class participation , chapter tests , final exam , lab work , notebook , or other . A diversity of assessment schemes were indicated by the four teacher groups . The teachers in the K - 2 Group chose classwork , class participation , class projects , and performance tasks - - most frequent ; and the K - 2 Group marked final exam , lab work , and notebook - - least frequent . The teachers in the 3 - 5 Group chose homework , classwork , class participation , class projects , and chapter tests - - most frequent ; and the 3 - 5 Group marked lab work , portfolios , and notebook - - least frequent . The teachers in the 6 - 8 Group chose homework , quizzes , classwork , and chapter tests - - most frequent ; and the 6 - 8 Group marked performance tasks , lab work , and portfolios - least frequent . Similarly , the teachers in the 9 - 12 Group chose homework , quizzes , classwork , and chapter tests—most frequent ; and the 9 - 12 Group marked performance tasks , lab work , and portfolios - least frequent . Classwork was the only consistent choice with high frequency and lab work with low frequency for all groups . A similar situation prevailed in this part as in PART III . The means of the scaled scores for all the K - 5 teachers were much higher than the means of the scaled scores for the 6 - 12 teachers . 1 1 2 The analytic scoring , with a range of 5 - 15 , for ail parts of the survey for all 126 respondents were re - scaled to meet the 1 , 2 , 3 standard ( i . e . , 1 = 1 - 8 , 2 = 9 - 11 , 3 = 12 - 15 ) . The results follow in Table 30 . Table 30 PART l - V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between Re - scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 6 1 2 1 1 29 2 . 17 3 - 5 8 1 2 9 29 2 . 03 6 - 8 20 9 5 34 1 . 56 9 - 12 1 6 15 3 34 1 . 62 Calculated Chi - Square = 16 . 85 , df = 6 The value of Chi - Square exceeded the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 010 , and PV = . 990 . There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 113 A totai of all scored parts of the survey was presented in Table 31 with respect to teacher grade level groups . Each cell represents the sum of all 1 ' s , 2 ' s , or 3 ' s for each group for all parts from the 126 respondents . Table 31 PART l - V of the Survey Instrument : Chi - Square Test and Level of Significance for Differences between All Scaled Scores of Teacher Grade Level Groups Score : 1 2 3 Total Mean K - 2 39 55 51 145 2 . 08 3 - 5 45 45 55 145 2 . 07 C O i CD 86 52 32 170 1 . 68 9 - 12 78 54 38 170 1 . 76 Calculated Chi - Square = 32 . 02 , df = 6 The value of Chi - Square exceeded the critical value of 12 . 59 at six degrees of freedom for alpha equal to . 05 . The actual Tail End Value and the Percentile Value were TEV = . 001 , and PV = . 999 . There is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . 114 Mean Scores . The mean scores were higher for the groups K - 2 and 3 - 5 than the mean scores for groups 6 - 8 and 9 - 12 in all cases except one ( i . e . , the anomaly occurred in PART I ) . There were no discernible differences in mean scores between groups K - 2 and 3 - 5 or between groups 6 - 8 and 9 - 12 . Chi - Sauare Test Results . The null hypothesis was rejected in five cases . In the two cases of acceptance - - PART I and PART II - - PART II would be rejected at a . 08 level of significance . The anomaly again occurred in PART I . Table 15 . 1 and Table 15 . 2 were composite tables ( i . e . , containing PART l - V ) . Both tables show alpha values less the . 005 significance level ( with the critical value at 18 . 55 ) . In te rv ie w s The interviews were conducted immediately following the collection of the survey instruments . Each of the selected respondents was asked questions on student evaluation , teacher evaluation , and program evaluation . The student evaluation questions asked for the respondents ' view of alternative assessment and their students ' view of alternative assessment . Questions for teacher evaluation focused on self - evaluation and the program evaluation questions examined alternative assessment as it applies to the current mathematics curriculum . 115 There was a total of ten telephone interview sessions . Each interviewee responded to questions listed in the Interview Outline . The recorded comments provided information on student evaluation , teacher evaluation , and program evaluation . Student Evaluation . All ten interviewed teachers praised the value of alternative assessment , but viewed the alternative process as something they have to do in addition to their regular duties . The primary teachers and intermediate teachers were more comfortable with alternative assessment than middle school teachers or high school teachers . Three of the primary and intermediate teachers had actually practiced alternative assessment over the last several years ; but the positive gains they were making using logs , journals , and portfolios was over­ shadowed by the administrative and parental pressure to produce higher achievement on the competency - based testing program mandated by the local school districts . Teacher Evaluation . Most teachers interviewed indicated that self - evaluation was an on - going process that included feedback from their interaction with students , colleagues , and parents . The teachers said that a formal administrative evaluation had little influence on their teaching performance . Program Evaluation . There were mixed responses to the question of whether the teachers ' current mathematics curriculum supported alternative assessment . The positive responses focused on : a new textbook series that involved a problem solving approach 116 through the use of manipulatives ; workshops on the use of the text ; and teacher freedom to use a method they believed in . All primary and intermediate teachers had negative comments on competency - based testing for a variety of reasons . The teachers implied that the competency - based testing was an extremely inadequate , frustrating , and time consuming practice . The respondents that had practiced alternative assessment for several years stated that they believed in the alternative method and wanted to continue the practice ; but , because of the recent emphasis on competency - based testing , the testing took too much of their time and energy . Summary The problem , as stated in Chapter 1 , is the lack of substantive data that accurately describes teacher awareness in alternative assessment of student achievement in mathematics . This descriptive study provides supportive evidence showing that significant differences in the data does exist , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups . The results from the Chi - Square Tables were two - fold : ( 1 ) the mean scores for K - 2 and 3 - 5 teacher grade level groups were consistently higher than the mean scores of the 6 - 8 and 9 - 12 groups ( i . e . , the mean scores of the K - 5 groups exceeded the mean scores of the 6 - 12 groups in all cases except one ( PART I ) ) ; ( 2 ) 117 the results verified that there is a significant difference in the scores , as a measure of teacher awareness of assessment practices , among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) in five of the seven applications of the chi - square test . CHAPTER V CONCLUSIONS AND RECOMMENDATIONS Introduction The results of this study indicated that there were significant differences in teacher awareness and practice of alternative assessment among the four teacher grade level groups ( i . e . , K - 2 , 3 - 5 , 6 - 8 , 9 - 12 ) . The results further show that teachers had differing views of alternative assessment techniques , practices , and nomenclature . The conclusions and recommendations contained in this chapter summarize the data and examine the implications of the findings that direct alternative assessment strategies for mathematics instruction . The chapter concludes with suggestions for future research on the investigation of teacher awareness of alternative assessment of students in mathematics . Conclusions To investigate teachers ' awareness of assessment alternatives , the following objectives directed this descriptive survey research : to compile a comprehensive set of educational evaluation and mathematics assessment standards , to develop a valid survey instrument to measure teacher awareness of 118 119 alternative assessment practices based on the standards , to develop a scaling technique to be applied to each of the completed survey instruments , to administer the survey to four select groups of kindergarten through twelfth - grade teachers , to compare the four teacher grade level groups using a chi - square test , and to compare the data results to existing information on assessment practices . The original intent of the survey was to investigate teacher awareness in alternative assessment . That quest led to the examination of differences in awareness and practice of alternative assessment between teacher grade level groups . The summary conclusions for Parts l - V explore Research Question 3 . Research Questions 1 and 2 follow with their own respective summaries . Research Question 1 Can a survey instrument be designed to provide data to investigate teacher awareness of alternative assessment of students in mathematics ? A survey instrument was designed to provide data that did examine teacher awareness of alternative assessment . The survey items were based on a set of standards and the items were modified over time to match the overall intent of the survey . The compilation of a comprehensive set of evaluation and assessment standards is not a difficult task at any given point in time . A 1 2 0 problem arises due to the dynamic nature of the standards . By the time the current series of standards have been evaluated , reviewed , and revised , the " new " standards are changed and provide a different base for survey design , thereby creating a dilemma . The survey process needs to be continuous and the survey instrument needs to include these elements of change . The interview process was most important to the overall impact of the information that was received . If the interview had been a focal point of the survey , interviewer training would be a necessary condition of the study . For the survey instrument used in this descriptive study , the changes that were made through the development of the questionnaire would suggest that the more closely the instrument resembles the attributes to be measured , the more realistic the expected results . The application of the principles of alternative assessment was needed in the development of an instrument to measure teacher awareness of alternative assessment practices . Research Question 2 Would a scaling technique and psychometric measurement reveal differences in teacher awareness of alternative assessment by grade level ? The scaled scores served as categorical data for the application of the chi - square test . The chi - square test described significant differences between the grade level groups . The study 121 has provided evidence that shows there were differences between grade level groups . In the quest to establish an informational base in determining differences in awareness and practice of alternative assessment between teacher grade level groups , the survey met a portion of that goal . The conclusions from the data would suggest that the primary and intermediate teachers have a better understanding of alternative assessment techniques , strategies , and practices than the middle school and high school teachers . According to the survey instrument rating system that was used , the K - 5 teachers were better informed or more familiar with alternative assessment techniques , practices , and nomenclature than the 6 - 12 teachers . Caution must be exercised in the scaling of any survey instrument . A conscious effort must be made to scale the instrument without the inclusion of bias . Two safeguards were helpful in the design of a scaling technique . They were : comparison of the design , intent , and purpose of the scaling technique to a learning model or paradigm ; and comparison of each scaled item to a benchmark standard . The primary results indicated consistent differences of means of scaled scores between groups and verified the rejection of the null hypothesis in five of the seven applications of the chi - square test on the parts of the survey instrument . These results were achieved through a process based on a set of objectives . 122 There is a degree of researcher satisfaction to be gained from psychometric measurement . It is reassuring to show that a given situation is true or not true based on mathematical manipulations . At a time when qualitative research is popular , quantitative methods tend to add credence to the claim of teacher difference in alternative assessment practices . Research Question 3 How familiar are classroom teachers with alternative assessment practices and are teachers using alternative assessment techniques to evaluate student performance ? Conclusions for the parts of the survey synthesized primarily from the data from the frequency tables of the survey instrument and scaled scores of the tables and in Appendix C were as follows : Part I - The teachers chose the level of importance they would give to an assessment practice in evaluating students . Of the ten purposes of evaluation that were listed , five had an alternative assessment orientation and five a traditional testing orientation . As indicated in Part I of the completed survey , teachers value all five purposes of evaluation from the assessment mode . The remaining five purposes in the traditional mode were less valued . It is difficult to argue for a teachers ' acceptance of alternative assessment as a better method of evaluation . There is sufficient 123 evidence in Part I to suggest that teachers tend to believe that the characteristics and attributes usually associated with alternative assessment methodology are reasonable choices in the evaluation of students ; however , there was little evidence from Part V of the survey to support the teachers’ actual use of these same strategies . An example of this situation occurred with item 08 . The teachers gave a low evaluation for " compare student ' s performance to others " , but in Part V the evidence shows a heavy reliance on testing , quizzes , and exams . It appears that teachers mark one process but actually do another . A response from Part I showed no significant differences between the groups and a majority of teachers perceived little difference between the two sets of statements . But the item responses from teachers , from the same school , were quite varied . This may indicate that the teachers do not have a clearly structured set of purposes for the evaluation of students based on a school philosophy . Several of the items in the survey were altered to meet the bias of the respondent . A good example was in Part I , item 01 . A number of teachers responded with a high score after altering the statement by crossing out the word " not " in answering item 01 which asked , " Find out what students do not know . " These kinds of changes skew the results and may further explain the anomaly in Part I . It could be conjectured that these types of alterations were not dealt with using the scoring system of this survey . 124 Part II - There were ten multipie - choice questions in this part of the questionnaire . The questions dealt with alternative assessment and incorporated a full range of assessment techniques , practices , and nomenclature . Part II favored the language of alternative assessment and the results were again mixed . Based on the scaling that was used , all groups except the middle school teachers had an adequate grasp of the language of assessment . Most of the respondents view calculators , computers , and manipulatives as appropriate for the assessment process , but a significant number of teachers believe that they are solely responsible for the assessment of students ( i . e . , omitting the student as an assessor ) . Approximately an equal number of teachers marked informal testing and higher order thinking as second most - frequent choices for characteristics of alternative assessment . A justification for higher order thinking would seem more reasonable than informal testing . The informal label may arise from the notions attributed to informal education . Item 04 asked about the appropriate use of calculators , computers , and manipulatives as part of the assessment process . Again almost all teachers shared the popular response that the use of all three is appropriate , but there was little evidence in Part IV to support the teachers ' use of calculators and computers . Calculators and computers in Part IV were neither mentioned often among teachers nor mentioned consistently by a given teacher . 125 Part III - In Part III the teachers were to mark their level of understanding of ten alternative methods of assessment that included : recorded informal observations , structured interview plans , math journals , student attitude inventories , holistic scoring techniques , performance assessment tasks , open - ended questions , student reports using self - assessment data , mathematics portfolios , and math projects . Structured interview plans , student reports using self - assessment data , and holistic scoring techniques were given the most frequent " less sure " responses . Both structured interview plans and reports using self - assessment data are relatively recent assessment devices for student evaluation . Actually , they have been in use since the early 1970s but have become more popular in the 1990s . Holistic scoring has appeared in the literature frequently since the mid - 1980s , but apparently has not to the notice of most teachers in this study . That these terms are relatively " new " might explain the lower rating from the teachers . Mathematics portfolios received a mixed review from the 6 - 12 teachers but the K - 5 teachers marked portfolios as more familiar . This is understandable in light of the fact that the use of portfolios is more prevalent in the K - 5 schools . However , the descriptions that the K - 5 teachers used in item 01 of Part IV in listing what goes into a portfolio suggest that the teachers were confusing portfolios with student folders . Student folders are generally regarded as : a container of the students ' work , but the 126 responsibility of this evaluation process is a function of the teacher and not the student ; the work samples are a similar selection of materials from student to student ; and accountability is a primary function . A number of teachers , who claim to use them , have missed the intent of a portfolio . The K - 5 teachers demonstrated a clear advantage over the 6 - 12 groups . It would seem that the K - 5 teachers have more experience with a variety of assessment methodologies . The 9 - 12 group admittedly knew fewer methods than any other groups . Structured interview plans , holistic scoring techniques , student attitude inventories , and student reports using self - assessment data rated lowest in the individual scoring . Projects , portfolios , and performance tasks scored well . Part IV - A series of open - ended questions dealing with portfolios , projects , and performance tasks comprised this part of the survey . Teachers were asked to describe , outline , or list appropriate items for each . The K - 5 groups offered a wide array of examples and were consistent with the applications to portfolios , projects , and performance tasks . It was evident from the listings that the K - 5 teachers were comfortable with the terms , accurate with their approach , and knowledgeable in their practice . The 6 - 12 groups left nearly half of the questions blank , but the few teachers that gave excellent answers were knowledgeable about the forms of alternative assessment . 127 Item 01 on portfolios best characterizes the differences among the four groups of teachers for Part IV . The K - 2 teachers included the following popular choices for materials to be placed in the students ' portfolios ( the number of times the selection was listed by all teachers in each grade level group follows each choice ) : pattern and measurement samples ( 21 ) , selected tests / quizzes ( 15 ) ; computational samples ( 4 ) , journals ( 17 ) , projects ( 11 ) , surveys ( 7 ) , and explorations ( 5 ) . Portfolio samples for the 3 - 5 Group mentioned most often were : journals / logs ( 13 ) , projects ( 15 ) , tests / quizzes ( 11 ) , observations ( 6 ) , and problem solving ( 5 ) . The 6 - 8 Group most frequently chose : problem solving ( 6 ) , journals ( 6 ) , notes ( 6 ) , essays ( 4 ) , projects ( 12 ) , tests / quizzes ( 13 ) , and student work ( 6 ) . The 9 - 12 Group most frequently mentioned : problem solving ( 6 ) , journals ( 5 ) , projects ( 10 ) , tests / quizzes ( 22 ) , homework ( 10 ) , and concepts ( 4 ) . From the survey responses most teachers viewed the portfolio as their responsibility . The teacher had ownership . This approach does not allow for the creative use of portfolios . The student portfolio should , according to the literature , provide for : the students ' self - initiating problem solving activities ; sharing of responsibility ; the creation of materials that reveal interests , special talents , problem solving opportunities ; and a positive approach toward learning . These attributes were seldom indicated by the teachers . 128 Part V - The information requested in this part of the survey described what portion of the students ' grade , as a percentage , was determined by homework , quizzes , classwork , projects , portfolios , performance - based tasks , class participation , chapter tests , final exam , lab work , notebook , or other . As would be expected , the 6 - 12 groups were keyed to the traditional mode of assessment . The K - 5 groups listed a wide variety of assessment methods and their selections were consistent with the answers to the questions in Part III on portfolios , projects , and performance tasks . It appears that some of the K - 5 teachers in this study understand and may practice alternative assessment , but most K - 5 teachers rely on classwork , class participation , and projects . The K - 5 teachers had a more varied selection , whereas tests , quizzes , and exams were the choice for the 6 - 12 groups . Nearly all of the " other " choices were from the K - 5 groups that included : journals , cooperative settings , work choice , free time , partner work , " hands on " activities , prior knowledge , anecdotal records , math folder , checklist of observable math behavior , group work , extensions , explorations , and observations . Math journals were mentioned frequently and should have been included in the choices of selection . It should be noted that there was a definite transition of how grades were determined by the teachers . The K - 2 teachers were clustered around classwork , class participation , class projects , and performance tasks . This moved to classwork , 129 homework , and class participation for the 3 - 5 Group - - homework has replaced projects and performance tasks . The 6 - 12 Group chose homework , quizzes , classwork , and chapter tests - - quizzes and test replacing class participation as the more frequent choices . This changing evaluation process needs further research and study . Recommendations As the volume of information about the teachers ' awareness of alternative assessment practices increases , this information would direct alternative assessment techniques , strategies , and practices . Any data on teacher awareness of alternative assessment could provide a more accurate picture of current evaluation practices . This information could modify a course of study on assessment , develop objectives for an inservice or preservice program , or improve national standards on assessment . The kind of data gained from this survey adds credibility to the claim that teachers have awareness of alternative forms of assessment and that alternative assessment is in use in the schools . Two primary themes that should direct other surveys were realized from this study - - contextualization and critical thinking . Resnick stated that there was a key assumption of conventional test design that was false ( Wiggins , 1993 ) . That assumption was decontextualization ( i . e . , that if we know something , we know it 130 in any context ) . The theoretical model for this survey was contextualization which exemplifies the underlying philosophy for a learning model . This type of learning model provides the basis for authentic assessment . This fundamental component of contextualization must be the cohesive force for other descriptive surveys . The other theme was critical thinking as an inherent element in the cognitive modeling for alternative assessment . Researchers like Paul , Chaffee , Travis , Keeley , and Scriven have written compelling arguments that incorporate intellectual standards , teaching for critical thinking , assessing student thinking , and the use of critical thinking in shaping the mind for the 21st Century . These researchers believe that the assessment of thinking should use the same learning paradigm that is fundamental to alternative assessment and that future studies of research on the assessment of students needs to be guided by the same principles that use assessment - critical thought . Suggestions for Future Research The original statements that guided this study concerned teacher awareness of alternative assessment of students in mathematics . To a large extent , that set of statements have been investigated . As expected , there are significant differences between the teacher grade level groups regarding this awareness . There is a multitude of research projects that could add to the 131 information base for teacher awareness of alternative assessment and further investigate the differences between grade levels . Implications from this study would suggest that we hone in on areas of need . Exactly , what are the alternative assessment practices that are used most or least by grade level and the particular assessment practices that best fit the students ' needs for a given grade level . We need to look at the reasons why a particular alternative assessment practice has a higher success rate in promoting student understanding by grade level . A clearer picture of teachers ' strengths and weaknesses in awareness and practice of alternative assessment would guide curriculum development and inservice programs . Future research needs to be done on the investigation of a possible link between teacher awareness of alternative assessment practices and teacher attributes , such as : gender , number of years of teaching experience and number of years of teaching mathematics , number of students in the class ( es ) and number of students in the school , grade level taught , type of college degree , accessibility to the NCTM Standards , and college work in assessment . If a closer tie between a particular teacher attribute and superior assessment practices could be established , preservice and inservice programs should address those special needs . Teachers are concerned with assessment . We need to identify and categorize these concerns so solutions can be found . 132 The areas of investigation , as a direct result of this study , could include : the compilation of a complete set of educational and mathematics assessment standards - - the Assessment Standards from NCTM ( 1995 ) and National Standards ( 1996 ) ; the development of a more comprehensive survey instrument that would focus on the attributes for each teacher grade level ; the development of a scaling technique for rating surveys that incorporates the principles of measurement and evaluation standards ; the administration of the survey to a much larger random sample ; the expansion of research on classroom observation of alternative assessment in progress ; and the development of an in - depth interview process with teachers and students investigating attitudes toward alternative assessment . Other areas of investigation for alternative assessment issues are mentoring new teachers , developing National Standards of alternative assessment , and assessing critical thinking by authentic assessment . Mentoring new teachers in the use of alternative assessment techniques has been described as an effective method to best deal with difficult problems with students . According to recent research , alternative assessment methods are effective in dealing with problems that teachers encounter which includes : student motivation , students ' individual differences , student evaluation / assessment , monitoring student progress over time , and coping with change . If preservice teachers are shown an effective way of dealing with real 133 problems , then a reliable informational base in alternative assessment is justifiable . The creation of national standards for student performance appears to be a goal of the current educational reform movement . These standards will contain recommendations for student assessment . It would be in the best interest of the student that the standards on assessment are effective and research based . NCTM ' s Assessment Standards for School Mathematics ( Draft , 1993 ) would be an excellent source for a project to develop national assessment standards . Paul ( 1992 ) offers a thorough taxonomy for intellectual assessment that involves all subject disciplines . He provides a complete set of criteria for assessment that parallels the principles of alternative assessment . If the research on the assessment of critical thinking is as meaningful as he and other proponents predict , future studies should include an investigation of alternative assessment in critical thinking . Appendix A Pilot Instruments : OSU Survey ( A ) and ( B ) 134 135 OSU SURVEY ( A ) ASSESSMENT SURVEY The purpose of the survey is to investigate the teachers ' awareness in educational assessment of students in mathematics . There are 5 items that relate to each of 7 national assessment standards . An attempt was made to key all 35 items to the NCTM Evaluation & Professional Standards and popular texts on measurement & evaluation . For each item , please grade all responses A , B , C , and D using the scale : 4 , 3 , 2 , 1 ( i . e . , 4 - best answer , 3 - next best , 2 - not likely , 1 - least likely ) . 1 : Standard 1 : Teachers should be skilled in c h o o s in g assessm ent methods for instructional decisions . 01 What is the most important consideration in selecting a method of assessing a student ' s mathematical knowledge ? A . The assessment should identify student excellence . B . The method should be an integral part of instruction . C . It should be consistent with the school philosophy . D . Any assessment should involve some type of reward . 0 2 Multiple sources of information are necessary in choosing mathematical tasks that - - A . identify what students do not know . B . allow for a wide variety of tests , if only testing is used . C . present the same mathematical concept in different ways . D . focus on a specific set of mathematical skills . 0 3 When can a variety of assessment methods be used ? A . in a whole - class setting . B . in small groups . C . individually . D . all of the above . 04 An essay question - A . is a reasonable selection as a method of assessment . B . is a good selection for a language / arts class , not math . C . takes too much time to grade . D . works best as an enrichment activity . 05 Mathematics assessment methods should not be selected on the basis of the - - A . type of information sought . B . use to which the information will be put . C . determination of what the students do not know . D . development level and maturity of the student . 137 Standard 2 : Teachers should be skilled in developing assessment methods for instructional decisions . 06 What is the best source of information to determine the validity of a math test that the teacher designed ? A . ask students if the test is fair . B . give the test to several classes and compare results . C . ask the principal . D . ask other teachers to judge the test . 07 Reliability is likely to increase on a multiple - choice math test by : A . adding an essay question . B . adding more questions to the test . C . reducing the number of questions on the test . D . administering the test to many other classes . 08 Teachers should formulate a test plan or " blueprint " before writing out a test in mathematics . A . Statement is definitely TRUE . B . Statement is probably TRUE . C . Statement is probably FALSE . D . Statement is definitely FALSE . 0 9 Developing methods to assess higher - order thinking in mathematics - A . is a goal of competency - based education . B . requires a focus on accountability . C . insures a rank - ordering of students . D . none of the above . 1 0 An assessment format should match the instructional format implies : A . Students should be able to use calculators on the test . B . Students should be tested in cooperative groups , if they work in cooperative groups C . If teachers use standardized tests , then teachers should teach from the tests . D . Students should be evaluated using a variety of techniques . 138 Standard 3 : The teachers should be skilled in scoring and interpreting the results of both externally - produced and teacher - produced assessment methods . 11 What does a student ' s score of 75 % on a test indicate ? A . That 25 % of the class did better on the test . B . The student understands 75 % of the material covered . C . That 75 % of the items were answered correctly . D . The student earns about a " C " grade . 1 2 Calculators , computers , and manipulatives are not appropriate for the assessment process . A . Statement is definitely TRUE . B . Statement is probably TRUE . C . Statement is probably FALSE . D . Statement is definitely FALSE . 1 3 A stanine of ( 8 ) indicates - - A . above average . B . average . C . below average . D . none of the above . 1 4 A student problem solving profile could use a simple scoring scheme of : 4 - Excellent , 3 - Good , 2 - Average , 1 - Poor , 0 - Nothing . A . No , not appropriate for a math exercise . B . No , works best in observable setting . C . Yes , works with many assessment activities . D . Yes , but only applies to lower - order thinking skills . 1 5 A grade - equivalent score of 6 . 3 refers to - - A . sixth grade , third month . B . 6 . 3 years . C . six years , three months . D . 6 . 3 grades . 139 Standard 4 : Teachers should be skilled in using assessment results when making decisions about individual students , planning teaching , developing curriculum , and school improvement . 16 Assessment techniques such as students ' self - inventories , self - reports , interviews , and observation of others do not " fit " into mathematical assessment . A . Statement is definitely TRUE . B . Statement is probably TRUE . C . Statement is probably FALSE . D . Statement is definitely FALSE . 17 Assessing students ' mathematical disposition suggests : A . looking at the ways students approach tasks . B . checking student confidence and willingness to explore . C . monitoring students ' appreciation of the value of math . D . all of the above . 1 8 National studies show that teachers spend about what percent of their time on assessment activities ? A . more than 75 % . B . between 50 % and 75 % . C . between 25 % and 50 % . D . less than 25 % . 1 9 The assessment of students ' ability to communicate mathematics should avoid : A . the use of computers and calculators . B . having students write about mathematics . C . letting students discuss mathematical ideas D . none of the above . 20 Formative - summative evaluation is best described by : A . Informal - formal B . process - product C . higher - order - lower - order D . simple - complex 140 Standard 5 : Teachers should be skilled in developing valid grading procedures which use pupil assessments . 21 Mathematical evaluation is not synonymous with grading . A . False , all grading is a form of evaluation . B . True , evaluation data should be a necessary condition to assigning grades . _ _ C . False , evaluation implies grading and vice versa . D . True , assigning grades is a necessary condition for the evaluation of data . 22 Analytic scoring : A . produces one single score . B . is an ambiguous term . C . is a scoring technique that correlates test reliability with content validity . D . produces several scores . 23 Holistic scoring : A . produces one single score . B . is an ambiguous term . C . is a scoring technique that correlates test reliability with content validity . D . produces several scores . 24 Assessment scoring . A . produces one single score . B . is an ambiguous term . C . is a scoring technique that correlates test reliability with content validity . D . produces several scores . 25 The proposed National Examination System is likely to use - A . performance - based tests . B . multiple - choice tests . C . competency - based tests . D . true - false tests . 141 Standard 6 : Teachers should be skilled in communicating assessment results to students , parents , other lay audiences , and other educators . 26 Norm - referencing describes student test performance - A . as it relates to carefully defined content . B . relative to other students , in a group . C . compared to items drawn from predetermined text material . D . in terms of specific learning objectives . 27 Criterion - referencing describes student test performance - A . by reflecting on the score of a student compared to others . B . as compared to an appropriate reference sample of students . C . in terms of specific learning objectives . D . relative to other students in the group . 28 The consensus among mathematics educators that standardized achievement testing emphasizes students ' lower - order thinking suggests : A . That this type of testing should be encouraged in the primary grades only . B . Higher - order thinking requires a different assessment . C . Both A & B . D . Neither A nor B . 29 When are math test scores reliable ? A . After the students " learn " the material . B . If a student retakes the same test and has similar results . C . Only if the test was valid . D . When the scores correlate well with other test scores in other subjects . 3 0 The mathematics curriculum Standards emphasize problem solving , reasoning , communication , and making mathematical connections . Which statement is true ? A . Problem solving is limited to " word problems " only . B . Mathematical reasoning involves making conjectures , gathering evidence , and building an argument . C . Mathematical communication does not include writing . D . Mathematical connections implies how numbers connect . 142 Standard 7 : Teachers should be skilled in recognizing unethical and otherwise inappropriate assessm ent methods and uses of assessment inform ation . 31 Student - constructed math tests : A . are impractical . B . offer a reasonable assessment alternative . C . relieves the teacher of responsibility . D . presents a difficult ethical question . 32 In teaching mathematics , teachers do not need to be concerned with gender , race , or ethnicity . A . Statement is definitely TRUE . B . Statement is probably TRUE . C . Statement is probably FALSE . D . Statement is definitely FALSE . 3 3 Who is responsible to assess student knowledge in mathematics ? _ _ A . parents & student . B . student & teacher . C . teacher . D . student . 34 Test bias is best characterized by : A . unfair comparisons . B . differences between groups . C . opinions against groups . D . unjust toward minorities . 3 5 Alternative assessment ( e . g . , math journals , projects , portfolios ) should not : A . allow for individual growth . B . rank - order students . C . monitor learning over time . D . recognize a range of learning styles . 143 OSU SURVEY ( B ) ASSESSMENT SURVEY The purpose of the survey is to investigate the teachers ' awareness in educational assessment of students in mathematics . There are 7 items that relate to each of the 7 national assessment standards from the NCME Standards for Educational Assessment of Students . An attempt was made to key all items to the NCTM Evaluation & Professional Standards and popular texts on measurement & evaluation . 144 Standard 1 : Teachers should be skilled in choosing assessment methods appropriate for instructional decisions . 01 PLEASE LIST THE WAYS THAT YOU EVALUATE STUDENTS IN MATHEMATICS : Standard 2 : Teachers should be skilled in developing assessment methods appropriate for instructional decisions . 0 2 WHICH OF THESE MATHEMATICAL EVALUATION METHODS DID YOU DEVELOP ON YOUR OWN ? HOW ? Standard 3 : The teachers should be skilled in administering , scoring , and interpreting the results of both externally - produced and teacher - produced assessment methods . 0 3 HOW DO YOU RECORD AND REPORT STUDENT PROGRESS IN MATHEMATICS ? 145 Standard 4 : Teachers should be skilled in using assessment results when making decisions about individual students , planning teaching , developing curriculum , and school improvement . 0 4 WHAT DO YOU DO WITH EVALUATION RESULTS ? Standard 5 : Teachers should be skilled in developing valid pupil grading procedures which use pupil assessm ents . 0 5 WHAT CONSTITUTES VALID GRADING PROCEDURES ? Standard 6 : Teachers should be skilled in communicating assessment results to students , parents , other lay audiences , and other educators . 0 6 HOW DO YOU COMMUNICATE STUDENT PROGRESS TO STUDENTS ? PARENTS ? ADMINISTRATORS ? 146 Standard 7 : Teachers should be skilled in recognizing unethical , illegal , and otherwise inappropriate assessment methods and uses of assessment information . 0 7 WHAT METHODS OF EVALUATION ARE INAPPROPRIATE OR UNETHICAL ? Appendix B Survey Instrument and Interview Outline 147 148 Dear Participant , I need your assistance to collect information on assessment practices by filling out the following survey . The assessment survey is designed to investigate teachers ' evaluation of students in mathematics . This survey will provide data to be used in a qualitative study of teachers - kindergarten through twelfth grade . A critical issue that will shape the way we evaluate students ' performance , to meet the demands of national assessment standards , is alternative assessment . Few educational movements have caught the attention of educators as quickly and as forcefully as alternative assessment , as a more direct measure of student performance . This movement has been defined as , " everything that a multiple - choice test is not . " Arguably , the most important factor in the assessment equation is the teacher . If more was known about the teachers ' awareness of alternative assessment , this information would help initiate , design , and direct alternative assessment techniques , strategies , and practices . The data on teacher awareness of alternative assessment could provide a clearer picture of current evaluation methodology . This information could be used to : modify a course of study on assessment , develop objectives for an inservice or preservice program , or improve national standards on assessment . I would appreciate a few minutes of your time to complete the five - part questionnaire . Your responses are totally anonymous and there is no right or wrong . Please be as candid as possible . The results will be used in my dissertation , as a requirement for an advanced degree in Mathematics Education at The Ohio State University . Thanks again for your participation . Sincerely , John Drury ASSESSMENT SURVEY 149 The purpose of this survey is to investigate teachers ' educational assessment of students in mathematics . General Information : 1 . Sex : female _ _ _ _ m ale _ _ _ 2 . Number of years teaching experience : _ _ 3 . Number of years teaching mathematics : _ _ 4 . Circle the grade level ( s ) you taught during 1992 - 1993 . K 1 2 3 4 5 6 7 8 9 10 11 12 5 . College degree : ( circle one ) BA BA + MA MA + PhD . BS BS + MS MS + PhD . + 6 . How many students attend your school ? _ _ _ _ _ 7 . Number of students in class ( or class average ) : _ _ _ _ _ _ _ _ _ 8 . Do you have access to a copy of the National Council of Teachers of Mathematics Evaluation Standards : ( circle one ) yes no 9 . Have you ever seen a copy of standards for evaluation , assessment , measurement , or testing ? ( circle one ) yes no 10 . How much college course work in evaluation , assessment , measurement , or testing have you taken ? ( circle one ) A . None at all B . Part of one or more courses C . One course D . 2 or more courses Please complete the following five - part questionnaire . 150 PART I Indicate the level of importance to your assessment practices for the following purposes of evaluation : ( not important ) 1 2 3 4 5 ( very important ) 01 Find out what students do not know 02 Provide students with feedback 0 3 Check students ' ability to reason 04 Satisfy an administrative directive 05 Verify students ' computational skills 0 6 To keep students on task 0 7 Monitor student progress over time 08 Compare student performance to others 0 9 Help students organize their thinking 1 0 Identify students ' misconceptions 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 151 PART II Please choose the best answer : 01 Alternative assessment is best characterized by : A . informal testing . B . projects and portfolios . C . higher order thinking skills . D . cooperative learning . 02 A mathematics essay question - - A . is a reasonable selection for assessment . B . is a good selection for a language / arts class , not math . C . takes too much time to grade . D . works best as an enrichment activity . 03 Assessing students ' mathematical disposition suggests : A . looking at the ways students approach tasks . B . checking student confidence and willingness to explore . C . monitoring students ' appreciation of the value of math . D . all of the above . 04 Calculators , computers , and manipulatives are appropriate for the assessment process . A . Statement is definitely TRUE . B . Statement is probably TRUE . C . Statement is probably FALSE . D . Statement is definitely FALSE . 0 5 The assessment of student knowledge in mathematics is the responsibility of the : a ) teacher ; b ) student . A . ( a ) only . B . ( b ) only . - C . ( a ) & ( b ) . D . Neither ( a ) nor ( b ) . PART II Please choose the best answer : 06 Multiple sources of information are necessary in choosing mathematical tasks that - - A . identify what students do not know . B . allow for a wide variety of tests . C . present the same math concept in different ways . D . focus on a specific set of mathematical skills . 07 Holistic scoring : A . produces several scores . B . is an ambiguous term . C . correlates test reliability with content validity . D . produces one single score . 08 Performance - based tasks emphasize - - A . Accountability . B . Accuracy . C . A uthenticity . D . Analysis . 09 Alternative assessment should not : A . allow for individual growth . B . rank - order students . C . monitor learning over time . D . recognize a range of learning styles . 1 0 The assessment of students ' ability to communicate mathematics should include : 1 ) the use of computers and calculators ; 2 ) writing about mathematics ; 3 ) letting students discuss mathematical ideas . A . ( 1 ) & ( 2 ) . B . ( 3 ) only . C . none of the above . D . all of the above . 153 PART III Indicate your level of understanding for the following methods of assessment : ( not sure ) 1 2 3 4 5 ( very familiar ) 01 Recorded informal observations 02 Structured interview plan 0 3 Math journals 04 Student attitude inventories 05 Holistic scoring techniques 0 6 Performance assessment tasks 07 Open - ended questions 08 Reports using self - assessment data 0 9 Mathematics portfolios 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 2 3 4 5 1 0 Math projects 1 2 3 4 5 154 PART IV In the space provided , list your answers to the following questions . 01 What " stuff " could be included in a math portfolio . 0 2 Name three mathematical projects appropriate for your students . 1 ) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 2 ) 0 3 Briefly outline a mathematical performance task . 155 PART V About what percent of each of the following do you use in determining the grade for each student at the end of the grading period ? _ _ _ _ _ % Homework % Quizzes % Classwork % Class participation % . Class projects % . Chapter tests % Final exam % Performance tasks % Lab work % P ortfolios % . Notebook % Other - describe : _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 100 % The Interview Outline 156 A . Student Evaluation : 01 What is your view of alternative assessment ? 0 2 How do your students ' view alternative assessment ? B . Teacher Evaluation : 01 Do you evaluate yourself ? How ? 02 Is self - evaluation helpful ? How ? C . Program Evaluation : 01 Does your current mathematics curriculum support the alternative assessment approach ? 02 Explain . Appendix C Assessment Survey Data and Comments 1 5 7 K - 2 Teacher Score for Each Survey Part 158 K - 2 Teacher Part : 1 2 3 4 5 Total 01 3 2 2 3 1 1 1 02 1 1 1 2 1 6 03 1 1 3 2 1 8 04 2 3 2 2 1 1 0 05 2 3 1 2 1 9 06 2 1 1 1 1 6 07 2 3 2 1 1 9 08 2 1 1 1 2 7 09 1 3 2 1 2 9 1 0 1 1 2 1 2 7 1 1 1 1 2 2 2 8 1 2 2 3 2 2 2 1 1 1 3 1 2 1 3 2 9 1 4 1 3 1 3 2 1 0 1 5 3 2 2 3 2 1 2 1 6 2 2 2 3 2 1 1 1 7 1 2 2 3 2 1 0 1 8 2 3 2 3 2 1 2 1 9 1 3 3 3 2 1 2 20 1 3 3 3 2 1 2 21 2 3 3 2 3 1 3 22 2 3 1 3 3 1 2 23 1 3 2 3 3 1 2 24 3 3 2 3 3 1 4 25 2 3 3 3 3 1 4 26 1 2 2 3 3 1 1 27 3 3 3 3 3 1 5 28 2 3 3 2 3 1 3 29 2 1 1 2 3 9 3 - 5 Teacher Score for Each Survey Part 159 3 - 5 Teacher Part : 1 2 3 4 5 Total 01 2 1 2 2 1 8 02 1 1 3 2 1 8 03 2 2 1 3 2 10 04 2 1 3 3 2 1 1 05 3 3 2 3 2 13 06 2 3 1 3 1 10 07 1 3 2 3 1 1 0 08 2 3 2 3 1 1 1 09 2 1 3 3 1 1 0 10 3 2 3 3 1 1 2 1 1 1 3 3 3 1 1 1 12 1 2 1 1 1 6 1 3 2 1 1 2 1 7 14 3 3 3 3 3 15 1 5 2 2 3 3 2 1 2 1 6 2 2 2 1 1 8 17 1 2 1 3 2 9 1 8 1 2 1 3 2 9 19 1 2 1 3 2 9 20 1 1 1 3 2 8 21 2 3 2 2 2 1 1 22 1 1 1 2 2 7 23 3 1 2 1 2 9 24 1 1 2 1 2 7 25 3 3 3 3 3 15 26 2 3 3 3 3 14 27 3 3 3 2 3 1 4 28 1 3 3 2 3 1 2 29 1 3 3 3 3 1 3 6 - 8 Teacher Score for Each Survey Part 160 6 - 8 Teacher Part : 1 2 3 4 5 Total 01 1 1 2 1 1 6 02 2 2 1 3 1 9 03 1 1 1 1 1 5 04 1 1 1 1 1 5 05 2 1 3 1 1 8 06 1 1 1 1 1 5 07 1 1 1 1 1 5 08 2 1 1 1 1 6 09 2 1 1 1 1 6 1 0 1 1 1 1 1 5 1 1 2 2 2 1 1 8 12 1 2 2 1 1 7 1 3 1 1 1 2 1 6 14 2 1 1 2 1 7 1 5 3 1 1 2 1 8 16 1 1 2 2 1 7 1 7 2 2 2 2 1 9 18 3 2 3 2 1 1 1 1 9 2 2 2 3 1 1 0 20 3 2 3 3 1 12 21 2 3 3 3 1 1 2 22 2 3 3 3 1 1 2 23 1 3 3 2 2 1 1 24 1 1 1 2 2 7 25 1 1 1 2 2 7 26 2 1 1 2 2 8 27 1 1 1 2 2 7 28 1 2 1 1 2 7 29 2 3 1 3 2 1 1 30 3 3 3 3 2 1 4 31 1 2 3 1 3 1 0 32 2 2 2 2 3 1 1 33 2 3 3 3 3 1 4 34 2 1 1 3 3 1 0 9 - 12 Teacher Score for Each Survey Part 161 Teacher Part : 1 2 3 4 5 Tot 01 2 3 1 1 1 8 02 3 1 1 1 1 7 03 2 2 2 1 1 8 04 2 1 1 2 9 05 2 3 1 1 1 8 06 3 2 1 3 1 1 0 07 2 2 3 3 1 2 08 2 2 1 1 1 7 09 1 1 3 1 1 7 10 2 2 2 1 1 8 1 1 3 3 1 1 1 9 1 2 3 3 1 1 1 9 13 1 2 1 1 1 6 14 2 2 1 1 1 7 1 5 1 1 1 1 1 5 16 2 1 1 2 1 7 1 7 2 3 1 2 1 9 1 8 2 3 1 2 1 9 1 9 1 2 2 2 1 8 20 1 3 2 2 1 9 21 3 3 2 2 1 1 1 22 1 1 3 2 1 8 23 1 2 1 3 1 8 24 2 3 1 3 1 1 0 25 2 2 2 3 1 1 0 26 3 3 2 3 1 1 2 27 2 3 2 3 1 1 1 28 3 3 2 1 2 1 1 29 2 1 1 1 2 7 30 2 1 2 2 2 9 31 1 3 2 2 2 1 0 32 2 1 2 3 2 1 0 33 1 1 1 1 3 7 34 3 3 3 3 3 1 5 162 Written Teacher Comments from the Assessment Survey K - 2 ( 05 ) " To keep students on task - - Engaged ? " Part IV K - 2 ( 06 ) Tam not familiar enough with ' math projects ' to answer this question . " P - IV K - 2 ( 07 ) " have to think about this . " P - IV K - 2 ( 08 ) " Not really accurate for kindergarten . " P - V K - 2 ( 10 ) " I ' am not sure I understand this question ? " P - ll K - 2 ( 12 ) " unsure of this request . " P - IV K - 2 ( 19 ) " + inservices on alternative assessment . " G - l " I do not really understand these questions - - ! use assessment whether I like it or not . " P - l " Grade for prior knowledge . " P - V K - 2 ( 20 ) " I really don ' t know what this is . " P - IV K - 2 ( 23 ) " Find out what students do know . " P - l " Observations and anecdotal records . " P - V K - 2 ( 27 ) " + Journals . " P - V 3 - 5 ( 04 ) " I like the idea but too time consuming w / writing portfolios and reading portfolios . " P - V 3 - 5 ( 05 ) " The most powerful form of assessment for me is day - to - day observation . " P - V 3 - 5 ( 08 ) " I do not determine grades . " P - V 3 - 5 ( 16 ) 3 - 5 ( 19 ) 3 - 5 ( 20 ) 3 - 5 ( 23 ) 3 - 5 ( 26 ) 3 - 5 ( 28 ) 6 - 8 ( 06 ) 6 - 8 ( 17 ) 6 - 8 ( 18 ) 9 - 12 ( 07 ) 9 - 12 ( 08 ) 9 - 12 ( 18 ) 163 " Not sure of question . " P - IV " I don ' t give actual grades . " P - V " I don ' t like alternative assessment - - my life is too full already . Math is much more quantitative and lends itself to standardized testing—Help ! " P - V " Not time to complete this task . " P - IV " I prefer to look at what kids do know and then go from there . " P - l " Due to our grading / assessment system , I don ' t think in % . Try to look at kid and progress made by her / him . " P - V " I / we don ' t really grade this way . We don ' t do ' scoring ' , but rather look at it on a continuum of sorts . " P - V " Projects are difficult in algebra . " P - V " I’am lost on this one . " P - IV " Why do it if it ' s not important . " P - V " This varies by quarter . " P - V " Different classes - different % ' s . " P - V " A bunch of jargon ! " P - IV " Attendance - it ' s a form of bribery . With 50 % of the classes abs . everyday in gen . 9th grade classes there is no continuity . " P - V BIBLIOGRAPHY Aiken , L . R . ( 1979 ) . Psychological testing and assessment . ( 3rd ed . ) . Boston : Allyn and Bacon . Andrews , T . E . , & Barnes , S . ( 1990 ) . Assessment in teaching . In W . R . Houston ( Ed . ) , Handbook of research on teacher education ( pp . 569 - 598 ) . New York : Macmillan . Ary , D . , Jacobs , L . C . , & Razavieh , A . ( 1990 ) . Introduction to research in education . ( 4th ed . ) . Montreal : Holt , Rinehart and Winston . Berlak , H . , Newmann , F . , Adams , E . , Archbald , D . , Burgess , T . , Raven , J . , Romberg , T . ( 1992 ) . Toward a new science of educational testing and assessment . Albany , NY : SUNY Press . Binet , A . ( 1975 ) . Modern ideas about children . ( S . Heisler , Trans . ) . San Francisco : Author . ( Original work published 1911 ) . Borg , W . R . , Worthen , B . R . , & Valcarce , R . W . ( 1986 ) . Teachers ' perception of the importance of educational measurement . Journal of Experimental Education , 55 ( 1 ) , 9 - 14 . Brandt , R . S . ( Ed . ) . ( 1992 ) . Readings from Educational Leadership : Performance assessment . Alexandria , VA : Association for Supervision and Curriculum Development . Brandt , R . S . ( Ed . ) . ( 1993 ) . Teaching for understanding [ Special issue ] . Educational Leadership , 51 ( 5 ) . Brown , S . , Cooney , T . , 8s Jones , D . ( 1990 ) . Mathematics teacher education . In W . R . Houston ( Ed . ) , Handbook of research on teacher education ( pp . 639 - 656 ) . New York : Macmillan . 164 165 California Mathematics Council . ( 1989 ) . Assessment alternatives in mathematics . Berkeley , CA : Author . Campione , J . & Brown , A . L . ( 1987 ) . Linking dynamic assessment with school achievement . In C . Lidz ( Ed . ) , Dynamic assessment : An interactional approach to evaluating learning potential . New York : Guilford Press . Campione , J . C . , Brown , A . L . , & Connell , M . L . ( 1989 ) . Metacognition : On the importance of understanding what you are doing . In R . Charles & E . Silver ( Eds . ) , The teaching and assessing of mathematical problem solving ( pp . 93 - 114 ) . Reston , VA : National Council of Teachers of Mathematics . Charles , R . I . & Silver , E . A . ( Eds . ) . ( 1989 ) . The teaching and assessing of mathematical problem solving . Reston , VA : National Council of Teachers of Mathematics . Charles , R . , Lester , F . , & O ' Daffer , P . ( 1992 ) . How to evaluate progress in problem solving . Reston , VA : National Council of Teachers of Mathematics . Clarke , D . J . , Clarke , D . M . , & Lovitt , C . J . ( 1990 ) . Changes in mathematics teaching call for assessment alternatives . In T . Cooney , & C . Hirsch ( Eds . ) , Teaching and learning mathematics in 1990s ( pp . 118 - 129 ) . Reston , VA : National Council of Teachers of Mathematics . Cobb , P . , Wood , T . , Yackel , E . , Nicholls , J . , Wheatley , G . , Trigatti , B . , & Perlwitz , M . ( 1991 ) . Assessment of a problem - centered second - grade mathematics project . Journal for Research in Mathematics Education , 22 ( 1 ) , 3 - 29 . Cooney , T . & Hirsch , C . ( Eds . ) . ( 1990 ) . Teaching and learning mathematics in 1990s . Reston , VA : National Council of Teachers of Mathematics . Cooney , T . ( 1992 ) . A survey of secondary teachers ' evaluation practices in Georgia . Athens , GA : University of Georgia . 166 Costa , A . L . ( 1989 ) . Re - assessing assessment . Educational Leadership , 46 ( 7 ) , 2 . Crosswhite , J . ( 1987 ) . Cognitive science and mathematics education : A mathematics educator ' s perspective . In A . Schoenfeld ( Ed . ) , Cognitive science and mathematics education ( pp . 265 - 278 ) . Hillsdale , NJ : Lawrence Erlbaum Associates . Ewell , P . T . ( 1991 ) . To capture the ineffable : New forms of assessment in higher education . In G . Grant ( Ed . ) , Review of research in education ( vol . 17 , pp . 75 - 125 ) . Washington , DC : American Educational Research Association . Farr , . R . , & Griffin , M . ( 1973 ) . Measurement gaps in teacher education . Journal of Research and Development in Education , 7 ( 1 ) , 19 - 28 . Fennema , E . , Carpenter , T . , & Lamon , S . ( 1991 ) . Integrating research on teaching and learning mathematics . Albany , NY : State University of New York Press . Fowler , F . J . ( 1990 ) . Survey Research Methods . Newbury Park : Sage Publications . Galluzzo , G . R . , & Craig , J . R . ( 1990 ) . Evaluation of preservice teacher education programs . In W . R . Houston ( Ed . ) , Handbook of research on teacher education ( pp . 569 - 598 ) . New York : Macmillan . Gardner , H . ( 1985a ) . The mind ' s new science . New York : Basic Books . Gardner , H . ( 1985b ) . Frames of mind : The theory of multiple intelligences . New York : Basic Books . Garofalo , J . , & Lester , F . K . ( 1985 ) . Metacognition , cognitive monitoring , and mathematical performance . Journal for Research in Mathematics Education , 16 , 163 - 176 . 167 Gay , L . R . ( 1987 ) . Educational research : Competencies for analysis and application . ( 3rd . ed . ) . Columbus : Merrill Publishing . Gifford , B . , & O’Connor , M . ( Eds . ) . ( 1992 ) . Changing assessments : Alternative views of aptitude , achievement and instruction . Norwell , MA : Kluwer Academic Publishers . Glasser , W . ( 1992 ) . The quality school : Managing students without coercion . ( 2nd . ed . ) . New York : HarperCollins . Goslin , D . ( 1967 ) . Teachers and testing . New York : Russell Sage Foundation . Grouws , D . A . ( Ed . ) . ( 1992 ) . Handbook of research on mathematics teaching and learning . New York : Macmillan . Gullickson , A . , ( 1985 ) . Student evaluation techniques and their relationship to grade and curriculum . Journal of Educational Research , 79 ( 2 ) , 96 - 100 . Gullickson , A . , ( 1986 ) . Teacher education and teacher - perceived needs in educational measurement and evaluation . Journal of Educational Measurement , 23 ( 4 ) , 347 - 354 . Haertel , E . H . ( 1991 ) . New forms of teacher assessment . In G . Grant ( Ed . ) , Review of research in education ( vol . 17 , pp . 3 - 29 ) . Washington , DC : American Educational Research Association . Herman , J . L . , Aschbacher , P . R . , & Winters , L . ( 1992 ) . A practical guide to alternative assessment . Alexandria , VA : Association for Supervision and Curriculum Develooment . Hiebert , J . & Carpenter , T . P . ( 1992 ) . Learning and teaching with understanding . In D . A . Grouws ( Ed . ) , Handbook of research on mathematics teaching and learning ( pp . 3 - 38 ) . New York : Macmillan . Higgins , J . L . , Kasten , M . , & Suydam , M . N . ( 1979 ) . Assessing mathematical achievement . Columbus , OH : ERIC . 168 Howe , R . , Blosser , P . , & Warren , C . ( 1990 ) . Trends and issues in education : Curriculum and instruction . Columbus , OH : ERIC . Jones , P . S . ( Ed . ) . ( 1970 ) . A history of mathematics education in the United States and Canada . Wash . DC : National Council of Teachers of Mathematics . Kamii , C . ( Ed . ) . ( 1990 ) . Achievement testing in the early grades : The games grown - ups play . Washington , DC : National Association for the Education of Young Children . Karier , C . J . ( 1972 ) . Testing for order and control in the corporate liberal state . Educational Theory , 22 , 159 - 180 . Kilpatrick , J . ( 1992 ) . A history of research in mathematics education . In D . A . Grouws ( Ed . ) , Handbook of research on mathematics teaching and learning ( pp . 3 - 38 ) . New York : Macmillan . Kulm , G . ( Ed . ) . ( 1991 ) . Assessing higher order thinking in mathematics . Washington , DC : American Association for the Advancement of Science . Lidz , C . ( Ed . ) . ( 1987 ) . Dynamic assessment : An interactional approach to evaluating learning potential . New York : Guilford Press . Lindquist , M . M . ( Ed . ) . ( 1989 ) . Results from the fourth mathematics assessment of the National Assessment of Educational Progress . Reston , VA : National Council of Teachers of Mathematics . Martinez , M . E . , & Lipson , J . I . ( 1989 ) . Assessment for learning . Educational Leadership 46 { 7 ) , 73 - 75 . Minium , E . W . ( 1978 ) . Statistical reasoning in psychology and education . ( 2nd ed . ) . New York : John Wiley & Sons . Mitchell , R . ( 1992 ) . Testing for learning : How new approaches to evaluation can improve American schools . New York : Macmillan . 169 Muir , S . , & Wells , C . ( 1983 ) . Informal evaluation . The Social Studies , 74 ( 1 ) , 95 - 98 . National Commission on Testing and Public Policy . ( 1990 ) . From gatekeeper to gateway : Transforming testing in America . Chestnut Hill , MA : Commission . National Council of Teachers of Mathematics . ( 1989 ) . Curriculum and evaluation standards for school mathematics . Reston , VA : Council . National Council of Teachers of Mathematics . ( 1991 ) . Professional standards for teaching mathematics . Reston , VA : Council . National Council of Teachers of Mathematics . ( 1993 ) . Assessment standards for school mathematics ( draft ) . Reston , VA : Council . National Council on Measurement in Education . ( 1990 ) . The development of standards for teacher competence in educational assessment of students . Lincoln , NE : Council . National Research Council ( Steen , L . ) . ( 1989 ) . Everybody counts : A report to the nation on the future of mathematics education . Washington , DC : National Academy Press . National Science Foundation . ( 1991 ) . Assessing student learning . Washington , DC : Author . Nesher , P . , & Kilpatrick , J . ( 1990 ) . Mathematics and cognition : A research synthesis by the International Group for the Psychology of Mathematics Education . Cambridge : Cambridge University Press . Newmann , F . , & Wehlage G . ( 1993 ) . Five standards of authentic instruction . Educational Leadership , 50 ( 7 ) , 8 - 12 . Nitko , A . J . ( 1983 ) . Educational tests and measurement an introduction . New York : Harcourt Brace Jovanovich . 170 Ohlsson , S . , Ernst , A . , & Rees , E . ( 1992 ) . The cognitive complexity of learning and doing arithmetic . Journal for Research in Mathematics Education , 23 ( 5 ) , 441 - 467 . O ' Neil , J . ( 1993 ) . Can national standards make a difference ? Educational Leadership , 50 ( 5 ) , 4 - 8 . Paul , R . ( 1992 ) . Critical thinking : What every person needs to survive in a rapidly changing world . Santa Rosa , CA : The Foundation for Critical Thinking . Payne , D . ( 1982 ) . Measurement in education . In H . Mitzel ( Ed . ) , Encyclopedia of educational research ( pp . 1182 - 1190 ) . New York : Macmillan . Perrone , V . ( Ed . ) . ( 1991 ) . Expanding student assessment Alexandria , VA : Association for Supervision and Curriculum Development . Peterson , P . ( 1988 ) . Teaching for higher - order thinking in mathematics : The challenge for the next decade . In D . Grouws , T . Cooney , & D . Jones ( Eds . ) , Perspectives on research on effective mathematics teaching ( pp . 2 - 26 ) . Reston , VA : National Council of Teachers of Mathematics . Porter , A . ( 1989 ) . A curriculum out of balance : The case of elementary school mathematics . Educational Researcher , 18 ( 5 ) , 9 - 15 . Resnick , L . B . , & Resnick , D . P . ( 1992 ) . Assessing the thinking curriculum : New tools for educational reform . In B . Gifford & M . O ' Connor ( Eds . ) , Changing assessments : Alternative views of aptitude , achievement and instruction ( pp . 37 - 75 ) . Norwell , MA : Kluwer Academic Publishers . Roeder , H . ( 1972 ) . Are today ' s teachers prepared to use tests ? Peabody Journal of Education , 49 ( 3 ) , 239 - 240 . Roeder , H . ( 1973 ) . Teacher education curricula - your final grade is F . Journal of Educational Measurement , 10 ( 2 ) , 141 - 143 . 171 Romberg , T . A . ( 1992a ) . Assessing mathematics competence and achievement . In H . Berlak , F . Newmann , E . Adams , D . Archbald , T . Burgess , J . Raven , T . Romberg , Toward a new science of educational testing and assessment ( pp . 23 - 52 ) . SUNY Press . Romberg , T . A . ( Ed . ) . ( 1992b ) . Mathematics assessment and evaluation : Imperatives for mathematics educators . Albany , NY : SUNY Press . Scheaffer , R . L . , Mendenhall , W . , & Ott , L . ( 1990 ) . Elementary survey sampling . ( 4th ed . ) . Boston : PWS - KENT Schoenfeld , A . ( Ed . ) . ( 1987 ) . Cognitive science and mathematics education . Hillsdale , NJ : Lawrence Erlbaum Associates . Schoenfeld , A . ( 1992 ) . What ' s in a model ? Issues in the use of simulation models to analyze student understanding : A reaction to Ohlsson , Ernst , and Rees . Journal for Research in Mathematics Education , 23 ( 5 ) , 468 - 473 . Shepard , L . ( 1989 ) . Why we need better assessment . Educational Leadership , 46 ( 7 ) , 4 - 9 . Siegel , H . ( 1990 ) . Educating reason : Rationality , critical thinking and education . London : Routledge . Siegel , S . ( 1956 ) . Nonparametric statistics for the bahavioral sciences . New York : McGraw - Hill Silver , E . A . , & Kilpatrick , J . ( 1989 ) . Testing mathematical problem solving . In R . l . Charles & E . A . Silver ( Eds . ) , The teaching and assessing of mathematical problem solving . Reston , VA : National Council of Teachers of Mathematics . Spring , J . ( 1990 ) . The American school 1642 - 1990 . ( 2nd ed . ) White Plains , NY : Longman . Stenmark , D . ( 1990 ) . Assessment alternatives in mathematics . Berkeley , CA : EQUALS Publications . 172 Stenmark , D . ( 1991 ) . Mathematics assessment : Myths , models , good questions , and practical suggestions . Reston , VA : National Council of Teachers of Mathematics . Stiggins , R . J . & Conklin , N . F . ( 1992 ) . In teachers ' hands : Investigating the practices of classroom assessment Albany , NY : SUNY Press . Stiggins , R . , Griswold , M . , & Wikelund , K . ( 1989 ) . Measuring thinking skills through classroom assessment . Journal of Educational Measurement 26 ( 3 ) , 247 - 260 . Thorndike , R . M . , Cunningham , G . K . , Thorndike , R . L . , & Hagen , E . P . ( 1991 ) . Measurement and evaluation in psychology and education . New York : Macmillan . Webb , N . & Briars , D . ( 1990 ) . The role of assessment in teaching and learning . In T . Cooney & C . Hirsch ( Eds . ) , Teaching and learning mathematics in 1990s ( pp . 108 - 117 ) . Reston , VA : National Council of Teachers of Mathematics . Webb , N . ( 1992 ) . Assessment of students ' knowledge of mathematics : Steps toward a theory . In D . A . Grouws ( Ed . ) , Handbook of research on mathematics teaching and learning ( pp . 661 - 683 ) . New York : Macmillan . Webb , N . ( 1993 ) . Assessment for the mathematics classroom . In N . Webb & A . Coxford ( Eds . ) , Assessment in the mathematics classroom ^ pp . 1 - 6 ) . Reston , VA : National Council of Teachers of Mathematics . Wiggins , G . ( 1989 ) . Teaching to the ( authentic ) test . Educational Leadership , 46 ( 7 ) , 41 - 47 . Wiggins , G . ( 1992 ) . Creating tests worth taking . Educational Leadership , 49 ( 8 ) , 26 - 33 . Wiggins , G . ( 1993 ) . Assessment : Authenticity , context , and validity . Phi Delta Kappan , 75 ( 3 ) , 200 - 214 . 173 Wise , S . L . , Lukin , L . E . , & Roos , L . L . ( 1991 ) . Teacher beliefs about training in testing and measurement . Journal of Teacher Education , 42 ( 1 ) , 37 - 42 . Wolf , D . P . ( 1989 ) . Portfolio assessment : Sampling student work . Educational Leadership , 46 ( 7 ) , 35 - 39 . Wolf , D . P . , Bixby , J . , Glenn , J . , & Gardner , H . ( 1991 ) . To use their minds well : Investigating new forms of student assessment . In G . Grant ( Ed . ) , Review of research in education ( vol . 17 , pp . 31 - 73 ) . Washington , DC : American Educational Research Association . Worthen , B . & Spandel , V . ( 1991 ) . Putting the standardized test debate in perspective . Educational Leadership , 48 ( 5 ) , 65 - 69 .