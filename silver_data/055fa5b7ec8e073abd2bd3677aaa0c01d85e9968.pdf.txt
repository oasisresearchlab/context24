A SYSTEMATIC REVIEW OF THE EMPIRICAL VALIDATION OF OBJECT - ORIENTED METRICS TOWARDS FAULT - PRONENESS PREDICTION BASSEY ISONG * and EKABUA OBETEN † Department of Computer Science , North - West University Private Bag X2046 , Mmabatho 2735 , South Africa * 24073008 @ nwu . ac . za † obeten . ekabua @ nwu . ac . za Received 14 July 2013 Revised 18 August 2013 Accepted 21 September 2013 Object - oriented ( OO ) approaches of software development promised better maintainable and reusable systems , but the complexity resulting from its features usually introduce some faults that are di±cult to detect or anticipate during software change process . Thus , the earlier they are detected , found and ¯xed , the lesser the maintenance costs . Several OO metrics have been proposed for assessing the quality of OO design and code and several empirical studies have been undertaken to validate the impact of OO metrics on fault proneness ( FP ) . The question now is which metrics are useful in measuring the FP of OO classes ? Consequently , we investigate the existing empirical validation of CK þ SLOC metrics based on their state of signi¯cance , vali - dation and usefulness . We used systematic literature review ( SLR ) methodology over a number of relevant article sources , and our results show the existence of 29 relevant empirical studies . Further analysis indicates that coupling , complexity and size measures have strong impact on FP of OO classes . Based on the results , we therefore conclude that these metrics can be used as good predictors for building quality fault models when that could assist in focusing resources on high risk components that are liable to cause system failures , when only CK þ SLOC metrics are used . Keywords : Metrics ; object - oriented ; fault proneness ; systematic review ; empirical ; validation . 1 . Introduction In the last decade , several software ¯rms have witnessed and incorporated object - oriented ( OO ) technology into their software development environments [ 1 , 2 ] . Presently , this technology has gained worldwide popularity in several small , medium and large software organizations leading to the growth of OO languages , OO methodologies , OO tools , OO metrics , and others [ 1 , 3 – 9 ] . OO paradigm approaches are believed to provide better maintainable and reusable systems . However , due to the complexity introduced by its features like encapsulation , inheritance , polymor - phism and dynamic binding , it is likely that they might introduce some types of International Journal of Software Engineering and Knowledge Engineering Vol . 23 , No . 10 ( 2013 ) 1513 – 1540 # . c World Scienti¯c Publishing Company DOI : 10 . 1142 / S0218194013500484 1513 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . faults that are di±cult to detect or even di±cult to identify the impact of changes . In the realm of project management , time , cost and scope are the three \ stalagmites " where quality is indispensable [ 5 ] . Defects during development are inevitable and the earlier they are found and ¯xed , the lesser it costs and the higher the quality of the products delivered [ 2 , 5 – 8 , 10 – 17 ] . Regrettably , due to the size and complexity of today ' s software applications , it becomes cumbersome to estimate or predict the quality [ 5 ] . Therefore , software metrics are indispensable . Software metrics are used to measure software processes , products , resources and allow engineers to quantitatively de¯ne their extent of success or failure [ 18 ] . They are used to evaluate the quality of software , used by organizations to take mean - ingful , useful managerial and technical decisions related to cost , e®ort , and time [ 1 , 18 – 20 ] . Thus , using metrics during development process is a viable step towards constructing quality systems . In the existing literature , many software metrics have been proposed and are broadly classi¯ed into traditional and OO metrics [ 18 , 19 , 21 , 22 ] . Moreover , several OO metrics have been proposed for assessing the quality of OO design and codes [ 1 , 3 , 19 , 20 , 23 – 26 ] , since the traditional product metrics are not suitable [ 1 ] . In particular , these metrics are used to capture di®erent OO software attributes , such as class complexity , inheritance hierarchy , the internal cohesion and the degree of coupling between di®erent classes [ 1 , 11 , 20 ] . Capturing the structural properties of software products is a giant step towards improving product quality and reducing cognitive complexity [ 11 , 27 ] . Software engineers usually achieved this by predicting the vital quality attributes such as FP ( fault proneness ) , productivity , maintainability , and others , during software devel - opment early stages via the building of predictive models using OO metrics and historical data [ 11 ] . The consequence is that identifying or predicting OO classes that are faulty early could help an organization in focusing quality improvement activities which in turn , can reduce future maintenance e®orts [ 11 , 27 , 28 ] . However , only few empirical studies exist that have validated and revalidated these metrics with respect to FP [ 2 – 4 , 6 , 7 , 19 , 27 , 29 – 33 ] . In addition , these studies proposed several prediction models where quality attributes and OO metrics are used as dependent and inde - pendent variables , respectively . A commonly used set of OO metrics is the one proposed by [ 1 ] , also known as CK metric suits . CK metrics display the measurable features of OO software , raised huge interest among researchers and engineers , and triggered many empirical studies that validated those metrics . However , with existing empirical evidences , results shown that most metrics are related to FP while others are not . Moreover , their ¯ndings seemed not to be consistent with other ¯ndings [ 7 ] . For instance , in one study a metric is considered to be having an in°uence on FP , while it is insigni¯cant in another study . This , however , a®ects decision making in selecting directly OO metrics which are related to class FP for evaluating the structural quality of the software . Therefore , our concern is which of these metrics are useful in measuring the essential external quality attributes like FP , e®ort and maintainability of OO software . In software engineering ¯eld , empirical study of real software systems is the only acceptable way . 1514 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . In order to establish generic OO design metrics that has impact on FP or main - tainability of OO classes , our aim in this paper is to perform a systematic literature review ( SLR ) of the existing and published empirical validation of CK þ SLOC metrics . The rationale behind this SLR is that we lack resources to carry out empirical studies on real world software systems . Secondly , only few SLR on this subject area exist in literature which lack recent evidences and other criteria aimed at validating CK þ SLOC metrics relationship with FP . This work considered empirical studies from the perspectives of their level of signi¯cance and insigni¯cance with FP , their state of validation , and their usefulness in terms of software quality . The objective is to help software engineers in making quick decision as to which metrics are generic in class fault and maintainability prediction when CK þ SLOC metrics are used . This paper is organized as follows : Introduction is in Sec . 1 and we brie°y describe the metrics used in this SLR in Sec . 2 . Section 3 is the research methodology used , while in Sec . 4 we explain executing and the results of this SLR . The results are analyzed by answering the research questions in Sec . 5 while the results are brie°y discussed in Sec . 6 . Lastly , Sec . 7 concluded the SLR . 2 . Metric under Study In this study , only studies that empirically validated the CK metric suit will be considered . Recently , most empirical studies have validated one of the traditional metrics , SLOC as having huge impact on FP even stronger than some of the OO metrics [ 4 , 5 , 29 , 34 ] . Thus , we shall also consider studies that take SLOC and CK metrics into account in this study . Table 1 presents the CK and SLOC metrics that this study will be concerned with and their descriptions . In the table , there are six CK metrics and one size metric of the traditional product metric . Table 1 . Metrics studied [ 1 , 18 ] . Metric De¯nition CK : Weighted Methods per Class ( WMC ) A count of methods implemented within a given class . Coupling between Objects ( CBO ) CBO for a class is count of the number of other classes to which it is coupled and vice versa . Response for a Class ( RFC ) The count of methods implemented within a class plus the number of methods accessible to an object class due to inheritance . Lack of Cohesion ( LCOM ) For each data ¯eld in a class , the percentage of the methods in the class using that data ¯eld ; the percentages are averaged then subtracted from 100 percent . Depth of Inheritance ( DIT ) The length of the longest path from a given class to the root in the inheritance hierarchy . Number of Children ( NOC ) The NOC is the number of immediate subclasses of a class in a hierarchy . Size : Source Lines of Code ( SLOC ) It counts the lines of code ( nonblank and non - commented ) in the body of a given class and all its methods . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1515 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 3 . Research Methodology This study has been conducted by strictly following the guidelines for performing SLR given by Kitchenham et al . [ 35 , 36 ] . SLR provides the means to gather and analyze a collection of published research ¯ndings which assist in answering stated research questions . The results of our SLR will be useful in identifying the current state - of - the - art of empirical validation of OO and size metrics relationship to FP involving CK and SLOC metrics . The steps involve in this study are discussed in subsequent sections . 3 . 1 . Planning The planning stage of this SLR is described in this section . Discussions include the research questions to be answered , search strategy used , the databases used , the inclusion and exclusion criteria de¯ned , and the methodology used to obtain the results . 3 . 1 . 1 . Research questions In this work , we aim at providing a comprehensive account of published empirical evidences in order to identify which of the CK þ SLOC metrics have a strong in°uence on FP . Thus , the research questions we intend to answer are as follows : RQ 1 : Which metric ( s ) among CK metric suit and SLOC has impact on FP of a class ? RQ 2 : What techniques are being used to validate the metrics in RQ1 and which is the best ? RQ 3 : What extent have the metrics in RQ1 been validated ? RQ 4 : Of what relevance are the empirical validations ? RQ 5 : Are there generic metrics for predicting faulty classes ? 3 . 1 . 2 . Search strategy This study considers the review of 17 - year e®orts in empirical validation of CK þ SLOC metrics , between January 1995 to December 2012 . These periods were stra - tegically chosen with respect to the birth of CK metric suits and this research in particular , as well as to su±ciently explore the scope that surrounded this study . We documented all search results to enhance the clarity of the search process and avoid duplications . Accordingly , a search record was maintained as well as taking account of all studies ( selected and rejected ) . Strategies used in achieving the set objectives are discussed in the following sections . 1516 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 3 . 1 . 3 . Search terms The search terms / strings we used to obtain the needed information are listed in Table 3 . These search terms were formulated with the assistance of a librarian alongside our research skills . They were constructed by adhering to the steps sug - gested in [ 35 , 37 ] . The steps followed in constructing the search terms are shown in Table 2 above . The search terms were applied manually during the process and the use of generic terms were avoided . We did not include SLOC in the search terms because it was not used as part of the studies title . As shown above , Table 2 presents the steps involved in developing the search terms shown in Table 3 . The steps were basically designed for the search terms / strings that are capable of yielding results when used on the electronic databases considered in this research . 3 . 1 . 4 . Resource used The databases used in this study for searching the research articles are subsets of those largely recognized by researchers worldwide . The databases are presented in Table 4 . In this SLR , databases such as IEEE Xplorer , Springer Link and ACM were not searched directly since they were indexed or linked to the Engineering Village Table 3 . Search terms . Search term 1 Object - oriented metrics AND Faults 2 Object - oriented metrics AND faulty classes 3 OO metrics AND fault - proneness 4 CK metrics AND fault - proneness 5 Validation of OO metrics 6 Empirical Validation of OO metrics 7 OO classes fault - proneness 8 Fault - proneness of OO classes 9 Investigation of Fault - proneness AND OO metrics 10 Investigation of Fault - proneness OR OO metrics 11 OO metrics AND software fault 12 OO metrics AND software failure Table 2 . Search terms development step . Step 1 . Key terms are created by decomposing each research questions into individual facets such as results , context , comparison , and intervention . 2 . By identifying abbreviations and similar key search or alternative terms . 3 . Checking of keywords in articles . 4 . Using Boolean OR & AND to incorporate and link key search terms / strings with others respectively to obtain better search results . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1517 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . database ( Compendex and Inspec ) . Moreover , we excluded sources like Yahoo , Google and CiteseerX , etc . because they generated huge amount of inappropriate information . 3 . 2 . Study selection criteria and procedure Based on the de¯ned source selection , the review process aims to discover related and relevant studies to be used for data extraction . This is achieved by de¯ning basic and detailed inclusion and exclusion criteria in accordance with the research questions . We used the inclusion criterion to identify and select studies related to empirical validation of CK þ SLOC metrics , techniques used , programming language used , phases of SDLC applied to , method used for data collection , and the validation environments . Table 5 presents the inclusion and exclusion criteria used in this study . As shown in Table 5 , the inclusion criteria are those that enable us to select relevant articles that best suit the objective of this SLR , while the exclusion criteria are those that help us to make decisions quickly by rejecting articles that are not relevant to this study . Table 5 . Study selection criteria . Selection criteria Inclusion criteria 1 . Studies conducted in the past 17 years i . e . between 1995 and 2012 . 2 . The article is peer reviewed . 3 . The article exists in full text and cited the CK metrics suite paper . 4 . Articles discussing empirical validation of CK þ SLOC and other metrics in°uence on fault - proneness of OO classes . 5 . The article can be a cases study , systematic review , comparative study , literature review , or a survey published in a proceedings or journals . 6 . Articles written in English language . 7 . Articles explicitly states research methodology and results . 8 . Articles are a replicated study of the previous published empirical study . Exclusion criteria 1 . Article that does not match the inclusion criteria will be excluded . 2 . Article only related to SLOC or LOC and empirical study of other OO metric suits validation will be excluded . 3 . Article discussing only CK metrics will be excluded . Table 4 . Databases used . Database name Google Scholar Engineering Village ( Compendex , Inspec . ) Scopus 1518 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . Though systematic and literature review papers were collected , they were only used to ¯nd the original studies with respect to the detailed inclusion and exclusion criteria and also to assist in validating our ¯ndings . However , they were not in - cluded for any further analysis . We found several literature review and few sys - tematic review articles that assisted in answering RQ1 and RQ4 . The authors individually selected the studies by applying the inclusion and exclusion criteria . Every study included was subject to at least two iterations of checking . We applied the criteria to all the studies by ¯rst reading the titles , keywords , abstracts and conclusions . A study is included if it satis¯ed the study ' s inclusion criteria , oth - erwise is excluded . In general , studies are selected for inclusion on the basis of their abstracts , introductions , conclusions and source of publication by applying the basic inclusion and exclusion criteria . 3 . 3 . Quality assessments Quality in this context is a function of the presence of detailed and supporting information in the studies that assists in answering the research questions . The quality criteria listed in Table 6 were used alongside the inclusion and exclusion criteria to asses the quality of all included studies [ 35 , 37 ] . The evaluation aided us to fully understand the state of empirical validation of each included study . The se - lected research articles were assessed against a number of checklist questions and each question answered with Yes ( Y ) or No ( N ) . Accordingly , Table 7 presents the quality assessment of each selected article . In the above tables , Table 6 presents the quality questions that need to be answered in Table 7 in order to access the quality of each selected article . Table 7 presents the quality of all the articles selected where N represent NO which denotes that a question is not met by the paper , otherwise Y represent YES , if the question is met . Table 6 . Study quality criteria . Quality criteria 1 . Is a suitable objective of study and introduction of CK metric and fault - proneness provided ? 2 . Are the systems under study , the programming language , environments of study , and tools used clearly provided ? 3 . Does the study ' s research methodology clearly de¯ned and suitable for the study [ 36 ] ? 4 . Is the study design stated clearly and references properly utilized ? 5 . Does the methodology of the research aligned with the study design , the study design to research questions , and the research questions to conclusions [ 36 ] ? 6 . Were positive and negative ¯ndings of the study clearly reported and compared with related studies ? 7 . Does the study reported validity threats related to the study results ? 8 . Does the study report any limitations or recommendations based on results ? Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1519 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 3 . 4 . Data extraction The data extraction process aimed at consistently and accurately recording the information obtained from the studies to avoid duplication e®ect that can bring about potential threat to unbiased reporting of ¯ndings [ 35 ] . In this SLR , a data extraction form or template was designed and used for information extraction to help us answer the research questions ( see Table 8 ) . Accordingly , all incon - sistencies as well as di±culties found were resolved and the extracted data was checked at least twice by the authors . For duplicated publications , the most recent information was used for data extraction and synthesis . However , in this SLR , we decided to include replicated studies because it helped us to answer RQ3 . Table 7 . Quality of selected studies . Id 1 . Is introduction provided ? 2 . Is the prog . language stated ? 3 . Is the research method de¯ned ? 4 . Is the design of study stated ? 5 . Is the study design cohesive ? 6 . Are validity threat reported ? 7 . Are positive & negative ¯ndings reported ? 8 . Is there any limitations reported ? 1 Y Y Y Y Y N Y Y 2 Y Y Y Y Y Y Y N 3 Y Y Y N Y N Y Y 4 Y Y Y Y Y N Y N 5 Y Y Y Y Y N Y N 6 Y Y Y Y Y Y Y N 7 Y Y Y Y Y Y Y N 8 Y Y Y Y Y N Y N 9 Y Y Y Y Y N Y N 10 Y Y Y Y Y N Y N 11 Y Y Y Y Y N Y N 12 Y Y Y Y Y N Y N 13 Y Y Y N Y N Y N 14 Y Y Y Y Y N Y N 15 Y Y Y Y Y Y Y N 16 Y Y Y Y Y Y Y N 17 Y Y Y Y Y N Y N 18 Y Y Y Y Y Y Y N 19 Y Y Y Y Y Y Y N 20 Y Y Y Y Y Y Y N 21 Y Y Y N Y N Y N 22 Y Y Y N Y Y Y N 23 Y Y Y N Y N Y N 24 Y Y Y N Y N Y N 25 Y Y Y N Y N Y N 26 Y Y Y N Y Y Y N 27 Y Y Y N Y Y Y N 28 Y Y Y N Y Y Y N 29 Y Y Y Y Y N Y N * * N ¼ NO ; Y ¼ YES 1520 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 4 . Execution and Results The authors independently carry out the process involved in searching for articles that satis¯ed the de¯ned inclusion and exclusion criteria in the data extraction phase . The authors scanned the database by using the search terms / strings and the basic de¯ned inclusion and exclusion criterion of the articles found to select relevant articles . The data extraction forms were used and each author performed validation on the extracted data in order to accomplish inter - study consistency . All the infor - mation about the total number of results obtained ( selected and rejected articles ) from each database by using each search term were recorded in the search record for this SLR . After applying all search terms on the stated databases , we retrieved a total of 4683 articles . Table 8 . Data extraction form . No . Extraction ¯elds 1 Extract document information Title AuthorsPublisher Published in : i . Journal ii . Conference Year 2 Study objective 3 Study Type : i . Replicated ii . Non - Replicated 4 Environment : i . Academia ii . Non - Academia 5 Study Subject : i . Professionals Systems ii . Students Systems 6 Programming Language 7 Metrics Studied : 8 Statistical analysis technique 9 Variables : i . Dependent ii . Independent 10 Product Release : i . Pre - release ii . Post - release 11 Metric Collection Tool : i . Tool ii . Manual iii . N / A 12 Metric relationship with Fault Proneness : i . Signi¯cant ii . Insigni¯cant Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1521 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . With the 4683 studies , 2765 studies were excluded on the basis of title reading . Furthermore , the remaining 1918 articles ' title and abstract were read through the application of the inclusion and exclusion criteria and 182 articles emerged for in - clusion . This was possible because we spent almost a month searching for relevant articles . Lastly , the authors scanned and removed duplicate articles except replicated studies , resulting in 67 remaining studies . Through continuous application of the detailed criteria on the 67 studies , 29 studies emerged and 38 studies were discarded on the basis of exclusion criterion . In all , 29 relevant articles were found through the SLR . The entire process of the SLR is shown in Fig . 1 and the result found in each database is presented in Table 9 . Fig . 1 . Systematic literature review process . Table 9 . Results found per database . Source name Found studies Selected studies 1 Google Scholar 2689 66 2 Compendex / Inspec 1750 71 3 Scupus 244 45 Sum 4683 182 1522 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . In Table 9 , the ¯rst column shows the name of the applicable database used , column 2 shows the total studies found in that database while column 3 shows that the total number of relevant articles selected from the ones found during the review process shown in Fig . 1 . In addition , based on the study ' s selected sources , Table 10 presents the list of selected journal and conference papers including their year of publication , authors and title considered in this SLR . For the authors , we used only the ¯rst author ' s name due to space constraint . For more information , refer to the reference below . Of all the 29 articles selected , there are 5 articles from conference proceedings and 24 articles are from journals . Table 10 . Study of selected articles . Id Ref . Year Author Title 1 [ 11 ] 2001 Emam et al . The prediction of faulty classes using object - oriented design metrics 2 [ 27 ] 1998 Briand et al . A Comprehensive Empirical Validation of Design Measures for OO Systems 3 [ 28 ] 2001 Emam et al . The Confounding E®ect of Class Size on the Validity of OO Metrics 4 [ 4 ] 2002 Yu et al . Predicting FP using OO Metrics : An Industrial Case Study 5 [ 5 ] 2008 Zu et al . An Empirical Validation of Object - Oriented Design Metrics for Fault Prediction 6 [ 29 ] 2000 Briand et al . Exploring the relationships between design measures and soft - ware quality in OO systems 7 [ 30 ] 1996 Basili et al . A Validation of Object - Oriented Design Metrics as Quality Indicators 8 [ 34 ] 2005 Gyimothy et al . Empirical Validation of OO Metrics on Open Source Software for Fault Prediction 9 [ 31 ] 2007 Olague et al . Empirical Validation of Three Software Metrics Suites to Pre - dict FP of OO Classes Developed Using Highly Iterative or Agile Software Development Processes 10 [ 32 ] 2006 Zhou et al . Empirical Analysis of Object - Oriented Design Metrics for Pre - dicting High and Low Severity Faults 11 [ 38 ] 2010 Singh et al . Empirical validation of object - oriented metrics for predicting FP models 12 [ 6 ] 1999 Tang et al . An Empirical Study on Object - Oriented Metrics 13 [ 12 ] 2003 Succi et al . Practical assessment of the models for identi¯cation of defect - prone classes in OO commercial systems using design metrics 14 [ 7 ] 2003 Subramanyam et al . Empirical Analysis of CK Metrics for OO Design Complexity : Implications for Software Defects 15 [ 33 ] 2009 Aggarwal et al . Empirical Analysis for Investigating the E®ect of Object - Ori - ented Metrics on FP : A Replicated Case Study 16 [ 39 ] 2001 Briand et al . Replicated Case Studies for Investigating Quality Factors in OO Designs 17 [ 40 ] 2008 Olague et al . An empirical validation of OO class complexity metrics and their ability to predict error - prone classes in highly iterative , or agile , software : a case study 18 [ 13 ] 2010 Malhotra et al . Empirical validation of OO metrics for predicting FP at dif - ferent severity levels using support vector machines Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1523 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 5 . Analysis In this section , we are going to perform the analysis of our ¯ndings by answering the above research questions . 5 . 1 . CK + SLOC metric relationship with FP RQ1 : Which metric ( s ) among CK metric suit and SLOC has an impact on FP of a class ? In this SLR , 29 studies which are related to empirical validation of the CK þ SLOC metrics were found . In these studies , 7 metrics ( i . e . 6 CK metrics and 1 \ traditional " metric ) were empirically validated against their in°uence on OO class FP . Analysis shows that some metrics appears to be signi¯cant , some strongly signi¯cant , some insigni¯cant , while some are negatively signi¯cant across the studies . Moreover , some studies categorized their signi¯cance and insigni¯cance based on the severity of the fault found such as high , medium , low and ungraded [ 10 , 18 , 24 ] . However , this SLR made no distinction between positive or negative signi¯cance , and signi¯cance based on fault severity . Thus , 29 empirical studies result are presented . In all the 29 studies , the relationship between CK þ SLOC metrics and the FP of a class were validated . Analysis presented in Table 11 shows that some metrics were found to be signi¯cant in some studies , some insigni¯cant , while others were not measured at all . We present the analysis of this ¯nding as follows : Complexity measure : For WMC , 21 studies con¯rmed its impact on FP of OO classes . The validation based on the hypothesis constructed con¯rms that classes Table 10 . ( Continued ) Id Ref . Year Author Title 19 [ 41 ] 2012 S . Singh et al . Validating the E®ectiveness of OO Metrics over Multiple Releases for Predicting FP 20 [ 14 ] 2008 Shatnawi et al . The e®ectiveness of software metrics in identifying error - prone classes in post - release software evolution process 21 [ 8 ] 2005 Janes et al . Identi¯cation of defect - prone classes in telecommunication software systems using design metrics 22 [ 42 ] 2009 English et al . Fault Detection and Prediction in an Open - Source Software Project 23 [ 43 ] 2008 Goel et al . Empirical Investigation of Metrics for Fault Prediction on OO Software 24 [ 44 ] 2011 Shaik et al . Investigate the Result of Object Oriented Design Software Metrics on FP in Object Oriented Systems : A Case Study 25 [ 46 ] 2011 Dallal , J . A . Transitive - based object - oriented lack - of - cohesion metric 26 [ 9 ] 2010 Dallal et al . An object - oriented high - level design - based class cohesion metric 27 [ 46 ] 2010 Zhou et al . On the ability of complexity metrics to predict fault - prone classes in Object - Oriented systems 28 [ 47 ] 2007 Pai et al . Empirical Analysis of Software Fault Content and FP Using Bayesian Methods 29 [ 48 ] 2012 Johari et al . Validation of OO Metrics Using Open Source Software System : An Empirical Study 1524 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . having more member functions or methods are more likely to have faults than classes with small or no member functions . However , only one study [ 7 ] found it to be insigni¯cant and 6 other studies did not measure it at all . Coupling measures : Analysis indicates that 23 of the studies found CBO having a strong in°uence on class FP . The signi¯cance is that a class which is highly coupled tends to be more fault - prone than a class that is loosely coupled . One study found CBO to be insigni¯cant and 5 of the studies did not measure it in their study . Accordingly , RFC was reported to have a strong signi¯cant relationship with class FP in 24 studies . This ¯ndings show that a class with higher response sets tends to be more fault - prone than others with less response sets . Interestingly , none of the studies that measured RFC found it to insigni¯cant while 5 of the studies did not measure RFC . Cohesion measure : In this SLR , analysis shows that 14 studies reported LCOM having signi¯cant impact on class FP . Accordingly , 4 studies found LCOM to be insigni¯cant while 11 studies did not measure it in their studies . The overall results con¯rmed that a class with low cohesion value is more likely to have faults than a class with high cohesion value . Inheritance measures : For class inheritance measures , only 9 studies reported that DIT has signi¯cant e®ects on class FP , though with strong and weak signi¯cance . In the same vein , 15 studies found it to be insigni¯cant while 5 studies did not measure Table 11 . Metrics validation . Metric Signi¯cant Insigni¯cant N / A WMC [ 11 ] , [ 28 ] , [ 4 ] , [ 5 ] , [ 29 ] , [ 30 ] , [ 34 ] , [ 7 ] [ 12 ] , [ 8 ] , [ 9 ] , [ 27 ] , [ 45 ] [ 31 ] , [ 32 ] , [ 38 ] , [ 6 ] , [ 7 ] , [ 33 ] , [ 39 ] , [ 13 ] , [ 41 ] , [ 14 ] , [ 43 ] , [ 44 ] , [ 47 ] , [ 48 ] CB0 [ 11 ] , [ 27 ] , [ 28 ] , [ 4 ] , [ 5 ] , [ 29 ] , [ 30 ] , [ 34 ] , [ 31 ] , [ 6 ] [ 12 ] , [ 40 ] , [ 45 ] , [ 9 ] , [ 46 ] [ 32 ] , [ 38 ] , [ 7 ] , [ 33 ] , [ 39 ] , [ 13 ] , [ 41 ] , [ 14 ] , [ 8 ] , [ 42 ] , [ 43 ] , [ 44 ] , [ 47 ] , [ 48 ] RFC [ 11 ] , [ 27 ] , [ 28 ] , [ 4 ] , [ 5 ] , [ 29 ] , [ 30 ] , [ 13 ] , (cid:1)(cid:1)(cid:1) [ 7 ] , [ 40 ] , [ 45 ] , [ 9 ] , [ 46 ] [ 31 ] , [ 32 ] , [ 38 ] , [ 6 ] , [ 12 ] , [ 33 ] , [ 39 ] , [ 34 ] , [ 41 ] , [ 14 ] , [ 8 ] , [ 42 ] , [ 43 ] , [ 44 ] , [ 47 ] , [ 48 ] LCOM [ 27 ] , [ 28 ] , [ 4 ] , [ 34 ] , [ 31 ] , [ 32 ] , [ 38 ] , [ 33 ] , [ 28 ] , [ 30 ] , [ 41 ] , [ 43 ] [ 11 ] , [ 5 ] , [ 29 ] , [ 6 ] , [ 12 ] , [ 7 ] , [ 39 ] , [ 13 ] , [ 8 ] , [ 44 ] , [ 45 ] , [ 9 ] , [ 48 ] [ 40 ] , [ 14 ] , [ 42 ] , [ 46 ] , [ 47 ] DIT [ 27 ] , [ 29 ] , [ 30 ] , [ 34 ] , [ 12 ] , [ 7 ] , [ 39 ] , [ 11 ] , [ 28 ] , [ 4 ] , [ 31 ] , [ 32 ] , [ 38 ] , [ 5 ] , [ 40 ] , [ 45 ] , [ 9 ] , [ 46 ] [ 8 ] , [ 48 ] [ 6 ] , [ 33 ] , [ 13 ] , [ 41 ] , [ 14 ] , [ 42 ] , [ 43 ] , [ 44 ] , [ 47 ] NOC [ 4 ] , [ 29 ] , [ 32 ] [ 27 ] , [ 34 ] , [ 31 ] , [ 32 ] , [ 38 ] , [ 33 ] , [ 11 ] , [ 28 ] , [ 5 ] , [ 30 ] , [ 12 ] , [ 7 ] , [ 39 ] , [ 13 ] , [ 41 ] , [ 14 ] , [ 42 ] , [ 43 ] [ 40 ] , [ 8 ] , [ 45 ] , [ 9 ] , [ 46 ] [ 44 ] , [ 47 ] , [ 48 ] SLOC [ 4 ] , [ 5 ] , [ 29 ] , [ 34 ] , [ 32 ] , [ 38 ] , [ 7 ] , [ 33 ] , [ 39 ] , (cid:1)(cid:1)(cid:1) [ 11 ] , [ 27 ] , [ 28 ] , [ 30 ] , [ 31 ] , [ 6 ] , [ 40 ] , [ 13 ] , [ 41 ] , [ 42 ] , [ 43 ] , [ 44 ] , [ 46 ] , [ 47 ] [ 12 ] , [ 14 ] , [ 45 ] , [ 9 ] , [ 48 ] * * N / A : not applicable . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1525 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . it . With more emphasis , the insigni¯cance of DIT indicates that a class with higher number of inheritance hierarchy is not likely to have faults . For NOC , only 3 studies found it to be signi¯cantly related to FP , while 15 studies reported it as insigni¯cant . The insigni¯cance results show that a class having a higher number of children is not likely to be fault - prone than others with less number of children . However , 11 of the studies did not measure NOC . Class Size measure : Lastly , analysis shows that SLOC of a class has a strong rela - tionship with FP . About 17 studies con¯rm its signi¯cance , but no study found it to be insigni¯cant while 12 studies did not measure SLOC . The results indicate that a class having a larger number of lines of code is more likely to have faults than classes with small code lines . Table 11 presents the degree of metric validation across all studies selected in this SLR . It shows the di®erent metrics as well as the studies that found them to be either signi¯cant or insigni¯cant or not measured ( N / A ) . Table 12 . Metrics validation systems . Id Validation systems 1 Industry Projects ( 2 versions Commercial Java application ) 2 Student Projects ( 8 information systems by UMLD ) 3 Industry Project ( A large telecommunications framework ) 4 Industry Project ( A large network service management system . ) 5 Industry Project ( NASA Metrics Data Program ) 6 Student Projects ( 8 information systems by UMLD ) 7 Student Projects ( 8 information systems by UMLD ) 8 Open Source Project ( 7 versions of Mozilla ) 9 Open Source Project ( 6 versions of Mozilla Rhino ) 10 Industry Project ( NASA Metrics Data Program ) 11 Industry Project ( NASA Metrics Data Program ) 12 Industry Project ( Subsystems of HMI software ) 13 Industry Projects ( 2 commercial software ) 14 Industry Project ( large B2C e - commerce application ) 15 Student Projects ( 12 di®erent systems by USIT ) 16 Student Projects ( open multi - agent system development environment , LALO ) 17 Open Source Project ( 6 versions of Mozilla Rhino ) 18 Industry Project ( NASA Metrics Data Program ) 19 Industry Projects ( 5 projects from PROMISE public data repository ) 20 Open Source Project ( 3 Versions of Eclipse using Bugzilla and change log ) 21 Industry Project ( 5 projects of real - time telecommunication systems ) 22 Open Source Project ( 4 projects of Eclipse software ) 23 Industry Project ( NASA Metrics Data Program ) 24 Student Projects ( 10 systems by M . Tech Post Graduate student ' s projects ) Open Source Project ( 5 Open Source Java Projects ) 25 Open Source Project ( 2 Java open source software systems ) 26 Open Source Project ( 4 Java open source software systems ) 27 Open Source Projects ( 3 major releases of Eclipse java project ) 28 Industry Project ( NASA Metrics Data Program ) 29 Open Source Project ( JHotDraw 7 . 5 . 1 , 2 - D drawing editors ) 1526 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . T a b l e 13 . M e tr i c s v a li d a t i o n d e t a il s . P a p e r i d T ec hn i q u e D e p e nd e n t v a r i a b l e I nd e p e nd e n t v a r i a b l e M e tr i c c o ll ec t i o n t oo l P r og . l a n g u ag e S t ud y t y p e R e l e a s e 1 L R F P C K & O t h e rs ( 24 ) J a v a st a t i c a n a l y s i s t oo l J A VA N R P r e 2 L R F P C K M e tr i c s M - S y st e m b a s e d o n G E N þþ C þ þ N R P r e 3 L R F P C K & O t h e rs C o mm e r c i a l m e tr i c s c o ll ec t o r C þþ N R P r e 4 O L S , L D A F P C K O T H E R S 8 M e tr i c t oo l i n t e g r a t e d w i t h R i g i J A VA N R P r e 5 O L S , AN F I S F C K S L O C (cid:1)(cid:1)(cid:1) C þ þ N R P r e 6 L R F P C K & O T H E R S 49 M - S y st e m b a s e d o n G E N þþ C þ þ N R P r e 7 L R F P C K M - S y st e m b a s e d o n G E N þþ C þ þ N R P r e 8 L R / M L F P C K S L O C C o l u m bu s C þþ N R P r e 9 L R F P C K O T H E R S S o f t w a r e S y st e m M a r k up L a n g u ag e J A VA N R P r e 10 L R / M L F P C K S L O C (cid:1)(cid:1)(cid:1) C þ þ N R P r e 11 L R / M L F P C K S L O C (cid:1)(cid:1)(cid:1) C þ þ N R P r e 12 L R F P C K - N O C (cid:1)(cid:1)(cid:1) C þ þ N R P r e 13 P R M , N B R M , Z I N B R M F C K L O C W e b M e tr i c s C þþ N R P r e 14 O L S F W M C , C B O , D I T , S I Z E (cid:1)(cid:1)(cid:1) C þþ , J a v a N R P r e 15 L R F P C K & O T H E R S 49 M a nu a l J a v a R P r e 16 L R F P C K & O T H E R S 49 A t oo l b a s e d o n t h e F A S T p a rs e r t ec hn o l og y C þþ R P r e 17 L R F P W M C , L O C , C o m p l e x i t y S o f t w a r e S y st e m M a r k up L a n g u ag e J AV A N R P r e 18 M L ( S V M ) F P C K S L O C (cid:1)(cid:1)(cid:1) C þ þ N R P r e 19 L R F P C K , L O C & O T H E R S (cid:1)(cid:1)(cid:1) C þ þ N R P r e 20 L R F P C K & O T H E R S B o r l a nd T og e t h e r J A VA N R P o st 21 P R M , N B R M , Z I N B R M F P C K & O t h e rs (cid:1)(cid:1)(cid:1) C þ þ N R P r e 22 L R F P C K & O t h e rs (cid:1)(cid:1)(cid:1) j a v a N R P r e 23 L R F P C K & O t h e rs (cid:1)(cid:1)(cid:1) C þ þ N R P r e 24 L R F P C K , L O C & O T H E R S (cid:1)(cid:1)(cid:1) j a v a N R P r e 25 L R F P L C O M ( C K ) & o t h e rs (cid:1)(cid:1)(cid:1) j a v a N R P r e 26 L R F P L C O M ( C K ) & o t h e rs (cid:1)(cid:1)(cid:1) j a v a N R P r e 27 L R F P W M C , L O C , C o m p l e x i t y (cid:1)(cid:1)(cid:1) J AV A R P r e 28 P R M , N B R M F P , F C C K , S L O C (cid:1)(cid:1)(cid:1) (cid:1)(cid:1)(cid:1) N R P r e 29 L R F P C K (cid:1)(cid:1)(cid:1) J A VA N R P r e * L R : L og i st i c R e g r e ss i o n ; * M L : M a c h i n e L e a r n i n g ; * O L S : O r d i n a r y L e a st S q u a r e ; * L D A : L i n e a r D i s c r i m i n a n t A n a l y s i s ; * P R M : P o i ss o n R e g r e ss i o n M o d e l ; * N B R M : N e ga t i v e B i n o m i n a l R e g r e ss i o n M o d e l ; * Z I N B R M : Z e r o s - I n° a t e d N e ga t i v e B i n o m i n a l R e g r e ss i o n M o d e l ; * AN F I S : A d a p t i v e N e u r o - F u zz y I n f e r e n ce S y st e m ; * S V M : Supp o rt V ec t o r M a c h i n e ; R : R e p li c a t e d ; N R : N o n - r e p li c a t e d ; P r e : P r e - r e l e a s e ; P o st : P o st - r e l e a s e . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1527 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 5 . 2 . Metric validation techniques RQ2 : What techniques are being used to validate the metrics in RQ1 and which is the best ? All the 29 studies found in this SLR explicitly stated the techniques used in conducting their individual study . Table 12 presents the techniques used , metrics studied , the variables employed ( dependent and independent ) and the tools employed for metric collection . Analysis shows that there are di®erent techniques that are being used such as machine language , LR etc . ( see Table 13 ) . Moreover , LR is the most reported techniques used to study the in°uence of OO metrics on FP . From this ¯nding , it is clear that LR is the best and largely used statistical techniques for predicting FP of a class using OO metrics ( CK þ SLOC ) . The ¯ndings shows that about 76 % of the studies used LR model ( i . e . univariate and multivariate ) , while other techniques reported in a few of the studies account for 24 % ( see Fig . 2 ( a ) ) . In addition , the variables employed in such models are the dependent and inde - pendent variables which can be explained in terms of cause and e®ect . In an exper - iment , an independent variable is the cause or input , while the dependent variable is the output or e®ect [ 36 ] . Thus , the dependent and independent variables are tested to validate if they are the actual e®ect and cause , respectively . In this study , we found that FP was used as the dependent variable in a majority of the studies ( 87 % ) , while 10 % used faults data ( F ) , and 3 % used fault count ( FC ) as dependent variable ( see Fig . 2 ( b ) ) For independent variable , CK þ SLOC metrics and others were speci¯cally used , though others were not considered in this study . LR , 22 , 76 % OTHERS , 7 , 24 % ( a ) FP , 26 , 87 % F , 3 , 10 % FC , 1 , 3 % ( b ) Fig . 2 . ( a ) Statistical techniques used ; ( b ) dependent variables used . Tool , 12 , 41 % Not _ stated , 16 , 56 % Manual , 1 , 3 % Fig . 3 . Metric collection methods . 1528 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . In the same vein , metric collection method being critical to the accuracy of the metric validated was also considered . Analysis shows that only 3 % of the studies collected metrics manually , 41 % stated the tools used in the collection , while 56 % mentioned nothing about how metrics were collected ( see Fig . 3 ) . 5 . 3 . Metric validation state RQ3 : To what extent have the metrics in RQ1 been validated ? The state of metric validation can be considered from di®erent perspectives : the study context , programming language , product release and the study type . Table 12 present the systems used for the metric validation systems , Table 13 present details of the metric validations while Table 7 of Sec . 3 . 3 presents the quality of each study using the quality criteria from Table 6 . 5 . 3 . 1 . Study subject and context In all the 29 studies considered in this SLR , we found that the empirical studies of CK þ SLOC metric ' s relationship with FP of OO classes have been centered on both academic and non - academic environments using software products developed by students and software professionals . The academic environment is mainly systems developed by students while the non - academic is either open source software ( OSS ) projects or industrial software systems developed by professionals . Most of the se - lected studies product as shown in Table 12 are either applications , components or middleware , ranging from OSS projects like mozilla [ 31 , 34 , 40 ] , eclipse [ 14 , 42 , 46 ] , NASA project [ 5 , 13 , 32 , 38 , 43 , 47 ] , to telecommunication systems [ 4 , 8 , 28 ] etc . of variable size ranging from small to large sized systems . Table 12 presents the di®erent systems or applications ( OSS and Non - OSS ) used by each study selected in this SLR . Table 13 presents the metric validation details of all studies considered in this SLR . The details include the variables used , statistical technique used , programming language used , metric tools , study type and release . Analysis shows that non - academic empirical studies of OO metrics lead with about 79 % . On the other hand , only 21 % of the validation have so far been recorded Students ( Academia ) , 6 , 21 % Professionals ( Non - Academia ) , 23 , 79 % ( a ) Students , 6 , 20 % OSS , 10 , 33 % Non - OSS , 14 , 47 % ( b ) Fig . 4 . ( a ) Metric validation environments ; ( b ) metric validation projects . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1529 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . in the academic environment like University of Maryland ( UMLD ) [ 27 , 29 , 32 ] and University School of Information Technology ( USIT ) [ 33 ] et al . ( see Fig . 4 ( a ) ) . Further analysis shows that 21 % of the systems used were written by students and 79 % by mainly software professionals , though most studies used same data sets from public repository such as eclipse , NASA , etc . ( see Fig . 4 ( a ) ) . In addition , analysis shows that in all the projects studied , 20 % are student ' s projects , 33 % are OSS while 47 % are non - OSS systems ( see Fig . 4 ( b ) ) . 5 . 3 . 2 . Programming language In all the studies , only applications written with programming languages such as : Java and C þþ have so far been used for validating the impact that OO design metrics has on FP of OO classes . These show how the two OO languages have dominated today ' s software applications . Further analysis has it that applications written in C þþ slightly lead with 54 % in both industry and academic , while applications written in Java followed with 43 % and 3 % of the studies did not mention the language of their application ( see Fig . 5 ) . 5 . 3 . 3 . Study type and release By study type we mean either the study is a replicated one or not . The emphasis on replicated work in this study lies on the fact that only few works exist on empirical validation of OO design metrics with respect to CK þ SLOC . In their study , Basili et al . [ 30 ] stressed the need for replication work since it will help to re - validate the metrics , provide understanding and usefulness of the metrics with regard to di®erent types of faults . In this work , analysis shows that only 14 % of the studies are repli - cated study while 86 % are non - replicated ( see Fig . 6 ( a ) ) . Among the replicated studies are Briand et al . [ 29 , 39 ] replicating the work of Basili et al . [ 30 ] , Aggarwal et al . [ 33 ] replicating Briand et al . [ 29 , 39 ] and Zhou et al . [ 46 ] replicating Olague et al . [ 31 ] . Other studies were found reusing datasets of previous work . For release , we mean the state of the system studied when its structural properties were measured and validated : pre - release and post - release . For instance , pre - release means measuring of faults during development and testing , while those faults mea - sured after the system has been released to the users is the post - release . Analysis shows that 97 % of the systems whose quality were evaluated were at their earlier Java , 13 , 43 % C + + , 16 , 54 % Not _ Stated , 1 , 3 % Fig . 5 . Programming language . 1530 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . phases of software development ( design , code , testing ) where the systems have not been released to the market . There ¯nding indicates that OO design metrics were e®ective at measuring the structural properties such as FP of the classes . However , only 3 % of the studies empirically studied the e®ectiveness of the metrics on a post - release application ( maintenance ) by categorizing faults at di®erent levels of severity ( high , medium and low - impact errors ) [ 14 ] ( see Fig . 6 ( b ) ) . 5 . 4 . The usefulness of measuring OO metrics and FP relationship RQ4 : Of what relevance are the CK þ SLOC metrics and empirical validations ? In most of the studies considered in this SLR , it has fully been stressed that the empirical evidence is a vital step towards ensuring their practical relevance in soft - ware organizations . It shows that without empirical evidence product metrics are associated with important external attributes but , they will remain of little value . In particular , these studies [ 1 , 7 , 20 , 28 ] provided an expression of the theoretical basis for developing quantitative models that relates OO metrics to FP . The studies hy - pothesized that the relationship is due to the e®ects it has on cognitive complexity ( see Fig . 7 ) . In Fig . 7 , the indication is that the structural properties of classes ( e . g . coupling , cohesion , inheritance ) have impact on cognitive complexity which in turn , relates to FP and maintainability . Cognitive complexity is a measure of the mental burden imposed on the persons ( developers , testers , inspectors , maintainers , etc . ) who have to deal with the component . Accordingly , high cognitive complexity results in a component exhibiting unwanted external qualities like FP and reduced under - standability and maintainability . Hence , metrics that have the ability to measure these structural properties would be considered good predictors of FP . Replicated , 4 , 14 % Non - Replicated , 25 , 86 % ( a ) Pre - release , 28 , 97 % Post - release , 1 , 3 % ( b ) Fig . 6 . ( a ) Study type ; ( b ) study product release . Fig . 7 . Theoretical basis of OO product metrics [ 11 ] . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1531 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . The studies explained that the expression of such a relationship can serve dual vital purposes : the early prediction and identi¯cation of software components that are of high risk and the construction of preventative ( e . g . design , programming ) strategies [ 11 ] . To this end , using OO design metrics such as CK metrics would help organizations to assess software development of any size rapidly at a reduced cost , take solution actions early and thus , avoid costly rework [ 13 , 27 , 33 ] . We see that in today ' s software development realm , producing large software systems with high quality requires a complex and lengthy activity . Therefore , measuring the structural properties of the system is important in order to focus the available resources on the most critical parts of the system and enhance client ' s satisfaction . As a preventive measure , designers and developer will be guided by developing systems with com - ponents that are of controlled size , highly cohesive , sparsely coupled , and controlled inheritance since they are less likely to contain faults . 5 . 5 . Generic OO design metrics for FP prediction RQ5 : Are there generic metrics in RQ1 for predicting faulty classes ? In this SLR , all the studies we found have ¯ndings that express the impact of CK or CK þ SLOC metrics on FP . Analysis in this study shows that not all the studies measured all the metrics . In addition , the results in some studies contradict results from other studies and datasets were reused . In the study performed by [ 7 ] , two systems written in C þþ and Java were used . Analysis indicates that WMC was signi¯cant with C þþ and was not signi¯cant with Java . Accordingly , DIT was found to be signi¯cant in few studies and insigni¯cant in most studies . This is also appli - cable to other metrics . Figure 8 shows the distribution of the signi¯cance and in - signi¯cance of the CK or CK þ SLOC metrics in°uence on FP of OO classes . CK + SLOC Metric Validation 23 24 21 14 9 3 17 1 0 1 4 15 15 0 5 5 6 11 5 11 12 0 5 10 15 20 25 30 35 CBO RFC WMC LCOM DIT NOC SLOC N / A Insignificant Significant Fig . 8 . Validation of CK þ SLOC relationship with FP . 1532 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . The presentation in Fig . 8 shows that the best predictors of FP seems to vary according to the type of applications used , the language written , and the target application domain . Moreover , SLOC , CBO , RFC , and WMC are the metrics that were reported as having strong signi¯cant relationship with FP in most of the studies , followed by LCOM . This is in line with ¯ndings in [ 50 , 51 ] . The results were measured as a function of the value of each metric . That is , the higher the value , the higher the FP of the class . Accordingly , DIT and NOC has the highest results of insigni¯cancy in all the studies in this SLR . 6 . Discussions With the domination of OO programming in software development , several OO metrics have been developed and channeled towards estimating the quality of OO software systems . Measuring and evaluating the quality of software could help take quick design decisions at a reduced cost before time during software development . In this study , we found 29 studies , indicating that only few empirical evidence mea - suring the impact of CK þ SLOC metrics on FP and the predictive models used exist . The studies used di®erent OO measures such as coupling , cohesion , inheritance and size measures . All the studies built models that predicts the FP based on the statistical techniques of LR and their predictive accuracy were reported based on either cross validation or goodness of ¯t [ 53 ] . We found that most of the models , especially LR , are good ( i . e . with high predictive accuracy ) in predicting faulty classes in software product . These models utilizes FP as the dependent variable obtained during the testing phase , while the OO metrics are the independent vari - ables obtained during design and coding phases . However , statistical techniques like LR can only predict the FP of a class without giving information regarding the possible number of faults in that class . Analysis in this study also shows that of all the metrics used in each study , size , complexity , coupling measures were the metrics found to be having strong impact on FP of OO classes , followed by cohesion in studies that mainly focus on CK þ SLOC metrics . In most studies , inheritance measures were found to be insigni¯cant . Based on this , some authors argued that DIT has an impact on the understandability of OO application and does not support reusability , while others argued that the number of methods involved is the factor that a®ects understandability [ 11 , 41 ] . Considering the importance of replicated studies to re - validate the metrics , we found that only few replicated studies exist and most of the studies were based on shared or reused dataset of previous studies obtained from NASA , OSS ( mozilla , eclipse projects ) etc . In addition , results obtained from most of the studies were not consistent with results from other studies in terms of signi¯cance level . Some metrics appears to be signif - icantly related to FP , while some were not or tends to be negatively signi¯cant . In addition , the best predictors of FP vary according to the class of language , appli - cations and the targeted domain . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1533 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . With regards to the software products used in the empirical studies , we found that it revolved within the sphere of students , OSS , and non - OSS projects , with non - OSS dominating followed by OSS . Though there were replicated studies of the student ' s project , only three of such projects actually exist . With the quality of the systems , we found that a majority of the systems was developed by professionals ( 79 % ) which add to the validity of the study . Going by the release period of the products , we found that validation were performed on only pre - release products ( 97 % ) and only one ( 3 % ) study actually performed it on post - release product . However , in the study conducted by [ 41 ] , ¯ndings recommend that as a system evolves , it becomes more cumbersome to use OO metrics to accurately identify the FP of classes . As such , alternative methods should be used if we want to achieve high accuracy . We also found that of all OO languages , only applications written in C þþ and Java have so far been used to evaluate metrics impacts on FP . The consequence of our ¯ndings is that empirical studies of OO metrics in°uences on quality attributes like FP and maintainability is vital to preserve their practical rele - vance in software companies . Measuring FP is equally essential in order to facilitate the allocation of resources with respect to testing , analysis and veri¯cation , while mea - suring its maintainability could facilitate impact analysis and regression testing . Hence , during development e®ort should be technically geared towards keeping all those metrics at a reasonable level since measurement is a function of each metric value . 6 . 1 . Strengths and weaknesses In this SLR , we have covered at least a large number of articles that assist in extracting relevant information used . At this point , we can say we are sure that the study actually covers the empirical validation of CK þ SLOC metrics and the models that utilized them which have been published to date . We have strictly followed the guidelines by Kitchenham et al . [ 35 ] and used credible and trusted sources considered to be rich and recognized by research bodies worldwide . However , possible threats could be on the search terms used , the risks posed by not covering all the relevant studies or most relevant studies could be hidden in the sources we excluded , as well as the risk of misrepresenting the ¯ndings of some of the papers found , such as not considering results obtained at di®erent fault severity levels , as well as the level of signi¯cance and insigni¯cance of the metrics . We are very con¯dent that if most relevant studies were not found , the information they contain will have no signi¯cant e®ect on the results of this SLR . To counter these , the two authors of this SLR worked collaboratively and ana - lyzed all selected studies . In addition , all decisions and results were checked , rechecked and inconsistencies resolved . 6 . 2 . Related works In this section , we present a brief description of previous works . The few studies we found are described as follows . 1534 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . A study was carried out by [ 50 ] on empirical studies of software FP prediction . The review was performed on studies between 1995 to 2010 and focused speci¯cally on the statistical techniques used . The study ¯ndings were that , among other techniques used , LR is the best technique that is use to derive fault predictors . In addition , the study recommended that future research should focus on more class level metrics . In another study , [ 51 ] conducted a SLR of empirical evidences of published articles in order to identify the relationship between CK metrics and functional correctness . The study was carried out on 20 identi¯ed relevant empirical studies and the results obtained showed that WMC , CBO , RFC and LCOM metrics are good indicators of functional correctness of OO classes , while DIT and NOC were found to be not useful indicators . In another study , [ 52 ] performed a SLR to identify software metrics and to assess their applicability in software fault prediction . They based their study on selection and performances of metrics . The study was carried out on 106 articles between 1991 and 2011 basically on both OO metrics and tra - ditional metrics . Their results shown that OO metrics ( 49 % ) were used almost twice as frequent when compared to the traditional metrics ( source code or process ) . In addition , CK metrics were the frequently used metrics among the OO metrics . Their conclusion was that more studies need to be performed on large scale industrial systems in order to ¯nd metrics that are more relevant for the industry and to aid decisions on which metrics should be used in a particular context . In all these studies , reviews were based on certain attributes which are di®erent from our focus in this SLR . Our work is speci¯cally on CK þ SLOC metrics and their degree of signi¯cance and insigni¯cance , validation state and usefulness . 7 . Conclusions With the increased popularity of OO paradigm coupled with the complexity intro - duced by its features , there is an increasing need to ensure high software quality since it plays a vital role in any software organization successes . This requires that OO design metrics should be used to evaluate the quality of software during software development since software is intangible . By quantifying the design , its quality will be improved which in turn can lower the probability of the software being °awed through the revision of improper design . This can be done at considerably small cost and reduced e®orts than during late in design or maintenance . Many software metrics have been proposed for this purpose , in particular , CK metric suite and the size measures . Several empirical studies have reported the im - pact of these metrics on FP . But to know which metrics are useful in this regard , the SLR presented in this article explored the existing empirical validation of CK þ SLOC metrics and the models that utilized them from three aspects : ( 1 ) their level of signi¯cance and insigni¯cance with FP , ( 2 ) their state of validation , and ( 3 ) their usefulness in terms of software quality . These selected aspects are essential in gaining good understanding of whether a metric has in°uence on FP of OO classes or not . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1535 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . We have analyzed the di®erent empirical studies in order to know the general trends in OO design measures of CK þ SLOC and FP . To this end , we present the found results of metrics signi¯cant and insigni¯cant in all the studies ( Table 11 and Fig . 8 ) . In addition , we have presented the di®erent techniques , tools , language , projects and the domain where the validation to place . The main ¯ndings of this SLR are as follows : . SLOC , CBO , RFC , WMC are metrics with strong relationship with FP and are considered to the best predictors of FP . LCOM is somehow an indicator of FP in all studies that considered CK þ SLOC metrics , while DIT and NOC were found to be insigni¯cant in most of the studies . From the results obtained , it shows that the best predictors of FP vary according to the class of applications as well as the application domain involved . . Twenty nine empirical studies of CK þ SLOC metrics and FP of OO class have been studied . Six of them are student ' s project while twenty three are non - students projects ( mainly OSS and industrial applications ) . . Only applications written in C þþ and Java have so far been used for empirical studies involving the validation of OO metrics and FP . . Prediction models built that utilize the variables were mostly based on LR . Only few machine learning and other techniques have been used . Therefore , LR is the best statistical technique used for FP predictions . . The empirical studies circled around pre - release software products . Only one study has so far been performed on post - release ( maintenance ) product . . Only few replicated studies exist , though most studies reused dataset of previous studies . Future work includes performing systematic review on the relationship between FP and other OO metrics suits as well as OO metric and software maintainability . Based on the ¯ndings obtained from this SLR , we provide a number of recommendations : ( a ) To predict the FP of OO class with some level of accuracy when CK þ SLOC metrics are used , SLOC , CBO , RFC , WMC and LCOM should be used . In addition , LR should be used as the predictive model since is the best model with high predictive power . However , other metrics , DIT , and NOC can only be considered based on their value measured in that particular software product . This is because , though they appears not to be regular class FP indicators , however their signi¯cance or insigni¯cance could be as a result of either the developers ' experience or the inheritance strategy applied . Based on this , we cannot conclude on which of the metrics that can be used as generic metrics for FP prediction of a class . ( b ) To ensure high quality software that is stable and maintainable , developers need to go for a low - coupled , highly cohesive design and controlled size and inheritance . In particular , strong focus should be placed on size and coupling as they appear to be strong and stable indicator of FP . 1536 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . ( c ) To assess the quality of OO software products either under development or maintenance , measures should strongly not be based on the nature of the en - vironment involved , instead on steady indicators of design problems and impacts on external quality attributes . ( d ) More empirical studies should be performed on applications written in other OO languages other than C þþ or Java . In addition , more empirical studies should be performed in the academic and more replicated studies should be carried out in order to re - validate the metrics and keep them relevant . ( e ) E®ort should be geared towards post - release software products in order to con¯rm if models utilizing OO metrics can e®ectively predict class FP accu - rately or not . ( f ) During impact analysis of OO software systems , as a quality support , metrics should be used to assess ¯rst , the software quality in order to see where attention can be most needed before e®ecting changes . In all , we suggest that developers and maintainers should use these metrics consistently to evaluate and then identify which OO classes requires attention in order to channel resources on those classes or components that are likely to result in grave failures . References 1 . S . Chidamber and C . F . Kemerer , A metrics suite for object oriented design , IEEE Trans . Softw . Eng . 20 ( 6 ) ( 1994 ) 476 – 493 . 2 . S . Chidamber , D . Darcy and C . Kemerer , Managerial use of metrics for object oriented software : An exploratory analysis , IEEE Trans . Softw . Eng . 24 ( 8 ) ( 1998 ) 629 – 639 . 3 . M . Cartwright , An empirical view of inheritance , Information and Software Technology 40 ( 1998 ) 795 – 799 . 4 . P . Yu , T . Systa and H . Muller , Predicting FP using OO metrics : An industrial case study , in Proceedings of Sixth European Conference on Software Maintenance and Reengi - neering , Budapest , Hungary , 2002 , pp . 99 – 107 . 5 . J . Xu , D . Ho and L . F . Capretz , An empirical validation of object - oriented design metrics for fault prediction , Journal of Computer Science 4 ( 7 ) ( 2008 ) 571 – 577 , 1549 – 3636 . 6 . M . H . Tang , M . H . Kao and M . H . Chen , An empirical study on object - oriented metrics , in Proceedings of 6th IEEE International Symposium on Software Metrics , 1999 , pp . 242 – 249 . 7 . R . Subramanyam and M . S . Krishnan , Empirical analysis of CK metrics for object - oriented design complexity : Implications for software defects , IEEE Trans . Software Eng . 29 ( 2003 ) 297 – 310 . 8 . A . Janes et al . , Identi¯cation of defect - prone classes in telecommunication software sys - tems using design metrics , International Journal of Information Sciences 176 ( 2006 ) 3711 – 3734 . 9 . J . Al - Dallal and L . C . Briand , An object - oriented high - level design - based class cohesion metric , Information & Software Technology 52 ( 2010 ) 1346 – 1361 . 10 . L . Briand , J . Wuest , S . Ikonomovski and H . Lounis , Investigating quality factors in object - oriented designs : An industrial case study , in Proceedings of the International Conference on Software Engineering , 1999 , pp . 345 – 354 . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1537 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 11 . K . E . Emam , W . L . Melo and J . C . Machado , The prediction of faulty classes using object - oriented design metrics , Journal of Systems and Software 56 ( 2001 ) 63 – 75 . 12 . G . Succi , W . Pedrycz , M . Stefanovic and J . Miller , Practical assessment of the models for identi¯cation of defect - prone classes in object - oriented commercial systems using design metrics , Journal of Systems and Software 65 ( 2003 ) 1 – 12 . 13 . R . Malhotra , A . Kaur and Y . Singh , Empirical validation of object - oriented metrics for predicting FP at di®erent severity levels using support vector machines , International Journal of System Assurance Engineering Management 3 ( 2010 ) 269 – 281 . 14 . R . Shatnawi and W . Li , The e®ectiveness of software metrics in identifying error - prone classes in post - release software evolution process , Journal of Systems and Software 81 ( 2008 ) 1868 – 1882 . 15 . B . Boehm and V . Basili , Software defect reduction : Top 10 lists , IEEE Computer 34 ( 1 ) ( 2001 ) 135 – 137 . 16 . G . Myers , T . Badgett , T . Thomas and C . Sandler , The Art of Software Testing , 2nd ed . ( John Wiley & Sons , 2004 ) . 17 . S . Kanmani et al . , Object - oriented software fault prediction using neural networks , In - formation and Software Technology 49 ( 2007 ) 483 – 492 . 18 . N . Fenton and M . Neil , Software metrics : Successes , failures and new directions , Journal of Systems and Software 47 ( 1999 ) 149 – 157 . 19 . W . Li and S . Henry , Object - oriented metrics that predict maintainability , Journal of Systems and Software 23 ( 1993 ) 111 – 122 . 20 . F . B . Abreu and R . Carapuca , Object - oriented software engineering : Measuring and controlling the development process , in Proceedings of the Fourth International Con - ference on Software Quality , 1994 . 21 . N . Fenton and S . L . P°eeger , A Rigorous and Practical Approach , 2nd ed . ( International Thomson Computer Press , 1977 ) . 22 . M . J . Shepperd and D . Ince , Derivation and Validation of Software Metrics ( Clarendon Press , Oxford , 1993 ) . 23 . M . Lorenz and J . Kidd , Object - Oriented Software Metrics ( Prentice - Hall , Englewood Cli®s , 1994 ) . 24 . B . Henderson - Sellers , Object - Oriented Metrics : Measures of Complexity ( Prentice - Hall , Englewood Cli®s , 1996 ) . 25 . L . Briand , P . Devanbu and W . Melo , An investigation into coupling measures for C þþ , in Proceedings of the 19th International Conference on Software Engineering , 1997 , pp . 412 – 421 . 26 . S . Benlarbi and W . Melo , Polymorphism measures for early risk prediction , in Proceed - ings of the 21st International Conference on Software Engineering , 1999 , pp . 334 – 344 . 27 . L . Briand , J . Daly , V . Porter and J . Wust , A comprehensive empirical validation of design measures for object oriented systems , in Proceedings of the 5th International Symposium on Software Metrics , 1998 . 28 . K . E . Emam , S . Benlarbi , N . Goel and S . N . Rai , The confounding e®ect of class size on the validity of object - oriented metrics , IEEE Trans . Software Eng . 27 ( 2001 ) 630 – 650 . 29 . L . C . Briand , J . W ü st , J . W . Daly and D . V . Porter , Exploring the relationships between design measures and software quality in object - oriented systems , Journal of Systems and Software 51 ( 2000 ) 245 – 273 . 30 . V . Basili , L . Briand and W . Melo , A validation of object oriented design metrics as quality indicators , IEEE Transactions on Software Engineering 22 ( 10 ) ( 1996 ) 751 – 761 . 31 . H . M . Olague , L . H . Etzkorn , S . Gholston and S . Quattlebaum , Empirical validation of three software metrics suites to predict FP of object - oriented classes developed using 1538 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . highly iterative or agile software development processes , IEEE Trans . Software Eng . 33 ( 2007 ) 402 – 419 . 32 . Y . Zhou and H . Leung , Empirical analysis of object oriented design metrics for predicting high severity faults , IEEE Transactions on Software Engineering 32 ( 10 ) ( 2006 ) 771 – 784 . 33 . K . K . Aggarwal , Y . Singh , A . Kaur and R . Malhotra , Empirical analysis for investigating the e®ect of object - oriented metrics on FP : A replicated case study , Software Process Improvement and Practice 14 ( 2009 ) 39 – 62 . 34 . T . Gyim ó thy , R . Ferenc and I . Siket , Empirical validation of object - oriented metrics on open source software for fault prediction , IEEE Trans . Software Eng . 31 ( 2005 ) 897 – 910 . 35 . B . Kitchenham and S . Charters , Guidelines for performing systematic literature reviews in software engineering , Keele University and Durham University Joint Report , Tech . Rep . EBSE 2007 – 001 , 2007 . 36 . M . Svahnberg et al . , A systematic review on strategic release planning models , Journal of Information and Software Technology 52 ( 2010 ) 237 – 248 . 37 . J . Hannay , D . Sj ø berg and T . Dyb å , A systematic review of theory use in software engineering experiments , IEEE Transactions on Software Engineering 33 ( 2 ) ( 2007 ) 87 – 107 . 38 . Y . Singh , A . Kaur and R . Malhotra , Empirical validation of object - oriented metrics for predicting FP models , Software Quality Journal 18 ( 2010 ) 3 – 35 . 39 . L . C . Briand , J . Wust and H . Lounis , Replicated case studies for investigating quality factors in object - oriented designs , Empirical Software Engineering 6 ( 2001 ) 11 – 58 . 40 . H . M . Olague , L . H . Etzkorn , S . L . Messimer and H . S . Delugach , An empirical validation of object - oriented class complexity metrics and their ability to predict error - prone classes in highly iterative , or agile , software : A case study , Journal of Software Maintenance 20 ( 2008 ) 171 – 197 . 41 . S . S . Rathore and A . Gupta , Validating the e®ectiveness of object - oriented metrics over multiple releases for predicting FP , in Proceedings of 19th Asia - Paci¯c Software Engi - neering Conference , 2012 , pp . 350 – 355 . 42 . M . English , C . Exton , I . Rigon and B . Cleary , Fault detection and prediction in an open - source software project , in 5th International Conference on Predictor Models in Software Engineering , 2009 , pp . 17 : 1 – 17 : 11 . 43 . B . Goel and Y . Singh , Empirical investigation of metrics for fault prediction on object - oriented software , Computer and Information Science , 2008 , pp . 255 – 265 . 44 . A . Shaik et al . , Investigate the result of object oriented design software metrics on FP in object oriented systems : A case study , Journal of Emerging Trends in Computing and Information Sciences 2 ( 4 ) ( 2011 ) 1 – 10 . 45 . J . Al - Dallal , Transitive - based object - oriented lack - of - cohesion metric , Procedia Com - puter Science , 2011 , pp . 1581 – 1587 . 46 . Y . Zhou , B . Xu and H . Leung , On the ability of complexity metrics to predict fault - prone classes in object - oriented systems , Journal of Systems and Software 83 ( 2010 ) 660 – 674 . 47 . G . J . Pai and J . B . Dugan , Empirical analysis of software fault content and FP using Bayesian methods , IEEE Trans . Software Eng . 33 ( 2007 ) 675 – 686 . 48 . K . Johari and A . Kaur , Validation of object oriented metrics using open source software system : An empirical study , ACM SIGSOFT Software Engineering Note 37 ( 1 ) ( 2012 ) 1 . 49 . J . W . Creswell , Research Design : Qualitative , Quantitative and Mixed Methods Approaches , 4th Edition , 2013 . 50 . P . Saxena and M . Saini , Empirical studies to predict fault proneness : A review , Inter - national Journal of Computer Applications 22 ( 2011 ) . Empirical Validation of OO Metrics Towards Fault - Proneness Prediction 1539 I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y . 51 . Y . A . Khan , M . O . Elish and M . El - Attar , A Systematic Review on the Impact of CK Metrics on the Functional Correctness of Object - Oriented Classes ( Springer , 2012 ) , pp . 258 – 273 . 52 . D . Radjenovic , M . Hericko , R . Torkar and A . Zivkovic , Software fault prediction metrics : A systematic literature review , Information and Software Technology 55 ( 2013 ) 1397 – 1418 . 53 . Briand et al . , Assessing the applicability of fault - proneness models across object - oriented software projects , IEEE Transactions on Software Engineering 28 ( 7 ) ( 2002 ) 706 – 720 . 1540 B . Isong & E . Obeten I n t . J . S o f t . E ng . K no w l . E ng . 2013 . 23 : 1513 - 1540 . D o w n l o a d e d fr o m www . w o r l d s c i e n ti f i c . c o m by KO R E A UN I V E R S I T Y S E J ONG C A M P U S L I BR A R Y on 12 / 26 / 14 . F o r p e r s on a l u s e on l y .