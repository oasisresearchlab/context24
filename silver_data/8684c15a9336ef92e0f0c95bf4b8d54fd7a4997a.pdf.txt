50 Ways to Bake a Cookie : Mapping the Landscape of Procedural Texts Moran Mizrahi The Hebrew University of Jerusalem Jerusalem , Israel moranmiz @ cs . huji . ac . il Dafna Shahaf The Hebrew University of Jerusalem Jerusalem , Israel dshahaf @ cs . huji . ac . il ABSTRACT The web is full of guidance on a wide variety of tasks , from chang - ing the oil in your car to baking an apple pie . However , as content is created independently , a single task could have thousands of corresponding procedural texts . This makes it difficult for users to view the bigger picture and understand the multiple ways the task could be accomplished . In this work we propose an unsupervised learning approach for summarizing multiple procedural texts into an intuitive graph representation , allowing users to easily ex - plore commonalities and differences . We demonstrate our approach on recipes , a prominent example of procedural texts . User studies show that our representation is intuitive and coherent and that it has the potential to help users with several sensemaking tasks , including adapting recipes for a novice cook and finding creative ways to spice up a dish . CCS CONCEPTS â€¢ Informationsystems â†’ Summarization ; Personalization ; â€¢ Com - puting methodologies â†’ Information extraction . KEYWORDS Procedural texts ; Multi - document summarization ; Sensemaking ; Cooking recipes ACM Reference Format : Moran Mizrahi and Dafna Shahaf . 2021 . 50 Ways to Bake a Cookie : Map - ping the Landscape of Procedural Texts . In Proceedings of the 30th ACM International Conference on Information and Knowledge Management ( CIKM â€™21 ) , November 1 â€“ 5 , 2021 , Virtual Event , QLD , Australia . ACM , New York , NY , USA , 11 pages . https : / / doi . org / 10 . 1145 / 3459637 . 3482405 1 INTRODUCTION Procedural texts play an important part in our lives : recipes , how - to instructions , scientific procedures , navigating directions and Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , QLD , Australia Â© 2021 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - 8446 - 9 / 21 / 11 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3459637 . 3482405 manuals are only a few common examples . The web includes pro - cedural texts on a variety of topics , from recipe websites 1 to Maker websites 2 and general how - to websites 3 . However , a single task might have thousands of corresponding procedural texts . This is both due to variations ( for example , dif - ferent recipes for the same dish ) and due to the distributed nature of the web , where content is created independently by people who do not communicate . Thus , looking at one ( or a few ) procedural texts only gives the reader a limited view of the possibilities . Con - sequently , when people try to determine the best choice for them given preferences ( e . g . , taste ) and constraints ( budget , time , items they do or do not have ) , they often resort to extensive browsing and comparisons between different texts to get the bigger picture . Automatic understanding of procedural texts is a difficult prob - lem , requiring capturing the interplay between entities , attributes and their dynamic transitions . There has been a recent surge in work in understanding procedural texts [ 1 , 6 , 16 , 26 , 41 , 55 ] and in visualizing procedural texts as graphs [ 9 , 29 , 30 , 34 , 43 , 46 , 62 ] . However , these works focus exclusively on analyzing a single pro - cedural text . In contrast , our goal in this paper is to automatically summarize and organize many texts sharing the same goal , allowing users to explore commonalities and differences between texts at a glance . We envision a system that will guide the user in finding a way to complete the task that best fits their prefer - ences or constraints . Importantly , the chosen alternative could be a modification or combination of the original texts . We focus on recipes , a prominent example of procedural texts . We build a system taking as input multiple recipes for the same dish . The output is an intuitive graph representation , mapping the entire landscape of variations . See Figure 1 for a summary of âˆ¼ 200 apple - cake recipes . A node in the graph corresponds to a set of similar actions , and a directed path represents a way to make the dish . Alternative paths indicate different approaches , such as creaming butter and sugar before adding the other ingredients ( bottom path ) or mixing them all in a single step ( middle path ) . The graph makes it easy to identify common ingredients ( flour , apples , baking powder , sugar and eggs ) and techniques , as well as anomalies that could potentially spark innovative ideas , such as using yogurt , allspice or zucchini , or using a microwave to bake the cake instead of an oven . We believe such a representation could be especially useful to users who want to adjust a recipe to meet specific preferences or needs ; to novice cooks looking to avoid rookie mistakes ( e . g . , many recipes do not explicitly mention the need to rinse grains or let the 1 allrecipes . com , epicurious . com 2 https : / / www . instructables . com 3 Wikihow . com , eHow . com Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1304 Figure 1 : Summary graph for apple cake recipes . Each node represents a cluster of similar instructions . Darker nodes indicate larger clusters ; thicker edges indicate strong connections . Paths correspond to execution plans . Nodes show a compressed summary of their instructions : main cluster verb and its most frequent ingredients . The â€œbeatâ€ node is clicked on , showing a full summary , including ingredient quantity ranges , cooking instruments and preparation time range . Next to the â€œbeatâ€ node is a sample of its associated instructions . On the left is a list of the least common ingredients . Clicking on an ingredient that does not appear in the graph reveals hidden paths with this ingredient ( in blue ) . meat rest ) ; and to anyone looking for new ideas for spicing up a familiar dish . Our contributions are : â€¢ We propose a novel approach for summarizing procedural texts sharing a goal into an intuitive graph representation . â€¢ We demonstrate our approach on cooking recipes . We de - vise an unsupervised recipe parser , taking into account the unique structure of recipes . We believe the principles behind the parser could be generalized to other domain - specific parsers for procedural texts . We then propose a general - purpose algorithm for constructing the summarization graph . â€¢ We assess the quality of our pipelineâ€™s individual components and conduct a user study to evaluate our representation in terms of intuitiveness ( can users understand it with no ex - planation ? ) , coherence ( do paths correspond to recipes ? ) and utility ( can it help users performing sensemaking 4 tasks ? ) . User studies demonstrate that our representation is intu - itive and coherent . Evaluation by cooking experts shows the graph users perform better than users of a baseline interface at several sensemaking tasks , including adapting recipes for novice users and finding creative ingredients . â€¢ Wereleaseopen - sourcecodeathttps : / / github . com / moranmiz / 50 - Ways - to - Bake - a - Cookie . We believe that our representation could serve as foundation for future systems that digest a large set of procedural texts . We are particularly excited by the potential of such system to synthesize new procedures , rather than simply recommend existing ones . 4 Sensemaking [ 50 ] is the task of constructing a mental representation of interrelated piecesofinformation , ofteninthecontextofunderstandinglargedocumentcollections . 2 PROBLEM DEFINITION Given a large set of procedural texts sharing the same goal , we wish to summarize these texts in a way that will help users view the big picture . In particular , we want to find a representation that will ( 1 ) allow the user to explore commonalities and differences between the ways to complete the task , ( 2 ) make it easy for the user to choose a way to complete the task , satisfying personal preferences or constraints . Importantly , the chosen way need not be one of the original procedural texts , but rather could be a modification ( or combination ) of the original texts . More formally , Definition 1 ( Summary Graph ) . Let S be a set of procedural texts sharing the same goal . Each ğ‘  âˆˆ S is a pair ( ğ‘‚ ğ‘  , ğ¼ ğ‘  ) , where ğ¼ ğ‘  is a sequence of instructions , and ğ‘‚ ğ‘  is a set of objects needed to carry out the instructions . Our goal is to construct a summary graph ğº S = ( ğ‘‰ , ğ¸ ) . Each node in ğ‘‰ represents a set of ( semantically similar ) instructions from S . There are also two special nodes , START and END . Directed paths from START to END represent ways toward achieving the goal . Nodes are weighted and labeled ; edges are weighted . Figure 1 shows an example for summary graph , summarizing âˆ¼ 200 apple - cake recipes . To facilitate exploration , we provide several visual cues : dark nodes contain more instructions , and thick edges represent strong connections between the nodes . Nodes could contain hundreds of instructions , and thus we need to summarize their contents for the visualization . For recipes , we specify the action ( e . g . , â€œmixâ€ , â€œbakeâ€ ) along with a statistical summary of the ingredients , tools , and execution time - range . Left click on a node reveals quantities ( see â€œbeatâ€ node ) ; right click shows its actual ( natural - language ) instructions ( see a sample near â€œbeatâ€ ) . The graph representation gives a general overview that allows users to explore different ways to bake a cake and better understand Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1305 Figure 2 : A scheme demonstrating our general approach to constructing the summarization graph . The stages are : gathering data , parsing it , clustering instructions based on predefined similarity measure , constructing the graph and visualizing it . the process . For example , consider the highlighted â€œbeatâ€ node . Looking at this node , one could deduce that butter , appearing in 53 . 3 % of the instructions , is more popular than shortening or oil , that this step could use a mixer and only takes a few minutes . The thick edge from node â€œbakeâ€ to node â€œcoolâ€ indicates that cooling the cake after baking it is crucial . Alternative paths indicate different approaches , such as creaming butter and sugar before adding the other ingredients ( bottom path ) or mixing them all in a single step ( middle path ) . The graph interface also makes it easy to identify anomalies that could potentially spark innovative ideas . Expanding the â€œbakeâ€ node , we observe it is possible to bake a cake using a microwave . 5 The rare ingredient list includes ingredients such as allspice and even zucchini ( interestingly , the rarest ingredient is yeast ; upon further examination , we realized that the vast majority of cake recipes are indeed risen by baking soda / powder 6 ) . 3 IMPLEMENTATION Before diving into the details , we give a general overview of our approach towards constructing the summary graph , illustrated in Figure 2 . First , we gather data of procedural texts sharing the same goal . Second , we parse the data using our unsupervised parser . Then , we take advantage of the structure extracted by our parser to define a similarity measure between instructions and cluster similar instructions . These clusters constitute the graphâ€™s nodes . Next , we connect nodes so that every path corresponds to an execution plan . As the resulting graph might be noisy and too large to visualize ef - fectively , we prune it , reducing noise in the process . Note that while the first three steps in the scheme ( gathering data , parsing , similar - ity ) are task - dependent , the final step is general . Code is available at https : / / github . com / moranmiz / 50 - Ways - to - Bake - a - Cookie . 4 DATA COLLECTION We gather data of procedural texts sharing the same goal . For recipes , we crawled Allrecipes . com for 18 , 976 recipes of 98 popu - lar dishes . The average number of ingredients per recipe is 10 . 11 5 https : / / tinyurl . com / apple - mug - cake 6 https : / / tinyurl . com / yeast - leavened - cake ( std = 4 . 09 ) . The average number of instructions per recipe is 3 . 86 ( std = 1 . 865 ) before tokenization , and 12 . 65 ( std = 6 . 65 ) after tokeniza - tion ( see Section 5 . 1 ) . The average number of words per recipe is 162 . 01 ( std = 76 . 13 ) . Considering instructions only , the average number of words is 116 . 33 ( std = 64 . 7 ) . The vocabulary size is 9322 . In Section 5 . 2 . 2 , we construct a word2vec model on recipe instruc - tions . For this step , we also use the instructions of 97 , 862 recipes from " Now Youâ€™re Cooking ! " 7 . The average length of a recipe in this dataset ( considering instructions only ) is 63 . 45 words ( std = 46 . 13 ) . The vocabulary size of this additional dataset is 44 , 601 . 5 MODEL 5 . 1 Unsupervised parser Referring back to Definition 1 , in our use case S is a set of cooking recipes for the same dish . Each recipe ğ‘  âˆˆ S is a pair ( ğ‘‚ ğ‘  , ğ¼ ğ‘  ) , where ğ‘‚ ğ‘  is a set of ingredient objects , and ğ¼ ğ‘  is a sequence of instructions . We define an ingredient object ğ‘œ âˆˆ ğ‘‚ ğ‘  as a tuple consisting of the ingredientâ€™s quantity , quantity unit and name . An instruction object ğ‘– âˆˆ ğ¼ ğ‘  consists of the instructionâ€™s main verb ( e . g . â€œmixâ€ for â€œmix all the ingredientsâ€ ) , sets of ingredient objects and instrument names that appear in the instruction , and an instructionâ€™s time range tuple ( indicating minimal and maximal duration ) . We want to parse natural - language recipes into our represen - tation and use the structure to compare instructions . We have ex - perimented with off - the - shelf parsers , including open - IE [ 53 ] and UDPipe [ 54 ] . However , recipe data has several unique character - istics and challenges , and thus we decided to implement our own parser . One prominent challenge is that in recipes , the same ingredient is often referred to in multiple forms . For example , the ingredient list might mention specific ingredients as â€œground nutmegâ€ and â€œcinnamonâ€ , but the instructions will refer to â€œspicesâ€ ( generaliza - tion ) . Similarly , the ingredient list might mention â€œGranny Smith applesâ€ , but the instructions will only mention â€œapplesâ€ . We refer to that specific type of generalization as abbreviation . Keeping track of abbreviations and generalizations has two im - portant advantages : when parsing instructions such as â€œsift sugar 7 Data is available at http : / / www . ffts . com / recipes . htm . Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1306 Figure 3 : Parser outputs for an apple - cake recipe . The upper rectangle is an ingredient parsing output in which â€œground cinnamonâ€ is the parsed ingredient and â€œspiceâ€ is its general - ization . No abbreviation for â€œground cinnamonâ€ was explic - itly found in text and thus the abbreviation is identical to the parsed ingredient ; The two rectangles below are instruc - tion parsing outputs . In the upper one , the parser managed to extract â€œcinnamonâ€ , â€œcloveâ€ and â€œallspiceâ€ from â€œspicesâ€ . and spicesâ€ , we can identify the implicit list of ingredients . When comparing different recipes , we can better measure similarity be - tween ingredients . For example , we can conclude that â€œvanillaâ€ is similar to â€œvanilla extractâ€ , but â€œbreadâ€ and â€œbread crumbsâ€ are certainly different . Thus , our parser implements two complementary tasks â€“ ingre - dient parsing and instruction parsing . We found it helpful to take into account the full instruction text when parsing ingredient lines , and the ingredient list when parsing instruction lines . A note on generalization . Abbreviations and generalizations are common in many procedural texts , from material science to make and craft instructions . Hence , we believe similar methods could be helpful when implementing other domain - specific parsers as well . Ingredient parsing . Our ingredient - line parser first parses the ingredient lines and tries to extract the ingredient name , quantity and unit using regular expressions . In addition , the parser also looks for abbreviations and generalizations in the text . To derive an ingredient abbreviation we lemmatize the instruc - tion text and search for the longest consecutive word sequence that the ingredient name shares with the text . If there are several longest sequences , we prefer one that ends with a noun ( an ingredientâ€™s abbreviation is usually consecutive adjectives followed by a noun ) . A failure to find an abbreviation is usually caused by a more generalized description in the instructions ( e . g . , â€œspicesâ€ for â€œground cinnamonâ€ ) . To derive a generalization of a missing ingredient , we remove the already - found abbreviations . Then , for every noun in the text ( e . g . , â€œspiceâ€ ) , we use WordNet [ 19 ] and check whether â€œfoodâ€ or â€œfruitâ€ is one of its hypernyms . In this case , if the noun is also a hypernym of the missing ingredient , we consider it the ingredientâ€™s generalization ( see example outputs in Figure 3 ) . We note that the ratio of recipes containing a generalization in our data is 8 . 56 % , and that this ratio varies significantly among different dishes ( e . g . , close to 0 % for â€œdeviled eggsâ€ and around 38 % for â€œwhole - grain breadâ€ ) . Instruction parsing . When parsing an instruction , we want to extract its main verb , ingredients , tools and preparation time range . For obtaining tools and preparation time we rely on regular ex - pressions . To derive the main verb we build upon the coreNLP parser [ 37 ] . Applied to the raw data , the coreNLP parser finds the correct verb for only âˆ¼ 75 % of the sentences , perhaps due to the imperative form ( which is rare in training data ) . Thus , we concate - nate the prefix â€œYou shouldâ€ to the instructions . If still no verb is found by the parser , we look up verbs from a list of common cooking verbs ( the collection of all the verbs we managed to parse before ) . As noted above , identifying the ingredients is done using the extracted abbreviations and generalizations . Refer to Figure 3 for output examples . Sentence tokenization . In the recipes of our dataset , one line in the instructions often corresponds to multiple actions . We divide these instructions into sub - instructions that are as concise and as simple as possible . To do so , we first tokenize the raw instructions using the coreNLP sentence tokenizer . Then , we break down com - plex instructions consisting of several verbs , using the common cooking verbs list found by our parser . For example , the instruction : â€œCombine the water , 1 / 2 cup sugar and chocolate in a saucepan and cook over low heat just until the chocolate meltsâ€ is divided into : â€œCombine the water , 1 / 2 cup sugar , and chocolate in a saucepanâ€ and â€œcook over low heat just until the chocolate meltsâ€ . This last step ( breaking down complex instructions ) affects 14 . 43 % of the instructions in the data . Evaluation . We manually evaluated our unsupervised parser on 200 ingredient lines and 200 instruction lines , randomly selected . For ingredients , the parser achieved accuracy of 93 . 5 % for extract - ing the ingredients , 95 . 5 % and 97 % for deriving abbreviations and generalizations , and 100 % and 99 . 5 % for parsing amounts and units . As for the instructions , our parser succeeded in extracting the right verb for 93 . 5 % of them , the instrument for 95 . 5 % of them and the time description for 100 % . Moreover , it identified correctly 95 . 26 % of the ingredients appearing in them . In comparison , open - IE [ 53 ] identified the right verb for only 76 . 5 % of the instructions ( failing to extract anything for 17 % of them ) . It was also very difficult to infer ingredients or tools from the output ( Representative outputs : [ V : Mix ] [ ARGM - LOC : in onion , cilantro , tomatoes ] [ ARG1 : , and garlic ] , [ V : shortening ] [ ARG1 : Cream ] â€“ for â€œCream shorteningâ€ , [ V : Add ] [ ARG1 : the sugar and vanilla and beat well ] ) . On the other hand , UDPipe [ 54 ] found the right verb for 82 . 5 % of the instructions . Failures are often due to identifying verbs as nouns ( Representative outputs : [ N : Cover ] [ N : skillet ] , [ N : Spoon ] [ N : mixture ] [ ADP : into ] [ N : cups ] ) . We note a recent relevant work by Diwan et al . [ 15 ] , suggesting a NER model to infer recipe instruction structure . We could not compare our results to theirs as the authors released only partial code and data at the time of completing this paper . 5 . 2 Clustering As noted earlier , each node in the graph corresponds to a set of semantically similar instructions . Similar instructions could be , for example , â€œcream shortening and sugar until fluffyâ€ and â€œbeat butter Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1307 and sugar using an electric mixer about 2 minutes until creamyâ€ as shown in Figure 1 . It is not straightforward to measure how semantically close two cooking instructions are . For example , consider the following instructions ( taken from apple - cake recipes ) : ( 1 ) â€œToss together the shredded apple , cinnamon and sugar in a bowl until evenly coatedâ€ ( 2 ) â€œIn a large bowl , mix sliced apples , sugar , cinnamon , allspice , clove and nutmegâ€ ( 3 ) â€œIn a large bowl , mix flour , baking powder , cinnamon , all - spice , clove and nutmegâ€ Although ( 2 ) and ( 3 ) share more content , ( 1 ) and ( 2 ) are semantically closer . The reason is that ( 1 ) and ( 2 ) correspond to the stuffing preparation phase , whereas ( 3 ) does not . In particular , word embedding models ( such as [ 7 , 11 , 49 ] ) are un - likely to capture a meaningful distance : in preliminary explorations we performed , those methods clustered together instructions with very different verbs and different ingredients . Thus , we decided to take advantage of the structure extracted by our parser and create a filtered list of candidate pairs of instructions . We require that two instructions could be considered for the same cluster only if the verbs are similar and they share enough ingre - dients , where ingredients that are common for the dish , such as apples , count more than rare ones ( note that in the example above , ( 1 ) and ( 2 ) share more frequent ingredients , even though ( 2 ) and ( 3 ) share more ingredients in total ) . In the following , we explain the filtering steps and the clustering method . 5 . 2 . 1 Candidate pairs of instructions filtering . Verb similarity . As word embedding models achieve poor perfor - mance on verbs [ 51 ] , we manually clustered the most frequent 100 verbs in the data and chose a representative verb per cluster . Then , we replaced verbs in the instructions with their representative . Similarity of two ingredient objects . To determine whether two ingredient objects are similar , we take into account their full ingre - dient names ( ğ‘– 1 ğ‘“ , ğ‘– 2 ğ‘“ correspondingly ) and abbreviations ( ğ‘– 1 ğ‘ , ğ‘– 2 ğ‘ ) , and check if : ğ‘šğ‘ğ‘¥ (cid:16) ğ½ (cid:16) ğ‘– 1 ğ‘“ , ğ‘– 2 ğ‘“ (cid:17) , ğ½ (cid:16) ğ‘– 1 ğ‘“ , ğ‘– 2 ğ‘ (cid:17) , ğ½ (cid:16) ğ‘– 1 ğ‘ , ğ‘– 2 ğ‘“ (cid:17) , ğ½ (cid:16) ğ‘– 1 ğ‘ , ğ‘– 2 ğ‘ (cid:17)(cid:17) â‰¥ ğ‘¡ 1 where ğ‘¡ 1 âˆˆ [ 0 , 1 ] is a threshold and ğ½ is the Jaccard index 8 . For instance , for the name - abbreviation pairs : ( grand smith apple , apple ) and ( red apple , apple ) the similarity is 1 . Similarity of two ingredient sets . Let ğ¼ 1 , ğ¼ 2 be two sets of ingredi - ent objects ; to measure their similarity , we use the weighted Jaccard similarity coefficient 9 ( also known as Ruzicka similarity ) , taking into account also the frequency of the items in S . This coefficient can be restated as : ğ½ ğ‘Š ( ğ¼ 1 , ğ¼ 2 ) : = (cid:205) ğ‘¥ âˆˆ ğ¼ 1 âˆ© ğ¼ 2 ( ğ‘› ğ‘¥ ) (cid:205) ğ‘¦ âˆˆ ğ¼ 1 âˆª ğ¼ 2 (cid:0) ğ‘› ğ‘¦ (cid:1) where ğ‘› ğ‘¥ is the number of recipes in which ingredient ğ‘¥ appears . 8 ğ½ ( ğ‘‹ , ğ‘Œ ) = | ğ‘‹ âˆ© ğ‘Œ | | ğ‘‹ âˆª ğ‘Œ | . In our case , ğ‘‹ , ğ‘Œ are the words in the ingredient name / abbreviation . 9 ğ½ ğ‘Š ( ğ‘¥ , ğ‘¦ ) = (cid:205) ğ‘— ğ‘šğ‘–ğ‘› ( ğ‘¥ğ‘— , ğ‘¦ğ‘— ) (cid:205) ğ‘— ğ‘šğ‘ğ‘¥ ( ğ‘¥ğ‘— , ğ‘¦ğ‘— ) for two real vectors ğ‘¥ , ğ‘¦ . We consider ğ¼ 1 , ğ¼ 2 to be similar if ğ½ ğ‘Š ( ğ¼ 1 , ğ¼ 2 ) > ğ‘¡ 2 for a threshold ğ‘¡ 2 âˆˆ [ 0 , 1 ] . To calculate ğ½ ğ‘Š ( ğ¼ 1 , ğ¼ 2 ) , the threshold ğ‘¡ 1 must be set in advance , as computing ingredientsâ€™ intersection or union expects knowing for every pair of ingredients ğ‘– 1 âˆˆ ğ¼ 1 , ğ‘– 2 âˆˆ ğ¼ 2 whether they are similar or not . We used Grid - Search on a dataset of 180 manually tagged ingredient list pairs to set values for these two hyperparameters ( within bounds : 0 - 1 ) , setting ğ‘¡ 1 = 0 . 35 , ğ‘¡ 2 = 0 . 325 . For instance , recall the example from the beginning of this sec - tion . The ingredients of the instructions ( 1 ) , ( 2 ) and ( 3 ) are respec - tively : ğ¼ 1 = { apples , sugar , cinnamon } , ğ¼ 2 = { apples , sugar , cinnamon , allspice , clove , nutmeg } , ğ¼ 3 = { flour , baking powder , cinnamon , clove , allspice , nutmeg } . Assuming apples appears 180 times in the multi - ple recipe set , flour 160 times , sugar 160 , cinnamon 140 , baking pow - der 90 , nutmeg 35 , clove 15 , and allspice 10 ; then , ğ½ ğ‘¤ ( ğ¼ 1 , ğ¼ 2 ) â‰ˆ 0 . 89 and ğ½ ğ‘Š ( ğ¼ 2 , ğ¼ 3 ) â‰ˆ 0 . 25 . That is , even though ğ¼ 2 and ğ¼ 3 share more ingredients in total , the similarity score of ğ¼ 1 and ğ¼ 2 is much higher as they share more frequent ingredients . 5 . 2 . 2 Training word2vec on recipes . After filtering pairs of instructions , taking advantage of the struc - tured output of the parser , we can use a word embedding model to compute similarities . We trained a CBOW variant of bigram word2vec model [ 39 ] of dimension 100 on recipe instructions , using Gensim [ 48 ] . As mentioned in Section 4 , in addition to the Allrecipes data , in this step we also included a large data set of recipes from â€œNow Youâ€™re Cooking ! â€ . Note that using the full instruction means that factors like instruments and time ranges are reflected in the embeddings . 5 . 2 . 3 The clustering method . We now define the similarity distance between two instructions that pass the filtering step ( share a similar verb and enough ingredi - ents ) to be the cosine distance between their instruction embeddings ( average of word embeddings ) . We define the distance between two instructions that do not pass the filtering step to be infinity . We chose hierarchical clustering with complete - linkage criterion , merging clusters to the point when only infinitely distant clusters were left . We chose the linkage and stop criteria after evaluating several criteria on three manually clustered dishes ( that were not used for the evaluation ) . Figure 1 shows a sample of instructions clustered together ( to the right of the â€œbeatâ€ node ) . We note that we also experimented with clustering with con - straints ( e . g . , forcing two instructions from the same recipe to be in separate clusters ; taking into account the instructionsâ€™ relative position in recipe ) . However , these approaches did not seem to improve the resulting clusters . 5 . 3 Constructing the summary graph We can now construct the summary graph ğº = ( ğ‘‰ , ğ¸ ) . For every cluster , we define a corresponding vertex with weight equals to the number of instructions in it . We also define source and target vertices START and END . We aim to connect vertices corresponding to subsequent actions . Hence , for every two vertices ğ‘£ ğ‘™ , ğ‘£ ğ‘˜ âˆˆ ğ‘‰ \ { START , END } , we con - sider ( ğ‘£ ğ‘™ , ğ‘£ ğ‘˜ ) âˆˆ ğ¸ if there exist recipes in which an instruction from ğ‘£ ğ‘˜ comes right after an instruction from ğ‘£ ğ‘™ . The edge weight ğ‘¤ ( ğ‘£ ğ‘™ , ğ‘£ ğ‘˜ ) is the number of such recipes . Similarly , for every vertex Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1308 ğ‘£ âˆˆ ğ‘‰ \ { START , END } we consider ( START , ğ‘£ ) âˆˆ ğ¸ ( or ( ğ‘£ , END ) âˆˆ ğ¸ ) if there are instructions in ğ‘£ that start ( or end ) a recipe . The edge weight is the number of such instructions . Pruning and noise reduction . The graph is often too large to visualize effectively . Thus , we prune small clusters and weak edges , as well as nodes and edges that do not belong to a path from START to END . We then choose up to 20 paths to be displayed to the user . Note that this pruning is only for visualization purposes , and the full graph is kept in memory . Pruned parts might be shown to the user as a part of the interaction ( e . g . , if they choose to explore a rare ingredient , light - weighted vertices and paths might be added back into the visualization ) . Ideally , we would have liked to display the 20 heaviest paths to the user . However , picking out the heaviest simple paths in a graph is an NP - hard problem . Thus , we resorted to a heuristic approach adapted from [ 20 ] . First , we invert the edge weights and search for K - shortest paths in terms of the edge weights ( with a K that is sufficiently bigger than the number of paths we finally display to the user ) . 10 As our edges are added locally , some short paths do not actually represent a full recipe ( e . g . , if there are parts of the recipe that could be carried out in a different order , this creates a cycle in the graph that can be shortcut ) . Thus , we filter out paths that are too short ( number of edges ) . This bound is set to be the minimal recipesâ€™ number of instructions after trimming 10 % of the smallest values . Finally , we rerank the remaining paths by normalizing their weights over their lengths . The highest 20 ranked paths are chosen to compose the graph displayed to the user . Importantly , noisy instructions are likely to either become small clusters and be pruned or join an existing , large cluster and have virtually no effect on its summary ( what the user sees ) . Building the graph for âˆ¼ 200 parsed recipes takes around 1 - 2 minutes on a personal computer . Visualization . We built a user interface using React . js showing the compact version of the summary graph ( refer again to Figure 1 ) . Dark nodes contain more instructions , and thick edges represent strong connections between the nodes . Every cluster is represented by the main verb and a summarization of the ingredients . Ingredi - ents are accompanied with relative frequency in the cluster ; clicking on node reveals quantity range ( normalized to the most frequent number of servings ) , tools and time range . The user can also choose to see the full list of instructions . Further actions include seeing lists of common and rare ingredients , tracking ingredients through a graph , and multi - faceted filtering . User interactions ( such as re - questing specific ingredients ) might result in uncovering paths that were hidden before , as they were not in the 20 chosen paths . 6 EVALUATION We now turn to evaluating our representation . We wished to answer three main questions : ( 1 ) Is the representation intuitive , ( 2 ) Is the representation coherent ( i . e . , do paths correspond to recipes ) , and ( 3 ) Is the representation useful . We recruited in total 50 participants , including 10 experts . Following the recommendation of [ 45 ] , we chose to run multiple tests with 11 - 20 users in each . This also had 10 As we wished to display 20 paths to the user , we set K to 60 . Measures # of scores Average Std ( 1 ) Node coherence 60 4 . 55 0 . 723 ( 2 ) Reasonable paths 40 3 . 825 1 . 196 ( 3 ) Graph comprehensibility ( 1st exp . ) 20 4 0 . 973 ( 3 * ) Graph comprehensibility ( 2nd exp . ) 20 3 . 85 0 . 72 Table 1 : Graphâ€™s clarity & coherence ( Likert scale , 1 - 5 ) . the benefit of being able to closely observe all the participants using the system . We randomly sampled a set of dishes from the most popular categories ( soup , salad , cake etc . ) , having at least 100 recipes each . For the experiments we sampled four dishes out of this set : two simple ones ( guacamole , omelette ) and two complex ones ( apple cake , spaghetti ) , judged by the average number of instructions . 6 . 1 Intuitiveness and coherence of representation We started by evaluating the intuitiveness and coherence of the summary graph . 20 student volunteers were recruited to this ex - periment . 11 participated in part I , and all participated in part II . Part I : Intuitiveness . We showed participants the UI for one of the four dishes without providing any explanation . We asked them to explain what nodes , edges and paths from START to END represent . Full , accurate response rates were 81 . 8 % , 90 . 9 % , 90 . 9 % ( nodes , edges , paths respectively ) . The others provided partially correct explana - tions . For example , one participant wrote that an edge represents â€œa transition between steps in the preparation of the recipe " , and a path represents â€œall steps in a recipe " , but described a node as â€œthe most common ingredients " , which we considered too vague . Thus , we conclude that the graph is indeed mostly intuitive . Part II : Coherence . In this part we provided the participants with a brief explanation of the UI . Our goal was to test the coherence of the representation ( Do nodes correspond to instructions ? Do paths correspond to recipes ? ) , once the participants understood the UI . Recipes and paths . Given a random recipe , we asked the partici - pants to mark a path on the graph that fits it best , achieving 75 % success rate . Afterwards , we asked for the opposite , writing a recipe corresponding to a random marked path , achieving 90 % success . When translating recipes to graphs , most failures were a result of the participants searching for a path that fitted the given recipe exactly ( although they were told to mark the one that fits it best ) . In translating graphs to recipes , one non - native English speaker participant failed to understand some of the instructions ; another wrote â€œgo over the nodes and perform the steps described in themâ€ but did not provide an explicit recipe . These results suggest it is relatively straightforward to translate between recipes and paths . Node and path coherence . We asked the participants to : ( 1 ) pick three nodes and rate the coherence of the instructions within them ; ( 2 ) follow two random marked paths and rate how much they represent a possible recipe . We also asked them to ( 3 ) rate the graph according to its comprehensibility . All ratings were in a Likert scale of 1 - 5 [ 33 ] . See Table 1 for results . Results are encouraging overall , with nodes rated as very coherent , paths rated as good , and the graph as comprehensible . Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1309 6 . 2 Utility to users After evaluating the representation , we turned to evaluate its utility to users . We recruited another 20 student volunteers who were randomly divided into two groups ( A and B ) , and asked them to rate their cooking level of expertise ( Likert scale , 1 - 5 . group A : mean level score was 3 . 5 , std = 0 . 92 . group B : mean = 3 . 6 , std = 0 . 8 ) . To the best of our knowledge , no benchmark exists for graphs that summarize many procedural texts . Thus , as a baseline we simulated what people are likely to use today â€“ recipe books and websites . In this condition , users received a searchable file that contained hundreds of recipes for the same dish . We focused on two dishes : guacamole ( easy ) and apple cake ( harder ) . Each user saw both dishes : Group A worked on the gua - camole dish first and group B on the apple cake first . For the first dish , users received a searchable file ( similar to cooking books and recipe websites ) ; in the second , they got the UI . For both dishes , we asked the users to perform the following two tasks : ( 1 ) Clarifying a recipe for a novice cook . We asked participants to add missing details that might not be trivial to a novice cook ( e . g . , add an important action such as cool - after - baking ; explain vague descriptions such as â€œal - denteâ€ , or specify an exact amount of salt instead of â€œto tasteâ€ ) , and replace unusual things with more common ones . ( 2 ) Adding a creative twist to spice up a recipe . We limited the time for completing each task to 8 minutes . In the clarifying task , to avoid the case participants know the answer from experience , we required references supporting their answers . After each task , the participants rated how hard it was for them , and were encouraged to share insights about the dish . At the end , they were asked to provide general feedback and , as in the experiment of Section 6 . 1 , to rank the graphâ€™s comprehensibility . For the first task ( clarifying ) , we selected recipes with common mistakes . 11 For the second ( adding a twist ) we picked the simplest recipe in the data , in terms of number of actions and ingredients . Participantsâ€™ insights and feedback . We were encouraged to find that participants identified almost twice more insights when using the graph ( 13 vs . 7 ) . Overall , feedback was very positive . Snippets include : â€œIt was such a relief using the summary graph after having to go over so many recipesâ€ , â€œThis graph is awesome ! â€ , â€œThe statistics information was very handy and accessible . I wish all my recipes were shown to me in such formâ€ . Negative feedback focused mostly on the UI , and not on the content of the graph itself . A note on fixation . While observing participants performing the tasks , we noticed that many baseline users fixated on one recipe ( often the first one on the list ) . As one user explained in their feedback , â€œI decided to focus on one recipe and base most of my modifications on it . The graph gave a more global view from which I could infer changes more easilyâ€ . Participantsâ€™ output . Verifying feasible outcomes : Since our edge creation method is local , we wanted to verify that the usage of the graph can still yield feasible outcomes . Thus , we asked three cooking experts to 11 https : / / tinyurl . com / guacamole - common - mistakes , https : / / tinyurl . com / cake - common - mistakes . Figure 4 : Two of the participantsâ€™ modified recipes after clarifying them for the novice cook with the support of the graph . For example , in the left modified recipe ( guacamole ) , the participant decided to mash the avocado with a fork in - stead of food processor . In the right modified recipe ( apple - cake ) , the participant realized that the greasing - the - pan ac - tion was missing and added it . rate the feasibility of all the experimentâ€™s outcomes on a Likert scale of 1 - 7 . We measured the mean score , resulting in 5 . 65 for the file ( std = 1 . 515 ) and 5 . 63 using the graph ( std = 1 . 461 ) . Thus , we conclude that using the graph does not change the feasibility of the usersâ€™ outcome . Clarifying for the novice cook : After collecting all the changes suggested by the participants ( see Figure 4 for examples of adjusted recipes ) , we recruited two cooking expert to annotate whether changes suggested by participants : ( 1 ) could really assist a novice cook , ( 2 ) could be crucial for the recipe to succeed . Our experts had good agreement â€“ for guacamole we mea - sured Cohenâ€™s Kappa = 0 . 661 [ 10 ] , accuracy = 0 . 867 ; for apple cake Kappa = 0 . 593 and accuracy = 0 . 806 . We took only changes chosen by both annotators as ground truth and counted how many were detected by each participant . For the more complex dish ( apple cake ) , participants performed significantly better using the graph ( the average number of changes without the graph was 1 . 9 , with the graph 3 . 7 , p - value = 1 . 06E - 05 ; critical changes : 1 . 4 without the graph , 3 . 1 with , p - value = 7 . 68E - 07 ; independent samples t - test ) . For the simpler dish ( guacamole ) there was only a slight advantage in favor of the graph . These results are compatible with our intuition that the graph can help more with complex recipes . We also tested whether the more experienced cooks ( 10 people ; cooking expertise 4 - 5 ) , being more aware of nuances , performed significantly better using the graph . It was indeed the case for both dishes ( 2 . 5 on average without the graph , 3 . 9 with , p - value = 0 . 014 ; critical changes : 1 . 1 without , 2 . 4 with , p - value = 0 . 0016 ; independent samples t - test ) . Adding a twist : To reduce individual bias , we collected the two groupsâ€™ unique ingredients ( i . e . , those appeared in one group and Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1310 Figure 5 : Percentages of times that unique graphâ€™s ingre - dients beat unique listâ€™s ingredients . Comparisons are com - puted within participant . not in other ) and compared them . For that , we asked five cooking experts to rank ( Likert scale , 1 - 5 ) each ingredient in terms of : ( 1 ) surprise ( how surprising it is for the dish ? ) and ( 2 ) tastiness ( how suitable it is in terms of taste ? ) . We then computed for every pair of ratings a creativity score , which we defined as the minimum of these ratings . Creativity is often defined as a combination of novelty and value [ 23 , 31 ] ; We chose the minimum since we wanted this score to reflect both the novelty ( surprise ) and the value ( tastiness ) . Likert scores are difficult to compare among different people . Thus , for each expert , we made pairwise comparisons between each two ingredients they rated , and computed the percentages of times an ingredient from one group beats ingredients from the other . The results are in Figure 5 . For the apple cake dish , the graphâ€™s in - gredients beat those of the file in all parameters . For the guacamole dish , graph ingredients won in terms of tastiness and creativity but not surprise . Looking closer at the results , we observed that baseline users often made ingredients up ( not basing them on a recipe ) , while graph users observed ingredients used in recipes and tried to generalize them ( e . g . , different salty snacks or different tropical fruit ) , which might explain these findings . Tables 2 and 3 show the winning unique ingredients in terms of creativity and their origin ( graph or baseline ) . Figure 6 shows a sample of four prepared guacamole dishes based on the graph users suggestions . A note on task difficulty . After each task , the participants rated its difficulty on a scale of 1 - 5 ( 1 stood for â€œpiece of cakeâ€ , 12 and 5 for â€œextremely difficultâ€ ) . Results are in Table 4 . Overall , the tasks where the user had access to the graph were rated as easier than those supported by the list ( baseline ) , but the effect was not large . The change was most pronounced in the clarifying and creativity tasks for the more complex dish ( both statistically significant , p - values = 0 . 023 , 0 . 048 ) . While preliminary , we believe these studies demonstrate the potential of the summary graph representation in helping people navigate ( and make sense of ) a large body of procedural texts . 7 RELATED WORK Our work is related to multiple lines of work . 12 No pun intended Rank Ingredient Total creativity score Origin 1 pretzel fragments 18 graph 2 parmesan cheese 17 graph 3 barbeque pringles 16 list - kidney bean 16 graph 5 soup nuts 15 graph - chicken breast 15 graph - cream cheese 15 graph 8 sour cream 14 list - balsamic vinegar 14 graph 10 bulgarian cheese 13 list Table 2 : The top - ten ranked ingredients in terms of creativ - ity for the guacamole dish . There were in total 25 ingredi - ents to compare after collecting the two groupâ€™s unique in - gredients , 9 came from the list and 16 from the graph . Rank Ingredient Total creativity score Origin 1 blueberries 19 graph - cherries 19 graph 3 cranberry juice 17 graph - wrapped caramels 17 list 5 coconut flour 15 graph 6 candied lemon 14 list - shredded coconut 14 graph - banana 14 graph 9 lotus spread 13 graph - carrots 13 graph Table 3 : The top - ten ranked ingredients in terms of creativ - ity for the apple - cake dish . There were in total 34 ingredi - ents to compare after collecting the two groupâ€™s unique in - gredients , 19 came from the list and 15 from the graph . Task Graph support ? Avg . Std Avg . Std Clarifying X 3 . 3 1 . 1 3 . 3 0 . 9 V 2 . 8 0 . 75 2 . 5 0 . 67 Adding a twist X 2 . 2 1 . 17 2 . 4 1 . 11 V 2 . 1 1 . 22 1 . 6 0 . 8 Table 4 : Difficulty level statistics per task with and without the graph support ( left : guacamole , right : apple cake ) . Sensemaking . Broadly speaking , the goals of our system align with these of the sensemaking domain . As described by D . M . Russel [ 50 ] , Sensemaking is the task of constructing a mental represen - tation of interrelated pieces of information relevant to answering task - specific questions , often in the context of understanding large document collections . In this paper , the interrelated pieces are a large collection of procedural texts sharing the same goal , and the aim is to help users understand them and easily explore com - monalities and differences in them . Sensemaking has been studied extensively in various fields , including HCI [ 27 , 50 ] , information science [ 14 , 25 , 28 ] , organizational science [ 61 ] and education [ 2 ] . As opposed to our work , much of the sensemaking work relies on crowdsourcing for aggregating and arranging the different pieces of information . Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1311 Figure 6 : Examples of participantsâ€™ creative guacamole dishes obtained with the support of the graph : ( A ) gua - camole with pretzel fragments , cherry tomatoes and green onion ; ( B ) guacamole with feta cheese and chives ; ( C ) gua - camole with mango , pineapple and corn ; ( D ) guacamole with chicken breast , red beans and jalapeno . Multi - document summarization . Our work is also related to multi - document summarization , and in particular to graph - based multi - document summarization approaches [ 3 , 18 , 20 , 24 , 38 , 63 ] . These works also represent document units as graphs , on which they apply graph - based ranking algorithms to generate a summary . However , the output is a text ( the summary ) and not a graph that allows users to explore commonalities and differences between the texts . We are also not aware of such methods applied to procedural texts . Procedural texts . Understanding procedural texts is the base of a substantial body of research within natural language understanding [ 4 , 5 , 12 , 13 , 36 , 42 , 52 , 56 ] . A prominent line of work suggests ways to transform natural language instructions into a graph structured representation [ 9 , 29 , 30 , 34 , 43 , 46 , 62 ] . These works use a graph to represent a single procedural text . In contrast , we summarize many procedural texts into a single graph . We believe our representation could aid users in performing sensemaking tasks such as modifying a given procedure to satisfy individual preferences or constraints . Cooking Recipes . Much research regarding procedural texts fo - cuses on cooking recipes [ 32 , 40 , 44 ] . Importantly , most work does not make changes to recipes , but instead focuses primarily on rec - ommending recipes from an existing pool [ 17 , 21 , 22 , 57 â€“ 60 ] . Re - cently , Majumder et al . [ 35 ] sought to combine work from recom - mender systems and text generation . However , their system gives the user only a little control over the text being produced . Perhaps the closest work to ours is a work by Chang et al . [ 8 ] , which assists cooking experts and culinary students in browsing and comparing hundreds of recipes via an interactive system . However , their use case is very different from ours , as their output summarizes only some of the aspects of recipes , providing a very different view of the landscape , meant for an audience of experts . We also note that the idea of aggregating recipes has been sug - gested before , sometimes jokingly , in popular culture . The book â€œCooking for Geeksâ€ [ 47 ] includes a recipe for the â€œAverage Internet Pancakesâ€ , noting that â€œNo oneâ€™s ever wrong on the Internet , so the average of a whole bunch of right things must be righter , right ? The quantities here are based on the average of the eight different pancake recipes from an online searchâ€ . The website ThePudding took this idea one step further , taking 200 chocolate chip cookie recipes and trying to generate the average cookie using a mathematical average , predictive text algorithms , and neural networks . 13 8 CONCLUSION AND FUTURE WORK The web is full of procedural texts , many of them sharing the same goal . When performing sensemaking tasks one needs to be able to view the bigger picture ; however , this is often time - consuming , requiring extensive browsing and comparisons . In this work we proposed a novel unsupervised learning ap - proach for which the input is a set of procedural texts sharing the same goal , and the output is an intuitive graph representation sum - marizing them , mapping the landscape of possibilities . We believe this representation could allow users to explore commonalities and differences between the various ways to carry out a task and devise a way to accomplish the task . We demonstrated our system on cooking recipes , a promiment example of procedural texts . We devised an unsupervised recipe parser , taking into account the unique structure of recipes , and proposed an algorithm for constructing the summarization graph . User studies showed that our representation is easy to work with and could help users with several sensemaking tasks , such as un - derstanding or modifying a recipe . In the future , we plan to apply the proposed approach to other domains . For example , many scientific areas use procedural texts ( material science , manufacturing medicine ) . Using a graph repre - sentation might help the scientist gain knowledge and insights into the process . Another exciting avenue is exploring the creativity - supporting aspects of the graph . We believe identifying anomalies in the graph could help surfacing creative options . Beyond the specific application in this paper , we envision a future where fully automated systems can digest a large set of procedural texts , answering queries and modifying the texts according to user needs and preferences . ACKNOWLEDGEMENTS We thank the anonymous reviewers for their insightful comments , Hyadata Lab members for thoughtful remarks , and the participants in our user studies . This work was supported by the European Research Council ( ERC ) under the European Unionâ€™s Horizon 2020 research and innovation programme ( grant no . 852686 , SIAM ) . 13 https : / / pudding . cool / 2018 / 05 / cookies / Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1312 REFERENCES [ 1 ] Aida Amini , Antoine Bosselut , Bhavana Dalvi Mishra , Yejin Choi , and Hannaneh Hajishirzi . 2020 . Proceduralreadingcomprehensionwithattribute - awarecontext flow . arXiv preprint arXiv : 2003 . 13878 ( 2020 ) . [ 2 ] Abraham Arcavi and Alan H Schoenfeld . 1992 . Mathematics tutoring through a constructivist lens : The challenges of sense - making . The Journal of Mathematical Behavior ( 1992 ) . [ 3 ] ElenaBaralis , LucaCagliero , NaeemMahoto , andAlessandroFiori . 2013 . GRAPH - SUM : Discovering correlations among multiple terms for graph - based summa - rization . Information Sciences 249 ( 2013 ) , 96 â€“ 109 . [ 4 ] Michael Beetz , Ulrich Klank , Ingo Kresse , Alexis Maldonado , Lorenz MÃ¶sen - lechner , Dejan Pangercic , Thomas RÃ¼hr , and Moritz Tenorth . 2011 . Robotic roommates making pancakes . In 2011 11th IEEE - RAS International Conference on Humanoid Robots . IEEE , 529 â€“ 536 . [ 5 ] Mario Bollini , Stefanie Tellex , Tyler Thompson , Nicholas Roy , and Daniela Rus . 2013 . Interpreting and executing recipes with a cooking robot . In Experimental Robotics . Springer , 481 â€“ 495 . [ 6 ] Antoine Bosselut , Omer Levy , Ari Holtzman , Corin Ennis , Dieter Fox , and Yejin Choi . 2017 . Simulating action dynamics with neural process networks . arXiv preprint arXiv : 1711 . 05313 ( 2017 ) . [ 7 ] Daniel Cer , Yinfei Yang , Sheng - yi Kong , Nan Hua , Nicole Limtiaco , Rhomni St John , Noah Constant , Mario Guajardo - Cespedes , Steve Yuan , Chris Tar , et al . 2018 . Universal sentence encoder . arXiv preprint arXiv : 1803 . 11175 ( 2018 ) . [ 8 ] Minsuk Chang , LÃ©onore V Guillain , Hyeungshik Jung , Vivian M Hare , Juho Kim , and Maneesh Agrawala . 2018 . Recipescape : An interactive tool for analyzing cooking instructions at scale . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . 1 â€“ 12 . [ 9 ] David L Chen and Raymond J Mooney . 2011 . Learning to interpret natural language navigation instructions from observations . In Twenty - Fifth AAAI Con - ference on Artificial Intelligence . [ 10 ] Jacob Cohen . 1960 . A coefficient of agreement for nominal scales . Educational and psychological measurement 20 , 1 ( 1960 ) , 37 â€“ 46 . [ 11 ] Alexis Conneau and Douwe Kiela . 2018 . Senteval : An evaluation toolkit for universal sentence representations . arXiv preprint arXiv : 1803 . 05449 ( 2018 ) . [ 12 ] Estelle Delpech et al . 2008 . Investigating the structure of procedural texts for answering how - to questions . [ 13 ] Estelle Delpech , Murguia Elizabeth , et al . 2007 . A Two - Level Strategy for Parsing Procedural Texts . [ 14 ] Brenda Dervin . 2003 . Human studies and user studies : a call for methodological inter - disciplinarity . Information Research 9 , 1 ( 2003 ) , 9 â€“ 1 . [ 15 ] Nirav Diwan , Devansh Batra , and Ganesh Bagler . 2020 . A named entity based approach to model recipes . In 2020 IEEE 36th International Conference on Data Engineering Workshops ( ICDEW ) . IEEE , 88 â€“ 93 . [ 16 ] Xinya Du , Bhavana Dalvi Mishra , Niket Tandon , Antoine Bosselut , Wen - tau Yih , Peter Clark , and Claire Cardie . 2019 . Be consistent ! improving procedural text comprehension using label consistency . arXiv preprint arXiv : 1906 . 08942 ( 2019 ) . [ 17 ] David Elsweiler , Christoph Trattner , and Morgan Harvey . 2017 . Exploiting food choice biases for healthier recipe recommendation . In Proceedings of the 40th international acm sigir conference on research and development in information retrieval . 575 â€“ 584 . [ 18 ] GÃ¼nesErkanandDragomirRRadev . 2004 . Lexrank : Graph - basedlexicalcentrality as salience in text summarization . Journal of artificial intelligence research 22 ( 2004 ) , 457 â€“ 479 . [ 19 ] Christiane Fellbaum . 2012 . WordNet . The encyclopedia of applied linguistics ( 2012 ) . [ 20 ] Katja Filippova . 2010 . Multi - sentence compression : Finding shortest paths in word graphs . In Proceedings of the 23rd international conference on computational linguistics ( Coling 2010 ) . 322 â€“ 330 . [ 21 ] Peter Forbes and Mu Zhu . 2011 . Content - boosted matrix factorization for recom - mender systems : experiments with recipe recommendation . In Proceedings of the fifth ACM conference on Recommender systems . 261 â€“ 264 . [ 22 ] Jill Freyne and Shlomo Berkovsky . 2010 . Intelligent food planning : personalized recipe recommendation . In Proceedings of the 15th international conference on Intelligent user interfaces . 321 â€“ 324 . [ 23 ] Berys Gaut . 2010 . The philosophy of creativity . Philosophy Compass 5 , 12 ( 2010 ) , 1034 â€“ 1046 . [ 24 ] George Giannakopoulos , George Kiomourtzis , and Vangelis Karkaletsis . 2014 . Newsum : â€œn - gram graphâ€ - based summarization in the real world . In Innovative Document Summarization Techniques : Revolutionizing Knowledge Understanding . IGI Global , 205 â€“ 230 . [ 25 ] Term L Griffith . 1999 . Technology features as triggers for sensemaking . Academy of Management review 24 , 3 ( 1999 ) , 472 â€“ 488 . [ 26 ] Aditya Gupta and Greg Durrett . 2019 . Tracking discrete and continuous entity state for process understanding . arXiv preprint arXiv : 1904 . 03518 ( 2019 ) . [ 27 ] NathanHahn , JosephChang , JiEunKim , andAniketKittur . 2016 . TheKnowledge Accelerator : Big picture thinking in small pieces . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems . 2258 â€“ 2270 . [ 28 ] Erling Havn et al . 2006 . Sensemaking in technology - use mediation : Adapting groupware technology in organizations . Computer Supported Cooperative Work ( CSCW ) 15 , 1 ( 2006 ) , 55 â€“ 91 . [ 29 ] Shihono Karikome , Noriko Kando , and Tetsuji Satoh . 2018 . Flow Graph Gen - eration Method for Visualizing Procedural Texts . In Proceedings of the 20th In - ternational Conference on Information Integration and Web - based Applications & Services . 360 â€“ 364 . [ 30 ] ChloÃ© Kiddon , Ganesa Thandavam Ponnuraj , Luke Zettlemoyer , and Yejin Choi . 2015 . Mise en place : Unsupervised interpretation of instructional recipes . In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing . 982 â€“ 992 . [ 31 ] Carolyn Lamb , Daniel G Brown , and Charles LA Clarke . 2018 . Evaluating compu - tational creativity : An interdisciplinary tutorial . ACM Computing Surveys ( CSUR ) 51 , 2 ( 2018 ) , 1 â€“ 34 . [ 32 ] Shuyang Li and Julian McAuley . 2020 . Recipes for Success : Data Science in the Home Kitchen . Harvard Data Science Review 2 . 3 ( 2020 ) . [ 33 ] Rensis Likert . 1932 . A technique for the measurement of attitudes . Archives of psychology ( 1932 ) . [ 34 ] Hirokuni Maeta , Tetsuro Sasada , and Shinsuke Mori . 2015 . A framework for procedural text understanding . In Proceedings of the 14th International Conference on Parsing Technologies . 50 â€“ 60 . [ 35 ] Bodhisattwa Prasad Majumder , Shuyang Li , Jianmo Ni , and Julian McAuley . 2019 . Generating personalized recipes from historical user preferences . arXiv preprint arXiv : 1909 . 00105 ( 2019 ) . [ 36 ] Jonathan Malmaud , Earl Wagner , Nancy Chang , and Kevin Murphy . 2014 . Cook - ing with semantics . In Proceedings of the ACL 2014 Workshop on Semantic Parsing . 33 â€“ 38 . [ 37 ] Christopher D . Manning , Mihai Surdeanu , John Bauer , Jenny Finkel , Prismatic Inc , Steven J . Bethard , and David Mcclosky . 2014 . The Stanford CoreNLP natural language processing toolkit . In In ACL , System Demonstrations . [ 38 ] Rada Mihalcea and Paul Tarau . 2004 . Textrank : Bringing order into text . In Pro - ceedingsofthe2004conferenceonempiricalmethodsinnaturallanguageprocessing . 404 â€“ 411 . [ 39 ] Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Jeff Dean . 2013 . Distributed representations of words and phrases and their compositionality . In Advances in neural information processing systems . 3111 â€“ 3119 . [ 40 ] Weiqing Min , Shuqiang Jiang , Linhu Liu , Yong Rui , and Ramesh Jain . 2019 . A survey on food computing . ACM Computing Surveys ( CSUR ) 52 , 5 ( 2019 ) , 1 â€“ 36 . [ 41 ] Bhavana Dalvi Mishra , Lifu Huang , Niket Tandon , Wen - tau Yih , and Peter Clark . 2018 . Tracking state changes in procedural text : a challenge dataset and models for process paragraph comprehension . arXiv preprint arXiv : 1805 . 06975 ( 2018 ) . [ 42 ] Dipendra K Misra , Jaeyong Sung , Kevin Lee , and Ashutosh Saxena . 2016 . Tell me dave : Context - sensitive grounding of natural language to manipulation instruc - tions . The International Journal of Robotics Research 35 , 1 - 3 ( 2016 ) , 281 â€“ 300 . [ 43 ] Shinsuke Mori , Hirokuni Maeta , Yoko Yamakata , and Tetsuro Sasada . 2014 . Flow Graph Corpus from Recipe Texts . . In LREC . 2370 â€“ 2377 . [ 44 ] Dena F Mujtaba and Nihar R Mahapatra . 2020 . Towards Natural Language Understanding of Procedural Text Using Recipes . In Progress in Computing , Analytics and Networking . Springer , 359 â€“ 367 . [ 45 ] Jakob Nielsen and Thomas K Landauer . 1993 . A mathematical model of the finding of usability problems . In Proceedings of the INTERACTâ€™93 and CHIâ€™93 conference on Human factors in computing systems . 206 â€“ 213 . [ 46 ] Gustavo Patow . 2010 . User - friendly graph editing for procedural modeling of buildings . IEEE Computer Graphics and Applications 32 , 2 ( 2010 ) , 66 â€“ 75 . [ 47 ] Jeff Potter . 2010 . cooking for geeks . Oâ€™Reilly Media , Incorporated . [ 48 ] Radim Rehurek , Petr Sojka , et al . 2011 . Gensimâ€”statistical semantics in python . Retrieved from genism . org ( 2011 ) . [ 49 ] Nils Reimers and Iryna Gurevych . 2019 . Sentence - bert : Sentence embeddings using siamese bert - networks . arXiv preprint arXiv : 1908 . 10084 ( 2019 ) . [ 50 ] Daniel M Russell , Mark J Stefik , Peter Pirolli , and Stuart K Card . 1993 . The cost structure of sensemaking . In Proceedings of the INTERACTâ€™93 and CHIâ€™93 conference on Human factors in computing systems . 269 â€“ 276 . [ 51 ] Roy Schwartz , Roi Reichart , and Ari Rappoport . 2016 . Symmetric patterns and coordinations : Fast and enhanced representations of verbs and adjectives . In Proceedingsofthe2016ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics : Human Language Technologies . 499 â€“ 505 . [ 52 ] Mohit Shridhar , Jesse Thomason , Daniel Gordon , Yonatan Bisk , Winson Han , Roozbeh Mottaghi , Luke Zettlemoyer , and Dieter Fox . 2020 . Alfred : A benchmark for interpreting grounded instructions for everyday tasks . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition . 10740 â€“ 10749 . [ 53 ] Gabriel Stanovsky , Julian Michael , Luke Zettlemoyer , and Ido Dagan . 2018 . Su - pervised open information extraction . In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) . 885 â€“ 895 . [ 54 ] Milan Straka and Jana StrakovÃ¡ . 2017 . Tokenizing , pos tagging , lemmatizing and parsing ud 2 . 0 with udpipe . In Proceedings of the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies . 88 â€“ 99 . Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1313 [ 55 ] Niket Tandon , Bhavana Dalvi Mishra , Joel Grus , Wentau Yih , Antoine Bosselut , and Peter Clark . 2018 . Reasoning about actions and state changes by injecting commonsense knowledge . EMNLPâ€™18 . arXiv preprint arXiv : 1808 . 10012 ( 2018 ) . [ 56 ] Dan Tasse and Noah A Smith . 2008 . SOUR CREAM : Toward semantic processing of recipes . Carnegie Mellon University , Pittsburgh , Tech . Rep . CMU - LTI - 08 - 005 ( 2008 ) . [ 57 ] Chun - Yuen Teng , Yu - Ru Lin , and Lada A Adamic . 2012 . Recipe recommendation using ingredient networks . In Proceedings of the 4th Annual ACM Web Science Conference . 298 â€“ 307 . [ 58 ] Thomas Theodoridis , Vassilios Solachidis , Kosmas Dimitropoulos , Lazaros Gymnopoulos , and Petros Daras . 2019 . A survey on AI nutrition recommender systems . In Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments . 540 â€“ 546 . [ 59 ] Christoph Trattner and David Elsweiler . 2017 . Food recommender systems : importantcontributions , challengesandfutureresearchdirections . arXivpreprint arXiv : 1711 . 02760 ( 2017 ) . [ 60 ] Mayumi Ueda , Syungo Asanuma , Yusuke Miyawaki , and Shinsuke Nakajima . 2014 . Recipe recommendation method by considering the users preference and ingredient quantity of target recipe . In Proceedings of the International MultiCon - ference of Engineers and Computer Scientists , Vol . 1 . 12 â€“ 14 . [ 61 ] Karl E Weick . 1995 . Sensemaking in organizations . Vol . 3 . Sage . [ 62 ] Yoko Yamakata , Shinji Imahori , Hirokuni Maeta , and Shinsuke Mori . 2016 . A methodforextractingmajorworkflowcomposedofingredients , tools , andactions fromcookingproceduraltext . In 2016IEEEInternationalConferenceonMultimedia & Expo Workshops ( ICMEW ) . IEEE , 1 â€“ 6 . [ 63 ] Jinming Zhao , Ming Liu , Longxiang Gao , Yuan Jin , Lan Du , He Zhao , He Zhang , and Gholamreza Haffari . 2020 . SummPip : Unsupervised Multi - Document Sum - marization with Sentence Graph Compression . In Proceedings of the 43rd In - ternational ACM SIGIR Conference on Research and Development in Information Retrieval . 1949 â€“ 1952 . Full Paper Track CIKM â€™21 , November 1 â€“ 5 , 2021 , Virtual Event , Australia 1314