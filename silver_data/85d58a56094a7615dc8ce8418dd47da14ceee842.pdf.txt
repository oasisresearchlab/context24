Anywhere & Everywhere : A Mobile , Immersive , and Ubiquitous Vision for Data Analytics Niklas Elmqvist Aarhus University , Aarhus , Denmark September 2023 Abstract Data is collected everywhere in our increasingly instru - mented world and people are increasingly wanting to access this data from anywhere in it . This kind of anywhere & ev - erywhere data present new challenges and opportunities for data - driven sensemaking and decision - making that will re - quire leveraging novel mobile , immersive , and ubiquitous technologies undergirded by recent advances in human cog - nition . In this paper , we examine these emerging forms of analytics that are transforming how data analysis will be con - ducted in the future : in an ecosystem of connected devices , interactive visualizations , and collaborating users with vast amounts of data and analytical mechanisms available at their fingertips . Keywords : Ubiquitous analytics , ubiquitous computing , physical computing , immersive analytics , virtual environ - ments , data science . 1 Introduction Data is now collected everywhere and can be accessed any - where . Whether you are deciding which product to buy , which potential customer to visit , or just which lunch place to frequent , many situations in our everyday personal and pro - fessional lives benefit from access to relevant , accurate , and actionable data . Such access support awareness , promote un - derstanding , and help us make the right decisions in today’s complex information society . This anywhere data access is made possible by an increasing amount of everywhere data that is collected from virtually all aspects of our physical and digital world [ 27 ] : shopping lists and purchase histo - ries ; movie , music , and book preferences ; electronic health records and medical test results ; colleague , friend , and fam - ily relationships ; professional experience and education , and so on . While significant privacy , security , and safety con - cerns are intrinsic to this confluence of anywhere and every - where data , there is today also an unprecedented opportunity to use this data to support individuals in navigating the com - plexities of their professional and personal lives . Fortunately , the last 20 years of the mobile revolution has given us the means to achieve this ; mobile computing is now the domi - nant computing platform on the planet , with more than 15 billion mobile devices in existence in 2020 1 and more than 6 billion of them being “smart” and able to access the internet . 2 However , these devices—for all their mobility—currently are mere portholes into the digital world , are rarely designed to work together effectively to support one user , let alone mul - tiple ones , and lack the powerful analytical tools needed to enable data - driven decision - making on the go . Fortunately , this may be about to change , with mobile and ubiquitous computing [ 46 ] as well as extended reality ( XR ) [ 44 ] finally beginning to transform the fields of visual - ization and data science . Applying these technologies to data analysis suggests a future of ubiquitous [ 24 ] and immersive analytics [ 40 ] where clusters of networked mobile devices form an ecosystem for data analytics that can be accessed anytime and anywhere . Such a vision of mobile , immersive , and ubiquitous sensemaking environments would blend state - of - the - art analytics methods with our physical reality to en - able making sense of any kind of data in virtually any situa - tion . However , we shouldn’t be weaving computation into our everyday lives just because we can . Rather , progress in cog - nitive science [ 17 , 35 , 42 ] supports leveraging the new gener - ation of mobile , immersive , and ubiquitous technologies to - wards data analytics . These so - called post - cognitive frame - works suggest that human thought is not contained merely within our heads , but encompasses the entire ecosystem [ 39 ] of other people , physical artifacts in our surroundings , and our very own bodies . Distributing computational nodes into our physical surroundings will thus enable us to better scaf - fold analytical reasoning , creativity , and decision making . In this paper , we will investigate how the prevalence of col - 1 https : / / www . statista . com / statistics / 245501 / multiple - mobile - device - ownership - worldwide / 2 https : / / www . statista . com / statistics / 330695 / number - of - smartphone - users - worldwide / 1 a r X i v : 2310 . 00768v1 [ c s . H C ] 1 O c t 2023 PrimaryDisplay Secondary Displays ( a ) Anywhere and everywhere data scenario . ( b ) Ubiquitous analytics using Augmented Reality . Figure 1 : Mobile , immersive , and ubiquitous sensemaking . Two examples of data analytics conducted in a sensemaking environment of connected devices , interactive visualizations , and multiple collaborators . DATA WORLD collection access Everywhere Data Anywhere Data Figure 2 : Anywhere and everywhere data . Today data is collected from everywhere and is increasingly being accessed from anywhere . lected everywhere data can enable leveraging it for anywhere and anytime access . To achieve this , we will first explore the concepts of anywhere and everywhere data , and see how current technologies can ( and cannot ) support cognition in these ubiquitous computing environments . We will also re - view current research in ubiquitous and immersive analytics that build toward this vision . Finally , we synthesize the cur - rent research challenges facing the scientific community and describe the outlook for future research on the topic . 2 Anywhere & Everywhere Data The “third wave” of computing—ubiquitous computing— envisioned by Mark Weiser and Xerox PARC in the late 1980s [ 46 ] is essentially here , even if it looks subtly differ - ent from their original vision [ 22 ] . Instead of talking alarm clocks , we have voice - driven home assistants ; instead of cheap and disposable computational “tabs , ” we have smart - phones that we bring everywhere we go ; instead of an inter - active liveboard in every office , we have Zoom and Google Meet videoconferences at our beck and call . Nevertheless , with billions of mobile devices in existence in the world today—many of them smart—and a burgeoning Internet of Things making increasing inroads into our physical reality , it is safe to say that we are rapidly approaching a world where computing has indeed been woven into everyday life . The critical difference is that , unlike in the original vision of ubiq - uitous computing , the implementation has been more about personal devices than shared infrastructure—what Harrison et al . [ 31 ] call quality rather than quantity computing . Regardless , this quiet ubiquitous and mobile computing revolution has had two very specific outcomes relevant to data analytics ( Figure 2 ) : the emergence of ( 1 ) everywhere and ( 2 ) anywhere data . For the former , it has led to digital data being collected across all of our society and in virtu - ally all walks of life , both in the real world and online . The Internet of Things encompasses a wide and growing array of devices , such as webcams and security cameras , smart thermostats and light bulbs , digital weather stations , pollu - tion and air quality sensors , smart locks , connected home appliances , etc . These devices are also increasingly be - coming entwined into professional settings , such as for con - nected healthcare devices and monitors , autonomous farm - ing equipment , wireless inventory trackers , biometric secu - rity scanners , wireless sensor networks , and unmanned mili - tary equipment . Common for all of the datasets collected by these devices is that they are local , temporal , and contextual : • Local : connected to a specific geographic or seman - tic location ( e . g . , the temperature on top of the Eiffel tower ) ; • Temporal : associated with a point in time or a temporal pattern ( e . g . , the temperature on May 1 ) ; and • Contextual : related to a specific situation , and thus best interpreted in that context ( e . g . , a car engine’s tempera - ture when traveling at 60 miles per hour ) . The situation is slightly different for data collected online , as there may be no geographical location associated with the data . Furthermore , in many cases , even data collected from the real world is stored in databases where these local , tempo - ral , and contextual aspects are discarded or aggregated . For 2 example , the thousands of webcams located around the world that merely show video to whoever happens to tune in repre - sent a lost opportunity ; what if we instead continuously ran privacy - preserving image analysis algorithms on this footage to capture environmental data such as wind speed , people density , snow accumulation , beach erosion , or road traffic ? Nevertheless , it is safe to say that virtually everything that we do online is tracked and recorded , a tasks that is only made easier by the fact that in the digital world , instrumentation is trivial . The second outcome from the mobile computing revolu - tion is that technology advances has instilled in users a desire to be able to access this data anytime and anywhere . Many people are accustomed to enjoying near - constant connectiv - ity with the internet and all of its trappings , from social me - dia and video streaming to email and instant messaging . The step to expecting the same anywhere data access even for analytics and sensemaking tasks is not far . However , while current devices certainly are capable of accessing , managing , and storing these datasets , input and output technology has only recently reached a level where such sensemaking can be conducted . But how should we go about doing so effectively ? Post - Cognitive Frameworks Traditional cognitive science views the individual hu - man as a fundamental unit of cognition , with a basic workflow consisting of perception to understand your surroundings , cognition within the mind , and physical action to manipulate the surrounding environment . It follows that in traditional cognitive science , the mind maintains a model of the world , and the senses are used to continuously update this model . Such a model is called solipsism , and holds that you can only be sure about your own mind and not the external world ; in essence , you could replace the world with simulated sen - sor input and muscle output—as in the movie The Matrix ( 1999 ) —and you would be none the wiser . However , the last few decades of research have slowly chipped away at this solipsistic view of the mind . For example , post - it notes , notebooks , and smartphones trivially extend our memory [ 17 ] . Discussions with other people facilitate thinking and their abilities complement ours , forming a socially distributed cognitive system [ 35 ] . Kirsh and Maglio [ 2 ] found evidence that expert Tetris players per - form costly geometric rotation in the world rather in their minds . In other words , cognition is essentially a product of an individual’s interaction with their environ - ment rather than a closed system inside the individual’s mind [ 39 ] . Frameworks that go beyond the classic human in - formation processing model are called post - cognitive frameworks . We will discuss three particular ones here , all of which have useful properties that we draw upon in this paper . However , we note that these frameworks , as well as cognitive science as a whole , is still very much a work in progress and thus—to bastardize a phrase by statistician George E . P . Box—that they may all be incor - rect to some degree , but some may still be useful . • Extended cognition : The unofficial motto of Clark and Chalmers’ extended cognition frame - work is that “Cognitive processes ain’t ( all ) in the head ! ” [ 17 , p . 8 ] , arguing that the surrounding en - vironment is a fundamental component of all hu - man cognition—that , in fact , we’re all effectively cyborgs , but in the most natural way in symbiosis with our environment . • Socially distributed cognition : Developed by UCSD cognitive psychologist Ed Hutchins [ 35 ] in the 1980s and 90s , socially distributed cognition ( DCog ) holds that human cognition is distributed across sociocultural systems in the individual’s sur - roundings , which includes physical artifacts , other individuals , and cultural systems ( history , practice , etiquette , etc ) . • Embodied cognition : The basic tenet of embodied cognition is that thinking is fundamentally influ - enced by and inseparable from our own bodies [ 42 ] . These ideas have been fundamental to the areas of embodied and tangible interaction in HCI [ 1 ] . Beyond these three , we also note Scaife and Roger’s concept of external cognition [ 3 ] in support of graphical representations , which , even if it does not quite reach the level of a framework , discusses how visualization helps cognition by offloading computation and memory , re - representing data in a more suitable form , and graph - ically constraining inferences . Additional References [ 1 ] Paul Dourish . 2001 . Where the Action Is : The Foun - dations of Embodied Interaction . MIT Press , Cam - bridge , MA , USA . [ 2 ] David Kirsh and Paul Maglio . 1994 . On Distin - guishing Epistemic from Pragmatic Action . Cog - 3 nitive Science 18 , 4 ( 1994 ) , 513 – 549 . https : / / doi . org / 10 . 1207 / s15516709cog1804 _ 1 [ 3 ] Michael Scaife and Yvonne Rogers . 1996 . External cognition : how do graphical representations work ? International Journal of Human - Computer Studies 45 , 2 ( 1996 ) , 185 – 213 . https : / / doi . org / 10 . 1006 / ijhc . 1996 . 0048 3 The Cognitive Case Advances in cognitive science summarized as so - called post - cognitive frameworks —such as embodied [ 42 ] , ex - tended [ 17 ] , distributed cognition [ 35 ] ( see sidebar ) —suggest that human thinking is a system - level process [ 39 ] not merely contained within our brains , but which expands to also in - clude the world around us , the physical artifacts in our vicin - ity , our own bodies , as well as other people . In a post - cognitive framework , cognition is represented as information being transformed from one media to another through inter - actions , such as a person using a pen to write a reminder on a post - it note , placing the note on a refrigerator , and then read - ing the reminder at a later date and acting upon it . In other words , tools do not amplify our mind , but instead transform certain cognitive activities—such as remembering long num - ber sequences—into other , less taxing cognitive activities— such as reading . Analogously , a visual representation of data on a digital screen is another form of media that a person can interact with in order to view , manipulate , and understand the underlying data—but so is the notepad the person uses to jot down notes , the phone through which they speak to a col - league , and the calculator they employ for quick arithmetic . Effectively supporting sensemaking thus means instru - menting the entire ecosystem of artifacts involved in the cognitive process . This is in contrast to traditional human - computer interaction ( HCI ) and visualization paradigms , which tend to consider only the actual interface between user and machine : the visual output from the screen , and the user input from the mouse , keyboard , touchscreen , or microphone . By distributing interactive representations of data on a mul - titude of digital devices scattered around our physical sur - roundings as well as with the collaborators involved in the cognitive system , we are for all intents and purposes creating a cybernetic extension of the mind , expanding it using these digital devices . This notion would have been revolutionary if not for the fact that we have already been doing this for thou - sands of years ever since the first human picked up the first fallen branch and used it to dig a hole in the dirt . Just like a shovel is a cybernetic extension of a person’s arms to enable them to dig better , and an excavator takes this concept of hu - man extension even further , so a computer can be seen as a cybernetic extension of our logic , reasoning , and memory— or , as Steve Jobs famously puts it , a “bicycle for the mind . ” Nevertheless , from the digging example , it is clear that the type of tool makes a big difference , and even if digging may be a solved problem , the same cannot be said of sensemaking . Of course , the argument here is not that the more devices we weave into our everyday environment , the more effective the cognitive process . As Harrison et al . [ 31 ] point out with their quality vs . quantity computing argument , human atten - tion is a scarce commodity , and the current focus on a sin - gle , highly - capable personal device seems to have won out over the “one user to many devices” ubicomp vision from the 1990s . However , there clearly exists a middle ground between a single device per person and dozens . In addi - tion , nothing says that the devices have to be homogeneous ; it may be difficult to use two tablets at the same time , but a tablet and a smartwatch can be complementary . For one thing , data analysts do not only use computers but tend to sur - round themselves with pen and paper , calculators , reference material , books , and other physical artifacts , not to mention other analysts [ 39 ] . For another , physical space is a key factor in the data analysis process ; Wright et al . [ 48 ] describe how some professional intelligence analysts would use the entire floor of their office to arrange documents during analysis , and Andrews and North conducted empirical studies demonstrat - ing the utility of significant visual space in facilitating sense - making [ 7 ] . In fact , the intelligent use of space as part of cognition is a cornerstone of post - cognitive frameworks [ 37 ] , simplifying choice , facilitating perception , and aiding com - putation . Furthermore , proxemics —hailed by some as the new ubicomp [ 29 ] —tells us how people relate physically to artifacts and other people as they interact with them ; for ex - ample , we typically turn to face people we speak to . These are all prime arguments in favor of instrumenting all of the components involved in the cognitive process—ranging from notepads , books , and other people—using networked digital devices . Drawing from all three of the ubiquitous computing , visual computing , and visual analytics traditions , we call this approach ubiquitous analytics [ 24 ] . 4 The Gap in Our Tech If cognitive science supports the use of these networked groups of devices to facilitate sensemaking , how come we have not yet seen a plethora of such ubiquitous analytics sys - tems on the market and in the scientific literature ? The an - swer is that until only recently , the technology required to harness such anywhere and everywhere data has been out - side our reach . More specifically , the gaps in our technology include the screen size , the input surfaces , and the general design of the mobile devices we need for this endeavor . 4 Both screen size and input surfaces suffer from a device miniaturization tradeoff , where mobile devices already max - imize the input and output dimensions to encompass the full size of the device itself . They simply cannot be made much larger to avoid diminishing the mobility and portability of a smartwatch , tablet , or smartphone . One solution for both in - put and output is to go beyond the device itself to appropriate the physical world as part of the interaction [ 30 ] . For ex - ample , portable projectors can turn any nearby surface into a display of arbitrary size [ 21 ] . Depth cameras , ultrasound , or electrical sensing can similarly transform walls , tables , or even our very own bodies into touch surfaces . The rise of consumer - level mixed and augmented reality [ 44 ] equipment has taken this idea even further by turning our entire world into a potential canvas for data display and manipulation . In - stead of our smartphones being mere portholes into an unseen world of data , XR technology has broken down the fourth wall hemming us in . A hurdle remains , however : current mobile devices are still designed using the “quality computing” mindset . This means that each individual device is intended to be used in isolation and with the undivided attention of the user . A significant gap for mobile computing is to derive new design paradigms where multiple devices can stack together and scaffold each other for the current task while minimizing barriers and te - dious housekeeping . We will demonstrate some examples of how to design such stacking devices in the treatment to come . Sensemaking & Visualization Sensemaking is the activity of searching for a represen - tational schema to fit available data [ 4 , 5 ] ( e . g . , a mental model ) , allowing people to attribute meaning to avail - able data and answer questions about it . In terms of the cognitive foundations discussed earlier in this paper , this activity often involves a combination of internal and external cognitive representations , such as data tables , charts , notes , sketches , and calculations . These repre - sentations should ideally be chosen to facilitate men - tal activities required ( memory , computation , planning ) , thereby minimizing the cost structure [ 5 ] of cognition . Data visualizations have long been used for commu - nicating insights because of their accessible and visual form . However , visualizations are also effective for providing data - driven overviews , generating hypothe - ses , and answering questions at little cognitive cost . This makes visualization particularly suitable for sense - making , where exploring the data for meaning and hy - potheses is a significant part . Such exploratory data analysis [ 6 ] represents an alternative to more traditional hypothesis - driven confirmatory data analysis . Additional References [ 4 ] G . Klein , B . Moon , and R . R . Hoffman . 2006 . Making Sense of Sensemaking 1 : Alternative Per - spectives . IEEE Intelligent Systems 21 , 4 ( 2006 ) , 70 – 73 . https : / / doi . org / 10 . 1109 / MIS . 2006 . 75 [ 5 ] Daniel M . Russell , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . The Cost Structure of Sense - making . In Proceedings of the ACM Conference on Human Factors in Computing Systems . ACM , New York , NY , USA , 269 – 276 . https : / / doi . org / 10 . 1145 / 169059 . 169209 [ 6 ] John W . Tukey . 1977 . Exploratory Data Analysis . Addison - Wesley , Boston , MA , USA . 5 Ubiquitous , Immersive & Situated Analytics While command - line tools , automated scripts , and libraries are common in general data science tasks such as computa - tion , wrangling , and confirmatory analysis [ 15 ] , the kind of exploratory data analysis common to sensemaking ( see side - bar ) often benefits from a more fluid and visual interaction model . This is particularly true in mobile settings , where the precise text entry required for programming and command - line interfaces remains challenging on handheld devices . In such situations , it is more convenient to turn to interactive vi - sual interfaces and automated recommendations . The scien - tific field of data visualization concerns itself with precisely these visual and interactive data displays . In fact , the field has recently undergone a dramatic change with the rise of ubiqui - tous [ 24 ] , immersive [ 26 , 40 ] , and situated analytics [ 25 ] for tackling these use - cases . Three - dimensional visual representations have long been the norm in many scientific applications for visualization , such as flow visualization , medical imaging , and volumetric rendering . However , the very first applications of data vi - sualization to immersive settings actually came from outside the visualization field . In 2003 , Bowman et al . [ 12 ] proposed a research agenda for so - called information - rich virtual en - vironments ( IRVEs ) that combined 3D Virtual Reality with information visualization . Touch - enabled tabletops were an early platform , with Spindler and Dachselt [ 45 ] proposing a tangible lens for interacting with data on or above a horizon - 5 tal display . Finally , visualization made inroads into mobile computing in a much more unobtrusive manner , with the first applications being commercial ones on smartphones . Lee et al . [ 38 ] review mobile data visualization in a recent book on the topic . Starting in 2011 , I joined this research area by propos - ing the notion of an embodied form of human - data interac - tion [ 23 ] . This launched my research agenda on this topic , and my students and I followed this up with an embodied lens used for exploring data on a touch - based tabletop [ 36 ] . It eventually led to Pourang Irani and I defining the ubiqui - tous analytics [ 24 ] paradigm in 2013 , which serves as an um - brella term for the research field : anytime , anywhere sense - making performed on a plethora of networked digital devices , not just immersive ones . My students and I also proposed several computing infrastructures for realizing this vision for data analytics , including Munin ( a peer - to - peer middleware based on Java ) [ 10 ] , PolyChrome ( which was the first web - based framework ) [ 9 ] , and Vistrates ( a mature web replica - tion framework for component - based visualization author - ing ) [ 11 ] . Researchers have since taken our ideas further ; for example , ImAxes [ 19 ] enables data analysis in Virtual Real - ity using powerful hand gestures for connecting dimensional axes in 3D . Another early example was Butscher et al . ’s work combining parallel coordinates display in augmented reality on top of a tabletop display [ 14 ] . Along the way , several variations of these ubiquitous forms of analytics have emerged . Immersive analytics , initially in - troduced by Chandler et al . [ 16 ] in 2015 , take a specific focus on immersive and 3D spatial technologies to support sense - making [ 40 ] . Situated analytics [ 25 ] , on the other hand , em - phasizes the spatial referents for data in the real world . Willet et al . [ 47 ] built on this in 2017 for embedded data representa - tions that are deeply integrated with the spaces , objects , and contexts to which the data refers . Given the one - to - many ratio of users to devices in tradi - tional ubicomp , cardinality is a common denominator also for ubiquitous analytics . In the below subsections , we discuss cardinality from three different perspectives and give specific examples for each : multiple devices , multiple resources , and multiple collaborators . Devices Now and in the Future : In this vision of an in - creasingly ubiquitous and mobile future , the traditional view of a “device” as a physical artifact with computa - tion , storage , memory , display , and input is being chal - lenged . Some such physical devices will surely remain , but in other ways , devices will recede into the back - ground or be replaced by a single mixed / augmented re - ality display . Figure 3 : Two users collaborating using the David and Goliath system . The woman on the left is interacting with the large touch display ( “Goliath” ) , which is—by its size and orientation—a public and shared surface . The man on the right is interacting with his smartwatch ( “David” ) , which is used for personal storage and private data manipulation . 5 . 1 Multiple Devices The first factor worth investigating in a ubiquitous approach to analytics is how to best manage the multiple types of de - vices that a user will engage with during sensemaking . As already mentioned , human attention is a finite resource that must be managed judiciously . Current device platforms are typically designed for focused use ; for example , a smart - phone engages the user’s hand , often the dominant one , so adding a second smartphone is seldom helpful . Rather , adding multiple devices to an interaction should be comple - mentary , either by physical form factor ( e . g . , a smartwatch or a large display ) , by physical placement ( e . g . , hand - held , wall - mounted , or head - mounted ) , by task ( e . g . , a primary display used for map navigation and secondary ones to show legends and drill - down details ) , or by combinations of these . Users are rarely helped by two identical devices inhabiting the same position in this design space , except possibly for comparison tasks where holding two tablets side by side may be benefi - cial . We studied this phenomenon in a research paper from 2018 on the interplay between smartwatches and large touch dis - plays [ 32 ] that we informally dubbed “David & Goliath . ” The form factor of these two different computing platforms are radically different : a smartwatch is a fundamentally personal device , whereas a large display is a fundamentally public one . Smartwatches have small displays , are attached to a person’s wrist and are thus always within reach , and are only really accessible—both in terms of physical reach as well as social practices—to the wearers themselves . Any action performed and any data displayed on a smartwatch will accordingly be personalized . In contrast , a large touch display is often ver - tically mounted on a wall , is visible to many by virtue of its 6 Figure 4 : Hybrid interfaces in ReLive . The 3D VR interface ( left ) and the 2D desktop interface ( right ) are used depending on the task . First - person 3D invites situated analytics , whereas the 2D desktop better supports higher - level analysis . size , and invites interaction by anyone within physical reach . This , in other words , is a prime example of how a ubiquitous analytics environment can be designed to use complementary device platforms . Figure 3 shows an example of the David & Goliath system in action . Drawing on the personal affordances of the smart - watch , we mainly use the smaller display as a personal stor - age container as well as a mediator and a remote control—all tasks that are well - suited to the device . The large display , on the other hand , is a public and shared display that provides the fundamental data visualization for the team working on a specific task . Because of its size , it can show dashboards of multiple visualizations rather than just one . Devices can also complement each other over time . In the recent ReLive [ 34 ] system ( Figure 4 ) , we proposed a hy - brid desktop / VR interface that gives the same user access to two different ubiquitous analytics interfaces depending on task . ReLive was built to help mixed reality designers and re - searchers analyze real - time telemetry from user studies con - ducted in virtual or augmented reality environments . Thus , the primary data being visualized is 3D tracking and event logs over time . Here , again , the two analysis interfaces—an in - situ 3D Virtual Reality interface and an ex - situ 2D desk - top interface—are complementary in that each is suited for a specific task . When it comes to understanding 3D data , such as how two participants worked together in a 3D assembly task , nothing beats viewing the data from a first - hand per - spective in 3D . However , when deriving high - level abstract findings , such as the average distance between participants over an entire session , the 2D desktop interface is optimal . Having access to both interfaces allows a user to pick the right tool depending on task . But it is not enough that two devices are complementary— they should actively support each other . This is particularly important in ReLive , where the same user will be switch - ing between the two different interfaces time and time again , sometimes as part of the same task . This interface switch leads to a “cognitive context switch , ” where the user must re - orient themselves within the new interface in relation to the other interface . In ReLive , this is facilitated by providing common anchors between the two views . The 2D desktop view provides a 3D in - situ viewport that is visible at all times . Analogously , the 3D Virtual Reality view replicates many of the interface features from the desktop view , and selections made inside the first - hand perspective can be accessed in the 2D view . Takeaway : Each device involved in ubiquitous analyt - ics should have a clear role that is complementary to the other devices and transitions between them should be seamless . 5 . 2 Multiple Resources Given that the above discussion is at the granularity of en - tire devices , then our next concern is how to manage the resources associated with these devices , such as displays , computational power , input affordances , etc . Resource man - agement quickly becomes onerous and almost all - consuming when multiple devices are involved , and automation is thus required . For example , merely imagine logging into your typical workplace network , and then multiply this for every device you want to include in a work session . If the overhead associated with using multiple devices becomes overwhelm - ing , people will simply stick to a single device . One example where such automated resource management is critical is display management . In a typical ubiquitous an - alytics scenario , we might imagine that the displays avail - able to a person will change dynamically over the course of a work session . For example , while leaving your car or bus on the way to the office , you might only have access to your smartphone , allowing you to view a single data display at a time . Once you get to your office and your desk , you can 7 ( a ) Ubiquitous analytics scenario involving multiple devices . Visual Similarity equality of visual properties all same all diﬀerent Default Size Encoding Vis . Type Axis Data Similarity existence of data points in both subsets same distinct overlap Density Source Connectivity constellation / interplay deﬁned by the data ﬂow exclusive none supplementary Source Example : Small multiples all same distinct none Example : Scatterplot matrix same all same but one bi - directional Example : Dashboard all diﬀerent overlap uni - directional ( b ) Visualization relationships used to guide automatic layout . Figure 5 : Automatic visualization layout using Vistribute . The Vistribute system will dynamically reorganize the visual - izations to be displayed on the available surfaces whenever the device configuration changes ( left ) . Relationships between the different visualizations are used to ensure that similar representations are linked ( right ) . For example , the time - series charts on the tablet in the left picture are always laid out vertically on the same display and with a common horizontal axis . boot up your computer and distribute an entire visualization dashboard across your monitors as well as your personal de - vices . Finally , when you head into the conference room for a meeting , the projected screen as well as the laptops belong - ing to your colleagues could be used to display even more detailed data visualizations . However , for this to be practical , the layout of visualizations across available displays should be automatic lest the user gets continually bogged down in moving charts around . Furthermore , such layout must orga - nize closely related charts together on the same display as well as respect their geometry affinity . Such dynamic layout across ubiquitous analytics environ - ments was our focus in the Vistribute [ 33 ] system ( Figure 5 ) from 2019 . Based on a design space of visualization re - lationships ( Figure 5b ) , the Vistribute layout manager per - forms real - time constraint solving based on a set of high - level visualization layout heuristics . These heuristics include multi - chart relationships , such as the visual and data similar - ity as well as data flow connectivity in the figure , but also single - chart heuristics . For example , dense data displays , such as geographical maps , are given more display space , and a skewed - aspect ratio chart , like a time - series line chart , will be given wide and short display allocations . The VisHive toolkit [ 20 ] tackles a different but similar problem : computational resource management . More specif - ically , mobile ubiquitous analytics often call for significant computation , such as when performing textual analysis , clus - tering , or machine learning . The computational power of an individual mobile device may be insufficient to complete this calculation on its own in a timely manner . One solution is to simply use a remote computational resource , but even if the internet connectivity would be there—which is not a given in many mobile on - the - go situations—the data to be processed is often simply too large to effectively upload on the fly . The VisHive system solves this by forming an ad - hoc cluster , or hive , of mobile devices for load balancing computation in the field . Designed to work in conjunction with web - based visu - alization systems , VisHive is a small JavaScript library that runs directly in a device’s web browser and requires no spe - cialized software to be installed on the device . In this way , a user can simply bring additional mobile devices online to help process computational tasks in case a particular compu - tation is taking too long to complete . Takeaway : Resource management across multiple de - vices involved in a ubiquitous analytics environment should be automated to minimize the user burden . 5 . 3 Multiple Collaborators Finally , the third cardinality factor in a ubiquitous analyt - ics system is the individual users that often come together to work on realistic tasks . In general , collaborative visual - ization is a grand challenge of data visualization research , but ubiquitous analytics have the benefit of being designed to be collaborative from the very foundation . For example , the David and Goliath system discussed above can easily be used in a collaborative manner ( as in Figure 3 ) , and the two differ - ent interfaces in ReLive could just as easily be employed by two parallel users rather than the same one in sequence . One example of this is the Branch - Explore - Merge tabletop system [ 41 ] that we proposed in 2012 for collaboration across tabletops and mobile devices ( Figure 6 ) . A precursor to the D & G system discussed earlier , Branch - Explore - Merge uses the same philosophy of private and personal devices ( smart - phones and tablets ) vs . public and shared devices ( large touch tabletops in this case ) as in the smartwatch and wall display scenario . However , with B - E - M the focus is specifically on the coordination and consensus mechanisms required for a 8 Figure 6 : Collaboration using Branch - Explore - Merge . The mobile device , one per user , is generally synchronized with the data display on the tabletop . However , if the user wants to deviate from the shared display , they can branch the current state of the tabletop on their personal device , make the desired changes , and then merge back their findings to the shared display . Merging requires consensus . visualization system used by multiple users . While a user should be able to modify the visualization on their own per - sonal device at will , any change made on the shared tabletop will directly affect all collaborators . To manage this process , B - E - M draws on basic revision control principles from soft - ware engineering , where the user can branch the current state of the shared display on their own device , explore the data on their own , and then finally merge back their changes—or dis - card them if the exploration turns out to be a dead end . The B - E - M system requires a vote from all participants around the tabletop for changes to be merged back onto the shared display . ( a ) Comparing stacked lenses . ( b ) Consensus to overlay lenses . Figure 7 : Collaborative data analysis using the Prox - emic Lens . In the left image , the two collaborators have approached each other sufficiently that their body language indicates their work is closely coupled , so their respective lenses are stacked vertically . In the right image , the collabo - rators both raise their hands in consensus , causing the lenses to be overlaid to allow for direct comparison in the same vi - sual space . Voting is a somewhat disruptive coordination mechanism , and often more implicit mechanisms are better . In the Prox - emic Lens [ 8 ] project from 2016 , we used proxemics infor - mation [ 29 ] such as the distance between users , the direction of their bodies and head , their hand and foot gestures , and the spatial arrangement of objects and people in 3D space to guide interaction . The goal of the project was to be able to in - fer user intention in a ubiquitous analytics scenario from their body language and physical navigation in a space . We were particularly interested in studying how a large shared display can be best utilized depending on the collaborative coupling of the people using it ; separate viewports ( lenses ) for people working independently , and stacked or overlaid viewports for people working closely together ( Figure 7 ) . We used a static environment and a floor - to - ceiling display with a Vicon mo - tion capture system to track this information for multiple col - laborators , but in a mobile environment more subtle biomet - ric or inertial sensing technology will be required . We found that our participants overall enjoyed the implicit interaction of the Proxemic Lens system and that their intention was of - ten inferred correctly . However , they also indicated a pref - erence for explicit rather than implicit gestures for actions that are typically seen as commands , such as creating charts , splitting viewports , and consensus operations ( Figure 7b ) . Takeaway : Collaboration in ubiquitous analytics re - quires careful consideration of coordination and con - sensus , just like for general collaborative work , but the heterogeneous devices typically employed in ubiquitous analytics settings makes such coordination mechanisms straightforward to integrate . 6 Challenges & Outlook This future vision for data analytics is still a new notion , and its various manifestations as visual , ubiquitous , immersive , and situated analytics are still nascent and emergent . My re - search group has been a significant driver in this field , but the story is much bigger than just our efforts . The greater re - search community is energetic and growing , with new and exciting analytical systems being proposed at every major conference and journal issue ; certainly too many to discuss in a single review article . However , we claim that the tech - niques and technologies described here are a representative cross - section of ubiquitous analytics research . Based on this review , we would summarize our takeaways using a single theme : device diversity . Basically , it is the varied and heterogeneous nature—as well as their effective utilization—of the individual devices involved in a sense - making task that makes ubiquitous analytics powerful . This idea is also supported by the post - cognitive frameworks dis - cussed earlier in this article . If heterogeneity is the lead theme of ubiquitous analytics , where is the field going in the future ? Ens et al . [ 26 ] pre - 9 sented a vision for immersive analytics in 2021 and outlined the grand research challenges of that field . We are support - ive of these challenges in general , but we here complement their technical nature with our own list of higher - level future challenges : • The Future is Mixed : While handheld devices with screens are here to stay , it seems almost inevitable that future devices will eventually be based on Augmented and Mixed Reality [ 44 ] . AR / MR displays have the ca - pacity to turn your entire surrounding world into a can - vas for visual data displays , and the technology is con - stantly improving . This should mean that immersive 3D visualizations and interaction techniques will become increasingly important in the future . • Human - Centered Artificial Intelligence ( HCAI ) Teaming : While mostly glossed over in this article , the future of ubiquitous analytics is closely entwined with artificial intelligence . Only with powerful automated algorithms and recommendations at our beck and call will we be able to overcome the computational chal - lenges of tomorrow . However , rather than the black - box pipeline model of traditional AI , we believe in the use of visual interactive interfaces as inflection points for involving human operators in the loop . This is known as human - centered artificial intelligence ( HCAI ) [ 43 ] , but this is outside the scope of this article . • Standards , Components & Practices : If future sense - making environments are characterized by heteroge - neous systems and devices , then we will need standards as well as standardized components and practices to en - able multiple vendors to provide their own versions of these tools . While there exist several immersive analyt - ics [ 18 ] and Augmented Reality toolkits [ 28 ] , we will need a much richer ecosystem , including for software development , session and view management , naviga - tion , etc . Furthermore , many existing toolkits are built on proprietary 3D game engines such as Unity . It is dif - ficult to predict the future here , but based on past history , technologies based on open standards , such as the web - based VRIA [ 13 ] and Vistrates [ 11 ] toolkits , are safer bets than those built on closed and proprietary technol - ogy . • Accessibility & Inclusivity : The field of data visualiza - tion is just now recognizing the accessibility of interac - tive visual representations to people with visual , motor , or cognitive impairments , etc . Ubiquitous analytics will need to learn from these lessons at an early stage . How - ever , the heterogeneous nature of ubiquitous analytics can once again play in our favor in that the inclusion of diverse platforms into the sensemaking loop may make it easier to accommodate people of varying physical and cognitive ability . • Of Scale and Scalability : With the exception of the VisHive project , most of this paper has not concerned itself with large scale data management . While data vi - sualization is often seen as a best - in - class solution for the human aspect of big data [ 27 ] , there are many chal - lenges on the computational and data management side that must be solved in other to enable mobile sensemak - ing at this scale and magnitude . • Evermore Everywhere : Similarly , while the every - where data aspect of this paper is more of about provid - ing opportunity for anywhere data , we still need further work on capturing , integrating , and synthesizing hetero - geneous data from multiple sources in our environment . While privacy and security must remain foremost in our minds , such new data about our world will only con - tinue to make data - driven decision - making better and more effective . The current state of ubiquitous data analytics has been more than ten years in the making . There is now a thriving and creative research community that is invested in taking this vision forward into the future . Perhaps one day we will truly see sensemaking become embedded into the fabric of everyday life . Acknowledgments The author thanks Zhicheng Liu for his careful feedback on this article . References [ 7 ] Christopher Andrews , Alex Endert , and Chris North . 2010 . Space to Think : Large , High - Resolution Displays for Sensemaking . In Proceedings of the ACM Confer - ence on Human Factors in Computing Systems . ACM , New York , NY , USA , 55 – 64 . https : / / doi . org / 10 . 1145 / 1753326 . 1753336 [ 8 ] Sriram Karthik Badam , Fereshteh Amini , Niklas Elmqvist , and Pourang Irani . 2016 . Supporting Visual Exploration for Multiple Users in Large Display Envi - ronments . In Proceedings of the IEEE Conference on Visual Analytics Science and Technology . IEEE , Piscat - away , NJ , USA , 1 – 10 . https : / / doi . org / 10 . 1109 / vast . 2016 . 7883506 10 [ 9 ] Sriram Karthik Badam and Niklas Elmqvist . 2014 . PolyChrome : A Cross - Device Framework for Col - laborative Web Visualization . In Proceedings of the ACM Conference on Interactive Tabletops and Sur - faces . ACM , New York , NY , USA , 109 – 118 . https : / / doi . org / 10 . 1145 / 2669485 . 2669518 [ 10 ] Sriram Karthik Badam , Eli Fisher , and Niklas Elmqvist . 2015 . Munin : A Peer - to - Peer Middleware for Ubiqui - tous Analytics and Visualization Spaces . IEEE Trans - actions on Visualization and Computer Graphics 21 , 2 ( 2015 ) , 215 – 228 . https : / / doi . org / 10 . 1109 / TVCG . 2014 . 2337337 [ 11 ] Sriram Karthik Badam , Andreas Mathisen , Roman R¨adle , Clemens N . Klokmose , and Niklas Elmqvist . 2019 . Vistrates : A Component Model for Ubiq - uitous Analytics . IEEE Transactions on Visual - ization and Computer Graphics 25 , 1 ( Jan . 2019 ) , 586 – 596 . https : / / doi . org / 10 . 1109 / TVCG . 2018 . 2865144 [ 12 ] Doug A . Bowman , Chris North , Jian Chen , Nicholas F . Polys , Pardha S . Pyla , and Umur Yilmaz . 2003 . Information - rich virtual environments : theory , tools , and research agenda . In Proceedings of the ACM Sym - posium on Virtual Reality Software and Technology , . ACM , New York , NY , USA , 81 – 90 . https : / / doi . org / 10 . 1145 / 1008653 . 1008669 [ 13 ] Peter William Scott Butcher , Nigel W . John , and Pana - giotis D . Ritsos . 2021 . VRIA : A Web - based Framework for Creating Immersive Analytics Experiences . IEEE Transactions on Visualization and Computer Graphics 27 , 7 ( 2021 ) , 3213 – 3225 . https : / / doi . org / 10 . 1109 / TVCG . 2020 . 2965109 [ 14 ] Simon Butscher , Sebastian Hubenschmid , Jens M¨uller , Johannes Fuchs , and Harald Reiterer . 2018 . Clusters , Trends , and Outliers : How Immersive Technologies Can Facilitate the Collaborative Analysis of Multidi - mensional Data . In Proceedings of the ACM Conference on Human Factors in Computing Systems . ACM , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3173664 [ 15 ] Longbing Cao . 2018 . Data Science : A Compre - hensive Survey . Comput . Surveys 50 , 3 , Article 43 ( 2018 ) , 42 pages . https : / / doi . org / 10 . 1145 / 3076253 [ 16 ] Tom Chandler , Maxime Cordeil , Tobias Czauderna , Tim Dwyer , Jaroslaw Glowacki , Cagatay Goncu , Matthias Klapperstueck , Karsten Klein , Falk Schreiber , and Elliot Wilson . 2015 . Immersive Analytics . In Proceedings of the International Symposium on Big Data Visual Analytics . IEEE , Piscataway , NJ , USA , 1 – 8 . https : / / doi . org / 10 . 1109 / BDVA . 2015 . 7314296 [ 17 ] Andy Clark and David Chalmers . 1998 . The Extended Mind . Analysis 58 , 1 ( 1998 ) , 7 – 19 . https : / / doi . org / 10 . 1093 / analys / 58 . 1 . 7 [ 18 ] Maxime Cordeil , Andrew Cunningham , Benjamin Bach , Christophe Hurter , Bruce H . Thomas , Kim Mar - riott , and Tim Dwyer . 2019 . IATK : An Immersive An - alytics Toolkit . In Proceedings of the IEEE Conference on Virtual Reality and 3D User Interfaces . IEEE , Pis - cataway , NJ , USA , 200 – 209 . https : / / doi . org / 10 . 1109 / VR . 2019 . 8797978 [ 19 ] Maxime Cordeil , Andrew Cunningham , Tim Dwyer , Bruce H . Thomas , and Kim Marriott . 2017 . ImAxes : Immersive Axes as Embodied Affordances for Inter - active Multivariate Data Visualisation . In Proceedings of the ACM Symposium on User Interface Software and Technology . ACM , New York , NY , USA , 71 – 83 . https : / / doi . org / 10 . 1145 / 3126594 . 3126613 [ 20 ] Zhe Cui , Shivalik Sen , Sriram Karthik Badam , and Niklas Elmqvist . 2019 . VisHive : Supporting web - based visualization through ad hoc computational clus - ters of mobile devices . Information Visualization 18 , 2 ( 2019 ) , 195 – 210 . https : / / doi . org / 10 . 1177 / 1473871617752910 [ 21 ] Raimund Dachselt , Jonna H¨akkil¨a , Matt Jones , Markus L¨ochtefeld , Michael Rohs , and Enrico Rukzio . 2012 . Pico projectors : firefly or bright future ? Interactions 19 , 2 ( 2012 ) , 24 – 29 . https : / / doi . org / 10 . 1145 / 2090150 . 2090158 [ 22 ] Paul Dourish and Genevieve Bell . 2011 . Divining a Digital Future — Mess and Mythology in Ubiquitous Computing . MIT Press , Cambridge , MA , USA . [ 23 ] Niklas Elmqvist . 2011 . Embodied Human - Data Interac - tion . In Proceedings of the ACM CHI Workshop on Em - bodied Interaction : Theory and Practice in HCI . ACM , New York , NY , USA . [ 24 ] Niklas Elmqvist and Pourang Irani . 2013 . Ubiquitous Analytics : Interacting with Big Data Anywhere , Any - time . IEEE Computer 46 , 4 ( 2013 ) , 86 – 89 . https : / / doi . org / 10 . 1109 / mc . 2013 . 147 11 [ 25 ] Neven A . M . ElSayed , Bruce H . Thomas , Kim Mar - riott , Julia Piantadosi , and Ross T . Smith . 2016 . Sit - uated Analytics : Demonstrating immersive analytical tools with Augmented Reality . Journal of Visual Lan - guages & Computing 36 ( 2016 ) , 13 – 23 . https : / / doi . org / 10 . 1016 / j . jvlc . 2016 . 07 . 006 [ 26 ] Barrett Ens , Benjamin Bach , Maxime Cordeil , Ul - rich Engelke , Marcos Serrano , Wesley Willett , Arnaud Prouzeau , Christoph Anthes , Wolfgang B¨uschel , Cody Dunne , Tim Dwyer , Jens Grubert , Jason H . Haga , Nu - rit Kirshenbaum , Dylan Kobayashi , Tica Lin , Mon - surat Olaosebikan , Fabian Pointecker , David Saffo , Nazmus Saquib , Dieter Schmalstieg , Danielle Albers Szafir , Matt Whitlock , and Yalong Yang . 2021 . Grand Challenges in Immersive Analytics . In Proceedings of the ACM Conference on Human Factors in Com - puting Systems . ACM , New York , NY , USA , Article 459 , 17 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3446866 [ 27 ] Danyel Fisher , Robert DeLine , Mary Czerwinski , and Steven Mark Drucker . 2012 . Interactions with big data analytics . Interactions 19 , 3 ( 2012 ) , 50 – 59 . https : / / doi . org / 10 . 1145 / 2168931 . 2168943 [ 28 ] Philipp Fleck , Aimee Sousa Calepso , Sebastian Huben - schmid , Michael Sedlmair , and Dieter Schmalstieg . 2022 . RagRug : A Toolkit for Situated Analytics . IEEE Transactions on Visualization and Computer Graphics ( 2022 ) , 14 pages . https : / / doi . org / 10 . 1109 / TVCG . 2022 . 3157058 [ 29 ] Saul Greenberg , Nicolai Marquardt , Till Ballendat , Rob Diaz - Marino , and Miaosen Wang . 2011 . Proxemic in - teractions : the new ubicomp ? Interactions 18 , 1 ( 2011 ) , 42 – 50 . https : / / doi . org / 10 . 1145 / 1897239 . 1897250 [ 30 ] Chris Harrison . 2010 . Appropriated Interaction Sur - faces . IEEE Computer 43 , 6 ( 2010 ) , 86 – 89 . https : / / doi . org / 10 . 1109 / MC . 2010 . 158 [ 31 ] Chris Harrison , Jason Wiese , and Anind K . Dey . 2010 . Achieving Ubiquity : The New Third Wave . IEEE Mul - timedia 17 , 3 ( 2010 ) , 8 – 12 . https : / / doi . org / 10 . 1109 / MMUL . 2010 . 53 [ 32 ] Tom Horak , Sriram Karthik Badam , Niklas Elmqvist , and Raimund Dachselt . 2018 . When David Meets Goliath : Combining Smartwatches with a Large Ver - tical Display for Visual Data Exploration . In Pro - ceedings of the ACM Conference on Human Fac - tors in Computing Systems . ACM , New York , NY , USA , 19 : 1 – 19 : 13 . https : / / doi . org / 10 . 1145 / 3173574 . 3173593 [ 33 ] Tom Horak , Andreas Mathisen , Clemens Nylandsted Klokmose , Raimund Dachselt , and Niklas Elmqvist . 2019 . Vistribute : Distributing Interactive Visualiza - tions in Dynamic Multi - Device Setups . In Proceed - ings of the ACM Conference on Human Factors in Computing Systems . ACM , New York , NY , USA , 616 : 1 – 616 : 13 . https : / / doi . org / 10 . 1145 / 3290605 . 3300846 [ 34 ] Sebastian Hubenschmid , Jonathan Wieland , Daniel Im - manuel Fink , Andrea Batch , Johannes Zagermann , Niklas Elmqvist , and Harald Reiterer . 2022 . Re - Live : Bridging In - Situ and Ex - Situ Visual Analytics for Analyzing Mixed Reality User Studies . In Pro - ceedings of the ACM Conference on Human Fac - tors in Computing Systems . ACM , New York , NY , USA , 24 : 1 – 24 : 20 . https : / / doi . org / 10 . 1145 / 3491102 . 3517550 [ 35 ] Edwin Hutchins . 1995 . Cognition in the Wild . MIT Press , Cambridge , MA , USA . [ 36 ] K . Kim and N . Elmqvist . 2012 . Embodied lenses for collaborative visual queries on tabletop displays . Infor - mation Visualization 11 , 4 ( 2012 ) , 319 – 338 . https : / / doi . org / 10 . 1177 / 1473871612441874 [ 37 ] David Kirsh . 1995 . The Intelligent Use of Space . Arti - ficial Intelligence 73 , 1 - 2 ( 1995 ) , 31 – 68 . https : / / doi . org / 10 . 1016 / 0004 - 3702 ( 94 ) 00017 - U [ 38 ] Bongshin Lee , Raimund Dachselt , Petra Isenberg , and Eun Kyoung Choe . 2022 . Mobile Data Visualization . Chapman and Hall / CRC Press , Boca Raton , FL , USA . [ 39 ] Zhicheng Liu , Nancy J . Nersessian , and John T . Stasko . 2008 . Distributed Cognition as a Theoretical Frame - work for Information Visualization . IEEE Transac - tions on Visualization and Computer Graphics 14 , 6 ( 2008 ) , 1173 – 1180 . https : / / doi . org / 10 . 1109 / TVCG . 2008 . 121 [ 40 ] Kim Marriott , Falk Schreiber , Tim Dwyer , Karsten Klein , Nathalie Henry Riche , Takayuki Itoh , Wolf - gang Stuerzlinger , and Bruce H . Thomas ( Eds . ) . 2018 . Immersive Analytics . Lecture Notes in Computer Sci - ence , Vol . 11190 . Springer International Publishing , Berlin , Germany . https : / / doi . org / 10 . 1007 / 978 - 3 - 030 - 01388 - 2 [ 41 ] Will McGrath , Brian Bowman , David McCallum , Juan David Hincapi ´ e - Ramos , Niklas Elmqvist , and 12 Pourang Irani . 2012 . Branch - explore - merge : Facili - tating Real - time Revision Control in Collaborative Vi - sual Exploration . In Proceedings of the ACM Confer - ence on Interactive Tabletops and Surfaces . ACM , New York , NY , USA , 235 – 244 . https : / / doi . org / 10 . 1145 / 2396636 . 2396673 [ 42 ] Lawrence A . Shapiro . 2011 . Embodied Cognition . Routledge , New York , NY , USA . [ 43 ] Ben Shneiderman . 2022 . Human - Centered AI . Oxford University Press , Oxford , United Kingdom . [ 44 ] Maximilian Speicher , Brian D . Hall , and Michael Nebeling . 2019 . What is Mixed Reality ? . In Pro - ceedings of the ACM Conference on Human Factors in Computing Systems . ACM , New York , NY , USA , 537 : 1 – 537 : 15 . https : / / doi . org / 10 . 1145 / 3290605 . 3300767 [ 45 ] Martin Spindler , Christian Tominski , Heidrun Schu - mann , and Raimund Dachselt . 2010 . Tangible Views for Information Visualization . In Proceedings of the ACM Conference on Interactive Tabletops and Sur - faces . ACM , New York , NY , USA , 157 – 166 . https : / / doi . org / 10 . 1145 / 1936652 . 1936684 [ 46 ] Mark Weiser . 1991 . The Computer for the 21st Century . Scientific American 265 , 3 ( 1991 ) , 94 – 104 . https : / / doi . org / 10 . 1145 / 329124 . 329126 [ 47 ] Wesley Willett , Yvonne Jansen , and Piere Dragicevic . 2017 . Embedded Data Representations . IEEE Trans - actions on Visualization and Computer Graphics 23 , 1 ( Jan . 2017 ) , 461 – 470 . https : / / doi . org / 10 . 1109 / TVCG . 2016 . 2598608 [ 48 ] William Wright , David Schroh , Pascale Proulx , Alex Skaburskis , and Brian Cort . 2006 . The Sandbox for Analysis : Concepts and Evaluation . In Proceedings of the ACM Conference on Human Factors in Com - puting Systems . ACM , New York , NY , USA , 801 – 810 . https : / / doi . org / 10 . 1145 / 1124772 . 1124890 13