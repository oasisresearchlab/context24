Evaluating vector - space models of analogy Dawn Chen ( sdawnchen @ gmail . com ) Joshua C . Peterson ( peterson . c . joshua @ gmail . com ) Thomas L . Grifﬁths ( tom grifﬁths @ berkeley . edu ) Department of Psychology , University of California , Berkeley , CA 94720 USA Abstract Vector - space representations provide geometric tools for rea - soning about the similarity of a set of objects and their relation - ships . Recent machine learning methods for deriving vector - space embeddings of words ( e . g . , word2vec ) have achieved considerable success in natural language processing . These vector spaces have also been shown to exhibit a surprising ca - pacity to capture verbal analogies , with similar results for nat - ural images , giving new life to a classic model of analogies as parallelograms that was ﬁrst proposed by cognitive scientists . We evaluate the parallelogram model of analogy as applied to modern word embeddings , providing a detailed analysis of the extent to which this approach captures human relational sim - ilarity judgments in a large benchmark dataset . We ﬁnd that that some semantic relationships are better captured than oth - ers . We then provide evidence for deeper limitations of the par - allelogram model based on the intrinsic geometric constraints of vector spaces , paralleling classic results for ﬁrst - order simi - larity . Keywords : analogy ; word2vec ; GloVe ; vector space models Introduction Recognizing that two situations have similar patterns of rela - tionships , even though they may be superﬁcially dissimilar , is essential for intelligence . This ability allows a reasoner to transfer knowledge from familiar situations to unfamiliar but analogous situations , enabling analogy to become a power - ful teaching tool in math , science , and other ﬁelds ( Richland & Simms , 2015 ) . Computational modeling of analogy has primarily focused on comparing structured representations that contain labeled relationships between entities ( Gentner & Forbus , 2011 ) . However , the questions of where these re - lations come from and how to determine that the relationship between one pair of entities is the same as that between an - other pair are an unsolved mystery in such models . Some models , such as DORA ( Doumas , Hummel , & Sandhofer , 2008 ) and BART ( Lu , Chen , & Holyoak , 2012 ) , try to learn relations from examples , but have only demonstrated success on comparative relations such as larger . Another possibility is that the representations of entities themselves contain the information necessary to infer rela - tionships between entities and that relations do not need to be learned separately . An instantiation of this hypothesis is the parallelogram model of analogy ( see Figure 1 ) , ﬁrst pro - posed by Rumelhart and Abrahamson ( 1973 ) over 40 years ago . In this model , entities are represented as points in a Eu - clidean space and relations between entities are represented as their difference vectors . Even though two pairs of points may be far apart in the space ( i . e . , they are featurally dissim - ilar ) , they are considered relationally similar as long as their difference vectors are similar . Although Rumelhart and Abra - hamson found that this simple model worked well for a small domain of animal words with vectors obtained using multidi - mensional scaling , little progress was made on the parallelo - gram model after the initial proposal , with the exception of a handful of reasonably successful applications ( see Ehresman & Wessel , 1978 ) . However , in the past few years , the parallelogram model was reincarnated in the machine learning literature through popular word embedding methods such as word2vec ( Mikolov , Sutskever , Chen , Corrado , & Dean , 2013 ) and GloVe ( Pennington , Socher , & Manning , 2014 ) . These word representations enable verbal analogy problems such as king : queen : : man : ? to be solved through simple vector arith - metic , i . e . , v queen − v king + v man results in a vector very close ( in terms of cosine distance ) to v woman . Word embeddings like word2vec and GloVe have also been used successfully in a variety of other natural language processing tasks , suggesting that these representations may indeed contain enough infor - mation for relations to be inferred from them directly . Re - cently , researchers in computer vision have been successful in extracting feature spaces that exhibit similar properties in both explicit ( supervised ) ( Radford , Metz , & Chintala , 2015 ) and implicit ( unsupervised ) ( Reed , Zhang , Zhang , & Lee , 2015 ) ways , yielding linearized semantic image transforma - tions such as object rotations and high - level human face inter - polations . The potential for applying the parallelogram model of analogy to vector space models appears to be domain - agnostic , broadly applicable to both semantic and perceptual domains . This suggests a promising cognitive model and pro - vides the opportunity to evaluate a classic theory in large - scale , ecologically valid contexts . man woman king queen Figure 1 : The parallelogram model of analogy completes the analogy king : queen : : man : ? by adding the difference vector between king and queen to man . This forms a parallel - ogram in the underlying vector space . In this paper , we evaluate the parallelogram model of anal - ogy as applied to modern vector - space representations of words . Focusing on the predictions that this approach makes about the relational similarity of words , we provide a new dataset of over 5 , 000 comparisons between word pairs that exemplify 10 different types of semantic relations . We ﬁnd that the parallelogram model captures human relational sim - 1746 ilarity judgments for some semantic relations , but not others . We then show that human relational similarity judgments for pairs of words violate the geometric constraints of symme - try and triangle inequality , just as Tversky ( 1977 ) showed for judgments of ﬁrst - order similarity between words . This cre - ates a challenge for any vector space model that aims to make predictions about relational similarity . Relational Similarity One way to evaluate vector space models such as word2vec and GloVe as accounts of analogy is to compare their as - sessments of relational similarity – the similarity of the re - lation between one pair of words to that of another – with human judgments . A good foundation for this task is the SemEval - 2012 Task 2 dataset ( Jurgens , Turney , Mohammad , & Holyoak , 2012 ) , which contains prototypicality scores based on human data for word pairs that exemplify 79 dif - ferent semantic relations . These relations were taken from a taxonomy of semantic relations ( Bejar , Chafﬁn , & Embret - son , 1991 ) and are subtypes of 10 general types , such as CLASS - INCLUSION , SIMILAR , and CONTRAST . Participants were given three or four paradigmatic examples of a relation and asked to generate additional examples of the same rela - tion . A total of 3 , 218 unique word pairs were generated for the 79 relations , with an average of 41 word pairs per rela - tion . A prototypicality score for each participant - generated word pair was calculated based on how often a second group of participants chose the word pair as the best and worst ex - ample of the relation among a set of choices . Table 1 shows examples illustrating two representative subtypes of each of the ten general types of relations . According to the parallelogram model , two pairs of words ( A : B and C : D ) are relationally similar to the extent that their difference vectors ( v B − v A and v D − v C ) are similar . How appropriate is this geometric relationship for the var - ious semantic relations ? As a preliminary investigation of this question , we projected the 300 - dimensional word2vec vectors into a two - dimensional space using principal compo - nents analysis separately for each relational subtype in the SemEval dataset , and visualized the difference vectors for the participant - generated word pairs from each relation . Figure 2 shows the difference vectors for the 20 relational subtypes that are shown in Table 1 . Examining the difference vectors for each relation shows that the parallelogram rule does not appear to capture all re - lations . CASE RELATIONS Agent : Instrument ( e . g . , farmer : tractor ) shows a nearly perfect correspondence with what we would expect under the parallelogram model , with all differ - ence vectors aligning . However , many of the relations ap - pear to have no clear geometric pattern . Nevertheless , simply looking at projections of the difference vectors is not sufﬁ - cient to evaluate the power of geometric models of relational similarity to capture various relations , because information is lost in the projections . What is required is a detailed evalua - tion on judgments of relational similarity between word pairs Table 1 : Examples of word pairs instantiating each of two representative subtypes from each general relation type in the SemEval - 2012 Task 2 dataset Relation type Subtype Example 1 . CLASS - Taxonomic ﬂower : tulip INCLUSION Class : Individual river : Nile 2 . PART - WHOLE Object : Component car : engine Collection : Member forest : tree 3 . SIMILAR Synonymy car : auto Dimensional Simi - simmer : boil larity 4 . CONTRAST Contrary old : young Reverse buy : sell 5 . ATTRIBUTE Item : Attribute beggar : poor Object : State coward : fear 6 . NON - ATTRIBUTE Item : Nonattribute ﬁre : cold Object : Nonstate corpse : life 7 . CASE Agent : Instrument soldier : gun RELATIONS Action : Object plow : earth 8 . CAUSE - PURPOSE Cause : Effect joke : laughter Cause : Compensa - hunger : eat tory action 9 . SPACE - TIME Location : Item library : book Time : Associated winter : snow Item 10 . REFERENCE Sign : Signiﬁcant siren : danger Representation diary : person within each relation . Although the SemEval - 2012 dataset contains prototypical - ity scores for the participant - generated word pairs within each relation , which have been interpreted as the relational similar - ities between the participant - generated pairs and the paradig - matic pairs , prototypicality is inﬂuenced by other factors such as the production frequencies of words ( Uyeda & Mandler , 1980 ) . Moreover , because participants were encouraged to focus on the relation illustrated by the paradigmatic exam - ples , the prototypicality scores may not have much to do with the particular word pairs chosen as paradigmatic examples . Experiment 1 aims to address these problems . Experiment 1 : Benchmarking Relational Similarity To overcome the limitations of the SemEval - 2012 Task 2 dataset for our purposes , we collected a new large dataset that directly measures human judgments of relational simi - larity between word pairs , focusing on comparisons between word pairs with similar relations . Participants We recruited 823 participants from Amazon Mechanical Turk . Participants were paid $ 2 . 00 for the 20 - 1747     & / $ 6 6  , 1 & / 8 6 , 2 1   7 D [ R Q R P L F     & / $ 6 6  , 1 & / 8 6 , 2 1   & O D V V , Q G L Y L G X D O     3 $ 5 7  : + 2 / (   2 E M H F W  & R P S R Q H Q W     3 $ 5 7  : + 2 / (   & R O O H F W L R Q  0 H P E H U     6 , 0 , / $ 5   6 \ Q R Q \ P L W \     6 , 0 , / $ 5    ' L P H Q V L R Q D O  6 L P L O D U L W \     & 2 1 7 5 $ 6 7   & R Q W U D U \     & 2 1 7 5 $ 6 7   5 H Y H U V H     $ 7 7 5 , % 8 7 (   , W H P $ W W U L E X W H     $ 7 7 5 , % 8 7 (   2 E M H F W 6 W D W H     1 2 1  $ 7 7 5 , % 8 7 (   , W H P  1 R Q D W W U L E X W H     1 2 1  $ 7 7 5 , % 8 7 (   2 E M H F W  1 R Q V W D W H     & $ 6 (  5 ( / $ 7 , 2 1 6   $ J H Q W  , Q V W U X P H Q W     & $ 6 (  5 ( / $ 7 , 2 1 6   $ F W L R Q  2 E M H F W     & $ 8 6 (  3 8 5 3 2 6 (   & D X V H  ( I I H F W     & $ 8 6 (  3 8 5 3 2 6 (    & D X V H  & R P S H Q V D W R U \  $ F W L R Q     6 3 $ & (  7 , 0 (    , W H P  / R F D W L R Q     6 3 $ & (  7 , 0 (    7 L P H  $ V V R F L D W H G  , W H P       5 ( ) ( 5 ( 1 & (   6 L J Q  6 L J Q L I L F D Q W       5 ( ) ( 5 ( 1 & (    5 H S U H V H Q W D W L R Q Figure 2 : Visualizations of difference vectors for 20 relational subtypes using two - dimensional projections of word2vec word vectors obtained separately for each relation using principal components analysis . minute study . We excluded 158 participants from the data analysis because they failed two or more of the attention checks ( see below ) . Stimuli The stimuli for this study were taken from the SemEval - 2012 Task 2 dataset . We were mainly interested in how people rate relational similarities between participant - generated word pairs within each of the 79 relational sub - types . However , because the total number of such “within - subtype” pairwise comparisons is still enormous , we selected the most representative subtype for each relation type out of the two shown in Table 1 . The subtype we chose is the ﬁrst of each pair of subtypes that appears in Table 1 . We then randomly chose 30 word pairs out of the entire participant - generated set for each of the 10 subtypes and formed all possible within - subtype comparisons between these word pairs . This created a set of 4 , 350 within - subtype compar - isons . Finally , in order to encourage participants to use the entire rating scale , we added 925 “between - subtype” com - parisons , which are comparisons between word pairs from different subtypes within a type ( e . g . , Object : Component and Collection : Member , both subtypes of PART - WHOLE ) , and 925 “between - type” comparisons , which are comparisons be - tween word pairs from the representative subtypes of differ - ent relational types ( e . g . , Object : Component and Taxonomic CLASS - INCLUSION ) . Procedure Participants were given instructions about re - lational similarity , which included an example of two word pairs that have similar relationships ( kitten : cat and chick : chicken ) and an example of word pairs with dissimilar re - lationships ( chick : chicken and hen : rooster ) . Participants then viewed two pairs of words side - by - side on each page and were asked to rate the similarity of the relationships shown by the two word pairs on a scale from 1 ( extremely different ) to 7 ( extremely similar ) . They rated 100 comparisons in a random order , 70 of which were within - subtype , 15 of which were between - subtype , and 15 of which were between - type . The left - right order of the two word pairs on the screen was chosen randomly ( but order within pairs was of course maintained ) . After every 20 trials , there was an attention check question that asked participants to indicate whether two words are the same or different . Results & Discussion We obtained at least 10 good rat - ings for each comparison , with an average of 10 . 74 ratings per comparison . The mean rating across all comparisons was 4 . 52 ( SD = 2 . 17 ) . As expected , we obtained the highest re - lational similarity ratings for within - subtype comparisons ( M = 5 . 01 , SD = 1 . 98 ) , mid - level ratings for between - subtype comparisons ( M = 4 . 02 , SD = 2 . 14 ) and the lowest ratings for between - type comparisons ( M = 2 . 70 , SD = 1 . 93 ) . We calculated relational similarity for each comparison us - 1748 ing word2vec and GloVe word representations . We used the 300 - dimensional word2vec vectors trained on the Google News corpus that were provided by Google ( Mikolov et al . , 2013 ) , and the 300 - dimensional GloVe vectors trained on a Common Crawl web crawl corpus that were provided by Pennington et al . ( 2014 ) . We tested two measures of simi - larity between difference vectors , cosine similarity and Eu - clidean distance . Speciﬁcally , for a given comparison be - tween two word pairs , A : B and C : D , letting r 1 = v B − v A and r 2 = v D − v C , we calculated the cosine similarity , r 1 · r 2 (cid:107) r 1 (cid:107)(cid:107) r 2 (cid:107) , as well as a similarity measure based on Euclidean distance , 1 −(cid:107) r 1 − r 2 (cid:107) . Cosine similarity is typically used to measure similarity in vector spaces such as word2vec and GloVe . However , using Euclidean distance corresponds more closely to the original parallelogram model , in which not only the directions but also the lengths of the difference vectors needed to be similar for two word pairs to be considered relationally similar . Figure 3 shows Pearson’s correlations between predicted relational similarity scores and average human relational sim - ilarity ratings on each relation type ( including both within - subtype and between - subtype comparisons ) for each vector space and similarity measure . There is considerable variation in the performance of word2vec and GloVe in predicting hu - man relational similarity ratings . As might be expected from examining Figure 2 , cosine similarity performs the best on CASE RELATIONS ( relation 7 ) . However , cosine similarity completely fails on SIMILAR ( relation 3 ) , CONTRAST ( rela - tion 4 ) , and NON - ATTRIBUTE ( relation 6 ) . Euclidean distance boosts performance on the latter two relations , but still under - performs overall compared to most other relations . Neverthe - less , Euclidean distance does perform very well on SPACE - TIME ( relation 9 ) . These results indicate that a single relational comparison strategy cannot capture all semantic relations in the spaces provided . It is unclear if such a result is a reﬂection of the word embeddings or actual variation in human analogical strategies . Next , we turn to the broader question of the ap - propriateness of the class of geometric models in general for representing human relational similarity behavior . Violations of Geometric Constraints Distance metrics in vector spaces must obey certain geomet - ric constraints , such as symmetry ( the distance from x to y is the same as the distance from y to x ) and the triangle in - equality ( if the distance between x and y is small and the dis - tance between y and z is small , then the distance between x and z cannot be very large ) . Cosine similarity , used to mea - sure similarity between word2vec representations , also obeys symmetry and an analogue of the triangle inequality ( Grif - ﬁths , Steyvers , & Tenenbaum , 2007 ) . However , psycholog - ical representations of similarity do not always obey these constraints ( Tversky , 1977 ) . The famous example of this is that people judge North Korea to be more similar to China than the other way around , a violation of symmetry . Grifﬁths et al . ( 2007 ) examined the word representations derived by Latent Semantic Analysis ( Landauer & Dumais , 1997 ) , an - other well - known vector space model , and found that these representations are unable to account for violations of sym - metry and the triangle inequality in human word association data . Nevertheless , all prior work has focused on ﬁrst - order similarity between words , and second - order ( relational ) sim - ilarity between word pairs might be expected to follow a dif - ferent pattern . In this section , we show that human judgments of relational similarity also do not satisfy the geometric con - straints of symmetry and the triangle inequality . Vector space models such as word2vec and GloVe cannot account for these violations . Experiment 2 : Symmetry In this experiment , we examined whether there were any pairs of word pairs for which participants’ judgments of relational similarity changed when the presentation order was reversed . We might expect such asymmetry to occur when a word pair has multiple relations and shares ones of its less salient relations with another word pair . For example , when presented with angry : smile – exhausted : run , one might think , “an angry person doesn’t want to smile” and “an exhausted person doesn’t want to run , ” but when presented with exhausted : run – angry : smile , one might think , “running makes a person exhausted , but smiling doesn’t make a person angry . ” Thus , participants might give high relational similarity ratings in the ﬁrst presentation order and low ratings in the second order . Participants We recruited 1 , 102 participants from Amazon Mechanical Turk , who gave informed consent and were paid $ 1 . 00 for the 10 - minute study . We excluded 99 participants from the data analysis because they failed two or more of the attention checks ( see below ) . Stimuli We randomly selected 220 within - subtype , 220 between - subtype , and 60 between - type comparisons from all possible comparisons formed using the entire SemEval - 2012 Task 2 dataset . We created two versions of each comparison , in which the order of the word pairs were switched . Procedure Participants were given instructions about rela - tional similarity and the two examples used in Experiment 1 illustrating similar and dissimilar relationships . They saw one word pair in each comparison ﬁrst and were asked to think of the relationship between the words . Then after a 600 ms delay , the other word pair was shown and participants were asked to rate the similarity of the relationships on a 7 - point scale . Participants rated 50 comparisons , including 22 within - subtype , 22 between - subtype , and 6 between - type compar - isons . Each participant viewed each comparison in only one of its presentation orders . After every 10 trials , there was 1749 - 0 . 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 1 2 3 4 5 6 7 8 9 10 P e a r s o n ' s r Relation Type - 0 . 1 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 1 2 3 4 5 6 7 8 9 10 P e a r s o n ' s r Relation Type cosinesimilarity Euclideandistance ( a ) word2vec ( b ) GloVe Figure 3 : Pearons’s r between human relational similarity ratings and model predictions on different relation types for ( a ) word2vec and ( b ) GloVe . The name and examples of each numbered relation type are shown in Table 1 . an attention check question that asked participants to indicate whether two words are the same or different . Results & Discussion We obtained about 50 ratings for each comparison in each presentation order . We conducted a t - test for each comparison to see if the two presentation orders resulted in signiﬁcantly different relational similarity ratings . 77 of these t - tests were statistically signiﬁcant at the . 05 level . The number of t - tests that we would expect to be signiﬁcant at the α = 0 . 05 level if presentation order did not matter for any of the comparisons is 25 . Assuming that the t - tests are independent , a binomial test reveals that this devi - ation is statistically signiﬁcant , p < . 001 . Examining the comparisons for which different presenta - tion orders resulted in signiﬁcantly different relational sim - ilarity ratings conﬁrms our guess as to when people’s judg - ments of relational similarity might not obey symmetry . The previously mentioned example of angry : smile and exhausted : run indeed elicited higher ratings in the direction shown here ( 4 . 76 mean rating ) than in the opposite direction ( 2 . 36 mean rating ) . As another example , people rated hairdresser : comb – pitcher : baseball as more relationally similar ( 6 . 10 mean rating ) than pitcher : baseball – hairdresser : comb ( 4 . 84 mean rating ) . In the ﬁrst presentation order , participants might be thinking that “a hairdresser handles a comb” and “a pitcher handles a baseball , ” whereas in the second presenta - tion order , they might be thinking “a pitcher plays a speciﬁc role in baseball , ” which doesn’t ﬁt with hairdresser : comb . Experiment 3 : Triangle Inequality For this experiment , we created triads of word pairs for which we expected people’s relational similarity judgments to vio - late the triangle inequality , such as nurse : patient , mother : baby , and frog : tadpole . This triad violates the triangle in - equality because nurse : patient : : mother : baby is a good analogy ( relationally similar ) , and so is mother : baby : : frog : tadpole , but nurse : patient : : frog : tadpole is not . In this example , the middle pair has multiple relations and shares one of them with the ﬁrst pair and a different one with the last pair . We presented the two word pairs in each analogy together and asked participants to rate the quality of the anal - ogy rather than relational similarity , because we wanted to encourage participants to consider the two relations together rather than using one relation as a reference . Participants We recruited 71 participants from Amazon Mechanical Turk , who gave informed consent and were paid $ 0 . 50 for the 5 - minute study . This group of participants did not overlap with the participants in Experiment 2 . We ex - cluded 11 participants from the data analysis because they failed one of the attention checks ( see below ) . Stimuli We created twelve triads of word pairs for which analogy quality judgments are likely to violate the triangle inequality . For every triad , the analogy formed between the ﬁrst and third word pairs was expected to be rated low and the other two analogies were expected to be rated highly . Procedure Participants were given instructions about ver - bal analogies and the two examples used in Experiments 1 and 2 as examples of good and bad analogies , respectively . They were then asked to rate the quality of each analogy on a scale from 1 ( very bad ) to 7 ( very good ) . For each of the twelve triads , each participant viewed one of the three analo - gies . Each participant received four analogies formed be - tween the ﬁrst and second word pairs of various triads ( anal - ogy type 1 - 2 ) , four formed between the second and third word pairs ( type 2 - 3 ) , and four formed between the ﬁrst and third word pairs ( type 1 - 3 ) . Because two thirds of these analogies are expected to be rated highly , participants also viewed four “ﬁller” analogies expected to be given low ratings . Finally , there were two attention check questions that asked to partic - ipants to simply choose 1 ( or 7 ) for a bad ( or good ) analogy . Results & Discussion We obtained 20 ratings for each analogy . We calculated the mean participant rating for each analogy and conducted a one - way between - subjects ANOVA to test if there was an effect of the analogy type ( 1 - 2 , 2 - 3 , or 1 - 3 ) on the mean analogy quality rating . This revealed a sig - niﬁcant effect of analogy type , F ( 2 , 33 ) = 45 . 57 , p < 0 . 001 . Post hoc comparisons using the Tukey HSD test indicated that the mean ratings for both type 1 - 2 analogies ( M = 5 . 44 , SD = . 99 ) and type 2 - 3 analogies ( M = 5 . 43 , SD = . 63 ) were signiﬁcantly higher than the mean rating for type 1 - 3 analo - gies ( M = 2 . 99 , SD = . 46 ) , p < . 001 , whereas the mean rat - ings for type 1 - 2 and type 2 - 3 analogies did not differ signif - icantly from each other . This is consistent with our expec - tation that types 1 - 2 and 2 - 3 analogies would both be rated highly , whereas type 1 - 3 analogies would be rated lowly . These results indicate that participants’ analogy quality rat - ings violated the triangle inequality . 1750 0 0 . 2 0 . 4 0 . 6 0 . 8 1 1 - 2 2 - 3 1 - 3 S c a l e d S c o re Analogy Type lawyer : books , chemist : beakers , librarian : books human word2vec GloVe Figure 4 : Mean human ratings and predicted relational simi - larities ( scaled to the range 0 - 1 ) for the triad lawyer : books , chemist : beakers , and librarian : books . Error bars indicate 1 SEM for scaled human ratings . We obtained the predicted relational similarity between the word pairs in each analogy by calculating the cosine simi - larity between difference vectors using word2vec and GloVe representations . Then we conducted separate ANOVAs for the two representational spaces to test whether there was an effect of analogy type on the predicted relational similarity in each space . Neither ANOVA indicated a signiﬁcant effect of analogy type . For word2vec , F ( 2 , 33 ) = 1 . 20 , p = . 31 . For GloVe , F ( 2 , 33 ) = . 24 , p = . 79 . These results indicate that the predictions of relational similarity made by word2vec and GloVe do not violate the triangle inequality for our stimuli . Because each participant contributed ratings to more than one analogy ( although only one per triad ) , the observations are not entirely independent in the ﬁrst overall ANOVA that we conducted on the participant data . Thus , we conducted a separate between - subjects ANOVA for each of the twelve triads to test if there was an effect of analogy type ( 1 - 2 , 2 - 3 , or 1 - 3 ) on the analogy quality ratings for each triad . All twelve ANOVAs were signiﬁcant , with every p < . 01 . We then conducted post hoc comparisons using the Tukey HSD test . The pattern we expected was that types 1 - 2 and 2 - 3 analogies would have signiﬁcantly higher ratings than type 1 - 3 analogies , but would not differ signiﬁcantly from each other . We observed this pattern for seven of the twelve tri - ads . For every one of the remaining triads , the mean ratings for the type 1 - 2 and type 2 - 3 analogies were higher than the mean rating for the type 2 - 3 analogy , but which differences were statistically signiﬁcant differed among the triads . Fig - ure 4 shows an example of one of the seven triads with the expected pattern and compares the mean participant ratings and predicted relational similarities for the three analogies . Conclusions Our results provide a clearer picture of the utility of vector - space models of analogy . The parallelogram model makes good predictions of human relational similarity judgments for some relations , but is less appropriate for others . For exam - ple , consider the word pairs represented as vectors in Fig - ure 2 . As one would expect , relation SIMILAR seems to be best represented by a short difference vector rather than the direction of the difference vector . More generally , in more complex analogies with the source and target each consist - ing of many points in the vector space , one could imagine many ways of describing relationships between the two sets of points . More challenging are the constraints posed by the geomet - ric axioms . In our datasets , we found considerable violations of two of these axioms , which cannot be overcome through better embedding methods . In light of this , it would be inter - esting to follow the history of models of ﬁrst - order similarity in considering the use of featural representations ( Tversky , 1977 ) , exploring methods of measuring similarity in vector spaces that are no longer subject to the constraints imposed by the metric axioms ( Krumhansl , 1978 ) , or reformulating the problem as probabilistic inference ( Grifﬁths et al . , 2007 ) . Acknowledgments . Supported by grant number FA9550 - 13 - 1 - 0170 from the Air Force Ofﬁce of Scientiﬁc Research . References Bejar , I . I . , Chafﬁn , R . , & Embretson , S . ( 1991 ) . A taxonomy of semantic relations . In Cognitive and psychometric analysis of analogical problem solving ( pp . 55 – 91 ) . Springer . Doumas , L . A . , Hummel , J . E . , & Sandhofer , C . M . ( 2008 ) . A theory of the discovery and predication of relational concepts . Psychological review , 115 ( 1 ) , 1 . Ehresman , D . , & Wessel , D . L . ( 1978 ) . Perception of timbral analo - gies . Centre Georges Pompidou . Gentner , D . , & Forbus , K . D . ( 2011 ) . Computational models of analogy . Wiley interdisciplinary reviews : cognitive science , 2 ( 3 ) , 266 – 276 . Grifﬁths , T . L . , Steyvers , M . , & Tenenbaum , J . B . ( 2007 ) . Topics in semantic representation . Psychological Review , 114 ( 2 ) , 211 . Jurgens , D . A . , Turney , P . D . , Mohammad , S . M . , & Holyoak , K . J . ( 2012 ) . Semeval - 2012 task 2 : Measuring degrees of rela - tional similarity . In Proceedings of the ﬁrst joint conference on lexical and computational semantics - volume 1 ( pp . 356 – 364 ) . Krumhansl , C . ( 1978 ) . Concerning the applicability of geomet - ric models to similarity data : The interrelationship between similarity and spatial density . Psychological Review , 85 , 450 - 463 . Landauer , T . K . , & Dumais , S . T . ( 1997 ) . A solution to plato’s problem : The latent semantic analysis theory of acquisition , induction , and representation of knowledge . Psychological Review , 104 ( 2 ) , 211 . Lu , H . , Chen , D . , & Holyoak , K . J . ( 2012 ) . Bayesian anal - ogy with relational transformations . Psychological review , 119 ( 3 ) , 617 . Mikolov , T . , Sutskever , I . , Chen , K . , Corrado , G . S . , & Dean , J . ( 2013 ) . Distributed representations of words and phrases and their compositionality . In Advances in neural information processing systems ( pp . 3111 – 3119 ) . Pennington , J . , Socher , R . , & Manning , C . D . ( 2014 ) . Glove : Global vectors for word representation . In Emnlp ( Vol . 14 , pp . 1532 – 1543 ) . Radford , A . , Metz , L . , & Chintala , S . ( 2015 ) . Unsupervised repre - sentation learning with deep convolutional generative adver - sarial networks . arXiv preprint arXiv : 1511 . 06434 . Reed , S . E . , Zhang , Y . , Zhang , Y . , & Lee , H . ( 2015 ) . Deep visual analogy - making . In Advances in neural information process - ing systems ( pp . 1252 – 1260 ) . Richland , L . E . , & Simms , N . ( 2015 ) . Analogy , higher order think - ing , and education . Wiley Interdisciplinary Reviews : Cogni - tive Science , 6 ( 2 ) , 177 – 192 . Rumelhart , D . E . , & Abrahamson , A . A . ( 1973 ) . A model for ana - logical reasoning . Cognitive Psychology , 5 ( 1 ) , 1 – 28 . Tversky , A . ( 1977 ) . Features of similarity . Psychological review , 84 ( 4 ) , 327 . Uyeda , K . M . , & Mandler , G . ( 1980 ) . Prototypicality norms for 28 semantic categories . Behavior Research Methods & Instru - mentation , 12 ( 6 ) , 587 – 595 . 1751