Argument Placement Recommendation and Relevancy Assessment in an Intelligent Argumentation System Feng Li Nian Liu Wei Jiang Xiaoqing ( Frank ) Liu Department of Computer Science Missouri University of Science & Technology 500 West 15th Street , Rolla , MO 65409 { lftrd , nlb4c , wjiang , ﬂiu } @ mst . edu Abstract —Argumentation is a critical process for many social activities that need collaborative intelligence . Existing intelli - gent argumentation systems allow multiple stakeholders from distributed geographical locations to share their opinions and contribute to a decision making process . In the current sys - tem , a stakeholder needs to read all the existing arguments posted by other stakeholders before contributing his / her own ideas / arguments . However , when information accumulates and an argumentation network becomes considerably large , it will cost tremendous time and effort for the stakeholder to read and comprehend all existing arguments . In this paper , we propose methods to implement a recommendation component built into an intelligent argumentation system . The recommendation compo - nent can automatically assist a stakeholder to better understand the current state of an argumentation by summarizing and identifying a subset of existing arguments that are relevant to the stakeholder . Thus , our proposed work will allow a stakeholder to efﬁciently and effectively express his / her thoughts in an intel - ligent argumentation system in relevant argumentation thread . We also empirically evaluate the effectiveness of the proposed recommendation component , and the empirical results indicate it is effective according to a real dataset . Keywords —Collaboration enabling technologies , argumenta - tion , and collaborative decision making and support I . I NTRODUCTION Argumentation is a very common process in our society , and it plays a signiﬁcant role in many social and business activities that need collaboration . An efﬁcient argumentation will help stakeholders to better understand the problem and its possible solutions . As a consequence , the stakeholders will have a better chance to come to an agreement that meets the the best interest of all group members . An intelligent argumentation system ( IAS ) was developed to assist group decision making [ 16 ] by recording , organizing and analyzing how stakeholders argue with one another regarding an issue . Applying Toulmin Model [ 9 ] , an IAS decomposes an natural argument into several parts mapping into elements in a tree structure . By organizing all the arguments in a tree hierarchy , an IAS can compute preference score for each pos - sible solution . Through comparing all the preference scores , an IAS is capable of predicting and assisting participants to make decisions . Even though an IAS can improve effectiveness of an ar - gumentation and facilitate the progress of collaboration in many aspects , empirical studies in [ 19 ] have shown that the effectiveness of an IAS is highly correlated to the number of participants ( or stakeholders ) and arguments . That is , when arguments keep accumulating in the system , the stakeholders need to spend more time and effort in reading and under - standing previous arguments posted by the stakeholders . This greatly reduces the effectiveness of an IAS . In practice , a stakeholder can obtain some general under - standing of an on - going argumentation progress in a short period of time by reading a summary or asking other stake - holders . However , in the existing IAS , a stakeholder needs to read many posted arguments to comprehend the current state of an argumentation . The time and the effort spent on reading a large amount of arguments are tremendous , and this sets up an obstacle for stakeholders to use the existing systems more effectively , especially when the number of arguments becomes considerably large . Let consider the following scenarios : • When a stakeholder has not followed an argumentation process dealing with an issue for some time , the system may have accumulated thousands of new arguments . Instead of reading all new arguments , it is in the best interest of the stakeholder to know only newly added relevant arguments . This can get the stakeholder involved in the argumentation as soon as possible . • When a stakeholder has a new idea or argument regarding the current argumentation , the stakeholder may want to know whether there is a similar idea already posted in the system by other stakeholders . The stakeholder may also what to know the best place to post his or her argument in relevant argumentation threads instead of examining through all the arguments . In general , stakeholders may post the same arguments or place arguments in less relevant places when the number of arguments increases . The duplicated arguments and improper placement will affect the decision making performance of an IAS . To improve the efﬁciency and effectiveness of an IAS when it becomes large , we need a component in the 978 - 1 - 4673 - 6404 - 1 / 13 / $ 31 . 00 ©2013 IEEE 427 current system that can assist a stakeholder to place his or her arguments . We term such a component as the recommendation component in an IAS . A . Our Contribution In this paper , we propose methods to implement the ar - gument placement recommendation component built into an existing IAS . The proposed recommendation component has the following beneﬁts for both a stakeholder and an IAS : • Duplication detection : Duplicated arguments are very common in an intelligent argumentation system . The duplicated or near duplicated arguments are redundancies to argumentation tree that need to be eliminated . By using our recommendation component , suspected duplicated arguments can be detected and provided to a stakeholder and a system administrator . This helps the stakeholder to reﬁne his or her arguments and the system adminis - trator to remove redundant arguments to make existing arguments in the IAS well organized . • Relevant argument retrieval : There can be thousands of arguments in an IAS . In this case , retrieving argu - ments based on a stakeholder’s interest is necessary . The proposed recommendation component can present related arguments and their summary to a stakeholder to help him or her obtain what is needed without spending a large amount of time in examining other irrelevant arguments . • Argument placement : In the existing IAS , a stakeholder determines where his or her arguments are posted in the current argumentation tree . When the current state of an argumentation contains thousands of arguments , the proper placement of a stakeholder’s arguments becomes very difﬁculty . To assist the stakeholder , the proposed recommendation component will suggest the stakeholder a list of potential locations in the argumentation tree . Among these locations , the stakeholder can pick the most suitable one to place his or her argument . The recommendation component can be implemented as an interactive process between a stakeholder and an IAS . By using the proposed component , we envision that the number of arguments read by a stakeholder will be largely reduced , and consequently , we can improve the effectiveness of an IAS . The rest of the paper is organized as follows : Section II provides an overview of existing argumentation systems and some information retrieval techniques necessary for the implementation of the proposed recommendation component . Section III presents our methodologies to implement the rec - ommendation component . Section IV shows the effectiveness of the recommendation component through extensive experi - mental results . Section V concludes the paper with some future research directions . II . R ELATED W ORK AND B ACKGROUND Argumentation is a process where communities can identify possible solutions for an existing problem and exchange their ideas to select the solution that best meets their needs [ 10 ] , [ 37 ] . A wide range of social computing technologies have developed to replace full / partial function of human argumen - tation process [ 3 ] , [ 4 ] , [ 7 ] , [ 11 ] , [ 15 ] , [ 20 ] , [ 21 ] , [ 25 ] , [ 27 ] , [ 33 ] , [ 35 ] . An argumentation system assists stakeholders to compre - hend information in system by organizing all arguments in an argumentation tree . Several empirical studies have shown the importance of an argumentation which generally helps institutions and organizations to make better decisions and other activities that need collaborative intelligence . An argu - mentation system is widely used in the ﬁelds of engineering design , project planning and social debate [ 13 ] , [ 16 ] , [ 18 ] . Toulmin proposed a model including six interrelated com - ponents for analyzing arguments [ 9 ] . Following Toulmin’s model , gIBIS , representing the design dialog as a graph [ 6 ] , was developed for argumentation based conﬂict resolution engineering design . The system represents the argumentation as a combination of issues , positions and arguments , but it does not support representations of requirements and outcomes . On the base of gIBIS , REMAP [ 26 ] provides the representation of goals , decisions , and design artifacts . Different from these system , Sillince [ 34 ] proposed a more general model of argumentation . Truethmapping [ 2 ] and Debategraph [ 1 ] follow the organization of tree structure , but do not provide decision making assistance to a stakeholder . Potts and Burns [ 5 ] developed a model that regards design argumentation as a combination of artifacts and deliberation nodes . In their model , artifacts represent speciﬁcation while deliberation nodes represent issues , alternatives or justiﬁca - tions . The progress and relation of deliberation is clear in such a model , but it does not provide additional decision making assistance . HERMES [ 24 ] was developed aid decision making . By structuring the argumentation as well as providing reasoning system , it not only captures the informal organiza - tional memory embodied in a decision making setting , but also helps users during a decision making process . Nevertheless , the system is not effective because its weighted system does not reﬂect the attitude of users . Research project Deliberatorium [ 14 ] enables large - scale collaboration on Internet and provides an online system that allows participants all over the world to argue on the same topic . The main limitation of the system is that there is no decision making assistance . That is , the system can organize argumentation content in a tree structure , but it lacks of functionality to analyze and quantify the result of an argumen - tation . Stakeholders cannot acquire any information without carefully check each argument . A . Intelligent Argumentation System An intelligent argumentation system ( IAS ) [ 16 ] organizes arguments in a tree hierarchy . As shown in Figure 1 , the root of the tree is the issue , which deﬁnes the problem we need to solve in current argumentation . All possible solutions to the issue are respectively described and listed on level 2 , which called alternatives . Issue and alternatives are identiﬁed in an IAS before stakeholders can add any new arguments . 428 Figure 1 . An IAS Hierarchy Stakeholders can only add an argument or an evidence under either an alternative or an argument . An argument is the basic element in IAS , which is posted by stakeholders and contains text content , weight , and connection with its parent argument . The text content of the argument is what a stakeholder used to defend or attack the argument’s parent argument . The weight of an argument is a real number between - 1 and 1 that expresses how strong a stakeholder defends or attacks the argument’s parent argument . Evidences can be added in connection to arguments . Its text content is restricted to support an argument only . It usually presents as a link , or other forms of published data . A priority is another attribute of an argument in an IAS . Each stakeholder has a priority score between - 1 and 1 that describes the degree of his or her inﬂuence in the current argumentation . There are also some tools for an IAS to detect abnormal groups of stakeholders and potential irrational behaviors based on the weight values , and evaluate the impacts caused by those behaviors . On the other hand , there is no mechanism in the existing IAS to support or uphold the validity of argument placement , which may cause some problem that affects the effectiveness of the system . B . Recommender System and Topic Detection Recommender systems [ 23 ] , [ 31 ] generally provide users recommendations for certain items based on the user proﬁles and information gathered from similar users . In our system , we do not have these user proﬁles and mechanisms to determine similar users , so techniques related to recommender systems cannot be directly applied . On the other hand , our work is more related to topic detection and tracking ( TDT ) study , initiated by DARPA , focuses on analyzing , measuring and classifying news stories based on their contents and published time . In the TDT research , the vector space model and Cosine similarity [ 12 ] are used to measure the related degree of news documents . In [ 30 ] , Schultz and Liberman improved the initial techniques by using idf - weighted Cosine coefﬁcient . However , this technique is highly correlated to the size of the documents and will largely increase the computational complexity . Yang et al . presented a method to reduce the computational complexity by using INCR - idf [ 38 ] . Among several different measurements of text relevance , tf - idf based Cosine similarity is commonly used because of its simplicity and proven effectiveness . At the ﬁrst glance , it seems possible to directly apply TDT techniques to implement our proposed recommendation component . However , the argument text in our problem do - main is very different from news stories in many aspects : ( 1 ) an argument is generally much shorter than a news article , so it may not contain sufﬁcient information to apply TDT techniques , ( 2 ) an argument is more colloquial and less logical than news articles , and ( 3 ) the placement of an argument follows a tree structure in an IAS , but a news story does not . The TDT algorithm cannot treat arguments as normal news stories while those differences exist , but some techniques proposed in the TDT research can be useful for text based information retrieval . Our recommendation metric is partially based on Cosine similarity measure with the tf - idf term weighting scheme . III . P ROPOSED M ETHODS TO I MPLEMENT THE A RGUMENT P LACEMENT R ECOMMENDATION AND R ELEVANCY A SSESSMENT C OMPONENT Figure 2 . Sample Argument Clusters When stakeholders join an argumentation process , there are two major actions : read and write . Stakeholder read arguments in an IAS to obtain background knowledge and track the latest progress of current argumentation . Then the stakeholders can express their own ideas toward the issue . In an IAS , two types of read actions from stakeholders alternate : simply browsing and reading with a particular interest . These activities help stakeholders explore the argumentation content in both breadth and depth . That is , stakeholders can get a general impression on an issue while browsing and gain an in - depth knowledge of a speciﬁc aspect of the issue while reading with a particular purpose . Similarly , when stakeholders write an argument , there are two common scenarios : ( 1 ) the stakeholders know the exact location in the current argumentation tree to place their arguments , and ( 2 ) the stakeholders are not certain where to place their new arguments due to a large number of relevant arguments in the IAS . Our recommendation and assessment component is designed to support the above scenarios for both read and write actions in an IAS as follows : 429 • When a stakeholder browses the arguments in the cur - rent argumentation tree and tries to obtain a general impression of current argumentation progress , instead of showing the entire argumentation tree , the recom - mendation component can group similar arguments into clusters and provide the summary of each cluster to the stakeholder . This saves the stakeholder’s time and helps the stakeholder to quickly get an overall knowledge of the current argumentation progress . • If a stakeholder has a speciﬁc interest , the stakeholder can encode his or her interest into a set of key words . Based on these key words , the proposed recommendation and assessment component can generate a list of top - k arguments or clusters most similar to his or her interest . If the size of cluster is large , the stakeholder has the option to let the system generate a list of top - k similar arguments within the cluster . • Similarly , when a stakeholder is about to place his or her arguments in the argumentation tree , the proposed component can generate a list of top - k potential locations for the placement of the stakeholder’s arguments . A . Interactive Recommendation and Assessment Process The recommendation and assessment component is an op - tional module that interacts with a stakeholder . It does not make any decisions for the stakeholder but provides suggestion to assist the stakeholder acquire useful or needed information and place his or her argument in an appropriate location in the argumentation tree . Depending on the different scenarios discussed previously , a stakeholder has options on what type of suggestion he or she needs ( e . g . , in - depth or breadth understanding of the current state of an argumentation ) . When an argumentation just started , the number of argu - ments in an IAS can be very small . Therefore , it is very likely that a stakeholder does not need to get feedback from the recommendation and assessment component at the beginning . On the other hand , when the number of arguments becomes very large , the stakeholder can turn on the recommendation and assessment component ( on his or her own discretion ) . From the technical perspective , the recommendation and as - sessment component is capable of producing the following information based on a stakeholder’s query 1 : top - k most similar arguments and top - k most similar clusters and their summaries ( Figure 2 ) . The top - k most similar arguments provide the stakeholder an in - depth understanding of the current argumentation related his or her query . On the other hand , The top - k most similar clusters and their summaries provide the stakeholder a breadth coverage of the current argumentation system . To implement the recommendation and assessment com - ponent , we need to develop methods to ﬁnd out relevant arguments or relevant clusters according to a stakeholder’s query . An argument cluster should satisfy two conditions : ( 1 ) 1 A stakeholder’s query refers to either a list of key words representing the stakeholder’s particular interest or the actual argument the stakeholders plans to post regarding the current argumentation . any argument in a cluster should be adjacent to at least one other argument in the same cluster , and ( 2 ) all arguments in a cluster are relevant to each other . The ﬁrst condition preserves the structure of an argumentation tree , while the second condition ensures that the clusters are useful from the perspective of information retrieval . In this paper , the original data is a set of arguments , each of which contains textual content , weight , link , posted time and a stakeholder’s ID . Here , we want to identify the relationship between the input query and each argument in the argumentation tree based on their textual contents . Thus , we only use the textual content of each argument and ignore other attributes of the argument . Once a stakeholder ﬁnd the best location to place his or her arguments , the stakeholder will decide the relationship ( either support or attack ) toward their parent arguments . There are three main tasks to implement the recommendation and assessment component : • Task 1 - argument representation : The original argu - ments are in forms of textual paragraphs , and our goal is to ﬁnd a method to convert textual paragraphs into representations that allow us to systematically measure information similarity . • Task 2 - relevance or similarity measure : Once the arguments are represented in a uniform way , we need to develop metrics to measure the relevance between any two arguments . We need to consider not only the similarity of their textual contents , but also their locations in the argumentation tree . • Task 3 - generating top - k similar arguments or clus - ters : Based on the similarity measures from task 2 , given an input query from a stakeholder , we can generate a list of either the top - k most similar arguments or the top - k most similar argument clusters . B . Argument Representation The original arguments in an IAS are paragraphs of texts . To make them mathematically meaningful and comparable , there are generally two common ways to represent them : the n - gram model [ 22 ] , [ 29 ] , [ 36 ] and the vector space model [ 12 ] , [ 32 ] . Each model has its own advantages . In this paper , we focus on the vector space model . Under this model , we convert the textual content of each argument into a global vector space where each dimension corresponds to a term in the argument and each entry contains the frequency information regarding the term . In addition , we also remove stop words , such as “not” , “is” , “are” . We consider those terms as noises . For different argument , the noisy term may be different , so we have a database for all common noisy terms as well as a special designed database for each argument topic . In the example given below , u and v are two arguments belonging to the same dataset . We ﬁrst build a global vector space G by collecting all terms from u and v . Then we ﬁlter out noisy terms . By computing the frequency of each term , we convert u and v into their corresponding term frequency vectors ~ u and ~ v . A concrete example is given below : 430 • Original argument : u : Sedan works better because it saves gas v : SUV is a better choice because it can go everywhere • Noisy terms : N = { because , it , is , a , can } • The global vector space : G = { better , choice , everywhere , gas , go , save , sedan , suv , work } • Generating the frequency vectors : ~ u = { 1 , 0 , 0 , 1 , 0 , 1 , 1 , 0 , 1 } ~ v = { 1 , 1 , 1 , 0 , 1 , 0 , 0 , 1 , 0 } C . Relevance / Similarity Measurement Cosine similarity is one of the most common metrics to identify similar textual information . To implement the rec - ommendation and assessment component , we adopt Cosine similarity in this paper . In addition , an IAS contains a large number of arguments organized in a tree structure . For any two given arguments , the closer the two arguments are in the tree , the more the two arguments are semantically similar . Therefore , our similarity metric between two arguments u and v is deﬁned as follows : sim ( u , v ) = α × cos ( u , v ) + β × dist ( u , v ) ( 1 ) where cos ( u , v ) denotes the Cosine similarity between u and v , and dist ( u , v ) denotes the shortest distance based measure between u and v in an argumentation tree . α and β are coef - ﬁcients that weight the importance of cos ( u , v ) and dist ( u , v ) . 1 ) Cosine Similarity and tf - idf Term Frequency : After fea - ture selection , each argument is represented as a vector with n - dimensional space , where n is the number of unique terms in all existing arguments in the current argumentation tree . Cosine similarity between u and v is given in Equation 2 : cos ( u , v ) = ~ u · ~ v | ~ u | | ~ v | ( 2 ) In the above equation , ~ u and ~ v are the frequency vectors of u and v . Both vectors contain tf - idf ( term frequency and inverse document frequency ) values [ 28 ] . These values have been proven to be very effective to identify similar textual information . 2 ) The Distance Metric between u and v : The distance between two arguments u and v in an argumentation tree is the normalized shortest path from u to v . Let T denote the current argumentation tree , diameter ( T ) denote the longest path between two arguments in T , and shortest path ( u , v ) denote the shortest path between u and v . Then dist ( u , v ) is deﬁned as : dist ( u , v ) = 1 − shortest path ( u , v ) diameter ( T ) ( 3 ) As mentioned previously , a stakeholder’s query is either an argument or a list of key words that represent the stakeholder’s interest . The proposed recommendation component ﬁrst con - verts the query into the vector space representation . Since the argumentation tree is dynamic , the global vector space changes Algorithm 1 Recommendation and Assessment Component Require : Input ( u , T , C , k 1 , k 2 , k 3 ) { u is the input query , T is an argumentation tree , C a set of clusters in T and the k values are user deﬁned thresholds } 1 : Generating top - k 1 similar arguments : 2 : for v i in T do 3 : Compute s i = cos ( u , v i ) 4 : end for 5 : Sort v i ∈ T in the decreasing order of s i 6 : return the top - k 1 arguments 7 : Generating top - k 2 similar clusters : 8 : for c i in C do 9 : Compute the center cc i of c i 10 : Compute s i = cos ( u , cc i ) 11 : end for 12 : Sort c i ∈ C in the decreasing order of s i 13 : return the top - k 2 clusters 14 : Summarization : 15 : for c i in C do 16 : Computer the frequencies of each term in c i 17 : Sort the terms in c i in the decreasing order of their term frequencies 18 : return the top - k 3 most frequent terms in c i 19 : end for whenever a new argument is added to the tree . Therefore , the global vector space used in the conversion process depends on the arguments in the current argumentation tree . The same query may have different vector space representations when it is inputed to the system . D . Implementation of the Recommendation and Assessment Component After the input query is converted , the recommendation and assessment component generates the expected outcome according to the option selected by the stakeholder . There are two types of outcome : top - k most similar arguments and top - k most similar clusters with their summaries . To generate the top - k most similar arguments , the recommendation and assessment component only adopts Cosine similarity due to the fact that the location of the input query in the argumentation tree is unknown . However , to generate the top - k clusters , the recommendation and assessment component uses both Cosine similarity and the metric presented in Equation 1 . Initially , the recommendation and assessment component clusters the arguments in the current argumentation tree . Our proposed similarity measure sim ( u , v ) is used as the metric to guide the clustering process . Once the clusters are formed , the input query is compared with each cluster center using Cosine similarity to generate a list of top - k most similar clusters . The main steps performed by the recommendation and assessment component are presented in Algorithm 1 , including the two main options : generating the top - k most similar argu - ments , and generating the top - k most similar clusters and their summaries . To generate the summarization information , the 431 recommendation and assessment component current returns the top - k most frequent terms in each cluster . However , other text summarization techniques ( e . g . , [ 8 ] , [ 17 ] ) can be built directly into the recommendation and assessment component . Once a stakeholder ﬁnalized the placement of his or her argument , the component will analyze the relationship between the newly added argument and its nearby neighboring argu - ments , and cluster it based on the current existing clusters . That is , each time a new argument is added to an IAS , the recommendation and assessment component executes a singleton clustering process , and either puts the argument in a cluster or makes the argument as the seed of a new cluster . In our approach , the threshold t is pre - selected threshold , which decides whether an argument is relevant and to be potentially grouped into a cluster . The distance between an argument and a cluster center is calculated using the distance metric deﬁned in Equation 1 . The main steps of the clustering process are described in Algorithm 2 . Algorithm 2 Clustering Require : u , C , t , where u is a newly added argument , C is a set of clusters in T , and t is a user deﬁned threshold 1 : m = | C | 2 : for c i in C do 3 : Compute the center cc i of c i 4 : Compute s i = sim ( u , cc i ) { using Equation 1 } 5 : end for 6 : Find c j such that s j = max ( s 1 , . . . , s m ) 7 : if s j > t then 8 : c j = c j ∪ { u } 9 : else 10 : c m + 1 = { u } { adding a new cluster } 11 : C = C ∪ c m + 1 12 : end if After a stakeholder ﬁnalizes the placement of his or her argument , if the placement is very different from the location suggested by the recommendation component , the argumen - tation system can record and analyze all activities done by the same stakeholder , and alert the system administrator . This can assist the system administrator to detect inappropriate behaviors or malicious acts from the stakeholder . IV . E MPIRICAL E VALUATION The objective of this empirical study is to evaluate whether our recommendation and assessment component can effec - tively assist a stakeholder to place his or her argument and obtain a general knowledge regarding the current state of an argumentation . We also would like to see how much effort a stakeholder could be potentially saved . Note that our current experimental results were generated through a simulation process where we adopted an existing argumentation dataset and selected a subset of relevant arguments for performing subsequent recommendations . A . Dataset Description The data were generated through an argumentation process using the system developed in [ 19 ] . The experiment was conducted with a group of 24 stakeholders who were recruited from a software engineering class . In this study , stakeholders were asked to provide their opinions on selection of soft - ware quality assurance and testing strategy for a software development organization . Three alternatives were under con - sideration . The requirement and background of the software development were also given as a part of issue description . Stakeholders argued with one another according to their own understanding of the software development , and its quality , cost and other requirements . They shared 205 arguments , and among these argument , 97 of them are comments on alternatives and the rest arguments are directly associated with the earlier arguments . Our experiments were conducted on this dataset . Note that according to our observation , the running time of the recommendation and assessment component is negligible . As a result , we do not report the actual running time here . B . Evaluation Methodology From the dataset discussed above , we reconstructed the argumentation process by sequentially adding arguments into the system according to their submitted time stamps . Each time an argument was added into the system as a newly submitted argument , the recommendation and assessment component produced a list of the top - k most similar arguments or clusters . By comparing the argument’s original location with those of the recommended arguments in the top - k list or clusters , we can evaluate the accuracy of the proposed implementation of the recommendation and assessment component . We randomly selected ten arguments for this evaluation study . C . Evaluation of the Top - k List of Arguments Under this evaluation , the recommendation and assessment component produces a list of top - k most similar arguments to a stakeholder based on the similarity metric we described in Sec - tion III . In our study , we randomly picked 10 arguments from 50 latest posted arguments in system as testing samples . The reason to select from the most recently posted 50 arguments is that at the beginning of argumentation , a stakeholder does not need any assistance to post his or her arguments . When the number of arguments accumulates , the stakeholder is likely to switch on the recommendation and assessment component . Therefore , in our experiments , we simulated this scenario , and we only focused on the most recent added arguments . The results are shown in Figure 3 . According to the ﬁgure , four of the ten arguments were contained in their corresponding lists of the top - 5 most similar arguments , and nine of the ten arguments were contained in their corresponding lists of the top - 40 most similar arguments . On average , each of the ten arguments is expected to be contained in a list of the top - 15 most similar arguments . Therefore , a stakeholder is expected to read 15 / 205 ≈ 7 . 3 % of the total number of arguments to ﬁnd the appropriate location 432 Figure 3 . The top - k most similar arguments for his or her argument when using the recommendation and assessment component . In other words , it is very likely that the proposed component can help a stakeholder save much time and effort during the argumentation process without degrading the quality of the results . D . Evaluation of Top - k List of Clusters Figure 4 . The top - k most similar clusters In this experiment , we selected the same ten arguments as in the last experiment , and the recommendation and assessment component produced a list of top - k most similar clusters . The system clustered all 205 arguments into 18 clusters . The results are shown in Figure 4 . According to the ﬁgure , four of the ten arguments were contained in their corresponding lists of the top - 2 most similar clusters , and nine of the ten arguments were contained in their corresponding lists of the top - 5 most similar clusters ( the results are the same for k = 6 ) . On average , each of the ten arguments is expected to be contained in a list of the top - 3 most similar clusters . E . Cluster Summarization When the cluster size is large , to help a stakeholder to effectively and quickly choose the right cluster to read , the recommendation and assessment component can provide a summary for each cluster . Even if a stakeholder does not have much background knowledge regarding the issue and its al - ternatives , the stakeholder may obtain some information from these summaries . As stated previously , the empirical results were generated from an argumentation process conducted in a software engineering course , in which each stakeholder was a computer science student who knew basic concept of software development . Table I shows summaries of a list of the top - 5 most similar clusters that the recommendation component provided to a stakeholder in response to a query at a particular time . The summary contains a few top most frequent terms . In addition to generating cluster summaries , we can also generate a top - k list arguments within a large cluster . Alter - natively , we can further break a large cluster into a set of smaller clusters . We will added these alternative solutions to the recommendation and assessment component in the future . V . C ONCLUSION AND F UTURE W ORK When the number of arguments in an intelligent argumenta - tion system ( IAS ) increases , its effectiveness in assisting stake - holders to make wise decisions in the current IAS becomes limited . Thus , in this paper , we proposed a recommendation and assessment component ( built into an IAS ) that can help stakeholders to navigate through thousands of arguments more efﬁciently and effectively . One key challenge remain for the current system is the calculation of the threshold t . When the number of arguments is small , learning the value of t can be difﬁcult . However , when there are many arguments in an IAS , we can select a random sample to determine the best value for t . Since the argumentation tree is dynamic in nature , the value t needs to be updated once a while . The arguments in an IAS are generally short texts . As a future work , to further improve the accuracy of the proposed recommendation and assessment component , we will explore the relevant techniques in the ﬁeld of Pragmatics that pro - vide alternative ways to represent and analyze arguments . In addition , we will conduct user studies to determine how our system inﬂuences stakeholders during an argumentation using or without using the recommendation component . In our current implementation , Cosine similarity is used as part of our similarity metric . In the future , we will evaluate how other similarity metrics work in our system . Furthermore , as stated in Section III , the vector space model and the n - gram model are two most common and effective ways to represent textual information . The vector space has the advantage to identify global similarity , such as common sets of terms . On the other hand , the n - gram model has the advantage to identify local similarity , such as common text fragments . We will im - plement the recommendation and assessment component using the n - gram model . We hope that the two implementations will complement each other . R EFERENCES [ 1 ] Debate graph . http : / / debategraph . org / stream . aspx ? nid = 61932iv = 05 . [ 2 ] Truth mapping . http : / / www . truthmapping . com / . [ 3 ] I . Benbasat and J . Lim . Information technology support for debiasing group judgments : an empirical evaluation . Organizational Behavior and Human Decision Processe , 83 : 167 – 183 , 2000 . [ 4 ] R . J . Boland , A . K . Maheshwari , D . Teeni , D . Schwartz , and R . V . Tenkasi . Sharing Perspectives in Distributed Decision Making . Computer - Supported Cooperative Work , 1992 . [ 5 ] Potts C . and Burns G . Recording the reasons for design decisions . Proceedings of the 10th international conference on Software engineering , Singapore , pp . , pages 418 – 427 , 1988 . 433 TABLE I S UMMARIZATION OF SELECTED CLUSTERS Cluster ID Size Cluster Summaries 1 53 software metrics comprehensive program activities opposing development money phases business 2 20 software unpredictable metrics adopted wrong worthless quality task bring rate 5 17 metrics projects going weight company light program large estimate market 9 3 gives incorrectly faced eliminates company proof projects historical discomﬁted allow 10 4 building development organization metrics comprehensive large need software management real [ 6 ] Conklin , Jeff , Begeman , and Michael L . gibis : A hypertext tool for exploratory policy discussion . ACM Transactions on Information Systems ( TOIS ) , 6 : 303 – 331 , 1998 . [ 7 ] G . Convertino , D . Billman , J . Shrager , P . Pirolli , and J . P Massar . The cache study : Group effects in computer - supported collaborative analysis . Journal of Computer Supported Cooperative Work , 17 : 353 – 393 , 2008 . [ 8 ] Dipanjan Das and Andr´e F . T . Martins . A survey on automatic text summarization , 2007 . [ 9 ] Toulmin S . E . In The Uses of Argument . Cambridge , UK , University Press , 1958 . [ 10 ] F . H . v . Eemeren and R . Grootendorst . A Systematic Theory of Argumentation : The Pragmadialectical Approach . Cambridge University Press , 2003 . [ 11 ] Shelly Farnham , Harry R . Chesley , Debbie E . McGhee , Reena Kawal , and Jennifer Landau . Structured online interactions : Improving the decision - making of small discussion groups . In Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work , pages 299 – 308 , Philadelphia , Pennsylvania , December 2 - 6 2000 . [ 12 ] Karen Sparck Jones and Peter Willett ( editors ) . Readings in Information Retrieval . Morgan Kaufmann , San Francisco , California , USA , 1997 . [ 13 ] M . Klein and L . Iandoli . Supporting collaborative delibera - tion using a large - scale argumentation system : The mit collaborato - rium . MIT Sloan Research Paper No . 4691 - 08 , Available at SSRN : http : / / ssrn . com / abstract = 1099082 . [ 14 ] Mark Klein . Achieving collective intelligence via large - scale on - line argumentation . CCI Working Paper 2007 - 001 , MIT Sloan School of Management Working Paper 4647 - 07 , 2007 . [ 15 ] K . Kramer and J . King . Computer - based systems for coperative work and group decision making . Computing Surveys , 20 : 115 – 146 , 1988 . [ 16 ] Frank Liu , Ekta Khudkhudia , Lei Wen , Vamshi Sajja , and Ming Leu . Chapter 9 : An intelligent computational argumentation system for supporting collaborative software development decision making . In Artiﬁcial Intelligence Applications for Improved Software Engineering Development : New Prospects , pages 167 – 180 . IGI , 2009 . [ 17 ] Kun Liu , Evimaria Terzi , and Tyrone Grandison . Manyaspects : A system for highlighting diverse concepts in documents . In VLDB ’08 : Proceedings of the 34rd International Conference on Very Large Data Bases , Auckland , New Zealand , August 2008 . [ 18 ] X . F . Liu , S . Raorane , and M . Leu . A web - based intelligent collaborative system for engineering design . In Collaborative Product Design and Manufacturing Methodologies and Applications , pages 37 – 58 . Springer , 2007 . [ 19 ] Xiaoqing Liu . Empirical study of an intelligent argumentation system in mcdm . Collaboration Technologies and Systems ( CTS ) , 2011 , pages 125 – 133 , May 2011 . [ 20 ] R . Luppicini . Review of computer mediated communication research for education . Instructional Science , 35 : 141 – 185 , 2007 . [ 21 ] L . A . Macaulay and A . Alabdulkarim . Facilitation of e - meetings : State - of - the - art review . e - Technology , e - Commerce and e - Service , 2005 . [ 22 ] Udi Manber . Finding similar ﬁles in a large ﬁle system . Technical Report TR 93 - 33 , Department of Computer Science , The University of Arizona , Tucson , Arizona , October 1993 . [ 23 ] Stuart E . Middleton , Nigel R . Shadbolt , and David C . De Roure . Ontological user proﬁling in recommender systems . ACM Trans . Inf . Syst . , 22 ( 1 ) : 54 – 88 , January 2004 . [ 24 ] Karacapilidis N . and Papadias D . Hermes : Supporting argumentative discourse in multi - agent decision making . Proceedings of the 15th National Conference on Artiﬁcial Intelligence ( AAAI ) , Madison , WI , AAAI / MIT Press , pp . , pages 827 – 832 , 1998 . [ 25 ] G . P . Pervan and D . J . Atkinson . Gdss research : An overview and historical analysis . Group Decision and Negotiation , 4 : 475 – 483 , 1995 . [ 26 ] B . Ramesh and V . Dhar . Supporting system development by capturing deliberations during requirements engineering . IEEE Transaction on Software Engineering , 18 : 498 – 510 , 1992 . [ 27 ] P . Reagan - Cirincione . Improving the accuracy of group judgment : a process intervention combining group facilitation , social judgment analysis , and information technology . Organizational Behavior and Human Decision Processes , 58 : 246 – 270 , 1994 . [ 28 ] Gerard Salton , James Allan , and Chris Buckley . Automatic structuring and retrieval of large text ﬁles . Communications of the ACM , 37 ( 2 ) : 97 – 108 , February 1994 . [ 29 ] Saul Schleimer , Daniel S . Wilkerson , and Alex Aiken . Winnowing : Local algorithms for document ﬁngerprinting . In Proceedings of the ACM SIGMOD Conference on Management of Data , pages 76 – 85 , San Diego , California , United States , June 9 - 12 2003 . ACM . [ 30 ] J . Michael Schultz and Mark Liberman . Topic detection and tracking using idf - weighted cosine coefﬁcient . In Proceedings of the DARPA Brocast News Workshop , pages 189 – 192 . Morgan Kaufmann Publishers , Inc , 1999 . [ 31 ] Andriy Shepitsen , Jonathan Gemmell , Bamshad Mobasher , and Robin Burke . Personalized recommendation in social tagging systems using hierarchical clustering . In Proceedings of the 2008 ACM conference on Recommender systems , RecSys ’08 , pages 259 – 266 , New York , NY , USA , 2008 . ACM . [ 32 ] Narayanan Shivakumar and Hector Garcia - Molina . SCAM : A copy detection mechanism for digital documents . In Proceedings of the 2nd International Conference in Theory and Practice of Digital Libraries ( DL’95 ) , Austin , Texas , USA , June 11 - 13 1995 . [ 33 ] Jeff Shrager , Dorrit Billman , Gregorio Convertino , J . P . Massar , and Peter Pirolli . Soccer science and the bayes community : Exploring the cognitive implications of modern scientic communication . Topics in Cognitive Science , 2 : 53 – 72 , January 2010 . [ 34 ] J . Sillence . Intelligent argumentation systems : Requirements , models , research agenda , and applications . Encyclopedia of Library and Informa - tion Science , pages 176 – 217 , 1997 . [ 35 ] H . S . Smallman . JIGSAW – joint intelligence graphical situation awareness web for collaborative intelligence analysis . In Macrocognition in Teams : Theories and Methodologies , pages 321 – 337 , 2008 . [ 36 ] Daria Sorokina , Johannes Gehrke , Simeon Warner , and Paul Ginsparg . Plagiarism detection in arXiv . In Sixth IEEE International Conference on Data Mining ( ICDM06 ) , pages 1070 – 1075 , Hong Kong , China , December 18 - 12 2006 . [ 37 ] D . N . Walton and E . C . W . Krabbe . Commitment in dialogue : Basic concepts of interpersonal reasoning . Albany , NY : State University of New York Press , 1995 . [ 38 ] Yiming Yang , Jaime Q . Carbonell , Ralf D . Brown , Thomas Pierce , Brian T . Archibald , and Xin Liu . Learning approaches for detecting and tracking news events . IEE Intelligent System , Junly / August : 32 – 43 , 1999 . 434