Prompting for Discovery : Flexible Sense - Making for AI Art - Making with DreamSheets Shm Garanganao Almeda J . D . Zamfirescu - Pereira Kyu Won Kim Pradeep Mani Rathnam Bjoern Hartmann UC Berkeley Berkeley , CA , USA ABSTRACT Design space exploration ( DSE ) for Text - to - Image ( TTI ) models entails navigating a vast , opaque space of possible image outputs , through a commensurately vast input space of hyperparameters and prompt text . Minor adjustments to prompt input can surface un - expectedly disparate images . How can interfaces support end - users in reliably steering prompt - space explorations towards interesting results ? Our design probe , DreamSheets , supports exploration strategies with LLM - based functions for assisted prompt construc - tion and simultaneous display of generated results , hosted in a spreadsheet interface . The flexible layout and novel generative func - tions enable experimentation with user - defined workflows . Two studies , a preliminary lab study and a longitudinal study with five expert artists , revealed a set of strategies participants use to tackle the challenges of TTI design space exploration , and the interface features required to support them – like using text - generation to define local “axes” of exploration . We distill these insights into a UI mockup to guide future interfaces . CCS CONCEPTS • Human - centered computing → Interaction paradigms . ACM Reference Format : Shm Garanganao Almeda J . D . Zamfirescu - Pereira Kyu Won Kim Pradeep Mani Rathnam Bjoern Hartmann . 2024 . Prompting for Dis - covery : Flexible Sense - Making for AI Art - Making with DreamSheets . In Proceedings of arXiv Preprint . ACM , New York , NY , USA , 13 pages . https : / / doi . org / 10 . 1145 / nnnnnnn . nnnnnnn 1 INTRODUCTION Text - to - Image ( TTI ) models like DALL•E [ 33 ] and Stable Diffu - sion [ 37 ] generate images from a combination of text prompts and numerical parameters ( e . g . , random seeds ) . Such models are wide adoption in a variety of settings , from marketing collateral to inde - pendent art making . A critical skill for users of Text - to - Image ( TTI ) models is un - derstanding the relationships between prompt text inputs and im - age outputs . Building such an understanding is neither trivial nor Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . arXiv Preprint , , © 2024 Copyright held by the owner / author ( s ) . ACM ISBN 978 - x - xxxx - xxxx - x / YY / MM . https : / / doi . org / 10 . 1145 / nnnnnnn . nnnnnnn straightforward [ 48 , 49 ] : the spaces of possible inputs and outputs are massive , and the mapping of one to the other is highly opaque . Current patterns in commercial interfaces present limited sup - port for exploration : a text box for prompt input and an area for displaying and saving a few output images . Some offer a number of additional features to support prompt - engineering : canned prompt ideas , including options to influence “style , " and sliders for manipu - lating hyperparameters . This lack of explicit interface support has led to the creation of resources such as community - curated prompt books [ 28 ] , spread - sheets [ 46 ] , and tutorials [ 27 , 39 ] that document exploration pro - cesses . Researchers have also begun to study prompting prac - tices [ 3 , 16 , 21 ] and to propose alternative interfaces for interacting with TTI ( e . g . , Promptify [ 2 ] ) and other types of generative models ( e . g . , GanZilla [ 9 ] , Spacesheets [ 24 ] ) . These systems tend to support particular prompt - image workflows , supporting users in refining prompts towards a goal . In this paper we argue that supporting Text - To - Image users goes beyond ensuring that they can achieve a particular end result : gain - ing an understanding of the mapping between input and output is core to successful co - creation with generative AI systems . Exploring the relationship between TTI inputs and outputs is a sensemaking process [ 31 , 38 ] where users aim to build mental representations that allow them to reliably produce desired outputs . While the input and output spaces are massive and opaque , they are not arbitrary : prompters can develop reliable " navigation " strategies with thought - ful observation and experience . By evaluating many input - output examples , users can begin to sense patterns , learning to predict where their prompt will map to in output space , through a particular model . They can then use this information for crafting and steering inputs towards desirable results . Thus , our guiding research question is : How might new interfaces best support users in sensemaking for successful art making with such models ? To investigate this question , we built DreamSheets , a tool that enables TTI users to develop their own exploration strategies within a spreadsheet interface . In DreamSheets , spreadsheet cells can contain prompts , or images generated from those prompts . A set of novel prompt manipulation functions enable users to explore prompt space through the construction and strategic combination of categorical lists , alternative wordings , embellishments , synonyms , and more . These functions are implemented through prompts to a large language model ( LLM ) . Spreadsheets may not readily provide the ideal affordances for organizing imgage collections ; however , they are a highly flexible substrate for what - if exploration ; by presenting image and text generation tools within a customizable sandbox , DreamSheets a r X i v : 2310 . 09985v1 [ c s . H C ] 15 O c t 2023 arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann enables users to define their own workflows for sensemaking with formula construction and layout design . We investigated users’ exploration strategies in two studies with DreamSheets : a 1 - hour lab study with 12 primarily amateur par - ticipants , and a two - week longitudinal study with five expert TTI artists . In these studies , we examined how both groups ( 1 ) develop intuition for prompt designs that yield specific outputs , and ( 2 ) use DreamSheets’s affordances for computational prompt manip - ulation , workflow creation , and output evaluation . Our primary insights lie in : ( 1 ) Observing patterns in the user - defined strategies and sup - port structures utilized by participants in DreamSheets throughout their TTI exploration journeys , as they discover new creative directions and shift creative control to and from the generative system ; and ( 2 ) How the sensemaking insights and skills users develop as they sample information across input and output space in - teract with visual communication skills , critical for success in prompt - image domains and , potentially , beyond . We use these insights to generate a UI mockup to inform po - tential future interfaces , and report on feedback on these mockups from our participants . Our contribution is three - fold : ( 1 ) DreamSheets , a flexible platform for exploring the joint design space of prompts , seeds , and other TTI hyperparame - ters . ( 2 ) The first ( to our knowledge ) longitudinal study of experi - enced artists using TTI models , focused on understanding how artists use these models and how they make sense of the prompt design space . ( 3 ) A set of UI design suggestions , co - designed in a visual UI mock - up with our artist participants , to enable the kinds of sense - making they pursued while working in DreamSheets . 2 RELATED WORK Our work here builds on prior research showing that considering many alternatives in parallel can effectively aid design space ex - ploration [ 14 , 34 ] , such as through gallery interfaces [ 26 ] , tracking exploration history [ 15 , 18 ] , offering suggestions for possible input shifts [ 26 ] , and effective organization [ 25 , 36 , 45 ] . Spreadsheets en - able many of these abilities where commonly - used TTI interfaces lack them . In this section , we draw explicit connections with Creativity Support Tools , prompting and other TTI model workflows , design space exploration of images in non - TTI contexts , and sensemaking . 2 . 1 Creativity Support In 2007 , Shneiderman identified four underlying design principles for creativity support tools ( CSTs ) : support exploratory search , en - able collaboration , provide rich history - keeping , and design with low thresholds , high ceilings , and wide walls [ 41 ] . A more recent body of research explores how CST design can aid users’ creative processes and productivity [ 5 , 10 ] . Spreadsheets are themselves an example of a tool that supports creative exploration , enabling users to sepa - rate fixed values from values they want to vary , affording effective exploration and evaluation of “what - if” scenarios [ 35 , 41 ] . 2 . 2 Prompting & Text - to - Image Model Workflows At the surface , prompting can appear straightforward , but craft - ing effective prompts is a challenge [ 22 , 48 , 49 ] . How a prompt directly impacts model outputs is an active area of research [ 20 , 40 ] . Choosing the right language to achieve desirable visual results in these prompt - based interactions can be difficult , presenting challenges for users seeking to reliably harness TTI systems to - wards creative goals [ 49 ] ; this has motivated online user communi - ties [ 8 , 32 ] and researchers to develop and investigate new prompt - ing techniques [ 22 , 23 ] and tools supporting prompt discovery and exploration [ 2 , 12 ] . These tools tend to be goal - driven , helping artists elicit the images they already have in mind , and showing them alternatives—rather than explicitly supporting sensemaking as DreamSheets does . 2 . 3 Design Space Exploration of Images These prompt discovery tools in fact continue a long line of research into design space exploration of images . When visual judgment of an artifact produced by a human designer is the primary method of evaluation , as it is in computer graphics and animation , prior work has often focused on browsing interfaces , such as in Marks et al . ’s seminal Design Galleries [ 26 ] . Interaction techniques for browsing include multi - step galleries [ 26 ] ; map metaphors [ 43 ] ; or faceted browsing [ 13 ] . Narrowing down from the explored designs , users may wish to pursue multiple alternative options for deeper exploration , though typically many orders of magnitude fewer than the number of algorithmically explored designs , as in GEM - NI [ 47 ] . Spreadsheets’ usefulness for visual design space exploration in part stems from the intrinsic 2D matrix layout enabling “small multiples” , a term Edward Tufte popularized [ 44 ] as an answer to the question “compared to what ? ” In a 2D matrix , a large number of images can be readily compared with each other , and the best candidate images identified . Spreadsheets have a rich history of serving as vehicles for exploratory work , in accounting and far beyond – – utilized as early as 1994 for information visualization of data and images themselves [ 4 , 19 ] , including images generates from a numerical input space [ 24 ] 2 . 4 Sensemaking A number of our observations relate to the broader sense - making literature , including Pirolli and Card’s seminal work on information foraging [ 30 ] —DreamSheets offers users an information scent on prompts—and sensemaking more broadly [ 31 , 38 ] . This line of work models how users navigate and make decisions in information - rich environments ( like DreamSheets ) , balancing between the perceived cost of seeking information and the potential reward of finding what they’re seeking . DreamSheets’s design draws upon the free energy principle of the brain theory from cognitive science [ 11 ] which describes how the brain reduces uncertainty by making predictions and updating an internal mental model ac - cordingly , generatively optimizing its internal model with sensory input to enhance prediction accuracy . This principle formed a ba - sis for Davis et . al’s Creative Sense - Making ( CSM ) framework [ 7 ] , which they applied to human - AI co - creation in the collaborative drawing domain . DreamSheets’s design also draws inspiration DreamSheets arXiv Preprint , , Function Name Description tti ( prompt , [ seed ] , [ cfg ] ) Generate an image ( at the returned URL ) using the given prompt and , optionally , seed and a classifier - free guidance ( cfg ) parameters . gpt ( prompt ) LLM function for arbitrary prompt . gpt _ list ( prompt , length ) Populates length cells in a row ( or column ) with words / phrases of type prompt . list _ completion ( prompt ) Like gpt _ list , but prompt is a list of items , rather than a description . synonyms ( prompt ) Generates a list of synonyms . antonyms ( prompt ) Generates a list of antonyms . divergents ( prompt ) Generates “divergent” words . alternatives ( prompt ) Generates a list of alternative word - ings for prompt . embellish ( prompt ) Generates an embellished alterna - tive to prompt , commonly using more specific or detailed words . Table 1 : The LLM - based functions available in our prototype . Each list - producing function additionally has an _ t alter - native ( e . g . , synonyms _ t ) that transposes the output into a column . and lessons from existing sensemaking interfaces – including clas - sics like Scatter / Gather [ 6 ] and more modern implementations like Sensecape [ 42 ] . 3 PROMPT & IMAGE EXPLORATION WITH DREAMSHEETS DreamSheets leverages the spreadsheet model in support of itera - tion and exploration of the TTI generation prompt input space . The features of DreamSheets are embedded within a spreadsheet ( built on Google Sheets ) that recomputes and re - renders images , allowing drag - based “autofill” and other common spreadsheet functionality . DreamSheets offers access to diffusion model image generation as a spreadsheet function that can take the content of other cells in the sheet as input , including combinations or transformations of multi - ple cells . These features support the user in efficiently exploring , observing how generated outputs are influenced by modifications to the input . To aid prompt exploration , our prototype also includes a set of LLM - based functions for manipulating prompts directly , including gpt _ list and list _ completion for generating or extending a list of items of a certain description , embellish to create a detailed variation of the input text , and alternatives to generate multiple variations of a seed prompt ( see Table 1 for a full list ) . 3 . 1 Design From a design perspective , integrating TTI model functionality was relatively straightforward—we devoted significant design energy to developing a set of prompt exploration functions ( see Table 1 ) , themselves based on prompting a LLM . Drawing on prior work in prompt design , we identified the test - ing of alternative phrasings and the addition of detail as core ac - tivities in TTI prompt exploration [ 22 , 28 ] . These activities help users explore neighboring points in design space and recognize fruitful directions for further prompt explorations . We operational - ized support for these activities as the alternatives , divergents , and embellish functions . Similarly , synonym and antonym gen - eration are core NLP building blocks , useful for creating variation that targets specific wordsin a longer prompt—we integrated these capabilities through the synonyms and antonyms functions . Critically , to use these concepts in a spreadsheet paradigm and support the generation of sets of images , we designed these func - tions to output lists of values that populate across a column ( or row ) of cells . These variations can be referenced by cell in traditional spreadsheet style and used as prompts , or concatenated with other values to form longer prompts . We also provided functions to extend lists of prompts or prompt parts , allowing users to build on a conceptual list by providing a few initial examples . 3 . 2 DreamSheets Implementation We explored different services to provide the underlying spread - sheet functionality for DreamSheets , including building our own spreadsheet interface from scratch , open source spreadsheets Hand - sOnTable 1 and LuckySheet 2 , and both Excel and Google Sheets . One major challenge in integrating with an existing spreadsheet is the relatively long latency of image generation itself : up to 15 seconds or more , even when using cloud APIs . Spreadsheet users are accustomed to rapid updates and recomputations in response to changes in cell values—a multi - minute delay resulting from a backlog of image prompt updates and , consequently , new image generations , would be unacceptably slow . This need drove our use of the Stability . ai API , 3 which supports parallel image generation requests with the Stable Diffusion 2 model , and offers sub - 15 sec - ond response times . This critically enabled the full - scale “small multiples” visualizations of results that we wanted users to be able to utilize to view and evaluate results across multiple input axes simultaneously . Ultimately , we selected Google Sheets as the spreadsheet inter - face , as it is easily extensible and accessible to most people . Google Sheets’ Apps Script environment lets developers create add - ons in a JavaScript - like environment , has a sufficiently long timeout ( 30 seconds ) for custom functions , and allows users to continue to edit the sheet even while our custom formulas , which required back - end calls to TTIs and LLMs , awaited responses . As a side benefit , because Google Sheets is already an online - native platform , rapid collaboration and version history are built - in . We implemented DreamSheets as a Google Sheets Apps Script add - on and a proxy web server written in JavaScript using Ex - pressJS . The add - on adds custom functions described in Table 1 , making the corresponding requests to the proxy web server which 1 https : / / handsontable . com 2 https : / / github . com / dream - num / Luckysheet 3 https : / / api . stability . ai / docs arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann Prompt / Seeds 4235 542626 92904 persian 🐈 🐈⬛ 😽 sphynx 😸 🗿 🐱 siamese 🐈 😿 😽 Stability . ai API OpenAI GPT - 3 API TTI Endpoint LLM Endpoint TTI Prompt Cache Prompt Seed CFG Image Moon over skyline… 4325 0 . 3 🌃 Golden Gate bridg… 4141 0 . 9 🌉 Bridge in fog shr… 9481 0 . 1 🌁 ﹦ GPT _ LIST ( " cats " ) ﹦ IMAGE ( TTI ( " a " & $ A4 & " cat " ) ) DreamSheets Cloud Server DreamSheets User Interface A B C D Figure 1 : The DreamSheets implementation . LLM ( A ) and TTI ( B ) functions fetch from separate endpoints of the DreamSheets cloud server ( C ) which forwards requests to the OpenAI ChatGPT and Stability . ai Stable Diffusion cloud - based APIs . TTI requests are cached ( D ) using a hash of ( prompt text , seed , classifier - free guidance ) as a key . handles caching and calling the appropriate API to either Stabil - ity . ai or OpenAI . Figure 1 illustrates how the proxy server facilitates communication between the Google Sheets add - on and Stability . ai or OpenAI . For the tti function , the proxy server makes a hash using a combination of the prompt , seed , and guidance values and checks if the image has been generated before . Otherwise , an API call is made to Stability . ai to generate a 512 × 512 - pixel image which is then cached in the file system for easy retrieval in the future . The LLM - based functions that return a list utilizes OpenAI’s ChatGPT with gpt - 3 . 5 - turbo . To ensure that ChatGPT returns a properly formatted list with the appropriate length , it is initialized with the following messages : system : Respond with a Javascript array literal with the given length in parentheses user : types of animals ( length : 5 ) " assistant : [ " dog " , " cat " , " frog " , " horse " , " deer " ] user : [ PROMPT ] ( length : [ LENGTH ] ) The implementation for each LLM - based function differs only in the prompt sent to the LLM proxy server : each function prepends different additional instructions to the user’s inputted prompt . The complete list of full prompts sent to ChatGPT are : list _ completion Similar items to this list without repeating " [ LIST ] " synonyms Synonyms of " [ USER INPUT ] " antonyms Antonyms of " [ USER INPUT ] " divergents Divergent words to " [ USER INPUT ] " alternatives Alternative ways to say " [ USER INPUT ] " embellish Embellish this sentence : [ USER INPUT ] 4 METHOD Having built DreamSheets , we first ran a preliminary 1 - hour lab study with novice users to understand how users approach using DreamSheets for TTI exploration ; this revealed that DreamSheets enables a variety of custom workflows , but that sensemaking was nearly always among the first activity participants engaged in . Following this study , we ran a second , 2 - week longitudinal study with expert users . This second study was intended explicitly to bet - ter understand the kinds of custom workflows experts would build for sensemaking , given enough time , and what kinds of individual activities those sensemaking workflows consisted of . 4 . 1 Preliminary Lab Study In this initial study , we sought to observe how participants used DreamSheets to define and use a text - to - image generation work - flow ; we gave participants a concrete task and training in the tool , but did not direct them beyond that . 4 . 1 . 1 Participants . We recruited 12 participants via email lists and social media . All 12 reported some spreadsheet experience , with most ( 10 out of 12 ) reporting frequent use ( many times or daily ) . 10 out of 12 participants also had some experience with TTI models , and only 1 participant ( P1 ) reported no prior experience with LLMs . 4 . 1 . 2 Task and Protocol . Each study took place through a Zoom call that lasted approximately 60 minutes , during which partici - pants and the facilitating researcher collaborated in a shared Google Sheets document . We designed a concept art creation task to give users a direction achievable in the short amount of time provided , while leaving room for subjectivity and creativity : users were given a single inspirational image , then asked to generate three new im - ages that could fit in a style and unspecified narrative as suggested by the inspiration image . We included a prompt explaining the task in the activity sheet , as well as an image of a post - apocalyptic , ruined Seattle , complete with space needle 4 ( see Fig . 2 , cell B3 ) . 4 This image was borrowed with gratitude from Andy Salerno , whose blog post [ 39 ] originally inspired this work . DreamSheets arXiv Preprint , , 14770 66111 17154 7543 Post - apocalyptic scene objects City in ruins . Post - apocalyptic , crumbling buildings . A B C D E F G 1 2 3 4 5 6 78 = IMAGE ( TTI ( $ C2 , D $ 1 ) ) Post - apocalyptic highway , vehicle husks . Burnt sky . City behind walls , sewer draining into ocean . abandoned car torn billboard broken streetlight rubble pile abandoned car in a city [ … ] torn billboard in a city [ … ] broken streetlight in a city [ … ] rubble pile in a city [ … ] = IMAGE ( TTI ( $ C5 , D $ 1 ) ) = ALTERNATIVES ( B2 ) City in ruins , view from a broken window . Burnt sky . = B5 & " in a " & C2 = GPT _ LIST ( B4 ) Figure 2 : DreamSheets in typical use . Gray lozenges show user - entered formulas , while dashed lines show cell values containing computed or generated content . Here , an initial prompt ( B2 ) is expanded using = variations into column ( C2 : C4 ) . Together with a row of seeds ( D1 : G1 ) , this yields a set of images ( D2 : G4 ) . Further exploration is enabled by = gpt _ list ( B5 : B8 ) and concatenation ( & ) into new prompts ( C5 : C8 ) . Our protocol began with a brief tutorial to DreamSheets and its functionalities , followed by an observation of participants as they engaged in the concept art task . We used an example sheet to walk participants through a tutorial to first remind participants of general spreadsheet operations ( i . e . using formulas with cell references and expanding them with autofill ) and then introducing DreamSheets’s image and text generation functions . Once users were comfortable using the TTI and GPT functions , we introduced the concept art activity . Participants were encouraged to think aloud as they generated the three images required to complete the task . 4 . 1 . 3 Data Collection and Analysis . We observed , recorded , and transcribed video and audio of each interview , including the ˜40 minutes of system use , in entirety , throughout which participants were encouraged to think aloud and provide clarification when prompted . We then engaged in an exploratory qualitative data analysis using the recordings , transcripts , and resulting spreadsheet artifacts . We recorded responses to surveys completed before and after the interview , and reviewed usage data , containing logs of each text or image generation function call used in DreamSheets . 4 . 1 . 4 Preliminary Study Results : DreamSheets in use . Here , we provide an overview of some results specific to the preliminary lab study , which informed our second , longitudinal study . We discuss usage patterns and themes informed by both studies in sections 5 and 7 . More than half of the participants in this study ( 7 out of 10 ) reported limited to no experience with TTI systems , but all partici - pants were able to successfully utilize a prompt - crafting workflow in the DreamSheets system , and to produce generations that they were satisfied with for the concept art task . Though authored di - rectly by participants , the workflows adopted by more novice par - ticipants were likely inspired by the example structures showcased during the initial tutorial phase , with P3 and P4 copying from the tutorial examples directly . Figure 3 : Examples of prompts authored by participants in the first study The seven participants with limited prompt - engineering experi - ence ( P1 , 2 , 3 , 4 , 6 , 8 , 10 ) wrote their prompt in “English” ranging from brief sentence fragments to detailed scene descriptions . Mean - while , 4 of the 5 participants who reported substantial or extensive TTI experience ( P5 , P7 , P9 , P11 ) wrote in a structure specific to ”prompt language” – comma separated lists of terms , including modifiers to influence visual style . Novice and experienced partici - pants found LLM - based functions useful for creating or improving their prompts . Participants with more spreadsheet experience more readily adopted string concatenation strategies to construct prompts . Us - ing LLM - based functions to generate a series of words in a particu - lar category , like GPT _ LIST ( camera angles ) or synonyms ( " red " ) , participants could introduce word - level variation to a manually au - thored prompt or prompt structure . We describe this LLM - assisted dynamic prompt construction as a prompt - space exploration strategy in Section 5 . 2 . This formative study confirmed DreamSheets’s usefulness as an exploratory TTI system and illuminated promising usage patterns , as we observed even novice participants begin developing various strategies and structures to support their task completion goals in the ˜40 minutes provided . However , the brevity and constraints of this first - use study format prevented users from fully leverag - ing functionality of DreamSheets to develop strategies for user - defined goals . This encouraged the longitudinal study to observe how experienced generative artists might utilize DreamSheets to craft workflows towards “real - world” creative goals . 4 . 2 Longitudinal Expert Study Design We turned to a longitudinal study to better understand the kinds of custom workflows experts would build when given the time and flexibility to pursue authentic creative goals . 4 . 2 . 1 Participants . To recruit experts for our second user study , we sent recruitment messages to individuals publicly participating in generative art communities on social media , and recruited 5 individ - uals ( designated as E1 - 5 to differentiate from Study 1 participants ) . 4 . 2 . 2 Protocol . We conducted three 45 minute interviews span - ning 2 weeks with each participant . Participants were instructed to use the tool for ˜7 - 10 hours over the course of the 2 week study . We suggested 30 - 45 minutes of tool use per day to fulfill this , but par - ticipants were given the freedom to decide the length and structure of their work sessions . As with the first study , the initial interview began with a short tutorial reviewing spreadsheet functionality and demonstrating arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann GPT DIVERGENTS ANTONYMS LIST _ COMPLETION SYNONYMS GPT _ LIST ALTERNATIVES EMBELLISH 0 50 100 150 Count of LLM - based Functions Used by Participants Figure 4 : Number of times participants used each of the LLM - based functions during the activity in our preliminary lab study . Figure 5 : Number of times participants used each of the LLM - based functions the two weeks of our longitudinal expert study . Individual colors represent individual participants consistently across functions ( 5 total ) . DreamSheets functions . The collaborative spreadsheet shared with each participant included documentation and examples of DreamSheets function use . Participants could contact the research team via email if they had questions throughout the study . The second interview took place 1 week into the study . We asked participants to explain their exploration goals and strategies , and to use relevant parts of their spreadsheets to illustrate . We described back to participants our observations , allowing them to clarify any potential misinterpretations of their actions . Based on the feedback we received , we designed a UI mockup that incorporated elements inspired by the structures built and functions used by participants during their first week of using DreamSheets . In the third and final 45 - minute interview , we again asked partic - ipants to describe the creative explorations evident in their spread - sheets , and to explain how they integrated DreamSheets’s func - tionalities into their creative process . We then showed participants the UI mockup to gain their perspective and elicit further feedback and suggestions for designing more supportive TTI interfaces . Finally , participants were asked to share 3 - 5 of their favorite generations created using the DreamSheets system , allowing us to better consider which DreamSheets explorations were most “successful” to our participants . 4 . 2 . 3 Data Collection and Analysis . We analyzed our participants’ usage of DreamSheets as observed or described during interviews , as well as the resulting artifacts : the sheets and usage logs , contain - ing the full chronology of function calls made to the DreamSheets system . We periodically viewed their spreadsheets throughout the 2 - week study , including their Version History – a detailed record of changes made to the sheet , which we used to recover and save copies of previous versions . We used these sources to identify participants exploratory goals and strategies while using DreamSheets . We identified usage pat - terns across participants , and considered how workflows adapted throughout user’s exploratory journeys in DreamSheets . 5 FINDINGS : OBSERVING USER - DEFINED TTI WORKFLOWS Across both studies , participants’ use of DreamSheets and the artifacts they produced allowed us to observe and identify key elements of their TTI creative workflow : their goals , the strategies DreamSheets arXiv Preprint , , Figure 6 : Images generated with the same seed can have vi - sual similarities . E5 explored with goal of locating a seed biased towards generating “a central object” and located 7935 . Gaining this information contributed to the success of P5’s creative goal to generate “vector” style graphics . These were among their favorite generations . Green prompt text is manually written by the user . Orange indicates text pulled from a manually curated list . Purple indicates LLM - generated text . they chose to pursue them , and the actions ( functions , formulas ) and structures , ( spreadsheet layout choices ) they elected to utilize . We identified strategies adopted by TTI users to navigate prompt - image space and describe these findings below . 5 . 1 Exploration without Prompt Manipulation Prompt - crafting is central to the effective use of TTI models . How - ever , the ability to quickly manipulate , evaluate , and select numeri - cal hyperparameters ( the seed and cfg , or classifier - free guidance ) alone provides users of DreamSheets with useful axes on which to scaffold exploration and selection . Generating many images using the same prompt but different seeds was a common strategy across participants in both studies . All 5 expert participants utilized seed variations to quickly eval - uate many “versions” of the same prompt . A seed variation based exploration strategy allows the user to quickly reveal a series of visually diverse outputs without having to engage in the mental effort required to edit prompt language . Technically , seeds define the specific random noise that the dif - fusion model will use as a starting point ; the model then repeatedly “de - noises” successive versions , to generate an image , with the text prompt acting as a guide . Thus , while there is no perceptual correla - tion between adjacent seeds , images generated with the same seed may share certain visual similarities to the original noise pattern . E5 explored possible seeds with a particular sense - making goal : locating a seed that would bias the image generation to feature “a central object” on a flat background . P5 found 7935 after trying only a few different seeds in DreamSheets , and used this value in many other explorations ( see Figure 6 ) . E2 and E5 were particularly interested in exploring different cfg values . E2 , E3 , and E5 developed an exploration structure equiv - alent to creating a “slider” : delegating a cell for a specifying a guidance value , then regenerating with different guidance values before choosing an ideal “setting . ” All participants tried organizing generated outputs in a 2D matrix “contact sheet” layout ( as described by P1 ) , and 3 of the 5 experts ( P1 , P4 , P5 ) explicitly remarked on its usefulness . These explorations allowed users to make sense of available options in a local area , recognize interesting values , and leverage this information towards more successful future generations . Overall , all participants manipulated hyperparameters , allow - ing them to travel along one dimension at a time through input space , learning the idiosyncracies of a particular image generation model’s output space along that axis , separate from the complexity introduced by prompt manipulation . 5 . 2 Dynamic Prompt Construction “Does Stable Diffusion know the same artists I do ? ” ( P11 ) Participants manipulated language to make movements in prompt - space that would , ideally , translate into movements towards more interesting areas of image - space . One common sense - making strategy we observed across both studies : participants make local edits to key descriptive words within an initial prompt . By constructing conceptually similar alter - natives , participants tested the effects of specific words or phrase within a larger prompt . For example : A twisted man that exists purely to seek revenge and consume power . . . is manually edited to : A twisted man that exists purely to seek revenge and is on the edge of death . . . and finally to : A twisted ghoulish man that exists purely to seek revenge and is on the edge of death These manually written prompts were passed to TTI ( ) by E4 in the same exploration session ; E4 generated 8 - 10 versions of each prompt , using different seeds for variation , before iterating on the prompt text , noting : “Ghoulish was a word that helps , so I kept using that word . ” ( E4 ) Even novice participants recognized the need for this kind of exploration ; P6 , a novice user with limited prompting experience , said : “I think it’s good to know how things change depend - ing on different variables . . . the spreadsheet helps with navigating what exactly is changing within the image . ” ( P6 ) In DreamSheets , participants can engage in this iterative , ex - ploratory prompt - editing process with the aid of DreamSheets’s LLM - based functions and spreadsheet concatenation , streamlining the discovery of useful points in prompt - space . 5 . 2 . 1 Prompt Templates and Axes . Participants utilized lists of words that could swap into specified “slots” in longer prompts , arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann Figure 7 : E3 is interested in generating animal - plant hybrids in their textured film photography style . They first created a “settings panel” structure in their sheet , delegating a cell for each desired input component . They used a combina - tion of LLM list functions and concatenation to construct a dynamic prompt template . Changing any of the input cells regenerated the displayed image results , allowing them to experiment – e . g . , entering different guidance values until settling on 11 . authoring a type of dynamic , concatenated “prompt template” struc - ture . These lists can be constructed manually , or by using one of the list - generating LLM functions in DreamSheets . By referencing from multiple categorical lists , participants select semantic “axes” to define a 2D prompt space for exploration : expert participant E1 used an LLM generated list of facial expressions and a manually curated list of subjects ( girl , dog , cat ) together to explore and understand how individual facial expressions interacted with individual subjects ( see Figure 8 for an illustration ) . These “axes” were neither numerical nor ordinal , but provided a useful sensemaking structure ; E1 discovered that a “smiling dog” would not , in fact , smile—but that a “grinning dog” did . E1 also used concatenation to append " , well lit , studio photography , portrait " to each prompt in this sheet , titled “ Ex - pressions Exploration 1 , ” explaining that grounded the results of their exploration in a consistent “default” style . They intended to use the information they gained about effectively “prompting for emotions” to improve future generative art pieces where aesthetic style is part of their creative goal . 5 . 2 . 2 LLM Function Use & Workflow Structure . All of our expert participants used the LLM functions to some extent , including E4 and E5 , who typically preferred to manually craft their prompts or rely on hyperparameters to create variation . 4 of 5 experts ( E1 , E2 , E3 , E5 ) utilized cell concatenation to craft dynamic prompt tem - plates with LLM - generated prompt parts . E4 used LLM - generations to suggest new ideas in a particular category , e . g . , ideas for unique camera angles . See Figures 4 and 5 for counts of how frequently participants utilized each of the LLM functions across both studies . For 3 of 5 expert participants ( E1 , E2 , E5 ) , the LLM - based list generation functions gpt _ list and list _ completion comprised more than half of their LLM Function use . E3 also used these list generation functions many times—in fact , more than any other smiling dog grinning cat frowning bird sad gerbil wide - eyed hamster happy ﬁsh A LIST ( “facial expressions” ) brown - haired LIST ( “pet animals” ) . { { } } PROMPT INPUT SPACE IMAGE OUTPUT SPACE A happy brown - haired ﬁsh Not all images are discinct Not all images are where expected Not all images even reﬂect prompt A smiling brown - haired dog Prompt Space mapped to Image Space Template o ﬀ ering two axes …leads to… an exploration of input / output mapping : Figure 8 : Prompt templates can offer “axes” of exploration for sensemaking ; these axes then also map ( often imperfectly ) from the prompt input space to the image output space , as illustrated here . participant—but their use of DreamSheets stood out overall : E3 made 9268 LLM function calls , 7 . 6 times more than the next most frequent user of the LLM functions ; including 5851 embellish calls . See Figure 7 for a sample of the sophisticated text - manipulation workflow they developed . E1 , E2 , and E3 were interested in using prompt text primarily or entirely generated by the LLM functions . Both E2 and E3 developed a structural strategy that involved explicitly designating an area of their sheets for generating and manipulating lists of text , an area for systematically combining values these terms into full prompts , and an area for displaying the resulting images . DreamSheets arXiv Preprint , , Figure 9 : A small subset of the full ( 32 prompts x 13 seeds ) exploration that E4 generated in a single session with DreamSheets . They attempted to generate more focused images towards a concept art creation goal , but much pre - ferred generations in this exploratory set . With LLM - functions for automatically generating points along a semantic axis , users can quickly experiment with axes in prompt space without having to formulate their own prompt word ideas - they can choose camera angle as a “slider” to explore , then pick their “favorite setting” from the generated results - without having to recall the words to describe it . 5 . 2 . 3 Facilitating discovery by relinquishing creative control . E4 much preferred using DreamSheets to generate from “random” concepts with the goal of seeing “how the AI interpreted very vague and unlikely prompts . ” In this setting , relinquishing control over the image generation to the system was welcomed . E4 chose only results from this type of “random exploration” ( see Figure 9 ) to share at the end of the study . AI - generated creative content inherently introduces unexpected results that users may not have considered ; users can take advan - tage of this by handing their creative - decision making labor—and control—to a generative system . As the LLM - based functions are nondeterministic , they may generate different text each time the sheet is reloaded . E2 and E3 embraced this nondeterminism . E3 was explicitly satisfied with new generations appearing whenever they reloaded the sheet , each following their chosen prompt structure and style , while featuring novel prompt parts injected by the LLM functions . E1 and E3 inter - rupted the nondeterminism by " setting " results - when particularly satisfied or interested in a given prompt part generated by the LLM , they manually edited or copied these cells as raw text to prevent regeneration of the related prompts and images . When engaging in a co - creative generative process , users choose when to introduce unexpected variability , and when to take back creative control . In both studies , participants utilized the LLM - based functions to introduce a range of variation to their prompts : from prompts entirely generated by the LLM , to generating only single word ( i . e . color ) – or , rejecting the LLM - generated suggestions altogether and manually overwriting them . Figure 10 : E1 began this exploration with a prompt almost entirely constructed with LLM - generated text . After evaluat - ing the selection of outputs for visually interesting results , they copied these promising prompt terms to new cells . They began a new exploration , progressively appending additional dynamic terms , then “setting” them . They selected the image outlined in black as one of their favorite images generated during the study , and went on to use the “monochromatic” and “watercolor” prompt terms they discovered to direct many future generations towards a pleasing aesthetic . E1 selected the image outlined in black in Figure 10 as one of their favorite images generated during the study ; the explo - ration process that led to this image exemplifies how users leverage DreamSheets’s flexibility to shift creative control to and from the generative system , as they responded to new discoveries and creative directions . At first , E1 had no particular idea in mind , ap - proaching DreamSheets with the goal of discovering something novel and unexpected . This inspired them to craft a prompt template almost entirely comprised of LLM - generated text . After generating and evaluating 25 images with this template , they identified an in - teresting result using a combination of “embellish ( “minimalism” ) ” and “monochrome” as its prompt . At this point , their goals began to shift : these terms provided E4 access to an interesting aesthetic space , and by “setting” them , E1 could explore a promising local “patch . ” “These pieces showcase the unexpected , delightful results I got during this study ! I didn’t set out to make pixel art or watercolors , but through the course of the study I discovered these aesthetic spaces that I really loved ! ” ( E1 ) E1 continued to use the " monochromatic " and " watercolor " to direct future explorations towards this appealing aesthetic space , and used these terms to generate several of their favorite images . All expert participants alluded to “discovery” being a part of their motivation to use generative art tools , and something that DreamSheets’s exploratory features supported well . E5 described themselves as “hardly ever prompting with intention at this point , ” instead opting to describe their process as “prompting for discov - ery . ” arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann Figure 11 : An image selected by P2 , using the prompt : “photo taken with a dji camera of Tahiti islands , iceland ultra - wide lens , rembrandt lighting mammatus clouds , HDR photogra - phy . ” They discovered that “DJI Camera” consistently gener - ated aerial landscape photography . 5 . 2 . 4 Discovering New Concepts . Sometimes participants discov - ered new concepts and labels that they had not considered before in their practice . Consider an exploration session that resulted in one of E2’s favorite generated images , Figure 11 . This was driven by a desire to generate landscape photography style images of islands . As with other explorations , they concatenated results from several LLM - generated lists to form this prompt , but in this case manually added “photo taken with a dji camera of . . . ” They had discovered that invoking DJI , a drone camera company , helped to generate quality aerial images . “DJI is this Chinese company that makes drones . . . when you use that in a prompt , it’s . . . giving you a really good up in the air perspective . . . you might use words like , ‘aerial shot’ or ‘bird’s - eye view’ that don’t work as good as saying , ‘DJI camera . ’ So a big part of this whole thing , is improving your vocabulary of artistic terms to let you know what kind of references you need to make in a prompt to make the image better . ” ( E2 ) 6 CODESIGNING THE DREAMSHEETS 2 . 0 UI MOCKUP As a final step in understanding how participants viewed their own sense - making processes , and to validate that we were gaining an understanding of how to better to support these processes , we developed UI mockups that we shared with participants for their feedback . We included features that were requested throughout our expert participants’ use of DreamSheets , including a negative prompt space ( see Figure 12 ) . 6 . 1 Visual Layout We designed two visual layout settings that users can freely toggle between : a grid view ( 12 , left ) and a focused list view ( 12 , right ) . This was informed by how our participants structured the visual display of images in their sheets : they valued the evaluation affordances of the “small - multiples” contact sheet layout , but viewing results in detail required adjusting column size or “zoom” settings in the spreadsheet . Organizing outputs into an evaluation friendly visual layout facilitates quick recognition of interesting image results . 6 . 2 “Banking” Prompt Text and Components Even experienced prompt artists may have trouble keeping the names of their favorite internet aesthetics or lighting styles at hand , and useful prompt components may be lengthy or otherwise difficult to recall . To that end , we designed a prompt “token bank” system ( Figure 12 , and featured in Figure 13 , right ) that would allow users to con - vert any highlighted prompt text into a Saved Token for simple reuse in future prompts . Saved tokens can be further edited and explored , encouraging users to develop accurate and informed sensemaking data . Tokens can also be converted into dynamic tokens . 6 . 3 Dynamic Tokens : Supporting Exploratory Axes Dynamic tokens take the role of the “slots” used by participants to specify where to introduce text variation into their dynamic prompt templates , while eliminating the need for users to work with cell concatenation . Prompt variations are automatically generated , systematically combined , and populated across several columns of generated images . Users can append , edit , and remove prompt words for each column of exploration , at will . Seeds create the variation in each row , and users can easily randomize all seeds , manually edit them , or generate more . 6 . 4 Participant Feedback We used UI mockup design to elicit feedback and speculative ideas from participants . Participants overall reflected positively on the concept of being able to save and recover prompt parts for use in future explorations . E4 compared this to their current strategy of saving prompts in a text document , including frequently used modifiers that help in achieving consistent image styles . “If I can drag and drop a presaved dynamic chunk . . . I can fully focus on sculpting the prompt and being creative . ” ( E4 ) Participants , especially E1 and E5 , were excited by the idea of a “Save session” feature , and each described a similar expected use case : to save the current state of the system , pausing their workflow to return at a later date . E5 expressed a preference to separate their “generation” process ( crafting prompts and generate hundreds , even thousands of images ) from their “evaluation” process ( curating the selection of images ) , and described being able to return to a previous exploration at a later date as a potential “game - changer . ” Participants had a number of ideas for what an “Explore this image” option could introduce , with the potential to build upon DreamSheets’s functionalities to support both broad and focused exploration strategies . These suggestions included : ( 1 ) seman - tic level prompt - image editing in the style of ControlNet [ 50 ] ; ( 2 ) Image - to - Text generation like CLIP Interrogator [ 29 ] or Mid - journey’s / describe function [ 1 ] ; ( 3 ) inpainting and outpainting ; among several other ideas for focused image - to - image or image - to - text transformations . DreamSheets arXiv Preprint , , Figure 12 : Views of the Dreamsheets 2 . 0 UI Mockup , showcasing the two visual layouts that users can freely toggle between : a grid view ( left ) and a focused list view ( right ) . DreamSheets 1 . 0 users valued the “small - multiples” contact sheet layout , but viewing results in detail required them to change “zoom” settings or tediously adjust the sizes of columns and rows . An improved UI would provide appropriate interface structures to support TTI users as they move between broad and focused evaluations of results , Figure 13 : Views of elements featured in the interactive UI Mockup . Dynamic tokens fill the role of “slots” used by par - ticipants to flexibly introduce text variation into dynamic prompt templates , while eliminating the need to write cell concatenation formulas . The LLM used to support this inter - action is surfaced ; users can control how the prompt is sent . Any word or phrase can be saved as a prompt token ; users can explore a term further to gain more informed sense - making data . 7 DISCUSSION Our findings reveal challenges , tensions , and opportunities in the TTI prompt - exploration process . How can we apply this under - standing to guide future exploratory interface designs ? 7 . 1 Prompt Exploration as Foraging While the sensemaking strategies that TTI users develop as they iteratively sample information across input and output space helps users to develop vocabulary and visual communication concepts that carry to other spaces , new models present entirely new latent spaces to discover and learn how to “prompt for . ” Figure 14 : As users explore prompt - image space , they dis - cover interesting new directions to pursue . They can expand their explorations into new directions , or focus their explo - ration towards promising results . User’s co - creative strate - gies adapt to shifting exploration goals . TTI interface designers seeking to support the broad explo - ration and discovery processes necessary to navigate a vast , opaque prompt - image space can reduce users’ exploratory “cost” by de - signing for Recognition over Recall . Viewing the outputs of explo - rations in an expandable “contact sheet” layout , as afforded by DreamSheets , users can efficiently evaluate a wide selection of variations and recognize interesting directions from displayed out - puts . With LLM assistance , users can quickly generate individual points to sample along a semantic axis , allowing them to move through a local “patch” in prompt space without needing to man - ually recall and formulate the right language for this movement - effectively lowering the perceived cost of searching this area of prompt space . To echo Information Foraging theory [ 30 ] , we observed partici - pants taking cues from the generated results of previous prompt - space explorations , then estimating the “information value” of a arXiv Preprint , , Almeda , Zamfirescu - Pereira , Kim , Mani Rathnam , and Hartmann local area in the TTI design space , before making their next move . After trying a particular prompt , users consider how likely they are to discover valuable images in a local “patch , ” against the perceived effort it would require , and use this to determine whether they should venture deeper , or leave the patch and choose a new direc - tion for exploration . By lowering the exploration cost , such as with LLM functions for assisted prompt - crafing , users can explore more and more widely . We illustrate stages in the nonlinear exploratory process that TTI users can fluidly move through in Figure 14 . 7 . 2 Shifting the Locus of Control to Match Creative Goals As TTI users decide whether to expand their search in new direc - tions , or venture into a more focused exploration , flexible options for AI involvement can play a role in fluidly supporting these shifts in goals . AI - generated serendipity is ideal for expansive search , but when a promising “scent” is unexpectedly identified , the user will want the power and agency to hone in . Such discoveries are , by nature , difficult to predict . Even when users hand off creative - labor , and thus , control , to the inspirational power of AI - generated spontane - ity , they can maintain the flexibility to strategically reclaim that control at any time . This tension echoes the challenges observed by Lawton et al . in “When is a Tool a Tool ? ” [ 17 ] . Future work should continue to study the way that co - creative systems can either adapt to users’ shifting goals , or provide users with the flexi - bility to choose and self - define where and how a generative tool can influence their workflow . 7 . 3 Learning Words for the World , through an AI - generated Lens As TTI users visually observe and evaluate the results of their prompt - space explorations , they learn words that are useful for prompting a specific image generation model . They also develop a sense of visual information that they can carry to other models—and sometimes , the world . The information latent in text - to - image models becomes more accessible with the help of LLM suggestions , and can go beyond learning better prompt language , towards developing general pur - pose visual communication skills . As consumer Text - To - Image tools rapidly proliferate , they have the potential to allow users to acces - sibly learn these visual - semantic associations in practice , including those typically developed through study of visual media history . However , this also surfaces the potential for AI - generated content to proliferate misinformation with the illusion of majority opinion , as described by Zhou et al . [ 51 ] In the case of TTI , inaccuracies— a particular artist’s name mapping to the wrong visual style , for instance—could prove immensely challenging to identify and cor - rect . This indicates an avenue for future studies into the potential influence of TTI to influence visual culture , including the potential to amplify existing biases against underrepresented groups in visual history . 8 CONCLUSION Text - to - Image models challenge users to navigate vast , opaque design spaces on both sides—prompt input and image output . DreamSheets provides a flexible , spreadsheet - based interface for users to author strategies to achieve creative goals , and facilitating sensemaking—developing through experience the language and working understanding needed to reliably steer image generations towards interesting outputs . Through two user studies , including a longitudinal expert study , we observed challenges , tensions , and op - portunities in the TTI prompt - exploration process . We utilized these insights to develop a UI mockup , improved with participant feed - back , and suggesting features for future supportive TTI exploration interfaces . Finally , we considered the implications of supporting users’ sensemaking in prompt - image space , and beyond . 9 DISCLOSURE The authors used ChatGPT for minor copy editing tasks . REFERENCES [ 1 ] 2023 . Documentation for Midjourney’s / describe Function . https : / / docs . midjourney . com / docs / describe Accessed : 2023 - 09 - 15 . [ 2 ] Stephen Brade , Bryan Wang , Mauricio Sousa , Sageev Oore , and Tovi Grossman . 2023 . Promptify : Text - to - Image Generation through Interactive Prompt Explo - ration with Large Language Models . In Proceedings of UIST 2023 . ACM , 1 – 14 . [ 3 ] Minsuk Chang , Stefania Druga , Alexander J . Fiannaca , Pedro Vergani , Chinmay Kulkarni , Carrie J Cai , and Michael Terry . 2023 . The Prompt Artists . In Creativity and Cognition . ACM , Virtual Event USA , 75 – 87 . https : / / doi . org / 10 . 1145 / 3591196 . 3593515 [ 4 ] Ed Huai - hsin Chi , Joseph Konstan , Phillip Barry , and John Riedl . 1997 . A Spread - sheet Approach to Information Visualization . In Proceedings of the 10th An - nual ACM Symposium on User Interface Software and Technology ( Banff , Alberta , Canada ) ( UIST ’97 ) . Association for Computing Machinery , New York , NY , USA , 79 – 80 . https : / / doi . org / 10 . 1145 / 263407 . 263513 [ 5 ] John Joon Young Chung , Shiqing He , and Eytan Adar . 2021 . The Intersection of Users , Roles , Interactions , and Technologies in Creativity Support Tools . In Designing Interactive Systems Conference 2021 ( Virtual Event , USA ) ( DIS ’21 ) . Association for Computing Machinery , New York , NY , USA , 1817 – 1833 . https : / / doi . org / 10 . 1145 / 3461778 . 3462050 [ 6 ] Douglass R Cutting , David R Karger , Jan O Pedersen , and John W Tukey . 2017 . Scatter / gather : A cluster - based approach to browsing large document collections . In ACM SIGIR Forum , Vol . 51 . ACM New York , NY , USA , 148 – 159 . [ 7 ] Nicholas Davis , Chih - Pin Hsiao , Kunwar Yashraj Singh , Brenda Lin , and Brian Magerko . 2017 . Creative Sense - Making : Quantifying Interaction Dynamics in Co - Creation . In Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition ( Singapore , Singapore ) ( C & C ’17 ) . Association for Computing Machin - ery , New York , NY , USA , 356 – 366 . https : / / doi . org / 10 . 1145 / 3059454 . 3059478 [ 8 ] Remi Durant . 2023 . Artist Studies . https : / / remidurant . com / artists / Accessed : 2023 - 09 - 15 . [ 9 ] NoyanEvirgenandXiang’Anthony’Chen . 2022 . GANzilla : User - DrivenDirection Discovery in Generative Adversarial Networks . In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology . 1 – 10 . [ 10 ] Jonas Frich , Lindsay MacDonald Vermeulen , Christian Remy , Michael Mose Biskjaer , andPeterDalsgaard . 2019 . MappingtheLandscapeofCreativitySupport Tools in HCI . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 18 . https : / / doi . org / 10 . 1145 / 3290605 . 3300619 [ 11 ] Karl Friston . 2009 . The free - energy principle : a rough guide to the brain ? Trends in cognitive sciences 13 , 7 ( 2009 ) , 293 – 301 . [ 12 ] Pol Baladas Gerard Serra , Oriol Domingo . 2022 . A programmable interface for creative exploration . Machine Learning for Creativity and Design Workshop at the 36th Conference on Neural Information Processing Systems ( NeurIPS 2022 ) ( December 2022 ) . https : / / neuripscreativityworkshop . github . io / 2022 / papers / ml4cd2022 _ paper19 . pdf [ 13 ] Elena L . Glassman , Tianyi Zhang , Björn Hartmann , and Miryung Kim . 2018 . Visualizing API Usage Examples at Scale . Association for Computing Machinery , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3174154 [ 14 ] Björn Hartmann , Loren Yu , Abel Allison , Yeonsoo Yang , and Scott R . Klem - mer . 2008 . Design as Exploration : Creating Interface Alternatives through Par - allel Authoring and Runtime Tuning . In Proceedings of the 21st Annual ACM Symposium on User Interface Software and Technology ( Monterey , CA , USA ) ( UIST ’08 ) . Association for Computing Machinery , New York , NY , USA , 91 – 100 . https : / / doi . org / 10 . 1145 / 1449715 . 1449732 DreamSheets arXiv Preprint , , [ 15 ] Jeffrey Heer , Jock Mackinlay , Chris Stolte , and Maneesh Agrawala . 2008 . Graph - ical histories for visualization : Supporting analysis , communication , and eval - uation . IEEE transactions on visualization and computer graphics 14 , 6 ( 2008 ) , 1189 – 1196 . [ 16 ] Chinmay Kulkarni , Stefania Druga , Minsuk Chang , Alex Fiannaca , Carrie Cai , and Michael Terry . 2023 . A Word is Worth a Thousand Pictures : Prompts as AI Design Material . https : / / arxiv . org / abs / 2303 . 12647v1 [ 17 ] Tomas Lawton , Kazjon Grace , and Francisco J Ibarrola . 2023 . When is a Tool a Tool ? User Perceptions of System Agency in Human – AI Co - Creative Drawing . In Proceedingsofthe2023ACMDesigningInteractiveSystemsConference . 1978 – 1996 . [ 18 ] BrianLee , SavilSrivastava , RanjithaKumar , RonenBrafman , andScottRKlemmer . 2010 . Designing with interactive example galleries . In Proceedings of the SIGCHI conference on human factors in computing systems . 2257 – 2266 . [ 19 ] Marc Levoy . 1994 . Spreadsheets for images . In Proceedings of the 21st annual conference on Computer graphics and interactive techniques . 139 – 146 . [ 20 ] Pengfei Liu , Weizhe Yuan , Jinlan Fu , Zhengbao Jiang , Hiroaki Hayashi , and Graham Neubig . 2021 . Pre - train , Prompt , and Predict : A Systematic Survey of Prompting Methods in Natural Language Processing . arXiv : 2107 . 13586 [ cs . CL ] [ 21 ] VivianLiuandLydiaB . Chilton . 2021 . DesignGuidelinesforPromptEngineering Text - to - Image Generative Models . https : / / doi . org / 10 . 48550 / ARXIV . 2109 . 06977 [ 22 ] Vivian Liu and Lydia B Chilton . 2022 . Design Guidelines for Prompt Engineering Text - to - Image Generative Models . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 384 , 23 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3501825 [ 23 ] VivianLiu , JoVermeulen , GeorgeFitzmaurice , andJustinMatejka . 2022 . 3DALL - E : Integrating Text - to - Image AI in 3D Design Workflows . arXiv : 2210 . 11603 [ cs . HC ] [ 24 ] BryanLohandTomWhite . 2018 . SpaceSheets : interactivelatentspaceexploration through a spreadsheet interface . ( 2018 ) . [ 25 ] Aran Lunzer and Kasper Hornbæk . 2008 . Subjunctive Interfaces : Extending Applications to Support Parallel Setup , Viewing and Control of Alternative Sce - narios . ACM Trans . Comput . - Hum . Interact . 14 , 4 , Article 17 ( jan 2008 ) , 44 pages . https : / / doi . org / 10 . 1145 / 1314683 . 1314685 [ 26 ] J . Marks , B . Andalman , P . A . Beardsley , W . Freeman , S . Gibson , J . Hodgins , T . Kang , B . Mirtich , H . Pfister , W . Ruml , K . Ryall , J . Seims , and S . Shieber . 1997 . Design Galleries : A General Approach to Setting Parameters for Computer Graphics and Animation . In Proceedingsofthe24thAnnualConferenceonComputerGraphicsand Interactive Techniques ( SIGGRAPH ’97 ) . ACM Press / Addison - Wesley Publishing Co . , USA , 389 – 400 . https : / / doi . org / 10 . 1145 / 258734 . 258887 [ 27 ] Lars Nielsen . 2022 . An advanced guide to writing prompts for Midjourney ( text - to - image ) . MLearning . ai ( Sep 2022 ) . https : / / medium . com / mlearning - ai / an - advanced - guide - to - writing - prompts - for - midjourney - text - to - image - aa12a1e33b6 Accessed : 2023 - 09 - 15 . [ 28 ] Guy Parsons . 2022 . The DALL·E 2 Prompt Book . https : / / dallery . gallery / the - dalle - 2 - prompt - book / [ 29 ] pharmapsychotic . 2023 . CLIP Interrogator : A promptengineeringtool for text - to - image models . https : / / github . com / pharmapsychotic / clip - interrogator Accessed : 2023 - 09 - 15 . [ 30 ] Peter Pirolli and Stuart Card . 1999 . Information foraging . Psychological review 106 , 4 ( 1999 ) , 643 . [ 31 ] Peter Pirolli and Stuart Card . 2005 . The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis . In Proceedings of international conference on intelligence analysis , Vol . 5 . McLean , VA , USA , 2 – 4 . [ 32 ] proxima centauri b , surea . i , Stephen Young , and Encyclopedia Erratica . 2023 . Image Synthesis Style Studies Database by parrotzone . art . https : / / web . archive . org / web / 20230325013519 / https : / / docs . google . com / spreadsheets / d / 14xTqtuV3BuKDNhLotB _ d1aFlBGnDJOY0BRXJ8 - 86GpA / edit # gid = 0 [ 33 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical Text - Conditional Image Generation with CLIP Latents . arXiv : 2204 . 06125 [ cs . CV ] [ 34 ] EricRawn , JingyiLi , EricPaulos , andSarahChasins . 2023 . UnderstandingVersion Control as Material Interaction with Quickpose . In Proceedings of the SIGCHI conference on human factors in computing systems . [ 35 ] MitchelResnick , BradMyers , KumiyoNakakoji , BenShneiderman , RandyPausch , Ted Selker , and Mike Eisenberg . 2005 . Design Principles for Tools to Support Creative Thinking . ( 1 2005 ) . https : / / doi . org / 10 . 1184 / R1 / 6621917 . v1 [ 36 ] Daniel Ritchie , Ankita Arvind Kejriwal , and Scott R Klemmer . 2011 . d . tour : Style - based exploration of design example galleries . In Proceedings of the 24th annual ACM symposium on User interface software and technology . 165 – 174 . [ 37 ] Robin Rombach , Andreas Blattmann , Dominik Lorenz , Patrick Esser , and Björn Ommer . 2022 . High - Resolution Image Synthesis With Latent Diffusion Models . ProceedingsoftheIEEE / CVFConferenceonComputerVisionandPatternRecognition ( CVPR ) ( June 2022 ) , 10684 – 10695 . [ 38 ] Daniel M . Russell , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . The Cost Structure of Sensemaking . In Proceedings of the INTERACT ’93 and CHI ’93 Con - ference on Human Factors in Computing Systems ( Amsterdam , The Netherlands ) ( CHI ’93 ) . Association for Computing Machinery , New York , NY , USA , 269 – 276 . https : / / doi . org / 10 . 1145 / 169059 . 169209 [ 39 ] Andy Salerno . 2022 . 4 . 2 Gigabytes , or : How to Draw Anything . https : / / andys . page / posts / how - to - draw / [ 40 ] Victor Sanh , Albert Webson , Colin Raffel , Stephen H . Bach , Lintang Sutawika , Zaid Alyafeai , Antoine Chaffin , Arnaud Stiegler , Teven Le Scao , Arun Raja , Manan Dey , M Saiful Bari , Canwen Xu , Urmish Thakker , Shanya Sharma Sharma , Eliza Szczechla , Taewoon Kim , Gunjan Chhablani , Nihal Nayak , Debajyoti Datta , Jonathan Chang , Mike Tian - Jian Jiang , Han Wang , Matteo Manica , Sheng Shen , ZhengXinYong , HarshitPandey , RachelBawden , ThomasWang , TrishalaNeeraj , Jos Rozen , Abheesht Sharma , Andrea Santilli , Thibault Fevry , Jason Alan Fries , RyanTeehan , TaliBers , StellaBiderman , LeoGao , ThomasWolf , andAlexanderM . Rush . 2021 . Multitask Prompted Training Enables Zero - Shot Task Generalization . https : / / doi . org / 10 . 48550 / ARXIV . 2110 . 08207 [ 41 ] Ben Shneiderman . 2002 . Creativity Support Tools . Commun . ACM 45 , 10 ( oct 2002 ) , 116 – 120 . https : / / doi . org / 10 . 1145 / 570907 . 570945 [ 42 ] SanghoSuh , BryanMin , SrishtiPalani , andHaijunXia . 2023 . Sensecape : Enabling Multilevel Exploration and Sensemaking with Large Language Models . arXiv preprint arXiv : 2305 . 11483 ( 2023 ) . [ 43 ] Jerry O . Talton , Daniel Gibson , Lingfeng Yang , Pat Hanrahan , and Vladlen Koltun . 2009 . Exploratory Modeling with Collaborative Design Spaces . In ACM SIGGRAPH Asia 2009 Papers ( Yokohama , Japan ) ( SIGGRAPH Asia ’09 ) . Associ - ation for Computing Machinery , New York , NY , USA , Article 167 , 10 pages . https : / / doi . org / 10 . 1145 / 1661412 . 1618513 [ 44 ] Edward R Tufte . 1993 . Envisioning information . Vol . 199 . Graphics Press Cheshire , CT . [ 45 ] Robert F . Woodbury and Andrew L . Burrow . 2006 . A typology of design space ex - plorers . Artificial Intelligence for Engineering Design , Analysis and Manufacturing 20 , 2 ( 2006 ) , 143 – 153 . https : / / doi . org / 10 . 1017 / S0890060406060136 [ 46 ] Stephen Young . 2022 . COG Prompt Parrot . https : / / github . com / kyrick / cog - prompt - parrot [ 47 ] Loutfouz Zaman , Wolfgang Stuerzlinger , Christian Neugebauer , Rob Woodbury , Maher Elkhaldi , Naghmi Shireen , and Michael Terry . 2015 . GEM - NI : A System for Creating and Managing Alternatives In Generative Design . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems ( Seoul , Republic of Korea ) ( CHI ’15 ) . Association for Computing Machinery , New York , NY , USA , 1201 – 1210 . https : / / doi . org / 10 . 1145 / 2702123 . 2702398 [ 48 ] JDZamfirescu - Pereira , HeatherWei , AmyXiao , KittyGu , GraceJung , MatthewG Lee , Bjoern Hartmann , and Qian Yang . 2023 . Herding AI Cats : Lessons from Designing a Chatbot by Prompting GPT - 3 . ( 2023 ) . [ 49 ] J . D . Zamfirescu - Pereira , Richmond Wong , Bjoern Hartmann , and Qian Yang . 2023 . Why Johnny can’t prompt : how non - AI experts try ( and fail ) to design LLM prompts . In Proceedings of the 2023 CHI conference on human factors in computing systems ( CHI’23 ) . [ 50 ] Lvmin Zhang and Maneesh Agrawala . 2023 . Adding conditional control to text - to - image diffusion models . arXiv preprint arXiv : 2302 . 05543 ( 2023 ) . [ 51 ] Jiawei Zhou , Yixuan Zhang , Qianni Luo , Andrea G Parker , and Munmun De Choudhury . 2023 . Synthetic Lies : Understanding AI - Generated Misinfor - mation and Evaluating Algorithmic and Human Solutions . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Ger - many ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 436 , 20 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3581318