2018 ICSEE International Conference on the Science of Electrical Engineering Identifying Abusive Comments in Hebrew Facebook Chaya Liebeskind Department of Computer Science Jerusalem College of Technology , Lev Academic Center Jerusalem , Israel liebchaya @ gmail . com Shmuel Liebeskind Department of Computer Science Jerusalem College of Technology , Lev Academic Center Jerusalem , Israel israellieb @ gmail . com Abstract —In this study , we aim to classify comments as abusive or non - abusive . We develop a Hebrew corpus of user comments annotated for abusive language . Then , we investigate highly sparse n - grams representations as well as denser character n - grams representations for comment abuse classiﬁcation . Since the comments in social media are usually short , we also inves - tigate four dimension reduction methods , which produce word vectors that collapse similar words into groups . We show that the character n - grams representations outperform all the other representation for the task of identifying abusive comments . Index Terms —abusive comments , dimension reduction , n - grams , n - grams characters , semantic analysis , word embedding I . I NTRODUCTION Popular Web search engines , such as Google , Yahoo and Bing , and media - sharing websites , such as YouTube , have settings for safe search that ﬁlters out abusive content , includ - ing racist , sexual - oriented harassment , bullying , and hateful speech . Many Internet companies have standards that all users must follow , in conjunction with systems which use regular expressions and blacklist , to catch bad language and thus remove a post . However , due to the increasing availability of user generated online content , maintaining a list of offensive words to ﬁlter content against is not a satisfactory solution . Therefore , there is a growing interest in applying natural language processing ( NLP ) methods to abusive language detection . Typically , two approaches for identifying abusive content were investigated : blacklist - based automated approach to con - struct an offensive word list and Machine Learning ( ML ) approach , which composed of two general steps : ( 1 ) learn the model from a training corpus , and ( 2 ) classify a test corpus based on the trained model . While most prior work focused on abusive language detec - tion for different languages , such as English [ 1 ] – [ 3 ] , German [ 4 ] Arabic [ 5 ] , [ 6 ] , and Chinese [ 7 ] , we are interested in applying these approaches to Hebrew . Hebrew is characterized by highly productive morphology and , as far as we know , has not been investigated before . Considering the absence of a blacklist of Hebrew offensive words , we ﬁrst used a statistical measure to extract a blacklist of hundreds of abusive words , which was manually annotated . Then , we used the extracted list to enrich our user comments dataset with examples of abusive comments . Next , we adopt a supervised ML approach for abusive language detection . we represent each comment as a vector of features . Our feature sets include either text - based features or features made by dimensionality reduction methods . We compare two text representation approaches , i . e . , n - grams and character n - grams , and four semantic representation , generated by dimensionality reduction techniques , i . e . , Latent Semantic Analysis ( LSA ) [ 8 ] , [ 9 ] , Latent Dirichlet Allocation ( LDA ) [ 10 ] , [ 11 ] , Random projection ( RP ) [ 12 ] and Word Embedding [ 13 ] , [ 14 ] , by training a classiﬁer to detect abusive comments , analyzing the relevant features and recognizing abusive language in new comments . II . C OMMENT A BUSE C LASSIFICATION Comment abuse classiﬁcation is a binary classiﬁcation task of determining if a given comment is abusive . An abusive comment includes one of the following three types of offen - sive language [ 15 ] : Vulgar , which include explicit and rude sexual references , Pornographic , and Hateful , which includes offensive remarks concerning peoples race , religion , country , etc . For example , in a political domain , the comment I already prepared a ﬂight ticket in case the puppy Bozy was chosen is abusive , whereas the comment Who exactly did you harm except for the Israeli citizen ? The Open - Fire Regulations have not changed . The only thing you worry about and do not tell us is your Teva stocks and your electric company stocks . . expresses negative sentiment , but is not abusive . A . Obtaining a user comments dataset We have downloaded via Facebook Graph API all posts of Members of Knesset ( MKs ) between 2014 - 2016 ( n = 130 MKs , m = 33 , 537 posts ) . The data included also the comments to these posts ( n = 5 . 37M comments posted by 702 , 396 com - mentators ) . [ 16 ] – [ 18 ] . The average length of a comment is 7 words and the average length of a post is 22 words . A sub - corpus of 1489 comments was manually annotated for comment abuse classiﬁcation . The sub - corpus included 266 abusive comments , 1216 non - abusive comments , and 7 unknown comments . Thus , we had to handle the problem of imbalanced class distribution , where the number of observa - tions belonging to one class is signiﬁcantly lower than those belonging to the other classes . A simple way to ﬁx imbalanced datasets is simply to balance them by oversampling instances of the minority class . Recently , there has been growing interest in oversampling 978 - 1 - 5386 - 6378 - 3 / 18 / $ 31 . 00 ©2018 IEEE 2018 ICSEE International Conference on the Science of Electrical Engineering methods for imbalanced classiﬁcation [ 19 ] – [ 21 ] . Many of the oversampling methods lead to model over - ﬁtting , since they either duplicate instances or create new synthetic examples . To avoid over - ﬁtting , we adopted a simpler oversampling approach to increase the number of abusive comments in our dataset . We extracted a blacklist of hundreds of abusive words and balanced the dataset by adding abusive comments that include at least one word from the blacklist . 1 ) Generating a blacklist of abusive words : The input of the blacklist generation process was an initial list of 67 abusive words . We extended this list by applying a statistical measure of word co - occurrence . Assuming that words that occur frequently together are topically related [ 22 ] , for each abusive word in the initial list , we extracted the 100 most similar word using Dice coefﬁcient [ 23 ] and our unannotated corpus of over than 5 million comments . The Dice coefﬁcient normalizes the frequency of co - occurrence , or intersection of the comment sets of the two terms , by dividing it by the sum of the individual terms frequencies and multiplying it by two , so that we get a measure between 0 and 1 , with 1 indicating complete co - occurrence : Dice ( x , y ) = | C x ∩ C y | | C x | + | C y | = 2 ∗ count ( c ∈ C | x ∈ c , y ∈ x ) count ( c ∈ C | x ∈ c ) + count ( c ∈ C | y ∈ c ) ( 1 ) where C x is the comment set where term x appears and C y is the comment set where term y appears . Then , two annotators selected the abusive words from these candidate lists . We observed a Kappa [ 24 ] value of 0 . 92 , which is considered as almost perfect agreement [ 25 ] . The ﬁnal blacklist includes 683 domain - speciﬁc abusive words . B . Supervised comment abusive classiﬁcation In this research , we adopt a supervised Machine Learning ( ML ) approach for classifying Facebook comments . The ﬁrst step in training a classiﬁer is deciding what features of the text are relevant , and how to encode these features . First , We investigate two types of text representations : 1 ) N - grams representation - An n - gram is a contiguous se - quence of n words . Each of the n - grams in the comment is considered as a feature . The score of the feature is the n - gram number of occurrences in the comment divided by the comment length ( termed normalized word count ) . The n - grams representation is a high - dimensional sparse representation for documents of any length . However , the sparsity problem is much more critical for short texts , such as comments , where most words have only one occurrence 2 ) Character n - grams representation - Character n - grams are strings of length n . For example , the character 3 - grams of the string ”abusive” would be : ”abu” , ”bus” , ”usi” , ”siv” , and ”ive” . Each of the character n - grams of the comment is considered as a feature and scored by its normalized count in the comment . Since there is much less character combinations than n - gram combinations , character n - grams representation overcomes the problem of sparse data that arises when using n - grams representation . However , it still produces a considerably larger feature set . Due to the tendency of noise and misspellings to have smaller impact on substring patterns than on n - gram patterns , character n - gram features can be quite effective for short informal text classiﬁcation [ 26 ] , [ 27 ] . Another approach to overcome the sparsity problem of the n - grams representation is to apply dimensional reduction methods for semantic analysis . Next , we examine four semantic vector representations . Each of the representations is generated by a different di - mension reduction method , which produces word vectors that collapse similar words into groups . All of the representations are built using entirely unsupervised distributional analysis of large amount of unlabeled text . 1 ) Latent Semantic Analysis ( LSA ) [ 8 ] , [ 9 ] uses Singular Value Decomposition ( SVD ) to construct a semantic space from a large matrix of term - document association data . SVD is a linear algebra procedure of decomposing an arbitrary matrix into three matrices , two of which are orthonormal and the third is a diagonal matrix whose diagonal values are the singular values of the matrix . 2 ) Latent Dirichlet Allocation ( LDA ) [ 10 ] , [ 11 ] is a generative statistical model for detecting latent semantic topics in large corpora . Documents are represented as random mixtures over latent topics , where each topic is characterized by a distribution over all the words . The topic probabilities provide an explicit dense representa - tion of a document . The main challenge of constructing LDA model is how to estimate the distribution infor - mation of latent topics within the document . Various algorithms , such as Expectation Maximization ( EM ) [ 28 ] and Gibbs sampling [ 29 ] are used to address this challenge . 3 ) Random Projection ( RP ) [ 12 ] projects the original high - dimensional data onto a lower - dimensional sub - space using a random matrix whose columns have unit lengths . The core idea behind random projection is given in the Johnson - Lindenstrauss lemma [ 30 ] : if points in a vector space are projected onto a randomly selected subspace of suitably high dimension , then the distances between the points are approximately preserved . 4 ) Word Embedding [ 13 ] , [ 14 ] approaches reduce the high dimensionality of words using neural probabilis - tic language models . A d - dimensional vector of real numbers models the contexts of each word . The vectors are meaningless on their own , but semantically similar words have similar vectors . Inspired by the methods for learning word vectors using neural networks , documents are also mapped to vectors [ 31 ] . Given many contexts sampled from the document , the document vectors pre - dict the next word in the given context . 2018 ICSEE International Conference on the Science of Electrical Engineering III . E VALUATION A . Evaluation setting The supervised classiﬁcation was performed on the balanced sub - corpus ( see section II - A ) . It contains 1216 abusive com - ments and 1216 non - abusive comments . The unsupervised learning of dense vector representations was performed on the large corpus of 5 . 37M comments . For classiﬁcation , Weka 1 [ 32 ] , [ 33 ] data mining software was used . We used 10 - fold cross - validation to estimate the classiﬁcation accuracy . For dimensionality reduction , GenSim 2 python library with the settings of 300 dimensions for all the four semantic vector representations was used . B . Results In our experiments , we used the Support Vector Machine ( SVM ) classiﬁcation method [ 34 ] . Given labeled training data , the algorithm outputs an optimal hyperplane which categorizes new examples . Table I presents the accuracy , precision , recall , and F1 results of all the dimensional reduction methods , extracted by the unlabeled data . The best semantic vector representation was Word Embedding . Word Embedding out - performed all the other semantic models . For all of the rep - resentations the accuracy advantage of the Word Embedding model was statistically signiﬁcant 3 . We note that given the LDA vectors , the SVM method classiﬁed almost all the examples as abusive . We tried to change the model’s parameters , such as the vector dimension , but it didn’t improve the results . TABLE I SVM RESULTS FOR ALL THE SEMANTIC VECTOR REPRESENTATIONS . Representation Accuracy Precision Recall F1 LSA 0 . 6687 0 . 721 0 . 669 0 . 648 LDA 0 . 5039 0 . 751 0 . 504 0 . 342 RP 0 . 6514 0 . 689 0 . 651 0 . 633 Word Embedding 0 . 7003 0 . 713 0 . 700 0 . 696 Table II presents the accuracy , precision , recall , and F1 results of the two types of text representation : N - grams rep - resentations ( unigram , bigram , and trigram ) and Character n - grams ( character 2 - grams , 3 - grams , 4 - grams , and 5 - grams ) . The unigram representation and the character n - grams rep - resentations are better than all the semantic vector representa - tions , presented in Table I . The unigram representation outperformed all the other n - grams representations signiﬁcantly . However , the best rep - resentations were the character 4 - grams and character 5 - grams . The accuracy advantage of the character 4 - grams representation over the unigram representation was statistically signiﬁcant . 1 http : / / www . cs . waikato . ac . nz / ml / weka / 2 https : / / radimrehurek . com / gensim / index . html 3 In all the reported experiments , statistical signiﬁcant was measured ac - cording to the paired t - test at the 0 . 05 level TABLE II SVM RESULTS FOR THE N - GRAMS AND C HARACTER N - GRAMS REPRESENTATIONS . Representation Accuracy Precision Recall F1 Unigram 0 . 8031 0 . 805 0 . 803 0 . 803 Bigram 0 . 6259 0 . 720 0 . 626 0 . 581 Trigram 0 . 5306 0 . 729 0 . 531 0 . 401 Character 2 - grams 0 . 7973 0 . 797 0 . 797 0 . 797 Character 3 - grams 0 . 8285 0 . 829 0 . 829 0 . 829 Character 4 - grams 0 . 8379 0 . 839 0 . 838 0 . 838 Character 5 - grams 0 . 8346 0 . 836 0 . 835 0 . 834 IV . R ELATED W ORK Most prior work in the area of offensive language detec - tion focused on using supervised classiﬁcation with n - gram features [ 1 ] , [ 35 ] – [ 37 ] and / or character n - gram features [ 2 ] , [ 38 ] , [ 39 ] . Some of the works extracted additional features by hand - crafted regular expressions and blacklists [ 1 ] , [ 35 ] , [ 40 ] . However , reference [ 41 ] showed that blacklist - based systems which simply identify words that fall on a listing of known abusive words are performing poorly . Reference [ 1 ] detected abusive tweets via semi - supervised LDA approach . They utilized statistical topic modeling on a huge Twitter corpus to exploit linguistic regularities in abusive language . They showed that their approach performs competitively with a variety of ML algorithms . Recently , there is growing interest in using distributional semantics features for comment abusive classiﬁcation . Refer - ence [ 42 ] learned distributed low - dimensional representations of comments using word embeddings [ 31 ] . Then , they used the low - dimensional vectors as inputs to a logistic regression ( LR ) classiﬁer . The word embeddings representation outperformed the baseline unigram representation . Reference [ 2 ] used a more sophisticated algorithm to learn Word Embeddings representation and added linguistic , n - grams , character n - grams , and syntactic features . They showed that their features combination is powerful . In the last three years , some works applied deep learning to determine whether or not a comment should be classiﬁed as abusive . Reference [ 38 ] trained a Recurrent Neural Network ( RNN ) language model per class ( accept , reject ) , and used the probability ratio of the two models to accept or reject user comments . Their experiments on the dataset of reference [ 42 ] showed that both their RNN method and a linear regression classiﬁer operating on word embedding representation perform worse than a combination of SVM and Naive Bayes classiﬁers ( NBSVM ) that use character and token n - grams . To beat NBSVM , reference [ 38 ] used an SVM to combine features from all the three methods . Reference [ 3 ] experimented with a new publicly available dataset of 1 . 6M moderated user comments from a Greek sports news portal and an existing dataset of 115K English Wikipedia talk page comments . They showed that a GRU RNN [ 43 ] operating on word embeddings outpeforms LR or Multi - Layer Perceptron classiﬁer with character or word n - gram features . 2018 ICSEE International Conference on the Science of Electrical Engineering Their RNN model also outperforms a vanilla Convolutional Neural Network ( CNN ) operating on word embeddings , and a baseline that uses an automatically constructed . word list with precision scores . They further improved the overall results of their RNN by a novel classiﬁcation - speciﬁc attention mechanism . V . C ONCLUSIONS AND F UTURE W ORK We introduced the task of comment abusive classiﬁca - tion . We established a Hebrew corpus of user comments annotated for abusive language . We investigated two types of text representations ( n - grams and character n - grams ) and four dimensional reduction methods for learning distributional representations unsupervisingly . We showed that the character n - grams representation is better than all the other representations for our task . We plan to investigate deep learning models , such as RNN and CNN , for comment abuse classiﬁcation . One common limitation for deep learning models is the large amount of data needed to train them . To increase the number of abusive comments , we plan to adopt the oversampling method that we have presented in this paper . R EFERENCES [ 1 ] G . Xiang , B . Fan , L . Wang , J . Hong , and C . Rose , “Detecting offensive tweets via topical feature discovery over a large scale twitter corpus , ” in Proceedings of the 21st ACM international conference on Information and knowledge management . ACM , 2012 , pp . 1980 – 1984 . [ 2 ] C . Nobata , J . Tetreault , A . Thomas , Y . Mehdad , and Y . Chang , “Abusive language detection in online user content , ” in Proceedings of the 25th international conference on world wide web . International World Wide Web Conferences Steering Committee , 2016 , pp . 145 – 153 . [ 3 ] J . Pavlopoulos , P . Malakasiotis , and I . Androutsopoulos , “Deeper atten - tion to abusive user content moderation , ” in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing , 2017 , pp . 1125 – 1135 . [ 4 ] B . Ross , M . Rist , G . Carbonell , B . Cabrera , N . Kurowsky , and M . Wo - jatzki , “Measuring the reliability of hate speech annotations : The case of the european refugee crisis , ” in Proceedings of NLP4CMC III : 3rd Workshop on Natural Language Processing for Computer - Mediated Communication , M . Beiwenger , M . Wojatzki , and T . Zesch , Eds . , 2016 , pp . 6 – 9 . [ 5 ] E . A . Abozinadah and J . H . Jones Jr , “Improved microblog classiﬁcation for detecting abusive arabic twitter accounts , ” International Journal of Data Mining & Knowledge Management Process ( IJDKP ) , vol . 6 , no . 6 , pp . 17 – 28 , 2016 . [ 6 ] H . Mubarak , K . Darwish , and W . Magdy , “Abusive language detection on arabic social media , ” in Proceedings of the First Workshop on Abusive Language Online , 2017 , pp . 52 – 56 . [ 7 ] H . - P . Su , Z . - J . Huang , H . - T . Chang , and C . - J . Lin , “Rephrasing profanity in chinese text , ” in Proceedings of the First Workshop on Abusive Language Online , 2017 , pp . 18 – 24 . [ 8 ] S . Deerwester , S . T . Dumais , G . W . Furnas , T . K . Landauer , and R . Harshman , “Indexing by latent semantic analysis , ” Journal of the American society for information science , vol . 41 , no . 6 , pp . 391 – 407 , 1990 . [ 9 ] T . K . Landauer , P . W . Foltz , and D . Laham , “An introduction to latent semantic analysis , ” Discourse processes , vol . 25 , no . 2 - 3 , pp . 259 – 284 , 1998 . [ 10 ] D . M . Blei , A . Y . Ng , and M . I . Jordan , “Latent dirichlet allocation , ” Journal of machine Learning research , vol . 3 , no . Jan , pp . 993 – 1022 , 2003 . [ 11 ] X . Hu , N . Sun , C . Zhang , and T . - S . Chua , “Exploiting internal and external semantics for the clustering of short texts using world knowl - edge , ” in Proceedings of the 18th ACM conference on Information and knowledge management . ACM , 2009 , pp . 919 – 928 . [ 12 ] E . Bingham and H . Mannila , “Random projection in dimensionality reduction : applications to image and text data , ” in Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining . ACM , 2001 , pp . 245 – 250 . [ 13 ] T . Mikolov , I . Sutskever , K . Chen , G . S . Corrado , and J . Dean , “Distributed representations of words and phrases and their composi - tionality , ” in Advances in neural information processing systems , 2013 , pp . 3111 – 3119 . [ 14 ] C . Ma , W . Xu , P . Li , and Y . Yan , “Distributional representations of words for short text classiﬁcation , ” in Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing , 2015 , pp . 33 – 38 . [ 15 ] T . Jay and K . Janschewitz , “The pragmatics of swearing , ” Journal of Politeness Research . Language , Behaviour , Culture , vol . 4 , no . 2 , pp . 267 – 288 , 2008 . [ 16 ] C . Liebeskind , K . Nahon , Y . HaCohen - Kerner , and Y . Manor , “Compar - ing sentiment analysis models to classify attitudes of political comments on facebook ( november 2016 ) , ” Polibits , vol . 55 , pp . 17 – 23 , 2017 . [ 17 ] C . Liebeskind , S . Liebeskind , and Y . HaCohen - Kerner , “Comment relevance classiﬁcation in facebook , ” in 18th International Conference on Computational Linguistics and Intelligent Text Processing , Budapest , Hungary , 2017 . [ 18 ] C . Liebeskind and K . Nahon , “Challenges in applying machine learning methods : Studying political interactions on social networks , ” in Semantic Keyword - Based Search on Structured Data Sources , J . Szymaski and Y . Velegrakis , Eds . Cham : Springer International Publishing , 2018 , pp . 136 – 141 . [ 19 ] S¸ . Ertekin , “Adaptive oversampling for imbalanced data classiﬁcation , ” in Information Sciences and Systems 2013 . Springer , 2013 , pp . 261 – 269 . [ 20 ] Z . Zheng , Y . Cai , and Y . Li , “Oversampling method for imbalanced classiﬁcation , ” Computing and Informatics , vol . 34 , no . 5 , pp . 1017 – 1037 , 2016 . [ 21 ] A . Fern´andez , S . Garcia , F . Herrera , and N . V . Chawla , “Smote for learning from imbalanced data : Progress and challenges , marking the 15 - year anniversary , ” Journal of Artiﬁcial Intelligence Research , vol . 61 , pp . 863 – 905 , 2018 . [ 22 ] H . Sch¨utze and J . O . Pedersen , “A cooccurrence - based thesaurus and two applications to information retrieval , ” Information Processing & Management , vol . 33 , no . 3 , pp . 307 – 318 , 1997 . [ 23 ] F . Smadja , K . R . McKeown , and V . Hatzivassiloglou , “Translating col - locations for bilingual lexicons : A statistical approach , ” Computational linguistics , vol . 22 , no . 1 , pp . 1 – 38 , 1996 . [ 24 ] J . Cohen , “A coefﬁcient of agreement for nominal scales , ” Educational and psychological measurement , vol . 20 , no . 1 , pp . 37 – 46 , 1960 . [ 25 ] J . R . Landis and G . G . Koch , “The measurement of observer agreement for categorical data , ” biometrics , pp . 159 – 174 , 1977 . [ 26 ] S . Raaijmakers and W . Kraaij , “A shallow approach to subjectivity classiﬁcation , ” in ICWSM , 2008 . [ 27 ] F . Aisopos , G . Papadakis , K . Tserpes , and T . Varvarigou , “Content vs . context for sentiment analysis : a comparative analysis over microblogs , ” in Proceedings of the 23rd ACM conference on Hypertext and social media . ACM , 2012 , pp . 187 – 196 . [ 28 ] T . Minka and J . Lafferty , “Expectation - propagation for the generative as - pect model , ” in Proceedings of the Eighteenth conference on Uncertainty in artiﬁcial intelligence . Morgan Kaufmann Publishers Inc . , 2002 , pp . 352 – 359 . [ 29 ] T . L . Grifﬁths and M . Steyvers , “Finding scientiﬁc topics , ” Proceedings of the National academy of Sciences , vol . 101 , no . suppl 1 , pp . 5228 – 5235 , 2004 . [ 30 ] W . B . Johnson and J . Lindenstrauss , “Extensions of lipschitz mappings into a hilbert space , ” Contemporary mathematics , vol . 26 , no . 189 - 206 , p . 1 , 1984 . [ 31 ] Q . Le and T . Mikolov , “Distributed representations of sentences and documents , ” in International Conference on Machine Learning , 2014 , pp . 1188 – 1196 . [ 32 ] M . Hall , E . Frank , G . Holmes , B . Pfahringer , P . Reutemann , and I . H . Witten , “The weka data mining software : an update , ” ACM SIGKDD explorations newsletter , vol . 11 , no . 1 , pp . 10 – 18 , 2009 . [ 33 ] I . H . Witten , E . Frank , M . A . Hall , and C . J . Pal , Data Mining : Practical machine learning tools and techniques . Morgan Kaufmann , 2016 . [ 34 ] S . S . Keerthi , S . K . Shevade , C . Bhattacharyya , and K . R . K . Murthy , “Improvements to platt’s smo algorithm for svm classiﬁer design , ” Neural computation , vol . 13 , no . 3 , pp . 637 – 649 , 2001 . 2018 ICSEE International Conference on the Science of Electrical Engineering [ 35 ] D . Yin , Z . Xue , L . Hong , B . D . Davison , A . Kontostathis , and L . Ed - wards , “Detection of harassment on web 2 . 0 , ” Proceedings of the Content Analysis in the WEB , vol . 2 , pp . 1 – 7 , 2009 . [ 36 ] Y . Chen , Y . Zhou , S . Zhu , and H . Xu , “Detecting offensive language in social media to protect adolescent online safety , ” in Privacy , Security , Risk and Trust ( PASSAT ) , 2012 International Conference on and 2012 International Confernece on Social Computing ( SocialCom ) . IEEE , 2012 , pp . 71 – 80 . [ 37 ] W . Warner and J . Hirschberg , “Detecting hate speech on the world wide web , ” in Proceedings of the Second Workshop on Language in Social Media . Association for Computational Linguistics , 2012 , pp . 19 – 26 . [ 38 ] Y . Mehdad and J . Tetreault , “Do characters abuse more than words ? ” in Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue , 2016 , pp . 299 – 303 . [ 39 ] Z . Waseem and D . Hovy , “Hateful symbols or hateful people ? predictive features for hate speech detection on twitter , ” in Proceedings of the NAACL student research workshop , 2016 , pp . 88 – 93 . [ 40 ] S . O . Sood , J . Antin , and E . F . Churchill , “Using crowdsourcing to improve profanity detection . ” in AAAI Spring Symposium : Wisdom of the Crowd , vol . 12 , 2012 , p . 06 . [ 41 ] S . O . Sood , E . F . Churchill , and J . Antin , “Automatic identiﬁcation of personal insults on social news sites , ” Journal of the American Society for Information Science and Technology , vol . 63 , no . 2 , pp . 270 – 285 , 2012 . [ 42 ] N . Djuric , J . Zhou , R . Morris , M . Grbovic , V . Radosavljevic , and N . Bhamidipati , “Hate speech detection with comment embeddings , ” in Proceedings of the 24th international conference on world wide web . ACM , 2015 , pp . 29 – 30 . [ 43 ] K . Cho , B . Van Merri¨enboer , C . Gulcehre , D . Bahdanau , F . Bougares , H . Schwenk , and Y . Bengio , “Learning phrase representations using rnn encoder - decoder for statistical machine translation , ” arXiv preprint arXiv : 1406 . 1078 , 2014 .