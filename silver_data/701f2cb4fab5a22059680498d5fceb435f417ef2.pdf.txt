Full length article Who views online extremism ? Individual attributes leading to exposure Matthew Costello a , * , James Hawdon b , Thomas Ratliff c , Tyler Grantham d a Department of Criminology , Sociology , and Geography , Arkansas State University , 3131 Humanities and Social Sciences , State University , AR 72467 , USA b Department of Sociology , Virginia Tech University , 205a Norris Hall , Blacksburg , VA 24061 , USA c Department of Criminology , Sociology , and Geography , Arkansas State University , 3073 Humanities and Social Sciences , State University , AR 72467 , USA d Department of Criminology , Sociology , and Geography , Arkansas State University , 3070 Humanities and Social Sciences , State University , AR 72467 , USA a r t i c l e i n f o Article history : Received 12 January 2016 Received in revised form 6 May 2016 Accepted 13 May 2016 Keywords : Online victimization Online extremism Exposure to online hate Routine activities theory Flocking and feathering a b s t r a c t Who is likely to view materials online maligning groups based on race , nationality , ethnicity , sexual orientation , gender , political views , immigration status , or religion ? We use an online survey ( N ¼ 1034 ) of youth and young adults recruited from a demographically balanced sample of Americans to address this question . By studying demographic characteristics and online habits of individuals who are exposed to online extremist groups and their messaging , this study serves as a precursor to a larger research endeavor examining the online contexts of extremism . Descriptive results indicate that a sizable majority of respondents were exposed to negative materials online . The materials were most commonly used to stereotype groups . Nearly half of negative material centered on race or ethnicity , and respondents were likely to encounter such material on social media sites . Regression results demonstrate African - Americans and foreign - born respondents were signi ﬁ cantly less likely to be exposed to negative material online , as are younger respondents . Additionally , in - dividuals expressing greater levels of trust in the federal government report signi ﬁ cantly less exposure to such materials . Higher levels of education result in increased exposure to negative materials , as does a proclivity towards risk - taking . © 2016 Elsevier Ltd . All rights reserved . While the Internet has obvious bene ﬁ ts , its uncensored nature also exposes users to extremist ideas some ﬁ nd vile , offensive , and disturbing . Authorities consider online extremism a threat to na - tional security and note the need for research on it ( e . g . Hussain & Saltman , 2014 ; Levin , 2015 ; The White House , 2015 ) . While scholars are discussing strategies for countering the effects of extremism ( Helmus , York , & Chalk , 2013 ; Neumann , 2013 ) , few have investigated who is exposed to extremist materials ( for ex - ceptions , see Hawdon , Oksanen , & R € as € anen , 2014 ; R € as € anen et al . , 2015 ) . Yet , we must understand who sees extremist materials if we are to effectively limit exposure or disseminate counter - messages . Moreover , since youth appear to be most vulnerable to extremist messages ( Oksanen , Hawdon , Holkeri , N € asi , & R € as € anen , 2014 ; Onuoha , 2014 ; Torok , 2016 ) , there is an enhanced need to investigate what online behaviors place them at risk for exposure . To help guide efforts in combatting online extremism by understanding who sees these materials , we use a sample of youth and young adults to investigate the behavioral and attitudinal factors that lead to exposure . We frame the analysis using routine activity theory ( RAT ) , which argues that crimes occur when a motivated offender , a suitable target , and a lack of capable guard - ians converge in time and space ( Cohen & Felson , 1979 ) . The theory explains how victims ’ activities can expose them to dangerous people , places , and situations . We also extend RAT by incorporating insights from social learning theory ( Akers , 1977 ) . Speci ﬁ cally , we consider if those who distrust government are more likely to view extremist messages because their ideology leads them to frequent online environments where extremist opinions are posted . There - fore , we focus on two research questions : R1 : What behaviors place youth and young adults at risk of being virtually proximate to extremist materials ? R2 : Does the lack of trust in the government increase exposure to extremist materials , all else being equal ? By identifying behaviors and attitudes that lead to extremism , our research will help authorities design strategies to counter its effects . * Corresponding author . E - mail address : mcostello @ astate . edu ( M . Costello ) . Contents lists available at ScienceDirect Computers in Human Behavior journal homepage : www . elsevier . com / locate / comphumbeh http : / / dx . doi . org / 10 . 1016 / j . chb . 2016 . 05 . 033 0747 - 5632 / © 2016 Elsevier Ltd . All rights reserved . Computers in Human Behavior 63 ( 2016 ) 311 e 320 The current study , which was approved by the Intuitional Review Boards ( IRBs ) of the universities involved in the project as well as the National Institute of Justice , begins with a discussion of online extremism . We then review RAT and extend it by considering in - sights from social learning theory . We then predict exposure to online hate materials among a sample of 1029 youth and young adults . We conclude by considering the implications of our research . 1 . Online extremism : its nature , types , and dangers The phenomenon we consider is a type of cyberviolence ( see Wall , 2001 ) andgoes by many names : onlineextremism , online hate , or cyberhate . We consider online hate or extremism to be the use of information computer technology ( ICT ) to profess attitudes devalu - ating others because of their religion , race , ethnicity , gender , sexual orientation , national origin , or some other characteristic . As such , online hate material is a distinct form of cyberviolence as abuse is aimed at a collective identity rather than a speci ﬁ c individual ( Hawdon et al . , 2014 ) . Contrasting exposure to online hate with cyberbullying , R € as € anen andhiscolleagues ( forthcoming ) argue , that : exposure to online hate material does not attack the individual in isolation ; instead , this form of violence occurs when individuals are unwittingly exposed to materials against their will that express hatred or degrading attitudes toward a collective to which they belong . That is , hate materials denigrate groups ; it is not an attack that focuses on individuals . Extremists , both individuals and organized groups , champion their cause , recruit members , advocate violence , and create inter - national extremist communities through websites , blogs , chat rooms , ﬁ le archives , listservers , news groups , internet commu - nities , online video games , and web rings ( Amster , 2009 ; Burris , Smith , & Strahm , 2000 ; Franklin 2010 ; Hussain & Saltman , 2014 ) . Organized hate groups such as the Ku Klux Klan have used the web since its public inception ( Amster , 2009 ; Gerstenfeld , Grant , & Chiang , 2003 ) , but individuals maintaining sites or commenting online have surpassed organized groups as the main perpetrators ( Potok , 2015 ) . Given the nature of our analysis ( self - reported exposure to online hate materials ) , we cannot determine if the material to which the respondents refer was posted by a formal group or an individual ; nevertheless , the respondents claim the site expressed hatred toward some collective d the essence of our de ﬁ nition of online hate materials . It is important to realize exposure to online hate material may not be victimizing , per se . Some people actively seek such mate - rials , and they would not be “ victimized ” in the traditional sense of the word . Others , however , come upon this material inadvertently . Even when the material is found accidently , we should not over - state the dangers these materials pose . Many people view hate materials without experiencing negative consequences , and most hate messages do not directly advocate violence ( Douglas , McGarty , Bliuc , & Lala , 2005 ; Gerstenfeld et al . , 2003 ; Glaser , Dixit , & Green , 2002 ; McNamee , Peterson , & Pe ~ na , 2010 ) . Nevertheless , exposure to hate materials correlates with several problematic behaviors and attitudes ( Subrahmanyam & (cid:2) Smahel , 2011 ) . For example , members of targeted groups can experience mood swings , anger , and fear after exposure ( Tynes , 2006 ; Tynes , Reynolds , & Green ﬁ eld , 2004 ) . In addition , exposure to online hate materials is inversely related to social trust ( Nasi et al . , 2015 ) . Long - term exposure to hate materials can reinforce discrimination against vulnerable groups ( Cowan & Mettrick , 2002 ; Foxman & Wolf , 2013 ) and lead to an inter - generational perpetuation of extremist ideologies ( Perry , 2000 ; Tynes , 2006 ) . In some cases , exposure to online hate materials is directly linked to violence , including acts of mass violence and terror ( Federal Bureau of Investigation 2011a ; for a list of deadly attacks see Freilich , Belli , & Chermak . , 2011 ; The New America Foundation International Security Program 2015 ) . Recently , exposure to extremist ideology has been implicated in recruiting youth to extremist causes , including terrorist organizations such as the Islamic State of Iraq and the Levant ( ISIL ) . It is therefore important to understand who is likely to be exposed to these materials . 2 . Correlates of exposure The limited number of existing studies analyzing exposure to online hate and extremism rely on Cohen and Felson ’ s ( 1979 ) routine activity theory ( RAT ) and its recent revisions . RAT argues that crimes occur when a motivated offender , a suitable target , and a lack of capable guardians converge in time and space ( Cohen & Felson , 1979 ) . Individuals ’ activities can place them in danger by bringing them into contact with potential offenders and into en - vironments that lack guardians who could confront those offenders ( see Cohen & Felson , 1979 ; Miethe & Meier , 1990 ) . In addition , in - dividuals ’ routines in ﬂ uence how attractive they are to offenders , and the probability of victimization increases as target attractive - ness increases ( Cohen & Felson , 1979 ) . While there are complicating factors for applying RAT to the online world ( see Tillyer & Eck , 2009 ; Yar , 2005 , 2013 ) , the cyberlifestyle - routine activities perspective ( Eck & Clarke , 2003 ; Reyns , 2013 ; Reyns , Henson , & Fisher , 2011 ) overcomes some of these problems . Most notably , while cybervictims and offenders do not converge in time and space as victims and offenders do in the of ﬂ ine world , they nevertheless come into virtual contact through their networked devices ( Reyns et al . , 2011 ) . The asynchronous nature of cyberviolence is clearly seen with exposure to hate ma - terial . Those posting hate materials can offend people across spaces and time because , once materials are posted , people can become exposed to them without ever directly interacting with offenders . The primary factor likely resulting in hate material exposure is proximity to “ offenders . ” More precisely , given the asynchronous nature of the Internet , proximity to the virtual places where offenders have been is the primary determinant of exposure . In the language of RAT , victimization should be related to factors leading one into dangerous places . As noted above , one need not directly encounter an offender ; instead , one only need arrive at a place on the web where the offender has left offensive materials . Unlike offenders in traditional street crimes or even cybercrimes such as online fraud or cyberbullying , hate speech “ offenders ” do not select speci ﬁ c targets . Indeed , those who post materials expressing hate do not necessarily aim to “ victimize ” anyone , per se . In fact , their main objectives are often to recruit and connect like - minded people in support of their cause , educate others about their group , promote association with the group , invoke the ‘ natural right ’ of the group , and denunciate others for defaming their group ( see Douglas et al . , 2005 ; McNamee et al . , 2010 ) . While these “ offenders ” are more likely to target some groups than others depending on what brand of extremism and hate they harbor , this does not necessarily mean members of the targeted groups are any more likely to be exposed to this material than are members of other groups . Just as target suitability is not particularly relevant to our study , providing guardianship online is extremely dif ﬁ cult and likely does not determine exposure . In general , many studies ﬁ nd that levels of guardianship do not strongly in ﬂ uence online victimization . For example , physical guardianship such as using ﬁ rewalls , anti - virus programs , ﬁ ltering , and blocking software , do not appear to reduce the likelihood of victimization ( Bossler & Holt , 2009 ; Fleming , Greentree , Cocotti - Muller , Elias , & Morrison , 2006 . Furthermore , the social guardianship of online behavior provided by parents produces contradicting effects ( compare Lwin , Stanaland , & Miyazaki , 2008 ; Marcum , Higgins & Ricketts 2010a ; Marcum , M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 312 Higgins & Ricketts 2010b ) . With respect to exposure to online hate materials , hate speech is generally protected in the U . S . and there are no ﬁ ltering programs that would prevent hateful materials from being found . While some providers such as YouTube remove ma - terials others report as offensive , these tactics are limited in their overall effectiveness ( see Foxman & Wolf , 2013 for a discussion ) . Therefore , to understand what leads to exposure we must consider what places one at risk of being virtually proximate to offensive materials . One factor that logically increases the proba - bility of encountering offensive materials is the time one spends online : the more time online , the greater the chances of coming into contact with hate materials , all else being equal . Several researchers found time spent online increased the likelihood of being a victim of a variety of cybercrimes ( Hinduja & Patchin , 2008 ; Henson , Wilcox , Reyns , & Cullen , 2010 ; Pratt , Holtfreter , & Reisig , 2010 ; contrast Bossler & Holt , 2009 ; Reyns et al . , 2011 ; Reyns , Burek , Henson & Fisher , 2013 ) , and we anticipate that time spent online will be an important predictor because it increases the probability of entering a “ dangerous ” website or using a “ dangerous ” service . In addition to the time spent online , using numerous Internet services and social networking sites ( SNS ) should increase exposure to online hate materials . With every site a user visits , she or he runs a risk of seeing extremist messages and hate material . Indeed , in one study , “ active users ” ( those using six or more services ) were nearly twice as likely to view online hate material as were “ passive users ” ( Hawdon et al . , 2014 ) . It is likely a more re ﬁ ned measure of what sites were visited would increase this effect . For example , in a study of young Finnish Facebook users , visiting websites advo - cating self - harm d including sites that promoted suicide or cut - ting d increased the likelihood of exposure to online hate materials ( R € as € anen et al . , 2015 ) . Although re ﬁ ned measures of Internet use are obviously preferable , even a relatively crude global measure of use correlates strongly with exposure . Spending time online and accessing numerous sites are likely to increase exposure to hate materials simply by increasing oppor - tunities for chance occurrences with offensive materials . Other behaviors , however , likely bring one into contact with offensive materials more directly . For example , having numerous online contacts will likely increase one ’ s virtual proximity to online hate material because the greater the number of contacts one has , the higher the probability that one of them expresses extremist , hateful attitudes . In a study of over 1000 American Internet users , for example , the number of Facebook friends one had increased the odds of being exposed to hate materials ( Hawdon et al . , 2014 ) . Number of Facebook friends also increased the odds of exposure to hate materials among Finnish youth , although the effect was sta - tistically signi ﬁ cant only at liberal levels ( R € as € anen et al . , 2015 ) . In addition to one ’ s online behaviors , one ’ s online associates would in ﬂ uence his or her virtual proximity to potential offenders . There is considerable overlap between offending and victimization ( for a review see Jennings , Piquero & Reingle , 2012 ) , and this is true for both of ﬂ ine and online victimization ( e . g . Bossler & Holt , 2009 ; Holtfreter , Reisig , Leeper Piquero , & Piquero , 2010 ) . In Bossler , Holt and May ’ s ( 2012 ) study of middle and high school students , those whose peers engaged in online harassment were more likely to be harassed themselves . In addition , it is well documented that those who are victimized once are more likely to be victimized again ( Fagan & Mazerolle , 2011 ; Finkelhor , Ormrod , & Turner , 2007 ) , and those who experience one type of cybervictimization are more likely to be victimized by different types of cybervictimization ( Reyns , Burek , Henson , & Fisher , 2013 ) . The tendency for repeat victimization is , in part , a result of victims participating in activities occurring in the company of offenders . The link between online behaviors , associates , and victimization is well theorized by RAT and cyberlifestyle routine activity theory . However , another possibility is that certain attitudes and world - views increase one ’ s exposure to dangerous people and places . Speci ﬁ c attitudes may increase exposure because they lead users to search for topics , click on banner ads , read blogs , join chat groups , and read news stories that express extremist opinions . Speci ﬁ cally , people with particular political ideologies will likely be exposed to hate materials more frequently than those with opposite political leanings . Let us now consider this hypothesized relationship . 2 . 1 . Ideology and exposure to online hate Radical rightwing groups and individuals professing rightwing extremist ideologies are the most active producers of online hate material at this time ( see Hawdon et al . , 2014 ; Potok , 2015 ; Ratliff , Hawdon , Middleton , Tan , & Snow , 2015 ) . Rightwing hate groups include those advocating racial superiority and call for racial purity . They also include groups expressing hatred of a particular culture or lifestyle that they deem threatening to their own values and culture ( e . g . anti - Muslim , anti - Semitic , anti - Arab , anti - Hispanic , anti - LBGT ) . A third type of rightwing hate group includes anti - government nationalists . All of these types , and especially the last , express negative attitudes toward the government . Indeed , the sovereign citizen movement , which may have as many as 300 , 000 members , do not believe the federal government has authority over them ( Potok , 2015 ; FBI 2011b ) . Many of these groups consider the government as unwilling or unable to protect their interests . Even worse , from their perspective , they often see the government as protecting or advancing the interests of some hated group ( see Hawdon et al . , 2014 ) . Given the online presence of rightwing groups and individuals holding extreme anti - government ideologies ( Ratliff et al . , 2015 ) , it is likely one ’ s views toward the government would in ﬂ uence their proximity to hate materials and extremist ideas . There are two possible mechanisms for this . The ﬁ rst mechanism is what social learning theorists refer to as “ ﬂ ocking ” : those who distrust the government are likely to associate with others who distrust gov - ernment . Thus , those who have become alienated from the gov - ernment “ ﬂ ock ” to those with similar attitudes . The second possible mechanism could be “ feathering . ” Here , people begin to interact with those who harbor anti - government attitudes , and , as they do , begin to learn these values and attitudes . As they adopt and express these anti - government attitudes , those sharing those attitudes positively reinforce them ( for a discussion of feathering and ﬂ ocking see Akers , 1977 ) . We do not have the data to test which mechanism is at play , and , as in the of ﬂ ine world , it is most likely that both feathering and ﬂ ocking occurs . Regardless , anti - governmental attitudes likely increase exposure to online hate materials through one or both of these mechanisms . The link between feathering , ﬂ ocking and victimization may apply to all sorts of victimization , but it could be particularly rele - vant to the online world . Cybertechnology enables SNS and news sites to use information collected about individual users to personalize what they see on their screens . This process creates a “ ﬁ lter bubble ” ( Pariser , 2011 ) where the information people see online increasingly re ﬂ ects attitudes , beliefs , and lifestyles similar to their own . Thus , individuals who harbor anti - government sen - timents will likely be attracted to anti - government messages . As they read these messages , algorithms record their anti - government disposition , and personalization would then increase the likelihood of seeing additional content that con ﬁ rms and reinforces their anti - government worldview . This process will eventually narrow and polarize the information to which one is exposed . If the process continues , it likely leads to being exposed to increasingly extreme views ( see Hawdon , 2012 ) . Since rightwing extremists are highly active on the web , disproportionately hold anti - government M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 313 dispositions , and often express hate towards groups , those with anti - government attitudes are more likely to be “ ﬁ ltered ” into on - line environments that contain hate materials . To be clear , this is not saying that those who distrust the gov - ernment or hold anti - governmental views will become extremists or inevitably see rightwing hate messages . The link is probabilistic , and there is a continuum of anti - governmental attitudes d not just radical rightwing ideologies . The ﬁ lter bubble simply implies that strongly held beliefs are likely to be ampli ﬁ ed . Therefore , the more one dislikes the government , the more likely they will be ﬁ ltered toward hate material . Conversely , the more one expresses favorable attitudes toward the government , the more likely they will be ﬁ ltered away from hate material . 3 . Methods We employ descriptive and multivariate techniques to uncover factors in ﬂ uencing exposure to online hate material . Logistic regression is used to assess factors in ﬂ uencing exposure to hateful material online . Logit techniques are preferred when analyzing a binary dependent variable , and the effect of independent variables are reported as odds ratios which show relative changes in the odds of an outcome when an independent variable ’ s value is increased by one unit , holding all other effects constant . Three sets of independent variables are utilized . Exposure vari - ables are behaviors that place one in proximity to offensive mate - rials in virtual space . Non - RAT variables are those that do not necessarily bring one into virtual proximity with offenders or hate materials but are correlated with various types of online victimi - zation . For example , being victimized of ﬂ ine does not necessarily have any direct connection with one ’ s online activities ; however , of ﬂ ine victimization correlates with a variety of types of online victimization ( Helweg - Larsen , Schütt , & Larsen , 2012 ) . Similarly , self - control may in ﬂ uence victimization , but this variable is not theoretically related to RAT , at least in its original formulation . The ﬁ nal set of included variables capture demographic characteristics to guard against the possibility they would confound the rela - tionship between trust in government and exposure . 3 . 1 . Sample The sample consists of 1034 Internet users aged 15 to 36 . Data were collected during the week of January 28 , 2015 from demo - graphically balanced panels of people who voluntarily agreed to participate in research surveys . Survey Sample International ( SSI ) recruits potential participants through random digit dialling , ban - ner ads , and other permission - based techniques . Email invitations were sent to a sample of panel members strati ﬁ ed to re ﬂ ect the U . S . population between the ages of 15 e 36 on age , gender , and geographic region . Demographically balanced online panels protect against bias in online surveys because screening can eliminate respondents and panelists who have previously participated ( Evans & Mathur , 2005 ; Wansink , 2001 ) . Moreover , the recruitment and selection processes , theuseofpre - panelinterviews , andincentivesincreasethevalidityof responses because those who volunteer to be in the panel tend to be more serious about answering the questions ( see Wansink , 2001 ) . 3 . 2 . Dependent variable Exposure to Hateful Material : The dependent variable gauges respondents ’ exposure to negative , hateful material online . Re - spondents were asked if they have seen or heard any materials online that expressed negative views about any group because of the their race , nationality , ethnicity , sexual orientation , gender , political views , immigrant status , or religion over the past three months . Following our de ﬁ nition of hate materials discussed above , the variable used to operationalize exposure to these materials explicitly refers to views expressed about groups . Two - thirds of respondents ( 65 . 4 % ) report having seen or heard such materials during the three months prior to being interviewed . 3 . 3 . Independent variables 3 . 3 . 1 . Exposure variables Trust in the Government : The variable of central interest , trust in government , isconsideredanexposurevariablebecauserespondents who lack trust in the government may be more inclined to visit websites expressing extremist opinions . The level of trust in gov - ernment is measured using a composite scale of three items ranging from 1 to 10 . The items evaluate respondents ’ trust in local govern - ment , Congress , and the President . Higher scores indicate a greater leveloftrustasavalueof10correspondstotheresponsethatthelocal government ( or Congress or President ) “ can be fully trusted ” and a value of 1 corresponds to the response that “ you cannot be too careful ” with the local government ( or Congress or President ) . The three trust items were combined and averaged . Overall , respondents report a moderate level of trust , with a mean of 4 . 9 . Online Activity : We use global measures of online activity . First , the number of hours per day that respondents use the Internet is included , with the expectation that more time online will increase the likelihood of hate material exposure . Next , the squared term of this variable is included to detect a possible non - linear relationship . This is important because individuals may view negative materials when initially accessing the Internet and engage in activities that avoid these materials as their time online continues . Finally , dummy variables indicating whether respondents used various social media sites over the past three months are included to discover on which sites extremist materials are more likely found . We control for six of the most commonly traf ﬁ cked social media sites according to the survey results : Facebook , Twitter , YouTube , Google þ , Tumblr , and photo - sharing sites , such as Instagram . Online Victimization : As noted above , victims frequently suffer multiple victimizations . Thus , we anticipate that individuals who have been targets of online harassment will have elevated rates of exposure . We examine this possibility using a variable that queries respondents if they have been targeted with hateful or degrading material online at any time . Twenty - three percent ( 22 . 8 % ) of re - spondents indicate they have been targets of online hate . Targeting took on many forms , although individuals were most likely to be targets of hate based on their race or ethnicity ( 9 . 6 % ) , appearance ( 7 . 5 % ) , religion ( 6 . 7 % ) sexual orientation ( 5 . 9 % ) , political views ( 5 . 6 % ) , nationality ( 5 . 4 % ) , and sex / gender ( 4 . 5 % ) . Online attachments : Online attachment is evaluated by asking respondents how close they feel to an online group to which they belong . Closeness is determined using a 5 - point scale with higher scores indicating greater attachment . A response of 5 indicates that individuals “ feel very close to an online community to which they belong , ” while a value of 1 indicates that they feel “ not close at all ” to such a community . This item has been used in previous studies of online victimization to assess if online attachments serve as a risk or a protective factor ( see Oksanen et al . , 2014 ) . A sizable share of respondents report a close attachment to an online community , with nearly one - third of those surveyed responding with either a 4 or a 5 on this item . 3 . 4 . Non - routine activity variables Risk - Taking : A growing body of research argues that individuals ’ levels of self - control are related to their chances of being victimized M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 314 ( see , for example , Schreck , 1999 ; Schreck , Wright , & Miller 2002 ; Jennings et al . , 2012 ) . Several studies of various forms of online victimization ﬁ nd those with low levels of self - control have higher risks of victimization ( e . g . Holtfreter , Reisig , & Pratt , 2008 ; van Wilsem 2013a ; van Wilsem 2013b ) . Others , however , report self - control is not an important determinant of cybervictimization ( e . g . Bossler & Holt , 2010 ; Ngo & Paternoster , 2011 ) or the effect of self - control on victimization is partially mediated by exposure to motivated offenders ( Reyns , Henson , & Fisher , 2014 ) . While we lack a comprehensive measure of self - control , but we include a measure of risk - taking , which re ﬂ ects one of the primary mechanisms linking self - control and victimization ( see Schreck , 1999 ) . We measure risk - taking on a scale from 1 to 10 where respondents were asked how true the statement “ I enjoy taking risks ” was for them . Higher scores indicate higher levels of risk taking . The mean level of risk taking is 6 . 5 . Of ﬂ ine Attachments : Past research ﬁ nds poor social integration and a lack of social bonds are associated with risky and deviant behavior ( Colvin , Cullen , & Vander Ven 2002 ) . We control for this possibility by including two measures that gauge respondents ’ of ﬂ ine attachments . Like the measure of online attachments , both types of of ﬂ ine attachments are measured on a 5 - point scale with higher numbers indicating greater attachment . One measure asks respondents how close they feel to their friends , while the second assesses closeness to family . Seventy - eight percent of respondents reported they were close to friends , responding with a 4 or 5 . Likewise , over 80 percent of those surveyed reported they are close to their families ( either a 4 or a 5 ) . 3 . 5 . Socio - demographic characteristics Demographic factors may also in ﬂ uence exposure to online hate materials , although the literature is generally mixed concerning the effects these factors have on online victimization . We control for sex , race , age , region of the country , immigrant status , education , employment status , and living arrangement to gain an under - standing of who is most likely to be exposed to these materials . 4 . Results Table 1 reports the means , standard deviations , and minimum and maximum values for all variables included in the analysis . Table 2 summarizes the online activities of survey respondents . The vast majority of respondents ( 82 . 1 % ) spend at least 2 h online per , on average . Around 90 percent of respondents reported using Facebook ( 90 . 7 % ) and YouTube ( 89 . 7 % ) in the past three months . Over half of respondents reported using Twitter ( 53 . 3 % ) or Wiki - pedia ( 51 . 4 % ) , while 40 percent used Google þ and 37 . 6 percent utilized Skype . Just over a quarter of respondents ( 25 . 8 % ) were active on Tumblr . Table 3 provides a detailed overview of the type of exposure respondents encountered . Of the 65 . 4 percent of respondents who saw or heard hate material online in the prior three months , 45 . 7 percent stated the material pertained to group stereotypes . A quarter of respondents ( 24 . 8 % ) indicated the materials advocated hate towards a group , and another quarter ( 24 . 5 % ) stated the ma - terial blamed a group for the nation ’ s problems . Smaller , though not inconsequential , percentages of respondents said the materials called for violence ( 19 . 9 % ) or discrimination ( 16 . 6 % ) against the group . The most common forms of online hate pertained to race ( 46 . 3 % ) , sexual orientation ( 33 % ) , religion ( 27 . 3 % ) , nationality or immigration status ( 20 . 7 % ) , sex / gender ( 20 . 6 % ) , and politics ( 19 . 4 % ) . Table 4 shows most respondents encountered hate material online either occasionally ( 44 . 2 % ) or very infrequently ( 25 . 6 % ) . Far smaller shares stated they never see such material ( 12 . 1 % ) or see it only frequently ( 17 . 1 % ) . Respondents were most likely to encounter hate material on Facebook ( 47 . 6 % ) , YouTube ( 29 . 9 % ) , and Twitter ( 18 . 8 % ) , the three sites most commonly used overall . Interestingly , though sizable percentages of respondents reported visiting Wikipedia ( 51 . 4 % ) , Google þ ( 40 % ) photo - sharing sites ( 37 . 6 % ) , and Tumblr ( 25 . 8 % ) in the past three months , the percentage reporting that they viewed negative material on these sites were all below 10 percent . This suggests negative materials were largely clustered . It was most common for respondents to deliberately ﬁ nd their way to the negative material they encountered ( 31 . 8 % ) , but 17 . 8 percent found the material by accident and 14 percent were linked to the site by a friend or acquaintance . Table 5 shows the results of regressing exposure to online hate material on the independent variables . The ﬁ rst model controls for exposure variables , including hours per day respondents spent online ( and its squared term ) , websites visited , trust in govern - ment , online victimization , and closeness to an online community . The second model captures non - routine - activities variables , and the third model introduces socio - demographic variables . Model 1 reveals that one ’ s level of trust in the government is positively related to the likelihood of exposure to hate online ( OR ¼ 0 . 95 , p < 0 . 05 ) . This lends credence to our hypothesis that individuals who reported distrusting the government were more inclined to view websites disseminating hate material . Next , the amount of time respondents spend online ( OR ¼ 3 . 35 , p < 0 . 05 ) was a strong predictor of online exposure . In fact , each additional hour spent online increased the likelihood of seeing or hearing hate material by a factor of 3 . 6 . Interestingly , hours online demonstrated a quadratic inverted U - shaped relationship with exposure ( OR ¼ 0 . 82 , p < 0 . 05 ) , whereby spending over 3 h per day online decreased the likelihood of encountering hate material . This suggests those who view hate material online likely come upon it shortly after accessing the Internet . With time , they apparently participate in behaviors that virtually remove them from the dangerous places where motivated offenders disseminate extremist materials . YouTube users ( OR ¼ 1 . 96 , p < 0 . 01 ) were the most likely to see hate material . Tumblr ( OR ¼ 1 . 59 , p < 0 . 01 ) and photo - sharing site ( 1 . 55 , p < 0 . 01 ) users were also signi ﬁ cantly more likely to do so . Facebook , Twitter , and Google þ users , however , were not signi ﬁ - cantly more likely to view or hear online hate material . Individuals who have been targets of online hate ( OR ¼ 3 . 78 , p < 0 . 001 ) were signi ﬁ cantly more likely to view hate material . In fact , being a target had the strongest overall effect in the model , increasing the likeli - hood of encountering hate material by a factor of 3 . 8 . Being close to an online community did not signi ﬁ cantly affect exposure . The non - routine activities variables included in the second model donotproducesigni ﬁ canteffects . Risk - takingandclosenesstofriends and family of ﬂ ine were all non - signi ﬁ cant predictors of exposure . Moreover , all of the effects from the previous model remained consistent , with only slight variations in the magnitude of effects . The ﬁ nal model includes the socio - demographic variables . Age ( OR ¼ 0 . 96 , p < 0 . 01 ) was inversely related to exposure . The re - spondent ’ s race / ethnicity matters , as Blacks ( OR ¼ 0 . 64 , p < 0 . 05 ) and Asians ( OR ¼ 0 . 51 , p < 0 . 05 ) were less likely than Whites to be exposed to online hate material . Hispanics did not signi ﬁ cantly differ from Whites . Individuals with at least one parent born outside of the United States ( OR ¼ 1 . 58 , p < 0 . 01 ) were signi ﬁ cantly more likely to be exposed to online hate material . Education ( OR ¼ 1 . 34 , p < 0 . 001 ) was positively related to exposure , while unemployed respondents ( OR ¼ 0 . 64 , p < 0 . 05 ) and those living alone ( OR ¼ 0 . 54 , p < 0 . 01 ) were less likely to be exposed . Gender was not signi ﬁ cantly related to exposure , and there were no sig - ni ﬁ cant geographic differences , which supports the idea that online negativity is not locale - speci ﬁ c . Most importantly , the in ﬂ uence of M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 315 the exposure variables remained consistent with those reported in the previous models . The only noteworthy difference was that Google þ users ( OR ¼ 1 . 13 , p > 05 ) were now signi ﬁ cantly more likely to view hate material online . 5 . Discussion Online hate material and extremism has become a major concern in many western societies ( e . g . Foxman & Wolf , 2013 ; Waldron , 2012 ) , yet few studies investigate who is exposed to these mate - rials . Our study helps ﬁ llthis gap with an originalsurveyof American youth and young adults . We explored exposure to hate material by investigating the targets of hate speech and the sites or services whererespondentssaworheardthesematerials . Ourresultsshowed over sixty - ﬁ ve percent of respondents were exposed to hate mate - rials , and most of those exposed saw it accidently . Not surprisingly , these materials were seen most frequently on popular social networking sites . The hateful material most commonly focused on race and ethnicity ; however , othergroupswere alsofrequent targets . We relied on a slightly modi ﬁ ed version of routine activity theory to account for variation in exposure . We argued that the primary determinant for exposure to online hate materials will be online behaviors that increase one ’ s virtual proximity to enclaves frequented by extremists and those who express hate towards some collective . Results generally con ﬁ rmed our argument as time Table 1 Descriptive statistics of all variables . Variable Obs . Mean Std . dev . Min . value Max . value Hours Online / Day 1026 3 . 21 0 . 81 1 4 Hours Online / Day 2 1026 10 . 98 4 . 73 1 16 Use YouTube ¼ 1 1034 0 . 90 0 . 30 0 1 Use Facebook ¼ 1 1034 0 . 91 0 . 29 0 1 Use Twitter ¼ 1 1034 0 . 53 0 . 50 0 1 Use Photo - sharing ¼ 1 1034 0 . 38 0 . 48 0 1 Use Google þ ¼ 1 1034 0 . 40 0 . 49 0 1 Use Tumblr ¼ 1 1034 0 . 26 0 . 44 0 1 Trust Government 1005 4 . 87 2 . 51 1 10 Been Target of Online Hate ¼ 1 1027 0 . 23 0 . 42 0 1 Risk Taking 1003 6 . 47 2 . 44 1 10 Close to Online Community 1005 3 . 13 1 . 42 1 6 Close to Friends 1007 4 . 18 0 . 96 1 6 Close to Family 1009 4 . 41 0 . 98 1 6 Female ¼ 1 1034 0 . 50 0 . 50 0 1 Age 1034 24 . 66 6 . 19 15 36 Black ¼ 1 1034 0 . 11 0 . 31 0 1 Asian ¼ 1 1034 0 . 08 0 . 27 0 1 Hispanic ¼ 1 1034 0 . 11 0 . 31 0 1 Parent ( s ) Born Outside U . S . ¼ 1 1031 0 . 29 0 . 45 0 1 South ¼ 1 1034 0 . 31 0 . 46 0 1 West ¼ 1 1034 0 . 21 0 . 41 0 1 Northeast ¼ 1 1034 0 . 23 0 . 42 0 1 Education 1029 2 . 81 1 . 24 1 5 Unemployed ¼ 1 1034 0 . 19 0 . 39 0 1 Living Alone ¼ 1 1034 0 . 12 0 . 32 0 1 Table 2 Online activities of survey respondents . Hours / Day Online : < I Hour 34 . 0 % 1 e 2 Hours 13 . 7 % 2 e 5 Hours 40 . 3 % > 5 Hours 41 . 8 % Social Media Services Used : Facebook 90 . 7 % YouTube 89 . 7 % Twitter 53 . 3 % Wikipedia 51 . 4 % Google þ 40 . 0 % Photo - Sharing 37 . 6 % Skype 37 . 5 % Tumblr 25 . 8 % Table 3 Prevalence and type of negative material . Seen or heard negative views about a group : Yes 65 . 4 % No 35 . 4 % Negative material described as : Stereotyping 45 . 7 % Scapegoating for personal problems 27 . 0 % Scapegoating for national problems 24 . 5 % Advocated hatred 24 . 8 % Advocating violence 19 . 9 % Called for discrimination 16 . 6 % Negative material pertained to : Ethnicity or race 46 . 3 % Sexual orientation 33 . 0 % Religious conviction 27 . 3 % Nationality or immigrant status 20 . 7 % Sex / gender 20 . 6 % Political views 19 . 4 % Other 1 . 8 % Table 4 Encountering negative material online . Frequently encounter negative material online : Never 12 . 1 % Very infrequently 25 . 6 % Occasionally 44 . 2 % Frequently 17 . 1 % Heard negative views on : Facebook 47 . 6 % YouTube 29 . 9 % Twitter 18 . 8 % Ended up on site by : Deliberate navigation 31 . 8 % Referral 14 . 0 % Accident 17 . 8 % M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 316 spent online and frequenting popular websites increased the like - lihood of exposure . Most importantly , we argued speci ﬁ c attitudes would likely increase exposure . Given the prevalence of rightwing extremism online ( Potok , 2015 ; Ratliff et al . , 2015 ) , we argued anti - governmental attitudes would increase exposure through ﬂ ocking and feathering behaviors . This effect , while likely to occur in the of ﬂ ine world , could possibly be ampli ﬁ ed online because web ex - periences are personalized ( see Hawdon , 2012 ; Pariser , 2011 ) . As people holding anti - government attitudes click on , read , watch , or listen to materials that re ﬂ ect their anti - government views , their web experiences are personalized to provide them additional ma - terials that reaf ﬁ rm their views . Over time , it is possible that their online behaviors will ﬁ lter them toward increasingly extreme anti - governmental attitudes . Eventually , this ﬁ ltering process may lead to rightwing hate materials due to the correlation between anti - government attitudes and the numerical prevalence of radical rightwing content ( for a discussion of the ﬁ ltering process and personalized web experiences , see Pariser , 2011 ) . Conversely , those holding opinions more favorable toward the government may be ﬁ ltered away from rightwing extremist views . This ﬁ nding is relevant for several reasons . Theoretically , this suggestsinsightsfromsociallearningtheorycanpotentiallybeusedto strengthen leading theories of victimization . Currently , our under - standing of victimization is dominated by two theoretical traditions , Cohen and Felson ’ s routine activities theory ( 1979 ) and Gottfredson and Hirschi ’ s ( 1990 ) general theory of crime . While these frame - worksareclearlyuseful , thereisaneedtobetterunderstandtheroleof selection and socialization in the processes that determine risk . These processes are well documented in the of ﬂ ine world , at least when it comes to explanations of deviant behavior . It is well established that deviants select other deviants ( ﬂ ock ) and socialize each other into the ways of deviance ( feather ) . Yet , scholars have not directly incorporated notions of feathering and ﬂ ocking into studies of victimization . However , as noted above , there is consid - erable overlap between online offending and online victimization . Thus , just as low levels of self - control might increase one ’ s chances of being victimized ( Schreck , 1999 ) certain attitudes appear to heighten victimization by increasing the chances of associating with those who are likely to offend . These processes may be particularly true in the online world of ideas and symbols . The tendency for our online experiences to be personalized may create a ﬁ lter bubble that channels us to ever - narrowing perspectives . As our perspectives become narrow , we run the risk of also narrowing our online interactions . If we select d or ﬂ ock d to those like us , our online interactions become increasingly narrowed as we create a network of people who share our views . Over time , that network acts as a socializing d or feath - ering d agent convincing us that our opinions are “ common ” or “ typical . ” The ﬁ lter bubble likely increases the chances of this occurring because , as Pariser ( 2011 ) notes , most of us are unaware personalization is happening . We are therefore more likely to believe that our opinions , regardless of how narrow theyare , re ﬂ ect widely held views . 5 . 1 . Further analyses The ﬁ ndings on exposure to hate materials regarding race is somewhat perplexing yet highly important , particularly given that race - relatedcontentwasthemostfrequentformofonlinehate . When models were runwith “ White ” as the reference variable ( see Table5 ) , Hispanics were not signi ﬁ cantly different from whites in terms of exposure , while Blacks and Asians were less likely to be exposed . A possible reason for this is that Blacks and Asians self - selected away fromvirtualenvironmentssuitableforexposure . However , thisleftus withaperplexingresult d whywasthereadifferencebetweenAsians andHispanics , orBlacksandHispanics ? Workonsystemicracismand Table 5 Logistic regression analysis of exposure to negative material online ( Odds Ratios and Standard Errors ) . Model 1 Model 2 Model 3 O . R . Std . Err . O . R . Std . Err . O . R . Std . Err . Exposure to Hate Online Hours Online / Day 3 . 35 * 1 . 78 3 . 51 * * 1 . 90 3 . 00 * 1 . 68 Hours Online / Day 2 0 . 82 * 0 . 07 0 . 81 * 0 . 08 0 . 84 * 0 . 08 Use YouTube ¼ 1 1 . 96 * * 0 . 46 1 . 95 * * 0 . 47 1 . 99 * * 0 . 50 Use Facebook ¼ 1 0 . 89 0 . 23 0 . 89 0 . 23 0 . 88 0 . 24 Use Twitter ¼ 1 0 . 94 0 . 14 0 . 92 0 . 14 0 . 91 0 . 15 Use Photo - sharing ¼ 1 1 . 55 * * 0 . 25 1 . 51 * * 0 . 25 1 . 52 * * 0 . 26 Use Google þ ¼ 1 1 . 26 0 . 20 1 . 25 0 . 20 1 . 31 * 0 . 22 Use Tumblr ¼ 1 1 . 59 * * 0 . 30 1 . 59 * * 0 . 30 1 . 53 * 0 . 30 Trust Government 0 . 95 * 0 . 03 0 . 93 * 0 . 03 0 . 92 * * 0 . 03 Been Target of Online Hate ¼ 1 3 . 78 * * * 0 . 79 3 . 59 * * * 0 . 75 3 . 22 * * * 0 . 69 Close to Online Community 0 . 99 0 . 05 0 . 98 0 . 05 1 . 00 0 . 06 Risk Taking e e 1 . 03 0 . 03 1 . 04 0 . 03 Close to Friends e e 1 . 15 0 . 09 1 . 12 0 . 10 Close to Family e e 0 . 95 0 . 08 0 . 96 0 . 08 Female ¼ 1 e e e e 0 . 99 0 . 16 Age e e e e 0 . 96 * * 0 . 02 Black ¼ 1 e e e e 0 . 64 * 0 . 16 Asian ¼ 1 e e e e 0 . 52 * 0 . 15 Hispanic ¼ 1 e e e e 1 . 49 0 . 42 Parent ( s ) Born Outside U . S . ¼ 1 e e e e 1 . 58 * * 0 . 29 South ¼ 1 e e e e 1 . 17 0 . 23 West ¼ 1 e e e e 0 . 98 0 . 22 Northeast ¼ 1 e e e e 1 . 02 0 . 22 Education e e e e 1 . 34 * * * 0 . 11 Unemployed ¼ 1 e e e e 0 . 64 * 0 . 12 Living Alone ¼ 1 e e e e 0 . 54 * * 0 . 12 LR X 2 101 . 70 104 . 69 149 . 56 Log Pseudolikelihood (cid:2) 581 . 90 (cid:2) 575 . 77 (cid:2) 548 . 83 N 993 985 979 * p < 0 . 05 ; * * p < 0 . 01 ; * * * p < 0 . 001 ( two - tailed tests ) . M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 317 the question of “ whiteness ” ( i . e . Bonilla - Silva , 2001 , 2014 ; Yancey , 2003 ) suggests light - skinned Hispanics ( and potentially Asians ) havean “ honorarywhite ” statusinsociety ; thus , wemightexpectthat theirexposure - related behaviorswouldbesocialized ( “ feathered ” ) in a similar fashion , although compared to Whites this was not the case . To test this theoretical dilemma , we ran identical models with the reference variable for race switched to Black . Surprisingly , while Whites and Blacks were still statistically similar , Hispanics were more likely thanblacks to beexposed . Thisaddsa layerofcomplexity tothe interpretation , given no other signi ﬁ cance or signi ﬁ cance levels changed for other variables and that Asians were statistically no differentfromBlacks ( thus , thesamegeneralbehaviorsholdtrueasin the prior model ) . We suspect that the current anti - immigrant social narrative and political context may place Hispanics in online environments that may be otherwise immune from hate materials , but in our current context , provides opportunities for motivated offenders / perpetra - tors to express hateful messages . We also note that this is a perceptual measure , gauging an individual ’ s perceived exposure to hateful material d this is crucial for our point below . We speculate based on Bonilla - Silva ’ s hypothesis of an emerging “ Triracial Order , ” that Hispanics may be more vulnerable given their honorary white status in a context where anti - immigrant fervor is heightened . Most importantly , we could be observing Bonilla - Silva ’ s Triracial Order hypothesis in transition d do His - panics ( light to dark skin color variation notwithstanding ) that assimilate into a white perceptual schema in the context of everyday , of ﬂ ine life ﬁ nd themselves struck with the dissonant reality of color - blind racism ( Bonilla - Silva , 2014 ) manifesting in the online extremist environment ? In other words , while Hispanics may be making advances against structural inequalities in society and are becoming a larger percentage of the population , does this create suitable targets for motivated offenders whose racism is more blatant than blind ? Moreover , do variations in the structural barriers persisting in reality for minority groups create differential perceptual and / or online behavioral patterns ? As Yancey ( 2003 ) claims , the majority of Asians and Latinos self - identify as white on the Census , but a variation in group threat derived from different racial experiences ( see Blalock , 1967 ; Kanter 1977 ; Stainback , Ratliff , & Rosigno 2011 ) in the of ﬂ ine environment may beleading to increasedperceptual opportunities for Latinos and increased perceived threat to “ white ” power structures that moti - vated offenders act upon . Put differently , given the largest perceived numerical minority group threat in the U . S . are Latinos , Asian assimilation behaviors and online socialization patterns may shield them from hateful material whereas the numerical ( and arguably cultural , economic , political ) threat some whites perceive from His - panicsclasheswithanypotentialassimilativeattempts . Furthermore , these perceived hateful encounters may not only be coming from whites , butotherracialandethnicgroupsaswell . Importantresearch to dissect these complex and important ﬁ ndings are under - way d futureresearchshouldexaminemorecloselythematerialsand experiencesrespondents ﬁ ndhatefulaswellastheperceptualclarity of the social status , group af ﬁ liation , and ideological tendencies of motivated offenders or groups of motivated offenders . 6 . Limitations Our study has several limitations . First , we limit our sample to 15 e 36 year olds . This group was targeted because of their vulner - ability to being exposed to hate materials ; however , this nonethe - less limits our sample . Second , we used demographically balanced panel data . Doing so allows for representative demographics of U . S . citizens , but panel participants may have characteristics that differentiate them from individuals who chose not to participate . Yet this argument could be made about participants and non - participants in any survey . While we do believe our sample is demographically representative of theoretically important groups , we cannot determine if other biases related to this sampling pro - cedure are present . However , we are con ﬁ dent , given the frequent use of panel data for studies such as ours , that our results are reliable , valid , and important . 7 . Conclusion By modifying RAT , we uncovered several factors leading to an increased likelihood of exposure to online hate materials . First , virtual proximity to extremist enclaves and participation in SNS increase exposure ; however , the means by which individuals come across hateful materials varies . For example , while Facebook is the most frequented site it was not a signi ﬁ cant source of exposure . This is likely due to the nature of feathering and ﬂ ocking behaviors within and across one ’ s respective SNS d different social networking sites will have a differential opportunity structure for exposure . Thus , while Facebook might be most frequented , varia - tion within an individual ’ s online community will lead one to and from hateful materials . One source of this variation would be the online community ’ s attitudes toward the government . We ﬁ nd that anti - government attitudes , which likely re ﬂ ect opposition to the current form of government or its administration , leads to increased exposure . Thus , socialization and cognitive processes shape one ’ s worldview , solidifying cognitive schema about issues and ideologies , thereby personalizing and narrowing one ’ s ﬁ eld of vision toward enclaves of extremism . We argue this process results from classic “ feathering ” and “ ﬂ ocking ” behaviors . Next , socio - demographic factors in ﬂ uence exposure rates . Self - selection away from sites by some groups such as Blacks and Asians may reduce exposure , and contextual factors for Hispanics and children of immigrants may increase exposure . These are complex but clear indicators leading to virtual spaces where perceptual opportunities and constraints for hate emerge or dissi - pate . Put differently , a political context in which conceptions of “ whiteness ” are challenged simultaneously as perceived threats to extant power structures occur may be leading to increased expo - sure for minority groups that currently pose the clearest “ threat . ” Moreover , life experiences ( having been a target of hate in one ’ s lifetime ) and increased awareness of what hate may look like ( increased educational opportunities ) also increased opportunities for the perception d a “ naming ” or “ identi ﬁ cation of ” d hateful material and content . Furthermore , these individual factors may contribute to variation in how one engages the Internet . In conclusion , we ﬁ nd virtual proximity , time , and socio - demographic factors ( particularly race / ethnicity ) to be key attri - butes leading to the hate exposure . Further research can be done to parse out the ways individuals come into virtual proximity with motivated offenders , how individual attributes intersect with online behaviors ( i . e . SNSuse ) , andwhytheearlystagesofInternetuseseem to be the most vulnerable for perceived hate material exposure . This study is important because it sheds light on understudied areas concerning exposure to hate materials and the individual character - istics and socio - political contexts in which such exposure occurs . Acknowledgements This project was supported by Award No . 2014 - ZA - BX - 0014 , awarded by the National Institute of Justice , Of ﬁ ce of Justice Pro - grams , U . S . Department of Justice ( Grant # 2014 - ZA - BX - 0014 ) . The opinions , ﬁ ndings , and conclusions or recommendations expressed in this publication / program / exhibition are those of the author ( s ) and do not necessarily re ﬂ ect those of the Department of Justice . M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 318 Appendix 1 References Akers , R . L . ( 1977 ) . Deviant behavior : A social learning approach . Amster , S . - E . ( 2009 ) . From birth of a nation to stormfront : a century of communi - cating hate . In B . Perry , B . Levin , P . Igansi , R . Blazak , & F . Lawrence ( Eds . ) , Hate crimes ( pp . 221 e 247 ) . Westport , CT : Greenwood Publishing Group . Blalock , H . M . ( 1967 ) . Toward a theory of minority - group relations . Wiley . Bonilla - Silva , E . ( 2001 ) . White supremacy and racism in the post - civil rights era . Boulder , CO : Lynne Rienner Publishers . Bonilla - Silva , E . ( 2014 ) . Racism without racists : Color - blind racism and the persistence of racial inequality in America ( 4th ed . ) . Lanham , MD : Rowman & Little ﬁ eld Publishers , Inc . Bossler , A . M . , & Holt , T . J . ( 2009 ) . On - line activities , guardianship , and malware infection : an examination of routine activities theory . International Journal of Cyber Criminology , 3 ( 1 ) , 400 e 420 . Bossler , A . M . , & Holt , T . J . ( 2010 ) . The effect of self - control on victimization in the cyberworld . Journal of Criminal Justice , 38 ( 3 ) , 227 e 236 . Bossler , A . M . , Holt , T . J . , & May , D . C . ( 2012 ) . Predicting online harassment : victimization among a Juvenile population . Youth & Society , 44 , 500 e 523 . Burris , V . , Smith , E . , & Strahm , A . ( 2000 ) . White supremacist networks on the Internet . Sociological Focus , 33 ( 2 ) , 215 e 235 . Cohen , L . E . , & Felson , M . ( 1979 ) . Social change and crime rate trends : a routine activity approach . American Sociological Review , 588 e 608 . Colvin , M . , Cullen , F . T . , & Vander Ven , T . ( 2002 ) . Coercion , social support , and crime : an emerging theoretical consensus . Criminology , 40 , 19 . Cowan , G . , & Mettrick , J . ( 2002 ) . The effects of target variables and settting on perceptions of hate speech1 . Journal of Applied Social Psychology , 32 ( 2 ) , 277 e 299 . Douglas , K . M . , McGarty , C . , Bliuc , A . M . , & Lala , G . ( 2005 ) . Understanding cyberhate social competition and social creativity in online white supremacist groups . Social Science Computer Review , 23 ( 1 ) , 68 e 76 . Eck , J . E . , & Clarke , R . V . ( 2003 ) . Classifying common Police problems : a routine activity theory approach . In Theory and practice in situational crime prevention . crime prevention studies , vol . 16 ( pp . 7 e 39 ) . Evans , J . R . , & Mathur , A . ( 2005 ) . The value of online surveys . Internet Research , 15 ( 2 ) , 195 e 219 . Fagan , A . A . , & Mazerolle , P . ( 2011 ) . Repeat offending and repeat victimization : assessing similarities and differences in psychosocial risk factors . Crime & De - linquency , 57 , 732 e 755 . Federal Bureau of Investigation . ( 2011a ) . Domestic terrorism : Focus on militia extremism . https : / / www . fbi . gov / news / stories / 2011 / september / militia _ 092211 . Federal Bureau of Investigation . ( 2011b ) . Sovereign citizens : A growing domestic threat to law enforcement . https : / / leb . fbi . gov / 2011 / september / sovereign - citizens - a - growing - domesticthreatto - law - enforcement . Finkelhor , D . , Ormrod , R . K . , & Turner , H . A . ( 2007 ) . Re - victimization patterns in a national longitudinal sample of children and youth . Child Abuse & Neglect , 31 ( 5 ) , 479 e 502 . Fleming , M . J . , Greentree , S . , Cocotti - Muller , D . , Elias , K . A . , & Morrison , S . ( 2006 ) . Safety in cyberspace adolescents ’ safety and exposure online . Youth & Society , 38 ( 2 ) , 135 e 154 . Foxman , A . H . , & Wolf , C . ( 2013 ) . Viral hate : Containing its spread on the Internet . Macmillan . Franklin , R . ( 2010 ) . The hate directory . http : / / www . hatedirectory . com / hatedir . pdf Accessed 10 . 07 . 14 . Freilich , J . , Belli , R . , & Chermak , S . ( 2011 ) . United States Extremist Crime Database ( ECDB ) 1990 - 2010 . http : / / www . start . umd . edu / research - projects / united - states - extremist - crime - database - ecdb - 1990 - 2010 . Gerstenfeld , P . B . , Grant , D . R . , & Chiang , C . P . ( 2003 ) . Hate online : a content analysis of extremist Internet sites . Analyses of Social Issues and Public Policy , 3 ( 1 ) , 29 e 44 . Glaser , J . , Dixit , J . , & Green , D . P . ( 2002 ) . Studying hate crime with the internet : what makes racists advocate racial violence ? Journal of Social Issues , 58 ( 1 ) , 177 e 193 . Hinduja , Sameer , & Patchin , Justin W . ( 1990 ) . A general theory of crime . Stanford University Press . Hawdon , J . ( 2012 ) . Applying differential association theory to online hate groups : a theoretical statement . Journal of Research on Finnish Society , 5 , 39 e 47 . Hawdon , J . , Oksanen , A . , & R € as € anen , P . ( 2014 ) . Victims of online hate groups : American youth ’ s exposure to online hate speech . In J . Hawdon , J . Ryan , & M . Lucht ( Eds . ) , The causes and consequences of group violence : From bullies to terrorists ( pp . 165 e 182 ) . Lanham , MD : Lexington Books . Helmus , T . C . , York , E . , & Chalk , P . ( 2013 ) . Promoting online voices for countering vi - olent extremism . Rand Corporation . Table A1 Logistic Regression Analysis of Exposure to Negative Material Online With Modi ﬁ ed Reference Variable for Race ( Odds Ratios and Standard Errors ) Model 1 Model 2 Model 3 O . R . Std . Err . O . R . Std . Err . O . R . Std . Err . Exposure to Hate Online Hours Online / Day 3 . 35 * 1 . 78 3 . 51 * * 1 . 90 3 . 03 * 1 . 68 Hours Online / Day 2 0 . 82 * 0 . 07 0 . 81 * 0 . 08 0 . 83 * 0 . 08 Use YouTube ¼ 1 1 . 96 * * 0 . 46 1 . 95 * * 0 . 47 1 . 98 * * 0 . 49 Use Facebook ¼ 1 0 . 89 0 . 23 0 . 89 0 . 23 0 . 86 0 . 23 Use Twitter ¼ 1 0 . 94 0 . 14 0 . 92 0 . 14 0 . 90 0 . 15 Use Photo - sharing ¼ 1 1 . 55 * * 0 . 25 1 . 51 * * 0 . 25 1 . 52 * * 0 . 26 Use Google þ ¼ 1 1 . 26 0 . 20 1 . 25 0 . 20 1 . 30 * 0 . 21 Use Tumblr ¼ 1 1 . 59 * * 0 . 30 1 . 59 * * 0 . 30 1 . 55 * 0 . 31 Trust Government 0 . 95 * 0 . 03 0 . 93 * 0 . 03 0 . 91 * * 0 . 03 Been Target of Online Hate ¼ 1 3 . 78 * * * 0 . 79 3 . 59 * * * 0 . 75 3 . 22 * * * 0 . 69 Close to Online Community 0 . 99 0 . 05 0 . 98 0 . 05 1 . 00 0 . 06 Risk Taking e e 1 . 03 0 . 03 1 . 04 0 . 03 Close to Friends e e 1 . 15 0 . 09 1 . 12 0 . 10 Close to Family e e 0 . 95 0 . 08 0 . 96 0 . 08 Female ¼ 1 e e e e 1 . 01 0 . 16 Age e e e e 0 . 96 * * 0 . 02 White ¼ 1 e e e e 1 . 31 0 . 28 Asian ¼ 1 e e e e 0 . 69 0 . 22 Hispanic ¼ 1 e e e e 1 . 97 * 0 . 64 Parent ( s ) Born Outside U . S . ¼ 1 e e e e 1 . 57 * * 0 . 29 South ¼ 1 e e e e 1 . 16 0 . 23 West ¼ 1 e e e e 0 . 99 0 . 22 Northeast ¼ 1 e e e e 1 . 03 0 . 22 Education e e e e 1 . 34 * * * 0 . 11 Unemployed ¼ 1 e e e e 0 . 64 * * 0 . 12 Living Alone ¼ 1 e e e e 0 . 54 * * 0 . 12 LR X 2 101 . 70 104 . 69 147 . 89 Log Pseudolikelihood (cid:2) 581 . 90 (cid:2) 575 . 77 (cid:2) 549 . 66 N 993 985 979 * p < 0 . 05 ; * * p < 0 . 01 ; * * * p < 0 . 001 ( two - tailed tests ) . M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 319 Helweg - Larsen , K . , Schütt , N . , & Larsen , H . B . ( 2012 ) . Predictors and protective factors for adolescent Internet victimization : results from a 2008 nationwide Danish youth survey . Acta Paediatrica , 101 ( 5 ) , 533 e 539 . Henson , B . , Wilcox , P . , Reyns , B . W . , & Cullen , F . T . ( 2010 ) . Gender , adolescent life - styles , and violent victimization : implications for routine activity theory . Vic - tims & Offenders , 5 ( 4 ) , 303 e 328 . Sameer , Hinduja , Justin , W . , & Patchin . ( 2008 ) . Cyberbullying : An exploratory analysis of factors related to offending and victimization . Deviant Behavior , 29 ( 2 ) , 129 e 156 . Holtfreter , K . , Reisig , M . D . , Leeper Piquero , N . , & Piquero , A . R . ( 2010 ) . Low self - control and fraud offending , victimization , and their overlap . Criminal Justice and Behavior , 37 ( 2 ) , 188 e 203 . Holtfreter , K . , Reisig , M . D . , & Pratt , T . C . ( 2008 ) . Low self - control , routine activities , and fraud victimization . Criminology , 46 ( 1 ) , 189 e 220 . Hussain , G . , & Saltman , E . M . ( 2014 ) . Jihad trending : A comprehensive analysis of online extremism and how to counter it . London : Quilliam . Jennings , W . G . , Piquero , A . R . , & Reingle , J . M . ( 2012 ) . On the overlap between victimization and offending : a review of the literature . Aggression and Violent Behavior , 17 , 16 e 26 . Kanter , R . M . ( 1977 ) . Men and women of the corporation . Basic Books . Levin , B . ( 2015 ) . The original web of hate revolution Muslim and American homegrown extremists . American Behavioral Scientist , 0002764215588815 . Lwin , May O . , Stanaland , Andrea JS , & Miyazaki , Anthony D . ( 2008 ) . Protecting children ' s privacy online : How parental mediation strategies affect website safeguard effectiveness . Journal of Retailing , 84 ( 2 ) , 205 e 217 . Marcum , Catherine D . , Higgins , George E . , & Ricketts , Melissa L . ( 2010a ) . Potential factors of online victimization of youth : An examination of adolescent online behaviors utilizing routine activity theory . Deviant Behavior , 31 ( 5 ) , 381 e 410 . Marcum , Catherine D . , Higgins , George E . , & Ricketts , Melissa ( 2010b ) . Assessing sex experiences of online victimization : An examination of adolescent online be - haviors using routine activity theory . Criminal Justice Review . McNamee , L . G . , Peterson , B . L . , & Pe ~ na , J . ( 2010 ) . A call to educate , participate , invoke and indict : understanding the communication of online hate groups . Communication Monographs , 77 ( 2 ) , 257 e 280 . Miethe , T . D . , & Meier , R . F . ( 1990 ) . Opportunity , choice , and criminal victimization : a test of a theoretical model . Journal of Research in Crime and Delinquency , 27 ( 3 ) , 243 e 266 . N € asi , M . , R € as € anen , P . , Hawdon , J . , Holkeri , E . , & Oksanen , A . ( 2015 ) . Exposure to online hate material and social trust among Finnish youth . Information , Tech - nology and People , 28 ( 3 ) , 607 e 622 . Neumann , P . R . ( 2013 ) . Options and strategies for countering online radicalization in the United States . Studies in Con ﬂ ict & Terrorism , 36 ( 6 ) , 431 e 459 . Ngo , F . , & Paternoster , R . ( 2011 ) . Cybercrime victimization : an examination of in - dividual and situational level factors . International Journal of Cyber Criminology , 5 , 773 e 793 . Oksanen , A . , Hawdon , J . , Holkeri , E . , N € asi , M . , & R € as € anen , P . ( 2014 ) . Exposure to online hate among young social media users . In Soul of society : A focus on the lives of children & youth ( Sociological Studies of Children & Youth , volume 18 ) ( pp . 253 e 273 ) . Onuoha , F . C . ( 2014 ) . Why do youth join Boko Haram ? . Special Report . Washington , DC : US Institute for Peace . Pariser , E . ( 2011 ) . The ﬁ lter bubble : What the Internet is hiding from you . Penguin UK . Perry , B . ( 2000 ) . “ Button - Down terror ” : the metamorphosis of the hate movement . Sociological Focus , 33 ( 2 ) , 113 e 131 . Potok , M . ( 2015 ) . The year in hate & extremism , 2010 . Intelligence report , 141 . https : / / www . splcenter . org / ﬁ ghting - hate / intelligence - report / 2015 / year - hate - and - extremism - 0 . Pratt , T . C . , Holtfreter , K . , & Reisig , M . D . ( 2010 ) . Routine online activity and internet fraud targeting : extending the generality of routine activity theory . Journal of Research in Crime and Delinquency , 47 ( 3 ) , 267 e 296 . R € as € anen , P . , Hawdon , James , Holkeri , E . , N € asi , M . , Keipi , T . , & Oksanen , A . ( 2015 ) . Targets of Online Hate : Examining Determinants of Victimization among Young Finnish Facebook Users . Violence and Victims . Forthcoming . Ratliff , T . N . , Hawdon , J . , Middleton , J . , Tan , A . , & Snow , D . ( 2015 ) . Domestic extremism in the U . S . 1960 e 2015 . In Presented at the Annual Academy of Criminal Justice Sciences Meeting , March 4 . Orlando : FL . Regular Session . Reyns , B . W . ( 2013 ) . Online routines and identity theft victimization further expanding routine activity theory beyond direct - contact offenses . Journal of Research in Crime and Delinquency , 50 ( 2 ) , 216 e 238 . Reyns , B . W . , Burek , M . W . , Henson , B . , & Fisher , B . S . ( 2013 ) . The unintended con - sequences of digital technology : exploring the relationship between sexting and cybervictimization . Journal of Crime and Justice , 36 ( 1 ) , 1 e 17 . Reyns , B . W . , Henson , B . , & Fisher , B . S . ( 2011 ) . Being pursued online applying cyberlifestyle e routine activities theory to cyberstalking victimization . Criminal Justice and Behavior , 38 ( 11 ) , 1149 e 1169 . Reyns , B . W . , Henson , B . , & Fisher , B . S . ( 2014 ) . Digital deviance : low self - control and opportunity as explanations of sexting among college students . Sociological Spectrum , 34 ( 3 ) , 273 e 292 . Schreck , C . ( 1999 ) . “ Criminal victimization and low self - control : an extension and test of a general theory of crime . Justice Quarterly , 16 , 633 e 654 . Schreck , C . , Wright , R . , & Mitchell Miller , J . ( 2002 ) . A study of individual and situ - ational antecedents of violent victimization . Justice Quarterly , 19 , 159 e 180 . Stainback , K . , Ratliff , T . N . , & Rosigno , V . J . ( 2011 ) . “ The context of workplace sex discrimination : sex composition , workplace culture and relative power . Social Forces , 89 ( 4 ) , 1165 e 1188 . Subrahmanyam , K . , & (cid:2) Smahel , D . ( 2011 ) . Constructing identity online : identity exploration and self - presentation . In Digital youth ( pp . 59 e 80 ) . Springer New York . The New America Foundation International Security Program . ( 2015 ) . Homegrown extremists . http : / / securitydata . newamerica . net / extremists / deadly - attacks . html . The White House . ( 2015 ) . FACT SHEET : The White House Summit on countering violent extremism . https : / / www . whitehouse . gov / the - press - of ﬁ ce / 2015 / 02 / 18 / fact - sheet - white - house - summit - countering - violent - extremism . Tillyer , M . S . , & Eck , J . E . ( 2009 ) . Routine activities . In 21st century criminology : A reference handbook ( pp . 279 e 287 ) . Torok , R . ( 2016 ) . Social media and the use of discursive markers of online extremism and recruitment . In M . Jhader , L . Seng Neo , G . Ong , E . Tan Mingyi , & J . Chin ( Eds . ) , Combating violent extremism and radicalization in the digital era ( pp . 39 e 69 ) . IGI Global . Tynes , B . ( 2006 ) . Children , adolescents , and the culture of hate online . In N . Dowd , D . Singer , & R . F . Wilson ( Eds . ) , Handbook of children , culture , and violence ( pp . 267 e 289 ) . New York : Sage . Tynes , B . , Reynolds , L . , & Green ﬁ eld , P . ( 2004 ) . Adolescence , race and ethnicity on the internet : a comparison of discourse in monitored and unmonitored chat rooms . Journal of Applied Developmental Psychology , 25 , 667 e 684 . Waldron , J . ( 2012 ) . The harm in hate speech . Harvard University Press . Wall , D . ( 2001 ) . Crime and the Internet . New York : Routledge . Wansink , B . ( 2001 ) . Editorial : the power of panels . Journal of Database Marketing & Customer Strategy Management , 8 ( 3 ) , 190 e 194 . van Wilsem , J . ( 2013a ) . Bought it , but never got it : assessing risk factors for online consumer fraud victimization . European Sociological Review , 29 , 168 e 178 . van Wilsem , J . ( 2013b ) . Hacking and harassment : do they have something in common ? Comparing risk factors for online victimization . Journal of Contem - porary Criminal Justice , 29 , 437 e 453 . Yancey , G . ( 2003 ) . Who is white ? Latinos , Asians , and the new black / nonblack divide . Boulder , CO : Lynne Rienner Publishers . Yar , M . ( 2005 ) . The novelty of ‘ cybercrime ’ an assessment in light of routine activity theory . European Journal of Criminology , 2 ( 4 ) , 407 e 427 . Yar , M . ( 2013 ) . Cybercrime and society . London : Sage . M . Costello et al . / Computers in Human Behavior 63 ( 2016 ) 311 e 320 320