Machine Learning practices and infrastructures Glen Berman glen . berman @ anu . edu . au Australian National University Canberra , ACT , Australia ABSTRACT Machine Learning ( ML ) systems , particularly when deployed in high - stakes domains , are deeply consequential . They can exacer - bate existing inequities , create new modes of discrimination , and reify outdated social constructs . Accordingly , the social context ( i . e . organisations , teams , cultures ) in which ML systems are developed is a site of active research for the field of AI ethics , and interven - tion for policymakers . This paper focuses on one aspect of social context that is often overlooked : interactions between practitioners and the tools they rely on , and the role these interactions play in shaping ML practices and the development of ML systems . In par - ticular , through an empirical study of questions asked on the Stack Exchange forums , the use of interactive computing platforms ( e . g . Jupyter Notebook and Google Colab ) in ML practices is explored . I find that interactive computing platforms are used in a host of learn - ing and coordination practices , which constitutes an infrastructural relationship between interactive computing platforms and ML prac - titioners . I describe how ML practices are co - evolving alongside the development of interactive computing platforms , and highlight how this risks making invisible aspects of the ML life cycle that AI ethics researchersâ€™ have demonstrated to be particularly salient for the societal impact of deployed ML systems . CCS CONCEPTS â€¢ Computing methodologies â†’ Machine learning ; â€¢ Social and professional topics â†’ Socio - technical systems ; History of software . KEYWORDS machine learning , infrastructure studies , social practice ACM Reference Format : Glen Berman . 2023 . Machine Learning practices and infrastructures . In Proceedings of the AAI / ACM Conference on Artificial Intelligence , Ethics , and Society , August 08 â€“ 10 , 2023 , Montreal , QC . ACM , New York , NY , USA , 16 pages . https : / / doi . org / XXXXXXX . XXXXXXX 1 INTRODUCTION It follows from the notion that Machine Learning ( ML ) systems ought to be thought of as sociotechnical systems [ 122 ] â€”i . e . systems that are socially constructed , requiring both human actors and ma - chines to work [ 36 ] â€”that the social context in which an ML system Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . AIES â€™23 , August , 2023 , Montreal , QC , Canada Â© 2023 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - XXXX - X / 18 / 06 . . . $ 15 . 00 https : / / doi . org / XXXXXXX . XXXXXXX is researched , developed , and deployed is likely to shape the char - acteristics of that system . Given the increasing rate of ML system deployment in high - stakes domains , and widespread evidence of ML systems failing to meet societal expectations [ e . g . 25 , 69 , 94 , 123 ] , a key question for the ML field relates to infrastructuralisation and its implications for ML practices and deployed ML systems . This paper begins to address this question by attending to one aspect of social contextâ€”interactions between ML practitioners and the tools they use to research , build , and deploy ML systemsâ€”and demon - strating the relevance of this context to concerns raised by AI ethics researchers . The social context of ML system development has been studied in the emerging AI ethics field [ e . g . 15 , 33 , 55 , 80 ] . However , relatively little attention has been paid to tracing the relationship between specific material features of this context and the characteristics of ML systems that are developed [ 72 ] . That is , the role of mate - rial things ( e . g . software tools , office layouts , computer interfaces , network connections ) , which themselves are socially constructed , alongside social things ( e . g . people , beliefs , norms ) in shaping ML systems merits closer scrutiny . In this paper , I consider one aspect of this sociomaterial context of ML system development : the use of interactive computing platforms ( e . g . Jupyter Notebooks and Google Colaboratory ) during ML model development and evalu - ation . I explore the structure of these platforms and their use by ML practitioners , and consider the ways in which this use may contribute to conventions of ML practices . This exploration serves to illustrate the importance for the AI ethics field of attending both to the sociomaterial context of ML system development generally , and to the role of interactive computing platforms , in particular . The research question to which this exploration is addressed is : how are interactive computing platforms used in ML practices ? To answer this question I developed a probabilistic topic model of user - contributed questions on the Stack Exchange forums re - lated to ML and the use of interactive computing platforms . Stack Exchange forums were selected due to their wide use by data and computer scientists , software engineers , and technologists gener - ally [ 6 , 10 ] . Alongside this I undertook qualitative text analysis of a small sample of Stack Exchange questions . I find that interactive computing platforms are used in a range of ML practices , particu - larly in the data curation and processing , and model training and evaluation stages of ML system development . I highlight the role of interactive computing platforms in learning practices , and in practices of coordination across multiple infrastructures . To inter - pret these findings I draw on sociological studies of infrastructures and practices , particularly the work of sociologists Susan Leigh Star [ 20 , 129 â€“ 131 ] and Elizabeth Shove [ 124 , 125 , 145 ] , and cultural anthropologist Brian Larkin [ 73 , 74 ] . I conclude that learning and coordination roles are indicative of an infrastructural relationship between ML practitioners and interactive computing platforms , a r X i v : 2307 . 06518v2 [ c s . C Y ] 25 J u l 2023 AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman which renders some of the aspects of ML systems development that AI ethics discourse has highlighted as particularly consequen - tial ( e . g . the importance of training dataset provenance [ 32 , 40 ] ) as invisible to ML practitioners . As such , this paper contributes an empirical snapshot of the use of interactive computing platforms in ML practices , and argues for a renewed focus in the field of AI ethics on the emergence of digital platform infrastructures in the ML ecosystem . 2 RELATED WORK 2 . 1 The sociomaterial context of Machine Learning practices As ML systems have become objects of sociological interest [ e . g . 26 , 35 , 67 , 83 ] , the social context in which ML systems are re - searched , developed , commissioned , and deployed has garnered increased attention in diverse fields from Human - Computer Inter - action [ 54 , 84 ] , to Science and Technology Studies [ 28 ] , to public policy [ 71 ] . In this paper , I refer to sociomaterial context rather than social context to signal a particular focus on the intertwining of socially - constructed material thingsâ€”specifically , interactive com - puting platformsâ€”in ML practices . As Paul Leonardi et al . [ 76 â€“ 78 ] have argued , a sociomaterial perspective highlights how the ma - terial is socially constructed , and the social is enacted through ma - terial forms . A sociomaterial perspective invites us to consider the material things that ML practitioners enrol in their day - to - day work , alongside other aspects of the social context , and the contribution of these things to the stablisation of ML practices . In this context , ma - terial refers to the â€œproperties of a technological artifact that do not change , by themselves , across differences in time and contextâ€ [ 78 , p . 7 ] â€”for interactive computing platforms , and software generally , this includes their user interfaces and layouts , their core capabili - ties , and their dependencies [ 110 ] . My understanding of practices is informed by social practice theory [ 18 , 116 , 128 ] , which conceptu - alises practices as routinised ways of understanding and performing social activities [ 58 ] , and highlights that multiple practices can co - exist within the same cultural setting [ 116 , p . 646 ] . Machine Learning practices are thus the constitutive matter of â€˜doingâ€™ ML . Some prac - tices ( e . g . Agile meeting processes ) may be widely shared across cultures and organisations , and others ( e . g . the use of specific soft - ware ) may vary dramatically from practitioner to practitioner . In the field of AI ethics , a sociomaterial perspective has been used to highlight the challenges of translating AI ethics research into ML practices . Michael Veale and Reuben Binns [ 140 ] , for instance , studied how statistical measures of fairness can be implemented within the practical constraints of limited access to data on pro - tected characteristics , finding that new institutional arrangements will be necessary to support industry implementation of statistical measures of fairness that depend on access to sensitive data [ cf . 16 , 17 ] . Veale and Binns argue for future empirical research on the â€œmessy , contextually - embedded and necessarily sociotechni - calâ€ challenge of building â€˜fairerâ€™ ML systems [ 140 , p . 13 ] . Veale et al . [ 141 ] subsequently conducted an empirical study of ML practi - tioners in public sector organisations and their engagement with ethics issues during ML system development for high - stakes deci - sion making , finding that while practitioners have a high degree of awareness regarding ethical issues , they lack the necessary tools and organisational support to use this awareness in their ML prac - tices . Mona Sloane and Janina Zakrzewski [ 128 ] , who also situate their work within social practice theory , provide a more expanded overview of AI ethics practices , through an empirical study of the operationalisation of ethics in German AI startups . Sloane and Za - krzewski develop an anatomy of AI ethics practices , which they suggest can be used as a framework to inform improvements to ML system development practices . Relevantly , the anatomy includes â€˜ethics materialsâ€™ , defined as â€œconcrete objects , processes , roles , tools or infrastructures focused on â€˜AI ethicsâ€â€™ [ 128 , p . 5 ] . Holstein et al . [ 54 ] provide further support for the importance of ethics materials , through their empirical study of ML practitioners working in prod - uct teams in large technology firms to develop â€˜fairerâ€™ ML systems , which found that practitioners lack the tools needed to identify and address ethics issues that arise during ML system development . Finally , Will Orr and Jenny Davis [ 96 ] highlight how ML practices include the diffusion of responsibility for ethics during ML system development . Orr and Davis found a â€œpattern of ethical dispersionâ€ amongst practitioners : practitioners perceive themselves to be the inheritors of ethical parameters from more powerful actors ( regula - tors , clients , employers ) , which their expertise translates into the characteristics of systems they develop , which are then handed over to users and clients , who assume ongoing responsibility [ 96 , p . 7 ] . These studies , along with other empirical explorations of ML prac - tice [ e . g . 55 , 64 , 71 , 108 , 119 , 139 ] and several workshops focused on the research - to - practice gap [ 9 , 12 , 133 ] , have prompted calls for better support for practitioners attempting to operationalise AI ethics principles in their ML practices [ 88 , 120 , 121 ] . This study complements and inverts these empirical studies of AI ethics in ML practices . Rather than moving from the social to the sociomaterial , this study moves from the material to the sociomaterial . That is , rather than starting with interviews [ e . g . 54 , 55 , 96 , 108 , 119 , 128 , 141 ] or surveys [ e . g . 71 , 139 ] of practition - ers to explore their understanding and operationalisation of AI ethics in ML practices , the study begins with material artefacts that practitioners use and produce in the course of their ML practices , and explores what light these artefacts may shed on the translation of AI ethics to ML practices . A similar approach is followed by Max Langenkamp and Daniel Yue [ 72 ] in their study of open source ML software use , which consists of a review of code repositories on GitHub to establish the breadth of open source use followed by interviews with practitioners to provide further context . That study takes a broad perspective , exploring trends across open source software use . In contrast , this study takes a narrow perspective , exploring how a specific category of software tool is used in ML practices . 2 . 2 Interactive computing platforms and Machine Learning practices The specific material artefacts this study starts with are interactive computing platforms ( ICPs ) , also referred to as â€˜computational note - booksâ€™ [ 27 , 118 ] , â€˜literate programming toolsâ€™ [ 100 ] or â€˜integrated development environmentsâ€™ [ 150 ] . Two widely used ICPs are the Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada open - source Jupyter Notebook and Google Colab , Googleâ€™s exten - sion of Jupyter Notebook , designed to integrate with other Google services . 1 Figure 1 shows an example Jupyter Notebook . Figure 1 : A screenshot of a Google Colab notebook main - tained by PyTorch as part of their onboarding documenta - tion . The notebook can be accessed at : https : / / pytorch . org / tutorials / beginner / basics / buildmodel _ tutorial . html . The numbered grey cells are code cells . Immediately above each code cell is a natural language cell , which contains explanatory text . Immediately below each code cell is the output from running the cellâ€™s code . Technically , an ICP is an interactive shell for a programming language , such as Python [ 98 ] . The shell enables users to write and interact with code fragmentsâ€”called â€˜cellsâ€™â€”alongside natural language , and to assemble series of cells into a notebook , which can be shared with othersâ€”much in the same way that a word processor enables a user to assemble an editable document and share that with others . The notebook can be thought of as a computational narrative , which enables one to read and interact with a sequence of code alongside a narrative description of what the code does [ 68 ] â€”hence , the terms â€˜literate programming toolsâ€™ and â€˜compu - tational notebooksâ€™ . However , crucially , an ICP presents itself as only a shell : all but the most rudimentary code fragments depend on access to libraries of existing code , which a user must import into the shell environment . Similarly , particularly in the context of ML , data must be imported into the shell for the code to operate on and a compute resource must be accessed to process operations . Numerous digital infrastructures support importing code into a notebook , including the code repository GitHub , 2 in which many repositories include a notebook to demonstrate common use cases of the code [ 118 ] , PyPi , 3 which indexes and hosts Python - based code packages , and HuggingFace , 4 which indexes and hosts ML training and evaluation datasets and models . In this study , inter - active computing platform is thus preferred , as the infrastructural implications of â€˜platformâ€™ are a critical aspect of what defines these 1 Available at https : / / jupyter . org / and https : / / research . google . com / colaboratory / . 2 See https : / / github . com / . 3 See https : / / pypi . org / . 4 See https : / / huggingface . co / . tools : ICPs are highly networked arrangements , one part of a cir - cular web of infrastructures and inter - dependencies ( the Internet , cloud computing , programming languages and libraries ) . Interactive computing platforms pre - date the widespread adop - tion of ML techniques in applied settings . Indeed , their motivating design goal was to support reproducible science [ 45 , 68 , 98 ] ( see , e . g . [ 13 , 109 ] for discussions of their effectiveness at meeting this goal ) . However , as ML techniques have become ubiquitous , and data scientists have become widespread in industry , interactive computing platforms have become widely enrolled in ML practices . Commentators thus describe ICPs as the â€œtool of choiceâ€ for data scientists [ 99 ] , and practitioners vigorously debate the merits and drawbacks of using ICPs in applied settings [ e . g . 21 , 48 , 56 , 90 , 138 ] . Interactive computing platforms have also become objects of study in several fields adjacent to AI ethics . Human - Computer Interaction studies have developed empirical accounts of the way users interact with ICPs , focusing particularly on the role of ICPs in collaborations [ 143 , 150 ] and in data science [ 65 , 118 ] . Of particular relevance , Adam Rule et al . [ 118 ] conducted three studies of the use of ICPs by data scientists , which included a large - scale review of notebooks on GitHub and interviews with data scientists and found that ICPs tend to be used by data scientists during data exploration phases of a project , rather than for constructing and sharing detailed explanations of data analysis . Studies in the field of Software Engineering have also focused on documenting the use of ICPs , focusing particularly on ICPs as a site to study trends in code use [ 144 ] and reuse [ 70 , 100 ] , and on the their potential as educational tools [ 135 ] . Similarly , in the field of Computational Science , several studies have considered the role ICPs can play in supporting reproducible science [ 13 , 24 , 63 ] . This study provides a different perspective on ICP use , by considering ML practices in particular , and interpreting these practices through the lens of sociological studies of infrastructure , which shifts the focus of the study away from the individual user - notebook relationship and towards the broader relationship of ML practitioners to the suite of infrastructures involved in ML practices . 3 STUDYING INFRASTRUCTURES & PRACTICES Studying the relationship between practices and infrastructures can be vexed . Infrastructures may be functionally invisible to the social groups who make use of them in daily practices [ 130 ] , as I consider further in Section 6 . 2 . Further , infrastructures often span multiple practices across different social groups , which , particularly in the context of digital infrastructures , may not be geographically proxi - mate [ 19 ] . And , practices themselves are not purely infrastructuralâ€” as Shove et al . [ 126 ] argue , they bring together infrastructures and other materials , competencies , and ways of knowing . Sociological studies of infrastructures have orientated them - selves around the broad aim of rendering infrastructures , and their sociopolitical commitments , visible [ 19 ] . Ethnographic methods â€“ historically , fieldwork and participant observation ; more recently , multi - site studies â€“ have been used to empirically document infras - tructures [ 127 ] . Star [ 130 ] , for instance , advocates studying mo - ments of breakdown in infrastructures , seeing these as instances where infrastructures become visible to social groups . Star [ 130 ] AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman also observes that infrastructures are often learned as part of group membership , directing attention to moments of transience in social groups ( discussed further in Section 6 . 1 ) . However , digital infrastruc - tures present particular challenges : one cannot physically access online communities , and the number of physical sites is at least as large as the user - base of the infrastructure [ 19 ] . 5 In this study , I build on Starâ€™s insights by focusing , as a path towards understanding ICPs and their relationship to ML practices , on moments where ML practitioners are either experiencing ICP breakdowns or limitations in their own ICP capabilities . In partic - ular , and reflecting the challenge of direct observation of digital infrastructure use , the primary data source used are the questions asked by ML practitioners on popular online forums . This is supple - mented with analysis of ICP affordances and inter - dependencies . This approach follows in the spirit of other studies of digital infras - tructure , such as Plantin et al . â€™s [ 102 ] analysis of the documentation and inter - dependencies of the Figshare platform and Andre Brockâ€™s [ 22 ] analysis of Black Twitter through analysis of Twitter interfaces and user generated content , although the study presented here is narrower in scope . 4 METHOD This study consisted of an empirical study of user - generated con - tent on the Stack Exchange forums , supported by a close reading of a small number of exemplars texts [ 61 ] . In particular , a Struc - tured Topic Model ( STM ) [ 111 â€“ 114 ] of user - generated questions about ML and the use of interactive computing platforms on Stack Exchange forums was estimated . 6 A similar approach has been used in a number of studies of Stack Exchange forums [ 2 ] , for in - stance to identify challenges practitioners face in developing ML systems more generally [ 3 ] or themes in questions asked by mobile application developers [ 115 ] or themes in privacy - related [ 134 ] or security - related questions [ 149 ] . 7 4 . 1 Corpus development and description English - language Stack Exchange community forums , specifically Stack Overflow , Cross Validated , Data Science , Computer Science , and Software Engineering were mined for relevant questions . Stack Exchange claims to be the worldâ€™s largest programming commu - nity . 8 As of October 2022 , its most popular forum , Stack Overflow , had over 19 million registered users , who contribute , edit , and moderate questions and answers on the forum . 9 Previous research 5 Although outside the scope of this paper , an additional emerging challenge is auto - mated personalisation of digital infrastructures , which makes obtaining a general view of the infrastructure challenging [ 137 ] . ICPs do not currently afford personalisation in this way . 6 See [ 59 , 82 , 87 , 93 ] for overviews of topic modelling in the social sciences , and [ 11 , 23 ] for more critical perspectives . 7 Code to reproduce pre - processing steps and the topic model described below , are available at https : / / github . com / gberman - aus / aies _ 23 _ topic _ modelling . 8 See https : / / stackexchange . com / to access Stack Exchange and its forums . Stack Over - flow is broadly focused on computer programming . Cross Validated is a more spe - cialised forum , focused on statistics and data analysis . Software Engineering is a similarly specialised forum , focused on software systems development . Finally , Data Science and Computer Science are relatively small forums , focused on data and com - puter science respectively . However , reflecting the ubiquity of ML techniques in com - puting , questions related to ML occur in all of these forums , and , as all of these forums are user - moderated , their boundaries and scope are dynamic . 9 This estimate is based on a query of the Stack Exchange Data Dump . See [ 8 , 10 ] for studies of Stack Overflow usage . demonstrates that Stack Overflow is enmeshed in software engi - neering and data science practices [ e . g . 1 , 5 , 8 , 38 , 91 , 136 ] , and that ML techniques are a rapidly growing topic of discussion on the forum [ 3 ] . The Stack Exchange forums share data structures 10 and interface layouts , with annoymised user questions , answers , and comments from all Stack Exchange forum made available for querying and research through the Stack Exchange Data Dump [ e . g . 3 , 115 , 149 ] . 11 Questions related to ML and interactive computing platforms were extracted from the Stack Exchange forums listed above on 23 November , 2022 . Four example questions are shown in Figure 2 . To identify relevant questions the topical tags associated with every question were leveraged . Through manual review of the forums , and queries of the Stack Exchange Data Dump , 10 ICP tags and 32 ML related tags were identified . 12 These tags are listed in Appendix A . Having identified relevant ML and ICP tags , two datasets were extracted from the Stack Exchange Data Dump : all questions on the selected forums with at least one ML related tag ( a large dataset consisting of 485 , 053 questions ) , and all questions on these forum with at least one ICP related tag ( a smaller dataset of 75 , 639 questions ) . The ML tagged questions were filtered by the presence of an ICP term ( leaving 36 , 940 questions ) , and ICP tagged questions were filtered by ML terms ( leaving 9 , 634 questions ) . This procedure resulted in two datasets with some substantial overlap . After de - duplication , a final dataset of 21 , 555 ML and ICP related questions was left ; this dataset became the corpus used to estimate a STM topic model . . 13 4 . 2 Estimation of the topic model STM is a probabilistic , mixed - membership topic model , which ex - tends the widely - used Latent Dirichlet Allocation model by en - abling the inclusion of metadataâ€”here , the tags associated with questions and question creation dateâ€”in the model training process ( see [ 82 , 114 ] for introductions to STM ) . To prepare the corpus for topic modelling , pre - processing was undertaken using the ğ‘ ğ‘¡ğ‘š R package [ 112 ] ( see [ 46 , 147 ] for discussion of pre - processing proce - dures ) . Title and body fields for questions were concatenated into a single column . Questions on Stack Exchange forums are formatted using markdown , and often include large snippets of computer code . All code snippets and markdown were removed from questions . Code snippets were retained for subsequent analysis . Html sym - bols ( e . g . â€˜ & quot ; â€™ ) , special characters ( e . g . â€˜ & # 39 ; â€™ ) , punctuation , and superfluous white spaces were removed from questions . Ques - tions were converted to lowercase . Frequently occurring words with little topic predictive value ( â€™stopwordsâ€™ ) were removed from questions . Words in the questions were stemmed ( i . e . converted to 10 A detailed description of the database schema used across forums is provided by Stack Exchange on their forum about the Stack Exchange network , appropriately named Meta Stack Exchange , accessible at https : / / meta . stackexchange . com / questions / 2677 / database - schema - documentation - for - the - public - data - dump - and - sede . 11 The Stack Exchange Data Dump can be accessed at : https : / / archive . org / details / stackexchange . The database is updated weekly . 12 In studies of more niche topics only one tag has been used [ 134 ] , however , as in [ 3 ] , manual review demonstrated that there are no over - arching ML or ICP tags . 13 A significant advantage of the ğ‘ ğ‘¡ğ‘š R package relied upon is that it enables manual setting of the random seeds used during the model training processâ€”ensuring a higher degree of reproducability is possible . Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada ( a ) Topics : 13 ( 28 . 1 % ) , 5 ( 24 . 5 % ) , and 23 ( 13 . 3 % ) . The infras - tructure and inter - dependencies cluster . ( b ) Topics : 19 ( 15 . 6 % ) , 21 ( 11 . 2 % ) , and 16 ( 10 . 3 % ) . The data manipulation cluster . ( c ) Topics : 25 ( 48 . 2 % ) , 4 ( 9 . 6 % ) , and 8 ( 7 . 3 % ) . The model training cluster . ( d ) Topics : 13 ( 44 . 2 % ) , 5 ( 31 . 4 % ) , and 12 ( 6 . 6 % ) . The infras - tructure and inter - dependencies cluster . Figure 2 : Screenshots of four highly viewed questions on the Stack Overflow forum . The top three topics identified by the topic model and the cluster are reported in the caption of each image . their root form ) . The creation date of questions was converted into a numerical format . STM requires the researcher to set the number of latent topics ( ğ‘˜ ) to identify in a corpus . As such , selecting the optimal value for ğ‘˜ is an important decision , and requires testing a wide range of values [ 47 ] . Additional hyper - parameters can also be optimised , and different pre - processing regimes can also be tested against each other [ 46 , 85 ] . Given the preliminary nature of the study , ğ‘˜ values from 10 to 60 , at intervals of 5 were experimented with . The ğ‘ ğ‘¡ğ‘š packageâ€™s built in multi - model testing feature was used : for each value of ğ‘˜ , up to 50 model runs , with a maximum of 100 iterations each , were tested to ensure model stability . To select an optimal value of ğ‘˜ two evaluation metrics were used : exclusivity and semantic coherence [ 114 ] . Exclusivity is a measure of the difference in key words associated with each topic , whilst semantic coherence is a measure of how internally consistent each topicâ€™s key words are [ 147 ] . These measures tend to pull in oppo - site directions : exclusivity is likely to be optimised by increasing the number of topics , whilst semantic coherence can be optimised by decreasing the number of topics [ 114 ] . An optimal number of topics for social science research can be found by plotting exclu - sivity against semantic coherence for a range of ğ‘˜ values , and then choosing a value at which neither measure dominates [ 114 ] . How - ever , there is no â€˜rightâ€™ value for ğ‘˜ [ 107 ] ; the aim is to find a value of ğ‘˜ that enables meaningful interpretation [ 47 , 114 , 132 ] . In this instance , as can be seen in Figure 4 in the Appendix , models with ğ‘˜ values of around 25 represented an optimal trade off between exclusivity and semantic coherence . After inspection of keywords AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman associated with each topic and representative questions , the model with a ğ‘˜ value of 30 was selected . 4 . 3 Interpretation of the topic model To interpret the results of the topic model Yotam Ophir and Dror Walterâ€™s [ 95 , 142 ] three step process was followed . First , I qualita - tively interpreted the topics identified through review of the most probable words associated with each topic ( Figure 3a ) . Second , I analysed the relationships between topics by calculating their cor - relation , with a positive correlation indicating a high likelihood of two topics being found together in the one Stack Exchange question [ 111 , 112 ] . Third , I used a community detection algorithm to iden - tify clusters of topics and broader themes across the corpus ( Figure 3b ) . In particular , I used the Newman - Girvan method for commu - nity structure detection [ 92 ] , with the result being three clusters of topics . After review of the probable terms associated with topics within each cluster and representative questions , I labeled these clusters : infrastructure and inter - dependencies , data manipulation , and model training . As an additional final step , I made use of STMâ€™s ability to calculate the impact of covariates on topic prevalence to analyse the expected proportion of individual topics ( Figure 3c ) and clusters of topics over time ( Figure 3d ) . Throughout the above steps I moved between analysis of the topic model itself and deeper review of full Stack Exchange question and answer threads that are representative of particular topics or clusters of topics . Here , I adapted the approach of Paul DiMagg - gio , Manish Nag , and David Blei [ 34 ] , who , after training a topic model , identify topics of interest and then undertake analysis of the most representative texts for those topics . In particular , I identified the 10 Stack Exchange questions with the highest probability for each topic , and the 10 questions with the combined highest aver - age probability across topics within each cluster . For these highly representative questions , within each topic cluster I further sorted the questions by their view count on the Stack Exchange forums ( Figures 6 - 8 in the Appendix ) , enabling me to identify questions that were both highly representative of a given topic cluster and highly viewed on the Stack Exchange forum . 5 FINDINGS The topic model of Stack Exchange questions discussing interactive computing platforms and ML demonstrates that interactive com - puting platforms are implicated in a wide range of ML practices . ML practices are often conceptualised within a life cycle framework , with stages of ML development moving from problem formulation , to data curation and processing , to model training and evaluation , to model deployment and ongoing monitoring [ e . g . 7 , 75 , 88 , 105 , 106 ] . Figure 3a shows the most probable terms associated with each topic , and the expected proportion of each topic across the corpus . Unsur - prisingly , given the corpus focus on ICPs , the two topics most widely represented in the datasetâ€”13 and 5â€”are associated with Google Co - lab and Jupyter Notebook respectively . The most probable terms for most other topics are associated with many of the ML development stages , particularly data curation and processing ( e . g . see key terms for topics 28 , 4 , and 21 ) , and model training and evaluation ( e . g . see key terms for topics 19 , 11 , 7 , and 12 ) . The deeper review of identi - fied topics and representative questions highlights two inter - related themes , which address the studyâ€™s research question regrading use of ICPs in ML practices : the use of ICPs as learning laboratories ; and , their role as coordination hubs across ML infrastructures . 5 . 1 Learning laboratories for Machine Learning Interactive computing platforms serve as ML practice learning lab - oratories : they enable users to experiment with each otherâ€™s code and publicly - available datasets , learn how code functions through line - by - line interactions , and redeploy code in their own use cases . ICPs are thus part of the sociomaterial context for what Louise Amoore has described as the â€œ partial , iterative and experimental â€ nature of ML practices [ 4 ] , which is also reflected in Langenkamp and Yueâ€™s broader study of open source tools [ 72 ] . 14 Figure 1 shows an example of an ICP used as a learning labora - tory , drawn from a tutorial for PyTorch , an ML - focused high - level programming language . Figure 2b shows an example of a Stack Overflow question , titled â€˜ Keras , how do I predict after I trained a model ? â€ , which also reflects the use of an ICP as a learning labora - tory . This is one of the four most viewed questions from the data manipulation cluster of topics . The author of this question appears to be engaged in a learning practice : they describe themselves as â€œ playing with â€ the dataset , and write that they have â€œ read about â€ saving a trained model , but are now struggling to use the saved model in a prediction task . Not shown in Figure 2b are the com - munity answers the author received . 15 Each answer also includes a code snippet , demonstrating a solution . Similarly , the question â€œ FailedPreconditionError : Attempting to use uninitialized in Tensor - flow â€ ( Figure 2c ) , one of the most viewed questions in the model training cluster , includes a code snippet that is â€œ from the TensorFlow tutorial â€ , which the author is attempting to use with â€œ digit recogni - tion data from Kaggle â€ . In both these questions usersâ€™ learning is through an ICP , and is focused on understanding how to achieve a specific task using the Application Programming Interface ( API ) of a particular high - level programming library . When ML practitioners use interactive computing platforms as learning laboratories they engage in practices of code and data reuse . The author of the Stack Overflow question discussed above notes they are â€œ playing with the reuters - example dataset â€ , which is a publicly - available dataset used in topic modelling and text clas - sification tasks [ 79 ] , and provides a code snippet to illustrate the point at which they require assistance . Within ML practices reuse of publicly available datasets , such as the Reuters dataset for text classification or the ImageNet dataset for computer vision is well documented [ 32 ] . Patterns of dataset reuse can be found across the corpus : the Reuters dataset is referend in 11 questions ; ImageNet dataset is mentioned in 436 questions ; and , the MNIST handwrit - ten digits dataset is mentioned in 834 . Indirect evidence of code and data reuse in ML practices can also be found by reviewing the code snippets included in questions in the corpus . As discussed in Section 4 , during pre - processing code snippets were isolated from the text of questions on which the topic model was trained . 14 Foranextendeddescriptionoftherelationshipbetweenlearningpracticesanddigital infrastructures see [ 49 ] . 15 The full question , including community provided answers can be seen as : https : / / stackoverflow . com / questions / 37891954 / keras - how - do - i - predict - after - i - trained - a - model . Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada Of all questions , 89 . 7 % include a code snippet . Because the corpus consists of questions about using ICPs , many of these code snippets represent the point at which a user of an ICP has become stuck while trying to attempt to an ML related task . This is illustrated by the question titled â€œ How to load CSV file in Jupyter ? â€ , shown in Figure 2d . Here , the author of the question has included in the body of their question a screenshot of their Jupyter Notebook . As can be seen , the first cell in this notebook begins with the ğ‘–ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ function , which is how specific programming libraries or sub - libraries are im - ported into the ICP . In this case , the author has imported ğ‘›ğ‘¢ğ‘šğ‘ğ‘¦ , a mathematical functions library , and ğ‘ğ‘ğ‘›ğ‘‘ğ‘ğ‘  , a data analysis library . More broadly , the code snippets included in questions shed light on the substance of code that is entered into ICPs during ML related tasks . By calculating the frequency of the terms that immediately follow the ğ‘–ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ function , widely used programming libraries can be identified ( see Figure 5 in the Appendix ) . Among the 15 most frequently mentioned programming libraries in code snippets are : â€˜Sequentialâ€™ , â€˜Denseâ€™ , and â€˜Modelâ€™ ( specific components from Keras , a high - level library for deep learning ) ; â€™cv2â€™ ( a computer vision high - level library ) ; and , â€˜PyTorchâ€™ ( an alternative to TensorFlow ) . The code snippet in the question titled â€œ FailedPreconditionError : Attempting to use uninitialized in Tensorflow â€ , shown in Figure 2c , illustrates the significance of ğ‘–ğ‘šğ‘ğ‘œğ‘Ÿğ‘¡ functions for extending the abilities of ICPs both as learning laboratories and more generally . The code snippet includes the line : ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› _ ğ‘ ğ‘¡ğ‘’ğ‘ = ğ‘¡ğ‘“ . ğ‘¡ğ‘Ÿğ‘ğ‘–ğ‘› . ğºğ‘Ÿğ‘ğ‘‘ğ‘–ğ‘’ğ‘›ğ‘¡ğ·ğ‘’ğ‘ ğ‘ğ‘’ğ‘›ğ‘¡ğ‘‚ğ‘ğ‘¡ğ‘–ğ‘šğ‘–ğ‘§ğ‘’ğ‘Ÿ Across the corpus , 120 questions reference TensorFlowâ€™s Gradi - entDescentOptimizer . Gradient Descent is a type of optimisation algorithm used during training of a neural network [ 117 ] . This line of code enables the user to access the TensorFlow libraryâ€™s operationalisation of gradient descent algorithms through its APIâ€” alleviating the need for the user to code their own gradient descent algorithm . While TensorFlow is only one of a number of similar software libraries available , the volume of posts ( 38 . 6 % of all ques - tions ) in the corpus in which TensorFlow is mentioned , and the two most probable terms in topic 15 ( â€˜importâ€™ and â€˜tensorflowâ€™ ) , provides some indication of its widespread use in ICPs and ML practices . 5 . 2 Coordination hubs for ML infrastructures Assembling an ML workflow is a complex task , requiring coordina - tion of multiple infrastructures . Interactive computing platforms serve as coordination hubs , through which networks of infrastruc - tures are assembled to support ML practices . Reflecting this , as shown in Figure 3d , the cluster of topics associated with infrastruc - ture and inter - dependencies accounts for a significantly greater proportion of questions in the corpus than the cluster of topics associated with model training . The most viewed questions within the infrastructure and inter - dependencies cluster reveal the infras - tructural coordination that is at the heart of many ML practices . One of the most viewed questions within the infrastructure and inter - dependencies cluster is titled â€œ Can I run Keras model on gpu ? â€ ( Figure 2a ) . 16 Keras is a high - level API designed to support deep 16 See https : / / stackoverflow . com / questions / 45662253 / can - i - run - keras - model - on - gpu for the full question and its answer thread . learning techniques . 17 Keras is integrated into TensorFlow , and enables users to build a wide range of neural networksâ€”Keras makes it easier and more efficient to complete deep learning tasks within TensorFlow . A GPUâ€”Graphics Processing Unitâ€”is a spe - cialised microprocessor , which in many computing systems works alongside the more general - purpose Central Processing Unit ( CPU ) microprocessor . Whilst the GPU - CPU arrangement predates the emergence of Deep Learning , it turns out that GPU microprocessors are better suited to performing many of the computations required to train a neural network than CPUs . The author of this question is attempting to assemble a system that consists of a â€œ Tensorflow backend â€ and a â€œ Keras model â€ , interacted with through a â€œ Jupyter notebook â€ , and run on their computerâ€™s GPU . The highest scoring answer recommends installing CUDA , which is an additional par - allel programming platform designed to enable GPUs to be used for non - graphics processing tasks , such as model training . This answer provides hyperlinks to additional resources for installing CUDA and checking that TensorFlow is running properly on a GPU . Above this answer are two further user comments also linking to additional resources . As such , the author of this question is assem - bling a system that involves at least five interdependent layers : GPU , CUDA , TensorFlow , Keras , Juypter Notebook . The author is fortunate , however , as their aim is to train their model within â€œ 36 hours â€ , which suggests that either they have access to a powerful GPU , or they are training a model with a relatively small dataset ( for instance , as part of a learning exercise ) . In industrial or research settings , training a neural network requires access to much greater compute resources , which requires users to access a cloud resource , such as Amazon Web Services , and adds at least one additional layer of complexity to the system . The key words associated with topics within the infrastructure and inter - dependencies cluster ( shown in Figure 3a ) provide an additional perspective on the infrastructural coordination required to support ML tasks . In descending order of representation in the corpus , these topics are : 13 , 5 , 15 , 12 , 14 , 23 , 22 , 30 , and 10 . As al - ready observed , topics 13 and 5 relate to Google Colab and Jupter Notebook , two ICPs . Meanwhile , topic 15 includes â€˜importâ€™ and â€˜ten - sorflowâ€™ as the two most probable terms . Topic 23 includes â€˜gpuâ€™ , â€˜cpuâ€™ , and â€˜cudaâ€™ as probable terms . Topic 22 includes â€˜tensorflowâ€™ and â€˜tpuâ€™ , which is a reference to Tensor Processing Units , which are a new generation of GPUs specifically designed to support Ten - sorFlow . The presence of these topics , and their close correlations , as shown in Figure 3b , indicate that coordination between infras - tructures is widely discussed on Stack Exchange . Finally , Figure 3d shows the expected proportion of topic 13 ( Google Colab ) compared to topic 5 ( Jupyter Notebook ) over time . The topic model estimates that since 2017 questions related to Google Colab have increased compared to questions related to Jupyter Notebook . Significantly , a key point of difference between these two platforms is that Google Colab has been designed to integrate directly into Googleâ€™s cloud compute infrastructure , and is used as the platform of choice in TensorFlow and Keras tutorials . 17 See https : / / keras . io / for an introduction to Keras . AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman ( a ) Expected distribution of all topics across the corpus , with the most probable word associated with each topic . ( b ) Topiccorrelationnetwork , usingtheNewman - Girvan method , with a minimum correlation threshold of 0 . 01 . ( c ) Comparison of the expected topic proportions in the corpus over time for topics 13 ( Colab related questions ) and 5 ( Jupyter related questions ) . Dashed lines represent a confidence interval of 0 . 95 . ( d ) The expected topic proportions over time , with the three communities identified in Figure 3b treated as groups of topics . Dashed lines represent a confidence in - terval of 0 . 95 . Figure 3 : Visualisations of the estimated topic model . 6 DISCUSSION In this study , the intertwining of interactive computing platforms in ML practices was explored . The findings indicate that ICPs are learn - ing laboratoriesâ€”tools by which users experiment with and learn ML practices through line - by - line interaction with othersâ€™ code and publicly available datasets , facilitated by the APIs provided by high - level programming languages . The findings show also that ICPs are coordination hubsâ€”sites at which multiple different infrastructures are brought together to support ML practices , such as model train - ing or data processing . Given the role ICPs play as coordination hubs for ML practices , they can be conceptualised as an emerging form of â€˜digital infrastructureâ€™â€”an essential and widely participated in sociotechnical system [ 19 , 104 ] . Conceptualising ICPs in this way enables existing theorising about infrastructures to inform consid - eration of the sociopolitical significance of ICP use in ML practices , and helps connect ICP use to concerns raised in AI ethics discourse . To illustrate this , in the following subsections I consider how Brian Larkinâ€™s review of anthropological practices for studying infras - tructure [ 73 ] and Susan Leigh Starâ€™s description of the properties of infrastructure [ 130 ] can apply to ICPs . In each subsection I conclude with a brief reflection on implications for AI ethics discourse . Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada 6 . 1 An emerging infrastructural relationship As material objects , Larkin describes infrastructures as â€œ built net - works that facilitate the flow of goods , people , or ideas â€ [ 73 , p . 328 ] . At the same time , infrastructures are systems that support the func - tioning of other objects , and it is these objects that users of an infrastructure experience ; we experience hot water , not plumb - ing [ 73 , p . 329 ] . Star describes this characteristic of infrastructure as â€˜transparencyâ€™ : for users of an infrastructure , the tasks associ - ated with it seem easy and straightforwardâ€”transparent [ 130 ] . Star , however , understands infrastructures as relational . Transparency is not an inherent characteristic of a sociotechnical system , but rather a characteristic of an infrastructural relationship between a sociotechnical system and its users . The topic model of Stack Exchange questions is a snapshot of an emerging infrastructural relationship : as ML practitioners use ICPs as coordination hubs , facilitating flows of data and code across networks of disparate resources ( compute capacity , programming languages , datasets , etc . ) , they are forming an infrastructural re - lationship with the platform . The platform itself recedes into the background and the objects that the platform enables to functionâ€” predictive modelsâ€”come into the foreground . This is why ICPs excel as learning laboratories for ML . The affordances of the ICP , however , continue to have efficacy even as the platform itself be - comes transparent : the affordances enable and constrain users , and in doing so help configure practices associated with the ML tech - niques that the platform enables [ 30 , 31 ] . Starâ€™s understanding of infrastructures as relational also high - lights the relationship between infrastructures and groups : infras - tructures are â€œ learned as part of membership â€ [ 130 , p . 381 ] . This conceptualisation of the relationship between infrastructures and group membership appears to align closely to the burgeoning in - frastructural relationship between ML practitioners and ICPs . As the topic model interpretation illustrates , ML practitioners learn to use an ICPs as part of the process of becoming â€˜ML practitionersâ€™ . Star highlights that shared use of common infrastructures among practitioners helps reinforce their identity as a distinct group [ 130 ] . Non - members , meanwhile , encounter infrastructures as things they need to learn to use in order to integrate into a group . Note , for ex - ample , the authorâ€™s phrasing in the Stack Overflow question shown in Figure 2d : â€œ Iâ€™m new and studying machine learning . . . Iâ€™m getting problems about loading the CSV File into the Jupyter Notebook â€ . â€˜ML practitionerâ€™ is an ill - defined term frequently used in AI ethics discourse as a catchall for describing the data scientists , software engineers , and product managers who work on the research and development of ML systems . From an infrastructural perspective , however , the term can also be thought of symbolising a new set of infrastructural relations : where previously data scientists , software engineers , etc . , each worked within their own suites of tools , in - creasingly they use shared infrastructure , such as ICPs , enabling the collapsing of distinctions between these professional roles that is indicated in the term â€˜ML practitionerâ€™ . 6 . 1 . 1 Implications for AI ethics . A stream of AI ethics research has focused on the development of software and management tools to support ML practitioners ( see [ 88 ] for an overview ) . For this stream , ICPs may be a constraint , in so far as tool adoption is often held to be dependent on integration with existing ML infrastructure and practices [ e . g . 40 , 50 ] . Alternatively , the affordances of ICPs may offer new opportunities for future tool development . The grammar of ICP interactions may be applied to the design of tools intended to prompt practitioner reflection . The open source Fairlearn library , for example , provides example ICP notebooks 18 to demonstrate library uses . More broadly , however , as ICPs contribute to the configuring of ML practices , they shape the space in which AI ethics are situated . Here , Britt Parisâ€™s [ 97 ] reflections on the relationship between In - ternet infrastructure and constructions of time are instructive . ICPs , like the Internet at large , imagine particular temporal relations . ICPs , in particular , are premised on speed : the staccato call - and - response of user inputs and computer outputs helps configures a working environment in which the value of ML practices resides in their speed and efficiency . In this sense , conceptualising ICPs as ML infrastructure presents as a challenge to calls from AI ethics researchers for greater reflexivity in ML [ e . g . 37 , 146 ] . 6 . 2 Visible and invisible infrastructures As material objects , infrastructures are designed , and reflect , at least in part , the intentions of the designer . Yet , at the same time , infrastructures are â€œ built on an installed base â€ , often following paths of development laid down by preceding infrastructures [ 130 , p . 382 ] . And , infrastructures are often caught in circular webs of relations with other infrastructures : computers rely on the electricity grid to function , and the functioning of the modern electricity grid is reliant on computers [ 73 ] . Infrastructures therefore cannot be understood in isolation , in the same way that they cannot be designed in isola - tion . The role ICPs play as coordination hubs reflect this : they are built on top of the networked and decentralised infrastructures of the Internet , programming languages , and computing . In doing so , ICPs augment and extend these pre - existing infrastructures , both following path dependencies established by these infrastructures and charting new paths for future infrastructures [ cf . 148 ] . Larkin highlights that infrastructures also serve a â€˜poeticâ€™ func - tion [ 73 ] . Larkin draws on linguist Roman Jakobsonâ€™s concept of poetics [ 62 ] , which holds that in some speech acts the palpable qualities of speech ( roughly , sound patterns ) have primary impor - tance over representational qualities ( i . e . meaning ) . Infrastructures , argues Larkin , can have a poetic function , not reflected in the de - clared intentions of designers , nor in their technical capabilities [ 73 ] . Researchers of infrastructure , then , must take seriously the aesthetic aspects of infrastructure , and consider how infrastructures not only reflect the declared intention of those who build them , but also their ( undeclared ) interests . Larkinâ€™s description of the poetics of infrastructure mirrors Jenna Burrellâ€™s critique of blithe descriptions of algorithms as â€™opaqueâ€™ , which ignore the ways the appearance of opaqueness in an algorithmic system can reflect the politics of the institutions who operate them [ 26 ] . In this context , a significant line of future inquiry pertains to the different politics and interests reflected in the two ICPs identified as widely used by the topic model : Jupyter Notebook and Google Colab . For Larkin , the aesthetic aspects of infrastructure include the way infrastructures may at times appear transparent or invisible [ 73 ] . Here , Larkin takes issue with Starâ€™s description of infrastructures 18 See https : / / fairlearn . org / v0 . 8 / auto _ examples / index . html . AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman as â€˜invisibleâ€™ . Star describes this characteristic of infrastructure as " becoming visible upon breakdown " [ 130 , p . 382 ] . By standardising in - teractions between material objects , users , and other infrastructures , infrastructures become transparent to users , and , when this trans - parency becomes routine , the infrastructure itself appears invisible . Questions asked on Stack Exchange can thus be interpreted as in - stances of ML infrastructure becoming visible . To Larkin , however , the claim that infrastructures are invisible can only ever be partially valid : what the affordances of infrastructures make visible and in - visible is both an outcome a systemâ€™s technical capabilities and its poetic functions . Larkin and Starâ€™s debate on invisibility thus helps shed light on the mechanism by which ICPs become implicated in the characteristics of ML systems that are developed through their use . As infrastructural systems , ICPs standardise a particular form of presenting and interacting with codeâ€”the â€˜notebookâ€™ layout of descriptive and computation cells described in Section 2 . 2â€”and this standardisation renders some aspects of ML system development more visible to ML practitioners than others . Shifts in the aspects of ML system development that are transpar - ent to ML practitioners can have significant impacts on practition - ersâ€™ understanding of ML technologies . As discussed in Section 5 . 1 , ICPs support iterative experimentation with the APIs of high - level programming languages , which often occurs through probing and re - purposing of code written by others . Iterative experimentation with the API of a high - level programming language , however , is unlikely to reveal the full range of decisions that the creators of an API have made in operationalising a particular ML algorithm or technique . The point of Kerasâ€™ Tokenizer function ( shown in the code snippet in the Stack Overflow question in Figure 2b ) is that it enables users to convert the text in a corpus into a series of integers ( â€˜embeddingsâ€™ ) , so that computations ( e . g . topic modelling ) can be run on the corpus . The function enables users to choose whether or not to convert text to lowercase , but because the function has a default setting , this choice is not necessaryâ€”by default any call of the Tokenizer function will convert text to lowercase before con - version to numerical form . 19 This may seem inconsequential , but it can have a significant downstream impact : converting a corpus to lowercase means that the verb â€˜stackâ€™ and proper noun â€˜Stackâ€™ will be embedded as semantically identical . As APIs of high - level programming languages become more sophisticated , particularly as they start to incorporate pre - trained models for common ML tasks ( e . g . image classification , object de - tection and labelling , sentiment detection ) , the choices obfuscated by the API become more consequential . The TensorFlow Object Detection notebook 20 uses a CenterNet pre - trained model which was trained on the Common Objects in Context dataset [ 81 ] . This dataset includes labels for 91 categories of objects , including â€˜plateâ€™ , â€˜cupâ€™ , â€˜forkâ€™ , â€˜knifeâ€™ , â€˜spoonâ€™ , and â€˜bowlâ€™ ( but not , for instance , â€˜chop - stickâ€™ ) , and it is these objects that the CenterNet model can detect in images . This sequence of choices , and the constraints each choice imports into the ML system , are not surfaced by experimentation with the API in an ICP ; the infrastructural relationship between ML practitioners and ICPs renders transparent code reuse , but leaves detailed code knowledge opaque . 19 See https : / / www . tensorflow . org / api _ docs / python / tf / keras / preprocessing / text / Tokenizer for the Tokenizer documentation . 20 Accessible at https : / / www . tensorflow . org / hub / tutorials / tf2 _ object _ detection . 6 . 2 . 1 Implications for AI ethics . At stake in AI ethics discourse are questions of legitimacy . Arising from the recognition that code operationalises and reifies particular interpretations of essentially contested social constructs [ 20 , 60 , 89 ] is the challenge of locating where and how coding decisions are currently made , and where they ought to be made . What , if any , categories of gender ought to be included as labels in an image dataset [ 66 ] ? High - level APIs , interacted with through ICPs , obscure these decisions , and in doing so further entrench them in ML practices : what is unknown to ML practitioners is unquestioned . In this sense , the infrastructural relationship between practitioners and ICPs is an example of social arrangements helping configure ML practices as â€™black boxesâ€™ [ 26 ] , and is thus a new challenge to the efforts of AI ethics researchers to embed accountability for decision making in ML development [ 29 ] . 6 . 3 Development of infrastructures over time The role of coordination hub lends ICPs and the web of other infras - tructures they are related to ( compute resources , code repositories , etc . ) a semblance of hierarchical coherence . But , while infrastruc - tures may be presented as coherent , hierarchical structures , they are rarely built or managed in this way . Indeed , Jupyter Notebook began life as an open - source project focused on scientific computing within the Python programming language , before being adopted and adapted by ML practitioners and industry [ 45 ] . In this sense , the emergence of ICPs as infrastructure reflects a familiar process of adaptation and translation [ cf . 57 ] . Relevantly , Star highlights that infrastructures are fixed in modular increments [ 130 , p . 382 ] , with â€œ conventions of practice â€ co - evolving alongside the develop - ment of the infrastructure itself [ 130 ] . Here , Elizabeth Shoveâ€™s work on the co - evolution of infrastructures and practices offers a poten - tial framework by which to explore how ICPs and ML practices co - evolve [ 124 , 125 ] . Watson and Shove argue that infrastructural relations and prac - tices co - evolve through processes of aggregation and integration [ 145 ] . Aggregation refers to â€œ the ways in which seemingly localised experiences and practices combine and , in combining , acquire a life of their own â€ [ 145 , p . 2 ] . Individual ML practitioners , for example , each develop their own approach to coordinating the different layers of infrastructure needed to support ML tasks . However , as individuals share their approaches , and these coalesce into con - ventions , the conventions themselves shape future infrastructure development . The convention of using GPUs for model training , for example , creates the demand needed to justify the development of more specialised TPUs . Integration refers to ways that policies , processes , and artefacts at the level of the overarching infrastruc - ture are â€œ brought together in the performance of practices enacted across multiple sites [ 145 , p . 2 ] . Google , for example , sets various policies regarding the availability of Googleâ€™s GPU resources to users of Google Colab . These policy decisions ( e . g . the decision to offer limited free access to GPUs ) in turn are integrated into individual usersâ€™ ML practicesâ€”top - down policy decisions help inform the future development of conventions of practice , but do not determine them . For the field of AI ethics , the framework of aggregation and integration offers a path towards understanding how norms in ML practices , such as the use of particular opera - tionalisations of fairness metrics , co - evolve as a product of both Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada the integration of particular fairness approaches into high - level programming languages and the aggregation of local approaches to â€˜managingâ€™ ethics issues into shared practices . 6 . 3 . 1 Implications for AI ethics . Conceptualising interactive com - puting platforms as an emerging form of â€˜digital infrastructureâ€™ situates them alongside other digital â€™platformsâ€™ that have coalesced into infrastructures ( e . g . WeChat [ 101 ] , Facebook [ 51 , 52 , 103 ] , and Google [ 103 ] ) . The prominence of these digital infrastructures in mediating contemporary life has led to the development of the plat - form governance field [ 43 ] . 21 Platform governance researchers have explored how digital infrastructures attempt to exercise governance over their users , and how digital infrastructures themselves can be more effectively governed . Robert Gorwa , for example , has stud - ied the governance of online content , particularly user - generated content on digital platforms [ 42 ] . As Gorwa argues , there is an increasing nexus between AI ethics discourse and platform gover - nance discourse : algorithmic systems , particularly predictive ML systems , are core components of the governance regimes of digital infrastructures [ 44 ] . Tarleton Gillespie , for example , critiques the positioning of ML tools as the solution to social media content moderation [ 41 ] . ICPs advance this nexus , but in the reverse di - rection : as the platforms have developed from software tools for scientific computing to general purpose coordination hubs for ML practices they have begun to integrate affordances more commonly associated with digital platforms . Google Colab , for example , in - tegrates directly into Google Driveâ€”a widely used cloud storage and file sharing platform . We can interpret this integration as an effort to cultivate network effects [ 14 ] : if I care about sharing my notebook with others , then it makes sense that I will seek out the ICP that integrates directly with the file sharing system most of my colleagues use . But , to the extent that a notebook is â€˜contentâ€™ , and the extent that this content may include ML models that have been shown to cause significant social harm , ICP operators have so far eluded responsibility for this content . For the field of AI ethics , then , the potential for ICP operators to exercise governance functions over ICP users may be worth further consideration . 7 LIMITATIONS Conceptually , as Eric Baumer and Micki McGee [ 11 ] argue , topic modelling risks using a statistical model of a corpus to speak on be - half of a social group . This risk is compounded by the fact that the so - cial group who generates content that enters a corpus ( in this study , people who ask questions on Stack Exchange forums ) may not be representative of the social group of interest to the study ( here , ML practitioners ) . Relevantly , among the Stack Overflow user base , as of 2016 , only 5 . 8 % of contributors were female [ 38 ] . Additionally , while there are versions of Stack Overflow in multiple languages , only the English - language version has been used in this study . As such , fu - ture research will need to validate the extent to which the practices identified in this study are representative of ML practitioners . The focus of Stack Exchange questions also presents a funda - mental limitation for studies of ML practitioners . Stack Exchange questions are points of troubleâ€”they represent moments when a user has been unable to complete a task . As such , it may be the 21 Similarly , theemergenceofearlierinformationinfrastructuresledtothedevelopment of the internet governance field [ 53 ] and information infrastructure studies [ 20 ] . case that there are a range of practices that are not represented in the Stack Exchange corpus , simply because they are practices so familiar they do not necessitate asking any questions . Given the discussion on transparency and infrastructures in Section 6 . 1 , this means Stack Exchange questions can only offer a partial account of infrastructural relationships . There are also limitations inherent in the pre - processing and model training process outlined in Section 4 . 2 . In particular , stemming of words may have reduced the seman - tic depth of the topic model , as may have removal of code snippets from the corpus . The validation of topic models is an ongoing area of research [ 46 , 85 ] . As this is a preliminary study , no attempt has been made to externally validate the accuracy of the topics iden - tified ( e . g . through comparing the latent topics identified by the topic model to coded themes identified by expert human reviewers of the same corpus , as in [ 86 ] ) . More broadly , the approach taken in this study will benefit from complementary qualitative studies to both validate and contextualise findings ( e . g . ethnographic studies of practitioners in multiple social contexts [ 39 ] ) . 8 CONCLUSION Interactive computing platforms , such as Jupyter Notebook and Google Colab , are widely used by ML practitioners . In this paper , I conducted a topic model analysis of user - contributed questions on the Stack Exchange forums related to interactive computing plat - forms and ML . I found interactive computing platforms are used by ML practitioners in two categories of practices : in learning practices , particularly to support probing and reuse of othersâ€™ code ; and , in coordination practices , to help marshal the various infrastructures needed to enact ML tasks . I argued that these practices constitute an emerging infrastructural relationship between ML practitioners and interactive computing platforms , in which both the platforms and ML practices are co - evolving . I highlighted several consequences of this infrastructuralisation , in terms of configuring the space in which AI ethics operates and responds to , designing interventions in ML practices , making visible the operationalisation in code of social constructs , and the platform power of ICP operators . As the ML field advances , a pressing issue is therefore the relationship between the social context ICPs form part of and the characteristics of ML systems that are developed . Tracing these relations is critical for resisting the enclosure of AI ethics by a set of social arrange - ments that may themselves be contributing to the production and deployment of harmful ML systems . ACKNOWLEDGMENTS This research is part of a larger PhD research project , supported by the Australian Government Research Training Program Scholarship . I acknowledge feedback generously provided by Jochen Trumpf , Jenny Davis , Ben Hutchinson , Kate Williams , Charlotte Bradley , Ned Cooper , Kathy Reid , and the anonymous reviewers . REFERENCES [ 1 ] Rabe Abdalkareem , Emad Shihab , and Juergen Rilling . 2017 . On Code Reuse from StackOverflow : An Exploratory Study on Android Apps . Information and Software Technology 88 ( Aug . 2017 ) . [ 2 ] Arshad Ahmad , Chong Feng , Shi Ge , and Abdallah Yousif . 2018 . A Survey on Mining Stack Overflow : Question and Answering ( Q & A ) Community . Data Technologies and Applications 52 , 2 ( Jan . 2018 ) . AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman [ 3 ] Moayad Alshangiti , Hitesh Sapkota , Pradeep K . Murukannaiah , Xumin Liu , and Qi Yu . 2019 . Why Is Developing Machine Learning Applications Challenging ? A Study on Stack Overflow Posts . In 2019 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement ( ESEM ) . IEEE , Porto de Galinhas , Recife , Brazil . [ 4 ] Louise Amoore . 2019 . Doubt and the Algorithm : On the Partial Accounts of Machine Learning . Theory , Culture & Society 36 , 6 ( Nov . 2019 ) . [ 5 ] LeAn , OnsMlouki , FoutseKhomh , andGiulianoAntoniol . 2017 . StackOverflow : A Code Laundering Platform ? . In 2017 IEEE 24th International Conference on Software Analysis , Evolution and Reengineering ( SANER ) . [ 6 ] Ashton Anderson , Daniel Huttenlocher , Jon Kleinberg , and Jure Leskovec . 2012 . Discovering Value from Community Activity on Focused Question Answering Sites : A Case Study of Stack Overflow . In Proceedings of the 18th ACM SIGKDD InternationalConferenceonKnowledgeDiscoveryandDataMining . ACM , Beijing China . [ 7 ] Rob Ashmore , Radu Calinescu , and Colin Paterson . 2022 . Assuring the Machine Learning Lifecycle : Desiderata , Methods , and Challenges . Comput . Surveys 54 , 5 ( June 2022 ) . [ 8 ] Sebastian Baltes and Stephan Diehl . 2019 . Usage and Attribution of Stack Overflow Code Snippets in GitHub Projects . Empirical Software Engineering 24 , 3 ( June 2019 ) . [ 9 ] Marguerite Barry , Aphra Kerr , and Oliver Smith . 2020 . Ethics on the Ground : From Principles to Practice . In Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency . Association for Computing Machinery . [ 10 ] Anton Barua , Stephen W . Thomas , and Ahmed E . Hassan . 2014 . What Are Developers Talking about ? An Analysis of Topics and Trends in Stack Overflow . Empirical Software Engineering 19 , 3 ( June 2014 ) . [ 11 ] EricP . S . BaumerandMickiMcGee . 2019 . SpeakingonBehalfof : Representation , Delegation , and Authority in Computational Text Analysis . In Proceedings of the 2019 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Honolulu HI USA . [ 12 ] Kathy Baxter , Yoav Schlesinger , Sarah Aerni , Lewis Baker , Julie Dawson , Krish - naram Kenthapadi , Isabel Kloumann , and Hanna Wallach . 2020 . Bridging the Gap from AI Ethics Research to Practice . Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency ( 2020 ) . [ 13 ] Marijan Beg , Juliette Taka , Thomas Kluyver , Alexander Konovalov , Min Ragan - Kelley , Nicolas M . ThiÃ©ry , and Hans Fangohr . 2021 . Using Jupyter for Repro - ducible Scientific Workflows . Computing in Science & Engineering 23 , 2 ( 2021 ) . [ 14 ] Paul Belleflamme . 2018 . Platforms and Network Effects . In Handbook of Game Theory and Industrial Organization , Volume II , Luis CorchÃ³n and Marco Marini ( Eds . ) . Edward Elgar Publishing . [ 15 ] James Bessen , Stephen Michael Impink , and Robert Seamans . 2022 . The Cost of Ethical AI Development for AI Startups . In Proceedings of the 2022 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Oxford United Kingdom . [ 16 ] AlexBeutel , JilinChen , TulseeDoshi , HaiQian , AllisonWoodruff , ChristineLuu , Pierre Kreitmann , Jonathan Bischof , and Ed H . Chi . 2019 . Putting Fairness Prin - ciples into Practice : Challenges , Metrics , and Improvements . In Proceedings of the 2019 AAAI / ACM Conference on AI , Ethics , and Society ( AIES â€™19 ) . Association for Computing Machinery , New York , NY , USA . [ 17 ] Miranda Bogen , Aaron Rieke , and Shazeda Ahmed . 2020 . Awareness in Prac - tice : Tensions in Access to Sensitive Attribute Data for Antidiscrimination . In Proceedings of the 2020 Conference on Fairness , Accountability , and Transparency . Association for Computing Machinery . [ 18 ] Pierre Bourdieu . 2020 . Outline of a Theory of Practice . In The New Social Theory Reader . Routledge . [ 19 ] Geoffrey C . Bowker , Karen Baker , Florence Millerand , and David Ribes . 2009 . Toward Information Infrastructure Studies : Ways of Knowing in a Networked Environment . In International Handbook of Internet Research , Jeremy Hunsinger , Lisbeth Klastrup , and Matthew Allen ( Eds . ) . Springer Netherlands , Dordrecht . [ 20 ] GeoffreyC . BowkerandSusanLeighStar . 2000 . SortingThingsout : Classification and Its Consequences . MIT Press . [ 21 ] Demetrios Brinkmann . 2021 . Jupyter Notebooks In Production ? [ 22 ] AndrÃ© Brock . 2018 . Critical Technocultural Discourse Analysis . New Media and Society 20 , 3 ( 2018 ) . [ 23 ] Gavin Brookes and Tony McEnery . 2019 . The Utility of Topic Modelling for Discourse Studies : A Critical Evaluation . Discourse Studies 21 , 1 ( Feb . 2019 ) . [ 24 ] Duncan A . Brown , Karan Vahi , Michela Taufer , Von Welch , and Ewa Deelman . 2021 . Reproducing GW150914 : The First Observation of Gravitational Waves From a Binary Black Hole Merger . Computing in Science Engineering 23 , 2 ( March 2021 ) . [ 25 ] Joy Buolamwini and Timnit Gebru . 2018 . Gender shades : Intersectional accu - racy disparities in commercial gender classification . In Conference on fairness , accountability and transparency . PMLR , 77 â€“ 91 . [ 26 ] Jenna Burrell . 2016 . How the Machine â€˜thinksâ€™ : Understanding Opacity in Machine Learning Algorithms . Big Data and Society 3 , 1 ( 2016 ) . [ 27 ] Souti Chattopadhyay , Ishita Prasad , Austin Z . Henley , Anita Sarma , and Titus Barik . 2020 . Whatâ€™s Wrong with Computational Notebooks ? Pain Points , Needs , and Design Opportunities . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . ACM , Honolulu HI USA . [ 28 ] AngÃ¨le Christin . 2017 . Algorithms in Practice : Comparing Web Journalism and Criminal Justice . Big Data & Society 4 , 2 ( Dec . 2017 ) . [ 29 ] A . Feder Cooper , Emanuel Moss , Benjamin Laufer , and Helen Nissenbaum . 2022 . Accountability in an Algorithmic Society : Relationality , Responsibility , and Robustness in Machine Learning . In 2022 ACM Conference on Fairness , Accountability , and Transparency . ACM , Seoul Republic of Korea . [ 30 ] Jenny L Davis . 2020 . How artifacts afford : The power and politics of everyday things . MIT Press . [ 31 ] Jenny L . Davis and James B . Chouinard . 2016 . Theorizing Affordances : From Request to Refuse . Bulletin of Science , Technology & Society 36 , 4 ( 2016 ) . [ 32 ] Emily Denton , Alex Hanna , Razvan Amironesei , Andrew Smart , and Hilary Nicole . 2021 . OntheGenealogyofMachineLearningDatasets : ACriticalHistory of ImageNet . Big Data & Society 8 , 2 ( July 2021 ) . [ 33 ] Advait Deshpande and Helen Sharp . 2022 . Responsible AI Systems : Who Are the Stakeholders ? . In Proceedings of the 2022 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Oxford United Kingdom . [ 34 ] PaulDiMaggio , ManishNag , andDavidBlei . 2013 . ExploitingAffinitiesbetween Topic Modeling and the Sociological Perspective on Culture : Application to Newspaper Coverage of U . S . Government Arts Funding . Poetics 41 , 6 ( Dec . 2013 ) . [ 35 ] Paul Dourish . 2016 . Algorithms and Their Others : Algorithmic Culture in Context . Big Data and Society 3 , 2 ( 2016 ) . [ 36 ] Fred Emery . 1993 . Characteristics of Socio - Technical Systems . In The Social Engagement of Social Science , Volume 2 , Eric Trist , Hugh Murray , and Beulah Trist ( Eds . ) . University of Pennsylvania Press , Philadelphia . [ 37 ] BenjaminFishandLukeStark . 2021 . ReflexiveDesignforFairnessandOtherHu - man Values in Formal Models . In Proceedings of the 2021 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Virtual Event USA . [ 38 ] Denae Ford , Justin Smith , Philip J . Guo , and Chris Parnin . 2016 . Paradise Un - plugged : Identifying Barriers for Female Participation on Stack Overflow . In Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Founda - tions of Software Engineering . ACM , Seattle WA USA . [ 39 ] Diana E . Forsythe . 1993 . Engineering Knowledge : The Construction of Knowl - edge in Artificial Intelligence . Social Studies of Science 23 , 3 ( Aug . 1993 ) . [ 40 ] Timnit Gebru , Jamie Morgenstern , Briana Vecchione , Jennifer Wortman Vaughan , Hanna Wallach , Hal DaumÃ© Iii , and Kate Crawford . 2021 . Datasheets for Datasets . Commun . ACM 64 , 12 ( Dec . 2021 ) . [ 41 ] Tarleton Gillespie . 2020 . Content Moderation , AI , and the Question of Scale . Big Data and Society 7 ( 2020 ) . [ 42 ] Robert Gorwa . 2019 . The Platform Governance Triangle : Conceptualising the Informal Regulation of Online Content . Internet Policy Review 8 , 2 ( June 2019 ) . [ 43 ] Robert Gorwa . 2019 . What Is Platform Governance ? Information , Communica - tion & Society 22 , 6 ( May 2019 ) . [ 44 ] Robert Gorwa . 2020 . Towards Fairness , Accountability , and Transparency in Platform Govvernance . AoIR Selected Papers of Internet Research ( Feb . 2020 ) . [ 45 ] Brian Granger and Fernando PÃ©rez . 2021 . Jupyter : Thinking and Storytelling with Code and Data . Preprint . [ 46 ] Justin Grimmer , Roberts . Margaret E . , and Stewart , Brandon M . 2022 . Text as Data : ANewFrameworkforMachineLearningandtheSocialSciences . Princeton . [ 47 ] Justin Grimmer and Brandon M . Stewart . 2013 . Text as Data : The Promise and Pitfalls of Automatic Content Analysis Methods for Political Texts . Political Analysis 21 , 3 ( 2013 ) . [ 48 ] Joel Grus . 2018 . I Donâ€™t like Notebooks . : Jupyter Notebook Conference & Training : JupyterCon . https : / / conferences . oreilly . com / jupyter / jup - ny / public / schedule / detail / 68282 . html [ 49 ] Frode Guribye . 2015 . From Artifacts to Infrastructures in Studies of Learning Practices . Mind , Culture , and Activity 22 , 2 ( April 2015 ) . [ 50 ] MichaelaHardt , XiaoguangChen , XiaoyiCheng , MicheleDonini , JasonGelman , Satish Gollaprolu , John He , Pedro Larroy , Xinyu Liu , Nick McCarthy , Ashish Rathi , Scott Rees , Ankit Siva , ErhYuan Tsai , Keerthan Vasist , Pinar Yilmaz , MuhammadBilalZafar , SanjivDas , KevinHaas , TylerHill , andKrishnaramKen - thapadi . 2021 . AmazonSageMakerClarify : MachineLearningBiasDetectionand Explainability in the Cloud . In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . ACM , Virtual Event Singapore . [ 51 ] Anne Helmond . 2015 . The Platformization of the Web : Making Web Data Platform Ready . Social Media and Society 1 , 2 ( 2015 ) . [ 52 ] Anne Helmond , David B . Nieborg , and Fernando N . van der Vlist . 2019 . Face - bookâ€™sEvolution : DevelopmentofaPlatform - as - Infrastructure . InternetHistories 3 , 2 ( April 2019 ) . [ 53 ] Jeanette Hofmann , Christian Katzenbach , and Kirsten Gollatz . 2017 . Between Coordination and Regulation : Finding the Governance in Internet Governance . New Media & Society 19 , 9 ( Sept . 2017 ) . [ 54 ] Kenneth Holstein , Jennifer Wortman Vaughan , Hal DaumÃ© , Miroslav DudÃ­k , and Hanna Wallach . 2019 . Improving Fairness in Machine Learning Systems : What Do Industry Practitioners Need ? . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada [ 55 ] AspenHopkinsandSerenaBooth . 2021 . MachineLearningPracticesOutsideBig Tech : How Resource Constraints Challenge Responsible Development . In Pro - ceedingsofthe2021AAAI / ACMConferenceonAI , Ethics , andSociety . Association for Computing Machinery . [ 56 ] Jeremy Howard . 2020 . Creating Delightful Libraries and Books with Nbdev and Fastdoc . [ 57 ] Thomas P . Hughes . 1987 . The Evolution of Large Technological Systems . The social construction of technological systems : New directions in the sociology and history of technology 82 ( 1987 ) . [ 58 ] Jack Ingram , Elizabeth Shove , and Matthew Watson . 2007 . Products and Prac - tices : Selected Concepts from Science and Technology Studies and from Social Theories of Consumption and Practice . Design Issues 23 , 2 ( 2007 ) . [ 59 ] Karoliina Isoaho , Daria Gritsenko , and Eetu MÃ¤kelÃ¤ . 2021 . Topic Modeling and Text Analysis for Qualitative Policy Research . Policy Studies Journal 49 , 1 ( Feb . 2021 ) . [ 60 ] Abigail Z . Jacobs and Hanna Wallach . 2021 . Measurement and Fairness . In Proceedings of the 2021 ACM Conference on Fairness , Accountability , and Trans - parency . Association for Computing Machinery . [ 61 ] Thomas Jacobs and Robin TschÃ¶tschel . 2019 . Topic Models Meet Discourse Analysis : A Quantitative Tool for a Qualitative Approach . International Journal of Social Research Methodology 22 , 5 ( Sept . 2019 ) . [ 62 ] Roman Jakobson . 1960 . Linguistics and Poetics . In Style in Language . MIT Press , MA . [ 63 ] StÃ©phanieJuneau , KnutOlsen , RobertNikutta , AliceJacques , andStephenBailey . 2021 . Jupyter - EnabledAstrophysicalAnalysisUsingData - ProximateComputing Platforms . Computing in Science Engineering 23 , 2 ( March 2021 ) . [ 64 ] HarmanpreetKaur , HarshaNori , SamuelJenkins , RichCaruana , HannaWallach , and Jennifer Wortman Vaughan . 2020 . Interpreting Interpretability : Under - standing Data Scientistsâ€™ Use of Interpretability Tools for Machine Learning . Conference on Human Factors in Computing Systems - Proceedings ( 2020 ) . [ 65 ] Mary Beth Kery , Marissa Radensky , Mahima Arya , Bonnie E . John , and Brad A . Myers . 2018 . The Story in the Notebook : Exploratory Data Science Using a Literate Programming Tool . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . ACM , Montreal QC Canada . [ 66 ] Os Keyes . 2018 . The Misgendering Machines : Trans / HCI Implications of Au - tomatic Gender Recognition . Proceedings of the ACM on Human - Computer Interaction 2 , CSCW ( 2018 ) . [ 67 ] Rob Kitchin . 2014 . Big Data , New Epistemologies and Paradigm Shifts . Big Data & Society 1 , 1 ( April 2014 ) . [ 68 ] Thomas Kluyver , Benjamin Ragan - Kelley , Fernando PÃ©rez , Brian Granger , Matthias Bussonnier , Jonathan Frederic , Kyle Kelley , Jessica Hamrick , Jason Grout , Sylvain Corlay , Paul Ivanov , DamiÃ¡n Avila , Safia Abdalla , Carol Willing , and Jupyter development team . 2016 . Jupyter Notebooks â€“ a Publishing Format for Reproducible Computational Workflows . In 20th International Conference on Electronic Publishing ( 01 / 01 / 16 ) , Fernando Loizides and Birgit Scmidt ( Eds . ) . IOS Press . [ 69 ] Allison Koenecke , Andrew Nam , Emily Lake , Joe Nudell , Minnie Quartey , Zion Mengesha , ConnorToups , JohnRRickford , DanJurafsky , andSharadGoel . 2020 . Racial disparities in automated speech recognition . Proceedings of the National Academy of Sciences 117 , 14 ( 2020 ) , 7684 â€“ 7689 . [ 70 ] Andreas P . Koenzen , Neil A . Ernst , and Margaret - Anne D . Storey . 2020 . Code Duplication and Reuse in Jupyter Notebooks . In 2020 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . IEEE . [ 71 ] P . M . Krafft , Meg Young , Michael Katell , Karen Huang , and Ghislain Bugingo . 2020 . Defining AI in Policy versus Practice . In Proceedings of the AAAI / ACM Conference on AI , Ethics , and Society . Association for Computing Machinery . [ 72 ] MaxLangenkampandDanielN . Yue . 2022 . HowOpenSourceMachineLearning Software Shapes AI . In Proceedings of the 2022 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Oxford United Kingdom . [ 73 ] Brian Larkin . 2013 . The Politics and Poetics of Infrastructure . Annual Review of Anthropology 42 ( 2013 ) . [ 74 ] BrianLarkin . 2020 . 7 . PromisingForms : ThePoliticalAestheticsofInfrastructure . In The Promise of Infrastructure , Nikhil Anand , Akhil Gupta , and Hannah Appel ( Eds . ) . Duke University Press . [ 75 ] MichelleSengAhLeeandJatinderSingh . 2021 . RiskIdentificationQuestionnaire for Detecting Unintended Bias in the Machine Learning Development Lifecycle . In Proceedings of the 2021 AAAI / ACM Conference on AI , Ethics , and Society . ACM , Virtual Event USA . [ 76 ] PaulM . Leonardi . 2012 . Materiality , Sociomateriality , andSocio - TechnicalSystems : What Do These Terms Mean ? How Are They Related ? Do We Need Them ? SSRN Scholarly Paper ID 2129878 . Social Science Research Network , Rochester , NY . [ 77 ] Paul M . Leonardi and Stephen R . Barley . 2008 . Materiality and Change : Chal - lengestoBuildingBetterTheoryaboutTechnologyandOrganizing . Information and Organization ( 2008 ) . [ 78 ] Paul M Leonardi , Bonnie A Nardi , and Jannis Kallinikos . 2012 . Materiality and Organizing : Social Interaction in a Technological World . Oxford University Press , Oxford . [ 79 ] David D . Lewis . 1997 . UCI Machine Learning Repository : Reuters - 21578 Text Categorization Collection Data Set . https : / / archive . ics . uci . edu / ml / datasets / reuters - 21578 + text + categorization + collection [ 80 ] Lan Li , Tina Lassiter , Joohee Oh , and Min Kyung Lee . 2021 . Algorithmic Hiring in Practice : Recruiter and HR Professionalâ€™s Perspectives on AI Use in Hiring . In Proceedings of the 2021 AAAI / ACM Conference on AI , Ethics , and Society . Association for Computing Machinery . [ 81 ] Tsung - Yi Lin , Michael Maire , Serge Belongie , Lubomir Bourdev , Ross Girshick , JamesHays , PietroPerona , DevaRamanan , C . LawrenceZitnick , andPiotrDollÃ¡r . 2015 . Microsoft COCO : Common Objects in Context . arXiv : arXiv : 1405 . 0312 [ 82 ] Nathan C . Lindstedt . 2019 . Structural Topic Modeling For Social Scientists : A Brief Case Study with Social Movement Studies Literature , 2005 â€“ 2017 . Social Currents 6 , 4 ( Aug . 2019 ) . [ 83 ] Adrian Mackenzie . 2015 . The Production of Prediction : What Does Machine Learning Want ? European Journal of Cultural Studies 18 , 4 - 5 ( 2015 ) . [ 84 ] Michael Madaio , Lisa Egede , Hariharan Subramonyam , Jennifer Wort - man Vaughan , and Hanna Wallach . 2022 . Assessing the Fairness of AI Systems : AI Practitionersâ€™ Processes , Challenges , and Needs for Support . Proceedings of the ACM on Human - Computer Interaction 6 , CSCW1 ( March 2022 ) . [ 85 ] Daniel Maier , A . Waldherr , P . Miltner , G . Wiedemann , A . Niekler , A . Keinert , B . Pfetsch , G . Heyer , U . Reber , T . HÃ¤ussler , H . Schmid - Petri , and S . Adam . 2018 . Applying LDA Topic Modeling in Communication Research : Toward a Valid and Reliable Methodology . Communication Methods and Measures 12 , 2 - 3 ( April 2018 ) . [ 86 ] David Mimno , Hanna Wallach , Edmund Talley , Miriam Leenders , and Andrew McCallum . 2011 . Optimizing Semantic Coherence in Topic Models . In Proceed - ingsofthe2011ConferenceonEmpiricalMethodsinNaturalLanguageProcessing . [ 87 ] John W . Mohr and Petko Bogdanov . 2013 . Introductionâ€”Topic Models : What They Are and Why They Matter . Poetics 41 , 6 ( Dec . 2013 ) . [ 88 ] Jessica Morley , Luciano Floridi , Libby Kinsey , and Anat Elhalal . 2020 . From What to How : An Initial Review of Publicly Available AI Ethics Tools , Methods and Research to Translate Principles into Practices . Science and Engineering Ethics 26 , 4 ( Aug . 2020 ) . [ 89 ] Emanuel Moss . 2022 . The Objective Function : Science and Society in the Age of Machine Intelligence . arXiv : 2209 . 10418 [ cs ] [ 90 ] Alexander Mueller . 2018 . 5 Reasons Why Jupyter Notebooks Suck . https : / / towardsdatascience . com / 5 - reasons - why - jupyter - notebooks - suck - 4dc201e27086 [ 91 ] Seyed Mehdi Nasehi , Jonathan Sillito , Frank Maurer , and Chris Burns . 2012 . What Makes a Good Code Example ? : A Study of Programming Q & A in Stack - Overflow . In 2012 28th IEEE International Conference on Software Maintenance ( ICSM ) . [ 92 ] M . E . J . Newman and M . Girvan . 2004 . Finding and Evaluating Community Structure in Networks . Physical Review E 69 , 2 ( Feb . 2004 ) . [ 93 ] SergeyI . Nikolenko , SergeiKoltcov , andOlessiaKoltsova . 2017 . TopicModelling for Qualitative Studies . Journal of Information Science 43 , 1 ( Feb . 2017 ) . [ 94 ] Ziad Obermeyer and Sendhil Mullainathan . 2019 . Dissecting Racial Bias in an Algorithm That Guides Health Decisions for 70 Million People . In Proceedings of the Conference on Fairness , Accountability , and Transparency . Association for Computing Machinery . [ 95 ] Yotam Ophir , Dror Walter , and Eleanor R Marchant . 2020 . A Collaborative Way of Knowing : Bridging Computational Communication Research and Grounded Theory Ethnography . Journal of Communication 70 , 3 ( June 2020 ) . [ 96 ] Will Orr and Jenny L . Davis . 2020 . Attributions of Ethical Responsibility by Artificial Intelligence Practitioners . Information Communication and Society 23 , 5 ( 2020 ) . [ 97 ] Britt S Paris . 2021 . Time Constructs : Design Ideology and a Future Internet . Time & Society 30 , 1 ( Feb . 2021 ) . [ 98 ] Fernando Perez and Brian E . Granger . 2007 . IPython : A System for Interactive Scientific Computing . Computing in Science & Engineering 9 , 3 ( 2007 ) . [ 99 ] JeffreyM . Perkel . 2018 . WhyJupyterIsDataScientistsâ€™ComputationalNotebook of Choice . Nature 563 , 7729 ( Nov . 2018 ) . [ 100 ] JoÃ£o Felipe Pimentel , Leonardo Murta , Vanessa Braganholo , and Juliana Freire . 2019 . A Large - Scale Study about Quality and Reproducibility of Jupyter Note - books . In 2019 IEEE / ACM 16th International Conference on Mining Software Repositories ( MSR ) . IEEE . [ 101 ] Jean Christophe Plantin and Gabriele de Seta . 2019 . WeChat as Infrastructure : The Techno - Nationalist Shaping of Chinese Digital Platforms . Chinese Journal of Communication 12 , 3 ( 2019 ) . [ 102 ] Jean - ChristophePlantin , CarlLagoze , andPaulNEdwards . 2018 . Re - Integrating Scholarly Infrastructure : The Ambiguous Role of Data Sharing Platforms . Big Data & Society 5 , 1 ( Jan . 2018 ) . [ 103 ] Jean Christophe Plantin , Carl Lagoze , Paul N . Edwards , and Christian Sandvig . 2018 . Infrastructure Studies Meet Platform Studies in the Age of Google and Facebook . New Media and Society 20 , 1 ( 2018 ) . [ 104 ] Jean Christophe Plantin and Aswin Punathambekar . 2019 . Digital media infras - tructures : pipes , platforms , and politics . Media , Culture and Society 41 , 2 ( 2019 ) , 163 â€“ 174 . AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman [ 105 ] Neoklis Polyzotis , Sudip Roy , Steven Euijong Whang , and Martin Zinkevich . 2017 . Data Management Challenges in Production Machine Learning . Proceed - ings of the ACM SIGMOD International Conference on Management of Data Part F1277 ( 2017 ) . [ 106 ] Neoklis Polyzotis , Sudip Roy , Steven Euijong Whang , and Martin Zinkevich . 2018 . Data Lifecycle Challenges in Production Machine Learning : A Survey . ACM SIGMOD Record 47 , 2 ( Dec . 2018 ) . [ 107 ] Kevin M . Quinn , Burt L . Monroe , Michael Colaresi , Michael H . Crespin , and Dragomir R . Radev . 2010 . How to Analyze Political Attention with Minimal Assumptions and Costs . American Journal of Political Science 54 , 1 ( Jan . 2010 ) . [ 108 ] Bogdana Rakova , Jingying Yang , Henriette Cramer , and Rumman Chowdhury . 2021 . Where Responsible AI Meets Reality : Practitioner Perspectives on En - ablers for Shifting Organizational Practices . Proceedings of the ACM on Human - Computer Interaction 5 , CSCW1 ( April 2021 ) . [ 109 ] Bernadette M . Randles , Irene V . Pasquetto , Milena S . Golshan , and Christine L . Borgman . 2017 . Using the Jupyter Notebook as a Tool for Open Science : An Empirical Study . In 2017 ACM / IEEE Joint Conference on Digital Libraries ( JCDL ) . IEEE . [ 110 ] Johan RedstrÃ¶m . 2005 . On Technology as Material in Design . Design Philosophy Papers 3 , 2 ( June 2005 ) . [ 111 ] Margaret E . Roberts , Brandon M . Stewart , and Edoardo M . Airoldi . 2016 . A Model of Text for Experimentation in the Social Sciences . J . Amer . Statist . Assoc . 111 , 515 ( July 2016 ) . [ 112 ] Margaret E . Roberts , Brandon M . Stewart , and Dustin Tingley . 2019 . Stm : An R Package for Structural Topic Models . Journal of Statistical Software 91 ( Oct . 2019 ) . [ 113 ] Margaret E . Roberts , Brandon M . Stewart , Dustin Tingley , and Edoardo M . Airoldi . 2013 . The Structural Topic Model and Applied Social Science . In Ad - vances in Neural Information Processing Systems Workshop on Topic Models : Computation , Application , and Evaluation , Vol . 4 . Harrahs and Harveys , Lake Tahoe . [ 114 ] Margaret E . Roberts , Brandon M . Stewart , Dustin Tingley , Christopher Lucas , Jetson Leder - Luis , Shana Kushner Gadarian , Bethany Albertson , and David G . Rand . 2014 . Structural Topic Models for Open - Ended Survey Responses . Ameri - can Journal of Political Science 58 , 4 ( 2014 ) . [ 115 ] Christoffer Rosen and Emad Shihab . 2016 . What Are Mobile Developers Ask - ing about ? A Large Scale Study Using Stack Overflow . Empirical Software Engineering 21 , 3 ( June 2016 ) . [ 116 ] JosephRouse . 2007 . PracticeTheory . In PhilosophyofAnthropologyandSociology . Elsevier . [ 117 ] Sebastian Ruder . 2017 . An Overview of Gradient Descent Optimization Algo - rithms . ( 2017 ) . arXiv : 1609 . 04747 [ cs . LG ] [ 118 ] Adam Rule , AurÃ©lien Tabard , and James D . Hollan . 2018 . Exploration and Expla - nation in Computational Notebooks . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . Association for Computing Machinery , New York , NY , USA . [ 119 ] Mark Ryan , Josephina Antoniou , Laurence Brooks , Tilimbe Jiya , Kevin Macnish , and Bernd Stahl . 2021 . Research and Practice of AI Ethics : A Case Study Ap - proach Juxtaposing Academic Discourse with Organisational Reality . Science and Engineering Ethics 27 , 2 ( 2021 ) . [ 120 ] JanaSchaichBorg . 2021 . FourInvestmentAreasforEthicalAI : Transdisciplinary Opportunities to Close the Publication - to - Practice Gap . Big Data & Society 8 , 2 ( July 2021 ) . [ 121 ] Daniel Schiff , Bogdana Rakova , Aladdin Ayesh , Anat Fanti , and Michael Lennon . 2021 . Explaining the Principles to Practices Gap in AI . IEEE Technology and Society Magazine 40 , 2 ( June 2021 ) . [ 122 ] Andrew D . Selbst , Danah Boyd , Sorelle A . Friedler , Suresh Venkatasubramanian , and Janet Vertesi . 2019 . Fairness and Abstraction in Sociotechnical Systems . In Proceedings of the Conference on Fairness , Accountability , and Transparency ( Atlanta , GA , USA ) ( FAT * â€™19 ) . AssociationforComputingMachinery , NewYork , NY , USA , 59 â€“ 68 . [ 123 ] Renee Shelby , Shalaleh Rismani , Kathryn Henne , Ajung Moon , Negar Ros - tamzadeh , Paul Nicholas , Nâ€™mah Yilla , Jess Gallegos , Andrew Smart , Emilio Garcia , and Gurleen Virk . 2022 . Sociotechnical Harms : Scoping a Taxonomy for Harm Reduction . ( Oct . 2022 ) . arXiv : 2210 . 05791 [ cs . HC ] [ 124 ] Elizabeth Shove . 2003 . Comfort , Cleanliness and Convenience : The Social Orga - nization of Normality . Berg . [ 125 ] Elizabeth Shove . 2016 . Matters of Practice . In The Nexus of Practices ( 1st ed . ) . Routledge . [ 126 ] Elizabeth Shove , Mika Pantzar , and Matt Watson . 2012 . The Dynamics of Social Practice : Everyday Life and How It Changes . SAGE , Los Angeles . [ 127 ] Antti Silvast and Mikko J . Virtanen . 2019 . An Assemblage of Framings and Tamings : Multi - Sited Analysis of Infrastructures as a Methodology . Journal of Cultural Economy 12 , 6 ( Nov . 2019 ) . [ 128 ] Mona Sloane and Janina Zakrzewski . 2022 . German AI Start - Ups and â€œAI Ethicsâ€ : Using A Social Practice Lens for Assessing and Implementing Socio - Technical Innovation . In 2022 ACM Conference on Fairness , Accountability , and Transparency . ACM , Seoul Republic of Korea . [ 129 ] Susan Leigh Star . 1989 . The Structure of Ill - Structured Solutions : Boundary ObjectsandHeterogeneousDistributedProblemSolving . In DistributedArtificial Intelligence . Elsevier . [ 130 ] Susan Leigh Star . 1999 . The Ethnography of Infrastructure . American behavioral scientist 43 , 3 ( 1999 ) . [ 131 ] Susan Leigh Star and Karen Ruhleder . 1996 . Steps Toward an Ecology of Infras - tructure : Design and Access for Large Information Spaces . Information Systems Research 7 , 1 ( March 1996 ) . [ 132 ] Shaheen Syed and Marco Spruit . 2017 . Full - Text or Abstract ? Examining Topic Coherence Scores Using Latent Dirichlet Allocation . In 2017 IEEE International Conference on Data Science and Advanced Analytics ( DSAA ) . IEEE . [ 133 ] Katarzyna Szymielewicz , Anna Bacciarelli , Fanny Hidvegi , Agata Foryciarz , Soizic PÃ©nicaud , and Matthias Spielkamp . 2020 . Where Do Algorithmic Ac - countability and Explainability Frameworks Take Us in the Real World ? From Theory to Practice . In Proceedings of the 2020 Conference on Fairness , Account - ability , and Transparency . Association for Computing Machinery . [ 134 ] Mohammad Tahaei , Kami Vaniea , and Naomi Saphra . 2020 . Understanding Privacy - Related Questions on Stack Overflow . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . [ 135 ] Chiin - Rui Tan . 2021 . The Nascent Case for Adopting Jupyter Notebooks as a Pedagogical Tool for Interdisciplinary Humanities , Social Science , and Arts Education . Computing in Science Engineering 23 , 2 ( March 2021 ) . [ 136 ] ChristophTreudeandMarkusWagner . 2019 . PredictingGoodConfigurationsfor GitHub and Stack Overflow Topic Models . In 2019 IEEE / ACM 16th International Conference on Mining Software Repositories ( MSR ) . IEEE , Montreal , QC , Canada . [ 137 ] Jasmin Troeger and Annekatrin Bock . 2022 . The Sociotechnical Walkthrough â€“ a Methodological Approach for Platform Studies . Studies in Communication Sciences 22 , 1 ( June 2022 ) . [ 138 ] MichelleUfford , MPacer , MathewSeal , andKyleKelley . 2018 . BeyondInteractive : Notebook Innovation at Netflix . [ 139 ] Ville Vakkuri , Kai - Kristian Kemell , Joni Kultanen , and Pekka Abrahamsson . 2020 . The Current State of Industrial Practice in Artificial Intelligence Ethics . IEEE Software 37 , 4 ( July 2020 ) . [ 140 ] Michael Veale and Reuben Binns . 2017 . Fairer Machine Learning in the Real World : Mitigating Discrimination without Collecting Sensitive Data . Big Data & Society 4 , 2 ( Dec . 2017 ) . [ 141 ] Michael Veale , Max Van Kleek , and Reuben Binns . 2018 . Fairness and Account - ability Design Needs for Algorithmic Support in High - Stakes Public Sector Decision - Making . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . ACM , New York , NY , USA . [ 142 ] Dror Walter and Yotam Ophir . 2019 . News Frame Analysis : An Inductive Mixed - method Computational Approach . Communication Methods and Measures 13 , 4 ( Oct . 2019 ) . [ 143 ] April Yi Wang , Anant Mittal , Christopher Brooks , and Steve Oney . 2019 . How Data Scientists Use Computational Notebooks for Real - Time Collaboration . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( Nov . 2019 ) . [ 144 ] Jiawei Wang , Li Li , and Andreas Zeller . 2020 . Better Code , Better Sharing : On the Need of Analyzing Jupyter Notebooks . In Proceedings of the ACM / IEEE 42nd International Conference on Software Engineering : New Ideas and Emerging Results . [ 145 ] Matt Watson and Elizabeth Shove . 2022 . How Infrastructures and Practices ShapeEachOther : Aggregation , IntegrationandtheIntroductionofGasCentral Heating . Sociological Research Online ( Jan . 2022 ) . [ 146 ] Lindsay Weinberg . 2022 . Rethinking Fairness : An Interdisciplinary Survey of CritiquesofHegemonicMLFairnessApproaches . JournalofArtificialIntelligence Research 74 ( May 2022 ) . [ 147 ] Ryan Wesslen . 2018 . Computer - Assisted Text Analysis for Social Science : Topic Models and Beyond . arXiv : 1803 . 11045 [ cs ] [ 148 ] LangdonWinner . 1980 . DoArtifactsHavePolitics ? In TheWhaleandtheReactor a Search for Limits in an Age of High Technology . Vol . 109 . The MIT Press . [ 149 ] Xin - Li Yang , David Lo , Xin Xia , Zhi - Yuan Wan , and Jian - Ling Sun . 2016 . What Security Questions Do Developers Ask ? A Large - Scale Study of Stack Overflow Posts . Journal of Computer Science and Technology 31 , 5 ( Sept . 2016 ) . [ 150 ] Amy X . Zhang , Michael Muller , and Dakuo Wang . 2020 . How Do Data Science Workers Collaborate ? Roles , Workflows , and Tools . Proceedings of the ACM on Human - Computer Interaction 4 , CSCW1 ( May 2020 ) . A LIST OF TAGS USED IN QUERY OF THE STACK EXCHANGE DATA DUMP Interactivecomputingplatformtags : colab , google - colaboratory , ipython , ipython - notebook , ipywidgets , jupyter , jupyter - lab , jupyter - notebook , jupyterhub , pyspark . Machine Learning tags : artificial - intelligence , backpropagation , Machine Learning practices and infrastructures AIES â€™23 , August , 2023 , Montreal , QC , Canada caffe , classification , cnn , computer - vision , conv - neural - network , convolutional - neural - network , deep - learning , feature - selection , image - processing , keras , lstm , machine - learning , machine - learning - model , neural - network , neural - networks , nlp , nltk , opencv , opti - mization , predictive - modelling , predictive - models , pytorch , random - forest , regression , scikit - learn , spacy , stanford - nlp , svm , tensorflow , tensorflow2 . 0 . B TOPIC MODEL VISUALISATIONS 10 15 20 25 30 35 40 45 50 55 60 9 . 4 9 . 5 9 . 6 9 . 7 9 . 8 âˆ’80 âˆ’70 âˆ’60 âˆ’50 Semantic coherence E xc l u s i v i t y Mean exclusivity vs . semantic coherence for trained models Figure 4 : Exclusivity vs Semantic Coherence for a range of models trained on the Machine Learning in interactive com - puting platforms dataset . Figure 5 : The 15 most frequently mentioned programming libraries imported in code snippets in questions about inter - active computing platforms and ML on the Stack Exchange forums . AIES â€™23 , August , 2023 , Montreal , QC , Canada Berman C REPRESENTATIVE QUESTIONS BY TOPIC CLUSTER Figure 6 : Most viewed questions : infra . & inter - dependencies cluster . Figure 7 : Most viewed questions : data manipulation cluster . Figure 8 : Most viewed questions : model training cluster .