Proceedings of the First Workshop on Abusive Language Online , pages 85 – 90 , Vancouver , Canada , July 30 - August 4 , 2017 . c (cid:13) 2017 Association for Computational Linguistics Using Convolutional Neural Networks to Classify Hate - Speech Björn Gambäck and Utpal Kumar Sikdar Department of Computer Science Norwegian University of Science and Technology NO – 7491 Trondheim , Norway gamback @ ntnu . no utpal . sikdar @ gmail . com Abstract The paper introduces a deep learning - based Twitter hate - speech text classiﬁca - tion system . The classiﬁer assigns each tweet to one of four predeﬁned categories : racism , sexism , both ( racism and sex - ism ) and non - hate - speech . Four Con - volutional Neural Network models were trained on resp . character 4 - grams , word vectors based on semantic information built using word2vec , randomly generated word vectors , and word vectors combined with character n - grams . The feature set was down - sized in the networks by max - pooling , and a softmax function used to classify tweets . Tested by 10 - fold cross - validation , the model based on word2vec embeddings performed best , with higher precision than recall , and a 78 . 3 % F - score . 1 Introduction During the Spring of 2017 , parliamentary commit - tees in Germany and the UK strongly criticised leading social media sites such as Facebook , Twit - ter and Youtube ( Google ) for failing to take sufﬁ - cient and quick enough action against hate - speech , with the German government threatening to ﬁne the social networks up to 50 million euros per year if they continue to fail to act on hateful postings ( and posters ) within a week ( Thomasson , 2017 ) . When called to witness in front of the UK Home Affairs Committee , all the social media companies refused to reveal both the number of people they employ to battle hate - speech and the amount they spend on this . However , Google claimed to have invested “hundreds of millions” while Facebook stated that they had thousands of people work - ing on the problem . The German government estimated that the companies combined already spend some 50 million euros per year and that the suggested new German law would increase that amount by 50 % ( CDU / CSU & SPD , 2017 , p . 14 ) . Regardless of the resources actually devoted by the social media networks , it is clear that their cur - rent efforts are not enough : “we are disappointed at the pace of development of technological so - lutions” ( Home Affairs Committee , 2017 , p . 24 ) . The UK and German governments also indicate that they are moving in the direction of treating online content providers in analogy with publish - ers of printed material , with the same obligations to abide to publishing laws . With legislation in other countries set to follow ( Nielsen , 2017 ) , properly identifying hate - speech is a pressing issue , not only for the major play - ers , but also for smaller companies , clubs , and or - ganisations that allow for user - generated content on their sites ( albeit the current German law pro - posal makes an exception for sites with less than 2 million users ) . Many such sites currently use slow , manual moderation , which mean that abu - sive posts will be left online for too long with - out appropriate action being taken or that content will be published with delay ( which might be un - acceptable to the users , e . g . , in online chat rooms ) . Following the work by Collobert et al . ( 2011 ) , deep neural networks have been shown to ef - fectively solve several language processing tasks such as part - of - speech tagging , sentiment analy - sis , and named entity recognition . Here a Convo - lutional Neural Network ( CNN ) model with var - ious features is utilised for hate - speech categori - sation . Word vectors based on semantic informa - tion are built for all tokens using an unsupervised learning algorithm , word2vec . The word vectors are merged with a set of extracted features , down - sized using max - pooling , and together with char - acter n - grams ( 4 - grams ) fed to the neural network model to predict the categories of each tweet . 85 The paper is organised as follows : Previous work on hate - speech identiﬁcation is discussed in Section 2 . Section 3 describes the deep learning - based hate - speech categorisation strategy , while experiments and results are reported in Section 4 . Finally , Section 5 summarises the discussion . 2 Related Work Although the above - noted law - maker interest in the issue is fairly recent , the task of identifying hate speech and abusive language in online content has already been topical in the research commu - nity for 20 years . Spertus ( 1997 ) built the decision tree - based classiﬁer ‘Smokey’ which utilised 47 syntactic and semantic sentential features . When trained on a small set of 720 web page posts man - ually annotated ( as “ﬂame” , “okay” or “maybe” ) and evaluated on 502 other messages , ‘Smokey’ performed well on classifying the non - inﬂamatory messages , but fell completely short on ﬂame texts ( thus obtaining an accuracy of only 88 . 2 % on a task with a majority - class baseline of 86 . 1 % ) . Addressing the dataset size problem , Sood et al . ( 2012 ) collected 1 . 6 million comments from a Ya - hoo ! social news site , of which 6 , 500 were ran - domly selected for annotation by 221 persons on Amazon Mechanical Turk ( AMT ) . Several Sup - port Vector Machine classiﬁers were trained on varying - size parts of this dataset using mainly word n - gram features , indicating that classiﬁca - tion performance kept improving with increased datasets , but not as rapidly after the data size had passed 1 , 500 items . Looking at another set of AMT - annotated Yahoo ! news posts , Nobata et al . ( 2016 ) experimented with several different word - internal , n - gram - based , syntactic , and distribu - tional semantic features , concluding that character n - grams alone contribute sufﬁciently strongly for an online gradient descent learner to perform well on this type of data . Moving away from features based solely on the language used in online messages , Chen et al . ( 2012 ) proposed a model also taking into account the posting patterns of the users in order to single out persons exhibiting abusive behaviour . Simi - larly , Buckels et al . ( 2014 ) aimed to extract traits from online user behaviour that would indicate an - tisocial personality . This is of particular impor - tance for swift moderation of online chat rooms , as addressed by , e . g . , Yin et al . ( 2009 ) and Papeg - nies et al . ( 2017 ) , with the latter suggesting several types of features ( at the morphological , syntactic and user behaviour levels ) that can be used for identifying when gamers on a French MMO ( mas - sively multiplayer online ) game site move from discussing game - related issues to posting personal inﬂammatory remarks . Of particular relevance to the present work are previous efforts on identifying abusive language on Twitter . Xiang et al . ( 2012 ) created offensive - language topic clusters using Logistic Regres - sion over a set of 860 , 071 tweets automatically annotated using a boot - strapping technique and supplemented with a dictionary of 339 offensive words . When tested on 4 , 029 randomly selected tweets collected just after the training set , the lexicon - enhanced clustering outperformed a key - word matching baseline . Logistic Regression and a dictionary was also utilised by Davidson et al . ( 2017 ) ; however , they used crowd - sourcing to cre - ate their hate - speech dictionary and aimed to sepa - rate the tweets into three classes : hate - speech , of - fensive language , and neither . Working on a set of 24 , 802 manually labelled tweets , they achieved good recall and precision overall , but noted that almost 40 % of the actual hate - speech tweets were misclassiﬁed , although with 3 / 4 of those being mistaken for offensive language only . A recurring problem with several of these ex - periments has been that the annotated datasets have not always been made publically available . However , Ross et al . ( 2016 ) had a set of 541 Ger - man tweets annotated , in particular addressing the issues of annotator and annotation reliability , and what information should be provided to the an - notators . Waseem ( 2016 ) discusses similar issues while providing a set of 6 , 909 English tweets hate - speech annotated by CrowdFlower users , 1 and extending a previous such dataset ( Waseem and Hovy , 2016 ) . This dataset will be used in the ex - periments reported below . Wulczyn et al . ( 2016 ) also used CrowdFlower to obtain human annotations of 115 , 737 comments on Wikipedia as to whether they contained per - sonal attacks and harassment . They furthermore experimented with strategies to automatically ex - pand the dataset , comparing Multi - Layer Percep - trons ( a single - hidden - layer neural network ) to Logistic Regression , and word n - grams to charac - ter n - grams ; concluding the Logistic Regression with character n - grams performed best . 1 https : / / www . crowdflower . com / 86 Figure 1 : Hate - speech classiﬁer 3 CNN - based Hate - Speech Classiﬁcation This section describes the hate - speech identiﬁca - tion system architecture based on Convolutional Neural Networks ( CNN ) . An overview of the sys - tem is shown in Figure 1 . The ﬁrst step of the system is to generate feature embeddings . Feature embeddings for all words were constructed by us - ing word embeddings and character n - grams . The word embeddings were generated in two ways , through word2vec ( Mikolov et al . , 2013a , b ) and through random vectors . In the random vec - tor setting , all the words in the corpora are ini - tialised with random values . In the word2vec version , word vectors are generated based on the context . There are two types of such embed - dings : continuous - bags - of - words ( CBOW ) and skip - gram models . In the CBOW architecture , the model predicts the current word from a window of surrounding context words . In the skip - gram model , the context words are predicted using the current word . In addition to the word embeddings , length 28 one - hot character n - gram vectors were generated , with 26 elements for the English alphabet , one for digits , and one for all other characters / symbols . The feature embeddings were produced by con - catenating the word embeddings with these char - acter n - gram vectors . A pooling layer in the network converts each tweet into a ﬁxed length vector , capturing the in - formation from the entire tweet . A max - pooling layer then captures the most important latent se - mantic factors from the tweets . On the output side , a softmax layer calculates the class probability distributions for each tweet and assigns the hate - speech classes / labels based on the probability values . 4 Experiments Four approaches to hate - speech classiﬁcation were tested , based on different feature embeddings . All models were applied to the English Twitter hate - speech dataset created by Waseem ( 2016 ) . 2 Each tweet in the dataset has been annotated by one Ex - pert annotator and three Amateur annotators , with four labels : non - hate - speech ( 84 % of the data ) , racism , sexism , and both ( i . e . , racism and sexism ) . Waseem ( 2016 ) deﬁned the “Expert” annota - tors as those having both a theoretical and ap - plied knowledge of hate speech ( those were re - cruited among feminist and antiracism activists ) , while the “Amateur” annotations were obtained by crowd - sourcing ( on the CrowdFlower platform ) . We combined the annotated tags for each tweet based on majority voting , where the Expert was given double unit votes and each of the Amateurs was given a single unit vote . The class distributions of the dataset are shown in Table 1 . The total size of the dataset ( 6 , 655 tweets ) is slightly lower than the original set ( Waseem reported it as containing 6 , 909 tweets ) , since some of the annotated tweets were unavail - able or had been deleted . Data Number of tweets Racism 91 Sexism 946 Both ( racism & sexism ) 18 Non - hate - speech 5600 Total 6655 Table 1 : Twitter hate - speech dataset statistics 2 http : / / github . com / zeerakw / hatespeech 87 System setup Precision Recall F 1 - score C NN Random vectors 0 . 8668 0 . 6726 0 . 7563 word2vec 0 . 8566 0 . 7214 0 . 7829 Character n - grams 0 . 8557 0 . 7011 0 . 7695 word2vec + character n - grams 0 . 8661 0 . 7042 0 . 7738 Logistic Regression with character n - grams 0 . 7287 0 . 7775 0 . 7389 ( Waseem and Hovy , 2016 ) Table 2 : System performance ( 10 - fold cross - validated ) 4 . 1 Results The average 10 - fold cross - validated results for all four Convolutional Neural Network ( CNN ) models are shown in Table 2 , and compared to the Logistic Regression ( LogReg ) model used by Waseem and Hovy ( 2016 ) . In the ﬁrst CNN model , random word vec - tors were considered as feature embeddings when training the network . This baseline model achieved precision , recall and F - score values of 86 . 68 % , 67 . 26 % and 75 . 63 % , respectively , mark - ing a drastic improvement in precision compared to the LogReg model , but at the expense of lower recall . In the second approach , word2vec word vectors were taken as feature embeddings to learn the CNN model , resulting in clearly ( 7 . 3 % ) im - proved recall , for an F - score of 78 . 29 % , even though the precision actually was slightly reduced compared to using the random vectors . The third and fourth models both added charac - ter n - grams to the input of the CNN model . In line with the experiments reported on the same dataset by Waseem and Hovy ( 2016 ) , length 4 character n - grams were used . In the third model , only the character n - gram were considered as fea - ture embeddings when training the CNN model , while in the fourth model , the feature embeddings were generated by concatenating word2vec word embeddings and character n - grams . Tested by 10 - fold cross - validation , the latter system showed better precision ( 86 . 61 % ) than recall ( 70 . 42 % ) , for an F - score of 77 . 38 % . However , although the character n - grams thus helped a little in improving precision , the word2vec model without character n - grams still achieved the best results of all the compared mod - els , with the precision , recall and F - score values of 85 . 66 % , 72 . 14 % and 78 . 29 % , respectively . Note that all CNN models convincingly outperformed Logistic Regression in terms of both precision and F 1 - score , while the LogReg model achieved better recall than all the neural network models . 4 . 2 Error Analysis An error analysis was carried out for each of the 10 folds . The confusion matrices are shown in Ta - ble 3 . It can be observed that the model overall did not identify many tweets as hate - speech tweets . This may be due to insufﬁcient training instances . Furthermore , the system wrongly identiﬁed some non - hate - speech tweets as hate - speech . In particular , the system was not able to identify properly the category ‘both’ , since the examples of this category are very few ( 1 or 2 per fold ) with respect to the whole set of training instances . The system performed better in the ‘sexism’ category than in the other hate - speech categories ( ‘both’ and ‘racism’ ) because the number of tweets of this category are larger . 5 Conclusion and Future Work Here we have experimented with a system for Twitter hate - speech text classiﬁcation based on a deep - learning , Convolutional Neural Network model . The classiﬁer assigns each tweet to one of four predeﬁned categories : racism , sexism , both ( racism and sexism ) and neither . Two CNN models were created based on dif - ferent input vectors sets that were fed to the neural networks for training and classiﬁcation . Word vec - tors based on semantic information were built us - ing an unsupervised strategy , word2vec , and com - pared to a randomly generated vector baseline . In additional , two CNN models were trained on char - acter 4 - grams , as well as on a combination of word vectors and character n - grams . The feature set is down - sized in the networks by a max - pooling layer , while a softmax layer is utilised to assign the tweets their most probable label category . 88 True CNN Fold - 1 Fold - 2 Fold - 3 Fold - 4 Fold - 5 b s r n b s r n b s r n b s r n b s r n both 0 0 0 1 0 2 0 0 0 0 0 1 1 1 0 0 0 1 0 0 sexism 1 70 0 25 0 71 0 20 0 78 0 19 0 82 0 18 0 69 0 23 racism 0 0 5 6 0 0 0 6 0 0 2 8 0 0 5 7 0 0 1 8 neither 0 13 1 543 0 15 4 547 0 11 2 544 0 11 3 537 0 13 0 550 Fold - 6 Fold - 7 Fold - 8 Fold - 9 Fold - 10 both 1 1 0 0 0 1 0 0 0 1 0 0 0 2 0 1 1 3 0 0 sexism 0 66 0 17 0 72 0 18 0 80 0 33 0 70 0 26 0 70 0 18 racism 0 0 3 1 0 0 1 3 0 0 6 9 0 0 1 9 0 0 6 4 neither 0 9 4 563 0 10 0 560 0 7 2 527 0 16 0 540 0 6 0 562 Table 3 : Confusion matrices for each fold , with rows showing the true labels and columns system outputs . Legend : ‘b’ = both , ‘s’ = sexism , ‘r’ = racism and ‘n’ = neither . Trained and tested by 10 - fold cross - validation , the system based on word2vec word vectors per - formed best overall , with an F 1 - score of 78 . 3 % . Adding character n - grams slightly increased the precision , but resulted in lower recall and F - score . The tested models and neural network archi - tectures could be extended in several ways : The word2vec embeddings used here were built on skip - grams that predict the context words using the current word . An alternative would be to use continuous - bags - of - words that basically do the opposite and predict the current word from a window of surrounding context words . Also , fol - lowing Waseem and Hovy ( 2016 ) only length 4 character n - grams were used . Clearly it would be interesting to explore whether these are uniformly ineffective when changing the n - gram size . The experiments reported here were carried out on a convolutional network architecture , but other types of deep neural networks could obviously be tried . In particular , the bi - directional Long Short - Term Memory ( LSTM ) recurrent neural network architecture has shown itself to be useful to lan - guage processing problems where utilising the se - quential nature of the input is more essential , such as named entity recognition and sentiment analy - sis , although most of the best performing systems in SemEval 2016 ( the International Workshop on Semantic Evaluation ; Task 4 : Sentiment Analysis in Twitter ) actually utilised convolutional neural networks or combinations of CNNs and other ap - proaches ( Nakov et al . , 2016 ) . A long those lines , Sikdar and Gambäck ( 2017 ) report experiments with a set - up for named entity recognition combining an LSTM with a more tra - ditional machine learning classiﬁer based on Con - ditional Random Fields ( CRF ) . Such an approach could be tested also for the abusive language clas - siﬁcation task , either using the LSTM / CRF com - bination or including CNN . Acknowledgments The work reported here was carried out within the CZ09 Czech - Norwegian Research Programme un - der Project Contract 7F14047 , HaBiT ( “Harvest - ing big text data for under - resourced languages” ; http : / / www . habit - project . eu ) funded by the Research Council of Norway ( NFR ) and the Czech Republic’s Ministry of Education , Youth and Sports ( MŠMT ) through the EEA / Norway Fi - nancial Mechanism . Thanks to the four anonymous reviewers for comments that helped improve the paper . References Erin E . Buckels , Paul D . Trapnell , and Delroy L . Paul - hus . 2014 . Trolls just want to have fun . Personality and Individual Differences 67 : 97 – 102 . CDU / CSU & SPD . 2017 . Gesetzentwurf der Frak - tionen der CDU / CSU und SPD : Entwurf eines Gesetzes zur Verbesserung der Rechtsdurchsetzung in sozialen Netzwerken ( Netzwerkdurchsetzungs - gesetz — NetzDG ) . Drs . 18 / 12356 , Deutscher Bundestag , Berlin , Germany . Ying Chen , Yilu Zhou , Sencun Zhu , and Heng Xu . 2012 . Detecting offensive language in social me - dia to protect adolescent online safety . In Proceed - ings of the 2012 ASE / IEEE International Confer - ence on Social Computing and 2012 ASE / IEEE In - ternational Conference on Privacy , Security , Risk and Trust . IEEE Computer Society , Amsterdam , The Netherlands , pages 71 – 80 . Ronan Collobert , Jason Weston , Léon Bottou , Michael Karlen , Koray Kavukcuoglu , and Pavel Kuksa . 2011 . Natural language processing ( almost ) from 89 scratch . Journal of Machine Learning Research 12 : 2493 – 2537 . Thomas Davidson , Dana Warmsley , Michael Macy , and Ingmar Weber . 2017 . Automated hate speech detection and the problem of offensive language . In Proceedings of the International AAAI Confer - ence on Web and Social Media ( ICWSM ) . Ameri - can Association for Artiﬁcial Intelligence , Toronto , Canada . To appear . Home Affairs Committee . 2017 . Hate crime : abuse , hate and extremism online . Fourteenth Report of Session 2016 – 17 HC 609 , House of Commons , Lon - don , UK . Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean . 2013a . Efﬁcient estimation of word represen - tations in vector space . CoRR abs / 1301 . 3781 . Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg Cor - rado , and Jeffrey Dean . 2013b . Distributed repre - sentations of words and phrases and their composi - tionality . In Advances in Neural Information Pro - cessing Systems 26 ( NIPS 2013 ) . Curran Associates , Red Hook , NY , USA , pages 3111 – 3119 . Preslav Nakov , Alan Ritter , Sara Rosenthal , Fabrizio Sebastiani , and Veselin Stoyanov . 2016 . SemEval - 2016 Task 4 : Sentiment analysis in Twitter . In Pro - ceedings of the 10th International Workshop on Se - mantic Evaluation . ACL , San Diego , California . Nikolaj Nielsen . 2017 . EU states back bill against on - line hate speech . EUobserver , May 24 . https : / / euobserver . com / justice / 138009 . Chikashi Nobata , Joel Tetreault , Achint Thomas , Yashar Mehdad , and Yi Chang . 2016 . Abusive lan - guage detection in online user content . In Proceed - ings of the 25th International Conference on World Wide Web . International World Wide Web Confer - ences Steering Committee , Montreal , Canada , pages 145 – 153 . Etienne Papegnies , Vincent Labatut , Richard Dufour , and Georges Linarès . 2017 . Impact of content features for automatic online abuse detection . In Alexander Gelbukh , editor , Computational Linguis - tics and Intelligent Text Processing : Proceedings of the 18th International Conference . Springer , Bu - dapest , Hungary . Björn Ross , Michael Rist , Guillermo Carbonell , Ben - jamin Cabrera , Nils Kurowsky , and Michael Wo - jatzki . 2016 . Measuring the reliability of hate speech annotations : The case of the European refugee crisis . In 3rd Workshop on Natural Lan - guage Processing for Computer - Mediated Commu - nication . Bochum , Germany , pages 6 – 9 . Utpal Kumar Sikdar and Björn Gambäck . 2017 . Named entity recognition for Amharic using stack - based deep learning . In Alexander Gelbukh , editor , Computational Linguistics and Intelligent Text Pro - cessing : Proceedings of the 18th International Con - ference . Springer , Budapest , Hungary . Sara Owsley Sood , Elizabeth F . Churchill , and Judd Antin . 2012 . Automatic identiﬁcation of personal insults on social news sites . Journal of the Ameri - can Society for Information Science and Technology 63 ( 2 ) : 270 – 285 . Ellen Spertus . 1997 . Smokey : Automatic recognition of hostile messages . In Proceedings of the 14th Na - tional Conference on Artiﬁcial Intelligence and 9th Conference on Innovative Applications of Artiﬁcial Intelligence . American Association for Artiﬁcial In - telligence , Providence , Rhode Island , pages 1058 – 1065 . Emma Thomasson . 2017 . German cabinet agrees to ﬁne social media over hate speech . Reuters , Apr 5 . http : / / uk . reuters . com / article / idUKKBN1771FK . Zeerak Waseem . 2016 . Are you a racist or am i seeing things ? Annotator inﬂuence on hate speech detec - tion on Twitter . In Proceedings of 2016 EMNLP Workshop on Natural Language Processing and Computational Social Science . ACL , Austin , Texas , pages 138 – 142 . Zeerak Waseem and Dirk Hovy . 2016 . Hateful sym - bols or hateful people ? Predictive features for hate speech detection on Twitter . In Proceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Lin - guistics : Human Language Technologies . ACL , San Diego , California , pages 88 – 93 . Ellery Wulczyn , Nithum Thain , and Lucas Dixon . 2016 . Ex Machina : Personal attacks seen at scale . CoRR abs / 1610 . 08914 . Guang Xiang , Bin Fan , Ling Wang , Jason I . Hong , and Carolyn P . Rose . 2012 . Detecting offensive tweets via topical feature discovery over a large scale Twit - ter corpus . In Proceedings of the 21st ACM Inter - national Conference on Information and Knowledge Management . ACM , Maui , Hawaii , pages 1980 – 1984 . Dawei Yin , Zhenzhen Xue , Liangjie Hong , Brian D . Davison , April Kontostathis , and Lynne Edwards . 2009 . Detection of harassment on Web 2 . 0 . In Proceedings of the Content Analysis in the WEB 2 . 0 Workshop at WWW2009 . Madrid , Spain . 90