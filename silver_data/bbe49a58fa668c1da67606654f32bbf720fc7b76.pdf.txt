Automatic analysis of artistic paintings using information - based measures Jorge Miguel Silva a , b , ∗ , Diogo Pratas a , b , c , Rui Antunes a , b , S´ergio Matos a , b , Armando J . Pinho a , b a Institute of Electronics and Informatics Engineering of Aveiro , University of Aveiro , Portugal b Department of Electronics , Telecomunications and Informatics , University of Aveiro , Portugal c Department of Virology , University of Helsinki , Finland Abstract The artistic community is increasingly relying on automatic computational analysis for authentication and classiﬁca - tion of artistic paintings . In this paper , we identify hidden patterns and relationships present in artistic paintings by analysing their complexity , a measure that quantiﬁes the sum of characteristics of an object . Speciﬁcally , we apply Normalized Compression ( NC ) and the Block Decomposition Method ( BDM ) to a dataset of 4 , 266 paintings from 91 authors and examine the potential of these information - based measures as descriptors of artistic paintings . Both mea - sures consistently described the equivalent types of paintings , authors , and artistic movements . Moreover , combining the NC with a measure of the roughness of the paintings creates an e ﬃ cient stylistic descriptor . Furthermore , by quantifying the local information of each painting , we deﬁne a ﬁngerprint that describes critical information regard - ing the artists’ style , their artistic inﬂuences , and shared techniques . More fundamentally , this information describes how each author typically composes and distributes the elements across the canvas and , therefore , how their work is perceived . Finally , we demonstrate that regional complexity and two - point height di ﬀ erence correlation function are useful auxiliary features that improve current methodologies in style and author classiﬁcation of artistic paintings . The whole study is supported by an extensive website ( http : / / panther . web . ua . pt ) for fast author characterization and authentication . Keywords : Image Analysis , Data Compression , BDM , Artistic Paintings , Algorithmic Information Theory Introduction Artistic paintings are concrete visual expressions of human evolution and creativity to share emotions , values , visions , beliefs , and trends of history and culture . The creation , interpretation , and analysis of artistic paintings are social , contextual , subjective , passive , and , beyond superﬁcial characteristics , complex to compute and automatize [ 1 ] . In particular , it is theorized that art is an output of social agents , particularly a human experience , that can only be imitated by machines [ 2 ] . One of the non - trivial characteristic analysis of artistic paintings is related to the process of measuring the infor - mation contained in those paintings . Artistic paintings contain information related to schools , periods , and artists [ 3 ] . The artistic community widely uses automatic computational analysis of artistic paintings for authentication of artis - tic paintings [ 4 , 5 ] . Currently , this process does not substitute human experts completely ; however , it is an essential additional control for fraud and mislead detections [ 6 ] . Furthermore , applying new techniques and pre - existing ones that are new to the ﬁeld , can be useful not only for authorship attribution and fraud detection but also for art style categorization and organization , and even for art content explanation . In this paper , we introduce novel solutions for automatic computational analysis of artistic paintings and for the problem of artist authentication . When addressing artist authentication , several questions arise : What deﬁnes a painter’s style ? How does the author expose information ? How does the author di ﬀ ers and relates to other artists ? Furthermore , taking inspiration from information theory : How do we best quantify information in a painting ? How is ∗ Corresponding author Email address : jorge . miguel . ferreira . silva @ ua . pt ( Jorge Miguel Silva ) Preprint submitted to Pattern Recognition February 4 , 2021 a r X i v : 2102 . 01767v1 [ c s . C V ] 2 F e b 2021 the information utilized across the canvas ? Moreover , what can information quantiﬁcation tell us about the author’s style , way of painting , and relationships with other authors ? These complex questions are at the core of this paper’s development , where we describe and compare solutions for unsupervised measures of probabilistic and algorithmic information in images ( 2D ) of artistic paintings . Our contributions are as follows : • We perform a direct comparison between state - of - the - art unsupervised probabilistic and algorithmic informa - tion measures to specify each measure’s strengths and weaknesses . • We show that hidden patterns and relationships present in artistic paintings can be identiﬁed by analysing their complexity . • We show an e ﬃ cient stylistic descriptor by combining the Normalized Compression and a measure of the paintings’ roughness . • We propose a new descriptor of the artists’ style , artistic inﬂuences , and shared techniques . • We show that average local complexity describes how each author typically composes and distributes the ele - ments across the canvas and , therefore , how their work is perceived . • We demonstrate that these measures can serve as useful auxiliary features capable of improving current method - ologies in the classiﬁcation of artistic paintings . To explain how we achieve this , we ﬁrst compare the Normalized Compression ( NC ) , employing a data compres - sion tool chosen after a competitive benchmark , with the Block Decomposition Method ( BDM ) [ 7 ] , and the inherent Coding Theorem Method ( CTM ) measures [ 8 , 9 ] . The BDM is an information - based measure that uses small Turing machines to approximate the algorithmic information , approximating to the Shannon entropy as a fallback mecha - nism . After this comparison , we make use of the average NC of each artist together with the roughness exponent α of the two - point height di ﬀ erence correlation function ( HDC ) , to group artists by style . Furthermore , we provide a local complexity matrix that characterizes each artist using the NC and use it to construct a phylogenetic tree that portraits the relationship between artists in terms of exposing information to the observer . Finally , we use the regional complexity ﬁngerprints and the roughness exponent α as useful auxiliary features that , combined with state - of - the - art approaches , improve the results of style and artist classiﬁcation tasks . The remaining of this paper is organized as follows . In the next section , we describe related work , followed by a description of the methods . We present the major results in the next section , with further results presented in Supplementary Material . Finally , we discuss the results obtained , draw ﬁnal conclusions , and point out possible future lines of work . Related Work Measuring the information contained in paintings requires fast , e ﬃ cient , and automatic computation due to the diversity and large quantity of the existing artistic paintings [ 10 ] . To measure the information ( or complexity ) con - tained in paintings , we ﬁrst need to deﬁne what is the quantity of information of an image . We deﬁne the quantity of information of an image as the smallest number of bits required by a model to represent an image losslessly . To perform this task , the model searches for unknown patterns of similarity between sub - regions of the image [ 11 , 12 , 13 ] and uses this information to create this compressed representation of the image , relying exclusively in the patterns of the two - dimensional pixels without using exogenous information . There are several approaches to quantify the amount of information . Kolmogorov described three , namely com - binatorial [ 14 , 15 , 16 ] , probabilistic [ 17 ] , and algorithmic [ 18 ] . Independently , the works of Solomono ﬀ [ 19 , 20 ] and Chaitin [ 21 ] addressed the same lines . While the Kolmogorov complexity is non - computable , it can be approximated with programs for such purpose , such as data compressors , using probabilistic and algorithmic schemes . Practical applications to approximate the Kolmogorov complexity for multiple dimensional digital objects have been developed using Turing machines [ 7 , 22 , 23 , 9 ] and data compressors [ 24 , 25 , 26 , 27 , 28 , 29 ] . Recently , Zenil et 2 al . have shown that this methodology has a closer connection to algorithmic information than other measures based on statistical regularities [ 7 ] , namely fast lossless compression methods , for sources that follow algorithmic schemes . The majority of the lossless compression algorithms are limited to ﬁnding simple statistical regularities as they have been designed for fast storage reduction [ 30 , 31 ] ; accordingly , they provide slight improvements over the Shan - non entropy [ 17 ] . However , there are several which are designed for e ﬃ cient compression at the expense of more computational resources . For example , lossless compression algorithms , such as GeCo [ 32 ] , are hybrids between probabilistic and algorithmic schemes . Besides having several context models of di ﬀ erent orders , GeCo uses sub - programs that allow substitution [ 33 ] and reverse complement modeling [ 34 ] . These last two are sub - programs of probabilistic and algorithmic information nature . Another example is PAQ8 [ 35 ] , a general - purpose compressor that combines multiple context models using a neural network , transform functions , secondary structure predictors , and other simple sub - programs . Usually , the problem is how to ﬁnd fast and e ﬃ cient algorithmic models for data compres - sion . Lossless data compressors are tightly related to the concept of minimal description length [ 36 ] and algorithmic probability [ 37 , 25 , 38 ] . Therefore , representative algorithms can be e ﬃ ciently embedded in these data compressors , including small Turing machines . The idea of automatic computational analysis of artistic paintings is mature [ 4 , 5 ] , and the artistic community has widely relied on it for authentication of artistic paintings . Speciﬁcally , the characteristics of artistic paintings have been analysed through several statistical techniques and properties , namely fractal [ 39 ] , wavelet - based [ 4 ] , hidden Markov models [ 40 , 41 ] , Fisher kernel based [ 42 ] , sparse coding model [ 43 , 44 ] , color and brightness [ 5 ] , illumination [ 45 ] , stroke [ 46 , 47 ] , Print Index [ 48 ] , and entropy - based analysis [ 49 , 50 ] . Recently , the work of Machado and Lopes [ 50 ] , using fractional calculus , showed the potentiality of measures based on entropy to describe hierarchical clustering of paintings and their correlation with artistic movements . Regarding style and author classiﬁcation , several recent works have proposed the usage of Convolutional Neural Networks ( CNNs ) . A straightforward approach is to combine features extracted from multiple CNN layers , such as proposed by Peng et al . [ 51 ] . Another more e ﬀ ective approach is based on representing images by the principal com - ponents of a Gram matrix that captures correlations across the di ﬀ erent feature maps obtained from a convolutional layer of a pretrained deep CNN , such as VGG16 or VGG19 . Mao et al . [ 52 ] combine this representation with the features from all the ﬁve convolutional blocks of the VGG16 , learning a joint representation that can simultaneously capture content and style of visual arts . On the other hand , Chu et al . [ 53 ] apply a support vector machine ( SVM ) to the Gram representation to perform author and style classiﬁcation . Then , they improve the results by automatically learning correlations between feature maps . Methods In this section , we describe the measures used , their normalizations , the methodology , and the compression bench - mark performed . 0 . 1 . Information - based measures Algorithmic information [ 19 , 20 , 18 , 21 ] di ﬀ ers from a perspective of pure probabilistic information [ 17 ] because it considers that the source , rather than generating symbols from a probabilistic ergodic function , creates structures that represent algorithmic schemes [ 54 , 55 ] . Therefore , to reverse the problem , there is the need to identify the program ( s ) and parameter ( s ) that generate the outcome ( s ) [ 18 , 21 , 38 ] . However , the algorithmic information , K ( x ) , is non - computable [ 56 ] , mostly because of the halting problem [ 57 ] . Therefore , we have to rely on approximations . Namely , in this subsection , we describe the Normalized Compression and two BDM normalizations . Then , we establish the local application of the Normalized Compression to create a complexity matrix for each author and the methods used to create a distance matrix and the phylogenetic tree . Finally , we describe a non - information - based measure , the two - point height di ﬀ erence correlation function . Normalized Compression ( NC ) An e ﬃ cient compressor , C ( x ) , gives a possible approximation for the Kolmogorov complexity ( K ( x ) ) , where K ( x ) < C ( x ) ≤ | x | ( | x | is the length of string x in the appropriate scale ) . Usually , an e ﬃ cient data compressor is a program that approximates both probabilistic and algorithmic sources using a ﬀ ordable computational resources ( Time 3 and RAM ) . Although the algorithmic nature may be more complex to model , data compressors may have embedded sub - programs to handle this nature . For a deﬁnition of safe approximation , see [ 58 ] . The normalized version , known as the Normalized Compression ( NC ) , is deﬁned by NC ( x ) = C ( x ) | x | log 2 | A | = C ( x ) | x | , ( 1 ) where x is a string , C ( x ) is the compressed size of x in bits , | A | the number of di ﬀ erent elements in x ( size of the alphabet ) and | x | the length of x . Since we consider a binary matrix of each image , | A | = 2 , log 2 2 = 1 . Given the normalization , the NC enables to compare the information contained in the strings independently from their sizes [ 29 ] . If the compressor is e ﬃ cient , then the compressor can approximate the quantity of probabilistic - algorithmic information in data using a ﬀ ordable computational resources . Normalized Block Decomposition Method ( NBDM ) Another possible approximation to the Kolmogorov complexity is given by the use of small Turing machines , where these small computer programs approximate the components of a broader representation . The Coding Theo - rem Method uses the algorithmic probability between a string’s production frequency from a random program and its algorithmic complexity . As such , the more frequent a string is , the lower Kolmogorov complexity it has ; and strings of lower frequency have higher Kolmogorov complexity . The Block Decomposition Method ( BDM ) extends the power of a CTM , approximating local estimations of algorithmic information based on Solomono ﬀ - Levin’s al - gorithmic probability theory . In practice , it approximates the algorithmic information and , when it loses accuracy , it approximates the Shannon entropy . Since in this article we intend to perform a direct comparison of both measures , we ﬁrst considered the normalization of the BDM ( NBDM 1 ) , given by the number of elements ( length ) of the digital object as NBDM 1 ( x ) = BDM ( x ) | x | log 2 | A | = BDM ( x ) | x | . ( 2 ) However , the normalization of the BDM is usually performed using a minimum complexity object ( BDM Min ) and a maximum complexity object ( BDM Max ) . A minimum complexity object is ﬁlled with only one symbol , like a binary string of only zeros . In contrast , a maximum complexity object is an object that , when decomposed ( by a given decomposition algorithm ) , yields slices that cover the highest CTM values and are repeated only after all possible slices of a given shape have been used once . Using these two objects , the NBDM 2 for a given string can be computed as NBDM 2 ( x ) = BDM ( x ) − BDM Min BDM Max − BDM Min , ( 3 ) where BDM ( x ) is the BDM value of that string , BDM Min is the minimum complexity object , and BDM Max is the maximum complexity object . Kolmogorov complexity is invariant only up to a constant factor , which depends on the choice of a description language K = K (cid:48) + L , where K is the total complexity , K (cid:48) is the description of the object and L is the description of the language . As such , by performing the normalization according to Equation 3 , the normalization is aiming to remove the constant factor as K − K Min K Max − K Min = K (cid:48) + L − K (cid:48) Min − L K (cid:48) Max + L − K (cid:48) Min − L = K (cid:48) − K (cid:48) Min K (cid:48) Max − K (cid:48) Min , ( 4 ) where K Max and K Min are the maximum and minimum Kolmogorov complexity objects and K (cid:48) Max and K (cid:48) Min are the maximum and minimum Kolmogorov complexity description of the objects . In this article , we perform a direct comparison between the NC and the NBDM 1 . Furthermore , we compare the two types of BDM normalization and their impact on the results . 4 Local complexity analysis using the Normalized Compression The Normalized Compression ( NC ) was used to approximate the local ( or regional ) complexity of images of artistic paintings . To that end , all of the dataset images were divided into 16x16 blocks ( 256 equal regions ) and the NC was computed for each block , generating a complexity matrix . Other patch sizes were also tested , speciﬁcally patch sizes of 8x8 and 32x32 blocks . Following this operation , the average complexity matrix was generated for each author , using the complexity matrices of their paintings . The average complexity matrices were then used to obtain a similarity matrix , in which the distance between matrices was determined as d ( A , B ) = n (cid:88) i = 0 n (cid:88) j = 0 | a ij − b ij | , ( 5 ) where d is the distance between the complexity matrix A and B , and a ij and b ij are the complexity values at the index i and j of matrices A and B , respectively . Subsequently , using the similarity matrix , a phylogenetic tree was computed recurring to two methods , namely UPGMA ( unweighted pair group method with arithmetic mean ) [ 59 ] and the Kruskal minimum spanning tree algorithm [ 60 ] , in order to portrait complexity relationships among di ﬀ erent authors . 0 . 2 . Two - point height di ﬀ erence correlation function The two - point height di ﬀ erence correlation ( HDC ) function was computed to quantify brightness contrast as HDC ( r ) = [ h ( (cid:126) x + (cid:126) r ) − h ( (cid:126) x ) ] 2 = 1 N r (cid:88) (cid:126) x , | (cid:126) r | = r [ h ( (cid:126) x + (cid:126) r ) − h ( (cid:126) x ) ] 2 , ( 6 ) where the r is the distance between two - pixel points , over - bar represents the spatial average at a ﬁxed distance r for all possible points ; N r is the number of possible pairs at a distance r , h ( x ) is pixel intensity at the position x . Using the HDC function , its roughness exponent α was determined as α = log 10 ( HDC ( r final ) ) − log 10 ( HDC ( r initial ) ) log 10 ( r final ) − log 10 ( r initial ) , ( 7 ) where ( α ) is the slope of the HDC curve in a double logarithmic plot of the surface growth model . The slope was calculated from r initial = 10 to r final , which matches the point where the HDC function saturates , approximately 30 % of the image’s width . Assessment pipeline In order to fairly evaluate the information - based measures , we designed a pipeline for processing images . It respects the following steps : Obtaining the dataset images ; converting the images to PGM format ; quantization of the images to 8 bits ( 256 levels ) using the Lloyd - Max algorithm ; binarization of the images ( conversion to 01 format in ASCII ) and ﬁnally , applying the information - based measurements ( NC , NBDM 1 and NBDM 2 ) . Quantization was performed using the Lloyd - Max algorithm [ 61 , 62 ] since reducing the precision of the pix - els ( alphabet ) in images enables the ﬁltering of small variations that might occur during the digitalization process . Binarization to 01 format in ASCII was performed since the BDM currently only supports a small alphabet . Finding an e ﬀ ective data compressor To compute the NC , we have to ﬁnd an e ﬀ ective data compressor , meaning , a compressor that best represents each image , while using reasonable resources . Since our aim is later to apply this measure to a dataset of artistic painting , we compared seven compression tools , namely GZIP [ 63 ] , BZIP2 [ 64 ] , XZ [ 65 ] , LZMA [ 66 ] , AC [ 67 ] , PPMD [ 68 ] , and PAQ8 [ 35 ] . As depicted in Figure 1 , the PAQ8 tool shows the best compression ratio for this dataset . In fact , it shows an improvement of ≈ 26 % to the second best tool ( XZ ) . The disadvantage is the use of higher RAM and substantially more computational time . Nevertheless , since our purpose is to ﬁnd the number of bits of a shortest program to reproduce the image , it is a ﬀ ordable to spend these computational resources . Therefore , we used the PAQ8 tool to compress each of the quantized images . The code was compiled using the package provided from [ 69 ] . The PAQ8 5 version used was kx v7 . PAQ8kx v7 is an archiver that achieves the highest compression rates at the expense of speed and memory ( approximately 1 , 6 GB of RAM for this dataset ) . We used the mode that usually provides the highest compression ratio ( command parameter : “ - 8” ) . The PAQ8 compressor uses a context mixing algorithm between a large number of models independently predicting each quantized pixel’s next bit [ 70 ] . The predictions are combined using a neural network and arithmetic coding [ 71 , 72 ] . For automatic installation , use the script Install . sh , while for more information of PAQ , see the work of Knoll and Freitas [ 73 ] . The computations ran in a single core Ubuntu Linux computer running at 2 . 13 GHz with 1 . 6 GB of RAM . Using this machine , the compression of the whole dataset with PAQ8 required approximately 270 hours of real - time , without parallelization . Figure 1 : Benchmark of lossless data compression tools speciﬁcally for the processed dataset of artistic paintings . The y - axis depicts the sum of the number of bytes to compress the dataset , where each image was compressed individually using each tool Results Comparison of NC and BDM In order to compare NC with BDM , we performed three types of tests . Namely , we compared the robustness of both measures according to increasing rates of random pixel changes in paintings , tested their application on di ﬀ erent types of images , and made an assessment of the minimal information bounds . In the ﬁrst test , we assessed the impact of an increasing rate of pixel editions using a pseudo - random uniform distribution and compared both information - based measures . This approach is not identical to image noise , but rather a pure edition of pixels . For the purpose , for each of the three authors ( Theodore Gericault , Marc Chagall , and Rene Magritte ) we select a painting , making 50 adulterated copies of each painting with increasing edition rate ( from 1 to 50 % ) . Finally , we measured the NC ( Eq . 1 ) , the NBDM 1 ( Eq . 2 ) , and NBDM 2 ( Eq . 3 ) in all the paintings . Figure 2 ( A ) depicts the values obtained for the NC and BDM . The results show that , when using the same type of normalization , NC is more robust to the increment of pixel edition than NBDM ( NBDM 1 ) . On the other hand , whereas NBDM 1 considers the normalization by the length of the input object , NBDM 2 performs a normalization that aims to mimic the removal of the constant factor related to Kolmogorov complexity ( see Eq . 4 ) . Since the NBDM 2 normalization does not take into account the constant of the description language , it shows a more robust behavior than NBDM 1 , which increases rapidly with the increase of pixel edition . Since NC and NBDM 1 have the same type of normalization , we will focus on comparing these normalizations from now on . In the second test , we applied both measures to six datasets with distinct nature ( 9 images each ) to understand how NBDM 1 and NC behave with di ﬀ erent types of images . The six datasets were : artistic images from 2 di ﬀ erent datasets [ 3 , 74 ] ; cellular automata images ; diabetic retinopathy images [ 75 ] ; chest computed radiography ( CR ) images [ 76 ] and photographic images [ 77 ] . The results are depicted in Figure 2 ( B ) . Overall , the majority of the datasets show similar behavior regarding the NC and NBDM 1 . The exceptions to this are the CR and cellular automata datasets , which exhibit a more algorithmic behavior . The latter dataset is constituted by images created with small programs with simple rules . Whereas the compressor has di ﬃ culty compressing this type of images , the BDM can point to their algorithmic nature , and , thus 6 Figure 2 : Information - based measures evaluation . ( A ) Impact of increasing pseudo - random substitution on information - based measures : NC ( approximated using the PAQ8 algorithm ) and two BDM normalizations ( NBDM 1 and NBDM 2 ) . ( B ) Values of the NC and NBDM 1 for di ﬀ erent types of images . ( C ) Image transformation pipeline leading to BDM underestimation of the amount of information contained in the transformed object . attribute them with minimal value . This outcome shows the importance of the BDM in the detection of simple algorithmic outputs embedded into data . In the last test , we selected one of the most complex images identiﬁed by the NBDM in the last subsection to test if the BDM could accommodate speciﬁc data alterations . This test is depicted in Figure 2 ( C ) . After the binarization process , we performed a super - sample image transformation where each char was ampliﬁed to a 4x4 representation . This value was selected since the BDM has the default block size value of 4x4 in 2D structures . After this operation , the BDM was computed for the original and the super - sampled image . While the original image was measured with 370981 bits , the super - sampled image had only 79 bits . This abrupt decrease in the complexity value indicates that the BDM underestimates the amount of information contained in the object . The BDM analyses object information in blocks instead of looking at the whole object . Speciﬁcally , blocks analysed by the BDM ( default block size value of 4x4 in 2D structures ) have the same size as the super - sample image transformation ( each char was ampliﬁed to a 4x4 representation ) ; therefore , the complexity attributed to each block is approximately zero ( since each block is composed of all zeros or ones ) , and hence the overall value attributed to the complexity of the object will drop dramatically . This analysis shows that BDM is not prepared to deal with the information associated with the choice of the model , unlike the NC . The NC relies on the use of a lossless data compressor , bounded by a maximum information channel capacity . From these three tests , we are able to notice some advantages and limitations of both measures . Ranking these measures is not a fair task because they have di ﬀ erent characteristics and nature . Therefore , in the remainder of the article , we use the NC and NBDM in a combined mode to recover insights and characteristics from the images of the artistic paintings . Information - based measures in images of artistic paintings Herein , we investigate the use of information measures to analyse a dataset of artistic paintings . This dataset [ 3 ] contains 4 , 266 images of artistic paintings from 91 authors , with approximate geometric sizes . The 91 authors are well - known painters , such as Claude Monet , Frida Kahlo , Henri Matisse , Jackson Pollock , Picasso , Rembrandt , and Salvador Dali . In the following subsections , we present the results of applying the measures , combining the NC with the HDC function , measuring local complexity for di ﬀ erent authors and constructing a phylogenetic tree , as well as using these features to improve style and artist classiﬁcation . We also measure the impact of normalizing these images by performing image normalization and then applying the measures mentioned above in the dataset . Afterwards , we compared the average variation di ﬀ erence and the percentage di ﬀ erence between the results obtained for each author . The results are shown in the Supplementary Material in section A . 1 . 7 Global measures analysis In this subsection , we measure an approximation to the Kolmogorov complexity for the dataset of artistic paintings . The same pipeline , described in the methods section , was used , with the di ﬀ erence that the Lloyd - Max algorithm quantization was set to 16 , 64 , and 256 levels ( 4 , 6 , and 8 bits respectively ) . Important to note that Lloyd - Max algorithm forced normalization of the images for the 16 and 64 levels , while the 256 level was the original level of the images , and , as such , these images were not normalized . This process was performed to evaluate the impact of the quantization on the measures used to approximate the Kolmogorov complexity in artistic painting images . From the results obtained from the measures , we show unknown characteristics and insights into temporal traits . In general , the complexity of each painting follows the example of Figure 3 . Paintings with low complexity are classiﬁed as abstract and minimalist , following simple patterns . As the complexity increases , we start to recognize paintings with di ﬀ erent local complexities , meaning , there are regions with high complexity and detail ( generally on the center / bottom of the paintings ) surrounded by low complexity regions ( same color background ) namely known as chiaroscuro . This pattern begins fading , as the complexity increases since the highest complexity paintings are also the most irregular , detailed , and convoluted . Figure 3 : Examples of artistic paintings with di ﬀ erent levels of complexity where painting images were quantized to 8 bits . The NC and NBDM 1 values of each painting are displayed in its lower right corner . Regarding the average complexity values for each artist , Figure 4 shows the average of NBDM 1 and NC , re - spectively . Each artist has an associated color , and lines of the same color illustrate its relative positional deviation in di ﬀ erent quantizations . The same results for NBDM 2 are exposed and discussed in the Supplementary Material . 8 Noticeably , quantization impacts the NBDM 1 more than the NC , since the relative positioning between authors varies more in the former . On average , the variation is 13 . 4 ± 11 . 37 relative positions of each author in NBDM 1 , while in NC , the variation is 4 . 9 ± 4 . 3 positions . Figure 4 : Average Normalized Block Decomposition Method using NBDM 1 ( A ) , and Average Normalized Compression ( B ) for each author where images of paintings where quantized for 4 , 6 , and 8 bits . The authors are sort given the value of NBDM 1 and NC , respectively . To see this result in more detail , please visit the website associated with the article . Despite the higher variation present in the NBDM 1 , both measures are capable of detecting styles with low and high complexity . Artists such as Mark Rothko , Lucio Fontana , Piet Mondrian , El Lissitzky can be easily identiﬁed on the low side of the complexity spectrum . Minimalism , Abstract Expressionism , and Constructivism movements are associated with these styles . On the other hand , artists from Abstract Expressionism , such as Willem de Kooning , Jackson Pollock , and Jasper Johns , characterize the highest complexity side of the spectrum , as well as other artists with a more detailed and convoluted style , like Gustav Klimt and Vincent van Gogh . Abstract Expressionism is characterized by aggressive features combined with random and geometric features and spontaneity [ 78 ] . The reason for Abstract Expressionism artists being present at both extremes of the complexity spectrum is because this style itself divided into two opposites , Action Painting and Color Field . In Action Painting , the paint was thrown directly on the canvas , through instinctive gestures , where chance and randomness determined the evolution of painting [ 79 ] . This style is characteristic of artists like Jackson Pollock ( known for the technique of “dripping” ) and Willem de Kooning . On the other hand , Color Field is more mystical and meditative . This style of painting has few elements in the frames , indeﬁnite limits , and explores the sensory e ﬀ ects of color , as well as the subtlety of chromatic relations [ 80 ] . A speciﬁc example of an artist that followed this trend was Mark Rothko . In 9 all cases , Jackson Pollock had complexity values utterly di ﬀ erent from other artists , the average complexity of his paintings being approximate to random ( normalized value close to 1 ) . Although he denied his paintings were random , similar results were also found in previous work , which deﬁned Jackson Pollock’s dripping paintings as not typical artworks [ 5 ] . Combining the NC with the roughness exponent of HDC function We used the average NC together with the roughness exponent ( α ) of the two - point height di ﬀ erence correlation ( HDC ) function , which measures the roughness exponents of brightness surfaces , to assess the ability of these mea - sures to distinguish di ﬀ erent styles . Accordingly , we made usage of style labeled paintings available in the dataset . From these labeled images , we computed for its author the average NC and the value of α . The roughness exponent was used as an additional measure since it has proven to be capable of some di ﬀ erentiation between styles [ 5 ] . We discarded the usage of BDM due to quantization impacting it more than the NC . Using the average NC and α of each labeled painter , we created a scatter plot ( Figure 5 ) and represented each artistic movement as an ellipse , with the center in the points’ center of mass and with a width corresponding to the standard deviation . Figure 5 : Combining the HDC with NC . ( A ) Average and standard deviation for each style in NC and α , respectively . ( B ) Results grouped by styles using average NC and average α of HDC for each artist labeled on the dataset . As shown in Figure 5 ( A ) , both measures alone are not capable of e ﬃ ciently separating styles , However , when combined , the styles are well conﬁned into di ﬀ erent regions ( except for Abstract Expressionism ) , showing that to - gether these measures are representatives of artistic movements . The roughness exponent α captures the level of brightness and relative spatial position and is correlated to variations in painting techniques and genres [ 5 ] . The NC adds to the level of brightness and relative spatial position provided by the HDC , the notion of average information present in each artist’s painting . This amount of information di ﬀ ers depending on the artistic movement and historical circumstances . Interestingly , similar to NC , the roughness exponent of the HDC varies greatly in Abstract Expressionism , being that in this artistic movement , there is an inverse correlation between the NC and α . Namely , artists like Jackson Pollock and Willem de Kooning ( Action Painting ) presented a high average NC and a low α , whereas , Mark Rothko ( Color Field ) had polar results . This atypical behavior corroborates the big di ﬀ erence between the two currents of Abstract Expressionism . The Action Painting usage of instinctive gestures and randomness creates high NC values and spatial correlation approaching a random image . In contrast , in Color Field , we get more minimalist images with high spatial contrast between regions but low complexity . 10 Local complexity of paintings In this section , we divided the images into identical quadrilateral sizes and measure the algorithmic information for each one ( 16x16 blocks ) . Then , we computed the average of each quadrilateral for all the paintings for each painter . The results are shown in Figure 6 , illustrating the same authors as those in Figure 3 . Note however that matrices of Figure 6 were computed using all the authors’ paintings present in the dataset . The complete results are available on the website associated with this article . The same computation was repeated for blocks of sizes 8x8 and 32x32 . Analysis of these results , included in the Supplementary Material , show that 16x16 is the minimum patch size for which the di ﬀ erences in the compression rate are noticeable and can therefore be used as a measure between paintings . All artists have a unique complexity matrix ( ﬁngerprint ) . This ﬁngerprint shows , on average , where artists paint with more detail and give more emphasis as well as the average range of complexity the artist operates . For instance , Jackson Pollock and Jasper Johns show high complexity values dispersed over the canvas . At the same time , artists like Francis Bacon and George de la Tour focus more on the center of the canvas , and Mark Rothko and Piet Mondrian give their highest complexities around the borders of paintings . Figure 6 : Heat maps of the local complexity matrix ( ﬁngerprint ) of some authors , computed with the NC . This ﬁngerprint shows the author’s range of complexity and the locations in the canvas painted with more detail ( or complexity ) . To see all matrices , please visit the website associated with this article . Since the 16x16 ﬁngerprints conveyed the best results regarding detail and di ﬀ erentiation ( see Supplementary Material in section A . 2 ) , the phylogenetic trees were constructed utilizing the distance computed from the ﬁngerprints with block size . Concretely , two phylogenetic trees were constructed to portray the relations between di ﬀ erent artists . 11 One tree was constructed using the UPGMA algorithm , which is illustrated in Figure 7 , and another tree was build using the Kruskal minimum spanning tree algorithm [ 60 ] , which is depicted in the Figure S3 of the Supplementary Material in section A . 4 . Figure 7 : Artists’ phylogenetic tree computed recurring to the UPGMA algorithm . Each artist has a sample painting and a colour associated with one of his styles ( the colour was chosen based on nearest leaves ) assigned to him , as well as a description of some styles usually associated with the author . To obtain an improved view of the tree , please visit the website related to this article . The tree shows the ﬁngerprint’s capacity of grouping artists from the same artistic movements mutually . Broad groupings of artists from styles are present in the tree , namely , Renaissance , Baroque , Romanticists , Impressionists , Surrealism , Cubism , and Abstract Expressionism . Also , the tree shows smaller groupings of sister leaf - nodes with the same style . On the other hand , the tree depicts relationships of inﬂuence between authors of di ﬀ erent artistic 12 movements . This relation is seen in the case of Titian , who inﬂuenced Diego Velazquez ; Caravaggio , who inﬂuenced Francisco de Zurbar´an ; Frida Kahlo , who inﬂuenced Amedeo Modigliani ; Sandro Botticelli who inﬂuenced William Blake ; Claude Lorrain who inﬂuenced Joseph Mallord William Turner ; and Peter Paul Rubens who inﬂuenced Jean - Antoine Watteau . On the other hand , some authors seem unrelated in style and inﬂuence , for instance , Francis Bacon and Georges de la Tour , George Braque and Hieronymus Bosch , Peter Paul Rubens and Frida Kahlo , Max Ernst and Giorgione , and Rembrandt van Rijn and Roy Lichtenstein . There can be many reasons for this to occur , for instance , the number of regions the images were divided can be sub - optimal for some images of artistic paintings , decreasing the sensi - tivity of the measure and jeopardizing the tree’s construction . On the other hand , the algorithm used to measure the similarity between matrices or the algorithm used to construct the tree ( UPGMA ) may not be the most appropriate for all cases , however , we have tested the Kruskal minimum spanning tree algorithm which yielded similar results ( see Supplementary Material in section A . 4 ) . Additionally , these seemingly unrelated connections could reveal undiscov - ered elements and relationships . For instance , one of Roy Lichtenstein’s early artistic idols was Rembrandt van Rijn . Moreover , if artists are not related regarding the artistic movement or inﬂuence , the vicinity among them could be rep - resenting another property . This aspect is not necessarily related to the period or movement the artists were inserted in , but rather , the way authors projected their compositions , ideas , and impressions onto the canvas . Complexity can be approximated by the total number of properties transmitted by an object and detected by an observer . By dividing images into blocks of equal size and evaluating its local complexity , we are quantifying the local information being transmitted . On the other hand , by averaging the canvas results per artist , we obtain a matrix that describes how the author exposes information to the observer . This information intertwines various notions critical to how the work is perceived , such as composition which describes where the artist places the subject and how the background elements support it , as well as the unity , balance , movement , rhythm , focus , contrast , pattern , and proportion of the painting . For instance , the proximity between Hans Holbein and Vermeer could be due to both of them having used optics to achieve precise positioning in their compositions , namely by performing a combination of curved mirrors , camera obscura , and camera lucida [ 81 ] . Another example that this information can convey is space by depicting where positive ( subject itself , which is usually more detailed ) and negative ( the area of painting around it ) spaces are on the canvas . Artists can play with a balance between these two spaces to further inﬂuence how viewers interpret their work . Therefore , the similarity between di ﬀ erent artists concerning the regional ( local ) complexity can reﬂect the similarity in thought regarding their approaches to painting . For instance , the proximity between Francis Bacon and Georges de la Tour could be due to the former being heavily inﬂuenced by the Baroque style and having made dramatic use of contrasts of light and shadow . These methods are characteristic of the chiaroscuro principle and its radicalization in the Tenebrista school ( signature style of Georges de la Tour ) [ 82 , 83 ] . The intense contrasts of light and shadow highlight the characters , and although exaggerated , it is lighting that increases the feeling of realism , making the muscles and facial expressions more evident . Simultaneously , the presence of large blackened areas highlights the chromatic research and the illuminated space , which acquire their value as elements of the composition . We conclude that this novel technique is a unique descriptor of the authors’ paintings since it not only aggregates authors of the same style close to each other and demonstrates the inﬂuences that authors had on others . It also serves as an insight into the way the artist projects its art . Evaluation of measures for classiﬁcation purposes To quantitatively evaluate the use of these measures for classiﬁcation purposes , we assessed their impact when used as additional features to improve state - of - the - art classiﬁcation methods . For this purpose , we recreated a recently published state - of - the - art method as a baseline and improved the results by combining our proposed measures . Based on current methods [ 52 , 53 ] , we extracted a Gram representation using the ﬁrst convolutional layer from the ﬁfth convolutional block of the VGG16 network which was pre - trained with the imagenet dataset ( no signiﬁcant result di ﬀ erence was found between the use of VGG16 or VGG19 ) . Principal component analysis ( PCA ) was applied to the Gram matrix to reduce the dimensionality and , ﬁnally , this vector was provided to an SVM to perform classiﬁcation . Afterwards , the features obtained from computing the HDC and the regional complexity were used for author and style classiﬁcation using the XGBoost classiﬁer [ 84 ] and combined with the baseline classiﬁer via a Voting Classiﬁer ensemble . The results of the baseline and ensemble classiﬁers , applied to the Paintings91 dataset in the author and style classiﬁcation task using the labels provided in the dataset , are shown in Table 1 . 13 Table 1 : Accuracy results obtained for the test set in style and author classiﬁcation task using state - of - the - art ( SoA ) , state - of - the - art with regional complexity ( RC ) and ensemble with our measures ( RC and HDC ) . Classiﬁcation Task Number of Classes Number of Images SoA Baseline SoA Baseline + RC SoA Baseline + RC + HDC Style 13 2338 0 . 622 0 . 644 0 . 650 Author 91 4266 0 . 480 0 . 490 0 . 500 The results show that the inclusion of the Regional Complexity , increased the accuracy of the results 2 . 2 p . p . and 1 . 0 p . p in the style and author classiﬁcation tasks respectively . Moreover , the overall inclusion of the proposed measures ( HDC + RC ) increased the accuracy in both classiﬁcation tasks by 2 . 8 p . p . and , 2 . 0 p . p . in the style and author classiﬁcation tasks , respectively . These results indicate that these predictors are useful auxiliary features capable of improving current methodologies in the classiﬁcation of artistic paintings . This is congruent with the results obtained with Nanny et al . [ 85 ] , since handcrafted features and non - handcrafted features seem to extract di ﬀ erent information from the input images and , as a result , the fusion of the two types of features improves the results obtained when using non - handcrafted features only . Furthermore , regional complexity ( RC ) has a higher impact on the improvement of the accuracy than the HDC features , demonstrating the importance and distinction of Regional Complexity as a feature . Discussion In this work , we develop , use , and compare unsupervised pattern recognition techniques to quantify information in images of artistic paintings . We rely on two approaches , namely data compression using the Normalized Compression ( NC ) , and the Block Decomposition Method ( BDM ) , to estimate information of both probabilistic and algorithmic sources . To approximate the NC , we benchmark a set of data compressors , where we show that the most e ﬀ ective for this dataset is PAQ8 . Subsequently , this article is organized into two broad sections . The ﬁrst is the evaluation and comparison of information - based measures ; the second is applying these information - based measures to a dataset of artistic paintings . On the measure evaluation section , we assessed the NC and BDM using three tests . In the ﬁrst test , we evaluated the NC and two normalizations of the BDM , regarding their robustness when images undergo uniform pixel editing and their behavior when applied to di ﬀ erent types of datasets . We found that in terms of uniform pixel editing , the NC is more robust than BDM with the same kind of normalization . The NC is a measure of compression ( in this case , using the PAQ compressor ) that makes use of the digital object in its entirety to create the shortest possible representation without loss of information . In contrast , BDM divides the digital object into blocks and , based on the complexity of the blocks , estimates the image complexity in its entirety . This means that BDM cannot determine the information shared between the blocks , which causes it to increase , when compared to the NC , with the increase in uniform pixel editing . In the second test , we compared both measures using di ﬀ erent image natures . We found that the results of the NC and NBDM are similar , except for the computed radiography and the cellular automata dataset , which exhibited a more algorithmic behavior . The cellular automata data was created with small programs with simple rules . While the compressor had di ﬃ culty compressing this data , BDM could approximate their algorithmic nature and thus assign them a value close to a minimal complexity value . The ability to identify an algorithmic nature incorporated in the data demonstrates the relevance of BDM as a measure . In the third test , we found that a super sample image transformation causes an underestimation of the amount of information contained in the object by BDM . Again , this is due to BDM analysing the object in blocks , instead of using the object in its entirety . Since the ampliation size was the same as the blocks analysed by BDM , the complexity attributed to each block was approximately zero . Consequently , the overall value attributed to the image complexity decreased dramatically . This aspect demonstrated that BDM cannot handle information contained between each block and can easily underestimate the amount of information present in a digital object . In the second phase , we applied these measures to estimate the complexity of a dataset of paintings . We calculated the NC and NBDM in this dataset with di ﬀ erent quantizations and assessed the results in terms of average complexity 14 per author . Afterward , we combined the NC with the exponent of the roughness of the HDC function in the labeled paintings of the dataset . Finally , we computed the average regional complexity of each author regarding their paintings and built a phylogenetic tree . We found that paintings with low complexity are abstract , minimalist , and follow simple patterns . Paintings with a slightly higher average complexity possess di ﬀ erent regional complexities , speciﬁcally , a region with high complexity and detail surrounded by a background of low complexity . With more complexity , this noticeable pattern begins to fade , and the most complex paintings are globally irregular , detailed , and convoluted . Regarding the average complexity values for each artist , we found that NC and NBDM behave similarly , where quantization impacted more the NBDM . We also found that the low side of the complexity spectrum was characterized by Abstract Expressionism , Minimalism , Constructivism movements , with authors such as Mark Rothko , Lucio Fontana , Piet Mondrian , and El Lissitzky . Also , artists from Abstract Expressionism characterized the high complexity side of the spectrum , such as Willem de Kooning , Jackson Pollock , and Jasper Johns , as well as other artists with a more detailed and convoluted style , like Gustav Klimt and Vincent van Gogh . Due to two di ﬀ erent currents ( Color Field with authors with low average complexity and Action Painting with authors with high complexity ) , Abstract Expressionism was present at the polar ends of the spectrum . In all cases , Jackson Pollock had average complexity values that were utterly di ﬀ erent from other artists , being the average complexity of his paintings close to random . Although he denied being a creator of random paintings , this result and others [ 5 ] seem to indicate that Jackson Pollock’s dripping paintings are not typical artworks , and this is possibly related to the inclusion of many symbolic layers and dispersion intentions over the canvas by the author . When evaluating the artists’ average NC together with the roughness exponent ( α ) of the HDC function in the labels images of the dataset , we found that styles are well conﬁned into di ﬀ erent regions , showing that the combination of these measures gives a robust representation of artistic movements . The NC adds to the level of brightness and relative spatial position evidenced by the roughness exponent , the notion of average information present in each artist’s painting , which is consistent within the same style and historical circumstances . We also ﬁnd that in Abstract Expressionism , the NC is inversely correlated to α . Concretely , artists related to Colour Field painting presented a high α and low NC , whereas artists related to Action Painting presented the exact polar results ( low α and high NC ) . Finally , we divided the image into equal quadrilateral parts and estimated the local complexity of each painting on the dataset and used it to ascertain each artist’s average regional matrix ( ﬁngerprint ) . Complexity can be thought of as a measure of the total number of properties transmitted by an object and detected by an observer . By dividing images into blocks of equal size and evaluating its local complexity , we quantiﬁed the local information being transmitted . Furthermore , by averaging the canvas results per artist , we obtain a unique ﬁngerprint that describes how the author exposes information to the observer . Among other things , these ﬁngerprints give speciﬁc insights regarding each artist’s way of painting , showing where , on average , artists paint with more detail and give more emphasis , while also providing insights into each artist’s range of complexity . Using these matrices , we computed a distance matrix and utilized it to construct a phylogenetic tree . We discovered that these phylogenetic trees aggregated authors of the same style close to each other , as well as artists’ inﬂuence relationships , like Francis Bacon and Georges de la Tour , and George Braque and Hieronymus Bosch . Furthermore , we observed proximity between artists due to shared methods and techniques which are not correlated with the temporal era or artistic movement . An example of this occurrence is the proximity between Hans Holbein and Vermeer which don’t share styles , but both used optics to achieve precise positioning in their compositions . This evidence shows that artists’ ﬁngerprints contain critical information into how the work is perceived , such as composition , unity , balance , movement , rhythm , focus , contrast , pattern , and proportion of the painting and space . Finally , we show that these measures improve current methodologies in the classiﬁcation of artistic paintings and thus extract information which di ﬀ ers from non - handcrafted features . Furthermore , regional complexity provided the largest increase in accuracy on the classiﬁcation tasks , showing its relevance as a descriptor of images of artistic paintings . Conclusions In this paper , we introduce novel solutions to the ﬁeld of computer analysis of artistic paintings and the problem of artist classiﬁcation and authentication . Speciﬁcally , we assessed the viability of unsupervised measures that ap - proximate the quantity of probabilistic and algorithmic information for performing these tasks . Our direct comparison between NC and BDM allowed us to understand the strengths and weaknesses of both measures . Although BDM 15 has di ﬃ culty dealing with uniform pixel edition and full information quantiﬁcation given the block representability , it serves as a useful tool for measure and indentiﬁcation of data content having similarity to simple algorithms . On the other hand , the NC is more robust to data alterations ( pixel edition and quantization ) and is able to measure the quantity of information without underestimation . Regarding the application of information - based measures in artistic paintings , we studied and developed techniques that can be valuable for art authorship attribution and validation , art style categorization and organization , and art content explanation . Namely , the NC proved to be a robust measure that as a whole gives us some insight regarding the complexity of di ﬀ erent styles showing hidden patterns and relationships present in artistic paintings that share the same range in complexity . Furthermore , it could be a stylistic descriptor when coupled with the roughness exponent α . On the other hand , ﬁngerprints depict how each author perform typical content distribution on canvas . Thus , they can provide a suitable means of art content explanation , as well as being valuable for art authorship attribution and validation . Moreover , since they provided insights regarding the artists’ way of painting , they can be used as a means of relating authors , being therefore useful for depicting artists’ stylistic inﬂuences , and shared techniques . Additionally , using the distance between the artists’ regional complexity , we also ﬁnd some interesting links between authors regarding the usage of space , technique , composition , rhythm , and pro - portion . Finally , we demonstrated that the regional complexity and the HDC function of the paintings could serve as useful auxiliary features capable of improving current methodologies in author and style classiﬁcation of images of artistic paintings . Regarding future continuations to this study , there are many possible future lines of work that can be considered . For example , in this work we analysed the images of paintings by converting them to monochrome , and it would be interesting to separate the colour channels and to analyse them separately , therefore studying the inﬂuence of colour in the paintings in terms of complexity . Additionally , it would be interesting to explore how to separate di ﬀ erent characteristics of the ﬁngerprint , as well as detecting unknown repeated patterns that appear multiple times in a painting by creating and analysing their complexity surfaces [ 13 ] . Lastly , another interesting study would be to replicate the developed work in this article using a competitive compressor that would select the best compressor model for each painting or region . Website A support website to this site can be accessed at http : / / panther . web . ua . pt / . This site showcases among other things , the pipeline of this study , the author’s average NC and NBDM variation for di ﬀ erent quantization levels , the results of combining the NC with the roughness exponent of HDC function ( α ) , a complete catalogue of each author’s ﬁngerprints as well as several examples of each author’s paintings , and the computed phylogenetic trees with a magniﬁer to allow a better observation of the results . Acknowledgements This work was funded by National Funds through the FCT - Foundation for Science and Technology , in the context of the project UID / CEC / 00127 / 2019 and the research grants SFRH / BD / 141851 / 2018 and SFRH / BD / 137000 / 2018 for J . M . S and R . A , respectively . D . P . is funded by national funds through FCT - Fundac¸˜ao para a Ciˆencia e a Tecnologia , I . P . , under the Scientiﬁc Employment Stimulus - Institutional Call - CI - CTTI - 94 - ARH / 2019 . Author contributions statement J . M . S . and D . P . designed the experiment and wrote the manuscript . J . M . S . , D . P . , R . A . and S . M . executed the data analysis . All the authors discussed the results and revised the manuscript . Additional information Competing interests The authors declare no competing interests . 16 References [ 1 ] R . W . Weisberg , Creativity : Understanding innovation in problem solving , science , invention , and the arts , John Wiley & Sons , 2006 . [ 2 ] A . Hertzmann , Can computers create art ? , in : Arts , Vol . 7 , Multidisciplinary Digital Publishing Institute , 2018 , p . 18 . [ 3 ] F . S . Khan , S . Beigpour , J . Van de Weijer , M . Felsberg , Painting - 91 : a large scale database for computational painting categorization , Machine vision and applications 25 ( 6 ) ( 2014 ) 1385 – 1397 . [ 4 ] S . Lyu , D . Rockmore , H . Farid , A digital technique for art authentication , Proceedings of the National Academy of Sciences 101 ( 49 ) ( 2004 ) 17006 – 17010 . [ 5 ] D . Kim , S . - W . Son , H . Jeong , Large - scale quantitative analysis of painting arts , Scientiﬁc reports 4 ( 2014 ) 7370 . [ 6 ] H . Zhang , S . Sfarra , K . Saluja , J . Peeters , J . Fleuret , Y . Duan , H . Fernandes , N . Avdelidis , C . Ibarra - Castanedo , X . Maldague , Non - destructive investigation of paintings on canvas by continuous wave terahertz imaging and ﬂash thermography , Journal of Nondestructive Evaluation 36 ( 2 ) ( 2017 ) 34 . [ 7 ] H . Zenil , S . Hern´andez - Orozco , N . A . Kiani , F . Soler - Toscano , A . Rueda - Toicen , J . Tegn´er , A decomposition method for global evaluation of Shannon entropy and local estimations of algorithmic complexity , Entropy 20 ( 8 ) ( 2018 ) 605 . [ 8 ] J . - P . Delahaye , H . Zenil , Numerical evaluation of algorithmic complexity for short strings : A glance into the innermost structure of ran - domness , Applied Mathematics and Computation 219 ( 1 ) ( 2012 ) 63 – 77 , towards a Computational Interpretation of Physical Theories . doi : https : / / doi . org / 10 . 1016 / j . amc . 2011 . 10 . 006 . [ 9 ] F . Soler - Toscano , H . Zenil , J . - P . Delahaye , N . Gauvrit , Calculating Kolmogorov complexity from the output frequency distributions of small Turing machines , PloS one 9 ( 5 ) . [ 10 ] J . Smiers , Arts under pressure : Protecting cultural diversity in the age of globalisation , Zed Books , 2003 . [ 11 ] P . J . Ferreira , A . J . Pinho , A method to detect repeated unknown patterns in an image , in : International Conference Image Analysis and Recognition , Springer , 2014 , pp . 12 – 19 . [ 12 ] A . J . Pinho , P . J . Ferreira , Finding unknown repeated patterns in images , in : 2011 19th European Signal Processing Conference , IEEE , 2011 , pp . 584 – 588 . [ 13 ] D . Pratas , A . J . Pinho , On the detection of unknown locally repeating patterns in images , in : International Conference Image Analysis and Recognition , Springer , 2012 , pp . 158 – 165 . [ 14 ] A . Romashchenko , A . Shen , N . Vereshchagin , Combinatorial interpretation of Kolmogorov complexity , Theoretical Computer Science 271 ( 1 - 2 ) ( 2002 ) 111 – 123 . [ 15 ] R . K . Niven , Combinatorial entropies and statistics , The European Physical Journal B 70 ( 1 ) ( 2009 ) 49 – 63 . [ 16 ] S . Mantaci , A . Restivo , G . Rosone , M . Sciortino , A new combinatorial approach to sequence comparison , Theory of Computing Systems 42 ( 3 ) ( 2008 ) 411 – 429 . [ 17 ] C . E . Shannon , A mathematical theory of communication , Bell system technical journal 27 ( 3 ) ( 1948 ) 379 – 423 . [ 18 ] A . N . Kolmogorov , Three approaches to the quantitative deﬁnition of information’ , Problems of information transmission 1 ( 1 ) ( 1965 ) 1 – 7 . [ 19 ] R . J . Solomono ﬀ , A formal theory of inductive inference . Part I , Information and control 7 ( 1 ) ( 1964 ) 1 – 22 . [ 20 ] R . J . Solomono ﬀ , A formal theory of inductive inference . Part II , Information and control 7 ( 2 ) ( 1964 ) 224 – 254 . [ 21 ] G . J . Chaitin , On the length of programs for computing ﬁnite binary sequences , Journal of the ACM ( JACM ) 13 ( 4 ) ( 1966 ) 547 – 569 . [ 22 ] F . Soler - Toscano , H . Zenil , A computable measure of algorithmic probability by ﬁnite approximations with an application to integer se - quences , Complexity 2017 . [ 23 ] N . Gauvrit , H . Zenil , F . Soler - Toscano , J . - P . Delahaye , P . Brugger , Human behavioral complexity peaks at age 25 , PLoS computational biology 13 ( 4 ) . [ 24 ] M . Li , J . H . Badger , X . Chen , S . Kwong , P . Kearney , H . Zhang , An information - based sequence distance and its application to whole mitochondrial genome phylogeny , Bioinformatics 17 ( 2 ) ( 2001 ) 149 – 154 . [ 25 ] R . Cilibrasi , P . M . Vit´anyi , Clustering by compression , IEEE Transactions on Information theory 51 ( 4 ) ( 2005 ) 1523 – 1545 . [ 26 ] R . Cilibrasi , P . Vitanyi , Automatic extraction of meaning from the web , in : 2006 IEEE International Symposium on Information Theory , 2006 , pp . 2309 – 2313 . [ 27 ] M . Cebri´an , M . Alfonseca , A . Ortega , The normalized compression distance is resistant to noise , IEEE Transactions on Information Theory 53 ( 5 ) ( 2007 ) 1895 – 1900 . [ 28 ] A . R . Cohen , P . M . Vit´anyi , Normalized compression distance of multisets with applications , IEEE transactions on pattern analysis and machine intelligence 37 ( 8 ) ( 2014 ) 1602 – 1614 . [ 29 ] D . Pratas , A . J . Pinho , On the approximation of the Kolmogorov complexity for DNA sequences , in : Iberian Conference on Pattern Recogni - tion and Image Analysis , Springer , 2017 , pp . 259 – 266 . [ 30 ] S . Maniccam , N . Bourbakis , Lossless compression and information hiding in images , Pattern Recognition 37 ( 3 ) ( 2004 ) 475 – 486 . [ 31 ] Z . - M . Lu , S . - Z . Guo , Lossless information hiding in images , Syngress , 2016 . [ 32 ] D . Pratas , A . J . Pinho , P . J . Ferreira , E ﬃ cient compression of genomic sequences , in : 2016 Data Compression Conference ( DCC ) , IEEE , 2016 , pp . 231 – 240 . [ 33 ] D . Pratas , M . Hosseini , A . J . Pinho , Substitutional tolerant markov models for relative compression of DNA sequences , in : International Conference on Practical Applications of Computational Biology & Bioinformatics , Springer , 2017 , pp . 265 – 272 . [ 34 ] A . J . Pinho , A . J . Neves , P . J . Ferreira , Inverted - repeats - aware ﬁnite - context models for DNA coding , in : 2008 16th European Signal Process - ing Conference , IEEE , 2008 , pp . 1 – 5 . [ 35 ] M . Mahoney , Data Compression Programs , http : / / mattmahoney . net / dc / ( accessed May 16 , 2020 ) . [ 36 ] J . Rissanen , Modeling by shortest data description , Automatica 14 ( 5 ) ( 1978 ) 465 – 471 . [ 37 ] M . Li , X . Chen , X . Li , B . Ma , P . M . Vit´anyi , The similarity metric , IEEE transactions on Information Theory 50 ( 12 ) ( 2004 ) 3250 – 3264 . [ 38 ] M . Li , P . Vit´anyi , et al . , An introduction to Kolmogorov complexity and its applications , Vol . 3 , Springer , 2008 . [ 39 ] R . P . Taylor , A . P . Micolich , D . Jonas , Fractal analysis of Pollock’s drip paintings , Nature 399 ( 6735 ) ( 1999 ) 422 – 422 . 17 [ 40 ] C . R . Johnson , E . Hendriks , I . J . Berezhnoy , E . Brevdo , S . M . Hughes , I . Daubechies , J . Li , E . Postma , J . Z . Wang , Image processing for artist identiﬁcation , IEEE Signal Processing Magazine 25 ( 4 ) ( 2008 ) 37 – 48 . [ 41 ] J . Li , J . Z . Wang , Studying digital imagery of ancient paintings by mixtures of stochastic models , IEEE Transactions on Image Processing 13 ( 3 ) ( 2004 ) 340 – 353 . [ 42 ] M . Bressan , C . Cifarelli , F . Perronnin , An analysis of the relationship between painters based on their work , in : 2008 15th IEEE International Conference on Image Processing , IEEE , 2008 , pp . 113 – 116 . [ 43 ] B . A . Olshausen , M . R . DeWeese , Applied mathematics : The statistics of style , Nature 463 ( 7284 ) ( 2010 ) 1027 . [ 44 ] J . M . Hughes , D . J . Graham , D . N . Rockmore , Quantiﬁcation of artistic style through sparse coding analysis in the drawings of Pieter Bruegel the Elder , Proceedings of the National Academy of Sciences 107 ( 4 ) ( 2010 ) 1279 – 1283 . [ 45 ] D . G . Stork , Y . Furuichi , Image analysis of paintings by computer graphics synthesis : an investigation of the illumination in Georges de la Tour’s Christ in the carpenter’s studio , in : Computer image analysis in the study of art , Vol . 6810 , International Society for Optics and Photonics , 2008 , p . 68100J . [ 46 ] M . Lettner , R . Sablatnig , Estimating the original drawing trace of painted strokes , in : Computer image analysis in the study of art , Vol . 6810 , International Society for Optics and Photonics , 2008 , p . 68100C . [ 47 ] M . Shahram , D . G . Stork , D . Donoho , Recovering layers of brush strokes through statistical analysis of color and shape : an application to van Gogh’s” self portrait with grey felt hat” , in : Computer image analysis in the study of art , Vol . 6810 , International Society for Optics and Photonics , 2008 , p . 68100D . [ 48 ] S . B . Hedges , Image analysis of renaissance copperplate prints , in : Computer image analysis in the study of art , Vol . 6810 , International Society for Optics and Photonics , 2008 , p . 681009 . [ 49 ] V . M . Petrov , Entropy and stability in painting : An information approach to the mechanisms of artistic creativity , Leonardo 35 ( 2 ) ( 2002 ) 197 – 202 . [ 50 ] J . T . Machado , A . M . Lopes , Artistic painting : A fractional calculus perspective , Applied Mathematical Modelling 65 ( 2019 ) 614 – 626 . [ 51 ] K . - C . Peng , T . Chen , Cross - layer features in convolutional neural networks for generic classiﬁcation tasks , in : 2015 IEEE International Conference on Image Processing ( ICIP ) , IEEE , 2015 , pp . 3057 – 3061 . [ 52 ] H . Mao , M . Cheung , J . She , Deepart : Learning joint representations of visual arts , in : Proceedings of the 25th ACM international conference on Multimedia , 2017 , pp . 1183 – 1191 . [ 53 ] W . Chu , Y . Wu , Image style classiﬁcation based on learnt deep correlation features , IEEE Transactions on Multimedia 20 ( 9 ) ( 2018 ) 2491 – 2502 . [ 54 ] D . Hammer , A . Romashchenko , A . Shen , N . Vereshchagin , Inequalities for Shannon entropy and Kolmogorov complexity , Journal of Com - puter and System Sciences 60 ( 2 ) ( 2000 ) 442 – 464 . [ 55 ] T . Henriques , H . Gonc¸alves , L . Antunes , M . Matias , J . Bernardes , C . Costa - Santos , Entropy and compression : two measures of complexity , Journal of Evaluation in Clinical Practice 19 ( 6 ) ( 2013 ) 1101 – 1106 . [ 56 ] S . Terwijn , L . Torenvliet , P . M . B . Vit´anyi , Nonapproximablity of the normalized information distance , CoRR abs / 0910 . 4353 . arXiv : 0910 . 4353 . [ 57 ] A . Rybalov , On the strongly generic undecidability of the halting problem , Theoretical Computer Science 377 ( 1 - 3 ) ( 2007 ) 268 – 270 . [ 58 ] P . Bloem , F . Mota , S . de Rooij , L . Antunes , P . Adriaans , A safe approximation for Kolmogorov complexity , in : International Conference on Algorithmic Learning Theory , Springer , 2014 , pp . 336 – 350 . [ 59 ] R . R . Sokal , A statistical method for evaluating systematic relationships . , Univ . Kansas , Sci . Bull . 38 ( 1958 ) 1409 – 1438 . [ 60 ] J . B . Kruskal , On the shortest spanning subtree of a graph and the traveling salesman problem , Proceedings of the American Mathematical society 7 ( 1 ) ( 1956 ) 48 – 50 . [ 61 ] S . Lloyd , Least squares quantization in PCM , IEEE transactions on information theory 28 ( 2 ) ( 1982 ) 129 – 137 . [ 62 ] D . S . Taubman , M . W . Marcellin , JPEG2000 : Image compression fundamentals , Standards and Practice 11 ( 2 ) . [ 63 ] J . Gailly , M . Adler , The gzip home page , http : / / www . gzip . org / ( accessed May 16 , 2020 ) . [ 64 ] bzip2 , http : / / www . bzip . org / ( accessed May 16 , 2020 ) . [ 65 ] L . Collin , XZ Utils , https : / / tukaani . org / xz / ( accessed May 16 , 2020 ) . [ 66 ] I . Pavlov , 7 - Zip , https : / / www . 7 - zip . org / ( accessed May 16 , 2020 ) . [ 67 ] M . Hosseini , D . Pratas , A . J . Pinho , AC : A compression tool for amino acid sequences , Interdisciplinary Sciences : Computational Life Sciences 11 ( 1 ) ( 2019 ) 68 – 76 . [ 68 ] J . Cleary , I . Witten , Data compression using adaptive coding and partial string matching , IEEE transactions on Communications 32 ( 4 ) ( 1984 ) 396 – 402 . [ 69 ] A . J . Buchner , PAQ , https : / / github . com / JohannesBuchner / paq / ( accessed May 16 , 2020 ) . [ 70 ] M . V . Mahoney , Adaptive weighing of context models for lossless data compression , Tech . rep . , Florida Institute of Technology CS Depart - ment of the W University Blvd ( 2005 ) . [ 71 ] J . Rissanen , G . G . Langdon , Arithmetic coding , IBM Journal of research and development 23 ( 2 ) ( 1979 ) 149 – 162 . [ 72 ] A . Mo ﬀ at , R . M . Neal , I . H . Witten , Arithmetic coding revisited , ACM Transactions on Information Systems ( TOIS ) 16 ( 3 ) ( 1998 ) 256 – 294 . [ 73 ] B . Knoll , N . de Freitas , A machine learning perspective on predictive coding with PAQ8 , in : 2012 Data Compression Conference , IEEE , 2012 , pp . 377 – 386 . [ 74 ] Best Artworks of All Time , https : / / www . kaggle . com / ikarus777 / best - artworks - of - all - time / data ( accessed May 18 , 2020 ) . [ 75 ] Diabetic Retinopathy Detection , https : / / www . kaggle . com / c / diabetic - retinopathy - detection / overview ( accessed May 18 , 2020 ) . [ 76 ] X . Wang , Y . Peng , L . Lu , Z . Lu , M . Bagheri , R . Summers , Chestx - ray8 : Hospital - scale chest X - ray database and benchmarks on weakly - supervised classiﬁcation and localization of common thorax diseases , in : IEEE CVPR , 2017 , pp . 3462 – 3471 . [ 77 ] COCO - Common Objects in Context , http : / / cocodataset . org / # download ( accessed May 18 , 2020 ) . [ 78 ] C . Shapiro , et al . , Abstract Expressionism : The politics of apolitical painting , Prospects 3 ( 1978 ) 175 – 214 . [ 79 ] H . Rosenberg , The Tradition Of The New , Hachette Books , 1994 . 18 [ 80 ] L . Garrard , Colourﬁeld painting : Minimal , Cool , Hard Edge , Serial and Post - painterly Abstract Art from the Sixties to the present , Crescent Moon Publishing , 2007 . [ 81 ] D . Hockney , Secret Knowledge : Rediscovering the Lost Techniques of the Old Masters , Viking Studio , 2006 . [ 82 ] S . Yang , G . Cheung , P . Le Callet , J . Liu , Z . Guo , Computational modeling of artistic intention : Quantify lighting surprise for painting analysis , in : 2016 Eighth International Conference on Quality of Multimedia Experience ( QoMEX ) , IEEE , 2016 , pp . 1 – 6 . [ 83 ] L . Fichner - Rathus , Foundations of art and design : An enhanced media edition , Cengage Learning , 2011 . [ 84 ] T . Chen , C . Guestrin , XGBoost : A scalable tree boosting system , in : Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’16 , ACM , New York , NY , USA , 2016 , pp . 785 – 794 . doi : 10 . 1145 / 2939672 . 2939785 . URL http : / / doi . acm . org / 10 . 1145 / 2939672 . 2939785 [ 85 ] L . Nanni , S . Ghidoni , S . Brahnam , Handcrafted vs . non - handcrafted features for computer vision classiﬁcation , Pattern Recognition 71 ( 2017 ) 158 – 172 . doi : https : / / doi . org / 10 . 1016 / j . patcog . 2017 . 05 . 025 . URL http : / / www . sciencedirect . com / science / article / pii / S0031320317302224 19 A . Supplement A . 1 . Comparison towards normalized images The images provided by the dataset were not normalized . This section evaluates the e ﬀ ects and possible impact of the 8 - bit images’ normalization on the measures used . The images were normalized by forcing the brightest pixels to white ( 255 ) , the darkest pixels to black ( 0 ) , and spreading the ones in between . We computed each measure’s average values per author for the normalized images , and then we measured the average di ﬀ erence and its standard deviation between them and the previously obtained results . Furthermore , we also computed the average percentage di ﬀ erence and standard deviation as Mean Percentage Di ﬀ erence = n (cid:88) i = 0 | a i − b i | a i + b i 2 × 100 , ( 8 ) a and b are the average value of the measure for a given author for the normalized and non - normalized images , respectively , and i is the author . Table S1 describes the average variation between the measures taken directly from the dataset and those taken after normalization . Table S1 : Author’s Average di ﬀ erence and the percentage di ﬀ erence between normalized and non - normalized images for the NBDM 1 , NBDM 2 , NC , and α . Measure Average ± Standard Deviation Percentage Di ﬀ erence ( % ) NBDM 1 0 . 031 ± 0 . 001 3 . 978 NBDM 2 0 . 015 ± 0 . 001 3 . 977 NC 0 . 017 ± 0 . 002 2 . 531 α 0 . 001 ± 0 . 000 0 . 545 The results show that measures have low average variation and percentage di ﬀ erences , being the most a ﬀ ected the NBDM and the least a ﬀ ected the roughness exponent α . Therefore , we can conclude that they are resistant and that the normalization has no signiﬁcant impact on the measures utilized . To assess the impact of the image normalization on the Regional Complexity , we performed the Mantel test and computed the average di ﬀ erence between the normalized and non - normalized images’ distances . The results are shown in Table S2 . The Mantel test measures the correlation between two distance matrices . The results show a high correlation of 0 . 955 with a p - value of 0 . 001 and a low average di ﬀ erence of distance between authors of 3 . 2622 ± 2 . 820 . Since the only di ﬀ erence between the two distances is that one was computed from normalized images and the other from non - normalized images , we conclude with the results obtained that this measure is also robust to normalization . Consequently , image normalization has a minimal impact and does not signiﬁcantly inﬂuence the measure . A . 2 . Comparison towards other ﬁngerprints As explained in the Methods section of this article , when creating the ﬁngerprints , we tried to select a patch size that is the minimum for the di ﬀ erences in the compression rate to be signiﬁcant and capable of being used as a measure between paintings . To this end , we computed the regional complexity of each image for the 8x8 , 16x16 , and 32x32 blocks of the image . It is worth mentioning here that for the regional complexity of 8x8 and 16x16 , the division of the image was performed to divide the image into the number of tiles given equally . The result is that the images are divided into tiles which have slightly di ﬀ erent sizes . On the other hand , for the 32x32 regional complexities , the images were divided into blocks of the exact same size , except for the last tiles , which were the remain of each image ( the remain is the result of images not being an exact multiple of the desired tile size ) . There are two reasons for this di ﬀ erence in the division method of blocks . Firstly , when we divide the image into a few blocks , each block has a reasonable size and therefore , the variation with the addition of a row or column , does not a ﬀ ect the results of the compression , in contrast with small tiles the addition of a column or a row a ﬀ ects more signiﬁcantly the compression results of each tile . Secondly , cropping tiles with the same size in larger blocks would cause a large 20 remainder which would be more inaccurate than to distribute the remainder among the other blocks . The results of each author’s ﬁngerprints ( computed for the 8x8 , 16x16 , and 32x32 blocks ) are shown on the auxiliary website of this article . Furthermore , some illustrative results are exempliﬁed in Figure S1 . Figure S1 : Heat maps of the local complexity matrix ( ﬁngerprint ) of some authors for the di ﬀ erent number of blocks the images were divided . This ﬁngerprint shows the author’s range of complexity and where they paint with more detail . To see all ﬁngerprints , please visit the website of this article . Qualitatively , as can be seen in Figure S1 the images of the authors show similar patterns for each author . However , with the increase in patch size , from 16x16 blocks to 32x32 blocks the patterns become less noticeable , as such a good balance between detail and di ﬀ erentiation would be the 16x16 blocks . Qualitatively , we computed the distance matrix for each author using the images of di ﬀ erent patch sizes , and to those distances , we performed the Mantel test and measured the average di ﬀ erence between them . The results are shown in Table S2 . Since the matrices correspond to distances computed for the same measure but with a di ﬀ erent number of blocks , it should be expected for the distance between authors to be similar , thus yielding a high correlation between distance 21 Table S2 : Mantel Test between distance Matrices and Average di ﬀ erence between them . For the Mantel test , all results had a p - value of 0 . 001 . Comparison methods Mantel Test Average ± Standard Deviation 16x16 blocks * 0 . 955 3 . 262 ± 2 . 820 8x8 vs 16x16 blocks 0 . 951 14 . 959 ± 12 . 372 32x32 vs 16x16 blocks 0 . 918 74 . 092 ± 50 . 952 * Normalized vs non - normalized images . matrices . The results show a high correlation between the distances computed from 8x8 and 32x32 ﬁngerprints towards the 16x16 ﬁngerprints distance . However , there is a higher correlation ( 0 . 951 ) and lower average variation between 8x8 and 16x16 ﬁngerprints distance than between 16x16 and 32x32 ﬁngerprints distance ( 0 . 918 ) . This reveals that the increase in the number of blocks from 16x16 to 32x32 decreases consistency between the same author’s ﬁngerprints as the correlation between distances decreases signiﬁcantly . Thus , we can conclude that the 16x16 ﬁngerprints can give a more optimized balance between detail and di ﬀ erentiation since it retains correlation to the 8x8 ﬁngerprints and provides a more detailed map of the author’s complexity range . A . 3 . Average NBDM 2 per Artist Figure S2 shows the average NBDM 2 per artist . Each artist has an associated color and its relative positional deviation in di ﬀ erent quantizations is illustrated by lines of the same color . This measure , on average , has a relative positional variation between each author of 13 . 2 ± 13 . 2 , a value slightly lower than in NBDM 1 , although with a higher average standard deviation . This aspect , combined with the fact that the authors’ position varies slightly concerning their position in NBDM 1 , demonstrates that , overall , normalization has minimal impact on the measure and , thus , it does not inﬂuence the results obtained with BDM . A . 4 . Kruskal minimum spanning tree To verify the congruence of the UPGMA tree , we constructed another tree from the distance tree using the Kruskal minimum spanning tree algorithm [ 60 ] . This algorithm uses the connected graph created by the distance between authors and removes the edges’ subset that forms a tree that includes every vertex , where the sum of the weights of all the edges in the tree is minimized . The resulting tree is shown in Figure S3 and can also be viewed in more detail on the article’s website . Despite being organized in a di ﬀ erent and more sparse manner , the same connections are observed in the UPGMA tree . The tree Kruskal minimum spanning tree retains the relationships of inﬂuence between authors of di ﬀ erent artistic movements ( Titian and Diego Velazquez ; Caravaggio and Francisco de Zurbar´an ; Frida Kahlo and Amedeo Modigliani ; Sandro Botticelli and William Blake ; Claude Lorrain and Joseph Mallord William Turner ; and Peter Paul Rubens and Jean - Antoine Watteau ) , as well as shows the ﬁngerprint’s capacity of grouping some artists from the same artistic movements mutually . We can conclude from this that qualitatively the ﬁngerprints are useful description tools of the artist’s way of painting despite the algorithm used to represent the tree . A . 5 . Replication of Results All the results presented in this paper can be fully replicated , under a Linux machine , using the scripts provided at the repository https : / / github . com / asilab / panther . These include the automatic installation of the tools , download the dataset , assessment , benchmarking , measurement , and visualization of the results . First , there is the need to give execution access to the scripts using chmod + x * . sh and perform automatic installation of the tools using bash make . sh and pip3 install - r requirements . txt A . 5 . 1 . Information - based Measures Assessment To download and prepare the dataset , use script Dataset . sh . To reproduce the compression benchmark , use script Benchmark . sh . To perform all comparisons between NC , NBDM 1 and NBDM 2 use Compare . sh . 22 Figure S2 : Author’s average Normalized Block Decomposition Method ( ANBDM ) using NBDM 2 for 4 , 6 , and 8 - bit quantization . The authors are sort given the value of NBDM 2 . To see this result in more detail , please visit the website associated with the article . To replicate the impact of increasing pseudo - random substitutions of pixels for the NC and di ﬀ erent types of BDM normalizations ( NBDM 1 and NBDM 2 ) , use script Pixel _ Edition . sh . To test the di ﬀ erent values of the NC and NBDM in di ﬀ erent datasets use Diverse _ Images . sh . If you desire to replicate the cellular automata objects run ca . sh . To replicate the super - sampling experience and the results of underestimation of BDM , run Side _ Information _ Test . sh . A . 5 . 2 . Information - based measures applied to artistic paintings To perform all the pipeline execute Run . sh . To quantitize images run Quantize . sh and to trim and binarize use Trimm _ and _ Binarization . sh . To compute the average NC , NBDM 1 , and NBDM 2 for each author use scripts Average _ Complexity . sh . To compute the NC with the HDC results use scripts NC _ HDC . sh . To recreate the reports of Regional Complexity , use the following command : . / Region _ Complexity . sh . To recreate the reports of author’s Fingerprints , use the following command : . To recreate the authors’ ﬁngerprints heat maps run Fingerprints . sh . To assess the author average variation and percentage di ﬀ erence between normalized and non - normalized measures , use the following command : . / norm _ vs _ non _ norm . sh . To perform the Mantel test and view the average variance between di ﬀ erent distance matrices , use the following command : . / Mantel _ test _ and _ variation . sh . To recreate the phylogenetic trees , run Tree . sh . To make the feature ﬁle for author and style classiﬁcation , run : . / Create _ classification _ data . sh . 23 Figure S3 : Artists’ phylogenetic tree computed recurring to Kruskal minimum spanning tree . Each artist has a painting and a color of a style ( chosen based on nearest leaves ) assigned to him , as well as a description of some styles usually associated with the author . To obtain an improved view of the tree , please see the website associated to the article . To perform author classiﬁcation , run the jupyter ﬁle Painting91 _ author _ classification . ipynb . To perform style classiﬁcation , run the jupyter ﬁle Painting91 _ style _ classification . ipynb . 24