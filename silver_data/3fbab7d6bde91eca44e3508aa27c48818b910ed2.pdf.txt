Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 www . elsevier . com / locate / cogsys A parallel distributed processing model of Wason’s selection task Action editor : Steve J . Hanson a , b * Jacqueline P . Leighton , Michael R . W . Dawson a Centre for Research in Applied Measurement and Evaluation , Faculty of Education , 6 - 110 Education North Building , University of Alberta , Edmonton , Alberta , Canada T 6 G 2 G 5 b Biological Computation Project , Department of Psychology , University of Alberta , Edmonton , Alberta , Canada T 6 G 2 E 9 Received 1 September 2000 ; received in revised form 10 March 2001 ; accepted 17 June 2001 Abstract Architectural accounts of cognitive performance are important to explore because they provide the infrastructure for algorithmic theories of cognition [ Dawson , M . R . W . ( 1998 ) . Understanding cognitive science . Malden , MA : Blackwell ] . Three parallel distributed processing ( PDP ) networks were trained to generate the ‘p’ , the ‘p and not - q’ and the ‘p and q’ responses , respectively , to the conditional rule used in Wason’s selection task [ Wason , P . C . ( 1966 ) . Reasoning . In : Foss , B . M . ( Ed . ) , New Horizons in Psychology , London , Penguin ] . Afterward , each trained network was analyzed for the algorithm it developed to learn the desired response to the task . Analyses of each network’s solution to the task suggested a ‘specialized’ algorithm that focused on card location . For example , if the desired response to the task was found at card 1 , then a speciﬁc set of hidden units detected the response . In addition , we did not ﬁnd support that selecting the ‘p’ and ‘q’ response is less difﬁcult than selecting the ‘p’ and ‘not - q’ response . Human studies of the selection task usually ﬁnd that participants fail to generate the latter response , whereas most easily generate the former . We discuss how our ﬁndings can be used to ( a ) extend our understanding of selection task performance , ( b ) understand existing algorithmic theories of selection task performance , and ( c ) generate new avenues of study of the selection task . (cid:211) 2001 Elsevier Science B . V . All rights reserved . 1 . Introduction then Q and four cards displaying instances of a p , a not - p , a q , and a not - q . In the actual task , each card No other task has spurred as much research into contains a letter on one side and a number on the human reasoning as has Wason’s ( 1966 ) selection other side . Participants are instructed to test the truth task ( Evans , Newstead , & Byrne , 1993 ) . Fig . 1 or falsity of the rule by selecting the fewest cards illustrates the task , which involves presenting a possible from the set of four . Although participants participant with a conditional rule in the form of If P can see only side of each card , they are told that each card’s ﬂip side contains information that might be useful in testing the rule . * Corresponding author . Tel . : 1 1 - 780 - 492 - 1167 ; fax : 1 1 - 780 - According to propositional logic , only the pairing 492 - 0001 . of the ‘p’ ( i . e . , the antecedent ) with the ‘not - q’ ( i . e . , E - mail address : jacqueline . leighton @ ualberta . ca ( J . P . Leig - hton ) . the negation of the consequent ) falsiﬁes and , there - 1389 - 0417 / 01 / $ – see front matter (cid:211) 2001 Elsevier Science B . V . All rights reserved . PII : S1389 - 0417 ( 01 ) 00035 - 3 208 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 models theory ( 1983 ; Johnson - Laird & Byrne , 1991 ) proposes that any context that impairs participants’ ability to consider counter - examples to the selection task’s rule will hinder logical performance . Finally , Rips’ ( 1994 ) syntactic theory proposes that particip - ants fail to respond correctly to the selection task because the task calls for a sophisticated application of mental rules that many participants either do not have or have not yet mastered . One similarity among the ﬁrst three theories — pragmatic reasoning theory , Fig . 1 . Wason’s card selection task . social contract theory , and mental models — is that fore , conclusively tests the rule ( Garnham & Oakhill , each provides an algorithmic account of perform - 1994 ) . Typically only 10 % of participants select ance ; that is , each theory speciﬁes a procedural cards corresponding to ‘p’ and ‘not - q’ , however . description of how participants solve the selection Most participants select either the ‘p’ alone or the ‘p’ task . Rips’ ( 1994 ) syntactic theory also provides an and the ‘q’ ( for a complete review of the selection algorithmic account but , in addition , the theory task , the reader is referred to Evans et al . , 1993 ) . speciﬁes an architectural account of participants’ Why do so many participants fail to respond performance — a system of productions that imple - logically to the selection task ? This is a question that ments logical routines . has spurred numerous studies and a host of theories Rips’ ( 1994 ) theory suggests that a system of ( e . g . , Cheng & Holyoak , 1985 , 1989 ; Cosmides , productions underlies reasoning , but some critics 1989 ; Johnson - Laird & Byrne , 1991 ; Rips , 1994 ) . have argued that his theory is unconvincing because Unfortunately , many of these theories are algorith - it fails to reﬂect the inductive quality of human mic and do not address the question of the kind of reasoning ( e . g . , Oaksford & Chater , 1993 ) . For architecture that underlies performance . Specifying example , unlike pragmatic reasoning theory , social the architecture of cognitive performance is useful contract theory , and mental models theory , syntactic because it anchors algorithmic theories to more theory in general ignores the role of context in concrete descriptions of performance ; ‘black box’ reasoning , and the non - monotonicity of reasoning descriptions are precluded ( Dawson , 1998 ) . ( Byrne , 1989 ; Evans et al . , 1993 ) . According to Cheng and Holyoak ( 1985 , 1989 ) account for some theorists , other architectures might offer more participants’ poor performance with a pragmatic credible accounts of reasoning ( e . g . , Oaksford & reasoning theory . According to the theory , particip - Chater , 1993 ) . In particular , a connectionist architec - ants possess domain - speciﬁc schemata that , invoked ture might be more representative of human reason - in meaningful contexts , facilitate reasoning re - ing , as Shastri ( 1991 ) explains : sponses . Cheng and Holyoak ( 1985 , 1989 ) suggest that participants perform poorly on the selection task Connectionism offers an extremely efﬁcient because it lacks a meaningful context . In support , metaphor for reasoning where inference is re - they have empirically shown that logical responses to duced to spreading activation in a parallel the selection task increase when the task is framed in network . . . . The connectionist approach suggests a meaningful context , such as when participants must alternate formulations of information processing . decide which person , among four , stands in violation Thus instead of viewing a knowledge - based sys - of a permission rule ( see Liberman and Klar , 1996 , tem as a theorem prover or a production system , for a discussion of how the permission context may one may view it as a system that performs change the nature of the task ) . Cosmides’ ( 1989 ) constraint satisfaction , energy minimization , or social contract theory proposes a similar account of evidential and probabilistic reasoning ( p . 263 ) . participants’ poor performance , although the domain - speciﬁc schemata in this theory are invoked spe - Specifying the architecture of an algorithmic ciﬁcally in response to situations involving costs and account of cognitive performance is important be - beneﬁts . Alternatively , Johnson - Laird’s mental cause it provides ‘‘an account of the mental program - J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 209 ming language in which cognitive algorithms are PDP networks to extend our understanding of selec - written’’ ( Dawson , 1998 , p . 159 ) . Such an account tion task performance . First , PDP networks learn to serves to clarify theories and to extend our under - solve tasks by means of pattern classiﬁcation or standing of the cognitive performance under study . mapping input patterns to output responses . This For instance , we can pursue questions such as ‘‘how method of learning to solve tasks is compatible with might domain - speciﬁc schemata be instantiated in many of the algorithmic theories of selection task the brain ? ’’ or ‘‘are rules or some other operation performance , such as pragmatic reasoning theory underlying performance ? ’’ To begin answering such ( Cheng & Holyoak , 1985 ) . In fact , pattern classiﬁca - questions , we need to explore architectural accounts tion accounts of reasoning in general have been of reasoning alongside algorithmic accounts . Explor - proposed ( e . g . , Bechtel & Abrahamsen , 1991 ; Gobet ing functional architectural accounts of cognitive & Simon , 1998 ; Goldstone & Barsalou , 1998 ) . performance can bring us closer to more complete Pattern classiﬁcation accounts of reasoning assume theories of cognition . that people make sense of their environment by In this paper we explore whether a speciﬁc categorizing objects and events not only to make connectionist or parallel distributed processing predictions about their ( unseen ) characteristics , but ( PDP ) architecture , termed the value unit architec - also to decide upon actions in light of the categoriza - ture , can extend our understanding of participants’ tion . For example , Bechtel and Abrahamsen ( 1991 ) , performance on the selection task . Hence , we attempt reiterating an idea proposed by Margolis ( 1987 ) , to resolve the critique we levy against theories of suggest the following view of how reasoning might selection task performance ; namely , that they are not proceed according to the pattern classiﬁcation view : linked to a functional architecture . This research is exploratory since to our knowledge no one has The recognition of one pattern constitutes an simulated performance on the selection task using a internal cue which , together with the external connectionist architecture . Other investigators have cues available from outside the system , facilitates used connectionist architectures to model other kinds yet another recognition . Thus , we work our way of ( inferential ) problems but not speciﬁcally the through a complex problem by recognizing some - selection task ( e . g . , Derthick , 1991 ; Shastri , 1991 ) . thing , and with the help of that result , recognizing As a general overview of the paper , we ﬁrst something further . ( p . 141 ) discuss why PDP networks can be used to explore an architectural account of selection task performance . Viewing reasoning from the perspective of pattern Second , we provide a general introduction to PDP classiﬁcation complements theories such as Cheng networks and in particular the value unit architecture , and Holyoak’s pragmatic reasoning theory ( 1985 ) which is the speciﬁc architecture we use in the and Cosmides’ social contract theory ( 1989 ) , which present studies . Third , we illustrate how three differ - emphasize the inductive quality of reasoning . ent value unit networks were trained to generate Another important reason for employing PDP different responses to the selection task and how networks is that they characterize , albeit roughly , the each network can help us understand participants’ kind of processing that occurs in the brain ( Dawson , responses to this task . Finally , we discuss the results 1998 ) . PDP networks are considered ‘brain - like from all three networks and their relation to existing systems’ in that they are built from inter - connected , algorithmic accounts of performance on the selection simple processing units that can be used to classify task . patterns . We turn now to a description of PDP networks . 2 . Why use PDP networks to explore an 2 . 2 . A PDP network of value units architectural account of performance on the selection task ? A PDP network is a system of inter - connected , simple processing units that can be used to classify 2 . 1 . Pattern classiﬁcation patterns presented to it . A PDP network is usually There are two reasons why we would want to use made up of three kinds of processing units : ( a ) Input 210 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 units encode the stimulus or activity pattern that the units , and either ampliﬁes or attenuates the signal network will eventually classify ; ( b ) hidden units being sent from one processing unit to another . detect features or regularities in the input patterns A network is not given a ‘step by step’ procedure that can be used to determine classiﬁcation decisions ; for solving a desired task , but , is instead trained to and ( c ) output units represent the network’s response solve the task . Consider a popular supervised learn - to the input pattern ; that is , the category to which the ing procedure called the generalized delta rule pattern is to be assigned on the basis of the features ( Rumelhart , Hinton & Williams , 1986 ) . To train a or regularities that have been detected by the hidden network with this rule , one starts with a network ( of units . Processing units communicate by means of a pre - speciﬁed number of hidden units ) that has weighted connections . Fig . 2 provides an illustration small , randomly assigned connection weights . The of a typical network . network is then ‘developed’ by presenting it a set of In most cases , a processing unit carries out three training patterns , each of which is associated with a central functions : First , a processing unit computes desired response . To train a network to classify a the net input or the total signal that it receives from pattern correctly , a pattern is presented to the net - other units . A net input function is used to carry out work’s input units , and the network generates a this calculation . After the processing unit determines response to this stimulus using its existing con - its net input , it transforms it into an internal level of nection weights . The network’s response is then activity , which typically ranges between 0 and 1 . The compared against the desired output ( i . e . , the correct internal activity level is calculated by means of an response ) and an error value is computed for each of activation function . Finally , the processing unit the network’s output units . This error value is then determines the signal that needs to be sent to other fed backwards through the network , and it is used to units . This signal is created by applying an output modify connection weights in such a way that the function to the unit’s internal activity . The most next time the pattern is presented to the network , the common output function is the identity function , network’s output errors will be smaller . By repeating suggesting that the signal sent out from a unit equals this procedure a large number of times for each the unit’s internal activity . ( The reader is referred to pattern in the training set , the network’s response Dawson ( 1998 ) for a more complete explication of errors for each pattern can be reduced to near zero . the different functions . ) A weighted connection acts At the end of this procedure , the network will have a as a communication channel between two processing very speciﬁc pattern of connectivity ( in comparison Fig . 2 . Illustration of a typical PDP network , including layer of input units , hidden units , and output units . J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 211 to its random start ) and will have learned to perform the decision regions and lead to the network’s correct the desired stimulus / response pairing ( if it is pos - responses ? sible for such a pairing to be learned ) . At ﬁrst glance it might appear uninteresting to A number of different versions of the generalized investigate whether a PDP network learns the desired delta rule exist , each designed to train networks input / output response to the selection task since we whose processors have speciﬁc properties . For in - know that PDP networks , as universal Turing ma - stance , one form of the generalized delta rule is chines , should have little difﬁculty learning the task applied when a logistic equation is used as an ( Dawson , 1998 ) . Our purpose , however , is not activation function ( Rumelhart et al . , 1986 ) . A simply to see whether we can train a network to modiﬁed version of the generalized delta rule can be solve the selection task but , more importantly , to used to train networks of value units ( Dawson & explore the algorithm or how a trained network Schopﬂocher , 1992 ) . A value unit is a processor that solves the task . The exploration is not trivial since uses a Gaussian equation for its activation function . we cannot predict the algorithm a connectionist network will develop to solve a task . Exploring how 2 . 3 . Problem difﬁculty and a PDP network ’ s a trained network solves the selection task can algorithm for problem solving extend our understanding of the task and its existing theories . It is because of our interest in exploring It is possible to evaluate a problem’s difﬁculty by how a trained network solves the task that we use the the extent of a network’s requirements for learning to value unit architecture , whose hidden units often solve the problem . For instance , the number of exhibit properties which render them interpretable hidden units that a network requires to solve a ( e . g . , Berkeley , Dawson , Medler , Schopﬂocher & problem is indicative of the problem’s difﬁculty Hornsby , 1995 ; Dawson , 1998 ; Dawson , Medler & ( Dawson , 1998 ) . Hidden units allow connectionist Berkeley , 1997 ) . Next , we train a value unit network networks to solve linearly nonseparable problems . to generate a response that human participants Linearly nonseparable problems are difﬁcult to solve , commonly make to the selection task , but is incom - compared to linearly separable problems , because plete . they require the network to divide the pattern space into multiple decision regions . In contrast , linearly separable problems require the network to make a 3 . Network 1 : selection of the ‘p’ card single division in the pattern space so as to create two decision regions . Linearly nonseparable prob - The goal of the ﬁrst study was to train a value unit lems can be solved by networks that have a layer of PDP network to generate the ‘p’ card in response to hidden units . Each hidden unit can be viewed as the selection task . We trained this ﬁrst network to creating a cut in the pattern space . Hence , the greater generate the ‘p’ card for two reasons : First , particip - the number of hidden units required by a network to ants typically select the ‘p’ card alone in response to solve a problem , the greater the number of decision the selection task ( see Evans et al . , 1993 ) . Second , regions or ‘cuts’ in the pattern space demanded by we wanted to train a network to generate a compara - the task . tively simple response , the selection of only one Later in the paper , we will show how the activity card , before training a network to generate a more within hidden units can be analyzed and interpreted difﬁcult response . The purpose of training this to uncover the algorithm by which a network learns network ( and others which will be described later in to solve a particular task . Interpreting hidden unit studies 2 and 3 ) is to determine the algorithm by activity informs us of the speciﬁc features that deﬁne which the network learns to generate a simple , but the decision regions created by the network to solve incomplete response , to the task . Ultimately , we the task . Although analyzing hidden unit activity want to examine the trained network’s algorithm to does not necessarily inform the question of problem see what it can teach us about performance on the or task difﬁculty , hidden unit activity does inform selection task and existing algorithmic theories of the the question of how the network solved the task ; that task . In the next section we discuss how we trained is , what are the important pattern features that deﬁne the network . 212 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 1 3 . 1 . Method Binary coding of conditional rule types and cards used to train networks and generate input patterns 3 . 1 . 1 . PDP version of Wason ’ s selection task : Text form Binary form network architecture When human participants are presented with the Rules : If vowel then even number 0 0 1 0 selection task , they already have a great deal of If vowel then odd number 0 0 1 1 knowledge about its components . For instance , par - If consonant then even number 0 1 1 0 ticipants come to the task with knowledge of ( a ) the If consonant then odd number 0 1 1 1 connective ‘if then’ , ( b ) different kinds of numbers If even number then vowel 1 0 0 0 ( i . e . , odd versus even ) , and ( c ) different letters ( i . e . , If even number then consonant 1 0 0 1 If odd number then vowel 1 1 0 0 vowels versus consonants ) . In contrast , PDP net - If odd number then consonant 1 1 0 1 works do not start with this kind of knowledge . PDP networks must ﬁrst be given this preliminary in - Cards : formation via some format that the network can A 0 0 0 process . Furthermore , the responses or behavior the E 0 0 1 J 0 1 0 network generates at the end of training should be K 0 1 1 broad or general enough ( i . e . , applicable across a 4 1 0 0 large set of distinct patterns ) to be of interest to 6 1 0 1 psychologists . Hence , we needed to ﬁrst ﬁnd a way 5 1 1 0 to encode the task for the network and , second , to 7 1 1 1 create a sufﬁcient number of input stimuli so that the network could be trained on a large number of patterns . their categories in a form that is easily available to To solve these issues , a binary code was de - the network . As illustrated in Table 1 , each card is veloped that allowed a representation of both the represented with three input units in such a way that task’s conditional rule and the four cards using 16 the ﬁrst two input units represent the card’s category , input units . Four inputs units were used to represent and the third input represents the card’s exemplar of the rule . The ﬁrst two input units reﬂected the that category . For instance , the ﬁrst two zeros in the antecedent of the rule , whereas the last two units code ‘000’ indicate that this string is a ‘vowel’ while reﬂected the consequent of the rule ( see Table 1 ) . the third zero indicates that , speciﬁcally , this string is 1 Four sets of three input units were then used to a letter ‘A . ’ represent the card categories . The ﬁrst two input 1 units of each set were used to represent the card’s Although the encoding of ‘vowel’ ( i . e . , 00 ) is on the surface more similar to the encoding of ‘even number’ ( i . e . , 10 ) than to category membership , whereas the last unit of each ‘odd number’ ( i . e . , 11 ) , this surface similarity should not bias the set was used to represent its speciﬁc instance . Using network’s solution . The reason for this is that our training set this encoding scheme , a training set was developed included all possible permutations of rules and associated solu - that included eight different conditional rules and tions ; hence , that the rules and ‘cards’ share some surface eight different instances of card categories ( two similarity among a portion of the patterns is offset by the lack of similarity shared among the remaining portion of patterns . For vowels , two consonants , two even numbers , and two example , suppose the network’s task is to learn to select the ‘p’ odd numbers ) . These card instances were crossed ( antecedent ) and the ‘q’ ( consequent ) in response to the rules it is with 24 unique orders generated from assembling presented ( see study 3 in this paper ) . In response to one form of four ‘cards’ in all possible combinations . This latter the rule , ‘‘if vowel then even’’ ( 0010 ) , the network would learn to step led to 384 unique orders of card values , which select the vowel card ( 00 ) and the even card ( 10 ) . In response to another rule , ‘‘if vowel then odd’’ ( 0011 ) , the network would were then crossed with each of the eight rules to learn to select the vowel card ( 00 ) and the odd card ( 11 ) . Hence , produce a ﬁnal training set of 3072 input patterns . any surface similarity between some rules and some cards should We believe that our encoding scheme captures the not bias the network’s solution of the task because the network underlying structure of the selection task . First , our learns to solve the task by responding to the full set of rules and binary coding scheme distinguishes exemplars from cards in the training set . J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 213 Second , because the network was examined after units , one corresponding to each card . The network it was presented a large number of training patterns , was trained to respond by turning ‘on’ one of its four it had the opportunity to determine for itself the output units . For example , output unit 1 turned ‘on’ underlying nature of the task . For example , all of the ( i . e . , was activated to a value of 1 ) if card 1 held the networks that we trained learned to ignore the last desired response ( i . e . , afﬁrmed the antecedent of the ‘bit’ of the encoded cards , and instead learned to rule ) , but turned ‘off’ if card 1 did not hold this select cards based on the ﬁrst two bits ( i . e . , cate - response . Only one output unit was activated in gory ) . This is exactly what human participants are response to an input pattern because , for network 1 , expected to distinguish when they are presented with the desired response involved only the selection of the selection task ; they automatically focus on card the ‘p’ card . After the network learned the solution , category as opposed to card instance . we examined this ‘mature’ network for how it solved As shown in Fig . 3 , network 1 required three the task . hidden units to learn the task . This was because pilot A mature network responds accurately and reliably simulations revealed that three hidden units was the to a complete set of training patterns . In this study , minimum number of hidden units required for the reliability of response required that ( a ) the network network to converge ( i . e . , to learn the desired be able to identify the presented rule , ( b ) the network mapping between input pattern and output response ) . have some representation that assigned each input If fewer than three hidden units were used , then the symbol to a more abstract category ( e . g . , differentiat - network was unable to generate the desired response ing between ‘vowel’ and ‘odd number’ ) , and ( c ) the to every pattern in the training set . We used the network have some representation of the ‘content’ of minimum number of hidden units to study the the presented rule , such that its output would indicate network’s solution of the problem ( and did not use what could be done to test the validity of the rule . more hidden units ) because it has been argued that We believe that network performance consistent with this kind of network is most likely to produce an these three requirements for such a large number of internal structure that can be tractably interpreted different patterns reﬂecting the selection task has ( e . g . , Berkeley et al . , 1995 ) . developed sufﬁcient abilities to be of psychological Fig . 3 also shows that the network had four output interest . In short , such a network could be used to Fig . 3 . Illustration of the PDP network trained to generate the card afﬁrming the antecedent of the conditional rule ( i . e . , the ‘p’ card ) . 214 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 extend our understanding of selection task perform - solved the task involved wire - tapping each indi - ance and existing algorithmic theories of the selec - vidual hidden unit for the input features it detected . tion task . Wire - tapping is one procedure that can be used to determine how PDP networks , in particular value 3 . 1 . 2 . Training unit networks , solve problems ( e . g . , Dawson , 1998 ; Network 1 was trained using Dawson and Schop - Moorehead , Haig , & Clement , 1989 ) . Wiretapping ﬂocher’s ( 1992 ) modiﬁcation of Rumelhart et al . ’s involves recording the responses of the hidden units ( 1986 ) generalized delta rule . The network was to the patterns in the training set . After the network trained with a learning rate of 0 . 001 and a momen - is trained on a set of input patterns , the patterns are tum of zero . Connection weights and unit biases ( i . e . , presented again to the network while their activities the mean of the Gaussian ) were randomly selected in individual hidden units are recorded . The recorded from the range of 2 1 . 0 to 1 1 . 0 . The weights and activities are plotted and examined for meaningful biases were updated after the presentation of each conﬁgurations . The conﬁgurations provide clues as pattern . The order of pattern presentation was ran - to how the network is solving the task ; that is , the domized during each epoch ( an epoch is deﬁned as conﬁgurations indicate which patterns fall into each the presentation of all patterns in the training set ) . of the decision regions created by the network to This was done to ensure that the network’s learning solve the task . of the task was contingent on the speciﬁc input patterns and not on their speciﬁc sequence of pre - 3 . 2 . 1 . Jittered density plots sentation . Jittered density plots of each hidden unit were The network was trained until it generated a ‘hit’ constructed subsequent to wiretapping , as shown in in response to every pattern . A desired response or Fig . 4 . A jittered density plot illustrates the dis - ‘hit’ consisted of an activation of 0 . 9 or higher in the tribution of activation values produced in a single output unit corresponding to the ‘p’ card along with hidden unit of a mature network following a pre - activations of 0 . 1 or lower in output units corre - sentation of a full set of input patterns . A single dot sponding to cards not afﬁrming the antecedent of the in the plot represents the activation that one input rule . The network converged to a solution to this pattern produces in a hidden unit . Hence , one plot problem after 83 epochs . Following training , network illustrates as many dots as there are input patterns . performance on the selection task was considered The x - axis on the jittered density plot ranges from 0 comparable to human performance in so far as the to 1 and shows the range of activation values network generated a reliable response to speciﬁc generated by the input pattern set . Dots are also input . That is , the network generated the ‘p’ card in randomly jittered along the y - axis to make them as response to the rule in the task , which is consistent discernible as possible . with a pattern typically shown by human particip - Jittered density plots of value unit networks are ants . frequently highly structured or ‘banded . ’ The distinct bands represent groups of input patterns that share 3 . 2 . Results : deﬁnite features of hidden units similar features and produce similar activations in a hidden unit . By examining the features that fall into The purpose of this ﬁrst study was to interpret the each band , it is possible to identify the features that method by which network 1 learned to solve the the network used to solve a problem . From the task ; that is , learned to select the ‘p’ card in response presence of the bands , we know that hidden units are to the conditional rule . Interpreting network 1 in - reliably detecting speciﬁc input features in solving volved examining each of the network’s hidden units the task ( Berkeley et al . , 1995 ) . Although bands for the input features it detected . Once the relation - provide information about the features used in ship between hidden units and input features was solving a problem , the bands do not necessarily known , it was then possible to determine how the provide information about the problem’s complexity . network solved the task . The number of hidden units is a better indicator of The ﬁrst step to understanding how the network task complexity . While the number of hidden units J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 215 Fig . 4 . Jittered density plots for each of the three hidden value units in network 1 . required by a network to solve a task indicates the example , a perfectly positive correlation between number of decision regions in the pattern space , input units 6 and 7 indicates that these units always bands reﬂect the features that characterize the deci - assume the same value ; if input unit 6 has a value of sion regions . As shown in Fig . 4 , all three hidden 1 . 0 , then so does input unit 7 . In contrast , a perfectly units in network 1 exhibited a high degree of negative correlation between a pair of input units banding . suggests that whenever one input unit is 1 . 0 , the With the aid of descriptive statistics , it is possible other is 0 . 0 and vice versa . Network 1’s hidden units to identify the speciﬁc features that cluster into each detected only deﬁnite binary features . A description band and , moreover , how the network uses this of the deﬁnite binary features detected by each conﬁguration or ‘carving of the input space’ to solve hidden unit in network 1 is presented in Table 2 . a task . By calculating the Pearson product - moment correlation among the patterns in a band , it is 3 . 2 . 2 . Interpretation of deﬁnite binary features possible to learn if a hidden unit is detecting deﬁnite An inspection of Table 2 suggests that network 1 binary features . A deﬁnite binary feature indicates a solved the task by detecting binary features repre - perfectly reliable correlation between input units . For senting rules and speciﬁc cards . First , although each hidden unit detected all eight rules , each hidden unit Table 2 detected a speciﬁc card . For example , notice that Deﬁnite features for bands from hidden units of network 1 hidden unit 0 was highly activated by patterns ( i . e . , a Hidden Band Deﬁnite features n band C in Table 2 ) whose deﬁnite features showed unit label input units 10 and 11 sharing a correlation of 1 . 0 with input units 0 and 1 , respectively . Recall that 0 A I0 – I2 , I0 – I10 , I2 5 I10 1152 0 B I0 – I2 , I1 – I11 1152 input units 10 and 11 represent card 3 values , 0 C I0 – I2 , I0 5 I10 , I1 5 I11 , 768 whereas input units 0 and 1 represent the antecedent I2 – I10 of the rule . In other words , hidden unit 0 was highly 1 A I0 – I2 , I0 – I7 , I2 5 I7 1152 activated when the desired response , ‘p’ , was located 1 B I0 – I2 , I1 – I8 1152 at card 3 . Notice also that hidden unit 0 was 1 C I0 – I2 , I0 5 I7 , I1 5 I8 768 I2 – I7 moderately activated by patterns ( i . e . , bands A and 2 A I0 – I2 , I0 – I4 , I2 5 I4 1152 B ) whose deﬁnite features showed input units 10 and 2 B I0 – I2 , I1 – I5 1152 11 sharing a correlation of 2 1 . 0 with input units 0 2 C I0 – I2 , I0 5 I4 , I1 5 I5 768 and 1 , respectively . In other words , hidden unit 0 I2 – I4 was not highly activated when the value at card 3 ‘ – ’ indicates a perfectly negative correlation between input failed to match the antecedent of the rule . units ; ‘ 5 ’ indicates a perfectly positive correlation between input The same analysis can be applied to hidden units 1 units . a n , number of patterns falling in each band . and 2 . For example , hidden unit 1 detected desired 216 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 responses at card 2 ( i . e . , inputs units 7 through 9 ) , generally . Cosmides’ ( 1989 ) social contract theory and hidden unit 2 detected desired responses at card and Johnson - Laird’s mental models theory ( 1983 ) 1 ( i . e . , input units 4 through 6 ) . Although card 4 are also unclear about the inﬂuence the evidence values were not directly detected by any of the might have on participants’ performance . All three hidden units , card 4 values were detected indirectly theories focus primarily on the nature of the rule and by all three hidden units . In value unit architectures , its associated context . In contrast , according to Rips’ it is possible for a zero signal to moderate high ( 1994 ) syntactic theory , the nature of the evidence activity or a ‘1’ response if both the ‘bias’ of the should have little inﬂuence on performance since architecture is equal to zero and the signal being sent mental rules operate on the syntax of the selection is equal to zero . In other words , in a state where task rule . In the next study , we trained a network to none of the three hidden units were activated ( i . e . , solve the task by selecting the ‘p’ and ‘not - q’ cards . the desired response was not found at card 1 , 2 or 3 ) , This is a response rarely exhibited by human par - this state activated output unit or card 4 ( i . e . , input ticipants . units 13 through 15 ) . 3 . 3 . Discussion 4 . Network 2 : selection of the ‘p’ card and the Network 1 learned to select the ‘p’ card in ‘not - q’ card response to the conditional rule by having each hidden unit detect values at speciﬁc card locations . 4 . 1 . Method This ‘specialized’ hidden unit algorithm did not discriminate among the rules used in the task since 4 . 1 . 1 . Network architecture all three hidden units detected all rules . Instead , the Network 2 was trained under the same method specialized algorithm discriminated among card loca - used to train network 1 — identical input encoding , tions to solve the task . We speculate that the net - training patterns , and output units were used . This work’s speciﬁc focus on card location points to the time , however , two output units instead of one were importance of the evidence in the selection task . The designed to turn ‘on’ in response to every input cards in the selection task illustrate the evidence with pattern since the solution of the task involved the which to test the rule . Although few existing theories selection of two ‘cards’ . As shown in Fig . 5 , network of selection task performance focus on the evidence , 2 required eight hidden units instead of three to learn some investigators have proposed that the kind of the task . Pilot simulations revealed that the network evidence available to participants plays an important could not learn to generate the desired mapping from role in how participants choose to test a rule ( e . g . , inputs to outputs with fewer than eight hidden units Klayman & Ha , 1987 ; Liberman & Klar , 1996 ) . For when the network was required to select two ‘cards . ’ example , Liberman & Klar ( 1996 ) suggested that if participants perceive the evidence needed to test a hypothesis as atypical , they might forego using the 4 . 1 . 2 . Training atypical evidence and choose to test the hypothesis Network 2 was trained similarly to network 1 with using more conventional evidence . The results ob - the exception that network 2 was trained to select tained from network 1 suggest that the evidence in two responses instead of one . Because network 2 the selection task might play an important role in selected two responses , it needed to learn to dis - participants’ responses . tinguish between propositions — ‘p’ and ‘not - q’ — At this time , it is unclear how the ﬁndings in its responses . We did not indicate to the network obtained from network 1 support or challenge exist - before its training which values represented ‘p’ and ing theories of selection task performance . For which values represented ‘not - q’ because learning to example , Cheng and Holyoak’s ( 1985 , 1989 ) prag - make this distinction is an integral part of learning matic reasoning theory is vague about how particip - the task . When human beings solve the selection ants might view the evidence or its role in reasoning task , they approach the task already knowing which J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 217 Fig . 5 . Illustration of the PDP network trained to generate both the card afﬁrming the antecedent and the card negating the consequent of the conditional rule ( i . e . , the ‘p’ and the ‘not - q’ cards ) . values represent ‘p’ and which values represent ‘not - the selection task ; they automatically focus on card q , ’ but at some point in their learning history human category as opposed to card instance . beings have had to learn to make the distinction between propositions . Learning to distinguish propo - 4 . 1 . 3 . Results sitions was part of the network’s training on the task . Network 2 was analyzed following the same As with network 1 , prior to training , the network’s approach used to analyze network 1 . As illustrated in connection weights were randomly set to values Figs . 6 and 7 , jittered density plots of each of the between 2 1 . 0 and 1 1 . 0 , while unit biases were set eight hidden units in network 2 revealed a high to 0 . 1 . The learning rate was 0 . 001 and no momen - degree of banding . Such pronounced banding sug - tum was used . At the end of training , the network gested that the network’s solution to the task in - generated a ‘hit’ in response to every pattern . A volved the detection of deﬁnite features . An exami - desired response or ‘hit’ consisted of an activation of nation of the plots , furthermore , suggested that pairs 0 . 9 or higher in the output units corresponding to the of hidden units had similar patterns of banding ; for desired response ( i . e . , ‘p’ or ‘not - q’ ) . An activation example , hidden units 0 and 6 , hidden units 1 and 4 , of 0 . 1 or lower characterized outputs units corre - hidden units 2 and 5 , and hidden units 3 and 7 . The sponding to other responses . The network learned to visual similarity observed in the plots between pairs generate the desired response to all patterns after 414 of hidden units was supported when we ran a epochs . correlation among hidden unit activity . In particular , In addition , because the network was examined we discovered that the activity of hidden units 3 and after it was presented a large number of training 7 shared a correlation of 2 0 . 99 when a desired patterns , it had the opportunity to determine for itself response was located at card 1 ( see Tables 3 and 4 ) ; the underlying nature of the task . For example , all of hidden units 0 and 6 shared a correlation of 0 . 99 the networks that we trained learned to ignore the when a desired response was located at card 2 ; last ‘bit’ of the encoded cards , and instead learned to hidden units 2 and 5 shared a correlation of 1 when a select cards based on the ﬁrst two bits ( i . e . , cate - desired response was located at card 3 ; and hidden gory ) . This is exactly what human participants are units 1 and 4 shared a correlation of 0 . 81 when a expected to distinguish when they are presented with desired response was located at card 4 . Strong 218 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Fig . 6 . Jittered density plots for the ﬁrst set of four hidden value units used in network 2 . Fig . 7 . Jittered density plots for the second set of four hidden value units used in network 2 . correlations between pairs of hidden units disap - through 4 represent the rule of the task , the ﬁrst two peared when undesired responses were located at bits represent the antecedent of the rule while the last their respective card locations . two bits represent the consequent . Hidden unit 2 was An examination of the deﬁnite features detected also highly activated by patterns that had a desired by network 2’s hidden units suggested a ‘specialized’ response ( in relation to the rule ) located at card 3 . algorithm similar to that found for network 1 . Tables This means that input patterns that had a desired 5 – 8 show the exhaustive list of deﬁnite features that response — ‘p’ or ‘not - q’ — located at card 3 highly all eight hidden units detected . To illustrate network activated hidden unit 2 . 2’s algorithm , we will focus on hidden unit 2 ( see Hidden unit 2’s activity was highly correlated with Table 7 ) . Although it would be too laborious to hidden unit 5’s activity in detecting desired re - describe here the entire list of deﬁnite features that sponses at card 3 . Decoding the list of deﬁnite hidden unit 2 detected , decoding the list indicates features detected by hidden unit 5 indicates that this that hidden unit 2 was highly activated by patterns hidden unit was highly activated by patterns that had whose deﬁnite features had the following values at the following values at input units 1 through 4 : 0011 , input units 1 through 4 : 0011 , 1100 , 0110 , 1001 , 1100 , 0110 , 1001 , 0111 , and 1000 . Hidden unit 5 did 0111 , 1110 , 0010 , 1101 . Recall that input units 1 not detect any deﬁnite features associated with card J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 219 Table 3 Correlation among hidden units when cards 1 and 2 are selected — network 2 H0 H1 H2 H3 H4 H5 H6 H7 Card 1 : H0 1 H1 0 . 09 1 H2 0 . 16 2 0 . 32 1 H3 0 2 0 . 11 0 1 H4 0 . 02 2 0 . 31 0 . 02 2 0 . 19 1 H5 0 2 0 . 24 2 0 . 28 0 . 154 0 . 18 1 H6 0 . 542 2 0 . 1 2 0 . 1 2 0 . 13 0 . 04 0 . 16 1 H7 0 0 . 09 0 2 0 . 99 0 . 212 0 0 . 144 1 Card 2 : H0 1 H1 0 1 H2 0 . 04 2 0 . 32 1 H3 2 0 . 16 2 0 . 25 2 0 . 21 1 H4 0 . 06 2 0 . 31 0 . 02 0 . 03 1 H5 2 0 . 18 2 0 . 24 2 0 . 28 0 . 02 0 . 181 1 H6 0 . 996 0 0 . 02 2 0 . 16 0 . 07 2 0 . 1 1 H7 0 . 191 2 0 . 11 2 0 . 13 2 0 . 34 0 . 197 0 . 105 0 . 21 1 Table 4 Correlation among hidden units when cards 3 and 4 are selected — network 2 H0 H1 H2 H3 H4 H5 H6 H7 Card 3 : H0 1 H1 0 . 09 1 H2 0 2 0 . 24 1 H3 0 . 307 2 0 . 25 0 . 03 1 H4 0 . 02 2 0 . 31 0 . 18 0 . 03 1 H5 0 2 0 . 24 1 0 . 03 0 . 18 1 H6 0 . 541 2 0 . 1 0 . 161 0 . 03 0 . 04 0 . 16 1 H7 2 0 . 1 2 0 . 11 0 . 106 2 0 . 34 0 . 196 0 . 105 2 0 . 22 1 Card 4 : H0 1 H1 2 0 . 1 1 H2 0 . 16 2 0 . 21 1 H3 0 . 309 2 0 . 1 2 0 . 21 1 H4 2 0 . 1 0 . 814 2 0 . 1 2 0 . 15 1 H5 0 0 . 748 2 0 . 28 0 . 03 0 . 224 1 H6 0 . 541 0 . 07 2 0 . 1 0 . 03 0 0 . 159 1 H7 2 0 . 1 0 . 173 2 0 . 13 2 0 . 34 0 . 163 0 . 106 2 0 . 22 1 values . In short , hidden units 2 and 5 were both 4 . 2 . Discussion highly activated by a large set of rules and helped to detect responses located at card 3 . Similar accounts Network 2 solved the task by means of specialized may be made for the remaining pairs of hidden units ‘pairs’ of hidden units . In particular , hidden units 0 ( see Tables 5 , 6 and 8 ) . and 6 detected desired responses located at card 2 , 220 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 5 Deﬁnite features for bands from hidden units 0 and 6 of network 2 a H0 - Deﬁnite features n H6 - Deﬁnite features n bands bands A I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I7 , 192 A I0 – I2 1344 I0 – I8 , I1 5 I2 , I1 – I3 , I1 5 I7 , I1 5 I8 , I2 – I3 , I2 5 I7 , I2 5 I8 , B I0 – I2 , I1 – I3 576 I3 – I7 , I3 – I8 , I7 5 I8 C I0 5 I1 , I0 – I2 , I0 – I3 , I0 5 I7 , 192 B I0 5 I1 , I0 – I2 , I0 5 I3 , I0 – I7 , 192 I0 – I8 , I1 – I2 , I1 – I3 , I1 5 I7 , I0 – I8 , I1 – I2 , I1 5 I3 , I1 – I7 , I1 – I8 , I2 5 I3 , I2 – I7 , I2 5 I8 , I1 – I8 , I2 – I3 , I2 5 I7 , I2 5 I8 , I3 – I7 , I3 5 I8 , I7 – I8 I3 – I7 , I3 – I8 , I7 5 I8 D I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I7 , 192 C I0 – I2 , I0 5 I7 , I1 – I3 384 I0 5 I8 , I1 – I2 , I1 – I3 , I1 – I7 , I1 5 I8 , I2 – I7 , I3 – I8 I1 5 I8 , I2 5 I3 , I2 5 I7 , I2 – I8 , I3 5 I7 , I3 – I8 , I7 – I8 D I0 – I2 , I1 5 I3 576 E I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I7 , 192 E I0 – I1 , I0 – I2 , I0 5 I3 , I0 5 I7 , 192 I0 5 I8 , I1 – I2 , I1 – I3 , I1 – I7 , I0 5 I8 , I1 5 I2 , I1 – I3 , I1 – I7 , I1 5 I8 , I2 5 I3 , I2 5 I7 , I2 – I8 , I1 – I8 , I2 – I3 , I2 – I7 , I2 – I8 I3 5 I7 , I3 – I8 , I7 – I8 I3 5 I7 , I3 5 I8 , I7 5 I8 F I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I7 , 192 I0 5 I8 , I1 5 I2 , I1 – I3 , I1 5 I7 , I1 – I8 , I2 – I3 , I2 5 I7 , I2 – I8 , I3 – I7 , I3 5 I8 , I7 – I8 G I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I7 , 192 I0 – I8 , I1 – I2 , I1 – I3 , I1 – I7 , I1 – I8 , I2 5 I3 , I2 5 I7 , I2 5 I8 , I3 5 I7 , I3 5 I8 , I7 5 I8 H I0 – I2 , I1 5 I3 768 I I0 – I2 , I0 5 I7 , I1 – I3 , I1 – I8 , 384 I2 – I7 , I3 5 I8 ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input units . a n , number of patterns falling in each band . hidden units 1 and 4 detected desired responses about both network 1 and network 2 is that their located at card 4 , hidden units 2 and 5 detected algorithms for solving the tasks involved ‘special - desired responses located at card 3 , and hidden units ized’ hidden units detecting desired responses at 3 and 7 detected desired responses located at card 1 . speciﬁc card locations . In comparison to the task network 1 had to solve , network 2’s task was more difﬁcult . Whereas net - work 1 required only three hidden units to solve its 5 . Network 3 : selection of the ‘p’ card and the task , network 2 required eight hidden units to solve ‘q’ card its task . It is not surprising that network 2 required a greater number of hidden units to solve its task , Both networks 1 and 2 solved the task by means however , given that it generated two responses of specialized hidden units that focused on card instead of just the one . Nevertheless , what is striking location . That hidden units specialized to discrimi - J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 221 nate card locations was intriguing to us because this were set to zero . The learning rate was 0 . 001 and no aspect of the selection task has not been examined momentum was used . At the end of training , the closely in the past . However , we were not only network generated a ‘hit’ in response to every intrigued by this ﬁnding but also by the apparent pattern . A desired response or ‘hit’ consisted of an difﬁculty of generating two card values instead of activation of 0 . 9 or higher in the output units just one . Although we expected the selection of two corresponding to the ‘p’ and ‘q’ cards , and an card values to be a more difﬁcult task , we did not activation of 0 . 1 or lower in output units corre - expect network 2 to need more than double the sponding to the other cards . The network learned to hidden units required to train network 1 . Recall that select the desired responses after 115 epochs of the number of hidden units required by a network to training . solve a task is indicative of the task’s difﬁculty . We conjectured that another reason for network 2’s task difﬁculty might have something to do with needing 5 . 2 . Results to select the ‘not - q’ response . Solving the task by selecting the ‘not - q’ response is highly uncommon As shown in Figs . 8 and 9 , jittered density plots of for human participants ; it is much more common for each of the hidden units displayed a high degree of participants to select the ‘p’ card or both the ‘p’ and banding , which suggested that network 3’s solution ‘q’ cards ( Evans et al . , 1993 ) . involved the detection of deﬁnite features . An in - We tested our conjecture by training a third spection of the jittered density plots indicated that network to select both the ‘p’ and the ‘q’ cards . In some hidden units were detecting similar deﬁnite this way , we hold constant the number of cards the features . For example , four out of the eight hidden network must select in responding to the task , while units ( i . e . , hidden units 0 , 2 , 4 , and 6 ) had similar at the same time testing to see if selecting the ‘q’ jittered density plots . Tables 9 and 10 show the response is easier to learn than the ‘not - q’ response . correlations among the hidden unit activity levels . Training a third network to select the ‘p’ and ‘q’ also From the tables , we see that the activity levels of served as a further test of the algorithms found for both hidden units 3 and 4 and hidden units 5 and 7 both networks 1 and 2 . correlated 0 . 99 when a desired response was located at card 1 . In contrast , when a desired response was located at card 2 , hidden units 0 and 4 shared a 5 . 1 . Method correlation of 0 . 99 . Moreover , when a desired re - sponse was located at card 3 , hidden units 4 and 6 5 . 1 . 1 . Network architecture shared a correlation of 0 . 99 , and when a desired The same method used to train both networks 1 response was located at card 4 , hidden unit 2 and 4 and 2 was used to train network 3 . As with network shared a correlation of 0 . 99 . Unlike network 2 , 2 , two output units were designed to turn ‘on’ in detecting a desired response at card 1 required four response to every input pattern since the desired hidden units , while detecting desired responses at response involved the selection of two cards . Sur - other card locations required only two . In addition , prisingly , we found that network 3 also required hidden unit 4 was involved in all response selections . eight hidden units to converge , which is the same A closer analysis of how network 3 solved the task number of hidden units required by network 2 . We revealed several interesting results . First , the hidden had expected network 3 to require fewer hidden units units in network 3 did not detect as many deﬁnite based on our prediction that selecting the ‘q’ card features in solving the task as we found for network might be more easily learned than selecting the 2 . For example , notice that network 3’s jittered ‘not - q’ card . density plots did not exhibit as many individual bands for each hidden unit as we observed for 5 . 1 . 2 . Training network 2 . Second , and more speciﬁcally , an inspec - As with networks 1 and 2 , prior to training , tion of the deﬁnite features detected by hidden unit 4 network 3’s connection weights were randomly set to revealed a correspondence to the four input units values between 2 1 . 0 to 1 1 . 0 , while its unit biases used to represent the rule in the task . Table 13 shows 222 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 6 Deﬁnite features for bands from hidden units 1 and 4 of network 2 a H1 - Deﬁnite features n H4 - Deﬁnite features n bands bands A I0 – I2 , I1 – I14 960 A I0 5 I1 , I0 – I2 , I0 – I13 , I0 5 I14 , 384 I1 – I2 , I1 – I13 , I1 5 I14 , I2 5 I13 , B I0 – I1 , I0 – I2 , I0 – I3 , I1 5 I2 , 384 I2 – I14 , I13 – I14 I1 5 I3 , I2 5 I3 , I13 5 I14 C I0 5 I1 , I0 – I2 , I0 5 I3 , I0 5 I13 , 192 B I0 5 I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 I0 – I14 , I1 – I2 , I1 5 I3 , I1 – I13 , I0 – I14 , I1 – I2 , I1 5 I3 , I1 – I13 , I1 – I4 , I2 – I3 , I2 – I13 , I2 5 I14 , I1 – I14 , I2 – I3 , I2 5 I13 , I2 5 I14 , I3 5 I13 , I3 – I14 , I13 – I14 I3 – I13 , I3 – I14 , I13 5 I14 D I0 5 I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 C I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I13 , 192 I0 5 I14 , I1 – I2 , I1 – I3 , I1 – I13 , I0 – I14 , I1 – I2 , I1 – I3 , I1 – I13 , I1 5 I14 , I2 5 I3 , I2 5 I13 , I2 – I14 , I1 – I14 , I2 5 I3 , I2 5 I13 , I2 5 I14 , I3 5 I13 , I3 – I14 , I13 – I14 I3 5 I13 , I3 5 I14 , I13 5 I14 E I0 5 I1 , I0 – I2 , I0 5 I3 , I0 5 I13 , 192 D I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 I0 5 I14 , I1 – I2 , I1 5 I3 , I1 5 I13 , I0 5 I14 , I1 5 I2 , I1 – I3 , I1 5 I13 , I1 5 I14 , I2 – I3 , I2 – I13 , I2 – I14 , I1 – I14 , I2 – I3 , I2 5 I13 , I2 – I14 , I3 5 I13 , I3 5 I14 , I13 5 I14 I3 – I13 , I3 5 I14 , I13 – I14 F I0 – I1 , I0 – I2 , I0 – I3 , I0 – I13 , 192 E I0 – I1 , I0 – I2 , I0 – I3 , I0 – I13 , 192 I0 5 I14 , I1 5 I2 , I1 5 I3 , I1 5 I13 , I0 5 I14 , I1 5 I2 , I1 5 I3 , I1 5 I13 , I1 – I14 , I2 5 I3 , I2 5 I13 , I2 5 I14 , I1 – I14 , I2 5 I3 , I2 5 I13 , I2 – I14 , I3 5 I13 , I3 – I14 , I13 – I14 I3 5 I13 , I3 – I14 , I13 – I14 G I0 – I1 , I0 – I2 , I0 – I3 , I0 5 I13 , 192 F I0 – I1 , I0 – I2 , I0 – I3 , I0 5 I13 , 192 I0 – I14 , I1 5 I2 , I1 5 I3 , I1 – I13 , I0 – I14 , I1 5 I2 , I1 5 I3 , I1 – I13 , I1 5 I14 , I2 5 I3 , I2 – I13 , I2 5 I14 , I1 5 I14 , I2 5 I3 , I2 – I13 , I2 5 I14 , I3 – I13 , I3 5 I14 , I13 – I14 I3 – I13 , I3 5 I14 , I13 – I14 H I0 – I1 , I0 – I2 , I0 5 I3 , I0 5 I13 , 192 G I0 – I1 , I0 – I2 , I0 5 I3 , I0 5 I13 , 192 I0 – I14 , I1 5 I2 , I1 – I3 , I1 – I13 , I0 – I14 , I1 5 I2 , I1 – I3 , I1 – I13 , I1 5 I14 , I2 – I3 , I2 – I13 , I2 5 I14 , I1 5 I14 , I2 – I3 , I2 – I13 , I2 5 I14 , I3 5 I13 , I3 – I14 , I13 – I14 I3 5 I13 , I3 – I14 , I13 – I14 I I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 H I0 5 I1 , I0 – I2 , I0 5 I3 , I0 5 I13 , 192 I0 – I14 , I1 5 I2 , I1 – I3 , I1 5 I13 , I0 5 I14 , I1 – I2 , I1 5 I3 , I1 5 I13 , I1 5 I14 , I2 – I3 , I2 5 I13 , I2 5 I14 , I1 5 I14 , I2 – I3 , I2 – I13 , I2 – I14 , I3 – I13 , I3 – I14 , I13 5 I14 I3 5 I13 , I3 5 I14 , I13 5 I14 J I0 5 I1 , I0 – I2 , I0 – I3 , I0 5 I13 , 192 I I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 I0 5 I14 , I1 – I2 , I1 – I3 , I1 5 I13 , I0 – I14 , I1 5 I2 , I1 – I3 , I1 5 I13 , I1 5 I14 , I2 5 I3 , I2 – I13 , I2 – I14 , I1 5 I14 , I2 – I3 , I2 5 I13 , I2 5 I14 , I3 – I13 , I3 – I14 , I13 5 I14 I3 – I13 , I3 – I14 , I13 5 I14 K I0 5 I1 , I0 – I2 , I0 5 I3 , I0 – I13 , 192 J I0 5 I1 , I0 – I2 , I0 – I3 , I0 5 I13 , 192 I0 5 I14 , I1 – I2 , I1 5 I3 , I1 – I13 , I0 5 I14 , I1 – I2 , I1 – I3 , I1 5 I13 , I1 5 I14 , I2 – I3 , I2 5 I13 , I2 – I14 , I1 5 I14 , I2 5 I3 , I2 – I13 , I2 – I14 , I3 – I13 , I3 5 I14 , I13 – I14 I3 – I13 , I3 – I14 , I13 5 I14 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 223 Table 6 . Continued a H1 - Deﬁnite features n H4 - Deﬁnite features n bands bands K I0 – I1 , I0 – I2 , I0 – I3 , I0 – I13 , 192 I0 – I14 , I1 5 I2 , I1 5 I3 , I1 5 I13 , I1 5 I14 , I2 5 I3 , I2 5 I13 , I2 5 I14 , I3 5 I13 , I3 5 I14 , I13 5 I14 L I0 – I1 , I0 – I2 , I0 – I3 , I0 5 I13 , 192 I0 5 I14 , I1 5 I2 , I1 5 I3 , I1 – I13 , I1 – I14 , I2 5 I3 , I2 – I13 , I2 – I14 , I3 – I13 , I3 – I14 , I13 5 I14 M I0 – I2 , I0 5 I3 , I1 – I14 , I2 – I13 576 ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input units . a n , number of patterns falling in each band . Fig . 8 . Jittered density plots for the ﬁrst set of four hidden value units used in network 3 . Fig . 9 . Jittered density plots for the second set of four hidden value units used in network 3 . 224 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 7 Deﬁnite features for bands from hidden units 2 and 5 of network 2 a H2 - Deﬁnite features n H5 - Deﬁnite features n bands bands A I0 – I2 , I1 – I3 , I1 – I10 , I1 – I11 , 384 A I0 5 I1 , I0 – I2 , I0 5 I3 , 768 I3 5 I10 , I3 5 I11 , 10 5 I11 I1 – I2 , I1 5 I3 , I2 – I3 B I0 – I2 , I1 – I3 , I1 5 I10 , I1 – I11 , 384 B I0 – I1 , I0 – I2 , I0 – I3 , 768 I3 – I10 , I3 5 I11 , I10 – I11 I1 5 I2 , I1 5 I3 , I2 5 I3 C I0 – I2 , I1 5 I3 , I10 5 I11 768 C I0 – I2 , I1 – I3 1536 D I0 – I2 , I1 5 I3 , I10 – I11 768 E I0 – I2 , I1 – I3 , I1 5 I11 , I3 – I11 768 ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input units . a n , number of patterns falling in each band . the deﬁnite features that activated hidden unit 4 . found in network 2 , in which pairs of hidden units After decoding the set of deﬁnite features , we see each detected rules and responses at speciﬁc card that hidden unit 4 detected all the rules used to train locations . This analysis can also be used to under - the network : 0011 , 1100 , 0110 , 1001 , 0010 , 1101 , stand the collaboration of hidden units in activating 0111 , and 1000 . Hidden unit 4 , however , failed to outputs 1 , 3 and 4 ( see Tables 11 – 13 ) . detect any deﬁnite features associated with card location . Hidden unit 4 in network 3 was similar to 5 . 3 . Discussion network 2’s hidden unit 5 , except that hidden unit 4 enabled all remaining hidden units to detect desired We trained network 3 in order to explore the responses ( i . e . , hidden unit 4 correlates highly with difﬁculty associated with network 2’s task . We all hidden units when desired responses are located wanted to ﬁnd out whether the task difﬁculty of at corresponding card locations ) whereas network 2’s selecting both the ‘p’ and ‘not - q’ cards originated hidden unit 5 only enabled hidden unit 2 to detect from network 2’s need to select two cards or from desired responses . the rigor of learning the ‘not - q’ selection . We An inspection of the remaining hidden units attempted to answer this question by training net - revealed that network 3’s algorithm for solving the work 3 to solve the task by selecting both the ‘p’ and task was similar to network 2’s algorithm but with the ‘q’ cards . In this way we held constant the some differences . For example , Table 11 shows the number of selections made by the network , while at deﬁnite features that activated hidden unit 0 . After the same time testing to see if selecting the ‘q’ decoding the deﬁnite features , we see that hidden response required fewer hidden units than network 2 . unit 0 was highly to moderately activated by patterns Training network 3 also served as a further test of that had the following values at input units 1 through the specialized algorithm found for both networks 1 4 : 0011 , 1100 , 0111 , 1000 , 0010 , 1101 , 0110 , and and 2 . 1001 . In addition , hidden unit 0 was activated by Our results indicated that selecting the ‘p’ and ‘q’ responses located at card 2 . Hidden unit 0 along with response to the selection task is as difﬁcult to hidden unit 4 helped to detect desired responses generate as selecting the ‘p’ and ‘not - q’ response . located at card 2 ; hidden unit 0 detected rules and Network 3 required eight hidden units to learn to responses at card 2 , whereas hidden unit 4 only solve the task — the same number of hidden units as detected rules . This division of labor among hidden network 2 required . Although network 3 required units in network 3 is slightly different from that fewer epochs to converge to a solution ( i . e . , 115 for J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 225 Table 8 Deﬁnite features for bands from hidden units 3 and 7 of network 2 a H3 - Deﬁnite features n H7 - Deﬁnite features n bands bands A I0 – I2 1536 A I0 – I2 1152 B I0 – I2 768 B I0 5 I1 , I0 – I2 , I0 5 I3 , I0 5 I4 , 192 I0 – I5 , I1 – I2 , I1 5 I3 , I1 5 I4 , I1 – I5 , I2 – I3 , I2 – I4 , I2 5 I5 , I3 5 I4 , I3 – I5 , I4 – I5 C I0 5 I1 , I0 – I2 , I0 5 I3 , I0 5 I4 , 192 C I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I4 , 192 I0 5 I5 , I1 – I2 , I1 5 I3 , I1 5 I4 , I0 – I5 , I1 5 I2 , I1 – I3 , I1 5 I4 , I1 5 I5 , I2 – I3 , I2 – I4 , I2 – I5 , I1 5 I5 , I2 – I3 , I2 5 I4 , I2 5 I5 , I3 5 I4 , I3 5 I5 , I4 5 I5 I3 – I4 , I3 – I5 , I4 5 I5 D I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I4 , 192 D I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I4 , 192 I0 5 I5 , I1 – I2 , I1 – I3 , I1 – I4 , I0 5 I5 , I1 – I2 , I1 – I3 , I1 – I4 , I1 5 I5 , I2 5 I3 , I2 5 I4 , I2 – I5 , I1 5 I5 , I2 5 I3 , I2 5 I4 , I2 – I5 , I3 5 I4 , I3 – I5 , I4 – I5 I3 5 I4 , I3 – I5 , I4 – I5 E I0 – I1 , I0 – I2 , I0 5 I3 , I0 – I4 , 192 E I0 5 I1 , I0 – I2 , I0 – I3 , I0 – I4 , 192 I0 – I5 , I1 5 I2 , I1 – I3 , I1 5 I4 , I0 – I5 , I1 – I2 , I1 – I3 , I1 – I4 , I1 5 I5 , I2 – I3 , I2 5 I4 , I2 5 I5 , I1 – I5 , I2 5 I3 , I2 5 I4 , I2 5 I5 , I3 – I4 , I3 – I5 , I4 5 I5 I3 5 I4 , I3 5 I5 , I4 5 I5 F I0 5 I1 , I0 – I2 , I0 – I3 , I0 5 I4 , 192 F I0 5 I1 , I0 – I2 , I0 – I3 , I0 5 I4 , 192 I0 5 I5 , I1 – I2 , I1 – I3 , I1 5 I4 , I0 – I5 , I1 – I2 , I1 – I3 , I1 5 I4 , I1 5 I5 , I2 5 I3 , I2 – I4 , I2 – I5 , I1 – I5 , I2 5 I3 , I2 – I4 , I2 5 I5 , I3 – I4 , I3 – I5 , I4 5 I5 I3 – I4 , I3 5 I5 , I4 – I5 G I0 – I1 , I0 – I2 , I0 – I3 , I0 – 14 , 192 I0 5 I5 , I1 5 I2 , I1 – I3 , I1 5 I4 , I1 5 I5 , I2 – I3 , I2 – I4 , I2 5 I5 , I3 – I4 , I3 – 15 , I4 5 I5 H I0 – I1 , I0 – I2 , I0 5 I3 , I0 5 I4 , 192 I0 – I5 , I1 5 I2 , I1 – I3 , I1 – I4 , I1 5 I5 , I2 – I3 , I2 – I4 , I2 5 I5 , I3 5 I4 , I3 – I5 , I4 – I5 I I0 5 I1 , I0 – I2 , I0 5 I3 , I0 – I4 , 192 I0 – I5 , I1 – I2 , I1 5 I3 , I1 – I4 , I1 – I5 , I2 – I3 , I2 5 I4 , I2 5 I5 , I3 – I4 , I3 – I5 , I4 5 I5 J I0 – I1 , I0 – I2 , I0 – I3 , I1 5 I2 , 384 I1 5 I3 , I2 5 I3 , I4 – I5 ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input units . a n , number of patterns falling in each band . network 3 versus 414 for network 2 ) , the number of the network had a ‘bad start’ — that is , the net - epochs a network requires to learn a task is not an work’s initial random weights were highly dissimilar unequivocal indicator of a task’s difﬁculty . A rela - from the network’s ﬁnal weights . The number of tively high number of epochs might only suggest that hidden units required by a network to converge to a 226 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 9 Correlation among hidden units when cards 1 and 2 are selected — network 3 H0 H1 H2 H3 H4 H5 H6 H7 Card 1 : H0 1 H1 0 1 H2 2 0 . 36 0 1 H3 2 0 . 31 0 . 131 2 0 . 3 1 H4 2 0 . 31 0 . 11 2 0 . 31 0 . 987 1 H5 2 0 . 1 0 2 0 . 1 0 . 265 0 . 249 1 H6 2 0 . 35 2 0 . 1 2 0 . 36 2 0 . 3 2 0 . 31 2 0 . 1 1 H7 2 0 . 1 0 2 0 . 1 0 . 298 0 . 269 0 . 988 2 0 . 1 1 Card 2 : H0 1 H1 0 . 06 1 H2 2 0 . 3 0 1 H3 2 0 . 3 0 . 05 2 0 . 36 1 H4 0 . 997 0 . 06 2 0 . 31 2 0 . 3 1 H5 0 . 169 0 . 07 2 0 . 18 0 . 223 0 . 169 1 H6 2 0 . 3 0 2 0 . 36 2 0 . 35 2 0 . 31 2 0 . 18 1 H7 2 0 . 14 0 . 103 0 . 05 0 . 06 2 0 . 16 0 . 249 0 . 05 1 Table 10 Correlation among hidden units when cards 3 and 4 are selected — network 3 H0 H1 H2 H3 H4 H5 H6 H7 Card 3 : H0 1 H1 0 . 02 1 H2 2 0 . 36 0 1 H3 2 0 . 35 0 . 08 2 0 . 36 1 H4 2 0 . 31 2 0 . 1 2 0 . 31 2 0 . 3 1 H5 2 0 . 18 2 0 . 14 2 0 . 18 0 . 222 0 . 168 1 H6 2 0 . 31 2 0 . 1 2 0 . 31 2 0 . 3 0 . 997 0 . 164 1 H7 0 . 05 0 . 09 0 . 05 0 . 06 2 0 . 16 0 . 247 2 0 . 14 1 Card 4 : H0 1 H1 0 1 H2 2 0 . 31 0 . 02 1 H3 2 0 . 36 0 . 07 2 0 . 3 1 H4 2 0 . 31 0 . 02 0 . 997 2 0 . 3 1 H5 2 0 . 18 0 . 09 0 . 163 0 . 222 0 . 165 1 H6 2 0 . 35 2 0 . 1 2 0 . 31 2 0 . 36 2 0 . 31 2 0 . 18 1 H7 0 . 05 0 . 145 2 0 . 14 0 . 06 2 0 . 16 0 . 247 0 . 05 1 solution is a much better indicator of task difﬁculty 2’s algorithm revealed some differences . For exam - since hidden units index the number of dimensions ple , unlike the role of hidden unit 4 in network 2 , or ‘cuts’ demanded by the problem space in order to hidden unit 4 in network 3 detected rules exclusive - solve the problem ( Dawson , 1998 ) . ly . However , hidden unit 4 in network 3 helped the Comparing network 3’s algorithm against network other hidden units detect desired responses at their J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 227 Table 11 solve the task is a better indicator of a task’s Deﬁnite features for bands from hidden units 0 , 1 , and 2 of difﬁculty . network 3 a Hidden Band Deﬁnite features n unit label 0 A I0 – I2 , I1 5 I3 , I1 – I7 , I1 – I8 , 384 6 . General discussion I3 – I7 , I3 – I8 , I7 5 I8 Our purpose in this paper was to explore a 0 B I0 – I2 1152 connectionist account of performance on Wason’s 0 C I0 – I2 1536 selection task . We attempted to meet this goal by illustrating how three different PDP networks gener - 1 A I0 – I2 3072 ated different solutions to the task . Two networks were trained to generate common but only partially 2 A I0 – I2 , I1 5 I3 , I1 – I13 , I1 – I14 , 384 correct responses ( i . e . , the ‘p’ card alone and both I3 – I13 , I3 – I14 , I13 5 I14 the ‘p and q’ cards ) and one network was trained to 2 B I0 – I2 1152 generate the fully correct response ( i . e . , ‘p and not - q’ ) . 2 C I0 – I2 1536 Results from training these networks suggested ‘ – ’ indicates a perfectly negative correlation between input that selecting the ‘p’ and ‘not - q’ response was more units ; ‘ 5 ’ indicates a perfectly positive correlation between input difﬁcult than selecting only the ‘p’ response . The units . a difﬁculty was reﬂected in the greater number of n , number of patterns falling in each band . hidden units required by network 2 to learn to select the ‘p’ and ‘not - q’ in response to the task . It was possible , however , that network 2 required eight hidden units to learn the task not because the task respective ‘speciﬁc’ card locations . Therefore , net - was solved by selecting two cards but because work 3 provided further evidence of a ‘specialized’ selecting the ‘not - q’ response was inherently dif - algorithm that focused on card location . To be sure , ﬁcult , as has been found with human participants . We network 3’s algorithm was slightly less complex if settled this confound by training a third network to we look at the deﬁnite features detected by each of select both the ‘p’ and ‘q’ cards in response to the its hidden units . For example , the jittered density task . plots of network 3’s hidden units ( with the exception The results obtained from training network 3 of hidden units 3 and 7 ) were characterized by few revealed that selecting the ‘p’ and ‘q’ response was bands . Only the jittered density plots of hidden units as difﬁcult as selecting the ‘p’ and ‘not - q’ response . 3 and 7 , as evidenced by their many bands , revealed Network 3 also required eight hidden units to a more intricate distinction among input patterns . converge to a solution ( as did network 2 ) . Although Although network 3’s algorithm appeared less intri - the algorithm that network 3 generated with these cate as revealed by the banding , this evidence does eight hidden units was characterized by the detection not suggest that generating the ‘p’ and ‘q’ solution is of fewer input features ( i . e . , network 3’s jittered more easily accomplished than generating the ‘p’ and density plots of hidden unit activity revealed fewer ‘not - q’ solution . Number of bands is not a reliable bands , suggesting fewer of the pattern’s deﬁnite indicator of task difﬁculty since it only reﬂects the features needed to be discriminated for a solution ) pattern features falling into each of the decision compared to network 2’s algorithm , banding results regions or cuts made by the hidden units . Although are not indicative of task difﬁculty . the bands elucidate the deﬁnite features that the Unlike number of hidden units , bands are not network used to generate a response , the bands do indicative of a task’s difﬁculty ; the greater the not by themselves reﬂect a task’s difﬁculty . The number of bands one observes in a network’s number of hidden units required by the network to 228 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Table 12 Deﬁnite features for bands from hidden units 3 and 7 of network 3 a H3 - Deﬁnite features n H7 - Deﬁnite features n bands bands A I0 – I2 , I1 5 I3 , I1 – I4 , I1 – I5 , 384 A I0 – I2 1632 I3 – I4 , I3 – I5 , I4 5 I5 AB I0 5 0 , I1 5 1 , I2 5 1 , I3 5 0 , I4 5 0 , 96 B I0 – I2 1056 I5 5 1 C I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 0 , 96 AC I0 5 0 , I1 5 1 , I2 5 1 , I3 5 0 , I4 5 0 , 96 I5 5 0 I5 5 0 D I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 0 , 96 AD I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 0 , 96 I5 5 1 I5 5 0 E I0 – I2 , I0 5 I4 , I1 5 I5 , I2 – I4 288 AE I0 5 1 , I1 5 1 , I2 5 0 , I3 5 1 , I4 5 0 , 96 I5 5 1 F I0 – I2 , I0 – I4 , I0 5 I5 , I1 5 0 , 192 96 I2 5 I4 , I2 – I5 , I3 5 1 , I4 – I5 B I0 5 1 , I1 5 1 , I2 5 0 , I3 5 1 , I4 5 0 , I5 5 0 G I0 5 0 , I1 5 I3 , I1 5 I5 , I2 5 1 , I3 5 I5 , 192 I4 5 1 C I0 – I1 , I0 – I2 , I0 – I3 , I0 5 I5 , 192 I1 5 I2 , I1 5 I3 , I1 – I5 , H I0 – I2 , I0 5 I4 , I2 – I4 384 I2 5 I3 , I2 – I5 , I3 – I5 , I4 5 0 I I0 5 0 , I1 5 1 , I2 5 1 , I3 5 0 , I4 5 1 , 96 D I0 5 1 , I1 5 0 , I2 5 0 , I3 5 0 , I4 5 0 , 96 I5 5 0 I5 5 0 J I0 5 1 , I1 5 I3 , I1 5 I5 , I2 5 0 , I3 5 I5 , 192 E I0 5 0 , I1 5 0 , I2 5 1 , I3 5 0 , I4 5 0 , 96 I4 5 0 I5 5 0 K I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 1 , 96 F I0 5 1 , I1 5 0 , I2 5 0 , I3 5 0 , I4 5 0 , 96 I5 5 0 I5 5 0 G I0 5 1 , I1 5 0 , I2 5 0 , I3 5 1 , I4 5 0 , 96 I5 5 0 H I0 5 1 , I1 5 1 , I2 5 0 , I3 5 1 , I4 5 0 , 96 I5 5 0 I I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 0 , 96 I5 5 1 J I0 5 1 , I1 5 1 , I2 5 0 , I3 5 0 , I4 5 1 , 96 I5 5 0 K I0 5 0 , I1 5 1 , I2 5 1 , I3 5 0 , I4 5 0 , 96 I5 5 0 ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input units or it can indicate that an input unit takes on a speciﬁc value or deﬁnite feature ( e . g . , I0 5 1 ) . a n , number of patterns falling in each band . solution does not signal a greater complexity of the Person A has little experience in computer pro - task being solved . The reason for this can be gramming but needs to create a computer pro - illustrated with the following scenarios : gram that will keep track of household expenses . J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 229 Table 13 expenses . Analyzing ‘banding’ in a value unit ar - Deﬁnite features for bands from hidden units 4 , 5 , and 6 of chitecture provides clues as to the algorithm de - network 3 veloped by the network to solve the task . These clues a Hidden Band Deﬁnite features n are important in order to understand how the task is unit label solved by the network . However , banding does not 4 A I0 5 I1 , I0 – I2 , I0 – I3 , I1 – I2 , 768 provide an index of task difﬁculty . The algorithm I1 – I3 , I2 5 I3 used to solve a task and the task’s difﬁculty are not 4 B I0 – I1 , I0 – I2 , I0 5 I3 , I1 5 I2 , 768 necessarily the same thing . I1 – I3 , I2 – I3 A possible criticism of the present approach is that 4 C I0 – I2 , I1 5 I3 1536 5 A I0 – I2 2688 the results we obtained are likely to be very depen - 5 B I0 – I2 , I1 5 0 , I5 5 0 288 dent on the representation of the task . This charge , 5 C I0 5 1 , I1 5 0 , I2 5 0 , I3 5 0 , I4 5 0 , 96 however , can be directed at most selection task I5 5 0 studies that manipulate contextual variables — the 6 A I0 – I2 , I1 5 I3 , I1 – I10 , I1 – I11 , 384 responses are dependent on the speciﬁc contextual I3 – I10 , I3 – I11 , I10 5 I11 6 B I0 – I2 1152 representation of the task . How investigators present 6 C I0 – I2 1536 ( or represent ) a problem to human participants ( or networks ) will undoubtedly inﬂuence the responses ‘ – ’ indicates a perfectly negative correlation between input units ; ‘ 5 ’ indicates a perfectly positive correlation between input made . The problem of representation has in large units or it can indicate that an input unit takes on a speciﬁc value part been the source of experimental manipulations or deﬁnite feature ( e . g . , I0 5 1 ) . with the selection task since how the task is pre - a n , number of patterns falling in each band . sented to participants has been shown to alter their behavior ( and the inferences made about reasoning The algorithm he or she uses to create the competence ) . For example , presenting the task within computer program is lengthy and intricate where a rich contextual framework leads to better ‘logical’ every step is included and its execution detailed performance than when the task is presented within ( as remembered from a course in programming an impoverished contextual framework . that he or she took years ago ) . It is because of the multitude of algorithmic theories about selection task performance that we Now consider : attempted to explore an architectural account . Col - lectively , the results obtained from training networks Person B has extensive experience in computer 1 , 2 , and 3 provide a different perspective of programming and needs to create a computer performance on the selection task . First , we found program that keep track of household expenses . that all three networks solved the task by focusing on The algorithm he or she uses will not likely be as card location . This focus on card location suggests intricate as the algorithm used by person A . The that the cards or the evidence from which to test the reason for this is that person B ’ s knowledge in rule in the selection task may be important to explain programming will simplify the algorithm to in - participants’ performance . Few theories have focused clude only the most fundamental and necessary on how participants speciﬁcally encode and interpret features , with the details at each step being the nature of the evidence in the selection task . To be already automated in procedural memory . sure , pragmatic reasoning theory , social contract theory , and mental models theory are all theories that Given both these scenarios , is it possible to evaluate can accommodate this speciﬁc dimension since they how difﬁcult it is to create a computer program that emphasize the interaction between the reasoner and will keep track of household expenses ? Not really the task . Nonetheless , this dimension has not yet because the algorithms developed by person A and B been fully explored . We believe that future human are more indicative of each person’s knowledge in studies of performance on the selection task should the task domain than of the structural difﬁculties of focus speciﬁcally on how participants view or en - creating a program to keep track of household code the evidence with which they will test the rule . 230 J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 Second , our results suggest that solving the selec - reasoning studies need to incorporate knowledge or tion task by selecting cards ‘p’ and ‘q’ is as difﬁcult expertise as a variable in models of performance . as selecting cards ‘p’ and ‘not - q . ’ This is a contro - In conclusion , architectural accounts are an im - versial conclusion since the current literature leads us portant contribution to inquiry because they not only to believe that selecting the ‘not - q’ card is inherently provide fundamental support or counters to theoret - difﬁcult for human participants to initiate . For exam - ical ideas but they are also a source of new theoret - ple , rule theorists suggest that people might not have ical ideas . According to Shastri ( 1991 ) , the schemas to generate the ‘not - q’ response ( Braine , 1978 ; Rips , 1994 ) , whereas other theorists suggest [ C ] onnectionism should not be viewed merely as that the ‘not - q’ response is obscured unless the task an implementation paradigm . For adopting the is framed in a meaningful context ( for a review , see connectionist paradigm forces us to revise many Evans et al . , 1993 ) . We think that the difﬁculty might of our views about representation and reasoning . be illusory , however ; in principle generating the ‘p’ The most signiﬁcant revisions stem from the fact and ‘not - q’ cards might be just as easy ( or difﬁcult ) that a connectionist system must operate without as generating the ‘p’ and ‘q’ cards . The mediating an interpreter . ( p . 282 ) variable determining how easy ( or hard ) it is to generate the ‘p’ and ‘not - q’ might be the ‘corre - We hope to see future studies focus on how reason - spondence’ between the participant and the task ; that ers encode the selection task and , in particular , how is , the level of expertise or knowledge that the they encode or interpret the evidence with which to participant brings to the task . test the rule . More generally , we hope to see more One distinguishing feature between novices and architectural accounts of reasoning performance in experts is in the algorithms they develop to solve the literature so that the tools used to increase our problems ( Anderson , 1983 ) . Experts tend to abstract understanding of cognitive phenomena do not remain simplifying features and generate more elegant solu - stagnant . tions to problems , in comparison to novices . For example , novices develop what could be termed ‘complex’ algorithms in comparison to experts if only because novices fail to appreciate some of the Acknowledgements simplifying conditions or ‘general patterns’ that experts readily see in the task ( Anderson , 1983 ; de The present research was funded by grants from Groot , 1965 , 1966 ; Jeffries , Polson , Razran & At - the Social Sciences and Humanities Research Coun - wood , 1977 ) . Hence , depending on the sample of cil of Canada ( SSHRC ) and the Natural Sciences and respondents tested , some solutions might appear to Engineering Research Council of Canada ( NSERC ) . be generated easily and some solutions to be gener - The authors would like to thank Dr . Robert J . ated with difﬁculty — if at all . The ‘not - q’ response Sternberg for his comments on an earlier version of might appear more difﬁcult for participants to select the paper . in abstract ( i . e . , lacking a meaningful context ) versions of the selection task because respondents with little logical expertise are normally tested . A lack of logical expertise deﬁnes respondents in most References studies of the selection task because investigators want to study ‘natural , everyday’ reasoning . In Anderson , J . R . ( 1983 ) . The architecture of cognition , Harvard University Press , Cambridge , MA . contrast , the ‘not - q’ response might be more easily Bechtel , W . , & Abrahamsen , A . ( 1991 ) . Connectionism and the generated in meaningful versions of the selection mind , Blackwell , Cambridge , MA . task because these versions normally use everyday Berkeley , I . S . N . , Dawson , M . R . W . , Medler , D . A . , Schop - contexts that allow respondents to use their everyday ﬂocher , D . P . , & Hornsby , L . ( 1995 ) . Density plots of hidden expertise and appreciate the appropriateness of the value unit activations reveal interpretable bands . Connection ‘not - q’ response . In short , we think that future Science 7 , 167 – 186 . J . P . Leighton , M . R . W . Dawson / Journal of Cognitive Systems Research 2 ( 2001 ) 207 – 231 231 Braine , M . D . S . ( 1978 ) . On the relation between the natural logic Goldstone , R . L . , & Barsalou , L . ( 1998 ) . Reuniting perception and of reasoning and standard logic . Psychological Review 85 ( 1 ) , conception . Cognition 65 , 231 – 262 . 1 – 21 . Jeffries , R . P . , Polson , P . G . , Razran , L . , & Atwood , M . ( 1977 ) . A Byrne , R . M . J . ( 1989 ) . Suppressing valid inferences with process model for missionaries - cannibals and other river cross - conditionals . Cognition 31 , 61 – 83 . ing problems . Cognitive Psychology 9 , 412 – 440 . Cheng , P . W . , & Holyoak , K . J . ( 1985 ) . Pragmatic reasoning Johnson - Laird , P . N . ( 1983 ) . Inference and mental models . In : schemas . Cognitive Psychology 17 , 391 – 416 . Mental models . Towards a cognitive science of language , Cheng , P . W . , & Holyoak , K . J . ( 1989 ) . On the natural selection of inference , and consciousness , Harvard University Press , Cam - reasoning theories . Cognition 33 , 285 – 313 . bridge , MA . Cosmides , L . ( 1989 ) . The logic of social exchange : Has natural Johnson - Laird , P . N . , & Byrne , R . ( 1991 ) . Deduction , Lawrence selection shaped how humans reason ? Studies with the Wason Erlbaum , Hillsdale , NJ . selection task . Cognition 31 , 187 – 276 . Klayman , J . , & Ha , Y . - W . ( 1987 ) . Conﬁrmation , disconﬁrmation , Dawson , M . R . W . ( 1998 ) . Understanding cognitive science , and information in hypothesis testing . Psychological Review 94 , Blackwell , Malden , MA . 211 – 228 . Dawson , M . R . W . , Medler , D . A . , & Berkeley , I . S . N . ( 1997 ) . Liberman , N . , & Klar , Y . ( 1996 ) . Hypothesis testing in Wason’s PDP networks can provide models that are not mere im - selection task : social exchange , cheating detection , or task plementations of classical theories . Philosophical Psychology understanding . Cognition 58 , 127 – 156 . 10 , 25 – 40 . Margolis , H . ( 1987 ) . Patterns , thinking , and cognition , The Dawson , M . R . W . , & Schopﬂocher , D . P . ( 1992 ) . Modifying the University of Chicago Press , Chicago , IL . generalized delta rule to brain networks of non - monotonic Moorehead , I . R . , Haig , N . D . , & Clement , R . A . ( 1989 ) . An processors for pattern classiﬁcation . Connection Science 4 , investigation of trained neural networks from a neuro - 19 – 31 . physiological perspective . Perception 18 , 793 – 803 . de Groot , A . D . ( 1965 ) . Thought and choice in chess , Mouton , Oaksford , M . , & Chater , N . ( 1993 ) . Reasoning theories and The Hague . bounded rationality . In : Manktelow , K . I . , & Over , D . E . ( Eds . ) , de Groot , A . D . ( 1966 ) . Perception and memory versus thought . Rationality : psychological and philosophical perspectives , In : Kleinmuntz , B . ( Ed . ) , Problem - solving , Wiley , New York . Routledge , London . Derthick , M . ( 1991 ) . Finding a maximally plausible model of an Rips , L . J . ( 1994 ) . In : The psychology of proof , The MIT Press , inconsistent theory . In : Barnden , John A . , & Pollack , Jordan B . Cambridge , MA . ( Eds . ) , High - level connectionist models . Advances in connect - Rumelhart , D . E . , Hinton , G . E . , & Williams , R . J . ( 1986 ) . ionist and neural computation theory , vol . 1 , Ablex , Norwood , Learning representations by back - propagating errors . Nature NJ , pp . 241 – 248 . 323 , 533 – 536 . Evans St . , B . T . J . , Newstead , S . E . , & Byrne , R . M . ( 1993 ) . Shastri , L . ( 1991 ) . The relevance of connectionism to AI : a Human reasoning : the psychology of deduction , Lawrence representation and reasoning perspective . In : Barnden , John A . , Erlbaum , Hillsdale . & Pollack , Jordan B . ( Eds . ) , High - level connectionist models . Garnham , A . , & Oakhill , J . ( 1994 ) . In : Thinking and reasoning , Advances in connectionist and neural computation theory , vol . Blackwell , Cambridge , MA . 1 , Ablex , Norwood , NJ , pp . 259 – 283 . Gobet , F . , & Simon , H . A . ( 1998 ) . Pattern recognition makes search possible : comments on Holding ( 1992 ) . Psychological Wason , P . C . ( 1966 ) . Reasoning . In : Foss , B . M . ( Ed . ) , New Research 61 , 204 – 208 . horizons in psychology , Penguin , London .