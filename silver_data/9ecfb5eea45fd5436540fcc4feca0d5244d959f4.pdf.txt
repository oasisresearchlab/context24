A Survey on Dialogue Management in Human - Robot Interaction MERLE M . REIMANN , Vrije Universiteit Amsterdam , Netherlands FLORIAN A . KUNNEMAN , Vrije Universiteit Amsterdam , Netherlands CATHARINE OERTEL , Delft University of Technology , Netherlands KOEN V . HINDRIKS , Vrije Universiteit Amsterdam , Netherlands As social robots see increasing deployment within the general public , improving the interaction with those robots is essential . Spoken language offers an intuitive interface for the human - robot interaction ( HRI ) , with dialogue management ( DM ) being a key component in those interactive systems . Yet , to overcome current challenges and manage smooth , informative and engaging interaction a more structural approach to combining HRI and DM is needed . In this systematic review , we analyse the current use of DM in HRI and focus on the type of dialogue manager used , its capabilities , evaluation methods and the challenges specific to DM in HRI . We identify the challenges and current scientific frontier related to the DM approach , interaction domain , robot appearance , physical situatedness and multimodality . CCS Concepts : • Computing methodologies → Discourse , dialogue and pragmatics ; • Computer systems organization → Robotics . Additional Key Words and Phrases : spoken interaction , dialogue management , social robots 1 INTRODUCTION For humans , spoken communication is a natural way of interacting with each other , their smart speakers and even their pets . Social robots are robots that are designed specifically to interact with their human users [ 14 ] for example by using spoken dialogue . For social robots , the interaction with humans plays a crucial role [ 7 , 27 ] , for example in the context of elderly care [ 15 ] or education [ 9 ] . Robots that use speech as a main mode of interaction do not only need to understand the user’s utterances , but also need to select appropriate responses given the context . Dialogue management ( DM ) , according to Traum and Larsson [ 88 ] , is the part of a dialogue system that performs four key functions : 1 ) it maintains and updates the context of the dialogue , 2 ) it includes the context of the utterance for interpretation of input , 3 ) it selects the timing and content of the next utterance , and 4 ) it coordinates with ( non - ) dialogue modules . In spoken dialogue systems , the dialogue manager receives its input from a natural language understanding ( NLU ) module and forwards its results to a natural language generation ( NLG ) module , which then generates the output ( see fig . 1 ) . In contrast to general DM , DM in human - robot interaction ( HRI ) has to also consider and manage the complexity added by social robots ( see fig . 2 ) . The concentric circles of the figure describe decisions that have to be made when designing a dialogue manager for human - robot interaction . From each circle , one or more options can be chosen and combined with each other . The robot appearance , the modalities of the interaction , interaction scenarios and the physical environment influence the DM . Their combination leads to high variability , but also great complexity . While pure neural networks are used for dialogue management in non - HRI contexts [ 13 , 96 ] , this approach is not adopted generally for HRI , where sparse data , need for robustness and control of high - stakes interactions pose additional constraints . While DM and HRI have not been studied extensively in combination , it is not the case for the fields individually . Harms et al . [ 37 ] Brabra et al . [ 13 ] , Deriu et al . [ 22 ] , Zhao et al . [ 96 ] and Trung [ 89 ] investigate DM , but not from a robotics perspective , and Skantze [ 82 ] looks at turn - taking , a part of DM . While there are reviews on DM in HRI , these Authors’ addresses : Merle M . Reimann , m . m . reimann @ vu . nl , Vrije Universiteit Amsterdam , De Boelelaan 1111 , Amsterdam , North Holland , Netherlands , 1081 HV ; Florian A . Kunneman , Vrije Universiteit Amsterdam , De Boelelaan 1111 , Amsterdam , North Holland , Netherlands , 1081 HV ; Catharine Oertel , Delft University of Technology , P . O . Box 5031 , Delft , South Holland , Netherlands , 2600 GA ; Koen V . Hindriks , Vrije Universiteit Amsterdam , De Boelelaan 1111 , Amsterdam , North Holland , Netherlands , 1081 HV . 1 a r X i v : 2307 . 10897v1 [ c s . R O ] 20 J u l 2023 2 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks Fig . 1 . The integration of the dialogue manager into a spoken dialogue system . have a specific user - group focus , such as patients suffering from dementia [ 78 ] . An overview of the present and future of natural language in HRI , without a specific focus on DM , is provided by [ 58 ] , [ 63 ] and [ 61 ] . In contrast to those reviews , we focus on dialogue managers which are used in physical robots and provide a general overview of DM in HRI . With this review , we aim at giving HRI researchers an overview of the currently used dialogue management systems and their capabilities , to help them make a more informed decision when choosing a dialogue manager for their system . 2 REVIEW We conducted a systematic review using the PRISMA protocol [ 65 ] . We determined inclusion and exclusion criteria , which guided the selection steps , based on our research questions : RQ1 : Which robots are commonly used for DM ? ( Section 2 . 1 ) RQ2 : Which types of dialogue managers are commonly used in HRI , and what are the reasons ? ( Section 2 . 2 ) RQ3 : Which capabilities do current dialogue managers used in HRI have ? ( Section 2 . 3 ) RQ4 : How are dialogue managers in HRI evaluated ? ( Section 2 . 4 ) RQ5 : What are the main challenges for DM in HRI ? ( Section 3 ) We used Scopus , IEEE and ACM for the literature search using the search terms “Robot AND ’mixed initiative’ " and “Robot AND ( ’dialog manager’ OR ’dialogue manager’ ) " resulting in 949 papers ( ACM : 556 , Scopus : 278 , IEEE : 115 ) . Performing a second search with the more general search terms “Robot AND ( dialog OR dialogue ) " , but a restriction to relevant conferences ( HRI , IUI , ICMI , AAMAS , SIGGRAPH , HAI , SIGDIAL , RO - MAN , IROS , INTERSPEECH , DIS , MHAI , AAAI ) led to another 504 papers ( ACM : 62 , Scopus : 350 , IEEE : 92 ) . To make sure that also papers that use the term ’interaction’ instead of ’dialogue’ in abstract and title are included , we performed a third search with the search A Survey on Dialogue Management in Human - Robot Interaction 3 Fig . 2 . Dialogue management in human - robot interaction is influenced by multiple factors that show high variability . Different robot appearances can be combined with varying modalities , interaction domains and environments . Some examples are given for each factor to illustrate it . term “’social interaction’ AND robot AND speech " . This led to 209 ( ACM : 20 , Scopus : 134 , IEEE : 55 ) papers . All papers were imported into Rayyan [ 69 ] for further processing . The formal exclusion criteria were chosen to filter out papers shorter than 4 pages , reviews , demonstrator papers , results which are not scientific papers or did not include a physical robot . Furthermore , we excluded papers written before 2005 since the NLU modules and DM capabilities have improved a lot since then . Additionally , the papers needed a focus on spoken DM or DM capabilities of the dialogue manager . DM capabilities are the conversational abilities the dialogue manager possesses . We decided to scope the review to only include papers that describe a whole dialogue manager . While other components like dialogue state trackers do help the dialogue manager , by providing information that the dialogue manager can then use to decide what its next action should be , they are out of scope for this survey . After duplicate deletion and keyword - based filtering ( “dialog " , “dialogue " , “dialogs " , “dialogues " , “conversation " , “conversational " , “conversations " and “discourse " ) , all authors independently performed a manual abstract screening of the remaining 753 papers , excluding papers that do not sufficiently focus on spoken human - robot interaction . Conflicting 4 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks decisions were discussed until an agreement was reached . A subsequent paper screening led to a total of 68 papers analysed for this review . 2 . 1 Robot appearance We classify the 69 robots found in the 68 papers by their appearance using the taxonomy in [ 7 ] . Figure 3 shows the resulting distribution of types of robots found . Humanoid robots ( 41 % ) are one of the more dominant categories in spoken human - robot interaction . Within this category the NAO robot , used in 10 papers , is the most commonly used humanoid robot [ 4 , 12 , 18 , 21 , 23 , 32 , 55 – 57 , 68 ] . The Pepper robot [ 43 , 67 , 93 ] and Maggie [ 2 , 3 , 35 ] are used in three papers each . A robot bartender [ 28 , 72 ] , Armar 3 [ 41 , 73 ] and the PR2 robot [ 33 , 92 ] are mentioned twice while all other humanoid robot appearances occur just once [ 19 , 24 , 44 , 51 , 53 , 62 , 87 ] . The second biggest category consists of functional robot appearances ( 30 % ) , the design of those robots is influenced by the task they are used for . The three Segway - based robots in this category are used for delivery and navigation [ 5 , 86 , 95 ] . Mobility plays a role for all robots in this category as they are used to help with information and action requests based on instructions [ 1 , 6 , 20 , 26 , 50 , 60 , 74 – 76 , 79 ] , act as a guide [ 31 , 53 , 54 , 59 , 77 , 91 ] or learn location names [ 30 , 66 ] . Fig . 3 . Appearance of the robots used in the surveyed papers . For the robots based on body parts , two robotic heads were used : Flobi [ 17 , 46 ] and Furhat [ 16 , 45 , 83 ] . In contrast to robotic heads , that do not have manipulators , robotic arms are used for object manipulation and grasping . We found robotic arms in five of the papers [ 70 , 71 , 80 , 81 , 85 ] . Robots based on other body parts were not found in any of the papers . All of the artifact shaped robots found in the papers are robotic wheelchairs [ 25 , 38 , 39 , 90 ] , which are used for navigation . The papers using android robots , all use ERICA as the robot [ 42 , 48 , 49 , 64 ] . One of the robots was not described sufficiently to classify it [ 34 ] . A Survey on Dialogue Management in Human - Robot Interaction 5 Fig . 4 . The dialogue management approaches over the years used in the surveyed papers . Based on the diversity of robot types used , we can conclude that the use of spoken dialogue systems is not restricted to specific robots with certain shapes or features , which adds to the high variability of factors influencing the DM ( see fig . 3 ) . 2 . 2 Types of DM in HRI While the first dialogue management approaches starting in the 60s were purely handcrafted , there has been a development into the direction of probabilistic and hybrid approaches . We use the framework provided by Harms et al . [ 37 ] as a basis for the classification of dialogue managers into handcrafted , probabilistic and hybrid approaches . In total , 45 of the 68 papers use handcrafted approaches , 12 use probabilistic ones and 11 make use of a hybrid approach ( see fig . 4 ) . From 2006 to 2010 , 17 of the 23 included dialogue managers were handcrafted , with model - based approaches making up over 50 % in total . Model - based approaches stayed popular from 2011 to 2015 , but ( partially observable ) Markov decision processes ( ( PO ) MDPs ) saw an increased use as well . From 2016 onward , those two approaches were surpassed by hybrid ones that can combine the advantages of both . 2 . 2 . 1 Handcrafted approaches . The main difference between the different handcrafted approaches lies in the information encoded in the states of the dialogue manager . Finite - state machines ( FSMs ) are a simple approach to handcrafted DM , where the states of the FSM directly correspond to the dialogue states . A simple FSM approach is used in [ 79 ] , 6 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks where the focus of the interaction lies on the learning of tasks through dialogue . [ 50 ] use a composition of multiple FSMs to manage the different interactions their robot is offering . However , nowadays they are mostly used as building blocks in combination with other additional functionalities in the surveyed papers . For example , [ 26 ] uses an FSM with predefined dialogues for knowledge acquisition , but aims at adding an autobiographical memory to the robot . Dialogue managers based on state charts , which are used to implement interaction patterns , are used in [ 17 , 46 , 70 , 71 ] . Interaction patterns are based on general sequences that can be found during dialogues and are defined before the interaction . Another dialogue manager based on state charts is IrisTK , which adds recursion [ 45 , 83 ] . Building upon IrisTK , [ 45 ] add a data - driven turn - taking approach to the system . To allow the human user to take more initiative and provide information more flexibly in dialogues , frame - based systems have been used [ 11 ] . Frame - based approaches employ empty slots , typically information units required to fulfill the users request , that can be filled at any point of the conversation . [ 35 ] present such a system , where multiple slots can be filled at a time , for action requests for the robot Maggie . A frame - based approach is also adopted in [ 93 ] , where the user’s food preferences are determined in an interview - like conversation by using slot - filling . The third handcrafted approach is the model - based approach . In addition to the frames with slots , a model - based dialogue manager has more complex states . Those states include some form of model , for example about the user , the environment , the situation or the context . Model - based dialogue managers often consider the user model , including the user’s goals and intention [ 18 , 74 , 76 , 77 , 86 , 91 , 92 ] . User models that influence the dialogue management can also be based on displayed emotion [ 3 , 23 ] or personality [ 4 ] of the user . For long - term interaction , including a model of the conversation history is especially relevant and enables the dialogue manager to learn from past interactions . Cobot’s dialogue manager described in [ 77 ] is designed for a long - term interaction , and therefore uses the conversation history to avoid repetitive dialogue or unnecessary offers . In [ 24 ] , the robot collects and stores user data that influences later conversations with the user . [ 53 , 54 ] use a stack to keep track of unfinished conversation sequences for tracking the context during the interaction . The dialogue manager used in [ 67 ] groups utterances into contexts , which then can be focused during different points of the conversation . The Information State Update approach [ 88 ] used by [ 74 – 76 ] , stores and uses amongst other things the dialogue context , information about the possible referents of pronouns , and information about the current turn and initiative . [ 1 , 6 , 80 ] also use the dialogue context and user’s intention , in addition to objects referenced in the environment , to determine the next dialogue move . Multiple expert modules , activated based on domain scores , are used by [ 66 ] and [ 30 ] . Plan - based systems , which belong to the model - based approaches , treat the conversation as a planning problem and aim at reaching a goal state by selecting from predefined actions . Plan - based dialogue management is used by [ 72 ] , [ 2 ] and [ 28 ] , who use the planner for the dialogue and action generation . Other plan - based systems are used by [ 90 ] for navigation of a robotic wheelchair and by [ 32 ] , with additional rule - based speech overlap management . [ 20 ] uses answer set programming for their planning module , which can generate a high - level plan based on the user’s request and a low - level plan for the motion planner . In [ 16 ] , a goal , based on novelty , dialogue history , relevance and diversity , is used for the utterance selection , while [ 31 ] performs logical inference over the goals and beliefs to this end . The dialogue manager used by [ 44 ] can be used as a model - based one , but a simplified version can also be used as a frame - based or FSM dialogue manager . Two dialogue managers do not fit the classification and were therefore classified as other handcrafted . [ 19 ] used timed petri nets to improve mutltimodal interaction , especially in respect to turn - taking . Petri nets are state - transition networks that have tokens , which determine the current configuration state and whether a transition is enabled . In addition to utilizing this approach , timed Petri nets use real time transitions of A Survey on Dialogue Management in Human - Robot Interaction 7 the tokens to be able to model the configuration according to the input . [ 68 ] use a dialogue manager that uses XML files for generating the dialogue in Slovac languages . 2 . 2 . 2 Probabilistic approaches . In contrast to handcrafted approaches , probabilistic approaches learn the dialogue policy directly from data . A probabilistic approach used in only one surveyed paper is the example - based approach [ 87 ] that looks up the most similar utterance in its database , consisting of numerous conversations , and uses the answer given there as its own . A popular probabilistic approach used in DM are ( partially observable ) Markov decision processes ( ( PO ) MDPs ) . MDPs model the dialogue as a Markov process , moving from one state to another based on learned transition probabilities . For POMDPs , the current state is not known and is estimated based on observations ( e . g . perceived actions and utterances ) and their probabilities . The robotic wheelchairs used in [ 39 ] and [ 38 ] use dialogue to check their spatial semantic representation and make sure that it corresponds to the real environment , by asking questions about the environment . The POMDP dialogue manager in [ 5 ] rewards successful conversations , leading to task completion , while additional questions , confirmations and unsuccessful conversations are penalised . Two POMDPs , one for the DM and another one for deciding when to update the knowledge base , are used for improving the augmentation of the knowledge on an as - needed basis . [ 21 ] allow flexible navigation between the different sub - dialogues , to enable the user to change their mind about the order in which they want to do certain tasks . A Bayesian approach to learning the best dialogue strategy is used by [ 25 ] for a robotic wheelchair . Integrating reasoning with probabilistic common sense knowledge enables the robot in [ 95 ] and [ 59 ] to ignore irrelevant variables while planning . Another approach for limiting the state space is used in [ 55 ] , where probabilistic rules are used for Bayesian networks . ( PO ) MDPs are also used for multimodal dialogue , where they learn the strategies from multimodal instead of pure dialogue data [ 41 , 60 , 73 ] . We did not find a system purely based on an end - to - end learning approach , but end - to - end approaches are in fact used as parts of hybrid systems ( see section 2 . 2 , Hybrid approaches ) . A probabilistic approach which does not fit into either category described earlier is used by [ 85 ] . They generate all possible linguistic expressions for an action , which is possible since they use a simplified sentence structure . Then they use expected log loss reduction and Bayesian logistic regression , predicting which utterance should be selected . Using the best score , an utterance is selected and produced . After the production , the appropriateness of the utterance is rated based on the user’s reaction and the example is added to the training set . This leads to active learning during the conversation . 2 . 2 . 3 Hybrid approaches . Instead of focusing on either a handcrafted or data - driven approach , in recent years it has become more popular to use a combination of the two . These so - called hybrid approaches can be fitted according to the needs of the target application and the availability of data . The option to combine approaches can compensate for their weaknesses and utilise their strengths . Hybrid approaches are often used when the dialogue manager is distributed in a variety of submodules which focus on different aspects of the dialogue management , like turn - taking , engagement management or problem handling . [ 48 ] combine a finite - state turn - taking machine with a deep neural network , in order to improve the dialogue manager’s turn - taking capabilities . Turn - taking is also integrated into the otherwise model - based dialogue manager in [ 33 ] by adding a combination of incremental processing and lexical prediction . In [ 12 ] an FSM approach is combined with self - supervised learning to handle disengagement . To handle problems occurring during the dialogue more efficiently , [ 34 ] add an FSM with four states ( Start , Normal , Help , Error ) to the dialogue manager ARIADNE [ 40 ] . [ 81 ] also use an FSM for tracking the general state of the dialogue system , but make use of external services for questions and declarative utterances . 8 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks Table 1 . Common conversational capabilities observed in the 68 surveyed papers . Conversational Capability Amount Confirm 13 Ask for confirmation 24 Ask for repetition / rephrasing 10 Ask clarification questions 17 Reference resolution / Spatial grounding 24 Acquire knowledge 21 [ 49 ] use logistic regression to select so - called experts , which can have different strategies , while [ 42 ] rely on a priority system in combination with additional triggers for a backchannel and backup question module . Backchannels are short responses that are integrated into the conversation while listening , to show engagement ( e . g . “hmm " , “yeah " ) . In [ 64 ] a dialogue act tagger based on supervised machine learning ( Support Vector Machines ) is used to decide whether a statement response should be generated , based on either a decision tree or a response using an example - based approach . If neither have a sufficiently high confidence score , a backchannel is produced instead . It is also possible to make use of probabilistic rules for DM to reduce the parameter space by including expert knowledge [ 57 ] . A combination of a POMDP and a model - based approach is used in [ 56 ] , where the user’s goal and actions are modelled using Bayesian inference . A combination of an example - based and agenda - based approach is used in [ 51 ] . While the agenda graph is designed manually , the examples which are mapped to the nodes are learned from human - human dialogues . 2 . 3 Communication capabilities in HRI We list common capabilities that were explicitly mentioned in the reviewed papers in table 1 . Confirm . Explicit confirmations by the robot for establishing common ground are important , especially for task - based interaction , to increase task success [ 86 ] . Common ground describes shared beliefs , for example about the environment or the state of the conversation [ 84 ] , which is relevant , if the human and robot have to achieve a task together . Example use - case scenarios include movement instructions [ 31 , 35 ] , receptionist tasks [ 41 , 44 , 76 ] , grasping [ 71 ] , delivering items [ 86 ] or the establishment of common ground in situated interaction [ 18 ] . Ask for confirmation . A clear trend across more than 13 rd of all papers is the robot’s ability to ask for confirmation . This can happen either explicitly ( e . g . “Do you want . . . ? " , with an option for the user to ( dis - ) confirm ) or implicitly ( e . g . “I will now . . . " , with an option to cancel the action if it is not the desired one ) . [ 70 , 71 ] use a correctable information request pattern for implicit confirmations , and an explicit confirmation after an Information Request pattern , for integrating confirmation questions into their task - based interaction . Confirmations by the human can be used to ensure common ground about the environment [ 18 , 41 , 83 ] , to elicit information about user preferences [ 59 , 93 ] , to confirm the correctness of past actions [ 55 ] or to make sure that the conversation is not terminated too early [ 79 ] . At the same time , unnecessary confirmation or clarification questions can make the conversation inefficient and increase user frustration and are therefore often associated with a cost in reinforcement learning settings [ 5 , 25 , 38 , 55 , 95 ] . For example , robots which navigate or deliver items [ 5 , 25 , 57 , 95 ] , or make appointments and book something [ 44 , 76 ] often ask for confirmation , since a later correction after performing the action is more costly . To avoid unnecessary confirmation questions , [ 56 ] assigns a negative value to the reward function of their reinforcement learning dialogue strategy for A Survey on Dialogue Management in Human - Robot Interaction 9 additional confirmations , while the robot in [ 85 ] learns when and how to confirm through active learning . Since robots have to deal with challenging environments with noise , confirmation questions are used , when the confidence that the utterance was understood correctly is low [ 35 , 66 , 75 , 76 , 92 ] . Ask for repetition / rephrasing . In case of speech recognition problems , a repetition of the utterance can already help resolving them , while rephrasing gives the human the option to produce a different utterance which is easier to understand for the robot than the first one . To determine whether repetition is needed , different strategies are available . Robots ask users to repeat an utterance when the recognition is below a threshold [ 35 ] , no match for the input was found [ 17 , 31 ] or in case of underspecification [ 56 , 57 ] . If no grounding is achieved for object names that are referred to by a gesture accompanying a pronoun , the robot in [ 54 ] asks for repetition . Like repetition , rephrasing can be used when the dialogue manager finds no match for the input [ 31 , 43 , 51 ] , if the dialogue manager is uncertain either about the dialogue state [ 5 ] or about the correct recognition of the utterance [ 35 ] . Ask clarification questions . Clarification questions are asked in those cases where the robot is unsure if it has understood the utterance correctly [ 5 , 19 , 74 , 75 , 86 ] or when it is missing information [ 31 , 34 , 35 , 41 , 93 ] . Additional information to make complete plans [ 20 ] or determine the current context [ 92 ] can be acquired through clarification questions . If most parts of a user request are already specified and only some need additional clarification , [ 17 ] suggest to let the robot already start the action while clarifying the missing parts . Reference resolution / spatial grounding . Something which distinguishes robots from conversational agents is that they are physically embodied and situated in an environment . That is why situational grounding is important for robots that , for example , engage in navigation [ 38 , 39 , 57 , 77 ] , deliveries [ 86 ] or give a tour in the environment [ 54 , 70 , 79 ] . Situational grounding refers to the robot’s ability to ground concepts and referenced objects in the real world ( " Give me the red cup " would refer to a specific red cup that is present in the environment , not to the concept of a red cup in general ) . The robot in [ 18 ] engages in a naming game of objects in the environment with the user and focuses on establishing common ground . To do so , it makes its knowledge explicit , such that the human can correct it if necessary . Robotic arms that grasp and move objects , need to identify the object the user is talking about correctly [ 71 , 80 , 85 ] . For multimodal dialogue where the human refers to objects in the environment that are related to the robot’s task , the robot also needs to be aware which object the human is referencing using the available modalities ( e . g . gestures , speech , gaze ) [ 1 , 6 , 41 , 73 ] . Acquire knowledge . If the human is talking to the robot about previously unseen or unheard objects or people , the robot should be able to make sense of them . Knowledge augmentation allows for new knowledge to be added to the knowledge base of the robot . For navigating robots , questions about their environment improve their knowledge about the spatial semantic representation [ 38 , 39 ] . In the delivery domain , knowledge augmentation is used to learn names of objects or people which have to be delivered / should receive the delivery but are not yet in the knowledge base [ 5 , 86 ] . Another context in which knowledge from previous interactions and users is used , is for recommendations based on ( assumed ) user preferences [ 59 , 91 ] . The robot in [ 76 ] is able to acquire and store knowledge , which is explicitly declared . In some cases the interaction with the robot is used to teach it new actions [ 80 ] , grasping methods in combination with object names [ 71 ] , or following instructive tasks [ 79 ] . Other forms of knowledge acquisition include active learning from past interactions [ 85 ] , the internet [ 67 ] or updates of the world model [ 20 ] in order to avoid failures of the interaction . Another case of knowledge acquisition takes place when the robot learns personal information about the human and stores it in a knowledge base [ 3 , 26 ] . 10 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks 2 . 4 Evaluation methods of DM in HRI Different techniques have been used for evaluating the performance of dialogue managers in general . A detailed survey of them can be found in [ 22 ] . For the evaluation of dialogue managers in HRI , subjective and objective measures can be used ( see table 2 ) . Performing user studies for the evaluation has the advantage that they allow to evaluate the performance of the dialogue manager and robot in a real interaction , while allowing the users to give their opinions in questionnaires , like the Godspeed questionnaire [ 8 ] . That way , user frustration and other subjective measurements can be included in the evaluation . However , user studies are resource - and time - intensive . In the reviewed papers , 35 user studies were reported , with a few ( 3 ) of those being in - the - wild studies [ 12 , 16 , 45 ] . Other evaluation methods include simulations ( 7 ) , evaluation based on a corpus of previously gathered data ( 10 ) , while some papers just describe possible interaction scenarios ( 17 ) . The participant numbers reported for the user studies differ greatly , ranging from 2 to 97 participants , with an average of 21 participants ( SD 18 . 4 ) . Three studies [ 35 , 59 , 85 ] mention tests with users , but do not report any specifics about the number of participants . For in - the - wild studies it is more difficult to report exact participant numbers , since it is not always clear if every user interacted only once , which is why [ 12 , 16 , 45 ] report the total number of recorded interactions instead . For the evaluation of DM in HRI , task success is a common metric , since the dialogue and task are often tightly coupled in task - based systems and the dialogue is needed to achieve the goal . Since 58 of the 68 papers report on task - based interactions , task success offers an easily accessible option to evaluate the interaction . Due to the integration of the dialogue manager into a bigger system , the dialogue manager is often evaluated in combination with the other modules of the robot . For example , the task success can include the dialogue , but also the motor functions , to achieve the task . While the integration of dialogue managers into a robot opens up the possibility of using evaluation methods that asses the whole system , it complicates the evaluation . An example is that the dialogue manager gets the information from the speech recognition module , which can introduce misunderstandings that the dialogue manager then has to deal with . To avoid those problems , simulations or corpus - based evaluations can be used . An evaluation of the dialogue manager alone does not necessarily reflect how it would work in combination with the robot’s other parts , especially if the robot makes use of multimodal data . Number of turns is a metric that can be used system - independent and would aid in comparability of different systems and tasks if reported for all studies . For task - based studies we observed a high number of papers reporting the task - success rate ; a metric also observed as a common evaluation method by [ 22 ] . However , the evaluation of the system is still depending on the type of system used [ 22 ] . Even though , this can partly account for the high number of different evaluation metrics , it would be advantageous if common metrics , like the number of turns , used would be integrated into the evaluation of all studies , to make them more comparable . 2 . 5 Challenges Dialogue managers which are integrated into a robot do not act independently , but are part of a bigger architecture . While this is also true for dialogue managers used without robots , robots often make use of additional sensors and actuators to integrate multimodal in - and output into the system . Currently , there is no commonly used off - the - shelf solution for spoken human - robot interaction , but instead there is a variety of different frameworks , not only for dialogue management , but also for the related modules . This variety makes it challenging to select the most appropriate solution in cases where an existing framework is used . Due to the tight coupling of modules in a robot , the dialogue managers are also influenced by the problems of other modules , such as speech recognition errors [ 30 , 42 , 49 , 76 ] . Apart from A Survey on Dialogue Management in Human - Robot Interaction 11 Table 2 . Subjective and objective measures used for evaluating DM in HRI . Subjective measures User satisfaction [ 16 , 23 , 86 ] User frustration [ 5 , 86 ] Perceived interaction pace [ 21 ] Perceived understanding [ 57 , 86 ] Scales from social psychology / communication [ 87 ] Naturalness and pleasantness [ 57 , 60 ] Ease of use [ 21 , 86 ] Likability of the robot [ 24 , 34 , 49 , 54 , 87 ] ( Modified version of ) the Godspeed questionnaire [ 28 , 64 ] Items from the Interpersonal Communication Satisfactory Inventory [ 16 ] Perceived common ground [ 18 ] Likelihood of usage in the future [ 5 , 21 , 86 ] Appropriateness of the answer [ 31 , 57 ] Objective measures Number of turns [ 18 , 28 , 34 , 41 , 51 , 56 , 57 , 73 , 86 , 95 ] Number of repair turns [ 53 , 57 ] Number of fallback utterances [ 64 ] Number of rejected utterances [ 76 ] Precision and recall [ 48 , 64 ] Accuracy [ 5 , 38 , 48 , 55 , 81 , 95 ] F1 scores [ 5 , 48 ] Task success rate [ 5 , 18 , 19 , 28 , 29 , 34 , 41 , 51 , 60 , 73 , 76 , 83 , 86 ] Entropy reduction [ 38 , 39 ] Latency and false cut - in rate [ 48 ] Reward / Cost functions [ 5 , 25 , 59 , 73 , 95 ] Dialogue duration [ 57 ] improving the speech recognition module directly , it is possible to include mechanisms into the dialogue manager that are responsible for dealing with speech recognition errors [ 30 ] . Talking to a robot raises expectations about their conversational capabilities . When those expectations are not met , the user can become frustrated [ 5 ] . Expectations are shaped in part by the morphology of the robot [ 47 ] , making the consideration of the morphology on the expected conversational capabilities necessary . For example , [ 64 ] use the android robot ERICA and state that “Erica’s realistic physical appearance implies that her spoken dialogue system must have the ability to hold a conversation in a similarly human - like manner by displaying conversational aspects such as backchannels , turn - taking and fillers” . The robot morphology does not only affect the expectations , for example regarding the human - likeness of its conversational capabilities , but also limits the tasks the robot can do , impacting the domains the robot has to be able to converse about . In human - human conversations , common ground plays an important role and helps to reduce miscommunication [ 84 ] . In spoken HRI this is even more challenging since the perception of humans and robots is not the same . Expectations based on human - human conversations do not necessarily hold for human - robot conversations . This can lead to a gap between the perceived versus the real common ground [ 18 ] . 12 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks Interactions with robots are not purely speech based , but they can also make use of multimodal cues like gestures , gaze or facial expressions . When the robot is using multimodal input for deciding the next dialogue move , it is not enough to simply detect the multimodal cues , but they also need to be integrated for further processing . A separate model for multimodal fusion can be used that then forwards the fused information to the dialogue manager , as is done for example in [ 3 , 41 , 53 , 60 ] . Before integrating multimodal cues , a decision has to be made regarding the required modalities to decide which ones are necessary or expected in the specific type of interaction and should be used by the robot . The robot morphology is impacting the multimodal cue generation as well , as robotic heads , for example , cannot generate pointing gestures . Therefore , the robot’s appearance is adding both restrictions and expectations and should be chosen carefully . When a robot is placed in an environment , it can encounter the same person multiple times , or have longer interactions with the people , for example when acting as a guide [ 59 , 91 ] . In longer conversations or long - term interactions with multiple conversations , repetitions over time can annoy the user [ 77 ] . To solve this problem in long - term interactions , [ 77 ] suggest different options . For example , producing a number of different utterances for the same context which could reoccur , and remembering previous utterances or even whole conversations . To understand the robot’s behaviour and its decisions , additional explanations might be required [ 24 , 80 ] . Especially if the robot fails without an explanation the user might misinterpret the situation or cause the failure again , due to the lack of explanation . However , this leads to the next problem , which is the resources needed for designing complex dialogue managers . For example , for handcrafted approaches the structure has to be defined a priori [ 35 , 44 ] , knowledge has to be integrated [ 43 ] and even then it will not be able to cover unknown situations [ 39 , 76 ] . In contrast to handcrafted approaches , data - driven ones need less human effort , but rely on data for learning conversational behaviour . However , data collection in HRI is expensive [ 25 ] and for supervised learning expert feedback is needed [ 55 ] . It is possible that the human and the robot follow different conversational strategies , for example , one tries to exploit previous conversation topics , while the other one tries to explore new topics . If the robot does not notice those differences in strategies and rigidly follows its own strategy , it can lead to high tension in the dialogue [ 16 ] . Collecting data in an HRI setting is a challenging task , since the data is often multimodal and the interaction has to take place in a situated setting . This means that the data collection requires time , human participants and a system that can record all the required signals . However , if a specific robot is used for recording data , the generalizability to other robots is still unclear . The reporting of user studies and their results is still lacking uniformity . An example for this are the multiple ways of which length can be assessed in the context of dialogues . Some papers report the number of turns [ 16 , 18 , 41 ] , while others focus on the length of turns [ 24 , 51 ] or the total amount of time [ 45 ] . While the heterogeneous reporting on the length can make comparisons challenging , there are also still papers that do not report on the interaction length at all . Human - robot interaction offers the additional challenge of grounding the interaction in the environment the robot is physically located in . This is especially the case for multimodal interaction where the referral of objects can happen , for example , through gestures [ 1 , 6 ] or gaze [ 83 ] . A robot that is referring to locations around itself , needs to know its own position as well as the names and places of the locations around it [ 30 , 36 , 39 , 66 ] . The physical environment of the robot also contains objects , which the robot or human can refer to . Especially for robots that can perform object manipulation , it is important to be able to understand and produce references to those objects [ 53 , 56 , 71 , 80 , 85 ] . Grounding interactions in the environment is especially challenging since the environment can change over time , with objects being placed and removed , people appearing and disappearing , and also the robot itself moving in the environment . A Survey on Dialogue Management in Human - Robot Interaction 13 To date , handcrafted dialogue management approaches are still very common in HRI , due to lack of data , the aforementioned challenges due to the physical embodiment , but also because of the advantages it offers . If the robot’s conversation domain is small and transparency is required , a handcrafted approach might be a good option , whereas a probabilistic approach has the advantage that the actions can be learned from real interaction data , leading to less expert knowledge being required . 3 DISCUSSION Our survey of literature that details DM in the context of HRI research revealed a variety of used DM approaches , influenced by the task the robot should perform and the needed reliability and capabilities . In this section , we will discuss the key challenges that have to be faced to make progress in dialogue management for social robots . For task - based human - robot dialogues , the majority of systems are using handcrafted approaches ( see section 2 . 3 ) among which model - based approaches are the most popular ( see fig . 4 ) . End - to - end approaches , like they are used for non - HRI task - based DM [ 96 ] , have not been seen at all in the included papers . The resources needed for designing complicated dialogue managers constitute a challenge . For handcrafted approaches the structure has to be defined a priori [ 35 , 44 ] , knowledge has to be integrated [ 43 ] and even then they will not be able to cover unknown situations [ 39 , 76 ] . In contrast to handcrafted approaches , data - driven dialogue managers need less human effort , but rely on data for learning conversational behaviour . However , data collection in HRI is expensive [ 25 ] and expert feedback is needed for supervised learning [ 55 ] . In human - human conversations , common ground plays an important role and helps to reduce miscommunication [ 84 ] . In spoken HRI this is even more challenging since the perception of humans and robots is not the same . Expectations learned from human - human conversations do not necessarily hold for human - robot conversations . This can lead to a gap between the perceived versus the real common - ground [ 18 ] . The physical presence of robots has an effect on the interaction [ 52 ] , however , it is not clear how exactly those influences look like for the different combinations as they are illustrated in 2 . This makes it challenging to transfer knowledge gained from human - human or even human - agent interaction to human - robot interaction . While the possible interaction domains for DM in HRI span a wide area and can be combined with varying robots and environments ( see fig . 2 ) , most of them are task - based , for example for deliveries or navigation . Being in control of the interaction seems to be an important factor for DM in HRI , which makes handcrafted approaches a compelling option , especially in task - based interaction domains . One trend we observed is that hybrid approaches divide the dialogue manager into smaller expert modules that are responsible for specific tasks within the dialogue manager . The different experts use different DM strategies and approaches themselves , based on the task that is assigned to them . This overall strategy of distributing the task to experts leads to more flexibility in the construction of the interaction , since the parts that are responsible for different tasks can use the approach that is best for that specific task . A capability that is specific to DM in robots , is the grounding of the dialogue in the physical environment . For DM in HRI , the user and the robot are both physically situated in the environment , which can take different forms ( see fig . 2 ) . Because of this , they are exposed to changes , for example , due to people moving or objects being moved . A robot can encounter new or already known people [ 26 ] or unknown objects [ 71 ] during the conversation . This also relates to the question about endowing robots with a memory . More specifically , the physical situatedness of robots raises the question of how to manage such environmental dynamics in a robot’s memory . Due to their situatedness in the real world , interactions can happen more than once or for a longer time interval with the same robot . To solve the problem of repetitions over time in long - term interactions , [ 77 ] suggest different options to avoid repetition : producing a number 14 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks of different utterances for the same context which could reoccur , either in a rule - based way or by deploying machine learning - based natural language generation , and remembering previous utterances or even whole conversations . The question then becomes how to endow a robot with an effective memory to sustain such long - term interactions . Due to its physical presence in the environment , the robot’s appearance has to be taken into account as well ( see fig . 2 ) . When talking to a robot , their physical appearance raises expectations about conversational capabilities , while not making explicit which ones are actually present , and users can easily become frustrated when those expectations are not met . Therefore , to understand the robot’s behaviour and its decisions , additional explanations will be required [ 24 , 80 ] . To avoid future failures , the robot should be transparent about the reason of a failure when it happens , so that the user can try to avoid it in the future . The implications the chosen robot morphology has on the dialogue , is rarely discussed in the surveyed papers . Without this information , it is difficult to judge if and how the obtained results are transferable to a different robot . If the choice of robot and the resulting effects on the interaction would be more commonly discussed in research papers , this would help other researchers in choosing an appropriate robot appearance for their interactions . Dialogue managers that are integrated into a robot are part of a bigger system . Social robots are typically multimodal and therefore depend on modules , such as sensors , while influencing other modules . Which modalities are included varies from case to case , as indicated in fig . 2 . By influencing the actuators of the robot , the dialogue can have an immediate impact on the environment . The dialogue manager does not only interact with the NLU and NLG modules , but is often also linked to other modalities that , for example , manage the perception and production of multi - modal cues , like gestures or gaze . The dialogue manager is in addition influenced by the problems of certain modules , such as speech recognition errors [ 30 , 42 , 49 , 76 ] . Apart from improving the speech recognition module directly , it is possible to include mechanisms into the dialogue manager that are responsible for dealing with speech recognition errors [ 30 ] . Due to speech recognition difficulties , multiple common capabilities focus on types of repair ( see section 2 . 3 ) . However , while repairing problems in speech recognition with dialogue management techniques is an option , making the reasons for the failures explicit can help to improve the speech recognition on an HRI context . Speech recognition in HRI is impacted by noise of the robot’s motors and the environment the robot is placed in , especially during experiments outside of the lab . Robots can encounter multiple people , both at the same time and at different times , whose age , accent and way of speaking can vary . All of those factors influence the performance of the speech recognition module . During conversations , it is problematic if the robot loses track of the user or is ignoring multimodal cues [ 54 ] , while the human expects the robot to be able to process them . Since the dialogue manager is integrated into the robot’s architecture , the whole system should be taken into account for the evaluation . This means that it is not enough to evaluate the dialogue manager in a decoupled manner . Rather , it is necessary to consider the effects of the integration into the robot . Using real users for evaluations comes with the advantage that it provides a clearer picture of how the system performs in actual interactions . Several of the challenges we outlined relate to the variance of interaction domains , appearances , modalities and environments in HRI that need to be incorporated into the DM approach . One of these challenges is the integration into a bigger architecture , since problems in the other modules that relate to the multi - modal features of several robot types can impact the dialogue management and need to be accounted for . Another challenge is the lack of datasets for human - robot interaction , to further evolve probabilistic and hybrid approaches to DM in HRI . The data requirements are not only related to the domain of the interaction , but also to the type of robot and the location of the interaction , since those can impact the conversation . The problem of lack of data could be addressed by using large language models , that only have to be fine - tuned or can be directly prompted including recent turns in the conversation . However , A Survey on Dialogue Management in Human - Robot Interaction 15 they still have difficulties with situational awareness and the integration of the robot’s sensors and actuators [ 10 , 94 ] . Human - robot datasets cannot easily be substituted by human - human datasets , since robots have different abilities than humans and lack most of the common sense abilities humans have . Datasets , moreover , even need to take specific robot shapes and forms into account , as the capabilities present in different robot platforms differ from each other . It is therefore important to maximise transparency about the robot’s conversational capabilities . HRI researchers new to DM can make an informed decision regarding the selection of a dialogue management approach by assessing which of the presented approaches fits their requirements and limitations best . Based on our observations , hybrid approaches are a good option for more complex dialogue managers where the dialogue is an essential part of the interaction . If the interaction is simpler from a dialogue perspective , or not enough data is available , handcrafted approaches , especially model - based ones , are a viable option . While a variety of robots with a range of different shapes and appearances has been used for spoken HRI so far , it would be helpful if the implications of robot platform choices on the dialogue would be discussed more extensively . Especially due to the situatedness in the environment , the required multimodal inputs need to be taken into account in advance . As a start we would suggest to include only those , however , that are necessary for the interaction to not overly complicate the dialogue management system . Using already used evaluation metrics , especially those that are easy to record , would help to compare performance of the systems used . Even though dialogue is common in human - robot interactions , it is rarely the main focus of the interaction design . In current research , dialogue is often only seen as a tool to achieve a task with a robot . Moreover , in papers that do take a dialogue management perspective , the dialogue manager is typically evaluated in non - embodied agents , which neglects robot - specific challenges that need to be addressed . In order to more structurally address these challenges , it is important that the best of both fields is combined to develop a more standardised approach for DM that can be drawn upon in the diverse interaction scenarios that arise in HRI studies . ACKNOWLEDGMENTS This research was ( partially ) funded by the Hybrid Intelligence Center , a 10 - year programme funded by the Dutch Ministry of Education , Culture and Science through the Netherlands Organisation for Scientific Research , https : / / hybrid - intelligence - centre . nl , grant number 024 . 004 . 022 . REFERENCES [ 1 ] Wendy Aguilar and Luis A . Pineda . 2009 . Integrating Graph - Based Vision Perception to Spoken Conversation in Human - Robot Interaction . In Bio - Inspired Systems : Computational and Ambient Intelligence , Joan Cabestany , Francisco Sandoval , Alberto Prieto , and Juan M . Corchado ( Eds . ) . Vol . 5517 . Springer Berlin Heidelberg , Berlin , Heidelberg , 789 – 796 . https : / / doi . org / 10 . 1007 / 978 - 3 - 642 - 02478 - 8 _ 99 Series Title : Lecture Notes in Computer Science . [ 2 ] Fernando Alonso - Martín , Aívaro Castro - González , Francisco Javier Fernandez de Gorostiza Luengo , and Miguel Ángel Salichs . 2015 . Augmented robotics dialog system for enhancing human – robot interaction . Sensors 15 , 7 ( 2015 ) , 15799 – 15829 . [ 3 ] Fernando Alonso - Martín , Javier F . Gorostiza , María Malfaz , and Miguel A . Salichs . 2013 . MULTIMODAL FUSION AS COMMUNICATIVE ACTS DURING HUMAN – ROBOT INTERACTION . Cybernetics and Systems 44 , 8 ( Nov . 2013 ) , 681 – 703 . https : / / doi . org / 10 . 1080 / 01969722 . 2013 . 832096 [ 4 ] Amir Aly and Adriana Tapus . 2013 . A model for synthesizing a combined verbal and nonverbal behavior based on personality traits in human - robot interaction . In 2013 8th ACM / IEEE International Conference on Human - Robot Interaction ( HRI ) . 325 – 332 . https : / / doi . org / 10 . 1109 / HRI . 2013 . 6483606 ISSN : 2167 - 2148 . [ 5 ] Saeid Amiri , Sujay Bajracharya , Cihangir Goktolgal , Jesse Thomason , and Shiqi Zhang . 2019 . Augmenting knowledge through statistical , goal - oriented human - robot dialog . In 2019 IEEE / RSJ International Conference on Intelligent Robots and Systems ( IROS ) . IEEE , 744 – 750 . [ 6 ] Héctor H Avilés , Iván V Meza , Wendy Aguilar , and Luis Alberto Pineda . 2010 . Integrating Pointing Gestures into a Spanish - spoken Dialog System for Conversational Service Robots . . In ICAART ( 1 ) . Citeseer , 585 – 588 . 16 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks [ 7 ] Kim Baraka , Patrícia Alves - Oliveira , and Tiago Ribeiro . 2020 . An extended framework for characterizing social robots . In Human - Robot Interaction . Springer , 21 – 64 . [ 8 ] Christoph Bartneck , Dana Kulić , Elizabeth Croft , and Susana Zoghbi . 2009 . Measurement instruments for the anthropomorphism , animacy , likeability , perceived intelligence , and perceived safety of robots . International journal of social robotics 1 , 1 ( 2009 ) , 71 – 81 . [ 9 ] Tony Belpaeme , James Kennedy , Aditi Ramachandran , Brian Scassellati , and Fumihide Tanaka . 2018 . Social robots for education : A review . Science robotics 3 , 21 ( 2018 ) , eaat5954 . [ 10 ] Erik Billing , Julia Rosén , and Maurice Lamb . 2023 . Language models for human - robot interaction . In ACM / IEEE International Conference on Human - Robot Interaction , March 13 – 16 , 2023 , Stockholm , Sweden . ACM Digital Library , 905 – 906 . [ 11 ] Daniel G Bobrow , Ronald M Kaplan , Martin Kay , Donald A Norman , Henry Thompson , and Terry Winograd . 1977 . GUS , a frame - driven dialog system . Artificial intelligence 8 , 2 ( 1977 ) , 155 – 173 . [ 12 ] Dan Bohus and Eric Horvitz . 2014 . Managing human - robot engagement with forecasts and . . . um . . . hesitations . In Proceedings of the 16th international conference on multimodal interaction . 2 – 9 . [ 13 ] Hayet Brabra , Marcos Báez , Boualem Benatallah , Walid Gaaloul , Sara Bouguelia , and Shayan Zamanirad . 2021 . Dialogue Management in Conversational Systems : A Review of Approaches , Challenges , and Opportunities . IEEE Transactions on Cognitive and Developmental Systems ( 2021 ) . [ 14 ] Cynthia Breazeal , Kerstin Dautenhahn , and Takayuki Kanda . 2016 . Social robotics . Springer handbook of robotics ( 2016 ) , 1935 – 1972 . [ 15 ] Joost Broekens , Marcel Heerink , Henk Rosendal , et al . 2009 . Assistive social robots in elderly care : a review . Gerontechnology 8 , 2 ( 2009 ) , 94 – 103 . [ 16 ] Joana Campos , James Kennedy , and Jill F Lehman . 2018 . Challenges in Exploiting Conversational Memory in Human - Agent Interaction . In Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems . 1649 – 1657 . [ 17 ] Birte Carlmeyer , David Schlangen , and Britta Wrede . 2014 . Towards closed feedback loops in hri : Integrating inprotk and pamini . In Proceedings of the 2014 Workshop on Multimodal , Multi - Party , Real - World Human - Robot Interaction . 1 – 6 . [ 18 ] Joyce Y Chai , Lanbo She , Rui Fang , Spencer Ottarson , Cody Littley , Changsong Liu , and Kenneth Hanson . 2014 . Collaborative effort towards common ground in situated human - robot dialogue . In 2014 9th ACM / IEEE International Conference on Human - Robot Interaction ( HRI ) . IEEE , 33 – 40 . [ 19 ] Crystal ChaoandAndreaThomaz . 2016 . TimedPetri netsforfluentturn - taking over multimodalinteractionresourcesin human - robotcollaboration . The International Journal of Robotics Research 35 , 11 ( Sept . 2016 ) , 1330 – 1353 . https : / / doi . org / 10 . 1177 / 0278364915627291 [ 20 ] Xiaoping Chen , Jianmin Ji , Jiehui Jiang , Guoqiang Jin , Feng Wang , and Jiongkun Xie . 2010 . Developing high - level cognitive functions for service robots . . In AAMAS , Vol . 10 . 989 – 996 . [ 21 ] Heriberto Cuayáhuitl , Ivana Kruijff - Korbayová , and Nina Dethlefs . 2014 . Nonstrict hierarchical reinforcement learning for interactive systems and robots . ACM Transactions on Interactive Intelligent Systems ( TiiS ) 4 , 3 ( 2014 ) , 1 – 30 . [ 22 ] Jan Deriu , Alvaro Rodrigo , Arantxa Otegi , Guillermo Echegoyen , Sophie Rosset , Eneko Agirre , and Mark Cieliebak . 2021 . Survey on evaluation methods for dialogue systems . Artificial Intelligence Review 54 , 1 ( 2021 ) , 755 – 810 . [ 23 ] Laurence Devillers , Sophie Rosset , Guillaume Dubuisson Duplessis , Mohamed A . Sehili , Lucile Béchade , Agnés Delaborde , Clement Gossart , Vincent Letard , Fan Yang , Yücel Yemez , Bekir B . Türker , Metin Sezgin , Kevin El Haddad , Stéphane Dupont , Daniel Luzzati , Yannick Esteve , Emer Gilmartin , and Nick Campbell . 2015 . Multimodal data collection of human - robot humorous interactions in the Joker project . In 2015 International Conference on Affective Computing and Intelligent Interaction ( ACII ) . 348 – 354 . https : / / doi . org / 10 . 1109 / ACII . 2015 . 7344594 ISSN : 2156 - 8111 . [ 24 ] Francesca Dino , Rohola Zandie , Hojjat Abdollahi , Sarah Schoeder , and Mohammad H Mahoor . 2019 . Delivering cognitive behavioral therapy using a conversational social robot . In 2019 IEEE / RSJ International Conference on Intelligent Robots and Systems ( IROS ) . IEEE , 2089 – 2095 . [ 25 ] Finale Doshi and Nicholas Roy . 2007 . Efficient model learning for dialog management . In Proceedings of the ACM / IEEE international conference on Human - robot interaction . 65 – 72 . [ 26 ] MMSN Edirisinghe , MAVJ Muthugala , and AGBP Jayasekara . 2018 . Application of robot autobiographical memory in long - term human - robot social interactions . In 2018 2nd International Conference On Electrical Engineering ( EECon ) . IEEE , 138 – 143 . [ 27 ] Terrence Fong , Illah Nourbakhsh , and Kerstin Dautenhahn . 2002 . A survey of socially interactive robots : Concepts , Design and Applications . ( 2002 ) . [ 28 ] Mary Ellen Foster , Andre Gaschler , Manuel Giuliani , Amy Isard , Maria Pateraki , and Ronald PA Petrick . 2012 . Two people walk into a bar : Dynamic multi - party social interaction with a robot agent . In Proceedings of the 14th ACM international conference on Multimodal interaction . 3 – 10 . [ 29 ] Mary Ellen Foster , Andre Gaschler , Manuel Giuliani , Amy Isard , Maria Pateraki , and Ronald P . A . Petrick . 2012 . Two people walk into a bar : dynamic multi - party social interaction with a robot agent . In Proceedings of the 14th ACM international conference on Multimodal interaction - ICMI ’12 . ACM Press , Santa Monica , California , USA , 3 . https : / / doi . org / 10 . 1145 / 2388676 . 2388680 [ 30 ] Kotaro Funakoshi , Mikio Nakano , Toyotaka Torii , Yuji Hasegawa , Hiroshi Tsujino , Noriyuki Kimura , and Naoto Iwahashi . 2007 . Robust acquisition and recognition of spoken location names by domestic robots . In 2007 IEEE / RSJ International Conference on Intelligent Robots and Systems . IEEE , 1435 – 1440 . [ 31 ] Felix Gervits , Anton Leuski , Claire Bonial , Carla Gordon , and David Traum . 2021 . A Classification - Based Approach to Automating Human - Robot Dialogue . In Increasing Naturalness and Flexibility in Spoken Dialogue Interaction : 10th International Workshop on Spoken Dialogue Systems . Springer Singapore , 115 – 127 . [ 32 ] Felix Gervits and Matthias Scheutz . 2018 . Pardon the interruption : Managing turn - taking through overlap resolution in embodied artificial agents . In Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue . 99 – 109 . [ 33 ] Felix Gervits , Ravenna Thielstrom , Antonio Roque , and Matthias Scheutz . 2020 . It’s about time : Turn - entry timing for situated human - robot dialogue . In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue . 86 – 96 . A Survey on Dialogue Management in Human - Robot Interaction 17 [ 34 ] Petra Gieselmann and Mari Ostendorf . 2007 . Problem - sensitive response generation in human - robot Dialogs . In Proceedings of the 8th SIGDial Workshop on Discourse and Dialogue . 219 – 222 . [ 35 ] Javi F Gorostiza and Miguel A Salichs . 2010 . Natural programming of a social robot by dialogs . In 2010 AAAI Fall Symposium Series . [ 36 ] JinGuang Han , Emer Gilmartin , and Nick Campbell . 2013 . Herme , Yet Another Interactive Conversational Robot . In 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction . 711 – 712 . https : / / doi . org / 10 . 1109 / ACII . 2013 . 127 ISSN : 2156 - 8111 . [ 37 ] Jan - Gerrit Harms , Pavel Kucherbaev , Alessandro Bozzon , and Geert - Jan Houben . 2018 . Approaches for dialog management in conversational agents . IEEE Internet Computing 23 , 2 ( 2018 ) , 13 – 22 . [ 38 ] Sachithra Hemachandra and Matthew R Walter . 2015 . Information - theoretic dialog to improve spatial - semantic representations . In 2015 IEEE / RSJ International Conference on Intelligent Robots and Systems ( IROS ) . IEEE , 5115 – 5121 . [ 39 ] Sachithra Hemachandra , Matthew R Walter , and Seth Teller . 2014 . Information theoretic question asking to improve spatial semantic representations . In 2014 AAAI Fall Symposium Series . [ 40 ] Hartwig Holzapfel . 2005 . Towards development of multilingual spoken dialogue systems . In Proceedings of the 2nd Language and Technology Conference . [ 41 ] Hartwig Holzapfel . 2008 . A dialogue manager for multimodal human - robot interaction and learning of a humanoid robot . Industrial Robot : An International Journal 35 , 6 ( Oct . 2008 ) , 528 – 535 . https : / / doi . org / 10 . 1108 / 01439910810909529 [ 42 ] Koji Inoue , Divesh Lala , Kenta Yamamoto , Shizuka Nakamura , Katsuya Takanashi , and Tatsuya Kawahara . 2020 . An attentive listening system with android ERICA : Comparison of autonomous and WOZ interactions . In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue . 118 – 127 . [ 43 ] Radu Ion , Valentin Gabriel Badea , George Cioroiu , Verginica Barbu Mititelu , Elena Irimia , Maria Mitrofan , and Dan TUFIS , . 2020 . A Dialog Manager for Micro - Worlds . Studies in Informatics and Control 29 , 4 ( 2020 ) , 411 – 420 . [ 44 ] Ridong Jiang , Yeow Kee Tan , Dilip Kumar Limbu , Tran Anh Tung , and Haizhou Li . 2011 . A configurable dialogue platform for ASORO Robots . Proc of APSIPA ASC ( 2011 ) . [ 45 ] Martin Johansson and Gabriel Skantze . 2015 . Opportunities and obligations to take turns in collaborative multi - party human - robot interaction . In Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue . 305 – 314 . [ 46 ] Andreas Kipp and Franz Kummert . 2014 . Dynamic dialog system for human robot collaboration : playing a game of pairs . In Proceedings of the second international conference on Human - agent interaction . 225 – 228 . [ 47 ] Laura Kunold , Nikolai Bock , and Astrid Rosenthal - von der Pütten . 2023 . Not All Robots Are Evaluated Equally : The Impact of Morphological Features on Robots’ Assessment through Capability Attributions . ACM Transactions on Human - Robot Interaction 12 , 1 ( 2023 ) , 1 – 31 . [ 48 ] Divesh Lala , Koji Inoue , and Tatsuya Kawahara . 2018 . Evaluation of real - time deep learning turn - taking models for multiple dialogue scenarios . In Proceedings of the 20th ACM International Conference on Multimodal Interaction . 78 – 86 . [ 49 ] Divesh Lala , Pierrick Milhorat , Koji Inoue , Masanari Ishida , Katsuya Takanashi , and Tatsuya Kawahara . 2017 . Attentive listening system with backchanneling , response generation and flexible turn - taking . In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue . 127 – 136 . [ 50 ] Changyoon Lee , You - Sung Cha , and Tae - Yong Kuc . 2008 . Implementation of dialogue system for intelligent service robots . In 2008 International Conference on Control , Automation and Systems . IEEE , 2038 – 2042 . [ 51 ] Cheongjae Lee , Sangkeun Jung , Kyungduk Kim , and Gary Geunbae Lee . 2010 . Hybrid approach to robust dialog management using agenda and dialog examples . Computer Speech & Language 24 , 4 ( 2010 ) , 609 – 631 . [ 52 ] Jamy Li . 2015 . The benefit of being physically present : A survey of experimental works comparing copresent robots , telepresent robots and virtual agents . International Journal of Human - Computer Studies 77 ( 2015 ) , 23 – 37 . [ 53 ] Shuyin Li , Britta Wrede , and Gerhard Sagerer . 2006 . A computational model of multi - modal grounding for human robot interaction . In Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue - SigDIAL ’06 . Association for Computational Linguistics , Sydney , Australia , 153 . https : / / doi . org / 10 . 3115 / 1654595 . 1654626 [ 54 ] Shuyin Li , Britta Wrede , and Gerhard Sagerer . 2006 . A dialog system for comparative user studies on robot verbal behavior . In ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication . IEEE , 129 – 134 . [ 55 ] Pierre Lison . 2012 . Probabilistic dialogue models with prior domain knowledge . ( 2012 ) . [ 56 ] Pierre Lison . 2013 . Model - based bayesian reinforcement learning for dialogue management . arXiv preprint arXiv : 1304 . 1819 ( 2013 ) . [ 57 ] Pierre Lison . 2015 . A hybrid approach to dialogue management based on probabilistic rules . Computer Speech & Language 34 , 1 ( 2015 ) , 232 – 255 . [ 58 ] Rui Liu and Xiaoli Zhang . 2019 . A review of methodologies for natural - language - facilitated human – robot cooperation . International Journal of Advanced Robotic Systems 16 , 3 ( 2019 ) , 1729881419851402 . [ 59 ] Dongcai Lu , Shiqi Zhang , Peter Stone , and Xiaoping Chen . 2017 . Leveraging commonsense reasoning and multimodal perception for robot spoken dialog systems . In 2017 IEEE / RSJ International Conference on Intelligent Robots and Systems ( IROS ) . 6582 – 6588 . https : / / doi . org / 10 . 1109 / IROS . 2017 . 8206570 ISSN : 2153 - 0866 . [ 60 ] Lorenzo Lucignano , Francesco Cutugno , Silvia Rossi , and Alberto Finzi . 2013 . A dialogue system for multimodal human - robot interaction . In Proceedings of the 15th ACM on International conference on multimodal interaction . ACM , Sydney Australia , 197 – 204 . https : / / doi . org / 10 . 1145 / 2522848 . 2522873 [ 61 ] Matthew Marge , Carol Espy - Wilson , Nigel G Ward , Abeer Alwan , Yoav Artzi , Mohit Bansal , Gil Blankenship , Joyce Chai , Hal Daumé III , Debadeepta Dey , et al . 2022 . Spoken language interaction with robots : Recommendations for future research . Computer Speech & Language 71 ( 2022 ) , 101255 . 18 Merle M . Reimann , Florian A . Kunneman , Catharine Oertel , and Koen V . Hindriks [ 62 ] Yoichi Matsuyama , Hikaru Taniyama , Shinya Fujie , and Tetsunori Kobayashi . 2010 . Framework of communication activation robot participating in multiparty conversation . In 2010 AAAI Fall Symposium Series . [ 63 ] Nikolaos Mavridis . 2015 . A review of verbal and non - verbal human – robot interactive communication . Robotics and Autonomous Systems 63 ( 2015 ) , 22 – 35 . [ 64 ] Pierrick Milhorat , Divesh Lala , Koji Inoue , Tianyu Zhao , Masanari Ishida , Katsuya Takanashi , Shizuka Nakamura , and Tatsuya Kawahara . 2019 . A conversational dialogue manager for the humanoid robot ERICA . In Advanced Social Interaction with Agents . Springer , 119 – 131 . [ 65 ] David Moher , Larissa Shamseer , Mike Clarke , Davina Ghersi , Alessandro Liberati , Mark Petticrew , Paul Shekelle , and Lesley A Stewart . 2015 . Preferred reporting items for systematic review and meta - analysis protocols ( PRISMA - P ) 2015 statement . Systematic reviews 4 , 1 ( 2015 ) , 1 – 9 . [ 66 ] Mikio Nakano , Naoto Iwahashi , Takayuki Nagai , Taisuke Sumii , Xiang Zuo , Ryo Taguchi , Takashi Nose , Akira Mizutani , Tomoaki Nakamura , MuhanmadAttamim , etal . 2010 . Groundingnewwordsonthephysicalworldinmulti - domainhuman - robotdialogues . In 2010AAAIFallSymposium Series . [ 67 ] CarloNuccio , AgneseAugello , SalvatoreGaglio , andGiovanniPilato . 2018 . InteractionCapabilitiesofaRoboticReceptionist . In IntelligentInteractive Multimedia Systems and Services 2017 ( Smart Innovation , Systems and Technologies ) , Giuseppe De Pietro , Luigi Gallo , Robert J . Howlett , and Lakhmi C . Jain ( Eds . ) . Springer International Publishing , Cham , 171 – 180 . https : / / doi . org / 10 . 1007 / 978 - 3 - 319 - 59480 - 4 _ 18 [ 68 ] Stanislav Ondas , Jozef Juhar , Matus Pleva , Peter Fercak , and Rastislav Husovsky . 2017 . Multimodal dialogue system with NAO and VoiceXML dialogue manager . In 2017 8th IEEE International Conference on Cognitive Infocommunications ( CogInfoCom ) . IEEE , Debrecen , 000439 – 000444 . https : / / doi . org / 10 . 1109 / CogInfoCom . 2017 . 8268286 [ 69 ] Mourad Ouzzani , Hossam Hammady , Zbys Fedorowicz , and Ahmed Elmagarmid . 2016 . Rayyan—a web and mobile app for systematic reviews . Systematic Reviews 5 , 1 ( 2016 ) , 210 . https : / / doi . org / 10 . 1186 / s13643 - 016 - 0384 - 4 [ 70 ] Julia Peltason and Britta Wrede . 2010 . Pamini : A framework for assembling mixed - initiative human - robot interaction from generic interaction patterns . In Proceedings of the SIGDIAL 2010 Conference . 229 – 232 . [ 71 ] Julia Peltason and Britta Wrede . 2012 . Structuring Human - Robot - Interaction in Tutoring Scenarios . In Towards Service Robots for Everyday Environments . Springer , 471 – 482 . [ 72 ] Ronald PA Petrick , Mary Ellen Foster , and Amy Isard . 2012 . Social state recognition and knowledge - level planning for human - robot interaction in a bartender domain . In Workshops at the Twenty - Sixth AAAI Conference on Artificial Intelligence . [ 73 ] Thomas Prommer , Hartwig Holzapfel , and Alex Waibel . 2006 . Rapid Simulation - Driven Reinforcement Learning of Multimodal Dialog Strategies in Human - Robot Interaction . ( 2006 ) . [ 74 ] Marcelo Quinderé , L Seabra Lopes , and António JS Teixeira . 2007 . A Dialogue Manager for an Intelligent Mobile Robot . Natural Language Processing and Cognitive Science ( NLPCS ) ( 2007 ) . [ 75 ] Marcelo Quinderé , Luís Seabra Lopes , and António JS Teixeira . 2007 . An information state based dialogue manager for a mobile robot . In Eighth Annual Conference of the International Speech Communication Association . Citeseer . [ 76 ] Marcelo Quinderé , Luís Seabra Lopes , and António JS Teixeira . 2013 . Evaluation of a dialogue manager for a mobile robot . In 2013 IEEE RO - MAN . IEEE , 126 – 132 . [ 77 ] Stephanie Rosenthal and Manuela Veloso . 2010 . Mixed - initiative long - term interactions with an all - day - companion robot . In 2010 AAAI Fall Symposium Series . [ 78 ] Alessandro Russo , Grazia D’Onofrio , Aldo Gangemi , Francesco Giuliani , Misael Mongiovi , Francesco Ricciardi , Francesca Greco , Filippo Cavallo , Paolo Dario , Daniele Sancarlo , et al . 2019 . Dialogue Systems and Conversational Agents for Patients with Dementia : The Human – Robot Interaction . Rejuvenation research 22 , 2 ( 2019 ) , 109 – 120 . [ 79 ] Paul E Rybski , Kevin Yoon , Jeremy Stolarz , and Manuela M Veloso . 2007 . Interactive robot task training through dialog and demonstration . In Proceedings of the ACM / IEEE international conference on Human - robot interaction . 49 – 56 . [ 80 ] Lanbo She , Shaohua Yang , Yu Cheng , Yunyi Jia , Joyce Chai , and Ning Xi . 2014 . Back to the blocks world : Learning new actions through situated human - robot dialogue . In Proceedings of the 15th annual meeting of the special interest group on discourse and dialogue ( SIGDIAL ) . 89 – 97 . [ 81 ] Borui Shen and Diana Inkpen . 2016 . Speech intent recognition for robots . In 2016 Third International Conference on Mathematics and Computers in Sciences and in Industry ( MCSI ) . IEEE , 185 – 190 . [ 82 ] Gabriel Skantze . 2021 . Turn - taking in conversational systems and human - robot interaction : a review . Computer Speech & Language 67 ( 2021 ) , 101178 . [ 83 ] Gabriel Skantze , Anna Hjalmarsson , and Catharine Oertel . 2013 . Exploring the effects of gaze and pauses in situated human - robot interaction . In Proceedings of the SIGDIAL 2013 Conference . 163 – 172 . [ 84 ] Robert Stalnaker . 2002 . Common ground . Linguistics and philosophy 25 , 5 / 6 ( 2002 ) , 701 – 721 . [ 85 ] Komei Sugiura , Naoto Iwahashi , Hideki Kashioka , and Satoshi Nakamura . 2010 . Active learning of confidence measure function in robot language acquisition framework . In 2010 IEEE / RSJ International Conference on Intelligent Robots and Systems . IEEE , 1774 – 1779 . [ 86 ] Jesse Thomason , Shiqi Zhang , Raymond J Mooney , and Peter Stone . 2015 . Learning to interpret natural language commands through human - robot dialog . In Twenty - Fourth International Joint Conference on Artificial Intelligence . [ 87 ] Cristen Torrey , Aaron Powers , Matthew Marge , Susan R Fussell , and Sara Kiesler . 2006 . Effects of adaptive robot dialogue on information exchange and social relations . In Proceedings of the 1st ACM SIGCHI / SIGART conference on Human - robot interaction . 126 – 133 . A Survey on Dialogue Management in Human - Robot Interaction 19 [ 88 ] David R Traum and Staffan Larsson . 2003 . The information state approach to dialogue management . In Current and new directions in discourse and dialogue . Springer , 325 – 353 . [ 89 ] H Trung . 2006 . Multimodal dialogue management - state of the art . Human Media Interaction Department , University of Twente 2 ( 2006 ) . [ 90 ] Daniel Couto Vale and Vivien Mast . 2013 . Tacit social contracts for wheelchairs . In Proceedings of the SIGDIAL 2013 Conference . 294 – 303 . [ 91 ] Dimitrios Vogiatzis and Vangelis Karkaletsis . 2008 . A framework for human - robot interaction . In Proceedings of the 1st international conference on PErvasive Technologies Related to Assistive Environments . 1 – 7 . [ 92 ] Tom Williams , Gordon Briggs , Bradley Oosterveld , and Matthias Scheutz . 2015 . Going beyond literal command - based instructions : Extending robotic natural language interaction capabilities . In Twenty - Ninth AAAI Conference on Artificial Intelligence . [ 93 ] Jie Zeng , Yukiko I Nakano , Takeshi Morita , Ichiro Kobayashi , and Takahira Yamaguchi . 2018 . Eliciting user food preferences in terms of taste and texture in spoken dialogue systems . In Proceedings of the 3rd International Workshop on Multisensory Approaches to Human - Food Interaction . 1 – 5 . [ 94 ] BowenZhangandHaroldSoh . 2023 . Largelanguagemodelsaszero - shothumanmodelsforhuman - robotinteraction . arXivpreprintarXiv : 2303 . 03548 ( 2023 ) . [ 95 ] Shiqi Zhang and Peter Stone . 2015 . CORPP : Commonsense reasoning and probabilistic planning , as applied to dialog with a mobile robot . In Proceedings of the AAAI Conference on Artificial Intelligence , Vol . 29 . [ 96 ] Yin Jiang Zhao , Yan Ling Li , and Min Lin . 2019 . A review of the research on dialogue management of task - oriented systems . In Journal of Physics : Conference Series , Vol . 1267 . IOP Publishing , 012025 .