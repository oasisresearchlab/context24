Towards (cid:1) Integrated (cid:1) Model - Based (cid:1) Machine (cid:1) Learning (cid:1) Experimentation (cid:1) Framework Jomphon (cid:1) Runpakprakun 1 , (cid:1) Jati (cid:1) H . (cid:1) Husen 1 , 2 , (cid:1) Hironori (cid:1) Washizaki 1 , (cid:1) Nobukazu (cid:1) Yoshioka 1 , (cid:1)(cid:66)(cid:79)(cid:69)(cid:1) Yoshiaki (cid:1) Fukazawa 1 (cid:1) 1 Waseda (cid:1) University , (cid:1) Tokyo , (cid:1) Japan 2 Telkom (cid:1) University , (cid:1) Bandung , (cid:1) Indonesia k - jomphon @ moegi . waseda . jp , (cid:1) jatihusen @ telkomuniversity . ac . id , (cid:1) washizaki @ waseda . jp , nobukazuy @ acm . org , (cid:1) fukazawa @ waseda . jp Abstract —ML systems in critical applications , such as autonomous driving , require high - quality assurance and the ability to handle concept drift and performance drop . To address these challenges , we propose an integrated system be - tween the Multi - view Modeling tool to the automated pipeline for the ML Model Training and DNN Repair . Our preliminary integration and experiment has shown promising result . Keywords – MLOps ; ML Pipeline ; ML Experiment Man - agement ; Artifact Management ; Multi - View Modeling 1 . I NTRODUCTION Measuring various performance metrics is crucial in developing effective machine learning ( ML ) based systems to ensure they meet the desired quality levels . Reproducibility , version control , and efﬁcient workﬂow management are key components in achieving this goal . However , more speciﬁc ML - based solutions , such as deep neural network ( DNN ) repair , require a more specialized approach to conducting experiments successfully . Before this study , the multi - view modeling [ 1 ] and DNN repair frameworks [ 2 ] operated separately . Creating a new ML model using the framework required manual operation from training to evaluating performance and determine which classes needed to be repaired . This manual intervention in - volved setting up repair parameters , performing repairs , and evaluating the ﬁnal results against requirements . Then utilizing the modeling tools ensured quality by deriving performance parameters from top - level requirements and visually assessing the ML model’s test results . However , all these steps are manual hence , it is complicated to operate and prone to human error . Our research addresses the lack of automation by im - plementing a pipeline that automates the integration of the DNN repair tool for both based model creation and repair operations . This automated pipeline enables the Multi - view Modeling side to easily experiment with constructing new models without manually operating the tools . It also facilitates model performance assessment and repair decision - making without manually operating the repair tools or tracking ar - tifacts and experiments . This study aims to create an integrated approach for model - based ML system development . To achieve that objec - tive , we designed the following research questions : • RQ1 . What is the appropriate design approach for the integrated automated pipeline ? • RQ2 . How does the proposed automation of the ML model experimentation and repair processes affect overall system performance , reliability , and adaptability ? This study contributes to the software engineering body of knowledge in the form of a design for model - based MLOps . 2 . R ELATED W ORK Several studies have been done previously in machine learning model experimentation . Effective testing methods and tools are crucial to validate the performance and reliability of DNN models . Qunomon [ 3 ] is a testbed that bridges gaps between different perspectives and combines and compares various testing methods for ML component quality . The Experiment Management Meta - Model ( EMMM ) [ 4 ] offers a comprehensive framework of conceptualized structures and relationships extracted from subject tools . EMMM provides a valuable reference for tool developers and researchers to enhance existing tools or develop next - generation ML - speciﬁc tools . Selecting the appropriate MLOps tools , including asset management and experiment management tools , is paramount . Idowu et al . emphasize the customization potential of MLOps tools to align with speciﬁc use cases [ 5 ] . While Madan et al . provide an overview of MLOps technologies and tools suggestions [ 6 ] by Evaluating the simplicity and versatility of tools like MLFlow , AirFlow , KubeFlow , and especially Production Deploy ML model PerformanceMonitoring Based Model Pipeline Experiment Server PerformanceEvaluation DNN Repair Pipeline Object Storage Server DatasetStorage ArtifactStorage ModelRepos Development Start P u ll R a w D a t a S t o r e M ode l & A r t i f a c t s S t o r e M ode l & A r t i f a c t s Not all requirements satisﬁed , Trigger Repair Modeling Path for Fresh Model Experiment Path for Both Experiments Path for DNN Repair Experiment , in case requirement is not satisﬁed Path for DNN Repair Experiment , in case requirement is satisﬁed A ll r equ i r e m en t s s a t i sﬁ ed , S e l e c t M ode l t o be D ep l o y ed Pull Artifacts for Repair(cid:2) Figure 1 . Architecture diagram for ML pipelines and artifact management integration 593 2023 10th International Conference on Dependable Systems and Their Applications ( DSA ) 2767 - 6684 / 23 / $ 31 . 00 ©2023 IEEE DOI 10 . 1109 / DSA59317 . 2023 . 00086 202 3 10 t h I n t e r n a ti on a l C on f e r e n ce on D e p e nd a b l e S y s t e m s a nd T h e i r A pp li ca ti on s ( D S A ) | 979 - 8 - 3503 - 0477 - 0 / 23 / $ 31 . 00 © 2023 I EEE | DO I : 10 . 1109 / D S A 59317 . 2023 . 00086 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Figure 2 . Integration ﬂow between modeling and ML pipeline Data Version Control ( DVC ) 1 can assist in selecting the most suitable tool for the research at hand . 3 . ML P IPELINE I NTEGRATION Figure 1 summarizes the overview of our integration . We abstracted a set of actions , such as data preparation and training , into what we call the ”Based model pipeline , ” which will generate an ML model , then another set of actions , such as targeting class and optimizing ML model as a ”DNN Repair pipeline . ” With a clear separation , each type of pipeline can be triggered independently . After each pipeline template is created , it will be assigned the hyperparameter from the modeling tool , then the pipeline gets executed , it produces results and stores them into a storage server , and the model gets validated . Suppose the model performance fetched to the modeling tool did not satisfy the requirement . In that case , the user can use the Modeling tools to create a repair strategy by choosing the class , assigning repair priority based on the analyzed result , then triggering the repair pipeline . The interaction between Modeling tools and both types of workﬂow pipelines is represented in the ﬁgure 2 . To simplify the creation of the DVC pipeline’s ﬁle annotation , instead of manually deﬁning each step , we have developed a wrapper script that automates the pipeline creation process . After the ﬁrst run , the execution result will be fetched to the modeling tool , such as Astah * 2 , to validate performance and assign appropriate strategy if the repair process is needed . 4 . E VALUATION We did a preliminary experiment on the integrated system between our integration ( experiment group ) and a standard CLI with a separate requirements sheet ( control group ) . Both groups are tasked to complete a series of tasks in evaluating and repairing different version models . 1 https : / / dvc . org / 2 https : / / astah . net / In terms of the experiment reproducibility , the experiment group gains more understanding about the overview require - ment and what to expect since they have a view of Multi - Modeling , while in contrast , the control group tends to have a harder time interpreting the model performance result and conﬁg the repair parameter , based on just text description . Therefore , from this observation , we have the answer to the research questions . For RQ1 , we can argue that the design we used for the integration is appropriate . This argument is based on the positive sentiment from the participants . For RQ2 , since the user from the experiment group had a simpler time running the based pipeline and repair pipeline , therefore most of their focus was on the requirement assurance more than the operation itself , which differs from the control group , which was concerned about managing artifact in order to prepare for running repair process . Therefore , we can emphasize that the existence of automated ML experiment contribute to the overall system performance and reliability . 5 . C ONCLUSION AND F UTURE W ORK This paper presented our work on integrating multi - view modeling frameworks to an automate ML pipeline . The inte - gration supports the development of reliable ML systems by ensuring reproducibility , artifact version control , and system requirements assurance . In the future , we aim to enhance adoption by general - izing each component . Decoupling modeling tools , workﬂow pipeline engine , and artifact storage allow adopters to use their preferred tech stack . Further evaluation by conducting more experiments is also necessary to have a better evaluation . A CKNOWLEDGMENT This work was supported by JST - Mirai Program Grant Number JPMJMI20B8 . R EFERENCES [ 1 ] Husen , J . , Washizaki , H . , Yoshioka , N . , Tun , H . , Fukazawa , Y . , & Takeuchi , H . ( 2023 ) . Metamodel - Based Multi - View Modeling Framework for Machine Learning Systems . [ 2 ] Nakagawa , T . , Tokumoto , S . , Tokui , S . , & Ishikawa , F . ( 2023 ) . An Experience Report on Regression - Free Repair of Deep Neural Network Model . [ 3 ] Narita , K . , Akita , M . , Kim , K . , Iwase , Y . , Watanaka , Y . , Nakagawa , T . , & Zhong , Q . ( 2021 ) . Qunomon : A FAIR testbed of quality evaluation for machine learning models . [ 4 ] Idowu , S . , Struber , D . , & Berger , T . ( 2022 ) . EMMM : A Uniﬁed Meta - Model for Tracking Machine Learning Experiments . [ 5 ] Idowu , S . O . , Str¨uber , D . , & Berger , T . ( 2022 ) . Asset Management in Machine Learning : State - of - research and State - of - practice . ACM Computing Surveys , 55 ( 7 ) , 1 – 35 . [ 6 ] Ruf , P . J . , Madan , M . , Reich , C . , & Abdeslam , D . O . ( 2021 ) . Demystifying MLOps and Presenting a Recipe for the Selection of Open - Source Tools . Applied Sciences , 11 ( 19 ) , 8861 . 594 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .