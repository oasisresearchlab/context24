Information Extraction Methods for Text Documents in a Cognitive Integrated Management Information System Marcin Hernes Department of Economic Informatics Wroc ł aw University of Economics Wroc ł aw , Poland marcin . hernes @ ue . wroc . pl Abstract — In contemporary companies unstructured knowledge is essential , mainly due to the possibility to obtain better flexibility and competitiveness of the organization . For example , on the basis of automatic analysis of the experts’ opinions , the decision - makers are capable of taking decisions ( for example decisions concerning investments ) . This paper presents issues related to developing and evaluating a methods of information extraction performed by cognitive agent running in integrated management information system . The main advantages of this approach are cognitive agents’ ability of including a context of extracted information and its ability of automatic decision - making on the basis of extracted information . Keywords—information extraction ; cognitive agents ; integrated management information systems I . I NTRODUCTION Integrated Management Information Systems ( IMIS ) , developed often as multiagent systems , play a vital part in any kind of enterprise activity . These systems allow to not only access to the information and quick search for interesting us information , its analysis and drawing conclusions , but also , in addition to responding to stimuli from the environment , have the cognitive ability to learning through empirical experience gained through direct interaction with the environment [ 14 ] , which in turn allows for the automatic generation of variants of decisions and , in many cases , even taking and putting into action of the decisions . The biggest problem currently , however , turns out to be the processing of unstructured knowledge in IMIS . Note that knowledge contained in computer management systems is normally structuralized and the systems employ various methods for processing structuralized knowledge and resolving conflicts of such knowledge . However , in contemporary companies , unstructured knowledge is essential , mainly due to the possibility to obtain better flexibility and competitiveness of the organization . Therefore , unstructured knowledge supports structuralized knowledge to a high degree . It is mainly stored in natural language . Generally speaking , there are text databases that contain various types of text files , such as newspaper articles , e - books , e - mail , websites and all sorts of text files . The documents describe certain phenomena that occur in the real world , in the environment where a given organization operates . Text files are not internally structured in any way , the knowledge that they contain is non - structuralized or structuralized to a small degree . For example , the structure of an e - mail message contains information on sender , addressee , size , subject , but the rest of the message is a stream of symbols deprived of internal structure . It is important to say that text files are often a source of significant and useful knowledge . Therefore IMIS must be able to processing also such unstructured knowledge by performing such processes , as information retrieval , information extraction ( IE ) , text mining and natural language processing . The basic task of IE is to automatically extract information from unstructured and / or semi - structured machine - readable documents . That means data which can be detected in one or more texts should be classified , transformed , and stored for further use usually into some database [ 2 ] . The main problem however , is that despite the tremendous advances of IE techniques in recent years , open issues still remain regarding quality , reliability , and complexity , which hamper the widespread adoption of IE techniques [ 2 ] . These techniques mainly serve for the conversion of the gathered data into information or knowledge base – useful , legible and easily interpretable and thus more suitable to a decision - maker . However , for the definition of meaning of information , a human mind is necessary , and the change of knowledge into wisdom ( necessary to take a good decision ) requires not only human intellect but even human genius [ 23 ] . Therefore , it seems justified to use the technologies ( tools ) which perform cognitive and decision - making functions , the ones that take place in the human brain and owing to this are capable of understanding the real meaning of the observed phenomena and economic processes taking place in the organization environment . These tools include cognitive agents which often cooperate within the framework of a multi - agent system in order to effectively reach a set goal . The aim of this paper is to develop and to evaluate a methods of information extraction for text documents performed by cognitive agent running in a Cognitive Integrated Management Information System ( CIMIS ) . The first part of the paper shortly presents the state on the art in the field . Next the methods of information extraction in CIMIS is presented . The research experiment aims to evaluation of these methods is presented at the last part of the paper . This work was financially supported by the National Science Center ( decision No . DEC - 2013 / 11 / D / HS4 / 04096 ) 978 - 1 - 4799 - 8322 - 3 / 15 / $ 31 . 00 ©2015 IEEE II . R ELATED W ORKS Analysis of literary sources on the subject indicates that nowadays hybrid methods for processing unstructured knowledge are used ; the methods involve structuralization of knowledge , followed by symbolic processing ( e . g . with the use of expert systems or genetic algorithms ) or converting knowledge into numerical representation followed by numerical processing ( e . g . with the use of neural networks or fuzzy logic systems ) . Both cases , to the processing of knowledge , the following methods are used [ 19 ] : • Information ( documents ) Retrieval , • Information Extraction , • Text Mining , • Natural Language Processing . Information retrieval systems shall inform the user about the existence of sources ( sites ) , where you will find the documents complying with the requirements of the user [ 24 ] ( search for documents on the basis of requests made by the user ) . Information extraction is to identify an instance of a predefined event classes ( for example , an opinion about the product ) of their links and documents instances [ 19 ] . The information derived from the content of documents can be placed in the database . The most popular and most common tasks of text exploration are [ 27 ] : • grouping text files ( dividing the initial set of documents into sets that contain most similar documents ) , • classifying text files ( assigning documents to existing groups ) , • document importance ranking , • analyzing relations between documents ( e . g . quote network analysis ) . Understanding natural language ( natural language processing ) involves the application of automatic mechanisms for understanding the context of texts . It shall be made , inter alia , the designation of the individual parts of speech and searching for the meaning of the expression in the context of the complete analysis of the grammar [ 1 ] . Therefore , information extraction is not identified with information retrieval , text mining or a full understanding the context of texts . The IE is related with following areas [ 2 ] : • named entity extraction , aims at finding real - world objects in texts and classifying these objects into predefined categories such as names of persons , organizations , locations , temporal expressions , products , etc . ; this area was considered , for example , by [ 16 ] , [ 10 ] , • general entity extraction , aim at finding domain - independent entities with highest possible precision , but acceptable recall ; this area was considered , for example , by [ 3 ] , [ 4 ] , [ 13 ] . • characteristics and attributes of entities extraction , aims at automatically building highly complete profiles for entities ; this area was considered , for example , by [ 7 ] , [ 11 ] , • classes of entities extraction , aims at classifying all extracted entities with respect to suitable concepts ; this area was considered , for example , by [ 8 ] , [ 22 ] . • general relationships between entities aims at finding relationship between entities on the general , mainly semantic level ; this area was considered , for example , by [ 6 ] , [ 12 ] . IE at all presented areas is performed by different methods , techniques and tools , roots in artificial intelligence fields , including machine learning , logic and search algorithms , computational linguistics , and pattern recognition [ 20 ] , [ 25 ] , [ 26 ] . However their result quality does often not live up to the required standards of the respective applications [ 2 ] . Therefore , many companies still rely on manual curation of their knowledge bases . This need for human assistance for bridging the final quality gap has given rise to the extraction techniques which rely on hybrid architectures , transparently combining the efficiency of current algorithms with the cognitive power and flexibility of humans [ 2 ] . In opposite to hybrid methods this paper propose to use a cognitive agents in order to information extraction performed in CIMIS and related to all IE areas . The main originality of presented approach is the possibility to combine different information extraction methods in consistent , unified agents’ architecture . This allows for the inclusion a context of extracted information and for automatic decision - making on the basis of extracted information , in order to achieve greater efficiency of decision support process realized by CIMIS . III . M ETHODS FOR INFORMATION EXTRACTION IN CIMIS In order to information extraction from documents written in natural language , it was decided to use the architecture of cognitive agent The Learning Intelligent Distribution Agent ( LIDA ) developed by Cognitive Computing Research Group . ( CCRG ) under the leadership of professor Stan Franklin from the University of Memphis [ 9 ] . This architecture has been used in practices related to , inter alia , with automatic searching job opportunity by sailors serving in the US Navy . The CCRG elaborated in 2011 the framework ( in Java language ) significantly facilitating the implementation of the cognitive agent . In the construction of a LIDA agent mixed - used symbolically - connexionistic organization of memory is using , in an attempt to grounded the meaning of all symbols . It is necessary to properly process the unstructured knowledge , recorded mostly using natural language , such as customer opinions about products . The LIDA consists of the following modules [ 21 ] : Sensory Memory , Perceptual - Associative Memory , Workspace , Transient Episodic Memory , Declarative Memory , Attentional Codelets , Global Workspace , Procedural Memory , Action Selection , Sensory - Motor Memory . In the LIDA the majority of basic operations are performed by the so - called codelets , namely specialized , mobile programs processing information in the model of global workspace . The functioning of the cognitive agent is performed within the framework of the cognitive cycle and it is divided into three phases : the understanding phase , the consciousness phase and the selection of actions and learning phase . At the beginning of the understanding phase the stimuli received from the environment activate the codelets of the low level features in the sensory memory [ 21 ] . The outlets of these codelets activate the perceptual memory , where high level feature codelets supply more abstract things such as objects , categories , actions or events . The perception results are transferred to workspace and on the basis of episodic and declarative memory local links are created and then , with the use of the occurrences of perceptual memory , a current situational model is generated ; it other words the agent understands what phenomena are occurring in the environment of the organization . The consciousness phase starts with forming of the coalition of the most significant elements of the situational model , which then compete for attention so the place in the workspace , by using attentional codelets . The contents of the workspace module are then transferred to the global workspace ( the so - called “broadcasting” takes place ) , simultaneously initializing the phase of action selection . At this phase possible action schemes are taken from procedural memory and sent to the action selection module , where there compete for the selection in a given cycle . The selected actions activate sensory - motor memory for the purpose of creating an appropriate algorithm of their performance , which is the final stage of the cognitive cycle [ 9 ] . The cognitive cycle is repeated with the frequency of 5 – 10 times per second . Parallelly with the previous actions the agent’s learning is performed , which is divided into perceptual learning concerning the recognition of new objects , categories , relations ; episodic learning which means remembering specific events : what , where , when , occurring in the working memory and thus available in the awareness ; procedural learning , namely learning new actions and action sequences needed for solving the problems set ; conscious learning relates to learning new , conscious behaviors or strengthening the existing conscious behaviors , which occurs when a given element of the situational model is often in the workspace . The four main types of LIDA agents run in CIMIS [ 14 ] in order to perform the text analysis process : • Document retrieval agents , • Information extraction agents , • Text analysis agents , • Summarization agents . Document retrieval agents search and retrieve , from the internet sources the documents according to users’ needs . Each agent running on the basis of different document retrieving method . Next , the information extraction agents extract only valuable information from documents ( for example the advertisements are removed from text document ) . Each agent implement different information extraction method . The text analysis agent perform a natural language processing ( deep analysis ) . Each agent running on the basis of different deep analysis method . On the basis of results of this analysis , the summaries of all the documents are generated by cognitive agents . The integration of summaries is performing by using a consensus method [ 17 ] , [ 18 ] . This agent determines a summary presented to user ( users ) . This paper presents issues related to information extraction agents ( the issues related to the others agents are presented in [ 5 ] ) . The role of these agents is to identify essential information in text documents . For example , if opinions of mobile telephone users are to be analyzed , only those pieces of texts which contain opinions ( advertisements are to be omitted ) need to be extracted from text documents ( saved in a database by documents searching agents ) . Each agent uses a different method of extracting information , for example : • determining tags of beginnings and ends of essential fragments of texts in a document - the method is mainly used in case of files saved in html / xml format ( for example , the series of characters " " / > < p > " is treated as the beginning of an opinion whereas the series of characters " < / p > " is treated as an end of an opinion ( the characters are determined on the basis of a learning set of text documents ) ; • identifying essential fragments of texts on the basis of sets of key words or rules - the method is used in case of any document formats ( for example an opinion about a phone may be identified on the basis of such key words as " make " , " model " , " recommended / not recommended " ) , • identification of essential fragments of texts using documents representations in the form of a semantic network - semantic networks are created on the basis of a learning set , the networks serve as patterns representing particular classes of information ( for example a semantic network representing a client ' s opinion on a given mobile phone ) , whereas in the process of IE a text document is saved also in the form of a semantic network , and then a cognitive agent searches for a given pattern in a semantic network representing a text document ( the degree of similarity is defines as a parameter ) . This method allows for including a context of extracted information . As an example of third method , a document retrieval agent has received a task to find in the Internet documents whose contents match the following question : „What to invest in nowadays ? ” . For further investigation , one of the following opinions has been selected . The opinion reads as follows : „ It will be safe to invest in gold , especially taking account today’s substantial variations of the currency market . Polish zloty is not a safe investment due to the observable high fluctuation of the currency market ” . On the basis of a learning set , in the perceptual memory of an information extraction agent a semantic network has been saved which , among other things , contains terms ( nodes ) and links connoted with the topic of investments , as well as a thesaurus matching the terms . Then , a sample opinion has been entered into the sensory memory of an agent , and a shallow analysis of the text has been performed . As a result of the analysis , for example , words such as „invest” , „investment” have been changed into „investment” , and the word „variation” into „fluctuation” ( tokenization ) . Also complex sentences have been divided into clauses ( for example : „It is safe to invest in gold , especially taking account today’s substantial variations of the currency market . ” has been divided into two clauses : „It is safe to invest in gold” and „especially taking account today’s substantial variations of the currency market” . In the next stage , codelets have saved the opinion in the form of a semantic network . Figure 1 shows the section of the network matching the clause „It is safe to invest in gold” . Fig . 1 . The semantic network representing the sequence “It is safe to invest in gold” . It can be observed that the network has been enriched with the meaning of „gold” – it has been stressed that it refers to an „ore” . In Polish the word “zloty” mean both the golden and the Polish currency . The sentence : „Polish zloty is not a safe investment due to the observable high fluctuation of the currency market” on the other hand is represented in a way shown in Figure 2 ( it is a complex sentence , so it has not been broken up into two clauses ) . Fig . 2 . The semantic network representing the sequence “Polish zloty is not a safe investment due to the observable high fluctuation of the currency market” . It can be noted that in the sentence , the word „Polish zloty” has been replaced with the symbol of the currency , i . e . „PLN” . Moreover , the network has been enriched with the meaning of the word „Polish zloty” ( ”PLN” ) – it has been specified that it refers to a „currency” . Results of agents ' operations are saved ( as a patterns ) in agent’s episodic memory and in a database in a textual form . In order to searching for a given pattern in a semantic network representing another text document , the similarity detection attentional codelets , provided by LIDA Framework ( in Java ) , are used . It is enough only to make the configuration of these codelets ( example is presented on Figure 3 ) to run them . < task name = " Investment _ opinion1 " > < tasktype > CodeletObjectsComparator < / tasktype > < param name = " nodes " type = " String " > Investment , Gold , Safe , Ore < / param > < param name = " links " type = " String " > Investment : Safe , Investment : Gold , Gold : Ore < / param > < param name = " s _ level " type = " int " > 0 . 75 < / param > < / task > Fig . 3 . The example of similarity detection codelet . The codelet configured in this way perform extraction the opinions similar to the opinion “It is safe to invest in gold” , if they similarity level is 0 . 75 ( the colons denote the links ) . The agent based approach for information extraction is proposed mainly due to cognitive agents’ ability to analyse the meaning of the phenomena occurring in the environment , the possibility to automatically make the decisions by agents on the basis of results the information extraction and their ability to learn on the basis of an experience . These advantages may lead to higher efficiency of information extraction , in consequence . Very important advantage of using cognitive agents is also possibility to implementation different information extraction methods using a consistent , unified architecture . The main disadvantages of the proposed agent based approach is the complexity of a process of conversion the text document into semantic network , and also the LIDA framework’s high hardware requirements . The next part of paper presents a research experiment carried out in order to verify presented IE methods . IV . E XPERIMENT In order to verify information extraction methods using the cognitive agent , a research experiment has been carried out , in which results of automatic extraction were compared with results of an extraction performed by a human , i . e . a manual extraction . The following assumptions were adopted in the experiment : 1 . The extraction concerned documents , whose contents match the following question : “What to invest in nowadays ? ” Number of analyzed opinions : 300 . The limitation is connected with the fact that with respect to each single document , a manual extraction had to be performed , which is a time consuming procedure . The documents were in Polish language ( in this paper they were translated into English ) , because the CIMIS is developed in order to support the business processes mainly in Polish companies ( it does not preclude use of CIMIS in the future in relation to companies from other countries ) . Text documents’ analysis is highly dependent on the language . 2 . Because a lot of retrieved opinions concerned also question : “What not to invest in ? ” , the following assumption was made : if opinion is an answer the question : “What to invest in ? ” then it is relevant opinion , if opinion is an answer the question : “What not to invest in ? ” then it is not relevant opinion . 3 . A method of learning with a teacher was employed . On the basis of a learning set consisting of 75 opinions a configuration of codelet of extraction was performed . 4 . In order to determine the accuracy of results of automatic extraction in relation to results of manual extraction , the following measurements were performed : • effectiveness – this measure defines the relationship of the number of opinions whose has been extracted automatically to the number of opinions has been extracted manually ; this measure enables one to determine in how many cases the opinions has not been extracted by an agent ( an agent has not specified whether a phrase is an opinion ) ; the next used measures relate only to opinions effectively extracted by an agent , • precision – which specifies the accuracy of classification within a recognized class of opinions and it is defined in the following way onr orr orr p + = ( 1 ) where : p – precision , orr – relevant opinions extracted as relevant ones , onr – not relevant opinions extracted as relevant ones . • sensitivity – the relationship of the number of opinions recognized by an agent as relevant ones against all relevant opinions is defined in the following way : orn orr orr c + = ( 2 ) where : c - sensitivity , orr – relevant opinions extracted as relevant ones , orn – relevant opinions extracted as not - relevant ones . All the presented measures have values ranging from 0 to 1 . Research experiment was carried out in the following way : 1 . A document retrieval agents have received a task to find in the Internet documents whose contents match the following question : “What to invest in nowadays ? ” 2 . Manual extraction of 300 first opinions was performed ( notes on the opinions ) . 3 . Then , a learning set was created which contained 75 randomly selected opinions on the basis of which parameterization of codelets was made ( learning with a teacher ) . 4 . The next step involved loading , one by one , text documents containing remained 225 opinions ( the test set ) into the sensory memory , having them extracted by an agent , and saving results of the extraction in a database . 5 . The last step involved calculation of measures of effectiveness , precision and sensitivity of automatic analysis results taking into consideration particular three extraction methods ( table I ) . Method 1 refer to determining tags of beginnings and ends of essential fragments of texts in a document , Method 2 refer to identifying essential fragments of texts on the basis of sets of key words or rules and Method 3 refer to identification of essential fragments of texts using documents representations in the form of a semantic network . TABLE I . R ESULTS OF THE EXPERIMENTS Measure Method 1 Method 2 Method 3 Effectiveness 0 , 356 0 , 964 0 , 924 Precision 0 , 325 0 , 880 0 , 949 Sensitivity 1 , 000 0 , 771 0 , 855 Generalizing results of an information extraction performed by a cognitive agent , it can be said that the used methods of are characterized by different levels of effectiveness . The low effectiveness of Method 1 ( involving determining tags of the beginning and end of essential sections of a text in a document ) results from the fact that the test set contained also documents ( websites ) which were absent in the learning set ( 80 opinions has been extracted and only 26 was an answer to the question ) . The retrieved documents contained tags of beginnings and ends of opinions which were not included in the agent’s knowledge base . Consequently , extraction of opinions from these documents could not be performed . Since Method 1 allows only for extraction of opinions without analyzing their contents it is impossible to say which of the opinions concern the question „ What to invest in ? ” and which concern the question „What not to invest in ? ” . Therefore it has been assumed that all opinions defined using Method 1 answer the question „What to invest in ? ” which is why the measure of sensitivity is 1 . However , taking into account results obtained with the use of Method 2 , it may be said that they are characterized by the highest level of effectiveness among the analyzed methods ( 217 opinions has been extracted ) . It results mainly from the fact that opinions found in the test set have been characterized by key words similar to the ones found in opinions in the learning set . The measure of precision and sensitivity is lower , however , than in case of Method 3 mainly because Method 2 does not include the context of opinions . Taking into account Method 3 ( 208 opinions has been extracted ) , it can be said that its effectiveness is lower that effectiveness of Method 2 , which results mainly from the fact that the level of similarity ( as a parameter of codelets ) has been set to 75 % . There were however opinions with the level of similarity slightly lower than 75 % which ( according to manual annotation ) should have been treated as essential opinions ( ones that meet set criteria ) . Method 3 , however , allowed to achieve a higher level of precision and sensitivity since it included the context of opinions . Comparing the proposed approach to another ones ( presented in the section II of this paper ) it can be state , that the values of effectiveness , precision and sensitivity measures are very often similar to each other . However , the proposed approach allows for reduce human intervention in the IE process ( like in case the hybrid methods ) and also it allows for automatically decision making on the basis of IE process results . V . C ONCLUSIONS AND FUTURE WORK Nowadays , integrated management information systems , apart from processing structured knowledge , also have to enable processing unstructured knowledge , which very often constitutes the basis for taking decisions . Opinions of users or experts , which can be found online , serve as an example of this type of knowledge . On the basis of analysis of the experts’ opinions , decision - makers are capable of taking decisions ( for example decisions concerning investments ) . In order to extract this kind of information we can use cognitive agent programs . Contrary to other tools , on the basis of analysis , they can automatically take decisions and put them into practice ( for example decide to invest in gold , and stop investing in currencies ) . Results of the research experiment carried out in the article with the use of a prototype of CIMIS system allow for drawing a conclusion that a cognitive agent is capable of properly extracting information using a method which involves identification of essential sections of texts on the basis of a set of key words or rules , and a method which involves identification of essential sections of texts using representations of documents in the form of a semantic network . However , the method involving determining marks of beginnings and ends of essential sections of texts in a document cannot be used in the decision - making process , as it is characterized by a low level of effectiveness . It is also necessary to conduct further research aimed at developing a method involving identification of essential sections of a text using representations of documents in the form of a semantic network with nodes’ and links’ activation level ( “slipnet” [ 15 ] ) . This method can allow for take into consideration the probability level of associations between the nodes . The research may involve making changes in the algorithm of codelets’ functioning as well as their configuration . Research concerning implementation into the structure of the LIDA cognitive agent methods of carrying out deep text analysis and procedures for automatically decision making are also underway . R EFERENCES . [ 1 ] W . Abramowicz , E . Bukowska , and A . Filipowska , „Providing security by using Web monitoring systems” , „Zapewnienie bezpiecze ń stwa przez semantyczne monitorowanie cyberprzestrzeni” , e - mentor nr 3 ( 50 ) / 2013 . [ 2 ] W . T . Balke , “Introduction to Information Extraction : Basic Notions and Current Trends” , Datenbank - Spektrum , Vol . 12 , Issue 2 , Springer - Verlag , 2012 , pp . 81 – 88 . [ 3 ] M . Banko , M . Cafarella , S . Soderland , M . Broadhead , and O . Etzioni , “Open information extraction from the web” , in Proc of international joint conference on artificial intelligence ( IJCAI ) , Hyderabad , India , 2007 . [ 4 ] R . Bekkerman , and A . McCallum , “Disambiguating web appearances of people in a social network” , in Proc of international conference on World Wide Web ( WWW ) , Chiba , Japan , 2005 . [ 5 ] A . Bytniewski , and M . Hernes , „Using a cognitive agents in integrated management information system” , „Wykorzystanie agentów kognitywnych w budowie zintegrowanego systemu informatycznego zarz ą dzania” , in Por ę bska - Mi ą c T . , Sroka H . ( eds . ) Systemy wspomagania organizacji , Wydawnictwo UE w Katowicach , Katowice 2013 . [ 6 ] A . Carlson , J . Betteridge , and R . C . Wang , “Coupled semi - supervised learning for information extraction” , WSDM’10 , February 4 – 6 , New York , USA , 2010 . [ 7 ] S . Chaudhuri , V . Ganti , and D . Xin , “Mining document collections to facilitate accurate approximate entity matching” , in : Proc of international conference on very large data bases ( VLDB ) , Lyon , France . PVLDB , vol 2 ( 1 ) , 2009 . [ 8 ] P Cimiano , S . Handschuh and S . Staab , “Towards the selfannotating web” , in Proc of international conference on World Wide Web ( WWW ) , New York , NY , USA , 2004 . [ 9 ] Cognitive Computing Research Group , http : / / ccrg . cs . memphis . edu / , [ 29 . 10 . 2014 ] . [ 10 ] H . Duan , and Y . Zheng , “A study on features of the CRFs - based Chinese named entity recognition” , Int . J . Adv . Intell . 3 ( 2 ) : 287 – 294 , 2011 . [ 11 ] X . Dong , A . Halevy , and J . Madhavan , “Reference reconciliation in complex information spaces” , in : Proc of ACM international conference on management of data , Baltimore , MD , USA , 2005 . [ 12 ] O . Etzioni , M . Cafarella , D . Downey , A - M . Popescu , T . Shaked , S . Soderland , D . Weld , and A . Yates , “Unsupervised named - entity extraction from the web : An experimental study” , Artif . Intell . 165 ( 1 ) : 1 – 42 , 2005 . [ 13 ] J . Hassell , B . Aleman - Meza , and I . B . Arpinar , “Ontology - driven automatic entity disambiguation in unstructured text” in Proc of international semantic web conference , Athens , GA , USA , 2006 . [ 14 ] M . Hernes , “A Cognitive Integrated Management Support System for enterprises” , in : D . Hwang , J . Jung , N . T . Nguyen ( eds . ) , Computational Collective Intelligence Technologies and Applications , Lecture Notes in Artificial Intelligence , vol . 8733 , Springer - Verlag , 2014 , pp . 252 - 261 . [ 15 ] D . R . Hofstadter , and M . Mitchell , M . , “The copycat project : A model of mental fluidity and analogy - making” . in : Hofstadter D . and the Fluid Analogies Research group , Fluid Concepts and Creative Analogies . Basic Books . Chapter 5 , 1995 . [ 16 ] M . Konchady , “Text mining application programming” , Cengage Learning India Private Ltd . , 2009 . [ 17 ] M . Maleszka , and N . T . Nguyen , “Integration computing and collective intelligence” , Expert Systems with Applications , 2015 , vol . 42 ( 1 ) , 2015 , pp . 358 - 378 . [ 18 ] N . T . Nguyen , Advanced Methods for Inconsistent Knowledge Management , Springer - Verlag London , 2008 . [ 19 ] P . Potiopa , “Methods and tools for the automatic processing of textual information and its use in the process of knowledge management” , “Metody i narz ę dzia automatycznego przetwarzania informacji tekstowej i ich wykorzystanie w procesie zarz ą dzania wiedz ą ” , Automatyka 15 / 2 ( 2011 ) s . 409 - 419 . [ 20 ] F . Sebastiani , “Machine learning in automated text categorization” , ACM Computing Surveys ( CSUR ) . , vol . 34 ( 1 ) , New York 2002 . [ 21 ] J . Snaider , R . McCall , and S . Franklin , “The LIDA Framework as a General Tool for AGI” , in Proceedings of the 4th international conference on Artificial general intelligence ( AGI ' 11 ) , Jürgen Schmidhuber , Kristinn R . Thórisson , and Moshe Looks ( Eds . ) . Springer - Verlag , Berlin , Heidelberg , 2011 , pp . 133 - 142 . [ 22 ] E . Stoica , M . Hearst , and M . Richardson , “Automating creation of hierarchical faceted metadata structures” , in : Proc of human language technology conference of the association of computational linguistics , Rochester , NY , USA , 2007 . [ 23 ] R . Tadeusiewicz , „Cognitive systems – a new dimension of economic informatics” , “Systemy kognitywne – nowy wymiar informatyki ekonomicznej” , http : / / ryszardtadeusiewicz . natemat . pl / 75001 , systemy - kognitywne - nowy - wymiar - informatyki - ekonomicznej [ 29 . 12 . 2013 ] . [ 24 ] S . L . Tomassen , “Semi - automatic generation of ontologies for knowledge - intensive CBR” , Norwegian University of Science and Technology , 2002 . [ 25 ] R . E . Vlas , and W . N . Robinson , “Two rule - based natural language strategies for requirements discovery and classification in open source software development projects” , Journal of Management Information Systems , vol . 28 ( 4 ) , 2012 . [ 26 ] A . Wawer , “Mining opinion attributes from texts using multiple kernel learning” , IEEE 11th International Conference on Data Mining Workshops , 2011 . [ 27 ] C . Zhang , X . Zhang , W . Jiang , Q . Shen , and S . Zhang , ” Rule - based extraction of spatial relations in natural language text” , International Conference on Computational Intelligence and Software Engineering , 2009 .