Neuron NeuroView Architecting Discovery : A Model for How Engineers Can Help Invent Tools for Neuroscience Edward S . Boyden 1 , 2 , 3 , 4 , 5 , 6 , * and Adam H . Marblestone 1 , * 1 MIT Media Lab , Massachusetts Institute of Technology , Cambridge , MA 02139 , USA 2 McGovern Institute , Massachusetts Institute of Technology , Cambridge , MA 02139 , USA 3 Department of Brain and Cognitive Sciences , Massachusetts Institute of Technology , Cambridge , MA 02139 , USA 4 Department of Biological Engineering , Massachusetts Institute of Technology , Cambridge , MA 02139 , USA 5 Koch Institute , Massachusetts Institute of Technology , Cambridge , MA 02139 , USA 6 Lead Contact * Correspondence : esb @ media . mit . edu ( E . S . B . ) , amarbles @ media . mit . edu ( A . H . M . ) https : / / doi . org / 10 . 1016 / j . neuron . 2019 . 03 . 023 How can engineers help invent tools for neuroscience ? We here explore a model for how engineers can choose problems and map out possible technologies that help address them . We also discuss design principles of tools and the role of failure . Twentieth - century scientiﬁc research yielded many foundational discoveries that resulted in inventions such as com - puters and wireless communication . It was a productive century . Why ? One fac - tor may be that these successes were rooted in relatively mature sciences such as physics and chemistry . For example , in physics , there are a small number of building blocks—such as protons and electrons—and a small number of ways they interact—through the laws of quan - tum mechanics and special relativity . In chemistry , there is a fairly short list of kinds of atoms , enumerated in the peri - odic table . In contrast , some of the sci - ences we struggle with in the twenty - ﬁrst century , like neuroscience , involve many building blocks , which interact in many different ways . For example , consider the many different kinds of brain cell , the number of which is unknown even for the normal human brain , much less in the diversity of neurological and psychiat - ric conditions . It should be no surprise that we struggle to explain how the brain computes . In addition , treatments for brain diseases remain relatively few ; brain drugs cost perhaps $ 1 billion each for clinical development , taking a decade for clinical approval , and even those that make it to human trials fail 90 % of the time to be approved for human use ( Miller , 2010 ) . Because of the brain’s complexity , it shouldn’t be surprising that many of our hypotheses about the mechanisms un - derlying biological functions , or about intervention targets for diseases , end up proven wrong . How should engineers think about building tools that help confront neurosci - ence challenges today ? One metaphor that is sometimes used nowadays is the ‘‘moonshot . ’’ The actual Apollo program was based on solid physics knowledge . It was a tour - de - force engineering and management challenge , no doubt , but the number of foundational scientiﬁc un - knowns was small by 1962 ( for example , rockets had already taken humans into outer space ) . But imagine trying to land on the moon in the year 1600—before we understood calculus , mechanics , and aerodynamics . All the money on the planet , in the year 1600 , might not have gotten you to the moon . For some neuro - science challenges , we may be , meta - phorically speaking , closer to the year 1600 than 1960 . This doesn’t mean that systematic , concerted , and organized ef - forts can’t work in neuroscience , but it means that we have to choose the targets for those efforts correctly . Another concept that sometimes arises is ‘‘big data . ’’ Sheer quantity , of course , is not enough ; data ideally would be sufﬁciently precise , and have the right spatial and / or temporal resolution , to pinpoint funda - mental building blocks and how they interact . For example , brain mapping technologies that can reveal synaptic connections may help scientists answer questions that are not amenable to ana - lyses with lower - resolution methods . Thus , one powerful way of approaching problems of neuroscience is to try to un - derstand complex systems in terms of their underlying building blocks and inter - actions , as in ﬁelds like physics and chemistry before : to understand networks and circuits in terms of cells , and cells in terms of their component biomolecules . From these maps of the building blocks and interactions , we might be able to devise new hypotheses in a more system - atic way . In short , getting to the ground truth , which we deﬁne for the purposes of this essay as a level of precision of anal - ysis that allows building blocks and their fundamental interactions to be directly understood , can be worth it . Some brain diseases have been con - fronted successfully , sometimes through highly unexpected means . Julius Wag - ner - Jauregg , who won the Nobel Prize in 1927 , took patients with dementia paraly - tica , associated with late - stage syphilis , and inoculated them with malaria . Malaria caused a high fever that would kill the bacterium that causes syphilis . Of course , malaria sometimes killed the patient , too . One year later , antibiotics were discov - ered . Antibiotics directly confront the bac - terium , with fewer side effects . Of course , treating most brain diseases is far more complex than ﬁghting a single pathogen that can be selectively killed by a drug . Brain diseases often involve subtle changes in different brain cell types , over long periods of time . This might make it even more important , for many brain diseases , to acquire maps of the building blocks and their interactions . In general , there is a lack of technology for seeing and perturbing complex biolog - ical systems , including the brain , with suf - ﬁcient precision . Building tools that can Neuron 102 , May 8 , 2019 ª 2019 Elsevier Inc . 523 get down to ground - truth levels of description is hard to do . In neuroscience , however , there isn’t universal agreement about what the ground - truth level of description is—do we need to map indi - vidual biomolecules , or synapses , or cell types , before we can devise truly powerful explanations ? And if we assume a certain level to be ground truth and try to scale up the relevant technologies to map the brain at that level of description , what if we are wrong ( Marblestone and Boyden , 2014 ) ? Nevertheless , hope emerges from exam - ples like the crab stomatogastric gan - glion , where the ability to record from every cell , to map the connectivity be - tween them , and to derive molecular pro - ﬁles of the component cells , has yielded many fundamental insights into neural computation ( Prinz et al . , 2004 ; Schulz et al . , 2006 ) , suggesting that integrative observations of the activity , wiring , and molecular composition of neurons throughout entire neural circuits may be useful . Another reason building tools in neuro - science is hard is that technology inven - tors in neuroscience must often think backward from biological problems to design relevant tools . For example , one class of biological problem is to under - stand what kinds of behaviors or patho - logical states a set of neurons can , through their electrical activity , initiate or sustain . Optogenetic tools ( Boyden , 2011 ) enable the control of the electrical activity of speciﬁc cells with light and thus are useful for causally investigating the contribution of speciﬁc cells to a behavior or pathological state . However , the question of what a ground - truth level of precision is sometimes arises . As one example , some studies using optoge - netics treat electrical potentials in neu - rons as an abstraction layer , ignoring the underlying ion chemistries associated with the electrical pulses . But in some cases , this assumption breaks down— for example , light - activated chloride and proton pumps , and light - activated chlo - ride channels , can be used to silence neuronal electrical activity , but in each of these cases , the ions translocated during optogenetic silencing can sometimes affect synaptic communication ( Mahn et al . , 2016 ; Raimondo et al . , 2012 ) . Making a powerful , easy - to - use tech - nology sometimes requires serendipity . But in contrast to the expensive , slow luck required to develop a drug , the kind of luck needed here may , in principle , be made far cheaper and faster to obtain . For example , inventing a new technology sometimes requires you to stumble across the right reagent , such as with the aforementioned optogenetic tools or as with early characterizations of CRISPR by scientists interested in producing bet - ter yogurt ( Barrangou et al . , 2007 ) . What if we could invent new tools by searching for such reagents systematically , in various ecological niches , in a high - throughput way ? Innovation sometimes requires you to connect the dots across ﬁelds , as in the case of next - gen nucleic acid sequencing , where a combination of biological , chemical , and optical ideas were fused into an impactful technology . What if we could invent new tools by con - necting such dots in a highly scalable , deliberate way ? In our group at MIT , and with our collaborators , we are beginning to explore whether one might develop a discipline around the effective develop - ment of new tools , which one might call ‘‘architecting discovery . ’’ This discipline may be a learnable , teachable skill . Although these are early days , and much is in ﬂux , architecting discovery may involve , at its core , asking at least three kinds of question , listed below . The ﬁrst question is : how do we pick the class of problem that the tool will solve or the space of hypotheses it will allow users to probe ? One strategy is to look at exam - ples of speciﬁc hypotheses that re - searchers would like to test and then look for common intellectual structure to these hypotheses , so that a single new tool might help many groups solve prob - lems in parallel . As noted above , for example , optogenetics enables scientists to confront questions asking whether a speciﬁc cell type or neural pathway is causally involved in a behavior or patho - logical state . For expansion microscopy ( Wassie et al . , 2019 ) , the general class of questions we considered was , could we analyze a neural circuit in terms of its component cells and biomolecules , imag - ing across scales ? A corollary of this principle is , when you are inventing a new tool , don’t only take individual requests from other scientists . It can helpful to consider multiple scienti - ﬁc problems , or multiple hypotheses , and to then try to devise a technology that would help many groups confront many members of this entire set of problems or hypotheses . Is there an underlying , fundamental capability that is missing ? Then , think backward from this set of problems , ideally surveying multiple ﬁelds of science and engineering for potential solutions . Perhaps you will run out of skills or knowledge , which is okay ; if you have a concrete visualization of the class of problem , that can help you ﬁnd and moti - vate collaborators with appropriate solu - tion - domain knowledge . The second question is , how well can you envision or roadmap out the possible solutions so that you can pick the best one possible ? One trick is to look at what people are doing , and then imagine what it would mean to do the most oppo - site thing you can think of . This is obvi - ously just a heuristic , but sometimes it can help . For example , for expansion mi - croscopy , if everyone else is zooming in to see a biological system better , what happens if we blow up the biological sys - tem ( in an even way , of course ) , instead ? Another strategy is to map the landscape of currently practiced and conceived ac - tivities in an area , work to understand the fundamental limits for each one , and then ask why current approaches fall short of these fundamental limits ; perhaps a stalled approach can be rebooted , if we understand its bottlenecks and can ﬁnd a way to work around them by bringing in ideas from another domain . Carrying out such a process of identifying ideas that can be rebooted requires good ways to search the space of scientiﬁc approaches and papers , and potentially is assisted by being able to work in rapid communica - tion with a large collaborative network with diverse expertise . Many ideas are hiding in plain sight , perhaps in a partly failed or misunderstood state that ob - scures their true value . Maybe a new sci - entiﬁc journal , that republishes old and forgotten results , or obscure - seeming methods , would therefore be a useful thing to read ? Sometimes the knowledge underlying a major scientiﬁc tool discov - ery is present , but the wisdom to know that the knowledge is important is not yet present . More rigorously , you could try to split the set of possible candidate solu - tions to a problem into subsets that are Neuron NeuroView 524 Neuron 102 , May 8 , 2019 non - overlapping but that collectively tile the space of possibility . The idea is to iter - atively split the space of possibilities into two ( or more ) subsets , over and over— for example , split the set of possible solu - tions into one set with property A and one set that does not have property A . For example , you could take the space of all possible energy sources and split the set into two subcategories—renewable sour - ces and non - renewable sources . Then you could split the renewables into two subsets—solar and non - solar . And already the act of splitting is forcing us to think of new ideas . What are the non - solar renewable energy sources , for example ? Could we take advantage of tides , caused by the moon ? The outcome of this exercise is a diagram that looks like a tree , with the forking branches repre - senting different subsets of ideas , and the leaves of the tree representing poten - tial projects that could be tested via calcu - lations or via pilot studies ( because of this shape , we sometimes call this method making ‘‘tiling trees’’ in our group ) . Thinking like this helped Fritz Zwicky , an astrophysicist , to predict—in the early part of the twentieth century—many phe - nomena that are now being explored in astrophysics today , like dark matter and gravitational lenses . In the earliest days of optogenetics , we arrived at the core idea by going through the laws of physics systematically and thinking about what forms of energy ( me - chanical , magnetic , optical , etc . ) could be delivered to the brain and used to control neurons . In parallel , we thought about what molecular strategies could be used to make speciﬁc sets of neuron sensitive to those forms of energy ( nanoparticles , magnetic beads , light - activated proteins , etc . ) . Then , serendipitously , it turned out that the natural world had evolved a class of protein that , we found , contained mem - bers that worked to make genetically tar - geted brain cells sensitive to light . The third question is , once you have chosen a problem and have a roadmap of the space of possible solutions , how do you choose which path is the best ? In neuroscience , or other complex ﬁelds which involve lots of building blocks and interactions , one useful heuristic is a prin - ciple that you might call ‘‘the principle of applied laziness . ’’ In messy systems , like biological ones , the technologies that work really well will sometimes be very simple . Optogenetics , for example , involved essentially single genes encod - ing for microbial opsins . Some of this simplicity is serendipitous , of course— for example , in optogenetics , the fact that mammalian neurons had sufﬁcient endogenous levels of all - trans - retinal , the chemical co - factor required for micro - bial opsin function , was not predictable in advance , but had to be discovered by trying it out ( Boyden et al . , 2005 ) . For a tool to be simple , there is sometimes an element of discovery involved . Had opto - genetics required chemical co - factors to be administered into the living mamma - lian brain before optical illumination , this would have made many neuroscience ex - periments more complex and potentially less robust . It would also have made the tool harder to disseminate . Note well , the fact that an innovation in its ﬁnal form may be simple does not mean that the path to inventing it or realizing it is al - ways simple . But if in the early stages of a project we aim for ‘‘constructive fail - ures’’—failures that teach us something new , perhaps because they show us something that has never been seen before—they may show us a better path to a truly impactful solution , orthogonal to what everyone else is doing . From such wisdom , one can then sometimes move on to a simple , powerful design , avoiding the complex in favor of the sim - ple , precise , and / or robust . Sometimes there is a tension in biomedicine : do we pursue basic science for curiosity’s sake , or do we focus on translational work ? Of course , both basic science and translation are important . One way to connect the two is to consider a third path : what if we could accelerate our understanding of the basic science , via new technology , so that we could reduce the risk of translational work and magnify the impact of the latter ? To return to the moonshot analogy : suppose it’s the year 1600 . If someone were to pro - pose to land on the moon back then , would it have been possible for scientists to resist the temptation to just go for it , and instead to take a step back and accel - erate the invention of calculus , work out the laws of mechanics , and begin experi - ments on aerodynamics ? In the end , of course , the necessary progress occurred , but over a period of centuries . Is there a way of approaching the problem that would have accelerated this progress , achieving deliberately what the history of science has suggested was achieved by happenstance ? Considering the path of science and the events , structures , and ways of thinking that drive scientiﬁc revo - lutions is beyond the scope of this essay . But perhaps the perspectives contained within provide a model for how , in neuro - science , we might think about ways to take a step back to reduce the risk of , and accelerate , our path . ACKNOWLEDGMENTS E . S . B . was funded by John Doerr , Open Philan - thropy , the HHMI - Simons Faculty Scholars Award , and the NIH Director’s Pioneer Award . We thank John Doerr , Jini Kim , Tom Kalil , Patrick Collison , Michael Nielsen , Laura Deming , Joi Ito , Tom Ska - lak , and Clara Wu Tsai for feedback on the ideas here contained . REFERENCES Barrangou , R . , Fremaux , C . , Deveau , H . , Richards , M . , Boyaval , P . , Moineau , S . , Romero , D . A . , and Horvath , P . ( 2007 ) . CRISPR provides acquired resistance against viruses in prokaryotes . Science 315 , 1709 – 1712 . Boyden , E . S . ( 2011 ) . A history of optogenetics : the development of tools for controlling brain circuits with light . F1000 Biol . Rep . 3 , 11 . Boyden , E . S . , Zhang , F . , Bamberg , E . , Nagel , G . , and Deisseroth , K . ( 2005 ) . Millisecond - timescale , genetically targeted optical control of neural activ - ity . Nat . Neurosci . 8 , 1263 – 1268 . Mahn , M . , Prigge , M . , Ron , S . , Levy , R . , andYizhar , O . ( 2016 ) . Biophysical constraints of optogenetic inhibition at presynaptic terminals . Nat . Neurosci . 19 , 554 – 556 . Marblestone , A . H . , and Boyden , E . S . ( 2014 ) . Designing tools for assumption - proof brain map - ping . Neuron 83 , 1239 – 1241 . Miller , G . ( 2010 ) . Is pharma running out of brainy ideas ? Science 329 , 502 – 504 . Prinz , A . A . , Bucher , D . , and Marder , E . ( 2004 ) . Similar network activity from disparate circuit pa - rameters . Nat . Neurosci . 7 , 1345 – 1352 . Raimondo , J . V . , Kay , L . , Ellender , T . J . , and Akerman , C . J . ( 2012 ) . Optogenetic silencing stra - tegies differ in their effects on inhibitory synaptic transmission . Nat . Neurosci . 15 , 1102 – 1104 . Schulz , D . J . , Goaillard , J . M . , andMarder , E . ( 2006 ) . Variablechannelexpressioninidentiﬁedsingleandelectricallycoupledneuronsindifferentanimals . Nat . Neurosci . 9 , 356 – 362 . Wassie , A . T . , Zhao , Y . , and Boyden , E . S . ( 2019 ) . Expansion microscopy : principles and uses in biological research . Nat . Methods 16 , 33 – 41 . Published online December 20 , 2018 . Neuron NeuroView Neuron 102 , May 8 , 2019 525