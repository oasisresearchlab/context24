A Survey on Large Language Model Hallucination via a Creativity Perspective Xuhui Jiang 1 , 2 , 3 , Yuxing Tian 3 Fengrui Hua 3 Chengjin Xu 3 Yuanzhuo Wang 1 Jian Guo 3 1 CAS Key Laboratory of AI Safety & Security , Institute of Computing Technology , CAS 2 School of Computer Science and Technology , University of Chinese Academy of Science 3 International Digital Economy Academy , IDEA Research { jiangxuhui19g , wangyuanzhuo } @ ict . ac . cn , { tianyuxing , huafengrui , xuchengjin , guojian } @ idea . edu . cn Abstract Hallucinations in large language models ( LLMs ) are always seen as limitations . However , could they also be a source of creativity ? This survey explores this possibility , suggesting that hallucinations may contribute to LLM application by fostering creativ - ity . This survey begins with a review of the tax - onomy of hallucinations and their negative impact on LLM reliability in critical applications . Then , through historical examples and recent relevant the - ories , the survey explores the potential creative ben - efits of hallucinations in LLMs . To elucidate the value and evaluation criteria of this connection , we delve into the definitions and assessment methods of creativity . Following the framework of divergent and convergent thinking phases , the survey system - atically reviews the literature on transforming and harnessing hallucinations for creativity in LLMs . Finally , the survey discusses future research direc - tions , emphasizing the need to further explore and refine the application of hallucinations in creative processes within LLMs . 1 Introduction Recent advancements in artificial intelligence have propelled large language models ( LLMs ) into the spotlight , marking a significant leap in their ability to comprehend and gen - erate natural language . This surge in progress has sparked a global wave of research and practical applications , high - lighting the transformative impact of LLMs across various domains . Among these advancements , the phenomenon of hallucination within LLMs has emerged as a focal point of investigation . Characterized by the models’ tendency to pro - duce unfounded or misleading information without solid data backing , hallucination poses a challenge to the reliability and applicability of LLMs [ Ye et al . , 2023 ] . Despite the increas - ing volume of research , the comprehensive understanding of hallucination for LLMs remains to be explored . This study begins by outlining the taxonomies of hallucina - tions in LLMs , setting the stage for an in - depth review of key research efforts aimed at identifying and reducing these oc - currences . It highlights how existing literature predominantly views hallucinations as detrimental , advocating for strategies to minimize their presence , particularly in serious application scenarios like legal and financial . However , a key question raises and provokes deep reflec - tion : “ Is hallucination in LLMs always harmful , or does cre - ativity hide in hallucinations ? ” Different from previous sur - veys or studies about hallucination , this paper revisits the phe - nomenon from a positive perspective . In addition to the neg - ative impacts of hallucination on the reliability of LLMs , this paper recognizes a trend in research on the creativity of LLMs and explores the interplay between hallucination and creativ - ity , as well as how to unearth the value of LLM hallucination from the perspective of creativity . In our exploration of the interplay between LLMs’ hallu - cinations and creativity , we scrutinize notable historical ex - amples where hallucinations have catalyzed creative break - throughs . By examining these instances , we aim to uncover the complex dynamics between human creativity and halluci - nation , drawing insights from cognitive science underpinned by pertinent scholarly work . Furthermore , this paper reviews recent studies that focus on this specific interplay in the realm of LLMs , underscoring this critical interplay . This analysis lays the groundwork for a deeper comprehension of the sym - biotic relationship between hallucination and creativity . Recognizing this interplay , this paper delves into evaluat - ing its significance and value . We begin by examining the concept and evaluation of creativity through the lens of cog - nitive science , followed by a thorough review of the studies on LLM creativity , to understand its critical role and poten - tial . This discussion leads to the assertion : ” While minimizing hallucination risks , it’s vital to assess and harness its creative potential , maximizing the value of LLM hallucinations . ” To achieve the transformation from hallucination to cre - ativity , this paper follows the divergent and convergent phases of cognitive science to systematically review the literature on harnessing hallucination in LLMs for creativity . Specifically , we thoroughly explore the divergent phase , focusing on the methods and research that enhance LLMs’ ability to gener - ate creative hallucinations . Subsequently , we delve into the convergent phase , examining how these hallucinations can be critically assessed and refined into valuable creative outputs . Through this bifocal approach , the study highlights practi - cal implications and potential future directions in leveraging LLM hallucinations for creative endeavors . In conclusion , this paper casts an eye toward the horizon a r X i v : 2402 . 06647v1 [ c s . A I ] 2 F e b 2024 Figure 1 : General framework of the survey . of future research , contemplating strategies to broaden and deepen the exploration of the interplay between hallucination and creativity within LLMs . The rest of this paper is organized as shown in Figure 1 . Section 2 reviews existing LLM hallucination research . Sec - tion 3 questions the negativity of hallucinations and explores their interplay with creativity . Section 4 covers the defini - tion and assessment of creativity in LLMs . Section 5 looks at harnessing the interplay between hallucination and creativity . Finally , Section 6 outlines future directions for this field . 2 Hallucination in the Era of LLM The advent of LLMs like ChatGPT and LLaMA [ Touvron et al . , 2023 ] marks a significant milestone in the field of AI . These models , trained on vast datasets , have demonstrated re - markable proficiency in generating coherent text and opening new frontiers in AI - assisted writing , conversation , and con - tent creation . Their versatility and efficiency have made them indispensable in both academic research and commercial ap - plications . However , the ascendancy of LLMs brings with it a complex challenge : the phenomenon of ’hallucination’ , where models confidently generate incorrect or irrelevant in - formation . This often stems from issues like erroneous in - formation in the training data or the problematic alignment process [ Zhang et al . , 2023b ] . As LLMs are increasingly ap - plied in various aspects of our lives , comprehensively under - standing , detecting , and mitigating hallucinations has become crucial , serving not only as a focal point in academic research but also as a key prerequisite for the reliable deployment of these powerful AI systems . 2 . 1 Hallucination Taxonomy In dissecting the phenomenon of hallucinations within LLMs , it is crucial to categorize these instances for targeted and ef - fective resolutions . A widely accepted classification method [ Ye et al . , 2023 ] identifies two main types of hallucinations : factuality hallucinations and faithfulness hallucinations . Fac - tuality hallucinations encompass instances where the content generated by LLMs diverges from verifiable real - world facts . This category manifests in two primary forms . The first is factual inconsistency , where the model’s output directly con - tradicts known real - world information . The second form is factual fabrication , characterized by the generation of con - tent that has no basis in reality and cannot be substantiated with factual data . On the other hand , faithfulness hallucina - tions occur when the content produced by LLMs does not align with the user’s instructions or the context they have previously generated . This category includes three distinct phenomena . Instruction inconsistency is observed when the model’s output strays from the user’s specific directives . Con - text inconsistency arises when the output , although possibly factually correct , is irrelevant or inappropriate for the given situation . Lastly , logical inconsistency refers to flaws in the model’s reasoning processes or a mismatch between the rea - soning and the final output . Similarly , the work from [ Ji et al . , 2023 ; Dziri et al . , 2021 ] also echoes these perspec - tives , categorizing them as intrinsic hallucinations and ex - trinsic hallucinations . Additionally , [ Zhang et al . , 2023b ] categorizes hallucinations according to their types of con - flict : input - conflicting , where responses go against user in - puts ; context - conflicting , involving contradictions within the generated context ; and fact - conflicting , where outputs clash with established factual knowledge . Furthermore , several studies have categorized hallucina - tions across different applications involving LLMs . [ Ye et al . , 2023 ] have provided a summary of representative hallucina - tions in numerous downstream tasks , such as machine transla - tion , question and answer , dialog systems , and summarization systems , among others . The study by [ Rawte et al . , 2023 ] provides a structured summary and discussion , categorizing and addressing hallucinations specifically within LLMs , mul - tilingual LLMs , and domain - specific LLMs . These classifica - tions provide a clear framework for understanding the hallu - cinations that occur in LLMs during content generation and reveal the challenges and limitations faced by LLMs in vari - ous tasks . 2 . 2 Hallucination Detection Catering to the phenomenon of hallucination , existing stud - ies have proposed various detection and evaluation strate - gies . Reflecting the proposed classification of hallucinations , [ Huang et al . , 2023 ] have also summarized the correspond - ing detection methods for each category . For factuality hal - lucinations , they recommend strategies that involve retriev - ing external facts and implementing uncertainty estimation . As for faithfulness hallucinations , they also delineate sev - eral approaches , including classifier - based , QA - based , and prompting - based metrics , to sidestep the potential pitfalls of contradictory outputs . [ Zhang et al . , 2023b ] categorizes the approaches into two types : generation and discrimination . Generation methods consider hallucination as a generation characteristic , and evaluate the generated texts from LLMs , while discrimination approaches assess LLMs’ capability to distinguish between truthful and hallucinated statements . Ad - ditionally , research from [ Ye et al . , 2023 ] proposes meth - ods like reasoning classifiers , uncertainty measures , and self - assessment for identifying hallucinations . Furthermore , some research efforts focus on creating benchmarks specifically designed for various application sce - narios of LLMs in hallucination detection . HaluEval [ Li et al . , 2023 ] presents a large collection of generated and human - annotated hallucinated samples for assessing LLMs’ hallu - cination detection capabilities , revealing that incorporating external knowledge or adding reasoning steps can improve recognition accuracy . TruthfulQA [ Lin et al . , 2022 ] extends its assessment to 38 domains including law , finance , and pol - itics , employing both manual methods and automated fine - tuning of LLMs for evaluation . Considering the serious con - sequences in healthcare applications , Med - HALT [ Umapathi et al . , 2023 ] proposes a two - tiered approach , encompassing Reasoning Hallucination Tests ( RHTs ) and Memory Halluci - nation Tests ( MHTs ) , to evaluate the presence of hallucina - tions . In the scenarios mentioned , such as law , finance , and healthcare , hallucinations are typically detrimental . However , it’s worth contemplating whether , in certain domains , hallu - cinations might not always need to be viewed as problematic . 2 . 3 Hallucination Reduction Drawing from the detailed analysis of hallucination types and detection methods in LLMs outlined in the preceding sections , some research has focused on developing targeted strategies to reduce these hallucinations . The work by [ Zhang et al . , 2023b ] classifies approaches to mitigate hallucinations in LLMs based on the timing of their application within the LLM life cycle . For instance , during the reinforcement learn - ing from human feedback ( RLHF ) stage , a specific reward score targeting hallucinations can be designed and directly optimized through reinforcement learning . In the model in - ference stage , decoding strategies and the retrieval of exter - nal knowledge can be employed for retrieval - based enhance - ment . [ Ye et al . , 2023 ] summarizes five methods for address - ing hallucinations , including parameter adaptation and lever - aging external knowledge , and apply these approaches across various downstream tasks . [ Tonmoy et al . , 2024 ] presents an elaborate taxonomy based on a range of parameters , including dataset utilization , common tasks , feedback mechanisms , and types of retrievers . This systematic classification effectively differentiates between the various specialized approaches de - veloped for mitigating hallucination issues in LLMs . It also provides a detailed summary of various strategies based on prompt engineering for reducing hallucinations , including re - trieval augmented generation ( RAG ) , and self - refinement . Particularly , some research has focused on exploring how knowledge graphs ( KGs ) can aid LLMs in reducing hallucinations [ Sun et al . , 2023 ] [ Shi et al . , 2023 ] . [ Agrawal et al . , 2023 ] argues that KG - augmented retrieval techniques effectively address hallucination issues by expanding the model’s knowledge with non - parametric factual knowledge . These studies not only enhance our understanding of the op - erational mechanisms of LLMs but also provide critical guid - ance for improving the accuracy and reliability of models in practical applications . 3 The Creativity Hidden in Hallucination While existing studies have predominantly focused on iden - tifying and mitigating hallucinations in LLMs , often perceiv - ing these as drawbacks , a crucial question arises : Is halluci - nation in LLMs always harmful , or does creativity hide in hal - lucination ? This paper explores this vital question , aiming to Figure 2 : Cases of relations between hallucination and creativity . understand the hallucinations of LLMs and harness their po - tential creative value by reviewing historical cases , cognitive science literature , and recent advancements in LLM research . Historical examples , in which diverse forms of hallucina - tions have sparked revolutionary discoveries , offer insightful parallels and serve as a guide in understanding the potential creative value of hallucinations in LLMs . For instance , as shown in Figure 2 , consider the notion of factuality halluci - nations . Historically , the shift from a geocentric to a helio - centric model of the solar system was a monumental change in scientific thought . Initially , heliocentrism was dismissed as a factual error , much like how LLMs might generate seem - ingly erroneous information . However , just as Copernicus’s heliocentric model eventually revolutionized astronomy , hal - lucinations can lead to novel ideas , challenging conventional wisdom . Similarly , faithfulness hallucinations in LLMs can be likened to accidental discovery . For example , Alexander Fleming’s unintended experiment resulted in a groundbreak - ing medical breakthrough : penicillin . These examples high - light how both factuality and faithfulness hallucinations could be pivotal in driving creativity . Expanding upon these historical insights , the clue of the interplay between hallucination and creativity can also be ex - plored in cognitive science studies . The hallucinations ex - perienced by humans are seen as crucial for simulating cre - ative thought processes . For example , research [ Benedek et al . , 2014 ] on human creativity indicates that creative think - ing involves both the activation of the left prefrontal cortex , known for its role in imaginative thinking , and the engage - ment of the right hippocampus , essential for memory pro - cessing . Such insights underscore the idea that creativity is not merely about retrieving information but recombining and expanding upon existing knowledge , which is similar to hal - lucination [ Ye et al . , 2023 ] . Furthermore , neuroscience re - search on creativity [ Beaty , 2015 ] , exemplified by studies of improvisation in jazz musicians , parallels this concept . By monitoring different brain regions , researchers have discov - ered that improvisation activates the same areas as pseudo - random motor movements . This similarity suggests a link between the spontaneity of pseudo - random movements and creative processes , further implying an interplay between hal - lucinations and creativity . These cognitive science findings also provide valuable insights for research in LLMs . In the realm of LLMs , there’s an increasing focus on the interplay between hallucinations and creativity . As Sam Alt - man , CEO of OpenAI , elucidates in [ Salesforce , 2023 ] , there is a profound and often overlooked connection between the hallucinatory phenomena in LLMs and their creative output . Altman argues that LLM hallucination is a cornerstone in un - leashing the creative potential of AI . Recent studies also sup - port this view . The research [ Lee , 2023 ] provides a theoretical reference for understanding the interconnectedness of hallu - cination and creativity in LLMs , substantiating their corre - lation through rigorous mathematical analysis . Two surveys also support this point , the research [ Wang , 2024 ] suggests that this interplay is beneficial , while [ Rawte et al . , 2023 ] portrays hallucination models as ’collaborative creative part - ners’ . Even though their outputs might deviate from factual or instruction , they serve as catalysts for innovative thought . Despite the emerging evidence linking hallucination and creativity in LLMs , research in this field is still limited . There is a significant need for further research to both deepen our understanding of the value of the link between hallucination and creativity in LLMs and to explore how this interplay can be effectively harnessed for innovative applications . 4 The Creativity of Large Language Models Regarding the interplay between hallucinations and creativ - ity in LLM , establishing a definitive concept of creativity be - comes essential . However , creativity has long been a chal - lenging concept to both define and quantify due to its multi - faceted and intricate nature . In this section , we will explore definitions of creativity as understood in cognitive science , examine the approaches employed to measure creativity , and highlight recent studies that investigate LLM creativity . 4 . 1 Definition of Creativity While [ Treffinger , 1998 ] presents an extensive array of over 100 different definitions of creativity , it is noteworthy that most studies in this field typically utilize only a select few of these definitions . In cognitive science , creativity is often conceptualized from four distinct perspectives : cognitive pro - cesses associated with creativity ( later in this paper referred to as ‘process’ ) , personal characteristics of creative individu - als ( ‘person’ ) , creative products or outcomes ( ‘product’ ) and the interaction between the creative individual and the con - text or environment ( ‘press’ ) [ Couger et al . , 1993 ] . In this paper , we mainly introduce the ’process’ and ’product’ , as they are particularly pertinent to understanding the creativity of LLM , while the ’person’ and ’press’ categories are more aligned with human creativity . Regarding the process perspective of creativity , [ Torrance , 1977 ] defines it as the process of identifying problems or gaps in knowledge , developing hypotheses or propositions , testing and validating hypotheses , and ultimately sharing the findings . Similarly , [ Mednick , 1962 ] suggests that creativity involves combining associative elements into novel configu - rations that fulfill the requirements of a given task . [ Guil - ford , 2017 ] views creativity as a type of problem - solving and differentiates between two kinds of cognitive operations : divergent and convergent production . Divergent production is characterized by a wide - ranging search for multiple logi - cal solutions or alternatives to open - ended problems , while convergent production involves a narrow search for a single , precise solution to a problem where one specific answer is needed . They posit that divergent production processes are more closely associated with effective creative thinking . As the definition of creativity towards the product , [ Khatena and Torrance , 1973 ] defines creativity as the con - struction or organization of ideas , thoughts , and feelings into unusual and associative connections through the power of imagination . [ Gardner , 2011 ] posits that creative individuals possess the capacity to solve problems , fashion products , or formulate new questions in ways that are novel yet acceptable within a specific cultural context . Creativity is also perceived as the ability to generate or conceive something original and adaptive to task constraints , while also being of high quality , useful , aesthetically pleasing , and novel . Researchers often distinguish between two main types of creativity : everyday creativity , or ”little - C , ” common to nearly everyone , and eminent creativity , or ”big - C , ” which is seen in significant historical figures . Expanding on this , the Four C model [ Kaufman and Beghetto , 2009 ] of creativity in - troduces ”mini - c , ” representing the creative learning process , and ”Pro - c , ” indicating professional - level creative expertise . Despite the varied perspectives in defining creativity , a consensus exists among researchers regarding its core at - tributes . It is widely acknowledged that creativity is char - acterized by the generation of responses that are both novel and useful . However , the precise interpretation of these terms remains a subject of ongoing discourse . 4 . 2 Approaches for measuring creativity In the field of cognitive science , measuring creativity is proven to be a challenging task . These challenges stem from the subjectivity of creativity and the variety of environments in which it is manifested . Based on the various definitions of creativity , researchers have developed many different meth - ods to measure it . These methods are divided into four cate - gories , representing the four main dimensions of the creativ - ity definition : process , product , person , and press . Here , we focus on the widely adopted process and product approaches . The process approaches in creativity measurement focus on the specific cognitive processes and structures that are conducive to creative production . Divergent thinking tests ( DAT ) [ Olson et al . , 2021 ] have been most widely used for measuring creative processes or creativity - relevant skills . Examples of these tests include the Associative chain test ( ACT ) [ Marko et al . , 2018 ] , the Torrance Tests of Creative Thinking ( TTCT ) [ Torrance , 1977 ] , the Structure of the In - tellect Divergent Production Tests ( SOI ) [ Guilford , 2017 ] , Wallach - Kogan Creativity Tests and the Creativity Assess - ment Packet ( CAP ) . These tests , which are also known as measures of ideational fluency , include open or ill - structured problems that require individuals to generate as many re - sponses as possible , which are then scored to capture flu - ency ( number of responses ) , originality ( statistical rarity ) , flexibility ( number of different categories ) and elaboration ( amount of detail ) . Hence , the focal point of divergent think - ing tests is not only to consider the amount of responses but also the quality of these responses . Besides , there are some convergence thinking tasks that consider creative ideas are achieved by forming mutually remote associative ele - ments into new and useful combinations , like Remote Asso - ciates Test ( RAT ) [ Mednick , 1962 ] , Bridge - the - Associative - Gap Task ( BAG ) [ Gianotti et al . , 2001 ] . However , the funda - mental psychometric assumptions and underlying cognitive processes involved in them remain controversial . The product approaches are supported by the rationale that a comprehensive assessment of an individual’s creative capa - bilities should include the measurement of their concrete cre - ations . Central to this method is the Consensual Assessment Technique ( CAT ) [ Amabile , 1982 ] and widely implemented in studies focusing on the products of creativity . Distinct from other methods of assessment , the CAT does not rely on pre - determined theoretical frameworks of creativity . Instead , it utilizes the informed judgment of experts to evaluate the cre - ative outputs within their relevant fields . This unique charac - teristic of the CAT allows it to incorporate a range of perspec - tives . While the CAT for measuring creativity is known for its high inter - rater reliability , several situational variables like the number of tasks and the performance domain can impact this reliability . Furthermore , the practicality of implementing the CAT faces numerous challenges . The selection and ex - pertise level of judges are subjects of ongoing debate , with the consensus among judges notably swayed by their exper - tise . Additionally , judges personalities , as evidenced in [ Baer , 2015 ] , can influence creativity ratings , with more agreeable judges tending towards leniency . Cultural disparities among judges also play a role , as [ Niu and Sternberg , 2001 ] found in their comparison of American and Chinese judges’ evalu - ations of artistic creativity . Judges may also display biases , particularly when evaluating their own work . 4 . 3 Recent works on evaluating LLM’s creativity The section mentioned above delves into the approaches to measure human creativity from a cognitive science per - spective . However , since there are differences between LLM and humans , it might lead to irrelevant responses or serious logical issues , requiring us to additionally assess these ap - proaches . This predicament raises a question : how can we adapt these measures to effectively evaluate the creativity of LLM ? In light of LLM’s burgeoning potential , researchers have explored various approaches to measure the creativity of LLM . Broadly , these approaches fall into two distinct types . The first type involves adapting existing creativity assessment techniques from cognitive science for use with LLM . The sec - ond is to design a new approach specifically for measuring creativity in LLM . For the first type , some researchers think that creative problem - solving is a crucial ability for LLM . For exam - ple , [ Stevenson et al . , 2022 ] conducts a comparative analy - sis using the AUT , where both GPT - 3 and human subjects were instructed to generate novel and useful responses . The responses were rated on a scale from 1 to 5 by two hu - man judges , leading to the conclusion that humans outper - formed GPT - 3 in generating creative responses within the AUT . Building upon this , [ Summers - Stay et al . , 2023 ] de - vised a series of prompts aimed at sifting through the 690 al - ternative uses responses previously generated , isolating those that were both original and practical . These prompts required the evaluation of the pros and cons associated with employing the objects in their new , unconventional roles . While GPT - 3 demonstrated an ability to generate responses that were “sur - prisingly good , ” it notably failed to discern and discard im - practical alternative uses . [ Naeini et al . , 2023 ] introduces a novel dataset for evaluating creative problem - solving tasks by curating the problems and human performance results from the popular British quiz show Only Connect , an analogical proxy for RAT tests . [ Cropley , 2023 ] explore the creativity of LLM by using the DAT task on GPT - 4 and GPT - 3 . 5 compared to the human norms . In contrast to these approaches , [ G´oes et al . , 2023 ] propose an innovative , interactive method en - abling GPT - 4 to autonomously refine and enhance the cre - ativity of its outputs . They employ the AUT and the TTCT visual completion tasks to investigate the LLM’s creativity . Similarly , [ Guzik et al . , 2023 ] also uses TTCT to evaluate the creative abilities of GPT - 4 . For the second type , [ Wang et al . , 2024 ] proves in theory that LLM can be as creative as humans under the condition that it can properly fit the data generated by human creators . Additionally , they also introduce two concepts of creativity in LLM : relative and statistical creativity . For relative creativity , where LLMs are deemed as creative as a hypothetical , yet re - alistic , human creator if it can produce works indistinguish - able from that creator , as determined by an evaluator . Statis - tical creativity is a means for understanding whether and to what degree LLM achieves creativity by comparing it with existing human creators . Through the lens of statistical cre - ativity . And [ Lee , 2023 ] derive a mathematical characteri - zation of the trade - off between hallucination and creativity in LLM by developing a rigorous mathematical framework for analyzing the hallucination phenomenon in LLMs . Although researching creativity in LLMs become a trend , there is still a need for more theoretical studies and compre - hensive benchmarks to deepen understanding of this area . 5 Harness LLM Hallucination For Creativity Given the recognition of LLM hallucinations as potential catalysts for creativity , a pivotal question arises : How can we effectively harness hallucinations for creative thought while also mitigating their risks ? The aim is to enhance our un - derstanding and utilization of these phenomena , thereby am - plifying the creative potential of LLMs across various appli - cations , without compromising on accuracy . This requires methods that not only induce hallucinations but also critically evaluate them , transforming them into innovative sources . In addressing this challenge , our research revolves around a comprehensive consideration of two critical dimensions : the divergent phase and the convergent phase . These phases align with the framework outlined in fundamental research [ Press - ing , 1998 ] , which posits creativity as an interplay of gen - erative and evaluative processes , embracing both divergent and convergent thinking . The divergent phase stimulates LLM hallucinations tailored to user needs , fostering creative thought , while the convergent phase assesses these to trans - form them into innovative , applicable ideas , and our survey will systematically explore studies aligned with these phases . Figure 3 : The divergent phase stimulates the hallucination of LLMs , fostering creative thought . 5 . 1 Divergent Phase of LLM In the divergent phase , the emphasis extends beyond the mere generation of relevant hallucinations . It encompasses foster - ing the LLM’s capacity for hallucination with creativity . This phase benefits significantly from insights derived from ex - isting literature , which suggest a multi - faceted approach to model optimization , as shown in Figure 3 . For the hallucination ability enhancement of LLMs , Press - ing’s theory of improvisational creativity [ Pressing , 2007 ] suggests that improvisation is an acquired skill , requiring ex - tensive training to reach professionals , which literature un - derscores the importance of training . In concordance with the aforementioned views , recent studies [ Zhao et al . , 2024 ; Tian et al . , 2023 ] have proven the hallucination gap between different LLMs through extensive experiments , which points out the necessity of model training to improve the LLM’s abilities of hallucination and creativity . For instance , re - search [ Colin et al . , 2016 ] demonstrates how specific train - ing techniques can enhance the model’s ability to generate creative outputs . This research proposes that the cognitive process of creativity , especially the ’insight’ phenomenon in problem - solving , aligns closely with the mechanisms of hi - erarchical reinforcement learning ( HRL ) in artificial systems . This work underscores the potential of HRL to mimic human - like creative processes , offering a novel perspective on the capabilities of LLM in replicating complex cognitive behav - iors . For prompt engineering , by setting specific prompts and contexts , LLMs will continuously learn and adapt in contexts to enhance their understanding and response capabilities for hallucination generation and complex creative tasks . This theory can be traced back to the classic literature of cogni - tive science . For example , giving a prompt like : ” prompt : to come up with something clever , humorous , original , com - pelling , or interesting ” has been validated as effective for hu - man hallucination in research [ Beaty et al . , 2013 ] . In the prompt engineering research about LLM [ Hubert et al . , 2023 ; Koivisto and Grassini , 2023 ] , it is also the most widely adopted strategy for divergent thinking , enabling LLMs to ex - plore and respond to users’ creative requirements more easily , thereby exhibiting a higher level of creativity in applications . The integration of interaction - based hallucination genera - tion methods also offers a promising direction to enrich the divergent phase . This concept introduces two distinct types of interactions : multi - agent interaction and human - agent inter - action . For the interaction among multiple agents , a dynamic that has been investigated in recent studies like [ Liang et al . , 2023 ] , plays a crucial role . These multi - agent interactions encourage diverse and creative outputs from LLMs , as agents with varying perspectives and knowledge bases engage in col - laborative or competitive dialogues . For the human - agent in - teraction , an area receiving increasing attention as evidenced by [ Weber et al . , 2023 ; Rick et al . , 2023 ] , provides invaluable insights . This form of interaction allows for a more grounded and realistic feedback loop , where human creativity can in - spire and be inspired by the LLM’s responses , leading to more relatable and applicable hallucinations . In summary , these two types of interactions underpin the diversification of hal - lucination generation in LLMs , each contributing to a more dynamic , context - aware , and creatively stimulating phase . As examined in [ Koivisto and Grassini , 2023 ] , the diver - gent thinking ability of LLM is still far from human , which requires the improving of LLM divergent thinking abilities . 5 . 2 Convergent Phase of LLM The convergent phase , in stark contrast to the divergent phase , is dedicated to refining hallucinations into valuable creative contributions . This phase is characterized by a meticulous process of evaluating hallucinations , employing a systematic approach to identify , categorize , and select those that are most constructive and aligned with user needs . Different from existing hallucination detection and reduc - tion methods as discussed in Sections 2 . 3 and 2 . 2 , which di - rectly identify and eliminate hallucinations , the convergent phase involves discerning whether hallucinations are needed based on the context , eliminating harmful hallucinations , and identifying valuable ones , raising higher demands for LLM convergent thinking abilities , as shown in Figure 4 . To determine whether hallucinations are necessary for ap - plications , it’s crucial to optimize the intent recognition capa - bilities of LLMs . For instance , the 4C creativity theory dis - cussed in research [ Tian et al . , 2023 ] explores four scenarios requiring creativity , optimizing Little - C tasks for LLMs’ cre - ativity . Automating the discrimination of these task scenarios remains an area of urgent research . Moreover , balancing hal - lucination and faithfulness in LLMs based on the demand , as mentioned in research [ Zhang , 2023 ] , involves fine - tuning and knowledge fusion , but this area is still in its infancy , and lacking a systematic approach . To discern harmful hallucinations , a detailed and nuanced classification system for hallucinations is crucial . Existing research , as extensively discussed in Section 2 . 2 , has devel - oped a taxonomy for hallucinations predominantly under the assumption that they are detrimental and need to be mitigated . However , this approach overlooks the potential value of cer - tain hallucinations . The current classification lacks in anno - tating and recognizing beneficial hallucinations , thereby lim - iting the LLMs’ ability to differentiate between harmful and potentially valuable hallucinations . To evaluate the creative potential hidden within the sea of hallucinations produced by LLMs , it’s crucial to establish metrics and design methods for effectively assessing LLMs’ creative output . In terms of evaluation metrics , as discussed Figure 4 : The convergent phase refines hallucinations into valuable creative contributions . in Section 4 . 3 , the evaluation of creativity within these hal - lucinations can leverage existing metrics from cognitive sci - ence and those specifically developed for LLMs . The choice of metrics should align with the specific applications . For in - stance , artistic creation often emphasizes fluency , flexibility , originality , and elaboration [ Silvia et al . , 2008 ] , whereas sci - entific innovation is more focused on problem - solving abil - ities [ Tian et al . , 2023 ] . In terms of evaluation methods , those mentioned in Section 4 . 3 for assessing creativity are still applicable to hallucinations . However , these studies of - ten rely on manual assessment by data annotators or experts . Automating the assessment of creativity within hallucina - tions is key to transitioning from theory to practical appli - cations . From the model’s ability perspective , recent studies , such as [ Tian et al . , 2023 ; Zhao et al . , 2024 ] , propose self - reflection for automatic content evaluation and correction but highly rely on the model’s reasoning abilities , which requires effective training methods or prompt strategies in future re - search . From the interaction perspective , studies like ChatE - val [ Chan et al . , 2023 ] attempt to use multi - agent approaches to assess whether generated content meets requirements . Re - search [ Zhang et al . , 2023a ] evaluates the creative value be - hind LLM actions from a simulation perspective . Research from the human - agent perspective [ Rick et al . , 2023 ] , as - sessing user interactions with LLM - generated content , offers a way to evaluate creativity in hallucinations , moving away from traditional manual annotation . In conclusion , while many studies have explored this direc - tion , research in this field is still in its early stages . A more comprehensive evaluation metric system , richer datasets , and stronger models and framework designs are urgently needed for further exploration . 6 Conclusion and Future Work 6 . 1 Conclusion This paper revisits the hallucinations in LLMs , advocating for a paradigm shift where they are not solely viewed as neg - ative phenomena , but also as potential catalysts for creativ - ity . It establishes what hallucinations entail within LLMs and reviews research focused on their detection and reduction . Challenging the view of hallucinations as entirely negative , the study delves into their potential to spur creativity . Exam - ining historical cases and current research highlights the intri - cate interplay between hallucination and creativity in LLMs . The discussion follows the cognitive science framework of divergent and convergent thinking , providing a comprehen - sive review of studies on harnessing creative hallucinations . This work not only aligns with cognitive science principles but also opens avenues for applications and future research in leveraging hallucinations for creative purposes in LLMs . 6 . 2 Future Work Future research in the field of hallucinations and creativity within LLMs can be explored in several key areas : Deeper Theoretical Exploration : Although cognitive sci - ence has extensively studied the interplay between halluci - nations and creativity in humans as illustrated in Section 3 , there’s a need for more theoretical exploration within the con - text of LLMs . Future research should aim to deepen our un - derstanding of this relationship in LLMs , focusing on con - structing a theoretical basis that connects cognitive theories with the operational mechanisms of LLMs . Richer Datasets and Benchmarks : As discussed in Sec - tion 5 , there is a notable lack of available benchmarks and datasets for the study of hallucination and creativity . Future research urgently requires the development of richer datasets to facilitate research and experimentation in this domain . Ad - ditionally , the establishment of more comprehensive bench - marks is crucial for a deeper evaluation of the abilities of LLMs in manifesting creative outputs from hallucinations . Optimization of Method Designs : As discussed in Sec - tion 5 , leveraging hallucinations for creativity relies on the LLMs’ intrinsic reasoning capabilities to discern user intent , distinguish harmful hallucinations , and evaluate the creativity within hallucinations . Future research should thus focus on optimizing LLMs’ abilities in these areas through advance - ments in training strategy and framework design , ensuring effective utilization of hallucinations for creative output . Transformation of Hallucinations to Creativity in Mul - timodal Scenarios : As explored in Section 5 , the value of multimodal information during the divergent and convergent phases of creativity highlights a nascent yet challenging area of research . Future investigations are needed to tackle how to assess the creative value of hallucinations across different modalities and use multimodal information for creativity . Exploration of More Application Scenarios : In Sec - tions 4 and 5 , we examined various application fields where users’ demands for creativity differ , leading to diverse stan - dards for assessing the value of creativity within hallucina - tions . This underscores the necessity for future investigations to explore a broader range of application scenarios . Such ex - ploration is essential to achieve a more comprehensive under - standing and utilization of the interplay between hallucination and creativity across different contexts . Ultimately , these directions for future research endeavor to enrich the comprehension and application of hallucinations in LLMs , contributing innovative theories and methodologies and paving the way for practical applications . References [ Agrawal et al . , 2023 ] Garima Agrawal , Tharindu Ku - marage , Zeyad Alghami , and Huan Liu . Can knowledge graphs reduce hallucinations in llms ? : A survey . ArXiv preprint , 2023 . [ Amabile , 1982 ] T . M . Amabile . Social psychology of cre - ativity : A consensual assessment technique . Journal of Personality and Social Psychology , 1982 . [ Baer , 2015 ] John Baer . The importance of domain - specific expertise in creativity . Roeper Review , 2015 . [ Beaty et al . , 2013 ] Roger Beaty , Bridget Smeekens , Paul Silvia , et al . A first look at the role of domain - general cognitive and creative abilities in jazz improvisation . Psy - chomusicology : Music , Mind , & Brain , 2013 . [ Beaty , 2015 ] Roger E Beaty . The neuroscience of musical improvisation . Neuroscience & Biobehavioral Reviews , 51 : 108 – 117 , 2015 . [ Benedek et al . , 2014 ] Mathias Benedek , Emanuel Jauk , An - dreas Fink , Karl Koschutnig , Gernot Reishofer , Franz Ebner , and Aljoscha C Neubauer . To create or to recall ? neural mechanisms underlying the generation of creative new ideas . NeuroImage , 2014 . [ Chan et al . , 2023 ] Chi - Min Chan , Weize Chen , Yusheng Su , Jianxuan Yu , Wei Xue , Shanghang Zhang , Jie Fu , and Zhiyuan Liu . Chateval : Towards better llm - based evalua - tors through multi - agent debate . ArXiv preprint , 2023 . [ Colin et al . , 2016 ] Thomas R Colin , Tony Belpaeme , An - gelo Cangelosi , and Nikolas Hemion . Hierarchical rein - forcement learning as creative problem solving . Robotics and Autonomous Systems , 2016 . [ Couger et al . , 1993 ] J . Daniel Couger , Lexis F . Higgins , and Scott C . McIntyre . ( un ) structured creativity in information systems organizations . MIS Q . , 1993 . [ Cropley , 2023 ] David Cropley . Is artificial intelligence more creative than humans ? : Chatgpt and the divergent associ - ation task . Learning Letters , 2023 . [ Dziri et al . , 2021 ] Nouha Dziri , Andrea Madotto , Osmar Za ¨ ıane , and Avishek Joey Bose . Neural path hunter : Re - ducing hallucination in dialogue systems via path ground - ing . In Proc . of EMNLP , 2021 . [ Gardner , 2011 ] Howard Gardner . Creating minds : An anatomy of creativity seen through the lives of Freud , Ein - stein , Picasso , Stravinsky , Eliot , Graham , and Ghandi . Civitas books , 2011 . [ Gianotti et al . , 2001 ] Lorena R . R . Gianotti , Christine Mohr , Diego A . Pizzagalli , Dietrich Lehmann , and Peter Brugger . Associative processing and paranormal belief . Psychiatry and Clinical Neurosciences , 2001 . [ G ´ oes et al . , 2023 ] Luis Fabricio G ´ oes , Marco Volpe , Piotr Sawicki , Marek Grses , and Jacob Watson . Pushing gpt’s creativity to its limits : Alternative uses and torrance tests . 2023 . [ Guilford , 2017 ] Joy Peter Guilford . Creativity : A quarter century of progress . In Perspectives in creativity , pages 37 – 59 . Routledge , 2017 . [ Guzik et al . , 2023 ] Erik E . Guzik , Christian Byrge , and Christian Gilde . The originality of machines : Ai takes the torrance test . Journal of Creativity , 2023 . [ Huang et al . , 2023 ] Lei Huang , Weijiang Yu , Weitao Ma , Weihong Zhong , Zhangyin Feng , Haotian Wang , Qiang - long Chen , Weihua Peng , Xiaocheng Feng , Bing Qin , et al . A survey on hallucination in large language models : Prin - ciples , taxonomy , challenges , and open questions . ArXiv preprint , 2023 . [ Hubert et al . , 2023 ] Kent Hubert , Kim N Awa , and Darya Zabelina . Artificial intelligence is more creative than hu - mans : A cognitive science perspective on the current state of generative language models . 2023 . [ Ji et al . , 2023 ] Ziwei Ji , Nayeon Lee , Rita Frieske , Tiezheng Yu , Dan Su , Yan Xu , Etsuko Ishii , Ye Jin Bang , Andrea Madotto , and Pascale Fung . Survey of halluci - nation in natural language generation . ACM Computing Surveys , 2023 . [ Kaufman and Beghetto , 2009 ] James C . Kaufman and Ronald A . Beghetto . Beyond big and little : The four c model of creativity . Review of General Psychology , 2009 . [ Khatena and Torrance , 1973 ] Joe Khatena and E Paul Tor - rance . Thinking creatively with sounds and words : Norm - stechnical manual . Res . ed . ) Bensenville , IL : Scholastic Testing Service , 1973 . [ Koivisto and Grassini , 2023 ] Mika Koivisto and Simone Grassini . Best humans still outperform artificial intelli - gence in a creative divergent thinking task . Scientific re - ports , 2023 . [ Lee , 2023 ] Minhyeok Lee . A mathematical investigation of hallucination and creativity in gpt models . Mathematics , 2023 . [ Li et al . , 2023 ] Junyi Li , Xiaoxue Cheng , Wayne Xin Zhao , Jian - Yun Nie , and Ji - Rong Wen . Halueval : A large - scale hallucination evaluation benchmark for large lan - guage models . In Proc . of EMNLP , 2023 . [ Liang et al . , 2023 ] Tian Liang , Zhiwei He , Wenxiang Jiao , Xing Wang , Yan Wang , Rui Wang , Yujiu Yang , Zhaopeng Tu , and Shuming Shi . Encouraging divergent thinking in large language models through multi - agent debate . ArXiv preprint , 2023 . [ Lin et al . , 2022 ] Stephanie Lin , Jacob Hilton , and Owain Evans . TruthfulQA : Measuring how models mimic human falsehoods . In Proc . of ACL , 2022 . [ Marko et al . , 2018 ] Martin Marko , Drahomr Michalko , and Igor Rievcansky . Remote associates test : An empirical proof of concept . Behavior Research Methods , 2018 . [ Mednick , 1962 ] Sarnoff A . Mednick . The associative basis of the creative process . Psychological review , 1962 . [ Naeini et al . , 2023 ] Saeid Naeini , Raeid Saqur , Mozhgan Saeidi , John Giorgi , and Babak Taati . Large language models are fixated by red herrings : Exploring creative problem solving and einstellung effect using the only con - nect wall dataset , 2023 . [ Niu and Sternberg , 2001 ] Weihua Niu and Robert J . Stern - berg . Cultural influences on artistic creativity and its eval - uation . International Journal of Psychology , 2001 . [ Olson et al . , 2021 ] Jay A . Olson , Johnny Nahas , Denis Chmoulevitch , Simon J . Cropper , and Margaret E . Webb . Naming unrelated words predicts creativity . Proceedings of the National Academy of Sciences , 2021 . [ Pressing , 1998 ] Jeff Pressing . Psychological constraints on improvisational expertise and communication . In the course of performance : Studies in the world of musical improvisation , 1998 . [ Pressing , 2007 ] Jeff Pressing . Improvisation : Methods and models . In Physical Theatres : A Critical Reader , pages 66 – 78 . Routledge , 2007 . [ Rawte et al . , 2023 ] Vipula Rawte , Amit Sheth , and Amitava Das . A survey of hallucination in large foundation models . ArXiv preprint , 2023 . [ Rick et al . , 2023 ] Steven R Rick , Gianni Giacomelli , Hao - ran Wen , Robert J Laubacher , Nancy Taubenslag , Jen - nifer L Heyman , Max Sina Knicker , Younes Jeddi , Hen - drik Maier , Stephen Dwyer , et al . Supermind ideator : Ex - ploring generative ai to support creative problem - solving . ArXiv preprint , 2023 . [ Salesforce , 2023 ] Salesforce . A world without ai is becom - ing unthinkable , 2023 . [ Shi et al . , 2023 ] Xiao Shi , Zhengyuan Zhu , Zeyu Zhang , and Chengkai Li . Hallucination mitigation in natural lan - guage generation from large - scale open - domain knowl - edge graphs . In Proc . of EMNLP , 2023 . [ Silvia et al . , 2008 ] Paul J Silvia , Beate Winterstein , John T Willse , Christopher M Barona , Joshua T Cram , Karl I Hess , Jenna L Martinez , and Crystal A Richard . Assess - ing creativity with divergent thinking tasks : exploring the reliability and validity of new subjective scoring methods . Psychology of Aesthetics , Creativity , and the Arts , 2008 . [ Stevenson et al . , 2022 ] Claire Stevenson , Iris Smal , Matthijs Baas , Raoul Grasman , and Han van Maas . Putting gpt - 3’s creativity to the alternative uses test , 2022 . [ Summers - Stay et al . , 2023 ] Douglas Summers - Stay , Clare R Voss , and Stephanie M Lukin . Brainstorm , then select : a generative language model improves its creativity score . In The AAAI - 23 Workshop on Creative AI Across Modalities , 2023 . [ Sun et al . , 2023 ] Jiashuo Sun , Chengjin Xu , Lumingyuan Tang , Saizhuo Wang , Chen Lin , Yeyun Gong , Heung - Yeung Shum , and Jian Guo . Think - on - graph : Deep and re - sponsible reasoning of large language model with knowl - edge graph . arXiv preprint arXiv : 2307 . 07697 , 2023 . [ Tian et al . , 2023 ] Yufei Tian , Abhilasha Ravichander , Lian - hui Qin , Ronan Le Bras , Raja Marjieh , Nanyun Peng , Yejin Choi , Thomas L Griffiths , and Faeze Brahman . Macgyver : Are large language models creative problem solvers ? ArXiv preprint , 2023 . [ Tonmoy et al . , 2024 ] SM Tonmoy , SM Zaman , Vinija Jain , Anku Rani , Vipula Rawte , Aman Chadha , and Amitava Das . A comprehensive survey of hallucination mitiga - tion techniques in large language models . ArXiv preprint , 2024 . [ Torrance , 1977 ] E Paul Torrance . Creativity in the class - room ; what research says to the teacher . 1977 . [ Touvron et al . , 2023 ] Hugo Touvron , Thibaut Lavril , Gau - tier Izacard , Xavier Martinet , Marie - Anne Lachaux , Tim - othee Lacroix , Baptiste Roziere , Naman Goyal , Eric Ham - bro , et al . Llama : Open and efficient foundation language models . ArXiv preprint , 2023 . [ Treffinger , 1998 ] Donald J . Treffinger . Creativity , creative thinking , and critical thinking : In search of definitions . Gifted and Talented International , 1998 . [ Umapathi et al . , 2023 ] Logesh Kumar Umapathi , Ankit Pal , and Malaikannan Sankarasubbu . Med - halt : Medical do - main hallucination test for large language models . ArXiv preprint , 2023 . [ Wang et al . , 2024 ] Haonan Wang , James Zou , Michael Mozer , Anirudh Goyal , Alex Lamb , Linjun Zhang , Wei - jie J Su , Zhun Deng , Michael Qizhe Xie , et al . Can ai be as creative as humans ? , 2024 . [ Wang , 2024 ] Feng Wang . Lighthouse : A survey of agi hal - lucination . ArXiv preprint , 2024 . [ Weber et al . , 2023 ] Sebastian Weber , Bastian Kordyaka , Raphael Palombo , Dominik Siemon , and Bjoern Niehaves . Is a fool with a ( n ai ) tool still a fool ? an empirical study of the creative quality of human – ai collaboration . ACIS 2023 Proceedings , 2023 . [ Ye et al . , 2023 ] Hongbin Ye , Tong Liu , Aijia Zhang , Wei Hua , and Weiqiang Jia . Cognitive mirage : A review of hallucinations in large language models . ArXiv preprint , 2023 . [ Zhang et al . , 2023a ] Chi Zhang , Penglin Cai , Yuhui Fu , Haoqi Yuan , and Zongqing Lu . Creative agents : Empow - ering agents with imagination for creative tasks . ArXiv preprint , 2023 . [ Zhang et al . , 2023b ] Yue Zhang , Yafu Li , Leyang Cui , Deng Cai , Lemao Liu , Tingchen Fu , Xinting Huang , Enbo Zhao , Yu Zhang , Yulong Chen , et al . Siren’s song in the ai ocean : A survey on hallucination in large language models . ArXiv preprint , 2023 . [ Zhang , 2023 ] Chen Zhang . User - controlled knowledge fu - sion in large language models : Balancing creativity and hallucination . ArXiv preprint , 2023 . [ Zhao et al . , 2024 ] Yunpu Zhao , Rui Zhang , Wenyi Li , Di Huang , Jiaming Guo , Shaohui Peng , Yifan Hao , Yuanbo Wen , Xing Hu , Zidong Du , et al . Assessing and understanding creativity in large language models . ArXiv preprint , 2024 .