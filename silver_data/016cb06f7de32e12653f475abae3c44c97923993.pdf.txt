One of Many : Assessing User - level Effects of Moderation Interventions on r / The _ Donald Amaury Trujillo amaury . trujillo @ iit . cnr . it IIT - CNR Italy Stefano Cresci stefano . cresci @ iit . cnr . it IIT - CNR Italy ABSTRACT Evaluating the effects of moderation interventions is a task of para - mount importance , as it allows assessing the success of content moderation processes . So far , intervention effects have been almost solely evaluated at the aggregated platform or community levels . Here , we carry out a multidimensional evaluation of the user - level effects of the sequence of moderation interventions that targeted r / The _ Donald : a community of Donald Trump adherents on Reddit . We demonstrate that the interventions : 1 ) strongly reduced user ac - tivity ; 2 ) slightly increased the diversity of the subreddits in which users participated ; 3 ) slightly reduced user toxicity ; and 4 ) gave way to the sharing of less factual and more politically biased news . Importantly , we also find that interventions having strong commu - nity level effects are associated to extreme and diversified user - level reactions . Our results highlight that community - level effects are not always representative of the underlying behavior of individuals or smaller user groups . We conclude by discussing the practical and ethical implications of our results . Overall , our findings can inform the development of targeted moderation interventions and provide useful guidance for policing online platforms . CCS CONCEPTS • Human - centered computing → Empirical studies in collab - orative and social computing ; • Information systems → So - cial networks ; Social networking sites . KEYWORDS content moderation ; moderation interventions ; user - level effects ; toxicity ; news quality ; causal inference ACM Reference Format : AmauryTrujilloandStefanoCresci . 2023 . OneofMany : AssessingUser - level Effects of Moderation Interventions on r / The _ Donald . In 15th ACM Web Science Conference 2023 ( WebSci ’23 ) , April 30 - May 1 , 2023 , Austin , TX , USA . ACM , NewYork , NY , USA , 10pages . https : / / doi . org / 10 . 1145 / 3578503 . 3583626 1 INTRODUCTION For a few years now , online platforms have been facing public and governmental pressure to take action against online harms such Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspecificpermission and / or a fee . Request permissions from permissions @ acm . org . WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA © 2023 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 979 - 8 - 4007 - 0089 - 7 / 23 / 04 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3578503 . 3583626 as the spread of mis - and disinformation , and the rise of toxic and hateful speech . Platforms have responded to the growing pressure by deploying a multitude of moderation interventions , specific ac - tions through which they intend to mitigate user misbehavior [ 17 ] . As recent examples , Reddit , Facebook , Instagram , and Twitter at - tached warning labels to posts presenting disputed information about COVID - 19 and election results [ 22 , 36 ] , and banned toxic users and communities [ 19 , 20 , 31 ] . On the one hand , these mod - eration interventions appear as reasonable solutions , representing initial countermeasures to many online harms , and serve as public evidence of the platforms’ willingness to tackle the issues they contributed to create . On the other hand , many of such interven - tions are applied light - mindedly and without proper validation [ 4 ] . Content moderation is still mostly expert - driven , the design of in - terventions is based on “common sense and intuition” , and progress is sought via trial - and - error rather than a rigorous scientific ap - proach [ 11 ] . Consequently , the effectiveness of current content moderation strategies is largely open to question and the need for additional evaluation efforts is manifest [ 30 ] . Evaluating the effects of moderation interventions is challenging . First , effects are multidimensional : they affect multiple facets of user behavior , such as news consumption , interests , community participation habits , and polarization , to name a few [ 31 ] . However , existing research has almost solely considered content activity and toxicity when evaluating intervention effects [ 7 , 8 , 19 , 20 , 28 ] . Plenty of other dimensions are essentially unexplored , meaning that we currently only have a partial view of the full extent of the effects caused by moderation interventions . Second , intervention effects can be evaluated at different levels : from multiple or single platforms and communities , down to individual users . So far , the vast majority of works that evaluated intervention effects did so at the platform or community levels . However , aggregated effects at these levels are the combination of many and potentially diverse effects at the user level . Hence , such aggregated effects might not be truly representative of the underlying behavior of individuals or smaller user groups [ 14 , 27 ] . Moreover , the same aggregated effect could be the result of heterogeneous distributions of user - level effects [ 10 , 15 ] , each corresponding to a different practical situation . Knowledge of the fine - grained , user - level effects of moderation interventions could better inform the content moderation process and drive the development of more effective interventions [ 11 ] . 1 . 1 Contributions Guided by these considerations , we carried out a fine - grained and multidimensional analysis of the user - level effects experienced by core users of r / The _ Donald , a Reddit community of Donald Trump supporters that was moderated by platform administrators with a a r X i v : 2209 . 08809v4 [ c s . S I ] 1 M a r 2023 WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA Trujillo & Cresci sequence of interventions . Members of r / The _ Donald were repeat - edly denounced for toxicity , trolling , and harassment [ 13 , 23 ] . For these reasons the subreddit was quarantined in June 2019 , restricted in February 2020 , and finally banned in June 2020 [ 31 ] . The quaran - tine removed the subreddit from the platform’s search results and the feed of non - subscribed users , reducing its visibility . The restric - tion involved the removal of several moderators of r / The _ Donald who supported content in violation of Reddit’s policies . Moreover , it allowed new submissions only from approved users , which prac - tically halted user participation in the subreddit , causing mass user migrations to other platforms [ 19 , 31 ] . Finally , the ban permanently shut r / The _ Donald by removing it from the platform and by making it impossible for all users to access its contents . Some works already provided results about the platform and community level effects of these interventions [ 7 , 19 , 31 ] . However , focusing for the first time on user - level effects allows us to seek answers to the following relevant , yet unanswered , research question : RQ : Are user - level reactions homogeneous or heterogeneous ? In other words : Are there differences between effects at the com - munity and user levels ? The existence of very heterogeneous user - level effects could im - ply that different users manifest opposite effects to the same inter - vention . Therefore , answering this question is important to assess the extent to which current moderation interventions are capable of producing the desired outcome on most , if not all , users . More - over , despite being statistically infrequent and non - representative of the general behavior , fringe , deviant , and extreme reactions are those that are mostly relevant in the context of content modera - tion . Furthermore , exploring the relationship between effects at the community and user levels is crucial to assess the reliability of the former . In fact , depending on the distribution of user - level effects , aggregated community effects could either follow or overshadow the reactions of a minority of fringe , deviant , or extreme users . Finally , cross - checking and combining answers to the previous question opens up the possibility to explore the usefulness of user - level effects for the development of future moderation interventions , and for improving content moderation at large . 1 . 2 Ethics statement We are confident that this work will have a positive impact on the policing of online platforms by providing novel and valuable findings to inform future content moderation decisions . For exam - ple , part of our results show that certain moderation interventions result in a radicalized minority of the moderated users . In Section 6 we discuss the ethical implications of these results , including the need to carefully balance the risk of causing harms to minorities in pursuit of benefits for the larger community . This work is entirely based on public - only Reddit data , with the used dataset abiding by the FAIR principles [ 34 ] , since it is published in an interoperable and machine - readable format , and under a reusable license . Fur - thermore , it is indexed on the reference platform Zenodo with an associated DOI , as described in Section 3 . 2 RELATED WORK We first discuss works that assessed effects of moderation interven - tions at the platform and community levels , which account for the vast majority of the literature on the subject . Then , we reconsider some studies in terms of their contributions towards understanding effects at the user level . 2 . 1 Effects at the platform and community levels In [ 31 ] we evaluated the community effects of the sequence of interventions on r / The _ Donald —i . e . , quarantine , restriction , and ban— finding that the first two greatly reduced the activity of the moderated users while the latter was only symbolic . However , this came at the expense of an overall trend increase in toxicity . We also concluded that the restriction had stronger effects platform - wise than the quarantine and that core users of r / The _ Donald manifested more changes than the rest of users . Chandrasekharan et al . [ 7 ] eval - uated quarantine effects on r / The _ Donald and r / TheRedPill , finding that the quarantines made it more difficult for the moderated com - munities to attract new members , but that the overall degree of tox - icity of their existing members remained mostly unaffected . Shen and Rosé [ 29 ] studied Reddit’s quarantines of r / The _ Donald and r / ChapoTrapHouse in terms of changes in the activity , visibility , and political discussion of the two communities . They found that the in - terventions had a homogenizing effect on participation but limited effects on the visibility of community - internal issues and political language . These previous works evaluated effects at the community - level , based on the assumption that users within a community behave similarly [ 9 , 23 ] . Instead , Horta Ribeiro et al . [ 19 ] evalu - ated effects across platforms . They focused on users that migrated from r / The _ Donald and r / Incels to TheDonald . win and incels . co respectively , when the former Reddit communities got banned . Re - sults highlighted that both bans markedly reduced user activity on the new platforms , but also that former users of r / The _ Donald in - creased their toxicity and radicalization [ 19 ] . Other related studies are those that evaluated the effects of moderation interventions on other Reddit communities . Chandrasekharan et al . [ 8 ] and Saleem and Ruths [ 28 ] investigated the bans that targeted r / FatPeopleHate and r / CoonTown , uncovering that many users left Reddit after the bans , and that those who remained significantly decreased their use of hate speech [ 8 ] . Interestingly , many r / CoonTown members moved to r / The _ Donald after the bans , doubling their posting activity [ 7 ] . The effectiveness of moderation interventions was also evaluated on Instagram and Twitter . Chancellor et al . [ 6 ] and Gerrard [ 16 ] studied the effects of the 2012 ban of pro - eating disorders tags on In - stagram . Results showed that , despite the intervention , the problem - atic content continued circulating on the platform , that users shar - ing such content quickly found alternative ways to identify other pro - eating disorders users , and that Instagram’s recommendation system continued suggesting problematic content [ 16 ] . Moreover , pro - eating disorders communities showed increased participation , toxicity , and support for self - harm after the intervention [ 6 ] . In the context of evaluating deplatforming strategies , Jhaver et al . [ 20 ] investigated the effects of Twitter’s banning of the controversial influencers Alex Jones , Milo Yiannopoulos , and Owen Benjamin . They found that the intervention reduced the number of Twitter conversations about all three influencers and that their supporters exhibited decreased activity and toxicity . However , in contrast to One of Many : Assessing User - level Effects of Moderation Interventions on r / The _ Donald WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA these aggregated results , they also found that a subset of users sig - nificantly increased activity and toxicity , and measured an increased prevalence of offensive ideas and conspiracy theories associated with the banned influencers [ 20 ] . The above discussion reveals a broad consensus that modera - tion interventions tend to reduce the activity of the moderated users [ 7 , 8 , 19 , 20 , 28 , 31 ] . Regarding toxicity however , the results are still unclear and worthy of additional investigation . While some studies measured an overall reduction in toxicity following bans [ 8 , 20 ] and other softer interventions [ 21 ] , others found no effects at all [ 7 ] . More worryingly , some even found increased toxi - city after community bans [ 6 , 19 , 31 ] . Overall , the existing results highlight that oftentimes interventions cause a mixture of desired and undesired effects . 2 . 2 Towards effects at the user level The previous analysis also highlights that , so far , effects of moder - ation interventions have been assessed almost exclusively at the level of the platform [ 6 , 19 , 20 ] or the community [ 7 , 8 , 28 , 31 ] . As such , we currently have very limited knowledge of user - level effects . Nonetheless , despite focusing on aggregated effects , some of the above works also provided incidental information about user - level reactions to moderation interventions . For instance , Saleem and Ruths [ 28 ] presented results of community - level effects as pre - post intervention scatter plots of user activity . Similarly , Trujillo M . et al . [ 32 ] presented some results as scatter plots of user activity changes . In another example , Katsaros et al . [ 21 ] touched upon intra - user changes in toxicity , for users that received preemptive interventions on Twitter . A striking observation that arises from these studies is that user - level effects were very heterogeneous , as depicted by the large spread of points in the scatter plots in [ 28 , 32 ] . Yet , neither Saleem and Ruths nor Trujillo M . et al . devoted specific attention to this phenomenon , and Katsaros et al . did not delve into intra - user differences . Nevertheless , these partial results imply that moderation interventions caused contrasting effects in many users . As an example , even in those cases when interventions produce the overall desired effects , there might be a subset of users who manifest adverse reactions , which has important implications for the development of future moderation interventions and for the policing of online platforms . Our present work contributes to filling this knowledge gap . 3 DATASET For our study we utilize and enrich the dataset of core users ( CUs ) of r / The _ Donald ( TD ) that we developed in [ 31 ] . The original dataset was obtained from Reddit’s archival data on Pushshift [ 2 ] and is publicly available for research purposes . 1 In [ 31 ] we defined CUs as “those users who authored at least one post ( i . e . , either a submission or comment ) a week , for the whole 30 weeks of the pre - quarantine period” . The dataset features 2 , 239 CUs and contains all of their public postings ( i . e . , submissions and comments ) on Reddit , both within and without TD . Despite accounting for only circa 1 % of TD’s users , CUs generated more than 40 % of its content before the quarantine . 1 https : / / doi . org / 10 . 5281 / zenodo . 6250576 quarantine 26 Jun . 2019 Pre - Q Post - Q Pre - R Post - R restriction 26 Feb . 2020 210 days 210 days Figure 1 : Timeline of the interventions on TD . Quarantine effects are assessed by comparing Pre - Q and Post - Q . Com - bined effects of the quarantine and restriction are assessed by comparing Pre - Q and Post - R . Our present analyses cover the first two moderation interven - tions enforced on TD : the quarantine ( Q ) and the restriction ( R ) . We omit analyzing the ban since TD had already been inactive for several weeks when it occurred , because of the restriction [ 19 ] . Given that at the user level it is unwieldy to work with time series data on a daily or even weekly basis due to the high irregularity with which users create content on Reddit , we organize our data in pre - post intervention periods , as shown in Figure 1 . We then evaluate the effects of the quarantine by comparing user behavior between the Pre - Q and Post - Q periods , and the combined effects of the quarantine and restriction by comparing user behavior between the Pre - Q and Post - R periods . For consistency with [ 31 ] and the definition of CUs , each period spans 210 days ( 30 weeks ) . The Pre - R period is not used since it overlaps for the most part ( 84 % ) with Post - Q . The Pre - Q , Post - Q , and Post - R periods contain respectively 3 . 32M , 2 . 51M , and 0 . 85M postings . 4 METHODS Our analyses do not aim to establish causal relationships between moderation interventions and user - level behavioral changes . Rather , we seek to describe the associations and significance between the two . Nevertheless , previous studies that used different quasi - experimental methodssupportthe hypothesis thatthe interventions on TD indeed had causal effects at the community - level [ 19 , 29 , 31 ] . Naturally , these effects are the result of changes made by individual users after the interventions . 4 . 1 Characterizing user behavior We evaluate intervention effects in terms of the changes that the quarantine and restriction caused across multiple dimensions of user behavior . In addition to the widely - studied content activity and toxicity , we also evaluate possible effects on the trustworthiness of the news shared by users and on the diversity of the subreddits in which they participate . Posting activity . We measured user - level posting activity as the number of postings ( submissions and comments ) published by a user in a given period . Comment toxicity . Our indicator of toxicity is based on the se - vere toxicity score provided by the well - known Google Perspective API [ 26 ] , which was in part trained based on Reddit comments . Trustworthiness of shared news . To measure the trustworthi - ness of the news shared by users we used the scoring of news WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA Trujillo & Cresci outlets by Media Bias / Fact Check ( MBFC ) . 2 More specifically , we focused on the the user - level average political bias and factual re - porting level of the links shared by CUs . In detail , median scores are computed for each user , based on the links found within the postings made by that user . In MBFC , political bias is measured with an ordinal five - item scale on the US political spectrum , while factual reporting by means of six ordinal scores ranging from very low to very high factuality . To obtain the most representative level of users on each feature , we used the user - median on the ordinal scales . In cases in which the median was fractional , we rounded towards the user - mean level . Subredditdiversity . Subredditsrepresentcommunitieswithshared interests , values , and moderation practices [ 33 ] . We are thus in - terested in studying if and how users changed their participation in subreddits across the platform , after the interventions . Further - more , measuring diversity in participation is important , since lack of diversity is linked to the emergence of echo chambers [ 24 ] . We measure subreddit participation diversity in a given period via the Hill diversity index [ 18 ] , which extends and unifies various met - rics traditionally used for diversity , including richness ( the mere count of types ) , Shannon index ( a measurement of entropy ) , and Gini - Simpson index ( a probability ) . We adapt the Hill diversity to measure user participation in subreddits as : 𝑞 𝐷 = (cid:32) 𝑆 ∑︁ 𝑖 = 1 𝑝 𝑞𝑖 (cid:33) 1 / 1 − 𝑞 where 𝐷 is diversity ; 𝑞 is the order of the diversity ( increasing 𝑞 generally results in more weight given to abundant subreddits ) ; 𝑆 is the number of distinct subreddits ( richness ) ; and 𝑝 𝑖 is the relative abundance of subreddit 𝑖 . When 𝑞 = 1 , the index 1 𝐷 is called Hill - Shannon diversity because it is linked to the Shannon index 𝐻 ′ , as 𝐻 ′ = ln ( 1 𝐷 ) . Herein we use 1 𝐷 given its balance between rare and abundant subreddits , with values ranging from 1 when a given CU participates exclusively in a single subreddit , to richness 𝑆 when there is an equal proportion among subreddits in which a user participates . We remark that our data allows measuring subreddit diversity only in terms of active user participation ( i . e . , posting submissions and comments ) . As such , some users exhibiting low diversity might still passively browse many subreddits . 4 . 2 Quantifying effects When presenting results , we use the median ( ˜ 𝑥 ) to indicate the cen - tral tendency of a distribution ; the median absolute deviation ( mad ) to indicate the spread ; Kendall’s 𝜏 coefficient for association signifi - cance between two dimensions ; one - sided Wilcoxon signed - rank test ( 𝑉 ) for paired data ( of the same user ) before and after interven - tion ; and Wilcoxon - Mann - Whitney test for group independence ( 𝑍 ) between different groups of users . For the figures , we aimed to display all individual users while making evident the outliers , as these individuals can greatly influence the value of an indicator when measured at the community level . Naturally , this also extends to intervention effects , which we define as changes in a dimension of user behavior between pre - post intervention periods . 2 https : / / mediabiasfactcheck . com / Indicator of change . Changes in numeric variables are usually measured either in absolute or relative terms . However , both have important limitations since absolute change by itself is seldom use - ful without a value of reference , whereas relative change ignores the magnitude of change and it is not antisymetric . Logarithmic differences are an antisymetric alternative , but they also ignore the magnitude of the change . For these reasons , usually both absolute change and relative change ( or log differences ) are used as indica - tors of change . Here , we utilize a single change indicator recently proposed by Brauen et al . [ 5 ] , which takes into account both magni - tude and relative differences : the function 𝐹 𝜆 ( 𝑎 , 𝑏 ) , with 𝜆 ∈ [ 0 , 1 ] , a unitless antisymetric indicator of the change experienced by a variable 𝑥 ∈ R when passing from value 𝑎 to 𝑏 . It is defined as : 𝐹 𝜆 ( 𝑎 , 𝑏 ) =    𝑏 1 − 𝜆 − 𝑎 1 − 𝜆 1 − 𝜆 if 𝜆 ≠ 1 ln ( 𝑏 / 𝑎 ) if 𝜆 = 1 𝐹 𝜆 ( 𝑎 , 𝑏 ) interpolates between absolute change ( 𝜆 = 0 ) and log - arithmic differences ( 𝜆 = 1 ) . For our analyses we use 𝜆 = ½ in order to interpolate midway between the two , with the indicator of change 𝐹 ½ used herein being : 𝐹 ½ ( 𝑎 , 𝑏 ) = √ 𝑏 − √ 𝑎 ½ 5 RESULTS In the following subsections we present the results regarding the change of posting activity , subreddit diversity , and comment toxic - ity , as well as a description of the sharing of news links in terms of factual reporting and political bias . In addition , based on the large decrease in posting activity , we also delve into an analysis of user account inactivation , which is the ceasing of all platform - wise activity following the quarantine and restriction . Then , we discuss these results and their implications in Section 6 . Since many users reduced or ceased their activity after the inter - ventions , or never shared a link to a news outlet present in MBFC , we could not compute all the indicators for every user and every period . Hence , when illustrating results for some indicators , we report the number of active users ( 𝑛 ) involved in the analysis . 5 . 1 Posting activity In aggregate , the median user activity before the quarantine ( Pre - Q ) was 1 , 051 postings ( mad = 833 ) . Median user activity decreased to 711 ( mad = 682 ) in Post - Q and dropped to 51 ( mad = 76 ) in Post - R , demonstrating the effectiveness of the two interventions at reduc - ing user activity , in agreement with previous community - level results [ 31 ] . When analyzing effects at the user level , we see that the majority of users ( 72 % ) decreased their activity after the quar - antine , with a median change 𝐹 ½ = - 8 . 8 ( mad = 15 . 8 ) , corresponding to a median for absolute change of - 217 ( mad = 438 ) and for relative change of - 0 . 26 % ( mad = 0 . 41 ) . Some users ( 𝑛 = 18 ) stopped posting altogether , as shown in Figure 2a . Some even manifested extreme activity changes . The user with the highest increase ( 𝐹 ½ = 131 ) went from 1 . 4k postings in Pre - Q to 10 . 6k in Post - Q , whereas the one with the highest decrease ( 𝐹 ½ = - 239 ) went from 18k to 311 . One of Many : Assessing User - level Effects of Moderation Interventions on r / The _ Donald WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA 10 0 10 1 10 2 10 3 10 4 10 0 10 1 10 2 10 3 10 4 Pre−Q P o s t − Q −200 −100 0 + 100 x ~ = −8 . 8 c hange F ½ ( a ) User activity before and after the quarantine . 10 0 10 1 10 2 10 3 10 4 10 0 10 1 10 2 10 3 10 4 Pre−Q P o s t − R −200 −100 0 + 100 x ~ = −41 . 3 c hange F ½ ( b ) User activity before the quarantine and after the restriction . Figure 2 : Platform - wise activity of all users around the quarantine ( a ) and both interventions ( b ) . In the scatter plots , each dot represents a user and the axes represent the number of postings in the pre - post intervention periods . Dots below the main diagonal are users who decreased their activity and those above vice versa . Users who ceased activity are squished at the bottom . Marginal distributions are shown as density strips . In the adjacent univariate beeswarm plots , each dot represents a user , positioned and colored according to the value of their activity change 𝐹 ½ . When considering both interventions ( Figure 2b ) , 89 % of the users decreased their activity , as can be seen by the remarkable drop in 𝐹 ½ ( ˜ 𝑥 = - 41 . 3 ; mad = 26 ) . Moreover , a notable number of users ( 𝑛 = 407 ) ceased activity in Post - R . The beeswarm plot of Figure 2b shows the distribution of user - level activity changes . In comparison with that of Figure 2a , we see that the sequence of both interventions had stronger effects ( ˜ 𝑥 = - 41 . 3 vs ˜ 𝑥 = - 8 . 8 ) than the quarantine alone . Interestingly , we also note that the distribution of 𝐹 ½ is much more spread out ( mad = 26 vs mad = 15 . 8 ) , with many users exhibiting important changes in activity ( both decreases and increases ) . In addition , although most users were consistent in their direction of change , some manifested contrasting changes . In detail , 42 users decreased activity after the quarantine , but increased it after the restriction , whereas 525 did the opposite . Finally , we measured no correlation between account age and activity , or change in activity , for each intervention , with 𝜏 being close to 0 and 𝑝 > . 28 in all cases . 5 . 2 Subreddit diversity Overall , we measured a low median subreddit diversity in Pre - Q ( ˜ 𝑥 = 2 . 8 ; mad = 2 . 7 ) , meaning that the majority of users showed a strong preference for a very limited number of subreddits . As an example , 123 users ( 5 % of the total ) participated exclusively in TD during this period . These findings might support the existence of political echo chambers . As such , they appear to contradict pre - vious studies that reported no evidence of echo chambers among Reddit supporters of Donald Trump [ 12 ] . We note however that conclusive results on this regard would mandate a detailed analysis of the aforementioned accounts , which could simply be bogus or throwaway accounts specifically created by some users to remain anonymous within TD . We measured a weak , yet significant , positive correlation be - tween subreddit diversity and posting activity ( 𝜏 = . 18 ; p ≪ . 01 ) , as n = 1795 ; x ~ = 0 . 95 n = 2221 ; x ~ = 0 . 00 a r ound i n t e r v en t i on s a r ound qua r an t i ne −20 −10 0 + 10 + 20 diversity change F ½ Figure 3 : Change in subreddit diversity for active users . Af - ter both interventions , remaining users participated more in other subreddits ( in many cases considerably much more ) . well as between diversity and account age ( 𝜏 = . 12 ; p ≪ . 01 ) . Inter - estingly , we note that the diversity for users who ceased activity after the restriction was significantly lower ( Z = - 11 . 10 ; p ≪ . 01 ) with respect to that of the users who kept on posting on Reddit . In other words , the less diverse a user is in their subreddit participation habits , the more likely they are to stop activity on Reddit after the restriction . With reference to the 123 users who participated only in TD , 56 of them ( 46 % ) ceased activity in Post - R . User - level changes ( 𝐹 ½ ) in subreddit diversity can be computed only for those users who stayed active after one or both moderation interventions . For active users after the quarantine , we measured a balanced change in diversity ( ˜ 𝑥 = 0 ; mad = 0 . 54 ) , as shown in the top row of Figure 3 . When considering both interventions we found a moderately positive ( ˜ 𝑥 = . 94 ; mad = 1 . 86 ) change in diversity , mean - ing that after the restriction active users participated in an increased number of subreddits . As visible from the bottom row of Figure 3 , WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA Trujillo & Cresci n = 1777 ; x ~ = −0 . 03 n = 2214 ; x ~ = −0 . 01 a r ound i n t e r v en t i on s a r ound qua r an t i ne −0 . 5 0 . 0 + 0 . 5 + 1 . 0 + 1 . 5 toxicity change F ½ Figure 4 : Change in comment toxicity for active users . De - spite still being balanced in direction , after both interven - tions the change was asymmetrical , with many users re - markably increasing their toxicity . the majority of outliers also had positive changes . Indeed , the over - all median diversity increased from 2 . 8 in Pre - Q to 6 . 7 ( mad = 7 . 4 ) in Post - R . These results are consistent with work at the community level [ 31 , § 5 . 3 . 5 ] . 5 . 3 Comment toxicity In Pre - Q , the median user toxicity score was . 060 ( mad = . 02 ) , which decreased slightly but steadily both in Post - Q ( ˜ 𝑥 = . 058 ; mad = . 02 ) and Post - R ( ˜ 𝑥 = . 052 ; mad = . 02 ) . As shown in the top row of Figure 4 , user - level changes in toxicity after the quarantine were mostly symmetrical and concentrated in the region of 𝐹 ½ = 0 , meaning that the vast majority of users only manifested minor changes and that users who increased their toxicity were counterbalanced by a similar number of users who decreased it . Nonetheless , the figure also shows a couple of outlier users ( dark - colored ) who increased their toxicity substantially ( 𝐹 ½ ≃ 0 . 75 ) . Conversely , considering both interventions surfaces important differences between the effects manifested by the majority of the users and those manifested by the outliers . In fact , the majority of users slightly decreased their toxicity after the restriction , as demonstrated by a median 𝐹 ½ = - 0 . 03 . At the same time , the bottom row of Figure 4 shows that a significant number of users diverged from the bulk of the distribution . The majority of such divergent users manifested strong increases in toxicity , while a minority man - ifested moderate decreases . In other words , this result highlights that , when evaluated at the community level , the restriction caused a slight toxicity decrease . However , the user - level analysis reveals that a significant number of users strongly increased their toxicity , in spite of the opposite community effect . Incidentally , at the commu - nity level there was a surge in toxicity around the beginning of the George Floyd protests [ 31 , § 5 . 3 . 2 ] , thus it is likely that the outliers who increased their toxicity did so due to these events . This is an example of an exogenous event that can render more challenging the study of causality between intervention effects and changes in user behavior . There was no significant correlation between the number of comments and the toxicity of users in any of the three periods ( 𝜏 ≈ . 01 ; p > . 14 ) . In Pre - Q , there was a very weak signifi - cant negative correlation between subreddit diversity and toxicity ( 𝜏 = - 0 . 09 ; p ≪ . 01 ) , meaning that users with less diverse subreddit periods Pre - Q / Post - Q Pre - Q / Post - R ˜ 𝑥 mad ˜ 𝑥 mad posting activity - 8 . 8 15 . 8 - 41 . 3 25 . 9 subreddit diversity + . 005 . 535 + . 946 1 . 856 comment toxicity - . 006 . 037 - . 026 . 079 Table 1 : User - level median and spread values of behavior change indicators 𝐹 ½ . participation habits had a slight tendency to be more toxic . Table 1 contains a summary of the change indicators of user - level posting activity , subreddit diversity , and comment toxicity . 5 . 4 Trustworthiness of shared news For the three periods of interest ( Pre - Q , Post - Q , and Post - R ) there was a total of 372k submissions . Circa 220k submissions had an external link ( i . e . , pointing outside of Reddit ) , with 23k of links pointing to a news outlet contained in the MBFC repository . The vast majority of these links pointed to news outlets labeled as questionable sources ( 64 % ) or as politically biased ( 32 % ) . The rest of the links ( 4 % ) pointed to news outlets classified as either satire , conspiracy / pseudoscience , or pro - science . To investigate intervention effects on the factuality of the shared news , we associated each user to a news factual reporting score from MBFC . For each user , the factuality score is computed as the median of the factuality scores of the news outlets that the user linked in their submissions . Figure 5 shows , for each period , the re - lationship between user factuality scores and the number of shared links . This analysis allows evaluating whether users sharing more or less factual news are more or less prolific than others . In addition , it also allows assessing whether the moderation interventions on TD altered this relationship in some way . Throughout all three periods the most common user factuality score was low , as shown in Figure 5 ( orange - colored distributions ) . Users sharing low factu - ality news accounted for 48 % of all users in Pre - Q , 51 % in Post - Q , and 71 % in Post - R , demonstrating a steady increase . The second most common factuality score was mixed , which went from 46 % in Pre - Q , to 42 % in Post - Q , and 22 % in Post - R . The combination of the remaining scores accounted for < 7 % of users in all three periods . This analysis highlights that the sequence of interventions on TD resulted in a remarkable fraction of users sharing relatively less factual news , particularly because many users who had an average mixed factuality passed to an average low factuality , with a respec - tive difference of – 24 and + 23 percent points . When considering the number of shared links per user , we observe that the most pro - lific users are those with a mixed factuality score . This is reflected in Figure 5 by the spread and the outliers of the yellow - colored distributions . This phenomenon is mostly visible in Post - R , where the top - 5 link sharers ( representing 0 . 6 % of the 878 active users ) all had mixed factuality and published more than a thousand posts each , producing 28 % of all the links shared in that period . We repeated this analysis also for the political bias of the shared news . Perhaps surprisingly , Figure 6 shows that the majority of One of Many : Assessing User - level Effects of Moderation Interventions on r / The _ Donald WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA n = 1752 46 % 48 % 3 % 2 % < 1 % 1 % n = 1630 42 % 51 % 2 % 4 % < 1 % < 1 % n = 878 22 % 3 % 3 % 71 % < 1 % < 1 % Pre−Q Post−Q Post−R 1 10 100 1000 user share of factual reporting levels by period li n ks w / f a c t ua l r epo r t i ng pe r u s e r user−average factual reporting very low low mixed mostly factual high very high Figure 5 : User - average factual reporting level of shared news outlets for active users . Each dot represents a user , colored based on their most representative level and positioned according to the number of news links shared . Percent values represent the proportion of users with an average factuality level for a given period . Medians and interquartile ranges are shown in black . n = 920 26 % 31 % 20 % 20 % 3 % n = 778 23 % 22 % 25 % 28 % 2 % n = 239 19 % 19 % 16 % 44 % 2 % Pre−Q Post−Q Post−R 1 10 100 1000 user share of political bias levels by period li n ks w / po li t i c a l b i a s pe r u s e r user−average political bias left left−center least biased right−center right Figure 6 : User - average political bias level of shared news outlets for active users . Each dot represents a user , colored based on their most representative level and positioned according to the number of news links shared . Percent values represent the proportion of users with an average bias level for a given period . Medians and interquartile ranges are shown in black . link share ( % ) user - average bias Pre - Q Post - Q Post - R left 1 . 6 0 . 2 0 . 9 left - center 16 . 2 14 . 5 16 . 2 least biased 32 . 3 19 . 6 14 . 1 right - center 18 . 0 28 . 8 34 . 8 right 31 . 9 36 . 9 34 . 0 Table 2 : Link share of politically biased news . For each successive period the share of links by users who publish mainly right - center and right leaning outlets increases . users had a median left - center ( light - blue ) political bias . They ac - counted for 31 % of all users in Pre - Q , 28 % in Post - Q , and 44 % in Post - R . Regarding extremely biased users , we note a strong preva - lence of right biased users in all three periods , accounting for 20 % of all users in Pre - Q , 22 % in Post - Q , and 16 % in Post - R . Left biased users always accounted for ≤ 3 % of all users . The analysis of the most prolific users reveals an interesting trend . In all three periods , the users that shared the largest number of links always laid at the right side of the political spectrum , as shown by the fat tails , and by the presence of many outliers , in the distributions of the user with right - center and right political bias . As already observed for factual reporting , this phenomenon is particularly prevalent in Post - R . As visible from the rightmost panel of Figure 6 , the more WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA Trujillo & Cresci Q Post - Q Aux Post - R R 30 weeks 65 weeks inactivation window Figure 7 : We marked as inactivations those users who last posted content within the 65 weeks after the quarantine ( Q ) , taking also into account activity within an auxiliary period of 30 weeks beyond the period after restriction ( R ) . biased towards the right a user is , the more prolific they are . As an example , the top - 2 users who shared the most links in Post - R , respectively 696 and 643 links , are right biased and accounted for 25 % of all links shared in that period . This phenomenon is also visible in Table 2 , which reports the percentage of links shared for each class of political bias , in each period . Notably , the sum of the right - center and right biased links accounted for 49 . 9 % of all links in Pre - Q , 65 . 7 % in Post - Q , up to 68 . 8 % in Post - R , demonstrating that the moderation interventions on TD caused a progressive po - larization of the affected users . The percentage of left - center and left biased links remained roughly the same throughout the three interventions , while least biased links decreased steadily . 5 . 5 User account inactivation Due to the important reduction in active users , we delved into the effects of the interventions on user account inactivations . To this end , we collected additional data corresponding to the CUs activity during an auxiliary period covering 30 weeks following the end of Post - R ( i . e . , 65 weeks after quarantine ) . We then derived the last date in which a user published a posting in Reddit during this ex - tended time frame of 95 weeks . Finally , we defined as inactive users those whose last posting date was within the 65 weeks following the quarantine , up to the end of the Post - R period , as depicted in Figure 7 . At the platform level , we identified three kinds of user account inactivations : abandoned , deleted , and suspended . In an abandoned account a user simply stopped posting content to the platform . In a deleted account the user deliberately inactivated their account via the platform . In that case it can’t be reactivated , their username becomes unavailable , and they lose access to their account and posting history , and all postings are disassociated from the user but remain on the platform . If the user would like to delete the contents of the postings , they would need to do so prior to account dele - tion . In a suspended account , a Reddit administrator has forcefully shut the account , following violations of the platform’s policies . To derive the account status of all CUs , we used the official Reddit API . During the 65 weeks after quarantine , there were 1 , 121 account inactivations , slightly more than half of the initial core users , with 691 ( 62 % ) being abandoned , 348 ( 31 % ) deleted , and 82 ( 7 % ) sus - pended . As shown in Figure 8 , most of the inactivations ( 62 % ) oc - curred within the 30 weeks of the Post - R period , mostly in the few weeks after the restriction . Regarding the Post - Q period , interest - ingly most inactivations occurred after the launch of the forum thedonald . win by former members of TD , most likely due to the launch of TheDonald . win 1000 2000 a c t i v e u s e r s quarantine restriction ban 0 50 100 20 40 60 weeks since quarantine i na c t i v a t i on s abandoned deleted suspended Figure 8 : Time series of remaining active core users ( top line chart ) and corresponding user account inactivations ( bot - tom area chart ) after the quarantine and restriction . For completeness , we also include the ban , which did not have a visible effect on inactivations , unlike the launch of the fo - rum TheDonald . win by former members of the subreddit . migration of many of the subreddit users to the newly created plat - form [ 19 ] . In addition , in contrast to the trend of most of the time frame , upon launch of the forum , most inactivations were in the form of deleted accounts instead of abandoned ones , with 43 % and 39 % respectively in the following month . During the Pre - Q period , inactivated users published less post - ings , both by total of postings ( 1 . 59M vs 1 . 73M ) and by user - level median ( 980 vs 1 , 109 ) , with the latter being a significant difference ( 𝑍 = - 3 . 84 ; 𝑝 < . 01 ) . Concerning subreddit diversity , inactivated users were also less diverse ( ˜ 𝑥 = 1 . 73 ; mad = 1 . 08 ) compared to re - maining users ( ˜ 𝑥 = 4 . 73 ; mad = 4 . 86 ) . The difference is statistically significant ( 𝑍 = - 17 . 3 ; 𝑝 ≪ . 01 ) . For comment toxicity , on the other hand , there was significant higher toxicity ( 𝑍 = 6 ; 𝑝 ≪ . 01 ) among inactivated users ( ˜ 𝑥 = . 063 ; mad = . 02 ) compared to the remaining active users ( ˜ 𝑥 = . 057 ; mad = . 02 ) . With regards to the trustworthi - ness of shared news , we used the Cochran – Armitage test ( 𝑍 𝐶 ) to check for significant differences in user - average factual reporting and political bias by inactivation status . In general , remaining active users shared content leaning to the left of the US political spectrum compared to inactivated users ( 𝑍 𝐶 = - 3 . 1 , 𝑝 < . 01 ) . At the same time , remaining users shared news from sources with lower factuality compared to inactivated users ( 𝑍 𝐶 = - 2 . 8 , 𝑝 < . 01 ) . 6 DISCUSSION Our analyses provide novel and nuanced insights into the effects that the quarantine and the restriction had on the core users of One of Many : Assessing User - level Effects of Moderation Interventions on r / The _ Donald WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA r / The _ Donald . Overall , the two interventions had comparable ef - fects , although with different magnitudes . In particular , at the user level both the quarantine and the restriction : ( i ) strongly reduced user activity , ( ii ) slightly increased the diversity of the subreddits in which users participated , ( iii ) very slightly reduced user toxi - city , and ( iv ) led users to share less factual and more politically biased news , especially towards the right side of the political spec - trum . For each of these effects , we found that the restriction had a stronger impact than the quarantine , as demonstrated by the larger median values reported in Table 1 for effects of both inter - ventions ( Pre - Q / Post - R ) with respect to those of the quarantine ( Pre - Q / Post - Q ) . These user - level results mostly confirm previous ones obtained at the community level for the same moderation interventions [ 7 , 19 , 29 , 31 ] . In addition , our analyses also allow to provide answers to our RQ . Community versus user - level effects . An interesting finding of our work is that , for each intervention and for each dimension of user behavior , there were outliers who manifested exaggerated effects and that significantly deviated from the average community reactions . In Table 1 this is reflected by mad values that are larger than the corresponding median , in all but one case ( i . e . , restriction effect on user activity ) . The fact that a minority of outliers man - ifested effects that were several times stronger than those of the other users , implies that aggregated community level effects can be strongly influenced by the behavior of a minority of users . This mandates care when evaluating intervention effects exclusively at the platform or community level , as done in the majority of existing works [ 6 – 8 , 19 , 20 , 28 , 31 ] . In fact , depending on the underlying distribution of user - level effects , aggregated intervention effects might be weakly representative of the general user - level behaviors , being strongly dependent on the behavior of a handful of outliers . Or conversely , community effects could overshadow and conceal the behavior of some user minorities . The former scenario is well documented in the literature about online harms , where it is typical for a minority of fringe users to be responsible for the majority of the harms [ 27 , 37 ] . Instead , the latter possibility relates to Fou - cault Welles’ case for making Big Data small , in that platform and community effects could “silence [ minorities and outliers ] through statistical aggregation” [ 14 ] . In any case , our results suggest that increased attention should be devoted to the user - level effects of moderation interventions , and demand additional efforts for their measurement . Heterogeneous user - level effects . Our results also highlighted that the presence of outliers and fat tailed or highly skewed distribu - tions of user - level effects were more prominent after the restriction on r / The _ Donald and less so after the quarantine . In our quantitative results , this is demonstrated by larger mad values for the effects of the restriction than for those of the quarantine , as reported in Table 1 . Combined with previous findings , this important result tells us that the restriction had stronger effects overall , but also that it was associated with more extreme and diversified user reactions , perhaps also in response to exceptional events in this tumultuous political period , such as the George Floyd protests [ 31 ] . If confirmed in other contexts , this finding can have important practical and ethical implications for the policing of online platforms . Indeed , the choice of a moderation intervention can affect the balance between the effectiveness of the intervention at large , and the extreme — possibly undesired— deviations it might cause to the behavior of some users . A prime example in our work are the different rates at which users ceased to use their account ( be it for abandonment , dele - tion , or suspension ) after interventions or external events linked to the interventions , such as the creation of a more polarized or less moderated alternative online space . For the future , moderators and platform administrators should be aware of this issue and should account for both community and user level reactions when deciding on the enforcement of a moderation intervention . From an ethical standpoint , our results also call for renewed attention on the deli - cate balance between common versus minority good [ 1 ] . Scholars and practitioners are now faced with the question as to whether it is right to risk causing serious harm to a minority of deviant users , in order to obtain a mild benefit for the larger community . Futureworkincontentmoderation . Theresultspresentedherein also have important implications for the design and deployment of future moderation interventions . Specifically , we showed that each intervention , independently of the type and magnitude of its effects , was associated to diverse user reactions . In other words , dif - ferent users reacted differently to the same interventions . Related literature also showed that applying the same intervention to the same users multiple times , was also linked to diverse ( e . g . , reduced ) effects [ 21 ] . The existence of these heterogeneous reactions , which we measured empirically , is consistent with relevant theories from the social and cognitive sciences . These posit that user reactions to moderation interventions and other persuasive efforts are based on each user’s individual characteristics and on the context of the mod - eration [ 25 , 35 ] . Both these theories and our present results suggest that it is unlikely for a single moderation intervention to produce the desired effects ( e . g . , toxicity reduction ) for all moderated users . On the contrary , developing targeted interventions that account for individual and contextual characteristics could lead to more effec - tive and user - centered content moderation processes . For example , with respect to our previous discussion on minorities and outliers , future research could aim at designing moderation interventions that are capable of reaching community goals without sacrificing those of the individual users . To this end , our results support the re - cent experimentation with diversified moderation interventions [ 3 ] and the proposal of personalized content moderation [ 11 ] . 7 CONCLUSIONS We evaluated the effects that the quarantine and the restriction had on the core users of r / The _ Donald . Differently from previous work , we assessed effects at the user level , finding that the interventions produced some of the intended outcomes , including the reduction of user activity and toxicity , and the increase in the diversity of the subreddits in which users participated . However , both interventions also produced some unintended effects , as they led remaining users to proportionally share less factual and more politically biased news . Our results also highlighted that the interventions that appeared as overall more effective ( i . e . , that produced stronger effects ) were also associated with more varied user reactions . We conclude that platform and community level effects are not always representative of the underlying behavior of individuals or smaller user groups . We discussed the practical and ethical implications of our findings , WebSci ’23 , April 30 - May 1 , 2023 , Austin , TX , USA Trujillo & Cresci which hopefully motivate future research and experimentation on diversified and personalized content moderation . In addition , the existence of very diverse user reactions bears the question as to why such differences exist in the first place , and what are the char - acteristics that differentiate users who react differently . A limitation of our work is the focus on core users who were actively involved in a subreddit for a prolonged time ( and who produced the most con - tent ) , but which excludes users with less prominent participation levels ( and the respective intervention effects on these ) . In addition , our data features matched samples of users in multiple interven - tion periods , which lends itself to more sophisticated analyses with mixed models . Focusing on these aspects represents a promising direction for future work and experimentation . REFERENCES [ 1 ] Claire Andre and Manuel Velasquez . 1992 . The common good . Issues in Ethics 5 , 2 ( 1992 ) . [ 2 ] Jason Baumgartner , Savvas Zannettou , Brian Keegan , Megan Squire , and Jeremy Blackburn . 2020 . The Pushshift Reddit dataset . In AAAI ICWSM . [ 3 ] MichalBilewicz , PatrycjaTempska , GniewoszLeliwa , MariaDowgiallo , Michalina Tanska , Rafal Urbaniak , and Michal Wroczynski . 2021 . Artificial intelligence against hate : Intervention reducing verbal aggression in the social network environment . Aggressive Behavior 47 , 3 ( 2021 ) . [ 4 ] Catherine Blaya . 2019 . Cyberhate : A review and content analysis of intervention strategies . Aggression and Violent Behavior 45 ( 2019 ) . [ 5 ] Silvan Brauen , Philipp Erpf , and Micha Wasem . 2020 . On absolute and relative change . arXiv : 2011 . 14807 [ 6 ] StevieChancellor , JessicaAnnettePater , TrustinClear , EricGilbert , andMunmun De Choudhury . 2016 . # thyghgapp : Instagram content moderation and lexical variation in pro - eating disorder communities . In ACM CSCW . [ 7 ] Eshwar Chandrasekharan , Shagun Jhaver , Amy Bruckman , and Eric Gilbert . 2022 . Quarantined ! Examining the effects of a community - wide moderation intervention on Reddit . ACM TOCHI 29 , 4 ( 2022 ) . [ 8 ] EshwarChandrasekharan , UmashanthiPavalanathan , AnirudhSrinivasan , Adam Glynn , Jacob Eisenstein , and Eric Gilbert . 2017 . You can’t stay here : The efficacy of Reddit’s 2015 ban examined through hate speech . In ACM CSCW . [ 9 ] Stefano Cresci , Roberto Di Pietro , Marinella Petrocchi , Angelo Spognardi , and Maurizio Tesconi . 2020 . Emergent properties , models , and laws of behavioral similarities within groups of Twitter users . Computer Communications 150 ( 2020 ) , 47 – 61 . [ 10 ] Stefano Cresci , Roberto Di Pietro , and Maurizio Tesconi . 2019 . Semantically - aware statistical metrics via weighting kernels . In IEEE DSAA . [ 11 ] Stefano Cresci , Trujillo A . , and Tiziano Fagni . 2022 . Personalized interventions for online moderation . In ACM HT . [ 12 ] Gianmarco De Francisci Morales , Corrado Monti , and Michele Starnini . 2021 . No echo in the chambers of political interactions on Reddit . Scientific reports 11 , 1 ( 2021 ) . [ 13 ] Claudia Flores - Saviaga , Brian Keegan , and Saiph Savage . 2018 . Mobilizing the Trump train : Understanding collective action in a political trolling community . In AAAI ICWSM . [ 14 ] Brooke Foucault Welles . 2014 . On minorities and outliers : The case for making Big Data small . Big Data & Society 1 , 1 ( 2014 ) . [ 15 ] Andrew Gelman , Jessica Hullman , and Lauren Kennedy . 2023 . Causal quartets : Different ways to attain the same average treatment effect . Technical Report . Columbia University . https : / / statmodeling . stat . columbia . edu / 2023 / 02 / 24 / causal - quartets - different - ways - to - attain - the - same - average - treatment - effect / . [ 16 ] Ysabel Gerrard . 2018 . Beyond the hashtag : Circumventing content moderation on social media . New Media & Society 20 , 12 ( 2018 ) . [ 17 ] Tarleton Gillespie . 2018 . Custodians of the Internet : Platforms , Content Moderation , and the Hidden Decisions That Shape Social Media . Yale University Press . [ 18 ] Mark O Hill . 1973 . Diversity and evenness : A unifying notation and its conse - quences . Ecology 54 , 2 ( 1973 ) . [ 19 ] Manoel Horta Ribeiro , Shagun Jhaver , Savvas Zannettou , Jeremy Blackburn , Gianluca Stringhini , Emiliano De Cristofaro , and Robert West . 2021 . Do platform migrations compromise content moderation ? Evidence from r / The _ Donald and r / Incels . In ACM CSCW . [ 20 ] Shagun Jhaver , Christian Boylston , Diyi Yang , and Amy Bruckman . 2021 . Evalu - ating the effectiveness of deplatforming as a moderation strategy on Twitter . In ACM CSCW . [ 21 ] Matthew Katsaros , Kathy Yang , and Lauren Fratamico . 2022 . Reconsidering tweets : Intervening during tweet creation decreases offensive content . In AAAI ICWSM . [ 22 ] Nandita Krishnan , Jiayan Gu , Rebekah Tromble , and Lorien C Abroms . 2021 . Research note : Examining how various social media platforms have responded to COVID - 19 misinformation . HKS Misinformation Review 2 , 6 ( 2021 ) . [ 23 ] Joan Massachs , Corrado Monti , Gianmarco De Francisci Morales , and Francesco Bonchi . 2020 . Roots of Trumpism : Homophily and social feedback in Donald Trump support on Reddit . In ACM WebSci . [ 24 ] Antonis Matakos , Cigdem Aslay , Esther Galbrun , and Aristides Gionis . 2020 . Maximizing the diversity of exposure in a social network . IEEE TKDE ( 2020 ) . [ 25 ] Maria D Molina and S Shyam Sundar . 2022 . Does distrust in humans predict greater trust in AI ? Role of individual differences in user responses to content moderation . New Media & Society ( 2022 ) . [ 26 ] Bernhard Rieder and Yarden Skop . 2021 . The fabrics of machine moderation : Studying the technical , normative , and organizational structure of Perspective API . Big Data & Society 8 , 2 ( 2021 ) . [ 27 ] Ronald Robertson . 2022 . Uncommon yet consequential online harms . Journal of Online Trust and Safety 1 , 3 ( 2022 ) . [ 28 ] Haji Mohammad Saleem and Derek Ruths . 2018 . The aftermath of disbanding an online hateful community . arXiv : 1804 . 07354 [ 29 ] Qinlan Shen and Carolyn P Rosé . 2022 . A tale of two subreddits : Measuring the impacts of quarantines on political engagement on Reddit . In AAAI ICWSM . [ 30 ] Mohit Singhal , Chen Ling , Nihal Kumarswamy , Gianluca Stringhini , and Shirin Nilizadeh . 2022 . SoK : Content moderation in social media , from guidelines to enforcement , and research to practice . arXiv : 2206 . 14855 [ 31 ] Trujillo A . and Stefano Cresci . 2022 . Make Reddit Great Again : Assessing com - munity effects of moderation interventions on r / The _ Donald . In ACM CSCW . [ 32 ] Trujillo M . , Sam Rosenblatt , Guillermo de Anda Jáuregui , Emily Moog , Briane Paul V Samson , Laurent Hébert - Dufresne , and Allison M Roth . 2021 . When the echo chamber shatters : Examining the use of community - specific language post - subreddit ban . In WOAH . [ 33 ] Galen Weld , Amy X Zhang , and Tim Althoff . 2022 . What makes online commu - nities ‘better’ ? Measuring values , consensus , and conflict across thousands of subreddits . In AAAI ICWSM . [ 34 ] MarkDWilkinson , MichelDumontier , IJsbrandJanAalbersberg , GabrielleApple - ton , Myles Axton , Arie Baak , Niklas Blomberg , Jan - Willem Boiten , Luiz Bonino da Silva Santos , Philip E Bourne , et al . 2016 . The FAIR Guiding Principles for scientific data management and stewardship . Scientific Data 3 , 1 ( 2016 ) , 1 – 9 . [ 35 ] Emma J Williams , Amy Beardmore , and Adam N Joinson . 2017 . Individual differences in susceptibility to online influence : A theoretical review . Computers in Human Behavior 72 ( 2017 ) . [ 36 ] Savvas Zannettou . 2021 . “I Won the Election ! ” : An empirical analysis of soft moderation interventions on Twitter . In AAAI ICWSM . [ 37 ] Savvas Zannettou , Mai ElSherief , Elizabeth Belding , Shirin Nilizadeh , and Gi - anluca Stringhini . 2020 . Measuring and characterizing hate speech on news websites . In ACM WebSci .