Can Robotic Experimenters help improve HRI Experiments ? An Experimental Study Dan R . Suissa 1 ∗ , Shikhar Kumar 2 ∗ and Yael Edan 2 Abstract —To evaluate the design and skills of a robot or an algorithm for robotics , human - robot interaction user studies need to be performed . Classically , these studies are conducted by human experimenters , requiring considerable effort , and introducing variability and potential human error . In this paper , we investigate the use of robots in support of HRI experiments . Robots can perform repeated tasks accurately , thereby reducing human effort and improving validity through reduction of error and variability between participants . To assess the potential for robot - led HRI experiments , we ran an HRI experiment with two participant groups – one led by a human experimenter and another led mostly by a robot experimenter . We show that the replacement of several repetitive experiment tasks through robots is not only possible but beneficial : Trials performed by the robot experimenter had fewer errors and were more fluent . There was no statistically significant difference in participants’ perception w . r . t . cognitive load , comfortability , enjoyment , safety , trust and understandability between both groups . To the best of our knowledge , this is the first comparison between robot - led and human - led HRI experiments . It suggests that using robot experimenters can be beneficial and should be considered . Keywords— Human - Robot Interaction ; Autonomous Exper - iments ; Human - Centered Robotics ; Acceptability , Trust , Flu - ency ; I . I NTRODUCTION The domain of human - robot interaction ( HRI ) involves designing , evaluating and understanding the usage of robots , through experiments [ 1 ] following rigorous methodology to obtain knowledge [ 3 ] . To evaluate the design and skills of a particular robot or function of an algorithm , often , a user study needs to be performed . A strict procedure has to be fol - lowed from the time participants start the experiment to the end of it [ 14 ] . Experimenters in HRI studies must precisely follow the ”experimental scripts” to remove variability from their influence on the results as much as possible . These studies are classically conducted with a human as the experimenter [ 14 ] and examples are manifold , e . g . , [ 5 ] , [ 8 ] , [ 11 ] , [ 12 ] . Conducting a user experiment requires repetitive actions on the experimenter part . For example : the greeting of participants , filling of forms and questionnaires , instructions regarding purpose and background of the ex - periment and its procedure , starting the experiment ( robots and other technology ) , observing it , taking notes , ensuring 1 Dan is with the Department of Computer Science , Ben - Gurion Uni - versity of the Negev , Be’er Sheva , Israel danrouve @ bgu . ac . il , dan . rouven . suissa @ gmail . com 2 Shikhar and Yael are with the Department of Industrial Engineering and Management , Ben - Gurion University of the Negev , Be’er Sheva , Israel shikhar and yael @ bgu . ac . il ∗ Equal Contribution its safety , and so on [ 14 ] . This is obviously a lot of effort and tedious work . More importantly , we humans are bound to make mistakes in these repetitive tasks and they are under influence of human - human interactions . Also , if experiments are performed on consecutive days or are to be repeated at other times and locations , the experiment conditions will very likely vary . This is unfortunate , as it is important to ensure identical experimental conditions for all participants . In an effort to improve consistency and validity , and to reduce human effort , we investigated adding robotic experi - menters to support us while conducting an HRI study . An autonomous robot experimenter could have several benefits : • potential to make less mistakes • reduces variability between trials • reduce human - human influence • allows for precise replicability 1 • allows for sharing of experiments 2 • reducing effort for human experimenters To this end , we compare the influence of performing the repetitive tasks of the experiment with a robotic experi - menter . We repeat the same HRI experiment , once led by a human experimenter and once led mostly by a scripted au - tonomous robot experimenter . To the best of our knowledge , this is the first time that a direct comparison of human and robot experimenters for HRI studies is conducted . II . AUTOMATING HUMAN - ROBOT INTERACTION EXPERIMENTS The general idea to automate experiments through robotics is not new , however in HRI the idea is under - explored with respect to the automation of experiment tasks and the experiment procedure . We only found one study where two robots were recruiting bystanders as audience to watch and rate the comedic value of their comedy show [ 16 ] . The robots conducted their own human experiments in that they queried the audience after displaying experimentally balanced episodes of relational humor . This study partially shows the viability of robots conducting their own exper - iments by recruiting participants off the street . However , it does not treat a structured HRI experiment , there is no experimenter and thus it does not test for and discuss the automation of HRI experiments through robotics . 1 at any time and location with suitable robots 2 directly via code a r X i v : 2311 . 14454v1 [ c s . R O ] 24 N ov 2023 This leads us to our proposal , for which we first discuss the typical procedure of HRI experiments [ 14 ] : After initial greetings , participants are usually filling consent forms . After their consent , often participants need to fill further forms and a preliminary questionnaire , which inform on their back - ground and biases . If needed , participants are equipped with physiological measuring devices before they move towards the experiment area , and usually they are recorded with video and audio during the experiment . Then after completion of ( a part of ) the experiment the participants fill further questionnaires , which are now related to the experiment . This might be repeated several times . The experimenter finally conducts an interview and debriefs the participants . Note , that some experiments require the same participants to come multiple times and experience an experiment consecutively or with different setting . We propose , that most of the above steps that are repeated during each experiment , can be automated using robots . This frees up us humans conducting the experiment to focus on observation tasks rather than repetitive explanations and procedure . In our experiments we automated all these tasks , leaving us with only : the greeting , consent and a final debrief - all outside the lab ( outside the experiment space ) . An automated HRI experiment includes the actor robot ( s ) of the HRI experiment itself and at least one experimenter robot which supports the human experimenter ( s ) . Note , that sometimes the actor robot can also fulfill the role of the experimenter robot ( like in [ 16 ] ) . Also note , that the influence of having a robot run its own experiment versus adding robots to run the experiment ( our approach ) is beyond the scope of what we review in this study . III . METHODS The comparative experiments took place in the Au - tonomous Multi Robot Lab in the Industrial Engineering Department . A scene from the experiment and the experi - mentation area layout can be seen in Fig . 1 . A . Experimental Design We conducted a between - groups user study , comparing a human experimenter ( HE ) with a robot experimenter ( RE ) . This comparative study was build around a rather simple HRI experiment , identical for both groups , it included a short physical training session with the Gymmy robot [ 4 ] , [ 20 ] ( see Fig . 2 ) . Participants in both groups ( HE and RE ) were not informed about the existence of groups or the comparative experiment . Both groups were greeted by us , signed consent and then entered a lab in which they would either meet HE or RE . After the experiment within the lab , they would exit , fill a final questionnaire and get a short debrief ( not to inform other students on the nature of their experiment ) . This means that for all students , the experiment took place in a separate space to the greeting area and for RE , during the stay in the lab , this would mean not observing any other humans . We opted for a non - humanoid , mobile robot with speakers and a screen as RE ( Wyca Keylo tele - presence robot ) . A research assistant who was compensated by the university , was recruited as HE . The experiments were conducted on three consecutive days ( from 10am to 4pm with a 1h lunch break ) . A single experiment would last on average less than 20 minutes . On the first day the HE would start and on the second the RE – they would switch after lunch . On day three we performed four more HE experiments before lunch . During all experiments , for observation and safety reasons , a further human observer was present , unnoticed by the participants ( within the lab ) . Fig . 1 : Picture of the autonomous HRI environment . With the robot experimenter Keylo on the right hand side and a participant training with Gymmy , the robotic physical trainer ( in the training experiment ) . During the stay in the experiment area ( lab ) , the pro - cedure was the same for both groups ( HE , RE ) . First , participants would enter the lab where the experimenter welcomed them with a pre - defined text . Then , the experi - menter guided towards a computer where participants filled the pre - experiment questionnaire . All questionnaires , were provided using Google forms . See supplementary material 3 , for questionnaires . After completion of the first question - naire , the experimenter instructed the participants about the HRI experiment and start the Gymmy robot . Then the training would take place ( see Fig . 1 , participant training with Gymmy ) . After finishing the training experiment ( see next subsection ) , the experimenter would guide the participants back to the questionnaire computer . Participants would fill a first post experiment questionnaire ( denoted ”internal” ) . This questionnaire was rating the interaction / training with the Gymmy robot . Then , the experimenter would thank the participants and send them out of the lab – concluding the HRI experiment . Finally , participants would fill a last post experiment questionnaire once outside ( denoted ”external” ) . The participants were instructed that this questionnaire was about the whole experience inside the lab . Thus they rated the interaction with the experimenter ( HE or RE ) and the procedure itself concluding the comparative experiment . B . Gymmy Training Experiment We simplified and repeated an experiment conducted with Gymmy , a physical training robot , which was originally designed for older adults [ 4 ] . In the original experiment , participants would absolve a physical training with feedback 3 https : / / github . com / D - R - S / ahri _ supplement . git and a cognitive game . We removed the cognitive game from the experiment as well as the feedback the robot would give the participants . This left us with a five minute experiment of physical training of the upper body . It included five exercises with one set of eight repetitions each . We chose this experiment of reduced complexity to ensure that each participant would perceive the training experiment in a similar way – simple and quick . Thus , the completion of the internal experiment would have a similar influence on the overall study for all participants . Besides that , the chosen experiment had a high probability of success 4 . We collected data via questionnaires , videos and in addition , the Gymmy robot acquired automatically video and motion capture data . This data can inform on the use of the Gymmy robot with younger adults ( instead of the elderly for which it was originally purposed ) . It is important to note , that both the physical training as well as the cognitive game we omitted , are perceived as trivially easy by most ( healthy ) younger adults – which we were aware of beforehand and based on which we opted for this experiment . Fig . 2 : Picture of the Gymmy physical trainer as used in the training experiment . C . Robot Experimenter The RE supported us in all our tasks . To create our RE we used a Wyca Keylo tele - presence robot 5 ( see Fig . 3 ) . The approximate height of the robot is 1 . 64 m with a circular footprint of 52 cm diameter . It has 24 ” multi - point high touchscreen . It has two front cameras and one rear 3D RGB - D camera . Note , that the robot is capable of navigating autonomously , which we did not make use of . In future studies , the capability to move around within the experiment area is one point that distinguishes RE based experiment automation from automation of experiments via a simple computer ( e . g . tablet or labtop ) . A computer screen as experimenter ( Computer Experimenter , CE ) , would have technically sufficed for the experiment tasks we conducted via RE ( e . g . , automation of explanations via video and sound ) . However , prior work has shown that ( beyond their 4 In our experiments the training HRI experiment showed a success rate of 1 . 0 5 https : / / www . wyca - robotics . fr / movement capabilities ) robots bring unique benefits to the table compared with CE ( please see discussion section ) . We scripted the full interaction in Python ( i . e . , the full experiment procedure ) using the opencv computer vision library 6 , google text to speech library ( gTTS ) 7 as well as the tkinter library to display text and images on the screen 8 . We produced a fully autonomous robot experimenter , that required us only to turn it on once in the begging of a trial session ( it switches automatically from participant to partic - ipant ) . Note , that we opted for a scripted interaction rather than e . g . , a large language model ( LLMs ) to standardize the interaction ( and not have any randomness in the text ) . Even to the same prompt , LLMs might produce different answers – which is exactly what we want to reduce in our study . Note also , that a robot experimenter has the benefit of introducing varying experimental conditions in a controlled manner – which we did not make use of in our study . During a trial of our experiment , the robot , placed centrally facing the door would wait until it identified a human face , which ( if seen for enough consecutive frames ) would trigger a displayed and spoken text . This would happen four times , in the following order : When the participants entered the lab it would trigger the first text – 1 . Introduction and Pre - Experiment Questionnaire . When participants finished the questionnaire and came back to the robot it would trigger the second text – 2 . Training experiment explanation . After participants completed the training experiment , they would come back to the robot and the third text was triggered – 3 . Internal post experiment questionnaire . Finally , upon seeing the participants a last time after completion of the Questionnaires , it would trigger the last text – 4 . Farewell message . When the second text is triggered it also starts the training experiment ( starts the Gymmy robot ) . When the fourth text is triggered it starts a timer , which at its end resets the RE . When a text is finished , the RE waits for a certain time before the next text can be triggered . The RE instructed the participants to return to it , after the questionnaires and after the training experiment – in order to trigger the next phase . D . Participants A total of 33 undergraduate industrial engineering students participated in the experiment . For their participation , which was voluntary , they were compensated with one bonus point to their grade in a course . The experiment was publicized via the course page and open for registration to all . Participants were all aged 24 - 30 years old ( mean : 26 . 7 ± 1 . 29 ) , 14 male and 19 female . The participants were randomly split into two groups ( HE , RE ) . Group HE consisted of 18 students ( 6 male , 12 female and age : 26 . 61 ± 1 . 42 ) and group RE consisted of 15 students ( 8 male , 7 female and age : 26 . 8 ± 1 . 15 ) . Prior to the experiment they only received the information that they would participate in a physical training HRI experiment ( with the Gymmy robot ) . The study design was approved by the 6 https : / / opencv . org / 7 https : / / gtts . readthedocs . io / en / latest / 8 https : / / docs . python . org / 3 / library / tkinter . html Fig . 3 : Picture of a Participant interacting with the Wyca Keylo robot ( RE ) . Departmental Human Subjects Research Committee . Most students had no or very limited experience with robots and ( HRI ) experiments . E . Data Collection and Analysis Subjective measures were collected via the questionnaires . Objective measures were collected by quantitative analysis of video and notes manually taken during the experiment . Pre - liminary background data of the participants was collected using the technology adoption propensity index ( TAP ) [ 10 ] and negative attitude towards robots scale ( NARS ) [ 9 ] . The TAP questionnaire was divided in two parts . The first part contained questions about the frequency of use of technology . The second part contained questions about whether new technologies would give the participants more control over their daily lives as well about the ease of learning to use new technologies . Analysis was performed according to the recommendations of [ 10 ] . For NARS we took the sum of several questions within the questionnaire , according to the groups defined in [ 9 ] and then evaluated the average of each group ( as suggested in [ 9 ] ) . Further , we collected data with a post experiment questionnaire ( internal ) , which we adopted from [ 4 ] . Participants were asked to rate the HRI experiment ( in Likert scale between one and five ) . The subjective measures ( internal post experiment questionnaire ) were based on the Technology Acceptance Model [ 21 ] : perceived usefulness , ease of use , attitude towards the robot and intention to use the robot . Questionnaires included a manipulation check , by intro - ducing questions asking to answer with a certain value . This was conducted three times : in TAP , in NARS and in the internal post experiment questionnaire . A last post experiment questionnaire aimed to evaluate the overall experiment ( external ) . Participants were asked to rate the whole experience inside the lab – including the interactions with the experimenter and the explanations received . Its subjective measures were : cognitive load , com - fortability , enjoyment , fluency of interaction , safety , trust and understandability . Finally , the objective measures , which were collected via video and notes were : success rate , time - duration of the experiment , number of times participants asked the exper - imenter questions , number of errors ( textual , procedural ) . And , if participants were waiting for explanations to finish or not – i . e . , if they started moving on while explanations were given . Under errors we collected : textual errors – i . e , if exper - imenter made a mistake giving the experiment explanation or deviated from the predefined text ( e . g . , swapped the order of two points ) ; procedural errors – i . e . , if HE made a mistake or RE ran into a bug during the experiment ( e . g . , RE triggering an experiment phase wrongly or HE missing a step , like the filling of a questionnaire ) . During the experiment , the unnoticed observer noted all above occurrences watching the experiment through the video feed . Finally , we went over the video material and notes together to evaluate the quantitative measures . Note , that for a single experimenter , introducing a RE , can free up time to make and note important observations during the experiment . The data collected was first checked for normality using a Kolmogorov – Smirnov ( KS ) test . One - way analysis of vari - ance ( ANOVA ) was conducted on the measures which were normal . For non normal data , the Mann - U - Whitney test for between the groups design was conducted . The descriptive statistics , mean and standard deviation were computed for normal data and median was calculated for not normal data . For all evaluations , there was more than one question for each dependent variable ( subjective measures ) and the average of the questions was computed for each participant ( resulting in a score between one and five ) . The important independent variables were only the groups ( i . e . , group HE and RE ) . We are not emphasising on gender because the literature is inconclusive towards its effect [ 2 ] , [ 4 ] , [ 23 ] , [ 24 ] and it is not what we seek to measure in our study . IV . RESULTS A . Pre Experiment Questionnaire The data collected in TAP on frequency of usage was normally distributed ( D = 0 . 128 , p = 0 . 6445 ) . Further , results revealed no statistically significant difference between groups ( group HE vs RE – F ( 1 ) = 0 . 637 , p = 0 . 43 ) . The TAP control and learning parts were also normal ( D = 0 . 211 , p = 0 . 104 ) . There was no statistically significant difference between groups ( group HE vs RE F ( 1 ) = 0 . 043 , p = 0 . 838 ) . The manipulation check employed within the questionnaires yielded that 72 . 72 % of all ( HE and RE ) respondents gave correct response . 61 . 1 % and 86 . 67 % of the responses were correct for group HE and RE respectively . The NARS questionnaire was found to be normally dis - tributed ( D = 0 . 144 , p = 0 . 494 ) . The negative perception about robots in both groups ( F ( 1 ) = 0 . 045 , p = 0 . 834 ) was without statistically significant differences . The employed manipulation check found that 90 . 91 % of participants responded correctly . In group HE 88 . 89 % and in group RE 93 . 33 % of the responses were correct . Note , that the success rate between the second and first manipulation check in the pre - experiment questionnaire improved and that it is generally better when the RE is present . B . Internal Post Experiment Questionnaire There was no statistical significant difference between both groups ( see Table II ) . Nevertheless , we give descriptive statistics in Table I . Having a human or a robot experimenter did not result in any statistically significant differences in the subjective result of the training experiment , according to our measures . The training experiment itself is generally perceived as easy and the attitude is positive . The intention of use is low as the training was a very simple upper body exercise and as such too easy for young adults ( as noted above ) . Perceived usefulness Ease of use Attitude towards robot Intention to use Group HE 3 . 06 ± 1 . 30 4 . 16 ± 0 . 38 3 . 67 ± 0 . 61 3 . 17 ± 1 . 38 Group RE 2 . 46 ± 1 . 30 4 . 38 ± 0 . 40 3 . 33 ± 0 . 54 2 . 73 ± 1 . 33 TABLE I : Descriptive statistics for training experiment . Subjective metric KS Test Group ( HE vs RE ) Perceived usefulness D = 0 . 1849 , p = 0 . 2091 F ( 1 ) = 1 . 651 , p = 0 . 209 Ease of use D = 0 . 1818 , p = 0 . 2251 F ( 1 ) = 2 . 639 , p = 0 . 115 Attitude towards robot D = 0 . 1481 , p = 0 . 4635 F ( 1 ) = 2 . 76 , p = 0 . 107 Intention to use D = 0 . 2306 , p = 0 . 0597 F ( 1 ) = 0 . 809 , p = 0 . 376 TABLE II : Statistical test conducted on the subjective mea - sure of the training experiment . C . External Post Experiment Questionnaire The mean and standard deviation in case of cognitive load , understandability and fluency ( all normally distributed ) for each group are reported in Table III . In the cases of comfortability , enjoyment , safety and trust ( not normally distributed ) the median for each group is reported in Table III . We found one statistically significant difference , which was in fluency ( see Table III ) . Participants of group RE found that the experiment was more fluent then the participants in group HE . See Fig . 4 for a comparative plot of the descriptive statistics for fluency . D . Quantitative Results All results ( descriptive statistics ) are reported in Table V . The data for time duration was normally distributed ( D = 0 . 1201 , p = 0 . 7274 ) , with no statistically significant difference between the groups ( F ( 1 ) = 1 . 278 , p = 0 . 267 ) . The longest Group HE Group RE Cognitive Load ( X ± S ) 1 . 78 ± 0 . 81 1 . 8 ± 0 . 77 Comfortability ( median ) 4 . 5 4 . 5 Enjoyment ( median ) 4 4 Safety ( median ) 4 . 75 4 . 5 Trust ( median ) 5 5 Understandability ( X ± S ) 4 . 26 ± 0 . 51 4 . 24 ± 0 . 53 Fluency ( X ± S ) 4 ± 0 . 9 4 . 63 ± 0 . 53 TABLE III : Descriptive statistics of subjective measures in the external post experiment questionnaire . Subjective metric KS Test Group ( HE vs RE ) Cognitive Load D = 0 . 20 , p = 0 . 13 F ( 1 ) = 0 . 07 , p = 0 . 794 Comfortability D = 0 . 24 , p = 0 . 04 W = 105 . 5 , p = 0 . 27 Enjoyment D = 0 . 25 , p = 0 . 03 W = 144 , p = 0 . 74 Fluency D = 0 . 22 , p = 0 . 06 F ( 1 ) = 5 . 26 , p = 0 . 03 Safety D = 0 . 28 , p = 0 . 008 W = 130 . 5 , p = 0 . 87 Trust D = 0 . 41 , p = 0 . 001 W = 137 , p = 0 . 95 Understandability D = 0 . 23 , p = 0 . 06 F ( 1 ) = 0 . 007 , p = 0 . 94 TABLE IV : Statistical test conducted on the subjective measures of the external post experiment questionnaire trial in HE was 1020 seconds and the shortest 600 seconds long . In the RE group the shortest trial was 610 seconds while the longest was 920 seconds long . In group HE ques - tions were asked ( 30 in total ) and the human experimenter frequently made textual errors ( approx every other trial ) . HE made three while RE only one procedural error . The HE errors were mostly forgetting the internal questionnaire before the training . Twice the HE remembered before starting the Gymmy , once the observer had to intervene to safe the trial . In the RE error case , the participant stayed in the field of view of the experimenter robot , which triggered a text at the wrong time . Again , observer intervention prevented possible failure of the experiment . I . e . , we had to reset the current phase . Lastly , we observed that participants would be more patient with the robot experimenter than with the human experimenter , i . e . , they would wait for explanations Fig . 4 : Plot of the mean and standard deviation for fluency . to finish . Group HE Group RE Success Rate ( % ) 100 93 . 3 Time ( X ± S [ s ] ) 782 ± 115 742 ± 79 Questions ( X ± S [ s ] ) 1 . 667 ± 1 . 33 0 Textual Error ( # ) 8 0 Procedural Error ( # ) 3 1 Patience ( % ) 38 . 9 66 . 7 TABLE V : Descriptive statistics of objective measures . V . DISCUSSION AND CONCLUSION In the first subsection we discuss the results of our experiment – the comparison of the human led with the robot led experiment . What are the effects of letting robots run an HRI experiment ? Are there clear benefits and drawbacks ? The second subsection discusses a major benefit of robot led experiments – the replicability and validity of experi - ments . We follow the result - based discussion by giving our own observations as a further qualitative measure and discuss the work’s limitations . A . Robots in addition to Human Experimenters The experiments were successful , with only four procedu - ral error cases in 33 experiments ( three were with the human and one with the robot experimenter ; none of the error cases fully invalidated an experiment ) . This shows , it is clearly possible to utilise robots to conduct the repetitive tasks in an HRI experiment . Our results show no obvious downsides aside from robot errors however unveiled several benefits . The participants felt as safe and professionally guided with a robot experimenter as they did with the human experi - menter . The difference between both groups for cognitive load , understandability and trust was not statistically signif - icant as well . In subjective fluency , the robot experimenter outperforms the human experimenter . Participants would ask the human experimenter many questions . No participant attempted to direct questions to the robot experimenter . Note that participants were not informed of the level of autonomy of the robot . The nature of the questions and the success rates clearly indicate that there was no need to ask and in fact , asking may be counter - productive within our specific experiment . This opens the more general question of when it is beneficial and when not for participants to ask questions . While a case can be made that it is better that participants ask until they understand ( complex ) experiment explanations , results for our simple experiment showed a different picture . As our task was simple , questions seemed at best unnecessary . This is reflected when one compares the performance of RE vs HE groups on the manipulation check . Many participants asked the HE on how to answer the manipulation check . Asking questions did not result in better performance – it rather seemed to slow down the experiment and made participants uncertain . Interestingly , participants would allow the robot experimenter to finish explaining in twice as many cases as they would allow the human experimenter to do so . Finally , we want to note that experiments led by robots might fail due to errors in robot hard and software . In such cases it is good to have an observing and possibly intervening human experimenter present . Of course , error and intervention would influence the results of the experiment ( e . g . , by introducing human - human influence ) – and we think it should be defined beforehand when a trial has to be invalidated . Intervention for the RE occurred only once during all our experiment . As we were able to intervene and restart the current phase of the experiment within just a few seconds , we did not invalidate the trial . In comparison to that , we had to instruct the human experimenter several times to stick to the presented structure , text and procedure between trials . With HE , most mistakes were made at the beginning of running experiments ( e . g . , novelty and excitement ) and at the very end ( e . g . , focus and exhaustion ) . The fact that participants would let the robot finish its explanations but not the human experimenter astonished us . B . Replicability and Validity One of the major benefits of conducting an experiment with a robot experimenter , is that they can be replicated at later times and at different locations with relative ease and in a very precise way . This is , under the constrained that the same or similar robotic platforms and technologies are present . If experiments are largely led by robots , they can be easily shared between research groups and within the community and exactly replicated ( to the point of the exact same robot model , voice , behaviour and motion ) . The scripts make sure that the experiment protocol is followed . Unwanted human variability is reduced ( actually removed from any robot performed task ) . Interaction between two humans ( participant and experimenter ) is two sided biased , while the interaction between participant and robot is one - sided biased ( the robot acts towards all participants in the same way and does not care how it is perceived ) . We believe that this should increase the general validity of the experiments . C . Limitations and Future Work The recruited participants were engineering students that have high exposure to technology . Previous research have suggested that , the perception about robots changes with cultural differences [ 18 ] and age of the participants [ 5 ] . In [ 17 ] , the authors argued that different educational back - ground of the participants influences the interaction with robots . Therefore , it is possible , that replication of the same or similar studies will yield different outcomes when the background of the participant changes . A further limiting factor is posed by the robot experimenter itself . The type of robot ( e . g . , size and embodiment ) may have an influence on the perception and thus on the experiment itself . Studies which require proximate working with robots ( like human - robot collaboration with a manipulator as in [ 12 ] ) , would have safety concerns and thus would need robot skills to take care of this ( e . g . , shut off when danger of collision is detected ) . Also , the whole interaction was scripted by us and did not allow for any reactive behavior . Participants did not ask the robot questions , and could not have done so but future versions could include a reactive component that allows for more elaborate interaction with the robot ( s ) . Furthermore , robotic systems are bound to make mistakes [ 19 ] . Future robotic experimenters need to include methods for error resolution that function without human intervention , to increase the robustness of the process . Additionally , one could argue that we could have used a computer with a screen and camera ( computer experimenter CE ) instead of the experimenter robot . Indeed , the technical functionality of leading this specific experiment was independent of the fact that it is a robot . However , one can easily come up with cases where an experimenter ( and thus also an experimenter robot ) would need to move around with the participant – preventing the use of a computer to replace the experimenter . Moreover , previous research showed that robots are better accepted than virtual agents and that the physical presence has a positive effect on users [ 5 ] , [ 22 ] , [ 25 ] . R EFERENCES [ 1 ] Goodrich , M . A . , & Schultz , A . C . ( 2008 ) . Foundations and Trends® in Human – Computer Interaction . Foundations and Trends® in Hu - man – Computer Interaction , 1 , 203 - 275 . [ 2 ] Kumar , S . , Halloun , S . , Itzhak , E . , Tractinsky , N . , Nimrod , G . , & Edan , Y . ( 2022 , August ) . Exploring the influence of culture and gender on older adults’ perception of polite robots . In 2022 31st IEEE Interna - tional Conference on Robot and Human Interactive Communication ( RO - MAN ) ( pp . 1038 - 1043 ) . IEEE . [ 3 ] Hempel , C . G . ( 1966 ) . Philosophy of Natural Science . Printice Hall . Inc . , Englewood Cliffs . [ 4 ] Krakovski , M . , Kumar , S . , Givati , S . , Bardea , M . , Zafrani , O . , Nimrod , G . , . . . & Edan , Y . ( 2021 ) . “Gymmy” : designing and testing a robot for physical and cognitive training of older adults . Applied Sciences , 11 ( 14 ) , 6431 . [ 5 ] Kumar , S . , Itzhak , E . , Edan , Y . , Nimrod , G . , Sarne - Fleischmann , V . , & Tractinsky , N . ( 2022 ) . Politeness in human – robot interaction : a multi - experiment study with non - humanoid robots . International Journal of Social Robotics , 14 ( 8 ) , 1805 - 1820 . [ 6 ] Bradski , G . ( 2000 ) . The openCV library . Dr . Dobb’s Journal : Software Tools for the Professional Programmer , 25 ( 11 ) , 120 - 123 . [ 7 ] Lundh , F . ( 1999 ) . An introduction to tkinter . URL : www . pythonware . com / library / tkinter / introduction / index . htm . [ 8 ] Singh , A . K . , Baranwal , N . , Richter , K . F . , Hellstr¨om , T . , & Bensch , S . ( 2020 ) . Verbal explanations by collaborating robot teams . Paladyn , Journal of Behavioral Robotics , 12 ( 1 ) , 47 - 57 . [ 9 ] Nomura , T . , Suzuki , T . , Kanda , T . , & Kato , K . ( 2006 ) . Measurement of negative attitudes toward robots . Interaction Studies . Social Behaviour and Communication in Biological and Artificial Systems , 7 ( 3 ) , 437 - 454 . [ 10 ] Ratchford , M . , & Barnhart , M . ( 2012 ) . Development and validation of the technology adoption propensity ( TAP ) index . Journal of Business Research , 65 ( 8 ) , 1209 - 1215 . [ 11 ] Dennler , N . , Ruan , C . , Hadiwijoyo , J . , Chen , B . , Nikolaidis , S . , & Matari´c , M . ( 2023 ) . Design metaphors for understanding user expec - tations of socially interactive robot embodiments . ACM Transactions on Human - Robot Interaction , 12 ( 2 ) , 1 - 41 . [ 12 ] Kshirsagar , A . , Lim , M . , Christian , S . , & Hoffman , G . ( 2020 ) . Robot gaze behaviors in human - to - robot handovers . IEEE Robotics and Automation Letters , 5 ( 4 ) , 6552 - 6558 . [ 13 ] Naneva , S . , Sarda Gou , M . , Webb , T . L . , & Prescott , T . J . ( 2020 ) . A systematic review of attitudes , anxiety , acceptance , and trust towards social robots . International Journal of Social Robotics , 12 ( 6 ) , 1179 - 1201 . [ 14 ] Hoffman , G . , & Zhao , X . ( 2020 ) . A primer for conducting experiments in human – robot interaction . ACM Transactions on Human - Robot Interaction ( THRI ) , 10 ( 1 ) , 1 - 31 . [ 15 ] Arnold , C . ( 2022 ) . Cloud labs : where robots do the research . Nature , 606 ( 7914 ) , 612 - 613 . [ 16 ] Swaminathan , J . , Akintoye , J . , Fraune , M . R . , & Knight , H . ( 2021 , August ) . Robots that run their own human experiments : Exploring relational humor with multi - robot comedy . In 2021 30th IEEE Inter - national Conference on Robot & Human Interactive Communication ( RO - MAN ) ( pp . 1262 - 1268 ) . IEEE . [ 17 ] Akalin , N . , Krakovsky , M . , Avioz - Sarig , O . , Loutfi , A . , & Edan , Y . ( 2021 ) . Robot - assisted training with swedish and israeli older adults . In Social Robotics : 13th International Conference , ICSR 2021 , Singapore , Singapore , November 10 – 13 , 2021 , Proceedings 13 ( pp . 487 - 496 ) . Springer International Publishing . [ 18 ] Korn , O . , Akalin , N . , & Gouveia , R . ( 2021 ) . Understanding cultural preferences for social robots : a study in German and Arab communi - ties . ACM Transactions on Human - Robot Interaction ( THRI ) , 10 ( 2 ) , 1 - 19 . [ 19 ] Honig , S . , & Oron - Gilad , T . ( 2018 ) . Understanding and resolving failures in human - robot interaction : Literature review and model development . Frontiers in psychology , 9 , 861 . [ 20 ] Avioz - Sarig , O . , Olatunji , S . , Sarne - Fleischmann , V . , & Edan , Y . ( 2021 ) . Robotic system for physical training of older adults . Inter - national Journal of Social Robotics , 13 ( 5 ) , 1109 - 1124 . [ 21 ] Davis , F . D . ( 1989 ) . Perceived usefulness , perceived ease of use , and user acceptance of information technology . MIS quarterly , 319 - 340 . [ 22 ] Li , J . ( 2015 ) . The benefit of being physically present : A survey of experimental works comparing copresent robots , telepresent robots and virtual agents . International Journal of Human - Computer Studies , 77 , 23 - 37 . [ 23 ] Flandorfer , P . ( 2012 ) . Population ageing and socially assistive robots for elderly persons : the importance of sociodemographic factors for user acceptance . International Journal of Population Research , 2012 . [ 24 ] Saunderson , S . , & Nejat , G . ( 2020 ) . Investigating strategies for robot persuasion in social human – robot interaction . IEEE Transactions on Cybernetics , 52 ( 1 ) , 641 - 653 . [ 25 ] Fasola , J . , & Matari´c , M . J . ( 2010 ) . A socially assistive robot exercise coach for the elderly . Journal of Human - Robot Interaction , 1 ( 1 ) , 1 - 16 .