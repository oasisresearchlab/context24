Exploratory Data Science on Supercomputers for Quantum Mechanical Calculations William Dawson RIKEN Center for Computational Science , Kobe , Hyogo , 650 - 0047 , Japan Louis Beal Univ . Grenoble Alpes , MEM , L Sim , F - 38000 Grenoble , France Laura E . Ratcliff Centre for Computational Chemistry , School of Chemistry , University of Bristol , Bristol BS8 1TS , United Kingdom Hylleraas Centre for Quantum Molecular Sciences , Department of Chemistry , UiT The Arctic University of Norway , N - 9037 Tromsø , Norway Martina Stella The Abdus Salam International Centre for Theoretical Physics ( ICTP ) , Condensed Matter and Statistical Physics , 34151 Trieste , Italy Takahito Nakajima RIKEN Center for Computational Science , Kobe , Hyogo , 650 - 0047 , Japan Luigi Genovese † Univ . Grenoble Alpes , MEM , L Sim , F - 38000 Grenoble , France E - mail : luigi . genovese @ cea . fr October 2023 Abstract . Literate programming — the bringing together of program code and natural language narratives — has become a ubiquitous approach in the realm of data science . This methodology is appealing as well for the domain of Density Functional Theory ( DFT ) calculations , particularly for interactively developing new methodologies and workflows . However , effective use of literate programming is hampered by old programming paradigms and the difficulties associated with using High Performance Computing ( HPC ) resources . Here we present two Python libraries that aim to remove these hurdles . First , we describe the PyBigDFT library , which can be used to setup materials or molecular systems and provides high - level access to the wavelet based BigDFT code . We then present the related remotemanager library , which is able to serialize and execute arbitrary Python functions on remote supercomputers . We show how together these libraries enable transparent access to a r X i v : 23 1 0 . 09552v1 [ phy s i c s . c h e m - ph ] 14 O c t 2023 2 HPC based DFT calculations and can serve as building blocks for rapid prototyping and data exploration . 1 . Introduction In the field of quantum mechanical ( QM ) modeling , popular theories such as Density Functional Theory ( DFT ) [ 1 , 2 ] have the ability to predict the properties of both solid - state and molecular systems . While the conventional wisdom has been that DFT cannot blindly be applied as a black box method , theoretical progress and the development of best practices [ 3 ] have made it appealing for use as a building block for new advances and workflows . This type of use case is particularly potent at the intersection of computational chemistry and data science . At the same time , advances in algorithms and high performance computing ( HPC ) are enabling the application of DFT to larger and larger systems , making it a tool of interest for new disciplines [ 4 ] . One example of using DFT as a building block is for the development of machine - learning models [ 5 ] . This leads to requirements such as robust calculations , high - throughput runs , and careful data providence . Another example is the encapsulation of DFT based workflows for computing complex properties [ 6 , 7 , 8 ] . For these purposes , the DFT part is only a small , well - defined kernel , often called from a high - level scripting language and sitting in a much larger framework . In principle , scientists can develop these kinds of frameworks in any of the many open source DFT packages that are available today [ 9 ] ; however , old programming models and data structures with a narrow scope make this challenging . Several more recent electronic structure codes have tried to address this through alternative programming paradigms such as using modern C + + [ 10 , 11 ] , Python [ 12 , 13 , 14 , 15 ] , or Julia [ 16 , 17 , 18 , 19 ] . In the area of data science , literate programming [ 20 ] , such as through Juypter virtual laboratory notebooks , has become ubiquitous [ 21 ] . In this approach code , visualizations , and natural language narratives are intermingled into one unit . This practice has similar requirements to the previous areas in that DFT calculations should be based on high - level scripting and well - defined data structures . On the other hand , this kind of work often emphasizes exploratory calculations and short workflows that bring together methodologies and results [ 22 ] . Virtual notebooks are often used for interactive programming , where early calculation results drive further code development — a “write - eval - think - loop” as described by Granger and P´erez [ 23 ] . Thus , features such as databases , complex dependencies , and robust calculations become less important than development speed and legibility . In this Technical Note , we will describe two Python based libraries we have developed for use with literate programming : PyBigDFT and remotemanager . The first package , PyBigDFT , serves as a high level interface to set up , run , and post - process DFT calculations , specifically using the BigDFT code [ 24 ] . The remotemanager package is a general library for performing remote procedure call using Python on 3 supercomputers . We will first provide overviews of the two libraries , followed by comparisons to existing approaches . Then we will present some sample applications where these two libraries together can enable new and complex calculation workflows . For all of the workflows presented here , we have included matching Jupyter notebooks on Github ( github . com / BigDFT - group / resources ) . 2 . PyBigDFT and remotemanager Two features of BigDFT have served as core principles for the development of the Python libraries presented here . The first feature is the use of YAML as a language to write input and output files . YAML allows for the serialization of complex data structures by composing simple data types in a hierarchical fashion . YAML can thus serve as an intermediary between the ecosystems of a Python and Fortran code using dictionary data types ( built in for Python , from our Futile library for Fortran ) . The second feature is the use of optional calculations in BigDFT . When a calculation is run , users can pass a flag to check if a previous calculation with that same name had completed successfully ; if so , the calculation process returns immediately . This combination of serializability and lazy evaluation is manifest in both the overall PyBigDFT library and the remotemanager facility . Together , they can be used to build virtual lab notebooks that enable new and complex workflows . 2 . 1 . System Manipulation and Calculation with PyBigDFT Broadly , PyBigDFT can be divided into two sets of capabilities : ( 1 ) data structures for manipulating atomic systems and ( 2 ) functionality for driving calculations . The need for system manipulation may seem unintuitive to a user coming from codes that mainly represent the structures of interest as simple text files ( XYZ , POSCAR , etc ) . However , large systems often have a hierarchical structure , and users may wish to exploit this structure for manipulation . Such complicated systems can subsequently be decorated with the results of DFT calculations . In the spirit of the YAML approach , PyBigDFT hierarchically describes a system by composing simple data types ( List . 1 ) . At the lowest level is the Atom class , which is a named collection of basic data types . This flexible data structure allows users to store arbitrary data with a given Atom , which is useful both for pre - processing a system ( storing of atom names , sources , etc ) , and when extracting the results of a BigDFT calculation ( forces , charges , multipoles , etc ) . These atoms are organized into a list called a Fragment . A Fragment may be a layer of a solid - state system , a residue of a protein , a moiety of a molecular crystal , etc . These Fragment objects are then further organized into a named collection called a System . In principle , any hashable value may be used for a fragment name , but we have adopted the convention of NAME : ID as inspired by the residue naming scheme of proteins . This hierarchical arrangement means that the atoms are in principle not ordered . The System class provides a crucial function 4 # Create Three Atoms at1 = Atom ( { " r " : [ 0 , 0 , 0 ] , " sym " : " H " } ) at2 = Atom ( { " r " : [ 0 , 0 , 1 . 4 ] , " sym " : " H " } ) at3 = Atom ( { " r " : [ 10 , 0 , 0 ] , " sym " : " He " } ) # Construct a System from Two Fragments ( H2 , He ) sys = System ( ) sys [ " H2 : 1 " ] = Fragment ( [ at1 , at2 ] ) sys [ " He : 2 " ] = Fragment ( [ at3 ] ) # Iterate Over The System for fragid , frag in sys . items ( ) : for at in frag : print ( fragid , at . sym , at . get _ position ( ) ) Listing 1 : The hierarchy of Atom , Fragment , and System in PyBigDFT . Three Atom types are created , which are divided into two Fragment objects , and then combined into one System that can be accessed like a standard Python dictionary . called compute _ matching , which can efficiently generate a map between a System and an arbitrary set of Atom objects so that data may be passed to and from programs that don’t use a hierarchical representation or respect atom order . PyBigDFT also has support for extended systems through its UnitCell class . As the Fragment and System class only store shallow copies of their underling data , multiple views of the object of study ( System classes ) can be employed . To perform a calculation , users must construct an Inputfile and a SystemCalculator ( List . 2 ) . BigDFT , like many electronic structure codes , has numerous input parameters that control the various named modules . This motivates the definition of an input file as a hierarchy of dictionaries . When the SystemCalculator is run , the System and Inputfile are serialized as YAML that is then processed by BigDFT . The optional skip parameter can be used to trigger lazy evaluation . The result of a calculation is a Logfile , which is generated from the YAML output of BigDFT . Users can access the full hierarchy of data present in the Logfile using dictionary syntax . PyBigDFT also provides support for reading and writing standard atomic structure file formats , computing and plotting the Density of States , and visualization of molecules with their computed properties . To supplement the features of PyBigDFT , we provide interoperability modules to other popular packages . For system manipulation , we provide converters to and from ASE [ 25 ] , OpenBabel [ 26 ] , and RDKit [ 27 ] . For calculations using different quantum mechanical methods , we provide analogous classes to SystemCalculator and Logfile for DFTB + [ 28 ] , MRChem [ 29 ] , PSI4 [ 14 ] , and XTB [ 30 ] . 5 # Create an Input File inp = Inputfile ( ) inp . set _ hgrid ( 0 . 4 ) inp . set _ xc ( " PBE " ) inp [ " perf " ] = { " calculate _ forces " : False , " multipole _ preserving " : True } # Generate a Calculator and Run calc = SystemCalculator ( skip = True ) log = calc . run ( sys = sys , input = inp , name = " quick " , run _ dir = " scratch " ) # Access the Generated Logfile print ( log . energy ) print ( log . log [ " Memory Consumption Report " ] [ " Memory occupation " ] ) Listing 2 : A BigDFT calculation driven by PyBigDFT . First an Inputfile and SystemCalculator are created . The result of a run is stored in a Logfile . 2 . 2 . Flexible Access to HPC Resources with remotemanager A significant weakness of the initial PyBigDFT implementation was that the writing of workflows would be interrupted by the need to run computationally heavy calculations on remote machines . If a workflow was being written in a Jupyter notebook , one would need to convert that notebook to a script , submit it through the job system , wait for the calculation to complete , copy data to the machine with the Jupyter server , and then restart the notebook ( exploiting lazy calculations ) . Computationally demanding calculations include not just formulaic BigDFT runs , but a wide variety of pre - and post - processing operations . These requirements necessitate a strategy for driving the execution of arbitrary Python routines on ( potentially multiple ) remote machines . To fulfill this requirement we have developed a new library called remotemanager ( List . 3 ) . This library is able to serialize arbitrary Python routines and arguments that are sent to a remote machine and executed through a job system , after which the resulting data are synchronized to the local machine . For simple data types , serialization is done with YAML . For more complex data types , external libraries like Dill or JSONPickle can be selected . To use remotemanager , a user defines the function they want to run remotely , and uses it to create a Dataset . Sets of arguments are then added to the Dataset and the whole set can be run asynchronously . If auxiliary functions are required , they can be defined with the @ RemoteFunction decorator . The remotemanager package follows the model of BigDFT’s SystemCalculator in that a skip argument will check if the calculation has already completed , and if so no calculation is performed . The remotemanager library does not use a daemon on the remote machine and only needs to be installed on the user’s workstation . Collections of remote calls can be 6 # Function to Run on the Remote Machine def remote _ function ( sys , inp , run _ name ) : from BigDFT . Calculators import SystemCalculator calc = SystemCalculator ( ) log = calc . run ( sys = sys , input = inp , name = run _ name ) return log . energy # Create a Dataset to Store the Function remote = Dataset ( function = remote _ function , url = url , serialiser = serialdill ( ) ) # Append a Run with Data args = { " sys " : sys , " inp " : inp , " run _ name " : " remote " } remote . append _ run ( arguments = args ) remote . run ( ) # Submit the Calculation # Wait for Job Completion , Checking Every 10 Seconds remote . wait ( interval = 10 , timeout = 3600 ) # Fetch and Display the Results remote . fetch _ results ( ) print ( f ' energy : { remote . results } ' ) Listing 3 : An example of a remotely submitted calculation . First we define a function that we wish to run remotely . The function is given to the Dataset object along with a URL object that describes the remote computer . The arguments to the function are given to the append _ run method . Finally , the run method serializes everything , submits a calculation asynchronously , waits for the calculation to complete , and fetches the result . bundled together into the Dataset type , which is optimized to minimize commands sent to the remote machine ( a feature that helps in high latency environments ) . Connections are defined ( List . 4 ) via the URL module : a Python wrapper around the Secure Shell Protocol ( SSH ) . On top of the URL class is the Computer derived type and associated derived types for various specific machines . Each computer type is defined with information about how to generate job scripts and the associated options ( number of nodes , maximum wall time , etc ) . Front end versions of a machine can also be defined for low cost operations . A user planning to access a new machine can either define a new Computer derived type or define one using a YAML configure file . 2 . 3 . Literate Programming and Computational Continuity Code development inside virtual notebooks often differs substantially from best practices in software engineering [ 31 , 22 ] . As noted above , developers frequently use notebooks for exploratory calculations instead of building well structured workflows . The 7 # Basic Url url = URL ( user = " username " , host = " remote . host . address " ) url . test _ connection ( ) # YAML Configured url = BaseComputer . from _ yaml ( " summer . yaml " , user = " username " ) # Or Derived Type Computer url = Fugaku ( user = " username " ) # Computer Configuration url . mpi = 48 url . omp = 12 url . nodeshape = " torus " # Machine Specific Listing 4 : Definition of the URL base class and predefined Computer types . A URL can be defined as a simple remote address , with a configuration file , or as a derived type when complex logic is required for jobscript generation and submission . After a URL object is constructed , global job parameters can be set . remotemanager library can work well under these circumstances ( List . 5 ) . Entire Jupyter cells can be designated to run remotely using the “cell magics” included with remotemanager ( keyword sanzu ) . Thus , we envision remotemanager as a general library for performing Remote Procedure Call on HPC systems , which enables explorations that may have large computational requirements . The intermingling of text and code in literate programming make notebooks a perfect tool for collaborative efforts . The remotemanager framework can enable such collaborative use and “Computational Continuity” : allowing users to hand off notebooks and serialized results to their coworkers who can then add to the notebook and generate further results without having to redo computationally demanding portions . 2 . 4 . Handling Failure In exploratory calculations , programming mistakes are common . Developers will write an erroneous function to run remotely , arguments maybe be specified incorrectly , the remote environment could be setup wrong , job submission can fail , and a calculation might require more wall time than requested . As remotemanager is focused on exploratory workflows , it is essential to provide troubleshooting capabilities ( List . 6 ) . In remotemanager , runs are considered “complete” even if they fail ; a summary of the captured error message is available in the errors member variable of the Dataset . When the Dataset constructor is called with a modified function , a fresh Dataset is automatically created ( by comparing the function hash to the existing Dataset ) and the old Dataset stored to a backup file ; a subsequent run command will cause all calculations to be performed from scratch . If the error is caused by the remote environment , and a Dataset should be rerun without changing the function , the state of a Dataset can be 8 # [ Cell 1 : Run Dataset - Computing Energy of Many Systems ] for name , sys in systems . items ( ) : args = { " sys " : sys , " inp " : inp , " run _ name " : name } remote . append _ run ( arguments = args ) remote . run ( ) ; remote . wait ( ) ; remote . fetch _ results ( ) # [ Cell 2 : Process The Results - Find The Lowest Energy System ] energies = { k : v for k , v in zip ( systems , remote . results ) } mink = min ( energies , key = energies . get ) minsys = systems [ mink ] # [ Cell 3 : Magic Single Job - Restart the Job and Write Cubefiles ] % % sanzu url = url , serialiser = sdill % % sargs sys = minsys , inp = inp , run _ name = mink from BigDFT . Calculators import SystemCalculator inp . read _ orbitals _ from _ disk ( ) inp . write _ cubefiles _ around _ fermi _ level ( ) calc = SystemCalculator ( ) log = calc . run ( sys = sys , input = inp , name = run _ name ) Listing 5 : Jupyter cell executed remotely with cell magics ( sanzu ) . After a set of systems is processed , a single post - processing operation is defined , which can be run without the Dataset boilerplate . The sargs delimiter is used to indicate arguments to the function executed remotely . Return values , printed data , and errors appear in the notebook as if the cell was run locally . reset by calling wipe _ runs . A Dataset contains a list of individual Runner objects , which allow for fine grained control . Each Runner object contains the state of a given run , such as whether it is finished , was successful , or had errors or warnings . When the arguments of a given run are incorrectly specified , the associated Runner can be manually removed from the Dataset with the remove _ run function . If , for example , a given runner needed more wall time or failed due to a missing file , that run can be resubmitted with the force = True option . The remotemanager library can thus be used to interactively build workflows that run on remote machines using a trial and error processes with limited cognitive overhead . 3 . Comparison With Other Packages Numerous packages exist that provide high level access to quantum chemistry programs . The solutions available attempt to address various subsets of requirements : ease of use , ease of development , addressing complex systems , encapsulation of common workflows , orchestration of multiple tools , data providence , and the need for high - throughput calculations . Here we will outline some of those packages and compare them to the PyBigDFT and remotemanager combination . 9 # Broken Function def f ( x ) : returnnext ( open ( str ( x * * 2 ) ) ) ds = Dataset ( f ) ds . append _ run ( { " x " : " 3 " } ) ; ds . run ( ) ; ds . fetch _ results ( ) # # NameError : name ' returnnext ' is not defined print ( ds . errors [ 0 ] ) # Fixed Function , Broken Argument def f ( x ) : return next ( open ( str ( x * * 2 ) ) ) ds = Dataset ( f ) ds . append _ run ( { " x " : " 3 " } ) ; ds . run ( ) ; ds . fetch _ results ( ) # # TypeError : unsupported operand type ( s ) for * * or pow ( ) : ' str ' and ' int ' print ( ds . errors [ 0 ] ) # Fixed Argument ds . remove _ run ( 0 ) ds . append _ run ( { " x " : 3 } ) ; ds . run ( ) ; ds . fetch _ results ( ) # # FileNotFoundError : [ Errno 2 ] No such file or directory : ' 9 ' print ( ds . errors [ 0 ] ) # Fixed Environment open ( " temp _ runner _ remote / 9 " , ' w ' ) . write ( " data " ) ds . runners [ 0 ] . run ( force = True ) ; ds . fetch _ results ( ) # # None print ( ds . errors [ 0 ] ) Listing 6 : The remotemanager library provides access to Python error messages in failed runs so that remote functions can be debugged . By modifying the function or manipulating individual runners calculations can be resubmitted . 3 . 1 . Structures and Calculations There is significant interest in creating high level interfaces to existing QM codes , including the use of Graphical User Interfaces ( GUI ) and high level programming languages [ 32 ] . Web based interfaces also promise to offer easy access and ease of use ( see , for example , CalcUS [ 33 ] and the references therein ) . The focus of our developments is to empower capable programmers to be able to better exploit QM codes as building blocks , as opposed to simplifying access for novices ( as a GUI would ) . As PyBigDFT exposes core data structures for manipulating molecular systems , it can be viewed as similar to tools like OpenBabel [ 26 ] or RDKit [ 27 ] . These libraries offer a wider range of tools than PyBigDFT’s System class , which is why we have built interoperability modules between them . The PyBigDFT representation remains ideal to manipulate the system at various levels of a hierarchy . Inside the QMflows [ 34 ] package is the Molkit library for manipulating structures . It also includes the PLAMS library of Amsterdam Density Functional ( ADF ) [ 35 ] that has a similar structure to PyBigDFT’s 10 Inputfile and the ability to run and manage remote jobs . Our approach also differs from codes like GPAW [ 12 ] , PSI4 [ 14 ] , or PySCF [ 13 ] that aim to fully expose the underlying QM data structures in Python . These packages are extremely useful for developing methods , but come at the cost of reengineering a code from scratch and greater challenges when targeting exotic HPC platforms . In our approach , the only requirements for the compute nodes is to be able to compile the Fortran90 BigDFT program and run the Python ( version 3 . 5 + ) boilerplate code . This makes it similar to the client - server mode available in the Qbox code [ 36 ] , with the added benefit of the full Python ecosystem . TeraChem also has a client server mode based on Google’s Protocol Buffers that is effectively used for the TeraChem Cloud framework [ 37 ] . Our approach is perhaps most similar to the recent Dalton Project and its associated PyFRAME package for multiscale modeling [ 38 ] . Dalton Project shares many of the same design considerations : the existence of a mature code base and large systems as a target . A number of high level platforms exist that are able to target multiple electronic structure codes . The Atomic Simulation Environment ( ASE ) [ 25 ] supports dozens of different codes , has tools for building systems ( especially materials ) , and modules for post - processing calculations . The Atomic Simulation Recipes extension [ 39 ] builds on ASE to provide a number of recipes for common simulation tasks and can be run remotely through its MyQueue module . PyBigDFT is similar in that it has data structures to manage systems and calculator classes , and is used as glue code to build a BigDFT ASE calculator . ChemShell [ 40 , 41 ] focuses on QM / MM calculations , and thus can setup multiscale systems , run calculations using multiple codes , and includes a task farming capability for HPC resources . 3 . 2 . Remote Execution The remotemanager package on its own might be compared to industry tools aimed at cloud computing resources . It essentially implements remote procedure call , which is available in libraries like RPyC . In our case , we provide a middle layer that handles the concept of job submission ubiquitous on HPC resources . A number of tools have been developed to access cloud computing resources such as Hadoop or Apache - Spark . The Dask library includes dynamic task scheduling for building complex workflows . Parsl [ 42 ] has been designed to run task based Python programs on HPC machines . An important recent trend is the use of high - throughput QM calculations . The fireworks framework is able to orchestrate complex workflows of scripts [ 43 ] , and has been used extensively for high - throughput studies . Atomate [ 7 ] , which builds off of fireworks and pymatgen [ 44 ] , provides templates for common materials workflows . The AFLOW [ 6 ] library can be used for high - throughput calculations and has been used to build up a database of millions of materials . The combination of QM calculations and workflows on HPC resources makes the PyBigDFT - remotemanager combination similar to AiiDA [ 45 , 8 , 46 ] . In AiiDA there is a strong emphasis on reproducibility and 11 persistence of data and workflows . The implementation and setup of remotemanager is significantly simpler : it uses YAML files rather than the SQL database of AiiDA’s persistence layer and is built with basic commands like rsync and SSH instead of a dedicated daemon . For well - defined projects with a focus on the resulting data , AiiDA may be the tool of choice , whereas remotemanager is a powerful solution for exploratory calculations . The pyiron [ 47 ] library also provides high - level access to QM programs , alongside utilities to set up systems , run jobs , and store calculation results in a database . 4 . Complex Workflows For Production Here we present some sample uses of the BigDFT and remotemanager combination . We emphasize that these are not predefined workflows with well - defined input parameters . Rather , they are custom combinations of calculation and analysis built on high - level Python data structures . In addition to the full Jupyter notebooks available on Github , we also present program snippets that demonstrate key operations . 4 . 1 . Benchmarking The remotemanager package can significantly simplify the process of benchmarking new computers or calculation methods . Benchmarking a new platform aligns well with literate programming : users often first carry out exploratory calculations on small partitions that lead to know - how and rules of thumb that can be embedded in natural language stories and later code that is run on a large number of nodes . Starting with a cluster of 2CzPN ( 1 , 2 - bis ( carbazol - 9 - yl ) - 4 , 5 - dicyanobenzene ) containing 1000 molecules ( 54000 atoms ) [ 48 ] , we use PyBigDFT to extract subsets of various sizes . The benchmarking notebook then generates and launches jobs on the target machine with the desired number of nodes and threads using a Dataset . After the Dataset is computed , a magic cell is employed to run a Python function on the front end of the supercomputer that extracts the timing and memory statistics from each calculation and returns it as a standard Python dictionary ( List . 7 ) . As an example , we show the performance of BigDFT on the HPE Apollo2000 Gen10 Plus supercomputer located at the Research Center for Computational Science in Okazaki , Japan . Each node has two AMD EPYC 7763 processes with a total of 128 cores . We used 8 nodes for each calculation , with 16 MPI tasks and 8 OpenMP threads ( a configuration informed by the single node exploratory calculations in the notebook ) . The CPU time per atom is reported in Figure 1 . We observe that we quickly reach the linear scaling regime even with around 1000 atoms . The combination of PyBigDFT and remotemanager make it relatively easy to configure and benchmark new machines . Another example workflow that encapsulates processes performed on both the front end and compute nodes is the tuning of a code through the choice of compiler and flags ( List . 8 ) . We explored five different combinations using a 2CzPN dimer system in the cubic scaling mode of BigDFT ( Figure 2 ) . The code was benchmarked on an Intel Xeon 12 % % sanzu url = furl , remote _ dir = remote _ dir % % sanzu dbfile = " scale _ fetch _ " + computer % % sargs geoms = geoms , mpi = large _ mpi , omp = large _ omp # Gather Timing Statistics timing = { } for g in geoms : run _ name = g + " _ " + str ( mpi ) + " _ " + str ( omp ) with open ( " time - " + run _ name + " . yaml " ) as ifile : full = load ( ifile , Loader = SafeLoader ) timing [ run _ name ] = { " time " : full [ " WFN _ OPT " ] [ " Classes " ] [ " Total " ] [ 1 ] } # Gather Memory Statistics memory = { } for g in geoms : run _ name = g + " _ " + str ( mpi ) + " _ " + str ( omp ) with open ( " log - " + run _ name + " . yaml " ) as ifile : full = load ( ifile , Loader = SafeLoader ) memory [ run _ name ] = full [ " Memory Consumption Report " ] \ [ " Memory occupation " ] [ " Peak Value ( MB ) " ] timing , memory # Final Values Returned Listing 7 : Jupyter magic cell used to extract timing data and peak memory use from the BigDFT logfiles . This remote function is run once and synchronously , making it ideal for the “cell magics” approach . If additional properties are needed , any modification of the cell will cause it to run again from scratch . Gold 6152 using 4 MPI processes with 11 threads each . We used version 2021 . 5 . 0 of the Intel compiler and 7 . 3 . 1 of GCC , with the MKL library for both setups . We found that , for this particular cluster , the difference in architecture between the front end and compute nodes meant that the performance of the convolution routines benefited from explicitly setting the target architecture . Conversely , the inclusion of interprocedural optimization degraded performance . The notebook design relies heavily on cell magics to represent the exploratory process of trying different combinations of flags based on previous results . 4 . 2 . Validation of BigDFT : High Throughput The BigDFT code is based on a wavelet basis set and pseudopotentials . Thanks to its flexible Poisson solver , this paradigm can be applied to a variety of boundary conditions ( periodic , surface , wire , free ) . This makes BigDFT an unusual code in that it uses pseudopotentials for calculations of molecular systems , which are potentially far outside the training data used to construct these potentials . To validate BigDFT’s application to molecular systems , we compared it with the Gaussian based PSI4 code , using the W4 - 11 [ 49 ] dataset of atomization energies and the def2 - QZVP basis set [ 50 ] . We employed three different functionals ( PBE [ 51 ] , PBE0 [ 52 ] , B3LYP [ 53 ] ) , two sets of 13 Figure 1 : Calculation time and peak memory consumption ( per process ) of calculations of 2CzPN clusters of increasing size . pseudopotentials ( Krack [ 54 ] , Saha [ 55 ] ) , and compared against the PCSEG basis set series [ 56 ] . BigDFT calculations are performed with a grid spacing of 0 . 37 Bohr for Krack and 0 . 45 Bohr for the softer Saha NLCC ( non - linear core correction ) pseudopotentials . PSI4 calculations are performed with the default parameters ( spin unrestricted ) except that the DFT grid is increased to match Gaussian’s UltraFine grid . We removed molecules with sulfur , for which there is no Saha pseudopotential , and C 2 and ClO 2 for which PSI4 had convergence problems with the default settings ; in total , there were 3 × 7 × 136 = 2856 calculations to be performed . The notebook on Github details how the combination of PyBigDFT and remotemanager can encapsulate this workflow : each combination of code , basis set / pseudopotential , and functional is its own Runner that computes every structure and returns a dictionary of energy values ( List . 9 ) . As expected , the use of NLCC pseudopotentials greatly increases the precision of the calculation , even though the grid spacing can be relaxed . The pseudopotentials are also transferable between functionals , despite the initial training set ( we note here the recent , more comprehensive study of 14 Figure 2 : Calculation time for various parts of the BigDFT code built with different compilers and flags . Intel / O2 : O2 - qopenmp ; Intel / O3 : - O3 - qopenmp ; Intel / AVX - Skylake : - O2 - qopenmp - xSKYLAKE - AVX512 ; Intel / IPO : - O2 - qopenmp - ipo ; GC - C / O2 : - O3 - fopenmp - march = skylake - avx512 . Li . et al . [ 57 ] ) . 4 . 3 . Exploration of Excited States with T - CDFT Recently , we have introduced and implemented the Transition - Based Constrained DFT method for studying excited states [ 58 ] . The aim of T - CDFT is to provide a method for studying excitations in disordered supramolecular morphologies , which can easily be used in conjunction with BigDFT’s molecular fragment approach [ 59 , 60 ] to reach the required large system sizes . In practice , this requires a workflow that involves many steps , from setting up a system containing “active” ( i . e . those undergoing an excitation ) and “environment” molecules , to defining the transition to be imposed ( e . g . based on the outcome of a time - dependent ( TD ) DFT calculation ) , to generating basis sets for template gas phase molecules , to calculating excitation energies for pure , e . g . HOMO to LUMO , and / or mixed transition constraints on the full systems . For this latter step , it is first necessary to combine the converged density kernels associated with the pure constraints , a process which is run on the front end , as illustrated in List . 10 . Running this kernel on the remote machine avoids the need to copy matrices to one’s 15 # Setup Directory Structure source = join ( expanduser ( " ~ " ) , sdir , " bigdft - suite - 1 . 9 . 4 " ) updir = join ( expanduser ( " ~ " ) , udir ) build = join ( expanduser ( " ~ " ) , bdir ) makedirs ( build , exist _ ok = True ) makedirs ( updir , exist _ ok = True ) # Write the buildrc Configuration File . if upstream : with open ( join ( updir , " buildrc " ) , " w " ) as ofile : ofile . write ( buildrc ) else : with open ( join ( build , " buildrc " ) , " w " ) as ofile : ofile . write ( " extra _ prefixes = [ ' " + join ( expanduser ( " ~ " ) , udir , " install " ) + " ' ] \ n " ) ofile . write ( buildrc ) # Change to the Build Directory and Compile if upstream : chdir ( updir ) system ( " python " + join ( source , " bundler " , " jhbuild . py " ) + " - f buildrc build upstream - suite " ) else : chdir ( build ) system ( " python " + join ( source , " Installer . py - y build - a no _ upstream " ) ) Listing 8 : The function run remotely to compile the BigDFT code . To build BigDFT is a two step process that involves compiling upstream packages and then the main program . Compilation of the code is one example of the benefit of the arbitrary remote function execution capability of the remotemanager package . own machine and allows us to build “Post - DFT” functionality on top of an unchanged DFT code ( instead of incorporating this mixing into BigDFT’s Fortran ) . Figure 4 illustrates a generalised workflow for such a calculation , as well as optional additional post - processing steps , such as characterizing the imposed transitions via the means of a charge transfer parameter . Since TDDFT in BigDFT can currently only be employed for LDA calculations , the workflow instead uses NWChem [ 61 ] for the initial step of identifying the transition constraint that will be imposed in later steps , although this step could equally be substituted with another code or approach . Nonetheless , this integration of NWChem into the workflow highlights the benefits of the ability to execute arbitrary Python code with remotemanager . While other packages provide access to a popular code like NWChem , they may not provide access to all calculation methods ( for example , ASE doesn’t have settings for TDDFT ) , or to all the computed properties . For a specific use 16 Figure 3 : Precision of various calculation methods for the atomization energies of the W4 - 11 dataset compared to PSI4 calculations with the def2 - QZVP basis set . When the NLCC pseudopotentials are employed , the precision is similar to the triplet - ζ PCSEG - 2 basis set . This level of precision appears to be consistent across the different functionals . case though , it is easy to use Python as a glue code to build the appropriate input files and parse the results . The remotemanager class transparently allows the user to run that glue code on a remote machine over a large set of molecules . 5 . Conclusion In this Technical Note , we have presented two libraries we have been developing that can enable new kinds of QM calculations on High Performance Computers . The PyBigDFT library is used to set up the system to be studied and to run calculations with the BigDFT code . The remotemanager library offers utilities to asynchronously run these calculations ( or any arbitrary Python function ) straight from a Python script . These libraries can be deployed alongside Jupyter notebooks to enable a range of activities including exploratory calculations , literate programming , and the building of complex workflows that are applied to large datasets . An important benefit of the PyBigDFT and remotemanager capability presented here is for distribution of the code . It is now possible to install a BigDFT client version , which contains only PyBigDFT and remotemanager . These packages are significantly 17 # Setup Input Parameters cinp = Inputfile ( ) cinp . set _ xc ( functional ) if pp = = " Saha " : cinp . set _ psp _ nlcc ( ) cinp . set _ hgrid ( 0 . 45 ) elif pp = = " Krack " : cinp . set _ psp _ krack ( ) cinp . set _ hgrid ( 0 . 37 ) param _ id = str ( pp ) + " _ " + functional # Iterate logfiles = { } for k , v in systems . items ( ) : # Set Charge and Multiplicity cinp2 = deepcopy ( cinp ) cinp2 . charge ( charges [ k ] ) if mults [ k ] > 1 : cinp2 . spin _ polarize ( mpol = mults [ k ] - 1 ) logfiles [ k ] = calc . run ( sys = v , input = cinp2 , name = k , run _ dir = " bigdft _ " + param _ id ) return { k : v . energy for k , v in logfiles . items ( ) } Listing 9 : The function run remotely to process the W4 - 11 dataset with BigDFT . Parallelization is done over calculation parameters with each function processing every system . easier to install than the full BigDFT suite ( both are available on the PyPI repository ) . The client can be interfaced to a compute cluster with a full version of BigDFT installed once by the system administrators or available using containers like Docker or Singularity . We have attempted to minimize the requirements needed for the remotemanager library : there is no software that needs to be installed on the remote machine , no daemons or databases to run , and interactions with the queuing systems are deferred to the computer definition . A significant requirement , however , is that it must be possible to login to the machine without a password . The remotemanager library is built on top of SSH , so this can be accomplished using public key authentication or sshpass ( when both a key and password is required ) ; for machines with stricter security requirements ( such as one - time passwords ) , remotemanager won’t be usable . In principle , there is no requirement for compatibility between the Python implementation running locally ( 3 . 7 + ) and on the remote machine ( 3 . 5 + ) , except when using the Dill protocol for serialization . In this article , we have focused on literate programming in the context of data analysis , Python programming , and Jupyter notebooks . Another popular tool for 18 @ RemoteFunction def combine _ density _ kernels ( kernel _ info ) : # Combine the Density Kernels from Calculations with a Pure Constraint for p , kernel _ dir in enumerate ( kernel _ info [ ' kernel _ dirs ' ] ) : kernel _ file = join ( kernel _ dir , ' density _ kernel _ sparse . mtx ' ) rho _ a _ p = mmread ( kernel _ file ) # Set the Kernel to Zero on the First Step if p = = 0 : rho _ a = deepcopy ( rho _ a _ p ) rho _ a . data [ : ] = 0 . 0 rho _ a + = kernel _ info [ ' transition _ weights ' ] [ p ] * rho _ a _ p # Write the Kernel for Reading by BigDFT mmwrite ( join ( kernel _ info [ ' target _ dir ' ] , ' density _ kernel _ sparse . mtx ' ) , rho _ a ) Listing 10 : A @ RemoteFunction used in the T - CDFT workflow . By decorating this function , it can now be called by any Dataset . The function takes density kernels generated from T - CDFT calculations with pure constraints , and combines them according to weights taken from the transition breakdown coming from a TDDFT calculation , to be used in a calculation with a mixed constraint . For the generic case of a mixed transition , it is then enough to split the T - CDFT approach into multiple constraints . We can define the energy of the mixed transition by the SCF energy obtained from the density operator ˆ ρ a = (cid:80) p P ap ˆ ρ ap , where ˆ ρ ap is the SCF density obtained from the pure T - CDFT calculation with the constraint Tr (cid:16) ˆ ρ ˆ T ( a ) p (cid:17) = 1 . literate programming is Emacs Org - mode . Org - mode has already been employed to build software in the field of QM modeling ; in particular , we highlight the recent development of packages like Atrip [ 62 , 63 ] , QMCkl [ 64 ] , and TREXIO [ 65 ] . Such projects show the potential for literate programming to lead to full fledged software packages for the QM modeling community . These developments , and those presented here , hint of a future for the scientific community where new theoretical methods and computational schemes are shared in ways that bring together scientific narratives and concrete implementations . Acknowledgements Computations were performed using resources at the Research Center for Computational Science , Okazaki , Japan ( Project : 23 - IMS - C029 ) . Calculations were also performed using the Hokusai supercomputer system at RIKEN ( Project ID : Q23460 ) . This work was supported by MEXT as “Program for Promoting Research on the Supercomputer Fugaku” ( Realization of innovative light energy conversion materials utilizing the supercomputer Fugaku , Grant Number JPMXP1020210317 ) . This work also used the ARCHER2 UK National Supercomputing Service ( https : / / www . archer2 . ac . uk ) , and the 19 Figure 4 : Flow chart of a workflow for calculating excited state singlet and triplet energies of large supramolecular morphologies using Transition - Based Constrained DFT , built on PyBigDFT and remotemanager . Calculations on active molecules , environment molecules , and the full systems are highlighted in red , blue , and purple , respectively . Calculations run on the back end of the remote machine are in squares while front end calculations have rounded corners . computational facilities of the Advanced Computing Research Centre , University of Bristol ( http : / / www . bris . ac . uk / acrc / ) . LG , NT , and WD acknowledge the joint CEA – RIKEN collaborative action . LER and MS acknowledge support from an EPSRC Early Career Research Fellowship ( EP / P033253 / 1 ) . References [ 1 ] P . Hohenberg and W . Kohn . Inhomogeneous electron gas . Phys . Rev . , 136 : B864 – B871 , Nov 1964 . [ 2 ] W . Kohn and L . J . Sham . Self - consistent equations including exchange and correlation effects . Phys . Rev . , 140 : A1133 – A1138 , Nov 1965 . [ 3 ] Markus Bursch , Jan - Michael Mewes , Andreas Hansen , and Stefan Grimme . Best - practice dft protocols for basic molecular computational chemistry . Angewandte Chemie International Edition , 61 ( 42 ) : e202205735 , Oct 2022 . [ 4 ] William Dawson , Augustin Degomme , Martina Stella , Takahito Nakajima , Laura E . Ratcliff , and Luigi Genovese . Density functional theory calculations of large systems : Interplay between fragments , observables , and computational complexity . WIREs Computational Molecular Science , 12 ( 3 ) : e1574 , May 2022 . [ 5 ] Jonathan Schmidt , M´ario R . G . Marques , Silvana Botti , and Miguel A . L . Marques . 20 Recent advances and applications of machine learning in solid - state materials science . npj Computational Materials , 5 ( 1 ) : 83 , Aug 2019 . [ 6 ] Stefano Curtarolo , Wahyu Setyawan , Gus L . W . Hart , Michal Jahnatek , Roman V . Chepulskii , Richard H . Taylor , Shidong Wang , Junkai Xue , Kesong Yang , Ohad Levy , Michael J . Mehl , Harold T . Stokes , Denis O . Demchenko , and Dane Morgan . Aflow : An automatic framework for high - throughput materials discovery . Computational Materials Science , 58 : 218 – 226 , Jun 2012 . [ 7 ] Kiran Mathew , Joseph H . Montoya , Alireza Faghaninia , Shyam Dwarakanath , Muratahan Aykol , Hanmei Tang , Iek - heng Chu , Tess Smidt , Brandon Bocklund , Matthew Horton , John Dagdelen , Brandon Wood , Zi - Kui Liu , Jeffrey Neaton , Shyue Ping Ong , Kristin Persson , and Anubhav Jain . Atomate : A high - level interface to generate , execute , and analyze computational materials science workflows . Computational Materials Science , 139 : 140 – 152 , Nov 2017 . [ 8 ] Martin Uhrin , Sebastiaan P . Huber , Jusong Yu , Nicola Marzari , and Giovanni Pizzi . Workflows in aiida : Engineering a high - throughput , event - based engine for robust and modular computational workflows . Computational Materials Science , 187 : 110086 , 2021 . [ 9 ] Susi Lehtola and Antti J . Karttunen . Free and open source software for computational chemistry education . WIREs Computational Molecular Science , 12 ( 5 ) : e1610 , Sep 2022 . [ 10 ] Chong Peng , Cannada A . Lewis , Xiao Wang , Marjory C . Clement , Karl Pierce , Varun Rishi , Fabijan Pavoˇsevi´c , Samuel Slattery , Jinmei Zhang , Nakul Teke , Ashutosh Kumar , Conner Masteran , Andrey Asadchev , Justus A . Calvin , and Edward F . Valeev . Massively parallel quantum chemistry : A high - performance research platform for electronic structure . The Journal of Chemical Physics , 153 ( 4 ) : 044120 , Jul 2020 . [ 11 ] Karol Kowalski , Raymond Bair , Nicholas P . Bauman , Jeffery S . Boschen , Eric J . Bylaska , Jeff Daily , Wibe A . de Jong , Thom Dunning Jr . , Niranjan Govind , Robert J . Harrison , Murat Ke¸celi , Kristopher Keipert , Sriram Krishnamoorthy , Suraj Kumar , Erdal Mutlu , Bruce Palmer , Ajay Panyala , Bo Peng , Ryan M . Richard , T . P . Straatsma , Peter Sushko , Edward F . Valeev , Marat Valiev , Hubertus J . J . van Dam , Jonathan M . Waldrop , David B . Williams - Young , Chao Yang , Marcin Zalewski , and Theresa L . Windus . From nwchem to nwchemex : Evolving with the computational chemistry landscape . Chemical Reviews , 121 ( 8 ) : 4962 – 4998 , Apr 2021 . [ 12 ] J . Enkovaara , C . Rostgaard , J . J . Mortensen , J . Chen , M . Du(cid:32)lak , L . Ferrighi , J . Gavnholt , C . Glinsvad , V . Haikola , H . A . Hansen , H . H . Kristoffersen , M . Kuisma , A . H . Larsen , L . Lehtovaara , M . Ljungberg , O . Lopez - Acevedo , P . G . Moses , J . Ojanen , T . Olsen , V . Petzold , N . A . Romero , J . Stausholm - Møller , M . Strange , G . A . Tritsaris , M . Vanin , M . Walter , B . Hammer , H . H¨akkinen , G . K . H . Madsen , R . M . Nieminen , J . K . Nørskov , M . Puska , T . T . Rantala , J . Schiøtz , K . S . Thygesen , and K . W . Jacobsen . Electronic structure calculations with gpaw : a real - space implementation of the projector augmented - wave method . Journal of Physics : Condensed Matter , 22 ( 25 ) : 253202 , Jun 2010 . [ 13 ] Qiming Sun , Xing Zhang , Samragni Banerjee , Peng Bao , Marc Barbry , Nick S . Blunt , Nikolay A . Bogdanov , George H . Booth , Jia Chen , Zhi - Hao Cui , Janus J . Eriksen , Yang Gao , Sheng Guo , Jan Hermann , Matthew R . Hermes , Kevin Koh , Peter Koval , Susi Lehtola , Zhendong Li , Junzi Liu , Narbe Mardirossian , James D . McClain , Mario Motta , Bastien Mussard , Hung Q . Pham , Artem Pulkin , Wirawan Purwanto , Paul J . Robinson , Enrico Ronca , Elvira R . Sayfutyarova , Maximilian Scheurer , Henry F . Schurkus , James E . T . Smith , Chong Sun , Shi - Ning Sun , Shiv Upadhyay , Lucas K . Wagner , Xiao Wang , Alec White , James Daniel Whitfield , Mark J . Williamson , Sebastian Wouters , Jun Yang , Jason M . Yu , Tianyu Zhu , Timothy C . Berkelbach , Sandeep Sharma , Alexander Yu . Sokolov , and Garnet Kin - Lic Chan . Recent developments in the pyscf program package . The Journal of Chemical Physics , 153 ( 2 ) : 024109 , Jul 2020 . [ 14 ] Justin M . Turney , Andrew C . Simmonett , Robert M . Parrish , Edward G . Hohenstein , Francesco A . Evangelista , Justin T . Fermann , Benjamin J . Mintz , Lori A . Burns , Jeremiah J . Wilke , Micah L . Abrams , Nicholas J . Russ , Matthew L . Leininger , Curtis L . Janssen , Edward T . Seidl , Wesley D . Allen , Henry F . Schaefer , Rollin A . King , Edward F . Valeev , C . David Sherrill , and T . Daniel 21 Crawford . Psi4 : an open - source ab initio electronic structure program . WIREs Computational Molecular Science , 2 ( 4 ) : 556 – 565 , Jul 2012 . [ 15 ] Zilvinas Rinkevicius , Xin Li , Olav Vahtras , Karan Ahmadzadeh , Manuel Brand , Magnus Ringholm , Nanna Holmgaard List , Maximilian Scheurer , Mikael Scott , Andreas Dreuw , and Patrick Norman . Veloxchem : A python - driven density - functional theory program for spectroscopy simulations in high - performance computing environments . WIREs Computational Molecular Science , 10 ( 5 ) : e1457 , Sep 2020 . [ 16 ] David Poole , Jorge L . Galvez Vallejo , and Mark S . Gordon . A new kid on the block : Application of julia to hartree – fock calculations . Journal of Chemical Theory and Computation , 16 ( 8 ) : 5006 – 5013 , Aug 2020 . [ 17 ] Fadjar Fathurrahman , Mohammad Kemal Agusta , Adhitya Gandaryus Saputro , and Her - mawan Kresno Dipojono . Pwdft . jl : A julia package for electronic structure calculation using density functional theory and plane wave basis . Computer Physics Communications , 256 : 107372 , Nov 2020 . [ 18 ] Gustavo J . R . Aroeira , Matthew M . Davis , Justin M . Turney , and Henry F . Schaefer III . Fermi . jl : A modern design for quantum chemistry . Journal of Chemical Theory and Computation , 18 ( 2 ) : 677 – 686 , Feb 2022 . [ 19 ] Michael F . Herbst , Antoine Levitt , and Eric Canc ` es . Dftk : A julian approach for simulating electrons in solids . Proc . JuliaCon Conf . , 3 : 69 , 2021 . [ 20 ] D . E . Knuth . Literate programming . The Computer Journal , 27 ( 2 ) : 97 – 111 , Jan 1984 . [ 21 ] Mary Beth Kery , Marissa Radensky , Mahima Arya , Bonnie E . John , and Brad A . Myers . The story in the notebook : Exploratory data science using a literate programming tool . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , CHI ’18 , page 1 – 11 , New York , NY , USA , 2018 . Association for Computing Machinery . [ 22 ] Luigi Quaranta , Fabio Calefato , and Filippo Lanubile . Eliciting best practices for collaboration with computational notebooks . Proc . ACM Hum . - Comput . Interact . , 6 ( CSCW1 ) , apr 2022 . [ 23 ] B . E . Granger and F . P´erez . Jupyter : Thinking and storytelling with code and data . Computing in Science & Engineering , 23 ( 2 ) : 7 – 14 , 2021 . [ 24 ] Laura E . Ratcliff , William Dawson , Giuseppe Fisicaro , Damien Caliste , Stephan Mohr , Augustin Degomme , Brice Videau , Viviana Cristiglio , Martina Stella , Marco D’Alessandro , Stefan Goedecker , Takahito Nakajima , Thierry Deutsch , and Luigi Genovese . Flexibilities of wavelets as a computational basis set for large - scale electronic structure calculations . J . Chem . Phys . , 152 ( 19 ) : 194110 , May 2020 . [ 25 ] Ask Hjorth Larsen , Jens Jørgen Mortensen , Jakob Blomqvist , Ivano E . Castelli , Rune Christensen , Marcin Du(cid:32)lak , Jesper Friis , Michael N . Groves , Bjørk Hammer , Cory Hargus , Eric D . Hermes , Paul C . Jennings , Peter Bjerre Jensen , James Kermode , John R . Kitchin , Esben Leonhard Kolsbjerg , Joseph Kubal , Kristen Kaasbjerg , Steen Lysgaard , J´on Bergmann Maronsson , Tristan Maxson , Thomas Olsen , Lars Pastewka , Andrew Peterson , Carsten Rostgaard , Jakob Schiøtz , Ole Sch¨utt , Mikkel Strange , Kristian S . Thygesen , Tejs Vegge , Lasse Vilhelmsen , Michael Walter , Zhenhua Zeng , and Karsten W . Jacobsen . The atomic simulation environment—a python library for working with atoms . Journal of Physics : Condensed Matter , 29 ( 27 ) : 273002 , Jun 2017 . [ 26 ] Noel M . O’Boyle , Michael Banck , Craig A . James , Chris Morley , Tim Vandermeersch , and Geoffrey R . Hutchison . Open babel : An open chemical toolbox . Journal of Cheminformatics , 3 ( 1 ) : 33 , Oct 2011 . [ 27 ] RDKit — rdkit . org . https : / / www . rdkit . org / . [ Accessed 10 - Jul - 2023 ] . [ 28 ] B . Hourahine , B . Aradi , V . Blum , F . Bonaf´e , A . Buccheri , C . Camacho , C . Cevallos , M . Y . Deshaye , T . Dumitric˘a , A . Dominguez , S . Ehlert , M . Elstner , T . van der Heide , J . Hermann , S . Irle , J . J . Kranz , C . K¨ohler , T . Kowalczyk , T . Kubaˇr , I . S . Lee , V . Lutsker , R . J . Maurer , S . K . Min , I . Mitchell , C . Negre , T . A . Niehaus , A . M . N . Niklasson , A . J . Page , A . Pecchia , G . Penazzi , M . P . Persson , J . ˇRez´aˇc , C . G . S´anchez , M . Sternberg , M . St¨ohr , F . Stuckenberg , 22 A . Tkatchenko , V . W . - z . Yu , and T . Frauenheim . Dftb + , a software package for efficient approximate density functional theory based atomistic simulations . The Journal of Chemical Physics , 152 ( 12 ) : 124101 , Mar 2020 . [ 29 ] Peter Wind , Magnar Bjørgve , Anders Brakestad , Gabriel A . Gerez S . , Stig Rune Jensen , Roberto Di Remigio Eik˚as , and Luca Frediani . Mrchem multiresolution analysis code for molecular electronic structure calculations : Performance and scaling properties . Journal of Chemical Theory and Computation , 19 ( 1 ) : 137 – 146 , Jan 2023 . [ 30 ] Christoph Bannwarth , Eike Caldeweyher , Sebastian Ehlert , Andreas Hansen , Philipp Pracht , Jakob Seibert , Sebastian Spicher , and Stefan Grimme . Extended tight - binding quantum chemistry methods . WIREs Computational Molecular Science , 11 ( 2 ) : e1493 , Mar 2021 . [ 31 ] Konstantin Grotov , Sergey Titov , Vladimir Sotnikov , Yaroslav Golubev , and Timofey Bryksin . A large - scale comparison of python code in jupyter notebooks and scripts . In Proceedings of the 19th International Conference on Mining Software Repositories , MSR ’22 , page 353 – 364 , New York , NY , USA , 2022 . Association for Computing Machinery . [ 32 ] C . David Sherrill , David E . Manolopoulos , Todd J . Mart´ınez , and Angelos Michaelides . Electronic structure software . The Journal of Chemical Physics , 153 ( 7 ) : 070401 , Aug 2020 . [ 33 ] Rapha¨el Robidas and Claude Y . Legault . Calcus : An open - source quantum chemistry web platform . Journal of Chemical Information and Modeling , 62 ( 5 ) : 1147 – 1153 , Mar 2022 . [ 34 ] Felipe Zapata , Lars Ridder , Johan Hidding , Christoph R . Jacob , Ivan Infante , and Lucas Visscher . Qmflows : A tool kit for interoperable parallel workflows in quantum chemistry . Journal of Chemical Information and Modeling , 59 ( 7 ) : 3191 – 3197 , Jul 2019 . [ 35 ] G . te Velde , F . M . Bickelhaupt , E . J . Baerends , C . Fonseca Guerra , S . J . A . van Gisbergen , J . G . Snijders , and T . Ziegler . Chemistry with adf . Journal of Computational Chemistry , 22 ( 9 ) : 931 – 967 , Jul 2001 . [ 36 ] F . Gygi . Architecture of qbox : A scalable first - principles molecular dynamics code . IBM Journal of Research and Development , 52 ( 1 . 2 ) : 137 – 144 , 2008 . [ 37 ] Stefan Seritan , Keiran Thompson , and Todd J . Mart´ınez . Terachem cloud : A high - performance computing service for scalable distributed gpu - accelerated electronic structure calculations . Journal of Chemical Information and Modeling , 60 ( 4 ) : 2126 – 2137 , Apr 2020 . [ 38 ] J´ogvan Magnus Haugaard Olsen , Simen Reine , Olav Vahtras , Erik Kjellgren , Peter Reinholdt , Karen Oda Hjorth Dundas , Xin Li , Janusz Cukras , Magnus Ringholm , Erik D . Hedeg˚ard , Roberto Di Remigio , Nanna H . List , Rasmus Faber , Bruno Nunes Cabral Tenorio , Radovan Bast , Thomas Bondo Pedersen , Zilvinas Rinkevicius , Stephan P . A . Sauer , Kurt V . Mikkelsen , Jacob Kongsted , Sonia Coriani , Kenneth Ruud , Trygve Helgaker , Hans Jørgen Aa . Jensen , and Patrick Norman . Dalton project : A python platform for molecular - and electronic - structure simulations of complex systems . The Journal of Chemical Physics , 152 ( 21 ) : 214115 , Jun 2020 . [ 39 ] Morten Gjerding , Thorbjørn Skovhus , Asbjørn Rasmussen , Fabian Bertoldo , Ask Hjorth Larsen , Jens Jørgen Mortensen , and Kristian Sommer Thygesen . Atomic simulation recipes : A python framework and library for automated workflows . Computational Materials Science , 199 : 110731 , Nov 2021 . [ 40 ] Sebastian Metz , Johannes K¨astner , Alexey A . Sokol , Thomas W . Keal , and Paul Sherwood . Chemshell—a modular software package for qm / mm simulations . WIREs Computational Molecular Science , 4 ( 2 ) : 101 – 110 , Mar 2014 . [ 41 ] You Lu , Matthew R . Farrow , Pierre Fayon , Andrew J . Logsdail , Alexey A . Sokol , C . Richard A . Catlow , Paul Sherwood , and Thomas W . Keal . Open - source , python - based redevelopment of the chemshell multiscale qm / mm environment . Journal of Chemical Theory and Computation , 15 ( 2 ) : 1317 – 1328 , Feb 2019 . [ 42 ] Yadu Babuji , Anna Woodard , Zhuozhao Li , Daniel S . Katz , Ben Clifford , Rohan Kumar , Lukasz Lacinski , Ryan Chard , Justin M . Wozniak , Ian Foster , Michael Wilde , and Kyle Chard . Parsl : Pervasive parallel programming in python . In Proceedings of the 28th International Symposium on High - Performance Parallel and Distributed Computing , HPDC ’19 , page 25 – 36 , New York , 23 NY , USA , 2019 . Association for Computing Machinery . [ 43 ] Anubhav Jain , Shyue Ping Ong , Wei Chen , Bharat Medasani , Xiaohui Qu , Michael Kocher , Miriam Brafman , Guido Petretto , Gian - Marco Rignanese , Geoffroy Hautier , Daniel Gunter , and Kristin A . Persson . Fireworks : a dynamic workflow system designed for high - throughput applications . Concurrency and Computation : Practice and Experience , 27 ( 17 ) : 5037 – 5059 , 2015 . CPE - 14 - 0307 . R2 . [ 44 ] Shyue Ping Ong , William Davidson Richards , Anubhav Jain , Geoffroy Hautier , Michael Kocher , Shreyas Cholia , Dan Gunter , Vincent L . Chevrier , Kristin A . Persson , and Gerbrand Ceder . Python materials genomics ( pymatgen ) : A robust , open - source python library for materials analysis . Computational Materials Science , 68 : 314 – 319 , Feb 2013 . [ 45 ] Sebastiaan P . Huber , Spyros Zoupanos , Martin Uhrin , Leopold Talirz , Leonid Kahle , Rico H¨auselmann , Dominik Gresch , Tiziano M¨uller , Aliaksandr V . Yakutovich , Casper W . Andersen , Francisco F . Ramirez , Carl S . Adorf , Fernando Gargiulo , Snehal Kumbhar , Elsa Passaro , Conrad Johnston , Andrius Merkys , Andrea Cepellotti , Nicolas Mounet , Nicola Marzari , Boris Kozinsky , and Giovanni Pizzi . AiiDA 1 . 0 , a scalable computational infrastructure for automated reproducible workflows and data provenance . Scientific Data , 7 ( 1 ) , September 2020 . [ 46 ] Aliaksandr V . Yakutovich , Kristjan Eimre , Ole Sch¨utt , Leopold Talirz , Carl S . Adorf , Casper W . Andersen , Edward Ditler , Dou Du , Daniele Passerone , Berend Smit , Nicola Marzari , Giovanni Pizzi , and Carlo A . Pignedoli . Aiidalab – an ecosystem for developing , executing , and sharing scientific workflows . Computational Materials Science , 188 : 110165 , Feb 2021 . [ 47 ] Jan Janssen , Sudarsan Surendralal , Yury Lysogorskiy , Mira Todorova , Tilmann Hickel , Ralf Drautz , and J¨org Neugebauer . pyiron : An integrated development environment for computational materials science . Computational Materials Science , 163 : 24 – 36 , 2019 . [ 48 ] Y . Olivier , B . Yurash , L . Muccioli , G . D’Avino , O . Mikhnenko , J . C . Sancho - Garc´ıa , C . Adachi , T . - Q . Nguyen , and D . Beljonne . Nature of the singlet and triplet excitations mediating thermally activated delayed fluorescence . Physical Review Materials , 1 ( 7 ) : 075602 , Dec 2017 . [ 49 ] Amir Karton , Shauli Daon , and Jan M . L . Martin . W4 - 11 : A high - confidence benchmark dataset for computational thermochemistry derived from first - principles w4 data . Chemical Physics Letters , 510 ( 4 ) : 165 – 178 , Jul 2011 . [ 50 ] Florian Weigend and Reinhart Ahlrichs . Balanced basis sets of split valence , triple zeta valence and quadruple zeta valence quality for h to rn : Design and assessment of accuracy . Physical Chemistry Chemical Physics , 7 ( 18 ) : 3297 – 3305 , 2005 . [ 51 ] John P . Perdew , Kieron Burke , and Matthias Ernzerhof . Generalized gradient approximation made simple . Physical Review Letters , 77 ( 18 ) : 3865 – 3868 , Oct 1996 . [ 52 ] Carlo Adamo and Vincenzo Barone . Toward reliable density functional methods without adjustable parameters : The pbe0 model . The Journal of Chemical Physics , 110 ( 13 ) : 6158 – 6170 , Apr 1999 . [ 53 ] P . J . Stephens , F . J . Devlin , C . F . Chabalowski , and M . J . Frisch . Ab initio calculation of vibrational absorption and circular dichroism spectra using density functional force fields . The Journal of Physical Chemistry , 98 ( 45 ) : 11623 – 11627 , Nov 1994 . [ 54 ] M . Krack . Pseudopotentials for h to kr optimized for gradient - corrected exchange - correlation functionals . Theoretical Chemistry Accounts , 114 ( 1 ) : 145 – 152 , Sep 2005 . [ 55 ] Santanu Saha . Soft and accurate norm conserving pseudopotentials and their application for structure prediction . PhD thesis , University of Basel , 2017 . [ 56 ] Frank Jensen . Unifying general and segmented contracted basis sets . segmented polarization consistent basis sets . Journal of Chemical Theory and Computation , 10 ( 3 ) : 1074 – 1085 , Mar 2014 . [ 57 ] Wan - Lu Li , Kaixuan Chen , Elliot Rossomme , Martin Head - Gordon , and Teresa Head - Gordon . Greater transferability and accuracy of norm - conserving pseudopotentials using nonlinear core corrections . Chemical Science , 2023 . [ 58 ] Martina Stella , Kritam Thapa , Luigi Genovese , and Laura E . Ratcliff . Transition - based 24 constrained dft for the robust and reliable treatment of excitations in supramolecular systems . Journal of Chemical Theory and Computation , 18 ( 5 ) : 3027 – 3038 , May 2022 . [ 59 ] Laura E . Ratcliff , Luigi Genovese , Stephan Mohr , and Thierry Deutsch . Fragment approach to constrained density functional theory calculations using daubechies wavelets . J . Chem . Phys . , 142 ( 23 ) : 234105 , 2015 . [ 60 ] L . E . Ratcliff , L . Grisanti , L . Genovese , T . Deutsch , T . Neumann , D . Danilov , W . Wenzel , D . Beljonne , and J . Cornil . Toward fast and accurate evaluation of charge on - site energies and transfer integrals in supramolecular architectures using linear constrained density functional theory ( cdft ) - based methods . J . Chem . Theory Comput . , 11 ( 5 ) : 2077 – 2086 , 2015 . [ 61 ] E . Apr ` a , E . J . Bylaska , W . A . de Jong , N . Govind , K . Kowalski , T . P . Straatsma , M . Valiev , H . J . J . van Dam , Y . Alexeev , J . Anchell , V . Anisimov , F . W . Aquino , R . Atta - Fynn , J . Autschbach , N . P . Bauman , J . C . Becca , D . E . Bernholdt , K . Bhaskaran - Nair , S . Bogatko , P . Borowski , J . Boschen , J . Brabec , A . Bruner , E . Cau¨et , Y . Chen , G . N . Chuev , C . J . Cramer , J . Daily , M . J . O . Deegan , T . H . Dunning Jr . , M . Dupuis , K . G . Dyall , G . I . Fann , S . A . Fischer , A . Fonari , H . Fr¨uchtl , L . Gagliardi , J . Garza , N . Gawande , S . Ghosh , K . Glaesemann , A . W . G¨otz , J . Hammond , V . Helms , E . D . Hermes , K . Hirao , S . Hirata , M . Jacquelin , L . Jensen , B . G . Johnson , H . J´onsson , R . A . Kendall , M . Klemm , R . Kobayashi , V . Konkov , S . Krishnamoorthy , M . Krishnan , Z . Lin , R . D . Lins , R . J . Littlefield , A . J . Logsdail , K . Lopata , W . Ma , A . V . Marenich , J . Martin del Campo , D . Mejia - Rodriguez , J . E . Moore , J . M . Mullin , T . Nakajima , D . R . Nascimento , J . A . Nichols , P . J . Nichols , J . Nieplocha , A . Otero - de - la Roza , B . Palmer , A . Panyala , T . Pirojsirikul , B . Peng , R . Peverati , J . Pittner , L . Pollack , R . M . Richard , P . Sadayappan , G . C . Schatz , W . A . Shelton , D . W . Silverstein , D . M . A . Smith , T . A . Soares , D . Song , M . Swart , H . L . Taylor , G . S . Thomas , V . Tipparaju , D . G . Truhlar , K . Tsemekhman , T . Van Voorhis , ´A V´azquez - Mayagoitia , P . Verma , O . Villa , A . Vishnu , K . D . Vogiatzis , D . Wang , J . H . Weare , M . J . Williamson , T . L . Windus , K . Woli´nski , A . T . Wong , Q . Wu , C . Yang , Q . Yu , M . Zacharias , Z . Zhang , Y . Zhao , and R . J . Harrison . Nwchem : Past , present , and future . The Journal of Chemical Physics , 152 ( 18 ) : 184102 , May 2020 . [ 62 ] Tobias Sch¨afer , Alejandro Gallo , Andreas Irmler , Felix Hummel , and Andreas Gr¨uneis . Surface science using coupled cluster theory via local wannier functions and in - rpa - embedding : The case of water on graphitic carbon nitride . The Journal of Chemical Physics , 155 ( 24 ) : 244103 , Dec 2021 . [ 63 ] Atrip : An mpi - asynchronous implementation of ccsd ( t ) . https : / / alejandrogallo . github . io / atrip / . [ Accessed 07 - Jul - 2023 ] . [ 64 ] TREX CoE . QMCkl source code documentation . https : / / trex - coe . github . io / qmckl / README . html . [ Accessed 07 - Jul - 2023 ] . [ 65 ] Evgeny Posenitskiy , Vijay Gopal Chilkuri , Abdallah Ammar , Micha(cid:32)l Hapka , Katarzyna Pernal , Ravindra Shinde , Edgar Josu´e Landinez Borda , Claudia Filippi , Kosuke Nakano , Otto Kohul´ak , Sandro Sorella , Pablo de Oliveira Castro , William Jalby , Pablo L´opez R´ıos , Ali Alavi , and Anthony Scemama . Trexio : A file format and library for quantum chemistry . The Journal of Chemical Physics , 158 ( 17 ) : 174801 , May 2023 .