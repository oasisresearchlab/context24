Results from Deploying a Participation Incentive Mechanism within the Enterprise Rosta Farzan School of Information Science University of Pittsburgh 210 S . Bouquet St . Pittsburgh , PA 15260 rosta @ cs . pitt . edu Joan M . DiMicco , David R . Millen , Beth Brownholtz , Werner Geyer , Casey Dugan IBM Research 1 Rogers Street , Cambridge , MA 02142 { joan . dimicco ; david _ r _ millen ; beth _ brownholtz ; werner . geyer ; cadugan } @ us . ibm . com ABSTRACT Success and sustainability of social networking sites is highly dependent on user participation . To encourage contribution to an opt - in social networking site designed for employees , we have designed and implemented a feature that rewards contribution with points . In our evaluation of the impact of the system , we found that employees are initially motivated to add more content to the site . This paper presents the analysis and design of the point system , the results of our experiment , and our insights regarding future directions derived from our post - experiment user interviews . Author Keywords Incentive , reputation , enterprise , social networking ACM Classification Keywords H . 5 . 3 [ Information interfaces and presentation ] : Group and Organization Interfaces . INTRODUCTION Success and sustainability of social networking sites is highly dependent on user participation , and when certain user activity on a site has the effect of drawing other users to the site , it is especially critical that the site’s design has compelling incentives for these particular activities . Prior research done in psychology of community contribution [ 7 ] suggests four types of user motivation : an expectation of help in return , an increase in positive reputation , a sense of efficacy , and commitment to the community . Following on these findings in psychology , incentive systems have designed a variety of mechanisms , from incenting users with rewards and reputation [ 1 , 4 , 13 ] , to giving users specific goals to work towards [ 2 , 9 ] , to providing users features that personally benefit them [ 5 ] . We were interested in expanding on this work by building an incentive system into a tool within the enterprise , to determine if employees could be incented to increase their contributions to a company - internal web site . The website we chose as our platform is a social networking website for employees at IBM , a large software company . The site , called Beehive , provides a profile page for any user that signs up with the site , and users can share photos and lists on their profile . Users can also connect to others on the site , building out their social network , and they can comment on any profile , photo , or list on the site . The purpose of Beehive is to provide a platform for employees to get to know each other better and to have a mechanism for maintaining relationships with other employees on both a professional and personal level . As is the case with many community sites , for Beehive to fulfill its purpose , it is critical that the site have high and consistent levels of participation . As a first experiment in incentive systems , we decided to apply a point - based reward system to Beehive to determine if a point system with traditional ‘leveling - up’ to higher status levels could impact the behavior of employees . On the one hand , employees may find such systems to be contrary to their work ethic focused on producing high quality work and completing meaningful tasks , but on the other hand , point - based incentive mechanisms have been shown to be very effective in other domains , such as in peer - to - peer [ 11 ] and online learning communities [ 1 , 4 ] , so may also work within an enterprise setting . To design the point - based system , we analyzed seven weeks of usage data from Beehive to determine what types of activities on the site draw in the most visits . Based on this analysis , we designed a point system that awarded points to the types of content that receive the most views . To study the impact of the points system , we launched the feature to half of Beehive’s users , so one set of users saw the point system across the entire site and the other set of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . CHI 2008 , April 5 – 10 , 2008 , Florence , Italy . Copyright 2008 ACM 978 - 1 - 60558 - 011 - 1 / 08 / 04… $ 5 . 00 . CHI 2008 Proceedings · Policy , Telemedicine , and Enterprise April 5 - 10 , 2008 · Florence , Italy 563 users were unaware of the point system entirely . The results of our study demonstrate that points do have an impact on contributions to the site : users who saw the points contributed more content , although not indefinitely . To understand these findings in more detail , we interviewed six of the users in the point system’s experimental group , who explained their motivations for contributing , highlighting directions for future work . INCENTIVE SYSTEMS As summarized by Lui et al [ 11 ] , community contribution can be motivated by individual and interpersonal factors . Individual factors include extrinsic motivations , such as rewards and personal need , and intrinsic motivations , such as reputation and altruism . Interpersonal factors are motivations such as liking and affiliation . As mentioned previously , following the psychology research behind participation motivations , different systems have tried different approaches to encourage user contribution . The following is a brief overview of the different approaches . Incenting with Rewards To address users’ desire to receive something in exchange for contribution , one approach is to build a reward mechanism into the system . Bretzke and Vassileva have tried several reward mechanisms for encouraging contributions to their resource - sharing system Comtella [ 1 ] . Comtella is a system that allows the members of an online community share web resources amongst each other . The system rewards more cooperative users with incentives such as greater bandwidth for download or higher visibility in the community . A more recent version of Comtella uses an advanced reward mechanism to influence the quality of participation [ 3 , 4 ] . This new incentive mechanism only rewards high quality participation rather than all kinds . This is done by allowing the users to rate the contributions of others . Ratings are averaged and negative ratings serve to decrease the rewards given to low quality contributions . Incenting by Explaining Community Benefit According to the “collective effort” model people are more likely to work hard if they feel their contribution is important or identifiable to the group [ 8 ] . This matches users’ motivation to attachment or commitment to the community as suggested by Kollock [ 7 ] . Breenen , et al . applied this principle to the MovieLens system to address the problem of under - contribution [ 2 ] . They studied the effect of revealing to the user the uniqueness and benefit of their contribution , to determine which motivated users to rate more movies . In their analysis , they examined the differences between revealing the benefit to oneself versus the benefit to others . Their result shows that users are more likely to participate when they are reminded about benefit to oneself and the others . Also using the MovieLens system , Rashid , et al . studied the effect of identifying the beneficiary of a users’ contribution [ 12 ] , because it has been suggested that knowing the identity of the beneficiary plays an important role in attracting people’s contribution . Their results suggest how much the individual identifies with and likes the group correlates with user contribution level to the community . Incenting by Goal - Setting According to goal - setting theory [ 9 ] a challenging , short - term goal , rather than a vague , long - term goal stimulates high performance in users . Beenen et al [ 2 ] studied the effect of providing highly challenging and specific goals in motivating contribution in online communities by conducting an experiment in MoveLens . Their results show that specific goals resulted in higher number of ratings . Furthermore , they find out that group goals stimulate higher contribution than individual goals . Application of goal - setting theory can be observed in social - networking sites such as LinkedIn [ 9 ] which provided information about how complete a user’s profile is . Incenting by Reputation As suggested by Kollock [ 67 ] , reputation is an important factor motivating community contribution . Wasko et al [ 13 ] surveyed the users of an electronic network of a professional legal association to study the effect of reputation on users’ participation . They showed that people are more likely to share their knowledge when it enhances their reputation . At a basic level many social networking site employ reputation - based incentives by displaying the number of connections and friends a user has . Other community - based systems such as Flickr [ 6 ] address user reputation by highlighting specific user content , such as with Flickr’s “the most interesting photos . ” Incenting by Providing Self Benefit A final approach for incenting users is to encourage users’ participation by turning their feedback into an activity that is important and meaningful to them . Farzan and Brusilovsky used this approach in a course recommendation system by utilizing students’ rating of the courses to show their progress towards their career goals [ 5 ] . This is based upon the assumption that the main goal of students is to take courses that will help them to find an interesting career in the future . By rating the relevance of courses , students are better able to take advantage of the system and observe their progress towards each of their career goals . OUR APPROACH Choosing an incentive mechanism is greatly reliant on the nature of the application . A social networking site has certain characteristics that point towards incentive mechanisms that are more social in nature rather than task or feature focused , because the purpose of these sites is to enable and encourage social interaction . Given the different approaches outlined above , we thought that a first deployment of an incentive mechanism inside the enterprise should be a straightforward quantitative reward so that users would understand the system , and have an element of increasing a user’s reputation because an important part of the site’s social interaction includes impression management . Therefore we decided that a point - based incentive system that shows a user’s point value to both the user and to the community has appealing characteristics because it acts as both a reward and a way of increasing reputation . It would be difficult to incent users by explaining the community benefit of their contribution because the inherent value of contributed content to Beehive is not easily defined . Additionally , contributions made to Beehive do not offer any direct personal benefit to the users , besides the inherent pleasure in sharing with others , so it is not obvious what self - benefits could be used to incent users . However , it is possible to incent users by drawing attention for their contributions and highlighting those users who contribute the most . Therefore , to encourage greater contribution to Beehive , we settled on designing a point - based incentive mechanism that grants points and status labels to user , serving to give users a sense of reward and enhance the reputation of the top users . DESIGNING THE REWARD MECHANISM The first step in designing reward mechanisms for participation is figuring out which behavior ( s ) should be rewarded on a particular site . There are different types of actions that users can perform inside a social networking system but it is important to reward those actions that help the sustainability of the site . To design the reward mechanism we applied to Beehive , we considered the different types of content a user can add to the site . Beehive has three types of content : profiles , photos and lists . Users are able to add text content to their profile page as well as add social network connections . When users add photos , they upload digital pictures and provide a title and description . When users create lists , they create an itemized list of items on any topic of their choosing , which can say something about their background , interests , or opinions . Any visitor to the site can add comments to any content page , meaning any profile , photo , or list . Our goal was to determine which content generated the most activity on the site and reward that content with higher amounts of points . Right from the beginning , we decided that adding social network connections should not earn the user any points . Adding connections is as easy as a single click on the site and we were concerned that motivating people to connect would generate connections between people who did not have actual social relationships between them , distorting the social network of the site . Thus , we focused this analysis on determining how many points we should award to profiles , photos , lists , and comments . To do this , we measured the appeal of each content type on the site by measuring the amount of content generated of each type and the amount of comments each type received , over the first seven weeks the site was running . Table 1 presents these numbers , showing the number of profiles , photos , and lists , along with the number of comments put on all three . At the end of seven weeks , on average , each user had shared 3 . 0 photos and 1 . 3 lists and had commented 4 . 0 times on the site . These numbers indicate that photos are the most popular item to share on the site and content everywhere on the site is receiving comments . To evaluate the value each piece of content adds to the site , we computed the average number of clicks and comments each content type received . Figure 1 presents the average number of clicks on each photo and list across the seven weeks , excluding the clicks done by the owner of the content . Kruskal - Wallis 1 test of equality of populations shows significant difference between number of clicks on photos and lists every week ( α = 0 . 01 ) . Therefore the result suggests that lists attract significantly more visits than photos . Table 1 . The amount of each type of content on Beehive , across the first 7 weeks of usage Week Num of Profiles Comments on Profiles # of Photos Comments on Photos # of Lists Comments on Lists 1 65 66 133 45 64 28 2 90 118 193 74 92 55 3 105 155 251 119 117 87 4 118 196 308 144 137 121 5 126 227 373 164 164 151 6 160 270 480 179 217 182 7 185 292 562 201 245 244 0 2 4 6 8 1 2 3 4 5 6 7 Week c li cks Lists Photos Figure 1 . The average number of clicks on each photo and list over the first 7 weeks of usage of Beehive Figure 2 presents the average number of comments on photos and lists throughout the same time period . Again we excluded the comments left by the owner of the content . It is important to notice that the average number of comments is generally small , which is partially due to large number of photos and lists without comments . As shown in the figure , 1 Shapiro - Wilk W test for non - normality suggests that the sample is unlikely to be from a normal distribution . Therefore we used the non - parametric test of Kruskal - Wallis . across all seven weeks , the average number of comments on lists is higher than on photos ; however , the difference is only significant for last 4 weeks ( Kruskal - Wallis test ) . Nevertheless this result suggests lists attract significantly more comments as well as clicks . 0 0 . 2 0 . 4 0 . 6 1 2 3 4 5 6 7 Week c o mm en t s Lists Photos Figure 2 . The average number of comments on each photo and list over the first 7 weeks of usage of Beehive To determine the impact of comments on a single piece of content , we calculated the number of clicks a piece of content received before and after the first comment was made . Figure 3 and Figure 4 show the box plots comparing the number of clicks on photos and lists before and after the first comment . As shown in the figures , both photos and lists are visited more frequently after being commented on . The difference for photos is statistically significant ( Wilcoxon matched - pairs signed - rank test , α = 0 . 01 ) but in case of the lists the difference is not significant . Photos 0 5 10 15 Before After Figure 3 . Box - plot comparing the number of visits on photos List 0 5 10 15 20 25 Before After Figure 4 . Box - plot comparing the number of visits on lists To evaluate the importance of profile information , we compared the percentage of clicks on profile pages with the percentage of clicks on all the other possible sections of the site ( list , photo , network , and home pages ) . Figure 5 compares these percentages . Figure 6 compares number of comments left on profile pages versus comments left on photos and lists . The results in both of these figures suggest that profile pages attract a large percentage of clicks and comments as compared to other parts of the site . 0 % 20 % 40 % 60 % 80 % 100 % 1 2 3 4 5 6 7 Week ViewProfile OtherViewingactions Figure 5 . Percentage of clicks on profiles vs . clicks on photos , lists , people , network , and homepage , combined 0 % 20 % 40 % 60 % 80 % 100 % 1 2 3 4 5 6 Week Profile List Photo Figure 6 . Percentage of comments on profile pages vs . lists vs . photos Our conclusions from this analysis are : • because viewership of profiles is popular , having some content on the profile page is important for keeping the site vibrant ; • both lists and photos attract visitors , with lists drawing the most visitors ; • and comments are particularly influential for drawing visitors , on all types of content . Thus we decided our points reward equation would be follows : 5 points for every photo , 10 points for every list , 15 points for every comment , and a one time 100 points awarded for adding information to the profile page . We also defined four status classes based on the number of points , as shown in Table 2 . The purpose of this was to provide some benchmarks for users to know how they stand in relation to how many points we believe they should have , assisting users in setting goals and seeing a change in status as a reward for their site activity . We designed the points spread between classes with the intent of encouraging the lower end to add a little content and creating a greater challenge on the higher end . We made it very easy to move out of the first point class to the second : a user can do as little as add one piece of text content to their profile and then add either one list or one comment to jump from “new bee” to “worker bee . ” We thought this would provide motivation to get the user started . To move from the second level “worker bee” to third status “busy bee” requires more work , encouraging an active level of participation . The hardest level to achieve is “super bee” because we wanted the majority of the users to be in the “busy bee” class , keeping the users motivated to contribute . At the time we set these status classes , no user on the site had enough points to be a “super bee . ” Table 2 . point based status classes Status class Number of Points new bee < 110 worker bee < 500 busy bee < 2000 super bee > = 2000 Implementation of the Reward System With the points and status system designed , the next step was to implement the user interface on the site in such a way that users would become aware of their point levels and the point levels of those they care to compare themselves to . We designed a separate page on Beehive that explains the reward mechanism and shows the user his / her point status , as shown in Figure 7 . The page describes how users can earn points and illustrates the point formula using the user’s actual data . The graphics denoting the number of photos , lists and comments are identical to what the user would see on their profile page . The page also shows the range of all four status classes and the user’s position within that range . To assist users in making easy comparisons with other people on the site , when a user is looking at his / her points page , by scrolling down to the bottom , the user can compare his / herself with everyone in his / her Beehive social network , as shown in Figure 8 . The user’s connections are listed , ordered by their number of points , and when the user hovers the mouse over one of the names , it appears on the status class bar , highlighting the distance between the user and the individual in focus . Figure 7 . Presentation of information about the points and status classes Figure 8 . Comparing oneself with one’s network Figure 9 . List of top ten users with the highest number of points , shown on each user’s homepage Figure 10 . Advertising points and status Figure 11 . Top users on Beehive While we believe that awarding points alone may inspire some users to contribute more to the site because it can be seen as a reward , we also want to provide users with the personal benefit of increased reputation , because of the social focus of the site . By granting greater visibility to the users with the most points , the site will highlight their status to all users on the site and perhaps project an aspect of their expertise regarding using the site . We have incorporated this into the site by revealing point - related information on different parts of the system . Firstly , the ten users with the highest number of points are shown on the homepage of Beehive ( Figure 9 ) . We believe this will encourage users to contribute more , in order to place themselves in this top position of visibility on the homepage . The number of points and the class label of every user are always shown on the name badge on users’ profile page and anywhere on the site where a list of users is shown ( Figure 10 ) . This informs the user about the number of points every member of the site has , so that the user can compare him / her to this user . To especially highlight the top users , a new menu item was added called “top users on beehive , ” which takes the user to a page that shows all of the top users on the site ( Figure 11 ) . We wanted to increase the visibility of these types of users because they are so important for the health of the site , and we hope that they see this increase in visibility as personal motivation to continue to contribute to the site . EVALUATION OF INCENTIVE SYSTEM To evaluate the effect of the point system , we designed a controlled study . The goal of the study was to answer the following questions : • Does our point - based incentive system encourage users in an enterprise environment to add more content ? • Does assigning more points to comments encourage users to add more comments than photos and lists ? • Do incented users stop contributing after reaching a specific level ? • If incented users add more content to the site , does that inspire others to visit the site and add content ? Study Design To carry out the study , we assigned users randomly into two groups , control and experimental . In assigning the groups , we controlled for the joining time to make sure that average time of using the system in both groups was similar . The control group did not see any information about how to earn points or any other point - related information . The experimental group could see how to earn points and all other point - related information about themselves and others , including the members in the control group . ( During the experiment , a few users in the control group asked us why they couldn’t see their points and submitted bugs that their browsers didn’t show the bee icons . We explained we were running an experiment to test a feature . Although these users were aware of the experiment , they could not see their point values or compare themselves to their social network , so we do not believe their activity on the site was influenced by the point system . ) The evaluation was done though log analysis considering six weeks of usage logs – the three weeks before adding the point system and the three weeks after . For consistency we limited our analysis to the users who used the system consistently over the six - week period , which means they logged in at least once every week . We had 63 users in each group . Study Results Does our point - based incentive system encourage users in an enterprise environment to add more content ? To evaluate the significance of the point system , we compared the content being added by each group the week before and the week after the introduction of the points system . Error ! Reference source not found . , Error ! Reference source not found . , and Error ! Reference source not found . presents the data related to the number of lists , photos , and comments added by both groups . The results show a small decrease in the average number of contributions per person for the control group ( . 41 vs . . 26 contributions / person ) whereas there was a substantial increase in contributions for the experimental group after the point incentives were introduced ( . 62 vs . 1 . 85 contributions / person ) . These results shows a significant interaction between time and group ( df = 1 , 124 , F = 3 . 14 , p = 0 . 039 ) indicating that the groups behaved differently from each other over time . This was analyzed using a repeated - measures ANOVA , considering time as the repeated measure ( the week before and the week after introduction of points ) , group ( experimental , vs . control ) as the independent variable and total amount of new content added to the site as the dependent variable . In the three weeks following the introduction of the points , the amount of content contributed by the experimental group declined , returning to the levels of the control group . Figure 15shows this decline . A repeated - measures ANOVA comparing the three weeks after the points introduction shows a significant interaction of time and group , indicating that there is a significant decrease in the effect of points over time ( df = 1 , 124 , F = 6 . 55 , p = 0 . 0015 ) . List 0 0 . 1 0 . 2 0 . 3 before after exp control Figure 12 . Comparing the number of lists added by control and experimental groups before and after introducing points Photos 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 before after exp control Figure 13 . Comparing the number of photos added by control and experimental groups before and after introducing points Comments 0 0 . 2 0 . 4 0 . 6 0 . 8 1 1 . 2 1 . 4 before after exp control Figure 14 . Comparing the number of comments added by control and experimental groups before and after introducing points Does assigning more points to comments encourage users to add more comments than photos and lists ? For further analysis of the effect of incentive points , we looked at each type of content separately . Figure 15 highlights the results for the experimental group for different content types . When the points were first introduced , users in the experimental group added more comments ( avg = 1 . 22 ) than any other type of content ( avg . photos = . 43 , avg . lists = . 21 ) . Two - sample , paired t - tests comparing each of these types added after introducing points shows significant difference between the number of comments and lists ( t = - 1 . 9 , p = 0 . 03 ) , marginally significant difference between comments and photos ( t = - 1 . 6 , p = 0 . 05 ) , and no significant different between photos and lists ( t = 1 . 35 , p = 0 . 18 ) . This indicates that the users in the experimental group understood how to earn points and chose to add more comments than the other content types that earned fewer points . Moreover , it confirms that the peak in their adding content behavior is not a random response to a new feature in the system . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 1 2 3 4 week comment Photo List introducing points Figure 15 . Effect of points on experimental group behavior Do incented users stop contributing after reaching a specific level ? Looking into the behavior of individuals in the experimental group we observed that there seemed to be three different types of reactions to the point systems : • High contributors : these users consistently contributed highly after the points were introduced and their choice of contributions appear to be influenced the different point values assigned to the different content types , • Top - ten focused : these users continually added content to the site ensuring they remained within the top ten users on the site , • Level focused : these users added just enough content to the site to jump to the next status level and then they slowed down or stopped their contributions . Figure 16 graphs three users displaying each of these behaviors . The first data point in these charts is labeled “Pre , ” as in pre - introduction of the points . And the following weeks show the three weeks that the experiment ran . To validate our hypothesis that users were motivated in these three different ways , we interviewed users from each behavior group . In the next section , discussing the conclusions of the study and our interviews , we will present the details of what our users said about their motivations in relation to the points and status levels in the system . 0 200 400 600 800 1000 1200 1400 1600 1800 Pre Week1 Week2 Week3 High Contributor Top Ten Focused Level Focused Top Ten Range newbee busybee workerbee Figure 16 . Profile of a sample user in each category 2 In our analysis of how much users visited the points page , we discovered that 72 % of the users in the experimental group never actually visited the page describing the how to earn points throughout the three weeks of the experiment . This indicates to us that a large portion of the users may not have even noticed the existence of points , and therefore their behavior could not have been influenced by it . While we had thought it would be visible enough , in the ways described in the design section , it appears to not have been . Because we did obtain strong statistical evidence that the points - system inspired the experimental group to add content , yet the majority of the users in the experimental group were unaware of the system , we are convinced that points do influence content contribution . By increasing the visibility of the point system throughout the site , we could more dramatically impact the amount of content added to the site . If incented users add more content to the site , does that inspire others to visit the site and add content ? We hypothesized that an increase in contributions to the site would inspire more visits , even from the users in the control group . To validate our hypothesis , we computed the average number of views per user on the different content types over the six week period ( excluding clicks done by the owner of the content ) . Moreover , we compared the number of login times over the six weeks period . The data is depicted in Figure 17 . It is interesting to observe that the control group’s browsing and login patterns follow the experimental group’s pattern of adding content . As shown previously , the data suggests that the experimental group significantly added more content in week 4 in response to points . Looking into the browsing pattern of control group , there is a noticeable increase in logins and clicks on photos and profile pages in week 5 . This suggests that the increase of data in week 4 resulted in more visits from the control group in week 5 . However , as the experimental group contribution dropped 2 Profiles of three users out of the six who were interviewed . after week 4 , we observe that number of logins and clicks by the control group is dropping after week 5 . 0 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 Week A v e r age pe r u s e r Login Hive5 Photo People Introduced points Figure 17 . The number of logins and views on lists , photos and people in the control group before and after points were introduced To further study if the control group was influenced by the increase in content provided by the experimental group , we investigated the effect of comments left by experimental group on subsequent commenting behavior of the control group . The data shows that 59 . 2 % of comments left by the control group were in direct response to comments written by the experimental group ( 40 . 8 % of their comments were left on content with no prior comments or on content with comments from control users ) . This suggests that the experimental group’s comments drew the control group to the site and inspired them to respond to the communication sent by the experimental group users . The combination of these two findings suggests that the experimental group’s behavior did inspire others to visit and add comments to Beehive . Results Discussion and User Interviews The quantitative results from our study show that the users who saw the point system increased their contributions to the site immediately after the system was introduced on Beehive . After that point , there was a decay on the effect of the points on content creation . We saw the largest effect on the contribution of comments to the website , which is in line with what would be expected , given that comments received the highest amount of points . Examining the group of users who responded to the points more closely , it appears that some users were motivated to move their point status up to the next status level on the site , others were motivated to simply gain many points , and others were motivated to get themselves into the top ten position in the system and maintain their position there . To understand if our conjectures about user motivation were in fact how users were thinking about points , we interviewed six users within the point system experimental condition . We chose these six interview subjects based on their variety of behaviors on the site . The interviews were either on phone or face - to - face , in a semi - structured form . As we describe below , the feedback provided in the interviews confirmed our observations from the log analysis and offered further insight for future work . Different Behavior in Response to Points Prior to our interviews , we had classified the six interview subjects into the three different behavior patterns we observed on the site . Three of them appeared to be “level - focused , ” two appeared to “top - then focused , ” and one appeared to be a “high contributor . ” The data showed that level - focused users stopped contributing immediately after jumping to the next level . The interviews confirmed our observation and all three users explicitly stated that they had been encouraged by the points to get to the next level . The followings are quotes from the three level - focused users : “I stopped contributing right after getting to busy - bee level . ” “I didn’t want to be a new - bee . …I wanted to be a busy - bee . ” “I was really close to [ the ] 500 border and wanted to make it to the next level . ” The data related to top - ten focused users suggest that in order to maintain their position within the top ten , they were motivated to add content to the site over time . Of these interview subjects , one of the interviewees indicated that she wanted to consistently stay ranked above certain people by saying : “I have to be above other people that I work with . ” Her reasoning was that she wanted to be considered an expert in using this social software as part of her job . The other interviewee in the top ten said that he was happy to be in the top ten but that he was not specifically focusing on remaining there . Our conclusion from these users is that the users we saw as top - ten focused , may be more focused on competing within their social network and than being on specifically being on the top of the entire site . The outcome of their competitive behavior is that they remain in the top ten , but they were motivated by their desire to have a certain point value in relation to their social network . The data related to the high contributors shows continuous contribution over time . When we interviewed our example of a high contributor , she said that her main thought about the point system was this : “What will get me the most points ? Commenting . ” She further explained that she deliberately focused on adding comments to the site . She then said that after some time , she stopped paying attention to her exact point value and on making comments , but rather just continued to contribute to the site consistently without a constant focus on the points . This may have been because she was ranked in the number two position on the site and had very little distance to go to obtain the number one slot . Value of comments In our interviews , three users explicitly talked about the value of comments and approved of our decision to award comments the highest number of points . They described comments as a content type for building connections on the site and a way to get feedback about the usefulness of their content . Supporting our design , one of the interviewees stated that , after being encouraged by the points to write more comments , she felt more connected to the community of users because she had left comments on content she liked . Sustainability Our quantitative data shows that the impact of the point system quickly decayed after introduction . Because of this , we considered the fact that our point system never decreases a user’s point or status level over time . With no dynamic nature to our system , after a user has reached his / her desired level , there is no reason to ever push further . As soon as one reaches one’s desired position , the status is forever preserved , even if one stops contributing . The feedback from the interviews verified this . Here are quotes from four users indicating that they observed the static nature of the points and had a desire for them to decay so that they would have a reason to continue contributing : “I would continue contributing if the points were temporal . ” “ [ I think ] points should decay over time . ” “It’s funny that the points don’t degrade over time . ” “ [ There is ] nothing to show I was less busy last week . ” These quotes suggest that the users were aware that the static nature of the points had an impact on their behavior . This may indicate that a dynamic point system could be much more effective for sustaining high contributions to the site . Comparison with Others A large portion of the point’s web page is allocated to comparing oneself with the people in one’s network . We hypothesized that this design would encourage competition between users and that would inspire users to contribute in order to earn points . The previous quotes from our top - ten focused users begin to support this hypothesis . In further support , one of the interviewees described taking a screenshot of this page the first time he went to it , so that he would be able to observe his progress of earning points in comparison to the other people in his network . Other interviewees mentioned specifically caring about being ahead of the people they work with or being ahead of specific people : “I wouldn’t want to be less than others . ” “I don’t want to be seen as only a reader and not a contributor . ” From these comments , we believe that comparison to one’s network was an influential factor in motivating users to increase their points . CONCLUSIONS AND FUTURE WORK We began this research asking the question whether or not a point - based incentive system would motivate employees to contribute more to a company - internal social networking website . Our study results and interviews indicate that employees are definitely motivated by both points and status levels within our test platform , Beehive . Furthermore , we found evidence that this increase in contributions to the site inspired other users to visit more and comment more . The weakness of our point system was that the points and status did not have a decay function , nor were they dynamically adjusting to the user’s behavior or to factors on the site . We believe that this was main reason that we observed that the increase in contributions diminished shortly after the launch of the system . Our interviewees also raised this as an issue they were aware of and thought influenced their behavior . Our lesson from this is that when designing incentive mechanisms , it is important to consider that the benefits to the community may not offset the costs of building the system if the incentive mechanism does not continually incent users to contribute over time . On the other hand , running controlled experiments like the one we ran can be an effective method for determining the strengths and weakness of different incentives , which can aid designers in deploying the most effective mechanism for their community . Our next steps in this research will be to two - fold . First , we plan to explore applying a dynamic model to the point system to see if that will generate a sustainable increase in contribution levels . Second , we plan to apply a different type of incentive system to the site , again selecting from previous approaches taken , to observe which approach is most effective and appropriate for a workplace environment and for a social networking site . Our longer - term vision for this area of work is designing an incentive mechanism for an enterprise social network which targets large number of users with different characteristics and is sustainable over time . ACKNOWLEDGMENTS We thank all of the users of Beehive , especially our interview subjects . REFERENCES 1 . Bretzke H . , Vassileva J . ( 2003 ) Motivating Cooperation in Peer to Peer Networks , In Proc . Of UM03 , Springer Verlag LNCS 2702 , ( 2003 ) , 218 - 227 . 2 . Beenen G . , Ling K . , Wang X . , Chang K . , Frankowski D . , Resnick P . , Kraut R . E . , Using social psychology to motivate contributions to online communities , In Proc . CSCW 2004 , ACM Press ( 2004 ) , 212 - 221 . 3 . Cheng R . , Vassileva J . Design and Evaluation of an Adaptive Incentive Mechanism for Sustained Educational Online Communities . User Modeling and User - Adapted Interaction , special issue on User Modeling Supporting Collaboration and Online Communities ( 2006 ) , 16 ( 2 / 3 ) , 321 - 348 . 4 . Cheng , R . , Vassileva , J . : User motivation and persuasion strategy for peer - to - peer communities . In Proc . of the 38th Hawaii International Conference on System Sciences ( Mini - track “Online Communities in the Digital Economy” ) , IEEE Press ( 2005 ) , 193 – 202 5 . Farzan , R . , and Brusilovsky , P . Social navigation support in a course recommendation system . In : V . Wade , H . Ashman and B . Smyth ( eds . ) In Proc . AH ' 2006 , Springer Verlag ( 2006 ) , pp . 91 - 100 6 . http : / / www . flickr . com 7 . Kollock P . , The economies of online cooperation : gifts and public goods in cyberspace , In : Smith , M . A . , Kollock , P . ( Eds . ) , Communities in Cyberspace . Routledge , ( 1999 ) London . 8 . Ling K . , Beenen , G . , Ludford , P . , Wang , X . , Chang , K . , Li , X . , Cosley , D . , Frakowski , D . , Terveen , L . , Rashid , A . M . , Resnick , P . , and Kraut , R . Using social psychology to motivate contributions to online communities . JCMC , 10 ( 4 ) , 2005 . 9 . http : / / www . linkedin . com 10 . Locke , E . A . and G . P . Latham , Building a practically useful theory of goal setting and task motivation : A 35 year odyssey . American Psychologist , ( 2002 ) . 57 ( 9 ) : p . 705 - 717 . 11 . Lui S . , Lang K . , Kwok S . , Participation Incentive Mechanisms in Peer - to - Peer Subscription Systems , In Proc . of HICSS ' 02 , IEEE ( 2002 ) , Volume 9 , 302 - 309 . 12 . Rashid , A . M . , Ling , K . , Tassone , R . D . , Resnick , P . , Kraut , R . , and Riedl , J . Motivating participation by displaying the value of contribution . In Proc . of CHI 2006 , ACM Press ( 2006 ) . 955 - 958 . 13 . Wasko , M . M . and Faraj , S . , Why should I share ? Examining social capital and knowledge contribution in electronic networks of practice , MIS Quarterly ( 2005 ) , Vol . 29 No . 1 , 35 - 47 .