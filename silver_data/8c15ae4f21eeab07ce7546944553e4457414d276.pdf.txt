minOffense : Inter - Agreement Hate Terms for Stable Rules , Concepts , Transitivities , and Lattices Animesh Chaturvedi Indian Institute of Information Technology Dharwad Dharwad , Karnataka , ( India ) animesh . chaturvedi88 @ gmail . com Rajesh Sharma University of Tartu Tartu , ( Estonia ) rajesh . sharma @ ut . ee Abstract —Hate speech classification has become an important problem due to the spread of hate speech on social media platforms . For a given set of Hate Terms lists ( HTs - lists ) and Hate Speech data ( HS - data ) , it is challenging to understand which hate term contributes the most for hate speech classification . This paper contributes two approaches to quantitatively measure and qualitatively visualise the relationship between co - occurring Hate Terms ( HTs ) . Firstly , we propose an approach for the classification of hate - speech by producing a Severe Hate Terms list ( Severe HTs - list ) from existing HTs - lists . To achieve our goal , we proposed three metrics ( Hatefulness , Relativeness , and Offensiveness ) to measure the severity of HTs . These metrics assist to create an Inter - agreement HTs - list , which explains the contribution of an individual hate term toward hate speech classification . Then , we used the Offensiveness metric values of HTs above a proposed threshold minimum Offense ( minOffense ) to generate a new Severe HTs - list . To evaluate our approach , we used three hate speech datasets and six hate terms lists . Our approach shown an improvement from 0 . 845 to 0 . 923 ( best ) as compared to the baseline . Secondly , we also proposed Stable Hate Rule ( SHR ) mining to provide ordered co - occurrence of various HTs with minimum Stability ( minStab ) . The SHR mining detects frequently co - occurring HTs to form Stable Hate Rules and Concepts . These rules and concepts are used to visualise the graphs of Transitivities and Lattices formed by HTs . WARNING : This paper contains offensive language that commonly appears in hate speeches . Hate speech text present in this paper does not represent the views of authors . Index Terms —Harmful Content Online , Hate Speech , Natural Language Processing , Computational Linguistics , Data Analytics . I . I NTRODUCTION The spread of hate speech , especially on online social media platforms has forced Governments and policy makers to enact laws to curb this menace . Researchers have presented various solutions for predicting hate speech . These solutions often include the usage of predefined set of Hate Terms ( HTs ) ( e . g . , f * ggot , b * tch , f * ck , etc . ) for identifying hate speech . However , these solutions miss the fact that for a given Hate Speech data ( HS - data ) a list of HTs might not be effective in detecting Hate - Speech effectively . This is due to the fact that a Hate Terms list ( HTs - list ) might not be able to capture the severity and context of a HT , which is always important in detecting Hate - Speech . For multiple HS - data and multiple HTs - lists , we aim to investigate : i ) quantitative and ii ) qualitative analysis . Firstly , we perform quantitative analysis [ 1 ] using three pro - posed metrics : Hatefulness , Relativeness , and Offensiveness . ( See Section II ) . These metrics are inspired by the concepts of Shapley value [ 2 ] [ 3 ] , in particular on the idea of “the contribution by individual players in a game” . In our case , these metrics calculate “the contribution of an individual HT towards hate speech” , which is then used for generating Severe HTs - list for a specific HS - data . Secondly , we perform qualitative analysis inspired from Association Rule Mining , which provides an exhaustive list of association rules as an output . To extract only important rules , the ” interestingness ” measure [ 4 ] uses multiple thresholds to retrieve interesting and significant rules out of all the exhaustive rules . The interestingness separates interesting rules from the less or non interesting rules . The occurrence of any two HTs , for example , A and B together ( where A → B ) can have three interestingness thresholds : 1 ) minimum Support ( minSup ) is a threshold for minimum number of occurrences of HTs A and B occurring together , 2 ) minimum Confidence ( minConf ) is a threshold for minimum number of occurrences of A ∪ B divided by number of occurrences of HT A i . e . , N ( A ∪ B ) ÷ N ( A ) . 3 ) minimum Stability ( minStab ) is a threshold for minimum number of states in which rule exceeds minSup & minConf [ 5 ] - [ 7 ] . In our case , the stability is the number of HS - data in which a hate rule occurs with sufficient minSup and minConf . Hate rule occurring more than a minStab number are said to be Stable Hate Rule . To help in making efficient HS decisions , this work inves - tigates the following four research questions ( RQs ) . RQ1 : How to perform Inter - agreement analysis , which provide information about common HTs between a HS - data and multiple HTs - lists ? Approach : We generate an Inter - agreement HTs - list that contains HTs and two kinds of information about these HTs . First , it contains Offensiveness metric value of each HT in the HS - data and second , the HTs - lists which contains those HTs . The Inter - agreement HTs - list means agreement between the HS - data and the multiple HTs - lists ( see Section II ) . RQ2 How to use an Inter - agreement HTs - list to generate a Severe HTs - list for efficient Hate Speech classification ? Approach : From the Inter - Agreement HTs - list , we generate the Severe HTs - list having HTs with Offensiveness values above a proposed threshold minimum Offense ( minOffense ) . Severe HTs - list helps in HS classification ( see Section II ) . 2022 I E EE 9 t h I n t e r n a ti on a l C on f e r e n ce on D a t a S c i e n ce a nd A dv a n ce d A n a l y ti c s ( D S AA ) | 978 - 1 - 6654 - 7330 - 9 / 22 / $ 31 . 00 © 2022 I EEE | DO I : 10 . 1109 / D S AA 54385 . 2022 . 10032389 RQ3 How much better classification is achieved using the Severe HTs - list compared to any of the given HTs - lists ? Approach : We made a confusion - matrix to demonstrate the quality of classification for a HS - data over classes ( Hate , Relative - hate , No - hate ) . We found Severe HTs - list provides better results for confusion - matrix ( TP , TN , FP , FN , precision , recall , f - measure , and accuracy ) . This provides empirical jus - tification , to measure the inter - agreement between the Severe HTs - list with a HS - data as compared to the inter - agreement between the given set of HTs - lists with the HS - data ( see Section II ) . RQ4a : How to generate Stable Hate Rules ( SHRs ) that represent frequently co - occurring HTs among multiple HS - data ? Q4b How to make hate concepts and visualise the relationship between co - occurring HTs from SHRs ? Approach : The Inter - agreement HTs - list is used to make an intermediate representational database . Then , we used Stable Hate Rules mining over the database to discover co - occurring HTs . This helps to discover and analyse the co - occurring concepts of HTs ( see Section III ) . By exploring the solutions to the above four research questions , we put forward a mechanism for effective analysis : severity of each HT and co - occurrences of HTs . Note , the notation N denotes total Number of terms , lists , or datasets etc . To the best of our knowledge , this work is the first to introduce the metrics that measures the severity of Hate Terms . II . Q UANTITATIVE ANALYSIS : I NTER - A GREEMENT AND S EVERE H ATE T ERMS LISTS This section provides a quantitative analysis approach to generate an Inter - agreement HTs - list , which is further used to extract the Severe HTs - list for efficient hate speech classifica - tion . It is to be noted that HS - data may include non - hate data , either annotated wrongly as hate or misclassified as hate due to an inefficient classifier . In addition , we define the following three classes of hate speech , which captures the intensity of hate being present in the hate speech - Hate : class indicates the lines definitely contain HTs . - Relative - hate : class indicates the lines contain mild HTs . - No - hate : class indicates the lines do not contain HTs . We first describe hate speech analysis based on a HS - data with a single HTs - list ( Section II - A ) , then we explain a HS - data analysis using multiple HTs - lists ( Section II - B ) . A . Single Hate Terms List Analysis To do HS - data analysis , we retrieved five intra - agreement artifacts using a single HTs - list . We analyse HTs ( in HTs - list ) appearing in a line ( e . g . in tweet or post ) based on three classes ( Hate , Relative - hate , or No - hate ) . 1 . Creation of hate terms frequencies : As a first step , we parse the whole HS - Data text into separate lines based on the number of HTs it contains . It is denoted by N ( X ) , where X ∈ [ 1 , Z ] ( where Z represents the maximum number of hate terms in a line ) and for a certain X value N ( X ) points to all the lines which contain X number of HTs . Some X may not exist in N ( X ) i . e , X might be a discontinuous series of integers . 2 . AllHateTermsFrequencies and TopTermsFrequency : For each class of HS - data , these two provides information about the number of each hate term’s occurrences ( i . e . HTs’ frequencies ) and the HTs with top - X frequencies ( where X is an input parameter ) , respectively across the whole HS - Data . 3 . AllHTsPercentLine : For each HT in each class , the percentage of lines containing the HT across all the lines belonging to that class . 4 . OuterJoinHTsFrequencies and OuterJoinHTsPercent - Lines : These two give information about each HT ( with frequency and its percentage ) occurrences in a HS - data class . AllHateTermsFrequencies of all HTs in a class is used to produce outer join of frequencies of HTs in all classes . AllHTsPercentLine of each class is used to produce outer join of percentage HS - lines where HTs occur in all classes . 5 . Intra - Agreement between a single HTs - list and a HS - data : This provides the contribution of HTs in a single HTs - list towards a HS - data . The contribution is measured using two proposed metrics : Hatefulness and Relativeness . For each HTs over three classes ( Hate , Relative - hate , and No - hate ) , we calculate Hatefulness and Relativeness . These metrics have two cases for i ) Hate class , and ii ) Hate and Relative - hate classes . Definition : Hatefulness would be 1 if the Hate Term ( HT ) occurs in the hate speech class , otherwise it would be 0 . Mathematically , Hatefulness = { 1 or 0 | HT ∈ Hate class or not , respectively } Definition : Relativeness is the proportion of hate class to other classes ( Relative - hate or No - hate ) . Mathematically , Relativeness ( Hate ) = FreqHT in Hate Class FreqHT in Relative - hate class and FreqHT in No - hate class Relativeness ( Hate + Relative - hate ) = FreqHT in Hate Class + FreqHT in Relative - hate class FreqHT in No - hate class where FreqHT is the number of occurrences of the HT . In relativeness , when both numerator and denominator provide zero , it reflects HT neither belongs to Hate nor it belongs to No - hate classes in that HS - data . Relative - hate class leads to the ambiguous situation , where hate is contextually hateful . B . Multiple Hate Terms Lists analysis Mostly , the current state - of - the - art is limited to the hate speech analysis using single HTs - list . Next , we extend single HTs - list based analysis to multi HTs - lists analysis . Inter - agreement Hate Terms Analysis defined as the analysis of a HS - data , which is performed using a given set of multiple HTs - lists = { HTs - list1 , HTs - list2 , . . . HTs - listN } . Mathematically , we describe Inter - Agreement HTs Analysis as a matrix IA of size N × M , where N represents the number of HTs - lists and M number of classes in a HS - data . The IA ij represents the information about HTs of a given HTs - lists , which are present in a class of HS - data . Here , i represents HTs - list and j represents HS - data class . This answers RQ1 . In addition to the five intra - agreement artifacts , to perform the Inter - agreement HTs analysis we also created three inter - agreement artifacts that are defined as follows . 6 . Inter - Agreement HTs : For a given HS - data , this gives information about three metrics ( Hatefulness , Relativeness , and Offensiveness ) of all HTs present across all HTs - lists . This artifact also provides information about membership of HT “which HTs - list contains which HT” . This list is used to generate Severe HTs - list with significantly severe HTs . We defined the contribution of a HT towards the three labels ( Hate , Relative - hate , No - hate ) to generate the Intra - agreement HTs Matrix . For a matrix , let each HT have some contribution in HS - data due to Hatefulness and Relativeness . The Fig . 1 demonstrates the varying value of this Offensiveness for a HT . For a given HS - data , the HT will be most Hateful when its Offensiveness equals to 1 and the HT will be least hateful when its Offensiveness value is equal to 0 . Fig . 1 . Varying value of the Offensiveness of a HT for a given HS - data divided into classes ( Hate , Relative - hate , and No - hate ) . Definition : Offensiveness is the Harmonic mean of the Hatefulness and Relativeness . Another alternative means could be the Geometric mean . Mathematically , Offensiveness = 2 × Hatefulness × Relativeness ( Hatefulness + Relativeness ) For each HT , the calculated Offensiveness signifies the severity of a hate term . The severity of the hate term is the interestingness with high Offensiveness value . For hate - severity of a HT , we formulate the Offensiveness to classify terms either as hate or non - hate . This means , we considered the percentage contribution ( i . e . , overall input towards cost ) of a hate term occurrences to a hate class . The Hatefulness , Relativeness , and Offensiveness provide severity of HTs using HS - data labels . The three metrics are calculated for all HTs occurring in a given set of HTs - lists . Answers to RQ2 . The steps to generate Severe HTs - list using Inter - agreement HTs - list , which assists in better inter - agreement analysis . The Offensiveness provides help to separate out the highly severe HTs and the less severe HTs . Based on the high values of Offensiveness , we generated the Severe HTs - lists . The Severe HTs - list has been generated with HTs having Offensiveness value greater than a user - defined interestingness threshold minimum Offense ( minOffense ) . This step can be performed iteratively and heuristically to generate the Severe HTs - lists with various minOffense values . The expectation of the Severe HTs - list is to produce better hate speech classification as compared to the given set of HTs - lists . We present our results in a confusion - matrix as the Inter - Agreement between the HS - data and the given set of HTs - lists . Fig . 2 . Flow of Inter - agreement analysis for generation of Severe HTs - list . 7 . Inter - agreement Confusion - matrix : This provides in - formation about confusion - matrix with True Positive ( TP ) , True Negative ( TN ) , False Positive ( FP ) , and False Negative ( FN ) for the calculation of accuracy , precision , recall , and f - measure of each HT in all HTs - list for a HS - data . The calculation is done for the three cases given in the Table I . As per binary - relevance [ 9 ] , we combine two HS - data classes ( Hate , Relative - hate , No - hate ) only if they are cor - related . This is useful , when it is required to model hate - speech analysis as binary classification . Thus , we transformed three classes to binary classes , where two similar classes ( e . g . Hate and Relative - hate ) represent one class versus ( Vs ) No - hate . This means , we can combine Hate with Relative - hate assuming both are binary relevant . Thus , we exploited the binary relevance ( i . e . , correlation ) to do binary classification denoted as Hate + Relative - hate Vs No - hate . For the three classes , there are a total of 8 ( 2 3 ) possible cases . Considering binary - relevance , the Relative - hate class can fall into Hate or No - hate . This reduce the number of cases to 6 : Hate Vs No - hate ; Hate Vs Relative - hate ; Hate Vs Relative - hate + No - hate ; Hate + Relative - hate Vs No - hate ; Relative - hate Vs No - hate ; No - hate Vs Hate + Relative - hate . In a HS - data ( corpus ) , generally it is observed that occur - rence of hateful speech is less as compared to non - hateful speech . This leads to well - known imbalanced classes ( Hate Vs . No - hate ) problems based on frequency of HS - lines that contain HT or not - contains HTs . For example , Davidson et al . [ 8 ] defined the three classes : hate , offensive , and non - offensive , which has imbalanced class , as Hate class has 1431 tweets , 19191 tweets for Offensive , and 4164 for Non - offensive class . In this condition , the frequency of classified tweets represents an imbalanced confusion - matrix ( TP , TN , FP , FN ) in the three classes . Hence , we need to use the percentage ( or ratio ) of classified tweets with respect to “size of a particular dataset” . The percentage of classified HS - lines are used to represent TP , TN , FP , FN as given in Table I for proper scaling . For example , 1400 hates are correctly classified as TP in Hate class , which is smaller than 5000 incorrectly classified as FP in Offensive class . However , 1400 / 1431 = 0 . 97 hate in Hate class for TP and 5000 / 19191 = 0 . 26 hate in Offensive class for FP , here ratios are properly scaled according to the class size . The percentage of HS - lines in a given class is a better measure . In the Table I , we used the percentage of HS - lines in a class to evaluate metrics , which gave a fair result by avoiding imbalance . The results of the Severe HTs - list are compared with the given set TABLE I C ONFUSION - MATRIX OF THREE C ASE - STUDIES . CaseStudy class TP = percentage of HS - lines TN = percentage of HS - lines FP = percentage of HS - lines FN = percentage of HS - lines Hate with HTs occurring in Hate class without HTs occurring in NonOffensive class with HTs in NonOffensive class without HTs in Hate class Relative - hate with HTs occurring in Offensive class without HTs occurring in NonOffensive class with HTs in NonOffensive class without HTs in Offensive class Hate + Relative - hate with HTs occurring in Hate + Offensive class without HTs occurring in NonOffensive class with HTs in NonOffensive class without HTs in Hate + Offensive class of HTs - lists by common binary metrics : accuracy , precision , recall , and F - measure ( given in Table IX ) . Answers to RQ3 : For a HS - data , we discovered two facts . Fact 1 : for best recall , the FN should be zero . This happens when all HTs ( in a HTs - list ) are found in the Hate class of HS - data . Example , a large HTs - list tends to a low FN . Fact 2 : for best precision , the FP is zero . This happens when no HTs ( in a HTs - list ) are found in the No - Hate class of HS - data . Example , a small HTs - list tends to a low FP . Hence , for a given HS - data , the best conditions to select HTs leads to best precision and recall , thus we can generate a Severe HTs - list . 8 . Summary N ( HateTerms ) : This provides information of percent HS - lines with N HTs in a HS - data class e . g . , x % have 1 HT , y % have 2 HTs , z % have 3 HTs and so on . The results are given in the Table XI . Rare instances of the co - occurring HTs in a hate - speech is also interesting to study . Imbalance occurrences of hate speech as compared to normal speech leads to rare instances of HTs and HS - lines in a HS - data . Such rare HTs and HS - lines are the minority representative of HS - data . We can identify and list those rare HTs by identifying rare concepts and their effect on the classes . It is interesting to analyse those groups of rare HTs ( as hate concepts in Section III ) and their effect on the classes . It will highlight the concept of a hate speech with a list of those “rare instances in the HS - data” . It is interesting to analyse a rare hate related terms list such as Anglo , yt , obese etc . and their hateful effects on the imbalanced classes . This section on quantitative analysis leads to the interpre - tation that it is straight - forward to classify hate content from no - hate content . However , it is hard to classify Hate class from Offensive class because HTs occurs in both contents . Thus , in such conditions , qualitative analysis can provide help in visualization , which is described in next section . III . Q UALITATIVE ANALYSIS : S TABLE H ATE R ULES , C ONCEPTS , T RANSITIVITIES , AND L ATTICES This section describes qualitative analysis of multiple HS - data . We used ordered sequence of HTs in a HS - data for ordered rule mining , which produces interesting rules as compared to the unordered rule mining . Hence , we will use ordered mining , which considers ordering of HTs in a hate speech . This mining is explained and then defined as follows . Hate Speech Rule Mining Example : To discover co - occurrences of desired terms , we consider only HTs and con - textual terms in a hate speech . Suppose ‘Anglo’ is a contextual term , which is a white English speaking person . Suppose there are 19 tweets ( each as a hate speech ) with ‘sp * c’ , which is an ethnic slur for people from Spanish - speaking . Out of them 3 tweets are as follows Tweet 1 : “Black cops k * ll white citizens . sp * c cops k * ll Anglo citizens . Z * geuner cops r * pists . ” Tweet 2 : “No half - breed sp * c Anglo , k * lled so . ” Tweet 3 : “A * glo - S * xn Protestant , alive US . None , foreign f * lth” . The FreqHTs denotes the frequency of a Hate Term ( HT ) ( means number of occurrences of individual HT ) in a hate speech . The FreqHT of ‘Anglo’ and ‘sp * c’ are as follows : N ( Anglo ) = 3 and N ( sp * c ) = 18 . The FreqCoHTs denote the frequency of co - occurring HTs in a hate speech . The FreqCoHTs for ( Anglo and sp * c ) are as follows : N ( Anglo , sp * c ) = 2 ; N ( Anglo as antecedent ) = 1 ; and N ( sp * c as antecedent ) = 15 . When we treat tweets as unordered database , this will result in the following unordered hate rules [ Anglo ] → [ sp * c ] # SUP : 2 # CONF : 0 . 66 means N ( Anglo ∪ sp * c ) / N ( Anglo ) = 2 / 3 [ sp * c ] → [ Anglo ] # SUP : 2 # CONF : 0 . 11 means N ( Anglo ∪ sp * c ) / N ( sp * c ) = 2 / 18 When we treat tweets as ordered sequence database , this will result in the following ordered hate rule [ sp * c ] → [ Anglo ] # SUP : 2 # CONF : 0 . 13 means N ( Anglo ∪ sp * c ) / N ( sp * c as antecedent ) = 2 / 15 . Definition : Stable Hate Rule ( SHR ) mining is performed over multiple Hate Speech data ( HS - data ) with only hate - terms and Named - entities . This generated Stable Hate Rules ( SHRs ) , which can be read as “if someone uses a HT ‘A’ , then most probably the person may also use HT ‘B’ with a given probability” . The SHRs could be like [ A ] → [ B ] , where the [ A ] is antecedent and the [ B ] is its consequent . Answer to Q4a : The Fig . 3 presents an overview of the SHR mining , which has the following four steps . Step 1 : Representational Hate Speech Database ( RepHS - database ) is an intermediate database created from a given HS - data containing terms of two lists : the Inter - Agreement HT - list and the Named - Entities list . This means the ResHS - database contains each HS line having either hate - terms or named - entities . Each HS - data is pre - processed to RepHS - database containing each row with HTs of the Inter - agreement HTs - list ( for corresponding HS - data ) and Contextual Key - words ( in the Named - Entities list ) . Semantically , this RepHS - database is a sequential database , which contains a sequence of words containing only HTs ( in the Inter - agreement HTs - list ) and Named - Entities in each HS - line of the HS - data . This RepHS - database is used for Hate Rule Mining , which applies sequential rule mining ( as a special kind of association rule mining ) in ordered occurrences of various HTs . Fig . 3 . Methodology for the SHR mining to generate : Stable Hate Rules , Concepts , Transitivities , and Lattices . Step 2 : Stable Hate Rule ( SHR ) mining uses the ordered sequential rule mining over classes ( Hate , Relative - hate , No - hate ) . While SHR mining , the Named Entities is a Context ( women , regional , etc ) that generates SHRs for some context . The SHR mining over multiple ( N ) RepHS - database s retrieves several SHRs and concepts . The SHR mining detects the hate rules , which has stability greater than the given threshold of minStab . These hate rules are SHRs , which occur frequently in multiple RepHS - databases . The SHR mining resulted in the following outputs : the “Hate Rules for each HS - data” , the “Collection of Hate Rules in all HS - data” , the “Outer Join of Hate Rules” , and the “SHRs” . For the three classes and multiple HTs - list , each row of the “Outer Join of Hate Rules” table contains one hate rule with support and confidence . Step 3 : Post - processing visualization generates hate Con - cepts , Transitive graphs , and Lattice graphs from similar hate rules or SHRs in the form of A → B for two sets of HTs ( A and B ) . Following will provide an answer to Q4b : - A hate Concept is a superset of unique HTs in the similar hate rules that form antecedent and consequent with a set of HTs . Merge HTs in the antecedent and consequent of similar hate rules as a single set of hate Concept without considering the order of rules and the order of HTs in those rules . A hate Concept would be more comprehensive as compared to many similar hate rules . The A → B is interpreted as if ordered HTs in A occurs , then it will be followed by the ordered HTs in B . Consider the three HTs { a , b , c } that make hate rules : { a } → { b , c } ; { a } → { b } ; { a } → { c } . This will produce a hate Concept as { abc } . - We can generate information about the co - occurrences of the HTs , which are represented as SHRs ( visualized as Transitive graphs ) and Concepts ( visualized as Lattice graphs ) . This aims to detect transitivities and lattices formed between the HTs , which are defined as follows . Definition : Transitive graph visualizes hate rules with similar Hate - Terms to form a graph such that source nodes are represented by the concatenated HTs in the antecedent and target nodes are represented by the concatenated HTs in the consequent . Definition : Lattice graph visualizes hate rules with similar Hate - Terms to form a graph such that child nodes are repre - sented by the combination of concatenated HTs of its parent nodes . The root - node is the concatenation of all HTs in all the similar SHRs . To construct the graphs , we concatenated HTs in hate rules with the symbol ‘ ’ . Examples of SHRs , concepts , transitivities , and lattices are presented in the Section V . B . IV . D ATASET This section describes the 3 Hate Speech data ( HS - data ) and 6 Hate Terms - lists ( HTs - lists ) . We pre - processed HS - data and the HTs - list before using them for the experimentation ( in Section V ) . 1 ) Hate Speech data ( HS - data ) : We have used the follow - ing three HS - data for the experimentation . a ) Davidson et al . [ 8 ] ( Twitter tweets ) : The dataset contains 25k tweets with Hatebase lexicon out of 85 . 4 million tweets . CrowdFlower ( CF ) workers manually labeled 24 , 802 out of 25k tweets , according to the given definition of three cate - gories : hate speech , offensive but not hate speech , and neither offensive nor hate speech . Three or more persons done the intercoder - agreement score provided by CF is 92 % . Majority voting is used to label a tweet . Labeling of this dataset is done by random CrowFlower Workers ( humans ) . b ) de Gibert et al . [ 10 ] ( White Supremacy forum ) : It is composed of 1000s of sentences extracted from Stormfront , a white supremacist forum . For hate or not hate labelling , an annotation tool was developed that needed manual assistance for choosing the context before labelling : hate or not . c ) Gao et al . [ 11 ] ( Fox - news - comments ) : Authors created Fox News User Comments Corpus , they annotated corpus of hate speech with context information . The corpus has 1528 annotated comments , out of which 435 labeled as hateful on 10 NEWS comment threads of the Fox News website . Different HS - data have different class names . Table II shows how these dataset classes correspond to our classes ( Hate , Relative - hate , No - hate ) . 2 ) Hate Terms - lists ( HTs - lists ) : We used the following six sets of HTs - lists , which cover the following hate context . TABLE II H ATE S PEECH DATA Hate Speech Classes data Used in HS - data Used in our work Hate Hate Davidson et al . [ 8 ] Offensive Relative - Hate Non - Offensive No - Hate Hate Hate de Gibert et al . [ 10 ] Relational Hate Relative - Hate No - Hate No - Hate Hate Hate Gao et al . [ 11 ] – Relative - Hate No - Hate No - Hate a ) Chandrasekharan et al . [ 12 ] contains Reddit word list from two subreddits : r / f * tpeoplehate and r / C * * nTown , where Reddit hate lexicon 1 . b ) Gorrell et al . [ 13 ] contains tweets from the UK general elections to explore the abuse directed at politicians . The GATE abuse tagger is available at web - links 2 . c ) Hatebase 3 uses a broad multilingual vocabulary based on nationality , ethnicity , religion , gender , sexual discrimination , disability and class to monitor incidents of hate speech across 200 + countries . Vocabulary datasets contain valuable lexicon from various data repositories for trend analysis . d ) Bassignana et al . [ 14 ] given list named Hurtlex con - taining multilingual lexicons different targets of hate ( immi - grants and women ) for regional and cultural patterns . HurtLex contains lexicons of hate terms for 50 languages , which are divided into 17 categories , plus a macro - category indicating whether there is stereotype involved ) 4 . e ) Wiegand et al . [ 15 ] filtered the abusive words from a given set of negative polar expressions 5 . f ) Union : We made a union list from all the distinct HTs appearing in the above given five HTs - lists available online . We found both the HS - data and the given HTs - list has faults in the HTs due to : Stemmer NLP limitations , Not hateful without knowing context , and Annotators agree or disagree ( complete consensus ) . We stemmed the tokenized data both in the HS - data and in the HTs - lists . V . H ATE S PEECH A NALYTICS AND E XPERIMENTS In this section , first we describe HS - data analysis along with the generation of the Severe HTs - list . Next , we discuss the Hate Rules , Concepts , Transitivities , and Lattice . We also discuss experiments conducted from our Java based implemen - tation consisting of robust and statistical algorithms . A . Generation of Severe Hate Terms List We present the quantitative analysis as we aimed to retrieve Severe HTs - list from the given HTs - lists . The Severe HTs - list produces better results than the given HTs - lists . Although there were many resulting artifacts for each of three HS - data , to keep 1 https : / / www . dropbox . com / sh / 5ud4fwxvb6q7k20 / AAAH SN8i5cfmJRKJteEW2b2a 2 https : / / cloud . gate . ac . uk / shopfront / displayItem / gate - hate 3 https : / / hatebase . org / academia 4 https : / / github . com / valeriobasile / hurtlex 5 https : / / github . com / uds - lsv / lexicon - of - abusive - words brevity we present only a few results from Davidson et al . hate class to describe the hate - speech along with the various HTs - lists . We generated 8 artifacts discussed in Section II . The first 5 intra - agreement artifacts are based on Section II . A and next 3 are inter - agreement artifacts based on Section II . B . These 8 artifacts are discussed as follows . 1 . Creation of hate terms frequencies : In Table III , we provided N ( 0 ) , N ( 1 ) , . . . N ( X ) HTs found in the HS - lines of the HS - data ( Davidson et al of class 0Hate ) . The N ( 0 ) , N ( 1 ) , . . . N ( X ) hate terms are used from the Severe HTs - list with Offensiveness values greater than threshold minimum Offense ( minOffense ) = 0 . 70 . This particular example has a maximum value of N = 13 i . e . 13 number of HTs in a single hate speech . TABLE III N ( 0 ) , N ( 1 ) , N ( 2 ) . . . N ( X ) T ERMS E XAMPLE . Filename HateTerm Tweets N ( 0 ) HTs – # [ IDENTITY ] can get a job at the [ IDEN - TITY ] . Or as The [ IDENTITY ] . I hear they like diversity and tolerance . As long as you ain’t a cracker # [ TAG ] N ( 1 ) HTs f * ggot @ [ IDENTITY ] answer my [ IDENTITY ] f * ggot # [ TAG ] N ( 2 ) HTs f * ggot ; f * ck @ [ IDENTITY ] f * ck those f * ggots so on . . . . . . . . . 2 . AllHateTermsFrequencies and TopTermsFrequency : In Fig . 4 , the count of HTs ( belonging to Severe HTs - list ) are given for the Hate class of the Davidson et al . ( as a Hate class of HS - data ) for the top 20 most frequent terms ( threshold ) . Fig . 4 . Top - 20 HTs from Severe HTs - list ( 0 . 7 ) and Davidson et al Hate class . 3 . AllHTsPercentLine : This signifies X % of HS - lines with a particular HT in a HS - data class . The artifact tells about the number and percentage of HS - lines in which HT occurs . The Table IV shows first three HTs of Severe HTs - list with Offensiveness > minOffense ( 0 . 7 ) and Hate class of HS - data ( Davidson et al 0Hate ) . TABLE IV A LL HT S P ERCENT L INE E XAMPLE . Hate Term N ( HateTermInLines ) N ( Lines ) % ( HateTermLines ) f * ggot 249 1430 17 . 413 b * tch 240 1430 16 . 783 f * ck 199 1430 13 . 916 so on . . . . . . . . . 4 . OuterJoinHTsFrequencies and OuterJoinHTsPercent - Lines : The Table V and VI provide examples respectively , for the Severe HTs - list with Offensiveness > minOffense ( 0 . 7 ) . TABLE V O UTER J OIN HT S F REQUENCIES E XAMPLE . HateTerm Davidson et al . 0Hate Davidson et al 1Offensive Davidson et al . 2NonOffensive f * ggot 253 291 1 b * tch 269 11192 11 f * ck 221 2039 – so on . . . . . . . . . TABLE VI O UTER J OIN HT S P ERCENT L INES E XAMPLE . HateTerms Davidson et al . 0Hate Davidson et al 1Offensive Davidson et al . 2NonOffensive f * ggot 17 . 413 1 . 501 0 . 024 b * tch 16 . 783 54 . 627 0 . 264 f * ck 13 . 916 9 . 734 – so on . . . . . . . . . 5 . Intra - Agreement - HTs for each HTs - list : For a partic - ular class of a HS - data , we count the number of HS - lines that contain HTs which belong to a specific HTs - list . For each HT in a HTs - list , we calculated the Hatefulness and Relativeness based on their definitions ( in Section II ) . This information makes the intra - agreement HTs matrix for each given HTs - list . We found a low Relativeness measure when some HT is used alone . In Table VII relativeness of ‘tr * sh’ ranges from low as compared to the Relativeness of ‘eurotr * sh’ , “tr * * ler park tr * sh” , “tr * * ler tr * sh” , and “white tr * sh” . 6 . Inter - Agreement - HTs for multiple HTs - lists : For a HS - data , to make an Inter - agreement HTs among multiple HT - lists , we merged HTs of all the “Intra - Agreement HTs” . Then , for each HT , we used Hatefulness and Relativeness informa - tion to calculate its Offensiveness ( as defined in the Section II . B ) . We found low Offensiveness value of some HTs when used alone or without any context e . g . offensiveness of ’tr * sh’ is low as compared to the offensiveness of ‘eurotr * sh’ , “tr * * ler park tr * sh” , “tr * * ler tr * sh” , and “white tr * sh” . The Table VIII shows the three HTs for the inter - agreement between the Davidson et al . tweets and the given six HT - lists . Answer to RQ2 : Table VIII shows high Offensiveness results in optimum number of HTs . For each HT , Hatefulness and Relativeness in Table VIII is taken from the Hatefulness and Relativeness ( shown in Table VII ) . Offensiveness of Table VIII is calculated with the Hatefulness and Relativeness . Using Offensiveness value , we discriminate severe and mild hate lexicons , which created a Severe HTs - list to classify hate speech . This means , for high Offensiveness , the selected highly severe HTs can help to perform better hate speech classification . 7 . Inter - agreement Confusion - matrix : We intended to generate a Severe HTs - list as presented in Section II . B . This provides comparison between the Severe HTs - list and the baseline HTs - lists ( Chandrasekharan et al . , Gorrell et al . , Hatebase , Hurtlex , and Wiegand et al . ) . All these HTs - lists have inter - agreement between the HS - data and HTs . First , as given in the Table I , we constructed the confusion - matrix ( with TP , TN , FP , FN ) to calculate the precision and recall . Then , we calculate the accuracy , precision , recall , and f - measure ( or f - score ) . Answer to RQ3 : The Table IX shows the comparison between the Severe HTs - list and a given HTs - list which is best among all HTs - lists . In all cases , the Severe HTs - list resulted in best F - Score and contains best inter - agreeing HTs for a HS - data . This is because the Severe HTs - list contains the best HTs of all the HTs - list . Table IX shows results for high offensiveness threshold minOffense to make Severe HTs - list , which performed better than the classification provided by all the given set of HTs - lists . We found that a Severe HTs - list distinguishes between hateful and non hateful lines to achieve better classification . Table IX presents comparisons for the three HS - data . First , to classify Davidson et al . Hate Vs No - hate class , we generated a Severe HTs - list with 298 HTs with a Offensiveness greater than minOffense ( 0 . 7 ) . The Severe HTs - list resulted in the F - measure of 0 . 923 , which is better as compared to the HS - list of Gorrell et . al . which contains 403 abuse - terms and resulted in the 0 . 845 F - measure ( best among all given HTs - lists ) . Second , for HS - data of DeGilbert et al , we generated a Severe HTs - list with 578 HTs with a Offensiveness greater than minOffense ( 0 . 46 ) . The Severe HTs - list perform better as compared to the HS - list Union ( 13538 ) that produced best F - measure among the given HTs - lists . Third , for HS - data of Goa et al , we generated a Severe HTs - list with 622 HTs with a Offensiveness greater than minOffense ( 0 . 75 ) . The Severe HTs - list performs better as compared to HS - list Union ( 13538 ) that produced better results among the given HTs - lists . To produce a high value of precision and recall , we used two steps . First , we added HTs having high - severity ( i . e . , HTs occurring mostly in the Hate class ) , which have highest offensiveness . Second , we ignored HTs having less - severity ( i . e . , HTs appearing frequently in the Non - Offensive class ) , which has low offensiveness . The optimized size of Severe HTs - list contains only best HTs with high offensiveness , which produce best classification . For HS - data of Davidson et al , we used six given HTs - lists to retrieve a Severe HTs - lists . Instead of using all terms , we retrieved a subset of highly severe terms by setting an minOffense = 0 . 7 , which produced an optimized number of 298 HTs . These HTs are used to classify HS - line in a HS - data as hateful if they contain one or more hate terms . Similarly , we retrieved Severe HTs - list for the other HS - data : de Gilbert et al . and Gao et al . Table X shows the ranking of the HTs - list , which provides comparison of inter - agreement between a HS - data with HTs - lists ( with number of HTs ) . The ranking is ordered based on inter - agreement from high to low . From the table , we inferred that “inter - agreement does not depend on the number of HTs” , but “inter - agreement depends upon the agreement of HTs in HTs - list with the classes of HS - data” . We also inferred that “a HTs - list may well inter - agreed with a HS - data and may not be well inter - agreed with another HS - data” . TABLE VII I NTRA - A GREEMENT HT S E XAMPLE FOR HS - DATA ( D AVIDSON ET AL . ) AND HT S - LIST ( U NION ) . HateTerms ( HTs ) HateClassHS - lines # Offensive + Non - OffensiveHS - lines # HateClassHS - lines Hatefulness ( HateClass ) Relativeness ( HateClass ) # Hate + OffensiveHS - lines Non - OffensiveHS - lines # Hate + OffensiveHS - lines Hatefulness ( Hate + Offensive ) Relativeness ( Hate + Offensive ) f * ggot 249 1 1431 1 0 . 996 537 1 20622 1 0 . 998 b * tch 240 11 1431 1 0 . 956 10723 11 20622 1 0 . 999 f * ck 199 0 1431 1 1 2067 0 20622 1 1 tr * sh 106 680 1431 1 0 . 135 442 680 20622 1 0 . 394 eurotr * sh 0 1 1431 0 0 1 1 20622 1 0 . 5 tr * * ler parktr * sh 2 1 1431 1 0 . 667 2 1 20622 1 0 . 667 tr * * ler tr * sh 3 2 1431 1 0 . 6 6 2 20622 1 0 . 75 whitetr * sh 56 3 1431 1 0 . 949 91 3 20622 1 0 . 968 so on . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . TABLE VIII I NTER - A GREEMENT HT S BETWEEN THE D AVIDSON ET AL . AND THE SIX GIVEN HT S - LISTS . HTs Hatefulness ( Hate ) Relativeness ( Hate ) Offensiveness ( Hate ) Hatefulness ( Hate + Offensive ) Relativeness ( Hate + Offensive ) Offensiveness ( Hate + Offensive ) HateListNames f * ggot 1 0 . 996 0 . 998 1 0 . 998 0 . 999 Chandrasekharan et al Reddit hate lexicon ; Gorrell et al abuse - terms ; HateBaseList ; hurtlex EN ; Union ; Wiegand et al b * tch 1 0 . 956 0 . 978 1 0 . 999 0 . 999 Gorrell et al abuse - terms ; HateBaseList ; hurtlex EN ; Union ; f * ck 1 1 1 1 1 1 hurtlex EN ; Union ; Wie - gand et al tr * sh 1 0 . 135 0 . 238 1 0 . 394 0 . 565 HateBaseList ; hurtlex EN ; Union eurotr * sh 0 0 NaN 1 0 . 5 0 . 667 HateBaseList ; Union tr * * ler park tr * sh 1 0 . 667 0 . 8 1 0 . 667 0 . 8 HateBaseList ; Union tr * * ler tr * sh 1 0 . 6 0 . 75 1 0 . 75 0 . 857 HateBaseList ; Union white tr * sh 1 0 . 949 0 . 974 1 0 . 968 0 . 984 HateBaseList ; Union so on . . . . . . . . . . . . . . . . . . . . . . . . TABLE IX F OR THE THREE HS - DATA , THE TABLE PROVIDES A COMPARISON OF THE S EVERE HT S - LIST WITH THE GIVEN HT S - LISTS . T HIS ANSWERED RQ3 HTs - list Name ( minOf - fense , number of HTs ) HS - data Name and Class Accuracy Recall Precision F - Measure ComputeTime Gorrell et al abuse - terms Davidson et al 0Hate Vs . No - Hate 0 . 857 0 . 784 0 . 917 0 . 845 ( - , 403 ) Davidson et al 0Hate + 1Offensive Vs . No - Hate 0 . 845 0 . 761 0 . 915 0 . 831 12 sec Davidson et al 1 Offensive Vs . No - Hate 0 . 844 0 . 759 0 . 915 0 . 83 Offensiveness ( Hate ) Davidson et al 0Hate Vs . No - Hate 0 . 921 0 . 946 0 . 901 0 . 923 ( 0 . 7 , 298 ) Davidson et al 0Hate + 1Offensive Vs . No - Hate 0 . 929 0 . 962 0 . 903 0 . 931 17 sec Davidson et al 1 Offensive Vs . No - Hate 0 . 93 0 . 963 0 . 903 0 . 932 de Gibert et al 0Hate Vs . No - Hate 0 . 633 0 . 959 0 . 58 0 . 723 Union ( - , 13538 ) de Gibert et al 0Hate + 1RelationalHate Vs . No - Hate 0 . 629 0 . 951 0 . 578 0 . 719 1 min 31 sec de Gibert et al 1RelationalHate Vs . No - Hate 0 . 6 0 . 893 0 . 563 0 . 69 Offensiveness ( Hate ) de Gibert et al 0Hate Vs . No - Hate 0 . 821 0 . 832 0 . 814 0 . 823 ( 0 . 46 , 578 ) de Gibert et al 0Hate + 1RelationalHate Vs . No - Hate 0 . 8 0 . 789 0 . 806 0 . 797 14 sec de Gibert et al 1RelationalHate Vs . No - Hate 0 . 646 0 . 482 0 . 718 0 . 577 Union ( - , 13538 ) Gao et al 0Hate Vs . No - Hate 0 . 46 0 . 772 0 . 475 0 . 588 15 sec Offensiveness ( Hate ) ( 0 . 75 , 622 ) Gao et al 0Hate Vs . No - Hate 0 . 541 0 . 718 0 . 53 0 . 61 5 sec TABLE X R ANKING OF HT S - LIST N AME IN DECREASING ORDER OF I NTER - AGREEMENT WITH THE HS - DATA . HS - data Name HTs - lists Names ( number of HTs ) Davidsonetal Offensiveness ( Hate ) ( 0 . 7 , 298 ) , Gorrell et al abuse - terms ( 403 ) , HateBaseList ( 1015 ) , Wiegand et al lexicon - of - abusive - words ( 7156 ) , Hurtlex EN ( 5925 ) , Union ( 13538 ) , and Chandrasekharan et al Reddit hate lexicon ( 199 ) . de Gibert et al Offensiveness ( Hate ) ( 0 . 46 , 578 ) , Union ( 13538 ) , Hurtlex EN ( 5925 ) , Wiegand et al lexicon - of - abusive - words ( 7156 ) , Chandrasekharan et al Reddit hate lexicon ( 199 ) , HateBaseList ( 1015 ) , Gorrell et al abuse - terms ( 403 ) . Gao et al Offensiveness ( Hate ) ( 0 . 75 , 622 ) , Union ( 13538 ) , Wiegand et al lexicon - of - abusive - words ( 7156 ) , Hurtlex EN ( 5925 ) , Chandrasekharan et al Reddit hate lexicon ( 199 ) , Gorrell et al abuse - terms ( 403 ) , HateBaseList ( 1015 ) . 8 . Summary N ( HateTerms ) : Table XI summaries follow - ing information about the HS - data and HTs - list . The number of HTs “HateTerms ( N ) ” in HS - lines is depicted by N ( Entries ) . Table shows a few rows for the three classes { 0Hate , 1Of - fensive , 2NonOffensive } of Davidson et al and the HTs - list Chandrasekharan et al . Total number of rows has the N ( Entries ) × the number of classes in a HS - data × the number of given HTs - lists . Similar tables can be made for HS - data : de Gibert et al and Gao et al . B . Stable Hate Rules , Concepts , Transitivities , and Lattices Based on Section III , we present the qualitative analysis to visualize the Stable Hate Rules ( SHRs ) that can provide information about the co - occurrences of the rare HTs in HS - data . The SHRs are represented and visualized as Transitive graphs . In addition , the hate Concepts are being created from Stable Hate Rules ( SHRs ) . These hate Concepts are visualized as Lattice graphs . ( This subsection answers to Q4b . ) Basically , the rule - mining on HS - data suffers with two limitations . First , rule - mining over full HS - data generated exhaustive number of rules having hate - terms along with the stop - words ( e . g . In The To a , Can I , You n * gga , As a , etc . ) , which makes less sense . Thus , we removed stop - words from HS - data . Second , from the HS - data without stop - words , we made three different classes ( hate , relative - hate , no - hate ) that again resulted in an exhaustive number of rules . Finally , we made an intermediate Representational HS Database ( RepHS - database ) from Hate and Relative - hate class only . We made a RepHS - database with sequences of each hate speech contain - ing only HTs and contextual Named - Entities , which resulted in patterns of co - occurring HTs in a context . We made total 9 RepHS - database for mining from { Davidson et al . ( hate and offensive ) , de Gilbert et al . ( hate and relational - hate ) , Gao et al . ( hate ) } × their three Inter - agreement HTs - lists . In each RepHS - Database , we kept hate speech with only HTs in the three Inter - agreement HTs - lists and Named Entity ( list of synonyms for Women ( like girl , wife etc . ) and Regions ( like name of states or countries 6 ) . This provides rules related to hate speech against Women and Regions . 6 https : / / meta . wikimedia . org / wiki / List of countries by regional classification For the better interpretation from rules , we also included a number of occurrences of SHR’s antecedent , support , and confidence . We used association rule mining and sequential rule mining outputs with multiple threshold values of mini - mum support ( minSup ) and minimum confidence ( minConf ) . For conciseness , we omitted such detail about support and con - fidence . For sequential rule mining , we used the RuleGrowth algorithm [ 16 ] given in the SPMF data mining tools . The SHR mining is an extension of earlier work [ 5 ] and it is useful for the Hate Speech Project . Table XII demonstrates two hate concepts generated from similar SHRs with the same set of HTs . The rules resulted in the formation of two transitive graphs as shown in Fig . 5 . The rules also resulted in the formation of two lattice graphs of two concepts as shown in Fig . 6 . There are many such transitive and lattice graphs , which we skip presenting to keep brevity . Fig . 5 . Two Transitivity graphs of two sets of similar SHRs : “a * s b * tch boss” and “Europe race white” for Women and Regional context respectively . Fig . 6 . Two Lattice graphs of two Concepts : “a * s b * tch boss” and “Lat - tice Europe race white” . Root - nodes ( at the bottom ) are the hate Concepts . VI . R ELATED W ORKS Caselli et al . [ 17 ] described abuse and offense by studying Inter - Agreement . We have also analyzed Inter - agreement be - tween HTs - list and HS - data Classes , such that , this process generates Severe HTs - list . Pedersen [ 18 ] presented lists of HTs , whereas we have retrieved Severe HTs - list . Liu et al . [ 19 ] presented Multi - Task Deep Neural Network ( MT - DNN ) for learning text representations for multiple nat - ural language understanding ( NLU ) . Zampieri et al . [ 20 ] [ 21 ] annotated the datasets for abusive messages named Offensive Language Identification Dataset ( OLID ) , which they further used for Offensive Language in Social Media ( OffensEval ) . Devlin et al . [ 22 ] presented a popular language representation model named Bidirectional Encoder Representations from Transformers ( BERT ) for tasks like question answering and language inference . Recently , Mittos et al . [ 23 ] measured hate and toxicity with the percentage of hate words , and the level of toxic - ity / inflammatory . They used HTs available on hatebase . org , which were previously worked - out by Hine et al . [ 24 ] . Vidgen et al . [ 25 ] presented dynamic human and model based four TABLE XI F OR THE THREE HS - DATA AND SIX HT S - LIST , THE TABLE PROVIDE SUMMARISED OVERVIEW . Dataset Name and Class HateList Name HateTerms ( N ) N ( Entries ) TotalLines % ( Entries ) Davidson et al 0Hate Chandrasekharan et al Reddit hate lexicon 0 581 1430 40 . 629 Davidson et al 0Hate Chandrasekharan et al Reddit hate lexicon 1 671 1430 46 . 923 so on . . . . . . . . . . . . . . . . . . Davidson et al 1Offensive Chandrasekharan et al Reddit hate lexicon 0 16101 19190 83 . 903 Davidson et al 1Offensive Chandrasekharan et al Reddit hate lexicon 1 2654 19190 13 . 83 so on . . . . . . . . . . . . . . . . . . TABLE XII T WO HATE CONCEPTS ( FIRST ROW ) AND THEIR SHR S WITH SIMILAR HT S . a * s b * tch boss 5 a * s → b * tch boss → b * tch a * s a * s boss → b * tch boss → b * tch boss → a * s Europe race white 5 white → Europe race → white Europe white race → Europe race → white race → Europe rounds of hate speech training . Ball et al . [ 26 ] studied racial dialect using neural networks for harmful tweet detection . Vidgen et al . [ 27 ] described a contextual abuse dataset with six taxonomies for abusive , non - abusive , and neutral speech . VII . C ONCLUSIONS To collect inter - agreement information about the HTs - list ( Hate Terms list ) and the HS - data ( Hate Speech data ) , we answered the four research questions . We generated interesting reports that include : top frequent HTs , intra / inter - agreement of HTs in HTs - list with the HS - data , summarized hate - term occurrences , and Offensiveness of HTs . We also retrieved Stable Hate Rules ( SHRs ) and Concepts that are used to identify lattices and transitivity relationships between various HTs for a context . For quantitative analysis , using the proposed threshold minOffense for HTs , our Severe HTs - list has out - performed all the given HTs - lists . For qualitative analysis , our SHRs provided visual analytic as Transitive and Lattice graphs of the HTs co - occurring in HS - data for context of Women and Regions . A CKNOWLEDGMENTS Thanks to Prof . Nishanth Sastry , Dr . Bertie Vidgen , and Dr . Jatinder Singh for their discussions on the topic . Authors also thank The Alan Turing Institute for supporting this project by providing fellowship to Dr . Animesh Chaturvedi as Post Doctoral - RA at King’s College London ( U . K . ) . R EFERENCES [ 1 ] B . Vidgen , et al . ”Challenges and frontiers in abusive content detection . ” Association for Computational Linguistics , 2019 . [ 2 ] L . Shapley . ”Quota solutions op n - person games1 . ” Edited by Emil Artin and Marston Morse ( 1953 ) : 343 . [ 3 ] A . E . Roth , ed . The Shapley value : essays in honor of Lloyd S . Shapley . Cambridge University Press , 1988 . [ 4 ] L . Geng , and H . J . Hamilton . “Interestingness measures for data mining : A survey . ” ACM Computing Surveys ( CSUR ) 38 . 3 ( 2006 ) : 9 - es . [ 5 ] A . Chaturvedi , A . Tiwari , and N . Spyratos . “minStab : Stable Network Evolution Rule Mining for System Changeability Analysis . ” IEEE Trans . on Emerging Topics in Computational Intelligence ( 2019 ) . [ 6 ] A . Chaturvedi , A . Tiwari . “System Evolution Analytics : Evolution and Change Pattern Mining of Inter - Connected Entities” . IEEE International Conference on Systems , Man , and Cybernetics ( SMC ) , 2018 : 3877 - 3882 . [ 7 ] A . Chaturvedi , A . Tiwari , and N . Spyratos . “System Network Analytics : Evolution and Stable Rules of a State Series . ” IEEE 9th International Conference on Data Science and Advanced Analytics ( DSAA ) . IEEE , 2022 . [ 8 ] T . Davidson , et al . “Automated hate speech detection and the problem of offensive language . ” Int . AAAI Conf . on Web and Social Media . Vol . 11 . No . 1 . 2017 . [ 9 ] M . - L . Zhang , et al . “Binary relevance for multi - label learning : an overview . ” Frontiers of Computer Science 12 . 2 ( 2018 ) : 191 - 202 . [ 10 ] O . de Gibert , et al . “Hate speech dataset from a white supremacy forum . ” arXiv preprint arXiv : 1809 . 04444 ( 2018 ) . [ 11 ] L . Gao , and R . Huang . “Detecting online hate speech using context aware models . ” arXiv preprint arXiv : 1710 . 07395 ( 2017 ) . [ 12 ] E . Chandrasekharan , et al . “You can’t stay here : The efficacy of reddit’s 2015 ban examined through hate speech . ” ACM on Human - Computer Interaction 1 . CSCW ( 2017 ) : 1 - 22 . [ 13 ] G . Gorrell , et al . “Twits , twats and twaddle : trends in online abuse towards UK politicians . ” Int . AAAI Conf . on Web and Social Media . Vol . 12 . No . 1 . 2018 . [ 14 ] E . Bassignana , V . Basile , and V . Patti . “Hurtlex : A multilingual lexicon of words to hurt . ” 5th Italian Conf . on Computational Linguistics , CLiC - it 2018 . Vol . 2253 . CEUR - WS , 2018 . [ 15 ] M . Wiegand , et al . “Inducing a lexicon of abusive words – a feature - based approach . ” Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) . 2018 . [ 16 ] P . Fournier - Viger , et al . “Mining partially - ordered sequential rules com - mon to multiple sequences . ” IEEE Trans . on Knowledge and Data Engineering 27 . 8 ( 2015 ) : 2203 - 2216 . [ 17 ] T . Caselli , et al . “I feel offended , don’t be abusive ! implicit / explicit messages in offensive and abusive language . ” 12th Language Resources and Evaluation Conf . . 2020 . [ 18 ] T . Pedersen . “Duluth at SemEval - 2019 Task 6 : Lexical Approaches to Identify and Categorize Offensive Tweets . ” 13th Int . Workshop on Semantic Evaluation . 2019 . [ 19 ] X . Liu , et al . “Improving multi - task deep neural networks via knowl - edge distillation for natural language understanding . ” arXiv preprint arXiv : 1904 . 09482 ( 2019 ) . [ 20 ] M . Zampieri , et al . “Predicting the Type and Target of Offensive Posts in Social Media . ” NAACL - HLT ( 1 ) . 2019 . [ 21 ] M . Zampieri , et al . “Semeval - 2019 task 6 : Identifying and categorizing offensive language in social media ( offenseval ) . ” Proceedings of the 13th Int . Workshop on Semantic Evaluation . 2019 . [ 22 ] J . Devlin , et al . “Bert : Pre - training of deep bidirectional transformers for language understanding . ” NAACL - HLT ( 1 ) . 2019 . [ 23 ] A . Mittos , et al . ““And We Will Fight for Our Race ! ” A Measurement Study of Genetic Testing Conversations on Reddit and 4chan . ” Int . AAAI Conf . on Web and Social Media . Vol . 14 . 2020 . [ 24 ] G . Hine , et al . “Kek , cucks , and god emperor trump : A measurement study of 4chan’s politically incorrect forum and its effects on the web . ” Int . AAAI Conf . on Web and Social Media . Vol . 11 . No . 1 . 2017 . [ 25 ] B . Vidgen , et al . “Learning from the Worst : Dynamically Gener - ated Datasets to Improve Online Hate Detection . ” arXiv preprint arXiv : 2012 . 15761 ( 2020 ) . [ 26 ] A . Ball - Burack , et al . “Differential tweetment : Mitigating racial dialect bias in harmful tweet detection . ” Proceedings of the 2021 ACM Conf . on Fairness , Accountability , and Transparency . 2021 . [ 27 ] B . Vidgen , et al . “Introducing CAD : the Contextual Abuse Dataset . ” NAACL - HLT . 2021 .