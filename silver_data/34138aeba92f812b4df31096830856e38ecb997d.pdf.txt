About Programming Maturity in Finnish High Schools : A Comparison Between High School and University Students’ Programming Skills Erkki Kaila Department of Future Technologies 20014 University of Turku , Finland ertaka @ utu . ﬁ Rolf Lindén Department of Future Technologies 20014 University of Turku , Finland rolind @ utu . ﬁ Erno Lokkila Department of Future Technologies 20014 University of Turku , Finland eolokk @ utu . ﬁ Mikko - Jussi Laakso Department of Future Technologies 20014 University of Turku , Finland milaak @ utu . ﬁ ABSTRACT In this study , we compare students’ ability to learn and mas - ter a variety of computer programming concepts in two dif - ferent student groups . The ﬁrst group consists of 64 uni - versity level students with various backgrounds ( adult con - trol ) , and the second group consists of 40 Finnish junior high school students of age 15 ( adolescent treatment group ) . Nei - ther group had signiﬁcant prior programming experience . Both groups were taught a similar semester - long introduc - tory course on Python programming , using the same learn - ing management system ( LMS ) . We ﬁnd that for almost all of the concepts , both groups perform equally well , but students in the adolescent treatment group perform signiﬁ - cantly worse when learning the concepts of loop structures and repetition . The results are further compared to the lec - ture surveys that were collected from the junior high school course to further explain the causes of the ﬁndings . Based on the results and the teaching methods that are presented in this paper , we are able to show that adolescent junior high school students and adult university students have similar abilities to learn abstract computer science concepts using a fully functional programming environment . Keywords computer science education ; maturity ; adolescence ; junior high school ; Python ; teaching methods ; study habits Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full cita - tion on the ﬁrst page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or re - publish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . Request permissions from permissions @ acm . org . ITiCSE ’17 July 3 – 5 , 2017 , Bologna , Italy © 2017 ACM . ISBN 978 - 1 - 4503 - 4704 - 4 / 17 / 07 . . . $ 15 . 00 DOI : http : / / dx . doi . org / 10 . 1145 / 3059009 . 3059021 1 . INTRODUCTION There are several methodologies designed and proven to be eﬀective for teaching programming to adults ( or young adults ) . Most of the research conducted targets university level students , as most of the researchers in the area usually teach programming courses at universities ( or at least have tight connections to such teachers ) by themselves . However , according to popularity of graphical or visual programming environments , the current consensus seems to be that the methodologies used in the higher levels are not directly ap - plicable to elementary schools or junior high schools . We argue that although the materials and exercises likely re - quire adjusting , the same methods and technology we use successfully in university level programming courses can be perfectly well utilized in the lower level courses as well . In this paper , we try to prove this claim by comparing two programming courses . The ﬁrst one is a university level in - troductory course directed for students with non - computing background , and the second one a similar course taught at junior high school level to students aged 14 to 15 . The methodologies and educational technologies used are similar enough to allow comparison , but the course content for the younger students is somewhat simpliﬁed . Still , the learning goals of the matched sections are similar : after passing the course the students should be able to understand the fun - damentals of imperative paradigm ( such as conditional ex - ecution , repetition and subprograms ) and utilize it to write programs using Python . 2 . LITERATURE REVIEW An exact deﬁnition of what programming is seems to be transient and shifts over time ( see [ 1 ] ) , and the book “Psy - chology of Programming” [ 4 ] devotes the ﬁrst 77 pages for deﬁning programming . Since programming is such a varied task , there are multiple cognitive skills involved in it . What these skills actually are , is under some debate . Regardless , many seem to agree on at least problem - solving , deductive reasoning and logical thinking ( e . g . [ 4 ] pp . 63 – 82 , [ 13 ] ) . Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 122 Even if programming as a concept is elusive , the diﬃcul - ties in learning it are not . Du Boulay [ 3 ] identiﬁes ﬁve ar - eas of diﬃculty when learning programming : 1 ) orientation ; what beneﬁts and possibilities learning programming oﬀers 2 ) the notational machine ; what is the computer and its capabilities 3 ) notation ; the problems of syntax and seman - tics in programming languages 4 ) structures ; the building blocks of programs and 5 ) pragmatics ; the wider context of programming , such as debugging , designing and testing programs . There should be no debate over the claim that novice pro - grammers create more bugs and take more time to solve simple programming exercises . However , once students are able to write simple programs in one programming language , transitioning to other languages can be done with relative ease [ 5 ] . Learning to program , thus , is more than just learn - ing a programming language . The ﬁve areas of diﬃculties identiﬁed by [ 3 ] support this statement : When learning to program , all ﬁve areas need to be focused on , whereas learn - ing a new programming language allows the learner to focus on only the notational aspect . Building on this , visual pro - gramming languages such as Scratch are thus easier to learn initially , as the semantics layer can be mostly ignored . This can create problems later , when moving to a non - visual pro - gramming language . This is pointed out by both Weintrop & Wilensky [ 18 ] and DiSalvo [ 2 ] : the applicability of cur - rent visual programming languages is limited to learning the basics of programming and does not allow development of larger applications ( web , mobile or games , to name a few ) . DiSalvo also found that student motivation and interest fur - ther inﬂuence students’ views . Adapting active learning strategies have been found to both improve learning results and motivation in students . ( e . g . [ 8 ] , [ 16 ] , [ 11 ] ) . Active learning is heavily based on the currently widely adopted constructivist learning theo - ries , which have their roots in the works of Piaget and Vy - gotsky . In active learning , the focus is on engaging the stu - dent in the current task and encouraging them to construct information that is meaningful to them . This is done by providing the students with mental scaﬀolds in the form of study material and instruction . This is in sharp contrast to the still - too - often used lecturing , in which students are expected to passively listen to facts told by the teacher , and at the end of the course produce the same facts during an exam . The methods vary by subject : program visualizations ( e . g . [ 15 ] ) are hardly useful for students of history , whereas role - playing exercises work well for teaching multicultural - ism in America ( as described in [ 12 ] ) , but are unlikely to produce signiﬁcant results in teaching repetition in a CS1 course . 3 . ABOUT THE LEARNING MANAGEMENT SYSTEM Courses that are presented in this study rely heavily on the usage of a learning management system ( LMS ) called ViLLE . The LMS provides various general exercise types ( such as quizzes or sorting and categorizing exercises ) that can be used in programming education , as well as specialized programming exercise types that support several program - ming languages , including for example Python , Java , C # , C + + and JavaScript . A complete description of the system can be found in [ 10 ] . Earlier experiences about using ViLLE to teach program - ming can be found for example in [ 6 ] , [ 7 ] and [ 15 ] . 4 . PROGRAMMING COURSES OBSERVED IN THE STUDY 4 . 1 Programming Course at University Level The ﬁrst course observed ( N = 61 ) is a Python program - ming course at university level ( later UC ) . Unlike most pro - gramming courses at universities , the course is not directed for computer science or engineering students , but rather as a supplementary course for bioinformatics students and stu - dents with other majors interested in programming . The course lasts for 14 weeks , with two weekly two - hour sessions . The ﬁrst session is a teacher - driven lecture , with supplementary exercises done in the LMS right after the lec - ture part . The exercises are designed for students to actively engage into topics covered in the lecture . The other session is a demonstration session , where the students present their solutions to the programming tasks given to them a week earlier . Before the end of the course , the students complete a course project , which is a more extensive programming task . Typically , two ﬁnal weeks of the course are reserved for completing the project , and additional guidance is of - fered to students who feel they might need it . At the ﬁnal week of the course , an electronic exam is taken . The exam is done using the LMS , and it typically consists of ﬁve to seven programming assignments accom - panied with a quiz , a sorting or categorizing exercise , and one or two open questions ( such as “What do we mean by saying that strings in Python are immutable” or “Describe the program code given in detail” ) . The essay type questions are evaluated by teacher , while all other exercises are auto - matically assessed . The principle behind using an electronic exam is to provide a coding experience that resembles real programming as closely as possible . This means that the code can be tested , debugged and refactored as many times as needed within a three - hour time limit . The structure of the course is presented in Table 1 . As seen in the table , the course is a rather typical program - ming course about the imperative paradigm . The weekly structure is not strict : only one two - hour session was used Week # Topic 1 * Course introduction 2 Variables and expressions 3 String operations 4 Conditional statements 5 Repetition 6 Procedures and functions 7 Lists 8 Lists ( cont . , including matrices ) and tuples 9 Dictionaries , sets 10 File operations 11 Python’s modules 12 Handling errors 13 * * Course project Table 1 : The structure of the university course ( UC ) . * = Only half a week , * * = one and a half weeks . Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 123 for course introduction , and the ﬁnal two - hour session was spent on course project . Object - oriented programming is not discussed , although method calls and object creation are brieﬂy referred to when introducing for example ﬁle or string operations . The LMS was used quite extensively throughout the course . For each week ( except for the two ﬁnal rounds ) , a round con - sisting of seven to ten online exercises was oﬀered . The LMS was also used for recording the attendances in the lectures , demonstration scores and the course project submissions and evaluation . There was a minimum limit for demonstrations ( 40 % ) and online exercises ( 50 % ) that needed to be com - pleted to attend the ﬁnal exam . If a student exceeded the limit , he or she could collect some bonus points for the ﬁ - nal exam . There was no minimum requirement for attending the lectures , but the students who attended 10 or 11 of them ( excluding the course project assistance sessions at weeks 12 or 13 ) also gained a few bonus points for the ﬁnal exam . The course was gradually developed between the years 2010 and 2014 . A complete description of the development as well as the results can be found in [ 9 ] . 4 . 2 Programming Course at Highschool Level The second course observed ( N = 41 ) is a programming course taught at junior high school level ( JHSC ) ( in Finland , the participants are from grades eight and nine , being 14 to 15 year olds ) . It is an optional course for all students , and is also taught using Python as the programming language . The design is based on the same principles than in the university level programming course , but the methodology is developed further . Still , active learning is emphasized , and the LMS is used extensively throughout the course . The materials are designed to be a little lighter than in the university level , but the learning goals are still similar . The course is divided into seven modules and into total of 17 two - hour sessions . The seventeenth session is reserved for the ﬁnal exam . Typically , each module consists of three sections : 1 . Lecture is similar to lectures in the university level programming course : a theoretical introduction to the topic followed by supplementary online exercises . 2 . Tutorial consists of automatically assessed exercises accompanied with learning material ( such as text , code examples , tables and images ) . The materials are typi - cally a summary of lecture slides , presenting the most relevant topics needed to complete the exercises . The tutorials are answered in collaboration with other stu - dent , and discussion is encouraged . 3 . Practical work consists of ﬁve to six programming tasks . This is the only section which is completed outside of the LMS , although the answers are still submitted into the system if the teacher wants to assess them . The practical work is completed in collaboration with an - other student . An electronic exam , similar to one described in the previous section , was used in the high school course as well . The course structure is displayed in Table 2 . The course was modeled after the design principles and experiences collected from university level courses by the research group . A complete description of them can be found in [ 8 ] and [ 7 ] . 4 . 3 Course Comparison The course structures and methodologies resemble each other quite closely . Still , there are some methodological diﬀerences that need to be noted when the performance is compared . The methodology used in JHSC is a redesigned version of the one used in UC , and hence contains some research - based ( see e . g . [ 8 ] and [ 7 ] ) improvements . The most notable diﬀerence is the utilization of tutorial - based learning . In UC , online exercises were delivered without sup - plementary material attached ( although the students could download the lecture slides right after the lecture ) , while in JHSC the exercises were accompanied with learning mate - rial . Another notable diﬀerence is the utilization of collab - orative work in JHSC , which has been proven to be highly beneﬁcial for learning results ( see for example [ 14 ] ) . Finally , a formal feedback cycle was utilized in JHSC , while in the UC the students were required to ﬁll only the opening and closing surveys . A comprehensive comparison of courses is displayed in Table 3 . 5 . RESEARCH SETUP In order to ﬁnd out whether the methodology previously proven eﬀective at university level could be utilized with younger students as well , we compared an instance of the high school programming course ( JHSC ) to an instance of the university level course ( UC ) . With this , we attempt to ﬁnd answers to the following research problems : 1 . Can the methodology be used eﬀectively to teach all topics in the high school programming course ? 2 . If the learning performance is not similar throughout the courses , can we isolate individual topics where the diﬀerences occur ? 3 . If such topics can be isolated , can we ﬁnd plausible reasons for the discovered diﬀerences ? The research was conducted with one instance of UC and one instance of JHSC . The instances , participants and the study methods are described in the following subsections . 5 . 1 Data Sets For the JHSC , the data consisted of students’ lecture sur - vey answers for each of the lectures , as well as the assignment submission data for each of the assignments . There were a total of 12854 submissions to 129 assignments . The UC data set consisted of a similar set of assignment submissions as the JHSC , with 10710 submissions to 119 assignments . The assignments were grouped together to form lecture - sized rounds , and those rounds were grouped together form the Module # Topic 1 Introduction , variables and expressions 2 String operations 3 Conditional statements 4 Repetition 5 Functions 6 Lists 7 Python’s module , ﬁle operations ( brieﬂy ) Table 2 : The structure of the junior high school course ( JHSC ) . Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 124 course itself . Each student could submit multiple submis - sion to each of the assignments . On the university and JHS courses , there were eight and seven rounds with educational content , respectively . 6 . RESULTS 6 . 1 About the Similarity of Student Scores Be - tween the Two Courses Each of the groups A – F that are listed in the Table 4 were tested for similarity using Kolmogorov – Smirnov test . The p - values of the tests are listed in the Table 5 . The test results show that the students achieve similar performance on both of the programming courses . Only Group D ( Loops ) showed diﬀering student performance between the two courses , so that the students on the JHSC receive worse scores for the content group D than the students on the UC . While student populations show similar performance for most of the content groups , it might be possible that either of the student groups would consistently outperform the other group , but with so small a margin that it would remain undetected by the statistical tests . In order to account for this scenario , students’ normalized score distributions from both courses were checked visually for all content groups , and examined for diﬀerences . Apart from the content group D , there is no systematic diﬀerence between the medians of the two courses . 6 . 2 About the Assignment Submission Counts Between the Two Courses While submission scores are distributed quite similarly within the diﬀerent content groups , the same does not apply for the average assigment submission counts within the same groups . By average , the students on the university course submit their assignments twice , regardles of the content groups ( see Figure 1 ) , whereas on the JHSC students tend to do more submissions , especially for the content groups E and F ( see Figure 2 ) . Groups E and F also have a much higher variance than the other content groups . Group D that dis - plays diﬀerences between the two courses for the submission score distributions has similar median submission count as the earlier content groups A , B and C , but it has a higher variance than the preceding content groups do . Element UC JHSC Lectures Yes Yes Supplementaryonlineexercises Yes Yes Main online exer - cises As independent rounds As tutorials Practical work Yes ( as demon - strations ) Yes Feedback cycle Opening and closing surveys Feedback after each section Attendancesrecorded Yes No , attendance is mandatory Final project Yes No Electronic exam Yes Yes Table 3 : Comparison of the courses . Index 1 Index 2 Round content Group ID ( UC ) ( JHSC ) Introduction A 1 , 2 1 Strings B 3 2 Selection C 4 3 Loops D 5 4 Procedures E 6 5 Lists F 7 6 Table 4 : The round mapping between the two courses . The rounds were ordered and taught in a similar order to omit any problems with the round ordering . On both courses , the students were taught some content after the mapped rounds , but these rounds were omitted from the analysis . Round content Group ID K - S test p - value Introduction A 0 . 543 Strings B 0 . 54 Selection C 0 . 995 Loops D 0 Procedures E 0 . 637 Lists F 0 . 238 Table 5 : P - values for the Kolmogorov – Smirnov tests between the score distributions of the mapped parts of the university and junior high school courses . Only for the Group D the score distributions dif - fer statistically from each other . 6 . 3 About the Student Activity on the Courses Students have very diﬀerent activity patterns on the two courses . Students on the UC remain active even after the course events and work on the course material outside the class room , while students on the JHSC work very little or not at all on their free time . The diﬀerence between the study habits can be seen from the Figures 3 and 4 . The reasons behind these diﬀerences are discussed in the section 7 . 7 . DISCUSSION Based on the analysis of the similarity of submission scores and times , it seems that the methodology worked equally well for JHS students in all topics , with the exception of repetition . In that round , the JHS group performed signiﬁ - cantly worse ( the diﬀerence was statistically signiﬁcant with p = 0 . 001 ) , while in all other rounds no statistically signiﬁ - cant diﬀerences were found . The course methodologies were designed in similar fashion for most parts . The most notable diﬀerences are the introduction of tutorials and feedback in the JHS level , and the inclusion of a course project in the university level course . There are some possible reasons for the JHS students’ worse performance in the repetition round . First , to ﬁnd out if the students reported any particular diﬃculties , the answers to feedback surveys in the repetition round were analyzed . Notably , there was only a single student reporting technical diﬃculties . However , when the submission counts to feedback surveys were analyzed , an anomaly was detected ( see Table 6 ) . As seen in Table 6 , the amount of feedback given in round 4 was much lower than in other rounds . When analyzing the Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 125 Figure 1 : Boxplots of the average submission counts per assignment for the diﬀerent content groups on the university course . The average submission counts remain fairly constant for all content groups . There were 3 cases where the student had by aver - age more than ten submissions per assignment in an individual content group . These were removed from the ﬁgure to improve its readability . Submissions to Module # Topic feedback surveys 1 Introduction , variables and expressions 31 2 String operations 32 3 Conditional statements 30 4 Repetition 19 5 Functions 27 6 Lists 36 7 Python’s module , ﬁle op - erations 27 Table 6 : Number of submission made into feedback surveys in each round of JHSC feedback in more detail it seems that the amount of nega - tive feedback given throughout the course was very low . It is hence possible that the low total amount of feedback indi - cates more negative experiences that just were not reported . The lower number of feedback could also indicate lower par - ticipation in the repetition round . However , since there is no drop in the total number of exercise submissions in that round ( see Figure 2 ) , this seems highly unlikely . Both courses were taught by teachers that were experi - enced in teaching computer science and programming , and both courses were taught using the same sets of course mate - rial . While it is impossible to deﬁnitively prove that the re - ported diﬀerences are not caused by diﬀerences in the teach - ing , it remains unlikely that this is the case . All in all , the younger students seem to work more to get the same results . The submission counts ( as visualized in Figures 1 and 2 ) for all rounds are higher in all rounds of JHSC . It also notable that the submission counts in the university level course have a very little variation , while in the JHS level there are large diﬀerences between individual rounds . The very high number of submissions done in the ’Functions’ round is particularly interesting . It seems that the students worked a lot harder on that round to compen - sate on the worse success in the previous round . The statis - Figure 2 : Average submission counts per assignment for the content groups on the junior high school course . The average submission counts vary signiﬁ - cantly , and especially for the content groups E and F the variance of the submission counts increases when compared to the earlier content groups . There were 2 cases where the student had by average more than ten submissions per assignment in an individual con - tent group . These were removed from the ﬁgure to improve its readability . Figure 3 : Student submission activity on the univer - sity course . Each cell in the ﬁgure shows the cumu - lative amount of submissions that were made on a speciﬁc weekday during a three hour time interval . The students are most active during the tutorials , but work also outside the lectures and tutorials , as well as in the evenings . tical diﬀerences between JHS and university rounds seem to conﬁrm this : the diﬀerence in the repetition vanished in the subsequent topic . Still , it should be noted that the standard deviation is a lot higher in the JHS course than it is in the university level course , so the submission counts vary a lot more among JHS students . The submission behavior also seems to be highly diﬀer - ent among the younger students , as seen in Figures 3 and 4 . The students at the junior high school seem to submit almost exclusively during the class hours , while the students at uni - versity level submit evenly throughout the week . There are some obvious structural reasons for this : the students at JHS had dedicated tutorial sessions throughout the course where the majority of submissions seems to have been made . Still , it seems that the students in the JHS level work very little outside classroom . This might also be one of the reasons for the worse learning performance in the repetition round : it could be possible ( though there is no obvious evidence Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 126 Figure 4 : Student submission activity on the JHS course . The JHS students are active only during the tutorials , and spend little to no time on the as - signments apart from the tutorials . of this ) that had the students kept on working outside the class hours , the diﬀerence could have been smaller . Based on the results , it might be possible that at least some of the students in the JHS level are mostly externally motivated , while in the university level the motivation is more inter - nal . However , motivation is notoriously diﬃcult to measure [ 17 ] , and there is no direct evidence to support the assump - tion , especially as JHS students achieve as high scores as the university students . All in all , it still seems that the same methodology we have applied successfully in the university level can be used eﬀectively to teach programming in the junior high school level as well . There are diﬀerences in the learning perfor - mance , submission behavior and study habits , but in au - thors’ opinion none of them are too dramatic . Still , the sta - tistical diﬀerences provide valuable information which could be potentially used to ﬁne - tune the methodologies used to teach programming for younger students . For example , the tendency to only perform course work during class hours is probably not a new issue for teachers at such levels , but it still drastically decreases the number of hours spent working during the course . The worse performance in the repetition round is also something that should be addressed , for exam - ple by dedicating more sessions to the topic . 8 . REFERENCES [ 1 ] A . F . Blackwell . What is programming . In 14th workshop of the Psychology of Programming Interest Group , 2002 . [ 2 ] B . DiSalvo . Graphical qualities of educational technology : Using drag - and - drop and text - based programs for introductory computer science . IEEE Computer Graphics and Applications , 36 ( 6 ) : 12 – 15 , 2014 . [ 3 ] B . Du Boulay . Some diﬃculties of learning to program . In E . Soloway and J . Spohrer , editors , Studying the Novice Programmer , pages 283 – 299 . Lawrence Erlbaum Associates , London , 1989 . [ 4 ] J . - M . Hoc , T . R . G . Green , R . Samurcay , and D . J . e . Gilmore . Psychology of programming . Academic Press , 2014 . [ 5 ] J . Holvitie , T . Rajala , R . Haavisto , E . Kaila , M . - J . Laakso , and T . Salakoski . Breaking the programming language barrier : Using program visualizations to transfer programming knowledge in one programming language to another . In 12th International Conference on Advanced Learning Technologies ( ICALT ) , 2012 . [ 6 ] E . Kaila , E . Kurvinen , E . Lokkila , M . - J . Laakso , and T . Salakoski . Enhancing student - teacher communication in programming courses : a case study using weekly surveys . In Proceedings of ICEE 2015 - International Conference on Engineering Education , 2015 . [ 7 ] E . Kaila , E . Kurvinen , E . Lokkila , M . - J . Laakso , and T . Salakoski . Redesigning an object - oriented programming course . Accepted for publication in The ACM Transactions on Computing Education , 2016 . [ 8 ] E . Kaila , T . Rajala , M . - J . Laakso , R . Lind´en , E . Kurvinen , V . Karavirta , and S . T . Comparing student performance between traditional and technologically enhanced programming course . In Proceedings of the Seventeenth Australasian Computing Education Conference ( ACE2015 ) , Sydney , Australia , Sydney , Australia , 2015 . [ 9 ] E . Kaila , T . Rajala , M . - J . Laakso , R . Lind´en , E . Kurvinen , and T . Salakoski . Utilizing an exercise - based learning tool eﬀectively in computer science courses . Olympiads in Informatics , 8 , 2014 . [ 10 ] M . - J . Laakso , E . Kaila , and T . Rajala . Ville – desigining and implementing a collaborative education tool . Submitted into British Journal of Educational Technology , 2016 . [ 11 ] A . Matth´ıasd´ottir . How to teach programming languages to novice students ? lecturing or not . In International Conference on Computer Systems and Technologies - CompSysTech , volume 6 , 2006 . [ 12 ] J . P . McCarthy and L . Anderson . Active learning techniques versus traditional teaching styles : two experiments from history and political science . Innovative Higher Education , 24 ( 4 ) : 279 – 294 , 2000 . [ 13 ] M . McCracken , V . Almstrum , D . Diaz , M . Guzdial , D . Hagan , Y . B . D . Kolikant , and T . Wilusz . A multi - national , multi - institutional study of assessment of programming skills of ﬁrst - year cs students . ACM SIGCSE Bulletin , 33 ( 4 ) : 125 – 180 , 2001 . [ 14 ] T . Rajala , E . Kaila , J . Holvitie , R . Haavisto , M . - J . Laakso , and T . Salakoski . Comparing the collaborative and independent viewing of program visualizations . In Frontiers in Education 2011 conference , October 12 - 15 , Rapid City , South Dakota , USA , 2011 . [ 15 ] T . Rajala , M . - J . Laakso , E . Kaila , and T . Salakoski . Eﬀectiveness of program visualization : A case study with the ville tool . Journal of Information Technology Education : Innovations in Practice , 7 : 15 – 32 , 2008 . [ 16 ] T . Rajala , E . Lokkila , R . Lind´en , M . - J . Laakso , and T . Salakoski . Students’ perceptions on collaborative work in introductory programming course . In Proceedings of the EDULEARN15 Conference , pages 2795 – 2800 , 2015 . [ 17 ] M . Tour´e - Tillery and A . Fishbach . How to measure motivation : A guide for the experimental social psychologist . Social and Personality Psychology Compass , 8 : 328 – 341 , 2014 . [ 18 ] D . Weintrop and U . Wilensky . To block or not to block , that is the question : Students’ perceptions of blocks - based programming . In Proceedings of IDC ’15 , June 21 – 25 , 2015 , Medford , MA , USA . ACM , 2015 . Session 3B : Code Maturity ITiCSE ' 17 , July 3 - 5 , 2017 , Bologna , Italy 127