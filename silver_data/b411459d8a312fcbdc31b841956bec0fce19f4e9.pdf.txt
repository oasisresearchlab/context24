ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre Thomas Riisgaard Hansen and Jakob E . Bardram Centre for Pervasive Healthcare Department of Computer Science , University of Aarhus Aabogade 34 , DK8200 Aarhus N . , Denmark { bardram , thomasr } @ daimi . au . dk Abstract . Building capture and access ( C & A ) applications for use in the opera - tion theatre differs greatly from C & A applications built to support other settings e . g . meeting rooms or classrooms . Based on field studies of surgical operations , this paper explores how to design C & A applications for the operation theatre . Based on the findings from our field work , we have built the ActiveTheatre , a C & A prototype . ActiveTheatre is built to support collaboration in and around the operating theatre , to capture events instead of automatically capturing eve - rything , and to be integrated with existing applications already present in the operation theatre . The ActiveTheatre prototype has been developed in close co - operation with surgeons and nurses at a local hospital . The work on the proto - type and our initial evaluations have provided an insight into how to design , capture and access applications that are going to be used in other settings than the meeting room . 1 . Introduction Capture and Access ( C & A ) applications have been an expanding area along with the dawning of ubiquitous computing systems , cheaper storage and the development of new sensor technologies [ 18 ] . The increasing focus on C & A systems can be associ - ated with two compelling properties of the C & A systems . Firstly , C & A systems promise to enhance human memory to remember all events . Secondly , C & A systems promise to be able to do time shifting , which for instance could be re - experiencing a meeting , a lecture , a birthday by rewinding the tape and playing the episode with video , sounds , and annotations . These properties have been explored in a number of applications ( see Section 2 on related work ) . However , the basic workflow in many of them follows the same for - mat . First , there is a preparation phase where information is prepared and handed out before , e . g . , a meeting or a class . Then , in the capture phase , a range of media is re - corded like video , sound , pen strokes , and slide changes . Then , in the indexing phase , recorded material is structured and annotated either manually or more or less auto - matically . Finally , in the access phase , captured material can be viewed and navi - gated . It is characteristic for these systems that they capture and access information in 2 Thomas Riisgaard Hansen and Jakob E . Bardram a continuous flow , making no differentiation between discrete events in the capture phase . Furthermore , many C & A applications have an inherent single - user focus , ena - bling only individual users to prepare , capture , and access the information which has been recorded earlier . In this paper we want to draw the attention to other types of work domains where C & A systems are of great value but have to function in a different manner . In contrast to the continuous , single - user ‘prepare - record - annotate - access’ type of C & A systems , we point to the need for collaborative and event - based C & A systems . In such C & A systems , the users and triggers in the usage context help identify , record , and access discrete events of importance in the flow of time and this captured event - based infor - mation is immediately available for a collaborative set of users . By doing this , it is the overall goal of this paper to broaden our conceptual understanding of C & A applica - tions to also incorporate collaborative , event - based C & A . The empirical foundation of our research into C & A is surgical work in operating theaters . The operating theatre differs in a number of ways from meeting rooms or classrooms : it is a highly collaborative environment where skilled surgeons , anesthe - tists and nurses work together on treating a patient ; information is constantly ac - cessed , recorded , and re - accessed in the process of an operation ; there are discrete events during an operation where capture is extremely important , but at the same time during large parts of an operation capture is highly irrelevant . Hence , in the design of C & A technology for the operating theatre , it is important to help users capture what is relevant , and share that collaboratively at once , but also to help users in reducing the amount of irrelevant information which would , if captured , make the system useless . In this project we have worked closely with a range of surgeons , anesthesiologists , and operating nurses . The empirical foundation is described in Section 3 . Section 4 discusses the need for C & A technology in the operating theatre and Section 5 presents the design of ActiveTheatre , a C & A application for operating theatres focusing on its support for collaborative , event - based capture and access of critical clinical data . Section 6 presents details of the implementation of ActiveTheatre and section 7 pre - sents our initial evaluation of it done collaboratively with the clinicians participating in the project . Section 8 concludes the paper . The main contributions of this paper is thus to ( i ) broaden the understanding of C & A systems for new types of work domains , which is radically different from the meeting room or the classroom , and ( ii ) to present a concrete implementation of such a collaborative , event - based capture - and - access application . 2 . Related Work Developing systems that are able to automatically capture what is happening in our everyday life and later allow the user of the systems to access these data have been explored in several contexts . As pointed out in the survey chapter of [ 16 ] many of the developed projects , however , address a relatively small number of domains and deal with the same kind of problems . Especially capturing what is going on in meeting rooms or classrooms has been in focus . Even though the two settings are clearly different , the types of interaction go - ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 3 ing on are in many aspects similar . In many situations one person will give a presenta - tion and the rest of the participants will stay silent and take notes . Occasionally , a subject might be discussed in details by the participants , and in general it is hard to anticipate in advance when something interesting will be said . Furthermore , standard office technology like laptops , PDAs , and tablet PCs are useable in these two settings . These similarities have resulted in a set of capture and access applications that have a similar structure . First , material is prepared for use in class or at a meeting . Then when the event takes place , everything is captured in order not to miss important information . The captured material is then analyzed and indexed , and finally a uni - form access interface is provided to all the potential users of the system . This struc - ture has been used to build capture and access applications for meetings e . g . Coral [ 11 ] , TeamSpace [ 14 ] , NoteLook [ 5 ] and Dolphin [ 15 ] , or for building applications for the classroom , e . g . the Classroom 2000 project [ 1 , 12 ] . When applications move away from capturing the interaction in the meeting room or classroom new requirements that challenge the notion of capture and access arise . Moving automatic capture applications into the home challenges the configuration of these systems to fit into the everyday lives of people at home as pointed out in [ 17 ] . Using capture and access to follow the development of children with autism questions how to actually do the capturing of the activities of children who move around in different physical and social settings [ 6 ] . Capturing design workspaces questions how to capture unanticipated and collaborative events and how to structure these events optimally to reduce information overload . Arnalonescu et al . [ 2 ] investigates capture and access in the design space and uses discrete time - slices instead of continuous streams of data . We design for a different and rather challenging setting – the operating theatre . The operating theatre resembles some of the above mentioned domains in some aspects , but is clearly different in others . One major difference between the operating theatre and some of the other settings is probably the high degree of collaboration among the various different professions involved . Before the operation many different people have to prepare using different materials , during the operation extensive collaboration is needed , and after the operation many different persons with different backgrounds need to access the data captured in the operating theatre . Even though some projects address collaboration they mainly address the capturing of collaborative activities and not how to support collaborative preparation , capture and access data , and they do not address the same tight collaboration found in e . g . the operation theatre . In the operation theatre the really important thing to capture is not the entire opera - tion , but small parts of the operation , or when something diverges from what is ex - pected . Because it is almost impossible for an automatic system to index these mo - ments we found capturing systems that support explicit capturing and focus on events better suited than automatic capturing applications . In other C & A systems , events are used to index a captured stream of data . The main difference is , however , that in an event - based C & A system the user decides what constitute an event . Because identifi - cation of events are done during the capture phase , and not afterwards , data becomes accessible for collaborators immediately . One limitation to this approach is that in some cases , users would only realize an event to be important after it has happened . For example , how can we handle the case when the surgeon indicates that what just happened a few moments ago in the procedure should be recorded for later access ? In 4 Thomas Riisgaard Hansen and Jakob E . Bardram such cases , buffering techniques like the ‘Experience Buffer’ [ 7 ] may be applied . Finally , Chiu at al . [ 5 ] and Arnalonescu et al . [ 2 ] suggest systems that support explicit capturing during meetings or design workshops , but those systems only provide lim - ited support for collaboration , and they cannot be directly used in a sterile environ - ment such as an operating theatre . 3 . Field studies Most people are familiar with how a meeting is structured or what is going on in the classroom , but few people outside the hospital environment actually know what is going on in an operating theatre . In order to understand in details the work taking place while operating on a patient we have undertaken a range of in - depth field stud - ies . Because we are designing technology for operation rooms in general , the main objective of these studies was to study the similarities and differences between a wide range of operational procedures and types of operating rooms . In total more than 20 workdays of observations of patient operations have been done at four different hospi - tals . We have observed more than 40 unique operations at different departments , ranging from plastic surgery , orthopedic surgery , and obstetric surgery . Some of the departments use an electronic patient record for record keeping , while other depart - ments use a paper - based record . Relatively few detailed field studies of operating theatres with a technical focus in mind have been made , but as pointed out by Heath et al . [ 8 ] an operating theatre is clearly an intense work setting , where life - critical work is being done in close , and often silent , cooperation between extremely skilled persons . One of the main findings from these observations was that in order to make this delicate collaborative work succeed , there was a constant access to clinical and other related information before , during and after the operation . Furthermore , important aspects of the operation were captured and this information was afterward shared collaboratively . Hence , it became interesting to understand what kind of information was accessed and captured , when , by whom , and for what purpose . Our findings are summarized in Table I and are further detailed below . Fig . 1 . Using a paper - based medical record while operating ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 5 3 . 1 Information used during an operation We observed that the following types of material were used during an operating . • The patient’s record – The paper record or computer based record was always present in the operating theatre and was consulted in different situations ( see figure 1 and 2 ) . The surgeon did not have direct access to the record . It was usually situ - ated in one end of the operating room , either as a paper - based record lying on a ta - ble or accessible from a desktop PC placed on the table . Often the surgeon would ask the non - sterile nurse to read aloud from the journal . In the operating theatre the record was mainly a single user artifact because it wasn’t accessible to the sterile surgeons and nurses . • Medical Images – Medical images were ( depending on the operation ) used exten - sively during surgical operations . These images were located in the one end of the operating room together with other kinds of documentation , as can be seen in fig - ure 2 . • Instructions – In some situations an operation required the use of some special equipment e . g . an advanced implant or the mixture of some cement . The nurses and doctors used paper instructions and manuals to guide them in the procedure . The manual or instruction was found and placed open on a table nearby . Also anat - omy books and charts were used while operating . For example , in one situation some of the blood vessels were crossed in a strange pattern and the surgeon put an anatomy book with a picture of the blood vessel in the leg on a small table next to the patient . Fig . 2 . Accessing medical images and an electronic medical record while operating In the situations we observed there was a clear need for accessing information during the operation but in all the cases the access to the digital information was problematic and required that external books were brought in , that the nurse had to navigate and read aloud , or that the surgeon had to move away from the patient to access the in - formation . 6 Thomas Riisgaard Hansen and Jakob E . Bardram 3 . 2 Capture during an operation Looking closer to the kind of information captured during an operation , the following list contains the more important issues : • Notes – The nurses made notes before , during , and after the operation . In particu - lar , the nurses documented special events from the operation . For example , when the patient was anaesthetized or when the patient was moved into a new position . The surgeon made the description of the operation in the medical record after the operation and depending on the operation , this description was therefore docu - mented between one to sixteen hours after the operation had started . • Pictures : Pictures were used to document some parts of the operation . In one oper - ating theatre cameras were mounted in the operating lamp , the corner of the operat - ing room and below a computer screen . Because it was too complicated to put the pictures in the medical record , such pictures were not used to document the opera - tion . Instead they were printed out and given to the patient . In another operating theatre a normal digital still - picture camera was used by the nurse , who took pic - tures on request . These pictures were sometimes used to discuss a case at the morn - ing conference or to document what kind of operation a young surgeon had per - formed . Access Capture Design What • Patient data • Medical images • Instructions • Notes • Pictures • Video The system should support different types of data and integrate with existing systems When • Before • During • After • Before • During Event - based cap - tured and access Portable informa - tion By whom • The surgeon • Other doctors and nurses • The patient and rela - tives The surgeon and the nurses present at an operation Support for col - laboration and multiple users . How • With computers • Pictures on a camera • Browsing notes • Use of camera • Note taking • Typing in on computers New ways of interacting with the system Table 1 . Overview of Access and Capture in the operating theatre and the related design issues to consider . ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 7 • Video : We observed that video recordings were used , especially for operations carried out with an endoscope . The camera was mounted in the endoscope and the video could be streamed to a CD - ROM . However , these video recording were rarely accessed and most of the CDs remained untouched in the surgeon’s office , difficult for others to access . Our conclusion was that even though a lot of data was recorded and there was a need to produce data during the operation , it was difficult to actually record these data and later access them . 3 . 3 Access of captured data An important question to investigate in the field studies was to ask who actually used the information captured during an operation and for what purpose . • Documentation – Currently , the most used and hence most important piece of information accessed from an operation is the clinical description by the surgeon , which s / he entered in the medical record after the operation . This information is the key to further treatment and care by other fellow clinicians at the hospital and out - side . Hence , it was accessed by both doctors and nurses . However , recorded pic - tures and videos were never used as documentation at this point of time . The soft - ware managing the electronic patient record did not support pictures taken during an operation and it was therefore cumbersome to access the pictures . • Patient’s souvenir : The pictures were however often shown or given to the patient to keep . The pictures from the operation were shown to the patient on the digital camera and they were often printed out or burnt on a CD - Rom , which was given to the patient . • Learning : In some situations we observed the digital pictures and videos being used as instruments for learning . Some of the captured pictures were shown to and discussed with other doctors at their morning conference . • Personal history : In the plastic surgery department , pictures were used to docu - ment different types of operations by younger surgeon . From what we observed the captured data was used not just in one setting , but in many different settings by many different persons with different background . Using captured data for learning was clearly different from using them for documenting a procedure , which again was completely different from the kind of material the patient received on a CD - Rom . The last column of Table 1 is a summary of the core design requirements coming out of the analysis . 4 Moving Capture and Access into the Operating Theatre Based on our detailed field studies in operating theatres and our on - going interviews and conversations with surgeons and operating nurses , we are convinced that C & A technology has its purpose in an operating theatre . Such a system would help sur - 8 Thomas Riisgaard Hansen and Jakob E . Bardram geons and nurses to easily access relevant information at the right time and place , i . e . while operating and in the operating theatre . Furthermore , C & A technology can help the surgeon and the nurses in making the description of the operation in the medical records immediately during or shortly after the operation , instead of , as it happens now , where it may take hours before it is done . However , our detailed studies also reveal that there are some fundamental design requirements for C & A technology in the operating theatre , which makes it different from the C & A technology described in Section 2 as designed for , and used in , meet - ing rooms and classrooms . We need a new type of C & A technology that is better suited for work situations like the operating room , which is characterized as an in - tense co - located collaborative work environment , with little room for conventional computer technology like desktop PCs , laptops , mouse , and keyboards . It would , for example , be rather difficult for a surgeon to use a normal PC while operating . More specifically , we found that the notion of access was different in our case be - cause it is not something that is separated from the capturing part . In many systems data is first captured e . g . during a meeting and then after the meeting the data is up - loaded to a server for access . In the operating theatre , a lot of different information is accessed during the operation at the same time as information is captured . Some of the information accessed is information captured at e . g . operations carried out earlier but it is also information that has been captured during the same operation . Therefore , we found it difficult to maintain a strong division between capturing and accessing data . Furthermore , the captured information during an operation was not stored in a separate system and accessed through a specific interface afterwards . The captured data was stored in the Electronic Patient Record ( EPR ) , or in Picture Archives and Communication Systems ( PACS ) . In these systems the captured data was integrated with already existing data . The data accessed in relation to an operation would not only be the data captured with a C & A system , but a combination between data cap - tured with the system and data gathered from other systems ( e . g . EPR , PACS ) . 5 . ActiveTheatre Based on the findings from the field studies , we engaged in a user - centered design and development process with a group of doctors , surgeons , nurses , and computer scientists from a company developing PACS systems . We have conducted a future workshop [ 9 ] , a number of design workshops , and recorded a video prototype in an actual operating theatre [ 10 ] . The result is a first version of the ActiveTheatre system which will be presented in this section . 5 . 1 The palette metaphor ActiveTheatre is designed as an event - based capture and access system , which does not automatically capture everything . Hence , the basic temporal model is discrete rather than continuous along an indexed time line . An event can be a text note , a pic - ture or a video clip . To describe the system we have used the metaphor of a palette ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 9 ( resembles [ 13 ] ) . The palette provides a good metaphor because it can hold different types of data , you can put and take things from the palette at any point in time and several users can access the palette . The palette metaphor is illustrated in Figure 3 . Fig . 3 . The palette metaphor describes the ActiveTheatre system Before an operation the people involved in the event prepare for it . In ActiveThea - tre the surgeons and the nurses are able to place digital material on the palette in their offices that should be made easily available for access during the operation . The surgeon carries the palette to the operating theatre . In the operating theatre the people present are able to access the data on the palette and the palette is coupled to a context - aware system and a capturing system . The context - aware system is able to push relevant data to the palette depending on the situation e . g . some information is only relevant in the first part of the operation ; some information depends on the type of operation . The surgeons and nurses are also able to use a capture system in the operating theatre to push data to the palette . The data added to the palette is not a complete video stream of the entire operation , but small video sequences , pictures , or dictated notes that document an important event in the operation . After the operation the surgeon or a nurse carries the palette to an office where the data on the palette is used to create different kinds of documents depending on who the recipients are . The surgeon can choose a note and two pictures from the palette and add them to the electronic patient record , continue and choose a set of pictures and add them to an operation description for the patient , and he can finally choose some pictures to show e . g . next morning at the morning conference with the other doctors . The palette metaphor incorporates the following design principles ( see also Table I ) : • Event - based – The palette metaphor is an alternative to the timeline metaphor . In the operating theatre there is no need to capture everything , only the important events . During the workshops , this point was stressed several times by the surgeons and nurses ; they did not want to produce irrelevant information . The palette meta - phor emphasizes that events . • Heterogeneous Data and Systems – Almost all suggested capture and access systems deal with more than one type of data e . g . slides and video or pen strokes and web pages . ActiveTheatre makes no strong distinction between what is ac - 10 Thomas Riisgaard Hansen and Jakob E . Bardram cessed and what is captured ; both captured and accessed data is added to the pal - ette . We also wanted the ActiveTheatre to be able to integrate with existing sys - tems present in the hospitals . One of the partners in the project develops PACS software and we wanted to a ) propose a design that was able to extract data from these types of systems and add it to the palette and b ) be able to store captured data on the palette in PACS and other related systems after the operation . • Multiple users and collaboration – One of the novel issues coming out of the design process was the need for supporting multiple types of uses in a C & A system for operating theatres . Existing C & A systems all provide the same interface for ac - cessing the captured information no matter who uses the system . In the hospital we need multiple representations depending on who is going to access the data . With the palette it is possible to select a number of events and use them to easily gener - ate different representations . For learning and knowledge sharing purposes a lot of detailed pictures from a specific phase of the operation might be relevant , whereas the patient will be interested in only a single picture from that phase . With the pal - ette metaphor the doctor or nurse can use the palette to make the kind of documen - tation they need depending on who the recipient is . • New interaction metaphor – The palette metaphor also contains a basis for devel - oping new interaction methods in the operating theatre . First of all , the distinction between preparation , operation , and follow - up helps the surgeon to have relevant data available to access , but also to capture things during the operation and save it for later processing . Adding information to the palette during preparation allows the surgeon to look up and prepare information in a quiet environment and not in the interaction - limited and stressful environment of the operating theatre . During operation , a context aware system can identify and add relevant information to the palette with minimal disturbance of the surgeon . The objective of the system is to limit the interaction during the operation when accessing data on the palette and controlling the capturing system , and leave the rest of the interaction to before and after the operation in a richer interaction environment , e . g . with an office com - puter . 5 . 2 User Interaction with ActiveTheatre The ActiveTheatre system offers users a flexible way of preparing , accessing , captur - ing , and using medical information with regard to a surgical operation based on the ‘palette’ metaphor . The current user - interface of ActiveTheatre is shown in Figure 4 . On the left is a list of data categories , on the right is a list of items captured within the selected category ordered by the time of capture , and in the middle is the data area . Before the operation , a surgeon or nurse can prepare material to access later by select - ing and ordering this into groups . The different groups appear as separate items on the left . ActiveTheatre is also coupled with a simple context - aware system , which is able to add extra items and material to the interface depending on the context . ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 11 Fig . 4 . ActiveTheatre prototype overview During an operation the users are able to access all the material added to the Ac - tiveTheatre and to capture new material by e . g . taking pictures , recording video or dictating notes . The newly captured material is added to the system , ready for imme - diate access for all users . ActiveTheatre uses speech - based interaction and zoomable interfaces , thereby allowing the user to access data while using his hands to operate and to view data at a distance . After the operation , users can select material from the palette and this material can be exported in a number of formats depending on what types of system the data is going to be used in . If the pictures are going to be added to a PACS system one for - mat is used , if it is going to be printed out or put on a CD - ROM another format can be chosen . 5 . 3 The ActiveTheatre Architecture The ActiveTheatre is designed and refined to work in an operating theatre , but we wanted to start out with an extensible and modifiable architecture . We wanted the architecture to be flexible enough to also support other contexts e . g . a capture and access system for homes or public places , and modifiability was our main architec - tural goal [ 3 ] . The ActiveTheatre is built around five main components . The input component handles input from external input devices . In the ActiveTheatre we have an external speech component for controlling the application and dictating notes . We use a web cam to capture pictures and video and finally we have a Context Aware sub - system to push information to the system . 12 Thomas Riisgaard Hansen and Jakob E . Bardram Export of used and captured data is handled by the ViewGenerator component , which is able to take selective parts of the model and export it . An XML document is generated that describes the captured data , and how it is stored . An XSLT style sheet can then be combined with the XML document and the exported resources to create a XHTML document viewable in a web browser or another data format suitable for the receiving application . Figure 5 shows an overview of the architecture . Fig . 5 . ActiveTheatre prototype overview The core of the ActiveTheatre prototype was implemented with a model , view , con - troller pattern . The model is responsible for handling our different types of media : text , images and video . The view component is responsible for updating our zoomable interface and the controller is responsible for coordinating the communication . 5 . 4 Context filtered information ActiveTheatre cooperates with a context - awareness subsystem in three ways . First , the context - awareness subsystem is able to suggest digital information to the surgeon based on e . g . the type of operation , instruments used or the patient history . The sub - system monitors the progress of the operation and provide access to relevant data in a timely fashion by knowing the type of operation taking place in an operating theatre and then using this information to fetch relevant data , like surgical instructions . Sec - ond , just like users can capture data , changes in the usage context in the operating theatre can trigger data to be added to the palette or removed from it . Finally , the context - awareness sub - system is used to annotate captured data with relevant infor - mation , like the id of the patient , the operating surgeon , and the location . 5 . 5 Speech Interaction and Zoomable interfaces To navigate in the system during an operation we used speech commands only . Speech interaction allows the user to use the system while using both hands to do ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 13 physical work . Speech recognition was also used for creating small notes during the operation . For ActiveTheatre we used Microsoft Speech API ( SAPI 5 . 0 ) . SAPI is a speech recognition and generating system that comes with Microsoft Office XP and it has an API for controlling the speech recognition and generation . The speech engine we used was not trained for clinical practice , but for our proof of concept prototype it was sufficient to demonstrate how the system worked . A range of professional voice recognition systems which are specialized to certain medical terminology exists . Speech recognition can be used in two different ways . Either it can be used to issue commands , or it can be used to recognize continuous speech . We used a combination of the two techniques . For controlling the system we used command - based speech recognition . For making notes and annotating pictures we needed to recognize con - tinuous speech . We used a specific keyword to switch between dictation and com - mand mode . In dictation mode the system wrote everything the user said except some special commands e . g . “new line” . We also used synthesized voice along with anima - tions to give the user feedback about his / her action . This allowed the user to issue commands to the system without having to focus on the screen . Even though we did not use expensive speech recognition the system worked quite well . The system was able to recognize the different commands even though they were pronounced by different people . However , the speech recognition was more sensitive to the voices who had trained it when trying to recognize continuously speech . Because the layout of the operating theatre and the position of the people within depend on the type of operation carried out , we did not know in advance how far away the user would be from the screen . This fact combined with the need of some - times focusing on some small details without moving closer to the screen required a scalable interface . Therefore , most of the interface components in ActiveTheatre are zoomable . We used a modified version of the Piccolo framework to build the zoom - able components [ 4 ] . Each captured or accessed element , both text and pictures , was placed in a canvas that could be zoomed and panned . With piccolo the user could view even small details without moving away from her / his current position by using speech commands . 5 . 6 Exporting data to other systems Accessing the data captured from ActiveTheatre is not done with a special viewer . Depending on the captured data many different systems are able to get , store , and view the captured data . For documentation purposes the captured data is fed to the electronic patient record or a picture archiving system . The patients e . g . prefer to get their data either as a print out or on a CD - ROM ; some doctors want to export some of the captured data to web pages that could be used for learning purposes . To integrate ActiveTheatre with these different types of systems the surgeon or nurse is able to mark the resources from the palette they are going to use and then chose a template that specifies how these resources is going to be formatted . ActiveTheatre then ex - ports the selected resources along with an XML document describing the exported resources . With the use of XSLT transformation we implemented several templates 14 Thomas Riisgaard Hansen and Jakob E . Bardram for generating web pages from the exported resources , and are currently working on allowing other applications to use the exported data . 6 . Preliminary Evaluation / Initial Experience As a preliminary evaluation of ActiveTheatre , we conducted a scenario - based evalua - tion workshop in order to assess whether the system supported the need for collabora - tive , event - based access and capture in an operating theatre . The participants in the evaluation workshop were two surgeons , an anesthesiologist , and two operating nurses . The workshop lasted six hours and took place in a simulated operating theatre at our university . This operating theatre contained an operating table with a 17 inch touch screen on a moveable arm , a large wall - based display in the background , and microphones and loudspeakers . A picture from the workshop is shown in Figure 6 . The workshop was divided into a five - hour ‘play’ part and a one - hour interview part ; in the play phase , the clinicians played the scenarios a number of times and in the interview phase a focus group interview was done . We video recorded the whole workshop and have subsequently analyzed the tapes . Fig . 6 . Evaluation workshop The main purpose was to get early feedback on the system and its interface in the workshop , and even though we wanted to address several aspects of the system in the evaluation we focused on two main questions : • Does the event - based ‘palette’ metaphor in ActiveTheatre suit the work done in an operating theatre ? • Does ActiveTheatre support collaboration and multiple users ? ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 15 The main flow of the enacted scenario was : ( i ) a surgeon prepares for an operation in an office on a standard PC with keyboard and mouse ; ( ii ) the surgeon goes to the simulated operating theatre and pretends to perform an operation in this setting with the help of an assisting surgeon , a scrub nurse , and a non - sterile nurse ; ( iii ) after the operation the surgeon prepares different views , again in an office . The main findings are summarized below . 6 . 1 Event Based Capture and Access One of our main points we wanted to clarify was if the use of explicit capturing focus - ing on events was able to support the work done in the operating theatre . All the par - ticipants had a strong bias towards event - based capturing in contrast to continuous capturing . Their arguments were that it was seldom more than a couple of isolated events that were interesting to capture . Further , they found it important to only cap - ture the important events . A problem with hospital work is not always the lack of information , but sometimes too much available information . Being able to explicitly capture data allows the surgeon or nurse to only capture what they find important , and even in these situations they also find it important to be able to further sort the cap - tured data after the operation , which is illustrated by the following quote . Anesthesiologist : “If pictures are captured then there is someone who is going to judge if these pictures are going to be stored . Someone should be able to look at a sequence of pictures and decide if these pictures are relevant for the patient record . If this is not the case it should be possible to delete the pictures right away” . Following this discussion , the participants also talked about how to best capture or document an event . In some situations one surgeon actually found that a precise tex - tual description of an event was more valuable than a picture . It was commented that the value of a picture greatly depends on the type of operation carried out . The par - ticipants however agreed that if it was really easy to interact with a capturing system it would be relevant to capture pictures , video clips and texts . They also foresaw that these types of capturing systems could be used to require new and better ways of documenting operations illustrated by the following quote : Orthopedic surgeon : “If , with the help of the technology , it is possible to take pictures and videos it is probably going to be a requirement that you take pictures of different events during an operation” All the participants found speech to be an easy way to access capturing and access systems , but pointed out that it was really important that the system recognized cor - rectly if it should be pleasant to use . Finally , we discussed if dictated notes would be relevant to capture , because dictat - ing a note to some degree removes focus from the work at hand . In general the par - ticipants did not think that it was possible to generate a complete description of the operation while operating , but that a speech recognition system would be valuable in creating a draft of the operation description or making small reminders . It was espe - 16 Thomas Riisgaard Hansen and Jakob E . Bardram cially mentioned as being valuable for long operations , or if an operation differs a lot from what is originally expected . After the operation the surgeon will be able to cor - rect the mistakes in the draft and create the final version , as the following quote illus - trates : Head surgeon : “That is what I imagine . The part about generating the text can easily be done during the last part of the operation , but I think correcting the small details need to be done in a quite place . I think it is interesting to generate a draft of the text before you are carried away by the coffee table” . 6 . 2 Collaboration and Multiple users The second issue we wanted to evaluate was how our system supported collaborative work . Support for collaboration was an issue from the beginning of the evaluation workshop . When a surgeon prepared for an operation the prepared data should not only be accessible by the surgeon , but by all the people involved in the team like the scrub nurse pointed out : Scrub Nurse : ” For me it is logical . When John prepares the information for the op - eration the data is attached to the operation and not his login . If this is the case we will be able to access the pictures without John having to login all the time” . What she is pointing out is that it is not just the surgeon that prepares for an operation , but the entire team . The nurses are , for example , responsible for finding both the instruments and related digital material . Therefore she especially liked the idea that the nurses would be able to add things to the palette both before and during the opera - tion . ActiveTheatre is designed to work on a shared display and allows all users to ac - cess the system simultaneously . However , during an operation a lot of parallel events are going on at the same time . The nurse might look at some instructions she needs while the surgeon is documenting the operation with pictures . The participants sug - gested that we somehow addressed this problem of parallel activities by e . g . providing several screens but at the same time should pay attention to the difference between public and private information and displays . Integrating the capturing system with other already present systems in the hospital was also mentioned as central to a C & A application . The participants complained that it was too difficult ( and sometimes impossible ) to transfer data from one application to another . As illustrated in the quote below , it was , for example , especially compli - cated to attach digital images to the patient record : Surgeon : ” It is seldom I put the pictures in the journal . It is too complicated . Instead I give them to the patient” It is the easy integration between the different systems that is seen as the biggest ob - stacle if captured data is going to be used in the electronic patient record , enhanced documentation , patient souvenirs , for learning , or as part of a surgeons personal diary . ActiveTheatre – a Collaborative , Event - based Capture and Access System for the Operating Theatre 17 7 . Conclusion and future work We found that building capture and access systems for the operating theatre led to new design requirements not previously addressed by related systems . ActiveTheatre is a prototype of a novel system that addresses these challenges : • ActiveTheatre supports highly collaborative environments by allowing several users to work with the system before , during , and after an operation . • It is built around the idea of focusing on events structured with a palette metaphor . • ActiveTheatre is not designed as a monolith system , but built to be part of a net - work of applications that exchange data . • The prototype shows how speech and zoomable interfaces can be useful interaction techniques for capture and access applications . The next main target for the ActiveTheatre application is a pilot deployment for four to six weeks in an operating theatre in the hospital we cooperate with ( scheduled October 2005 ) . In order to meet this target , we are currently working on how to im - prove our system to better support parallel activities in the operating theatre as dis - cussed in the evaluation . We are also working on integrating our system with some of the existing systems provided by our commercial partners in the project in order to use real data in the pilot deployment . Though our research mainly have been based and focused on supporting medical work in relation to the operating theatre , some of our findings can also be used in other settings where events are more important than timelines , where collaboration is important , where new interfaces are needed , or where an application needs to work with a network of other applications . Exploring other areas is another issue we would like to pursue . References 1 . Abowd , G . , Atkeson , C . , Brotherton , J . , Enqvist , T . , Gulley , P . , LeMon , J . : Investi - gating the Capture , Integration and Access Problem of Ubiquitous Computing in an Educational Setting . Proceedings of CHI ( 1998 ) 440 - 447 . 2 . Arnalonescu , W . , Neeley , L . , Winograd , T . : Where the Wild Things Work : Captur - ing Shared Physical Design Workspaces . Proceedings of CSCW ( 2004 ) 533 - 541 . 3 . Bass , L . , Clements , P . , Kazman , R . : Software Architecture in Practice . Addison - Wesley Professional , 2 . edition ( 2003 ) . 4 . Bederson , B . B . , Grosjean , J . , & Meyer , J . : Toolkit Design for Interactive Struc - tured Graphics . IEEE Transactions on Software Engineering , vol . 30 nr . 8 ( 2004 ) 535 - 546 . 5 . Chiu , P . , Kapuskar , A . , Reitmeier , S . , Wilcox , L . : NoteLook : Taking Notes in Meetings with Digital Video and Ink . Proceedings of ACM Multimedia ( 1999 ) 1 - 10 . 18 Thomas Riisgaard Hansen and Jakob E . Bardram 6 . Hayes , G . , Kientz , J . , Truong , K . , White , D . , Abowd , G . , Pering , T . : Designing Capture Applications to Support the Education of Children with Autism . Proceed - ings of UbiComp , LNCS 3205 ( 2004 ) 161 - 178 . 7 . Hayes , G . , Truong , K , Abowd , G . , Pering , T : Experience Buffers : A Socially Ap - propriate , Selective Archiving Tool for Evidence - Based Care . Proceeding of CHI , Extended Abstracts ( 2005 ) 1435 - 1438 . 8 . Heath , C . Lehn , D . , Hindmarsh , J . , Svensson , M . , Sanchez , Luff , P . : Configuring Awareness . Computer Supported Cooperative Work vol . 11 nr . 3 - 4 ( 2002 ) 317 – 347 . 9 . Kensing , F . and Madsen . K . H . : Generating Visions : Future Workshops and Meta - phorical Design . In J . Greenbaum and M . Kyng , editors , Design at Work : Coopera - tive Design of Computer Systems , Lawrence Erlbaum Associates , Hillsdale , NJ ( 1991 ) 155 – 168 . 10 . Mackay , W . E . , Ratzer , A . , Janecek , P . : Video Artifacts for design : bridging the Gap between abstraction and detail , Proceedings of the conference on Designing Interactive Systems DIS , ACM ( 2002 ) 72 - 82 . 11 . Minneman , S . , Harrison , S . , Janssen , B . , Moran , T . , Kurtenbach , G . , Smith , I . : A Confederation of Tools for Capturing and Accessing Collaborative Activity . Pro - ceedings of ACM Multimedia ( 1995 ) 1 - 21 . 12 . Pimentel , M . , Abowd , G . , Ishiguro , Y . : Linking by Interacting : a Paradigm for Authoring Hypertext . Proceedings of Hypertext ( 2000 ) 39 - 48 . 13 . Rekimoto , J . : Pick - and - Drop : A Direct Manipulation Technique for Multiple Computer Environments , Proceedings of UIST ( 1997 ) 31 - 39 . 14 . Richter , H . , Abowd , G . , Geyer , W . , Fuchs , L . , Daijavad , S . , Poltrock , S . : Integrat - ing Meeting Capture within a Collaborative Team Environment . Proceedings of UbiComp ( 2001 ) 123 - 138 . 15 . Streitz , N . , Geissler , J . , Haake , J . , Hol , J . : DOLPHIN : Integrated Meeting Support across LiveBoards , Local and Remote Desktop Environments . Proceedings of CSCW 1994 ( 1994 ) 345 - 358 . 16 . Truong , K . , Abowd , G . , Brotherton , J . , Who , What , When , Where , How : Design Issues of Capture and Access Applications , Proceedings of UbiComp , LNCS 2201 ( 2001 ) 209 - 224 . 17 . Truong , K . , Huang , E . , Abowd , G . , CAMP : A Magnetic Poetry Interface for End - User Programming of Capture Applications for the Home . Proceedings of Ubi - Comp , LNCS 3205 ( 2004 ) , 143 - 160 . 18 . Weiser , M . : The Computer for the 21st Century . Scientific America ( 1991 ) .