The Efficacy of Prototyping Under Time Constraints Steven P . Dow , Kate Heddleston , Scott R . Klemmer Stanford University HCI Group Department of Computer Science Stanford , CA 94305 [ spdow , heddle , srk ] @ stanford . edu ABSTRACT Iterative prototyping helps designers refine their ideas and discover previously unknown issues and opportunities . However , the time constraints of production schedules can discourage iteration in favor of realization . Is this tradeoff prudent ? This paper investigates if—under tight time constraints—iterating multiple times provides more benefit than a single iteration . A between - subjects study manipu - lates participants’ ability to iterate on a design task . Participants in the iteration condition outperformed those in the non - iteration condition . Participants with prior experi - ence with the task performed better . Notably , participants in the iteration condition without prior task experience performed as well as non - iterating participants with prior task experience . Author Keywords Prototyping , iteration , empirical studies of design ACM Classification Keywords H . 1 . m . [ Information Systems ] : Models and Principles General Terms Experimentation , Design INTRODUCTION Many designers evangelize the value of prototyping [ 3 , 7 , 8 , 9 , 31 , 37 , 50 ] , encapsulated in the design adage , “Enlightened trial and error outperforms the planning of flawless intellect . ” Prototyping entails repeatedly trying ideas and getting feedback [ 31 ] . A canonical prototyping iteration comprises four steps : envisioning possibilities , creating a prototype to embody a possibility , getting feedback about the prototype , and reevaluating constraints [ 29 ] . However , time constraints often lead organizations and individuals to focus on realization rather than iteration [ 3 , 50 ] . This paper investigates if , under tight time constraints , several rapid prototypes yield more valuable design insights than allocating that time to a single iteration . Twenty - eight participants were randomly assigned to one of two conditions for an individual design task . Participants in the iteration condition were encouraged to test and refine their design multiple times . Participants in the non - iteration condition spent all their design time on construction ; they were prevented from testing their design . After the design period , participants set aside all prototypes and entered a build period to implement their design . The design task for this experiment was an egg drop exercise where participants design a vessel from everyday materials to protect a raw egg from a fall . This task has several appealing properties : success is objectively measur - able ( drop height ) , participants need only minimal technical expertise , there are many possible valid solutions , and it can be completed in an hour - long session . Drop height was the primary dependent variable . Participants also estimated their vessel’s performance before and after the design period . We gathered participant demographics and con - cluded each session with a semi - structured interview . The iteration condition significantly outperformed the non - iteration condition : the iterating participants’ designs reached higher drop heights before breaking an egg . Self - assessment of performance increased significantly across the design period for individuals in the iteration condition . Unsurprisingly , participants with prior egg drop experience outperformed those without prior experience . More notably , non - experienced participants in the iteration condition did as well as experienced participants in the non - iteration condition . Prior to describing our experiment , we summarize the existing literature that sheds light on the function and value of iterative prototyping . Oscillating Between Creation and Feedback Prototypes can help define an idea’s role , implementation , and look and feel [ 26 ] ; they can build empathy for users [ 8 ] ; they communicate to clients , users , and fellow design - ers [ 56 ] . Designers embody creative hypotheses in proto - types and then observe the outcome [ 31 ] . An iterative prototyping practice oscillates between creation and feedback : creative hypotheses lead to prototypes , leading to open questions , leading to observations of failures , leading to new ideas , and so on . In the creation phase , designers ask the abductive question of “what might be” [ 43 , 44 ] . Much of previous design research has emphasized the importance of creative idea generation [ 6 , 34 , 45 , 47 , 55 ] . Research on brainstorming [ 6 , 45 , 47 , 51 ] , synthesis [ 34 ] , and framing [ 22 , 57 ] tech - Submitted to Creativity and Cognition 2009 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . C & C’09 , October 26 – 30 , 2009 , Berkeley , California , USA . Copyright 2009 ACM 978 - 1 - 60558 - 403 - 4 / 09 / 10 . . . $ 10 . 00 . 165 niques seeks to improve the abductive part of prototyping . Expertise literature suggests expert practitioners develop an organizational framework for retrieval and application of knowledge [ 17 ] ; expert designers learn to effectively organize and act on locally contextual design information . In the feedback phase , designers make inferences from observations [ 35 ] . Experimentation and feedback leads designers to discover unknown attributes , constraints , and opportunities that may not have been conceived of a priori . Discovery is not an automatic consequence of experimenta - tion ; the way people frame problems makes some insights salient and hides others [ 32 ] . Prototyping With Internal & External Representations Designers can use mental imagery to envision and improve ideas [ 2 , 18 , 19 , 20 ] . Christensen and Schun analyzed an engineering design setting where designers use mental simulation as a proxy for external prototyping , reducing “uncertainty language” within meetings [ 4 , 10 ] . Similarly , Schön remarked that an expert designer possesses the ability to conduct a series of “what - if” moves with “discov - ered consequences , implications , appreciations , and further moves” [ 48 ] . But as Schön points out , the web of moves can become too complicated to manage in one’s head— even for virtuosos—due to limitations in human memory and processing . People leverage the physical world to overcome limitations in memory capacity [ 5 , 46 ] , to convert highly cognitive tasks into perceptual / motor tasks [ 12 , 25 , 27 , 38 ] , to effec - tively represent problems [ 36 , 58 ] , and to explore alterna - tives [ 33 , 41 , 42 ] . Kirsh and Maglio’s study of the game Tetris found that players manipulated the pieces more than was pragmatically necessary for moving them to the right place . [ 33 , 42 ] . Kirsh and Maglio argue that these manipu - lations provide an epistemic technique for exploring alternatives . Prototypes are designer’s way of trying things out . Larkin and Simon [ 36 ] explored the representational differences between a diagram and a written description . They demonstrate two external representations may be informationally equivalent , but have significantly different computational efficiency . Designers’ choice of external representations in prototyping has significant influence on how they explore a design space [ 9 , 21 , 39 , 40 ] . Tversky and Suwa investigated how external representa - tions promote discovery and inference . They show that by attending to visual features in sketches , designers discover ideas that were unintended when they were drawn [ 52 , 53 ] . Prototypes similarly elicit information about the design context that did not previously exist in the designer’s head . Is Iterative Prototyping Undervalued ? Design is often heavily time - constrained ; this can discour - age designers from iterating . Many feel that organizations undervalue iteration [ 3 , 16 , 30 , 49 , 50 ] . Prototyping has an actual bottom - line cost associated with it , but this cost estimate is often inaccurate or changes over time [ 3 ] . Organizations often avoid prototyping because they believe the cost / investment will be significant and the return will be minimal . As Schrage suggests , “it is hard to persuade companies that one more iteration costs less than a flawed product , ” [ 50 ] . While researchers have devised economic models and performed cost - benefit analysis to argue for rapid iteration [ 16 , 30 ] , resource considerations remain a primary barrier to its application in industry . On the view of prototyping as a learning process , psycho - logical explanations of learning barriers can provide insight into why prototyping may happen too little in practice . Dweck has demonstrated that people’s belief in whether intelligence is mostly fixed or mostly shaped by practice has a significant impact on whether people seek out learning opportunities [ 14 ] . Dodgson and Wood have shown that with high self - esteem , people respond less negatively to failure and focus on strengths rather than weaknesses [ 13 ] . Earnest experimentation requires risk . The educational psychology literature can inform how to structure the environment so that designers fully engage the prototyping process [ 1 , 14 ] . METHOD The design task had two conditions : individuals encouraged to conduct iterative testing ( iteration ) and individuals prevented from conducting iterative testing ( non - iteration ) . We tested the following hypotheses :  Participants in the iteration condition will outperform the non - iteration group .  Participants in the iteration condition will report a larger increase in pre / post confidence levels ( perceived ability ) than the non - iteration condition .  Participants with prior exposure to the design task will outperform participants with no exposure .  Participants with prior general design experience will outperform participants with no design experience . Materials and Design Task In selecting the experimental task , we sought to achieve the following four criteria :  Presents a clear , objective measure of design quality  Requires minimal design or engineering expertise  Can be completed by individuals within one hour  Offers many paths to achieve an effective result . We chose the egg drop exercise , where participants design a vessel from everyday materials to protect a raw egg from a fall . Variations of the exercise are practiced in secondary and tertiary education classrooms around the United States . This study measures performance by dropping a single egg from a one - foot marker , then two , then three , and so on until the egg cracks . Task performance is measured by the highest height ( in feet ) at which the egg survives a fall . Pilot studies showed that our choice of materials should be diverse enough to elicit many approaches yet challenging enough to produce a wide range of performances . We selected the following design materials : 8 pipe cleaners , 8 rubber bands , 8 popsicle sticks , one 4 " × 8 " piece of poster board , one sheet of tissue paper , one 4 " × 6 " piece of flat 166 foam , and one foot of scotch tape ( Figure 1 ) . Participants worked on a table next to a drop zone area with foot markers written on the wall ( Figure 3 ) . All of the supplies were on the table , including build materials , scissors , eggs , and instructions . Figure 1 : Materials constraints in the design task : pipe cleaners , popsicle sticks , rubber bands , tissue paper , poster board , and flat foam . For their participation , subjects received either credit towards their course research participation requirement or a $ 20 Amazon gift card . As additional incentive , participants were told the two best performing vessels would receive additional Amazon gift cards . Participants Twenty - eight students averaging 21 . 1 years old and representing a wide range of majors from our university participated in the study . Participants were randomly assigned to one of two conditions . The study balanced for gender , prior egg drop experience , and general design experience across the two conditions . Twelve of the participants had prior experience with the egg drop exer - cise . Six had either worked as product designers or partici - pated in regular design activities . Procedure Participants filled out a consent form and demographics questionnaire . The experimenter verbally described the egg drop exercise and the specific rules for the assigned condition . All participants were told they would have 25 minutes to design . They were given a set of construction materials , and were told they could get replacement materials if necessary . After the design period , the re - searcher cleared the workspace and provided a fresh set of the original materials ( this time without replacements ) . Participants were given 15 minutes to build the final design , followed by a 10 - minute interview , and the egg drop test ( Figure 2 ) . Figure 2 : Experiment procedure with time markers for requesting tests in the iteration condition ( triangles ) and for requesting task performance estimates ( vertical bars ) . During the design period , participants in the control group ( no iteration ) were provided one egg , which was also used in the final egg drop . Individuals in the manipulation group ( iteration ) were given a full carton of eggs . We encouraged iteration participants to conduct a test drop at the five , ten , fifteen , and twenty - five - minute marks during the design phase . We did not limit participants to only four drops , nor did we strictly enforce all four drops The drop zone was adjacent to the design table so participants in the iteration group could test their design ideas at any point ( Figure 3 ) . Figure 3 : Experimental setup for the design exercise Participants were asked to estimate their perceived per - formance on the task ( in feet ) , both after hearing the instructions and right before the egg drop test . We con - ducted a short open - ended interview at the end of the build phase , asking participants to describe their concept and their biggest concern for how the egg might break . RESULTS This section describes the effect of iterative testing on task performance , the effect of iterative testing on task confi - dence , and the influence of prior task exposure on design performance . Vessels created in the iteration condition outperformed the non - iteration condition , with an average successful egg drop height of 6 . 1 feet compared to an average of 3 . 3 feet ( t = 2 . 38 , p < 0 . 03 ) ( Figure 4 ) . 167 Figure 4 : Individuals in the iteration condition significantly outperformed the non - iteration condition in the egg drop mechanical design task . Participants’ confidence level in the iteration condition rose from an average of 4 . 14 to 5 . 93 feet from before to after the design task ( t = 2 . 21 , p < 0 . 05 ) . The non - iteration condition saw no significant change in perceived ability , averaging 3 . 1 for both pre and post design task ( Figure 5 ) . The pre - measure of performance slightly favors the iteration condition , although the mean self - estimates are not signifi - cantly different ( t = 1 . 92 , p = 0 . 23 ) . Figure 5 : Individuals’ self estimate of performance ( measured in feet ) —shows a significant rise between pre - and post - task estimate , but only in the iteration condition . Participants in both conditions estimated their performance fairly accurately . On average , iterators estimated 5 . 9 feet , just underestimating their actual score of 6 . 1 feet , and non - iterators estimated 3 . 1 feet , just underestimating their actual score of 3 . 3 feet . Influence of prior exposure to design task Twelve of the twenty - eight participants reported previously taking part in the egg drop exercise . Prior egg droppers outperformed those without experience , 6 . 3 feet compared to 3 . 5 feet ( t = 1 . 98 , p < 0 . 04 ) ( Figure 6 ) . Figure 6 : Individuals with prior exposure to the egg drop task significantly outperformed those who had not done this exercise before . Both experienced and inexperienced participants in the iteration condition outperformed their counterparts in the non - iteration condition ( Figure 7 ) . A two - way repeated measures analysis of variance ( ANOVA ) was performed , with Iteration ( iteration / non - iteration ) and Prior Experience ( prior / no - prior ) as factors and egg drop height as dependent variable . Participants with prior egg drop exposure in the iteration condition performed the best , with an average successful drop height of 8 . 7 feet compared to 3 . 8 feet for prior egg droppers in the non - iteration condition ( F ( 1 , 26 ) = 6 . 84 , p = 0 . 015 ) . Similarly for participants with no prior egg drop exposure , the iterative testing condition outperformed the non - iteration condition , 4 . 3 feet com - pared to 2 . 8 feet ( F ( 1 , 26 ) = 5 . 93 , p = 0 . 023 ) . The Iteration x Prior Experience interaction was nearly significant ( F ( 1 , 26 ) = 2 . 45 , p = 0 . 130 ) . Iteration helped participants with no prior egg drop experience perform at the same level as non - iterators with prior egg drop exposure . Figure 7 : Breakdown of participants with or without prior egg drop exposure and those in the iteration or non - iteration condition ( chart and table numbers in feet ) . 168 Influence of design experience on task performance Six of the twenty - eight participants had prior professional product design experience or participated in regular design activities . Prior design experience had no significant effect on the outcome of design task performance ( t = 1 . 84 , p < 0 . 17 ) . With only six qualifying participants , the sample size is not large enough to fully explore the effects of prior design experience . PARTICIPANT CREATIONS Participants explored a wide variety of creative design concepts including parachutes , damping stilts , tubes , boxes , suspension systems , and nests for catching the egg raw ( Figure 8 ) . The top three performers—15 , 13 , 10 feet— came from the iteration condition ( top of left column ) . Based on these participant creations , we conducted an analysis of the design space [ 15 ] and determined five key design dimensions : the amount of drag created in the air , the distance between the egg and the first point of impact , the damping upon impact , the balance of weight before and after impact , and the containment of the egg . While this analysis of the design space is informal , it sheds light on relevant design factors . The interviews provide further insight on how participants discovered important variables , and typically focused only just one or two of these factors . Iteration Condition Non - iteration Condition Figure 8 : Twenty - eight participant creations ordered according to best performers ( from top left down ) and separated by study condition ( iteration in left two columns ; non - iteration in right two columns ) INTERVIEWS The interviews revealed how participants employed different prototyping strategies , learned from iteration , and used mental simulation . Prototyping strategies Some participants employed their understanding of physics to build a vessel designed to absorb impact . For P22’s vessel ( see left ) , he coiled “the foam ( into ) a spring to absorb the shock . ” P24 said she included a “stabilizing layer” for “bigger surface area” and so “the force was a little more dispersed . ” As P3 explained “the part that hit the ground had the most impact , so I didn’t want that part to be the egg . ” Her design , a self - described “spiky creation , ” included damping stilts protruding in many directions . According to another participant , P18 , the key was to provide a “buffer , ” so the “impact point doesn’t hit the egg directly . ” Other participants approached the egg design task as bricoleurs . As P23 described , “I started with a poster board box and then lined it with the foam box , and then I tore up little pieces of foam ‘cause I had extra . And then , ‘cause I had ‘em I threw in the pipe cleaners around the top of the egg . On the bottom there are sticks , partly because I had ‘em , but also it makes it more likely to land on the bottom . ” P25 ( see right ) simply wrapped the egg with as many layers of materials as possible . This approach of mashing together materials echoes the opportunistic design practices reported by Hartmann et al . [ 23 ] . Other participants drew inspiration from objects outside of the immediate design context . P11 said , “My design is a Turkish cone . This is the same thing they use to sell chestnuts… When I drop chestnuts usually they would not crack , although [ chestnuts ] are much harder” than eggs ( see right ) . In a similar vein , P21 related the design task to protecting passengers in vehicles . Both participants thought of analogous situations for protecting precious objects . Many participants used the materials and gestures to communicate about the features of their vessel . P20 said “I designed an outer boundary [ hands around the prototype ] , using the [ looks up at reference sheet ] pipe cleaners… and I designed an inner boundary using the [ look up at sheet ] sticks . ” P22 ( iteration ) : 13 ft P11 ( iteration ) : 5 ft P25 ( no - iterat . ) : 7 ft 169 Learning from iteration Most participants in the iteration condition made a con - certed effort to learn and improve their designs with each iterative test . As P3 stated , “experimentation with materials is important , especially at the beginning , so you figure everything possible you can do with them . It is also really important to see what actually happens when it hits , ‘cause with my first design I didn’t realize it would hit so hard . ” Her main design insight was to have damping sticks protruding at different angles ( see right ) . P9 learned the vessels do not fall evenly : “What I didn’t account for is , as it gets to higher heights , this will not drop straight down . ” P18 recognized a different problem with her design . “The main problem with the last design is that it wasn’t covering the egg enough , so I was afraid it was going to fall out” ( see left ) . The iterative process helped participants identify issues such as creating drag , balancing the weight , managing the landing , and containing the egg . Iterative testing does not always reveal the source of failure . P28’s first vessel braced the egg with a square wooden structure . It broke at 1 foot . Then he added a platform underneath and parachute , while he kept the wooden frame ( see right ) . Although , his design continued to fail from low heights , P28 never inferred a key problem : the wooden frame can easily jab into the egg , cracking it with very little force . However in the final interview he did say “I was thinking that I could use—for the holding bay— instead of the wood , I could actually use the pipe cleaners since they are a little bit softer . ” Using mental simulation The interview right before the final egg drop asked partici - pants to envision how their concepts performed . P12 commented and gestured using his design , “When it falls , it’s probably going to fall one way or another . Once it starts getting dropped from higher , it’s going to bounce and flip maybe [ shows how the vessel might flip over ] . ” P14 projected his design would “land kinda crooked sideways . ” P27 was concerned her design would impact the floor on its side ( Figure 9 ) . She also correctly observed that the parachute should keep her design from falling on its side . Effects of manipulating iteration In the iteration condition , many participants expressed frustration with having to drop so early and often . At one point during the task P16 says to himself : “What is sturdy enough to support an egg drop ? ” Then he sighs , takes a deep breath , and sits back in his chair looking frustrated . He felt pressured to come up with something under the tight time constraint . In the interview he said , “I thought five minutes was too soon to really have anything substantial” ( see right ) . While the tight iteration cycles were stressful , his vessel scored 6 feet—average for the iteration condition and significantly better than the average non - iteration score . Other participants embraced the opportunity for iteration and really stress - tested their vessels , such as P22 who stood on the table to test his design . In the non - iteration condition , participants were often ready to test their idea before the end of time period , as P15 said , “so if I’m done can I start ? ” Similarly , with 10 minutes left in the design period P25 declares , “Alright , I’m finished . ” It was not clear ( at least to us ) a priori that the multiple - iteration condition would be so much more engaging for participants than the single - iteration condition . Iteration did not lead to divergence While participants in the iteration condition were allowed to test multiple egg drops , they did not necessarily explore a variety of concepts . As P16 described , “I’m not a very good outside - the - box thinker , so I kinda just had one idea and I was going to try to make it work . ” P27 , who had the best overall design , expressed a similar notion : “I went with the whole parachute idea…from the beginning . So , I had one core idea . ” Generally participants selected an initial design direction and iterated to improve on that idea . More unexpectedly , some participants claimed that their chosen design seemed like the only possibility . P21 said , “For some reason this seems to be the only idea . There needs to be a platform and then as good of cushion as P3 ( iteration ) : 5 ft P28 ( iteration ) : 1 ft Figure 9 : Participant using her vessel to illustrate possible failure scenarios . P16 ( iteration ) : 6 ft P18 ( iteration ) : 2 ft 170 possible . I don’t see any other way” ( see right ) . Likewise P20 asserted , “This is the best approach for such a design . ” Despite oft - mediocre preliminary tests and a wide range of possibilities available , many participants appeared fixated on their initial design concept . Factors that prevented divergence The short time period impacted why participants did not diverge . As P18 stated , “This is what I thought of first [ holding his design ] , and I started thinking , ‘well that’s one idea what else can I do ? ’ Then I said , ‘nah , I better make this to make sure I will have time . ’” P24 discussed the notion of changing to a new idea , “With time and with trials , I was sort of improving upon the first idea I had and not trying to scrap it and go on to a whole new idea . ” Participants may not have felt they had time to brainstorm different ideas , and once they got started , they found it difficult to justify changing to a new idea . While many participants described how they had “one idea and just went with it” ( P6 ) , some participants indicated ideation occurred before prototyping . P27 talked about constructing “some sort of box with the sticks and involv - ing rubber bands so the egg is in the middle . ” P24 said , “I think if I had more time I probably would have been more accurate , maybe even do some calculations . ” Participants may have considered ideas that were not pursued due to lack of time and perceived complexity . P4 commented : “There were a lot of different ideas I had originally… possibly even using the tissue paper like a parachute . ” Participants’ underlying assumptions affected their funda - mental design choices . P15 , like others in the experiment , assumed the egg had to drop by itself into a nest : “I just figured I was supposed to build a vessel to catch the egg on its own” ( see right ) . P11’s sense of personal pride in his “Turkish cone” perhaps dissuaded his willingness to pursue other concepts between iterations : “An [ alternate ] design may have been better… but I am proud of mine . ” ( P11 ) DISCUSSION Participants entered the final fifteen - minute build period armed only with what they learned during the design period . Why did participants in the iteration condition outperform non - iterators ? One interpretation says that participants in the iteration condition discovered more flaws and constraints , and tried more new concepts . Non - iterating participants could only speculate how their design would perform . Another interpretation says participants in the iteration condition became better carpenters ; they often built the same construction multiple times and thus they tuned the craft . These interpretations are not mutually exclusive , as experimenting and discovering constraints are part of craftwork . Why did participants in the iteration condition significantly increase their estimated performance on the design task ? Unlike the non - iteration condition , the iterating participants received multiple benchmarks . Each iterative test contrib - uted to their judgment of performance . Participants in the non - iteration condition also managed to correctly estimate their low performances , so it remains inconclusive whether the feedback alone leads to better self - estimates . Surpris - ingly , the non - iteration condition saw no rise in perceived performance despite working on the task for forty minutes . Why did iterating participants with prior experience far outperform all others ? Prior exposure to the egg drop exercise gave participants a head start in forming initial design concepts , but why did they make stronger gains with feedback than preliminary ideas from newbies ? One argument says that prior experience gives people an index of examples ( or cases ) and feedback merely aids people to sort through the good and bad ideas . Another argument says prior experience is not only about knowing examples ; it’s about knowing how to perceive and analyze feedback on proposed solutions . This finding suggests the possibility for scaffolding design expertise with domain - specific examples , along with various feedback perspectives . Future authoring tools , for example , could include domain - specific design exemplars , each with a host of expert feedback . What factors influence the use of rapid iteration ? We found some participants expressed anxiety from having to iterate too early and too frequently . The iteration condition demanded proficiency and imprecision . On the other hand , several of the non - iterating participants were unsatisfied because they could not immediately see how their design performed . Participants may favor longer iterations over short and early iterations to avoid duress ; this emotional factor may affect design outcome . Iterative prototyping does not necessarily lead to an exhaustive exploration of alternatives . Participants in both conditions of the study explored a narrow range of possi - bilities in the design space . The short time frame and uncertainty about more complex constructions influenced participants . Unlike many real - world design processes , the design period did not include structured time for divergent thinking . More interestingly , several of the participants talked about how they believed their idea to be the only possibility . Design research explains people often fixate on concepts , especially if they have invested energy and time into one path [ 11 , 28 ] . External validity is a concern for any lab study . While most real world design ventures are often social in nature , we focused on individual designers in this preliminary study to avoid the potential confounds of groupthink and interper - sonal relationships . Likewise , design problems are typically solved over the course of days or months . To control for external stimuli , we chose a time frame that only required a P21 ( iteration ) : 7 ft P15 ( no - iterat . ) : 2 ft 171 single uninterrupted session . Our choice of a design task placed value on having an objectively measurable outcome . In the real world , the problem space or “design brief” is often not set in stone ; it gets defined along the way . That said , the egg drop design exercise might be in some respects representative of design tasks that do have clear goals ( e . g . , designing a bridge always has a clear objective : to insure that cargo and people can cross safely ) . As a whole , participants demonstrated a range of creative solutions to the egg drop problem . Just as in real design settings , the outcomes cannot be defined by suc - cess / failure / right / wrong , but by what concept best fits the current design context . FUTURE WORK Questions remain about how designers perceive the efficacy of prototyping . Do designers undervalue rapid iteration ? Within a given timeframe , how do designers determine an iteration strategy ? How do designers decide the frequency and temporal spacing of iterations ? Do designers typically plan iterations or do they unfold organically ? The literature on organizational research can help us hypothesize about the interaction between plans and situated prototyping practices [ 3 , 24 , 50 , 56 ] . We hypothesize for example that planning for lots of rough iterations will achieve better results than planning fewer meticulous iterations . Does the particular formation of iteration affect how designers explore concepts in a design space ? Do designers benefit when explicit juxtaposition and reflection are built into iteration ? The study indicated that iteration did not necessarily lead to more divergence ; participants sought incremental improvements to their concept . We hypothe - size exploratory techniques—such as performing analogy training [ 54 ] and creating parallel prototypes—can lead to more divergence between iterations and enable more explicit comparisons when processing feedback . Do the benefits of iteration pertain to groups ? While we know group brainstorming leads to unique ideas and serves organizational functions [ 47 , 51 ] , the advantages of team prototyping are less understood . What strategies emerge ? Do participants prototype different ideas and later combine them ? Do participants work together to understand the feedback ? We hypothesize an interaction effect between groups and the presence of feedback ; groups will get farther with iterative feedback than individuals because of their ability to collaboratively perceive and interpret feedback on prototypes . Does iterative prototyping positively affect designer self - efficacy towards a design task ? Do the “small wins” of iterative prototyping lead to greater confidence as the design process proceeds ? Further , if iteration does have a positive effect on self - confidence ( and potentially team confidence ) , how do these emotional wins contribute to the overall outcome ? We hypothesize prototyping practices can have positive effects on individual emotions and team dynamics . In the face of motivational barriers , what methods encour - age the best practices for iteration ? For example , if we believe anxiety hinders rapid iteration , we can test the relative merits of anxiety management and team building techniques . If we find participants make false assumptions about prototyping’s return on investment , we can investi - gate how to structure the economic environment to encour - age best practices . CONCLUSIONS This paper investigated whether iterative prototyping outperforms a single iteration on a simple design task within a fixed time period . The results show that rapid iterators not only outperformed non - iterators , their self estimate of task performance significantly increased from before the design period to just before the task performance test . Participants with prior exposure to the design task outperformed those without prior experience . More notably , non - experienced participants in the iteration condition did as well as experienced participants in the non - iteration condition . This work suggests rapid iteration yields more valuable design insights than allocating that time to a single iteration . ACKNOWLEDGEMENTS We thank Björn Hartmann , Jeff Heer , Daniel Schwartz , Barbara Tversky , and Terry Winograd for helpful com - ments on early versions of this paper . REFERENCES 1 . Aronson , J . M . Improving academic achievement . Academic Press , 2002 . 2 . Athavankar , U . A . Mental Imagery as a Design Tool . Cybernetics and Systems 28 , 1 ( 1997 ) , 25 - 42 . 3 . Austin , R . and Devin , L . Artful Making : What Manag - ers Need to Know About How Artists Work . Financial Times Press , 2003 . 4 . Ball , L . J . and Christensen , B . T . Analogical reasoning and mental simulation in design : two strategies linked to uncertainty resolution . Design Studies 30 , 2 ( 2009 ) , 169 - 186 . 5 . Bilda , Z . and Gero , J . S . The impact of working memory limitations on the design process during con - ceptualization . Design Studies 28 , 4 ( 2007 ) , 343 - 367 . 6 . de Bono , E . Six Thinking Hats . Back Bay Books , 1999 . 7 . Brown , T . Change By Design . HarperCollins , 2009 . 8 . Buchenau , M . and Suri , J . F . Experience prototyping . Proceedings of the 3rd conference on Designing inter - active systems : processes , practices , methods , and techniques , ACM ( 2000 ) , 424 - 433 . 9 . Buxton , B . Sketching User Experiences : Getting the Design Right and the Right Design . Morgan Kauf - mann , 2007 . 10 . Christensen , B . T . and Schunn , C . D . The role and impact of mental simulation in design . Applied Cogni - tive Psychology 23 , 3 ( 2009 ) , 327 - 344 . 172 11 . Cross , N . Designerly Ways of Knowing . Springer , 2006 . 12 . De Leon , D . Building Thought Into Things . European Conference on Cognitive Science , ( 1999 ) , 37 - 47 . 13 . Dodgson , P . and Wood , J . Self - esteem and the cogni - tive accessibility of strengths and weaknesses after failure . Journal of Personality and Social Psychology 75 , 1 ( 1998 ) , 178 - 197 . 14 . Dweck , C . Mindset : The New Psychology of Success . Ballantine Books , 2007 . 15 . Dym , C . L . and Little , P . Engineering Design : A Project - Based Introduction . Wiley , 1999 . 16 . Erdogmus , H . The Economic Impact of Learning and Flexibility on Process Decisions . IEEE Softw . 22 , 6 ( 2005 ) , 76 - 83 . 17 . Ericsson , K . A . , Charness , N . , Feltovich , P . J . , and Hoffman , R . R . The Cambridge Handbook of Expertise and Expert Performance . Cambridge University Press , 2006 . 18 . Finke , R . A . and Slayton , K . Explorations of creative visual synthesis in mental imagery . Memory & Cogni - tion 16 , 3 ( 1988 ) , 252 - 7 . 19 . Finke , R . A . Creative Imagery . Lawrence Erlbaum Associates , 1990 . 20 . Gentner , D . and Stevens , A . L . Mental models . 1983 . 21 . Gero , J . S . and Schnier , T . Evolving Representations Of Design Cases And Their Use In Creative Design . in J . S . Gero , M . L . Maher and F . Sudweeks ( eds ) , Pre - prints Computational Models of Creative Design ( 1995 ) , 343 - 368 . 22 . Goffman , E . Frame Analysis : An Essay on the Organi - zation of Experience . Northeastern , 1986 . 23 . Hartmann , B . , Doorley , S . , and Klemmer , S . Hacking , Mashing , Gluing : A Study of Opportunistic Design and Development . Pervasive Computing 7 , 3 ( 2006 ) , 46 - 54 . 24 . Hinds , P . The Curse of Expertise : The Effects of Expertise and Debiasing Methods on Predictions of Novice Performance . Journal of Experimental Applied Psychology 5 , ( 1999 ) , 205 - 221 . 25 . Hollan , J . , Hutchins , E . , and Kirsh , D . Distributed Cognition : Toward a New Foundation for Human - Computer Interaction Research . ACM Transactions on Computer - Human Interaction 7 , 2 ( 2000 ) , 174 - 196 . 26 . Houde , S . and Hill , C . What Do Prototypes Prototype ? Handbook of Human - Computer Interaction , ( 1997 ) . 27 . Hutchins , E . Cognition in the Wild . The MIT Press , 1996 . 28 . Jansson , D . and Smith , S . Design Fixation . Design Studies 12 , 1 ( 1991 ) , 3 - 11 . 29 . John Paul Jones . Design Methods . Wiley , 1992 . 30 . Karat , C . Cost - Benefit Analysis of Usability Engineer - ing Techniques . Human Factors Society , ( 1990 ) , 839 - 843 . 31 . Kelley , T . The Art of Innovation . Profile Business , 2002 . 32 . Kershaw , T . C . and Ohlsson , S . Multiple causes of difficulty in insight : the case of the nine - dot problem . Journal of Experimental Psychology . Learning , Mem - ory , and Cognition 30 , 1 ( 2004 ) , 3 - 13 . 33 . Kirsh , D . and Maglio , P . On Distinguishing Epistemic from Pragmatic Action . Cognitive Science 18 , ( 1994 ) , 513 - - 549 . 34 . Kolko , J . Thoughts on Interaction Design . Brown Bear LLC , 2007 . 35 . Kolodner , J . L . and Wills , L . M . Powers of observation in creative design . Design Studies 17 , 4 ( 1996 ) , 385 - 416 . 36 . Larkin , J . and Simon , H . Why a Diagram is ( Some - times ) Worth Ten Thousand Words . Cognitive Science 11 , 1 ( 1987 ) , 65 - 100 . 37 . Laurel , B . Design Research : Methods and Perspec - tives . The MIT Press , 2003 . 38 . Lave , J . Cognition in practice . Cambridge University Press , 1988 . 39 . Lim , Y . , Stolterman , E . , and Tenenberg , J . The anatomy of prototypes : Prototypes as filters , proto - types as manifestations of design ideas . ACM Transac - tions on Computer - Human Interaction 15 , 2 ( 2008 ) , 1 - 27 . 40 . Lim , Y . , Pangam , A . , Periyasami , S . , and Aneja , S . Comparative analysis of high - and low - fidelity proto - types for more valid usability evaluations of mobile devices . Proceedings of the 4th Nordic conference on Human - computer interaction : changing roles , ACM ( 2006 ) , 291 - 300 . 41 . Maglio , P . , Matlock , T . , Raphaely , D . , Chernicky , B . , and Kirsh , D . Interactive Skill in Scrabble . Lawrence Erlbaum ( 1999 ) . 42 . Maglio , P . P . and Kirsh , D . Epistemic Action Increases With Skill . In Proceedings of the Eighteenth Annual Conference of the Cognitive Science Society 16 , ( 1996 ) , 391 - 396 . 43 . Martin , R . L . Creativity That Goes Deep . Business Week , 2005 . http : / / www . businessweek . com / innovate / content / aug2005 / di20050803 _ 823317 . htm . 44 . Merholz , P . , Wilkens , T . , Schauer , B . , and Verba , D . Subject To Change : Creating Great Products & Serv - ices for an Uncertain World : Adaptive Path on De - sign . O ' Reilly Media , Inc . , 2008 . 45 . Michalko , M . Thinkertoys : A Handbook of Creative - Thinking Techniques . Ten Speed Press , 2006 . 46 . Miller , G . A . The magical number seven , plus or minus 173 two : some limits on our capacity for processing infor - mation . Psychological Review 63 , 2 ( 1956 ) , 81 - 97 . 47 . Osborn , A . F . Applied Imagination : Principles and Procedures of Creative Problem Solving . Charles Scribner ' s Sons , 1963 . 48 . Schon , D . A . The Reflective Practitioner : How Profes - sionals Think in Action . Ashgate Publishing , 1995 . 49 . Schrage , M . Cultures of prototyping . In Bringing design to software book contents . 1996 , 191 - 213 . 50 . Schrage , M . Serious Play : How the World ' s Best Companies Simulate to Innovate . Harvard Business School Press , 1999 . 51 . Sutton , R . and Hargadon , A . Brainstorming groups in context : effectiveness in a product design firm . Admin - istrative Science Quarterly , ( 1996 ) . 52 . Suwa , M . , Gero , J . , and Purcell , T . Unexpected discoveries and S - invention of design requirements : Important vehicles for a design process . Design Stud - ies 21 , ( 2000 ) , 539 - 567 . 53 . Suwa , M . and Tversky , B . External Representations Contribute to the Dynamic Construction of Ideas . Pro - ceedings of the Second International Conference on Diagrammatic Representation and Inference , Springer - Verlag ( 2002 ) , 341 - 343 . 54 . Thompson , L . , Gentner , D . , and Loewenstein , J . Avoiding Missed Opportunities in Managerial Life : Analogical Training More Powerful Than Individual Case Training . Organizational Behavior and Human Decision Processes 82 , 1 ( 2000 ) , 60 - 75 . 55 . Torrance , E . P . Torrance tests of creative thinking . Personnel Press , Ginn and Co . , Xerox Education Co , 1974 . 56 . Warr , A . and O ' Neill , E . Understanding design as a social creative process . Proceedings of the 5th confer - ence on Creativity & Cognition , ACM ( 2005 ) , 118 - 127 . 57 . Ylirisku , S . , Halttunen , V . , Nuojua , J . , and Juustila , A . Framing design in the third paradigm . Proceedings of the 27th international conference on Human factors in computing systems , ACM ( 2009 ) , 1131 - 1140 . 58 . Zhang , J . and Norman , D . Representations in distrib - uted cognitive tasks . Cognitive Science 18 , 1 ( 1994 ) , 87 - 122 . 174