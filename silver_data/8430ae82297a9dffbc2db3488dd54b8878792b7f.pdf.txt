ISSN 2383 - 630X ( Print ) / ISSN 2383 - 6296 ( Online ) Journal of KIISE , Vol . 44 , No . 12 , pp . 1275 - 1281 , 2017 . 12 https : / / doi . org / 10 . 5626 / JOK . 2017 . 44 . 12 . 1275 ․ 이 논문은 2017 년도 정부 ( 미래창조과학부 ) 의 재원으로 정보통신기술진흥센 터의 지원을 받아 수행된 연구임 . ( R0124 - 16 - 0002 , 상대방의 감정을 추론 , 판단하여 그에 맞추어 대화하고 대응할 수 있는 감성지능 기술 연구개발 ) ․ 이 논문은 2017 한국컴퓨터종합학술대회에서 ‘ 가짜문장의 전이학습을 이용한 소규모 불균형 데이터의 욕설문장 분류방법 ’ 의 제목으로 발표된 논문을 확장 한 것임 논문접수 : 2017 년 8 월 8 일 ( Received 8 August 2017 ) 논문수정 : 2017 년 10 월 9 일 ( Revised 9 October 2017 ) 심사완료 : 2017 년 10 월 11 일 ( Accepted 11 October 2017 ) † †† 학생회원 종신회원 : : 연세대학교 컴퓨터과학과 tndls9304 @ yonsei . ac . kr 연세대학교 컴퓨터과학과 교수 ( Yonsei Univ . ) sbcho @ yonsei . ac . kr ( Corresponding author 임 ) Copyright Ⓒ 2017 한국정보과학회 ː 개인 목적이나 교육 목적인 경우 , 이 저작물 의 전체 또는 일부에 대한 복사본 혹은 디지털 사본의 제작을 허가합니다 . 이 때 , 사본은 상업적 수단으로 사용할 수 없으며 첫 페이지에 본 문구와 출처를 반드시 명시해야 합니다 . 이 외의 목적으로 복제 , 배포 , 출판 , 전송 등 모든 유형의 사용행위 를 하는 경우에 대하여는 사전에 허가를 얻고 비용을 지불해야 합니다 . 정보과학회논문지 제 44 권 제 12 호 ( 2017 . 12 ) 욕설문장 분류의 불균형 데이터 해결을 위한 전이학습 방법 ( A Transfer Learning Method for Solving Imbalance Data of Abusive Sentence Classification ) 서 수 인 † 조 성 배 †† ( Suin Seo ) ( Sung - Bae Cho ) 요 약 욕설문장을 지도학습 접근법으로 분류하기 위해서 욕설인지 아닌지 판별된 학습 문장이 필요 하다 . 문자수준의 컨볼루션 신경망이 각 문자에 대해 강건성을 가지기 때문에 욕설분류에 적합하지만 , 학 습에 많은 데이터가 필요하다는 단점이 있다 . 본 논문에서는 이를 해결하기 위해 임의로 생성한 욕설 / 비욕 설 문장 쌍을 컨볼루션 신경망을 기반으로 하는 분류기에 학습시켜 컨볼루션 신경망의 필터가 욕설의 특 징을 분류하도록 조정한 후 , 실제 훈련문장을 학습시킬 때 필터를 재사용하는 전이학습방법을 제안한다 . 이로써 데이터 부족과 클래스 불균형으로 인한 영향이 감소하여 분류 성능이 향상될 것이다 . 실험 및 평 가는 총 3 가지 데이터에 대해 수행되었으며 , 문자수준 컨볼루션 신경망을 활용한 분류기는 모든 데이터에 서 전이학습을 적용했을 때 더 높은 F1 점수를 획득하였다 . 키워드 : 자연어 분류 , 클래스 불균형 문제 , 전이학습 , 문자수준 컨볼루션 신경망 Abstract The supervised learning approach is suitable for classification of insulting sentences , but pre - decided training sentences are necessary . Since a Character - level Convolution Neural Network is robust for each character , so is appropriate for classifying abusive sentences , however , has a drawback that demanding a lot of training sentences . In this paper , we propose transfer learning method that reusing the trained filters in the real classification process after the filters get the characteristics of offensive words by generated abusive / normal pair of sentences . We got higher performances of the classifier by decreasing the effects of data shortage and class imbalance . We executed experiments and evaluations for three datasets and got higher F1 - score of character - level CNN classifier when applying transfer learning in all datasets . Keywords : natural language classification , class imbalance problem , transfer learning , character - level convolution neural network 1276 정보과학회논문지 제 44 권 제 12 호 ( 2017 . 12 ) 1 . 서 론 욕설분류는 스팸필터링처럼 자연어 분류의 대표적인 문제로 , 고전적인 텍스트 처리만으로 해결할 수 있었다 . 그러나 소셜 네트워크 서비스 ( SNS ) 가 널리 퍼짐과 함 께 인터넷 상에 텍스트 데이터의 양이 폭발적으로 증가 함에 따라 , 욕설의 양도 함께 증가했다 [ 1 ] . 또한 욕설이 특정 계층에게 집중되거나 신조어가 생기는 등 욕설의 종류와 표현방법이 다양해지면서 , 욕설분류 문제는 더 이상 간단한 방법으로 해결되지 않게 되었다 [ 2 ] . 또한 입력된 문장이 욕설을 포함하고 있는지에 대해 훈련되지 않은 분류기가 자동으로 감지할 수 있는 방법 은 없다 . 따라서 문장과 그 문장에 대한 욕설여부를 같이 학습시키는 지도학습의 접근법으로 분류기를 훈련시키는 것이 당연시되었다 [ 3 ] . 그러나 분류기의 학습을 위해 인 간이 제공할 수 있는 학습 데이터의 양에는 한계가 있고 , 욕설을 포함하고 있는 문장은 전체 문장에 비해 그 수가 적어 클래스 불균형이 나타난다는 문제가 있다 . 이를 해 결하기 위해서는 욕설문장과 비욕설문장이 균형을 이루 면서 많은 문장을 포함하고 있는 데이터가 필요하다 . 본 논문에서는 이를 해결하기 위해 임의의 문장을 생 성하고 이를 분류기에 미리 학습시킴으로써 클래스 불 균형의 영향을 감소시켜 다양한 형태의 욕설을 분류할 수 있는 방법을 제안한다 . 문자수준의 컨볼루션 신경망 은 문자의 원 - 핫 인코딩 ( one - hot encoding ) 을 입력으로 사용하는 컨볼루션 신경망이다 . 이미 이 방법이 텍스트 분류문제에서 유용하다고 알려졌지만 , 특히 단어를 구성 하는 문자 사이의 관계를 벡터로 나타내기 때문에 변환 된 욕설단어와 원래 단어 사이의 관계를 효과적으로 표 현할 수 있다 . 하지만 Zhang 등에 따르면 , 이 방법은 데이터가 많은 경우에 한하여 유효한 성능을 낼 수 있다 [ 3 ] . 이는 적은 학습 데이터만으로는 문장의 특성을 학습하기 어렵고 학습 문장의 수에 제한이 있는 욕설분류 문제에도 적용 될 것이다 . 문자수준 컨볼루션 신경망이 욕설의 특징 추출에 적 합함에도 불구하고 특징 학습을 위해서는 적지 않은 라 벨링된 문장들이 필요하다 . 따라서 욕설의 특징을 학습 할 수 있는 임의의 문장을 생성하여 분류기를 학습시키 면 분류 성능을 높이고 클래스 불균형 문제도 해결할 수 있다 . 2 . 관련연구 욕설분류는 욕설의 특징추출과 추출된 특징으로부터 분류하는 두 과정으로 이루어져 있다 . 문장의 특징추출 에는 주로 Bag - of - Word ( BoW ) 나 n - gram 의 BoW 가 사용된다 [ 4 ] . BoW 는 욕설분류에서 상당히 높은 성능을 얻을 수 있는 특징추출 방법이지만 SNS 와 같은 인터넷 상의 다양하고 많은 양의 텍스트를 처리하는데 적합하 지 않다 [ 5 ] . TF - IDF 는 텍스트의 특징을 추출하는 방법 중 하나 로 문장 분류에 주로 사용된다 [ 6 ] . 하지만 이전 연구들 에 따르면 단일 TF - IDF 는 욕설분류를 위한 텍스트의 특징추출에서 다른 알고리즘보다 상대적으로 낮은 성능 을 나타냈다 [ 7 , 8 ] . 사전이나 문장의 주제를 활용하여 분류 성능을 높이는 방법도 연구되고 있다 [ 9 , 10 ] . 텍스트 자체의 특징인 BoW 나 TF - IDF 와 같이 특징추출에 사용함으로써 단일 알고 리즘보다 높은 성능을 얻을 수 있다 . 하지만 방대한 사전 지식이나 문장에 대한 추가적인 정보 ( 주제 ) 가 요구되며 신조어나 새로운 주제에 적용할 수 없는 단점이 있다 . 최근에 텍스트로부터 특징을 추출하여 사용하는 방법 의 하나로 문단벡터 [ 11 ] 를 사용하여 욕설분류를 시도하 기도 했다 . 기존 방법인 BoW 와 비교했을 때 , 희소 벡 터를 생성하지 않기 때문에 처리속도는 빨라졌으나 분 류 성능은 큰 차이를 보이지 않았다 [ 8 ] . 최근에 문장의 언어학적 , 의미적 정보나 , Word2Vec [ 12 ] 등 여러 가지 알고리즘으로 추출된 텍스트의 모든 특징을 합성하여 사용하는 방법이 시도되고 있다 . 분류방법으로는 주로 서포트 벡터 머신과 나이브 베 이즈가 사용된다 [ 2 , 4 ] . 이 방법들은 BoW 나 TF - IDF 같 은 고전적인 특징추출방법과 함께 사용되었다 . 최근에 심층 신경망 ( DNN ) 방법이 발전하면서 텍스트 분류에 컨볼루션 신경망 ( CNN ) 이나 LSTM 이 사용되고 있다 . 문자수준의 CNN [ 3 ] 이나 단어수준의 CNN [ 13 ] 을 활용하 거나 , CNN 과 LSTM 을 함께 사용하는 방법에 대한 연 구가 활발히 이루어지고 있다 [ 14 - 17 ] . 데이터의 불균형이 심한 경우 , 분류기의 성능이 떨어 지기 때문에 , 문장을 생성하여 불균형을 해소하는 방법 이 있다 . 분류를 위한 문장을 생성하려면 문장의 추가적 인 정보가 필요한데 , 단어의 문장 성분 [ 18 ] 이나 , 문장 구 조 [ 19 ] 의 정보를 사용하여 문장을 생성한다 . 그러나 구 문적 분류를 학습하기 위한 데이터로는 너무 복잡하고 의미적 요소를 강하게 포함한다 . 더 간단한 방법으로 생 성한 문장만으로도 구문적 특징을 학습하는 것이 가능 하다 . 3 . 방 법 이 절에서는 분류 방법에 대한 동기와 분류에 사용된 문자수준 컨볼루션 신경망 [ 3 ] , 학습을 위한 문장을 생성 하는 방법 , 그리고 이 문장을 전이학습으로 분류기에 학 습시키는 과정을 설명한다 . 욕설문장 분류의 불균형 데이터 해결을 위한 전이학습 방법 1277 3 . 1 컨볼루션 신경망의 전이 전이학습에 사용되는 요소는 컨볼루션 신경망의 필터 이다 . 선학습과정에서 생성된 임의의 학습 데이터에 대 해 컨볼루션 신경망의 필터들이 학습되고 실제 데이터 를 학습할 때 이 필터를 가지고 학습을 시작한다 . 컨볼루션 신경망의 필터는 특성 벡터   가 주어질 때 ,  번째 컨볼루션 층이  번째 컨볼루션 층의 출력 인   에서 × 크기의 필터  는 다음과 같이 컨볼 루션 층의 출력   의 영향을 미친다 .                  ( 1 ) 컨볼루션 층의 출력인   은 최대 풀링 연산을 거치 는데 × 크기의 출력 벡터   는 × 크기의 영역에 서 풀링걸음 ( pooling stride ) 이  일 때 , 다음 식으로부 터 계산된다 .    max   ×  ( 2 ) 컨볼루션 신경망은 여러 개의 컨볼루션 층과 최대 풀 링 층이 번갈아 가며 쌓아 마지막에 완전 연결 층을 거 쳐서 특성 벡터의 속성을 예측한다 . 전이학습 과정에서 실제로 바뀐 것은 필터의 가중치 뿐이지만 실제 데이터 의 학습과정에서 이 가중치가 다른 곳에 수렴하면서 컨 볼루션 신경망 전체의 예측이 달라지게 된다 . 3 . 2 학습문장 생성방법 컨볼루션 신경망의 입력이 문자수준의 윈 - 핫 인코딩 된 행렬이므로 전이학습에 사용되는 문장도 문자수준에 서 생성되어야 한다 . 추가로 각 문장의 욕설 여부를 나 타내는 라벨이 필요하다 . 한 문장을 생성하기 위해 문자 집합 내의 각 문자의 출현 빈도와 문장의 길이가 결정되어야 한다 . 이 변수들 은 각각의 랜덤 변수로 확률적으로 선택된다 . 무작위로 선택한 문자들로 문장을 생성한 경우 , 실재 사용되는 문장과 구조적으로 다른 문장이 형성되기 때 문에 학습에 사용하기 어렵다 . 따라서 모든 문자요소에 대해 랜덤이 아닌 , 문자 빈도 ( Letter frequency ) [ 20 ] 를 사용하였다 . 실제 학습문장의 길이가 일정하지 않으므로 실제 데 이터의 정보를 최대한 반영하는 방법으로 학습문장의 길이를 정하여야 한다 . 전체 문장의 길이 분포와 비슷한 확률분포를 구하여 이 확률분포에 대해 문장의 길이를 결정하였다 . 결정한 문자 빈도 분포  와 위에서 결정한 문장 길 이 분포  에 대해서 문장생성 과정을 다음과 같이 표 현할 수 있다 .     ∈   where          ∈  ( 3 ) 이렇게 생성한 문장을 일반적 특성을 가진 문장이라 고 가정한 후 , 욕설의 특성을 가지는 문장을 생성한다 . 위에서 생성한 문장에 욕설의 특징을 부여하기 위해 이 미 알고 있는 욕설 목록에서 문장에 삽입할 욕설단어를 추출한다 . R bad - word ( x ) = W bad = ( w 1 , w 2 , . . . , w k ) where w i ∈ W ( 4 ) 위 수식에서 난수 발생기 R bad - word 는 욕설단어 목록에 서 하나의 단어   를 추출한다 .   는  개의 문자 로 이루어져 있다 . 식 ( 3 ) 에서 생성한 문장  에 식 ( 4 ) 에서 추출한 단어   를 식 ( 5 ) 의 난수 발생기   가 출력한 위치에 욕설단어를 삽입하여 , 전체 문장이 욕설의 특징을 가지 도록 변환한다 .      for                  ∈      n  out :  ′                          ( 5 ) 식 ( 3 ) 에서 생성한  와 식 ( 5 ) 에서 생성한  ′ 을 임 의의 개수만큼 생성하고 각각의 문장들을 욕설이 아닌 문장과 욕설문장으로 처리하여 전이학습에 사용할 데이 터를 얻을 수 있다 . 3 . 3 전이학습 및 실제학습 과정 그림 1 의 컨볼루션 신경망은 실제 데이터로 학습하기 이전에 절 3 . 2 에서 생성된 문장 집합  와  ′ 에 대해 학습한다 . 두 문장 집합의 차이는 욕설 단어의 삽입 여 부이기 때문에 분류기는 문장 내 욕설 여부에 대한 특 성을 분류 하도록 학습하게 된다 . 이렇게 학습한 컨볼루션 신경망의 필터는 기존과 다 른 가중치와 오프셋을 가지게 되고 이 필터를 새로운 컨볼루션 신경망에 적용한 후 , 실제 훈련 데이터를 사용 하여 학습시킨다 . 4 . 실험 및 결과 4 . 1 실험 데이터 실험에 사용한 데이터는 Kaggle 의 Detecting insults in Data Commentary ( insults ) , bullyingV3 [ 21 ] , 그리고 formspring 이다 . 표 1 에 모든 데이터에서 전체문장에 대한 욕설문장의 비율이 낮아 클래스 불균형이 심하게 나타난다 . 4 . 2 전이학습 적용 3 . 2 절의 방법을 사용하여 전이학습에 사용할 학습문장 을 생성한다 . 각 문장은 아래의 알파벳 26 개 , 숫자 10 개 , 그리고 특수문자 32 개 , 총 68 개의 문자로 구성된다 . 영 어 알파벳은 소문자화시켰으며 , ASCII 순으로 정렬하면 다음과 같다 . 그림 2 는 실제 데이터에서 추출한 영어 알파벳의 빈도 1278 정보과학회논문지 제 44 권 제 12 호 ( 2017 . 12 ) 그림 1 전이학습을 적용한 욕설 분류 방법 : 선학습과정 ( 위 ) 과 실제 데이터를 이용한 학습과정 ( 아래 ) Fig . 1 Classification method applying transfer learning : Pre - training process ( top ) and Real - training process ( bottom ) 표 1 실험 데이터의 욕설과 비욕설문장 개수와 불균형 정도 Table 1 The number of abusive / non - abusive sentences and class imbalance of each dataset Dataset Abusive Non - abusive Ratio of abusive insults 1 ) 2819 6010 31 . 92 % bullyingV3 2 ) 1227 3524 25 . 83 % formspring 3 ) 2360 23465 9 . 14 % 그림 2 모든 실험 데이터 문장의 알파벳 사용 분포와 일반적으로 알려져 있는 알파벳 사용 분포 [ 20 ] Fig . 2 Letter frequency of all sentences in dataset , and well - known letter frequency [ 20 ] 와 일반적으로 알려진 문자 빈도의 비교 그래프이다 [ 20 ] . 정 확하게 일치하지는 않지만 상대적으로 비슷한 경향을 가진 다는 것을 알 수 있으며 영어 알파벳 이외에 4 . 2 절의 모든 문자에 대하여 구한 후 , 이를 바탕으로 문자를 선택하였다 . 그림 3 은 이 논문에서 사용한 문장들의 길이 분포와 그것과 비슷한 분포를 가진 F - 분포이다 . F - 분포의 확률 밀도는 식 ( 6 ) 과 같이 구하며 , 실제 데이터에 대해 이 분 1 ) https : / / www . kaggle . com / c / detecting - insults - in - social - commentary 2 ) http : / / research . cs . wisc . edu / bullying / data . html 3 ) http : / / www . chatcoder . com / DataDownload 그림 3 실제 문장들의 길이분포와 생성한 문장들의 길이 분포 Fig . 3 Length distribution of sentences in dataset and length distribution of generated sentences 포로 피팅한 결과 ,   은 4 . 35 ,   는 5 . 25 , 스케일은 50 . 45 로 하여 확률 분포를 생성하였다 . 이 확률분포  에 대 해서 각 문장 길이를 결정하였다 .                           ( 6 ) (  is Beta Function ) 식 ( 4 ) 에 쓰이는 욕설목록으로는 550 개의 욕설단어로 구성된 google - bad - words 를 사용했다 . 데이터 불균형을 해소하기 위해 욕설문장과 비욕설문장의 비율을 1 : 1 로 생성했으며 7 : 3 의 훈련 , 테스트 비율로 나누어 컨볼루션 신경망을 학습시켰다 . 4 . 3 결과 및 분석 4 . 2 절에서 생성한 학습 문장을 컨볼루션 신경망의 필 터에 학습시킨 컨볼루션 신경망과 그렇지 않은 컨볼루 션 신경망에 6 : 4 로 분할한 실제 훈련문장을 학습시킨 후 테스트 문장으로 평가했다 . 욕설문장 분류의 불균형 데이터 해결을 위한 전이학습 방법 1279 표 2 전이학습 여부에 따른 각 실험 데이터의 평균 F1 점수 Table 2 Average F1 score of each dataset about whether the transfer learning is applied Dataset F1 score with no transfer learning Maximum F1 score with transfer learning ( the number of pre - training sentences ) insults 0 . 336 0 . 660 ( 250000 ) bullyingV3 0 . 487 0 . 548 ( 150000 ) formspring 0 . 171 0 . 262 ( 250000 ) 그림 4 미리 학습한 문장 수에 따른 각 데이터 셋에서의 F1 점수 변화 Fig . 4 Change in F1 score in each dataset about the number of pre - training sentences 실험은 각 실험 데이터와 적용한 가짜문장의 개수 , 그 리고 전이학습 여부에 대해 5 번씩 시행했다 . 데이터의 클래스 불균형이 심하므로 정확도는 모델의 성능평가에 사용할 수 없다 . 따라서 각 경우에 대해 F1 점수를 계산 하여 성능을 평가하였다 . 표 2 에서 전이학습을 적용한 컨볼루션 신경망이 적용 하지 않은 경우보다 F1 점수의 평균이 항상 높은 것을 알 수 있다 . 그림 4 에서 전이학습 과정에서 학습시킨 문 장의 개수가 많아지면 F1 점수가 증가하다가 일정 문장 개수 이상인 경우에는 특정 점수로 수렴하는 특성을 확 인할 수 있다 . bullyingV3 처럼 문장의 개수가 너무 적 거나 , formspring 처럼 클래스 불균형이 너무 심한 경우 에는 F1 점수가 큰 폭으로 상승하지는 않았지만 소폭의 상승세를 보인다 . 표 3 은 이 방법이 데이터 불균형을 어느 정도 해소해 줄 수 있는지를 알아보기 위해 다른 샘플링의 방법들을 insult 데이터에 적용한 결과이다 . 비교 알고리즘으로는 기존의 샘플링 방법인 업 - 샘플링 ( Up - sampling ) , 다운샘 플링 ( Down - sampling ) , 그리고 SMOTE ( Synthetic Minority Over - sampling Technique ) [ 22 ] 를 사용하였다 . 모든 샘플 링 방법에서 두 클래스 비율이 1 : 1 이 되도록 샘플링하여 모델을 학습시킨 후 같은 테스트 데이터에 대해 정밀도 , 표 3 insult 데이터에 기존 샘플링 방법들을 적용했을 때의 정밀도 , 재현율 , 그리고 F1 점수 Table 3 Precision , Recall , and F1 score for several con - ventional sampling methods in insult dataset Sampling Method Precision Recall F1 score No sampling 0 . 460 0 . 283 0 . 336 Up - sampling 0 . 490 0 . 360 0 . 407 Down - sampling 0 . 323 0 . 713 0 . 437 SMOTE 0 . 428 0 . 501 0 . 446 Ours ( 250k ) 0 . 739 0 . 602 0 . 660 그림 5 생성한 문장 개수에 따른 선학습 과정에 걸리는 시간 Fig . 5 Consumed time of pre - training process over the number of pre - training sentences 재현율 , 그리고 F1 점수를 계산하였다 . 다운샘플링한 경 우에 가장 높은 재현율을 얻을 수 있지만 , 정밀도와 F1 점수는 본 논문의 방법을 사용했을 때 가장 높은 것을 확인할 수 있다 . 선학습 모델을 훈련하는 시간 복잡도는 일반 컨볼루 션 신경망의 역전파 ( backpropagation ) 의 시간 복잡도와 동일하며 식 ( 7 ) 과 같다 [ 23 ] .        ⋅  ⋅  ⋅   ( 7 ) 여기서  을 컨볼루션 층의 인덱스라고 하면  는 컨볼루션 신경망의 깊이 ,   은  번째 컨볼루션 층의 필터의 개수 ,   은 필터의 길이 ,   은 출력 특성맵의 크기를 나타낸다 . 그림 5 는 가짜 문장의 개수에 따른 전이학습 모델의 훈련에 소모되는 시간을 그래프로 나타낸 것이다 . 학습 문장의 개수는 컨볼루션 신경망의 구조에 영향을 주지 않고 단순히 계산 회수에만 영향을 주기 때문에 학습 문장의 개수가 증가함에 따라 모델의 학습 시간은 선형 적으로 증가하는 것을 확인할 수 있다 . 5 . 결 론 기존의 문자수준 컨볼루션 신경망은 데이터가 적고 , 1280 정보과학회논문지 제 44 권 제 12 호 ( 2017 . 12 ) 클래스 불균형이 심한 욕설분류에서 좋은 성능을 나타 내지 못한다 . 이 문제의 해결 방안으로 우리는 임의의 문장을 생성하여 분류기에 미리 데이터의 특성을 학습 시키는 전이학습 방법을 제안하며 , 기존의 문자수준 컨 볼루션 신경망보다 약 1 . 1～2 배의 성능 향상을 확인하였다 . 또한 데이터 불균형의 해소의 관점에서 훈련 데이터 를 중복해서 사용하지 않으므로 과적합을 방지할 수 있 고 , 임베딩 이후 형식에 영향을 받지 않는 장점이 있다 . 욕설의 특징을 학습하기 위해서는 학습 데이터를 수 동으로 생성해야 하는 어려움이 있다 . 그러나 이 방법을 통해 욕설단어의 목록만으로도 학습 데이터를 생성할 수 있으며 , 이는 큰 도메인 내에서 욕설분류에 한정되지 않고 다양한 텍스트 분류 문제에서 구문적 특징을 검색 할 수 있는 방법으로 적용할 수 있을 것이다 . References [ 1 ] S . Sood , E . Churchill , and J . Antin , " Profanity use in online communities , " Proc . of SIGCHI Conf . on Human Factors in Computing Systems , pp . 1481 - 1490 , 2012 . [ 2 ] Y . Chen , Y . Zhou , S . Zhu , and H . Xu , " Detecting offensive language in social media to protect ado - lescent online safety , " Int . Conf . on Social Com - puting , pp . 71 - 80 , 2012 . [ 3 ] X . Zhang , J . Zhao , and Y . LeCun , " Character - level convolutional networks for text classification , " Ad - vances in Neural Information Processing Systems , pp . 649 - 657 , 2015 . [ 4 ] S . Sood , E . Churchill , and J . Antin , " Automatic identification of personal insults on social news sites , " Journal of Association for Information Science and Technology , Vol . 63 , No . 2 , pp . 270 - 285 , 2012 . [ 5 ] G . Xiang , B . Fan , L . Wang , J . Hong , and C . Rose , " Detecting offensive tweets via topical feature discovery over a large scale twitter corpus , " Int . Conf . on Information and knowledge management , pp . 1980 - 1984 , 2012 . [ 6 ] W . Zhang , T . Yoshida , & X . Tang , " A comparative study of TF * IDF , LSI and multi - words for text classification , " Journal of Expert Systems with Applications , Vol . 38 , No . 3 , pp . 2758 - 2765 , 2011 . [ 7 ] D . Ramage , S . T . Dumais , and D . J . Liegling , " Characterizing microblogs with topic models , " Int . Conf . on Web and Social Media , pp . 1 - 1 , 2010 . [ 8 ] N . Djuric , J . Zhou , R . Morris , M . Grbovic , V . Radosavljevic , and N . Bhamidipati , " Hate speech detection with comment embeddings , " Conf . on World Wide Web , pp . 29 - 30 , 2015 . [ 9 ] K . Dinakar , R . Reichart , and H . Lieberman , " Modeling the detection of Textual Cyberbullying , " Int . Conf . on Weblog and Social Media , Social Mobile Web Workshop , pp . 11 - 17 , 2011 . [ 10 ] N . D . Gitari , Z . Zuping , H . Damien , and J . Long , " A lexicon - based approach for hate speech detection , " Journal of Multimedia and Ubiquitous Engineering , Vol . 10 , No . 4 , pp . 215 - 230 , 2015 . [ 11 ] Q . V . Le , and T . Mikolov , " Distributed representa - tions of sentences and documents , " Int . Conf . on Machine Learning , pp . 1188 - 1196 , 2014 . [ 12 ] T . Mikolov , I . Sutskever , K . Chen , G . S . Corrado , and J . Dean , " Distributed representations of words and phrases and their compositionality , " Advances in Neural Information Processing Systems , pp . 3111 - 3119 , 2013 . [ 13 ] C . Nobata , J . Tetreault , A . Thomas , Y . Mehdad , and Y . Chang , " Abusive language detection in online user content , " Conf . on World Wide Web , pp . 145 - 153 , 2016 . [ 14 ] Y . Kim , " Convolutional neural networks for sen - tence classification , " Conf . on Empirical Method in Natural Language Processing , pp . 1746 - 1754 , 2014 . [ 15 ] C . Zhou , C . Sun , Z . Liu , and L . Lau , " A C - LSTM neural network for text classification , " preprint arXiv : 1511 . 08630 , 2015 . [ 16 ] Y . Kim , Y . Jernite , D . Sontag , and A . M . Rush , " Character - aware neural language models , " Asso - ciation for the Advancement of Artificial Intelli - gence , pp . 2741 - 2749 , 2016 . [ 17 ] J . Wang , L . C . Yu , K . R . Lai , and X . Zhang , " Dimensional sentiment analysis using a regional CNN - LSTM model , " Annual Meeting of the Asso - ciation for Computational Linguistics , pp . 225 - 230 , 2016 . [ 18 ] T . Chen , R . Xu , Q . Lu , B . Liu , J . Xu , and Z . He , " A Sentence vector based over - sampling method for imbalanced emotion classification , " Int . Conf . on Intelligent Text Processing and Computational Lin - guistics , pp . 62 - 72 , 2014 . [ 19 ] M . Iyyer , J . Boyd - Graber , and H . Daumé III , " Generating sentences from semantic vector space representations , " Proc . NIPS Workshop on Learning Semantics , 2014 . [ 20 ] R . Lewand , Cryptological Mathematics , pp . 199 , The Mathematical Association of America , 2000 . [ 21 ] J . M . Xu , K . S . Jun , X . Zhu , and A . Bellmore , " Learning from bullying traces in social media , " Conf . of North American chapter of Association for Computational Linguistics : Human Language Tech - nologies , pp . 656 - 666 , 2012 . [ 22 ] N . V . Chawia , K . W . Bowyer , L . O . Hall , and W . P . Kegelmeyer , " SMOTE : synthetic minority over - sampling technique , " Journal of Artificial Intelligence Research , Vol . 16 , pp . 321 - 357 , 2002 . [ 23 ] K . He , and J . Sun , " Convolutional neural networks at constrained time cost , " Proc . of IEEE Conf . on Computer Vision and Pattern Recognition , pp . 5353 - 5360 , 2015 . 욕설문장 분류의 불균형 데이터 해결을 위한 전이학습 방법 1281 서 수 인 2016 년 연세대학교 기계공학과 ( 학사 ) . 2017 년 ～ 현재 연세대학교 컴퓨터과학과 통합 과정 . 관심분야는 자연어 처리 , 시계열 데 이터 처리 조 성 배 정보과학회논문지 제 44 권 제 7 호 참조