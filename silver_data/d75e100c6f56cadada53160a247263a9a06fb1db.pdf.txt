 Abstract —Based on the idea of the difference method , in this paper , the difference method is applied to the calculation of the variance and covariance . The variance and covariance formulas are transformed as some new formulas by the difference method . The articles presented some original new variance and covariance formulas whose form that contains the individual difference , and leads to some corresponding new expansion formulas . The calculation of the variance and covariance about this method is less implicated with the changes of the overall sample . Finally , the theoretical analysis and practical application of image denoising show the feasibility of the new formula . Index Terms —variance ; covariance ; deformation formula ; image denoising I . INTRODUCTION HE analysis of variance and covariance is an important part of mathematical analysis . The variance reflects the dispersion degree that all possible values of random variables around the mathematical expectation . Covariance analysis is a statistical analysis method that bases on variance analysis and regression analysis [ 1 ] . Variance analysis is to explore the influence of factors at different levels on the experimental index difference from the perspective of the quality factor . In general , the quality factor can be artificially controlled . The variance and covariance analysis of the sample is an important significance work . The noise signal dramatic change is an important feature of the noise , and the variance is used to describe an important indicator of fluctuations in a sample . At present , some related theorems of the variance and covariance are used in a large number of related fields [ 2 - 6 ] , such as image denoising , and achieved some results . However , most of the variance calculation has something with the whole system that is consisted by the sample . There are some disadvantages for this method , such as the big calculation intensity , the big implication with the changes of This work was supported in part by the National Natural Science Foundation of China ( Grant No . 61075087 ) , the Natural Science Foundation Key Projects of Hubei Province Technology Projects ( Grant No . 2010CDA005 ) . Yuli Zhang is with the Shenzhen Institute of Advanced Technology , Chinese Academy of Science , Shenzhen , 518055 , China ( e - mail : yuli . zhang @ yahoo . cn ) . Huaiyu Wu is with the Engineering Research Center of Metallurgical Automation and Measurement Technology , Ministry of Education , Wuhan University of Science and Technology , Wuhan , 430081 , China ( e - mail : whyjwc @ 163 . com ) . Lei Cheng is with the Control Engineering Open Lab of Key Subjects of Henan Province , Jiaozuo , China ; the Engineering Research Center of Metallurgical Automation and Measurement Technology , Ministry of Education , Wuhan University of Science and Technology , Wuhan , 430081 , China ( E - mail : chenglei @ wust . edu . cn ) . overall system . In order to overcome these disadvantages and use variance and covariance for practical application , we put forward the difference between individuals method in this paper . Variance and covariance equation will be changed to the formation of the form that contains the sample individual difference by this method . We can regard the system that is composed of these samples as a rigid body by this method , then , the variance can be interpreted as the potential energy between the rigid bodies internal . This potential energy has nothing to do with the rigid body position , but it is only related to the potential energy between the rigid body internal points . The calculation of the variance and covariance about this method is less implicated with the changes of the overall sample . Finally , the feasibility of the new formula can be demonstrated by the theoretical analysis and practical application . II . T HE DEFORMATION OF THE COVARIANCE AND VARIANCE FORMULA Set the sample space of the random variable X for   | 1 , 2 , 3 , X i X I X i N    , where the realization of the individual i X is i x , the sample size of the X is X N . Sample mean : 1 X N i i X X X N    ( 1 ) The realization of the sample mean : 1 1 X N i i X x x N    ( 2 ) The variance of the sample space : 2 2 1 1 ( ) X N X i i X s x x N     ( 3 ) Similarly , the sample space of the random variable Y is   | 1 , 2 , 3 Y j Y I Y j N    , where the realization of the individual i Y is i y , the sample size of the Y I is Y N . We can also conclude that the sample mean Y , the realization y of the mean , the variance 2 Y s of the sample space Y I . Sample mean : 1 Y N j j Y Y Y N    ( 4 ) The realization of the sample mean : 1 1 Y N j j Y y y N    ( 5 ) The variance of the sample space : Some New Deformation Formulas about Variance and Covariance Yuli Zhang , Huaiyu Wu , Lei Cheng T Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 987 2 2 1 1 ( ) Y N Y j j Y s y y N     ( 6 ) If that , X Y N N N   ( 7 ) Then , the covariance : 1 1 cov ( , ) ( ) ( ) N i i i X Y x x y y N      ( 8 ) The deformation formula ( 1 ) : 2 1 1 2 1 1 1 cov ( , ) ( ) ( ) 1 = ( ) ( ) 2 N N i j i j i j i N N i j i j i j X Y x x y y N x x y y N              ( 9 ) The equation ( 9 ) can be proved as follows : Set vector as : 1 2 3 ( , , , ) T N x x x x  x   1 2 3 ( , , ) T N y y y y  y   1 ( 1 , 1 , 1 1 ) N H E R     1 ( 1 , 1 , 1 1 ) T N V E R     1 1 2 2 3 3 N N x y x y A x y x y                   1 1 1 2 1 3 1 2 1 2 2 2 3 2 3 1 3 2 3 3 3 1 2 3 N N N N N N N N x y x y x y x y x y x y x y x y B x y x y x y x y x y x y x y x y                           According to equation ( 2 ) and ( 5 ) , the equation ( 8 ) can be expanded to :   1 1 2 1 1 1 2 2 1 1 2 1 1 1 cov ( , ) ( ) ( ) 1 ( ) 1 ( ) ( ) ( ) 1 1 ( ) ( ) 1 ( ) ( ) 2 N i i i N i i i N N N i i i j i i j H V H V N N i j i j i j i N N i j i j i j X Y x x y y N x y x y N N x y x y N NE AE E BE N x x y y N x x y y N                                        (cid:0) ( The proof end ) According to the conclusions of the equation ( 9 ) , we can easy to get the deformation formula ( 2 ) . The deformation formula ( 2 ) ： 2 2 2 1 1 2 2 1 1 1 cov ( , ) ( ) 1 ( ) 2 X X X X N N X i j i j i X N N i j i j X s X X x x N x x N              ( 10 ) The equation ( 10 ) showed that the variance of a sample can be calculated by computing the difference between individuals . If we regard the system that is composed of these samples as a rigid body , then the variance can be interpreted as the potential energy between the rigid bodies internal . This potential energy has nothing to do with the rigid body position ( mean ) , but it is only related to the potential energy between the rigid body internal points . From the equation ( 10 ) , we can obtain the following conclusions . ( a ) If the overall potential energy is small , the potential energy of rigid body internally between various points is small . It also can be explained as follows from the frequency domain . If the overall signal is low frequency , then the all signal that we can get by the orthogonal decomposition are low frequency . ( b ) If the overall potential energy is big , the rigid body internally will contain the big relative potential energy points , but also may contain the small relative potential energy point . It also can be explained as follows from the frequency domain . If the overall signal is high frequency , it must contain the high - frequency , but also may contain low - frequency by the orthogonal decomposition . III . S EGMENTATION AND AGGREGATION RELATIONS OF THE SAMPLE The totality X S of the variable X is divided into X n samples , namely : 1 X S , 2 X S , 3 X S … X Xn S . Each sample means are denoted as 1 x , 2 x … X n x , The sample size is denoted as 1 X N , 2 X N , 3 X N … X Xn N . Set   1 2 , , . . . . . , 1 , 2 , . . . . . . Xi X i i i i X N S X X X i n   , then 1 2 . . . . . . . X X X X Xn S S S S    . The sample size X N of the totality X S : 1 X n X Xi i N N    ( 11 ) Each sample accounted for the overall sample proportion is set to 1 , 2 , 3 . . . . . X X i i X X N i n N    , Then , 1 1 X n Xi i     ( 12 ) Or , 1 X n X X i j j i       ( 13 ) Similarly , the totality Y S of the variable Y is divided into Y n samples , namely : 1 Y S , 2 Y S , 3 Y S … Y Y n S . Each sample means are denoted as 1 y , 2 y … Y n y , The sample size is denoted as 1 Y N , 2 Y N , 3 Y N … Y Yn N . The sample size Y N of the totality Y S : Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 988 1 Y n Y Yi i N N    ( 14 ) Set   1 2 , , . . . . . , 1 , 2 , . . . . . . Xi Y i i i i Y N S Y Y Y j n   , then 1 2 . . . . . . . Y Y Y Y Yn S S S S    . Each sample accounted for the overall sample proportion is set to 1 , 2 , 3 . . . . . Y Y i i Y Y N i n N    . Then , 1 1 Y n Yi i     ( 15 ) Or , 1 Y n Y Y i j j i       ( 16 ) In the case of X Y n n n   and X Y i i N N  , 1 , 2 , 3 . . . . . . . . i n  ， we set this . X Y i i i N N N   X Y i i i      X Y N N N   The mean x of the sample X S :   1 X n Xi i i x x     ( 17 ) The mean y of the sample Y S :   1 Y n Yi i i y y     ( 18 ) The deformation formula ( 3 ) ：               1 1 1 1 1 1 cov ( , ) cov ( , ) 1 cov ( , ) 2 X Y n n n X Y i i i i j i j i j i i j i n n n X Y i i i i j i j i j i i j S S S S x x y y S S x x y y                         ( 19 ) The equation ( 19 ) can be proved as follows : 1 ( 1 , 1 , 1 1 ) n h E R     1 ( 1 , 1 , 1 1 ) T n v E R     It is knowable that ,   1 1 cov ( , ) , ( 1 , 2 , . . . . . . i N X Y i i i i j j i i j i S S X Y x y i n N      ） ( 20 )   1 1 cov ( , ) N X Y i i i S S X Y x y N      ( 21 ) In the case of X Y n n n   and , 1 , 2 , 3 . . . . . . . . X Y i i N N i n   , the equation ( 12 ) and equation ( 15 ) can be written as : 1 1 n i i     ( 22 ) The equation ( 13 ) and equation ( 16 ) can be written as : 1 n i j j i       ( 23 ) The equation ( 17 ) can be written as :   1 n i i i x x     ( 24 ) The equation ( 18 ) can be written as :   1 n i i i y y     ( 25 ) The equation ( 21 ) can be written as the equation ( 26 ) .       1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 cov ( , ) 1 1 ( ) ( ) ( ) ( ) 1 ( ) ( ) ( ) ( ) i i X Y N i i i N n n n i i j j i i j j i j i j n n N n i i i j j h i j i n n n n n n S S X Y x y N X Y x y N x y x y N X Y E N N x y x y                                                                                             1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 , 1 ( ) ( ) ( ) ( ) 1 ( ) ( ) ( ) ( ) 1 ( ) ( ) i i v n n N n i i i j j h v i j i n n n n n n N n i i i j j i i i j i n j j n j h E x y x y X Y E E N x y x y X Y x y N x E                                                                                                           1 1 1 1 1 1 1 , 1 1 1 1 1 1 1 1 ( ) ( ) ( ) ( ) ( ) ( ) 0 ( ) ( ) cov ( , ) ( ) ( 0 0 cov ( , ) n n v n n n n n j n j n j n n n n X Y i i i h v i n n n n X Y i i i h i y x y E x y x y x y y S S E E x y y S S E                                                                                                                      1 1 1 1 1 1 1 1 1 1 1 1 ( ) ( ) 0 0 0 ( ) ( ) cov ( , ) 0 0 cov ( , ) 1 cov ( , ) 2 n n n v n n n n X Y i i i h v i n n n X Y i i i i j i j i j i i j i n n n X Y i i i i j i j i j i i j x x y y E x x y y S S E E S S x x y y S S x x y y                                                                   ( 26 ) ( The proof end ) In the equation ( 19 ) , if Y X  , then Y X i i S S  , i i x y  , we can obtain the deformation formula ( 4 ) . The deformation formula ( 4 ) ：               1 1 1 1 1 1 cov ( , ) cov ( , ) 1 cov ( , ) 2 X X n n n X X i i i i j i j i j i i j i n n n X X i i i i j i j i j i i j S S S S x x x x S S x x x x                         ( 27 ) The random variables and the sample points of the above discussed variance and covariance are in a one - dimensional space . We expand the conclusions to the m - dimensional space , then the conclusions are also right . When we expand the equation ( 27 ) to the m - dimensional space , we can get the deformation formula ( 5 ) . The deformation formula ( 5 ) ： Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 989                 1 1 1 1 1 1 cov ( , ) cov ( , ) 1 cov ( , ) 2 X X n n n T X X i i i i j i j i j i i j i n n n T X X i i i i j i j i j i i j S S S S x x x x S S x x x x                         ( 28 ) IV . T HE ANALYSIS OF THE VARIANCE EXTREME VALUE A . Introduction The analysis of the sample variance size is an important significant work . This section is mainly discussed in the one - dimensional and two - dimensional space . Firstly , for a random variable 1 m X   (cid:0) , we set that all possible values of the sample points are known , which respectively are 1 1 , , n x x x  . The proportion i  of all possible values is unknown . According to the values , we can classified the same value sample as the same sub - sample . We can get n sub - samples that they are Xi S .   1 2 , , . . . . . , | , 1 , 2 , ( 1 , 2 , . . . . . . ) Xi X i i i i X i j i i N S X X X X x j N i n      In case of i i x x  and cov ( , ) 0 X X i i S S  , the equation ( 28 ) can be written as the deformation formula ( 6 ) . The deformation formula ( 6 ) ：             1 1 1 1 cov ( , ) 1 2 n n T X X i j i j i j i j i n n T i j i j i j i j S S x x x x x x x x                 ( 29 ) B . The extreme value analysis For the equation ( 29 ) , it can be understood as : The overall sample variance is a function of 1 , n    , that :         1 1 1 , cov ( , ) 1 2 X X n n n T i j i j i j i j f S S x x x x            ( 30 ) Set :   1 1 , 1 n n i i g               then   1 , 0 n g     ( 31 ) According to the constraints ( 31 ) and introduce Lagrange multiplier , we set this .       1 1 1 , , , n n n L f g             ( 32 ) It can also be written in simple as : L f g    ( 33 ) For the equation ( 33 ) , we respectively calculate the partial derivatives for 1 , n    and make it zero . We can get the following equations . 1 2 0 0 0 n L L L              ( 34 ) They are expanded to ： 1 1 1 2 2 1 1 ( ) ( ) 0 ( ) ( ) 0 ( ) ( ) 0 n T i i i i n T i i i i n T i n i n i i x x x x x x x x x x x x                                             ( 35 ) Coupled with the constraints ( 31 ) , we can obtain the following equations : The equations ( 1 ) 1 1 1 2 2 1 1 1 ( ) ( ) 0 ( ) ( ) 0 ( ) ( ) 0 1 0 n T i i i i n T i i i i n T i n i n i i n i i x x x x x x x x x x x x                                                            ( 36 ) The equations ( 36 ) can be deformed as follows : The equations ( 2 )   1 1 1 2 2 1 1 1 ( ) ( ) ( ) ( ) ( ) ( ) 1 1 n T i i i i n T i i i i n T i n i n i i n i i x x x x x x x x x x x x                                                            ( 37 ) We set this : 1 2 ( ) T n      …   ( ) 1 1 2 T T T T m n n x x x R     X    1 1 1 1 T n v E    R    1 1 1 1 n h E    R  1 1 1 1 1 2 1 2 1 1 2 1 2 1 2 2 2 2 2 2 1 1 2 2 ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) ( ) T T T n n T T T n n T T T n n n n n n n n x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x                                          So the equations ( 37 ) can be abbreviated as follows : 1 v v E E          ( 38 ) Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 990 If  is nonsingular , the following results ( the equations ( 39 ) ) can be calculated from equations ( 38 ) . 1 1 1 1 h v v h v E E E E E                  ( 39 ) C . Analysis of the special circumstances For one - dimensional space , the values of the sample points are two differences values , namely 1 2 x x  ( 1 m  , 2 n  ) .     2 1 2 2 2 1 0 = 0 x x x x            ( 40 )           2 1 2 2 1 2 2 1 2 2 1 2 1 4 1 2 1 1 0 0 = 0 0 x x x x x x x x x x                            ( 41 )   2 1 2 2 x x     ( 42 ) 1 1 2 2 T         ( 43 ) At this time , the mean :   1 1 2 2 x x x   ( 44 ) Please take the results of equation ( 43 ) into equation ( 29 ) , we can get the deformation formula ( 7 ) . The deformation formula ( 7 ) ：   2 1 1 2 2 cov ( , ) X X S S x x   ( 45 ) The equation ( 43 ) showed that , for the overall sample of the fixed sample size , the sample points can only take two possible values , 1 x and 2 x . when the number of the value 1 x and the value 2 x is equal , the variance reaches a maximum value as   2 1 1 2 2 x x  . V . T HE APPLICATION OF VARIANCE AND COVARIANCE THEOREM A . Application I : image denoising The noise signal dramatic change is an important feature of the noise , and the variance is used to describe an important indicator of fluctuations in a sample . Set a grayscale image P consisting of the collection M . The height and width of the image P is H and W . Take the first pixel index of the image upper left corner as ( 1 , 1 ) A , the first pixel index of the image lower left corner as ( , 1 ) B H , the first pixel index of the image lower right corner as ( , ) C H W , the first pixel index of the image upper right corner as ( 1 , ) D W . Shown in Figure 1 . Fig . 1 . Image pixel index plot The set of pixel abscissa index consisted is the { 1 , 2 , . . . . } H  V , and pixel vertical coordinate index consisted is the { 1 , 2 , . . . . } W  H . The Cartesian product of V and H constituted is   ( , ) | , x y x y      C V H V H . The Cartesian product can be used to represent the collection of the coordinate index ( , ) x y of all pixels in the image . Function ( ) G  is said to strike the number of elements in the collection , then : ( ) H G  V ( ) W G  H The collection M can be described as :   ( , ) | ( , ) z x y x y   M C ( 46 ) Where the ( , ) z x y represents a pixel value of the pixel coordinate ( , ) x y . The N C represents a set that it consists of horizontal axis and vertical axis ( , ) u v of the target image pixels . The collection Ν of all target image pixels can be described as follows :   ( , ) | ( , ) z u v u v   N N C ( 47 ) where ， the ( , ) z u v represents a pixel value of the target pixel coordinates ( , ) u v . Apparently , because of  N C C , then  N M ( 48 ) All the pixel values constitute a sample S N , The variance of the sample denoted by 2 s N . The sample size is ( ) Q G  N C . According to the equation ( 10 ) :   2 2 2 ( , ) ( , ) 1 ( , ) ( , ) 2 i j s t s z i j z s t Q       N N N C C ( 49 ) If the characteristics of the target is the pixel values rapid change of each pixel , there are k N points pair ( , ) z i j and ( , ) z s t in the target pixel . k N is an even number , to meet [ 7 ] : ( , ) ( , ) 0 z i j z s t     ( 50 ) 2 2 2 2 1 ( ) 2 2 k s kc Q Q        N N ( 51 ) The equation ( 51 ) gives a lower bound 2 2 k Q  N of the target sample variance . Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 991 Set the image P contains one collection B , what composes of pixels of other property . The B C represents a set that it consist horizontal axis and vertical axis ( , )   of all the pixels . T is the number of pixels of the set B . ( ) T G  B C Sample B is made up of all the sample points . The variance of the sample :   2 2 2 ( , ) ( , ) 1 ( , ) ( , ) 2 i j s t s z i j z s t T       B B B C C ( 52 ) If the pixel value fluctuation of all the corresponding pixel points in the set B is very small , we can think that the point pair difference of all the pixels in the set B is less than  , namely : ( , ) ( , ) z i j z s t    ( 53 ) According to the equation ( 52 ) , we can obtain this :     2 2 2 ( , ) ( , ) 2 2 2 2 1 ( , ) ( , ) 2 1 2 2 i j s t s z i j z s t T T T           B B B C C ( 54 ) The equation ( 54 ) gives a upper bound 2 2  of the sample variance . By selecting the appropriate parameters , we can make the following equation was established . 2 2 2 2 k Q          N ( 55 ) Then , We can distinguish the noise sample and S B . Furthermore , we can distinguish the noise sets and collections B . B . Application II : object extraction According to the analysis of Figure 2 , we can know that the target background image is a horizontal thick lines and the image contains some noise , such as dark spots , and some bending vertical line exist in the left side . Fig . 2 . the original gray - scale image of contains the target and noise In order to extract the target pixel , we firstly analyze the characteristics of the target pixel . We can take a 29 5  mask to extract a 29 5  rectangular in the image . The set that contains some image points which are included by rectangular is T . The sample which is constituted by pixel value of the set T is S T and its variance is 2 s T . When the mask is sliding in the image , the variance 2 s T in different position is not the same . When some parts of the mask and the edge of target image overlap , the variance will be large . Around part of the target image and the target image is basically a binary image . According to the conclusion of the equation ( 44 ) and ( 45 ) , we can know that when the center of the mask and the image overlap , the variance will be the maximum . However , some variances of other positions may be small relatively . When the variance is more than 9280 , we can think that the position of this mask has fellowship with the target . Otherwise , when the variance is less than 9280 , we can think that the position of this mask has not fellowship with the target . Using the above operation method , we can get the figure 3 as shown in picture . Fig . 3 . the result image that was eliminated noise by variance index VI . CONCLUSION In this paper , the existing variance and covariance formulas are transformed to some new formulas by the difference method . And some corresponding new expansion formulas are presented by the new formulas . The new formula is entirely feasible by derivation and verification . This paper carried out a detailed analysis for the variance extreme value by the deformation formula . Finally , the new formula theorem is applied to image denoising . We can learn from these applications that these new formulas are entirely feasible for the actual application . The variance and covariance analysis of the sample is an important significance work . R EFERENCES [ 1 ] Zhou Y . D . Probability and mathematical statistics [ M ] . Beijing : China Renmin University Press , 2002 . [ 2 ] Swilem A . , Abd Ellah , A . H . , Elaw S . A fast image detection method using variance and variance covariance matrix [ C ] . The 7th International Conference on Informatics and Systems , 2010 . [ 3 ] Gilboa G . , Sochen N . Estimation of optimal PDE - based denoising in the SNR sense [ J ] . IEEE Transactions on Image Processing . 2006 , 15 ( 8 ) : 2269 - 2280 . [ 4 ] Portilla J . Image restoration using Gaussian scale mixtures in overcomplete oriented pyramids [ J ] . Proceedings of SPIE - The International Society for Optical Engineering . 2005 , 5914 : 1 - 15 . [ 5 ] Chang S . G . , Yu B . , Vetterli M . Adaptive wavelet thresholding for image denoising and compression [ J ] . IEEE Transactions on Image Processing . 2000 , 9 ( 9 ) : 1532 - 1546 . [ 6 ] Chang G . P . , Li L . S . , Chen D . The proof of a inequality and its deductions [ J ] . College Mathematics . 2009 , 25 ( 5 ) : 167 - 169 . Proceedings of 2012 International Conference on Modelling , Identification and Control , Wuhan , China , June 24 - 26 , 2012 992