Stat Comput ( 2006 ) 16 : 239 – 249 DOI 10 . 1007 / s11222 - 006 - 8769 - 1 A Markov Chain Monte Carlo version of the genetic algorithm Differential Evolution : easy Bayesian computing for real parameter spaces Cajo J . F . Ter Braak Received : April 2004 / Accepted : January 2006 C (cid:2) Springer Science + Business Media , LLC 2006 Abstract Differential Evolution ( DE ) is a simple genetic al - gorithm for numerical optimization in real parameter spaces . In a statistical context one would not just want the optimum but also its uncertainty . The uncertainty distribution can be obtained by a Bayesian analysis ( after specifying prior and likelihood ) using Markov Chain Monte Carlo ( MCMC ) sim - ulation . This paper integrates the essential ideas of DE and MCMC , resulting in Differential Evolution Markov Chain ( DE - MC ) . DE - MC is a population MCMC algorithm , in which multiple chains are run in parallel . DE - MC solves an important problem in MCMC , namely that of choosing an appropriate scale and orientation for the jumping distribu - tion . In DE - MC the jumps are simply a ﬁxed multiple of the differences of two random parameter vectors that are cur - rently in the population . The selection process of DE - MC works via the usual Metropolis ratio which deﬁnes the prob - ability with which a proposal is accepted . In tests with known uncertainty distributions , the efﬁciency of DE - MC with re - spect to random walk Metropolis with optimal multivariate Normal jumps ranged from 68 % for small population sizes to 100 % for large population sizes and even to 500 % for the 97 . 5 % point of a variable from a 50 - dimensional Student distribution . Two Bayesian examples illustrate the potential of DE - MC in practice . DE - MC is shown to facilitate mul - tidimensional updates in a multi - chain “Metropolis - within - Gibbs” sampling approach . The advantage of DE - MC over conventional MCMC are simplicity , speed of calculation and convergence , even for nearly collinear parameters and mul - timodal densities . C . J . F . Ter Braak Biometris , Wageningen University and Research Centre , Box 100 , 6700 AC Wageningen , The Netherlands 6700 AC e - mail : Cajo . terbraak @ wur . nl Keywords Block updating · Evolutionary Monte Carlo · Metropolis algorithm · Population Markov Chain Monte Carlo · Simulated Annealing · Simulated Tempering ; Theophylline Kinetics . 1 . Introduction This paper combines the genetic algorithm called Differen - tial Evolution ( DE ) ( Price and Storn , 1997 , Storn and Price , 1997 , Price , 1999 ) for global optimization over real parame - ter space with Markov Chain Monte Carlo ( MCMC ) ( Gilks et al . , 1996 ) so as to generate a sample from a target distribu - tion . In Bayesian analysis the target distribution is typically a highdimensionalposteriordistribution . BothDEandMCMC are enormously popular in a variety of scientiﬁc ﬁelds for their power and general applicability . Lampinen ( 2001 ) pro - vides a bibliography of DE and Gelman et al . ( 2004 ) and Robert and Casella ( 2004 ) provide introductions to MCMC . In our combination we run multiple Markov chains , which are initialized from overdispersed states , in parallel and let the chains learn from each other - instead of running the chains independently as a way to check convergence . ( Gel - man et al . , 2004 ) and as carried out in WinBUGS ( Lunn et al . , 2000 ) . The idea of combining genetic or evolution - ary algorithms with MCMC is explored , among others , by Liang and Wong ( 2001 ) , Liang ( 2002 ) and Laskey and Myers ( 2003 ) and is closely related to work in the 1990’s on par - allel tempering and adaptive direction sampling . ( Gilks and Roberts , 1996 ) . The combination of DE and MCMC solves an important problem in MCMC in real parameter spaces , namely that of choosing an appropriate scale and orienta - tion for the jumping distribution . Note that adaptive direc - tion sampling solves the orientation problem but not the scale problem . Springer 240 Stat Comput ( 2006 ) 16 : 239 – 249 Fig . 1 Differential Evolution in two dimensions with 40 ( a ) and 15 ( b ) members in the population ( d = 2 , N = 40 and 15 ) . The proposal vec - tor x p to update the i th member is generated from x i and the randomly drawn members x R 1 and x R 2 by ( 2 ) with γ = 2 . 4 / ( 2 × 2 ) 1 / 2 = 1 . 2 in ( a ) and γ = 1 . 0 in ( b ) and e = ( 0 , 0 ) in both . The dashed arrow in ( a ) points to the proposal when x R 1 would have been drawn after x R 2 . The reverse jump from x p to x i is obtained by translating the dashed arrow to x p . A commonly used jumping distribution for MCMC in a d - dimensional real parameter space is the multivariate normal distribution . ( Gelman et al . , 2004 ) . The problem then lies in specifying the covariance matrix of this distribution . The d variances and the d ( d − 1 ) / 2 covariances need to be chosen in such a way so as to balance progress in each step and a reasonable acceptance rate ( the square - root of the variance relates to the relevant scale of each parameter and the correla - tions relate to the orientation ) . Traditionally , all these are es - timated from a trial run and much recent research is devoted to ways of doing that efﬁciently and / or adaptively ( Haario et al . , 2001 ) . If parameters are highly correlated , special pre - cautions must be taken to avoid singularity of the estimated covariances matrix . In this paper , N chains are run in par - allel and the jumps for a current chain are derived from the remaining N - 1 chains . The simplest strategy , which balances exploration and exploitation of the space , takes the difference of vectors of two randomly chosen chains , multiplies the dif - ference with a factor γ and adds the result to the vector of the current chain ( Fig . 1 ) . The difference vector contains the required information on scale and orientation . Each proposal is shown to deﬁne a Metropolis step , in which each jump is as likely as the reverse jump , given the current state of the remaining chains . The N - chain is therefore a single random walk Markov chain on an N × d - dimensional space . The new method is called Differential Evolution Markov Chain ( DE - MC ) . The core of the method can be coded in about 10 lines , requiring only a function to draw uniform random num - bers and a function to calculate the ﬁtness of each proposal vector ( Fig . 2 ) . We provide some theory and intuition for why DE - MC works , which also suggests good values for N and γ , the only free parameters of the proposal scheme . We demon - strate how the method can be used for block updating in a multi - chain Gibbs sampler and provide DE - variants of sim - ulated annealing and simulated tempering . The effectiveness of the method is demonstrated on three known distributions ( normal , Student and normal mixtures ) and on two Bayesian data analysis examples . Fig . 2 C - style pseudocode for Differential Evolution Markov Chain and simulated tempering and annealing variants . Notation : X = N × d matrix with elements X [ i ] [ j ] and X [ i ] = x i , the i th member chain of the population ; x p = proposal d - vector x p , and ﬁtness ( . ) = π ( . ) , c = γ . Uniform ( a , b ) is a function for drawing uniform random numbers between a and b . Record ( X ) is a function to collect the draws . The function CoolingSchedule ( ) = 1 for DE - MC but unequal to 1 for simulated tempering and annealing versions of DE - MC . Springer