Semi - Supervised Classiﬁcation with Graph Convolutional Networks Thomas N . Kipf , Max Welling UAmsterdam Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 1 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 2 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 3 / 32 Deﬁnitions Undirected graph G = ( V , E ) with N nodes v i ∈ V , edges ( v i , v j ) ∈ E Adjacency matrix A ∈ R N × N ( binary or weighted ) Degree matrix D ii = (cid:80) j A ij Laplacian : L = D − A Normalized Laplacian : L = I − D − 1 / 2 AD − 1 / 2 Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 4 / 32 Task : Semi - Supervised Classiﬁcation Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 5 / 32 Previous methods Label information is smoothed over the graph via some form of explicit graph - based regularization ( e . g . graph Laplacian regularization in the loss ) : L = L 0 + λ L reg , ( 1 ) L reg = (cid:88) i , j A ij (cid:107) f ( X i ) − f ( X j ) (cid:107) 2 = f ( X ) (cid:62) Lf ( X ) . ( 2 ) L 0 : supervised loss w . r . t . the labeled part of the graph f ( · ) : neural network X is a matrix of node feature vectors X i Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 6 / 32 Previous Work Drawbacks The formulation of Eq . 1 relies on the assumption that connected nodes in the graph are likely to share the same label . This assumption might restrict modeling capacity , as graph edges need not necessarily encode node similarity , but could contain additional information . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 7 / 32 This Paper Encode the graph structure directly using a neural network model f ( X , A ) and train on a supervised target L 0 for all nodes with labels , thereby avoiding explicit graph - based regularization in the loss Conditioning f ( · ) on A will allow the model to distribute gradient information from the supervised loss L 0 and will enable it to learn representations all nodes ( with and without labels ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 8 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 9 / 32 Graph Convolutional Network ( GCN ) GCNs consist of the following layer - wise propagation rule H ( l + 1 ) = σ (cid:16) ˜ D − 12 ˜ A ˜ D − 12 H ( l ) W ( l ) (cid:17) . ( 3 ) ˜ A = A + I ( adjacency matrix with added self - connections ) ˜ D ii = (cid:80) j ˜ A ij W ( l ) is a layer - speciﬁc trainable weight matrix . H ( l ) ∈ R N × D is the matrix of activations in the l th layer ; H ( 0 ) = X . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 10 / 32 Graph Convolutional Network ( GCN ) In the following , we show that the form of this propagation is motivated via a ﬁrst - order approximation of localized spectral ﬁlters on graphs Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 11 / 32 Spectral Graph Convolutions Spectral convolutions on graphs are deﬁned as multiplication of a signal x ∈ R N ( scalar for every node ) with a ﬁlter g θ = diag ( θ ) parameterized by θ ∈ R N in the Fourier domain : g θ (cid:63) x = Ug θ U (cid:62) x , ( 4 ) U is the matrix of eigenvectors of the normalized graph Laplacian L = I − D − 12 AD − 12 = U Λ U (cid:62) , with a diagonal matrix of its eigenvalues Λ , and U (cid:62) x being the graph Fourier transform of x We can view g θ as a function of the eigenvalues of L , i . e . g θ ( Λ ) . However , multiplication with the eigenvector matrix U is O ( N 2 ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 12 / 32 Spectral Graph Convolutions Spectral convolutions on graphs are deﬁned as multiplication of a signal x ∈ R N ( scalar for every node ) with a ﬁlter g θ = diag ( θ ) parameterized by θ ∈ R N in the Fourier domain : g θ (cid:63) x = Ug θ U (cid:62) x , ( 4 ) U is the matrix of eigenvectors of the normalized graph Laplacian L = I − D − 12 AD − 12 = U Λ U (cid:62) , with a diagonal matrix of its eigenvalues Λ , and U (cid:62) x being the graph Fourier transform of x We can view g θ as a function of the eigenvalues of L , i . e . g θ ( Λ ) . However , multiplication with the eigenvector matrix U is O ( N 2 ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 12 / 32 Spectral Graph Convolutions with Chebyshev polynomials To circumvent this problem , g θ ( Λ ) can be approximated by a truncated expansion in terms of Chebyshev polynomials T k ( x ) up to K th order : g θ (cid:48) ( Λ ) ≈ K (cid:88) k = 0 θ (cid:48) k T k ( Λ ) , ( 5 ) θ (cid:48) ∈ R K is now a vector of Chebyshev coeﬃcients . Chebyshev polynomials are recursively deﬁned as T k ( x ) = 2 xT k − 1 ( x ) − T k − 2 ( x ) , with T 0 ( x ) = 1 and T 1 ( x ) = x . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 13 / 32 Spectral Graph Convolutions with Chebyshev polynomials Plugging g θ (cid:48) ( Λ ) back into our deﬁnition of a convolution of a signal x with a ﬁlter g θ (cid:48) , and using the equality ( U Λ U (cid:62) ) k = U Λ k U (cid:62) , we now have : g θ (cid:48) (cid:63) x ≈ K (cid:88) k = 0 θ (cid:48) k T k ( ˜ L ) x , ( 6 ) where ˜ L = L − I This expression is now K - localized since it is a K th - order polynomial in the Laplacian , i . e . it depends only on nodes that are at maximum K steps away from the central node ( K th - order neighborhood ) . The complexity of Eq . 6 is O ( | E | ) , i . e . linear in the number of edges Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 14 / 32 Spectral Graph Convolutions with Chebyshev polynomials Plugging g θ (cid:48) ( Λ ) back into our deﬁnition of a convolution of a signal x with a ﬁlter g θ (cid:48) , and using the equality ( U Λ U (cid:62) ) k = U Λ k U (cid:62) , we now have : g θ (cid:48) (cid:63) x ≈ K (cid:88) k = 0 θ (cid:48) k T k ( ˜ L ) x , ( 6 ) where ˜ L = L − I This expression is now K - localized since it is a K th - order polynomial in the Laplacian , i . e . it depends only on nodes that are at maximum K steps away from the central node ( K th - order neighborhood ) . The complexity of Eq . 6 is O ( | E | ) , i . e . linear in the number of edges Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 14 / 32 Approximated Spectral Graph Convolution g θ (cid:48) (cid:63) x ≈ K (cid:88) k = 0 θ (cid:48) k T k ( ˜ L ) x , ( 6 ) A neural network model based on graph convolutions can therefore be built by stacking multiple convolutional layers of the form of Eq . 6 , each layer followed by a point - wise non - linearity . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 15 / 32 Approximated Spectral Graph Convolution g θ (cid:48) (cid:63) x ≈ K (cid:88) k = 0 θ (cid:48) k T k ( ˜ L ) x , ( 6 ) Further simplify this by limiting K = 1 , i . e . a function that is linear w . r . t . L and therefore a linear function on the graph Laplacian spectrum . Successive application of ﬁlters of this form then eﬀectively convolve the k th - order neighborhood of a node , where k is the number of successive ﬁltering operations or convolutional layers in the model . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 16 / 32 Approximated Spectral Graph Convolution Setting K = 1 , Eq . 6 simpliﬁes to : g θ (cid:48) (cid:63) x ≈ θ (cid:48) 0 x + θ (cid:48) 1 ( L − I ) x ( 7 ) = θ (cid:48) 0 x − θ (cid:48) 1 D − 12 AD − 12 x , ( 8 ) with two free parameters θ (cid:48) 0 and θ (cid:48) 1 . We further constrain θ = θ (cid:48) 0 = − θ (cid:48) 1 to minimize the number of operations ( such as matrix multiplications ) per layer : g θ (cid:63) x ≈ θ (cid:16) I + D − 12 AD − 12 (cid:17) x , ( 9 ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 17 / 32 Approximated Spectral Graph Convolution I + D − 12 AD − 12 now has eigenvalues in the range [ 0 , 2 ] . Repeated application of this operator can therefore lead to numerical instabilities and exploding / vanishing gradients To alleviate this problem , a renormalization trick is used : I + D − 12 AD − 12 → ˜ D − 12 ˜ A ˜ D − 12 with ˜ A = A + I and ˜ D ii = (cid:80) j ˜ A ij . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 18 / 32 Approximated Spectral Graph Convolution Final approximation for scalar inputs x and a vector of features θ : g θ (cid:63) x ≈ θ (cid:16) ˜ D − 12 ˜ A ˜ D − 12 (cid:17) x ( 10 ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 19 / 32 Full Layer - Wise Linear Model We can generalize this deﬁnition to a signal X ∈ R N × C with C input channels ( i . e . a C - dimensional feature vector for every node ) and F ﬁlters or feature maps as follows : Z = ˜ D − 12 ˜ A ˜ D − 12 X Θ , ( 11 ) where Θ ∈ R C × F is now a matrix of ﬁlter parameters and Z ∈ R N × F is the convolved signal matrix . This ﬁltering operation has complexity O ( | E | FC ) Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 20 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 21 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 22 / 32 GCN For Semi - supervised Classiﬁcation We ﬁrst calculate ˆ A = ˜ D − 12 ˜ A ˜ D − 12 in a pre - processing step . 2 layer network is then represented by : Z = f ( X , A ) = softmax (cid:16) ˆ A ReLU (cid:16) ˆ AXW ( 0 ) (cid:17) W ( 1 ) (cid:17) . ( 12 ) Here , W ( 0 ) ∈ R C × H is an input - to - hidden weight matrix for a hidden layer with H feature maps . W ( 1 ) ∈ R H × F is a hidden - to - output weight matrix . The softmax is applied row - wise . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 23 / 32 GCN For Semi - supervised Classiﬁcation We then evaluate the cross - entropy error over all labeled examples : L = − (cid:88) l ∈Y L F (cid:88) f = 1 Y lf ln Z lf , ( 13 ) where Y L is the set of node indices that have labels . Batch gradient descent is used on the full dataset for every training iteration . Using a sparse representation for A , memory requirement is O ( | E | ) , i . e . linear in the number of edges . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 24 / 32 GCN For Semi - supervised Classiﬁcation We then evaluate the cross - entropy error over all labeled examples : L = − (cid:88) l ∈Y L F (cid:88) f = 1 Y lf ln Z lf , ( 13 ) where Y L is the set of node indices that have labels . Batch gradient descent is used on the full dataset for every training iteration . Using a sparse representation for A , memory requirement is O ( | E | ) , i . e . linear in the number of edges . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 24 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 25 / 32 Experiments Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 26 / 32 Results Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 27 / 32 Results on Diﬀerent Propagation Types Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 28 / 32 Runtimes on Random Graphs Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 29 / 32 Outline 1 Introduction 2 Graph Convolutional Network 3 GCN For Semi - supervised Classiﬁcation Model Setup and Training Experiments and Results 4 Conclusion Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 30 / 32 Limitations Memory : For large graphs that do not ﬁt in GPU memory , training on CPU can still be a viable option . No Edge Features Allowed : Limited to undirected graphs ( weighted or unweighted ) . Node Locality Implicitly assumed locality ( dependence on the K th - order neighborhood for a GCN with K layers ) and equal importance of self - connections vs edges to neighboring nodes . Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 31 / 32 Conclusion By their approximations , this work was able to achieve a rapid speedup in graph convolutions ( O ( N 2 ) → O ( | E | ) ) with greater accuracy than previous methods The major drawbacks are the requirement to ﬁt the entire graph into memory , working in the spectral domain , and only applicable to transductive tasks Thomas N . Kipf , Max Welling ( University of Amsterdam ) Semi - Supervised Classiﬁcation with Graph Convolutional Networks Presenter : Jack Lanchantin https : / / qdata . github . io / deep2Read 32 / 32