Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation Esteban Marquer 1 * and Miguel Couceiro 1 * 1 Universit´e de Lorraine , CNRS , LORIA , Nancy , F - 54000 , France . * Corresponding author ( s ) . E - mail ( s ) : esteban . marquer @ loria . fr ; miguel . couceiro @ loria . fr ; Abstract Analogical inference is a remarkable capability of human reasoning , and has been used to solve hard reasoning tasks . Analogy based reason - ing ( AR ) has gained increasing interest from the artiﬁcial intelligence community and has shown its potential in multiple machine learn - ing tasks such as classiﬁcation , decision making and recommendation with competitive results . We propose a deep learning ( DL ) frame - work to address and tackle two key tasks in AR : analogy detection and solving . The framework is thoroughly tested on the Siganalogies dataset of morphological analogical proportions ( APs ) between words , and shown to outperform symbolic approaches in many languages . Pre - vious work have explored the behavior of the Analogy Neural Network for classiﬁcation ( ANNc ) on analogy detection and of the Analogy Neural Network for retrieval ( ANNr ) on analogy solving by retrieval , as well as the potential of an autoencoder ( AE ) for analogy solving by generating the solution word . In this article we summarize these ﬁndings and we extend them by combining ANNr and the AE embed - ding model , and checking the performance of ANNc as an retrieval method . The combination of ANNr and AE outperforms the other approaches in almost all cases , and ANNc as a retrieval method achieves competitive or better performance than 3CosMul . We conclude with general guidelines on using our framework to tackle APs with DL . Keywords : Morphological analogy , Analogical proportions , Analogy solving , Retrieval , Word generation 1 a r X i v : 2303 . 18062v1 [ c s . C L ] 30 M a r 2023 Springer Nature 2021 L A TEX template 2 Solving morphological analogies : from retrieval to generation 1 Introduction Abstraction and analogical inference are remarkable capability of human rea - soning [ 1 , 2 ] . To some extent , analogical inference can be thought of as transferring knowledge from a source domain to a diﬀerent , but somewhat similar , target domain by leveraging simultaneously on similarities and dis - similarities . Analogical inference has been used to solve hard reasoning tasks , and analogy based reasoning has gained increasing interest from the arti - ﬁcial intelligence community and has shown its potential with competitive results in multiple machine learning tasks such as classiﬁcation , decision mak - ing and recommendation [ 3 – 6 ] . Furthermore , analogical inference can support data augmentation through analogical extension and extrapolation for model learning , especially in environments with few labeled examples [ 7 ] . Also , it has been successfully applied to several classical natural language processing ( NLP ) tasks such as machine translation [ 8 ] , several semantic [ 9 – 11 ] and mor - phological tasks [ 12 – 18 ] , ( visual ) question answering [ 19 ] , solving puzzles and scholastic aptitude tests [ 20 ] , and target sense veriﬁcation ( TSV ) [ 21 ] which tackles disambiguation . Many analogy based reasoning approaches are built upon the notion of analogical proportions ( AP s ) , statements of the form “ A is to B as C is to D ” denoted A : B : : C : D . Signiﬁcant eﬀort has been done in the past three decades to formally deﬁne and describe the properties of APs , and we cover key approaches related to our work in Section 2 . In particular , two tasks are usually considered for APs : analogy detection and analogy solving . Analogy detection refers to deciding whether a quadruple A , B , C , D forms a valid analogy A : B : : C : D , and analogy solving is the task of ﬁnding possible values x for which A : B : : C : x constitutes a valid analogy . Expressions A : B : : C : x for an indeterminate x are referred to as analogical equations or AP equations . We further detail the two tasks and related approaches to tackle them in Subsection 2 . 3 . Morphology has been used to develop analogy - based approaches [ 12 , 22 – 24 ] using various formal frameworks , further described in Section 2 . Indeed , morphological APs can be seen as character - string APs [ 12 , 23 ] , which can be generalized to APs between sequences of symbols and , in turn , to APs between structures . In that way , morphological APs relate strongly to many application settings of analogy . Additionally , morphological APs covers many regular phe - nomena of morphology and can be used to generate new but plausible words which are easily understandable by humans . This makes makes morphology an ideal empirical framework to develop and analyze approaches to tackle APs . Morphological APs are also interesting as a standalone task . Being able to successfully model morphological APs is useful to integrate morphologi - cal innovation in automatic systems and to generate linguistic resources , in particular for languages with complex morphology or that rely heavily on mor - phological innovation . For instance , [ 24 ] proposes a toolkit to extract analogical clusters of word morphology , which summarize words with similar morpho - logical behavior by relying only on text data . This kind of result can serve Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 3 as a basis for empirical analysis of morphology or as teaching material . In that trend , our previous work [ 18 ] details results on the transfer of analogy detection models between languages , and showcases the use of morphological analogy to compare languages empirically . All these aspects led us to develop a complete framework for AP manip - ulation using deep learning that we extensively tested on the morphology of more than 16 languages in the present article as well as other languages in our previous works [ 13 – 18 ] . This paper serves as a summary of previous work on analogy detection ( Analogy Neural Network for classiﬁcation , ANNc ) and analogy solving ( Analogy Neural Network for retrieval / generation , ANNr ) [ 13 – 18 ] , and extends on papers published in the ATA @ ICCBR2022 and IARML @ IJCAI2022 workshops [ 16 , 17 ] . In particular , we improve the results of the ANNr approach [ 17 ] by enabling word generation using results from the autoencoder ( AE ) from [ 16 ] . We compare the performance of all our models on analogy solving , including new model variants . Also , we provide an overview of the entire ANNc / ANNr framework on analogy solving designed to be used as a standalone reference to the models and training procedure , inte - grating results from all our experiments to propose guidelines for future use of the ANNc / ANNr framework . The present paper is organized as follows . • The basic formalism of APs is introduced in Subsection 2 . 1 with a more detailed description of morphological APs in Subsection 2 . 2 . Subsection 2 . 3 contains a brief summary of recent approaches in tackling APs with a focus on morphological APs . • We describe the framework components in Section 3 , with the embed - ding models , analogy processing models , and training strategy described respectively in Subsections 3 . 1 to 3 . 3 . • In Section 4 , we report experimental results of all our analogy solving mod - els . The experiments are performed on 16 languages of the Siganalogies [ 25 ] dataset described in Subsections 4 . 1 and 4 . 2 , including languages not stud - ied in our previous approaches [ 13 – 18 ] . The list of all models used is detailed in Subsection 4 . 3 , and Subsection 4 . 4 covers the model performance . • Then , we provide an overview of the results and conclusions from our pre - vious and current experiments and provide guidelines for future use of the ANNc / ANNr framework in Section 5 . Key aspects of the framework are dis - cussed in details , such as the beneﬁt of using ANNc and ANNr over other methods , the data augmentation process and its link with the axiomatic set - ting , the use of the framework in a multilingual context , as well as several limitations of the approaches used . • Finally , we conclude on the contributions of the present paper and on the overall framework in Section 6 Springer Nature 2021 L A TEX template 4 Solving morphological analogies : from retrieval to generation 2 Related approaches Analogy has been in a variety of settings and refers to similar but distinct notions . Several eﬀorts have been made to provide a unifying formal framework of analogy using diﬀerent axiomatic , logical , model theoretic , and functional approaches [ 23 , 26 – 28 ] . For instance , [ 29 ] separates analogies into : analogical proportions ( APs ) , relational proportions , simile , and metaphor . While there is not general consensus on the diﬀerent notions of analogies , it is generally accepted that they can be reformulated as APs . This is true for instance for relational proportions from [ 29 ] that follow the same writing as APs , while simile and metaphor can be seen as APs with some of the elements which are not explicitly expressed . In this paper , we focus on morphological APs , i . e . , APs A : B : : C : D that capture morphological transformations of the four words A , B , C , D ( e . g . , conjugation or declension ) . In Subsection 2 . 1 we introduce the formal framework we use for our approach , which follows the seminal work of [ 30 ] by exploiting the postulates of analogical proportions . We discuss the limitations of the formal framework in Section 5 . To give the reader an overview of possible formulations of the problem of analogy , we also provide a brief introduction to other key formal frameworks . In Subsection 2 . 2 we expand on the notion of morphological transformation and the resulting morphological analogical proportions . In Subsection 2 . 3 we present key approaches to detecting and solving morphological analogical proportions . As deep learning approaches to morphological analogies are strongly related to approaches on semantic word analogies , the latter will also be discussed here . 2 . 1 Analogical proportions and other formal frameworks of analogy In this work we focus on the notion of analogical proportions ( APs ) [ 27 , 31 ] , and in particular we follow the axiomatic setting introduced by Lepage [ 32 ] consisting in 4 axioms in the linguistic context for analogical proportions : symmetry ( if A : B : : C : D , then C : D : : A : B ) , central permutation ( if A : B : : C : D , then A : C : : B : D ) , strong inner reﬂexivity ( if A : A : : C : D , then D = C ) , and strong reﬂexivity ( if A : B : : A : D , then D = B ) . These postulates imply several other properties , for instance identity ( A : A : : B : B is always true ) , inside pair reversing ( if A : B : : C : D , then B : A : : D : C ) and extreme permutation ( if A : B : : C : D , then D : B : : C : A ) . This axiomatic setting is related to the common view of APs as geometric ( Equation ( 1 ) ) or arithmetic proportions ( Equation ( 2 ) ) or , in geometric terms , as parallelograms in a vector space ( Equation ( 3 ) ) : A B = C D , ( 1 ) A − B = C − D , ( 2 ) Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 5 (cid:126)A − (cid:126)B = (cid:126)C − (cid:126)D . ( 3 ) Most of the works on analogy relying on such a formalization manipulate APs between symbols and strings of symbols ( abc : abd : : efg : efh ) , which can be directly related to morphology ( cat : cats : : dog : dogs ) , but it is also possible to apply the axiomatic setting to other kinds of analogy for instance Boolean data as was done in [ 33 , 34 ] . While these axioms seem reasonable in the word domain , they can be criticized in other application domains [ 28 ] . In [ 18 ] , we explore some limitations of the axiomatic setting for training models of morphological APs , and in particular how accepting or refusing central permutation impacts the performance of our ANNc models . 2 . 2 Morphological analogical proportions In this paper , we focus on the study of morphological APs , that is , APs between words in which the underlying relation is a morphological transformation . A morphological transformation is a transformation of the structure of a word that follows a set of morphological rules , deﬁned by the language . Morphology is usually separated into inﬂectional morphology and deriva - tional morphology . On the one hand , derivational morphology refers to morphological transformations that allow to create new words in a systematic manner , for instance in English the preﬁx un - allows to create unaware from aware in the same manner as untold from told . On the other hand , inﬂectional morphology describes morphological transformations that express a change in the grammatical nature of a word without altering the core meaning of the word . For example , looked is the result of a change of tense in the English verb to look by adding the suﬃx - ed . The data we use in our approach is extracted from inﬂectional morphology datasets as described in Subsection 4 . 1 , so our experiments are limited to APs on inﬂectional morphology . Given that the morphological mechanisms of derivational and inﬂectional morphology are very close , this limitation in the scope of our work could easily be solved by using data containing derivational morphology , without modifying our approach . Additionally , examples presented in this paper contain both derivational and inﬂexional morphological transformations , to better illustrate the mechanisms of morphology . 2 . 3 Existing approaches to tackle analogical proportions As mentioned in the Introduction , approaches to APs are usually tackled using two tasks : analogy detection and analogy solving . 2 . 3 . 1 Analogy detection Analogy detection can be seen as a classiﬁcation task : given a quadruple A , B , C , D , we classify the AP A : B : : C : D as valid or invalid according to our notion of AP . It can be applied to extract analogies from data , for instance the tools in [ 24 ] are designed to generate analogical grids , i . e . , matrices of transformations of various words , similar to paradigm tables in linguistics [ 9 ] . Springer Nature 2021 L A TEX template 6 Solving morphological analogies : from retrieval to generation Each row of an analogical grid contain words using the same root , and going from one column to another corresponds to a single morphological transforma - tion no matter the row . By taking two rows and two columns of an analogical grids , we obtain an AP . This approach [ 24 ] detects morphological analogies using manually designed features such as the number of character occurrences and the length of the longest common subword . Analogy detection on a single quadruple is less trivial than it may appear , as in many cases the boundary between valid and invalid analogies is not clearly deﬁned . A solution is to use machine learning to learn the boundary from data , as Lim et al . implemented [ 10 ] for semantic word analogies and fur - ther explored in [ 11 ] . Using a dataset of semantic APs , they learn an artiﬁcial neural network to classify quadruples A , B , C , D into valid or invalid analogies , using pretrained word embeddings e A , e B , e C , and e D . We follow a similar approach to morphological analogies in [ 13 ] by replacing the GloVe [ 35 ] seman - tic embeddings used in [ 10 , 11 ] with a morphology - oriented word embedding model . The classiﬁer is detailed in Subsubsection 3 . 2 . 1 and Figure 1 under the name Analogy Neural Network for classiﬁcation ( ANNc ) . 2 . 3 . 2 Analogy solving by retrieval or generation Analogy solving is the process of completing an incomplete analogy , in par - ticular AP equations ( or analogical equations ) like A : B : : C : x where x is unknown . Analogy solving strongly relates to the concept of analogical inno - vation , an important mechanism of creativity [ 2 , 6 ] . It can also be seen as a transfer operation , where A is a source situation with a solution B , and C is a target situation for which we want the solution . The notion of analogy is particularly useful in this setting as it leverages simultaneously the similari - ties and diﬀerences between A , B , C to adapt B to the target situation C and obtain the solution . The Alea algorithm [ 8 ] relies on the number of character occurrence in A , B , C to determine the characters occurring in D the solution to the ana - logical , and proposes a Monte - Carlo estimation of the permutation of these characters to solve the AP equation . More speciﬁcally , [ 8 ] follows the results of [ 36 ] about closed form solutions and proposes a Monte - Carlo estimation of the solutions of an analogical equation by sampling among multiple sub - transformations . With bag ( A ) being the set of all characters in A , Alea considers bag ( D ) = ( bag ( B ) − bag ( A ) ) + bag ( C ) and thus D is a permutation of the characters of bag ( D ) . For example , the solution of cat : cats : : animal : x , x = animals is a permutations of the characters { a , a , i , l , m , n , s } , which can be obtained from the characters in cats but not in cat ( i . e . , { s } ) together with the characters of animal ( i . e . , { a , a , i , l , m , n } ) . This process cannot han - dle mechanisms like reduplication ( repeating part of a word ) that requires more complex comparisons between character occurrences . A similar approach was later proposed in [ 37 ] , using the postulates of [ 30 ] to address multiple characteristics of words , such as their length , the occurrence of characters and of patterns . Based on these features , the author proposes Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 7 an algorithm to solve analogies between character strings by ﬁrst extract - ing relevant features , then estimating the position of each character using an arithmetic on character positions , and ﬁnally generating the corresponding word . The method accounts for multiple potential solutions by comparing the predicted word with permutations of its characters . A more empirical approach which does not rely on the axioms of APs was proposed by [ 12 ] , and considers some transformation f such that B = f ( A ) and f ( C ) is computable . Following the observation that humans tend to use the simplest thinkable analogy to solve analogical equations [ 12 , 23 ] , the simplest transformation f is found by minimizing its Kolmogorov complexity . This is done by generating f by combining simple operations ( insertion , deletion , etc . ) and computing the length of the resulting program . With this process , not only obtain the solution of the AP equation but also the transformation f is obtained . Additionally , Kolmo is able to handle more complex mechanisms than Alea including reduplication . In [ 10 , 11 ] , a retrieval approach was proposed for semantic APs and later adapted to morphological APs in [ 15 , 17 ] . Similarly to the analogy detection approach proposed by the authors ( see Subsubsection 2 . 3 . 1 ) , the analogy solv - ing approach relies on pre - trained embeddings . An artiﬁcial neural network is used to predict the embedding of a solution , and the corresponding word is retrieved from a list of possible words based on its embedding . A similar neu - ral network is detailed in Subsubsection 3 . 2 . 2 and Figure 1 under the name Analogy Neural Network for retrieval / generation ( ANNr ) . Recently , [ 38 ] proposed a generation framework to solving sentence analo - gies . They use an autoencoder model ( named ConRNN ) trained to reconstruct sentences , and perform simple arithmetic operations on the embedding space to solve analogies . Once the analogy between embeddings is solved , the decoder part of ConRNN is used to generate the solution from the predicted embed - ding . Their model is a sequence - to - sequence model composed of 2 elements . First , a sentence ( as a sequence of words ) is used as input to an encoder RNN , and the last hidden state of the RNN is used as the sentence embedding . The latter is then fed to a decoder RNN that tries to predict the words of the input sentence . The use of a generative model achieves signiﬁcantly better results than the nearest neighbor algorithm on the same embedding space . With a similar sequence - to - sequence autoencoder ( AE ) model as [ 38 ] , we proposed in [ 16 ] an approach to generate words at the character level , and using simple vector arithmetic we achieved signiﬁcant performance improvement over base - lines on solving morphological AP equations . One of the aims of this paper is to further improve the performance by integrating the ANNr approach developed in [ 10 , 11 , 17 ] with the AE model . 3 Models In this section we describe the models as well as key technical details from our previous experiments [ 13 – 17 ] . Our framework can be split into two groups of Springer Nature 2021 L A TEX template 8 Solving morphological analogies : from retrieval to generation models , namely the embedding models and the analogy models , summarized in Figure 1 . To obtain suitable representations of words , we use two diﬀerent kinds of embedding models described in Subsection 3 . 1 : an embedding model designed for morphological applications and inspired from [ 39 ] and an autoen - coder ( AE ) model following a traditional sequence to sequence approach . To detect and solve analogies , we rely on the two learned models described in Subsection 3 . 2 : the Analogy Neural Network for classiﬁcation ( ANNc ) and Analogy Neural Network for retrieval / generation ( ANNr ) , which were initially introduced in [ 10 ] and reﬁned along our experiments . In addition to these , we experiment with multiple non - parametric approaches such as the parallelogram rule and 3CosMul [ 40 ] that we will also describe in Subsection 3 . 2 . A ﬁrst aspect of our framework that leverages the axiomatic setting of APs is the architecture of our two analogy processing models ( ANNc and ANNr ) , which is based on intuitions driven by the axiomatic setting as described in Subsection 2 . 1 . The second aspect that relies on the axiomatic setting is the data augmentation described in Subsubsections 3 . 3 . 3 and 3 . 3 . 4 , as it enables training models to ﬁt the formal postulates of AP by becoming invariant to them . 3 . 1 Embedding models An important part of many machine learning systems is ﬁnding features rel - evant to the task to accomplish and using the features to represent the data . In deep learning , this task is usually handled by a family of approaches called embeddings , real - valued vector representations of the data obtained by learn - ing an embedding model from data . It is commonly accepted that the quality of such representations , which corresponds to the amount and nature of the infor - mation contained in the embedding as well as the properties of the embedding space , is a key factor in the performance of deep learning approaches . Learn - ing an embedding model of high quality often requires high amounts of data and signiﬁcant training time which can be challenging , so for many applica - tions on text pre - trained large - scale embedding models are made available , for instance , Bert [ 41 ] . However , in our early experiments with pretrained word embeddings models ( in particular , GloVe [ 35 ] , word2vec [ 42 ] , and fasttext [ 43 ] ) we obtained poor performance 1 , which can be easily understood as these mod - els contain information of a semantic nature 2 while we need morphological information to deal with morphological APs . To solve this issue , we used with two diﬀerent embedding models : a model inspired from [ 39 ] , using a convolutional neural network ( CNN ) [ 44 ] , and a model based on the autoencoder ( AE ) technique [ 45 ] and Long - and Short - Term Memory network ( LSTM ) [ 46 ] . 1 We reproduced a similar experiment on the English data in Subsection A . 2 . 2 To be exact , these models relate to distributional semantics , which is based on the co - occurrence of words in text . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 9 Fig . 1 Morphological embedding models , data augmentation , analogy classiﬁcation ( ANNc ) and analogy retrieval ( ANNr ) models . 3 . 1 . 1 CNN - based embedding model The CNN - based model learns to detect key morphological patterns from the characters forming a word . To do so , the input of the model are the char - acters of a word . First , the characters are embedded into vectors of size m learned together with the rest of the word embedding model . As schematized in Figure 1 , multiple CNN ﬁlters are used , and each ﬁlter goes over the char - acter embeddings by spanning over the full embeddings of 2 to 6 characters , resulting in ﬁlter sizes between 2 by m and 6 by m . For each ﬁlter , the model computes the maximum output to serve as a component of the word embed - ding . We use 16 ﬁlters of each size between 2 to 6 , resulting in embedding of 80 Springer Nature 2021 L A TEX template 10 Solving morphological analogies : from retrieval to generation components . This last operation keeps only salient patterns detected by each of the ﬁlters , and forces each CNN ﬁlter to specialize in identifying a speciﬁc pattern of characters . By using character embeddings to encode character fea - tures , the model is able to capture patterns based on character such as “ - ing” but also based on features of characters like “vowel - vowel - consonant” . This ﬂexibility is useful to deal with phenomena like euphony which is , in very sim - ple terms , a change of sound to make a word easier to pronounce ( e . g . , far becomes further when adding the suﬃx - ther ) . These character patterns cor - respond to morphemes , which are the minimal units of morphology . As the main components of this embedding model are CNN ﬁlters , we coin it the CNN - based model . When used for analogy solving , the CNN - based model does not allow us to use an arbitrary embedding to generate the solution . Instead , we need to compute the embeddings of a list of candidate words and select the most relevant word accordingly , making the space of solution closed . This property is not an issue when working in a closed - world assumption ( i . e . , we know all the solution candidates , and no solution outside of these is accepted ) , but in an open - world assumption , we would theoretically have to compute the embeddings of all possible character strings , which is not feasible . 3 . 1 . 2 AE embedding model Our AE model stems from the above - mentioned limitation of the CNN - based model for analogy solving . To tackle this issue , we use an AE model that learns the embedding of a word from its characters and learns to generate word from embeddings . An AE can be seen as a lossy compression algorithm , composed of an encoder and a decoder . Taking an example in our setting , the encoder compresses the information of a word into an embedding and the decoder decompresses the embedding back into a word . In order to properly decode the embedding ( and to minimize the compression loss in our compression algo - rithm analogy ) , the model is trained to encode words and then decode the resulting embedding back into the original word . The diﬀerence between the original and the decoded word is used as the training objective in the autoen - coding task . Because the model is able to recreate the original word from the embedding , the latter contains the key information to represent the former . In more details , the decoder will learn to reproduce systematic or redundant parts of the training data without relying on the embedding , while key information to diﬀerentiate the training are encoded in the embedding by the encoder . The architecture for our model is a character - level sequence - to - sequence autoencoder model , based on the model described in [ 47 ] . We use Long - and Short - Term Memory network ( LSTM ) [ 46 ] , which are neural networks designed to handle sequences , and which allow us to encode and decode embeddings of a constant size no matter the length of the word , which we see as a sequence of characters . Indeed , in our setting we need morphological information , which requires knowing the characters composing a word . Each character of a word Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 11 is encoded into a one - hot vector 3 and fed into the encoder , which is a Bidirec - tional LSTM ( BiLSTM ) [ 48 ] , a variant of the LSTM that reads the elements of the input sequence in the forward and backward order simultaneously . This layer outputs four vectors : the last hidden state h f and cell state c f in the forward direction , and similarly h b and c b for the backward direction . The concatenation of these vectors e w = concat ( h f , h b , c f , c b ) is the embedding of the word . The decoder is an LSTM followed by a fully connected layer ( or perceptron or dense layer ) with softmax activation . The input for the ﬁrst step of the decoder is the above - mentioned embedding , split into two states h = concat ( h f , h b ) and c = concat ( c f , c b ) . The output of the decoder is a sequence of character predictions , with each prediction being a probability dis - tribution over all the characters seen in training obtained with the softmax activation . The process of decoding is usually a step by step process where each char - acter of the output is predicted one after the other , with the previous character used as input to predict the next one . The ﬁrst character is primed with beginning of word ( BOW ) character that marks the start of the word , and prediction is stopped when we encounter an end of word ( EOW ) character . During training , we accelerate training by using teacher forcing , a variant of this decoding process where the characters of word to predict are used in place of the predicted characters as input for the next steps as illustrated in Figure 1 . 3 . 2 Models for analogy processing To manipulate APs , we propose multiple neural network models , building upon the embedding models . Here we describe the structure and inner workings of these models , as well as how to use them for analogy detection and analogy solving . We also describe three approaches that do not rely on neural net - works to solve AP equations , namely , 3CosAdd [ 42 ] and 3CosMul [ 40 ] , and the parallelogram rule . 3 . 2 . 1 Analogy detection using ANNc The Analogy Neural Network for classiﬁcation ( ANNc ) follows the idea that a quadruple A , B , C , D constitutes a valid analogy A : B : : C : D if A and B diﬀer in the same way as C and D . If this is true for all the features of A , B , C , D , i . e . , for all dimensions of the embeddings e A , e B , e C , e D , then the analogy is true . The model we use is based on multiple CNN layers taking as input e A , e B , e C , e D , each of size n , stacked into a n × 4 matrix . Then , a ﬁrst set F 1 of CNN ﬁlters of size 1 × 2 is applied on the embeddings , such that for each component · i of the embedding vector , each ﬁlter spans across A i and B i simultaneously , and across C i and D i simultaneously , with no overlap . A second set F 2 of CNN ﬁlters of 2 × 2 is applied on the resulting | F 1 | × n × 2 3 A one - hot encoding vector of an element x i for a set { x 1 , . . . , x n } is a vector of size n containing 0 for all components except component i which is 1 . Springer Nature 2021 L A TEX template 12 Solving morphological analogies : from retrieval to generation tensor . Each ﬁlter in the second set of ﬁlters moves along the embedding dimen - sion one component at a time , as illustrated in Figure 1 , thus resulting in a | F 2 | × ( n − 1 ) × 1 tensor . For all CNN ﬁlters , the activation function is ReLU . Finally , the output of the second group of ﬁlters is fed to a fully connected layer with a single output that we bind between 1 and 0 using a sigmoid acti - vation . This ﬁnal output serves as a classiﬁcation score , with 0 for “not an AP” and 1 for valid APs . Intuitively , the ﬁrst set of CNN ﬁlters extracts the relations A : B and C : D and the second set compares A : B and C : D , which can be seen as the predicate “as” in “ A is to B as C is to D ” . Additionally , while it is possible to assume that embedding dimensions are independent from each other , it is rarely the case in practice . To handle dependent dimensions , the second set of ﬁlters have a size of 2 which results in overlaps between adjacent embedding dimensions , and the fully connected layer mixes the results of all ﬁlters from F 2 over all dimensions . 3 . 2 . 2 Analogy solving using ANNr An approach to solving A : B : : C : x is to ﬁnd how e B diﬀers from e A and to generate an e x that diﬀers from e C in the same way . Central permutation ( see Subsection 2 . 1 ) allows us to apply the same operations on A : C : : B : x , to obtain e x from e B using the diﬀerence between e A and e C . The Analogy Neural Network for retrieval / generation ( ANNr ) follows this intuition by using a two step process illustrated in Figure 1 . First , two separate fully connected layers f 1 , f 2 with ReLU activation are applied respectively on the concatenation of A and B and the concatenation of A and C . Intuitively , these layer determine the relation between e A and e B on the one side while keeping the key content of e B , and similarly for e A , e C the other side . Then , the concatenation of the outputs of f 1 and f 2 is fed into a last fully connected layer f 3 without activation , which generates e x the embedding of the predicted x . In preliminary experiments , we observed that using diﬀerent weights for f 1 , f 2 achieved better performance than sharing the weights ( which would result in a siamese architecture ) . This indicates a need for asymmetry between the relations between A and B and between A and C , and goes in the direction of relaxing the central permutation axiom . 3 . 2 . 3 Analogy solving with the parallelogram rule As mentioned in Subsection 2 . 1 , the parallelogram is one of the inspirations of the axiomatic setting of APs and has been used to solve APs since early works on word embeddings [ 42 , 49 ] . To compute the solution of an AP equation A : B : : C : x , the embeddings e A , e B , and e C are computed by the embedding model and used to compute e x = e B − e A + e C . Then , e X is used to ﬁnd the word X solution to the analogy . With the AE embedding model , x is obtained using the decoder and with the CNN - based model retrieval is used instead . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 13 3 . 2 . 4 Analogy solving with 3CosAdd or 3CosMul 3CosAdd [ 42 ] and 3CosMul [ 40 ] are retrieval approaches to solve AP equations within an embedding space and are often used even if they have known lim - itations . As retrieval approaches , both methods rely on the embeddings of candidate solutions to solve the equation . In [ 17 ] , we report results of 3CosAdd and 3CosMul applied on the embeddings trained with ANNc to measure the improvement brought by ANNr . 3CosAdd ( 4 ) can be seen as the parallelogram rule combined a cosine similarity to recover the closest solution . 3CosMul ( 5 ) maximizes a similarity built upon the cosine . Intuitively , the formula the angle between B and D on one side and the angle between C and D on the other side , and normalizes the result by the angle between A and D . In this read - ing of the formula , 3CosMul shares a similar intuition as ANNr . To avoid a 0 denominator , a small ε is added in ( 5 ) : 3CosAdd = argmax e D cos ( e D , e B − e A + e C ) , ( 4 ) 3CosMul = argmax e D cos ( e D , e B ) cos ( e D , e C ) cos ( e D , e A ) + ε . ( 5 ) We refer the reader to [ 40 ] for a detailed description of 3CosAdd and 3CosMul . 3 . 2 . 5 Analogy solving using ANNc It is also possible to use ANNc to solve analogies , by maximizing the clas - siﬁcation score over possible solutions . This method is most adapted to a retrieval approach , but it is possible to envision generating candidate solutions ( for instance , in as was done in Alea ) or even to maximize the classiﬁcation score in a machine learning generation algorithm ( for example , using a genetic algorithm ) . 3 . 3 Pre - training , training and evaluation In this subsection , we ﬁrst explain in Subsubsections 3 . 3 . 1 and 3 . 3 . 2 how to pre - train our embedding models , and detail the technical aspects of training our analogy detection and analogy solving models in Subsubsections 3 . 3 . 3 and 3 . 3 . 4 respectively . Pre - training is a wide - spread approach for embedding models , which consists of two steps : ﬁrstly , the embedding model is pre - trained on general - purpose data or data of the target domain , and secondly , the embedding model is transferred to serve as a component of the ﬁnal model on the target task . For instance , it is possible to transfer a part of a model and reuse it as a com - ponent of a larger model , as is usually done with large pretrained embedding models such as Bert [ 41 ] , wav2vec2 [ 50 ] , or vision transformers [ 51 ] . Then , it is possible to either train only the new part of the ﬁnal model , but it is also possi - ble to ﬁnetune the embedding model during the training . The pre - training and Springer Nature 2021 L A TEX template 14 Solving morphological analogies : from retrieval to generation ﬁnetuning approach allows to ﬁrst bring the embedding model to a globally viable state before specializing it on the task . Further details on the training hyperparameters are provided in appendix Subsection A . 1 . 3 . 3 . 1 Pre - training the CNN - based embedding model In [ 15 ] we conﬁrmed the beneﬁts of pre - training the CNN - based embedding model before analogy solving with ANNr . The CNN - based embedding is not designed for a standalone pre - training , therefore it is pre - trained on the analogy detection task with an ANNc model , following the ANNc training procedure described below . 3 . 3 . 2 Pre - training the autoencoder embedding model This subsubsection summarizes the task and criterion for pre - training the AE embedding model , following [ 16 ] . Autoencoding task . AEs are designed to be trained on an autoencoding task ( AE task ) . The prin - ciple of this task is , in our setting , to present a training dataset containing words to the model . The AE is then trained to encode - decode each word of the training dataset , and to minimize the error in the predicted word . Training criterion . We use the Cross - Entropy ( CE ) loss to train the AE , as it is the common way to train a model where each output is one among a series of class . In the following formula , we write L AE the loss used for our AE , which is exactly the CE loss but re - written in our setting : L AE ( D , decoder ( e x ) ) = − 1 | D | | D | (cid:88) i = 1 (cid:88) c ∈ V D c , i log ( decoder ( e x ) c , i ) , ( 6 ) where | D | is the number of characters to predict including the EOS character , V is the character vocabulary ( the set of characters present in the training data ) , D c , i is 1 it the i - th character of D is c and 0 otherwise , decoder ( e x ) is the decoder output and decoder ( e x ) c , i is the predicted probability that the i - th character of the prediction is c . 3 . 3 . 3 Training ANNc Here we summarize the training process of ANNc that achieved the most competitive performance , but further details can be found in [ 13 , 15 ] . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 15 Data augmentation . The axioms of APs described in Subsection 2 . 1 enable the generation multiple valid APs ( positive examples ) and invalid APs ( negative examples ) from each AP in our analogy dataset . This process is a data augmentation process that extends the amount of data available for training , and is necessary to obtain the negative examples required for training the classiﬁer . Finally , it allows the models to learn how to ﬁt the formal postulates of AP by becoming invariant to them . By using the symmetry and central permutation axioms , we are able to generate 7 more valid APs from a valid AP A : B : : C : D , namely , A : C : : B : D , D : B : : C : A , C : A : : D : B , C : D : : A : B , B : A : : D : C , D : C : : B : A , B : D : : A : C . From each of these valid APs , we can generate invalid APs that are in conﬂict with at least one axiom , following [ 10 , 11 ] . Given a valid AP A : B : : C : D , we generate the following invalid APs : B : A : : C : D , C : B : : A : D , and A : A : : C : D , for a total of 24 invalid APs . In practice , data augmentation is applied after the embedding model , as shown in Figure 1 . In the experiments reported in [ 15 , Appendix B ] , we identiﬁed that training ANNc with an imbalance between the positive and the negative examples resulted in a corresponding imbalance in the performance on the two classes of examples . Additionally , we identiﬁed that some invalid APs we generate have the form of valid APs , for instance when using sang : sang : : was : were ( with the underlying relation of going from the 1st to the 3rd person of singular ) , the invalid AP generation rule A : B : : C : D → A : A : : C : D produces sang : sang : : was : were , which we consider valid . To tackle these issues , we use the following data augmentation process : 1 . given an AP A : B : : C : D we compute the set of 8 valid and the set of 24 invalid APs mentioned above ; 2 . we remove APs from the invalid APs that have the same form as any of the valid APs ; 3 . if we have more than 8 invalid APs remaining , we sample without replacement 8 invalid APs from the ﬁltered set ; 4 . if we have less than 8 invalid APs remaining , we take the ﬁltered set of invalid APs and add the missing amount of APs by randomly sampling them with replacement from the ﬁltered set of invalid APs ; this process allows us to have at least one instance of each invalid AP . Training criterion . To train ANNc we use the Binary Cross - Entropy ( BCE ) loss which is a standard for binary classiﬁcation , and is written as follows : L ANNc ( y , y pred ) = − y log ( y pred ) − ( 1 − y ) log ( 1 − y pred ) = (cid:40) − log ( y pred ) if y = 1 , − log ( 1 − y pred ) otherwise , ( 7 ) Springer Nature 2021 L A TEX template 16 Solving morphological analogies : from retrieval to generation where y is the true class ( 1 or 0 ) and y pred is the predicted probability for class 1 ( i . e . , the probability that the AP is valid , the classiﬁcation score ) . 3 . 3 . 4 Training ANNr Here we summarize the key elements we use to obtain the best results with ANNr . Further details on the training process can be found in [ 17 ] . Data augmentation . To train ANNr , we use a similar data augmentation process as for ANNc , but considering only the valid APs . In other words , given an AP equation A : B : : C : x , x = D , we generate 7 other AP equations : A : C : : B : x , x = D , D : B : : C : x , x = A , C : A : : D : x , x = B , C : D : : A : x , x = B , B : A : : D : x , x = C , D : C : : B : x , x = A , B : D : : A : x , x = C . Training criterion . When ﬁne - tuning the embedding model while training ANNr , it is possible to observe collapse of the embedding space if the criterion is badly chosen : for instance , when using the mean squared error ( MSE ) ( or L 2 distance , see Equation ( 8 ) ) , it is possible for the model to move all the embeddings in a smaller area of the embedding space by multiplying them by 10 5 ; while this minimizes the MSE , it does not improve retrieval performance as the relative distance between embeddings does not change . MSE ( e D , e x ) = 1 n (cid:88) i ∈ [ 1 , n ] ( e D , i − e x , i ) 2 , ( 8 ) where e D , i is the i - th component of e D and n is the number of dimensions of the embeddings . In [ 17 ] we experimented with multiple training objectives designed to avoid this phenomena . In the present work we consider only the most successful one , called L norm . random in [ 17 ] that we rename L ANNr for clarity : L ANNr ( e D , e x ) = 1 + MSE ( e D , e x ) 1 + MSE ( batch shuﬄe ( e D ) , e x ) . ( 9 ) As the model is trained with batches of randomly selected samples , we asso - ciate each prediction with an unrelated embedding by permuting e D along the batch dimension ( batch shuﬄe ( e D ) in Equation ( 9 ) ) . Intuitively , we encour - age the prediction e x of ANNr to be close to the actual e D and far from other embeddings by normalizing MSE ( e D , e x ) based on distances between other embeddings . Inference . When used with the CNN - based embedding model , we do not have direct access to the word corresponding to the embedding predicted by ANNr . We Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 17 consider all the words appearing in the non - analogical data as candidates for retrieval , which includes words that do not appear in any analogy , and retrieve the closest one based on the cosine distance between the ANNr prediction and the embedding of each candidate word . Previous experiments [ 15 ] showed that cosine distance slightly outperforms euclidean distance in that setting . Training ANNr when using the CNN - based embedding model . As reported in [ 17 ] , we obtained the best results by ﬁrst training only ANNr without ﬁnetuning the embedding until ANNr converges ( i . e . , untill there is no improvement in the loss on the devlopement data ) , then training both models together . We limited the total training time to 50 epochs including both phases . Training ANNr when using the AE embedding model . When training ANNr while ﬁnetuning the AE embedding model , we add a generation loss term L AE to the training loss of the ANNr . In other words , L AE + ANNr is a convex combination of L ANNr and L AE . This allows us to maintain good decoding performance and to make use of the diﬀerences between the predicted and expected embedding to guide ANNr at the begin - ning of training . The L AE ( e D , e x ) used here is the same as the one used to pre - train the AE : L AE + ANNr ( e D , e x ) = ( 1 − λ ) L ANNr ( e D , e x ) + λ L AE ( D , decoder ( e x ) ) . ( 10 ) The parameter λ = min ( max ( epoch / 5 , 0 . 01 ) , 0 . 99 ) evolves during training , such that at the beginning of the training ( λ = 0 . 99 ) ANNr is training almost alone and the AE performance is not altered , and after 5 epochs , only the AE loss is used ( λ = 0 . 5 ) , following that better performance is obtained by ﬁrst training only ANNr [ 17 ] . In our early experiments , we attempted to use only L AE ( D , decoder ( e x ) ) as the criterion for analogy solving with AE + ANNr , but achieved poor per - formance . More speciﬁcally , the models got stuck in poor local optima at the beginning of training that resulted in the degradation of the quality of the AE while not reaching satisfying analogy solving performance . 4 Experiments In this section we report and discuss the performance of our framework on analogy solving . We compare multiple variants of our analogy solving approach and two baselines on morphological analogies in 16 languages of the Siganalo - gies [ 25 ] dataset we describe in Subsection 4 . 1 . This section focuses on latest results on analogy solving presented in Subsection 4 . 4 , but we also report addi - tional results on the pre - training of the AE and CNN embedding models in Subsections A . 3 and A . 4 . For extended studies on the behavior of the ANNc models , we refer the reader to [ 13 – 15 , 18 ] . We summarize the key ﬁndings of these works in Section 5 . Springer Nature 2021 L A TEX template 18 Solving morphological analogies : from retrieval to generation 4 . 1 Multilingual morphological analogies data The Siganalogies [ 25 ] we proposed in previous work is built upon three datasets described below . We brieﬂy survey the original datasets as well as the process used to generate analogies . Siganalogies is a dataset of morphological analogies built upon Sigmorphon 2016 [ 52 ] , Sigmorphon 2019 [ 53 ] , and the Japanese Bigger Analogy Test Set ( JBATS ) [ 54 ] . However in our experiments we only consider data from Sigmorphon 2016 and Sigmorphon 2019 . A more detailed description of the Siganalogies dataset , including the number of analogies for each language , can be found on the GitHub page of the datase 4 . Data from Sigmorphon 2016 and Sigmorphon 2019 The Sigmorphon shared tasks are a series of shared tasks focusing on tackling morphology - related tasks on multiple languages . The Sigmorphon 2016 [ 52 ] shared task focuses on morphological reinﬂec - tion , which consists in applying an inﬂexional morphological transformation on a word that may already be the result of such a transformation . Taking the example from the authors of the task , going from “ran” to “running” cor - responds to a transformation from ( some person of ) the past to the present participle of “to run” . The dataset covers 10 languages , namely Spanish , Ger - man , Finnish , Russian , Turkish , Georgian , Navajo , Arabic , Hungarian , and Maltese , which are “mostly languages with rich inﬂection” by the own words of the authors of [ 52 ] . The data is extracted from Wikitionary and underwent cleaning and other preprocessing steps . Sigmorphon 2016 contains 3 tasks , namely inﬂection ( task 1 ) , reinﬂection ( task 2 ) and unlabled reinﬂection ( task 3 ) . In our experiments we focus on the data for the inﬂection task , which contains triples such as “run , present participle , running” , although the mor - phological transformation is speciﬁed in more details . To do so we use a similar process as [ 37 ] by combining triples that share the same morphological trans - formation , for example if we have “dance , present participle , dancing” we can combine the two triple to obtain “run : running : : dance : dancing” . A similar process can be applied to the other two tasks . The Sigmorphon 2019 [ 53 ] shared task aims for “universal morphological inﬂection” and covers close to 100 languages . Once again , 3 tasks are proposed , namely crosslingual transfer for inﬂection generation ( task 1 ) and morpho - logical analysis and lemmatization in context ( task 2 ) , as well as a task for competing on previous editions of Sigmorphon . Here we focus only on task 1 , which was to leverage large amounts of data from a high resource lan - guage to perform morphological inﬂection on a low resource language with little amounts of data . The data contains pairs of high resource with low resource languages . For each language , the data contains pairs of words and the corresponding morphological transformation , as for task 1 of Sigmorphon 2016 . 4 https : / / github . com / EMarquer / siganalogies / blob / main / siganalogies description . pdf Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 19 Data from the Japanese Bigger Analogy Test Set The Japanese Bigger Analogy Test Set ( JBATS ) [ 54 ] is an analogy dataset covering 4 categories of relations : derivational and inﬂexional morphology as well as lexicographic and encyclopedic semantics . It was initially designed to evaluate the performance of the sub - character and character level embedding models in Japanese . Both morphological categories contain pairs of words sharing the same morphological transformation , that can be manipulated in a similar way as the Sigmorphon data . For each second word of the pair , a kanji form and an hiragana / katakana form are provided to cover possible alternate writings . In previous studies , both writing were considered without distinction , but further experiments in that regard would be interesting in further work . Siganalogies Siganalogies [ 25 ] covers more than 80 languages , however not all of them are suited for our study . Our language selection process is done in two steps that we detail in the following paragraphs : we ﬁrst exclude languages that do not have enough training analogies , then we train an AE model on each of the remaining languages and keep only languages with above 80 % accuracy for the AE task . We ﬁrst put aside languages in Sigmorphon 2019 that do not contain enough analogies for training the models , namely the low resource languages as well as Basque and Uzbeck , as they contain less than 50000 analogies in the training set . We also exclude Japanese as it contains kanjis , which require sig - niﬁcantly diﬀerent hyperparameters to achieve acceptable performance . Note that some languages appear in both Sigmorphon 2016 and Sigmorphon 2019 , but are counted as separate languages . Indeed , the pre - processing done in these two editions of Sigmorphon is not the same , in particular with regards to alphabets : in Sigmorphon 2016 everything is transformed in the Latin alphabet while in Sigmorphon 2019 the original alphabet is kept . At this step , we have 52 languages remaining : 10 languages from Sigmor - phon 2016 and the remaining 42 from Sigmorphon 2019 , with 6 languages ( Arabic , Finnish , German , Russian , Spanish , and Turkish ) appearing in both groups . The AE is trained on each of the remaining languages , with 5 diﬀer - ent training / test split and 10 random initialization per model , for a total of 2600 models ( 5 × 10 × 50 ) . The accuracy of the AE is detailed in Table A4 in appendix . For experiments beyond training the AE on each language , we only consider 10 models trained on the ﬁrst data split and only languages where the AE achieved an accuracy above 80 % on the AE task . The apparent discrepancies between the performance reported in Table A4 and the languages we selected ( in particular for Portuguese in Sigmorphon 2019 and Russian in Sigmorphon 2016 ) come from the diﬀerences in performance between the ﬁrst data split and the other 9 splits , which can be appreciated from the large standard deviation reported . Springer Nature 2021 L A TEX template 20 Solving morphological analogies : from retrieval to generation We end up with 16 languages : Turkish , Hungarian , and Georgian of Sigmorphon 2016 , and Adyghe , Arabic , Bashkir , English , French , Hebrew , Por - tuguese , Sanskrit , Slovak , Slovene , Swahili , Welsh , and Zulu from Sigmorphon 2019 . 4 . 2 Training , development and test data In our experiments , we use the standard of three dataset splits : the training set containing the examples learned by the model , the development set con - taining examples not seen during training and used to identify overﬁtting and interrupting the training when the performance stops increasing , and ﬁnally the test set to measure the ﬁnal performance , with examples that appear in neither the training or devlopement set . For APs , we follow the training and test split from Sigmorphon 2016 [ 52 ] , Sigmorphon 2019 [ 53 ] , and JBATS [ 54 ] when possible , and split the training set into our training and developement analogies . We exclude duplicates of the form A : B : : C : D ↔ C : D : : A : B ( corresponding to the axiom of symmetry ) but we keep analogies of the form A : B : : A : B . We randomly sample 500 development and 5000 test APs and at most 50000 training APs . For the AE task , we consider all the words appearing in training and test data from Sigmorphon and JBATS , which includes words that do not appear in any AP ( either because the AP is not used , or because there is no two pair of with the same morphological transformation containing the aforementioned word ) . We randomly sample 500 development and 500 test examples , and at most 40000 training examples , with no overlaps between the sets . 4 . 3 Analogy solving models Our framework allows us to propose both retrieval - based models and generation - based models , that we compare with two baseline symbolic approaches : the Alea approach from [ 8 ] as implemented in [ 12 ] , and the Kolmo approach from [ 12 ] . We consider 3 the retrieval model variants using the same CNN - based embedding model pre - trained using ANNc on analogy detection : CNN + ANNc , CNN + 3CosMul , and CNN + ANNr . CNN + ANNc corre - sponds to re - using both models without ﬁne - tuning on the retrieval task , as mentioned in Subsubsection 3 . 2 . 5 . CNN + 3CosMul uses the 3CosMul [ 40 ] approach on the embeddings obtained with the CNN - based model , once again without ﬁne - tuning . Finally , in CNN + ANNr the embedding model is ﬁne - tuned together with the ANNr , as described in Subsubsection 3 . 3 . 4 . The CNN + 3CosMul and CNN + ANNc retrieval models serve as a baseline to mea - sure the improvement brought by using ANNr in a retrieval approach . In [ 17 ] we used the 3CosMul [ 40 ] and 3CosAdd [ 42 ] approaches as baselines for our CNN + ANNr approach and showed signiﬁcant improvements when using CNN + ANNr . However , it can be argued that embeddings trained for analo - gies using ANNc encode relevant features in a way that is hard to manipulate Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 21 with 3CosMul and 3CosAdd . We compare CNN + ANNc with CNN + 3CosMul to measure this eﬀect , excluding 3CosAdd which performed worse than 3Cos - Mul in our previous studies . We also compare CNN + ANNc with CNN + ANNr to ascertain the beneﬁt of training an ANNr model when the setting is limitted to retrieval . In [ 16 ] we explored the potential of a character - level AE for analogy solv - ing , using a similar approach as [ 38 ] that we call AE + parallel here . Following the same approach , we pre - train an AE on our data without analogies then compute the embedding of the solution using the parallelogram rule ( Sub - subsection 3 . 2 . 3 ) , and ﬁnally we use the decoder of the AE to generate the predicted solution word . The last model we experiment with is AE + ANNr which combines the AE embedding model with ANNr to achieve higher performance . 4 . 4 Analogy solving performance To evaluate the performance of all analogy solving models we use the accuracy . For retrieval models , this corresponds to top - 1 retrieval accuracy , additionally hit rate at k for k ∈ { 1 , 3 , 5 , 10 } are listed in appendix Subsection A . 5 . For generative models , we use word accuracy b taking only the most likely predic - tion for each character , additionally character accuracy and other metrics are available in the detailed model outputs . The retrieval and generative models performance are reported in Table 1 and Table 2 respectively , with Table A5 in appendix comparing the results of both approaches in a single table . In this work we only consider models trained on a single language , and we discuss the possibility of a multilingual model in Section 5 General observations . A ﬁrst striking result is that the embedding based approaches outperform the symbolic baselines in all settings using ANNr and in most settings with CNN + 3CosMul , CNN + ANNc , and AE + parallel . This result is not surprising , as there is a well known trade - oﬀ between the performance of deep learning and the explainability of symbolic approaches . In particular , the contribution of Kolmo [ 12 ] to explainability is clear as it explicitly provides the underly - ing transformation used to solve the analogy . However , the contribution of Alea is more subtle as its main contribution in that regard are the theoretical grounding of the method and the ability to limit the space of solutions . Performance of the symbolic baselines . The baseline generation models have very low performance on Arabic , while the deep learning models do not appear to suﬀer from the same eﬀect . As reported in [ 16 ] , further analysis of the Arabic data reveals that the character encoding used decomposes each character into multiple encoded characters , resulting in longer and more complex sequences of characters than expected . However , on Slovene the performance is also very low even if the characters Springer Nature 2021 L A TEX template 22 Solving morphological analogies : from retrieval to generation Table 1 Analogy solving accuracy ( rate of fully well predicted words , in % ) in the retrieval setting ( closed world assumption ) , compared to the best generation model ( AE + ANNr ) . For models depending on an embedding model , and thus sensitive to random initializations , we report performance as mean ± standard deviation over 10 random initialization in each setting . Retrieval models Best gen . model Language CNN + ANNr CNN + 3CosMul CNN + ANNc AE + ANNr Sigmorphon 2016 Georgian 97 . 60 ± 0 . 23 85 . 58 ± 7 . 37 76 . 77 ± 9 . 57 87 . 50 ± 2 . 08 Hungarian 89 . 06 ± 1 . 71 74 . 89 ± 5 . 27 72 . 95 ± 8 . 02 90 . 58 ± 0 . 63 Turkish 84 . 75 ± 2 . 04 52 . 42 ± 4 . 33 44 . 43 ± 13 . 95 79 . 81 ± 8 . 58 Sigmorphon 2019 Adyghe 93 . 37 ± 0 . 97 58 . 01 ± 8 . 66 80 . 11 ± 5 . 10 98 . 50 ± 0 . 25 Arabic 72 . 08 ± 3 . 49 21 . 67 ± 5 . 44 40 . 73 ± 9 . 93 83 . 99 ± 1 . 28 Bashkir 57 . 63 ± 5 . 48 37 . 76 ± 11 . 12 65 . 38 ± 6 . 01 95 . 15 ± 0 . 92 English 92 . 29 ± 0 . 91 66 . 83 ± 15 . 67 65 . 51 ± 6 . 25 92 . 29 ± 4 . 57 French 93 . 15 ± 0 . 96 80 . 37 ± 7 . 97 62 . 87 ± 17 . 65 88 . 25 ± 2 . 24 Hebrew 66 . 52 ± 2 . 59 15 . 47 ± 10 . 12 36 . 10 ± 4 . 28 92 . 50 ± 0 . 25 Portuguese 93 . 12 ± 1 . 10 58 . 52 ± 18 . 48 70 . 53 ± 9 . 88 93 . 11 ± 8 . 32 Sanskrit 64 . 18 ± 2 . 62 33 . 20 ± 9 . 34 42 . 59 ± 4 . 88 91 . 48 ± 0 . 78 Slovak 56 . 23 ± 4 . 57 49 . 43 ± 3 . 13 39 . 58 ± 3 . 37 78 . 90 ± 0 . 86 Slovene 71 . 99 ± 2 . 24 57 . 79 ± 8 . 59 51 . 88 ± 6 . 69 82 . 41 ± 10 . 98 Swahili 68 . 56 ± 6 . 09 44 . 84 ± 7 . 77 44 . 46 ± 3 . 85 97 . 49 ± 0 . 21 Welsh 63 . 80 ± 3 . 13 47 . 30 ± 4 . 67 47 . 58 ± 5 . 72 96 . 79 ± 0 . 23 Zulu 76 . 59 ± 2 . 65 58 . 53 ± 4 . 42 42 . 56 ± 6 . 55 93 . 42 ± 0 . 73 involved are more or less the same as for Portugese and English . We propose the hypothesis that the languages where Alea and Kolmo perform poorly contain data with irregularities . Indeed , the data used to test Kolmo and Alea in [ 12 ] , introduced in [ 37 ] , has been ﬁltered to exclude analogies that can not be solved without knowledge of the language , in other words , without knowledge of the irregularities in the morphology of the language . Interestingly , English and Portugese where AE + parallel performs the worst are also the languages of Sigmorphon2019 where the symbolic baselines Alea and Kolmo perform the best . Portugese has a very regular inﬂexional mor - phology [ 55 ] , and the design of Alea and Kolmo allows them to handle morphological transformations which are frequent in those two languages , in particular aﬃxation [ 8 , 12 , 55 ] . Given that the performance of AE + ANNr and of models using the CNN - based embedding does not show the same tendency as AE + parallel , we hypothesize that the AE together with the AE pre - training task have trouble handling those transformations . However , due to the high variance in the performance it is hard to draw deﬁnite conclusions . While it would be beneﬁcial for the understanding of the limitations of Alea and Kolmo to perform an in depth morphological analysis of the data of languages were the performance is low , this falls out of the scope of this work . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 23 Table 2 Analogy solving accuracy ( rate of fully well predicted words , in % ) in the generation setting ( open world assumption ) , compared to the best retrieval model ( CNN + ANNr ) . For models depending on an embedding model , and thus sensitive to random initializations , we report performance as mean ± standard deviation over 10 random initialization in each setting . Symbolic baselines Alea [ 8 ] and Kolmo [ 12 ] were tested in the same setting as our models . Best ret . model Generative models Language CNN + ANNr AE + ANNr AE + parallel Alea Kolmo Sigmorphon 2016 Georgian 97 . 60 ± 0 . 23 87 . 50 ± 2 . 08 87 . 06 ± 6 . 28 84 . 97 79 . 94 Hungarian 89 . 06 ± 1 . 71 90 . 58 ± 0 . 63 83 . 57 ± 6 . 63 35 . 24 32 . 07 Turkish 84 . 75 ± 2 . 04 79 . 81 ± 8 . 58 83 . 03 ± 14 . 07 42 . 09 39 . 45 Sigmorphon 2019 Adyghe 93 . 37 ± 0 . 97 98 . 50 ± 0 . 25 81 . 90 ± 7 . 35 47 . 94 31 . 25 Arabic 72 . 08 ± 3 . 49 83 . 99 ± 1 . 28 78 . 40 ± 12 . 37 2 . 21 3 . 34 Bashkir 57 . 63 ± 5 . 48 95 . 15 ± 0 . 92 80 . 38 ± 18 . 55 22 . 29 29 . 89 English 92 . 29 ± 0 . 91 92 . 29 ± 4 . 57 65 . 61 ± 19 . 96 60 . 15 47 . 69 French 93 . 15 ± 0 . 96 88 . 25 ± 2 . 24 76 . 04 ± 10 . 20 54 . 48 54 . 39 Hebrew 66 . 52 ± 2 . 59 92 . 50 ± 0 . 25 91 . 16 ± 7 . 29 19 . 50 16 . 17 Portuguese 93 . 12 ± 1 . 10 93 . 11 ± 8 . 32 62 . 88 ± 24 . 26 78 . 01 71 . 28 Sanskrit 64 . 18 ± 2 . 62 91 . 48 ± 0 . 78 83 . 83 ± 5 . 37 42 . 80 28 . 83 Slovak 56 . 23 ± 4 . 57 78 . 90 ± 0 . 86 82 . 62 ± 6 . 66 30 . 66 28 . 81 Slovene 71 . 99 ± 2 . 24 82 . 41 ± 10 . 98 80 . 95 ± 8 . 19 2 . 64 5 . 43 Swahili 68 . 56 ± 6 . 09 97 . 49 ± 0 . 21 81 . 94 ± 21 . 80 60 . 23 43 . 02 Welsh 63 . 80 ± 3 . 13 96 . 79 ± 0 . 23 87 . 62 ± 12 . 69 14 . 47 19 . 15 Zulu 76 . 59 ± 2 . 65 93 . 42 ± 0 . 73 81 . 96 ± 15 . 81 26 . 17 27 . 69 ANNr improves on analogy solving performance The AE + parallel , CNN + ANNc , and CNN + 3CosMul models have signiﬁcantly lower performance on analogy solving than CNN + ANNr and AE + ANNr . While it is possible that this performance gap is caused by the ﬁnetuning on analogy solving present when ANNr is used but not the other models , we argue that this is not the main factor . Indeed , CNN + ANNc and CNN + 3CosMul use an embedding model trained with analogy while AE + parallel does not , yet the latter outperforms the former . By considering the gap in performance between ANNr and the other models , we conclude that ANNr , which was designed and trained speciﬁcally for analogy solving , performs better on that task than general purpose embedding models . As can be seen in Table 2 , we obtain equivalent or better performance with AE + ANNr than we obtained from CNN + ANNr , even though the latter beneﬁts from an embedding model designed speciﬁcally for morphology and from a closed set of possible solutions to retrieve from . The training procedure and architecture of AE + ANNr compared to CNN + ANNr diﬀer mostly in the use of the decoder output to compute the loss in AE + ANNr . By having direct access to the characters corresponding to the output of ANNr , it is likely that the model learns to avoid small diﬀerences in the word form that are not well captured by the CNN - based embedding model . In depth comparison of the Springer Nature 2021 L A TEX template 24 Solving morphological analogies : from retrieval to generation errors of the two models would be required to conﬁrm this hypothesis . We leave such studies for further work . Analogical training reduces sensitivity to random initialization . Putting aside the actual performance achieved , we observe that using ANNr signiﬁcantly reduces the standard deviation of model performance compared to using only the pretrained AE embedding . Indeed , as shown in appendix Table A4 , the AE has a very large standard deviation on the AE task , even when considering 50 models . A similar observation can be made in Tables 1 and 2 for CNN + 3CosMul , CNN + ANNc , and AE + parallel , while CNN + ANNr and AE + ANNr have a signiﬁcantly lower standard deviation . There are only two diﬀerences between the two groups of models : the use of ANNr and the ﬁnetuning of the embedding models using analogical data augmentation . In [ 14 ] , we also identiﬁed the signiﬁcant importance of data augmentation in the performance and stability of CNN + ANNc models on morphological analogies . Moreover , we observed on a diﬀerent task in ( the target sense veriﬁcation [ 21 ] ) that using ANNc and analogy during training also reduces the sensitivity of the model to input encoding . Overall , it appears that analogical training with ANNc or ANNr allows to compensate for high variance in embedding model performance and sensitivity to input conditions . Use of ANNc for analogy solving . Our experiments with ANNc revealed an unexpected weakness of the approach , namely , the time required to compute the score . For instance , for Turkish from Sigmorphon2016 , in average , running the retrieval with CNN + ANNc took more than 20 minutes against 46 seconds for CNN + 3CosMul and 40 seconds for CNN + ANNr . In comparison , it took 2 . 5 minutes to train for CNN + ANNc and 2 minutes for CNN + ANNr ( 4 . 5 minutes if we include the pretraining of the CNN - based embedding model ) , on a computer equipped with an Nvidia RTX A5000 Mobile used at close to 100 % of its processing capabilities . In this example , the time required to retrieve the solution with CNN + ANNc is an order of magnitude 10 times longer than the time to train an CNN + ANNr models from the CNN + ANNc model and apply it . Using CNN + 3CosMul is even faster as it is not necessary to train a new model , reaching a 30 times speedup . This issue is caused by having to repeat the computation of the classiﬁcation score for all the words of the vocabulary for each analogy to solve , however careful engineering might reduce the impact on run time . For example , selecting a subset of candidates using 3CosMul before applying CNN + ANNc as a retrieval model would allow for a signiﬁcant speedup . Additionally , the ANNc model is designed for classiﬁcation and has a ten - dency to distinguish poorly between comparatively meaningful solution to the AP equation . This can be conﬁrmed by extending the results to the top 10 high - est classiﬁcation scores , which signiﬁcantly increases the accuracy as shown in appendix Subsection A . 5 . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 25 Despite these limitations , CNN + ANNc outperforms CNN + ANNr on Bashkir , and CNN + 3CosMul on 7 languages ( Adyghe , Arabic , Bashkir , Hebrew , Portugese , Sanskrit , and Welsh ) . As mentioned before , the results become even more interesting when we look at the performance within the top 3 , 5 , and 10 retrieved words , for which CNN + ANNc outperforms CNN + 3CosMul respectively on 8 , 11 , and 12 languages out of 16 . This result is in line with the properties of ANNc and 3CosMul for retrieval , as 3CosMul relies on an arbitrary retrieval formula , while ANNc is learned together with the embedding , the latter resulting in a more appropriate alignment between the embedding space and the retrieval approach used . In simpler terms , ANNc is what was used to train the CNN - based embedding model for morphologi - cal analogies , so the features learned by the CNN - based embedding model are easier to properly manipulate with ANNc than with another model . 5 Discussion In this section we discuss the results of previous sections as well as the ones of our previous papers on the proposed approach , and also provide recommendations for using and further developing the framework . 5 . 1 Beneﬁt of ANNc and ANNr over symbolic , non - parametric , and other parametric approaches The framework we propose for analogy detection and solving uses ANNc and ANNr , two deep learning models inspired from the properties of APs . It can be argued that the architecture of ANNc and ANNr is not the most ﬁtting for the manipulation of APs , yet it is relatively easy to grasp and achieves good performance . As shown in this paper , the performance achieved is better than the one of non - parametric models such as the parallelogram rule and 3CosMul . Additionally , [ 11 ] showed , for semantic APs , the beneﬁt of the ANNc and ANNr models over multi - layer perceptron [ 56 ] ( up to 5 layers ) , random forest [ 57 ] and support vector machine [ 58 ] . The performance improvement is especially striking for ANNr , while for ANNc the beneﬁts are seen mostly on the SAT - based task which is considered a harder semantic analogy task [ 11 ] . Our framework also outperforms symbolic approaches to morphological APs . In all our works we compare ourselves with Alea [ 8 ] and Kolmo [ 12 ] , as well as with the approach of [ 24 ] in some cases . In [ 15 ] we compare CNN + ANNc with [ 24 ] as well as a relaxed formulation of Alea and Kolmo . It can be argued that comparing generative approaches to analogy solving with analogy detec - tion approaches such as Alea and Kolmo is unfair , and this was taken into account before drawing conclusions . Additionally , the top 10 generated solu - tions were considered in particular for valid AP detection , resulting in a higher accuracy for the baselines . In this setting , ANNc very signiﬁcantly outperforms the baselines on valid APs with no signiﬁcant diﬀerence on invalid APs . AE + ANNr and CNN + ANNr outperform the symbolic baselines by a very signiﬁcant margin in all cases . Furthermore , by considering the 10 most likely Springer Nature 2021 L A TEX template 26 Solving morphological analogies : from retrieval to generation retrieval results for CNN + ANNr ( see Subsection A . 5 ) , the accuracy improves above 99 % for all but 6 languages above 95 % . We observed a similar phe - nomenon in [ 15 ] for CNN + ANNr , with above 98 % accuracy for all but 2 languages ( at 95 % and 92 % respectively ) when considering the 10 most likely results . In [ 16 ] we managed to signiﬁcantly outperform our symbolic baselines with AE + parallel and to reach performance slightly lower performance with the generation approach than with the retrieval approach CNN + ANNr . Further analysis of the results revealed that AE + parallel was highly accurate with regular morphology and with certain permutations , while it struggled when the morphology was more irregular . These considerations resulted in us developing AE + ANNr , which outperforms CNN + ANNr on multiple languages as shown in Table 2 . 5 . 2 Improvements in the training process To achieve the best possible performance , we experimented with many dif - ferent parameters of the training procedure to reach the current state of the framework . Firstly , regarding ANNc , in [ 13 ] we identiﬁed an imbalance in the analogy detection performance due to the data augmentation process , as we later iden - tiﬁed in [ 15 ] : using the 8 equivalent forms of a valid analogy together with the 24 corresponding invalid forms skewed the data in favor of invalid analogies , while using only the 3 invalid forms obtained before computing the 8 valid form skewed the data in the other direction , resulting in a matching imbal - ance in the performance over the two classes for CNN + ANNc . A compromise was found by sampling 8 out of the 24 invalid forms , as presented in Sub - subsection 3 . 3 . 3 . Based on detailed analyses of results of some languages , in particular from [ 17 , 18 ] , we further reﬁned the data augmentation to exclude invalid forms that also appear in the valid forms . As explained later and as can be seen in [ 18 , 21 , 59 ] , proper care should be given to the data augmentation process to make the most of the beneﬁts it brings . Secondly , the current training procedure of ANNr is the result of multi - ple observations from [ 17 ] . Indeed , pre - training the embedding is necessary to achieve good performance on analogy solving with ANNr , and this can be achieved with relative ease by using CNN + ANNc ( with a 10 % to 40 % reported in [ 17 ] ) or an AE task ( as we identiﬁed in preliminary experiments to the present work ) . We also observed that when training only ANNr , the model performance was not satisfying , yet naively training CNN + ANNr with MSE resulted in a collapse of the embedding space . After experimenting with vari - ous training criterion based on these results , we achieved the best results with L ANNr ( as currently presented in Subsubsection 3 . 3 . 4 ) . While L ANNr is an easy to implement way to mitigate embedding space collapse , in many settings it achieves comparable performance to the other training criterion we consid - ered , so we encourage the reader to consider [ 17 , Table 1 . ] to have a better outlook when choosing the training criterion . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 27 Other details , in particular with regards to the implementation of approach , were reﬁned along our experiments . It would be beneﬁcial to further reﬁne our training process as well as the training parameters and hyperparameters , but we leave those considerations for further work due to time limitations . 5 . 3 Multilinguality In this work we did not attempt to model multiple languages at once or to transfer models between languages , as these aspects were extensively studied for CNN + ANNc in [ 13 , 14 , 18 ] . In particular , in [ 14 ] we experimented with diﬀerent forms of transfer from a source language to a target language with - out ﬁnetuning , within Sigmorphon 2016 and JBATS . Transferring the whole CNN + ANNc resulted in reasonable performance ( often above 50 % accuracy ) , however the transfer failed on some languages . Indeed , those languages used a diﬀerent set of characters than the rest of languages , resulting in a signiﬁ - cant amount of unrecognized characters . To tackle this issue that we call the alphabet gap , we used the CNN - based embedding model of the target language together with the ANNc of the source language . This did not improve the per - formance for all languages , likely due to a mismatch between the embedding space of the CNN - based embedding model ( trained on the target language ) and the one of the ANNc ( trained on the source language ) . In [ 14 ] we also experimented with a model covering multiple languages : either two representative languages or all languages at once , with several vari - ants . All variants achieved comparable results , with a high performance on positive examples and a poorer performance on negative examples . In all cases , as expected , the overall performance was poorer than with models dealing with only one language , with a slightly higher performance for bilingual models and a more consistent performance for the models on all languages . We performed further transfer experiments in [ 18 ] by transferring the full CNN + ANNc on Sigmorphon 2019 , which covers a wider range of languages . We leveraged languages present in both Sigmorphon 2016 and Sigmorphon 2019 to conﬁrm that our approach generalizes even when the distribution of mor - phological transformations is not the same , with a strong correlation between the performance loss of transferred models and the alphabet gap . A striking example is that of Arabic , for which the character representation in Sigmor - phon 2016 is completely diﬀerent than that of Sigmorphon 2019 : the former uses a romanized version of the words while the latter uses the actual UTF8 encoding of the Arabic characters . Furthermore , the high - resource languages of Sigmorphon 2019 form 4 clusters ( plus 4 outliers ) corresponding to diﬀerent sets of characters , i . e . , diﬀerent alphabets , as identiﬁed in [ 18 ] . Within each cluster and in particular the largest one , some alphabet gap remains ( e . g . , the accents present in French but not English ) , however it is no longer correlated with the transfer performance . Instead , we found striking similarities between the latter and the language families that can be found in Wikipedia . In par - ticular , similar clusters were found in a hierarchical clustering based on the transfer performance and the hierarchy of language families . Springer Nature 2021 L A TEX template 28 Solving morphological analogies : from retrieval to generation Based on our observations , it is possible to use the proximity in the Wikipedia language families to predict the performance of transferred models , which not only conﬁrm the transferability of morphological analogies between languages but also opens possibilities to empirically study morphological simi - larities between languages . Moreover , these results can be used to identify the language to use when dealing with low resource languages , by ﬁnding a closely related high resource language to train the language on . Finally , the large scale results with comparable transfer performance between closely related lan - guages can be used to design a multilingual analogy model similar to [ 14 ] on a larger scale . One such approach may be studied in further work , for exam - ple using diﬀerent components of the multilingual model for each cluster of languages . 5 . 4 Behavior of the models with regards to the axiomatic setting In [ 18 ] , transfer is also used to conﬁrm that changing the axioms used in the data augmentation process results in a sigiﬁcantly diﬀerent model correspond - ing to the changed axiomatic settings . This highlight the importance of the choice of the axiomatic setting in our framework , in particular since some axioms are discussed in some application settings [ 28 , 59 ] , as the model behav - ior can signiﬁcantly change depending on the chosen axioms . If enough data is available , we hypothesize that it is possible to determine the most ﬁtting set of axioms by ﬁnding the axiomatic setting with the closest performance to the analogical data . Experiments on a wider range of application domains would be required to conﬁrm this hypothesis . When analyzing the results of Navajo and Georgian in [ 17 ] , we identiﬁed several interesting behaviors of CNN + ANNr : ( i ) there is no signiﬁcant per - formance diﬀerence based on permutation , which indicates that the model is invariant to the axioms of APs , ( ii ) reﬂexivity and identity ( A : B : : A : B and A : A : : B : B respectively ) are well handled , ( iii ) when an example appears to violate strong reﬂexivity or strong inner reﬂexivity ( examples like A = B , C (cid:54) = D and A (cid:54) = B , C = D ) the ANNr model frequently gives a ( wrong ) answer which corresponds to a proper application of the violated axiom . 5 . 5 Model input In [ 21 ] we applied the data augmentation process and ANNc to target sense veriﬁcation , and observed that using ANNc together with our data augmen - tation during training reduces the sensitivity of the model to input encoding . The results of the present paper also indicate that data augmentation reduces the sensitivity to the initial setting of the model . Overall , it appears that our framework results in models that are less sensitive to slight changes in their input , as they are made invariant to changes in the input due to the axioms of APs . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 29 Additionally , we explored in [ 15 ] the sensitivity of CNN + ANNc and CNN + ANNr to perturbations in their input , by applying dropout on the word embeddings . By randomly replacing some embedding dimensions by 0 with a given probability , we found that beyond a certain dropout probability the performance of CNN + ANNc dropped drasticaly for invalid APs , and observed a similar but less striking phenomenon for CNN + ANNc on valid APs and for CNN + ANNr . The probability threshold depends on the language we con - sider , and we observe a plateau of high performance before the threshold . This allowed us to identify languages for which the embedding appears to contain redundant information ( hence there is little eﬀect of removing a few ) or con - versely languages that might beneﬁt from an increase in embedding size ( where the plateau of high performance does not appear , and that are more sensitive to dropout ) . In the latter category we ﬁnd Japanese , which is in line with the larger set of possible characters . 5 . 6 Limitations of the data used Over our experiments , we identiﬁed several limitations of our work due to the data we use for training our models . Firstly , the encoding of characters used in Sigmorphon 2016 is signiﬁcantly diﬀerent from the one of Sigmorphon 2019 and JBATS , as they respectively a rewriting of the language using roman alphabet and the standard UTF8 encoding of the characters of the language . As discussed above , this diﬀerence results in an alphabet gap between some languages , limiting the possibility of transferring models Additionally , JBATS contains multiple writings for some words , which has not been leveraged in our previous work on that language . Secondly , for most languages in the Siganalogies dataset , the grammatical categories represented are very skewed towards speciﬁc types of words . Among other eﬀects , this impacts the generalization ability of the AE embedding model as can be seen when trying to apply the model on words of grammati - cal categories underrepresented in the data . On the ﬂip - side , from the results of [ 18 ] it appears that CNN + ANNc overcomes this limitation and is able to properly generalize , if we exclude the impact of the alphabet gap . It is interesting to note that [ 12 ] uses a slightly diﬀerent version of the Sigmorphon 2016 data , where the analogies that cannot be inferred by relying only on the characters of the source terms have been removed . 5 . 7 Limitations of the symbolic approaches Along our experiments , and in particular in [ 17 ] , we identiﬁed several limi - tations of the Alea [ 8 ] and Kolmo [ 12 ] symbolic approaches that we use as baselines in most of our experiments . For instance , longer words and words with many repeated adjacent letters signiﬁcantly reduce the speed of the two approaches , with this phenomenon particularly striking for Kolmo , as was already identiﬁed by the authors of [ 12 ] . We solved this issue by introducing a timeout for Alea and Kolmo as described in [ 17 ] , as it appears that for most Springer Nature 2021 L A TEX template 30 Solving morphological analogies : from retrieval to generation languages less than 0 . 5 % of the AP equations took longer than 10 seconds to solve . Additionally , in [ 13 ] we found that Kolmo struggled with APs obtained in the data augmentation by using central permutation . It is interesting that this approach , based on empirical observations of human behavior in analogy solving , does not follow all the axioms of APs , as it further highlights the need for ﬂexibility with regards to the axiomatic setting . 5 . 8 Diversity in tackling analogical proportions Our framework proposes multiple technical solutions , in particular for analogy solving , each with their own beneﬁts . For instance , while ANNr outperforms 3CosMul , the latter does not require training an additional model . Also , while using ANNc for retrieval outperforms 3CosMul without requiring additional training , using the former is not recommended in most cases due to two key lim - itations : ( i ) the execution time for retrieval is greater than that of training an ANNr model and using traditional cosine - based retrieval , and ( ii ) ANNc tends to give similarly high scores to multiple solutions , which entails the expected solution appearing further in the ranking . However , ( ii ) can be a desired prop - erty of the model , and ( i ) can be reduced by engineering the process and preprocessing the candidates more eﬀectively . Additionally , as reported in [ 17 ] , 3CosMul does not systematically perform better than 3CosAdd , so it can be relevant to test both models . Similarly , while we use cosine distance for retrieval with CNN + ANNr based on preliminary experiments , there was no signiﬁcant diﬀerence between cosine and Euclidean distance . Beyond the choice of the model , using our framework requires to formulate the problem to tackle as APs . This step can be challenging , as can be seen in [ 59 ] or [ 21 ] where multiple formulations are explored , but the eﬀort is usually rewarded by good performance and the integration of analogical knowledge in the model . 6 Conclusion Our framework achieves very high analogy detection and solving performance , in a variety of settings . Both the CNN + ANNc for analogy detection and the AE + ANNr for analogy solving achieve consistent state of the art performance on all the languages used in our experiments , and outperform the symbolic baselines Alea [ 8 ] and Kolmo [ 12 ] by as much as 80 % in some cases . This gain in performance results from , among other things , ( i ) a representation of words learned on the data for the purpose of analogy manipulation , ( ii ) the ability of the model to integrate the dependencies between the embedding dimensions , and ( iii ) the ﬂexibility to go beyond arbitrary arithmetic formulas of APs such as 3CosAdd , 3CosMul , or the parallelogram rule . However , there is a known trade - oﬀ between the performance of deep learning models and their interpretability . In particular , it is usually diﬃcult to understand why an artiﬁcial neural network obtains a particular output . This also applies to our Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 31 framework , but further work might provide theoretical guaranties or empirical methods to tackle this limitation . In the current work we performed two sets of new experiments to conﬁrm the beneﬁt of using ANNc and ANNr . Firstly , we compared the retrieval per - formance of ANNc to ANNr and 3CosMul and showed that ANNc can be used to outperform 3CosMul , in particular when considering the top - 10 retrieved solutions . However , using ANNc in this manner results in signiﬁcant increase in retrieval time , which should be addressed in further work . Secondly , we combined ANNr and the AE embedding model , and outperform the symbolic baselines but also the previous approach relying on the parallelogram rule by as much as 30 % in some cases . This new model outperforms even the retrieval approach for multiple languages , despite the latter beneﬁting from a closed set of possible solutions . Overall , our framework shows that it is possible to obtain high perfor - mance when manipulating APs beyond arithmetic models on embeddings or manually - designed approaches . The framework leverages the properties and intuitions of APs in the design of the models , but also to augment data in a way that beneﬁts model performance , sensitivity to initial conditions , and makes the model invariant with regards to permutations following the axioms of APs . The approach can be applied to other types of data following our guidelines , as can be seen in [ 10 , 11 , 21 , 59 ] . Supplementary information . Our implementation is publicly available at GitHub : https : / / github . com / EMarquer / morpho - analogy - amai . Our model ﬁles are made available using Dorel , following the instructions in the GitHub README . Acknowledgments . This research was partially supported by the ANR project “Analogies : from theory to tools and applications” ( AT2TA ) , ANR - 22 - CE23 - 002 , by the TAILOR project funded by EU Horizon 2020 research and innovation program under GA No 952215 , and by the Inria Project Lab “Hybrid Approaches for Interpretable AI” ( HyAIAI ) . Appendix A Additional experimental results This appendix contains additional details for some of our experiments . Sub - section A . 1 covers the key hyperparameters used when training the model . Subsection A . 2 reports the results of pre - trained semantic embedding on solving morphological AP equations on English . Subsection A . 3 detains the performance of the CNN + ANNc model on analogy detection ( the pre - training task of CNN + ANNr and CNN + 3CosMul ) , and Subsection A . 4 covers the pre - training performance of the AE embedding model . Finally , Subsection A . 5 provide extended results for the analogy solving models . A . 1 Training hyperparameters The optimisation algorithm used for training our models is as follows : Springer Nature 2021 L A TEX template 32 Solving morphological analogies : from retrieval to generation • CNN + ANNc : Adam [ 60 ] with a learning rate of 10 − 3 and batches of 256 ; • CNN + ANNr : Adam with a learning rate of 10 − 3 and batches of 256 ; • AE pretraining : NAdam [ 61 ] ( slightly better results than Adam in our preliminary experiments ) with a learning rate of 10 − 2 and batches of 2048 ; • AE + ANNr : Adam with a learning rate of 10 − 3 and batches of 512 . A . 2 Semantic pre - trained embedding models on morphology Here we report the performance of ANNc using pre - trained semantic embed - dings , in particular GloVe6B 5 and fasttext 6 . For GloVe6B we use the models with 50 , 100 , 200 , and 300 dimensions , and the fasttext embeddings have 300 dimensions . It would be unreasonable to expect the best performance from semantic embeddings on a morphological task , due to for instance synonyms for which the forms ( and thus the morphemes ) are not distinguished . However , in English as in many languages some semantic features translate directly to morphemes , for instance the plural “ - s” , which may result in an amount of success . A ﬁrst issue encountered is that the pre - trained models cover only a small part of the word vocabulary : 37 . 69 % for GloVe6B and 53 . 35 % for fasttext . Taking only the words covered by both models ( to get a comparable result ) reduces the vocabulary to 37 . 15 % of its original size . Analogies containing only covered represent 10 . 33 % of the original APs . To obtain results that are more comparable to our CNN + ANNc model , which has the embedding trained for AP detection , we add a fully connected layer with output dimension 80 after the pre - trained embedding model , resulting on embeddings of comparable dimension to the CNN - based ones . Additionaly , this layer is meant to handle ﬁnetuning for the embedding model . We present in Table A1 results for model trained and tested on the original data , and in Table A2 for models using only covered APs . In each case we specify the dimension of the Glove6B model used , and models with a “ + ” sign are equipped with the fully connected layer . As one could expect , models using pre - trained embeddings and trained and tested on non - covered analogies have a signiﬁcantly lower performance than CNN + ANNc , as shown in Table A1 , for the most part due to unrecognized words during training and testing . In this setting , there is no signiﬁcant dif - ference between the models , with improvements of 2 % to 4 % on the F1 when learning a fully connected layer after the embedding . If we consider only cov - ered APs for training and testing the model , the F1 for GloVe6B jumps to 94 % to 99 % for models with the fully connected layer and to 81 % to 84 % for models without . Surprisingly , fasttext , which is based on embeddings of sub - words ( which are similar to morphemes ) , achieves a lower F1 of 52 % without and 56 % with the fully connected layer . In addition to the advantages of character - based embeddings ( avoiding unknown words ) and to the performance gap , our morphological embedding 5 GloVe trained on a wikipedia dump , see https : / / nlp . stanford . edu / projects / glove / 6 https : / / dl . fbaipublicﬁles . com / fasttext / vectors - wiki / wiki . en . vec Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 33 approaches result in more lightweight embedding models , since it is not nec - essary to store an embedding for each word . For instance , our CNN - based embedding model for English weights less than 100 KB , while Glove6B weights 171 MB , 347 MB , 693 MB and 1 GB for 50 , 100 , 200 , and 300 dimensions , respectively , and fasttext weights 6 . 6 GB . Table A1 Performance of the ANNc model on analogy detection ( in % , mean ± std . ) on English ( Sigmorphon 2019 ) , for all analogies . We consider several pre - trained embedding variants , for 5 random initialization of the model . Models with a “ + ” sign have a fully connected layer after the embedding and before ANNc . The balanced accuracy ( Bal . acc . ) is the average of the True Positive Rate ( TPR ) and True Negative Rate ( TNR ) , weighted by the number of the positive and negative examples respectively . Model F1 Bal . acc . TPR TNR FastText 52 . 21 ± 0 . 34 66 . 99 ± 0 . 28 59 . 69 ± 1 . 34 74 . 30 ± 1 . 44 GloVe6B 50 52 . 61 ± 0 . 21 67 . 30 ± 0 . 19 60 . 43 ± 2 . 33 74 . 17 ± 2 . 55 GloVe6B 100 52 . 82 ± 0 . 21 67 . 48 ± 0 . 18 60 . 05 ± 1 . 66 74 . 90 ± 1 . 78 GloVe6B 200 52 . 88 ± 0 . 33 67 . 52 ± 0 . 25 60 . 57 ± 1 . 96 74 . 47 ± 1 . 92 GloVe6B 300 52 . 70 ± 0 . 24 67 . 38 ± 0 . 21 60 . 07 ± 1 . 57 74 . 68 ± 1 . 86 FastText + 56 . 22 ± 0 . 35 70 . 08 ± 0 . 26 61 . 58 ± 1 . 75 78 . 58 ± 1 . 70 GloVe6B 50 + 54 . 38 ± 0 . 34 68 . 70 ± 0 . 26 59 . 82 ± 1 . 37 77 . 57 ± 1 . 47 GloVe6B 100 + 55 . 20 ± 0 . 25 69 . 31 ± 0 . 19 60 . 89 ± 1 . 10 77 . 74 ± 0 . 89 GloVe6B 200 + 55 . 54 ± 0 . 34 69 . 59 ± 0 . 24 62 . 46 ± 1 . 53 76 . 72 ± 1 . 78 GloVe6B 300 + 55 . 96 ± 0 . 24 69 . 92 ± 0 . 18 63 . 03 ± 1 . 71 76 . 81 ± 1 . 66 CNN + ANNc 99 . 39 ± 0 . 04 99 . 70 ± 0 . 05 99 . 76 ± 0 . 12 99 . 64 ± 0 . 03 Table A2 Performance of the ANNc model on analogy detection ( in % , mean ± std . ) on English ( Sigmorphon 2019 ) , for covered analogies only . We consider various variants of pre - trained embeddings , for 5 random initialization of the model , with all models trained and tested with covered analogies only . Models with a “ + ” sign have a fully connected layer after the embedding and before ANNc . The balanced accuracy ( Bal . acc . ) is the average of the True Positive Rate ( TPR ) and True Negative Rate ( TNR ) , weighted by the number of the positive and negative examples respectively . Model F1 Bal . acc . TPR TNR FastText 52 . 14 ± 0 . 19 66 . 93 ± 0 . 11 60 . 06 ± 2 . 14 73 . 79 ± 2 . 03 GloVe6B 50 81 . 70 ± 1 . 43 89 . 81 ± 0 . 80 95 . 30 ± 0 . 90 84 . 32 ± 1 . 88 GloVe6B 100 84 . 56 ± 1 . 27 91 . 26 ± 0 . 69 94 . 51 ± 0 . 55 88 . 02 ± 1 . 42 GloVe6B 200 84 . 03 ± 0 . 46 90 . 95 ± 0 . 28 94 . 36 ± 0 . 55 87 . 54 ± 0 . 62 GloVe6B 300 82 . 50 ± 0 . 42 90 . 09 ± 0 . 47 94 . 35 ± 2 . 52 85 . 83 ± 1 . 73 FastText + 56 . 24 ± 0 . 30 70 . 08 ± 0 . 24 61 . 08 ± 1 . 62 79 . 09 ± 1 . 44 GloVe6B 50 + 94 . 83 ± 0 . 86 97 . 15 ± 0 . 47 97 . 77 ± 0 . 52 96 . 52 ± 0 . 68 GloVe6B 100 + 98 . 37 ± 0 . 17 99 . 06 ± 0 . 11 99 . 11 ± 0 . 30 99 . 01 ± 0 . 19 GloVe6B 200 + 98 . 76 ± 0 . 15 99 . 34 ± 0 . 10 99 . 51 ± 0 . 18 99 . 17 ± 0 . 12 GloVe6B 300 + 98 . 83 ± 0 . 15 99 . 36 ± 0 . 09 99 . 47 ± 0 . 19 99 . 25 ± 0 . 14 Springer Nature 2021 L A TEX template 34 Solving morphological analogies : from retrieval to generation A . 3 CNN embedding pre - training performance We report in Table A3 the performance of the CNN + ANNc model on analogy detection . The models presented here are the same as the ones used for the CNN + ANNc model for analogy solving , and the CNN - based embedding model was reused for CNN + 3CosAdd and ﬁnetuned for CNN + ANNr . Table A3 Performance of the CNN + ANNc model on analogy detection ( in % , mean ± std . ) for 10 random initialization of the model . The balanced accuracy ( Bal . acc . ) is the average of the True Positive Rate ( TPR ) and True Negative Rate ( TNR ) , weighted by the number of the positive and negative examples respectively . Language F1 Bal . acc . TPR TNR Sigmorphon 2016 Georgian 98 . 26 ± 0 . 09 99 . 18 ± 0 . 07 99 . 39 ± 0 . 19 98 . 98 ± 0 . 09 Hungarian 99 . 82 ± 0 . 05 99 . 87 ± 0 . 04 99 . 80 ± 0 . 09 99 . 95 ± 0 . 03 Turkish 99 . 75 ± 0 . 08 99 . 83 ± 0 . 05 99 . 76 ± 0 . 09 99 . 91 ± 0 . 04 Sigmorphon 2019 Adyghe 97 . 37 ± 0 . 05 98 . 94 ± 0 . 04 99 . 55 ± 0 . 16 98 . 33 ± 0 . 08 Arabic 99 . 96 ± 0 . 02 99 . 98 ± 0 . 02 99 . 97 ± 0 . 04 99 . 98 ± 0 . 01 Bashkir 93 . 04 ± 0 . 07 97 . 07 ± 0 . 07 99 . 07 ± 0 . 17 95 . 06 ± 0 . 07 English 99 . 39 ± 0 . 04 99 . 70 ± 0 . 05 99 . 76 ± 0 . 12 99 . 64 ± 0 . 03 French 99 . 86 ± 0 . 06 99 . 88 ± 0 . 06 99 . 78 ± 0 . 11 99 . 98 ± 0 . 01 Hebrew 98 . 33 ± 0 . 12 99 . 18 ± 0 . 09 99 . 28 ± 0 . 21 99 . 09 ± 0 . 10 Portuguese 99 . 83 ± 0 . 09 99 . 88 ± 0 . 09 99 . 82 ± 0 . 17 99 . 95 ± 0 . 00 Sanskrit 98 . 08 ± 0 . 07 99 . 08 ± 0 . 05 99 . 20 ± 0 . 12 98 . 96 ± 0 . 06 Slovak 96 . 09 ± 0 . 15 98 . 02 ± 0 . 14 98 . 25 ± 0 . 36 97 . 79 ± 0 . 13 Slovene 99 . 65 ± 0 . 03 99 . 82 ± 0 . 04 99 . 81 ± 0 . 09 99 . 83 ± 0 . 03 Swahili 99 . 25 ± 0 . 04 99 . 66 ± 0 . 02 99 . 75 ± 0 . 07 99 . 57 ± 0 . 05 Welsh 98 . 63 ± 0 . 10 99 . 33 ± 0 . 11 99 . 37 ± 0 . 30 99 . 28 ± 0 . 12 Zulu 99 . 48 ± 0 . 04 99 . 78 ± 0 . 04 99 . 87 ± 0 . 08 99 . 69 ± 0 . 03 A . 4 Autoencoder embedding pre - training performance We report in Table A4 the AE accuracy at word level of the AE embedding model . The results presented cover 5 random data splits and 10 random ini - tialization of the model per split , resulting in 50 models per language . Only the 10 random initialization of the model were used for the ﬁrst random data split were used in our other experiments involving AE + ANNr and AE + parallel . A . 5 Extended analogy solving results In this appendix we provide Table A5 summarizing the results of all our analogy solving approaches for easier comparison . We describe and compare in the hit rate at k for k ∈ { 1 , 3 , 5 , 10 } for our retrieval models in Tables A6 to A9 . The hit rate corresponds to the rate of analogies for which the expected answer appears in the top k retrieved answers . For k = 1 , the hit rate is the accuracy . Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 35 Table A4 Accuracy ( in % , mean ± std . ) at the word level , of the AE pre - trained for at most 100 epochs on 40 , 000 random words , for 5 diﬀerent training / test splits and 10 random initialization of the model in each case . Languages in bold are the ones selected for further experiments . Language Accuracy ( % ) Language Accuracy ( % ) Sigmorphon 2016 Sigmorphon 2019 Arabic 75 . 72 ± 13 . 98 French 76 . 04 ± 10 . 20 Finnish 73 . 30 ± 9 . 96 German 64 . 98 ± 16 . 12 Georgian 87 . 06 ± 6 . 28 Greek 39 . 44 ± 21 . 68 German 69 . 50 ± 15 . 03 Hebrew 91 . 16 ± 7 . 29 Hungarian 83 . 57 ± 6 . 63 Hindi 58 . 08 ± 32 . 85 Maltese 77 . 07 ± 25 . 07 Hungarian 61 . 51 ± 13 . 81 Navajo 38 . 36 ± 21 . 41 Irish 10 . 39 ± 12 . 59 Russian 84 . 70 ± 6 . 63 Italian 70 . 92 ± 13 . 52 Spanish 78 . 36 ± 15 . 85 Kannada 0 . 05 ± 0 . 16 Turkish 83 . 03 ± 14 . 07 Kurmanji 76 . 52 ± 8 . 50 Sigmorphon 2019 Latin 69 . 90 ± 13 . 80 Adyghe 81 . 90 ± 7 . 35 Latvian 78 . 29 ± 5 . 53 Albanian 51 . 07 ± 13 . 56 Persian 59 . 14 ± 23 . 10 Arabic 78 . 40 ± 12 . 37 Polish 67 . 36 ± 18 . 58 Armenian 77 . 94 ± 4 . 87 Portuguese 62 . 88 ± 24 . 26 Asturian 73 . 71 ± 26 . 71 Romanian 62 . 76 ± 22 . 14 Bashkir 80 . 38 ± 18 . 55 Russian 67 . 76 ± 11 . 51 Belarusian 61 . 15 ± 15 . 30 Sanskrit 83 . 83 ± 5 . 37 Bengali 47 . 78 ± 25 . 46 Slovak 82 . 62 ± 6 . 66 Bulgarian 76 . 07 ± 7 . 18 Slovene 80 . 95 ± 8 . 19 Czech 61 . 08 ± 19 . 61 Sorani 77 . 43 ± 11 . 88 Danish 73 . 88 ± 11 . 70 Spanish 67 . 86 ± 21 . 80 Dutch 63 . 90 ± 19 . 41 Swahili 81 . 94 ± 21 . 80 English 65 . 61 ± 19 . 96 Turkish 68 . 03 ± 12 . 29 Estonian 66 . 78 ± 9 . 02 Urdu 52 . 02 ± 28 . 24 Finnish 34 . 68 ± 22 . 89 Welsh 87 . 62 ± 12 . 69 Zulu 81 . 96 ± 15 . 81 Springer Nature 2021 L A TEX template 36 Solving morphological analogies : from retrieval to generation T a b l e A 5 A cc u r a c y ( r a t e o f f u ll y w e ll p r e d i c t e d w o r d s , i n % ) o n t h e a n a l og y s o l v i n g t a s k s . F o r m o d e l s d e p e nd i n g o n a n e m b e dd i n g m o d e l , a nd t hu s s e n s i t i v e t o r a nd o m i n i t i a li z a t i o n s , w e r e p o r t p e r f o r m a n ce a s m e a n ± s t a nd a r d d e v i a t i o n o v e r 10 r a nd o m i n i t i a li z a t i o n i n e a c h s e tt i n g . S y m b o li c b a s e li n e s A l e a [ 8 ] a n d K o l m o [ 12 ] w e r e t e s t e d i n t h e s a m e s e tt i n g a s o u r m o d e l s . R e t r i e v a l m o d e l s G e n e r a t i v e m o d e l s L a n g u ag e C NN + ANN r C NN + 3 C o s M u l C NN + ANN c A E + ANN r A E + p a r a ll e l A l e a K o l m o S i g m o r pho n 2016 G e o r g i a n 97 . 60 ± 0 . 23 85 . 58 ± 7 . 37 76 . 77 ± 9 . 57 87 . 50 ± 2 . 08 87 . 06 ± 6 . 28 84 . 97 79 . 94 H un ga r i a n 89 . 06 ± 1 . 71 74 . 89 ± 5 . 27 72 . 95 ± 8 . 02 90 . 58 ± 0 . 63 83 . 57 ± 6 . 6 3 35 . 24 32 . 07 T u r k i s h 84 . 75 ± 2 . 04 52 . 42 ± 4 . 33 44 . 43 ± 13 . 95 79 . 81 ± 8 . 58 83 . 03 ± 14 . 07 42 . 09 39 . 45 S i g m o r pho n 2019 A d y g h e 93 . 37 ± 0 . 97 58 . 01 ± 8 . 66 80 . 11 ± 5 . 10 98 . 50 ± 0 . 25 81 . 90 ± 7 . 3 5 47 . 94 31 . 25 A r a b i c 72 . 08 ± 3 . 49 21 . 67 ± 5 . 44 40 . 73 ± 9 . 93 83 . 99 ± 1 . 28 78 . 40 ± 12 . 37 2 . 21 3 . 34 B a s h k i r 57 . 63 ± 5 . 48 37 . 76 ± 11 . 12 65 . 38 ± 6 . 01 95 . 15 ± 0 . 92 80 . 38 ± 18 . 55 22 . 29 29 . 89 E n g li s h 92 . 29 ± 0 . 91 66 . 83 ± 15 . 67 65 . 51 ± 6 . 25 92 . 29 ± 4 . 57 65 . 61 ± 19 . 96 60 . 15 47 . 69 F r e n c h 93 . 15 ± 0 . 96 80 . 37 ± 7 . 97 62 . 87 ± 17 . 65 88 . 25 ± 2 . 24 76 . 04 ± 10 . 20 54 . 48 54 . 39 H e b r e w 66 . 52 ± 2 . 59 15 . 47 ± 10 . 12 36 . 10 ± 4 . 28 92 . 50 ± 0 . 25 91 . 16 ± 7 . 29 19 . 50 16 . 17 P o r t u g u e s e 93 . 12 ± 1 . 10 58 . 52 ± 18 . 48 70 . 53 ± 9 . 88 93 . 11 ± 8 . 32 62 . 88 ± 24 . 26 78 . 01 71 . 28 S a n s k r i t 64 . 18 ± 2 . 62 33 . 20 ± 9 . 34 42 . 59 ± 4 . 88 91 . 48 ± 0 . 78 83 . 83 ± 5 . 3 7 42 . 80 28 . 83 S l o v a k 56 . 23 ± 4 . 57 49 . 43 ± 3 . 13 39 . 58 ± 3 . 37 78 . 90 ± 0 . 86 82 . 62 ± 6 . 6 6 30 . 66 28 . 81 S l o v e n e 71 . 99 ± 2 . 24 57 . 79 ± 8 . 59 51 . 88 ± 6 . 69 82 . 41 ± 10 . 98 80 . 95 ± 8 . 19 2 . 64 5 . 43 S w a h ili 68 . 56 ± 6 . 09 44 . 84 ± 7 . 77 44 . 46 ± 3 . 85 97 . 49 ± 0 . 21 81 . 94 ± 21 . 80 60 . 23 43 . 02 W e l s h 63 . 80 ± 3 . 13 47 . 30 ± 4 . 67 47 . 58 ± 5 . 72 96 . 79 ± 0 . 23 87 . 62 ± 12 . 69 14 . 47 19 . 15 Z u l u 76 . 59 ± 2 . 65 58 . 53 ± 4 . 42 42 . 56 ± 6 . 55 93 . 42 ± 0 . 73 81 . 96 ± 15 . 81 26 . 17 27 . 69 Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 37 Table A6 Accuracy , i . e . , hit rate at 1 ( in % , mean ± std . ) at the word level for the retrieval models . * * : highest average performance ; * : second highest average performance . CNN + ANNr CNN + 3CosMul CNN + ANNc Sigmorphon Language 2016 Georgian 97 . 60 ± 0 . 23 * * 85 . 58 ± 7 . 37 * 76 . 77 ± 9 . 57 Hungarian 89 . 06 ± 1 . 71 * * 74 . 89 ± 5 . 27 * 72 . 95 ± 8 . 02 Turkish 84 . 75 ± 2 . 04 * * 52 . 42 ± 4 . 33 * 44 . 43 ± 13 . 95 2019 Adyghe 93 . 37 ± 0 . 97 * * 58 . 01 ± 8 . 66 80 . 11 ± 5 . 10 * Arabic 72 . 08 ± 3 . 49 * * 21 . 67 ± 5 . 44 40 . 73 ± 9 . 93 * Bashkir 57 . 63 ± 5 . 48 * 37 . 76 ± 11 . 12 65 . 38 ± 6 . 01 * * English 92 . 29 ± 0 . 91 * * 66 . 83 ± 15 . 67 * 65 . 51 ± 6 . 25 French 93 . 15 ± 0 . 96 * * 80 . 37 ± 7 . 97 * 62 . 87 ± 17 . 65 Hebrew 66 . 52 ± 2 . 59 * * 15 . 47 ± 10 . 12 36 . 10 ± 4 . 28 * Portuguese 93 . 12 ± 1 . 10 * * 58 . 52 ± 18 . 48 70 . 53 ± 9 . 88 * Sanskrit 64 . 18 ± 2 . 62 * * 33 . 20 ± 9 . 34 42 . 59 ± 4 . 88 * Slovak 56 . 23 ± 4 . 57 * * 49 . 43 ± 3 . 13 * 39 . 58 ± 3 . 37 Slovene 71 . 99 ± 2 . 24 * * 57 . 79 ± 8 . 59 * 51 . 88 ± 6 . 69 Swahili 68 . 56 ± 6 . 09 * * 44 . 84 ± 7 . 77 * 44 . 46 ± 3 . 85 Welsh 63 . 80 ± 3 . 13 * * 47 . 30 ± 4 . 67 47 . 58 ± 5 . 72 * Zulu 76 . 59 ± 2 . 65 * * 58 . 53 ± 4 . 42 * 42 . 56 ± 6 . 55 Table A7 Hit rate at 3 ( in % , mean ± std . ) at the word level for the retrieval models . * * : highest average performance ; * : second highest average performance . CNN + ANNr CNN + 3CosMul CNN + ANNc Sigmorphon Language 2016 Georgian 99 . 54 ± 0 . 23 * * 93 . 34 ± 3 . 82 * 92 . 07 ± 4 . 92 Hungarian 97 . 49 ± 0 . 42 * * 89 . 04 ± 3 . 87 * 87 . 96 ± 5 . 84 Turkish 98 . 20 ± 0 . 48 * * 68 . 29 ± 4 . 04 * 63 . 64 ± 12 . 89 2019 Adyghe 99 . 63 ± 0 . 13 * * 74 . 78 ± 7 . 80 95 . 93 ± 1 . 84 * Arabic 91 . 33 ± 1 . 94 * * 38 . 61 ± 7 . 44 65 . 41 ± 11 . 60 * Bashkir 78 . 50 ± 3 . 00 * 55 . 72 ± 12 . 65 83 . 85 ± 3 . 96 * * English 98 . 66 ± 0 . 29 * * 76 . 34 ± 14 . 94 80 . 50 ± 4 . 66 * French 98 . 33 ± 0 . 30 * * 91 . 60 ± 4 . 64 * 82 . 94 ± 13 . 10 Hebrew 88 . 06 ± 2 . 09 * * 30 . 20 ± 15 . 80 59 . 69 ± 4 . 93 * Portuguese 99 . 06 ± 0 . 21 * * 79 . 18 ± 17 . 98 91 . 58 ± 6 . 02 * Sanskrit 89 . 95 ± 1 . 26 * * 53 . 90 ± 8 . 92 66 . 03 ± 4 . 88 * Slovak 87 . 86 ± 1 . 56 * * 67 . 81 ± 4 . 08 * 64 . 46 ± 4 . 00 Slovene 92 . 28 ± 0 . 72 * * 78 . 08 ± 8 . 26 * 75 . 92 ± 6 . 94 Swahili 84 . 72 ± 4 . 70 * * 60 . 57 ± 7 . 08 * 57 . 34 ± 5 . 10 Welsh 88 . 29 ± 1 . 92 * * 71 . 66 ± 5 . 04 76 . 67 ± 6 . 09 * Zulu 89 . 66 ± 1 . 66 * * 77 . 92 ± 4 . 10 * 64 . 51 ± 7 . 17 Springer Nature 2021 L A TEX template 38 Solving morphological analogies : from retrieval to generation Table A8 Hit rate at 5 ( in % , mean ± std . ) at the word level for the retrieval models . * * : highest average performance ; * : second highest average performance . CNN + ANNr CNN + 3CosMul CNN + ANNc Sigmorphon Language 2016 Georgian 99 . 73 ± 0 . 14 * * 94 . 92 ± 2 . 63 95 . 14 ± 3 . 16 * Hungarian 98 . 62 ± 0 . 29 * * 92 . 40 ± 3 . 29 * 91 . 75 ± 4 . 70 Turkish 99 . 28 ± 0 . 20 * * 73 . 95 ± 3 . 43 * 70 . 90 ± 11 . 30 2019 Adyghe 99 . 85 ± 0 . 07 * * 79 . 44 ± 7 . 22 98 . 08 ± 0 . 97 * Arabic 95 . 19 ± 1 . 14 * * 47 . 04 ± 8 . 23 74 . 75 ± 11 . 07 * Bashkir 87 . 12 ± 2 . 04 * 64 . 30 ± 11 . 48 89 . 61 ± 2 . 40 * * English 99 . 01 ± 0 . 22 * * 79 . 63 ± 14 . 15 85 . 14 ± 3 . 89 * French 98 . 86 ± 0 . 18 * * 93 . 91 ± 3 . 57 * 88 . 61 ± 9 . 81 Hebrew 93 . 13 ± 1 . 43 * * 40 . 07 ± 17 . 04 69 . 63 ± 4 . 61 * Portuguese 99 . 50 ± 0 . 17 * * 85 . 79 ± 15 . 20 96 . 26 ± 3 . 61 * Sanskrit 95 . 90 ± 0 . 48 * * 63 . 92 ± 7 . 26 76 . 12 ± 4 . 11 * Slovak 96 . 50 ± 0 . 46 * * 74 . 26 ± 4 . 15 74 . 42 ± 3 . 83 * Slovene 97 . 48 ± 0 . 28 * * 84 . 38 ± 7 . 26 84 . 41 ± 5 . 89 * Swahili 90 . 08 ± 3 . 70 * * 66 . 97 ± 7 . 03 * 63 . 30 ± 5 . 61 Welsh 93 . 88 ± 1 . 64 * * 79 . 10 ± 4 . 40 85 . 76 ± 4 . 72 * Zulu 92 . 83 ± 1 . 21 * * 84 . 28 ± 3 . 62 * 73 . 67 ± 6 . 59 Table A9 Hit rate at 10 ( in % , mean ± std . ) at the word level for the retrieval models . * * : highest average performance ; * : second highest average performance . CNN + ANNr CNN + 3CosMul CNN + ANNc Sigmorphon Language 2016 Georgian 99 . 84 ± 0 . 07 * * 96 . 19 ± 1 . 55 97 . 31 ± 1 . 68 * Hungarian 99 . 21 ± 0 . 16 * * 94 . 97 ± 2 . 49 95 . 01 ± 3 . 36 * Turkish 99 . 67 ± 0 . 09 * * 79 . 96 ± 2 . 71 * 79 . 22 ± 8 . 81 2019 Adyghe 99 . 95 ± 0 . 03 * * 84 . 02 ± 6 . 46 99 . 30 ± 0 . 41 * Arabic 97 . 82 ± 0 . 53 * * 58 . 14 ± 8 . 82 84 . 30 ± 9 . 44 * Bashkir 98 . 50 ± 0 . 50 * * 74 . 58 ± 8 . 39 94 . 27 ± 0 . 86 * English 99 . 31 ± 0 . 16 * * 83 . 26 ± 13 . 18 89 . 99 ± 2 . 95 * French 99 . 25 ± 0 . 13 * * 95 . 94 ± 2 . 50 * 93 . 62 ± 6 . 07 Hebrew 96 . 96 ± 0 . 78 * * 54 . 58 ± 15 . 98 80 . 83 ± 3 . 77 * Portuguese 99 . 74 ± 0 . 10 * * 91 . 98 ± 10 . 44 98 . 55 ± 1 . 50 * Sanskrit 98 . 78 ± 0 . 24 * * 75 . 24 ± 4 . 99 86 . 48 ± 3 . 03 * Slovak 98 . 77 ± 0 . 31 * * 80 . 71 ± 3 . 73 84 . 65 ± 3 . 10 * Slovene 99 . 16 ± 0 . 19 * * 89 . 77 ± 5 . 58 91 . 35 ± 4 . 13 * Swahili 95 . 42 ± 2 . 17 * * 75 . 30 ± 6 . 64 * 71 . 77 ± 5 . 76 Welsh 97 . 56 ± 0 . 84 * * 85 . 97 ± 3 . 66 93 . 26 ± 2 . 71 * Zulu 95 . 96 ± 0 . 64 * * 90 . 70 ± 2 . 80 * 84 . 30 ± 5 . 04 Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 39 References [ 1 ] Chollet , F . : On the measure of intelligence . CoRR ( 2019 ) [ 2 ] Mitchell , M . : Analogy making as a complex adaptive system . In : SFISSC , pp . 335 – 360 ( 2001 ) [ 3 ] Fahandar , M . A . , H¨ullermeier , E . : Learning to rank based on analogical reasoning . In : AAAI , pp . 2951 – 2958 ( 2018 ) [ 4 ] Fahandar , M . A . , H¨ullermeier , E . : Analogical embedding for analogy - based learning to rank . In : IDA . LNCS , vol . 12695 , pp . 76 – 88 ( 2021 ) [ 5 ] Hug , N . , Prade , H . , Richard , G . , Serrurier , M . : Analogical proportion - based methods for recommendation - ﬁrst investigations . FSS 366 , 110 – 132 ( 2019 ) [ 6 ] Mitchell , M . : Abstraction and analogy - making in artiﬁcial intelligence . ANYAS 1505 , 79 – 101 ( 2021 ) [ 7 ] Couceiro , M . , Hug , N . , Prade , H . , Richard , G . : Analogy - preserving func - tions : A way to extend boolean samples . In : IJCAI , pp . 1575 – 1581 ( 2017 ) [ 8 ] Langlais , P . , Yvon , F . , Zweigenbaum , P . : Improvements in analogical learning : Application to translating multi - terms of the medical domain . In : EACL , pp . 487 – 495 ( 2009 ) [ 9 ] Fam , R . , Lepage , Y . : Morphological predictability of unseen words using computational analogy . In : CAW @ ICCBR , vol . 1815 , pp . 51 – 60 ( 2016 ) [ 10 ] Lim , S . , Prade , H . , Richard , G . : Solving word analogies : A machine learning perspective . In : ECSQARU , vol . 11726 , pp . 238 – 250 ( 2019 ) [ 11 ] Lim , S . , Prade , H . , Richard , G . : Classifying and completing word analogies by machine learning . IJAR 132 , 1 – 25 ( 2021 ) [ 12 ] Murena , P . - A . , Al - Ghossein , M . , Dessalles , J . - L . , Cornu´ejols , A . : Solv - ing analogies on words based on minimal complexity transformation . In : IJCAI , pp . 1848 – 1854 ( 2020 ) [ 13 ] Alsaidi , S . , Decker , A . , Lay , P . , Marquer , E . , Murena , P . - A . , Couceiro , M . : A neural approach for detecting morphological analogies . In : DSAA , pp . 1 – 10 ( 2021 ) [ 14 ] Alsaidi , S . , Decker , A . , Lay , P . , Marquer , E . , Murena , P . - A . , Couceiro , M . : On the Transferability of Neural Models of Morphological Analogies . In : AIMLAI @ ECML - PKDD , vol . 1524 , pp . 76 – 89 ( 2021 ) Springer Nature 2021 L A TEX template 40 Solving morphological analogies : from retrieval to generation [ 15 ] Alsaidi , S . , Decker , A . , Marquer , E . , Murena , P . , Couceiro , M . : Tackling morphological analogies using deep learning - extended version . CoRR ( 2021 ) [ 16 ] Chan , K . , Kaszefski - Yaschuk , S . P . , Saran , C . , Marquer , E . , Cou - ceiro , M . : Solving Morphological Analogies Through Generation . In : IARML @ IJCAI - ECAI , vol . 3174 , pp . 29 – 39 ( 2022 ) [ 17 ] Marquer , E . , Alsaidi , S . , Decker , A . , Murena , P . - A . , Couceiro , M . : A Deep Learning Approach to Solving Morphological Analogies . In : ICCBR ( 2022 ) [ 18 ] Marquer , E . , Murena , P . - A . , Couceiro , M . : Transferring Learned Models of Morphological Analogy . In : ATA @ ICCBR , Nancy , France ( 2022 ) [ 19 ] Sadeghi , F . , Zitnick , C . L . , Farhadi , A . : Visalogy : Answering visual analogy questions . In : NeurIPS , pp . 1882 – 1890 ( 2015 ) [ 20 ] Peyre , J . , Laptev , I . , Schmid , C . , Sivic , J . : Detecting unseen visual relations using analogies . In : ICCV , pp . 1981 – 1990 ( 2019 ) [ 21 ] Zervakis , G . , Vincent , E . , Couceiro , M . , Schoenauer , M . , Marquer , E . : An analogy based approach for solving target sense veriﬁcation . In : NLPIR , Bangkok , Thailand ( 2022 ) [ 22 ] Hofstadter , D . , Mitchell , M . : The copycat project : A model of mental ﬂuidity and analogy - making . In : FCCAs , pp . 205 – 267 ( 1995 ) . Chap . 5 [ 23 ] Murena , P . - A . , Dessalles , J . - L . , Cornu´ejols , A . : A complexity based approach for solving hofstadter’s analogies . In : CAW @ ICCBR ( 2017 ) [ 24 ] Fam , R . , Lepage , Y . : Tools for the production of analogical grids and a resource of n - gram analogical grids in 11 languages . In : LREC , pp . 1060 – 1066 ( 2018 ) [ 25 ] Marquer , E . , Couceiro , M . , Alsaidi , S . , Decker , A . : Siganalogies - Mor - phological Analogies from Sigmorphon 2016 and 2019 [ 26 ] Lepage , Y . : Analogy and formal languages , vol . 53 , pp . 180 – 191 ( 2001 ) [ 27 ] Miclet , L . , Bayoudh , S . , Delhay , A . : Analogical dissimilarity : Deﬁnition , algorithms and two experiments in machine learning . JAIR 32 , 793 – 824 ( 2008 ) [ 28 ] Antic , C . : Analogical proportions . AMAI 90 , 595 – 644 ( 2022 ) [ 29 ] Barbot , N . , Miclet , L . , Prade , H . : Analogy between concepts . AI 275 , 487 – 539 ( 2019 ) Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 41 [ 30 ] Lepage , Y . , Ando , S . : Saussurian analogy : a theoretical account and its application . In : COLING , pp . 717 – 722 ( 1996 ) [ 31 ] Prade , H . , Richard , G . : A short introduction to computational trends in analogical reasoning . In : CAAR - CT . SCI , vol . 548 , pp . 1 – 12 ( 2014 ) [ 32 ] Lepage , Y . : De l’analogie rendant compte de la commutation en linguis - tique . Habilitation ` a diriger des recherches , Universit´e Joseph - Fourier - Grenoble I ( 2003 ) [ 33 ] Couceiro , M . , Hug , N . , Prade , H . , Richard , G . : Behavior of Analogical Inference w . r . t . Boolean Functions . In : IJCAI , pp . 2057 – 2063 ( 2018 ) [ 34 ] Couceiro , M . , Lehtonen , E . : Galois theory for analogical classiﬁers ( 2023 ) [ 35 ] Pennington , J . , Socher , R . , Manning , C . D . : Glove : Global vectors for word representation . In : EMNLP , pp . 1532 – 1543 ( 2014 ) [ 36 ] Yvon , F . : Finite - state transducers solving analogies on words . Report GET / ENST & LTCI ( 2003 ) [ 37 ] Lepage , Y . : Character - position arithmetic for analogy questions between word forms . In : CAW @ ICCBR , vol . 2028 , pp . 23 – 32 ( 2017 ) [ 38 ] Wang , L . , Lepage , Y . : Vector - to - sequence models for sentence analogies . In : ICACSIS , pp . 441 – 446 ( 2020 ) [ 39 ] Vania , C . : On understanding character - level models for representing morphology . PhD thesis , University of Edinburgh ( 2020 ) [ 40 ] Levy , O . , Goldberg , Y . : Dependency - based word embeddings . In : Short Papers . ACL , vol . 2 , pp . 302 – 308 ( 2014 ) [ 41 ] Devlin , J . , Chang , M . , Lee , K . , Toutanova , K . : BERT : pre - training of deep bidirectional transformers for language understanding . In : NAACL - HLT , pp . 4171 – 4186 ( 2019 ) [ 42 ] Mikolov , T . , Chen , K . , Corrado , G . , Dean , J . : Eﬃcient estimation of word representations in vector space . In : ICLR ( 2013 ) [ 43 ] Bojanowski , P . , Grave , E . , Joulin , A . , Mikolo , T . : Enriching word vectors with subword information . ACL 5 , 135 – 146 ( 2017 ) [ 44 ] LeCun , Y . , Boser , B . E . , Denker , J . S . , Henderson , D . , Howard , R . E . , Hub - bard , W . E . , Jackel , L . D . : Backpropagation applied to handwritten zip code recognition . NeurComp 1 ( 4 ) , 541 – 551 ( 1989 ) Springer Nature 2021 L A TEX template 42 Solving morphological analogies : from retrieval to generation [ 45 ] Kramer , M . A . : Nonlinear principal component analysis using autoasso - ciative neural networks . AIChE 37 ( 2 ) , 233 – 243 ( 1991 ) [ 46 ] Hochreiter , S . , Schmidhuber , J . : Lstm can solve hard long time lag problems . In : NeurIPS , pp . 473 – 479 ( 1996 ) [ 47 ] Chollet , F . : Character - level recurrent sequence - to - sequence model ( 2017 ) [ 48 ] Graves , A . , Schmidhuber , J . : Framewise phoneme classiﬁcation with bidi - rectional LSTM and other neural network architectures . NN 18 ( 5 - 6 ) , 602 – 610 ( 2005 ) [ 49 ] Mikolov , T . , Yih , W . - T . , Zweig , G . : Linguistic regularities in continuous space word representations . In : NAACL , pp . 746 – 751 ( 2013 ) [ 50 ] Baevski , A . , Zhou , Y . , Mohamed , A . , Auli , M . : wav2vec 2 . 0 : A framework for self - supervised learning of speech representations . In : NeurIPS , pp . 12449 – 12460 ( 2020 ) [ 51 ] Dosovitskiy , A . , Beyer , L . , Kolesnikov , A . , Weissenborn , D . , Zhai , X . , Unterthiner , T . , Dehghani , M . , Minderer , M . , Heigold , G . , Gelly , S . , Uszkoreit , J . , Houlsby , N . : An image is worth 16x16 words : Transformers for image recognition at scale . In : ICLR ( 2021 ) [ 52 ] Cotterell , R . , Kirov , C . , Sylak - Glassman , J . , Yarowsky , D . , Eisner , J . , Hulden , M . : The sigmorphon 2016 shared task – morphological reinﬂection . In : SIGMORPHON 2016 , pp . 10 – 22 ( 2016 ) [ 53 ] McCarthy , A . D . , Vylomova , E . , Wu , S . , Malaviya , C . , Wolf - Sonkin , L . , Nicolai , G . , Kirov , C . , Silfverberg , M . , Mielke , S . J . , Heinz , J . , Cotterell , R . , Hulden , M . : The SIGMORPHON 2019 shared task : Morphological analy - sis in context and cross - lingual transfer for inﬂection . In : CRPPM @ ACL , pp . 229 – 244 ( 2019 ) [ 54 ] Karpinska , M . , Li , B . , Rogers , A . , Drozd , A . : Subcharacter information in japanese embeddings : when is it worth it ? In : RELNLP , pp . 28 – 37 ( 2018 ) [ 55 ] Brakel , A . : Boundaries in a morphological grammar of portuguese . WORD 32 ( 3 ) , 193 – 212 ( 1981 ) [ 56 ] Haykin , S . : Neural Networks : a Comprehensive Foundation , ( 1994 ) [ 57 ] Ho , T . K . : Random decision forests . In : ICDAR , vol . 1 , pp . 278 – 282 ( 1995 ) [ 58 ] Cortes , C . , Vapnik , V . : Support - vector networks . ML 20 ( 3 ) , 273 – 297 ( 1995 ) [ 59 ] Alsaidi , S . , Couceiro , M . , Quennelle , S . , Burgun , A . , Garcelon , N . , Coulet , Springer Nature 2021 L A TEX template Solving morphological analogies : from retrieval to generation 43 A . : Exploring analogical inference in healthcare . In : IARML @ IJAI - ECAI . CEUR - WP , vol . 3174 , pp . 40 – 50 ( 2022 ) [ 60 ] Kingma , D . P . , Ba , J . : Adam : A method for stochastic optimization . In : ICLR ( 2015 ) [ 61 ] Dozat , T . : Incorporating nesterov momentum into adam ( 2016 )