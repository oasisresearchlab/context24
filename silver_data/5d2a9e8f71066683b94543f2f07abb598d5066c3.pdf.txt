Errors in Children ' s Subtraction MRC Applied Psychology Unit , Cambridge , England The Open University Many of the errors that occur in children ' s subtraction are due . to the use pf incor - rect strategies lpther than to the incorrect recall of numbertacts . A prdction system is presented for performing written subtraction which is consistent with an earlier analysis of the natJre of such a cognitive skill . Most of the incorrect strategies used by schoolchildren can be accounted for in a principled way by simple changes in the production system , such as the omission of individual r u l i or the inclusion of rules appropriate to other arithmetical tasks . The production system model is evaluated against a corpus of over 1500 subtraction problems done by 10 - year olds and is shown to account for about two - thirds of the ( nonnumber fact ) errors . It also provides an alternative , simpler interpretation of the subtraction . errors analysed by Brown and Burton ( 1978 ) . Some implications for teaching are discussed . ERRORS IN CHILDREN ' S SUBTRACTION At one time children ' s errors in written subtraction were largely attributed both to a failure to remember " number facts " correctly , such as 9 - 7 = 2 , and to a variety of contributing factors , such as faulty setting out of exercises , careless - ness , fatigue , and lack of concentration ( Downes & Paling , 1958 ) . Thyne ( 1 954 ) in his careful and detailed taxonomy of errors in arithmetic demonstrated the tThe Rodution System analysis of subtraction given in this paper was fmt presented at a meeting of the Society for the Study of Artificial Intelligence and Simulation of Behavior , in Hamburg , July 1978 . The starting point for the research was Michael Bennett ' s ( 1976 ) perspicacious analysis of children ' s errors in subtraction . We are grateful to Benedict du Boulay for constructive criticism and for introducing us to the literature on teaching arithmetic , and to Allan Collins , Jim Greeno , and Kurt VaoLehn for comments on earlicr drafts . The research was supported in part by grants from the UK Social Science Research Council held by Jim Howe . Requests for reprints should be sent to : Dr R . M . Young , MRC Applied Psychology Unit . 15 Chaucer Road , Cambridge CB2 2EF , England . 154 YOUNG AND O ' SHEA existence of failures in the process of recalling or determining the number facts . Various models for recall ( Sloman , 1974 ) and determination ( Woods & Hartley , 1971 ; Woods , Resnick , & Groen , 1975 ) of number facts have been advanced . But careful analysis of the emrs in . computation shown by individual pupils ( Ladford , 1972 ) forces the conclusion that many errors result from a failure in the process ofexecuting the subtraction rather than from carelessness or defective number facts . These errors fall into quite clear patterns and contemporary work - ers in education attribute them to the use of " erroneous algorithms " ( Ashlock , 1976 ) . This paper presents an attempt to throw light on the nature and causes of these errors by developing explicit representations for the erroneous algorithms and by examining their relationship to the correct ones . Implicit in our approach is the view that the incorrect procedures are worth understanding in their own right , and that it is more fruitful to regard the child as faithfully executing a faulty algorithm than as wrongly following a correct one . The procedure for correct subtraction will be represented as an information - processing model cast in the form of a set of rules , with the different kinds of error beiig accounted for mainly by the omission of various rules from the set . Number - fact errors exhibit a great deal of regularity in their own right ( Woods & Hartley , 1971 ) , but we will not be dealing with them in this paper . Errors in Subtraction Children in Britain are taught one of two main methods for carrying out mul - ticolumn subtraction ( Williams , 1971 ) . In both methods the numbers to be , sub - tracted are written one beneath the other with the corresponding digits aligned : 7 4 ( t minuend ) M2 MI - 2 8 ( t subtrahend ) S2 S 1 - ( t difference ) In both methods the columns are processed in order from right to left . They differ only in the technique used for " borrowing , " i . e . , when the subtrahend digit ( S ) is greater than the minuend digit ( M ) above it , ( S > M ) . In either case , a " ten " is " borrowed " from the column on the left , thus in the example M1 = 4 is treated as 14 . In the method of decomposition this 10 is made available by decrementing the digit in the minuend , thus M2 = 7 becomes 6 . In the equal addition method the ten is paid back by incrementing the digit in the subtrahend : the S2 = 2 would be treated as 3 . Figure 1 shows eight examples of incorrectly answered subtraction prob - lems , taken from Bennett ' s ( 1976 ) analysis of the errors in over 1500 subtrac - tions done by 10 - year olds . Similar examples are found in other analyses ( Lankford , 1972 ) . Figure 1 . Examples of subtraction errors . Example A is typical of a very common type of error where the student simply takes ' the difference of the two digits in each column , irrespective of which is the larger . Doing this produces an error in which the student ought to borrow , but does not . Example B illustrates what is in a seke the opposite kind of mistake , where the studentought not to borrow but nevertheless does . In this case he has found himself having to take 2 from 16 , and has dealt with the 10 in the result of 14 by carrying it into the second column . Carrying is of course not normally a step in substraction , and its consequence here is that the answer is 20 too low , since the s ' econd column has effectively been " borrowed from " twice , both times unnecessarily . Example C is similar in that the student has again 156 YOUNG AND O ' SHEA performed an inappropriate borrow and then had to cany , But in this case the digits in the lefthand column differ by one , so the subtrahend - plus - cany is now greater than the minuend - minus - borrow . Typically , as in this case , the student simply takes the smaller digit from the larger to yield a difference of 1 , which is " correct " though for the wrong reason . Examples D , E , and F show other errors which are still quite clear cut , though less common than those of A - C . In D , the student has written down an answer of zero in a case where S is greater than M , presumably on the grounds that " you can ' t take 7 from 2 . " In example E , the result of borrowing to an M of 1 is 10 instead of 11 . And in F , the student has performed the borrowing correctly , but has then added the digits in the second column instead of subtract - ing . Examples G and H are " pattern errors " involving the digit zero . In G , the student , on seeing the zero as the M digit , has written the other digit , 7 , as the result of the subtraction . In isolation , of course , this error is indistinguishable from those of type A where the child simply takes the smaller digit from the larger . It owes its separate existence to the fact that there are children who are capable of borrowing correctly and who therefore do not make mistakes of type A , but who , nevertheless , do consistently show errors of type G . Example H is similar , except that the student writes zero as the result . The ambiguity of problems like Example G highlights the need to distin - guish carefully between , on the one hand , errors , i . e . , actual wrongly answered problems , and on the other , faulty algorithms ( or " bugs " ) , i . e . , flaws in the program that generates the answers . Although an error is regarded as an indica - tion or manifestation of an underlying fault , there is no simple one - to - one rela - tionship between the fypes of errors and the fypes of faults . Rather , one has to look for relationships between underlying faults and the entire collection of errors a child makes on a set of problems . This issue will raise itself again when we come to consider how to evaluate a proposed explanation for the child ' s errors . Analysis of Bennett ' s Data Our approach will be to treat ~ ennek ' s ( 1976 ) subtraction problems as a data base against which our proposed explanations for the errors can be tested . To this end it is appropriate to summarize and classify its contents . Source of the Data . Bennett gave 10 - year old schoolchildren two batches of written subtraction problems on occasions four months apart . There are data from 33 children , of whom 8 took only the first test ; 7 only the second ; 18 took both . The first test consisted of 20 problems , the second of 42 , all problems requiring the subtraction of one two - digit number from another . Thus data are available on about 26 x 20 + 25 x 42 = 1570 individual subtractions , although owing to copying errors and omissions some children did either more or fewer ERRORS IN CHILDREN ' S SUBTRACTlON 1 57 problems than they were meant to . It was crucial that we hah access to the children ' s actual worksheets , showing , their crossings - out and borrowings ( Fig - ure I ) , not just to their written " answers . " Analysis of the Errors . The worksheets were examined problem by prob - lem in order to classify each erroneous subtraction . If the problem was structur - ally correct - i . e . , if a borrow had been correctly and appropriately performed - and the mistake was that the actual difference between two numbers was wrong by a small amount , then it was regarded as a number - fact error . Otherwise , it was treated as an algorithm error or a zero - pattern error , and was further classified by its type . ( One worksheet proved impossible to analyze , since after the first two probleins the answers were bizarre and bore no recognizable relation to the problems . ) Of the 1549 problems , 344 ( 22 percent ) were answered erroneously . Their breakdown is given in Table 1 , which also shows the number of children who exhibited e m of each class . TABLE 1 Analysis of Errors in Bennett ' s ( 1 976 ) Data - - - - Emr fype ( Figure 1 ) occumences children AIgorm & m errors ( 124 = 36 prcent ) Borr - - < A , 8 , C 51 3 Take smaller A 50 6 Always borrow B , . C 14 2 S > M - , zero D 4 1 One + 10 E 3 2 Add Column 2 F 2 1 Patiern = 16 percent ) a 0 - N - N G 41 8 0 - N = O H 7 2 N - N = N 6 3 Number - fad errors ( 127 = 37 percent ) ' 127 25 Impossible to amlyre ( 39 = 11 percent ) 39 1 ' ~ otal enom 344 ( = 100 percent ) . Of the algorithm errors , the most popular type ( called " Borrow when < " < M ) , and not to bomw when S YM , precisely the opposite of what he ought to do . This gives rise to errors of type A ( Figure 1 ) and S > M , and B or occasionally C when S < M . The next most popular kind is for the child simply never to borrow , leading to errors of type A . A number of children always borrow , whether they need to or not , giving rise to errors of types B and C . The other algorithm errors correspond directly to those illustrated as types D , E , and F . Of the zero - pattern errors , by far the largest class is of the " 0 - N = N " kind illustrated as type G . YOUNG AND O ' SHEA Three points need to be stressed concerning this classificatory exercise . First , and obviously , the analysis is only a rough one . Each of the more popular types has several variants , and an examintion of these often suggests a misun - derstanding that underlies the child ' s performance . Second , an element of in - terpretation is involved . This comes about because we have been trying to sort manifest errors on the basis of the faulty algorithms that produce them . As discussed , an error of the " 0 - N = N " type could also be regarded as a " take smaller " error , Similarly , that a child has borrowed when he should not does not of itself tell us whether this is because he has confused the circumstances in which he should and should not borrow , or because he always borrows . The resolution of questions like these must consider the child ' s entire set of answers to the test - and children are not perfectly consistent . But , third , any inaccuracy or bias in this interpretation in no way ' affects the validity of the following explanations , since our models will be tested by comparing their predictions against the child ' s performance on each individual problem , not against the summary statistics presented in Table 1 . PRODUCTION SYSTEM MODELS FOR SUBTRACTION Our account of subtraction emrs will make use of an information processing notation known as aproduction system . A production system ( PS ) consists of a collection of rules C ? A , whose lefthand sides consist of conditions C which specify when the righthand side actions A are meant to apply . PSs were intro - duced as psychological models by Newel1 and Simon ( 1972 ) who used them to characterize the behavior of adults solving certain kinds of symbolic puzzles . Since then , they have been used as a medium for expressing theories of various topics in cognitive psychology ( Anderson , 1976 ; Klahr & Wallace , 1976 ) . The modularity of the individual niles makes PSs especially suitable for describing the learning of a skill , since its growth can be modeled by the acquisition of new rules ( Young , 1976 ) . Our previous work using PSs for subtraction showed too that they offer a natural method of representing the way that subtraction behavior often consists of a mixture of different strategies ( Young , 1977 ) . Production System Conventions The production systems we use follow the conventions of the 0PS2 PS architec - ture ( Forgy & McDermott , 1977 ) , though we use a somewhat simplified nota - tion . The architecture has three components : 1 . A working memory ( WM ) , which is simply a set of elements such as ( S EQ M ) or ERRORS IN CHILDREN ' S SUBTRACTION 1 59 ( RESULT 5 ) . The elements are regarded as being unordered , though they are im - plicitly tagged with the time at which they were asserted , i . e . , added to the WM . WM is a strict set : no element can appear more than once . Any attempt to assert an item already present in WM is treated as a deletion of the item followed by its reassertion . Our PSs will make no use of explicit deletion , so once an item has been asserted it remains in WM indefinitely . A production memory , which holds a collection of production rules . The lefthand side of each rule is a conjunction of patterns which have to match against distinct elements of WM . The definition of matching is strict . The pattern has to be identical to the item in W M for the match to succeed , except that a variable ( indicated by a symbol beginning with " = " ) is allowed to match any component of the item . Thus the pattern ( RESULT = x ) would match the WM item ( RESULT 5 ) with x bound to 5 , but would not match ( RESULT ) or . ( RESULT 1 5 ) . The righthand side of a rule consists of a sequence of actions to be taken or items to be added to WM , the convention being that items are added in right - to - left order , so that the leftmost item is treated as the most " recent " for the purposes of conflict resolution ( 3 ( b ) ) . The rules are regarded as being unordered , though in the case of a growing PS , 0PS2 keeps note of the order in which the rules are added to the system . 3 . A conflict resolution method to determine which rule is to be fired when more than one is applicable . 0PS2 interprets a PS by repeated execution of a recognize - act cycle . The interpreter fust finds which rules have their conditions satisfied . These rules are potential candidates for firing and form the conflict set . The conflict resolution method is applied to the conflict set to discard all but one of the rules in it . The one remaining rule is then " fired , " i . e . , its actions are obeyed ; then the cycle repeats . The conflict resolution method of 0PS2 makes use of the following principles ( for further justifica - tion , see McDehon & Forgy , 1978 ) : ( a ) Refractoriness . No rule is ever fired more than once with its conditions matched to the same set of elements in WM . ( b ) Recency in WM . Rules whose conditions match more recent elements in W M knock out mles that match only older elements . ( c ) Special care . If rule R1 matches all the elements that R2 does and more besides , then R1 is a special case of R2 , and R2 is removed from the conflict set . ( d ) Recency in production memory . If after applying principles ( a ) - ( c ) there is still more than one rule left in the conflict set , then 0PS2 removes all but the one ( s ) most recently added to the system . ( e ) Arbitrary choice . If there is still more than one rule in the conflict set , then 0PS2 simply picks one arbitrarily . Modeling of Correct Subtraction Figure 2 shows a PS for subtraction using the decomposition technique for borrowing . The labels down the lefthand edge are just tags to allow us to refer to the individual rules and play no part in their actual functioning . For clarity , the names of the righthand side actions begin with a " * . " To consider the fust few rules briefly in turn : YOUNG AND CYSHEA FD : B2A : BS1 : BS2 : CM : IN : TS : NXT : - WA : DONE : B2C : AC : M = m , S = s S > M Borrow Borrow M = m , S = r P - Column FindDii NextColumn Result = x N o h e S = M Result 1 = x . . . . . . . . . . . . . . . . . i . FindDiff , ~ ext ~ olumn 3 Borrow 3 ' AddTenToM 3 ' Decrement 3 ' Compare 3 ' ReadMandS 3 ' TakeAbsDii ' Shiftleft , ProcessColumn 3 ' Write = x 3 ' HALT 3 Result 0 , NextColumn + ' Cony , Resuh = X e . . . . . . . . . . . . . . . . . . . . . . . . Figure 2 . Production system for subtraction by decomposition . Rule FD says that once the two digits in a column are known , the appropriate response is to set up the goal of subtracting them , and then later move to the next column . Rule B2A indicates that if the subtrahend digit is greater than the minuend digit - + S > M ) is one of the possible outputs of the Compare operator , as we will see below - then the appropriate response is to perform a Borrow . Rules BS 1 and BS2 spell out the mechanics of Borrowing . Rule BS2 is responsible for crossing - out and decrementing the digit borrowed from , either physically on paper or just " in the head ; " BSI adds the borrowed tern to the minuend digit . Rule CM says that an appropriate behavior when the two digits are known is to Compare them . Compare deposits in . WM an element indicating the relative sizes of the subtrahend and minuend digits , one of ( S < M ) , ( S > M ) , or ( S = M ) . We assume that rule Ch4 is a product of a child ' s training in subtraction and is acquired later than rule FD . Rule IN says that for the goal of dealing with one column of the subtradion , the fmt thing to do is to read the two digits . Rule TS says that the appropriate way to subtract two numbers is to take the absolute difference between them . The rest of the rules will be discussed later . The easiest way to understand the functioning of this PS is to trace its initial execution on an actual problem . Figure 3 summarizes its behavior . We assume that a child is faced with the problem we saw earlier : and that his attention is focused on the righthand column . Initially we assume his WM to contain just one relevant item , the symbol ( PROCESSCOLUMN ) which acts as a goal for the subtraction performance . Initially WM holds just ( PROCESSCOLUMN ) . Only one rule is applica - ble , IN , which fires , reading the two digits in the first column and asserting them in WM . The conflict set now consists of rules FD and CM as well as IN , since ERRORS IN CHILDREN ' S SUBTRACTION 161 Aifion taken , or Step recenv J Rule Cred element asserted . ( PROCESSCOLUMN ) ' ReadMandS ( M 4 ) Assert ( S 8 ) ( S 8 ) ( M 4 ) ( PROCESSCOLUMN ) I 2 . CM Do ' Cornpore Assert ( S > M ) ( S > M ( S 8 ) ( M 4 ) ( PROCESSCOWMN ) 3 . Assert ( BORROW ) ( BORROW ) ( S > M ) ( S 8 ) ( M 4 ) ( PROCESSCOLUMN ) , 4 . BS1 ( say ) Do ' AddTemToM 5 . BS2 ( sqy ) Do * Decrhemt 6 . FD Assert ( NEXTCOLUMN ) ( FINDMFF ) ( FINDDIFF ) ( NEXTCOLUMN ) ( BORROW ) ( S > M ) ( S 8 ) . . . 7 . TS Do ' TakeAbsDii As & ( RESULT 6 ) ( RESULT 6 ) ( RNDDIFF ) ( NEXTCOLUMN ) ( BORROW ) ( S > M ) . . . Trace of production system of Figure 2 on 74 - 28 = ? they are the ones whose conditions are satisfied . But IN is discarded because it has already fired for the WM element it matches , and by the principle of . . recency - in - production - memory rule CM is chosen over FD , and is Fired . Thus the child performs a Compare on the units column of the problem , which puts the symbol ( S > M ) in WM . On the next cycle the applicable rules are FD , B2A , CM , and IN , but CM and IN are discarded , and by the principle of recency ( in WM ) B2A wins out over FD . So B2A fires , depositing the element ( BORROW ) in WM . Since ( BORROW ) is the most recent element , it is clear that all rules except BS1 and BS2 are ruled out . There are no grounds for choosing between them , so they fire off in either order on successive cycles . They carry out the borrowing . By now all the rules which for one reason or another had priority over FD have fired , so it is now the turn of FD . It deposits in WM first the subgoal ( NEXTCOLUMN ) , and then the subgoal ( FINDDIFF ) which triggers TS . The actual differencing now takes place , between a minuend of 14 and a subtrahend of 8 , yielding the element ( RESULT 6 ) in WM . And so on . Rule NXT is responsible for handling the right - to - left order of processing the columns . There is a rule for writing down the answer digits ( WA ) , and a rule to stop the processing when the subtraction is complete ( rule DONE : the ( NO - MORE ) is put into WM by a ShiftLeft which fails to find another column ) . We have also included a rule B2C for a shortcut in processing the special case where S = M . Rule AC , a rule from addition for performing carries , and the row of dots 162 YOUNG AND WSHEA beneath it are added as reminders that although it is convenient to refer to the rules in Figure 2 as a " system , " they do not in any way form a structurally delimited " package " or " module . " Of the thousands of rules the child has , Figure 2 shows just those which happened to be relevant to subtraction . But if during the course of a subtraction circumstances arise appropriate for triggering some other rule , then that other rule will fire . In the PS as it stands , AC will never fire because in correct subtraction an itein to match ( RESUL ; T 1 = x ) will never be present in WM . However , as we shall see , if some of the subtraction rules are omitted then there will be circumstances in which AC may fire . A PS for subtraction using the method of equal addition can be obtained by replacing rule BS2 by a new rule which reads : BS3 : Borrow + Carry . We can justify the analysis , implicit in these rules by citing contemporary methods for teaching subtraction . Typically ( Fletcher , 1971 ) the students are given separate practice in taking differences and in comparing . They are initially given examples that do not require comparison . Borrowing is taught as the actions in BS 1 and BS2 . Modeling the Errors The children whose work was analyzed by Bennett ( 1976 ) had been taught the method of decomposition . In order to model their errors we added or omitted various rules from the PS of Figure 2 and then ran the modified PS using an OPS2 - like interpreter . Figure 4 shows the various new or modified rules that were drawn on in the analysis . ( It should be noted that these rules are not meant to form a production system : No one child would have them all . Figure 4 merely for convenience collects together in one place all the new rules mentioned be - low . ) The different error types are discussed individually , but it should be noted that several of them ( such as inappropriate borrowing ) do not occur in the special case where the digits in a column are equal . This is explained by the presence of rule B2C . The mistake of simply taking the smaller digit in a column from the larger ( seen in Example A of Figure 1 ) is obtained by omitting either the comparison 828 : S < M 81 : M = m , S = r NZN : M = m , S 0 ZNN : M 0 , S = s NU : M = m , SO ZNZ : M 0 , S = s SMO : S > M NNN : M = n , S = n Borrow Borrow Rewlt = m , NextColumn Rewlt = r , NextColumn Result 0 , NextColumn Ruult 0 , NextColumn Result 0 , NextColumn Result = n , NextColumn Fiiure 4 . Modified and additional rules rieeded to modd wrors in k d s ( 1976 ) data . ( N . B . h e r u k do not form a " RPduction Systm " - sw text for clarification . ) ERRORS IN . CHILDREN ' S SUBTRACTION 163 ' rule CM or else rule B2A which triggers the borrowing procedure . Either hy - pothesis is plausible , and for a particular student , analysis of past protocols might provide information to determine which is in fact the case . Another possibility is that both rules for the borrowing procedure are missing : BS 1 and BS2 . Errors in which the child borrows when S < M and not when S > M ( Examples A , B , C , Figure 1 ) suggest that the child has acquired , instead 9f B2A , an erroneous rule B2B which is similar but has the condition reversed . If the child had both B2A and B2B , then he would be making errors of the third kind given in Table 1 , i . e . , always borrowing . The explanatory power of these two rules should be noted . The four possible PSs generated by each rule being either present or absent account for , first , correct performance , and second , the fmt three types of error shown in Table 1 , i . e . , for 115 of the total of 124 algorithm errors found in the corpus ! Another possible reason for always borrowing is that instead of the com - parison rule CM , the student may have acquired a borrowing rule which always fires , such as B 1 . Such a rule could result from a student ' s believing that borrow - ing is an essential part of subtraction , perhaps as a consequence of being given a series of examples in which borrowing is always needed ( a point we will return to in the later discussion ) . In Example B ( Figure I ) , after taking the difference - between 16 and 2 to obtain 14 , the PS deals with the 10 by rule AC . Stude r i ' ts almost invariably complete their subtraction problems , fiiding some way to use up any spurious digits generated en route . The same thing happens in Example C , in this case giving " the right answer for the wrong reason . " The zero - pattern errors are also easily accounted for , since particular patiern - sensitive rules fit naturally into the framework of the existing PS . For example , from his earlier work on addition the child may well have learned two rules sensitive to zero , NZN and ZNN . Included in a PS for subtraction , the fmt , NZN , will do no harm , but rule ZNN will give rise to errors of the " 0 - N = N " type . Similar rules would account for the other zero - pattern errors . If the child remembers from addition just that zero is a special case , and that if a zero is present then one copies down as the answer one of the numbers given , then he may well have rules such as NZZ or ZNZ . The remaining rules in Figure 4 are needed to account for two of the less frequent errors . Rule SMO yields errors like that illustrated by Example D , where the child " can ' t take " a larger number from a smaller . Rule NNN covers the cases where a child asked for the difference between a digit and itself writes down that same digit . It is clearly another instance of a " pattern " rule . EVALUATION OF PRODUCTION = STEM MODELS We wish to answer the question : How well do the variant PSs just described account for the errors in Bennett ' s corpus ? There is , unfortunately , no genetally agreed - upon technique for answering this question , comparable to the use of 1 64 YOUNG AND ( YSHEA inferential statistics for testing simple quantitative models . Instead we had to devise an appropriate method . Two preliminary issues need to be settled . Span of Consistency . If we were to consider the corpus problem by prob - lem , it is clear that for each error . we can , with sufficient ingenuity , write a PS which exactly reproduces that particular error . But equally clearly , to offer a separate PS for each error is of no psychological value . If a PS , ( or any other model ) is to have validity as a representation of a child ' s subtraction abi1ity ; then that one PS must account for the child ' s performance over a whole range of problems . At first sight it might seem that this range should be the whole of a child ' s subtraction performance , i . e . , that we ought to allow just one PS to model each child . But the fact that the two tests taken by ( some of ) the children were administered some months apart , during which time the child ' s subtraction skill may well have changed , suggests that a more realistic requirement would be to demand that a single PS be used to cover an entire script , i . e . , the performance of a given child on a given occasion . Thus we will say that the span of consistency is to be an individual script . Constraints on Production Rules . Even given an entire script , one can imagine writing production rules whose conditions were so complex , bizarre , and ad hoc that each subtraction problem was effectively treated as a separati ' case , with the PS carefully tuned to match exactly the child ' s answers . Once again , this could be of no psychological value . We need instead to constrain the allowable rules to a form which is sufficientlyprincipled to act as a plausible and general model of the skill . At the present stage of the art of using PSs as psychological models it is not possible to state precisely an appropriate set of constraints , but the following considerations convey the flavor and seemed suffi - cient in practice : , 1 . The PSs given so far all share a definite style : for instance , the simplicity of the left - and righthand sides , and the absence of meaningless signals in WM . This style is to be shared by all variant " faulty " PSs . 2 . Since we are not concerned with modeling the number - fact errors , explicit numerals are banned from appearing in the conditions of the rules ( except for the zero in the zero - pattern rules ) . 3 . Variant PSs should share as many rules as possible . In other words , instead of freely creating new rules on an ad hoc basis , the analyst should , so far as is possible , build his PSs by combining rules from a common " kit " ( Young , 1976 , 1978 ) . In practice , no rules other than those shown in Figure 4 were added . Accounting for the Corpus Given the script as the span of consistency , the method of evaluation follows directly : , One writes an ( appropriately constrained ) PS which maximizes the ERRORS IN CHILDREN ' S SUBTRACTION 165 agreement between the predictions of the PS and the child ' s performance on the script , and the valuation of the PS is a measure of the claseness of this agree - ment . The fit of the PS is measured by scoring one " hit " for each erroneous answer correctly matched . Obviously , it may sometimes be possible to increase the number of hits at the expense of making a number of " false errors , " i . e . , errors predicted by the PS which the child does not in fact make , For example , as discussed above , if the script contains zero - pattern errors of type " 0 - N = N , " the PS will " hit " them if it includes rule ZNN . But it may be that the child does not make this error on every problem which offers an occasion for it , i . e . , those which have a top digit of zero . In this case the PS will make " false errors " for those problems where the child does not make this mistake . Our evaluation technique is to subtract the false errors from the hits , i . e . , to calculate : net score = ( hits - false errors ) = ( total errors - misses - false errors ) . This seems right since , one , it is " fair " in the sense that a proposed change to a PS which yields one extra hit at the cost of one extra false error , would leave the net score unchanged ; and two , it is a measure of the degree of overlap ( i . e . , agreement ) between the predictions of the model and the child ' s actual perfor - mance . Thus the procedure is , for each script , to begin with the " correct " PS of Figure 2 , which of course predicts no hits and makes no false errors , and then to incorporate successive changes so long as they improve the net score . It will be seen that , at least in simple cases , a proposed change to a PS leads to an increase in the score if it predicts an e m r which is in fact made on more than half of the occasions when it could be . Results TABLE 2 Production System ~ nalysis of Fault ) Algorithms in Bennett ' s ( 1976 ) Corpus - Na Fault type Drop rules Add rules 4 Borrow - when - < B2A 828 4 0 - N = N ZNN 4 Take smaller CM or B2A 1 Take smaller and N - 0 = 0 CM or B2A N U 1 0 - N = O P I Z 1 S > M + zero B2A SMO 1 N - N = N NNN 1 0 - N = N a n d N - N = N ZNN , NNN ? Number of scripts ( out of 51 ) which exhibited the fault . Table 2 shows for each of the variant PSs which of the rules of Figure 2 have to be dropped , and which rules ( of Figure 4 ) added , in order best to fit the child ' s 166 YOUNG AND O ' SHEA script . The table shows that the faulty methods can mostly be created from the " correct " PS by combining the omission of rule CM or B2A with the addition of one or more pattern rules . The exceptions both involve rule B2A , which is responsible for triggering borrowing . In two cases it has to be replaced , once by a rule with a reversed condition , once by a rule with an incorrect action . TABLE 3 Fit between Production System Model and Bennett ' s ( 1 976 ) Data Algorithm + patfern False Net score errors Hits Misses enws ( hits - false e m d The quantitative results of optimizing the PS for each script are sum - marized in Table 3 . Comparing the net score of 128 with t ! ie 178 errors provides the answer to the question of how well the PS accounts for the dala : The answer is that the PS accounts for a little over two - thirds of the errors . Among the scripts are two in which , of the 23 occasions when a particular error could be made , it actually is made on just half ( 1 1 or 12 ) . However , it happens that in both cases , the occasions on which the errors are made are thefirst ( 1 1 or 12 ) opportunities . It is as if the children were consistently making the error , then realized what they were doing , and thereafter got it right . If we relax the span of consistency slightly to allow the PS for these two children to be changed once in the middle of the script , then the net score rises to 150 out of 178 , which accounts for over five - sixths of the errors . Because of the nonstochastic nature of the PS models used here , and because they have been individually fitted to data from different children , it is difficult to test this degree of fit for " statistical significance " in the usual way . However , a guide to the likelihood of obtaining this amount of agreement " by chance " can be found by the following argument . The PS models can be re - garded as selecting a subset of 192 problems ( = 160 + 32 ) in which all the errors should occur . In fact ( Table 3 ) , of the 178 errors found , 160 lie within that subset and 18 fall outside it . Now there were 1549 problems in all , so if the children had been making errors " at random , " about 178 x 19211549 = 22 of them would have fallen in the subset , the remaining 156 outside it . These figures can be treated as the " expected " values in a 2 test ( Siegel , 1956 ) which yields a 2 = 933 , df = 1 , with an associatedp < < . OOl . So , although these values should not be taken too seriously ( since strictly speaking the preconditions for the 2 test are not met ) , this calculation confirms one ' s intuition that the agreement cannot be ascribed to chance . Another way to interpret these numbers is to consider the question : How consistent are the children ? In other words , given that a child makes an error of a particular type : then quite irrespective of whether the PS model accounts for his ERRORS IN CHILDREN ' S SUBTRACTION 167 behavior , how likely is he to make that error again on its other possible occa - sions ? Although this seems different to the question about the evaluation of the PS , its quantitative answer is the same . This comes about because to the extent that the children ' s errors are " consistent , " i . e . , rule - governed , then it turns out that we can capture that consistency in a PS of the allowed form . Thus we can say of the children ' s consistency that , in their algorithm and pattern errors , about two - thirds of the errors are part of an ( identijkbly ) consistent pattern of be - havior . Another approach to answering the question is to consider how consistent are the individual children . Of the 5 1 scripts , 13 ( 25 percent ) were totally correct and 5 ( 10 percent ) were perfectly consistent with a faulty algorithm ( i . e . , and contained no number - fact errors ) . A further 12 ( 24 percent ) were consistent with a faulty algorithm except for just one problem , and a further 10 ( 20 percent ) were consistent if one ignores the number - fact e m . Thus a total of 30 ( 59 percent ) were consistent except for at most one problem , or 40 ( 78 percent ) discounting number - fact errors . REANALYSIS OF BROWN AND BURTON ' S BUGGY DATA Fortunately an independent corpus of data exists on which our analysis can be tested . An alternative technique for modeling children ' s subtraction e m has been proposed recently by Brown and Burton ( 1978 ) . They adopt a notation which they call a procedural net , consisting of a collection of subprocedures ( written in a computer language , LISP ) together with a diagram showing their hierarchical relations . Each procedure is given as a correct version , but as - sociated with it are one or more different " buggy " alternatives which can be " plugged in . " A particular child ' s errors are simulated by replacing one or two selected subprocedures by appropriately faulty variants and then running the modified program . The Brown and Burton study draws on a data base of 19 , 500 subtraction problems done by 1325 Nicaraguan schoolchildren . Included in their paper is a A table1 of the 15 most frequently occurring bugs , which includes all that were made consistently by at least 9 of the children . On examining this table , one is struck by the fact that the majority of the bugs - in fact all but one of them - have to do with zeros in the top number ; these bugs arise when either subtracting or borrowing from a column with a zero in the minuend . There is nothing surprising about this , since borrowing from zero is the hardest part of the decomposition method and indeed reveals its main weakness as an algorithm , What makes one suspicious is the similarity of the different bugs . They evidently share elements ' This table of 15 bugs is given as Appendix 5 of the original technical report ( Brown & Burton , 1977 ; headed ' The 20 most frequently occurring bugs " ! ) . The published paper , presumably for reasons of space , shows only the first 14 . , I 68 YOUNG AND CTSHEA in common and appear to consist of minor variants of just two or three " core bugs . " This in turn suggests that a more satisfactory analysis would reveal the connections between them and would impose some structure on this rather rag - ged collection . In order to see whether our analysis of subtraction would throw any light on this matter , the PSs used so far were extended to handle subtraction problems of the , type studied by Brown and Burton and were then used to examine the relationship between the " correct " PS and the versions which produce the vari - ous bugs . The main results are as follows . The extension to new problem types is straightforward . In order to cope with borrowing from zero and with the case where the subtrahend has fewer digits than the minuend , the PS of Figure 2 has merely to be extended by adding further rules to the existing ones , in particular to spell out the mechanics of Decrementing which up to this point had been assumed to " just happen . " The necessary extra rules are shown in Figure 5 . LHE : TEN : DEC : DNL - DZ1 : DZ2r Dl & PROP : PZ : PNZ : M = m , S blank M ten , S = s k m e n t Decrement , Nonzero Decrement , Zero Dwement , Zero Decrement , Zero Ten Propagate Propugate , Zero Propagate , N a b Propagate ' ChangeZeroToNine " ReduceTmToNine " Look4tLeftM Decrement Decrement Figure 5 . Additional ~ l e s needed for Brown and Burton ' s ( 1978 ) poblmls . Rule LHE says that a blank in the subtrahend is to be treated as if it were a zero . Rule TEN applies specifically to problems of the form : The rule says that for the final ( lefthand ) column , the child subtracts the S digit from an M of 10 , rather than performing the usual borrowing steps . The rule is needed because in this special case the normal process yields bizarre results . Initially , it would have the child cross out the 1 to the left of the 0 and then immediately write one back in again , which is odd enough . Then , the outcome would be a number with a leading zero , quite unlike the numbers the child is used to , It seems far more likely that he would treat the " 1 0 " as ten . The rest of the rules are concerned with explicating the process of Decrementing . Rule DEC always fires first to see whether or not the digit to be borrowed from is zero . Rule DNZ deals with the straightforward case when it is nonzero . Rules DZ1 and DZ2 show that in order to borrow from zero , the child has to remember to do two ERRORS IN CHILDREN ' S SUBTRACTION 1 69 things : ( a ) to replace the 0 by a 9 , and ( b ) to propagate the carry leftward . ( We will see in a moment that many of the errors are due in part to his forgetting to do one or the other ) . Rules PROP , PZ , and PNZ spell out the details of the propaga - tion . Rule Dl0 handles borrowing from the special configuration of 10 described above . TABLE 4 Production System Analysis of Brown and Burton ' s ( 1 978 ) Most Frequent Bugs N a Bug type Drop rules Add wles 57 Bomd + om - O DZ1 , Dl0 54 Smaller - from - larger CM 50 Borrodrom - 0 and I & - 10 - OK DZ1 34 0 - N = N and mow - ovw - 0 - borrow DZ2 ZNN 14 0 - N = N and stops - borrow - at4 DZ1 , DZ2 ZNN 13 Smaller - fromlorger ond 0 - N = 0 CM ZNZ 12 0 - N = 0 and moveova - O - bomm DZ2 ZNZ 11 Borrow - * om - OondN - 0 - 0 DZ1 , Dl0 N U 10 0 - N = O a n d N - 0 = 0 ZNZ , N U 10 Bonow - from - 0 and 0 - N = N ' DZ1 , Dl0 ZNN 10 Moreom - 0 - bono ~ DZ2 10 N - 0 = 0 N U 10 0 - N = N TEN ZNN 9 0 - N = NandLeft - 10 - OK ZNN 8 Bonow - * om - 011 - 0 PNZ a Number of childrm ( out of 1325 ) who consistently exhibited the bug . The PS formed by taking Figures 2 and 5 together now represents a sub - stantially complete process model for ( correct ) multicolumn subtraction by the method of decomposition . Table 4 , which is analogous to Table 2 , lists Brown and Burton ' s 15 most frequent errors and shows for each error which of the rules of Figure 5 ( or Figure 2 ) have to be dropped , and which zero - pattern rules added , in order to exhibit that error . The table makes evident that the class of what we have called zero - pattern emrs ( 0 - N = N , 0 - N = 0 , N - 0 = 0 ) is essentially independent of , and can occur freely in conjunction with , the other ( " al - gorithm " ) errors . Moreover the algorithm errors can without exception be ac - counted for by simply omitting rules from the correct set . In other words all 15 errors can be accounted for by the omission of rules from the " correct " PS , together with the inclusion of zero - pattern rules . There is no need for " wrong " rules at all . The implications of this reanalysis are explored in the discussion below . It would be satisfying to be able to conclude this reanalysis by computing for Brown and Burton ' s data a score showing how much of their data was ac - counted for , as was done for Bennett ' s data . Unfortunately , because of the form 1 70 YOUNG AND WSHEA in which Brown and Burton ' s analysis is ' . presented , this is not possible . The reason is worth understanding in some detail , as it sterns from the difference in the ways that the quantitative assessment of the two models have been done . In fact the approaches are in an interesting way complementary : our analysis has been carried out on a problem - by - problem basis , excluding some of thk problems but dealing with all the children . Brown and Burton ' s is made on a child - by - child basis , excluding . some of the children but dealing with all the problems . In other words , whereas in our analysis we deemed that certain errors ( the number - fact errors ) were outside the analysis , but otherwise assessed the models by their coverage of the remaining problems , Brown and Burton first of all categorize their students by their degree of consistency with the model , deem the less consistent children to be outside the analysis , and assess the model on the proportion of children remaining . . One can however try to perform the comparison the other way round , by applying the evaluation technique used by Brown and Burton to Bennett ' s data . Brown and Burton provide ( p . 180 ) an elaborate set of criteria for sorting chil - dren into six classes of consistency . Class l contains those children who get all the problems correct , Class 2 those whose errors are fully accounted for by the model , and Class 3 those whose errors are , roughly speaking , explained by the model more often than not . For Brown and Burton ' s analysis , only children in classes 2 and 3 are said to " have " the bug in question . Applied to the 5 1 scripts in Bennett ' s corpus , 13 ( 25 percent ) fall into Class 1 , 12 ( 24 percent ) into Class 2 , and 5 ( 10 percent ) into Class 3 . We note in passing that these figures indicate that Bennett ' s students are very similar to Brown and Burton ' s in t e r n of consistency ( 34 percent in classes 2 and 3 , as against 38 percent ) , though rather more get all the problems right ( 25 percent against 3 percent ) . If we take just those 34 percent of the children who pass Brown and Burton ' s criterion , we find that their net score ( as defined earlier ) comes to 127 , just one less than the 128 found by considering all the children . This is not unexpected , since it is the more " consistent " children ( however defined ) who contribute predominantly to the score . The conclusion is that , unsurprisingly , the two approaches have about the same degree of empirical coverage , at least on Bennett ' s data , and since our reanalysis ' accounts for at least all of Brown and Burton ' s mostfrequent bugs , the same would be expected to hold true for their data too . The limitation on the coverage of either model ( to about one - third of the children , two - thirds of the errors ) appears to be determined not so much by the limited power of the models as by the uncaptured variability in the children ' s performance . DISCUSSION Role of Production Systems The ability to account for the different types of errors in a way that seems to us ( and , we hope , to the reader ) quite simple and straightforward , depends critically ERRORS IN CHILDREN ' S SUBTRACTION 171 upon some special properties of the PS language used to express the models . First , there is the question of the " grain size " of the analysis . PSs can be written at a variety of levels of detail . Indeed , during the course of this work we wrote several PSs at different levels . Some involved a more detailed analysis and included a finer division of the conditions and actions of the rules in Figure 2 . Others were coarser and used , for example , just a single borrowing rule . The objective was to choose a grain size fine enough to capture the distinctions in the data , i . e . , the diierent types of error , while ensuring that each individual rule could plausibly have been learned in the context of school mathematics . The ability to trade off parsimony against plausibility in choosing a level of detail appropriate to the data is one of the virtues of PS . analysis . Second , there is the independence of the rules in a PS like that of Figure 2 Each rule represents an intelligible component of the child ' s total subtraction ability . This makes possible the analysis of the skill into components which may be independently present or absent in a child ' s repertoire at any given time . This same independence underlies the fact that individual rules embodying different aspects of subtraction can simply be omitted from the set without the need to alter any of the ones that remain . The ability to write PSs which , when some of their rules are omitted , continue to tackle the original problem in a modified but still psychologically realistic way , contrasts favorably with the difficulty of achieving this using any of the more familiar means of expressing information - processing models , such as flowcharts or sequential - flow computer languages . This robust - ness of PSs mirrors the 0bSe ~ ation that students normally " finish " their subtrac - tion problems , no matter how faulty their methods . The conflict resolution method of the 0PS2 interpreter plays an important part in achieving this modularity . Without the conflict resolution it would have been necessary to include in the PSs a number of " housekeeping " activities - - rules , or actions in rules , which are concerned not with the subtraction problem itself but rather with the task of keeping the PS running smoothly - and these would have imposed interdependencies among the rules , thereby severely reduc - ing their modularity . The conflict resolution also makes it possible to capture the intimate mixture of data - driven and goal - driven activity that permeates the task . Although the task has a clear goal - subgoal structure reflected in the PS , much of the processing is triggered by the last item put into WM , in a working - forward manner . This means that the PS is able to " notice " special events as they occur and is sufficiently responsive to be willing to violate the hierarchical goal struc - ture when necessary . For example , if the main control structure of the PS is viewed as an AND - goal tree , as in Figure 6 , the main goal PROCESSCOLUMN has three subgoals to be performed in order . COMPARE , FINDDIFF , and NEXTCOLUMN . However , if S = M , so that rule B2C fires , then control jumps across the tree , to the NEXTCOLUMN node from somewhere below the COM - PARE . Thus the conflict resolution method gives the PS a control structure more flexible than a strict goal hierarchy . YOUNG AND O ' SHEA ProcessColumn Figure 6 . Goal structure of the production system of Figure 2 . Comparison with BUGGY The " procedural net " technique adopted by Brown and Burton ( 1978 ) and described above has many merits . For example , we would endorse their insis - tence that many of the mistakes children make are principled and are due to their following an incorrect procedure rather than , say , to an inability to follow a correct one . And we find admirable their use of BUGGY to help trainee teachers and to convey an appreciation of the fact that apparently random " surface " errors can be understood as manifestations of a simple , but deep , bug . However , BUGGY also has pretensions to psychological validity , and is offered as an appropriate way to understand the sttucture of a child ' s subtraction skill and the nature of his errors . Indeed strong claims are made in this regard : " The diagnostic modeling technique . . . can take the answers that a student gives on a test and . . . show not only which questions were answered incor - rectly but why they were incorrectly answered " ( Brown & Burton , 1978 , p . 183 ) . This claim seems to us questionable in view of certain features of the procedural net analysis . Although Brown and Burton quite correctly draw atten - tion to the difference between the " surface manifestation " of a bug and its underlying cause , we would argue that their bugs are themselves too superficial to serve an explanatory role , and are more like " symptoms " than " causes . " A number of signs point to this conclusion . One of them is the large number and close similarity of the different bugs . It suggests , as we argued earlier , that the classification is too superficial and that a deeper analysis would explain the behavior as a by - product of fewer but more fundamental kinds of - - - - - - - - - - - - - - errors . And we showed that this is indeed the case for the 15 most frequent bugs . ERRORS IN CHILDREN ' S SUBTRACTION 1 73 Another sign is the comparative inexplicitness of the procedural nets . Brown and Burton quite correctly distinguish between the conceptual level of a model and the implementation level where details may be " swept under the rug " ( p . 153 ) . The trouble is that it is at the implementation level that all their manipulation occurs . Bugs are simulated by writing ( in LISP ) new versions of one or more of the subprocedures , the network itself remaining unchanged . Since the changes are not reflected at the level of the network itself , the analysis of subtraction ability implicit in the net is largely wasted since it provides no basis for predicting , characterizing , or correcting the possible errors . Nature of Errors However , these are mainly technical objections . More relevant here is the fact that procedural nets and PSs differ in their view of the psychological nature of subtraction errors . According to Brown and Burton ( 1978 ) , children make errors because they have faulty versions of certain components of the skill . According to PSs , the errors are made primarily because certain components are missing . The respective analyses differ too in what they propose as the units from which the skill is composed . Brown and Burton follow a tradition of hierarchical analysis ( Gagne , 1970 ; Resnick , 1973 ) in which the components of the skill are taken to be closed subprocedures , representing self - contained subskills which actually appear in the final performance . In order to generate behavior from a collection of such units , one has to add to them a control structure which is external to the subprocedures themselves . PSs on the other hand avoid this psychologically unwarranted distinction between processing and control . Ac - cording to this view , the components of the skill are rules which specify what is to happen and when . A collection of such rules forms a complete model . Nothing extra needs to be added . These alternative views of errors correspond to a difference the analysis of the skill itself . Brown and Burton regard the skill in terms of an algorithm for performing subtraction . From this viewpoint , the prototypical kind of change to make to the algorithm is to replace a self - contained part of it ( i . e . , a subpme - dure ) by an alternative , possibly buggy , version . The PS analysis instead sees the skill as a more anarchic structure , made up from a collection of independent pieces each representing a chunk of codified local knowledge the child has about how to subtract . According to this view , the units which may change or be omitted are the individual rules . We argue that on the present evidence this is the more fruitful analysis . Repair Theory Many of the differences between BUGGY and the PS analysis proposed here are resolved in a pleasing and recent development from the earlier work . Brown and VanLehn ( 1980 ) put forward the outlines of what they call a repair theory of 1 74 YOUNG AND WSHEA bugs in subtraction . The essential idea is that some fault in a child ' s core proce - dure for subtraction leads sooner or later to an impasse , a situation from which the core procedure is unable to proceed . When this happens a heuristic problem - solver is brought into play to devise a repair that will allow the core procedure to continue . The observed bugs thus arise , roughly speaking , from the cross product of the set of possible impasses with the set of possible repairs . Repair theory promises an important theoretical advance . As Brown and VanLehn repeatedly point out , the theory is principled and so avoids the objec - tion made to BUGGY that one has to hand - code arbitrarily " buggy " versions of the subprocedures . The major contribution , it seems to us , is the insight that the troubles that arise in subtraction , i . e . , the things that can go wrong , can be analyzed separately from the child ' s responses - how he attempts to cope with them . ( The implied contrast is with theories such as BUGGY or our PS analysis which try to deal with both in one go . ) This separation pays dividends in both areas . On the one hand , Brown and VanLehn can now represent the core proce - dure , as a simple PS , similar to our Figure 2 and using a similar OPS2 - like conflict resolution scheme . Moreover , faulty procedures are created by " delet - ing " ( i . e . ; omitting ) ' individual rules from the PS . On the other hand , the fact that the child can produce a variety of responses to a given impasse ( itself caused by a particular faulty procedure ) means that the theory can come to grips with certain aspects of the variability of the child ' s perfonnance . For example , a child may switch between a number of different bugs even within the course of a single script ( what Brown and VanLehn call " bug migration " ) . Repair theory predicts that these different bugs will belong to a single family , since they all arise as responses to the same impasse . One main reservation concerns Brown and VanLehn ' s strategy of treating all bugs as equal , irrespective of their frequency of occurrence . Because of this , and because the more bizarre bugs tend to be among the less frequent , the shape of the theory is determined more by the very rare bugs than by the common ones , and this seems to us an infelicitous way to build a theory intended to be psychologically , empirically valid . Repair theory is still in its early days . Using Brown and VanLehn ' s chosen evaluation metric , the number of known bugs generated , it is predicting only 21 out of 89 , and because no attention is paid to their relative frequency it is impossible to estiniate what these 21 bugs yield by way of empirical coverage . Thus it would be premature to try at this stage to compare Repair Theory with BUGGY or our PS analysis in terms of how well it accounts for the data . But we await future developments with interest . Implications for Teiching In the absence of a satisfactory theory of classroom learning it is impossible in any strict sense to " derive " pedagogical recommendations from our analysis . ERRORS IN CHILDREN ' S SUBTRACTION 1 75 But it is worth demonstrating just one case where the PS analysis has conse - quences for classroom practice . This is the issue of consolidation versus dis - crimination training ( Ausubel & Robinson , 1969 ) . When a new aspect of a skill is introduced , current educational psychology sees it as a new box - like " component " of the skill . So in order to " establish " the new component " firmly , " massed practice is usually given aimed specifi - cally at exercising that new aspect . This is consolidation training . However , if the unit of learning is not a subprocedure but a condition - action rule , it becomes apparent that learning the circumstances in which the rule is evoked is as impor - tant as leaming the action to be performed . In fact the action itself will often already be familiar . According to this view , the appropriate kind of practice would mix the new aspwt of the skill with ' the older ones in order to exercise the detection of the new rule ' s conditions . This is discrimination training . This distinction suggests an account of the origin of one of the more puzzling subtraction errors , that of always borrowing ( Table 1 ) . From examining children ' s workbooks one finds that as soon as the topic of borrowing is intro - duced , the student is immediately presented with a long series of two - column subtraction problems all of which require borrowing . This is an ideal arrange - ment for acquiring an ( erroneous ) rule which says that one should begin a subtraction problem by borrowing ( i . e . , rule B1 of Figure 4 ) . It seems likely that this difficulty would never have arisen if the children had been given instead a mixture of problems , some of which required borrowing and some did not . As well as providing guidance for classroom teaching , the models pre - sented here could be used as student models for a program for teaching subtrac - tion ( Self , 1974 ) or with a computer tutor l i e that of O ' Shea ( 1979 ) where the tutorial strategy is itself represented as a set of production rules . Two issues in contemporary ' & search into the teaching of mathematics are that students can sometimes obtain correct answers by the use of principled but incorrect strategies , and their adoption of correct but untaught alternative methods . The PS analysis provides a way of describing such strategies in the case of subtraction and makes it possible to estimate how a particular strategy will be affected by a planned tutorial intervelltion . CONCLUSIONS With the help of production systems we have been able to construct parsimonious models of children ' s subtraction behavior which : 1 . Model subtraction skill as a collection of independent rules ; 2 . Can be " run " to generate actual behavior for each problem ; and 3 . Can account for the errors commonly seen in terms of the omission of correct rules or the inappropriate inclusion of rules Erom other arithmetical skills . 1 76 YOUNG AND WSHEA We have presented a technique for evaluating the production system model against the data , and shown that it accounts for at least two - thirds of the errors made by 10 - year olds on a written test . The same model accounts for the 15 raost frequent bugs reported by Brown and Burton ( 1978 ) , and provides a reinterpreta - tion of their data in terms of missing , rather than buggy , components . The account of subtraction errors presented in this paper is consistent with an earlier analysis of the structure of children ' s cognitive skill ( Young , 1978 ) , which showed that the skill is organized not as a tightly , integrated unitary " strategy , " but rather as a redundant , somewhat . , messy collection of indepen - dent rules capable of exhibiting strategies in a flexible and adaptive way . One of the aims of the work reported here was to extend . this analysis to the case of subtraction . This " piecemeal " view of cognitive skill leads naturally to an interpretation of emrs in terms of missing or inappropriate rules , and the ability to sustain this account in the face of a considerable body of data on children ' s actual subtraction errors lends strong support to the analysis . Of course , the model presented here has its limitations . Apart from the question of mistakes in the recall of number facts , the model fails to account for phenomena such as runs of errors or the effects of " set " ( Thyne , 1954 ) . Fur - thermore , although this work has taken the view that leaming subtraction consists of the acquisition of the appropriate new rules , we have not actually addressed the issue of where these new rules come from . That question must be deferred to a later paper . REFERENCES Anderson , J . R . Language , memory and thought . ~ illsdal & N . J . : Erlbaum . 1976 . Asklock , R . B . Error patterns in computation . London : Bell and Howell , 1976 . Ausubel , D . P . , & Robinson , F . G . School learning : ~ n introduction to educatioml psychology . : York : Holt . Rinehart & Winston , , 1 % 9 . Bennett , M . SUBSTITUTOR : A teaching program . Unpublished project report . Department of Intelligence , University of Edinburgh , 1976 . Bmwn , J . S . , & Burton . R . R . Diagnostic models for procedural bugs in basic mathematical skills . Beranek & Newman , December . 1977 . Brown , J . S . , & Burton , R . R . Diagnostic models for procedural bugs in basic mathematical skills . 1978 , 2 . 15S192 . Brown . J . S . , & VanLehn , K . Repair theory : A generative theory of bugs in procedural skills . 1980 . 4 , 379 - 427 . Downes , L . W . The teaching of arithmetic in primary schools . oxford : Oxford university Press , 1958 . Fletcher , H . Mathematics for schools . Reading , Mass . : Addison - Wesley , 1971 . Forgy , C . , & McDennott , J . OPS , a domain - independent production system language . Proceedings of the 5th Internatioml Joint Conference on Anijicial Intelligence , 933 - 939 , Cambridge , Mass . , 1977 . Gagne , R . M . The conditions of learning ( 2nd ed ) . New Yo & Holi , Rinehart & ' Winston , 1970 . Klahr , D . , & Wallace , J . G . Cognitive development : An information processing view . Hillsdale , N . J . : Erlbaum , 1976 . ERRORS IN CHILDREN ' S SUBTRACTION 177 Lankford , F . G . Some computational strategies of seventh grade pupils . ERIC reports . School of McDermott , I . , & Forgy , C . Production system conflict resolution strategies . In D . A . Waterman & F . Hayes - Roth ( Eds . ) , Pattern directed inference systems . New York : Academic Ress , 1978 . Newell , A . , & Simon . H . A . Hurnan . problern solving . Englewood Cliffs , N . J . : Prentice - Hall , 1972 . O ' Shea , T . A self - improving quadratic tutor . International Journal of an - ~ achine Studie ? , 1979 . 97 - 124 . symposium . instructional Science . 1973 , 2 , 31 1 - 362 . Self , J . A . Student models in CAI . International Journal of Man - Machine Studies , 1974 . 6 , 261 - 276 . McGraw - Hill , 1956 . Sloman , A . On learning about numbers . Proceedings offirst AlSB Conference . Sussex , 1974 . Thyne . J . M . Pafferns of error in the addition number facts . London : University of London Press , 1954 . J . D . Teaching technique in primary math . Windsor : National Foundation for Educational Research in England and Wales , 1971 . & Hartley , J . R . Some learning models for arithmetic tasks and their use in computer based learning . British Journal of Educational Psychology . 1971 . 41 , 39 - 48 . Woods , S . , Resnick , L . B . , & Groen , G . An experimental test of five process models for subtraction . l975 , 67 , 17 - 21 . Young , R . M . Seriation by children : An art @ cial intelligence analysis of a Piagetian task . Basel : 1976 . Young , R . M . Mixntres of strategies in s ~ ructurally adaptive production systems : Examples from seriation and subtraction . Proceedings of Workshop on Pattern Directed Inference Systems . SIGARTNewsletter , June 1977 . Young , R . M . Strategies and the shvcture 0f . a cognitive skill . In G . Underwood ( Ed . ) . Strategies of information processing . London : Academic Press , 1978 .