CNN Based iPS Cell Formation Stage Classifier for Human iPS Cell Growth Status Prediction Using Time - lapse Microscopy Images Slo - Li Chu , Li - Yu Lin and Ming - Dar Tsai Dept . of Information and Computer Eng . Chung Yuan Christian University slchu @ cycu . edu . tw , mingdar @ cycu . edu . tw Kuniya Abe , Kazuhiro Sudo and Yukio Nakamura BioResource Research Center , RIKEN Tsukuba , Japan abe @ rtc . riken . jp , kazuhiro . sudo @ riken . jp , yukio . nakamura @ riken . jp Hideo Yokota Center for Advanced Photonics , RIKEN Wako , Japan hyokota @ riken . jp Abstract —CNN classifiers using microscopy images to pick up induced pluripotent stem ( iPS ) cells from a lot of non - iPS cells ware proposed to improves efficiency of human iPS cell production . By selecting iPS - forming cells at early culture stage , it should be more promising to reduce a considerable amount of work . This paper proposes a CNN reprogramming stage classifier trained by respective types ( grown into high - , medium - , and low - growth status of iPS - like cells ) of time - lapse images taken from the completed cell culturing process . These trained CNNs are used to classify a time - lapse image taken in cell culturing as one stage ( a number of consecutive frames ) of a respective set of trained time - lapse images . The differences between the actual stage with respective classified stages are than calculated to decide which stage of the completed cell this time - step image taken in cell culturing is near to , then to predict the iPS cell growth status that the culturing cells finally grow into . The method achieved the 85 % accuracy to predict the growth status of culturing cells two days later , thus can be applicable for early selection suggestion of good iPS - forming cells . Keywords—CNN ; machine learning for cell images ; cell reprogramming stage classification ; human iPS cell formation prediction I . I NTRODUCTION Convolutional Neural Networks ( CNNs ) have been tested the ImageNet database to be proven successful in image classification [ 1 , 2 ] . The CNN image classifiers achieved impressive success in medical applications [ 3 - 5 ] , and also cell biology application [ 6 , 7 ] . CNNs have been developed to detect if a cell colony from somatic cells already reprogrammed into human induced pluripotent stem cells ( hiPSCs ) by learning the cell features or patterns on the microscopy images [ 8 - 10 ] . Such CNN classifier can improve efficiency in hiPSC production using microscopy images taken in or after cell culture . The image classification mainly based on denseness of cell textures in images ; as a colony of differentiated cells mostly appear as flat and dispersed , while iPS cells form compacted , multicellular colonies [ 11 ] . The CNN image classifier can detect other cells simultaneously to represent cell transition ( from non iPS - forming to iPS - forming vice versa ) in time - lapse images , to be useful in delineating iPS cell formation process [ 12 ] . The CNN classified time - lapse microscopy images were furthermore used to train RNNs ( recurrent neural networks ) and then to predict if the cells are going to be hiPSCs in future during cell culturing [ 13 ] . However , long - term - memory dependent RNNs ( e . g . , LSTM ) have avoided exploding and vanishing gradient problems but can only accurately predict 10 ∼ 20 time - steps in future if apparent short - term changes of the cell features or patterns appeared on the training images just before the prediction . A new RNN structure incorporated progressively the images newly generated into training to emphasize the short - term memory and thus to yield more time - steps with accurate predictions [ 14 ] . The promising cells , i . e . , cells with high probability of being hiPSCs in future should be selected at early stage to reduce a considerable amount of work in the hiPSC production . Such early selection is possible to achieve if the amount or formation of hiPS cells ( growth status ) in future during the culture can be predicted . However , the above RNN structures did not yet provide the growth status prediction . In this study , we pre - train multiple CNN classifiers by respective sets of time - lapse images taken from the same cell culture process . The time - lapse image sets are categorized according to the amount of hiPSCs detected in final images of the time - lapse image sets . These trained CNNs are then used to classify a time - lapse image taken in cell culturing as one stage ( a number of consecutive frames ) in each respective set of trained time - lapse images . The differences between the actual stage with respective classified stages are than calculated to decide which stage of the cell culture process this classified image taken in cell culturing is near to , then to predict the iPS cell growth status that the culturing cells finally grow into . In this primary study , the trained time - lapse image sets are categorized taken from high - , medium - , and low - hiPSC growth statuses of cultured cells . The prediction can be more detailed statuses : high - , semi - high , medium - , semi - medium , low - and no hiPSC growths . A deep residual learning CNN structure is used for this study [ 15 ] , and the experimental results show 85 % accuracy was achieved to predict the hiPSC growth status two - days later , thus can be applicable to be an early selection tool for hiPSC production . 616 2020 IEEE 20th International Conference on BioInformatics and BioEngineering ( BIBE ) 2471 - 7819 / 20 / $ 31 . 00 ©2020 IEEE DOI 10 . 1109 / BIBE50027 . 2020 . 00105 II . M ATERIALS Formation of human iPS cells from human cord blood : The iPS cells are cultured from CD34 positive ( CD34 + ) cells isolated from human cord blood with Stem Span SFEM ( SFEM ) and mTeSR1 media , and episomal vectors ( pCXLE - hOCT3 / 4 - shp53 - F , pCXLE - hSK , and pCXLE - hUL ) . Frozen human CD34 + cells were thawed , washed with SFEM and resuspended in expansion medium . After 24 h cultivation , the cells were collected and episomal vectors carrying reprogramming factor genes were introduced . After 72 h of cultivation in the expansion medium , the cells were collected , washed , resuspended in ES cell medium . At Day 5 , floating cells and ES medium were removed . The culture medium was replaced every 2 - 3 days until human pluripotent stem cell - like cells appeared , adherent and observed , as the cells undergoing reprogramming . Image acquisition : Time - lapse microscopic images with 30 min . interval were taken from an incubator ( Olympus LCV110 ) to obtain sets of time - lapse images . All the images are 12 - bit images with a resolution of 1392 × 1040 pixels . The original pixel width is about 0 . 65 μ m . III . A D EEP LEARNING SYSTEM FOR CLASSIFYING I PS FORMATION S TAGES The system uses a CNN with 50 - layer ( ResNet50 ) residual learning structure [ 15 ] to learn and then classify the image pattern of every input three - channel image as shown in Fig . 1 . The three channels represent probabilities of background ( Class 1 ) , other cells ( Class 2 ) , and iPS - like cells ( Class 3 ) from a time - lapse microscopy image as shown in 2 [ 12 ] , and by the Caffe CNN structure [ 16 ] . The target output of the CNN classifier is one iPS formation stage among consecutive Dormant , Revealing , and 1 ∼ n Growing stages in a set of full - series time - lapse images . For the time - lapse images taken as described in Section II , n is set as 5 , each Growing stage includes 25 frames , Revealing stage includes about 30 frames , and Dormant stage ( about 100 frames ) includes the beginning frame until Revealing stage as shown in Fig . 3 . In such stage definition , the iPS cells usually grow apparently in Revealing stage than its neighboring stages . Three ( High - growth , Medium - growth , and Low - growth ) CNN classifiers are trained by respective types of time - lapse images taken from the completed cell culturing process . The time - lapse images are categorized as types of High - growth , Medium - growth , and Low - growth according to the amount of iPS - like cells ( Class 3 ) at the stages as shown in Fig . 4 ( a ) . For instance , the average intensity of Class 3 was over 30 % at the beginning of the Dormant stage and achieved 75 % at the final ( fifth ) Growing stage in a High - growth time - lapse image set . As an example shown in Fig . 2 ( a ) , an image at the final stage is full of iPS - like cells . In a Medium - growth image set , the intensity was little over 10 % at the beginning of Dormant stage and achieved over 35 % at the final Growing stage . As the example shown in Fig . 2 ( b ) , a lot of iPS - like cells Figure 3 . An example of time - lapse image set for training CNN iPS forming stage classifier . Original images Class1 channel Class2 channel Class3 channel 3 - channel images ( a ) Image full of iPS - like cells ( High - growth ) ( b ) Image with a lot of iPS - like cells ( Medium - growth ) ( c ) Image with some iPS - like cells ( Low - growth ) Figure 2 . Template images for training CNNs with three - channels representing probabilities of cells in reprogramming into iPS - like cells ( Class 3 , blue ) , other cells ( Class 2 , green ) , or background ( Class 1 , red ) at the final stage of trained time - lapse images . Figure 1 . Deep learning system for classifying image as iPS forming stage 617 exists in an image at the final stage in Medium - growth time - lapse images . However , there are no apparent increases in Class 3 intensities among stages of Low - growth time - lapse images ( as Fig . 4 ( a ) . Therefore , the average pixel intensities of Class 2 channel are used to differentiate stages in the Low - growth image sets as shown in Fig . 4 ( b ) . However , the colony shapes of iPS cells are still clear ( as Class 3 channel in Fig . 2 ( c ) ) , even its average intensity is low . Besides , the slopes of the intensity increments are apparently higher at the Revealing stage than its neighboring ( Dormant and the first Growing ) stages as Class 3 for High and Medium growth image sets ( Fig . 4 ( a ) ) and as the Class 2 for Low growth time - lapse images ( Fig . 4 ( b ) ) . Each CNN stage classifier currently is trained by ten sets of time - lapse images . IV . H UMAN I PS CELL GROWTH P RECTION BASED ON STAGE C LASSIFICATION A . Human iPS cell formation stage classification for time - lapse micrsocopy image Time - lapse images consecutively yielded during cell culturing for hiPSC reprogramming are classified by all of the three trained ( High - growth , Medium - growth , Low - growth ) CNN classifiers . Each image is classified as an iPS cell formation stage Sc ( 1 ∼ ( n + 2 ) ) , representing either of the Dormant , Revealing , and 1 ∼ n Growing stages as shown in Fig . 5 . B . Human iPS cell growth status prediction by cumulative difference between actual and predicted stages by trained CNN stage classifiers The classified stage of every image , Sc is then used to calculate A , the average of the cumulative difference using the following equation . (cid:1845)(cid:1853) indicates the actual stage of the classified image . A thus calculated by averaging their difference from the first frame consecutively until the n - th time - lapse microscopy image taken in cell culturing . (cid:1827) (cid:3404) (cid:883) (cid:1866) (cid:3533)(cid:4666)(cid:1845)(cid:1855) (cid:3398) (cid:3041) (cid:3047)(cid:2880)(cid:2869) (cid:1845)(cid:1853)(cid:4667) The three ( High - growth , Medium - growth , and Low - growth ) CNN classifiers thus yield three average cumulative stage differences : AH , AM , and AL , respectively . Using AH , AM , and AL and two thresholds T and Tn ( representing certain values of A ) , what growth status the hiPSCs in culture ( a ) Average probabilty of iPS - like cells on image pixels ( b ) Average probabilty of other cells on image pixels Figure 4 . Growth status of iPS - like and other cells at various stages in time - lapse images represented by average intensities of probability images . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 ( Frame ) 0 . 2 0 . 25 0 . 3 0 . 35 0 . 4 0 . 45 0 . 5 0 . 55 ( Frame ) Figure 5 . Human iPS forming stage classification for a time - lapse image using trained CNN classifiers ( 1 ) Dormant stage Revealing stage Growing stage 1 Growingstage 2 Dormant stage Revealing stage Growingstage 2 Growing stage 1 High - growth trained time - lapse images Medium - growth trained time - lapse images Low - growth trained time - lapse images ( % ) High - growth trained time - lapse images Medium - growth trained time - lapse images Low - growth trained time - lapse images ( % ) 618 finally ( as the final time - step of the time - lapse microscopy images sets training the CNN classifiers ) grow into , can be predicted at the n - th frame using the following algorithm . Currently , the predicted final hiPSC growth status is categorized as High - growth ( full of iPS cells at the final stage ) , Semi - high - growth , Medium - growth ( a lot of iPS cells at the final stage ) , Low - growth ( only some iPS cells at the final stage ) , and No - growth ( no apparent iPS cells ) . The cells in culture growing into Semi - high - growth can be considered as finally grows with the iPS - like cells between the amounts of High - growth and Medium - growth as shown in Fig . 4 ( a ) . Meanwhile , cells in culture growing into Semi - medium - growth can be can be considered as finally grows between the amounts of Medium - growth and Low - growth . (cid:3) (cid:3) (cid:3) (cid:3) ALGORITHM (cid:3) 1 (cid:1861)(cid:1858)(cid:3)(cid:4666)(cid:1827)(cid:1834) (cid:3410) (cid:3398)(cid:1846)(cid:4667) (cid:1372) (cid:11)(cid:139)(cid:137)(cid:138)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) (cid:3)(cid:3)(cid:1857)(cid:1864)(cid:1871)(cid:1857)(cid:3)(cid:1861)(cid:1858)(cid:3) (cid:4666) (cid:3)(cid:1827)(cid:1839) (cid:3408) (cid:1846)(cid:3)(cid:428)(cid:1827)(cid:1838) (cid:3408) (cid:1846) (cid:4667) (cid:1372) (cid:22)(cid:135)(cid:143)(cid:139)(cid:486)(cid:11)(cid:139)(cid:137)(cid:138)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:1857)(cid:1864)(cid:1871)(cid:1857)(cid:3)(cid:1861)(cid:1858)(cid:3)(cid:4666)(cid:513)(cid:1827)(cid:1839)(cid:513) (cid:3409) (cid:1846)(cid:4667) (cid:1372) (cid:16)(cid:135)(cid:134)(cid:139)(cid:151)(cid:143)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:1857)(cid:1864)(cid:1871)(cid:1857)(cid:3)(cid:1861)(cid:1858)(cid:3)(cid:4666)(cid:1827)(cid:1838) (cid:3408) (cid:1846)(cid:4667) (cid:1372) (cid:22)(cid:135)(cid:143)(cid:139)(cid:486)(cid:16)(cid:135)(cid:134)(cid:139)(cid:151)(cid:143)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:1857)(cid:1864)(cid:1871)(cid:1857)(cid:3)(cid:3)(cid:1861)(cid:1858)(cid:3)(cid:4666)(cid:1846) (cid:3410) (cid:1827)(cid:1838) (cid:3408) (cid:3398)(cid:1846)(cid:1866)(cid:4667) (cid:1372) (cid:15)(cid:145)(cid:153)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) (cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:1857)(cid:1864)(cid:1871)(cid:1857)(cid:3)(cid:3)(cid:1861)(cid:1858)(cid:3)(cid:4666)(cid:1827)(cid:1838) (cid:3409) (cid:3398)(cid:1846)(cid:1866)(cid:4667) (cid:1372) (cid:17)(cid:145)(cid:486)(cid:137)(cid:148)(cid:145)(cid:153)(cid:150)(cid:138) Currently , T s set as 0 . 7 to improve the prediction accuracy according our experiments , indicating the absolute values of AH , AM , and AL should be under 0 . 7 to attach the cells in culturing as a final status of High - growth , Medium - growth or Low - growth . Tn is set as 1 , indicating the cells in culturing is predicted as No - growth if the average actual stage is one stage delayed than the average stage classified by the trained Low - growth CNN model . V . R ESULTS This experimental method was developed using a computer equipped with an Intel Core i9 - 9900k 3 . 6GHz , 64GB Ram , Asus Dual RTX2080Ti graphics card . Regarding the software , we used Linux ( OS ) , Python programming and the deep learning framework by TenserFlow / Keras . The computation of the average cumulative difference between classified and actual stages ( Equation (cid:297) 1 ) ) and hiPSC growth status prediction ( Algorithm 1 ) can be implemented at when a new time - lapse image generated by the incubator microscope . The new yielded image is classified as three - channel image ( downsized as 583 × 407 ) to be the input of the three ( High - growth , Medium - growth , and Low - growth ) CNN stage classifiers . The three - channel transformation takes 14 min . Meanwhile , the other computations including the CNN stage classifications and growth status predictions totally take under 1 min , therefore real - time growth status prediction for every new time - lapse image can be achieved . Figure 6 ( a ) shows the three average cumulative stage differences between the three classified stages with the actual stage calculated frame by frame for a test time - lapse image set that was finally detected as hiPSCs with High - growth status . Figure 6 ( b ) and ( c ) show the average cumulative stages differences between the three classified stages with the actual stages from test time - lapse image sets that were finally detected as hiPSCs with Medium - growth , and Low - growth statuses , respectively . Figure 6 also indicates the stage differences at the three ( 110 - , 120 - , and 136 - th ) frames of the Revealing stage . Figure 7 shows the confusion matrices for the predicted growth statuses ( using Equation 1 then Algorithm 1 ) and actual growth statuses from total 26 sets of time - lapse images that were detected as iPS cells of 8 High - growth , 4 Semi - high - growth , 6 Medium - growth , 3 Semi - medium - growth , and 5 Low - growth statuses at the final stage of the time - lapse images . Figure 7 ( a ) , ( b ) and ( c ) shows the predicted results at ( a ) Average of the cumulative difference in time - lapse images from culturing cells finally growing into high iPS cell growth status ( b ) Average of the cumulative difference in time - lapse images from culturing cells finally growing into medium iPS cell growth status ( c ) Average of the cumulative difference in time - lapse images from culturing cells finally growing into low iPS cell growth status Figure 6 . Examples of average cumulative differences between actual and classified stages by trained High - growth , Medium - growth and Low - growth CNN iPS cell formation stage classifiers . - 3 - 2 - 1 0 1 2 3 4 5 6 0 50 100 150 200 250 S t a g e d i ff e r e n c e Frame Trained High - growth model Trained Medium - growth model Trained Low - growth model Threshold Beginning of revealing stage Middle of revealing stage End of revealing stage - 7 - 5 - 3 - 1 1 3 5 0 50 100 150 200 250 S t a g e d i ff e r e n c e Frame Trained High - growth model Trained Medium - growth model Trained Low - growth model Threshold Beginning of revealing stage Middle of revealing stage End of revealing stage - 7 . 5 - 6 . 5 - 5 . 5 - 4 . 5 - 3 . 5 - 2 . 5 - 1 . 5 - 0 . 5 0 . 5 1 . 5 0 50 100 150 200 250 S t a g e d i ff e r e n c e Frame Trained High - growth model Trained Medium - growth model Trained Low - growth model Threshold Beginning of revealing stage Middle of revealing stage End of revealing stage 619 the 110 - , 120 - , and 136 - th frames representing one beginning , middle , or end frame at Revealing stage , respectively . Besides , only few iPS - like cells detected at the final stage of the time - lapse images were predicted correctly as No - growth status and not counted in the confusion calculation . Figure 7 ( a ) shows the prediction error at the beginning of Revealing stage achieved 55 % ( 14 / 26 ) ; meanwhile , the predicted error over one status ( e . g . , Medium - growth predicted as a High - or Low - growth status , not as Semi - high - growth or Semi - medium - growth status ) was 7 . 6 % ( 2 / 26 ) . Figure 7 ( a ) shows the prediction error at the middle of Revealing stage achieved 31 % ( 8 / 26 ) ( Fig . 7 ( b ) ) ; meanwhile , the predicted error over one status was 3 . 8 % ( 1 / 26 ) . The error at the end of Revealing stage was 15 % ( 8 / 26 ) ; meanwhile , the predicted error over one status was 0 ( Fig . 7 ( c ) ) . TABLE 1 shows all the predicted growth statuses and the stage differences calculated the end frame of Revealing stage as shown in Fig . 7 ( c ) ) . Because the final growing stage was about two days after the end of Revealing stage , we can say 85 % accuracy was achieved for predicting the iPS cell growth status of two - days later for the culturing cells . (cid:33) TABLE I . PREDICTED GROWTH STATUSES AND STAGE DIFFERENCES ( a ) Prediction at the beginning of Revealing stage ( b ) Prediction at the middle of Revealing stage ( c ) Prediction at the end of Revealing stage Figure 7 . Confusion matrices between actual and predicted growth statuses . Actual growth status AH AM AL Predicted status High ( 1 ) 0 . 70 4 . 53 5 . 00 High High ( 2 ) - 1 . 00 1 . 13 5 . 00 S - high High ( 3 ) - 0 . 60 3 . 57 5 . 00 High High ( 4 ) - 0 . 20 4 . 40 4 . 43 High High ( 5 ) 0 . 70 4 . 80 5 . 00 High High ( 6 ) - 0 . 63 3 . 17 4 . 97 High High ( 7 ) 1 . 60 5 . 00 4 . 20 High High ( 8 ) 0 . 93 3 . 80 5 . 00 High S - high ( 1 ) - 1 . 00 0 . 47 4 . 60 Medium S - high ( 2 ) - 1 . 00 1 . 83 4 . 67 S - high S - high ( 3 ) - 1 . 00 0 . 93 4 . 17 S - high S - high ( 4 ) - 1 . 00 2 . 00 4 . 63 S - high Medium ( 1 ) - 1 . 00 1 . 07 4 . 87 S - high Medium ( 2 ) - 1 . 00 - 0 . 37 2 . 80 Medium Medium ( 3 ) - 1 . 00 0 . 40 0 . 20 Medium Medium ( 4 ) - 1 . 00 1 . 37 4 . 67 S - high Medium ( 5 ) - 1 . 00 0 . 07 4 . 07 Medium Medium ( 6 ) - 0 . 86 0 . 09 2 . 87 Medium S - medium ( 1 ) - 1 . 00 - 0 . 93 0 . 50 Low S - medium ( 2 ) - 1 . 00 - 1 . 00 1 . 40 S - medium S - medium ( 3 ) - 1 . 00 - 1 . 00 1 . 47 S - medium Low ( 1 ) - 1 . 00 - 1 . 00 - 0 . 40 Low Low ( 2 ) - 1 . 00 - 1 . 00 - 0 . 30 Low Low ( 3 ) - 1 . 00 - 1 . 00 - 0 . 90 Low Low ( 4 ) - 1 . 00 - 1 . 00 - 0 . 60 Low Low ( 5 ) - 1 . 00 - 1 . 00 - 0 . 87 Low AH , AM , and AL : average cumulative stage differences by High - , Medium - , Low - growth trained models , respectively . S - high : Semi - high - growth S - medium : Semi - Medium - growth 620 The predictions at frames of Dormant stage ( before Revealing stage ) were worse no matter the cells in culture finally become High - growth , Medium - growth , or Low - growth status . The reason can be considered as the three average cumulative stage differences calculated for the frames of Dormant stage are all small as shown in Fig . 6 ( a ) , ( b ) and ( c ) , to difficulty predict accurate growth status . Meanwhile , the prediction after Revealing stage achieved no apparent better results . Because we hope to make accurate selection as early as possible , the prediction made at the end of Revealing stage ( as the 136 - th frame ) is a suitable solution . VI . C ONCLUSION This paper proposed a CNN iPS cell formation stage classifier that were trained by 30 sets of time - lapse images taken from the completed culture process in which iPS cells were being formed . These trained CNNs classified every time - lapse image in real - time culture as an iPS cell formation stage . The differences between the actual stages with the classified stage are then compared to predict what growth status of the cultured iPS cells finally become . The experimental result shows that 85 % prediction accuracy was achieved . Thus , this primary study for iPS growth status prediction was an effective method for early selection of iPS - forming cells . For practical use , more training sets of time - lapse images are required to improve training performance and thus prediction accuracies . More testing sets of time - lapse images are also required to prove the system effectiveness and prediction accuracies at various frames in cell culturing . Meanwhile , more stages ( currently 7 ) should be tried to accurately predict the final growth status as early as better . A CKNOWLEDGMENT Research supported by Ministry of Science and Technology ( MOST ) , R . O . C . , under Grant No . 108 - 2221 - E - 033 - 039 , 108 - 2923 - E - 033 - 002 - MY2 , and 108 - 2923 - E - 033 - 034 , by RIKEN Presidential Fund : Technology development for quantitative evaluation of cellular state based on image processing and machine learning . R EFERENCES [ 1 ] A . Krizhevsky , I . Sutskever , GE . Hinton , “ImageNet classification with deep convolutional neural networks , ” 25th Neural Information Processing Systems , 2012 , pp . 1097 . [ 2 ] J . Deng , et al . , " ImageNet : a large - scale hierarchical image database , " 2009 IEEE Conference on Computer Vision and Pattern Recognition , Miami , FL , 2009 , pp . 248 - 255 . [ 3 ] N . Tajbakhsh , J . Y . Shin , S . R . Gurudu , R . Todd Hurst , C . B . Kendall , M . B . Gotway , J . Liang , “Convolutional neural networks for medical image analysis : full training or fine tuning ? , ” in IEEE Transactions on Medical Imaging , vol . 35 , no . 5 , pp . 1299 - 1312 , May 2016 . [ 4 ] S . Christodoulidis , M . Anthimopoulos , L . Ebner , A . Christe and S . Mougiakakou , “Multisource transfer learning with convolutional neural networks for lung pattern analysis , ” in IEEE Journal of Biomedical and Health Informatics , vol . 21 , no . 1 , pp . 76 - 84 , Jan . 2017 . [ 5 ] K . Lekadir , et al . , “A convolutional neural network for automatic characterization of plaque composition in carotid ultrasound , ” in IEEE Journal of Biomedical and Health Informatics , vol . 21 , no . 1 , pp . 48 - 55 , Jan . 2017 . [ 6 ] O . Z . Kraus , J . Lei Ba , B . J . Frey , “Classifying and segmenting microscopy images with deep multiple instance learning , ” Bioinformatics , vol . 32 , Issue 12 , pp . 52 - 59 , 15 June 2016 . [ 7 ] Y . Song et al . , “A deep learning based framework for accurate segmentation of cervical cytoplasm and nuclei , ” 2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society , Chicago , IL , 2014 , pp . 2903 - 2906 . [ 8 ] K . Fan , S . Zhang , Y . Zhang , J . Lu , M . Holcombe , X . Zhang , “A machine learning assisted , label - free , non - invasive approach for somatic reprogramming in induced pluripotent stem cell colony formation detection and prediction , ” Scientific Reports 7 : 13496 , 2017 . [ 9 ] M . S . Kavitha , T . Kurita , S . Y . Park , SI . Chien , JS . Bae , BC . Ahn , “Deep vector - based convolutional neural network approach for automatic recognition of colonies of induced pluripotent stem cells , ” PLoS ONE 12 : e0189974 , 2017 . [ 10 ] H . Joutsijoki , M . Haponen , J . Rasku , K . Aalto - Setala , M . Juhola , “Machine learning approach to automated quality identification of human induced pluripotent stem cell colony images , ” Computational and Mathematical Methods in Medicine 3091039 , 2016 . [ 11 ] J . Wu , D . Okamura , M . Li , K . Suzuki , C . Luo , L . Ma , Y . He , Z . Li , et . al . , “An alternative pluripotent state confers interspecies chimaeric competency , ” Nature vol . 521 , pp . 316 - 321 , 2015 [ 12 ] Y . H . Chang , K . Abe , H . Yokota , K . Sudo , Y . Nakamura , M . D . Tsai , “Human induced pluripotent stem cell region detection in bright - field microscopy images using convolutional neural networks , ” Biomedical Engineering Applications Basis and Communications , vol . 31 , no . 2 , Apr . 2019 [ 13 ] Y . H . Chang , H . Yokota , K . Sudo , Y . Nakamura , S . L . Chu , H . Chih - Yung and M . D . Tsai , “Human induced pluripotent stem cell reprogramming prediction in microscopy images using LSTM based RNN , ” 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society ( EMBC ) , Berlin , Germany , 2019 , pp . 2416 - 2419 . [ 14 ] S . L . Chu , H . Yokota , K . Sudo , Y . Nakamura , Y . H . Chang , L . C . Fang and M . D . Tsai , “Prediction for morphology and states of stem cell colonies using a LSTM network with progressive training microscopy images , ” 42nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society ( EMBC ) , Montreal , Canada , 2020 , appear in July . [ 15 ] K . He , X . Zhang , S . Ren , and J . Sun , “Deep residual learning for image recognition , ” arXiv : 1512 . 03385 , 2015 . [ 16 ] Y . Jia , E . Shelhamer , J Donahue , S . Karayev , J . Long , R . Girshick , S . Guadarrama , T . Darrell , “Caffe : convolutional architecture for fast feature embedding , ” Proceedings of the 22nd ACM international conference on Multimedia , pp . 675 - 678 , Nov . 2014 . 621