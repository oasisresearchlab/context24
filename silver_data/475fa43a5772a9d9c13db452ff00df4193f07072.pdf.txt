Spatio - Temporal Parsing in Spatial Hypermedia Ph . D . Dissertation Thomas Schedel Supervisor : Assoc . Prof . Henrik Legind Larsen , PhD ; Aalborg University Co - Supervisor : Prof . Dr . Claus Atzenbeck ; Hof University ( Germany ) Assessment Committee : Assoc . Prof . Simonas Šaltenis , PhD ( chairman ) ; Aalborg University Assoc . Prof . Niels Olof Bouvin , PhD ; Aarhus University Assoc . Prof . Manolis Tzagarakis , PhD ; University of Patras ( Greece ) c (cid:13) Copyright by Thomas Schedel , 2015 Abstract Spatial Hypertext represents associations between chunks of information by spatial or visual attributes ( such as proximity , color , shape etc . ) . This allows expressing information structures implicitly and in an intuitive way . How - ever , automatic recognition of such informal , implicitly encoded structures by a machine ( a so - called spatial parser ) is still a challenge . One reason is , that conventional ( non - adaptive ) parsers are conceptually restricted by their under - lying source of information ( i . e . , the spatial hypertext ) . Due to this limita - tion there are several types of structures that cannot be recognized properly . This inevitably limits both quality of parser output and parser performance . We claim that considering temporal aspects in addition to spatial and visual properties in spatial parser design will lead to signiﬁcant increase in parsing accuracy , detection of richer structures and thus higher parser performance . For the purpose of providing evidence , parsers for recognizing spatial , visual and temporal object relations have been implemented and tested in a series of user surveys . It turned out , that in none of the test cases pure spatial or visual parser could outperform the spatio - temporal parser . Instead , the spatio - temporal parser was able to compensate limitations of conventional parsers . Furthermore , diﬀerences in parsing accuracy were successfully tested for statis - tical signiﬁcance . The results indicate a non - trivial eﬀect that is recognizable by humans . We have shown that the addition of a temporal parser shifts ma - chine detected structures signiﬁcantly closer to what knowledge workers intend to express . iii Resumé Spatial Hypertext repræsenterer associationer mellem informationsdele fra spa - tiale eller visuelle attributter ( såsom nærhed , farve , form osv . ) Dette gør det muligt at udtrykke informationsstrukturer implicit og på en intuitiv måde . Men automatisk genkendelse af sådanne uformelle , implicit kodede strukturer ( ved anvendelse af en såkaldt spatial parser ) er stadig en udfordring . En af grun - dene er , at konventionelle ( ikke - adaptive ) parsere begrebsmæssigt er begrænset af deres underliggende informationskilde ( dvs . den spatiale hypertekst ) . På grund af denne begrænsning , er der ﬂere typer af konstruktioner , der ikke kan genkendes korrekt . Dette begrænser uundgåeligt både parser output kvaliteten og parser ydeevnen . Vi hævder , at inddragelse af temporale aspekter i tillæg til spatiale og visuelle egenskaber i spatial parser design vil føre til betydelig øgning af parsing nøjagtighed samt detektering af rigere strukturer og dermed højere parser ydeevne . Med henblik på at vise dette , er parsere for genkendelse spatiale , visuelle og temporale objekt relationer implementeret og testet i en række brugerunder - søgelser . Det viste sig , at i ingen af testcasene var en ren rumlig eller visuel parser mere eﬀektiv end den spatio - temporale parser . I stedet var den spatio - temporale parser i stand til at kompensere for de konventionelle parseres be - grænsninger . Endvidere blev forskelle i parsing nøjagtighed med succes testet for statistisk signiﬁkans . Resultaterne indikerer en ikke - triviel eﬀekt , der kan observeres af mennesker . Vi har vist , at tilføjelse af en temporal parser rykker maskinopdagede strukturer betydeligt tættere på , hvad videnarbejdere har til hensigt at udtrykke . v Contents Abstract iii Resumé v 1 Introduction 1 1 . 1 Classic Hypertext . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 2 Spatial Hypertext . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1 . 3 Spatial Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1 . 4 Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 5 Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . 11 1 . 5 . 1 Spatial Parsing in VIKI and VKB . . . . . . . . . . . . 11 1 . 5 . 2 Adaptive Spatial Parsing . . . . . . . . . . . . . . . . . 15 1 . 5 . 3 Shared Spatial Parsing . . . . . . . . . . . . . . . . . . . 17 1 . 5 . 4 Three - Dimensional Spatial Parsing . . . . . . . . . . . . 19 1 . 5 . 5 Specialized Spatial Parsers . . . . . . . . . . . . . . . . 20 2 Formal View 23 2 . 1 Spatial Hypertext Languages . . . . . . . . . . . . . . . . . . . 24 2 . 2 Spatial Hypertext Interpretations . . . . . . . . . . . . . . . . . 31 3 Critical Review 37 3 . 1 Ambiguous Structures . . . . . . . . . . . . . . . . . . . . . . . 40 3 . 2 Destroyed Structures . . . . . . . . . . . . . . . . . . . . . . . . 43 3 . 3 Temporal Structures . . . . . . . . . . . . . . . . . . . . . . . . 44 3 . 4 Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4 Prototype 47 4 . 1 Editing System . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 . 1 . 1 Evolution of Spatial Hypertext . . . . . . . . . . . . . . 48 4 . 1 . 2 Editing Processes . . . . . . . . . . . . . . . . . . . . . . 54 4 . 1 . 3 Workspace Model . . . . . . . . . . . . . . . . . . . . . . 59 4 . 1 . 4 Specialization . . . . . . . . . . . . . . . . . . . . . . . . 67 4 . 2 Interpretation System . . . . . . . . . . . . . . . . . . . . . . . 72 vii Contents 4 . 2 . 1 Events . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 4 . 2 . 2 InfoUnitData . . . . . . . . . . . . . . . . . . . . . . . . 74 4 . 2 . 3 Interpretations . . . . . . . . . . . . . . . . . . . . . . . 80 4 . 2 . 4 Merging . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 4 . 3 Linking Editing and Interpretation System . . . . . . . . . . . 86 4 . 4 Parsers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 4 . 4 . 1 Generic Parser Model . . . . . . . . . . . . . . . . . . . 92 4 . 4 . 2 Spatial Parser . . . . . . . . . . . . . . . . . . . . . . . . 100 Three - Stage Spatial Parsing Algorithm . . . . . . . . . . 102 Stage 1 – Creation of Terminal Symbols . . . . . 108 Stage 2 – Parsing List Structures . . . . . . . . . 115 Stage 3 – Normalization . . . . . . . . . . . . . . 140 4 . 4 . 3 Visual Parser . . . . . . . . . . . . . . . . . . . . . . . . 148 4 . 4 . 4 Content Parser . . . . . . . . . . . . . . . . . . . . . . . 154 4 . 4 . 5 Temporal Parser . . . . . . . . . . . . . . . . . . . . . . 159 5 Test 177 5 . 1 Reference Data Collection . . . . . . . . . . . . . . . . . . . . . 179 5 . 1 . 1 Adapted Prototype . . . . . . . . . . . . . . . . . . . . . 179 5 . 1 . 2 Survey . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 5 . 2 Virtual Test Run . . . . . . . . . . . . . . . . . . . . . . . . . . 186 5 . 3 Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 5 . 3 . 1 Statistical Method . . . . . . . . . . . . . . . . . . . . . 195 5 . 3 . 2 Result . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197 6 Summary , Conclusion and Future Work 201 6 . 1 Summary and Conclusion . . . . . . . . . . . . . . . . . . . . . 201 6 . 2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205 Bibliography 209 Appendix 215 viii Chapter 1 Introduction Hypertext goes far beyond what we know today from the World Wide Web . The general idea behind and its basic concepts go much further than simply linking and following trails of webpages . Consequently , hypertext allows for much more advanced applications than we are using today in our digital lifes . This introductory chapter is intended to illustrate that . 1 . 1 Classic Hypertext Literally the preﬁx “hyper - ” means “over” or “beyond” , which highlights a su - periority over ( written ) text . So in the classic sense of the word one could understand hypertext as a kind of “super” - text . What makes such text “super” or superior over plain text is its structure ( i . e . , how elements of a document entity are related to each other ) . Unlike written text , which can be seen as a one - dimensional sequence of words , sentences or pages respectively , hypertext documents do not need to be linear . They are rather networks of document items which may be traversed in a non - linear fashion . This classic type of hypertext is also known as Node - Link Hypertext . Node - link hypertext has got its name from its underlying model , including two core elements , node and link . Nodes are holders of content ( i . e . , carriers of verbal or non - verbal information ) [ 1 ] . The ways in which these chunks of text or other media are interconnected are deﬁned by links [ 2 ] . Links describe ( nav - igable ) associations between nodes and can herewith determine both ( a ) how to reach a certain node and ( b ) how to interpret node content [ 1 ] . So on one hand links are tightly associated with traversal [ 1 ] and can therefore be 1 Chapter 1 . Introduction used as a means of navigation , but on the other hand links also can express meaning [ 3 ] and hence can be used as an instrument for giving node content a semantic context [ 1 ] . Following the node - link model , authors of hypertext documents are required to express information structures by formal nodes and links . Thus , writers of hypertext must use formalisms . This , however , has certain drawbacks . Explicitly creating and linking nodes is something many people are not familiar with . Therefore it is not surprising that some people may ﬁnd it unnatural and therefore diﬃcult to use the formal node - link scheme [ 1 , 4 ] . This is especially the case when users only have an incomplete or vague idea about what to express . Fuzzy or partial knowledge is usually of implicit nature . Formalisms however require explicit statements . Thus , tacit information which might have been left implicit in a less formal representation must be made explicit when using nodes and links [ 5 ] . This leads to an increased cognitive load and high eﬀort of expression . On the other hand ( formal ) hypertext is not an ideal representation technique for describing emerging information structure ; that is , for describing informa - tion that continually evolves [ 6 ] . Emerging structures change frequently and therefore require continuous structuring and restructuring of their representa - tion . Recurring restructuring of networks of nodes and links , however , can be cognitively diﬃcult and therefore time consuming [ 6 ] . Due to that overhead , traditional hypertext is poorly suited for many kinds of information analysis and design tasks [ 2 ] . Both , support for lowering users’ eﬀort of expression [ 7 ] and emerging structure support [ 1 ] can be provided by interfaces allowing for visual communication . Visual communication is conveyance of information via visual aids ( e . g . , shape , color etc . ) and can be diﬀerentiated from written and spoken communication by its ( a ) implicit ; ( b ) informal and ( c ) emergent nature [ 8 ] . Visual communi - cation is amazingly natural [ 8 ] and intuitive . Often people organize information in the form of notes on boards and desks and herewith unselfconsciously com - municate in a non - verbal but visual fashion [ 8 ] . Conveying such implicitly encoded information does not require prescriptive communication rules . Users do not need to agree on a basic communication framework [ 9 ] in order to un - derstand a visual message . This reduces communication overhead [ 9 ] and keeps the “visual language” used for communication lightweight and ﬂexible . Combining classic hypertext and visual communication makes it possible to convey nodes and links via visual aids and therefore to visually communicate information structure . This results in an alternative representation form of hy - pertext , which is natural , lightweight and ﬂexible . This new form of hypertext is called “Spatial Hypertext” . 2 1 . 2 . Spatial Hypertext 1 . 2 Spatial Hypertext Implicit As already pointed out , people may ﬁnd it diﬃcult to use the formal node - link scheme [ 1 , 4 ] . This is mainly because explicitly creating and linking formal nodes is something most people are not familiar with . However , people are accustomed to arranging objects in space [ 1 ] . A good example of this is our daily oﬃce work . We build heaps or piles of related papers on desk , we arrange cards on bulletin boards , write short notes on whiteboards or use a text marker to highlight important or associated parts in a document . In other words , we use our natural ability to perceive and associate objects to manage daily oﬃce work and thereby build visually perceivable networks of information objects . One could understand that as a physical implementation of hypertext . Spatial hypertext is based on that idea . Rather than explicitly connecting nodes by ( potentially typed ) formal links , as it would be done in node - link hypertexts , spatial hypertext expresses associations between information units implicitly by spatial and visual attributes ( e . g . , proximity , color , shape etc . ) [ 1 , 7 ] . Thus , as opposed to classic node - link hypertext where we deﬁne structure explicitly , the focus of spatial hypertext lies on implicit relationships [ 7 ] . Ambiguous A desired consequence of spatial hypertext’s implicit nature ( that is , of not deﬁning links explicitly ) is constructive ambiguity [ 3 , 9 ] . “Am - biguous” means in this context , that spatial hypertext allows for being inter - preted in multiple ways . Visual expression created by humans can be clear and explicit but may also leave some room for interpretation ; without being invalid . This allows to create information structure even when users only have a vague or incomplete idea about what to express [ 10 ] . That way spatial hypertext supports the creation of fuzzy or unclear information structures [ 10 ] . Informal Spatial hypertext permits users to express implicit knowledge in visual information spaces . It thereby supports intuitive interaction with a vi - sual medium and allows for direct manipulation of structure [ 6 ] . In spatial hypertext , modiﬁcation of information happens immediately by changing spa - tial and visual properties and does not require formalisms [ 11 ] . There is no need to prematurely commit to language conventions for expressing certain types of structure [ 12 ] . Instead spatial hypertext allows the user to create instances of structures even before naming and typing them [ 10 ] . It thereby supports ex - plorative development of emerging structures and visual languages [ 10 ] through informal interaction [ 12 ] . This informal nature of spatial hypertext has a great advantage : We do not run the risk of formalising information incorrectly or in - consistently . Formalization errors are usually diﬃcult to correct [ 5 ] and make “ill - formalized” information more diﬃcult to use than information not formal - ized [ 2 ] . In spatial hypertext we do not have this problem . 3 Chapter 1 . Introduction Emergent Since spatial hypertext expressions are based on language ele - ments that are easy to change ( i . e . , it is easy to change a visual property or move an object ) , spatial hypertext supports expression of evolving interpre - tations [ 7 ] . It is therefore appropriate for information - intensive tasks where information continually evolves [ 7 ] ; that is , for tasks which typically include collecting , analyzing , organizing and sharing of information [ 13 ] . The docu - ments resulting from such tasks are usually under constant modiﬁcation [ 13 ] and just rarely reach the state of a ﬁnal product [ 7 ] . Usually , they are more an encoding of evolving lightweight structures [ 14 ] or rather “freewheeling” struc - tures [ 3 ] . Spatial hypertext is therefore not only of implicit , ambiguous and informal but also of emergent nature [ 6 ] . 1 . 3 Spatial Parsing Having encoded information in spatial hypertext , human users can easily re - trieve and decode it again . For a machine , however , it is not necessarily easy to detect such implicit and idiosyncratic structures . This is solved by using so - called Spatial Parsers . Spatial parsers are ( software ) components which implement highly specialized structure detection algorithms . These detection algorithms are designed for retrieving information structures which are implicitly encoded in spatial and visual arrangements of objects generated by humans . We know these arrange - ments already as spatial hypertext . To avoid misunderstandings it should be noted , that analyzing spatial hyper - texts is no “parsing” in the classic sense of the term . In visual language pro - cessing “spatial parsing” is deﬁned as “the process of analysing an input picture to determine its syntactic structure” [ 15 ] . So , “parsing” is synonymous to “syn - tactic analysis” . This requires syntax deﬁnition , for example via picture layout grammars [ 15 ] or graph grammars [ 16 ] . Spatial hypertext , however , is of in - formal , implicit , ambiguous and emergent nature . Which means , that we do not know beforehand how words of the language are generated . Thus , prema - ture deﬁnition of an adequate grammar is not possible . For sure we can deﬁne “some” set of production rules . Such a formal grammar , however , does not diﬀer among diﬀerent users [ 17 ] and cannot emerge [ 10 ] . Thus it will not cover all desired structural aspects of the visual language . It is important to note , that in spatial parsing we do not assume that we can unambiguously recover syntactic structure [ 3 , 14 ] . The purpose of parsing spatial hypertexts is not to “debug” formal spatial or visual expression [ 3 ] . The point is rather to uncover some partially - framed structure which are hidden in human - generated spatial layouts [ 14 ] . 4 1 . 3 . Spatial Parsing One could also say , that spatial parsers infer implicit structural knowledge from explicit spatio - visual knowledge and thereby turn implicit information structures into explicit ones [ 10 ] . Since this is more a matter of interpretation than checking for syntactical cor - rectness , it should be considered to rather call such structure detectors “spatial interpreter” ( instead of “spatial parser” ) . Anyhow , to be consistent with exist - ing literature , we will use the term “parser” . Why do we need structure recognition ? When implemented and integrated into a spatial hypermedia system , a spatial parser could be used to trigger or support various high - level services . Such features include contextual search and intelligent navigation [ 6 ] , but also user notiﬁcation or structure suggestion [ 14 ] . Especially to be emphasised is a spatial parser’s support in multi - user envi - ronments ( i . e . , when multiple users collaborate on the same visual information space ) . By providing feedback about what the spatial parser ( and therefore the system ) has “understood” as structure , spatial parsing may identify ambiguous structures and suggest a common interpretation to all users [ 10 ] . Firstly , the users would become aware of the possible interpretations of the structures ; sec - ondly , they could eﬃciently agree on a common interpretation . This would avoid miscommunication based on contradictory interpretation of the spatial structure . Without such a shared understanding , the dialog between users about personal reﬂections and understanding of information becomes a diﬃ - cult task and the hypertext material themselves are only of limited utility [ 10 ] . What requirements must be met by a spatial parser in order to support such ad - vanced functionality ? In [ 10 ] three core requirements were identiﬁed : ( a ) spatial parsers must be able to interpret spatial and visual relationships ; ( b ) parsers must tolerate people’s diﬀerent ways of expressing structure spatially and vi - sually ( where over - interpretation should be avoided ) and ( c ) a spatial parser should extract only intended structure ( i . e . , parsers should “understand” what human users intend to express ) . Especially the last requirement poses major challenges when it comes to prac - tical implementation . A functional spatial parser must detect only intended structure , even though whether something is structure or not is a subjective matter of personal opinion and therefore depends on the user’s individual per - spective [ 10 ] . In many cases we neither have information about authors and their personal motivation nor about context of application . Nevertheless the parser should be able to deliver ( some ) meaningful results . This is probably the reason why only little work has been done on practical spatial parsing . Designing a spatial parser includes making several decisions . The most essen - tial ones are ( a ) deciding what kinds of structure should be recognized and 5 Chapter 1 . Introduction ( b ) which spatial or visual attributes should be used for doing that . Since in theory all aspects of visual appearance could be crucial for understanding spatial structure [ 10 ] , one might think , that detection of exhaustive explicit structure is only possible if a parser uses all aspects of what is expressed vi - sually [ 10 ] . This , however , is not feasible . The same applies to the decision of what kinds of structure should be recognized . We cannot satisfy all individual perceptions of what might be structure or not [ 10 ] , and therefore cannot detect “everything” . However , what can be done is identifying some structure which is accepted by most users . This is why spatial parsers are typically ( though not exclusively ) built on heuristics for spatial pattern recognition [ 10 , 12 ] . Such heuristics are ideally valid across diﬀerent contexts of application and cultural environments . Structures in human generated layouts are formally elusive . This is mainly because they only become manifest in the user’s thoughts and therefore only exist in mind [ 17 ] . This makes it diﬃcult to discuss them . Nevertheless , it has been tried to identify several categories of spatial and visual structures . 1 . 4 Structures According to [ 12 ] there are four common ways of noting relationships visually and spatially ( Fig . 1 . 1 ) : ( a ) relationships by spatial arrangement ; ( b ) relation - ships by object type ; ( c ) relationships by collection and ( d ) relationships by composition . Spatial Arrangement Relationships by spatial arrangement are expressed via spatial proximity and alignment , which can be of diﬀerent form [ 12 ] . A common , basic framework of such proximity - and alignment - based structure types may look as illustrated in Fig . 1 . 2 : Structure types are split up into two main categories , Ordered Groupings and Unordered Groupings . Ordered groupings require visual uniformity of objects ( i . e . , the members of such groups must be of the same type ) and they require a certain alignment of objects . As for unordered groupings , the opposite is the case : They may be built up of objects of diﬀerent types and do not require a certain alignment of members . They are unordered [ 10 ] . Ordered groupings are , for instance , Lists , which exist in two diﬀerent layouts : aligned horizontally , called Horizontal Lists and aligned vertically , labeled Ver - tical Lists [ 10 , 14 ] . Other ordered groupings are , Matrices [ 10 , 14 ] ( or Tables [ 3 ] ) , where objects are aligned both , vertically and horizontally [ 3 ] . Therefore , ma - trices and tables can be seen as compositions of lists [ 14 ] . Finally , so - called 6 1 . 4 . Structures a ) spatial arrangement b ) object type c ) collection d ) composite Figure 1 . 1 : Four common ways of noting relationships visually and spatially [ 12 ] Unordered Groupings Pile Heap Ordered Groupings Lists Horizontal List Vertical List Matrix / Table Stack Figure 1 . 2 : Basic spatial structure types [ 3 , 10 , 14 ] 7 Chapter 1 . Introduction Figure 1 . 3 : Relationships by object type [ 12 ] – sample layout with two visual categories of objects ( position and alignment do not matter ) Stacks are ordered groupings as well [ 10 , 14 ] . Stacks are deﬁned as sets of sig - niﬁcantly overlapping objects of the same type [ 14 ] that are aligned in some direction [ 10 ] . Thus , they may be considered as “compressed” lists . Pile [ 10 ] and Heap [ 14 ] are unordered groupings . They do not require a certain alignment of objects [ 10 ] . However , what they do require , is , that objects are partly overlapping and have either the same type , this way they form a pile , or they have diﬀerent types , which deﬁnes a heap [ 10 , 14 ] . Object Type Relationships noted by object type ( or by visual type ) are categorical relationships expressed by visual similarities ( see Fig . 1 . 3 ) [ 10 , 12 ] . “Visually similar” refers to objects that have similar color , font , extent , shape , border width etc . – their position and alignment do not matter . Even if objects were randomly distributed over the screen , they still might be perceived to have some categorical relation if they share certain visual properties [ 10 ] . That way we can express “category membership , that cross - cuts spatial positioning” [ 12 ] . This type of structure can be seen as Taxonomic Set , as taxonomic sets are groupings in which all members belong to the same category [ 3 ] . Collections Categorical relationships between objects may also be noted through so - called Collections [ 12 ] . There are two diﬀerent notions ( see Fig . 1 . 4 ) : ( a ) explicit and ( b ) implicitly deﬁned collections . Firstly , collections can be seen as explicit , regional selections of objects which reside in separate subspaces [ 10 ] . This notion supports the creation of subspace trees which then can express hierarchical ordering of collections [ 10 ] . This way it becomes possible to express hierarchical category structures [ 12 ] . Thus collec - tions can be used to deﬁne taxonomies . Such distinct subspace trees , however , neither ﬁt spatial hypertext’s implicit nor informal nature . They are rather means to organizing artifacts and are therefore more an application feature than a visual language feature . Thus , one could argue whether this type of ex - plicit structure has any relevance for spatial parsing . Nevertheless , hierarchical subspaces have become an integral part of several spatial hypermedia systems . 8 1 . 4 . Structures a ) b ) Figure 1 . 4 : Relationships by collection [ 12 ] – two samples for explicitly and implicitly deﬁned collections Secondly , a collection may be seen as an implicit step by step selection of objects . When objects get moved into clearly , spatially separated clusters over time , they form distinct areas that emerge [ 18 ] . When objects located together in such an area also relate to the same task [ 10 ] , they can be used to express activity - related relationships . This is why such implicit collections are usually called Activity - Related Areas [ 12 ] . One could argue now that these structures are nothing more than spatial clusters . Objects in the same area may refer to the same task but they do not need to . Just because two objects are located close to each other and are spatially separated from the rest of the hypertext , it does not necessarily mean that they refer to the same task . For sure they seem to have some relation , but the spatial hypertext does not “tell us” which one . The statement , that “objects in the same cluster relate to the same task” is just an assumption and nothing a spatial parser could verify . Thus from a spatial parsing perspective this notion of implicitly deﬁned collections refers more to spatial clustering than to activity realted working areas . Spatial clusters ﬁt perfectly into the category of Unordered Groupings ( since they are proximity - based and do not require a certain alignment of member objects ) . So one can discuss whether it does not make more sense to treat collections as “relationships noted by spatial arrangement” . Composites The last category of relationships to be discussed are noted by composition ( see Fig . 1 . 5 ) . The key element here are so - called Composites . According to spatial hypertext literature composites are deﬁned as lightweight , abstract , recurring , regular spatial patterns of diﬀerent object types [ 14 , 19 ] . They are spatial combinations of two or more instances of diﬀerent visual types , where each object occupies a known position in the structure [ 3 , 12 ] . There - fore , composites rely on both relative spatial positioning and the ability to distinguish between diﬀerent types of objects [ 3 ] . For instance , labeled verti - cal lists [ 14 , 19 ] can be deﬁned as composites , comprising of vertical lists with header symbols ( an example is illustrated in Fig . 1 . 5 ) . Using composites it be - comes possible to express relationships between diﬀerent types of objects [ 10 ] . 9 Chapter 1 . Introduction Figure 1 . 5 : Relationships by composition [ 12 ] – sample layout with three instances of labeled lists ( i . e . , compositions of vertical lists and header symbols ) Primary vs . Secondary In addition to classifying structures by their spa - tial and visual appearance , as we did in the last section , one can also categorize them by their expressive power and their visual eﬀects for the viewer . Depend - ing on how easily structures may be visually separated from each other and therefore how easily they can be identiﬁed as discrete meaningful units , we can distinguish between ( a ) primary and ( b ) secondary structures . Primary structures typically get noticed sooner by viewers than secondary structures . Thereby they get recognized as the structural “backbone” of a visual structure and “guide” the viewer through the interpretation process . Secondary structures rather build on top of primary structures and are often used for re - ﬁnement only ( i . e . , they express nuances of primary structures [ 20 ] ) . One could argue now ( as the ﬁndings in [ 20 ] suggest ) , that spatial properties ( e . g . , proximity , alignment etc . ) are primary means for describing structure , whereas color , shape , opacity etc . are secondary aspects of visual expression . Following this argumentation we can classify all previously deﬁned spatial struc - ture types ( incl . lists , stacks , spatial clusters etc . ) as primary structures . Tax - onomic sets ( expressed by visual similarity ) , however , overlap spatial structure and thereby link structure elements via tacit cross references [ 12 ] . Thus they can be regarded as secondary structures . The sample layout in Fig . 1 . 6 illustrates that . Fig . 1 . 6 shows a horizontal align - ment of four vertical lists ; each comprising three colored rectangular objects . One can understand that table - like layout of rectangles as an expression of the primary aspects of the overall information structure . The two diﬀerent colors assigned to rectangles only extend that “master” - structure by tacit cross refer - ences between list elements and thus cover secondary aspects of the structure . 10 1 . 5 . Implementations Figure 1 . 6 : Sample layout – primary vs . secondary structures 1 . 5 Implementations Pioneer implementations of spatial parsers were inspired by obervations of how people use map - centered hypertext systems . One of those systems was Aquanet , a hypertext system that allowed users to work with geometrical and textual information objects in a ( shared ) information space [ 21 ] . Experiences with Aquanet [ 18 ] showed , that people prefer spatial representations of hyper - text over more explicit and formal models [ 3 ] , and thus put particular impor - tance on implicit expressions [ 14 ] . In order to get a better understanding of such human - generated spatial lay - outs , a survey was conducted in both , computational and non - computational settings [ 3 , 14 ] . Within the scope of that study researchers examined several spatial hypertexts created in three diﬀerent systems [ 3 ] : ( 1 ) NoteCards [ 22 ] ; ( 2 ) the Virtual Notebook System ( VNS ) [ 23 ] and ( 3 ) Aquanet [ 21 ] . Hav - ing analyzed those sample hypertexts , each the result of a long - term informa - tion management or analysis task , it turned out that spatial layout and visual properties allow to identify speciﬁc types of structures ( such as , horizontal and vertical lists , taxonomic sets etc . ) [ 3 ] . Based on these ﬁndings , and the results of analogous studies of the way people organize materials [ 24 – 26 ] , an early “Heuristic Structure Recognizer” [ 3 ] was developed and tested . First experiments using that prototypical recognizer led to the conclusion , that automatic detection of implicit structure is feasible , and that it is therefore a worthwhile subject of further investigation [ 3 ] . This ﬁnding was one of the main driving forces for integrating a spatial parser into the VIKI system [ 12 ] . 1 . 5 . 1 Spatial Parsing in VIKI and VKB Instead of tightly coupling functionality in a more monolithic implementation , VIKI’s spatial parser realised its structure detection functionality via composi - tion of and delegation between independent structure recognition modules [ 14 ] . 11 Chapter 1 . Introduction Blackboard ( of shared information ) Statistics on types User - defined object types System - defined composite types Specialist Pipeline Stack Vertical List Horizontal List Composite Vertical List Horizontal List Resulting Spatial Parse Tree Initial Object Position , Extent and Type Strategist Orders Experts in Pipeline read statistics add new types Figure 1 . 7 : VIKI’s spatial parser – architecture for spatial recognition [ 14 ] This modular and thus ﬂexible architecture ( Fig . 1 . 7 ) comprized three core components : ( 1 ) a reconﬁgurable Pipeline of spatial structure recognizers ( “spe - cialists” ) ; ( 2 ) a Blackboard of shared information and ( 3 ) a so - called Strategist used for setting up the pipeline [ 14 ] . The “heart” of the VIKI parser was its Pipeline of specialists . Specialists were heuristics - based software components , responsible for identifying particu - lar types of structures . Those modules used the spatial display and its current parse as input and produced a new parse as output . Thus , each specialist was a small spatial parser in itself . VIKI included specialists for detecting both , ho - mogeneous structures , such as lists ( horizontal and vertical ) and stacks , but also heterogeneous structures , such as heaps and composites . Attributes used for recognizing these structure types included position , extent and object type . [ 14 ] Each specialist produced output which could be used as input for other special - ists . By doing so , specialists got linked together in a chain , or a pipeline [ 14 ] . Pipelining diﬀerent instances of ( not necessarily diﬀerent ) specialists together , has two desirable eﬀects : ( a ) a single specialist can operate multiple times ( even though we perform only a single pass ) [ 14 ] and ( b ) already detected structures can be re - parsed , which makes it possible to identify higher level structures [ 3 ] ( i . e . , the pipeline implements a bottom - up parsing strategy [ 14 ] ) . In addition to communicating via input and output , specialists shared global information via the Blackboard . This included information , such as object 12 1 . 5 . Implementations types ( deﬁned by the user ) , composite types ( deﬁned by the system ) but also statistics on the use of each type recorded in the blackboard . Specialists for heterogeneous structures created new ( system - deﬁned ) types , added them to the blackboard and updated usage statistics ( in order to reﬂect the new struc - tures ) . Specialists for the detection of homogeneous structures did not create new blackboard entries and used the types of their input objects instead . [ 14 ] The third and last component in VIKI’s parsing architecture was the so - called Strategist . The strategist‘s main task was to detect the optimal order in which specialists should be applied ( i . e . , the parsing “strategy” ) . This was accom - plished by performing some initial statistical analysis of object alignments . The resulting dominant orientation of the spatial layout was then used to determine the order of specialists in the pipeline . [ 14 ] One assumption of VIKI’s parser was the deﬁnition of user - generated types . It was assumed , that atomic information objects were given unique and mean - ingful types by the user . Practical experience with VIKI had shown , however , that often times users did not deﬁne such types [ 11 ] . This limited the spatial parser’s eﬀectivity , since VIKI , by default , treated untyped objects to be of the same type [ 7 ] . This problem was solved in VIKI’s successor VKB [ 7 ] , by patching in a visual preprocessor before the spatial parser . That preprocessor had the function to automatically assigning types to each object which did not have a user - deﬁned one . This was realized by implementing a heuristic type assignment algorithm building on the following simple rule : Objects which have similar visual attributes ( incl . width , height , background and border color , and border width ) are considered to have the same type , whereas visually dissimilar objects are considered to be of diﬀerent types [ 7 ] . Using this rule to automatically assigning visual types to objects , the preproces - sor did not only support the spatial parser in interpreting ambiguous layouts , but also decreased the workload for the users [ 11 ] . A more recent alternative to this very early implementation of a spatial parser is FLAPS [ 11 ] , which was ( among other applications ) also integrated into VKB . Unlike the spatial parser described in [ 14 ] and [ 7 ] respectively , the FLAPS - parser is a fuzzy - logics - based , multi - pass algorithm , which generates so - called “containment graphs” instead of simple parse trees [ 11 ] . Thus , what diﬀerenti - ats FLAPS from previous parser implementations , is ( 1 ) how parser output is represented and ( 2 ) how core structures are detected . Previous spatial parsers tried to resolve ambiguity by determining the best interpretation and discarding all others [ 11 ] . This procedure resulted in distinct containment hierarchies of visual structure elements ( i . e . , parse trees ) . Parser 13 Chapter 1 . Introduction output created by FLAPS , however , are graphs , where each node can have multiple parent nodes [ 11 ] . Such “containment graphs” may therefore include cycles . Thus , FLAPS produces no conventional parse trees as output . Just like previous parsers in VKB , also FLAPS uses independent structure rec - ognizers for piles , vertical lists , horizontal lists etc . The crucial diﬀerence is that recognition specialists in FLAPS are based on fuzzy - logic . FLAPS’ structure recognizers consist of fuzzy rules which can be processed by a fully - functional fuzzy - logic inference engine . Object attributes analyzed when doing such infer - ences , include ( a ) proximity and regularity and ( b ) visual similarity of objects . Proximity and regularity are determined by alignment and relative distance between objects . Evaluation of object similarity depends on visual character - istics ( e . g . , color , size etc . ) and object type ( e . g . , image , text etc . ) . This fuzzy - logics - based approach makes such recognizers particularly well suited for recognizing ambiguous structures . [ 11 ] FLAPS’ main parse procedure includes the following four steps : ( 1 ) recognize as many structures as possible ( by passing the whole space to every recognizer ) ; ( 2 ) automatically merge alternative interpretations into a single coherent struc - ture ; ( 3 ) repeat this procedure considering the recently detected structures and ( 4 ) keep doing this as long as further structures can be recognized [ 11 ] . For automatic merging FLAPS follows a minimalistic approach , where diﬀerent merging strategies are chosen , depending on whether two structures exclude , intersect , fully overlap or are identical . When two interpretations exclude or intersect , then no special merging action is required , since FLAPS can deal with both cases . When one structure is a subset of another ( i . e . , when one is contained by another ) , then the merging operation “absorbs” the subset structure and updates the relationship graph accordingly . Finally when two structures were assigned diﬀerent types but have exactly the same elements , they get joined into a new structure with a compound type ( i . e . , a new type automatically generated from both individual types ) . [ 11 ] Both VIKI’s and VKB’s original spatial parsers belong to the most important and best know parser implementations in the spatial hypermedia domain . Both broke ground for a completely new way of visual analysis : Spatial Parsing . Nevertheless , in addition to those pioneer implementations , there are further parsers used in other systems than VIKI and VKB . Some of them shall be mentioned in the following sections . 14 1 . 5 . Implementations 1 . 5 . 2 Adaptive Spatial Parsing As already pointed out , interpreting spatial hypertexts is a highly subjective issue . Whether something is perceived as structure or not strongly depends on a person‘s individual perspective [ 10 ] . However , users’ individual ways of visual thinking are usually unknown to a spatial hypermedia system . Nevertheless , a functional spatial parser still should be able to “understand” what a user intended to express by a certain arrangement of information objects . This poses great challenges for designers of spatial parsing algorithms . One possible ( though not the best ) strategy for approaching this problem , is adapting a spatial parser to its users . This could be accomplished , either by tai - loring a parser manually to particular user requirements ( e . g . , via customized implementation or conﬁguration ) , or by adapting a parser automatically ( e . g . , via supervised or unsupervised learning ) . While having the disadvantage of tying together parsers and user proﬁles ( which undesirably limits ﬂexibility ) , this adaptive approach still provides a possible solution to the aforementioned “subjective perception” - problem . The spatial parser design described in [ 17 ] is based on that idea . Building on the work presented in [ 3 , 14 ] , Igarashi et al . [ 17 ] developed an adaptive parser which uses explicit user feedback to self - adjust to users’ expectations . Their parser has the ability to “learn” from a user’s corrections of ( subjectively ) wrong interpretations made by the system and thereby supports automatic adaption . Conceptually the parser comprizes of two features : ( 1 ) a Link Model , which forms the basis for the parsing process and ( 2 ) Automated Parameter Tuning , which facilitates the parser in “learning” from users [ 17 ] . The core element of the so - called Link Model is a graph . Each vertex in that graph symbolizes an information object and each edge represents a candidate relationship . The main task of the structure recognition procedure is to eval - uate such candidates by their strength of connection and to reject those links which are not “ﬁt” enough to be part of an intended structure . [ 17 ] This basically works as follows : In a ﬁrst step links are created between ad - jacent objects . This link creation process happens in three steps : ( 1 ) sorting ; ( 2 ) ﬁnding candidates and ( 3 ) link creation . First , all objects get sorted by their upper left x - coordinate . Then , for each object , all proximity candi - dates are identiﬁed ( again by comparing x - coordinates ) . Finally , links to the closest neighbors are created ( i . e . , links to the nearest candidate in all eight directions ) . This link creation procedure gets triggered everytime an object was moved on the screen and so the neighborhood of some objects must have changed . The following steps are executed only on demand . [ 17 ] 15 Chapter 1 . Introduction In the next step the strengths of links are calculated . This strength calculation process includes two phases : ( 1 ) primary strength calculation and ( 2 ) interac - tion process [ 17 ] . Initially , primary calculations are done for each link . This includes calculation of a strength value and a list - level value . The strength of a link is deﬁned as a function of the distance between two objects , and the list - level ( i e . , the list likeliness ) is a function of both , distance and the x - / y - gaps between objects . Both functions ( strength and list - level ) can be adjusted by the adaption process , which is discussed afterwards . In addition to these two values , each link is also assigned a type . If the previously calculated list - level value is non - zero , then the link is typed as “list - link” ( horizontal or vertical respectively ) . Otherwise the link type is set to “cluster - link” . [ 17 ] The second part of the strength calculation is based on interactions among links and includes two revision cycles . In the ﬁrst cycle , links which probably do not link list elements together ( because they are conﬂicting with links be - tween surrounding objects ) , are assigned a decreased list - level value . For these purposes a parameterized factor is applied . In the second cycle , strength values are re - calculated through “repression and reinforcement” ( i . e . , adjacent links with diﬀerent types repress each other and adjacent links of the same type re - inforce each other ) . This has the eﬀect of strengthening links between objects that are located close to each other or are regularly aligned . [ 17 ] Having calculated how strong connections of certain types are , it becomes pos - sible to use those strength - indiators for ﬁltering out links which most likely belong to a structure . This is done as follows : First , the stronger ( or most stable ) links are selected . Then , objects connected by these links are grouped together in result candidates . The only thing that remains to be done is to decide on the ( primary ) type of these groupings ( i . e . , vertical list , horizontal list or just cluster ) . This decision is based on the number of links belonging to each structure type . The type that has the most links in a structure gets selected . [ 17 ] It becomes obvious , that the link model in [ 17 ] diﬀers fundamentally from the “pipeline of specialists” - approach presented in [ 3 , 14 ] . Shipman et al . ’s algo - rithms focus on the recognition of distinct classes of structures , and are partic - ularly well - suited for analysing layouts which resulted from meaningful human activities , such as document triage . The link model in [ 17 ] , on the other hand , targets more ﬂexible and ambiguous layouts that do not include the notions of stacks , heaps , composites etc . What also sets this parser apart from known solutions in VIKI and VKB , is its ability to adapt automatically to user expectations . The parser’s second essential feature besides the Link Model is called Automated Parameter Tun - 16 1 . 5 . Implementations ing and allows the parser to “learn” from explicit user feedback . This tuning mechanism is based on search heuristics and works interactively . [ 17 ] Building on genetic algorithms , the tuning mechanism operates on evolving generations of individuals . Individuals ( or candidate solutions ) lie in a conﬁg - uration parameter space and represent potential parser conﬁgurations . Each of these candidate conﬁgurations holds a set of parameters and a score . The score indicates how well the parser would perform ( in analysing user - generated training samples ) , if the respective conﬁguration parameters were applied . This “ﬁtness” - indicator is given by a ﬁtness function ( or evaluation function ) , which checks how close a given training parse result comes to the respective sam - ple structure . By statistically selecting solutions that are “ﬁt” enough and by applying operators , such as mutation and crossover , the tuning mechanism realises a search routine for ﬁnding “optimal” parser conﬁgurations . [ 17 ] Combining this heuristic parameter tuning mechanism with an interactive user interface allows for incremental reﬁnement of a spatial parser’s conﬁguration , without the need to deﬁne any numerical parameters . This is an attractive al - ternative to the cognitive complexity of tuning a set of conﬁguration parameters manually . [ 17 ] 1 . 5 . 3 Shared Spatial Parsing The spatial parser developed by Reinert et al . [ 10 , 27 ] targets a diﬀerent aspect of spatial hypermedia : Collaboration . Amongst other beneﬁts , spatial parsers can be used to resolve inconsistencies in structural interpretation and can be therefore especially helpful in collaborative environments . For that reason Reinert et al . implemented an incremental parser whose parse results can be stored persistently and shared among diﬀerent collaborative users . Their shared spatial parser was designed as an open parsing service provided by an open and collaborative spatial hypermedia system , called CAOS [ 10 , 27 ] . Conceptually the CAOS - parser builds on VIKI ( Sect . 1 . 5 . 1 ) and the algorithm discussed in the last section ( Sect . 1 . 5 . 2 ) . In addition to recognizers for lists and heaps the CAOS - parser also implements heuristics for the detection of matrices ; which is ( semantically ) not supported by VIKI and Igarashi et al . ’s implementation . Stacks , composites and clusters are not part of the design . [ 10 ] Measures used for inferring these types of structures include indicators for prox - imity , alignment and extent , but not for visual similarities . As for proximity there is only a single measure : the absolute distance between two objects in 17 Chapter 1 . Introduction two - dimensional space . When used together with a distance threshold that indicates how far apart objects can be from each other to still have a struc - tural relation , this measure allows for identifying spatially separated structures . That thresold value is deﬁned by two conﬁguration parameters ( one parameter for each dimension ) . Alignment , on the other hand , is decided by analysing position deviations in both dimensions . The position used for this is the upper left corner of an object’s bounding box . The maximum allowed variances in both directions are given by conﬁguration parameters again . [ 10 ] The CAOS - parser implements an event - driven , bottom - up algorithm . It is event - driven insofar as the parsing procedure gets triggered by editing events ( i . e . , manipulation of objects ) . Thus , single parser runs are not performed on demand but whenever spatial structures might have changed . When started , parsing happens in a bottom - up fashion . This means that the algorithm tries to build more complex structures out of simpler ones . By doing this in a repetitive fashion the parser can identify high - level structures ( e . g . , lists of lists ) . [ 10 ] Like VIKI also the CAOS - parser uses conﬁgurable structure experts to recog - nize certain types of structures . There are four experts called in the following order : ( 1 ) heap expert ; ( 2 ) horizontal list expert ; ( 3 ) vertical list expert and ( 4 ) matrix expert [ 10 ] . The heap expert is invoked ﬁrst . During execution , the following happens : Firstly , all objects in the information space are sorted according to their x - coordinate . Once that is done , all pairwise combinations of objects are checked for overlapping . When two objects overlap , the ratio between overlapping area and object extent is calculated for both objects . If one of those values exceeds a given limit , the heap expert treats the two objects as heap elements . Here the expert pursues the strategy of making heaps as big as possible . [ 10 ] Detection of heaps is followed by list recognition . The expert for recognizing horizontal lists basically proceeds as follows : In a ﬁrst step all objects get sorted by their upper left x - coordinate . This allows for horizontal iteration over all objects in the information space . In a second step , each object is assigned an itersection box . Position and extent of such a box depend on list alignment and proximity parameters . In the horizontal case an intersection box touches the upper right corner of an object . The expert then iterates through all objects from left to right and performs intersection checks between intersection boxes and upper left corner points . When two objects intersect they can be regarded as list elements . In this case the expert either builds a new list starting with these two objects or a previously detected list gets extended ( where lists are build as long as possible ) . Objects identiﬁed as list elements are skipped in further passes . Basically , the vertical list expert does the same . The only diﬀerences lie in the relative positioning of intersection boxes ( i . e . , in the vertical case they would touch the bottom left corner of an 18 1 . 5 . Implementations object ) and the coordinate used for sorting ( i . e . , in the vertical case it would be the upper left y - coordinate ) . [ 10 ] The matrix expert , which is called last , turns lists of lists into matrices and therefore depends on the list experts . Thus , list experts always must be called before the matrix expert . Its working principle can be described by the fol - lowing three steps : ( 1 ) look for matrix candidates ; ( 2 ) verify candidates as matrices and ( 3 ) substitute spatial objects . Firstly the matrix expert iterates through all objects in the information space and identiﬁes potential matrices . Such a matrix candidate is either a horizontal list of vertical lists , or a vertical list of horizontal lists . In both cases element lists must be of the same length . In the second step candidates are reparsed to check for correct alignment . This is done by checking , whether a vertical list of horizontal lists could also have been parsed as horizontal list of vertical lists . When this is the case , the expert substitutes the respective list of lists for a new spatial object that represents a matrix structure . [ 10 ] One basic assumption of the CAOS - parser is , that spatial hypertext simulates desk work and is therefore conceptually limited to vision in two - dimensional space . The same applies to Igarashi et al . ’s adaptive spatial parser ( Sect . 1 . 5 . 2 ) and parser implementations in VIKI and VKB ( Sect . 1 . 5 . 1 ) . This , however , does not necessarily have to be the case . Spatial hypertext implementations may go far beyond the classic “deskwork - paradigm” . Working with spatial hypertext can be more than simply arranging papers on a 2d - canvas . 1 . 5 . 4 Three - Dimensional Spatial Parsing Nielsen and Ørbæk [ 28 , 29 ] , for instance , have explored spatial hypertext in three - dimensional spaces . In [ 28 , 29 ] they described a spatial parser for TOPOS , a prototypical information management system which supports informal group - ings of information objects in a three - dimensional space . Nielsen and Ørbæk argued , that there is only little diﬀerence between subjective and objective placements of objects in a two - dimensional space . Which means , that the diﬀerence between perceived structure and physical structure is fairly small when the information space is limited to two dimensions . The reason for that is , that spatial hypermedia systems that implement two - dimensional information spaces allow users to view spatial structures from a ﬁxed perspec - tive only . Although the information space can be navigated via zooming and panning , the viewing angle is always the same . [ 28 , 29 ] This is not the case in a three - dimensional environment . There , camera position and orientation can have signiﬁcant inﬂuence on how proximity and proportions 19 Chapter 1 . Introduction of objects are perceived . In other words , depending on the viewing angle , groupings of objects may look completely diﬀerent . For this reason it does not make much sense to parse such a space from an objective global view point . The resulting structures would much too often confuse users . Instead three - dimensional parsers should analyze the scene from a user’s ( subjective ) viewpoint . This can be accomplished by providing the parser with the user’s current viewing frustum . Nielsen and Ørbæk’s parser implementation is based on that idea . [ 28 , 29 ] Although being designed for usage in a three - dimensional context , the core parsing algorithm was mainly inspired by VIKI’s ( Sect . 1 . 5 . 1 ) and Igarashi et al . ’s spatial parser ( Sect . 1 . 5 . 2 ) . For that reason the TOPOS - parser uses Igarashi et al . ’s link model ( in a slightly modiﬁed and extended form , called “proximity model” ) combined with Shipman et al . ’s concept of conﬁgurable structure experts ( for recognizing clusters and arbitrarily oriented lists ) . Au - tomated parameter tuning via evolutionary algorithms , however , was not im - plemented . [ 28 , 29 ] Contrary to parser implementations in VIKI and VKB , the TOPOS - parser does not search the space for well - structured layouts and rather focuses on the recognition of ( rough ) groupings of objects [ 28 , 29 ] . It therefore operates on a higher level of abstraction . While being conceptually valid , this approach is rather inappropriate in more specialized contexts of application , such as linear document authoring or movie editing . This is why more specialized parsers typically do not build on such “general purpose” - algorithms . Instead they implement algorithms which are tailored to speciﬁc application purposes and thus operate on a lower abstraction level . Good examples for that can be found in the work by Yamamoto et al . [ 30 – 32 ] . 1 . 5 . 5 Specialized Spatial Parsers Yamamoto et al . [ 30 – 32 ] developed a series of spatial hypermedia systems ( la - beled as “ART” - systems ) , that support early stages of information authoring . Such information authoring includes writing research articles or books , prepar - ing multimedia presentations or editing movies . Systems in the “ART - family” use spatial representations not as a medium for representing ﬁnal artifacts but as a means for authoring linear , hierarchical , and network structures . [ 31 , 32 ] Spatial parsers can be used in ART - systems to convert such structures into sequential texts , slides or video clips . Thus , the focus of an ART - parser is not on identiﬁcation of certain structure types ( such as , stacks , clusters etc . ) , but on translation of spatial information into more explicit textual or multimedial artifacts which can be used in an ongoing authoring process . [ 30 – 32 ] 20 1 . 5 . Implementations Currently there are no parser implementations available for translating hier - achical arrangements and network structures [ 32 ] . However , ART - systems sup - port the conversion of spatially aligned objects to linear text documents . Thus , parsing of linear structure is possible [ 30 ] . The respective spatial parser simply scans all objects on the screen sequen - tially from top - to - bottom or from left - to - right ( depending on its conﬁguration ) and thereby serializes their textual content [ 30 , 31 ] . Other spatial and visual features , such as shape , size , color etc . , have no inﬂuence on the parser’s de - cisions [ 31 ] . Although being an apparently simple approach to spatial parsing this linear structure recognizer still fulﬁlls its application purpose . Finally , it should be noted , that expressing structure via arbitrary arrangement of objects , as known from other systems , is not a use case in ART . Unlike other information spaces , the two - dimensional ART - space has pre - assigned semantics and is therefore more a feature interface than a “free” information space [ 31 ] . This can be largely ascribed to the working principle of the spatial parser : If a user intends to use the parser for auto - generating documents from spatially aligned text snippets , then he must follow predeﬁnded language conventions . In concrete terms , an object’s relative position in 2d - space is always interpreted as its position in the respective document sequence . Interpretation of arbitrary arrangements of objects is not supported . Thus , it can be argued whether the “ART - family” of authoring systems really implement spatial hypertext . Never - theless , we regard the ART - parser as specialized spatial parser . A last example for a specialized spatial parser is given in [ 33 ] , where spatial neighborhood detection in Web Squirrel is presented . Neighborhoods in Web Squirrel are groups of items clustered around labels . Such labeled clusters can be nested inside each other and thereby support the creation of hierarchical category structures . The size of such neighborhoods is decided by a conﬁgurable spatial parser which implements the following algorithm : First , the neighborhood boundary of each neighborhood label M is set to the label’s Vicinity . The Vicinity of an object is deﬁned as the object’s bounding rectangle , scaled by a given factor ( e . g . , 1 . 5 ) . Then , for each object whose Vicinity intersects a neighborhood boundary , and for each neighborhood label having a smaller fontzise than M the following is done : that item or neighbor - hood is added to M and M ’s neighborhood boundary is updated to the union of former bounds and the Vicinity of the newly added object . This gets re - peated either until all items have been assigned to some neighborhood , or until the Vicinities of all remaining objects lie outside of any neighborhood . [ 33 ] 21 Chapter 1 . Introduction 22 Chapter 2 Formal View The last chapter was supposed to serve as both , an introduction into the ﬁeld ( s ) of spatial hypermedia and spatial parsing and as an overview of relevant liter - ature . It was shown how spatial hypertext and spatial parsing are informally deﬁned ( Sect . 1 . 2 and Sect . 1 . 3 ) and which practical solutions to the parsing - problem were developed ( Sect . 1 . 5 ) . In summary , we can deﬁne spatial hypertext as an alternative representation form of traditional hypertext , which is natural , lightweight and ﬂexible . In contrary to classic node - link hypertext , spatial hypertext expresses associations between information objects implicitly by spatial and visual attributes [ 1 , 7 ] , supports constructive ambiguity [ 3 , 9 ] , does not require premature ( formal ) language deﬁnition [ 12 ] , and supports expression of evolving lightweight struc - tures [ 7 , 14 ] . In short , spatial hypertext is of implicit , ambiguous , informal and emergent nature ( Sect . 1 . 2 ) . Information structures which are implic - itly encoded in such human - generated arrangements of objects are detected by heuristics - based ( software ) components , so - called spatial parsers . Spatial parsers infer implicit structural knowledge from explicit spatio - visual knowl - edge and thereby turn implicit information structures into explicit ones . In short , the process of parsing spatial hypertexts can be deﬁned as retrieving hidden information structures from human - generated layouts ( Sect . 1 . 3 ) . Although being accepted within the spatial hypermedia community , this view on spatial hypertext and spatial parsing is purely informal . Nobody has tried yet to deﬁne both spatial hypertext and spatial parsing formally . Which means that there is no common theoretical , mathematical basis yet , which could be used to approach the parsing problem more systematically . This chapter is intended to change that . 23 Chapter 2 . Formal View 2 . 1 Spatial Hypertext Languages As pointed out already , spatial hypertext can be seen as an alternative rep - resentation form of traditional hypertext . Rather than making information structure explicit by deﬁning formal nodes and links , spatial hypertext targets at expressing and communicating implicit structure via visual aids ( e . g . , shape , color etc . ) . Visual expression and communication of implicit structural knowl - edge requires an appropriate visual notation . Such a visual language must be compatible with the core characteristics of spatial hypertext ( Sect . 1 . 2 ) and therfore has to be lightweight , ﬂexible and intuitive . We denote such visual notations as Spatial Hypertext Languages . Spatial hypertext languages are informal , visual languages for implicit structure representation . Expressions in such a language are collections of visual features that describe structure but , as opposed to visual programming languages , do not specify behaviour . Spatial hypertext languages are not intended for specify - ing dynamics and are rather used for describing static networks of information units . In a general sense , spatial hypertext is structure expressed in a visual representation language . From a formal point of view , one can see a language as a set of ( meaningful ) structures , which are called words . Words are constructed from symbols and the set of symbols from which the words of the language may be formed is known as alphabet . This simple , set - theoretical deﬁnition applies not only to string - based languages , where words are viewed as one - dimensional sequences of symbols , but also holds true for visual languages . Also visual languages can be deﬁned as sets of words constructed from symbols . The crucial diﬀerence , however , is that ( 1 ) “visual symbols” are graphical rather than textual and ( 2 ) “visual words” are diagrams rather than strings . A good example for that are languages deﬁned by picture layout grammars [ 15 ] . Following this idea , we can deﬁne spatial hypertext languages as sets of spa - tial hypertext artifacts ( i . e . , words ) , where each artifact is nothing more than a ﬂat collection of spatial hypertext symbols . We use the term “artifact” due to the emergent character inherent to spatial hypertexts ( Sect . 1 . 2 ) : that is , arrangements of information objects that emerge in the course of an informa - tion analysis task are rather intermediate results ( or steps ) of a development process than just self - contained expressions in a particular language . For this reason , we consider the term “artifact” as being more appropriate than simply calling elements of a spatial hypertext language “words” . Thus we deﬁne spa - tial hypertext languages as sets of spatial hypertext artifacts . Such artifacts are sets of spatial hypertext symbols , and symbols are collections of spatial or visual properties ( such as , position , shape , color etc . ) . Symbol properties are represented as instances ( or elements ) of attribute types , which are sets of 24 2 . 1 . Spatial Hypertext Languages attribute values . The deﬁnition of such types forms the visual character of a spatial hypertext language . Spatial examples for such attribute types include position , size , orientation , but also shape . We deﬁne “shape” as all the geometrical information of an object that is invariant to changes of location , orientation and size . Visual attributes , on the other hand , may include line settings ( such as line style , color , thickness etc . ) , surface properties ( such as ﬁll color , textures etc . ) , but also opacity or transparency values . The concrete deﬁnition of such spatial and visual attribute types strongly depends on the visual user interface of a spatial hypermedia system . One system , for example , might allow for arbitrary placement of objects in R 2 , whereas another one holds objects in a discrete two - dimensional grid . Although both systems support spatial arrangement of objects they still implement diﬀerent deﬁnitions of position : the ﬁrst one builds on real - valued vectors , whereas the latter one assignes objects to cells in a grid . Thus , in theory we can identify several classes of attribute types which most likely belong to a spatial hypertext language ( such as : position , size , orientation , shape , color etc . ) . The exact deﬁnition of these sets of attribute values depends on concrete system implementation . Another point to be noted , relates to the deﬁnition of well - formed words ( or well - formed artifacts ) . As pointed out already in the last chapter ( Sect . 1 . 3 ) , we cannot know how words of a spatial hypertext language are generated before the hypertext gets modeled and the visual language has emerged . Thus premature deﬁnition of an adequate formal grammar is not possible . We therefore need an alternative approach to grammatical construction in order to formally deﬁne spatial hypertext . Here we beneﬁt from the set - theoretical view on formal languages , that was menioned before : If we deﬁne a formal language L as some set of words over an alphabet Σ and if we denote the set of all words over the same alphabet as Σ ∗ , then L eﬀectively is a subset of Σ ∗ ( i . e . , L ⊆ Σ ∗ ) . Such a subset could be deﬁned now in two ways : either by explicitely listing or describing all elements that belong to the set of well - formed words ( e . g . , by using a formal grammar , an automaton etc . ) or by excluding all words from Σ ∗ which do not belong to the language . The latter approach allows for an easy , formal approximation to languages with an unclear syntactic structure . Spatial hypertext languages are good examples for that . This will become clear from the following details : As designers of spatial hypermedia systems we may not be able to predict ex - actly which artifacts might be regarded as being well - formed , but we usually know which hypertexts are uncommon or simply not possible . When design - ing spatial hypermedia interfaces two fundamental decisions must be made , ( 1 ) which spatial or visual properties should be used and ( 2 ) which constraints should be put on visual information objects . 25 Chapter 2 . Formal View First of all , the designer must specify relevant spatial and visual attribute types . It must be deﬁned which classes of properties should be supported by the visual interface ( e . g . , position , shape , size etc . ) , and it must be decided how to implement these features . This implicitly deﬁnes the set of all visual symbols that can be formed ; that is , the spatial hypertext “alphabet” . Secondly , the designer must decide on potential constraints on symbols and symbol combinations . It must be deﬁned whether to prohibit certain attribute value combinations ( e . g . , via respective rules in a symbol editing dialog ) , or if particular symbol combinations in the workspace should be avoided ( e . g . , by activating or deactivating gui components that are used for symbol creation ) . This way the system designer determines which symbols are allowed and may be put together in the same artifact . The designer thereby limits the number of artifacts which can be built and eﬀectively deﬁnes the spatial hypertext language that is available via the user interface . That language can be further reﬁned by the user of the system . In the course of creating , modifying and deleting symbols , users select subsets of attribute type deﬁnitions ( e . g . , by choosing only black and white as ﬁll - color ) and tend to avoid certain attribute value and symbol combinations ( e . g . , black spheres are never used together with white rectangles ) . By adding such additional con - straints on symbols and attributes , users implicitly reﬁne an interface language into “their language” ( which is the language currently in use ) . So , in practical implementations both can limit the range of a spatial hypertext language , system designers and users . Designers impose restrictions on visual interfaces and users of such interfaces choose those features that might be ap - propriate for solving a certain problem . Insofar we do not fully agree with [ 34 ] stating that such a visual language is “not prescriptive or restrictive” . To some extent every spatial hypertext language is restrictive . Spatial hypertext lan - guages are always bound to system implementations and are therefore limited by system design . In other words , there is no spatial hypertext implementation which allows for “total freedom” in expression . Although this might sound negative , it still allows us to deﬁne sets of spatial hypertext artifacts which most likely do not belong to a certain spatial hyper - text language . By excluding these words from the full set of artifacts , we can approximate a spatial hypertext language as follows : L SH = Σ ∗ SH \ X SH ( 2 . 1 ) Here , L SH is a symbolic placeholder for a single spatial hypertext language ( i . e . , a set of spatial hypertext artifacts ) , Σ ∗ SH is the set of all artifacts which can be build from given attribute type deﬁnitions , and X SH is an eXclusion set comprising all spatial hypertext artifacts not part of the language L SH . According to this deﬁnition , X SH must be a subset of Σ ∗ SH . We decided that 26 2 . 1 . Spatial Hypertext Languages X SH should be a proper subset , and therefore may not be equal to Σ ∗ SH . The reason for this is , that we consider empty spatial hypertext languages ( such as L SH = (cid:0) Σ ∗ SH \ Σ ∗ SH (cid:1) = ∅ ) as being of no practical relevance . One could even argue , that such an empty set of artifacts is no spatial hypertext language anymore , since the spatial aspect ( in the form of spatial arrangements of objects ) is completely missing . Only expression of space ( even if it is just an empty information space ) forms a spatial language . Otherwise it would be nothing more than just some empty language . Thus we deﬁne : X SH ⊂ Σ ∗ SH ( 2 . 2 ) We also assume , that the empty spatial hypertext artifact H ε ( which is just an empty set of spatial hypertext symbols ) , is not an element of the exclusion set X SH . This is intended to guarantee , that the empty artifact H ε does never get excluded and is therefore an element of any spatial hypertext language . Thus we can be sure that H ε is always a well - formed artifact . Given that H ε = ∅ , we can extend our deﬁnition from Eq . 2 . 2 to : X SH ⊂ Σ ∗ SH , H ε / ∈ X SH ( 2 . 3 ) The second fundamental component besides the exclusion set X SH is Σ ∗ SH . Σ ∗ SH is deﬁned as the set of all spatial hypertext artifacts which can be gener - ated based on a given spatial hypertext “alphabet” , which we denote as Σ SH . Even though this deﬁnition was inspired by the Kleene - hull Σ ∗ over an alpha - bet Σ , it is mathematically not exactly the same . This will become clear from the following details : Assume that we have n ≥ 1 Attribute types A 0 , A 1 , . . . , A n − 1 . Each A i shall be deﬁned as a non - empty set of attribute values ( i . e . , A i 6 = ∅ for 0 ≤ i ≤ n − 1 ) . Then we can deﬁne the non - empty set of all spatial hypertext symbols which may be formed from elements out of A 0 , A 1 , . . . , A n − 1 as : Σ SH = ( A 0 × A 1 × . . . × A n − 1 ) ( 2 . 4 ) According to this deﬁnition , the “alphabet” Σ SH represents the set of all at - tribute value combinations ( i . e . , n - tuples of attributes ) which could be formed from n predetermined attribute types . Our deﬁnition of Σ ∗ SH builds on this n - ary cartesian product as follows : Σ ∗ SH = { H | H ⊆ Σ SH } = 2 Σ SH ( 2 . 5 ) Σ ∗ SH is the set of all Hypertext artifacts H ( i . e . , ﬂat collections of symbols ) that are subset of or equal to the spatial hypertext “alphabet” Σ SH . Thus , Σ ∗ SH is the set of all subsets of Σ SH ( incl . H ε , Σ SH ∈ Σ ∗ SH ) and is therefore the powerset of Σ SH . Given these deﬁnitions we can ﬁnally rewrite L SH = (cid:0) Σ ∗ SH \ X SH (cid:1) to : L SH = (cid:16) 2 Σ SH \ X SH (cid:17) = (cid:16) 2 ( A 0 × A 1 × . . . × A n − 1 ) \ X SH (cid:17) ( 2 . 6 ) 27 Chapter 2 . Formal View Even though this is an apparently straightforward approach to formalization , it still allows us to talk about spatial hypertexts in a uniform way ( something which had not been possible before ) . This will proof very helpful in what we are going to do in the following chapters . In summary we can formally deﬁne a spatial hypertext language as follows : L SH = Σ ∗ SH \ X SH Σ ∗ SH = { H | H ⊆ Σ SH } = 2 Σ SH Σ SH = ( A 0 × A 1 × . . . × A n − 1 ) , n ≥ 1 A i 6 = ∅ ( 0 ≤ i ≤ n − 1 ) X SH ⊂ Σ ∗ SH , H ε / ∈ X SH , H ε = ∅ ⇒ L SH = (cid:16) 2 Σ SH \ X SH (cid:17) = (cid:16) 2 ( A 0 × A 1 × . . . × A n − 1 ) \ X SH (cid:17) ( 2 . 7 ) Here it becomes obvious that spatial hypertext languages are mainly deter - mined by two components : Σ SH and X SH . This allows for a parameterized deﬁnition of such languages in a “template - like” notation ( which will play an important role later in this thesis ) : L SH h Σ SH , X SH i : = (cid:16) 2 Σ SH \ X SH (cid:17) ( 2 . 8 ) So , instead of (cid:0) 2 Σ SH \ X SH (cid:1) one could also use the synonymous expression L SH h Σ SH , X SH i . This does not change the original meaning of Eq . 2 . 7 and is merely used for simpliﬁcation . The following example shall help us to better understand Eq . 2 . 7 : Let us assume , that we are looking for the smallest spatial hypertext language possible . Following Eq . 2 . 1 , every spatial hypertext language L SH can be de - ﬁned as L SH = (cid:0) Σ ∗ SH \ X SH (cid:1) , where X SH ⊂ Σ ∗ SH ( Eq . 2 . 2 ) . Thus , the size of L SH is determined by the size of both Σ ∗ SH and the exclusion set X SH . The larger Σ ∗ SH and the smaller X SH the greater the size of L SH , and , vice versa , the smaller Σ ∗ SH and the larger X SH the smaller the size of L SH will be . Con - sequently , if one intends to reduce the size of L SH to a minimum , then Σ ∗ SH must be minimized and X SH must be maximized . This is exactly what we are doing now : Firstly , we need an adequate deﬁnition of attribute types . According to Eq . 2 . 4 , both is required ( a ) there has to be at least one attribute type deﬁned and ( b ) attribute types may never be empty . Both requirements can be met , if we have only a single attribute type , including only a single attribute value . The semantics of the type , however , do not matter in this example ( typically it would be position ; since we are primarily interested in spatial expressions ) . 28 2 . 1 . Spatial Hypertext Languages Here , such a minimal attribute type shall be deﬁned as : A min = { a } When we apply now the rule implied by Eq . 2 . 4 on A min we get : Σ SH min = (cid:8) ( a ) (cid:9) ( 2 . 9 ) So , the minimal set of spatial hypertext symbols ( which we denote as Σ SH min ) includes only a single element with only one attribute . When we take this deﬁnition of a minimal spatial hypertext “alphabet” and apply the rule implied by Eq . 2 . 5 on it , then we get the following minimal set of spatial hypertext artifacts : Σ ∗ SH min = 2 Σ SHmin = 2 { ( a ) } = n(cid:8) ( a ) (cid:9) , ∅ o = n(cid:8) ( a ) (cid:9) , H ε o ( 2 . 10 ) This minimal set includes just two elements : an artifact with only a single symbol – the unary tuple ( a ) – and the empty spatial hypertext artifact H ε = ∅ ( which is by default included in the power set ) . So , we know already both minimal sets , Σ SH min ( Eq . 2 . 9 ) and Σ ∗ SH min ( Eq . 2 . 10 ) . What still needs to be determined is an adequate , maximized exclusion set ( which we will denote as X SHmax ) . According to Eq . 2 . 3 , an exclusion set X SH must be a proper subset of Σ ∗ SH and may not inlude H ε . In our case this means , that X SH max ⊆ ( Σ ∗ SH min \ { H ε } ) , which can be rewritten as follows : X SH max ⊆ (cid:16) Σ ∗ SH min \ { H ε } (cid:17) ⇔ X SH max ⊆ (cid:18) n(cid:8) ( a ) (cid:9) , H ε o \ { H ε } (cid:19) ⇔ X SH max ⊆ n(cid:8) ( a ) (cid:9)o The only two assignments of the variable X SH max which could fulﬁll the con - straint X SH max ⊆ { { ( a ) } } , are X SH max = ∅ and X SH max = { { ( a ) } } . Since we are searching for an exclusion set , that should be maximal in size , we can reject X SH max = ∅ . We therefore set : X SH max = n(cid:8) ( a ) (cid:9)o ( 2 . 11 ) Knowing now both required components Σ ∗ SH min ( Eq . 2 . 10 ) and the maximal exclusion set X SH max we can ﬁnally determine the minimal language L SH min : L SH min = Σ ∗ SH min \ X SH max = n(cid:8) ( a ) (cid:9) , H ε o \ n(cid:8) ( a ) (cid:9)o = { H ε } L SH min ⇔ L SH (cid:10) Σ SH min , X SH max (cid:11) ( 2 . 12 ) 29 Chapter 2 . Formal View From this ( Eq . 2 . 12 ) it can be concluded , that the smallest spatial hypertext language possible is a language that comprizes only of a single element , which is the empty spatial hypertext artifact ( H ε ) . Thus , the least we can express with a spatial hypertext language is an empty information space ( i . e . , white screen ) . Spatial hypertexts do not fall simply from sky , but are always the result of a development process that has to start from somewhere ( typically from an empty workspace ) . In this regard our deﬁnition makes perfect sense . So far we have discussed which artifacts ( or words ) belong to a spatial hypertext language . In addition to this “syntactic view” , if you want to call it that , there is still another aspect , that is even more important : semantics As we have already seen ( Sect . 1 . 4 ) , there is only little concrete structure in human - generated layouts . Although in spatial hypertext research one has tried to identify several categories of spatial and visual structures ( such as lists , stacks , piles , heaps etc . ) they still should be treated with caution . There is no guarantee that these spatial patterns are always valid or that their recognition brings any beneﬁt . The main reason for this is , that implicit structures typically emerge individually in mind and depend on the context in which they are used . This makes premature deﬁnition of default - structures extremely diﬃcult ( or even impossible ) . In other words , there is not too much we can say about spatial hypertexts before users start working on them . To put it in one sentence : Spatial hypertext structures result from creative work and therefore cannot be predicted ! Not only did this inﬂuence our deﬁnition of spatial hypertext languages ( as given in Eq . 2 . 7 ) , but has also aﬀected our understanding of “spatial parsing” : Rather than checking the canvas against predeﬁned structural patterns ( which is common practice today ) , spatial parsers should imitate humans in the way they perceive structure . In other words , instead of searching hypertexts for supposedly universal structures ( such as stacks , tables , heaps etc . ) , spatial parsers rather should perceive structure through the lense of a human observer ( i . e . , spatial parsers should “interpret” spatial hypertexts ) . As system designers we cannot with any certainty predict which structures are typically created by users . That is not possible . In this respect spatial hyper - text oﬀers just too much creative leeway . The one thing we can be sure of , however , are the basic principles by which human observers ( and thus hyper - text authors ) perceive spatial structure . Good examples include the so - called Gestalt - principles or rather Gestalt - heuristics ( such as the laws of similarity , proximity , or symmetry etc . ) . By an intelligent combination of such heuris - 30 2 . 2 . Spatial Hypertext Interpretations tics , spatial parsers could provide structural interpretations which might come quite close to what author ( s ) had in mind when they were creating a hypertext . This way one could detect intended structure for a large number of people in many diﬀerent contexts of application , even though it is unknown who created the hypertext and for what purposes . Our parsing algorithms ( that will be discussed later on ) build on this idea . They take spatial hypertext artifacts as parser input , analyse them with basic , common sense heuristics and ﬁnally generate output in the form of so - called interpretations , which are discussed in the following section . 2 . 2 Spatial Hypertext Interpretations As already pointed out in Sect . 1 . 2 , spatial hypertext is of ambiguous nature . This allows for reading spatial hypertext artifacts in diﬀerent ways . Both , humans and parsers may have diﬀerent views on spatial hypertext and its implicitly encoded information . Depending on the angle from which one tries to understand the spatial and visual dependencies displayed on screen ( or provided via other interfaces ) , there will typically be more than only one way to read the hypertext . Depending on your previous knowledge in mind and where you start with your analysis , diﬀerent aspects are treated with diﬀerent priority , so that some structures will be preferred over others . This results in multiple ( alternative ) interpretations . Interpretations are encodings of how spatial hypertext can be understood ( by both humans or parsers ) and thus form the semantic complement to spatial hypertext artifacts ( Sect . 2 . 1 ) . In concrete terms , this means that they are formal descriptions of how visual symbols and ( even more important ) symbol relations can be interpreted . Typically , symbols are treated as visual placehold - ers for information objects , and object relations are implicitly given by symbol properties . Insofar interpretations only vary in object relations but not in the number of objects . We express such interpretations as collections of information structures , or rather as networks of information objects ( remember that spatial hypertext is actually an alternative representation form of node - link hypertext ; Sect . 1 . 1 ) . However , to distinguish clearly between the node - link model of classic hypertext and our formal interpretation model , we will use the terms “information unit” and “association” instead of “node” and “link” : Let X I be a set of k ( alternative ) interpretations I i ( where 0 ≤ i ≤ k − 1 ) : X I = { I 0 , I 1 , . . . , I k − 1 } ; | X I | = k ( 2 . 13 ) 31 Chapter 2 . Formal View (  ,  ) = {  0 ,  1 ,  2 } , {  0 ,  1 } , {  0 ,  2 } , {  1 ,  2 } è  0  1  2 Figure 2 . 1 : Example of a complete , undirected interpretation graph ( U , A ) , including three information units u 0 , u 1 and u 2 , which are connected by three associations { u 0 , u 1 } , { u 0 , u 2 } , and { u 1 , u 2 } . Each interpretation I i ( 0 ≤ i ≤ k − 1 ) included in X I ( Eq . 2 . 13 ) , shall be deﬁned as a triple ( U , A , w i ) , where U is a set of n information Units , A is a set of Associations , and w i represents a weighting function that is speciﬁc to interpretation I i : I i : = ( U , A , w i ) ( 2 . 14 ) Provided that Ω is the universal set of all theoretically possible information units ( i . e . , the basic set of all carriers of information ) , we can deﬁne U ( which is some collection of information units ) as an arbitrary subset of Ω and herewith as an element of 2 Ω : U = { u 0 , u 1 , . . . , u n − 1 } ∈ 2 Ω ; | U | = n ( 2 . 15 ) Since in theory all elements of U could be associated with each other and as we are dealing here only with undirected associations , we can deﬁne A as the set of ( binary ) subsets { u , u ′ } of U , which can be written as (cid:0) U 2 (cid:1) : A = (cid:18) U 2 (cid:19) = n { u h , u l } (cid:12)(cid:12)(cid:12) 0 ≤ h < l ≤ n − 1 o ( 2 . 16 ) The number of associations | A | is given here by a triangular number : | A | = (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:18) U 2 (cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) = (cid:18) | U | 2 (cid:19) = (cid:18) n 2 (cid:19) = n ! 2 ! ( n − 2 ) ! = n ( n − 1 ) 2 = n 2 − n 2 ( 2 . 17 ) Together U and A apparently form a complete undirected graph , where vertices ( or nodes ) represent information units and edges are regarded as associations . Fig . 2 . 1 illustrates a simple example with three information units u 0 , u 1 , u 2 . With this tool at hand we can express that in theory all carriers of information u ∈ U that are encoded in a spatial hypertext artifact could be associated with each other in some way . Modeling full interpretations , however , requires more than only describing plain connections between objects . Only specifying that 32 2 . 2 . Spatial Hypertext Interpretations all units might be related to each other is not suﬃcient . In addition we must be able to parameterize associations between information units . This means , it must be possible to deﬁne properties of object relations ( if there are any ) . This is why the tuple ( U , A ) gets extended by the binary relation w i . w i shall be a weighting function assigning weights ( i . e . , parameters ) to edges ( i . e . , associations ) . More precisely w i is a total function mapping A to a non - empty set of association Parameterizations , which we simply call P : w i : A → P , P = ( P 0 × P 1 × . . . × P m − 1 ) ∪ P ε , m ≥ 1 P j 6 = ∅ ( 0 ≤ j ≤ m − 1 ) P ε 6 = ∅ , P ε ⊂ P ( 2 . 18 ) A key role here is played by P ε . P ε is a ( non - empty ) set of so - called empty parameterizations . When assigned to an edge { u , u ′ } ∈ A , such an empty pa - rameterization p ∈ P ε may indicate either that there is no speciﬁc relationship between u and u ′ , or that such a relation is unknown ( there might be one , but we are note sure about it ) . Given that interpretations are collections of structures and structures are networks of meaningfully connected information units , we can use elements of P ε as structure delimiters . In concrete terms , elements of P ε can be used to separate discrete structures from each other . Mathematically expressed , using P ε we can deﬁne the j th discrete information structure included in an i th interpretation I i : = ( U , A , w i ) as a connected sub - graph I ′ ij which has the following properties : I ′ ij : = ( U ij , A ij , w ij ) U ij ⊆ U ; (cid:12)(cid:12) U ij (cid:12)(cid:12) ≥ 2 A ij = ( a (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) a ∈ (cid:18) U ij 2 (cid:19) ∧ w i ( a ) / ∈ P ε ) ⇒ A ij ⊆ A ; (cid:12)(cid:12) A ij (cid:12)(cid:12) ≥ 1 w ij : A ij → P \ P ε , ∀ a ∈ A ij : w ij ( a ) = w i ( a ) ( 2 . 19 ) According to this ( Eq . 2 . 19 ) , we can deﬁne information structures as connected sub - graphs I ′ ij of interpretation graphs I i . Such sub - graphs comprize of at least two vertices ( i . e . , information units u ∈ U ij ) which are connected by undirected edges ( i . e . , associations a ∈ A ij ) that are decorated only with values / ∈ P ε . We have chosen (cid:12) (cid:12) U ij (cid:12) (cid:12) ≥ 2 and so the constraint (cid:12) (cid:12) A ij (cid:12) (cid:12) ≥ 1 in Eq . 2 . 19 because we ﬁrmly believe that only relations create structure . Single information units are nothing more than atomic objects ; their internal composition ( i . e . , “payload” ) does not matter here . Spatial parsers search for visual object relations but do not “care” about content . 33 Chapter 2 . Formal View The following example is intended to make that a bit clearer : Assume we have selected ﬁve random information units u from Ω . For the sake of simplicity we number them continuously from u 0 to u 4 . The exact values of these variables shall not play a role here . Then we can , according to Eq . 2 . 15 and Eq . 2 . 16 deﬁne both components U and A as follows : U = { u 0 , u 1 , u 2 , u 3 , u 4 } A =    { u 0 , u 1 } , { u 0 , u 2 } , { u 0 , u 3 } , { u 0 , u 4 } , { u 1 , u 2 } , { u 1 , u 3 } , { u 1 , u 4 } , { u 2 , u 3 } , { u 2 , u 4 } , { u 3 , u 4 }    ( 2 . 20 ) In addition , the following parameter sets shall be given : P type = { type 0 , type 1 , type 2 } P weight = { 0 . 25 , 0 . 50 , 0 . 75 , 1 . 00 } P ε = { ε } Here , P type is a set of discrete type indicators ( ranging from type 0 to type 2 ) and P weight is a discrete set of real - valued weights , which we deﬁne ( for reasons of simplicity ) in steps of 14 from 0 . 25 to 1 . 00 . The mandatory set of empty parameterizations P ε shall comprise here only of a single element , which we denote as ε . With these parameter sets and the deﬁnitions given by Eq . 2 . 18 , we can now deﬁne the parameterization set P as follows : P = ( P type × P weight ) ∪ P ε =    ( type 0 , 0 . 25 ) , ( type 0 , 0 . 50 ) , ( type 0 , 0 . 75 ) , ( type 0 , 1 . 00 ) , ( type 1 , 0 . 25 ) , ( type 1 , 0 . 50 ) , ( type 1 , 0 . 75 ) , ( type 1 , 1 . 00 ) , ( type 2 , 0 . 25 ) , ( type 2 , 0 . 50 ) , ( type 2 , 0 . 75 ) , ( type 2 , 1 . 00 ) , ε    ( 2 . 21 ) Based on these deﬁnitions of U , A and P we will now describe three example interpretations : X I = { I 0 , I 1 , I 2 } . According to Eq . 2 . 14 , each of these interpretations I i is a triple ( U , A , w i ) , comprising of the two shared components U and A , and the interpretation speciﬁc weighting function w i . As per Eq . 2 . 18 w i is a total function and thus a special binary relation . We therefore illustrate w 0 , w 1 and w 2 in tabular form : see Fig . 2 . 2 . Each table in Fig . 2 . 2 includes | A | = 10 ordered pairs consisting of associa - tions { u , u ′ } ∈ A ( Eq . 2 . 20 ) and assigned parameterizations p ∈ P ( Eq . 2 . 21 ) . 34 2 . 2 . Spatial Hypertext Interpretations  (cid:2868) =  ,  ,  (cid:2868)  (cid:2869) =  ,  ,  (cid:2869)  (cid:2870) =  ,  ,  (cid:2870)  (cid:2868)  (cid:2869)  (cid:2870) {  (cid:2868) ,  (cid:2869) }  {  (cid:2868) ,  (cid:2869) }  {  (cid:2868) ,  (cid:2869) }  {  (cid:2868) ,  (cid:2870) }  {  (cid:2868) ,  (cid:2870) }  {  (cid:2868) ,  (cid:2870) } (cid:1872)    (cid:2870) , (cid:882) . 5(cid:882) {  (cid:2868) ,  (cid:2871) }  {  (cid:2868) ,  (cid:2871) } (cid:1872)    (cid:2868) , (cid:882) . 5(cid:882) {  (cid:2868) ,  (cid:2871) }  {  (cid:2868) ,  (cid:2872) }  {  (cid:2868) ,  (cid:2872) }  {  (cid:2868) ,  (cid:2872) } (cid:1872)    (cid:2869) , (cid:883) . (cid:882)(cid:882) {  (cid:2869) ,  (cid:2870) } (cid:1872)    (cid:2869) , (cid:882) . 75 {  (cid:2869) ,  (cid:2870) } (cid:1872)    (cid:2868) , (cid:882) . 5(cid:882) {  (cid:2869) ,  (cid:2870) }  {  (cid:2869) ,  (cid:2871) } (cid:1872)    (cid:2868) , (cid:882) . 5(cid:882) {  (cid:2869) ,  (cid:2871) }  {  (cid:2869) ,  (cid:2871) } (cid:1872)    (cid:2868) , (cid:882) . 5(cid:882) {  (cid:2869) ,  (cid:2872) } (cid:1872)    (cid:2869) , (cid:882) . 5(cid:882) {  (cid:2869) ,  (cid:2872) } (cid:1872)    (cid:2869) , (cid:883) . (cid:882)(cid:882) {  (cid:2869) ,  (cid:2872) }  {  (cid:2870) ,  (cid:2871) }  {  (cid:2870) ,  (cid:2871) }  {  (cid:2870) ,  (cid:2871) }  {  (cid:2870) ,  (cid:2872) } (cid:1872)    (cid:2870) , (cid:883) . (cid:882)(cid:882) {  (cid:2870) ,  (cid:2872) } (cid:1872)    (cid:2869) , (cid:882) . 75 {  (cid:2870) ,  (cid:2872) } (cid:1872)    (cid:2869) , (cid:882) . 75 {  (cid:2871) ,  (cid:2872) }  {  (cid:2871) ,  (cid:2872) }  {  (cid:2871) ,  (cid:2872) }  Figure 2 . 2 : Three example weighting functions w 0 , w 1 and w 2 illustrated in tabular form . Values of p were chosen arbitrarily . The deﬁnitions given by Eq . 2 . 19 allow for identifying a number of discrete information structures in the form of con - nected sub - graphs . Value pairs belonging to such structures are marked with diﬀerent colors ( red and blue ) . When we combine these colored tuples in the form described in Eq . 2 . 19 we get the following information structures : I ′ 00 =       { u 1 , u 2 , u 3 , u 4 } , (cid:8) { u 1 , u 2 } , { u 1 , u 3 } , { u 1 , u 4 } , { u 2 , u 4 } (cid:9) ,      (cid:0) { u 1 , u 2 } , ( type 1 , 0 . 75 ) (cid:1) , (cid:0) { u 1 , u 3 } , ( type 0 , 0 . 50 ) (cid:1) , (cid:0) { u 1 , u 4 } , ( type 1 , 0 . 50 ) (cid:1) , (cid:0) { u 2 , u 4 } , ( type 2 , 1 . 00 ) (cid:1)             I ′ 10 =   { u 0 , u 3 } , (cid:8) { u 0 , u 3 } (cid:9) , n(cid:0) { u 0 , u 3 } , ( type 0 , 0 . 50 ) (cid:1)o   I ′ 11 =   { u 1 , u 2 , u 4 } , ( { u 1 , u 2 } , { u 1 , u 4 } , { u 2 , u 4 } ) ,   (cid:0) { u 1 , u 2 } , ( type 0 , 0 . 50 ) (cid:1) , (cid:0) { u 1 , u 4 } , ( type 1 , 1 . 00 ) (cid:1) , (cid:0) { u 2 , u 4 } , ( type 1 , 0 . 75 ) (cid:1)     I ′ 20 =   { u 1 , u 3 } , (cid:8) { u 1 , u 3 } (cid:9) , n (cid:0) { u 1 , u 3 } , ( type 0 , 0 . 50 ) (cid:1)o   I ′ 21 =       { u 0 , u 2 , u 4 } , ( { u 0 , u 2 } , { u 0 , u 4 } , { u 2 , u 4 } ) ,    (cid:0) { u 0 , u 2 } , ( type 2 , 0 . 50 ) (cid:1) , (cid:0) { u 0 , u 4 } , ( type 1 , 1 . 00 ) (cid:1) , (cid:0) { u 2 , u 4 } , ( type 1 , 0 . 75 ) (cid:1)          35 Chapter 2 . Formal View ε ( type 1 , 0 . 75 ) ε ( t y p e 0 , 0 . 5 ) ε ( t y p e 2 , 1 . 0 ) ε ε ε ε u 0 u 3 u 4 u 2 u 1 ( t y p e 1 , 0 . 5 ) ( type 0 , 0 . 5 ) ε ε ε ( t y p e 1 , 0 . 75 ) ε ( t y p e 0 , 0 . 5 ) ε ε u 0 u 3 u 4 u 2 u 1 ( t y p e 1 , 1 . 0 ) ε ε ( t y p e 0 , 0 . 5 ε ( t y p e 1 , 0 . 75 ) ( t y p e 1 , 1 . 0 ) ε ε u 0 u 3 u 4 u 2 u 1 ( type 2 , 0 . 5 )  0  1  2 Figure 2 . 3 : Three example interpretations I 0 , I 1 and I 2 illustrated in the form of two - dimensional graph diagrams . Included structures are highlighted in red and blue . Since these tuples are graphs , one can also illustrate them in form of dia - grams . Fig . 2 . 3 illustrates I 0 , I 1 and I 2 in two - dimensional graph representa - tion ( aligned from left to right ) . Included information structures are highlighted with respective colors , red and blue ( which is consistent with Fig . 2 . 2 ) . Summarising the above it can be said , that interpretations of spatial hypertext artifacts are collections of clearly separable networks of meaningfully connected information units , which we denote as information structures . Together with our notion of spatial hypertext languages ( from Sect . 2 . 1 ) this understanding of interpretations and information structures will play an important role in following chapters . 36 Chapter 3 Critical Review The last two chapters provided diﬀerent views on spatial hypermedia . It was shown how spatial hypertext and spatial parsing are informally deﬁned in liter - ature ( Sect . 1 . 2 and Sect . 1 . 3 ) and which practical implementations of spatial parsers exist ( Sect . 1 . 5 ) . We also had a formal view on spatial hypertext . Chap - ter 2 provided a common mathematical , and hence terminological basis , which allows us now to talk about spatial hypertexts in a uniform way . According to Sect . 2 . 1 , spatial hypertext languages are deﬁned as sets of spatial hypertext artifacts , which are ﬂat collections of spatial hypertext symbols . This forms our “syntactic view” on such languages . Semantics are deﬁned by interpreta - tions ( Sect . 2 . 2 ) . Interpretations are encodings of how spatial hypertext can be understood and thus form the semantic complement to spatial hypertext artifacts . Technically they are graphs of connected information objects . Spatial parsers are the linking element between spatial hypertext artifacts and interpretations . They take artifacts as input , analyse them according to pre - deﬁned heuristics and generate output in the form of interpretations . In a nutshell , spatial parsers map artifacts to interpretations ( Fig . 3 . 1 ) . Parser 1 1 . 0 1 . 0 0 . 5 1 2 3 (cid:1835) ∈  (cid:1835) 2 3 (cid:1834) ∈   (cid:1834) Figure 3 . 1 : spatial parsers map spatial hypertext artifacts H to interpretations I 37 Chapter 3 . Critical Review One of the major goals in spatial hypermedia research is to design and develop good spatial parsing services . That is , ﬁnding feasible ways for automatically retrieving hidden structure from human generated layouts . Such implicit struc - ture detection belongs to the most essential features of a spatial hypermedia system . One could even go further arguing that only spatial parsers transform visual information spaces into real spatial hypermedia systems . Without struc - ture recognition they would be nothing more than plain graphical editors with a database in the backend . Or to put it diﬀerently , only spatial parsing makes an image on the screen a spatial hypertext . But this is almost a philosophical issue which can be discussed controversially . We shall not go into any more detail on this . Regardless of the role spatial parsers play in setting spatial hypermedia systems apart from normal diagramming applications , we would like to ask the following question : What makes a good spatial parser ? The answer to this question is strongly linked to the meaning of “good” and hence on what a potential system user is likely to expect from a parsing service . “good” is a vague rating and can relate to many diﬀerent assessment criteria . That is why in the following we focus on two major aspects only : ( a ) eﬃciency and ( b ) eﬀectiveness . Usually spatial parsers are realized as software components . Therefore , aspects such as processing speed and resource consumption have , without any doubt , a great relevance to developing good parsers . In concrete terms , when design - ing and implementing a fully - functional spatial hypermedia system it must be ensured that resource allocation by parsers is kept to a minimum and user interaction with the visual medium is not interrupted or interfered by unneces - sarily long parser runs . To put it brieﬂy , a good spatial parser should operate eﬃciently . In this respect , spatial parsers do not diﬀer from other software components . But , eﬃciency alone does not automatically make a good parser in terms of good structure detection performance . More important than eﬃciency is the quality of parser output ( i . e . the accuracy of interpretations ) . The closer a spatial parser’s interpretation of a spatial hypertext comes to the real understanding of human users , the greater the parser’s accuracy . The more accurate a parser’s interpretations are the better the parsing algorithm and hence the stronger the parser’s performance . Ideally , spatial parsers extract only structure that was really intended by authors . In other words , a perfect spatial parser detects exactly what a human user intended to express by a certain arrangement of information objects . 38 Therefore , good spatial parsers do not only perform as resource - saving and as fast as possible , but also generate interpretations of high accuracy and hence results of high quality . Unfortunately both objectives , maximized eﬃciency and maximal eﬀectiveness are inherently diﬃcult to reconcile . Especially in computer science they are often seen as competing aims . This is why we focus on a single aspect only , namely parsing accuracy . This leads us to the following question : Is there a need for increased parsing accuracy ? To avoid misunderstandings , it shall be noted that in this thesis we consider only un – customized parsers and hence systems that do not need to be tailored for user preferences . Thus , Adaptive Spatial Parsing ( Sect . 1 . 5 . 2 ) is not our issue here . Does the state - of - the - art in ( non - adaptive ) spatial parsing call for improved algorithms that provide more accurate and hence better results ? In our opinion this questions can be answered with “Yes” , for the following reason : Traditional ( non - adaptive ) parsing strategies ( as described in Sect . 1 . 5 . 1 ) build on the assumption that a single spatial hypertext artifact is a suﬃcient source of information for retrieving implicitly encoded structure that was intended by authors . Or in other words , it is assumed that static “snapshots” of visual information spaces include suﬃcient information for inferring correct structural meaning . But this need not always be the case . Quite the contrary : single spatial hypertext artifacts rarely allow for clear inferences on what authors really intended to express . The reason for this is that drawing unambiguous conclusions only from spatial and visual properties would require that structural descriptions given in a spatial hypertext artifact are also clear and explicit . Although being possible , this still contradicts spatial hypertext’s ambiguous and implicit nature ( Sect . 1 . 2 ) . Typically , spatial hypertext rather leaves some room for interpretation . That is , spatial hypertext allows the viewer ( either human or machine ) leeway to interpret spatial and visual properties ( Sect . 2 . 2 ) . The only one who could resolve such ambiguities correctly is the creater of the respective visual lan - guage and hence the author of the hypertext ( Sect . 2 . 1 ) . In short , spatial hypertext is ambiguous and disambiguation requires knowledge which only au - thors can have . Conventional ( non - adaptive ) parsers , however , do not consider such knowledge in their analysis , which innately limits parsing accuracy . This conceptual restriction makes it diﬃcult to design good parsing algorithms . Thus , there is with no doubt a need for improvement ! 39 Chapter 3 . Critical Review 3 . 1 Ambiguous Structures As already highlighted in Sect . 1 . 2 , lack of clarity is inherently part of spatial hypertext . As a consequence , disambiguation plays an essential role in spa - tial parsing . Nevertheless , apart from only few exceptions , such as FLAPS ( Sect . 1 . 5 . 1 ) , the focus in designing spatial parsers has been put on aspects such as collaboration ( Sect . 1 . 5 . 3 ) , three - dimensionality ( Sect . 1 . 5 . 4 ) , or linear document authoring ( Sect . 1 . 5 . 5 ) rather than on resolving ambiguities . In other words , although being crucial for successful spatial parsing , the topic of disam - biguation has been rather neglected in most current implementations . For this reason it is worth delving a bit deeper into that subject : What does “ambiguous” mean in connection with spatial hypertext ? An “ambiguous” spatial hypertext has diﬀerent possible meanings . The mean - ing of a spatial hypertext as a whole is deﬁned by the meaning of individual in - formation units ( nodes ) , which depends on both node content and context [ 1 ] . Context again is deﬁned by ( implicit ) associations of information units with adjacent nodes within the hypertext [ 1 ] , which is determined by spatial and visual properties respectively . As discussed in Sect . 2 . 2 , information units and associations together form information structures and structures build inter - pretations . So , one could argue that interpretations are manifestations of the meaning of spatial hypertext . Thus , by calling a spatial hypertext “ambiguous” we are emphasizing that one could infer more than only one interpretation . Intended ( or constructive [ 3 , 9 ] ) ambiguity is given , when users deliberately ex - press unclear or fuzzy information structures and herewith allow for alternative interpretation . This means , authors are aware that there are multiple ways how a given hypertext could be understood . This constructive use of ( intended ) am - biguities to express vague structures is a core feature of spatial hypertext [ 3 , 9 ] . We discussed that already in Sect . 1 . 2 . In addition to such intended ambiguities , however , evolution of spatial hy - pertexts might also result in ambiguities that are unintended by authors [ 35 ] . Spatial hypertext’s implicit , informal and emergent nature ( Sect . 1 . 2 ) may lead to inconsistencies between intention and actual expression . So , it is for exam - ple possible , that edit operations applied to spatial objects may accidentally modify the context of related expressions , which then may become undesir - ably ambiguous [ 13 , 36 ] . Another example refers to the visual language used . It is not only the case that the spatial hypertext changes over time [ 9 ] , the users’ understanding of their task and herewith the spatial hypertext language may evolve as well [ 9 , 20 , 36 , 37 ] . As a consequence , expressions that could be clearly understood before a change of language , may become ambiguous after - wards since the meaning of those visual features used has changed [ 37 ] . This 40 3 . 1 . Ambiguous Structures 0 . 5 0 . 0 0 . 5 0 . 0 0 . 0 0 . 0 0 . 0 1 1 . 0  0 1 . 0 2 3 5 2 3 4 5 0 . 0 0 . 0 1 4 1  1 2 3 4 5 0 . 5 0 . 5 1 . 0 1 . 0 2 3 5 1 4 1 . 0 1 . 0 1 . 0 1 . 0 1 . 0 Figure 3 . 2 : example : list - structures formed by ambiguously aligned rectangles complicates interpretation of information or makes it practically impossible at all [ 36 , 37 ] . This is best explained with an example . Fig . 3 . 2 illustrates an ambiguous sample hypertext and its interpretation by a conventional spatial parser at two consecutive points in time ( k 0 and k 1 ) . Interpretations are represented here as graphs which are complete , undirected and weighted . Given weights assigned to edges ( i . e . , to associations ) between information units range from 0 . 0 to 1 . 0 and indicate the strength of a certain relationship ( in this case the strength of spatial dependencies ) . Thus , a weight of 0 . 0 would mean that two objects have no spatial relation , whereas a weight of 1 . 0 indicates an immediate dependency . For further details on interpretations see our previous deﬁnitions in Sect . 2 . 2 . In state k 0 ( top - left of Fig . 3 . 2 ) objects 1 , 2 and 3 in the middle of the infor - mation space apparently form a horizontal list ; thus they can be interpreted as structure elements . Rectangles 4 and 5 in the bottom - left and top - right corner , however , are located too far away from potential neighbors to have a spatial relation ; thus they do not contribute to any structure . A spatial parser can easily detect that , as can be seen in the bottom - left of Fig . 3 . 2 . 41 Chapter 3 . Critical Review When an author pushes now rectangle 4 and 5 closer together , in order to save space for example , then we get what is illustrated at k 1 . Suddenly the layout becomes ambiguous . Only by analysing the spatial layout it is not possible any - more to decide which rectangles form a discrete list and which objects do not . Consequently , the spatial parser’s interpretation becomes ambiguous either . This is why the interpretation graph in the bottom right of Fig . 3 . 2 comprizes a single , big information structure which includes all ﬁve information units . The list - structure formed by objects 1 , 2 and 3 , which could be recognized at state k 0 , is still part of this big structure , but , since all the delimiting zero - weightings have gone , it cannot be unambiguously identiﬁed anymore . The author of this sample hypertext , however , still might recognize that hor - izontal list as an independent structure . Perhaps the snapshot on the right was simply intended as a spatially compact ( i . e . , “compressed” ) version of the hypertext on the left and hence the author does not see any semantic diﬀerence between k 0 and k 1 . Possibly in the user’s mind the list formed by objects 1 , 2 and 3 still exists as a discrete unit . In the spatial parser’s interpretation , however , it does not . From this we can conclude that implicit information structures in spatial hyper - text are always a mixture of desired and undesirable structures . Thus , spatial hypertext includes both , intended and unintended ambiguities . We denote the degree of such ( intended and unintended ) ambiguousness as level - of - ambiguity . It can be measured as the number of possible alternative interpretations that can be derived from a spatial hypertext . It herewith de - termines how hard it is to come to a correct interpretation . The smaller that level is the easier it gets to infer the correct meaning and hence the better a spatial parser will perform . Consequently , if one intends to improve parsing performance that level must be decreased . This brings us back to the subject of “disambiguation” . A possible way to achieve that is suggested in [ 36 ] . According to [ 36 ] , ( un - wanted ) ambiguities can be eliminated by considering a spatial hypertext’s edit history ( called “navigable history” ) . In concrete terms , if we do not only look at a static image of our information space , but rather take into account its evolution as an additional source of information , disambiguation of visual structures may become possible . This is why in [ 36 ] it was suggested to use such a history to enhance spatial parsing . A possible implementaton , however , was not described . Thus , we can see an edit history as a means to reduce the level of ( unintended ) ambiguity in spatial hypertext and thus as a means to increase parsing accuracy . 42 3 . 2 . Destroyed Structures 1 2 3 4 1 . 0  0 1 . 0 1 . 0 0 . 5 0 . 5 0 . 25 1 2 3 4 1 2 4  1 1 . 0 0 . 0 0 . 0 1 2 4 Figure 3 . 3 : example : ( partly ) destroyed list - structure of diagonally aligned rectangles 3 . 2 Destroyed Structures Besides ambiguous structures ( Sect . 3 . 1 ) we can identify another structure cat - egory . So - called destroyed structures are information structures described spa - tially or visually , which used to exist in the past , but were partly or completely destroyed in the course of an editing process . Thus , all information structures which could be automatically detected at a given time in the past but are not ( fully ) visible anymore at present , due to changes made to spatial and visual attributes , fall in this category . A very simple example which illustrates the nature of such destroyed structures is given in Fig . 3 . 3 . Fig . 3 . 3 illustrates a diagonally aligned list of rectangular shaped information objects and its interpretation by a spatial parser at two diﬀerent points in discrete time ( k 0 and k 1 ) . At k 0 the interpretation of the given spatial hypertext comprizes a single information structure including all four information units . At k 1 however unit number 3 is missing which leads to a drop of the spatial dependency of units 1 , 2 with rectangle 4 to zero . Deleted object number 3 is not included at all . The recognized information structure includes only units 1 and 2 . However , what might be geometrically correct does not necessarily need to be valid from a human user’s perspective . Probably object number 3 was accidentally destroyed or the user simply forgot to move 2 and 4 closer together . Maybe from a user’s point of view units 1 , 2 and 4 still form a list . A conventional spatial parser , however , recognizes only a small fraction of that intended structure . A similar example that illustrates this issue can be found in [ 36 ] . 43 Chapter 3 . Critical Review 0 . 0 1 1 2 1 . 0 2 1 2 1 2  0  1 Figure 3 . 4 : example : ( completely ) destroyed object relation This becomes even more apparent in cases where information structures are completely destroyed . You only have to look at Fig . 3 . 4 . As in the previous ex - ample , also Fig . 3 . 4 illustrates two consecutive snapshots of a sample hypertext together with its interpretation by a spatial parser . Due to their spatial prox - imity at time point k 0 , both objects 1 and 2 are considered as being strongly related . That is , the parser “sees” a spatial relation with a strength of one - hundred percent . A single time step later , however , both objects 1 and 2 have moved too far away from each other to still have a spatial relation . Conse - quently , the parser does not just detect a weak connection , but he recognizes none at all . This does not necessarily need to be correct . Maybe the change from k 0 to k 1 happened accidentally ( possibly as a side eﬀect of another edit - ing operation ) , or the parser’s conﬁguration simply does not ﬁt the author’s understanding of proximity . Note , that we have absolutely no guarantee that heuristics used for spatial parsing are universally correct . So there are enough reasons why a conventional spatial parser erroneously detects nothing in k 1 . 3 . 3 Temporal Structures Both ambiguous ( Sect . 3 . 1 ) and destroyed structures ( Sect . 3 . 2 ) can not be de - tected properly by conventional spatial parsers , even though they are expressed spatially and visually . It is not surprising that structures formed by totally dif - ferent attributes than position , size , shape , color etc . can not be recognized either . This category includes ( pure ) temporal structures . The very simple example illustrated in Fig . 3 . 5 is characteristic of this type of structures . Fig . 3 . 5 shows two rectangular information units which are located too far away from each other to be regarded as spatially associated ( i . e . , the strength of spatial dependency would be 0 . 0 ) . Thus a spatial parser would not see any information structure . However there still might be an association between unit 1 and 2 , as , when you look back in edit history it could be 44 3 . 4 . Solution 0 . 0 2 1 2 1 1 . 0 1 alternatemodification 2 spatial temporal Figure 3 . 5 : example : ( pure ) temporal structure formed by alternate modiﬁcation of rect - angular information objects recognized that both objects were repeatedly modiﬁed in an alternate fashion . This operation pattern might indicate that there is an association between object 1 and 2 ; that is , both objects seem to be related somehow . Human users might have the same association in mind . This information , however , is not available to conventional spatial parsers , which limits their practical value . 3 . 4 Solution These issues may only be overcome by giving up the idea that spatial and visual attributes are suﬃcient for detecting intended structure . In addition to properties like position , size , shape etc . further sources of information need to be considered in spatial parser designs . We suggest that temporal aspects of spatial hypertext are the perfect choice for solving those problems discussed in the previous sections . A spatial parser which is “aware” of previous structures ( i . e . , information structures which used to exist but are not visible anymore ) and “knows” about temporal dependencies between information units could ( a ) ﬁlter out discrete structures most likely seen by human users ; ( b ) complete corrupted structures and ( c ) detect associa - tions that are purly temporal . We expect this to lead to a signiﬁcant increase in parsing accuracy , and hence higher parser performance . Although the idea of enhancing spatial parsing by temporal information was proposed already in [ 12 ] and [ 36 ] it has never been realized . Neither there is an algorithmic design for such a temporal extension nor was it implemented in prototypical form . It is therefore still unknown whether such a spatio - temporal parser would perform better than a conventional spatial parser . This thesis is intended to change that . 45 Chapter 3 . Critical Review 46 Chapter 4 Prototype Research results only applicable in a single application context are generally very limited , as conclusions cannot be applied to other contexts . This is why we tried to carry out our investigations as context - independent and therefore as implementation - independent as possible . To achieve that , we did not build our research algorithms on some speciﬁc spatial hypermedia application . This would have been too restrictive . Instead , our algorithm design was rather driven by a theoretical model of a universal spatial hypermedia system . In other words , in contrast to the usual practice in spatial hypermedia research we decided to come from theory to prototype , and not the other way round . We deﬁne “typical” spatial hypermedia systems as compositions of two sub - systems : ( a ) Editing System ( Sect . 4 . 1 ) and ( b ) Interpretation System ( Sect . 4 . 2 ) . In a nutshell , editing systems support creation of visual structure , whereas in - terpretation systems perform automatic structural analysis . Linked together they realise interactive structure creation loops . This represents the functional core of spatial hypermedia systems . Spatial Hypermedia System Interpretation System Editing System Figure 4 . 1 : Spatial hypermedia system deﬁned as composite of two interconnected sub - systems : Editing System ( Sect . 4 . 1 ) and Interpretation System ( Sect . 4 . 2 ) 47 Chapter 4 . Prototype 4 . 1 Editing System Spatial hypertext is not designed on a drawing board and thus is not con - structed following a predeﬁned blueprint . Instead , visual information structure emerges ( Sect . 1 . 2 ) . That is , users do not “engineer” formal information struc - ture , but rather interact with objects in a visual information space to gradually develop meaningful visual expression . This is rather a creative than a construc - tive process . Therefore special development tools are required . So - called editing systems provide users with interactive access to visual information spaces and herewith support the step - by - step creation of visual structure . Thus , from an application - oriented perspective , editing systems are tools for spatial hypertext development . They therefore form the basis for any spatial hypermedia system . In order to formally describe such systems it is crucial to understand how spatial hypertext evolves . If we can describe emerging spatial or visual expressions then we can also deﬁne how an editing system behaves . 4 . 1 . 1 Evolution of Spatial Hypertext As far as possible , we tried to keep the following deﬁnitions implementation - independent and avoided the use of an own formal notation . The only excep - tions to this are generic deﬁnitions , that is , the way we describe parameterised sets , functions or other mathematical objects . In concrete terms , when the deﬁnition of a mathematical object X depends on one or several other objects ( or parameters ) P 0 , P 1 , . . . , P n , then we formally express this as follows : X h P 0 , P 1 , . . . , P n i This notation was inspired by generic programming , hence the expression above looks quite similar to what you might know from source code templates . Note , that we used this notation already in Sect . 2 . 1 when we introduced spatial hypertext languages L SH ( for details see page 28 ) . So , a good example for this “template - like” notation would be . . . L SH h Σ SH , X SH i : = (cid:16) 2 Σ SH \ X SH (cid:17) . . . which is nothing else than a parameterized set (cid:0) 2 Σ SH \ X SH (cid:1) or rather a set of sets determined by two factors : Σ SH and X SH . This could also be applied to other mathematical objects , such as tuples , relations or functions . In fact this is exactly what we do in our following deﬁnitions . 48 4 . 1 . Editing System In order to keep mathematical expressions as compact as possible and there - fore to facilitate readability of our formal model several basic deﬁnitions are required . This includes the following deﬁnition of R s h Σ SH i : R s h Σ SH i : = n R (cid:12)(cid:12)(cid:12) R ⊆ (cid:0) Σ SH ∪ { ε } (cid:1) × (cid:0) Σ SH ∪ { ε } (cid:1)o = 2 ( Σ SH ∪ { ε } ) × ( Σ SH ∪ { ε } ) ( 4 . 1 ) According to Eq . 4 . 1 R s h Σ SH i is deﬁned as the parameterized set of all binary relations R ⊆ (cid:0) Σ SH ∪ { ε } (cid:1) × (cid:0) Σ SH ∪ { ε } (cid:1) and therefore depends on two factors : Σ SH und ε . Here , Σ SH represents any set of spatial hypertext symbols and thus any spatial hypertext “alphabet” ( see Eq . 2 . 4 in Sect . 2 . 1 ) . The second parameter ε is an empty symbol ( i . e . , a symbolic placeholder for “nothing” ) and is supposed to be no element of Σ SH . As an example , for a given symbol set Σ SH = { s 0 , s 1 , s 2 , s 3 } a valid relation R ∈ R s h Σ SH i might look as follows :    ( ε , s 0 ) , ( s 1 , s 2 ) , ( s 3 , ε )    ∈ R s h { s 0 , s 1 , s 2 , s 3 } i ( 4 . 2 ) Therefore , elements ( or instances ) of R s h Σ SH i are nothing more than sets of binary symbol tuples or rather mappings of symbols ( i . e . , elements on the left side are mapped to symbols on the right ) . We use such relations to describe substitutions or replacement operations . In the example given above ( in Eq . 4 . 2 ) we perform three substitutions at once : ε ( quasi “nothing” ) becomes s 0 , s 1 transforms into s 2 and s 3 changes to ε ( i . e . , s 3 is getting deleted ) . Thus , relation R describes a transformation of the symbol set Pre s ( R ) = { s 1 , s 3 } , which is deﬁned in Eq . 4 . 3 , into the target set Post s ( R ) = { s 0 , s 2 } , given by Eq . 4 . 4 . Pre s : R s h Σ SH i → 2 Σ SH , R 7→   [ ( s , s ′ ) ∈ R { s }   \ ε ( 4 . 3 ) Post s : R s h Σ SH i → 2 Σ SH , R 7→   [ ( s , s ′ ) ∈ R (cid:8) s ′ (cid:9)  \ ε ( 4 . 4 ) However , our goal here is not to describe general transformations on any symbol sets . Our aim is rather to deﬁne replacement operations on spatial hypertext 49 Chapter 4 . Prototype artifacts . After all we want to describe formally how spatial hypertext evolves . In concrete terms , we are looking for a universal description of how artifacts or “words” of any spatial hypertext language are generated . This requires to reﬁne or rather to constrain the previously deﬁned set R s h Σ SH i as follows : R H h Σ SH , X SH i =     R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) R ∈ R s h Σ SH i , R 6 = ∅ ∧   ∄ n(cid:0) a , a ′ (cid:1) , (cid:0) b , b ′ (cid:1)o ∈ (cid:18) R 2 (cid:19) : ( a , b 6 = ε ∧ a = b ) ∨ (cid:0) a ′ , b ′ 6 = ε ∧ a ′ = b ′ (cid:1)   ∧ Pre s ( R ) , Post s ( R ) ∈ 2 H , H ∈ L SH h Σ SH , X SH i     ( 4 . 5 ) Unlike R s h Σ SH i this deﬁnition of R H h Σ SH , X SH i does not only depend on the spatial hypertext “alphabet” Σ SH but also on X SH . In Sect . 2 . 1 we deﬁned X SH as an exclusion set on 2 Σ SH . According to Eq . 2 . 8 X SH forms together with Σ SH a spatial hypertext language L SH h Σ SH , X SH i . Thus , the deﬁnition of R H does not just depend on a spatial hypertext “alphabet” , but on a full spatial hypertext language . Our deﬁnition of R H h Σ SH , X SH i restricts R s h Σ SH i by three constraints : Firstly , R H h Σ SH , X SH i may not include the empty set . Empty relations R = ∅ include no mappings of symbols and hence describe no changes . Even though such “neutral” operations ( or rather transitions ) have their right to exist , we will deal with them separately in later sections . For our current deﬁnitions we rather assume that Hypertext - Relations ∈ R H h Σ SH , X SH i always contain at least one symbol tuple . Second and third constraint refer to tuple elements : There may be no unordered pair { ( a , a ′ ) , ( b , b ′ ) } of binary tuples ∈ R for which ( a , b 6 = ε ∧ a = b ) or ( a ′ , b ′ 6 = ε ∧ a ′ = b ′ ) . This means in plain language that symbols may occur only once , on the left as well as on the right side of relations R ∈ R H h Σ SH , X SH i . The exception to this are ε - entries . The reason for the last restriction lies in constraint number three : Pre s ( R ) as well as Post s ( R ) must be ( not necessarily proper ) subsets of a valid spatial hypertext artifact . With “valid” we mean , that the respective artifact has to be element of the spatial hypertext language formed by Σ SH and X SH , which is L SH h Σ SH , X SH i . Therefore Pre s ( R ) , Post s ( R ) ∈ 2 H with H ∈ L SH h Σ SH , X SH i . In conclusion , R H h Σ SH , X SH i represents the set of all ( theoretically ) possible replacement operations on spatial hypertext artifacts H ∈ L SH h Σ SH , X SH i . 50 4 . 1 . Editing System Regardless of how the underlying spatial hypertext language is deﬁned , we can always distinguish between three basic operations on spatial hypertext artifacts : Artifacts , which are nothing more than ﬂat collections of symbols , can be ( 1 ) extended by new symbols ( i . e . , they can “increase” in size ) ; ( 2 ) symbols can be removed from an artifact ( i . e . , they can “decrease” ) and ( 3 ) included symbols can be modiﬁed ( by “changing” their attribute values ) . These three classes of relations can be deﬁned as subsets of R H h Σ SH , X SH i : R increase h Σ SH , X SH i = ( R (cid:12)(cid:12)(cid:12) (cid:12)(cid:12) R ∈ R H h Σ SH , X SH i , ∀ (cid:0) s , s ′ (cid:1) ∈ R : s = ε ∧ s ′ 6 = ε ) R decrease h Σ SH , X SH i = ( R (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) R ∈ R H h Σ SH , X SH i , ∀ (cid:0) s , s ′ (cid:1) ∈ R : s 6 = ε ∧ s ′ = ε ) R change h Σ SH , X SH i = ( R (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) R ∈ R H h Σ SH , X SH i , ∀ (cid:0) s , s ′ (cid:1) ∈ R : (cid:0) s , s ′ 6 = ε (cid:1) ∧ (cid:0) s 6 = s ′ (cid:1) ) ( 4 . 6 ) If one understands now single hypertexts H ∈ L SH as states and elements e of R increase ∪ R decrease ∪ R change ( Eq . 4 . 6 ) as state transitions or rather as events , then we can eﬀectively use sequences of spatial hypertext artifacts and symbol relations for describing a spatial hypertext’s evolution . For this we use the following automaton : A H h Σ SH , X SH , M H i =     S H h Σ SH , X SH i , E H h Σ SH , X SH i , δ H h Σ SH , X SH i , H init , F H h M H i     , M H ⊆ L SH h Σ SH , X SH i ( 4 . 7 ) A H is a deterministic and ( potentially ) inﬁnite automaton , whose ﬁve compo - nents are deﬁned using three parameters : Σ SH , X SH and M H . Just like Eq . 4 . 5 and Eq . 4 . 6 , also the deﬁnition of this ( Hypertext ) Automaton A H depends on Σ SH , X SH and thus on the language L SH h Σ SH , X SH i . In addition , however , A H is also determined by a very special set of so - called “Mature” artifacts M H ⊆ L SH h Σ SH , X SH i . These artifacts are meant to be hy - pertexts that include already meaningful structure and therefore should have signiﬁcant information content . Thus , M H represents a subset of L SH h Σ SH , X SH i whose elements are more than just any steps in a development process . They rather should be understood as intermediate results with a signiﬁcant degree of consistency . 51 Chapter 4 . Prototype The exact deﬁnition of M H strongly depends on individual development context and development goals of hypertext authors . This is why , at this point , we cannot specify M H any further . States of A H are nothing more than “words” of a spatial hypertext language . For this reason , we set S H , which is the set of all possible states of A H , equal to the language L SH : S H h Σ SH , X SH i = L SH h Σ SH , X SH i ( 4 . 8 ) Following this deﬁnition , the automaton A H h Σ SH , X SH , M H i could ( theoreti - cally ) take up any H ∈ L SH h Σ SH , X SH i as machine state . Based on Eq . 4 . 6 we deﬁne the total set of input signals or rather events e as : E H h Σ SH , X SH i =       e (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) e ∈    R increase h Σ SH , X SH i ∪ R decrease h Σ SH , X SH i ∪ R change h Σ SH , X SH i       ( 4 . 9 ) Consequently , any addition , removal or modiﬁcation of symbols could trigger a state transition . How such events e ∈ E H h Σ SH , X SH i make the automaton A H “move” through S H h Σ SH , X SH i and thus through the language L SH h Σ SH , X SH i , is deﬁned by the following transition function δ H : δ H h Σ SH , X SH i : (cid:0) S H h Σ SH , X SH i × E H h Σ SH , X SH i (cid:1) ⇀ S H h Σ SH , X SH i , ( H , e ) 7→ (cid:16) Post s ( e ) ∪ (cid:0) H \ Pre s ( e ) (cid:1)(cid:17) ∈ S H h Σ SH , X SH i , Pre s ( e ) ⊆ H ∧ Post s ( e ) ∩ (cid:0) H \ Pre s ( e ) (cid:1) = ∅ ( 4 . 10 ) The transition function δ H h Σ SH , X SH i maps pairs of states and events ( H , e ) to successor states ∈ S H h Σ SH , X SH i by substituting Pre s ( e ) ⊆ H for Post s ( e ) . The resulting collections of symbols , or rather the resulting successor states , must be element of S H h Σ SH , X SH i and thus have to be valid artifacts of the un - derlying spatial hypertext language . Furthermore , the symbols to be replaced are expected to be part of H ( i . e . , Pre s ( e ) ⊆ H ) and , as a last requirement , Post s ( e ) may not contain symbols that are already included in ( H \ Pre s ( e ) ) , which is the immutable part of H . Function δ H is only deﬁned if all these conditions are met . The initial state of A H h Σ SH , X SH , M H i shall be equal to H ε : H init = H ε ∈ S H h Σ SH , X SH i ( 4 . 11 ) 52 4 . 1 . Editing System Spatial hypertexts do not fall simply from sky , but are always the result of a development process that has to start from somewhere ( typically from an empty information space ) . Our formal equivalent to “empty space” is the empy spatial hypertext artifact H ε ( i . e . , the empty set ; see Sect . 2 . 1 ) . Since H ε is el - ement of any spatial hypertext language , it is necessarily also ∈ S H h Σ SH , X SH i . Therefore the empty artifact may be used as initial state . The set of ﬁnal states or rather ﬁnal hypertexts F H shall be equal to the pre - viously mentioned set of mature hypertext artifacts M H : F H h M H i = M H ( 4 . 12 ) Consequently , each spatial hypertext artifact H ∈ M H represents a potential ﬁnal state of A H h Σ SH , X SH , M H i . Having deﬁned all ﬁve components of A H we can ﬁnally discuss its dynamics . Let B H h Σ SH , X SH , M H i be the behaviour of our automaton A H ; that is , the set of all valid sequences of input signals ( i . e . , events ) and their respective sequences of states ( i . e . , hypertexts ) the automaton would pass through . In addition , let B ′ H h Σ SH , X SH , M H i be a subset of B H h Σ SH , X SH , M H i reﬁning the behaviour of A H : B ′ H h Σ SH , X SH , M H i ⊆ B H h Σ SH , X SH , M H i ( 4 . 13 ) Each element of this subset B ′ H h Σ SH , X SH , M H i shall be a binary tuple of value sequences which we denote as ( E , H ) . E is a sequence of input signals or rather events e k ∈ E H h Σ SH , X SH i . For a given time horizon k e ∈ N + we deﬁne E as follows : E ( 0 . . . k e − 1 ) = (cid:0) e 0 , e 1 , . . . , e k e − 1 (cid:1) , e k ∈ E H h Σ SH , X SH i , k = 0 , 1 , . . . , k e − 1 ( 4 . 14 ) Driven by E ( 0 . . . k e − 1 ) the automaton A H passes through certain sequences of states . We denote these sequences as H ( 0 . . . k e ) and deﬁne them as : H ( 0 . . . k e ) = (cid:0) H 0 , H 1 , . . . , H k e (cid:1) , H 0 = H init H k + 1 = δ H h Σ SH , X SH i ( H k , e k ) , δ H h Σ SH , X SH i ( H k , e k ) ! , k = 0 , 1 , . . . , k e − 1 H k e ∈ F H h M H i ( 4 . 15 ) Therefore B ′ H h Σ SH , X SH , M H i describes how a spatial hypertext , encoded in L SH h Σ SH , X SH i , can evolve from H ε to a ( ﬁnal ) mature state ∈ M H . 53 Chapter 4 . Prototype As pointed out already , the exact deﬁnition of M H strongly depends on indi - vidual development context and development goals of hypertext authors . Con - sequently , if there is no such information available , which is the default case , then it is not possible to give a precise deﬁnition of M H . So we must assume that any spatial hypertext could be in a form which is , from an observer’s per - spective , consistent and therefore potentially ﬁnal . This is why in this general case A H may be in a ﬁnal state ∈ M H at any point in discrete time . This allows for the following simpliﬁcation : A H h Σ SH , X SH i : = A H h Σ SH , X SH , L SH h Σ SH , X SH ii ⇔    S H h Σ SH , X SH i , E H h Σ SH , X SH i , δ H h Σ SH , X SH i , H ε    ( 4 . 16 ) With this partial default - parameterization , if you want to call it that , we eﬀec - tively set F H equal to S H which is the underlying spatial hypertext language L SH h Σ SH , X SH i . This is almost like deﬁning A H without ﬁnal states F H . Based on this simpliﬁcation we can redeﬁne the behaviour B H of A H h Σ SH , X SH i as follows : B H h Σ SH , X SH i : = B H h Σ SH , X SH , L SH h Σ SH , X SH ii = B ′ H h Σ SH , X SH , L SH h Σ SH , X SH ii ( 4 . 17 ) 4 . 1 . 2 Editing Processes So far we considered only dynamics of artifacts or rather “words” in spatial hypertext languages . Thus , with our considerations from previous Sect . 4 . 1 . 1 we focused solely on language attributes . In concrete terms , we described formally how spatial and visual representations of implicit structure can evolve , starting from an empty visual word . However , in this section we are not simply interested in dynamics of language elements but rather in complete editing systems . The behaviour of such interactive visual information spaces is not only deter - mined by the underlying visual language . In addition to spatial and visual symbol properties there are further attributes which play an important role for editing spatial hypertext ( e . g . , unique object identiﬁers , content , usage statis - tics etc . ) . We summarize these attributes by the term “workspace meta data” . In this section we complement our previous deﬁnitions by such Meta data M . 54 4 . 1 . Editing System To this end , we extend the basic component Σ SH , as it was used already in our initial deﬁnition of R s h Σ SH i in Eq . 4 . 1 , to a binary cartesian product : Σ SH × M . Elements of Σ SH × M are binary tuples of spatial hypertext symbols ∈ Σ SH and additional meta data ∈ M . In the following we refer to such tuples as information units u : ∀ u ∈ ( Σ SH × M ) : u : = u . symbol , u . meta _ data ! ; u . symbol ∈ Σ SH , u . meta _ data ∈ M ( 4 . 18 ) The term “information unit” was introduced already in Sect . 2 . 2 , but in a diﬀerent context . Information units u ∈ ( Σ SH × M ) , as described here , are primarily used for spatial hypertext Representation . Information units , as we deﬁned them in Sect . 2 . 2 rather deal with its Interpretation . Therefore , the term “information unit” is used in connection with both , spatial parsing as well as editing systems . Having extended Σ SH to ( Σ SH × M ) we can reformulate the parameterized set of symbol relations R s h Σ SH i , as it was deﬁned in Eq . 4 . 1 , as follows : R u h Σ SH , M i = n R (cid:12)(cid:12) (cid:12) R ⊆ (cid:0) ( Σ SH × M ) ∪ { ε } (cid:1) × (cid:0) ( Σ SH × M ) ∪ { ε } (cid:1)o = 2 (cid:16) ( ( Σ SH × M ) ∪ { ε } ) × ( ( Σ SH × M ) ∪ { ε } ) (cid:17) ( 4 . 19 ) The basic structure of this relation set is the same as in Eq . 4 . 1 . The only diﬀerence is , that elements of binary tuples may now include both spatial and visual attributes as well as meta data . Analogous to this , both auxiliary functions Pre s and Post s , as deﬁned in Eq . 4 . 3 and Eq . 4 . 4 , can be adapted for use with information units u ∈ ( Σ SH × M ) . Following the naming convention from Eq . 4 . 19 we denote these functions with Pre u ( Eq . 4 . 20 ) and Post u ( Eq . 4 . 21 ) and deﬁne them as follows : Pre u : R u h Σ SH , M i → 2 ( Σ SH × M ) , R 7→   [ ( u , u ′ ) ∈ R { u }   \ ε ( 4 . 20 ) Post u : R u h Σ SH , M i → 2 ( Σ SH × M ) , R 7→   [ ( u , u ′ ) ∈ R (cid:8) u ′ (cid:9) \ ε ( 4 . 21 ) In contrast to what we did previously in Sect . 4 . 1 . 1 we are here not just dealing with collections of symbols s ∈ Σ SH , but rather with sets of information units u ∈ ( Σ SH × M ) . Consequently , our replacement operations cannot operate directly on spatial hypertext artifacts H ∈ L SH h Σ SH , X SH i . What we need 55 Chapter 4 . Prototype instead is an adequate abstraction of L SH h Σ SH , X SH i that we will refer to as U h Σ SH , X SH , M i : U h Σ SH , X SH , M i =   U (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) U ∈ 2 ( Σ SH × M ) , ∄ (cid:8) u , u ′ (cid:9) ∈ (cid:18) U 2 (cid:19) : u . symbol = u ′ . symbol ∧ (cid:16)S u ∈ U { u . symbol } (cid:17) ∈ L SH h Σ SH , X SH i   ( 4 . 22 ) Actually , U h Σ SH , X SH , M i is nothing more than the power set of ( Σ SH × M ) restricted by two constraints : Firstly , U ∈ U h Σ SH , X SH , M i may not include any pair of information units { u , u ′ } where u and u ′ share their symbol attribute ( i . e . , u . symbol = u ′ . symbol ) . This means , any combination of spatial and visual properties ( i . e . , each symbol ) may occur only once in U . The reason for this can be found in the second constraint of Eq . 4 . 22 . According to that , all symbols of U together must form a valid element of L SH h Σ SH , X SH i , that is a spatial hypertext artifact . Therefore , each U ∈ U h Σ SH , X SH , M i implicitly contains an artifact H ∈ L SH h Σ SH , X SH i . In a certain sense , one could say that U h Σ SH , X SH , M i represents a spatial hypertext language L SH h Σ SH , X SH i “enriched” by meta data . This also includes an empty element ; based on the model of H ε ∈ L SH h Σ SH , X SH i . For this we use the empty set of information units U ε : U ε : = ∅ ∈ U h Σ SH , X SH , M i ( 4 . 23 ) If one substitutes in Eq . 4 . 5 all components that are deﬁned on symbols , such as R s h Σ SH i , Pre s , Post s and L SH h Σ SH , X SH i , for R u h Σ SH , M i , Pre u , Post u , and U h Σ SH , X SH , M i , then we get the following set of relations : R U h Σ SH , X SH , M i =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12) (cid:12) R ∈ R u h Σ SH , M i , R 6 = ∅ ∧   ∄ n(cid:0) a , a ′ (cid:1) , (cid:0) b , b ′ (cid:1)o ∈ (cid:18) R 2 (cid:19) : ( a , b 6 = ε ∧ a = b ) ∨ (cid:0) a ′ , b ′ 6 = ε ∧ a ′ = b ′ (cid:1)   ∧ Pre u ( R ) , Post u ( R ) ∈ 2 U , U ∈ U h Σ SH , X SH , M i   ( 4 . 24 ) Just like R H h Σ SH , X SH i in Eq . 4 . 6 , also R U h Σ SH , X SH , M i can be further re - ﬁned by adding constraints . This way , we deﬁne three sub - classes of operations . 56 4 . 1 . Editing System Unlike speciﬁed in Eq . 4 . 6 these operations are now called create , delete and modify rather than increase , decrease or change : R create h Σ SH , X SH , M i = ( R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈ R U h Σ SH , X SH , M i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u = ε ∧ u ′ 6 = ε ) R delete h Σ SH , X SH , M i = ( R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈ R U h Σ SH , X SH , M i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u 6 = ε ∧ u ′ = ε ) R modify h Σ SH , X SH , M i = ( R (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) R ∈ R U h Σ SH , X SH , M i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : (cid:0) u , u ′ 6 = ε (cid:1) ∧ (cid:0) u 6 = u ′ (cid:1) ) ( 4 . 25 ) Again , U h Σ SH , X SH , M i , Pre u , Post u , as well as the relations from Eq . 4 . 25 can be used to deﬁne an automaton . Unlike A H ( Eq . 4 . 7 ) , however , that new automaton does not build on spatial hypertext artifacts H , but on sets of information units U . Consequently , we denote such information Unit Automata with A U : A U h Σ SH , X SH , M i =     S U h Σ SH , X SH , M i , E U h Σ SH , X SH , M i , δ U h Σ SH , X SH , M i , U init     ( 4 . 26 ) Here , the set of possible states of A U shall be equal to U h Σ SH , X SH , M i : S U h Σ SH , X SH , M i = U h Σ SH , X SH , M i ( 4 . 27 ) Similar to E H in Eq . 4 . 9 , the set of input signals or rather events E U is deﬁned as a union of relations : R create , R delete and R modify E U h Σ SH , X SH , M i =   e (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) e ∈   R create h Σ SH , X SH , M i ∪ R delete h Σ SH , X SH , M i ∪ R modify h Σ SH , X SH , M i     ( 4 . 28 ) Apparently , there are clear parallels to the previous deﬁnition of A H in Sect . 4 . 1 . 1 . This also applies to the state transition function δ . In concrete terms , δ H from Eq . 4 . 10 and the following deﬁnition of δ U ( Eq . 4 . 29 ) diﬀer only in their un - derlying sets of states and events . This is why the following partial mapping 57 Chapter 4 . Prototype looks very similar to what was previously deﬁned in Eq . 4 . 10 : δ U h Σ SH , X SH , M i : (cid:0) S U h Σ SH , X SH , M i × E U h Σ SH , X SH , M i (cid:1) ⇀ S U h Σ SH , X SH , M i , ( U , e ) 7→ (cid:16) Post u ( e ) ∪ (cid:0) U \ Pre u ( e ) (cid:1)(cid:17) ∈ S U h Σ SH , X SH , M i , Pre u ( e ) ⊆ U ∧ Post u ( e ) ∩ (cid:0) U \ Pre u ( e ) (cid:1) = ∅ ( 4 . 29 ) The fourth and last component of automaton A U is its initial state or rather its initial set of information units U init ( Eq . 4 . 30 ) . That initial state shall be equal to U ε from Eq . 4 . 23 . Final states are not deﬁned . With this we follow the simpliﬁcation from Eq . 4 . 16 . U init = U ε ∈ S U h Σ SH , X SH , M i ( 4 . 30 ) Finally , let B U h Σ SH , X SH , M i be the behaviour of A U h Σ SH , X SH , M i ; that is , the set of all ingoing sequences of events and their respective states ( or rather , collections of information units ) . Elements of B U h Σ SH , X SH , M i are binary tuples of event and state sequences denoted as ( E , U ) . For a given time horizon k e ∈ N + such E is deﬁne as : E ( 0 . . . k e − 1 ) = (cid:0) e 0 , e 1 , . . . , e k e − 1 (cid:1) , e k ∈ E U h Σ SH , X SH , M i , k = 0 , 1 , . . . , k e − 1 ( 4 . 31 ) The sequence of states A U passes through for such an input E ( 0 . . . k e − 1 ) is denoted as U ( 0 . . . k e ) and can be formally described as follows : U ( 0 . . . k e ) = (cid:0) U 0 , U 1 , . . . , U k e (cid:1) , U 0 = U init U k + 1 = δ U h Σ SH , X SH , M i ( U k , e k ) , δ U h Σ SH , X SH , M i ( U k , e k ) ! , k = 0 , 1 , . . . , k e − 1 ( 4 . 32 ) Each tuple ( E , U ) ∈ B U h Σ SH , X SH , M i that fulﬁlls both conditions , Eq . 4 . 31 and Eq . 4 . 32 , is called an Editing Process ! 58 4 . 1 . Editing System 4 . 1 . 3 Workspace Model Object attributes that can be found in every spatial hypermedia workspace and therefore also in any editing system are : ( 1 ) object keys ( i . e . , unique object identiﬁers ) and ( 2 ) node content ( i . e . , “payload” of information units ) . Certainly , there may be further attributes , such as author information , usage statistics etc . Those , however , do not necessarily need to be implemented in a system . As for keys and content , on the other hand , we can be certain that in some form they can be found in every visual information space . They may be realised in diﬀerent ways ( e . g . , as integers , texts etc . ) but they still share common semantics ; that is , in principle they serve the same purpose : Object keys are used for unique identiﬁcation of information units and therefore make it possible to associate or rather to link objects with each other . Node content , again , can be understood as “payload” of information units , that is , as what makes a simple object a carrier of information . Since there is no hypermedia system without nodes and links , both node content as well as keys are inevitably part of any real spatial hypermedia system . For this reason we decided to integrate both attributes into our theoretical model . To this end , we substitute the previously introduced meta data symbol M for the cartesian product of two new set - parameters : ( K × C ) . Here , K stands for Keys and C means Content . Therefore , that unary attribute u . meta _ data , which we deﬁned in Eq . 4 . 18 , changes into a binary tuple of key und content : ∀ u ∈ (cid:0) Σ SH × ( K × C ) (cid:1) : u : =   u . symbol , u . key , u . content !   ; u . symbol ∈ Σ SH , u . key ∈ K , u . content ∈ C ( 4 . 33 ) An appropriate derivative of U h Σ SH , X SH , M i , which accepts both set - parameters K and C instead of M , shall be deﬁned as follows : U h Σ SH , X SH , K , C i =   U (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) U ∈ U h Σ SH , X SH , ( K × C ) i , ∄ (cid:8) u , u ′ (cid:9) ∈ (cid:18) U 2 (cid:19) : u . key = u ′ . key   ( 4 . 34 ) This partial reﬁnement of the parameterized set U h Σ SH , X SH , M i ( Eq . 4 . 22 ) by M = ( K × C ) is combined with the constraint , that keys ∈ K have to be unique in each U ∈ U h Σ SH , X SH , ( K × C ) i . This means , each u ∈ U must be clearly identiﬁable by u . key . Thus , there may be no unordered pair { u , u ′ } in U for which u . key = u ′ . key . 59 Chapter 4 . Prototype R U is deﬁned similarly : R U h Σ SH , X SH , K , C i =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈ R U h Σ SH , X SH , ( K × C ) i , Pre u ( R ) , Post u ( R ) ∈ 2 U , U ∈ U h Σ SH , X SH , K , C i   ( 4 . 35 ) Also here we substitute M for ( K × C ) and hence we reﬁne the given superset of relations R U h Σ SH , X SH , M i to a subset R U h Σ SH , X SH , ( K × C ) i . Replace - ment operations R described this way may only be deﬁned on elements of U h Σ SH , X SH , K , C i . This is why our deﬁnition in Eq . 4 . 35 also includes the constraints Pre u ( R ) , Post u ( R ) ∈ 2 U and U ∈ U h Σ SH , X SH , K , C i . When we intersect now R U h Σ SH , X SH , K , C i with relation sets R create , R delete and R modify ( which were originally deﬁned in Eq . 4 . 25 ) , and when we substitute M for ( K × C ) again , then we can apply the previously known replacement operations for creation , modiﬁcation and deletion of information units also on elements of U h Σ SH , X SH , K , C i . For R create and R delete this would look as follows : R create h Σ SH , X SH , K , C i = R U h Σ SH , X SH , K , C i ∩ R create h Σ SH , X SH , ( K × C ) i R delete h Σ SH , X SH , K , C i = R U h Σ SH , X SH , K , C i ∩ R delete h Σ SH , X SH , ( K × C ) i ( 4 . 36 ) According to this , both R create as well as R delete are deﬁned as intersections of R U h Σ SH , X SH , K , C i with partially reﬁned relation sets from Eq . 4 . 25 . With this we eﬀectively describe Types of relations that combine properties of both R U h Σ SH , X SH , K , C i as well as of R create or R delete . This is a simple form of multiple inheritance . In a similar way we can describe modify - relations . Just like R create and R delete also R modify can be deﬁned by intersecting two sets of relations : in this case R U h Σ SH , X SH , K , C i and R modify h Σ SH , X SH , ( K × C ) i . Also R modify “inherits” properties from R U h Σ SH , X SH , K , C i and from its counterpart in Eq . 4 . 25 . Here we add the constraint , that information units may only be mapped to units with the same key . This means , for each binary tuple ( u , u ′ ) which is an element of a modify relation R ∈ R modify h Σ SH , X SH , K , C i we expect that u . key = u ′ . key . The purpose of this constraint is to ensure that information units keep their identity . Otherwise R modify would not describe modiﬁcations but rather im - plicit deletion and recreation . Semantically , this would not be what we intend to express with R modify . 60 4 . 1 . Editing System R modify h Σ SH , X SH , K , C i =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈   R U h Σ SH , X SH , K , C i ∩ R modify h Σ SH , X SH , ( K × C ) i   , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u . key = u ′ . key   ( 4 . 37 ) Relations included in R modify h Σ SH , X SH , K , C i describe changes of both sym - bols as well as content . It may be useful now to view both categories of replace - ment operations separately . This can be achieved by mapping both attributes u . content and u . symbol to identical values ( just as we did with u . key ) . More precisely , we extend our previous deﬁnition from Eq . 4 . 37 by constraints . . . ∀ ( u , u ′ ) ∈ R : u . content = u ′ . content or ∀ ( u , u ′ ) ∈ R : u . symbol = u ′ . symbol This reduces R modify to those relations , that either describe only modiﬁcations of symbols ( Eq . 4 . 38 ) or change of content ( Eq . 4 . 39 ) . R change _ symbol h Σ SH , X SH , K , C i =     R (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) R ∈ R modify h Σ SH , X SH , K , C i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u . content = u ′ . content     ( 4 . 38 ) R change _ content h Σ SH , X SH , K , C i =     R (cid:12) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) (cid:12) R ∈ R modify h Σ SH , X SH , K , C i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u . symbol = u ′ . symbol     ( 4 . 39 ) No matter if element of R H h Σ SH , X SH i ( Eq . 4 . 5 ) , R U h Σ SH , X SH , M i ( Eq . 4 . 24 ) or now of R U h Σ SH , X SH , K , C i , relations always had to contain at least one binary tuple ( i . e . , R 6 = ∅ ) . Replacement operations , that replace nothing were not allowed . We intend to change that with the following deﬁnition of R ε : R ε = ∅ ( 4 . 40 ) R ε is an empty set of binary tuples and thus an empty binary relation . Empty relations describe no changes and therefore can be used as “neutral” transitions in a dynamic system , that is , as switching operations that do not change the current system state . This is exactly what R ε is used for in the following automaton . As we could see already in previous sections , we can use deﬁnitions of sets , such as Eq . 4 . 22 , and relations , like in Eq . 4 . 24 , to create system models in 61 Chapter 4 . Prototype form of deterministic automata . Since Eq . 4 . 34 builds on Eq . 4 . 22 and Eq . 4 . 35 is based on Eq . 4 . 24 we can do that also for the ( K × C ) - extension from this section . We denote such automata that build on workspace meta data K and C as Workspace Automata A W : A W h Σ SH , X SH , K , C , E symbol i =     S W h Σ SH , X SH , K , C i , E W h Σ SH , X SH , K , C , E symbol i , O W h Σ SH , X SH , K , C i , T W h Σ SH , X SH , K , C , E symbol i , G W h Σ SH , X SH , K , C , E symbol i , s init     ( 4 . 41 ) Unlike A H ( Eq . 4 . 7 ) and A U ( Eq . 4 . 26 ) the workspace automaton A W is not only determined by Σ SH , X SH or by an abstract set of meta data M . Instead the given list of parameters in Eq . 4 . 41 comprises , in addition to Σ SH and X SH , also K , C and E symbol . Here , parameters K and C replace the abstract meta data symbol M ( just like in Eq . 4 . 34 or in Eq . 4 . 35 ) . E symbol , on the other hand , is a symbolic placeholder for a set of symbol events and therefore has to be subset of R change _ symbol h Σ SH , X SH , K , C i ( Eq . 4 . 38 ) : E symbol ⊂ R change _ symbol h Σ SH , X SH , K , C i ( 4 . 42 ) This extended parameter list allows us to determine which operations , in ad - dition to construction and destruction , are allowed on symbols included in information units . This makes it easy to adapt the behaviour of A W to con - crete spatial hypertext languages . You only need to deﬁne appropriate deriva - tives of R change _ symbol . This means , you only have to extend the deﬁnition of R change _ symbol with constraints that describe exactly how symbol attributes may change in certain language ( s ) . Examples for this will be presented later on in Sect . 4 . 1 . 4 . Workspace automata A W may be in the following states S W : S W h Σ SH , X SH , K , C i =   s : = ( U , V ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ( U , V ) ∈ (cid:0) U h Σ SH , X SH , K , C i × 2 K (cid:1) , (cid:16)S u ∈ U { u . key } (cid:17) ⊆ V   ( 4 . 43 ) Unlike S H in Eq . 4 . 8 and S U in Eq . 4 . 27 states s ∈ S W are not simply deﬁned as sets of spatial hypertext symbols H ∈ L SH h Σ SH , X SH i or as sets of information units U ∈ U h Σ SH , X SH , M i . We rather deﬁne them as binary tuples ( U , V ) , with U ∈ U h Σ SH , X SH , K , C i and V ∈ 2 K . Here , U represents , as before , a set of information units u ∈ ( Σ SH × ( K × C ) ) . Keys ∈ K uniquely identify these objects and are collected in V . More precisely , the key set V contains all identiﬁers , that were assigned to information units until state s = ( U , V ) and therefore cannot be used for labelling of new objects . This also includes 62 4 . 1 . Editing System keys of information units that used to exist in the past but are no element of U anymore at present state s = ( U , V ) . This also explains the second constraint in Eq . 4 . 43 : ( S u ∈ U { u . key } ) ⊆ V . According to this , all u . key of current u ∈ U must be included in V ( i . e . , they must be marked as “in use” ) . However , the constraint also says that not necessarily all keys ∈ V must also be assigned to objects in U ; thus V may also include “deprecated” keys . This allows us to keep track of assigned and unassigned object identiﬁers and therefore helps to ensure that new objects always get a key that is not in use already . This is an aspect of editing spatial hypertext that was not considered in previous Sect . 4 . 1 . 1 and Sect . 4 . 1 . 2 . The initial state s init of our workspace automaton shall be equal to ( U ε , ∅ ) : s init = (cid:0) U ε , ∅ (cid:1) ∈ S W h Σ SH , X SH , K , C i ( 4 . 44 ) Thus , the starting point of any sequence of state transitions in A W is always a binary tuple of two components : an empty set of information units U ε ( Eq . 4 . 23 ) and consequently also an empty set of keys ∅ ⊂ K . Without objects there are also no identiﬁers . Similar to E H in Eq . 4 . 9 and E U in Eq . 4 . 28 the set of workspace events E W is deﬁned as a union of replacement operations : E W h Σ SH , X SH , K , C , E symbol i =     e (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) e ∈       R create h Σ SH , X SH , K , C i ∪ R delete h Σ SH , X SH , K , C i ∪ R change _ content h Σ SH , X SH , K , C i ∪ { R ε } ∪ E symbol          ( 4 . 45 ) The essential diﬀerence to E H and E U is that E W includes , in addition to the already known relations such as R create or R delete , the empty relation or rather the empty event R ε from Eq . 4 . 40 as well as the previously mentioned parameter E symbol ( Eq . 4 . 42 ) . Note , that E symbol was deﬁned as an exchangeable set of symbol events ∈ R change _ symbol h Σ SH , X SH , K , C i . Like δ H and δ U also A W ’s transition function maps binary tuples of states and events to successor states . Note , however , that unlike Eq . 4 . 10 and Eq . 4 . 29 , this transition function is not denoted with δ . We use the name T W instead : T W h Σ SH , X SH , K , C , E symbol i : S W h Σ SH , X SH , K , C i × E W h Σ SH , X SH , K , C , E symbol i ! ⇀ S W h Σ SH , X SH , K , C i ( 4 . 46 ) 63 Chapter 4 . Prototype This partial mapping is deﬁned as follows : (cid:0) ( U , V ) , e (cid:1) 7→ (cid:0) U ′ , V ′ (cid:1) , U ′ = (cid:16) Post u ( e ) ∪ (cid:0) U \ Pre u ( e ) (cid:1)(cid:17) ∈ U h Σ SH , X SH , K , C i V ′ =   V ∪   [ u ∈ Post u ( e ) { u . key }   , if e ∈ R create h Σ SH , X SH , K , C i V , else where : (cid:0) Pre u ( e ) ⊆ U (cid:1) ∧ (cid:16) Post u ( e ) ∩ (cid:0) U \ Pre u ( e ) (cid:1) = ∅ (cid:17) and if e ∈ R create h Σ SH , X SH , K , C i then ∄ u ∈ Post u ( e ) : u . key ∈ V ( 4 . 47 ) Driven by workspace events e ∈ E W , T W maps tuples ( U , V ) ∈ S W to ordered pairs ( U ′ , V ′ ) ∈ S W . For mapping U to U ′ , we replace in U subset Pre u ( e ) by Post u ( e ) which eﬀectively creates a new element of U h Σ SH , X SH , K , C i : U ′ = (cid:16) Post u ( e ) ∪ (cid:0) U \ Pre u ( e ) (cid:1)(cid:17) ∈ U h Σ SH , X SH , K , C i ( 4 . 48 ) V ′ is deﬁned by cases : V ′ =     V ∪   [ u ∈ Post u ( e ) { u . key }   , if e ∈ R create h Σ SH , X SH , K , C i V , else ( 4 . 49 ) If e is a construction event ( i . e . , e ∈ R create h Σ SH , X SH , K , C i ; see Eq . 4 . 36 ) then it shall be presumed that no u ∈ Post u ( e ) has already been recorded in V . Or , to express it diﬀerently : ∄ u ∈ Post u ( e ) : u . key ∈ V . In this case V needs to be expanded . Otherwise , if e / ∈ R create h Σ SH , X SH , K , C i then V remains unchanged . In this case we set V ′ = V . What mainly diﬀerentiates A W from A H and A U is its ability to generate output . This means , our workspace automaton A W does not only react on ingoing editing events with ( hidden ) state transitions but it also generates signals that can be detected from the outside . In concrete terms , A W notiﬁes its observers of every single state change . This is why that six - tuple given in Eq . 4 . 41 includes , in addition to already known components , such as sets of states and events etc . , two other objects : G W and O W . G W deﬁnes how A W Generates output signals . O W shall be the basic set of that Output . 64 4 . 1 . Editing System The generating ( or rather output ) function G W accepts tuples of states and events ( s , e ) ∈ ( S W × E W ) and provides the value calculated by T W ( s , e ) as output ∈ O W : G W h Σ SH , X SH , K , C , E symbol i : S W h Σ SH , X SH , K , C i × E W h Σ SH , X SH , K , C , E symbol i ! ⇀ O W h Σ SH , X SH , K , C i , ( s , e ) 7→ T W h Σ SH , X SH , K , C , E symbol i ( s , e ) ( 4 . 50 ) According to this , G W calculates and returns the successor state to s without changing its value . It therefore makes sense to set output signals O W equal to states S W . Each machine state of A W is also a potential output signal : O W h Σ SH , X SH , K , C i = S W h Σ SH , X SH , K , C i ( 4 . 51 ) Similar to Eq . 4 . 14 and Eq . 4 . 31 also the input of A W shall be deﬁned as tuples of input signals ( or rather events ) e ∈ E W : E ( 0 . . . k e ) = (cid:0) e 0 , e 1 , . . . , e k e (cid:1) , e k ∈ E W h Σ SH , X SH , K , C , E symbol i , k = 0 , 1 , . . . , k e ( 4 . 52 ) As pointed out already , there are two ways how workspace automata A W react on such sequences of events E ( 0 . . . k e ) : Firstly , they pass through a hidden sequence of states S ( 0 . . . k e + 1 ) ; see Eq . 4 . 53 . In this respect the deﬁnition of A W is not diﬀerent from A H ( Eq . 4 . 15 ) or A U ( Eq . 4 . 32 ) . S ( 0 . . . k e + 1 ) = (cid:0) s 0 , s 1 , . . . , s k e + 1 (cid:1) , s 0 = s init s k + 1 = T W h Σ SH , X SH , K , C , E symbol i ( s k , e k ) , T W h Σ SH , X SH , K , C , E symbol i ( s k , e k ) ! , k = 0 , 1 , . . . , k e ( 4 . 53 ) Secondly , workspace automata A W also provide these hidden states as output and thus notify their system environment ( i . e . , their external observers ) of internal state changes . This is why we denote such sequential Workspace - output as W ( 0 . . . k e ) : W ( 0 . . . k e ) = (cid:0) W 0 , W 1 , . . . , W k e (cid:1) , W k = G W h Σ SH , X SH , K , C , E symbol i ( s k , e k ) , G W h Σ SH , X SH , K , C , E symbol i ( s k , e k ) ! , k = 0 , 1 , . . . , k e ( 4 . 54 ) 65 Chapter 4 . Prototype Workspace     + 1           Figure 4 . 2 : Abstract blockdiagram of a dynamic workspace system , deﬁned as workspace automaton A W . Functions T W and G W are illustrated as system blocks . The given pair of vertical lines at the bottom represents a memory component . In a nutshell , workspace automata A W transform ingoing sequences of edit events E ( 0 . . . k e ) into outgoing sequences of workspaces W ( 0 . . . k e ) : Workspace  0 …      0 …   A more detailed illustration of such workspace systems , which includes both automata functions T W ( Eq . 4 . 46 ) , G W ( Eq . 4 . 50 ) as well as a state memory can be found in Fig . 4 . 2 . Such workspace models A W form the basis for our deﬁnition of editing systems : According to Fig . 4 . 3 , editing systems extend workspaces by viewer and con - troller components and hence build on the MVC - pattern . Thus we can easily summarize an editing system’s behaviour as follows : Viewing components re - ceive sequences of user interface activities , such as pressing left mouse button , moving the mouse and releasing the button again , and pass them on to a controlling module . The controller accepts those sequences of activities and translates them into adequate commands ( or editing events e k ∈ E W ) . These events are then forwarded as input signals to a workspace model A W . That model switches to a new state , as described in Eq . 4 . 53 or Eq . 4 . 47 respectively , and ﬁnally publishes the updated status W k to its observers ; that is view and controller . Thus , one could understand editing systems as visual dynamic sys - tems that are driven by user activities . For easier legibility we deﬁne : ∀ W ∈ O W h Σ SH , X SH , K , C i : W : = W . info _ units , W . keys _ in _ use ! ; W . info _ units ∈ U h Σ SH , X SH , K , C i , W . keys _ in _ use ∈ 2 K ( 4 . 55 ) 66 4 . 1 . Editing System Editing System view Workspace controller     + 1       Model           Figure 4 . 3 : Editing system illustrated as a composite of workspace model A W ( Eq . 4 . 41 ) , view and controller component 4 . 1 . 4 Specialization In the last section we deﬁned both workspaces and editing systems for any spatial hypertext language L SH h Σ SH , X SH i . We neither speciﬁed concrete spa - tial hypertext symbols Σ SH nor was any speciﬁc exclusion set X SH deﬁned . Consequently , our system model above ( Fig . 4 . 3 ) leaves it open which spatial and visual attributes to use for developing spatial hypertext . We also limited deﬁnitions for unique object identiﬁcation and for content handling to what is strictly necessary ( see Eq . 4 . 33 , Eq . 4 . 39 , or Eq . 4 . 47 ) . This makes our system model highly adaptable to a variety of practical implementations , including our research prototype . For our test implementation we have chosen the following visual language L # SH : L # SH = (cid:16) Σ # ∗ SH \ X # SH (cid:17) Σ # ∗ SH = n H (cid:12)(cid:12)(cid:12) H ⊆ Σ # SH o = 2 Σ # SH Σ # SH = (cid:0) A position × A size × A orientation × A shape × A color (cid:1) X # SH = ∅ ⇒ L # SH = (cid:16) 2 Σ # SH \ ∅ (cid:17) = 2 Σ # SH = 2 ( A position × A size × A orientation × A shape × A color ) ( 4 . 56 ) Here we follow our previous deﬁnitions from Eq . 2 . 7 in Sect . 2 . 1 . 67 Chapter 4 . Prototype Eq . 4 . 56 includes ﬁve basic attribute types : position , size and orientation of objects as well as their shape and color . Further attributes , such as surface texture , line style etc . , would have been too speciﬁc and would unnecessar - ily complicate the following deﬁnitions . For the same reason we deﬁned no constraints on L # SH , that is , exclusion set X # SH was set to ∅ . The above mentioned attribute types are deﬁned as follows : A position = (cid:8) ( x , y , z ) (cid:12)(cid:12) x , y ∈ Z , z ∈ N 0 (cid:9) A size = n ( w , h ) (cid:12) (cid:12)(cid:12) w , h ∈ N + o A orientation = { AXIS _ ALIGNED } A shape = { RECTANGLE , ELLIPSE } A color = (cid:8) ( r , g , b ) (cid:12) (cid:12) r , b , g ∈ { 0 , 1 , . . . , 255 } (cid:9) ( 4 . 57 ) A position is deﬁned as a set of 2 - or rather 2 . 5 - dimensional vectors . Here , x , y are position coordinates in a two - dimensional ( discrete ) grid Z × Z . The depth coordinate z ≥ 0 indicates an object layer . Thus , z = 0 identiﬁes the bottom - level in an information space . The given size - attribute is deﬁned as proportions ( w , h ) , where both width w as well as height h may only take values > 0 . This is intended to guarantee that objects in an information space always have a ( positive ) spatial extent . For the sake of simplicity we do not support object rotation , hence objects shall be axis - aligned . For this reason , A orientation comprises of only a single element , that is the symbolic placeholder AXIS _ ALIGNED . In A shape we distinguish between rectangular and ellipsoidal shapes , represented by two discrete ﬂags RECTANGLE and ELLIPSE . Although further shapes could be speciﬁed they are not necessarily required for our prototypical system . Finally , elements of A color are deﬁned as rgb colors , that is , as triples ( r , g , b ) of integral values ∈ { 0 , 1 , . . . , 255 } . Further attributes are not used . From these sets of attribute values we can form 5 - tuples or rather symbols s ∈ Σ # SH ( Eq . 4 . 56 ) whose elements shall be denoted as follows : ∀ s ∈ Σ # SH : s : =     s . position , s . size , s . orientation , s . shape , s . color     ; s . position ∈ A position , s . size ∈ A size , s . orientation ∈ A orientation , s . shape ∈ A shape , s . color ∈ A color ( 4 . 58 ) 68 4 . 1 . Editing System Now that both is known , symbol properties as well as their value ranges , we can specify operations on symbols . This means , now we can deﬁne R change _ symbol - relations , that describe how attributes from Eq . 4 . 58 may change . This requires , in a ﬁrst step , that we reﬁne R change _ symbol h Σ SH , X SH , K , C i from Eq . 4 . 38 to a fully speciﬁed R change _ symbol h Σ # SH , ∅ , N 0 , String i . Σ SH = Σ # SH and X SH = ∅ or rather X SH = X # SH are integral components of L # SH and were already deﬁned in Eq . 4 . 56 . With K = N 0 we restrict the set of valid object keys ∈ K to integers ≥ 0 and thus set the type of u . key to “unsigned int” , so to speak . Theoretically , one could use any set of uniquely identiﬁable objects as key type K . String should be a set of character strings . The underlying character encoding ( e . g . , ASCII , UTF - 8 etc . ) is of no importance to us . Thus , with C = String we limit our model to string - based content ( i . e . text ) . Therefore , we deal with hyper - text in the classical sense of the term . However , our model is not limited to that . Just like K also C may be chosen arbitrarily . The most fundamental editing operations on objects in a 2 . 5 - dimensional space include translation ( i . e . , change of position ) , scaling ( i . e . , change of size or proportions ) and shifting objects to diﬀerent layers . These three categories of edit operations ( or rather events ) can be deﬁned as derivatives of R change _ symbol h Σ # SH , ∅ , N 0 , String i : E translate =     R (cid:12)(cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈ R change _ symbol h Σ # SH , ∅ , N 0 , String i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u ′ . symbol = translate ( u . symbol , ~ v t ) , ~ v t ∈ ( Z × Z )     E scale =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) R ∈ R change _ symbol h Σ # SH , ∅ , N 0 , String i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u ′ . symbol = scale ( u . symbol , ~ v s ) , ~ v s ∈ (cid:0) R + × R + (cid:1)   E shift _ layer =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12) (cid:12) R ∈ R change _ symbol h Σ # SH , ∅ , N 0 , String i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u ′ . symbol = shift _ layer ( u . symbol , ∆ z ) , ∆ z ∈ Z   ( 4 . 59 ) These relation sets include three core mappings that specify how symbols may change : translate ( Eq . 4 . 60 ) , scale ( Eq . 4 . 61 ) and shift _ layer ( Eq . 4 . 62 ) . For reasons of clarity , we decided to deﬁne them separately . 69 Chapter 4 . Prototype translate ( Eq . 4 . 60 ) is a total mapping of binary tuples of symbols s ∈ Σ # SH and translation vectors ( a , b ) ∈ ( Z × Z ) to symbols s ′ ∈ Σ # SH with altered position coordinates s . position . x + a and s . position . y + b . Depth - coordinate z as well as remaining attributes do not change their values . translate : (cid:16) Σ # SH × ( Z × Z ) (cid:17) → Σ # SH ,            ( x , y , z ) , size , orientation , shape , color      , ( a , b )      7→        ( x + a , y + b , z ) , size , orientation , shape , color       ( 4 . 60 ) Scaling of objects ( Eq . 4 . 61 ) is deﬁned similarly . Also here we map pairs of sym - bols and vectors to geometrically modiﬁed symbols . The only diﬀerence is that scaling vectors are used instead of translation vectors and object dimensions are modiﬁed instead of positions . scale : (cid:18) Σ # SH × (cid:16) R + × R + (cid:17)(cid:19) → Σ # SH ,              position , ( w , h ) , orientation , shape , color       , ( a , b )       7→      position , (cid:0) round ( w × a ) , round ( h × b ) (cid:1) , orientation , shape , color      , round : R + → N + , ∀ x ∈ R + : round ( x ) = ( 1 , if x < 0 . 5 ⌊ x + 0 . 5 ⌋ , else ( 4 . 61 ) Modiﬁcation of depth coordinates ( i . e . , layers ) is deﬁned by shift _ layer : shift _ layer : (cid:16) Σ # SH × Z (cid:17) → Σ # SH ,     ( x , y , z ) , size , orientation , shape , color   , ∆ z   7→   (cid:0) x , y , shift _ depth _ val ( z , ∆ z ) (cid:1) , size , orientation , shape , color   , shift _ depth _ val : ( N 0 × Z ) → N 0 , ∀ ( z , ∆ z ) ∈ ( N 0 × Z ) : shift _ depth _ val ( z , ∆ z ) = ( 0 , if ( z + ∆ z ) < 0 z + ∆ z , else ( 4 . 62 ) 70 4 . 1 . Editing System E translate , E scale and E shift _ layer are not the only editing events that can be deﬁned on symbol properties from Eq . 4 . 58 . In addition we can also reﬁne R change _ symbol h Σ # SH , ∅ , N 0 , String i to modiﬁcations of s . shape ( Eq . 4 . 63 ) and s . color ( Eq . 4 . 64 ) . Attribute s . orientation , however , cannot change its value , since | A orientation | = 1 ( see Eq . 4 . 57 ) . E shape _ changed =   R (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12) R ∈ R change _ symbol h Σ # SH , ∅ , N 0 , String i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u . symbol . shape 6 = u ′ . symbol . shape   ( 4 . 63 ) E color _ changed =    R (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) R ∈ R change _ symbol h Σ # SH , ∅ , N 0 , String i , ∀ (cid:0) u , u ′ (cid:1) ∈ R : u . symbol . color 6 = u ′ . symbol . color    ( 4 . 64 ) All these edit events shall be combined under the common label E symbol _ changed : E symbol _ changed = E translate ∪ E scale ∪ E shift _ layer ∪ E shape _ changed ∪ E color _ changed ( 4 . 65 ) We use E symbol = E symbol _ changed together with the previously deﬁned param - eters Σ SH = Σ # SH , X SH = X # SH = ∅ , K = N 0 and C = String as default - settings or rather as default - conﬁguration of A W h Σ SH , X SH , K , C , E symbol i ( Eq . 4 . 41 ) , E W h Σ SH , X SH , K , C , E symbol i ( Eq . 4 . 45 ) and O W h Σ SH , X SH , K , C i ( Eq . 4 . 51 ) : A W : = A W h Σ # SH , ∅ , N 0 , String , E symbol _ changed i E W : = E W h Σ # SH , ∅ , N 0 , String , E symbol _ changed i O W : = O W h Σ # SH , ∅ , N 0 , String i ( 4 . 66 ) The last three types of symbol events we would like to introduce are , events for construction and destruction of information units ( Eq . 4 . 67 ) , events for modiﬁcation of content ( Eq . 4 . 68 ) and “neutral” or empty events ( Eq . 4 . 69 ) . Events for creation and deletion of information units shall be denoted as E create and E delete and are given by : E create : = R create h Σ # SH , ∅ , N 0 , String i E delete : = R delete h Σ # SH , ∅ , N 0 , String i ( 4 . 67 ) Change of content is deﬁned similarly : E content _ changed : = R change _ content h Σ # SH , ∅ , N 0 , String i ( 4 . 68 ) 71 Chapter 4 . Prototype Spatial Hypermedia System Interpretation System Editing System Figure 4 . 4 : Only interpretation systems make an editing system a fully - ﬂedged spatial hypermedia system The last category of events to be deﬁned in this section are empty events E ε : E ε : = { R ε } ( 4 . 69 ) E ε includes only a single element , which is the empty relation R ε from Eq . 4 . 40 . Our deﬁnition of E W from Eq . 4 . 66 implicitly includes these event categories : E W = E create ∪ E delete ∪ E symbol _ changed ∪ E content _ changed ∪ E ε ( 4 . 70 ) This will play an important role in Sect . 4 . 3 . 4 . 2 Interpretation System The second integral component of spatial hypermedia systems , besides the previously described editing systems , are interpretation systems ( see Fig . 4 . 4 ) . Editing systems serve the creation of spatial hypertext , whereas interpretation systems analyze spatial hypertext to infer visual structure ( for this see our considerations on “spatial parsing” in Sect . 1 . 3 ) . Without that capability of recognizing structural meaning such systems would be nothing more than just diagramming applications without signiﬁcant intelligence . Only interpretation systems turn an editing system into what we regard as a fully - ﬂedged spatial hypermedia system . Interpretation systems transform ingoing sequences of events e k ( Sect . 4 . 2 . 1 ) and info unit Data D k ( Sect . 4 . 2 . 2 ) into outgoing sequences of Interpretations I k ( Sect . 4 . 2 . 3 ) . Fig . 4 . 5 illustrates that as a block diagram . Note , however , that events e k are not to be confused with our deﬁnitions from Eq . 4 . 66 or Eq . 4 . 45 . 72 4 . 2 . Interpretation System Interpretation System       Figure 4 . 5 : Interpretation systems transform ingoing sequences of events e k and info unit data D k into outgoing sequences of interpretations I k 4 . 2 . 1 Events Provided that Ω is the universal set of all theoretically possible information units ( see Sect . 2 . 2 ) , we deﬁne the basic set of ingoing Events E h Ω i as : E h Ω i =       (cid:16) 2 Ω \ ∅ (cid:17) ×    CREATE , MODIFY _ SPATIAL , MODIFY _ VISUAL , MODIFY _ CONTENT , DELETE         ∪ n(cid:0) ∅ , ε (cid:1)o ( 4 . 71 ) Each of these events e ∈ E h Ω i is a binary tuple ( e . objects , e . operation ) : ∀ e ∈ E h Ω i : e : = e . objects , e . operation ! ( 4 . 72 ) Here , e . objects represents a set of information units ⊆ Ω or rather their ids . This set identiﬁes all objects , which are aﬀected by the speciﬁed event e . The second tuple element e . operation is a discrete operation ﬂag which serves event classiﬁcation . Thus , elements of E h Ω i include both , a set of objects for which an event has occurred and an identiﬁer of the event or operation type . This is best explained with some examples : Suppose we deﬁne Ω = { 0 , 1 , 2 } . Thus , the basic set of information units comprises only three possible objects . For the sake of simplicity we numbered them consecutively starting with zero . Now we shall be able , following our deﬁnition from Eq . 4 . 71 , to express the joint creation of objects 0 , 1 , 2 with ( { 0 , 1 , 2 } , CREATE ) , a possibly subsequent spatial modiﬁcation of 1 and 2 ( e . g . , via translation , scaling etc . ) could be described with ( { 1 , 2 } , MODIFY _ SPATIAL ) and a ﬁnishing deletion of object number 0 could be represented by ( { 0 } , DELETE ) . The binary tuple ( ∅ , ε ) , which is also included in Eq . 4 . 71 , is a special type of empty event . Apparently , our deﬁnition of E h Ω i is based on the assumption , that information units in a workspace can be ( a ) created ; ( b ) modiﬁed ( either spatially , visually or content - related ) and ( c ) they can be deleted . 73 Chapter 4 . Prototype 4 . 2 . 2 InfoUnitData In addition to events e k ∈ E h Ω i ( Sect . 4 . 2 . 1 ) interpretation systems accept a second input , which is info unit Data D k . Such data packages D k contain in - formation , which is primarily used for structural analysis , that is , for ( spatial ) parsing . Here we assume , that this includes geometrical properties of informa - tion units ( such as bounds , shape etc . ) as well as information regarding color and content . Just like events e k ∈ E h Ω i from Sect . 4 . 2 . 1 , also info unit data D k in this section are not to be confused with our previous deﬁnitions from Eq . 4 . 66 or with W . info _ units from Eq . 4 . 55 . For a precise mathematical deﬁnition of these data packages we need several auxiliary structures and operations . This includes , among other things , a deﬁ - nition of geometrical bounds : Our deﬁnition of Bounds h k i builds on k - dops and thus generalizes the conven - tional bounding box : Bounds h k i =    (cid:18) S 0 , S 1 , . . . , S ( k 2 − 1 ) (cid:19) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12)(cid:12) (cid:12) S i ∈ Slab , 0 ≤ i ≤ k 2 − 1 , k ∈ { 8 , 16 , 32 , . . . }    ( 4 . 73 ) Each b ∈ Bounds h k i is the Boolean intersection of extents along k / 2 directions and hence of k / 2 bounding “Slabs” ( Eq . 4 . 74 ) . k is limited to { 8 , 16 , 32 , . . . } . Slab = ( ( ~ n , d min , d max ) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) ~ n ∈ ( R × R ) ∧ | ~ n | = 1 , d min , d max ∈ R ∧ d max > d min ) ( 4 . 74 ) Slabs are triples of normal vectors ~ n and signed distances from the origin d min , d max ∈ R and describe the extent along a certain direction . This is also why d max > d min . References to elements of such k / 2 - tuples of triples ( ~ n , d min , d max ) may become complex and therefore diﬃcult to read . In order to avoid that , let us do the following notational simpliﬁcation : ∀ b ∈ Bounds h k i : b : =     (cid:0) b . normal [ 0 ] , b . min [ 0 ] , b . max [ 0 ] (cid:1) , (cid:0) b . normal [ 1 ] , b . min [ 1 ] , b . max [ 1 ] (cid:1) , . . . , (cid:18) b . normal h k 2 − 1 i , b . min h k 2 − 1 i , b . max h k 2 − 1 i(cid:19)    ( 4 . 75 ) With this “array - like” notation we can reference single attributes of bounding volumes b ∈ Bounds h k i via b . normal [ i ] , b . min [ i ] and b . max [ i ] ( for 0 ≤ i < k / 2 ) . 74 4 . 2 . Interpretation System For the sake of completeness , it should be pointed out that bounds ∈ Bounds h k i share their normal vectors : ∀ b , b ′ ∈ Bounds h k i : b . normal [ i ] = b ′ . normal [ i ] , i ∈ (cid:26) 0 , . . . , k 2 − 1 (cid:27) ( 4 . 76 ) It is quite obvious , that diﬀerent bounds with diﬀerent normal vectors would make no sense at all . Nevertheless , in order to keep our deﬁnitions formally correct we must exclude that explicitly . This also applies to a series of auxiliary functions on which we will build on with our parsing algorithms . This includes functions for accessing horizontal , vertical and diagonal bounds of b ∈ Bounds h k i . These access operations shall be deﬁned for any k ∈ { 8 , 16 , 32 , . . . } : Assuming that the x - coordinate of b . normal [ 0 ] is always 0 and that normal vectors b . normal [ i ] are deﬁned counter - clockwise for 0 ≤ i < k / 2 , we can deﬁne the following shortcuts : min h : Bounds h k i → R , ∀ b ∈ Bounds h k i : min h ( b ) = b . min (cid:20) k 4 (cid:21) max h : Bounds h k i → R , ∀ b ∈ Bounds h k i : max h ( b ) = b . max (cid:20) k 4 (cid:21) ( 4 . 77 ) min v : Bounds h k i → R , ∀ b ∈ Bounds h k i : min v ( b ) = b . min [ 0 ] max v : Bounds h k i → R , ∀ b ∈ Bounds h k i : max v ( b ) = b . max [ 0 ] ( 4 . 78 ) min d 0 : Bounds h k i → R , ∀ b ∈ Bounds h k i : min d 0 ( b ) = b . min (cid:20) k 8 (cid:21) max d 0 : Bounds h k i → R , ∀ b ∈ Bounds h k i : max d 0 ( b ) = b . max (cid:20) k 8 (cid:21) ( 4 . 79 ) min d 1 : Bounds h k i → R , ∀ b ∈ Bounds h k i : min d 1 ( b ) = b . min (cid:20) 3 k 8 (cid:21) max d 1 : Bounds h k i → R , ∀ b ∈ Bounds h k i : max d 1 ( b ) = b . max (cid:20) 3 k 8 (cid:21) ( 4 . 80 ) Here , suﬃx h ( Eq . 4 . 77 ) stands for “horizontal” , v ( Eq . 4 . 78 ) for “vertical” and d 0 , d 1 ( Eq . 4 . 79 , Eq . 4 . 80 ) for “diagonal” . We distinguish between diagonals from top - left to bottom - right ( d 0 ) and from top - right to bottom - left ( d 1 ) . This also explains why in Eq . 4 . 73 k was limited to { 8 , 16 , 32 , . . . } . Eq . 4 . 77 – Eq . 4 . 80 75 Chapter 4 . Prototype require that all four bounding axes are deﬁned , h , v , d 0 as well as d 1 . This only holds true if k ≥ 8 . We build on these shortcuts with several geometrical functions that will play an important role for our later deﬁnitions of parsing algorithms . Here , it is to be assumed that the basic semantics behind terms such as “union” , “intersects” , “contains” etc . are known . That is , it should be clear what it means to merge two bounding volumes , to check them for intersection , containment etc . Thus , we are not going to repeat the foundations of bounding volume geometry . Nev - ertheless , for consistency reasons , we must deﬁne at least those functions that will be used later on in our algorithms . Width and height of bounding volumes are the easiest to deﬁne . For this we simply calculate the diﬀerence between horizontal and vertical bounds from Eq . 4 . 77 and Eq . 4 . 78 : width : Bounds h k i → R + , ∀ b ∈ Bounds h k i : width ( b ) = max h ( b ) − min h ( b ) height : Bounds h k i → R + , ∀ b ∈ Bounds h k i : height ( b ) = max v ( b ) − min v ( b ) ( 4 . 81 ) Scaling and union are slightly more complex : scale : (cid:0) Bounds h k i × R (cid:1) ⇀ Bounds h k i , ( b , oﬀset ) 7→ b ′ ,    (cid:0) b ′ . min [ i ] = b . min [ i ] − oﬀset (cid:1) ∧ (cid:0) b ′ . max [ i ] = b . max [ i ] + oﬀset (cid:1)    , i ∈ (cid:26) 0 , . . . , k 2 − 1 (cid:27) ( 4 . 82 ) What is special about our deﬁnition of scale is , that no scaling factor is used . Instead dimensions of b ∈ Bounds h k i are increased or decreased by a ﬁxed oﬀset ∈ R . Thus we use the term “scaling” diﬀerently than usual . With our union - operation , however , we do not deviate from common semantics . Therefore it is deﬁned as follows : union : (cid:0) Bounds h k i × Bounds h k i (cid:1) → Bounds h k i , ( b 0 , b 1 ) 7→ b ′ ,   (cid:16) b ′ . min [ i ] = min (cid:0) b 0 . min [ i ] , b 1 . min [ i ] (cid:1)(cid:17) ∧ (cid:16) b ′ . max [ i ] = max (cid:0) b 0 . max [ i ] , b 1 . max [ i ] (cid:1)(cid:17)   , i ∈ (cid:26) 0 , . . . , k 2 − 1 (cid:27) ( 4 . 83 ) The remaining ﬁve auxiliary functions delta max , delta min , contains , intersects , and centroid require descriptions in form of pseudo code . 76 4 . 2 . Interpretation System Alg . 1 and Alg . 2 deﬁne maximal and minimal extent of bounding volumes b ∈ Bounds h k i . delta max maximizes the diﬀerence ( b . max [ i ] − b . min [ i ] ) , for 0 ≤ i < k / 2 , whereas delta min calculates the minimal ( b . max [ i ] − b . min [ i ] ) . Alg . 1 delta max : Bounds h k i → R + , b 7→ r , 1 : r ← (cid:0) b . max [ 0 ] − b . min [ 0 ] (cid:1) 2 : for i = 1 to (cid:16) k 2 − 1 (cid:17) do 3 : if (cid:0) b . max [ i ] − b . min [ i ] (cid:1) > r then 4 : r ← (cid:0) b . max [ i ] − b . min [ i ] (cid:1) 5 : end if 6 : end for 7 : return r By substituting ( ( b . max [ i ] − b . min [ i ] ) > r ) for ( ( b . max [ i ] − b . min [ i ] ) < r ) this algorithm for determining the maximal extent of bounding volumes b changes into a function for calculating their minimal extent delta min : Alg . 2 delta min : Bounds h k i → R + , b 7→ r , 1 : r ← (cid:0) b . max [ 0 ] − b . min [ 0 ] (cid:1) 2 : for i = 1 to (cid:16) k 2 − 1 (cid:17) do 3 : if (cid:0) b . max [ i ] − b . min [ i ] (cid:1) < r then 4 : r ← (cid:0) b . max [ i ] − b . min [ i ] (cid:1) 5 : end if 6 : end for 7 : return r Whether a given bounding volume b 1 ∈ Bounds h k i is contained by another bounding volume b 0 ∈ Bounds h k i is determined by Alg . 3 . For this we deﬁne possible return values as elements of { TRUE , FALSE } . Alg . 3 contains : (cid:0) Bounds h k i × Bounds h k i (cid:1) → { TRUE , FALSE } , ( b 0 , b 1 ) 7→ r , 1 : r ← TRUE 2 : for i = 0 to (cid:16) k 2 − 1 (cid:17) do 3 : if (cid:0) b 1 . min [ i ] < b 0 . min [ i ] (cid:1) ∨ (cid:0) b 1 . max [ i ] > b 0 . max [ i ] (cid:1) then 4 : return FALSE 5 : end if 6 : end for 7 : return r 77 Chapter 4 . Prototype When we substitute ( b 1 . min [ i ] < b 0 . min [ i ] ) for ( b 1 . min [ i ] > b 0 . max [ i ] ) and replace ( b 1 . max [ i ] > b 0 . max [ i ] ) by ( b 0 . min [ i ] > b 1 . max [ i ] ) , then we can eas - ily transform the contains - algorithm from Alg . 3 into an intersection test for bounding volumes : Alg . 4 intersects : (cid:0) Bounds h k i × Bounds h k i (cid:1) → { TRUE , FALSE } , ( b 0 , b 1 ) 7→ r , 1 : r ← TRUE 2 : for i = 0 to (cid:16) k 2 − 1 (cid:17) do 3 : if (cid:0) b 1 . min [ i ] > b 0 . max [ i ] (cid:1) ∨ (cid:0) b 0 . min [ i ] > b 1 . max [ i ] (cid:1) then 4 : return FALSE 5 : end if 6 : end for 7 : return r The last auxiliary function we want to deﬁne , serves the purpose of calculating a bounding volume’s centre point . We denote this function as centroid and deﬁne it with the following algorithm : Alg . 5 centroid : Bounds h k i → ( R × R ) , b 7→ (cid:18) x y (cid:19) , 1 : x ← 0 . 0 2 : y ← 0 . 0 3 : P ← corner _ points ( b ) 4 : for all (cid:18) a b (cid:19) ∈ P do 5 : x ← x + a 6 : y ← y + b 7 : end for 8 : return (cid:18) x / | P | y / | P | (cid:19) Here we assume that corner _ points ( b ) , which is used in Alg . 5 in line 3 , is deﬁned for any b ∈ Bounds h k i . The function value of corner _ points ( b ) should be a set of real - valued vectors P , where each ~ p ∈ P marks an intersection of two adjacent boundary lines of b ( i . e . , a corner point of b ) . In addition to Bounds h k i from Eq . 4 . 73 and the previously deﬁned auxiliary functions from Eq . 4 . 77 – Eq . 4 . 83 and Alg . 1 – Alg . 5 , our deﬁnition of informa - tion unit data D requires four speciﬁc object types . These types are labeled as Layer , Shape , Color , String and are deﬁned as can be seen in Eq . 4 . 84 . 78 4 . 2 . Interpretation System Layer = N 0 Shape = { RECTANGLE , ELLIPSE } Color = (cid:8) ( r , g , b ) (cid:12)(cid:12) r , b , g ∈ { 0 , 1 , . . . , 255 } (cid:9) String : set of character strings ( 4 . 84 ) Here , the ﬁrst three deﬁnitions of Layer , Shape and Color build on Eq . 4 . 57 . Layer corresponds to depth coordinates z ∈ N 0 from A position , Shape comprises RECTANGLE and ELLIPSE from A shape , and Color is , just like A color , de - ﬁned as a set of ( r , g , b ) - triples . String , on the other hand , represents a set of character strings . Just like in Sect . 4 . 1 . 4 also here the exact character encoding shall be of no importance . Although , in this special case , there is no substantial diﬀerence between these four sets of objects and our previous deﬁnitions from Sect . 4 . 1 . 4 , they still should be understood as independent object types . At least we will treat them as such . With all these deﬁnitions at hand we can ﬁnally determine info unit data D as : D h Ω , k i = ( D : = ( V , p ) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) V ∈ 2 Ω , p : V → InfoUnitData h k i ) ( 4 . 85 ) According to this deﬁnition , each data package D ∈ D h Ω , k i comprises two components : ( 1 ) a set of information units V and ( 2 ) a function p which assigns to each unit ∈ V an element out of InfoUnitData h k i . InfoUnitData h k i is a placeholder for the cartesian product of Bounds h k i ( Eq . 4 . 73 ) and our previously deﬁned object types Layer , Shape , Color and String ( Eq . 4 . 84 ) : InfoUnitData h k i : = (cid:0) Bounds h k i × Layer × Shape × Color × String (cid:1) ( 4 . 86 ) Thus each ( V , p ) ∈ D h Ω , k i assigns to a selection of information units V ﬁve - tuples ∈ InfoUnitData h k i . Attributes of such tuples are denoted as : ∀ d ∈ InfoUnitData h k i : d : =     d . bounds , d . layer , d . shape , d . color , d . text     ( 4 . 87 ) 79 Chapter 4 . Prototype 4 . 2 . 3 Interpretations As we know already , interpretation systems transform ingoing sequences of events e ∈ E h Ω i ( Sect . 4 . 2 . 1 ) and info unit data D ∈ D h Ω , k i ( Sect . 4 . 2 . 2 ) into outgoing sequences of interpretations I ∈ I h Ω , P i . Based on our considerations from Sect . 2 . 2 we deﬁne I h Ω , P i as follows : I h Ω , P i =    I : = ( U , A , w ) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) U ∈ 2 Ω , A = (cid:18) U 2 (cid:19) , w : A → P    ( 4 . 88 ) The included “empty” interpretation I ε can be described as : I ε : = (cid:0) ∅ , ∅ , w ε (cid:1) ∈ I h Ω , P i , Def ( w ε ) = ∅ ( 4 . 89 ) Thus , we use I ε as a symbolic placeholer for a triple ( U , A , w ) ∈ I h Ω , P i , with U = ∅ , the resulting empty set of associations A = ∅ and an empty mapping w = w ε = ∅ ( i . e . , Def ( w ε ) = ∅ ) . In the following we will work with a partial reﬁnement of I h Ω , P i : I h Ω i : = I h Ω , { ε , 0 . 0 , . . . , 1 . 0 } i ( 4 . 90 ) Here we set P equal to { ε , 0 . 0 , . . . , 1 . 0 } . According to Eq . 2 . 18 parameter set P shall meet the following criteria : P = ( P 0 × P 1 × . . . × P m − 1 ) ∪ P ε , m ≥ 1 P j 6 = ∅ ( 0 ≤ j ≤ m − 1 ) P ε 6 = ∅ , P ε ⊂ P For m = 1 , P 0 = { p ∈ R | 0 . 0 < p ≤ 1 . 0 } , P ε = { ε , 0 . 0 } and thus for P = P 0 ∪ P ε = { ε , 0 . 0 , . . . , 1 . 0 } this is satisﬁed . Technically , such interpretations ( U , A , w ) ∈ I h Ω i are complete , undirected and weighted graphs , which assign to each pair of information units { u , u ′ } ∈ A a weight ∈ { ε , 0 . 0 , . . . , 1 . 0 } . Such weights w ( { u , u ′ } ) shall describe the strength of a relation between u and u ′ ( i . e . , the higher the value the stronger the relationship ) . As an example , a weight w ( { u , u ′ } ) = 0 . 0 would mean that there is no immediate relationship between u and u ′ . A weight of ε , however , would indicate that it is unknown whether u and u ′ are associated or not ; there might be an association , but the interpretation system cannot make a clear decision . We could see already some simple examples for such interpretations in Chapter . 3 in Fig . 3 . 2 , Fig . 3 . 3 , Fig . 3 . 4 , or Fig . 3 . 5 respectively . 80 4 . 2 . Interpretation System Interpretation System merge       parser 0 parser 1 parser n ⋯ Figure 4 . 6 : Interpretation systems forward incoming edit steps ( e k , D k ) to internal parsing components . Parse results are then merged together and are ﬁnally delivered as output I k . 4 . 2 . 4 Merging Interpretation systems , as we deﬁne them , transform events e ∈ E h Ω i ( Eq . 4 . 71 ) and info unit data D ∈ D h Ω , k i ( Eq . 4 . 85 ) into interpretations I ∈ I h Ω i ( Eq . 4 . 90 ) . One could also say , that interpretation systems are dynamic systems which transform ingoing sequences of “edit steps” . . .   e 0 D 0 ! , e 1 D 1 ! , . . . , e k e D k e !   , e i D i ! ∈ E h Ω i × D h Ω , k i ! , i ∈ { 0 , 1 , . . . , k e } . . . into outgoing sequences . . . (cid:0) I 0 , I 1 , . . . , I k e (cid:1) , I i ∈ I h Ω i , i ∈ { 0 , 1 , . . . , k e } What still remains to be clariﬁed is how such transformations work ; that is , how tuples ( e , D ) are ﬁnally mapped to I . The main function of an interpretation system is to perform structural analyses on spatial hypertext , that is , to retrieve implicitly encoded structure . Theoreti - cally , such an analysis may be conducted under various aspects , such as spatial , visual , temporal , content - related or others . Therefore , with our deﬁnition of interpretation systems we generalize the concept of conventional spatial pars - ing from Sect . 1 . 3 . Fig . 4 . 6 illustrates that : Incoming edit steps ( e k , D k ) are forwarded to internal parsing components . These components ( or sub - systems ) are specialized in analysing certain aspects of spatial hypertext and hence pro - vide diﬀerent structural interpretations as parse result . Parse results are then merged together and are ﬁnally delivered as output I k . The rationale behind this is that when mixing spatial , visual etc . interpre - tations in the right proportions then we can ﬁlter out structures that were originally intended by hypertext authors . For this see also our considerations from Sect . 2 . 1 ( page 31 ) . 81 Chapter 4 . Prototype Before we can describe the aforementioned merge algorithm in detail , we need to deﬁne a speciﬁc auxiliary data structure , which is List h Q i : List h Q i =   ( q 0 , q 1 , . . . , q n ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) q i ∈ Q , i ∈ { 0 , 1 , . . . , n } , n ∈ N 0   ∪ { list ε } , list ε : = ( ) ( 4 . 91 ) Lists of “type” Q , if you want to call it that , are nothing more than ordered tuples ( q 0 , q 1 , . . . , q n ) of list elements q i ∈ Q ( for i ∈ { 0 , 1 , . . . , n } ) . For empty lists or rather 0 - tuples we use the symbolic placeholder list ε . This will serve as a kind of “default constructor” for empty lists . Although , in theory , various operations could be deﬁned on such lists , we limit ourselves only to those which are of importance to our algorithms . This in - cludes , among other things , functions add , size and get : Function add ( list , q ′ ) serves the purpose of extending a given list ∈ List h Q i by a new element q ′ ∈ Q . We formally describe that as follows : add : (cid:0) List h Q i × Q (cid:1) → List h Q i , ∀ (cid:0) list , q ′ (cid:1) ∈ (cid:0) List h Q i × Q (cid:1) : add (cid:0) list , q ′ (cid:1) = ( (cid:0) q 0 , q 1 , . . . , q n , q ′ (cid:1) , if list = ( q 0 , q 1 , . . . , q n ) where n ∈ N 0 (cid:0) q ′ (cid:1) , else ( 4 . 92 ) size ( list ) determines how many elements are included in a given list ∈ List h Q i . For this it returns the length of the underlying tuple : size : List h Q i → N 0 , ∀ list ∈ List h Q i : size ( list ) = ( ( n + 1 ) , if list = ( q 0 , q 1 , . . . , q n ) where n ∈ N 0 0 , else ( 4 . 93 ) get ( list , i ) serves index - based read access on single list elements . If the said index i lies out of range or if list is empty , then get ( list , i ) returns as function value the empty symbol ε . This way , function get remains totally deﬁned : get : (cid:0) List h Q i × N 0 (cid:1) → (cid:0) Q ∪ { ε } (cid:1) , ∀ list ∈ List h Q i : get ( list , i ) = ( q i , if (cid:0) list = ( q 0 , q 1 , . . . , q n ) (cid:1) ∧ ( 0 ≤ i ≤ n ) where n ∈ N 0 ε , else ( 4 . 94 ) 82 4 . 2 . Interpretation System Together with the deﬁnition of List h Q i in Eq . 4 . 91 , functions add ( Eq . 4 . 92 ) , size ( Eq . 4 . 93 ) and get ( Eq . 4 . 94 ) allow for statements as illustrated in Alg . 6 : Alg . 6 sample algorithm based on deﬁnitions in Eq . 4 . 92 , Eq . 4 . 93 , Eq . 4 . 94 1 : l 0 ← list ε ⊲ create an empty list l 0 2 : for i = 0 to 999 do 3 : l 0 ← add ( l 0 , i ) ⊲ ﬁll l 0 with integers ∈ { 0 , 1 , . . . , 999 } 4 : end for 5 : l 1 ← list ε ⊲ create another empty list l 1 6 : for i = 0 to (cid:0) size ( l 0 ) − 1 (cid:1) do 7 : l 1 ← add (cid:0) l 1 , get ( l 0 , i ) (cid:1) ⊲ copy all 1000 list entries from l 0 to l 1 8 : end for In addition to these three functions let us also describe the following auxiliary operations : empty , ﬁrst und last . These build on Eq . 4 . 93 and Eq . 4 . 94 and are merely used for syntactic simpliﬁcation : empty ( list ) checks , whether the given list includes no elements and provides the result as an element of the discrete set { TRUE , FALSE } : empty : List h Q i → { TRUE , FALSE } , ∀ list ∈ List h Q i : empty ( list ) = ( TRUE , if size ( list ) = 0 FALSE , else ( 4 . 95 ) ﬁrst ( list ) reﬁnes function get ( list , i ) from Eq . 4 . 94 to get ( list , 0 ) and thus re - turns the ﬁrst list element as function value : ﬁrst : List h Q i → (cid:0) Q ∪ { ε } (cid:1) , list 7→ get ( list , 0 ) ( 4 . 96 ) Similarly , last ( list ) can be deﬁned as : last : List h Q i → (cid:0) Q ∪ { ε } (cid:1) , list 7→ get (cid:0) list , size ( list ) − 1 (cid:1) ( 4 . 97 ) 83 Chapter 4 . Prototype Interpretation System merge       parser 0 parser 1 parser n ⋯ Figure 4 . 7 : Interpretation systems delegate edit steps to internal parsers . Parse results are then mixed together using the merging algorithm described in Alg . 7 . With these deﬁnitions at hand we can now deﬁne merge ( Fig . 4 . 7 ) as follows : Alg . 7 merge : (cid:16) List h I h Ω , ( R + 0 ∪ { ε } ) ii × List h R + 0 i (cid:17) ⇀ I h Ω , ( R + 0 ∪ { ε } ) i , ( interpretations , weightingFactors ) 7→ I merge Require : size ( interpretations ) = size ( weightingFactors ) ∧ empty ( interpretations ) = FALSE ! 1 : I merge ← merge ′ ﬁrst ( interpretations ) , 0 . 0 , ﬁrst ( interpretations ) , ﬁrst ( weightingFactors ) ! 2 : for i = 1 to (cid:0) size ( interpretations ) − 1 (cid:1) do 3 : I merge ← merge ′ I merge , 1 . 0 , get ( interpretations , i ) , get ( weightingFactors , i ) ! 4 : end for 5 : return I merge Alg . 7 accepts a list of interpretations ∈ I h Ω , ( R + 0 ∪ { ε } ) i and a list of weighting factors ∈ R + 0 as input and generates a single merged interpretation I merge of type I h Ω , ( R + 0 ∪ { ε } ) i as output . Prerequisites for this algorithm are , ﬁrstly , that there must be a weighting factor for each ingoing interpretation and secondly , that the given list of inter - pretations may not be empty ; that is , we expect at least one interpretation as input . Otherwise merge is undeﬁned . The algorithm essentially performs a cumulative , pairwise merge of interpreta - tions from i = 0 to ( size ( interpretations ) − 1 ) using get ( weightingFactors , i ) . 84 4 . 2 . Interpretation System The “heart” of this procedure is the pairwise merging function merge ′ , which is described in detail in the following Eq . 4 . 98 : merge ′ : I h Ω , ( R + 0 ∪ { ε } ) i × R + 0 × I h Ω , ( R + 0 ∪ { ε } ) i × R + 0 ! ⇀ I h Ω , ( R + 0 ∪ { ε } ) i , (cid:16) ( U , A , w 0 ) , α , ( U , A , w 1 ) , β (cid:17) 7→ (cid:0) U , A , w ′ (cid:1) , w ′ : A → (cid:16) R + 0 ∪ { ε } (cid:17) , ∀ a ∈ A : w ′ ( a ) =    ε , if (cid:16) w 0 ( a ) = ε (cid:17) ∧ (cid:16) w 1 ( a ) = ε (cid:17) α × w 0 ( a ) , else if (cid:16) w 0 ( a ) 6 = ε (cid:17) ∧ (cid:16) w 1 ( a ) = ε (cid:17) β × w 1 ( a ) , else if (cid:16) w 0 ( a ) = ε (cid:17) ∧ (cid:16) w 1 ( a ) 6 = ε (cid:17) α × w 0 ( a ) + β × w 1 ( a ) , else ( 4 . 98 ) merge ′ ( I 0 , α , I 1 , β ) accepts two interpretations I 0 , I 1 ∈ I h Ω , ( R + 0 ∪ { ε } ) i as in - put , mixes them according to given weighting factors α , β ∈ R + 0 and returns the merge result as ∈ I h Ω , ( R + 0 ∪ { ε } ) i . This is best explained with an example . Let us assume that there are two interpretations given : I 0 = ( U , A , w 0 ) ; I 1 = ( U , A , w 1 ) Shared components U and A shall be deﬁned as follows : U = { u 0 , u 1 , u 2 } ; A = (cid:18) U 2 (cid:19) =   { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }   Weighting functions w 0 , w 1 are given as : w 0 =   (cid:0) { u 0 , u 1 } , ε (cid:1) , (cid:0) { u 0 , u 2 } , 1 . 0 (cid:1) , (cid:0) { u 1 , u 2 } , 1 . 0 (cid:1)   ; w 1 =   (cid:0) { u 0 , u 1 } , ε (cid:1) , (cid:0) { u 0 , u 2 } , ε (cid:1) , (cid:0) { u 1 , u 2 } , 0 . 5 (cid:1)   Weighting factors α , β shall be set to 0 . 5 each . That is , we intend to mix I 0 , I 1 in a 50 % : 50 % - ratio . 85 Chapter 4 . Prototype  0  1  2  1 . 0 1 . 0 è  0  1  2  0 . 5   0  1  2  0 . 75 0 . 5  0 =  ,  ,  0  1 =  ,  ,  1      ′  0 , 0 . 5 ,  1 , 0 . 5 =  ,  ,  ′ Figure 4 . 8 : Two sample interpretations I 0 = ( U , A , w 0 ) and I 1 = ( U , A , w 1 ) mixed in a 50 % : 50 % - ratio using merge ′ ( I 0 , 0 . 5 , I 1 , 0 . 5 ) When we apply now merge ′ from Eq . 4 . 98 on I 0 , I 1 using α , β = 0 . 5 , then merge ′ ( I 0 , α , I 1 , β ) = merge ′ ( ( U , A , w 0 ) , 0 . 5 , ( U , A , w 1 ) , 0 . 5 ) results in a triple ( U , A , w ′ ) ∈ I h Ω , ( R + 0 ∪ { ε } ) i , where w ′ is set up as follows : w ′ =      (cid:0) { u 0 , u 1 } , ε (cid:1) , { u 0 , u 2 } , (cid:18)(cid:16) α × w 0 (cid:0) { u 0 , u 2 } (cid:1)(cid:17) = ( 0 . 5 × 1 . 0 ) = 0 . 5 (cid:19) ! ,   { u 1 , u 2 } ,   α × w 0 (cid:0) { u 1 , u 2 } (cid:1) + β × w 1 (cid:0) { u 1 , u 2 } (cid:1) ! = 0 . 5 × 1 . 0 + 0 . 5 × 0 . 5 ! = 0 . 75                   Thus it becomes : w ′ =    (cid:0) { u 0 , u 1 } , ε (cid:1) , (cid:0) { u 0 , u 2 } , 0 . 50 (cid:1) , (cid:0) { u 1 , u 2 } , 0 . 75 (cid:1)    This transformation of I 0 and I 1 into merge ′ ( I 0 , 0 . 5 , I 1 , 0 . 5 ) = ( U , A , w ′ ) is illustrated graphically in Fig . 4 . 8 . 4 . 3 Linking Editing and Interpretation System Spatial hypermedia systems are compound systems formed by editing systems ( Sect . 4 . 1 ) and interpretation systems ( Sect . 4 . 2 ) . Editing systems transform user interface activities ( such as keyboard or mouse events etc . ) into edit events e k ∈ E W h Σ SH , X SH , K , C , E symbol i ( Eq . 4 . 45 ) and workspaces W k ∈ O W h Σ SH , X SH , K , C i ( Eq . 4 . 51 , Eq . 4 . 55 ) . Both , e k and W k 86 4 . 3 . Linking Editing and Interpretation System Spatial Hypermedia System Interpretation System  ′       ′      Editing System conversion Figure 4 . 9 : Editing system and interpretation system linked by signal conversion layer strongly depend on the workspace model and hence on the concrete editing system . That is , parameters Σ SH , X SH , K , C and E symbol have signiﬁcant impact on the deﬁnition of an editing system’s output . The best illustration of this was given in Sect . 4 . 1 . 4 . Interpretation systems , on the other hand , turn events e k ∈ E h Ω i ( Eq . 4 . 71 ) and info unit data D k ∈ D h Ω , k i ( Eq . 4 . 85 ) into interpretations I k ∈ I h Ω i ( Eq . 4 . 90 ) . There is no direct dependency on Σ SH or X SH , which desirably increases reusability and ﬂexibility of our system model . In concrete terms , changes to workspaces do not automatically require adjustment of interpreters . This is especially helpful for application development . However , since both system interfaces require diﬀerent signals , it is not possible to link editing and interpretation system directly . Therefore , some kind of signal conversion layer is needed . According to Fig . 4 . 9 that conversion layer has to accomplish two functions : Firstly , to transform editing system output . . .   e 0 W 0 ! , e 1 W 1 ! , . . . , e k e W k e !   , e k W k ! ∈ E W h Σ SH , X SH , K , C , E symbol i × O W h Σ SH , X SH , K , C i ! . . . into interpretation system input . . .   e ′ 0 D 0 ! , e ′ 1 D 1 ! , . . . , e ′ k e D k e !   , e ′ k D k ! ∈ E h Ω i × D h Ω , k dop i ! , k ∈ { 0 , 1 , . . . , k e } . . . and , secondly , to transform resulting interpretations . . . (cid:0) I 0 , I 1 , . . . , I k e (cid:1) , I k ∈ I h Ω i , k ∈ { 0 , 1 , . . . , k e } 87 Chapter 4 . Prototype . . . back into editing system input again : (cid:16) I ′ 0 , I ′ 1 , . . . , I ′ k e (cid:17) , I ′ k ∈ I h Ω i , k ∈ { 0 , 1 , . . . , k e } Such a two - way signal conversion strongly depends on the exact deﬁnition of input and output signals . Unlike previous deﬁnitions of editing processes , workspaces etc . there is no generic formalism that universally describes how ( e k , W k ) are mapped to ( e ′ k , D k ) or I k is transformed into I ′ k . Knowledge about the exact deﬁnition of Σ SH , X SH , K , Ω etc . is needed to accurately decribe such transformations . In other words , it becomes necessary to specify more precisely both , editing and interpretation system . This is why our following deﬁnition of conversion functionality builds on E W and O W from Eq . 4 . 66 . In concrete terms , we deﬁne ordered pairs ( e k , W k ) as ∈ ( E W × O W ) and hence build on our default workspace model A W . From Eq . 4 . 66 we know , that K = N 0 ( i . e . , identiﬁers u . key are typed as “unsigned int” ) . This makes it possible to determine Ω for E h Ω i , D h Ω , k i and I h Ω i . It should be recalled , that both , keys ∈ K and objects ∈ Ω basically serve the same purpose : unique identiﬁcation of information units . Thus , there is no general need for keys ∈ K and objects ∈ Ω to be of diﬀerent types . This is why we set Ω = K = N 0 and hence E h Ω i to E h N 0 i and I h Ω i to I h N 0 i . The bounding volume parameter k , that is required by D h Ω , k i , is set to 16 . k = 16 fulﬁlls the condition k ∈ { 8 , 16 , 32 , . . . } from Eq . 4 . 73 and provides an approximation of the convex hull that is accurate enough for our purposes . Thus , tuples ( e ′ k , D k ) are deﬁned as ∈ ( E h N 0 i × D h N 0 , 16 i ) . Interpretations I k , I ′ k shall be of type I h N 0 i . For easier handling we have separated the conversion layer into three compo - nents : ( 1 ) convert _ event ; ( 2 ) convert _ info _ units and ( 3 ) convert _ interpretation . Here , convert _ event serves the transformation of e k ∈ E W into e ′ k ∈ E h N 0 i , convert _ info _ units converts W k ∈ O W into D k ∈ D h N 0 , 16 i ) and the third com - ponent convert _ interpretation realizes the change of I k ∈ I h N 0 i to I ′ k ∈ I h N 0 i . The blockdiagram in Fig . 4 . 10 illustrates that . convert _ event maps events e ∈ E W to pairs ( e ′ . objects , e ′ . operation ) ∈ E h N 0 i : convert _ event : E W → E h N 0 i , e 7→ e ′ . objects , e ′ . operation ! ( 4 . 99 ) Here , e ′ . objects ⊂ N 0 includes identiﬁers for all information units that are aﬀected by event e . 88 4 . 3 . Linking Editing and Interpretation System Spatial Hypermedia System  ′       ′      conversion convert _ event convert _ info _ units convert _ interpretation Editing System Interpretation System Figure 4 . 10 : Signal conversion between editing and interpretation system is deﬁned by three functions : convert _ event , convert _ info _ units , and convert _ interpretation . It can be formed from e as follows : e ′ . objects =    ∅ , if e ∈ E ε   [ u ∈ Pre u ( e ) { u . key }   , if e ∈ E delete   [ u ∈ Post u ( e ) { u . key }   , else ( 4 . 100 ) Since K = Ω = N 0 no special mapping is required for transforming u . key ∈ N 0 into objects ∈ Ω = N 0 . In other words , we can copy them directly . e ∈ E ε indicates an empty event ( Eq . 4 . 69 ) and hence that there are no objects for which an event has occurred . In this case , e ′ . objects can be set to ∅ . If e is not an empty event but ∈ E delete ( Eq . 4 . 67 ) , then e ′ . objects can be formed from keys included in Pre u ( e ) ( Eq . 4 . 20 ) . If e is neither ∈ E ε nor ∈ E delete , then identiﬁers from Post u ( e ) are used instead ( Eq . 4 . 21 ) . The second tuple element besides e ′ . objects is the operation ﬂag e ′ . operation . It can be formed from e as follows : e ′ . operation =    CREATE , if e ∈ E create MODIFY _ SPATIAL , if e ∈ E symbol _ changed \ E color _ changed MODIFY _ VISUAL , if e ∈ E color _ changed MODIFY _ CONTENT , if e ∈ E content _ changed DELETE , if e ∈ E delete ε , else ( 4 . 101 ) 89 Chapter 4 . Prototype Eq . 4 . 101 is a conditional mapping of events e ∈ E W to discrete operation ﬂags ( as deﬁned in Eq . 4 . 71 ) . It therefore classiﬁes events e according to whether they describe construction or destruction , change of spatial , visual or content - related attributes , or whether they represent any other event . convert _ info _ units deﬁnes , how we transform workspaces W ∈ O W into ade - quate info unit data packages ( V , p ) ∈ D h N 0 , 16 i : convert _ info _ units : O W → D h N 0 , 16 i , W 7→ ( V , p ) , V =   [ u ∈ W . info _ units { u . key }   p : V → InfoUnitData h 16 i , p =   [ u ∈ W . info _ units n(cid:0) u . key , value ( u ) (cid:1)o   ( 4 . 102 ) In V we collect keys for all information units included in workspace W . Func - tion p assigns to each u . key ∈ V some value ( u ) ∈ InfoUnitData h 16 i ( Eq . 4 . 86 ) . We deﬁne value ( u ) as a mapping of tuples u ∈ ( Σ # SH × ( N 0 × String ) ) , as described in Eq . 4 . 33 , to InfoUnitData h 16 i : value : (cid:16) Σ # SH × ( N 0 × String ) (cid:17) → InfoUnitData h 16 i ,   symbol , key , content !   7→   create _ bounds   symbol . position , symbol . size , symbol . orientation , symbol . shape   , symbol . position . z , symbol . shape , symbol . color , content   ( 4 . 103 ) Here , only the bounds - attribute ( see Eq . 4 . 87 ) requires some additional calcu - lation . This is represented by create _ bounds : create _ bounds : (cid:0) A position × A size × A orientation × A shape (cid:1) → Bounds h 16 i ,     position , size , orientation , shape     7→     ( ~ n 0 , min 0 , max 0 ) , ( ~ n 1 , min 1 , max 1 ) , . . . , ( ~ n 7 , min 7 , max 7 )     ( 4 . 104 ) 90 4 . 3 . Linking Editing and Interpretation System Spatial Hypermedia System Interpretation System Editing System view controller    ′    merge            ′      workspace parser 0 parser 1 parser n ⋯  ′  conversion convert _ event convert _ info _ units convert _ interpretation Figure 4 . 11 : Editing system ( Sect . 4 . 1 ) and interpretation system ( Sect . 4 . 2 ) interconnected via signal conversion functions convert _ event ( Eq . 4 . 99 ) , convert _ info _ units ( Eq . 4 . 102 ) , and convert _ interpretation ( Eq . 4 . 105 ) . Possible algorithms that realize this mapping of spatial symbol properties ( Eq . 4 . 57 ) to 8 - tuples of slabs ( Eq . 4 . 74 ) shall not be deﬁned here . The third and last conversion function besides convert _ event ( Eq . 4 . 99 ) and convert _ info _ units ( Eq . 4 . 102 ) is convert _ interpretation : convert _ interpretation : I h N 0 i → I h N 0 i , I 7→ I ( 4 . 105 ) In our special case there is no need for modifying interpretations before they get transmitted to application level . For our prototypical spatial hypermedia system we assume , that feedback provided by interpretation systems is used for graphical display only ( i . e . , as input for viewing components ) . For this , original I ∈ I h N 0 i as generated by merge ( see Alg . 7 ) is perfectly suﬃcient . That is why we deﬁne convert _ interpretation as an identical mapping I 7→ I . When we merge Fig . 4 . 3 ( editing system ) , Fig . 4 . 6 ( interpretation system ) and Fig . 4 . 10 ( conversion ) together , we get what is illustrated in Fig . 4 . 11 . Following this model , one could understand spatial hypermedia applications as dynamic , 91 Chapter 4 . Prototype Interpretation System merge       parser 0 parser 1 parser n ⋯ Figure 4 . 12 : The core of every interpretation system are integrated parsing components implementing highly specialized parsing algorithms . graphical and intelligent information systems that only “come to life” through user interaction . Activities in the visual information space are quasi the “pulse” of spatial hypermedia systems . 4 . 4 Parsers Spatial hypermedia systems can be deﬁned as composites of editing systems ( Sect . 4 . 1 ) and interpretation systems ( Sect . 4 . 2 ) . Editing systems are mainly determined by workspace models as described in Sect . 4 . 1 . 3 , whereas interpre - tation systems are primarily deﬁned by parsing algorithms . In other words , the core of every editing system is an information workspace and the heart of an in - terpretation system are integrated parsing components . On several occasions , we have already pointed out the importance of parsers for spatial hyperme - dia systems . According to Chapter . 3 and Sect . 4 . 2 , only structural analyses make a visual editor a fully - ﬂedged spatial hypermedia system . Thus , spatial parsers are of particular relevance to our system model . However , except for our informal descriptions in Sect . 1 . 3 and Sect . 1 . 5 and apart from our general considerations from Chapter . 3 no further explanations on the functionality of spatial parsers were given so far . Although being crucial for our system de - sign , our model ( see Fig . 4 . 12 ) is still missing some explicit and formal parser deﬁnition . This section is intended to change that . 4 . 4 . 1 Generic Parser Model As we know already from Sect . 4 . 2 . 4 , interpretation systems generalize the traditional concept of spatial parsing as we discussed it in Sect . 1 . 3 . Parsers included in interpretation systems do not label their output with pre - deﬁned 92 4 . 4 . Parsers     Parser   fade parse     + 1 Figure 4 . 13 : Parsers are dynamic systems determined by two components : parse and fade semantic types ( such as stack , heap , table etc . ) . In contrast to parsers in VIKI , VKB ( Sect . 1 . 5 . 1 ) etc . they are not designed as conﬁgurable structure experts or independent structure recognizers . They rather analyse one and the same structure ( s ) from diﬀerent perspectives ( such as spatial , visual , temporal , or content - related ) . Figuratively speaking , diﬀerent parsers view spatial hypertext through diﬀerent “glasses” and thus realise a kind of multi - level ﬁltering of structure . With this abstraction we expect to cover a much greater range of more general structures than possible with pattern - based approaches . Although our parsers analyse diﬀerent attributes with diﬀerent heuristics , they still have some characteristics in common . This allows us to deﬁne a generic parser model . Just like interpretation systems as a whole , also included parsers transform ingoing sequences of edit steps ( e , D ) ∈ ( E h Ω i× D h Ω , k i ) ( see Eq . 4 . 71 ; Eq . 4 . 85 ) into outgoing sequences of interpretations I ∈ I h Ω i ( Eq . 4 . 90 ) :  0  0 ,  1  1 , … ,       Parser  0 ,  1 , … ,    Therefore , both , interpretation systems and integrated parsers have more or less the same system interfaces . However , what diﬀerentiates them is their internal structure . Thus , we deﬁne parsers as dynamic systems determined by two components ( Fig . 4 . 13 ) : ( 1 ) parse and ( 2 ) fade . With parse we specify for selected perspectives ( such as spatial , visual etc . ) how to infer the strength of pairwise object relations and therefore how to create structural interpretations . Thus , parse contains the real parsing algorithm . The downstream function fade is to be understood as a sort of post - processor . 93 Chapter 4 . Prototype fade should post - process or rather ﬁnish interpretation results that were previ - ously generated by parse . Basically , this subsequent processing of parse results is supposed to work as follows : When parse cannot detect a relation between two objects , then the fading - module checks if there is still a connection known from a previous parser run . If the parser can “remember” such a relationship with a weight > 0 . 0 , then that old weight gets multiplied by a given fading factor ( which we will denote as α ) and is treated as our current parse result . If , however , there is no such relationship , or if the product of previous weight and fading factor α reaches a pre - deﬁned fading limit β , then we still accept the result of the current parser run . This means , then we accept that there is no perceivable association . In short , the “fading - feature” makes it possible , that associations which are not recognized anymore , do not simply get omitted . Instead , they fade away . Or in other words , the parser slowly “forgets” outdated associations . In this regard fade extends our parser model by some short - term memory . A similar aging - feature for viewport positions and motion paths in visual workspaces has been presented in [ 6 ] . This extension makes our parser model perfectly suited for the detection of destroyed structures , as we discussed them in Sect . 3 . 2 . We deﬁne our generic parser model using the following automaton : A P h Ω , n , α , β , Φ , ϕ i =       S P h Ω i , E P h Ω , n i , O P h Ω i , T P h Ω , n , α , β , Φ , ϕ i , G P h Ω , n , α , β , Φ , ϕ i , s init        ( 4 . 106 ) The generic Parser Automaton A P is a six - tuple , whose components are deter - mined by six parameters : Ω , n , α , β , Φ , and ϕ . Ω is the basic set of information units , as it was used already when we deﬁned E h Ω i ( Eq . 4 . 71 ) , D h Ω , k i ( Eq . 4 . 85 ) or I h Ω i ( Eq . 4 . 90 ) . n ∈ { 8 , 16 , 32 , . . . } shall be the bounding volume parameter , which is , according to Eq . 4 . 85 , expected by D h Ω , n i . Here we use n instead of k to avoid name collisions . α , β ∈ { 0 . 0 , . . . , 1 . 0 } are the previously mentioned conﬁguration parameters for the fade - post processor , that is , fading factor α and fading limit β . Φ is a set of event categories deﬁning when to trigger a full reparse ( for this see our deﬁnition of operation ﬂags in Eq . 4 . 71 ) . The last parameter ϕ shall be a mapping ( I h Ω i × E h Ω i × D h Ω , n i ) → I h Ω i deﬁning the core - parsing algorithm ; that is , the algorithm behind the system component parse . This is intended to keep the parser’s structure detection algorithm variable and therefore our theoretical model as ﬂexible as possible . 94 4 . 4 . Parsers These four constraints are summarized again in Eq . 4 . 107 : n ∈ { 8 , 16 , 32 , . . . } α , β ∈ { 0 . 0 , . . . , 1 . 0 } ϕ : (cid:0) I h Ω i × E h Ω i × D h Ω , n i (cid:1) → I h Ω i Φ ⊆   CREATE , MODIFY _ SPATIAL , MODIFY _ VISUAL , MODIFY _ CONTENT , DELETE , ε   ( 4 . 107 ) Just like full interpretation systems , also included parsers A P are to accept edit steps ∈ ( E h Ω i × D h Ω , n i ) as input and generate interpretations ∈ I h Ω i as output . This is why we set E P h Ω , n i to ( E h Ω i × D h Ω , n i ) and O P h Ω i to I h Ω i . The set of possible states the parser automaton may pass through shall be equal to ( I h Ω i × I h Ω i ) . In its initial state A P includes only empty interpretations , hence s init is set to ( I ε , I ε ) . S P h Ω i = I h Ω i × I h Ω i E P h Ω , n i = E h Ω i × D h Ω , n i O P h Ω i = I h Ω i s init = ( I ε , I ε ) ∈ S P h Ω i ( 4 . 108 ) Based on this , we can deﬁne the transition function T P as follows : T P h Ω , n , α , β , Φ , ϕ i : (cid:0) S P h Ω i × E P h Ω , n i (cid:1) → S P h Ω i , (cid:16) ( I , J ) , ( e , D ) (cid:17) 7→ (cid:0) I ′ , J ′ (cid:1) , I ′ = parse ( I , e , D ) J ′ = fade (cid:0) J , I ′ (cid:1) ( 4 . 109 ) T P maps pairs of states ( I , J ) ∈ S P h Ω i and input signals ( e , D ) ∈ E P h Ω , n i to subsequent states ( I ′ , J ′ ) ∈ S P h Ω i . This mapping or rather this transition from ( I , J ) to ( I ′ , J ′ ) takes place in two steps : Firstly , parse transforms inter - pretation I into I ′ , considering the ingoing edit step ( e , D ) . One could also say , that parse switches the ﬁrst half of the current state I to I ′ . In a second step , we map I ′ together with the remaining J to J ′ . This is accomplished by J ′ = fade (cid:0) J , I ′ (cid:1) . By this means T P connects both functions parse and fade in series and thus realises a two - stage state transition from ( I , J ) ∈ S P h Ω i to ( I ′ , J ′ ) ∈ S P h Ω i . The included auxiliary function parse can be seen as a conditional call of the parsing function ϕ ( Eq . 4 . 107 ) . It thus controls when to perform a reparse and 95 Chapter 4 . Prototype when to keep previous parse results instead : parse : (cid:0) I h Ω i × E h Ω i × D h Ω , n i (cid:1) → I h Ω i , ( I , e , D ) 7→ I ′ = ( ϕ ( I , e , D ) , if e . operation ∈ Φ I , else ( 4 . 110 ) A full reparse happens only if e . operation ∈ Φ ( Eq . 4 . 107 ) . Only when the assigned event category e . operation identiﬁes a given input event e as reparse event , then the ingoing triple ( I , e , D ) gets mapped to ϕ ( I , e , D ) . If , however , e . operation is not an element of Φ , then previous interpretation I is used as function value instead ; that is parse ( I , e , D ) = I . The second function , besides parse ( Eq . 4 . 110 ) , that plays an important role for the deﬁnition of T P ( Eq . 4 . 109 ) is fade . fade maps pairs of interpretations ( ( U 0 , A 0 , w 0 ) , ( U 1 , A 1 , w 1 ) ) to triples ( U 1 , A 1 , w ′ ) ; expressed formally : fade : (cid:0) I h Ω i × I h Ω i (cid:1) → I h Ω i , (cid:16) ( U 0 , A 0 , w 0 ) , ( U 1 , A 1 , w 1 ) (cid:17) 7→ (cid:0) U 1 , A 1 , w ′ (cid:1) ( 4 . 111 ) ( U 0 , A 0 , w 0 ) shall be understood as the ( temporal ) predecessor of ( U 1 , A 1 , w 1 ) . This means , ( U 0 , A 0 , w 0 ) is part of the ( still ) up - to - date parser state , whereas ( U 1 , A 1 , w 1 ) already represents a new ( internal ) parse result ; for details on this see fade ( J , I ′ ) in Eq . 4 . 109 . U 1 and A 1 can be copied directly into the result triple . Only weighting function w ′ needs recalculation . It is set up as follows : w ′ : A 1 → { ε , 0 . 0 , . . . , 1 . 0 } , ∀ a ∈ A 1 : w ′ ( a ) =    fade ′ (cid:16) w 0 ( a ) , w 1 ( a ) (cid:17) , if a ∈ A 0 w 1 ( a ) , else ( 4 . 112 ) For better legibility , we decided to split the deﬁnition of fade up into three parts : fade , which is given above , fade ′ ( Eq . 4 . 113 ) and fade ′′ ( Eq . 4 . 114 ) . Eq . 4 . 112 is to be understood as follows : When a given a ∈ A 1 is also element of A 0 , then both w 0 ( a ) and w 1 ( a ) and thus also fade ′ ( w 0 ( a ) , w 1 ( a ) ) are deﬁned . Then we can set w ′ ( a ) = fade ′ ( w 0 ( a ) , w 1 ( a ) ) . Or in other words , when associa - tions a are included in both , current interpretation graph ( U 1 , A 1 , w 1 ) as well as in its predecessor ( U 0 , A 0 , w 0 ) , then w ′ ( a ) can be set equal to fade ′ ( w 0 ( a ) , w 1 ( a ) ) . If , however , a is element of A 1 but not of A 0 , then it can be assumed that a is new ; that is , association a must have been introduced with the last time step ( e . g . , by adding new information units to the workspace ) . In this case the new weight w 1 ( a ) is taken over into the result graph without modiﬁcation , that is w ′ ( a ) = w 1 ( a ) . Deleted associations are excluded from the outset by copying U 1 , A 1 directly into the result triple ( U 1 , A 1 , w ′ ) . With ( U 1 , A 1 , w ′ ) we simply drop associations a which are ∈ A 0 but not ∈ A 1 anymore . 96 4 . 4 . Parsers fade ′ accepts pairs of weights ( x 0 , x 1 ) , checks whether they allow for reasonable fading , and provides either fade ′′ ( x 0 , x 1 ) or x 1 as result . Here x 0 represents the ( temporal ) predecessor of x 1 ( for this see Eq . 4 . 112 ) . fade ′ : (cid:16) { ε , 0 . 0 , . . . , 1 . 0 } × { ε , 0 . 0 , . . . , 1 . 0 } (cid:17) → { ε , 0 . 0 , . . . , 1 . 0 } , ∀ x 0 , x 1 ∈ { ε , 0 . 0 , . . . , 1 . 0 } : fade ′ ( x 0 , x 1 ) = ( fade ′′ ( x 0 , x 1 ) , if ( x 0 6 = ε ) ∧ (cid:0) x 1 ∈ { ε , 0 } (cid:1) x 1 , else ( 4 . 113 ) Only if fading of weights is necessary ( x 1 ∈ { ε , 0 } ) and also possible ( x 0 6 = ε ) , then we continue our calculation with fade ′′ ( x 0 , x 1 ) . Otherwise , current weight x 1 is used as result ; that is fade ′ ( x 0 , x 1 ) = x 1 . The Fading Core - Algorithm is deﬁned by fade ′′ : fade ′′ accepts weights x 0 ∈ { 0 . 0 , . . . , 1 . 0 } and x 1 ∈ { ε , 0 } and maps them to values ∈ { ε , 0 . 0 , . . . , 1 . 0 } : fade ′′ : (cid:16) { 0 . 0 , . . . , 1 . 0 } × { ε , 0 } (cid:17) → { ε , 0 . 0 , . . . , 1 . 0 } , ∀ ( x 0 , x 1 ) ∈ (cid:16) { 0 . 0 , . . . , 1 . 0 } × { ε , 0 } (cid:17) : fade ′′ ( x 0 , x 1 ) = ( x 0 × α , if ( x 0 × α ) ≥ β x 1 , else ( 4 . 114 ) When the product of old weight x 0 and fading factor α becomes greater or equal to fading limit β ( Eq . 4 . 107 ) , then we accept x 0 × α as “faded” weighting . Otherwise x 1 remains unchanged ; that is fade ′′ ( x 0 , x 1 ) = x 1 . This is best explained with an example . Let us assume that there are two interpretations given : I 0 = ( U 0 , A 0 , w 0 ) ; I 1 = ( U 1 , A 1 , w 1 ) U 0 , U 1 and A 0 , A 1 shall be deﬁned as follows : U 0 = U 1 = { u 0 , u 1 , u 2 } ; A 0 = A 1 =   { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }   Weighting functions w 0 , w 1 are given as : w 0 =    (cid:0) { u 0 , u 1 } , 1 . 0 (cid:1) , (cid:0) { u 0 , u 2 } , 1 . 0 (cid:1) , (cid:0) { u 1 , u 2 } , 0 . 0 (cid:1)    ; w 1 =    (cid:0) { u 0 , u 1 } , 1 . 0 (cid:1) , (cid:0) { u 0 , u 2 } , 0 . 0 (cid:1) , (cid:0) { u 1 , u 2 } , ε (cid:1)    97 Chapter 4 . Prototype  0  1  2 1 . 0 1 . 0 è  0  1  2 1 . 0  0  1  2 1 . 0  0 =  0 ,  0 ,  0  1 =  1 ,  1 ,  1 (cid:1858)  (cid:1856)   0 ,  1 =  1 ,  1 ,  ′   Figure 4 . 14 : Two sample interpretations I 0 = ( U 0 , A 0 , w 0 ) and I 1 = ( U 1 , A 1 , w 1 ) processed by fade ( I 0 , I 1 ) ( Eq . 4 . 111 ) . Fading factor α is set to 0 . 95 and fading limit β is 0 . 05 . Having set fading factor α = 0 . 95 and fading limit β = 0 . 05 , fade ( I 0 , I 1 ) pro - vides a result triple ( U 1 , A 1 , w ′ ) , where w ′ is formed as follows : w ′ =          { u 0 , u 1 } , fade ′ w 0 (cid:0) { u 0 , u 1 } (cid:1) , w 1 (cid:0) { u 0 , u 1 } (cid:1) ! = fade ′ 1 . 0 , 1 . 0 ! = 1 . 0   ,   { u 0 , u 2 } , fade ′′ w 0 (cid:0) { u 0 , u 2 } (cid:1) , w 1 (cid:0) { u 0 , u 2 } (cid:1) ! = fade ′′ 1 . 0 , 0 . 0 ! = 1 . 00 × 0 . 95 = 0 . 95   ,   { u 1 , u 2 } , fade ′′ w 0 (cid:0) { u 1 , u 2 } (cid:1) , w 1 (cid:0) { u 1 , u 2 } (cid:1) ! = fade ′′ 0 . 0 , ε ! = ε        Thus , w ′ becomes : w ′ =     (cid:0) { u 0 , u 1 } , 1 . 00 (cid:1) , (cid:0) { u 0 , u 2 } , 0 . 95 (cid:1) , (cid:0) { u 1 , u 2 } , ε (cid:1)     This is also illustrated graphically in Fig . 4 . 14 . Both auxiliary algorithms parse ( Eq . 4 . 110 ) and fade ( Eq . 4 . 111 ) are integral components of the transition function T P ( Eq . 4 . 109 ) . T P , in turn , can be found again in A P ’s output function G P : G P h Ω , n , α , β , Φ , ϕ i : (cid:0) S P h Ω i × E P h Ω , n i (cid:1) → O P h Ω i , (cid:16) s , ( e , D ) (cid:17) 7→ J , ( I , J ) = T P h Ω , n , α , β , Φ , ϕ i (cid:16) s , ( e , D ) (cid:17) ( 4 . 115 ) Here , T P determines for a given state s and input ( e , D ) the successor state to s , which is denoted as ( I , J ) . The second tuple element of this successor state J is used as return value . From Eq . 4 . 109 we know , that J needs to be a function value of fade ( Eq . 4 . 111 ) . Thus G P provides “faded” interpretations as output . Whether or how this inﬂuences parse results can be controlled via two 98 4 . 4 . Parsers     Parser       fade     + 1 parse (cid:1836)  (cid:1836)  + 1   Figure 4 . 15 : Blockdiagram of generic parser model A P as deﬁned in Eq . 4 . 106 tuning parameters α and β . As an example , α = 0 . 0 , β = 1 . 0 would deactivate the fading mechanism , since condition ( x 0 × α ) ≥ β from Eq . 4 . 114 cannot be satisﬁed for any x 0 . In this case fade would map ( ( U 0 , A 0 , w 0 ) , ( U 1 , A 1 , w 1 ) ) to ( U 1 , A 1 , w 1 ) ; hence G P delivers the latest ( unfaded ) result provided by parse . How G P ( Eq . 4 . 115 ) , embedded transition function T P ( Eq . 4 . 109 ) , as well as their integral components parse ( Eq . 4 . 110 ) and fade ( Eq . 4 . 111 ) are combined is best illustrated with a blockdiagram . Such a diagram can be found in Fig . 4 . 15 . We can conclusively summarize the behaviour of such dynamic parsing systems as follows : Parsers deﬁned by A P h Ω , n , α , β , Φ , ϕ i ( Eq . 4 . 106 ) accept ingoing sequences of edit steps V ( 0 . . . k e ) , where . . . V ( 0 . . . k e ) = (cid:0) v 0 , v 1 , . . . , v k e (cid:1) = (cid:18) e 0 D 0 (cid:19) , (cid:18) e 1 D 1 (cid:19) , . . . , (cid:18) e k e D k e (cid:19) ! , v k ∈ E P h Ω , n i , k = 0 , 1 , . . . , k e ( 4 . 116 ) Driven by V ( 0 . . . k e ) they pass through states S ( 0 . . . k e + 1 ) , S ( 0 . . . k e + 1 ) = (cid:0) s 0 , s 1 , . . . , s k e + 1 (cid:1) = (cid:18) I 0 J 0 (cid:19) , (cid:18) I 1 J 1 (cid:19) , . . . , (cid:18) I k e + 1 J k e + 1 (cid:19) ! , s 0 = s init , s k + 1 = T P h Ω , n , α , β , Φ , ϕ i ( s k , v k ) , k = 0 , 1 , . . . , k e ( 4 . 117 ) 99 Chapter 4 . Prototype . . . and ﬁnally they generate sequences of interpretations I ( 0 . . . k e ) as output : I ( 0 . . . k e ) = (cid:0) I 0 , I 1 , . . . , I k e (cid:1) , I k = G P h Ω , n , α , β , Φ , ϕ i ( s k , v k ) , k = 0 , 1 , . . . , k e ( 4 . 118 ) 4 . 4 . 2 Spatial Parser Parsers deﬁned by A P h Ω , n , α , β , Φ , ϕ i ( Eq . 4 . 106 ) do not classify structures ac - cording to predeﬁned patterns ; that is , they do not label their output as stacks , heaps , tables or other semantic types . They rather analyze the strength of pair - wise object relations and hence deliver weighted networks of objects ∈ I h Ω i , as deﬁned in Eq . 4 . 90 . Such analyses can be performed with regard to diﬀerent structural aspects . This includes spatial relationships . We mentionated that already in Sect . 1 . 4 when we discussed common structure types . Parsers that are specialized in analysing spatial properties of spatial hypertext and further - more build on our theoretical parser model from Eq . 4 . 106 are hereafter referred to as “spatial parsers” . Let Φ S be a set of event categories that indicate when to perform a full spatial parse . For this see our deﬁnitions of parse in Eq . 4 . 110 and Φ in Eq . 4 . 107 . Φ S =     CREATE , MODIFY _ SPATIAL , DELETE     ( 4 . 119 ) According to this deﬁnition of Φ S , a full reparse only happens in three cases : ( 1 ) when new information units were added to a workspace and thus spatial structure might have changed ; then the indicator CREATE is used ; ( 2 ) when spatial symbol properties got modiﬁed , due to translation , scaling etc . ; this is signaled by MODIFY _ SPATIAL and ( 3 ) information units were removed , which might have destroyed spatial structure ; this is indicated by DELETE . Assuming that our spatial parsing algorithm is deﬁned by some function parse S : ( I h Ω i × E h Ω i × D h Ω , k i ) → I h Ω i , we can use Φ S from Eq . 4 . 119 to par - tially reﬁne A P h Ω , n , α , β , Φ , ϕ i ( Eq . 4 . 106 ) , T P h Ω , n , α , β , Φ , ϕ i ( Eq . 4 . 109 ) , and G P h Ω , n , α , β , Φ , ϕ i from Eq . 4 . 115 as follows : A S h Ω , n , α , β i : = A P h Ω , n , α , β , Φ S , parse S i T S h Ω , n , α , β i : = T P h Ω , n , α , β , Φ S , parse S i G S h Ω , n , α , β i : = G P h Ω , n , α , β , Φ S , parse S i ( 4 . 120 ) This way our generic parser model A P h Ω , n , α , β , Φ , ϕ i turns into a parame - terised model for spatial parsers A S h Ω , n , α , β i . 100 4 . 4 . Parsers     Spatial Parser  (cid:1845)  (cid:1845)  (cid:1845) fade     + 1 parse (cid:1836)  (cid:1836)  + 1   Figure 4 . 16 : Blockdiagram of spatial parser model A S as deﬁned in Eq . 4 . 121 For our research prototype we speciﬁed in Sect . 4 . 1 . 4 several reﬁnements of our workspace model A W ( Eq . 4 . 66 ) . In Sect . 4 . 3 this has led to . . . Ω = N 0 and k = 16 . Both parameters can be used now for reﬁning or rather conﬁguring A S h Ω , n , α , β i , T S h Ω , n , α , β i and G S h Ω , n , α , β i . As an example we set α , β to . . . α = 0 . 95 and β = 0 . 05 . This results in the following default conﬁguration for spatial parsers A S : A S : = A S h N 0 , 16 , 0 . 95 , 0 . 05 i T S : = T S h N 0 , 16 , 0 . 95 , 0 . 05 i G S : = G S h N 0 , 16 , 0 . 95 , 0 . 05 i ( 4 . 121 ) If one substitutes now in Fig . 4 . 15 components A P , T P and G P for A S , T S and G S from Eq . 4 . 121 , then one gets the blockdiagram in Fig . 4 . 16 . 101 Chapter 4 . Prototype Three - Stage Spatial Parsing Algorithm According to our considerations from Sect . 2 . 1 ( page 30 ) , spatial parsers should rather imitate humans in the way they perceive structure than checking a canvas against pre - deﬁned and supposedly universal patterns ( such as heaps , piles , stacks etc . ) . In human perception , atomic objects are recognized ﬁrst and more complex structures emerge from simpler ones , not vice - versa . This bottom - up principle gets also reﬂected in our spatial parsing algorithm : parse S : (cid:0) I h Ω i × E h Ω i × D h Ω , k i (cid:1) → I h Ω i , ( I , e , D ) 7→ normalize (cid:16) parse _ list _ structures (cid:0) create _ terminals ( D ) (cid:1)(cid:17) ( 4 . 122 ) parse S follows our requirement from Eq . 4 . 107 and maps triples ( I , e , D ) ∈ ( I h Ω i × E h Ω i × D h Ω , n i ) to interpretations ∈ I h Ω i . This mapping proceeds in three stages : Firstly , create _ terminals ( D ) converts info unit data D ∈ D h Ω , k i into a collection of terminal symbols . In a second step , the bottom - up algo - rithm parse _ list _ structures transforms these terminals into a tree of alignment - oriented structures ( i . e . , “parse tree” ) . Finally , function normalize converts this hierarchical structure into a weighted , “ﬂat” graph ∈ I h Ω i . Note , that argu - ments I and e are not used in the current version of this algorithm . Before we go into any details on create _ terminals , parse _ list _ structures and normalize , some basic deﬁnitions are needed : The previously mentioned bottom - up parse requires internal type identiﬁca - tion of terminals and non - terminals and therefore needs deﬁnition of distinct symbols . For this purpose we introduce the discrete set StructureType : StructureType =   ATOM , UNALIGNED , HORIZONTAL _ LIST , VERTICAL _ LIST , DIAGONAL _ LIST0 , DIAGONAL _ LIST1   ( 4 . 123 ) Internally our spatial parser distinguishes between atoms , unaligned objects and collections of objects with horizontal , vertical or diagonal alignment . Anal - ogous to our deﬁnitions from Sect . 4 . 2 . 2 we make a distinction between diag - onal alignment from top - left to bottom - right ( DIAGONAL _ LIST0 ) and from top - right to bottom - left ( DIAGONAL _ LIST1 ) . More complex structure types ( such as tables , stacks , piles etc . ) have deliberately not been provided . We rather build on two of the most fundamental attributes of spatial structure and hence of spatial perception : spatial proximity and alignment . With this we intend to avoid ( potentially wrong ) over - interpretation of structure . 102 4 . 4 . Parsers As pointed out already , internally our parsing algorithm works with symbols . We denote the basic set of such parser symbols as S h Ω , k i and deﬁne it as a cartesian product : S h Ω , k i = (cid:16) ID × (cid:0) StructureType ∪ { ε } (cid:1) × Bounds h k i × (cid:0) Ω ∪ { ε } (cid:1) × List h ID i (cid:17) ( 4 . 124 ) Here , ID shall be regarded as a set of unique identiﬁers and ε represents some empty ( or NULL ) element . The deﬁnition of Bounds h k i can be found in Eq . 4 . 73 and List was introduced already with Eq . 4 . 91 . Elements of such ﬁve - tuples ∈ S h Ω , k i are denoted as follows : ∀ s ∈ S h Ω , k i : s : =       s . id , s . type , s . bounds , s . info _ unit , s . child _ ids      ( 4 . 125 ) Thus , parser symbols s ∈ S h Ω , k i have ﬁve attributes : ( 1 ) a unique identi - ﬁer s . id ∈ ID ( we will see afterwards what this is used for ) ; ( 2 ) an assigned structure type s . type ∈ ( StructureType ∪ { ε } ) ; ( 3 ) geometrical properties en - coded as s . bounds ∈ Bounds h k i ; ( 4 ) the information unit they are ( possibly ) linked with s . info _ unit ∈ ( Ω ∪ { ε } ) and ( 5 ) a list of child symbol identiﬁers s . child _ ids ∈ List h ID i ( note : our algorithm operates on symbol hierarchies ) . In the following we will frequently work with collections of symbols ⊂ S h Ω , k i and thus with the power set of S h Ω , k i . However , we will not build directly on 2 S h Ω , k i , but instead we use a constrained subset denoted as P S h Ω , k i : P S h Ω , k i =   S (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) S ∈ 2 S h Ω , k i , ∄ (cid:8) s , s ′ (cid:9) ∈ (cid:18) S 2 (cid:19) : s . id = s ′ . id   ( 4 . 126 ) P S h Ω , k i was designed to ensure , that each s contained in an S ⊆ S h Ω , k i can be clearly distinguished from other s ′ ∈ S , even though s and s ′ might have identical type , bounds etc . This makes elements of such S referenceable . From a software developer’s perspective , one could imagine S ∈ P S h Ω , k i as occupied object memory and identiﬁers assigned to s ∈ S as memory addresses or rather as pointers . At least you could implement them like this . Following this idea , our deﬁnition of P S h Ω , k i requires two basic operations : ( 1 ) create _ symbol ( Eq . 4 . 127 ) and ( 2 ) get _ symbol ( Eq . 4 . 128 ) . 103 Chapter 4 . Prototype create _ symbol :   P S h Ω , k i × (cid:0) StructureType ∪ { ε } (cid:1) × Bounds h k i × (cid:0) Ω ∪ { ε } (cid:1) × List h ID i   → S h Ω , k i , ( S , a 1 , a 2 , a 3 , a 4 ) 7→ ( id , a 1 , a 2 , a 3 , a 4 ) , ( id ∈ ID ) ∧ ( ∄ s ∈ S : s . id = id ) ( 4 . 127 ) create _ symbol accepts a set of parser symbols S ∈ P S h Ω , k i and four arguments a 1 , . . . , a 4 , that are ( according to Eq . 4 . 124 ) needed for setting up a new symbol tuple ∈ S h Ω , k i . These arguments a 1 , . . . , a 4 are then combined with some id ∈ ID , so that there is no s ∈ S for which s . id = id . This way create _ symbol ensures , that new symbols always get an identiﬁer that is not in use already in a given S ∈ P S h Ω , k i . The only thing that remains to be done , is adding new symbols s = create _ symbol ( S , a 1 , . . . , a 4 ) to S . For this , however , a statement such as S ← ( S ∪ { s } ) is completely suﬃcient . In fact , this is exactly what we use in our algorithms . Once created and added to S ∈ P S h Ω , k i , symbols s ∈ S can be retrieved again using the function get _ symbol : get _ symbol : (cid:16) P S h Ω , k i × (cid:0) ID ∪ { ε } (cid:1)(cid:17) → (cid:0) S h Ω , k i ∪ { ε } (cid:1) , ∀ ( S , id ) ∈ (cid:16) P S h Ω , k i × (cid:0) ID ∪ { ε } (cid:1)(cid:17) : get _ symbol ( S , id ) = ( s , if ( id 6 = ε ) ∧ ( ∃ ! s ∈ S : s . id = id ) ε , else ( 4 . 128 ) get _ symbol ( S , id ) tries to use a set of declared symbols S ∈ P S h Ω , k i in order to resolve a given id ∈ ( ID ∪ { ε } ) . When such an id is 6 = ε ( i . e . , it is not a “NULL pointer” ) and there is exactly one s ∈ S for which s . id = id , then get _ symbol delivers s as result . Otherwise id cannot be resolved in S , and hence ε ( “nothing” ) is returned . This way we keep get _ symbol totally deﬁned . In later algorithms we will operate on tree structures formed by parser symbols s ∈ S h Ω , k i . Hence , we will frequently work with child symbol lists s . child _ ids . Therefore , in order to decrease eﬀort of expression , it makes sense to wrap the most frequently used list - features in helper routines . We deﬁne two such auxiliary functions that are supposed to simplify child symbol access . These access operations are : ( 1 ) child _ count ( Eq . 4 . 129 ) and ( 2 ) child ( Eq . 4 . 130 ) . 104 4 . 4 . Parsers child _ count ( s ) is nothing more than a shortcut to the number of child symbols beneath s . That is , it simply takes s ’ list of child ids and detects size ( s . child _ ids ) , as deﬁned in Eq . 4 . 93 : child _ count : S h Ω , k i → N 0 , s 7→ size ( s . child _ ids ) ( 4 . 129 ) Index - based access on single child symbols can be achieved via child ( S , s , i ) . Here , s represents a parent symbol , i is a list index in s . child _ ids and S is the basic set of symbols where the child with id get ( s . child _ ids , i ) is supposed to be found . Formally we deﬁne child as follows : child : (cid:0) P S h Ω , k i × S h Ω , k i × N 0 (cid:1) → (cid:0) S h Ω , k i ∪ { ε } (cid:1) , ( S , s , i ) 7→ get _ symbol (cid:0) S , get ( s . child _ ids , i ) (cid:1) ( 4 . 130 ) Both , child _ count ( Eq . 4 . 129 ) and child ( Eq . 4 . 130 ) are merely used for nota - tional simpliﬁcation . This means , we could also do without them and use more verbose expressions instead . Our following deﬁnitions , however , are integral parts of the parsing algorithm and cannot be substituted : This includes two basic types of symbols : ( 1 ) S atom h Ω , k i ( Eq . 4 . 131 ) and ( 2 ) S struct h Ω , k i ( Eq . 4 . 132 ) . Both sets are derivatives of S h Ω , k i ( Eq . 4 . 124 ) . Symbols that can be used as structure elements , but do not describe structure themselves , are denoted as “atoms” . Formally we deﬁne them as : S atom h Ω , k i =       s (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) s ∈ S h Ω , k i , ( s . type = ATOM ) ∧   ( s . info _ unit 6 = ε ) ∧ (cid:0) child _ count ( s ) = 0 (cid:1) ∨ ( s . info _ unit = ε ) ∧ (cid:0) child _ count ( s ) = 1 (cid:1)       ⊂ S h Ω , k i ( 4 . 131 ) These are symbols s ∈ S h Ω , k i that are explicitely marked with structure type s . type = ATOM and for which either ( s . info _ unit 6 = ε ) ∧ ( child _ count ( s ) = 0 ) or ( s . info _ unit = ε ) ∧ ( child _ count ( s ) = 1 ) holds true . This means , either symbols s ∈ S atom h Ω , k i are atomic leaf nodes with s . info _ unit 6 = ε or they are internal nodes with exactly one child and without a reference to any information unit . By contrast , symbols that do represent structure are deﬁned by S struct h Ω , k i : S struct h Ω , k i =    s (cid:12)(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)(cid:12) s ∈ S h Ω , k i , ( s . type 6 = ATOM ) ∧ ( s . info _ unit = ε ) ∧ (cid:0) child _ count ( s ) > 0 (cid:1)    ⊂ S h Ω , k i ( 4 . 132 ) 105 Chapter 4 . Prototype Structure symbols s ∈ S struct h Ω , k i are tagged with a structure type 6 = ATOM ; thus the assigned value could also be ε . Additionally they must be linked with at least one child symbol as structure element . Consequently , symbols ∈ S struct h Ω , k i never can be found on leaf node level . As a last requirement , s . info _ unit should always be ε . Thus , structures do not point directly to car - riers of information in a workspace ; only their elements on leaf node level do . Creation of symbols ∈ S struct h Ω , k i is deﬁned by the following algorithm : 8 create _ structure :    P S h Ω , k i × (cid:0) StructureType \ { ATOM } ∪ { ε } (cid:1) × (cid:0) List h ID i \ { list ε } (cid:1)    →    S struct h Ω , k i ∪ { ε }    ,    S , type , ids    7→ s , 1 : s ← ε 2 : s 0 ← get _ symbol (cid:0) S , get ( ids , 0 ) (cid:1) ⊲ get ﬁrst tentitive child symbol s 0 3 : if s 0 6 = ε then 4 : b ← s 0 . bounds 5 : for i = 1 to (cid:0) size ( ids ) − 1 (cid:1) do ⊲ calculate union of all child bounds b 6 : s i ← get _ symbol (cid:0) S , get ( ids , i ) (cid:1) 7 : if s i = ε then 8 : return s 9 : end if 10 : b ← union ( b , s i . bounds ) ⊲ see : Eq . 4 . 83 for deﬁnition of union 11 : end for 12 : s ← create _ symbol ( S , type , b , ε , ids ) ⊲ new s ∈ S struct h Ω , k i 13 : end if 14 : return s create _ structure maps triples ( S , type , ids ) to structure symbols s ∈ S struct h Ω , k i ( in the fault case ε is used as return value instead ) . S is a set of predeﬁned symbols needed for resolving structure element ids , type is either a structure type 6 = ATOM or ε and the last argument ids represents a non - empty list of structure element identiﬁers . As an example , let us create a horizontal list formed from two atomic list elements ; we set . . . type = HORIZONTAL _ LIST and ids = ( s 0 , s 1 ) Both atoms s 0 , s 1 shall be given by . . . S = ( ( s 0 , ATOM , b 0 , u 0 , list ε ) , ( s 1 , ATOM , b 1 , u 1 , list ε ) ) ⊂ S atom h Ω , k i 106 4 . 4 . Parsers  2 , (cid:1834)(cid:1841)(cid:1844)   (cid:1841)(cid:1840)   (cid:1838) _ (cid:1838)  (cid:1845)  ,  (cid:1866)  (cid:1867)(cid:1866)  0 ,  1 ,  ,  0 ,  1  0 ,   (cid:1841)(cid:1839) ,  0 ,  0 ,    (cid:1872)   1 ,   (cid:1841)(cid:1839) ,  1 ,  1 ,    (cid:1872)  Figure 4 . 17 : hierarchical relationship between horizontal list s 2 and atoms s 0 , s 1 Here we assume , that ID = { s 0 , s 1 , . . . } and that Ω = { u 0 , u 1 , . . . } . This is why both attributes id and info _ unit are set to s 0 , s 1 and u 0 , u 1 respectively . b 0 , b 1 shall be arbitrary bounding volumes ∈ Bounds h k i . Their exact position and dimensions do not matter in this example . Given these deﬁnitions and assuming that create _ symbol from Eq . 4 . 127 assigns incremented symbol ids s i + 1 ∈ ID to new symbols , create _ structure ( S , type , ids ) will deliver the following : create _ structure     ( ( s 0 , ATOM , b 0 , u 0 , list ε ) , ( s 1 , ATOM , b 1 , u 1 , list ε ) ) , HORIZONTAL _ LIST , ( s 0 , s 1 )      =     s 2 , HORIZONTAL _ LIST , union ( b 0 , b 1 ) , ε , ( s 0 , s 1 )     The apparent hierarchical relationship between horizontal list s 2 and atoms s 0 , s 1 is illustrated in Fig . 4 . 17 . As already pointed out at the beginning , our spatial parsing algorithm realises a bottom - up parse . In this context , it works with two speciﬁc categories of symbols : ( 1 ) terminal and ( 2 ) non - terminal symbols . Terminal symbols are deﬁned as atoms ∈ S atom h Ω , k i ( Eq . 4 . 131 ) that do not have child symbols . Hence , they are atomic leaf nodes : S terminal h Ω , k i = ( s (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) s ∈ S atom h Ω , k i , child _ count ( s ) = 0 ) ⊂ S atom h Ω , k i ( 4 . 133 ) The power set of S terminal h Ω , k i can be deﬁned as a subset of P S h Ω , k i ( Eq . 4 . 126 ) : P terminal h Ω , k i = ( S (cid:12) (cid:12)(cid:12)(cid:12)(cid:12) S ∈ P S h Ω , k i , S ⊂ S terminal h Ω , k i ) ⊂ P S h Ω , k i ( 4 . 134 ) 107 Chapter 4 . Prototype The following operation speciﬁes how terminal symbols are instantiated : create _ terminal : (cid:0) P S h Ω , k i × Bounds h k i × Ω (cid:1) → S terminal h Ω , k i , ( S , b , u ) 7→ create _ symbol ( S , ATOM , b , u , list ε ) ( 4 . 135 ) The non - terminal counterpart to S terminal h Ω , k i is S nonterminal h Ω , k i . Non - terminals either can be structure symbols S struct h Ω , k i or non - terminal atoms ( S atom h Ω , k i \ S terminal h Ω , k i ) : S nonterminal h Ω , k i = S struct h Ω , k i ∪ (cid:0) S atom h Ω , k i \ S terminal h Ω , k i (cid:1) ( 4 . 136 ) Similar to Eq . 4 . 134 , also the power set of S nonterminal h Ω , k i can be expressed as a subset of P S h Ω , k i ( Eq . 4 . 126 ) : P nonterminal h Ω , k i = ( S (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) S ∈ P S h Ω , k i , S ⊂ S nonterminal h Ω , k i ) ⊂ P S h Ω , k i ( 4 . 137 ) Spatial Parsing Algorithm – Stage 1 – Creation of Terminal Symbols Based on Eq . 4 . 134 and Eq . 4 . 135 we describe the ﬁrst step of our three - stage spatial parsing algorithm parse S ( Eq . 4 . 122 ) as follows : 9 create _ terminals : D h Ω , k i → P terminal h Ω , k i , ( V , p ) 7→ S , 1 : S ← ∅ 2 : for all u ∈ V do 3 : S ← S ∪ n create _ terminal (cid:0) S , p ( u ) . bounds , u (cid:1) o ⊲ see : Eq . 4 . 135 4 : end for 5 : return S create _ terminals takes a “map” ( V , p ) ∈ D h Ω , k i ( Eq . 4 . 85 ) and creates for each information unit u ∈ V a new terminal symbol ∈ S terminal h Ω , k i ( Eq . 4 . 133 ) . Following Eq . 4 . 135 only information unit u and the assigned bounding volume p ( u ) . bounds are needed for this . Terminals created this way are collected in some S ∈ P terminal h Ω , k i ( Eq . 4 . 134 ) . As an example , let us assume that ( V , p ) deﬁnes two red rectangles with ids u 0 and u 1 ( provided that Ω = { u 0 , u 1 , . . . } ) : ( V , p ) =   { u 0 , u 1 } ,   (cid:16) u 0 , (cid:0) b 0 , 0 , RECTANGLE , ( 255 , 0 , 0 ) , “ content0 ” (cid:1)(cid:17) , (cid:16) u 1 , (cid:0) b 1 , 0 , RECTANGLE , ( 255 , 0 , 0 ) , “ content1 ” (cid:1)(cid:17)     108 4 . 4 . Parsers Both objects are located on the same layer 0 and their content is set to string literals “ content0 ” and “ content1 ” respectively . b 0 , b 1 are arbitrary bounding volumes ∈ Bounds h k i . Assuming again , that ID = { s 0 , s 1 , . . . } , create _ terminals transforms this deﬁ - nition of ( V , p ) into the following set of terminal symbols S : S = ( ( s 0 , ATOM , b 0 , u 0 , list ε ) , ( s 1 , ATOM , b 1 , u 1 , list ε ) ) ∈ P terminal h Ω , k i Apparently , we adopted here only spatial properties in form of bounding vol - umes b 0 , b 1 into the newly generated atoms . Other attributes ( such as layer , shape , color , content etc . ) are of no relevance to our spatial analysis and were therefore discarded . In the second stage of our spatial parsing algorithm , terminals generated ac - cording to Alg . 9 undergo a bottom - up analysis ( see parse S in Eq . 4 . 122 ) . Before we describe how such parse _ list _ structures ( create _ terminals ( ( V , p ) ) ) or rather parse _ list _ structures ( S ) proceeds , let us ﬁrst deﬁne a series of required auxiliary structures : With our previous deﬁnitions of parser symbols S h Ω , k i ( Eq . 4 . 124 ) it is already possible to describe symbol hierarchies ( i . e . , trees of symbols ) . For this , see in particular create _ structure from Alg . 8 . Symbol trees are inextricably linked with bottom - up parsing and thus play an important role for the second phase of our three - stage spatial parsing algorithm . Therefore , in parse _ list _ structures we will make intensive use of our previous deﬁnitions on hierarchical linking of symbols . In addition to this , however , we need another alternative formalism for deﬁning trees . This is described below . In the following we will repeatedly work with ( rooted ) out - trees ; that is , with trees having the following properties : OutTree h Q i : set of all ( rooted ) out - trees T : = ( V , E , r ) , V ( T ) : non - empty set of vertices ; (cid:0) V ( T ) 6 = ∅ (cid:1) ∧ (cid:0) V ( T ) ⊆ Q (cid:1) E ( T ) : set of directed edges (cid:0) v i , v j (cid:1) , v i , v j ∈ V ( T ) r ( T ) : root vertext of T ( i . e . , r ∈ V ( T ) , d − T ( r ) = 0 ∧ d + T ( r ) ≥ 0 ) ( 4 . 138 ) In total there are four operations on trees T ∈ OutTree h Q i that will be of rele - vance to our parsing algorithm : ( 1 ) leafs ( Eq . 4 . 139 ) ; ( 2 ) children ( Eq . 4 . 140 ) ; ( 3 ) level ( Eq . 4 . 141 ) and ( 4 ) add _ child ( Eq . 4 . 142 ) . 109 Chapter 4 . Prototype The ﬁrst operation leafs detects leaf nodes in out trees . This means , it takes a given T ∈ OutTree h Q i and delivers the set of all vertices v ∈ V ( T ) which do not have any children ; that is , for which d + T ( v ) = 0 . For example , leafs ( ( { r } , ∅ , r ) ) would return { r } . leafs : OutTree h Q i → 2 Q , T 7→ n v (cid:12)(cid:12)(cid:12) v ∈ V ( T ) ∧ d + T ( v ) = 0 o ( 4 . 139 ) Access on a node’s child vertices is deﬁned by function children . It accepts a T ∈ OutTree h Q i and a vertex v ∈ Q and returns the set of all vertices that are marked in E ( T ) as children of v . If v is / ∈ V ( T ) or if v ∈ leafs ( T ) then ∅ is returned . A good example for this would be children ( ( { r } , ∅ , r ) , r ) = ∅ . children : (cid:0) OutTree h Q i × Q (cid:1) → 2 Q , ( T , v ) 7→ n v ′ (cid:12) (cid:12) (cid:12) ∃ ! (cid:0) v , v ′ (cid:1) ∈ E ( T ) o ( 4 . 140 ) Levels of vertices v in trees T ∈ OutTree h Q i are determined by level ( T , v ) . For this we assume , that there is some function DISTANCE ( v 0 , v 1 , G ( V , E ) ) deﬁned , which can tell us the length of the shortest path from vertex v 0 to v 1 in a given graph G ( V , E ) . Here we also assume , that such a function is only deﬁned for v 0 , v 1 ∈ V . As an example , level ( T , r ( T ) ) would be 0 , since DISTANCE ( r ( T ) , r ( T ) , G ( V ( T ) , E ( T ) ) ) = 0 either . level : (cid:0) OutTree h Q i × Q (cid:1) ⇀ N 0 , ( T , v ) 7→ DISTANCE (cid:16) r ( T ) , v , G (cid:0) V ( T ) , E ( T ) (cid:1)(cid:17) , v ∈ V ( T ) ( 4 . 141 ) The last OutTree h Q i - “method” is add _ child . Applied on a given out tree T , add _ child ( T , v , v ′ ) extends T by a new leaf node v ′ . The second argument v in - dicates the vertex , beneath which v ′ is to be inserted . add _ child ( ( { r } , ∅ , r ) , r , v ) , for instance , would result in ( { r , v } , { ( r , v ) } , r ) . add _ child : (cid:0) OutTree h Q i × Q × Q (cid:1) ⇀ OutTree h Q i , (cid:0) T , v , v ′ (cid:1) 7→ (cid:16) V ( T ) ∪ (cid:8) v ′ (cid:9)(cid:17) , (cid:18) E ( T ) ∪ n(cid:0) v , v ′ (cid:1)o(cid:19) , r ( T ) ! , v ∈ V ( T ) ∧ v ′ / ∈ V ( T ) ( 4 . 142 ) Note , that in the following we will not work directly with OutTree h Q i but with a reﬁned subset denoted as T I h Ω , k i : T I h Ω , k i ⊂ OutTree h P S h Ω , k ii ( 4 . 143 ) Apparently , subset T I h Ω , k i identiﬁes speciﬁc out trees whose vertices are full sets of parser symbols rather than simple objects . That is , the tree node - “type” is P S h Ω , k i . For details see our deﬁnition of P S h Ω , k i in Eq . 4 . 126 . 110 4 . 4 . Parsers Each so - called “Interpretation Tree” T ∈ T I h Ω , k i is subject to a number of conditions : Firstly , root - vertices r of trees T shall comprise only terminal symbols , that is r ( T ) may include only symbols ∈ S terminal h Ω , k i ( Eq . 4 . 133 ) . Thus we deﬁne : r ( T ) ∈ P terminal h Ω , k i ( 4 . 144 ) In contrast to root r ( T ) , remaining vertices V ( T ) \ { r ( T ) } should contain only non - terminals ∈ S nonterminal h Ω , k i ( Eq . 4 . 136 ) : (cid:16) V ( T ) \ (cid:8) r ( T ) (cid:9) (cid:17) ⊂ P nonterminal h Ω , k i ( 4 . 145 ) Each parser symbol , no matter if terminal or non - terminal , may occur only once in T . Thus , for all S ∈ V ( T ) :   \ S ∈ V ( T ) S   = ∅ ( 4 . 146 ) When we denote the total set of parser symbols included in T as S Σ ( T ) and deﬁne it as follows . . . S Σ ( T ) : =   [ S ∈ V ( T ) S   ∈ P S h Ω , k i ( 4 . 147 ) . . . then ∀ s ∈ S Σ ( T ) : S Ψ ( T , s ) : =   child _ count ( s ) − 1 [ i = 0 n child (cid:0) S Σ ( T ) , s , i (cid:1)o ⊂ S Σ ( T ) ( 4 . 148 ) This means , that every single non - terminal in T has to be linked with child symbols that are also included in T . Here , S Ψ ( T , s ) represents the set of all child symbols of s in T . For a deﬁnition of child see Eq . 4 . 130 . Finally , ∀ ( S i , S j ) ∈ E ( T ) : (cid:16) 0 < (cid:12)(cid:12) S j (cid:12)(cid:12) < | S i | (cid:17) ∧     \ s ∈ S j S Ψ ( T , s )   = ∅   ∧     [ s ∈ S j S Ψ ( T , s )   = S i   ( 4 . 149 ) 111 Chapter 4 . Prototype In plain language , this means that each ( non - root ) vertex S ∈ ( V ( T ) \ { r ( T ) } ) comprises at least one symbol ( i . e . , | S | > 0 ) and child vertices S j always contain less symbols than their parents S i ( i . e . , (cid:12)(cid:12) S j (cid:12)(cid:12) < | S i | ) . Furthermore , each s ∈ S i must be assigned exactly one s ′ ∈ S j and each s ′ ∈ S j has to be assigned at least one s ∈ S i . This is best explained with an example . Suppose , we have an interpretation tree T = ( V , E , r ) ∈ T I h Ω , k i with V ( T ) , E ( T ) and r ( T ) being deﬁned as : V ( T ) = { S 0 , S 1 , S 2 , S 3 } ; E ( T ) =    ( S 0 , S 1 ) , ( S 1 , S 2 ) , ( S 0 , S 3 )    ; r ( T ) = S 0 To simplify things , we set S h Ω , k i equal to a set of symbolic placeholders s i ( for index i ≥ 0 ) : S h Ω , k i = { s 0 , s 1 , . . . } S 0 ∈ V ( T ) shall comprise three terminal symbols s 0 , s 1 , s 2 ∈ S terminal h Ω , k i : S 0 = { s 0 , s 1 , s 2 } ∈ P terminal h Ω , k i For remaining elements of V ( T ) we deﬁne : S 1 , S 2 , S 3 ∈ P nonterminal h Ω , k i In detail these sets of symbols are : S 1 = { s 3 , s 4 } ; S 2 = { s 5 } ; S 3 = { s 6 } Based on these speciﬁcations , the total set of symbols S Σ ( T ) from Eq . 4 . 147 can be determined as : S Σ ( T ) = S 0 ∪ S 1 ∪ S 2 ∪ S 3 = { s 0 , s 1 , s 2 , s 3 , s 4 , s 5 , s 6 } ∈ P S h Ω , k i Individual parent - child relations between these symbols are described below : s 0 , s 1 , s 2 are terminals ∈ S terminal h Ω , k i and therefore have no child symbols : s 0 . child _ ids = s 1 . child _ ids = s 2 . child _ ids = list ε Thus , the following should apply : S Ψ ( T , s 0 ) = S Ψ ( T , s 1 ) = S Ψ ( T , s 2 ) = ∅ For remaining s 3 , s 4 , s 5 , s 6 , however , S Ψ ( T , s i ) should be 6 = ∅ ( for 3 ≤ i ≤ 6 ) : s 3 . child _ ids = ( s 0 . id , s 1 . id ) s 4 . child _ ids = ( s 2 . id ) s 5 . child _ ids = ( s 3 . id , s 4 . id ) s 6 . child _ ids = ( s 0 . id , s 1 . id , s 2 . id ) ⇒ ⇒ ⇒ ⇒ S Ψ ( T , s 3 ) = { s 0 , s 1 } S Ψ ( T , s 4 ) = { s 2 } S Ψ ( T , s 5 ) = { s 3 , s 4 } S Ψ ( T , s 6 ) = { s 0 , s 1 , s 2 } 112 4 . 4 . Parsers ,  0 ,  1  2   = (cid:1845) 0 (cid:1845) 2 (cid:1845) 3 , (cid:1845) 1  5  3  4  6 Figure 4 . 18 : sample interpretation tree T ∈ T I h Ω , k i The interpretation tree formed from these deﬁnitions is illustrated graphically in Fig . 4 . 18 . From this illustration it becomes particularly clear that interpreta - tion trees T I h Ω , k i are composites or rather mixtures of primary and secondary structures . This means , in every T ∈ T I h Ω , k i we can diﬀerentiate between two structures , where one is embedded in the other . The primary structure in our example would be the out - tree of symbol sets deﬁned by V ( T ) , E ( T ) and r ( T ) . In Fig . 4 . 18 this is illustrated with black borders around braces that are connected by black upward pointing arrows . Embedded in this “host” - structure there is a ( directed ) graph , consisting of grey circles as nodes ( each labeled as a symbol s i ∈ S Σ ( T ) ) and grey arrows as edges pointing downwards . This sym - bol graph represents our secondary structure and is determined , as we know already from Eq . 4 . 125 , by symbol attribute s . child _ ids . Another good example for an interpretation tree would be : T = (cid:16)(cid:8) ∅ (cid:9) , ∅ , ∅ (cid:17) ∈ T I h Ω , k i This T comprises of a single vertex only , r ( T ) , which does not contain any symbols ( i . e . , r ( T ) = ∅ ) . For such a T the following applies : r ( T ) = ∅ ∈ P terminal h Ω , k i ( Eq . 4 . 144 ) ; (cid:16) V ( T ) \ (cid:8) r ( T ) (cid:9)(cid:17) = ∅ ⊂ P nonterminal h Ω , k i ( Eq . 4 . 145 ) and (cid:18) T S ∈ { ∅ } S (cid:19) = ∅ ( Eq . 4 . 146 ) ; S Σ ( T ) = ∅ ( Eq . 4 . 147 ) . This is why both is satisﬁed Eq . 4 . 148 and , since E ( T ) = ∅ , also Eq . 4 . 149 . Thus ( { ∅ } , ∅ , ∅ ) is a valid element of T I h Ω , k i . 113 Chapter 4 . Prototype For this special case of an empty interpretation tree we use a separate symbol : T I ε : = (cid:16)(cid:8) ∅ (cid:9) , ∅ , ∅ (cid:17) ∈ T I h Ω , k i ( 4 . 150 ) Our previous deﬁnition of T I h Ω , k i allows trees that may contain any number of symbols on leaf - node level . This means , T I h Ω , k i also includes trees T for which there is at least one S ∈ leafs ( T ) where | S | > 1 . But this is not always desirable , as we will see later on . At the latest when we must process the results of our bottom - up parse we will expect that each leaf node of an interpretation tree includes one and only one symbol ( i . e . , quasi as “start symbol” ) . This is why we supplement our previous deﬁnitions of trees with the following specialization : T ′ I h Ω , k i ⊂ T I h Ω , k i : T ′ I h Ω , k i = ( T (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) T ∈ T I h Ω , k i , ∀ S ∈ leafs ( T ) : | S | = 1 ) ∪ (cid:8) T I ε (cid:9) ( 4 . 151 ) A good example for such T ∈ T ′ I h Ω , k i is the tree illustrated in Fig . 4 . 18 . Since T ′ I h Ω , k i ⊂ T I h Ω , k i ⊂ OutTree h P S h Ω , k ii ⊂ OutTree h Q i , all operations that can be performed on OutTree h Q i can also be applied to T I h Ω , k i . This includes , among others , the previously deﬁned functions ( 1 ) leafs ( Eq . 4 . 139 ) ; ( 2 ) children ( Eq . 4 . 140 ) ; ( 3 ) level ( Eq . 4 . 141 ) and ( 4 ) add _ child ( Eq . 4 . 142 ) . In addition let us introduce two operations which are exclusively deﬁned on interpretation trees T I h Ω , k i : ( 1 ) child ( Eq . 4 . 152 ) and ( 2 ) leafs ( Alg . 10 ) . The ﬁrst of these functions “overloads” child from Eq . 4 . 130 : child : (cid:0) T I h Ω , k i × S h Ω , k i × N 0 (cid:1) → (cid:0) S h Ω , k i ∪ { ε } (cid:1) , ( T , s , i ) 7→ child (cid:0) S Σ ( T ) , s , i (cid:1) ( 4 . 152 ) Here we set the basic set of symbols , which is required in Eq . 4 . 128 for resolving symbol ids , to S Σ ( T ) from Eq . 4 . 147 . This way we specialize child ( S , s , i ) for usage on interpretation trees and hence the argument list changes from ( S , s , i ) to ( T , s , i ) . To give some examples , when we take our sample tree T from Fig . 4 . 18 again , then child ( T , s 3 , 1 ) would identify s 1 as the second child symbol of s 3 . Examples where we get ε as return value instead , include child ( T , s 5 , 99 ) or child ( T , s 2 , 0 ) . The second operation on T I h Ω , k i that we want to introduce is called leafs and builds on our previous deﬁnition of child from Eq . 4 . 152 . 114 4 . 4 . Parsers 10 leafs : (cid:0) T I h Ω , k i × S h Ω , k i (cid:1) ⇀ P terminal h Ω , k i , ( T , s ) 7→ S , Require : s ∈ S Σ ( T ) 1 : if child _ count ( s ) = 0 then ⊲ if s is a leaf node , then . . . 2 : return { s } ⊲ . . . s should be part of the result set 3 : end if 4 : S ← ∅ 5 : for i = 0 to (cid:0) child _ count ( s ) − 1 (cid:1) do ⊲ apply leafs on all children and . . . 6 : S ← S ∪ leafs (cid:0) T , child ( T , s , i ) (cid:1) ⊲ . . . collect result in S ∈ P terminal h Ω , k i 7 : end for 8 : return S The recursive algorithm in Alg . 10 accepts an interpretation tree T ∈ T I h Ω , k i and a symbol s ∈ S Σ ( T ) and detects the set of all terminal symbols that can be found beneath s . In other words , leafs ( T , s ) returns all leaf nodes of the symbol - subtree that starts at root - node s . If s is a leaf node itself , then leafs ( T , s ) returns { s } ∈ P terminal h Ω , k i . The leaf nodes beneath s 5 in our previous sample tree T ( Fig . 4 . 18 ) , for example , could be identiﬁed by leafs ( T , s 5 ) = { s 0 , s 1 , s 2 } . With all these deﬁnitions at hand we can ﬁnally continue with step number two of our three - stage parsing algorithm ( Eq . 4 . 122 ) , that is parse _ list _ structures . Spatial Parsing Algorithm – Stage 2 – Parsing List Structures To give you an idea of how the list detection mechanism works , we will go through an example . For the following demonstration we set . . . Ω = ID = N 0 and k = 16 This corresponds to the default setting of A S from Eq . 4 . 121 . In addition let us assume , that there is some D ∈ D h N 0 , 16 i given , which de - scribes four rectangular information units with grey ﬁll color and their ids as content . The spatial arrangement of these objects shall approximately corre - spond to what is illustrated in Fig . 4 . 19 . Let us also assume , that applying create _ terminals ( D ) from Alg . 9 on our given D has generated the following set of terminal symbols : S 0 =    s 0 , s 1 , s 2 , s 3     =    ( 0 , ATOM , b 0 , 0 , list ε ) , ( 1 , ATOM , b 1 , 1 , list ε ) , ( 2 , ATOM , b 2 , 2 , list ε ) , ( 3 , ATOM , b 3 , 3 , list ε )    ∈ P terminal h N 0 , 16 i 115 Chapter 4 . Prototype Figure 4 . 19 : Four rectangular information units with light grey ﬁll color and numerical ids as content For the sake of simplicity , symbolic placeholders s i as well as assigned attributes s i . id , s i . bounds = b i and s i . info _ unit were numbered sequentially from i = 0 to i = 3 . Bounding volumes b 0 to b 3 approximate the convex hulls of the four rectangles from Fig . 4 . 19 . Informally expressed , our list detection algorithm parse _ list _ structures will pro - cess S 0 as follows : In a ﬁrst , preparatory step , we determine for all symbols s ∈ S 0 possible alignments . For this , our algorithm locates for each s ∈ S 0 potential structure - neighbors N ⊂ S 0 , that is , objects s ′ , that are close enough to have a spatial relation with s . If there are no objects within the reach of s ( i . e . , | N | = 0 ) , we regard s as “unaligned” . But if | N | 6 = 0 , then we determine for all neighbors s ′ ∈ N the dominating alignment between s and s ′ . As deﬁned already in Eq . 4 . 123 , we diﬀerentiate between horizontal , vertical and diagonal alignment . Regarding the latter one , we explicitly separate between diagonals from top - left to bottom - right ( denoted as “diagonal0” ) and diagonals from top - right to bottom - left ( identiﬁed by “diagonal1” ) . In our example , neighbors of s 0 would be N = { s 1 , s 3 } . Object s 2 is located too far away from s 0 and thus may not have a direct spatial relation with s 0 . Fig . 4 . 19 clearly shows that both s 0 , s 1 as well as s 0 , s 3 are diagonally aligned ; once tilted to the right and once to the left . Therefore , s 0 is a potential element of structures with diagonal alignment . The same applies to the remaining symbols in S 0 . Due to their relative positioning , also s 1 , s 2 and s 3 are membership - candidates for diagonal lists . In order to keep an overview of which symbols are candidates for what kind of alignment , we collect the results of this pre - analysis in a special data structure , a so - called “AlignmentAccumulator” . We are using this term because such structures are eﬀectively used for “accumulating” alignment information . A detailed formal deﬁnition can be found on pages 124 to 127 . 116 4 . 4 . Parsers a ) b ) Figure 4 . 20 : Depending on whether we search for vertical lists ﬁrst and horizontal lists afterwards ( snapshot a ) ) or vice versa ( snapshot b ) ) you get diﬀerent parse results To simplify things we illustrate this alignment structure as a table : ❵❵❵❵❵❵❵❵❵❵❵❵ symbol alignment UA H V D0 D1 s 0 NC NC NC C C s 1 NC NC NC C C s 2 NC NC NC C C s 3 NC NC NC C C This table assigns to each cell ( s , a ) ∈ ( S 0 × { UA , H , V , D0 , D1 } ) an entry out of { NC , C , S } . The given column headers stand for “UnAligned” , “Horizontal” , “Vertical” , “Diagonal0” , and “Diagonal1” . Possible cell values indicate whether the symbol associated with the table row is “No Candidate” , “Candidate” or a “Structure element” . According to our sample table above , all four symbols ∈ S 0 are membership - candidates for structures with D0 - and D1 - alignment . Based on this preliminary evaluation , our algorithm tries to detect structures . At this point it is important to understand , that the order in which one searches for unaligned , horizontal , vertical etc . structures may have signiﬁcant impact on the parse result . An example for this can be found above in Fig . 4 . 20 : In snapshot a ) nine out of ten objects are assigned to yellow vertical lists . Thus , there is only one object left which could be used for a subsequent horizontal analysis ( here : object number 3 ) . Logically , that object alone cannot form a list and hence remains unassigned . But , if we search for horizontal lists ﬁrst and for vertical ones afterwards , then we get a very diﬀerent picture , as illustrated in snapshots b ) . Suddenly all ten objects can be assigned to structures ( here : blue horizontal lists ) . Apparently , the order in which we perform diﬀerent structural analyses may have signiﬁcant inﬂuence on the structures that can be detected . Unfortunately , we do not know in general which structure types to prefer over others . This 117 Chapter 4 . Prototype means , there is no universally valid order in which you should detect horizontal , vertical , diagonal etc . lists . This is why our general - purpose parsing algorithm has to consider all theoretical possibilities of interpretation . Applied to our example , these are all permutations ( a 0 , . . . , a 4 ) of table colums { UA , H , V , D0 , D1 } , which is a total of 5 ! = 120 combinations . Thus , in theory , we have to perform 120 alternative structure detection runs . For performance reasons , however , we decided to set a 0 to a ﬁxed value , that is a 0 = UA . Varying four instead of ﬁve elements requires to handle only 4 ! = 24 permutations , which reduces the workload to twenty percent . Moreover , it makes perfect sense to search for unaligned objects ﬁrst and for lists afterwards . For these reasons we decided to omit all combinations with a i = UA for 1 ≤ i ≤ 4 . Possibly there are even further permutations that can be excluded right from the start , for instance because they would lead to redundant structures . In this version of our algorithm , however , we do not make such assumptions . Rather we have chosen the strategy to consider all theoretical possibilities of interpretation ﬁrst and to eliminate redundant results afterwards . Let us start out with ( UA , H , V , D0 , D1 ) , which is the given column order in our sample table . The ﬁrst three columns UA , H , and V do not include C - entries , thus we can skip them . Column D0 , however , assigns to all four terminal symbols s 0 , . . . , s 3 the C - ﬂag and hence marks them as potential elements of D0 - aligned lists . Our algorithm sorts these candidate symbols { s 0 , s 1 , s 2 , s 3 } in ascending order according to their top - left bounds ( i . e . , min d 0 ( s i . bounds ) ; see Eq . 4 . 79 ) . This results in a sorted list ( s 0 , s 1 , s 3 , s 2 ) . The algorithm then sequentially runs through this list from left to right , that is from s 0 to s 2 , and tries to combine symbols of the same type ( here : ATOM ) to diagonal lists with a well formed shape . With “well formed” we mean , that we try to form lists with symmetrically arranged elements . This way we intend to resolve ambiguities in list membership . In our example , s 3 is perfectly aligned with s 0 . Hence , s 0 and s 3 unambiguously form a diagonal list . The same applies to s 2 and s 1 . Thus , all four terminal symbols s 0 , . . . , s 3 can be regarded as structure elements . Having updated our alignment table accordingly , we get : ❵❵❵❵❵❵❵❵❵❵❵❵ symbol alignment UA H V D0 D1 s 0 NC NC NC S C s 1 NC NC NC S C s 2 NC NC NC S C s 3 NC NC NC S C Apparently , all terminal symbols s 0 , . . . , s 3 are marked with the S - ﬂag , which identiﬁes them as structure elements . Hence , there are no symbols left which could be part of a D1 - aligned list . For this reason , we can skip column D1 and 118 4 . 4 . Parsers Figure 4 . 21 : sample reduction set S 1 Figure 4 . 22 : sample reduction set S 2 assemble our ﬁnal set of non - terminals as illustrated in Fig . 4 . 21 . Formally this can be expressed as : S 1 = ( (cid:0) 4 , DIAGONAL _ LIST0 , union ( s 0 . bounds , s 3 . bounds ) , ε , ( 0 , 3 ) (cid:1) , (cid:0) 5 , DIAGONAL _ LIST0 , union ( s 1 . bounds , s 2 . bounds ) , ε , ( 1 , 2 ) (cid:1) ) For this see our deﬁnitions of S nonterminal h Ω , k i from Eq . 4 . 136 and S struct h Ω , k i in Eq . 4 . 132 . When we repeat that with a slightly modiﬁed permutation ( UA , H , V , D1 , D0 ) , which prefers D1 - aligned lists over D0 - aligned lists , we get what is illustrated in Fig . 4 . 22 . Formally the corresponding reduction set S 2 would look as follows : S 2 = ( (cid:0) 6 , DIAGONAL _ LIST1 , union ( s 0 . bounds , s 1 . bounds ) , ε , ( 0 , 1 ) (cid:1) , (cid:0) 7 , DIAGONAL _ LIST1 , union ( s 3 . bounds , s 2 . bounds ) , ε , ( 3 , 2 ) (cid:1) ) Other permutations than ( UA , H , V , D0 , D1 ) or ( UA , H , V , D1 , D0 ) will result either in S 1 or S 2 . Therefore they are redundant and can be omitted . See Alg . 13 for a detailed description of the redundancy check . 119 Chapter 4 . Prototype Figure 4 . 23 : sample reduction set S 3 Figure 4 . 24 : sample reduction set S 4 Further structures can be detected on the next abstraction level . Applying the same list detection mechanism on symbols ∈ S 1 will result in . . . S 3 =     8 , DIAGONAL _ LIST1 , union   union s 0 . bounds , s 3 . bounds ! , union s 1 . bounds , s 2 . bounds !   , ε , ( 4 , 5 )     . . . which is illustrated in Fig . 4 . 23 . S 2 can be reduced to . . . S 4 =       9 , DIAGONAL _ LIST0 , union    union s 0 . bounds , s 1 . bounds ! , union s 3 . bounds , s 2 . bounds !    , ε , ( 6 , 7 )        . . . which is illustrated in Fig . 4 . 24 . 120 4 . 4 . Parsers   = (cid:1845) 0 (cid:1845) 2 (cid:1845) 3 (cid:1845) 1 (cid:1845) 4 Figure 4 . 25 : sample interpretation tree T ∈ T ′ I h N 0 , 16 i formed from terminals S 0 and non - terminals S 1 , S 2 and S 3 , S 4 Together , terminal symbols S 0 and their reduction sets S 1 , S 2 and S 3 , S 4 form an interpretation tree . . . T =        S 3 , S 4 , S 1 , S 2 , S 0    , ( ( S 0 , S 1 ) , ( S 1 , S 3 ) , ( S 0 , S 2 ) , ( S 2 , S 4 ) ) , S 0     ∈ T ′ I h N 0 , 16 i . . . which is shown in Fig . 4 . 25 . For this , see also our deﬁnitions of T I h Ω , k i from Eq . 4 . 143 and its reﬁned subset T ′ I h Ω , k i from Eq . 4 . 151 . This T forms the result of our bottom - up parsing algorithm and thus represents the function value of . . . parse _ list _ structures ( S 0 ) = T A detailed and complete , formal deﬁnition of parse _ list _ structures can be found on the following pages 122 to 138 . 121 Chapter 4 . Prototype Interpretation Tree Expansion parse _ list _ structures ( S ) follows our origi - nal deﬁnition of parse S from Eq . 4 . 122 and maps collections of terminal symbols S ∈ P terminal h Ω , k i to interpretation trees T ∈ T ′ I h Ω , k i : parse _ list _ structures : P terminal h Ω , k i → T ′ I h Ω , k i , S 7→ expand _ tree (cid:16)(cid:0) { S } , ∅ , S (cid:1) , S , 2 (cid:17) ( 4 . 153 ) Essentially , parse _ list _ structures ( S ) initiates the recursive expansion of a start - tree T = ( { S } , ∅ , S ) , beginning at root - node S ∈ P terminal h Ω , k i with a minimal list size of two elements . The resulting tree is guaranteed to be ∈ T ′ I h Ω , k i . In detail we deﬁne the recursive expansion of trees T ∈ T I h Ω , k i as follows : 11 expand _ tree : (cid:0) T I h Ω , k i × P S h Ω , k i × N 0 (cid:1) ⇀ T I h Ω , k i , ( T , S , minListSize ) 7→ T ′ , Require : (cid:0) S ∈ leafs ( T ) (cid:1) ∧ ( minListSize ≥ 2 ) ⊲ see : Alg . 10 1 : T ′ ← reduce ( T , S , minListSize ) ⊲ see : Alg . 12 2 : for all S ′ ∈ children (cid:0) T ′ , S (cid:1) do ⊲ see : Eq . 4 . 140 3 : T ′ ← expand _ tree (cid:0) T ′ , S ′ , minListSize (cid:1) 4 : end for 5 : return T ′ The core of expand _ tree ( T , S , minListSize ) , as deﬁned in Alg . 11 , are single steps T ′ ← reduce ( T , S , minListSize ) as can be seen in line 1 . For reasons of simplicity , we decided to put the formal deﬁnition of such expansion steps into a separate algorithm which can be found in Alg . 12 . In reduce ( T , S , minListSize ) we basically do the following : Firstly , we check whether | S | > 1 , since for a reduction we need at least two symbols . If that is not the case then T remains unchanged ( i . e . , reduce ( T , S , minListSize ) = T ) . Otherwise we continue by setting up our helper data structure “Alignment - Accumulator” , which was mentioned already in our introductory example ( on page 117 ) . A complete formal deﬁnition of that “table” - structure can be found on pages 124 to 127 . Once we have created and ﬁlled such an accumulator - instance we continue with the main structure - detection loop , which basically operates as follows : For each permutation ( a 0 , . . . , a 4 ) of discrete set Alignment ( see : Eq . 4 . 154 ) with a 0 = UNALIGNED , we reduce S to a set of non - terminals S reduction and expand the interpretation tree to T ← add _ child ( T , S , S reduction ) . Redundant reduction sets S reduction are rejected . See Alg . 13 for a detailed description of that pairwise redundancy check . 122 4 . 4 . Parsers 12 reduce : (cid:0) T I h Ω , k i × P S h Ω , k i × N 0 (cid:1) ⇀ T I h Ω , k i , ( T , S , minListSize ) 7→ T ′ , Require : (cid:0) S ∈ leafs ( T ) (cid:1) ∧ ( minListSize ≥ 2 ) ⊲ see : Alg . 10 1 : T ′ ← T 2 : if | S | > 1 then 3 : accu ← create _ accumulator ( S ) ⊲ see : Eq . 4 . 156 4 : accu ← ﬁll _ accumulator ( accu ) ⊲ see : Alg . 14 5 : for all permutations ( a 0 , . . . , a n ) of Alignment , 6 : where a 0 = UNALIGNED and n = (cid:0) | Alignment | − 1 (cid:1) do 7 : S reduction , terminate ! ← detect _ structures     S Σ (cid:0) T ′ (cid:1) , ( a 0 , . . . , a n ) , accu , minListSize     ⊲ see : Alg . 21 8 : if terminate = TRUE then 9 : T ′ ← add _ child (cid:0) T ′ , S , S reduction (cid:1) ⊲ see : Eq . 4 . 142 10 : return T ′ 11 : end if 12 : isRedundant ← FALSE 13 : for all S ′ ∈ children (cid:0) T ′ , S (cid:1) do ⊲ see : Eq . 4 . 140 14 : if redundant (cid:0) S reduction , S ′ (cid:1) = TRUE then ⊲ see : Alg . 13 15 : isRedundant ← TRUE 16 : break 17 : end if 18 : end for 19 : if isRedundant = FALSE then 20 : T ′ ← add _ child (cid:0) T ′ , S , S reduction (cid:1) ⊲ see : Eq . 4 . 142 21 : end if 22 : end for 23 : end if 24 : return T ′ One integral part of Alg . 12 , besides create _ accumulator and ﬁll _ accumulator in lines 3 , 4 and ( S reduction , terminate ) ← detect _ structures ( . . . ) in line 7 , is the redundancy check described from line 12 to line 18 . A given reduction set S reduction is redundant if it is equivalent to at least one reduction set from a previous run through the structure detection loop . That is , if it is equivalent to at least one S ′ ∈ children ( T ′ , S ) , with T ′ being the partly extended interpretation tree T . Two symbol sets S , S ′ ∈ P S h Ω , k i are regarded as being equivalent , if and only if ( 1 ) they have the same number of elements ( i . e . , | S | = (cid:12)(cid:12) S ′ (cid:12)(cid:12) ) and ( 2 ) for each s ∈ S there exists exactly one s ′ ∈ S ′ for which s . type = s ′ . type and s . child _ ids = s ′ . child _ ids . 123 Chapter 4 . Prototype Reformulated into a pairwise redundancy check for symbol sets ( S , S ′ ) : 13 redundant : (cid:0) P S h Ω , k i × P S h Ω , k i (cid:1) → { TRUE , FALSE } , (cid:0) S , S ′ (cid:1) 7→ r , 1 : if | S | 6 = (cid:12)(cid:12) S ′ (cid:12)(cid:12) then 2 : return FALSE 3 : end if 4 : for all s ∈ S do 5 : shared ← FALSE 6 : for all s ′ ∈ S ′ do 7 : if (cid:0) s . type = s ′ . type (cid:1) ∧ (cid:0) s . child _ ids = s ′ . child _ ids (cid:1) then 8 : shared ← TRUE 9 : break 10 : end if 11 : end for 12 : if shared = FALSE then 13 : return FALSE 14 : end if 15 : end for 16 : return TRUE Alignment Accumulator Given the following two discrete sets . . . F =     NO _ CANDIDATE , CANDIDATE , STRUCTURE _ ELEMENT     Alignment =     UNALIGNED , HORIZONTAL , VERTICAL , DIAGONAL0 , DIAGONAL1     ( 4 . 154 ) . . . we deﬁne the alignment “table” , which was mentioned in our introductory example ( on page 117 ) , as . . . AlignmentAccumulator h Ω , k i = ( ( S , f ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) S ∈ P S h Ω , k i , f : ( S × Alignment ) → F ) ( 4 . 155 ) Quite obviously , AlignmentAccumulator h Ω , k i is rather a map than simply a table . Nevertheless , it may be easier to visualize if you think of it as a two - dimensional table - like structure . When instantiated , accu ∈ AlignmentAccumulator h Ω , k i shall neither include CANDIDATE - nor STRUCTURE _ ELEMENT - entries . Consequently , for each “cell” ( s , a ) ∈ ( S × Alignment ) the value of f ( s , a ) must be NO _ CANDIDATE . 124 4 . 4 . Parsers In order to ensure that , we introduce the following constructor function : create _ accumulator : P S h Ω , k i → AlignmentAccumulator h Ω , k i , S 7→ ( S , f ) , f : ( S × Alignment ) → { NO _ CANDIDATE } ( 4 . 156 ) A concrete example of usage can be found in Alg . 12 in line 3 . Adequate setter and getter operations for accessing single “cells” in such an alignment “table” are deﬁned in Eq . 4 . 157 and Eq . 4 . 158 . set : AlignmentAccumulator h Ω , k i × S h Ω , k i × Alignment × F ! → AlignmentAccumulator h Ω , k i , (cid:0) ( S , f ) , s , a , v (cid:1) 7→ (cid:0) S , f ′ (cid:1) , f ′ : ( S × Alignment ) → F , ∀ ( x , y ) ∈ ( S × Alignment ) : f ′ ( x , y ) = ( v , if ( x = s ) ∧ ( y = a ) f ( x , y ) , else ( 4 . 157 ) get : AlignmentAccumulator h Ω , k i × S h Ω , k i × Alignment ! ⇀ F , (cid:0) ( S , f ) , s , a (cid:1) 7→ f ( s , a ) , s ∈ S ( 4 . 158 ) In addition to these basic operations on AlignmentAccumulator h Ω , k i , we intro - duce three more speciﬁc algorithms : ( 1 ) ﬁll _ accumulator ( deﬁned in Alg . 14 ) ; ( 2 ) structure _ candidates ( Alg . 15 ) and ( 3 ) unassigned _ symbols ( which can be found in Alg . 16 ) . ﬁll _ accumulator ( accu ) detects for each s ∈ accu . S ( that is , for all “table rows” ) the pairwise alignments a of s with its potential neighbors s ′ ∈ accu . S and marks the respective “cells” ( s , a ) in accu with the ﬂag CANDIDATE . A de - tailed description of alignment detection can be found in Alg . 17 . 14 ﬁll _ accumulator : AlignmentAccumulator h Ω , k i → AlignmentAccumulator h Ω , k i , accu 7→ accu ′ , 1 : accu ′ ← accu 2 : for all s ∈ accu ′ . S do 3 : A ← detect _ alignment (cid:0) s , accu ′ . S (cid:1) ⊲ see : Alg . 17 4 : for all a ∈ A do 5 : accu ′ ← set (cid:0) accu ′ , s , a , CANDIDATE (cid:1) ⊲ see : Eq . 4 . 157 6 : end for 7 : end for 8 : return accu ′ 125 Chapter 4 . Prototype Our second operation on AlignmentAccumulator h Ω , k i accepts three arguments : ( 1 ) the accu ∈ AlignmentAccumulator h Ω , k i to operate on ; ( 2 ) some permuta - tion of alignments alignOrder = ( a 0 , . . . , a n ) and ( 3 ) a selected align = a j for any j ∈ { 0 , 1 , . . . , n } . Given these arguments , structure _ candidates ( accu , alignOrder , align ) collects all s ∈ accu . S for which . . . get ( accu , s , a i ) 6 = STRUCTURE _ ELEMENT ( for 0 ≤ i < j ) ∧ get (cid:0) accu , s , a j (cid:1) 6 = NO _ CANDIDATE It herewith identiﬁes all symbols ∈ accu . S which are candidates for a j but are not marked as structure elements for preceding alignments a 0 . . . a j − 1 . 15 structure _ candidates : (cid:0) AlignmentAccumulator h Ω , k i × List h Alignment i × Alignment (cid:1) → P S h Ω , k i , ( accu , alignOrder , align ) 7→ S candidates , 1 : S candidates ← ∅ 2 : for all s ∈ accu . S do 3 : for i = 0 to (cid:0) size ( alignOrder ) − 1 (cid:1) do ⊲ see : Eq . 4 . 93 4 : a i ← get ( alignOrder , i ) ⊲ see : Eq . 4 . 94 5 : if a i = align then 6 : if get ( accu , s , a i ) 6 = NO _ CANDIDATE then ⊲ see : Eq . 4 . 158 7 : accu ← set ( accu , s , a i , CANDIDATE ) ⊲ see : Eq . 4 . 157 8 : S candidates ← S candidates ∪ { s } 9 : end if 10 : break 11 : end if 12 : if get ( accu , s , a i ) = STRUCTURE _ ELEMENT then ⊲ Eq . 4 . 158 13 : break 14 : end if 15 : end for 16 : end for 17 : return S candidates Our third and last operation on AlignmentAccumulator h Ω , k i identiﬁes “unas - signed” symbols . That is , it collects all symbols s ∈ accu . S which are not marked as structure elements . To achieve that , unassigned _ symbols ( accu ) checks for all s ∈ accu . S if there is at least one a ∈ Alignment for which get ( accu , s , a ) = STRUCTURE _ ELEMENT and returns all symbols that do not have such entries . In Alg . 16 we describe that in detail . 126 4 . 4 . Parsers 16 unassigned _ symbols : AlignmentAccumulator h Ω , k i → P S h Ω , k i , accu 7→ S unassigned , 1 : S unassigned ← ∅ 2 : for all s ∈ accu . S do 3 : isStructElement ← FALSE 4 : for all a ∈ Alignment do ⊲ Eq . 4 . 154 5 : if get ( accu , s , a ) = STRUCTURE _ ELEMENT then ⊲ Eq . 4 . 158 6 : isStructElement ← TRUE 7 : break 8 : end if 9 : end for 10 : if isStructElement = FALSE then 11 : S unassigned ← S unassigned ∪ { s } 12 : end if 13 : end for 14 : return S unassigned ﬁll _ accumulator , as deﬁned in Alg . 14 , requires in line 3 the detection of pair - wise alignments of symbols s with their neighbors s ′ ∈ S . This is realized by detect _ alignment ( s , S ) using the following procedure : In a ﬁrst step all spatial neighbors of s are identiﬁed . These are all symbols s ′ ∈ S that are close enough to have a spatial relation with s . For this we use N ← lookup _ neighbors ( s , S ) which is deﬁned in Eq . 4 . 159 . If there are no such objects ( i . e . , | N | = 0 ) then we regard s as being UNALIGNED . Otherwise , we determine for all neighbors s ′ ∈ N the dominating pairwise alignment between s and s ′ . For this we use detect _ alignment ( s , s ′ ) which is described in detail in Alg . 18 – Alg . 20 . 17 detect _ alignment : (cid:0) S h Ω , k i × P S h Ω , k i (cid:1) → 2 Alignment , ( s , S ) 7→ A , 1 : A ← ∅ 2 : N ← lookup _ neighbors ( s , S ) ⊲ see : Eq . 4 . 159 3 : if | N | = 0 then 4 : A ← { UNALIGNED } 5 : else 6 : for all s ′ ∈ N do 7 : ( a , β ) ← detect _ alignment (cid:0) s , s ′ (cid:1) ⊲ see : Alg . 18 – Alg . 20 8 : if a 6 = ε then 9 : A ← A ∪ { a } 10 : end if 11 : end for 12 : end if 13 : return A 127 Chapter 4 . Prototype Finding Spatial Neighbors Formally we deﬁne the lookup of neighboring parser symbols as . . . lookup _ neighbors : (cid:0) S h Ω , k i × P S h Ω , k i (cid:1) → P S h Ω , k i , ( s , S ) 7→ (cid:16) lookup (cid:0) neighborhood _ bounds ( s ) , S (cid:1) \ { s } (cid:17) ( 4 . 159 ) The included lookup ( neighborhood _ bounds ( s ) , S ) makes use of the bounding volume operation intersects ( b 0 , b 1 ) that was introduced alread with Alg . 4 : lookup : (cid:0) Bounds h k i × P S h Ω , k i (cid:1) → P S h Ω , k i , ( b , S ) 7→ S ′ ⊆ S , ∀ s ∈ S ′ : intersects ( b , s . bounds ) = TRUE ( 4 . 160 ) The exact deﬁnition of this search operation highly depends on how the parser is implemented . One obvious possibility would be to build on bounding volume hierarchies , such as QuadTrees . In fact , this is what we did in our implemen - tation . However , for our theoretical model Eq . 4 . 160 is completely suﬃcient . The search area b = neighborhood _ bounds ( s ) that is used for lookup ( b , S ) in Eq . 4 . 159 is calculated by three Bounds h k i - operations : scale from Eq . 4 . 82 , delta min ( Alg . 2 ) and delta max ( Alg . 1 ) : neighborhood _ bounds : S h Ω , k i → Bounds h k i , s 7→ scale s . bounds , (cid:18) 1 5 × delta max ( s . bounds ) + 4 5 × delta min ( s . bounds ) (cid:19) ! ( 4 . 161 ) Note , that the given oﬀset . . . (cid:18) 1 5 × delta max ( s . bounds ) + 4 5 × delta min ( s . bounds ) (cid:19) . . . that is used in Eq . 4 . 161 for scaling s . bounds , is crucial for the overall structure recognition procedure . The reason for this is , that the given oﬀset essentially determines size and dimensions of neighborhood _ bounds ( s ) , which in turn has signiﬁcant impact on the detection of spatially related objects . It is quite obvious , that using a ﬁxed oﬀset value , that does not take into account individual object proportions , would too often result in search areas that include the wrong neighbors . With “wrong” we mean , objects which were not intented to have a spatial relation . Consequently , although being the easiest this was not an option for us . At the other extreme , neighborhood _ bounds ( s ) that totally depend on the spatial environment of s ( i . e . , the context ) would certainly result in highly accurate selections of neighbors , but their calculation would also be very time consuming . Thus this was not an option either . 128 4 . 4 . Parsers With Eq . 4 . 161 we decided on a middle course between accuracy and eﬃciency . That is , search areas are dynamically adjusted to object size and proportions but do not require analysis of spatial context . Tests have shown , that our def - inition of neighborhood _ bounds ( s ) allows for reasonable selection of neighbors . Alignment Detection Pairwise alignment detection between symbols , as required in Alg . 17 ( line 7 ) , is realized by detect _ alignment ( Alg . 18 – Alg . 20 ) . detect _ alignment accepts a pair of parser symbols s 0 , s 1 ∈ S h Ω , k i and tries to determine their dominating ( or most apparent ) alignment . Results are encoded as tuples ( a , β ) with a ∈ ( Alignment ∪ { ε } ) and β ∈ { 0 . 0 , . . . , 1 . 0 } . a represents the detected alignment . a = ε means that a clear result could not be deter - mined . The second tuple element β is a certainty value ( ranging from zero to one - hundred percent ) that indicates how obvious alignment a is . Note , that even though β ∈ { 0 . 0 , . . . , 1 . 0 } it should not be confused with “Probability” . Given two symbols s 0 , s 1 , we expect for our pairwise alignment detection , that s 0 . bounds and s 1 . bounds are not nested inside each other . “Nesting” expresses rather explicit and formal than implicit an informal object relations and thus contradicts spatial hypertext’s implicit and informal nature ( Sect . 1 . 2 ) . For this reason , we decided that detect _ alignment ( s 0 , s 1 ) applied on nested symbols shall result in ( ε , 1 . 0 ) . This way we exclude such relations from our overall struc - ture detection procedure . In all other cases detect _ alignment ( s 0 , s 1 ) continues with some analysis of symmetry . In concrete terms , detect _ alignment ( s 0 , s 1 ) determines numerically how well s 0 and s 1 are aligned to x - and y - axis . This requires the calculation of a numerical symmetry _ indicator ( see Eq . 4 . 162 ) : 18 detect _ alignment : (cid:0) S h Ω , k i × S h Ω , k i (cid:1) → (cid:16)(cid:0) Alignment ∪ { ε } (cid:1) × { 0 . 0 , . . . , 1 . 0 } (cid:17) , ( s 0 , s 1 ) 7→ r , 1 : if (cid:0) contains ( s 0 . bounds , s 1 . bounds ) = TRUE (cid:1) ∨ (cid:0) contains ( s 1 . bounds , s 0 . bounds ) = TRUE (cid:1) ! then ⊲ see : Alg . 3 2 : return ( ε , 1 . 0 ) ⊲ “Nesting” is explicit relation ⇒ / ∈ Alignment 3 : end if 4 : ah ← symmetry _ indicator min v ( s 0 . bounds ) , max v ( s 0 . bounds ) , min v ( s 1 . bounds ) , max v ( s 1 . bounds ) ! 5 : av ← symmetry _ indicator min h ( s 0 . bounds ) , max h ( s 0 . bounds ) , min h ( s 1 . bounds ) , max h ( s 1 . bounds ) ! . . . Having calculated degrees of horizontal and vertical alignment ah and av , we can do the same for diagonal alignment ad 0 , ad 1 . For this we follow two basic 129 Chapter 4 . Prototype principles : ( 1 ) “ If it is neither horizontal nor vertical then it must be diagonal ” and ( 2 ) “ Two objects can never be aligned from top - left to bottom - right and from top - right to bottom - left at the same time ” . Depending on the orientation of centroid ( s 0 . bounds ) and centroid ( s 1 . bounds ) we either get ad 0 = 0 . 0 and ad 1 = ( 1 . 0 − | ah − av | ) or vice versa : 19 detect _ alignment ( s 0 , s 1 ) – part II . . . 6 : ad 0 ← 0 . 0 7 : ad 1 ← 0 . 0 8 : ( x 0 , y 0 ) ← centroid ( s 0 . bounds ) ⊲ see : Alg . 5 9 : ( x 1 , y 1 ) ← centroid ( s 1 . bounds ) 10 : ∆ x ← ( x 0 − x 1 ) 11 : ∆ y ← ( y 0 − y 1 ) 12 : if ( ∆ x > 0 ∧ ∆ y < 0 ) ∨ ( ∆ x < 0 ∧ ∆ y > 0 ) then 13 : ad 1 ← (cid:0) 1 . 0 − | ah − av | (cid:1) 14 : else if ( ∆ x > 0 ∧ ∆ y > 0 ) ∨ ( ∆ x < 0 ∧ ∆ y < 0 ) then 15 : ad 0 ← (cid:0) 1 . 0 − | ah − av | (cid:1) 16 : end if . . . After that , ah , av , ad 0 , and ad 1 are normalized to guarantee that they sum up to 1 . 0 . Finally amax = max ( { ah , av , ad 0 , ad 1 } ) identiﬁes the “winner” alignment . If there are several “winners” , then horzontal and vertical alignment are preferred over diagonal alignments : 20 detect _ alignment ( s 0 , s 1 ) – part III . . . 17 : at ← ( ah + av + ad 0 + ad 1 ) ⊲ make sure that . . . 18 : ah ← (cid:0) ah / at (cid:1) ⊲ . . . ah , av , ad 0 , ad 1 sum up to 1 . 0 19 : av ← (cid:0) av / at (cid:1) 20 : ad 0 ← (cid:0) ad 0 / at (cid:1) 21 : ad 1 ← (cid:0) ad 1 / at (cid:1) 22 : amax ← max (cid:0) { ah , av , ad 0 , ad 1 } (cid:1) ⊲ detect “winner” - alignment 23 : if amax = ah then 24 : return ( HORIZONTAL , amax ) 25 : else if amax = av then 26 : return ( VERTICAL , amax ) 27 : else if amax = ad 0 then 28 : return ( DIAGONAL0 , amax ) 29 : end if 30 : return ( DIAGONAL1 , amax ) 130 4 . 4 . Parsers An integral component of detect _ alignment is the function symmetry _ indicator ( see lines 4 – 5 in Alg . 18 ) . Like our deﬁnition of neighborhood _ bounds in Eq . 4 . 161 , also our deﬁnition of symmetry _ indicator is a trade - oﬀ between performance and eﬃciency , which has resulted from informal studio - tests . symmetry _ indicator maps real - valued quadruples ( min 0 , max 0 , min 1 , max 1 ) to strength values ranging from 0 . 0 to 1 . 0 . A value of 1 . 0 indicates that the two sections described by min 0 , max 0 and min 1 , max 1 are perfectly symmet - rical . A return value of 0 . 0 , on the other hand , means that both sections are disjunct ( i . e . , ( max 1 < min 0 ) ∨ ( min 1 > max 0 ) ) . A detailed deﬁnition of symmetry _ indicator is given in Eq . 4 . 162 : symmetry _ indicator : R 4 ⇀ { 0 . 0 , . . . , 1 . 0 } , symmetry _ indicator      min 0 , max 0 , min 1 , max 1     =     0 , if ( max 1 < min 0 ) ∨ ( min 1 > max 0 ) ! − 2∆ d + 1 , else if (cid:0) ∆ < 14 d (cid:1) − 3∆ d + 5 4 , else if (cid:0) 14 d ≤ ∆ < 38 d (cid:1) − ∆ d + 1 2 , else ∆ = (cid:12)(cid:12) (cid:12) (cid:12) min 0 + max 0 − min 1 − max 1 2 (cid:12)(cid:12)(cid:12) (cid:12) d = max 0 − min 0 + max 1 − min 1 ( min 0 , max 0 , min 1 , max 1 ∈ R ) , ( max 0 > min 0 ) ∧ ( max 1 > min 1 ) ( 4 . 162 ) Structure Detection The algorithmic “heart” of parse _ list _ structures ( . . . ) is deﬁned as . . . S reduction , terminate ! ← detect _ structures   S Σ (cid:0) T ′ (cid:1) , ( a 0 , . . . , a n ) , accu , minListSize   . . . which can be found in Alg . 12 in line 7 . The algorithm behind this is described formally in Alg . 21 – Alg . 25 . detect _ structures ( S , alignOrder , accu , minListSize ) creates pairs ( S ′ , terminate ) , with S ′ being a collection of newly generated structure symbols ( see : Eq . 4 . 132 ) and terminate as a boolean control ﬂag ∈ { TRUE , FALSE } which is exclusively used in the context of reduce ( Alg . 12 ) . In a nutshell , S ′ is the latest reduction 131 Chapter 4 . Prototype of accu . S and the boolean ﬂag terminate indicates whether to continue reducing accu . S or not . For details on usage of terminate see Alg . 12 , lines 8 – 21 . More speciﬁcally , in detect _ structures ( S , alignOrder , accu , minListSize ) we run sequentially through alignOrder = ( a 0 , . . . , a n ) from a 0 to a n , determine for each a i the respective structure _ candidates ( accu , alignOrder , a i ) ( see Alg . 15 ) and try to combine found candidate symbols in disjunct structures with align - ment a i . If a i = UNALIGNED then we create for each detected candidate a new structure symbol of type UNALIGNED and update the accumulator accordingly ( i . e . , we add STRUCTURE _ ELEMENT - entries ) . All unaligned structure symbols generated this way are collected in a set S unaligned . This ﬁrst stage is described in detail in Alg . 21 : 21 detect _ structures :      P S h Ω , k i × List h Alignment i × AlignmentAccumulator h Ω , k i × N 0     ⇀ (cid:0) P S h Ω , k i × { TRUE , FALSE } (cid:1) , ( S , alignOrder , accu , minListSize ) 7→ (cid:0) S ′ , terminate (cid:1) , Require : ( accu . S ⊆ S ) ∧ ( minListSize ≥ 2 ) 1 : S unaligned ← ∅ 2 : S list ← ∅ 3 : for i = 0 to (cid:0) size ( alignOrder ) − 1 (cid:1) do ⊲ Eq . 4 . 93 4 : a i ← get ( alignOrder , i ) ⊲ Eq . 4 . 94 5 : S candidates ← structure _ candidates ( accu , alignOrder , a i ) ⊲ Alg . 15 6 : if a i = UNALIGNED then 7 : for all s ∈ S candidates do 8 : accu ← set ( accu , s , UNALIGNED , STRUCTURE _ ELEMENT ) 9 : s ′ ← create _ structure (cid:0) S ∪ S unaligned ∪ S list (cid:1) , UNALIGNED , add ( list ε , s . id ) ! ⊲ Alg . 8 10 : S unaligned ← S unaligned ∪ (cid:8) s ′ (cid:9) 11 : end for 12 : else . . . If a i 6 = UNALIGNED then we check whether there are enough candidates for assembling lists with at least minListSize elements . If this is not the case , then we can skip the current alignment a i and continue with the next one from alignOrder instead . If , however , there are enough candidate symbols then we try to combine them to lists with alignment a i . For this we use detect _ lists ( S candidates , a i , minListSize ) which is described in detail in Alg . 26 . 132 4 . 4 . Parsers For each list ∈ detect _ lists ( S candidates , a i , minListSize ) we then create a new structure symbol , either of type HORIZONTAL _ LIST , VERTICAL _ LIST , DIAGONAL _ LIST0 or DIAGONAL _ LIST1 ( this depends on the current a i ) and for each list element we add a STRUCTURE _ ELEMENT - entry to the ac - cumulator . All list symbols created this way are collected in S list . See Alg . 22 for a complete formal deﬁnition : 22 detect _ structures ( S , alignOrder , accu , minListSize ) – part II . . . 13 : if | S candidates | < minListSize then 14 : continue 15 : end if 16 : for all l ∈ detect _ lists ( S candidates , a i , minListSize ) do ⊲ Alg . 26 17 : elementIds ← list ε 18 : for j = 0 to (cid:0) size ( l ) − 1 (cid:1) do ⊲ Eq . 4 . 93 19 : s j ← get ( l , j ) ⊲ Eq . 4 . 94 20 : accu ← set (cid:0) accu , s j , a i , STRUCTURE _ ELEMENT (cid:1) 21 : elementIds ← add (cid:0) elementIds , s j . id (cid:1) ⊲ Eq . 4 . 92 22 : end for 23 : listType ← HORIZONTAL _ LIST 24 : if a i = VERTICAL then 25 : listType ← VERTICAL _ LIST 26 : else if a i = DIAGONAL0 then 27 : listType ← DIAGONAL _ LIST0 28 : else if a i = DIAGONAL1 then 29 : listType ← DIAGONAL _ LIST1 30 : end if 31 : s ′ ← create _ structure (cid:0) S ∪ S unaligned ∪ S list (cid:1) , listType , elementIds ! ⊲ Alg . 8 32 : S list ← S list ∪ (cid:8) s ′ (cid:9) 33 : end for 34 : end if 35 : end for . . . Having detected at least one list ( i . e . , | S list | > 0 ) we copy all remaining sym - bols into our reduction set , that is S result = S unaligned ∪ S list . Thus , they can be reused in another structure detection run . For this , we lookup all remain - ing symbols from accu . S which were not marked as structure elements ( see : unassigned _ symbols ( accu ) from Alg . 16 ) . These symbols are then “cloned” and added to S result which is ﬁnally returned in form of ( S result , FALSE ) . With terminate = FALSE we signalize to continue reducing accu . S for other alignOrder s . The exact deﬁnition can be found in Alg . 23 . 133 Chapter 4 . Prototype 23 detect _ structures ( S , alignOrder , accu , minListSize ) – part III . . . 36 : if | S list | > 0 then 37 : S result ← S unaligned ∪ S list 38 : for all s ∈ unassigned _ symbols ( accu ) do ⊲ Alg . 16 39 : s ′ ← create _ symbol (cid:0) ( S ∪ S result ) , s . type , s . bounds , ε , add ( list ε , s . id ) (cid:1) 40 : S result ← S result ∪ (cid:8) s ′ (cid:9) 41 : end for 42 : return ( S result , FALSE ) 43 : end if . . . Note , however , that this does not automatically mean that we quit our bottom - up procedure when we cannot form lists ( i . e . , when | S list | = 0 ) . We rather continue reducing unaligned and unassigned symbols until only a single start - symbol is left . This way , we still get valid parse trees , even though there are no lists . This requires adequate reduction rules as those in Alg . 24 and Alg . 25 . Alg . 24 handles the case of (cid:12) (cid:12) unassigned _ symbols ( accu ) (cid:12) (cid:12) = (cid:12) (cid:12) S unaligned (cid:12) (cid:12) = 1 . In this crucial case we manually perform a “dummy” - reduction to ε . That means , we reduce both unaligned and unassigned symbol to a single start - symbol of type ε and signalize terminate = TRUE : 24 detect _ structures ( S , alignOrder , accu , minListSize ) – part IV . . . 44 : if (cid:16)(cid:12) (cid:12) S unaligned (cid:12) (cid:12) = 1 (cid:17) ∧ (cid:16)(cid:12) (cid:12) unassigned _ symbols ( accu ) (cid:12) (cid:12) = 1 (cid:17) then ⊲ Alg . 16 45 : ids ← list ε 46 : for all s ∈ S unaligned do 47 : ids ← add (cid:0) ids , get ( s . child _ ids , 0 ) (cid:1) ⊲ Eq . 4 . 92 , Eq . 4 . 94 48 : end for 49 : for all s ∈ unassigned _ symbols ( accu ) do ⊲ Alg . 16 50 : ids ← add ( ids , s . id ) ⊲ Eq . 4 . 92 51 : end for 52 : return (cid:16)(cid:8) create _ structure ( S , ε , ids ) (cid:9) , TRUE (cid:17) ⊲ Alg . 8 53 : end if . . . In all remaining cases we manually reduce unaligned symbols to a single parent symbol of type UNALIGNED and unassigned symbols to a single non - terminal with type ε . You could also say that we group unaligned symbols together under the label UNALIGNED and unassigned symbols under ε . Both are combined in S result and are ﬁnally returned together with terminate = TRUE . See Alg . 25 . 134 4 . 4 . Parsers 25 detect _ structures ( S , alignOrder , accu , minListSize ) – part V . . . 54 : S result ← ∅ 55 : if (cid:12)(cid:12) S unaligned (cid:12)(cid:12) > 0 then 56 : ids ← list ε 57 : for all s ∈ S unaligned do 58 : ids ← add (cid:0) ids , get ( s . child _ ids , 0 ) (cid:1) ⊲ Eq . 4 . 92 , Eq . 4 . 94 59 : end for 60 : S result ← S result ∪ (cid:8) create _ structure ( S , UNALIGNED , ids ) (cid:9) ⊲ Alg . 8 61 : end if 62 : if (cid:12)(cid:12) unassigned _ symbols ( accu ) (cid:12)(cid:12) > 0 then ⊲ Alg . 16 63 : ids ← list ε 64 : for all s ∈ unassigned _ symbols ( accu ) do ⊲ Alg . 16 65 : ids ← add ( ids , s . id ) ⊲ Eq . 4 . 92 66 : end for 67 : S result ← S result ∪ n create _ structure (cid:0) ( S ∪ S result ) , ε , ids (cid:1)o ⊲ Alg . 8 68 : end if 69 : return ( S result , TRUE ) 135 Chapter 4 . Prototype List Detection The core list detection algorithm that is described in Alg . 26 requires an adequate data structure for representing lists of symbols . For this we use the following derivative of List h S h Ω , k ii ( see Eq . 4 . 91 for a generic deﬁnition of lists ) : SymbolList h Ω , k i ⊂ List h S h Ω , k ii : SymbolList h Ω , k i =       list (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) list = ( s 0 , s 1 , . . . , s n ) ∈ (cid:0) List h S h Ω , k ii \ { list ε } (cid:1) , ∄ (cid:8) s i , s j (cid:9) : (cid:0) s i 6 = s j (cid:1) ∧ (cid:0) s i . id = s j . id (cid:1) , 0 ≤ i < j ≤ n , n ∈ N 0    ∪ { list ε } ( 4 . 163 ) What makes such lists ( s 0 , s 1 , . . . , s n ) ∈ SymbolList h Ω , k i special is not only the fact that they include only symbols s ∈ S h Ω , k i as list elements , but also that there may be no pair of symbols s i , s j for which s i . id = s j . id but s i 6 = s j . In a nutshell , list elements with same ids must also have the same attributes . Subsets of SymbolList h Ω , k i are used as return values for our list detection algorithm . detect _ lists , as deﬁned in Alg . 26 , accepts a triple of arguments ( S , a , minListSize ) , with potential list elements S ∈ P S h Ω , k i , the required list alignment a ∈ ( Alignment \ { UNALIGNED } ) and minListSize ∈ N 0 . These three arguments are mapped to a ( potentially empty ) set of lists L ⊂ SymbolList h Ω , k i . Here it shall be ensured , that all detected lists ∈ L are not empty and include at least minListSize elements . In order to achieve that , detect _ lists ( S , a , minListSize ) basically proceeds as follows : In a ﬁrst step all symbols s ∈ S get sorted in ascending order and according to their lower horizontal , vertical or diagonal bounds . This depends on the given alignment argument a . See Eq . 4 . 164 for a detailed description of this sort operation . In a second step , we run sequentially through that sorted list ( s 0 , s 1 , . . . , s n ) from s 0 to s n and check for each s i which list ∈ L ﬁts best . In concrete terms , given that s last denotes the last element of a list candidate , we ﬁlter out those lists from L for which , ( 1 ) s i and s last have the same type ( i . e . , s last . type = s i . type ) ; ( 2 ) s i and s last are close enough to have a spatial relation ( i . e . , intersects ( neighborhood _ bounds ( s last ) , s i . bounds ) ) ( see : Alg . 4 , Eq . 4 . 161 ) and ( 3 ) the pairwise alignment a ′ between s i and s last that is determined by ( a ′ , β ) ← detect _ alignment ( s last , s i ) ﬁts the required alignment given by argu - ment a ( i . e . , a ′ = a ) . From those list candidates that fulﬁll these three conditions we then select the one with a maximal β . This “winner” - list gets extended by s i . When no “winner” can be found ( for instance , because this was our ﬁrst run and hence L was still empty ) then we extend L by a new list which includes only s i . 136 4 . 4 . Parsers Having repeated that for each s i from our sorted list ( s 0 , s 1 , . . . , s n ) , we ﬁnally remove all list candidates from L which include less than minListSize elements . A detailed formal description is given in Alg . 26 . 26 detect _ lists : (cid:16) P S h Ω , k i × (cid:0) Alignment \ { UNALIGNED } (cid:1) × N 0 (cid:17) → 2 SymbolList h Ω , k i , ( S , a , minListSize ) 7→ L , Ensure : ∀ l ∈ L : (cid:0) empty ( l ) = FALSE (cid:1) ∧ (cid:0) size ( l ) ≥ minListSize (cid:1) 1 : L ← ∅ 2 : sortedSymbols ← sort ( S , a ) ⊲ Eq . 4 . 164 3 : for i = 0 to (cid:0) size ( sortedSymbols ) − 1 (cid:1) do ⊲ Eq . 4 . 93 4 : s i ← get ( sortedSymbols , i ) ⊲ Eq . 4 . 94 5 : γ ← 0 . 0 6 : list winner ← ε 7 : for all list candidate ∈ L do 8 : s last ← last ( list candidate ) ⊲ Eq . 4 . 97 9 : if s last . type = s i . type then 10 : if intersects (cid:0) neighborhood _ bounds ( s last ) , s i . bounds (cid:1) then 11 : (cid:0) a ′ , β (cid:1) ← detect _ alignment ( s last , s i ) ⊲ Alg . 18 12 : if (cid:0) a ′ = a (cid:1) ∧ ( β > γ ) then 13 : γ ← β 14 : list winner ← list candidate 15 : end if 16 : end if 17 : end if 18 : end for 19 : if list winner 6 = ε then 20 : L ← (cid:16) L ∪ (cid:8) add ( list winner , s i ) (cid:9)(cid:17) \ { list winner } ⊲ Eq . 4 . 92 21 : else 22 : L ← L ∪ (cid:8) add ( list ε , s i ) (cid:9) ⊲ Eq . 4 . 92 23 : end if 24 : end for 25 : for all list candidate ∈ L do 26 : if size ( list candidate ) < minListSize then ⊲ Eq . 4 . 93 27 : L ← L \ { list candidate } 28 : end if 29 : end for 30 : return L In line 2 Alg . 26 requires sorting of symbols by sortedSymbols ← sort ( S , a ) . sort ( S , a ) is supposed to sort S in ascending order using the comparator func - 137 Chapter 4 . Prototype tion compare ( s 0 , s 1 , a ) which is described in Alg . 27 . The exact deﬁnition of sort highly depends on the selected sorting algorithm and hence on concrete system implementation . For our theoretical model , however , it does not matter what algorithm we choose . Therefore it is suﬃcient to deﬁne sort as follows : sort : (cid:16) P S h Ω , k i × (cid:0) Alignment \ { UNALIGNED } (cid:1)(cid:17) → SymbolList h Ω , k i , ( S , a ) 7→ l : (cid:0) size ( l ) = | S | (cid:1) ∧   size ( l ) − 1 [ i = 0 (cid:8) get ( l , i ) (cid:9)   = S compare (cid:0) get ( l , i ) , get ( l , i + 1 ) , a (cid:1) ∈ { LESS , EQUAL } , i ∈ n 0 , 1 , . . . , (cid:0) size ( l ) − 2 (cid:1)o ( 4 . 164 ) Depending on the given alignment a , comparator function compare ( s 0 , s 1 , a ) selects for s 0 , s 1 lower horizontal , vertical or diagonal bounds min 0 , min 1 and checks whether min 0 is LESS than , GREATER than or EQUAL to min 1 : 27 compare : S h Ω , k i × S h Ω , k i × (cid:0) Alignment \ { UNALIGNED } (cid:1) ! →     LESS , EQUAL , GREATER     , ( s 0 , s 1 , a ) 7→ r , 1 : r ← EQUAL 2 : if a = HORIZONTAL then 3 : min 0 ← min h ( s 0 . bounds ) ⊲ Eq . 4 . 77 4 : min 1 ← min h ( s 1 . bounds ) 5 : else if a = VERTICAL then 6 : min 0 ← min v ( s 0 . bounds ) ⊲ Eq . 4 . 78 7 : min 1 ← min v ( s 1 . bounds ) 8 : else if a = DIAGONAL0 then 9 : min 0 ← min d 0 ( s 0 . bounds ) ⊲ Eq . 4 . 79 10 : min 1 ← min d 0 ( s 1 . bounds ) 11 : else if a = DIAGONAL1 then 12 : min 0 ← min d 1 ( s 0 . bounds ) ⊲ Eq . 4 . 80 13 : min 1 ← min d 1 ( s 1 . bounds ) 14 : end if 15 : if min 0 < min 1 then 16 : r ← LESS 17 : else if min 0 > min 1 then 18 : r ← GREATER 19 : end if 20 : return r 138 4 . 4 . Parsers The following snapshots from diverse interpretation trees will give you an im - pression of the power of the previously described list detection mechanism . ( Note , that these snapshots were chosen randomly ) 139 Chapter 4 . Prototype Spatial Parsing Algorithm – Stage 3 – Normalization The last step in our three - stage spatial parsing algorithm , besides creating ter - minal symbols ( Alg . 9 ) and detecting list structures ( Eq . 4 . 153 ) , is normalizing interpretation trees returned by parse _ list _ structures ( create _ terminals ( . . . ) ) . For this we deﬁne . . . normalize : T ′ I h Ω , k i → I h Ω i normalize ( T ) is supposed to transform ingoing interpretation trees T ∈ T ′ I h Ω , k i into weighted , “ﬂat” graphs ∈ I h Ω i , as we deﬁned them in Eq . 4 . 90 . This map - ping builds on the following considerations : First , let us deﬁne simple Paths from root to leaf in interpretation trees T ′ I h Ω , k i as elements of the following generic set : T P h Ω , k i = ( P (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) P ∈ T ′ I h Ω , k i , ∀ v ∈ V ( P ) : d + P ( v ) ∈ { 0 , 1 } ) ⊂ T ′ I h Ω , k i ( 4 . 165 ) Thus , ( simple ) root - to - leaf paths in interpretation trees are interpretation trees themselves . In addition to operations that are deﬁned on any T ∈ T ′ I h Ω , k i , such as leafs ( Eq . 4 . 139 ) , children ( Eq . 4 . 140 ) , level ( Eq . 4 . 141 ) , . . . etc . , we introduce two ad - ditional operations for navigating paths P ∈ T P h Ω , k i : ( 1 ) has _ next ( Eq . 4 . 166 ) and ( 2 ) next ( Eq . 4 . 167 ) . has _ next ( P , S ) takes a path P ∈ T P h Ω , k i and a vertex S ∈ P S h Ω , k i and checks whether S has a successor on P ( i . e . , if children ( P , S ) 6 = ∅ ) . If this is the case then TRUE is returned . Otherwise has _ next ( P , S ) = FALSE . This also includes the case that S / ∈ V ( P ) . Thus , has _ next ( P , S ) is totally deﬁned : has _ next : (cid:0) T P h Ω , k i × P S h Ω , k i (cid:1) → { TRUE , FALSE } , has _ next ( P , S ) = ( TRUE , if children ( P , S ) 6 = ∅ FALSE , else ( 4 . 166 ) The second required operation for iterating through paths P ∈ T P h Ω , k i is a single jump from one path - node to its successor . For this we use the function next . next ( P , S ) accepts a path P ∈ T P h Ω , k i and a vertex S ∈ P S h Ω , k i and returns the child ( or rather the successor ) of S in P . This is only deﬁned if children ( P , S ) 6 = ∅ . Thus , for navigating P we need both operations has _ next and next . next : (cid:0) T P h Ω , k i × P S h Ω , k i (cid:1) ⇀ P S h Ω , k i , ( P , S ) 7→ S ′ ∈ children ( P , S ) , children ( P , S ) 6 = ∅ ( 4 . 167 ) 140 4 . 4 . Parsers Additionally , let P T ( T ) be a function , that can split trees T ∈ T ′ I h Ω , k i up into collections of root - to - leaf paths { P 0 , P 1 , . . . , P n } , where n = (cid:12)(cid:12) leafs ( T ) (cid:12)(cid:12) − 1 : P T : T ′ I h Ω , k i → 2 T P h Ω , k i , T 7→ (cid:26) P 0 , P 1 , . . . , P (cid:16) | leafs ( T ) | − 1 (cid:17) (cid:27) ,   (cid:16) | leafs ( T ) | − 1 (cid:17) [ i = 0 V ( P i )   = V ( T ) ∧   (cid:16) | leafs ( T ) | − 1 (cid:17) [ i = 0 E ( P i )   = E ( T ) ( 4 . 168 ) From parse _ list _ structures ( Eq . 4 . 153 ) we can conclude , that each . . . { P 0 , P 1 , . . . , P n } ∈ P T (cid:0) T ′ I h Ω , k i (cid:1) . . . encodes a set of alternative interpretations . . . { I 0 , I 1 , . . . , I n } ∈ 2 ( I h Ω i ) ; ( n ∈ N 0 ) Thus , there is a total mapping . . . P T (cid:0) T ′ I h Ω , k i (cid:1) → 2 ( I h Ω i ) , P T ( T ) 7→ I P (cid:0) P T ( T ) (cid:1) . . . where function I P is deﬁned as : I P : T P h Ω , k i → I h Ω i , P 7→ I = ( U , A , w ) ( 4 . 169 ) Here , U shall be the set of all information unit identiﬁers s . info _ unit that can be found in the root node of P . A is the set of all binary subsets of U : U =   [ s ∈ r ( P ) { s . info _ unit }   ; A = (cid:18) U 2 (cid:19) ( 4 . 170 ) The total weighting function w is deﬁned as a binary relation : w : A → { ε , 0 . 0 , . . . , 1 . 0 } , w = R w (cid:0) P , r ( P ) (cid:1) ( 4 . 171 ) For this we introduce the recursive function R w ( P , S ) : R w ( P , S ) =       R ′ w ( P , S ) ∪ R w (cid:0) P , next ( P , S ) (cid:1) ! , if has _ next ( P , S ) = TRUE R ′ w ( P , S ) , else ( 4 . 172 ) 141 Chapter 4 . Prototype Illustrated with an example , if P is a simple path from root node r ( P ) = S 0 to leaf node S n then R w ( P , r ( P ) ) from Eq . 4 . 172 would result in : R w (cid:0) P , r ( P ) (cid:1) = R ′ w ( P , S 0 ) ∪ R ′ w ( P , S 1 ) ∪ . . . ∪ R ′ w ( P , S n ) Thus , R w ( P , r ( P ) ) simply reapplies R ′ w ( P , S ) on all nodes from root to leaf and calculates their union . The result is a binary relation that can be used as weighting function w , as deﬁned in Eq . 4 . 171 . In this context , it shall be noted that . . .   \ S ∈ V ( P ) R ′ w ( P , S )   = ∅ ; P ∈ T P h Ω , k i R ′ w ( P , S ) takes each s ∈ S and calculates for all pairwise combinations of child symbols { child ( P , s , i ) , child ( P , s , j ) } the relation R ′′ w ( P , S , s , i , j ) ; which is deﬁned in Eq . 4 . 174 . The union of all these binary relations forms the function value of R ′ w ( P , S ) : R ′ w ( P , S ) = [ s ∈ S   ( child _ count ( s ) − 2 ) [ i = 0 ( child _ count ( s ) − 1 ) [ j = i + 1 R ′′ w ( P , S , s , i , j )   ( 4 . 173 ) The relation R ′′ w ( P , S , s , i , j ) assigns values weight ( s . type , level ( P , S ) , i , j ) to unordered pairs { a . info _ unit , b . info _ unit } . Here , a is required to be a leaf node beneath child ( P , s , i ) and b shall be a leaf node under child ( P , s , j ) : R ′′ w ( P , S , s , i , j ) =     ( a . info _ unit , b . info _ unit ) , weight   s . type , level ( P , S ) , i , j     (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) a ∈ leafs (cid:0) P , child ( P , s , i ) (cid:1) ∧ b ∈ leafs (cid:0) P , child ( P , s , j ) (cid:1)   ( 4 . 174 ) Due to Eq . 4 . 171 , weight ( s . type , level ( P , S ) , i , j ) , as we use it in Eq . 4 . 174 , has to provide function values ∈ { ε , 0 . 0 , . . . , 1 . 0 } . Only then R ′′ w ( P , S , s , i , j ) , R ′ w ( P , S ) and ﬁnally also R w ( P , S ) form valid weighting relations . Parameters that must be included in this calculation are : ( 1 ) the structure type s . type of a parent symbol s ; ( 2 ) the ( structure - ) level of node S in P ( provided that s ∈ S ) and ( 3 ) child symbol indices i , j ∈ N 0 . 142 4 . 4 . Parsers In more detail , function weight looks as follows : weight : (cid:16)(cid:0) StructureType ∪ { ε } (cid:1) × N 0 × N 0 × N 0 (cid:17) ⇀ { ε , 0 . 0 , . . . , 1 . 0 } ,   structType , structLevel , i , j   7→ v =      weight type ( structType ) × weight level ( structLevel ) × weight distance ( i , j )   , if structType 6 = ε ε , else ( 4 . 175 ) Provided that structType 6 = ε we deﬁne weight ( structType , structLevel , i , j ) as a product of three factors : ( 1 ) weight type ( Eq . 4 . 176 ) ; ( 2 ) weight level ( Eq . 4 . 177 ) and ( 3 ) weight distance ( Eq . 4 . 178 ) . weight type maps structure types ∈ StructureType to weightings ∈ { 0 . 0 , . . . , 1 . 0 } . It herewith represents an indicator for the general strength of object - relations in structures of certain types ( such as horizontal , vertical lists etc . ) . Since function weight from Eq . 4 . 175 and thus also weight type is never used on root - node - level , we do not need to provide a deﬁnition of weight type ( ATOM ) . Therefore weight type is partially deﬁned : weight type : StructureType ⇀ { 0 . 0 , . . . , 1 . 0 } , weight type =     ( UNALIGNED , 0 . 0 ) , ( HORIZONTAL _ LIST , 1 . 0 ) , ( VERTICAL _ LIST , 1 . 0 ) , ( DIAGONAL _ LIST0 , 1 . 0 ) , ( DIAGONAL _ LIST1 , 1 . 0 )    ( 4 . 176 ) In Eq . 4 . 176 we do not make any speciﬁc assumptions about the diﬀerent strengths of object - relationships in horizontal , vertical or diagonal lists . The alignment of a list has no speciﬁc impact on the dependencies between its elements . Therefore weight type of a list is always 1 . 0 . For structure type UNALIGNED we use a weight of 0 . 0 instead , since unaligned objects are cer - tainly not associated with each other . The second weighting factor we use for quantifying the strength of object rela - tions is weight level . Clearly it makes a signiﬁcant diﬀerence whether two objects have a direct spatial relation or not . It makes a diﬀerence whether two objects are direct members of the same list or they rather lie in spatially separated structures and are related on a higher level of abstraction only . Objects with a direct spatial relation must have a stronger dependency than objects that are 143 Chapter 4 . Prototype only associated indirectly . This gets reﬂected by the following formula : weight level : N 0 ⇀ { 0 . 0 , . . . , 1 . 0 } , ∀ x ∈ N + : weight level ( x ) = 1 2 ( x − 1 ) ( 4 . 177 ) According to this deﬁnition , interpretation tree levels ( or rather structure - levels ) x = 1 , 2 , 3 , . . . , n get weighted as . . . weight level ( x ) = 1 , 1 2 , 1 4 , 1 8 , . . . , 1 2 ( n − 1 ) As we are working with ordered sequences of objects ( i . e . , lists ) , the strength of object relations is not only determined by structure type ( Eq . 4 . 176 ) and structure level ( Eq . 4 . 177 ) but also by the distance between objects inside a sorted structure . It is quite obvious , that consecutive list elements have a stronger spatial relation than list elements that are spatially separated by a sub - list . This is taken into consideration by the following weighting function : weight distance : ( N 0 × N 0 ) ⇀ { 0 . 0 , . . . , 1 . 0 } , ( i , j ) 7→ 2 ( i − j + 1 ) , j > i ( 4 . 178 ) Here , arguments i and j represent positive indices ∈ N 0 of two objects in a sequentially ordered structure , where j > i . Using the formula above , two consecutive structure elements ( i . e . , j − i = 1 ) get a weighting of 1 . 0 , for j − i = 2 we get 0 . 5 , for j − i = 3 the weight will be 0 . 25 and so forth . With all these deﬁnitions at hand it ﬁnally becomes possible to retrieve implic - itly encoded interpretations { I 0 , I 1 , . . . , I n } ⊂ I h Ω i from interpretation trees T ∈ T ′ I h Ω , k i . The only thing that remains to be done in order to realize the desired function normalize : T ′ I h Ω , k i → I h Ω i is merging I 0 , I 1 , . . . , I n together to a single result interpretation ∈ I h Ω i . Since we cannot know in general which of these interpretations to prefer we have rather decided on a maximal weight - ing strategy than mixing I 0 , I 1 , . . . , I n in speciﬁc proportions . A desirable side - eﬀect of taking over only maximal weightings into the ﬁnal interpretation graph is that smaller structures dissolve in bigger ones . Based on these considerations we deﬁne normalize as : normalize : T ′ I h Ω , k i → I h Ω i , T 7→ I = ( U , A , w ) , U =   [ s ∈ r ( T ) { s . info _ unit }   A = (cid:18) U 2 (cid:19) w = collect _ weights (cid:0) T , r ( T ) (cid:1) ( 4 . 179 ) 144 4 . 4 . Parsers collect _ weights ( T , S ) generalizes R w ( P , S ) from Eq . 4 . 172 for usage on full interpretation trees T ∈ T ′ I h Ω , k i . This is achieved by selecting only maximal weightings for the ﬁnal interpretation graph ( see : max _ weight from Eq . 4 . 180 ) . 28 collect _ weights : (cid:0) T ′ I h Ω , k i × P S h Ω , k i (cid:1) ⇀ 2 (cid:18) Ω 2 (cid:19) × { ε , 0 . 0 , . . . , 1 . 0 } ! , ( T , S ) 7→ R w Require : S ∈ V ( T ) 1 : R ← ∅ 2 : for all S ′ ∈ children ( T , S ) do ⊲ Eq . 4 . 140 3 : if R = ∅ then 4 : R ← collect _ weights (cid:0) T , S ′ (cid:1) 5 : else 6 : R merge ← ∅ 7 : for all ( a , v ) ∈ collect _ weights (cid:0) T , S ′ (cid:1) do 8 : R merge ← R merge ∪ (cid:26) (cid:16) a , max _ weight (cid:0) R ( a ) , v (cid:1)(cid:17)(cid:27) ⊲ Eq . 4 . 180 9 : end for 10 : R ← R merge 11 : end if 12 : end for 13 : R ′ ← ∅ 14 : for all s ∈ S do 15 : for i = 0 to (cid:0) child _ count ( s ) − 2 (cid:1) do ⊲ Eq . 4 . 129 16 : for j = i + 1 to (cid:0) child _ count ( s ) − 1 (cid:1) do 17 : v ← ε 18 : if s . type = UNALIGNED then 19 : v ← 0 . 0 20 : else if s . type 6 = ε then 21 : v ← 2 ( i − j − level ( T , S ) + 2 ) ⊲ Eq . 4 . 141 22 : end if 23 : for all s 0 ∈ leafs (cid:0) T , child ( T , s , i ) (cid:1) do ⊲ Alg . 10 , Eq . 4 . 152 24 : for all s 1 ∈ leafs (cid:0) T , child ( T , s , j ) (cid:1) do 25 : R ′ ← R ′ ∪     ( s 0 . info _ unit , s 1 . info _ unit ) , v     26 : end for 27 : end for 28 : end for 29 : end for 30 : end for 31 : return R ∪ R ′ 145 Chapter 4 . Prototype max _ weight : (cid:0) { ε , 0 . 0 , . . . , 1 . 0 } × { ε , 0 . 0 , . . . , 1 . 0 } (cid:1) → { ε , 0 . 0 , . . . , 1 . 0 } , ( w 0 , w 1 ) 7→ w max =   ε , if ( w 0 = ε ) ∧ ( w 1 = ε ) w 0 , else if ( w 0 6 = ε ) ∧ ( w 1 = ε ) w 1 , else if ( w 0 = ε ) ∧ ( w 1 6 = ε ) max ( w 0 , w 1 ) , else ( 4 . 180 ) For a better understanding , let us ﬁnally apply normalize on our introductory list - detection example from pages 115 – 121 . The resulting interpretation tree we got on page 121 was deﬁned as . . . T =       S 3 , S 4 , S 1 , S 2 , S 0    , ( ( S 0 , S 1 ) , ( S 1 , S 3 ) , ( S 0 , S 2 ) , ( S 2 , S 4 ) ) , S 0    ∈ T ′ I h N 0 , 16 i . . . where the root set of terminal symbols S 0 was given as . . . S 0 =      ( 0 , ATOM , b 0 , 0 , list ε ) , ( 1 , ATOM , b 1 , 1 , list ε ) , ( 2 , ATOM , b 2 , 2 , list ε ) , ( 3 , ATOM , b 3 , 3 , list ε )     ∈ P terminal h N 0 , 16 i When we calculate now normalize ( T ) , using our deﬁnitions from Eq . 4 . 179 , then we get a triple ( U , A , w ) ∈ I h Ω i with . . . U =   [ s ∈ S 0 { s . info _ unit }   = { 0 , 1 , 2 , 3 } A = (cid:18) U 2 (cid:19) =   { 0 , 1 } , { 0 , 2 } , { 0 , 3 } , { 1 , 2 } , { 1 , 3 } , { 2 , 3 }   . . . and a weighting function w which is calculated by . . . w = collect _ weights ( T , S 0 ) Essentially , collect _ weights ( T , S 0 ) , as we deﬁned it in Alg . 28 , generates two 146 4 . 4 . Parsers binary relations , which are . . . collect _ weights ( T , S 1 ) = ( (cid:0) { 0 , 3 } , 1 . 0 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0 (cid:1) ) ∪ collect _ weights ( T , S 3 ) = ( (cid:0) { 0 , 3 } , 1 . 0 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0 (cid:1) ) ∪   (cid:0) { 0 , 1 } , 0 . 5 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 3 , 1 } , 0 . 5 (cid:1) , (cid:0) { 3 , 2 } , 0 . 5 (cid:1)   =          (cid:0) { 0 , 1 } , 0 . 5 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 3 , 1 } , 0 . 5 (cid:1) , (cid:0) { 3 , 2 } , 0 . 5 (cid:1) , (cid:0) { 0 , 3 } , 1 . 0 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0 (cid:1)   . . . and . . . collect _ weights ( T , S 2 ) = ( (cid:0) { 0 , 1 } , 1 . 0 (cid:1) , (cid:0) { 3 , 2 } , 1 . 0 (cid:1) ) ∪ collect _ weights ( T , S 4 ) = ( (cid:0) { 0 , 1 } , 1 . 0 (cid:1) , (cid:0) { 3 , 2 } , 1 . 0 (cid:1) ) ∪    (cid:0) { 0 , 3 } , 0 . 5 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 1 , 3 } , 0 . 5 (cid:1) , (cid:0) { 1 , 2 } , 0 . 5 (cid:1)    =    (cid:0) { 0 , 3 } , 0 . 5 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 1 , 3 } , 0 . 5 (cid:1) , (cid:0) { 1 , 2 } , 0 . 5 (cid:1) , (cid:0) { 0 , 1 } , 1 . 0 (cid:1) , (cid:0) { 3 , 2 } , 1 . 0 (cid:1)             Both alternatives are merged together choosing maximal weightings : collect _ weights ( T , S 0 ) =    (cid:0) { 0 , 3 } , max _ weight ( 1 . 0 , 0 . 5 ) (cid:1) , (cid:0) { 0 , 2 } , max _ weight ( 0 . 5 , 0 . 5 ) (cid:1) , (cid:0) { 1 , 3 } , max _ weight ( 0 . 5 , 0 . 5 ) (cid:1) , (cid:0) { 1 , 2 } , max _ weight ( 1 . 0 , 0 . 5 ) (cid:1) , (cid:0) { 0 , 1 } , max _ weight ( 0 . 5 , 1 . 0 ) (cid:1) , (cid:0) { 3 , 2 } , max _ weight ( 0 . 5 , 1 . 0 ) (cid:1)           =    (cid:0) { 0 , 3 } , 1 . 0 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 1 , 3 } , 0 . 5 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0 (cid:1) , (cid:0) { 0 , 1 } , 1 . 0 (cid:1) , (cid:0) { 3 , 2 } , 1 . 0 (cid:1)    Illustrated as an overlay on Fig . 4 . 19 , where weightings are drawn as black lines with varying brightness , thickness and opacity : 147 Chapter 4 . Prototype 4 . 4 . 3 Visual Parser Dynamic parser systems , as we deﬁned them in Sect . 4 . 4 . 1 ( Eq . 4 . 106 ) , ana - lyze the strength of pairwise object relations and generate output in form of weighted graphs ∈ I h Ω i . To achieve that parsers focus on diﬀerent structural aspects . A good example for this could be seen in previous Sect . 4 . 4 . 2 where we discussed a spatial parsing algorithm . However , spatial dependency is not the only crucial factor for successful structure detection . As pointed out already in Sect . 1 . 4 ( on page 8 ) visual structure is not only determined by position , alignment etc . but also by visual ( dis - ) similarities . Parsers that take this into account in their analysis are called “visual parsers” . Let Φ V be a set of event categories that indicate when to perform a full visual parse . For this see our deﬁnitions of parse in Eq . 4 . 110 and Φ in Eq . 4 . 107 . Φ V =    CREATE , MODIFY _ SPATIAL , MODIFY _ VISUAL , DELETE     ( 4 . 181 ) In direct comparison , Φ V extends Φ S from Eq . 4 . 119 by an additional ﬂag MODIFY _ VISUAL . Thus , a full reparse is triggered not only when new infor - mation units were created or deleted or when spatial properties got modiﬁed ( e . g . , shape , proportions , dimensions etc . ) but also when purely visual at - tributes have changed , such as color . Provided that our visual parsing algorithm is deﬁned by a function parse V : ( I h Ω i × E h Ω i × D h Ω , k i ) → I h Ω i , we can use Φ V from Eq . 4 . 181 to partially reﬁne our generic parser model from Eq . 4 . 106 into a parameterized model for visual parsers A V h Ω , n , α , β i : A V h Ω , n , α , β i : = A P h Ω , n , α , β , Φ V , parse V i T V h Ω , n , α , β i : = T P h Ω , n , α , β , Φ V , parse V i G V h Ω , n , α , β i : = G P h Ω , n , α , β , Φ V , parse V i ( 4 . 182 ) When using the same default conﬁguration as given in Eq . 4 . 121 we get : A V : = A V h N 0 , 16 , 0 . 95 , 0 . 05 i T V : = T V h N 0 , 16 , 0 . 95 , 0 . 05 i G V : = G V h N 0 , 16 , 0 . 95 , 0 . 05 i ( 4 . 183 ) Following the blockdiagram in Fig . 4 . 15 visual parsers A V can be illustrated as seen in Fig . 4 . 26 . 148 4 . 4 . Parsers     Visual Parser       fade     + 1 parse (cid:1836)  (cid:1836)  + 1   Figure 4 . 26 : Blockdiagram of visual parser model A V as deﬁned in Eq . 4 . 183 parse V follows the deﬁnition of ϕ from Eq . 4 . 107 and maps triples ( I , e , D ) to interpretation graphs I ′ . Here , I , I ′ ∈ I h Ω i , e ∈ E h Ω i and D ∈ D h Ω , k i . Unlike the previously deﬁned spatial parser ( see : Eq . 4 . 122 ) our visual parser includes all three arguments I , e and D into the structure analysis process . That is , parse V utilizes not only spatial and visual properties D , but also the preceding edit event e and the latest visual parse result I : parse V : (cid:0) I h Ω i × E h Ω i × D h Ω , k i (cid:1) → I h Ω i , (cid:0) ( U , A , w ) , e , D (cid:1) 7→ (cid:0) U ′ , A ′ , w ′ (cid:1) ( 4 . 184 ) When an ingoing event e indicates that new information units e . objects were added to the workspace ( i . e . , e . operation = CREATE ) then U has to be ex - tended to U ′ = ( U ∪ e . objects ) . If , however , e . objects have been removed ( i . e . , e . operation = DELETE ) then U must be reduced to U ′ = ( U \ e . objects ) . In all other cases , such as MODIFY _ SPATIAL , MODIFY _ VISUAL etc . , U remains unchanged , that is U ′ = U . Expressed as piecewise function : U ′ =   U ∪ e . objects , if e . operation = CREATE U \ e . objects , if e . operation = DELETE U , else ( 4 . 185 ) Both cases e . operation = CREATE and e . operation = DELETE require not only to adjust U , as described in Eq . 4 . 185 , but also to update A , which builds 149 Chapter 4 . Prototype on U . For this we use the following rules : If e . operation = CREATE then the previous A must be extended by new associations { u , u ′ } / ∈ A for which either u , u ′ ∈ e . objects or u ∈ U ∧ u ′ ∈ e . objects holds . In the opposite case , that is e . operation = DELETE , we remove all { u , u ′ } from A where u or u ′ are not included in U ′ anymore , which makes them redundant . Otherwise A ′ = A : A ′ =   A ∪ (cid:18) e . objects 2 (cid:19) ∪   (cid:8) u , u ′ (cid:9) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:12) (cid:12) u ∈ U ∧ u ′ ∈ e . objects   , if e . operation = CREATE (cid:18) U ′ 2 (cid:19) , if e . operation = DELETE A , else ( 4 . 186 ) Note , that in Eq . 4 . 185 and Eq . 4 . 186 we check only whether e . operation = CREATE or e . operation = DELETE . Flags , such as MODIFY _ SPATIAL , MODIFY _ VISUAL etc . , are not included explicitely . The advantage of this is , that we can easily extend E h Ω i from Eq . 4 . 71 by additional ( and possibly more speciﬁc ) operation ﬂags without the need to adjust our visual parsing algorithm . This is especially beneﬁcial in application development . The last element in result triples ( U ′ , A ′ , w ′ ) ∈ I h Ω i , besides U ′ ( Eq . 4 . 185 ) and A ′ ( Eq . 4 . 186 ) , is the weighting function w ′ : w ′ : A ′ → { ε , 0 . 0 , . . . , 1 . 0 } , ∀ a ∈ A ′ : w ′ ( a ) = ( detect _ visual _ relation ( a , D ) , if a ∈ A recalc w ( a ) , else ( 4 . 187 ) ( Re - ) calculation of weights w ′ ( a ) = detect _ visual _ relation ( a , D ) is only re - quired for associations a ∈ A recalc . These are deﬁned as follows : A recalc = (cid:18) e . objects 2 (cid:19) ∪   (cid:8) u , u ′ (cid:9) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) u ∈ e . objects ∧ u ′ ∈ (cid:0) U \ e . objects (cid:1)   ( 4 . 188 ) According to this , ( re - ) calculation happens only for ( 1 ) associations with at least one modiﬁed object and ( 2 ) for associations which are completely new . In case of DELETE , however , weights w ( a ) do not need to be updated , since for no remaining a ∈ A ′ : a ∈ A recalc . Therefore ∀ a ∈ A ′ : w ′ ( a ) = w ( a ) ; which results in w ′ ⊂ w . Note that if e is an empty event ( i . e . , e = ( ∅ , ε ) ∈ E h Ω i ; see Eq . 4 . 71 ) , then we set U ′ = U , A ′ = A and thus also w ′ = w . Consequently , parse V ( I , ( ∅ , ε ) , D ) returns an unchanged I = ( U , A , w ) . When combined with fading of interpre - tations ( see Sect . 4 . 4 . 1 ; pages 93 – 94 ) this allows to simulate passing of discrete 150 4 . 4 . Parsers time and hence continuous aging of structure ; even without active involvement of human users . That is , theoretically empty events e = ( ∅ , ε ) could be used as ﬁxed system clock . Currently we do not make use of this option . The most crucial part of our visual parsing algorithm is detection of visual object relations . In the current version of our algorithm the strength of visual relations equates with the degree of visual similarity . This means , how strong the visual relation between two objects is , is only determined by how optically similar they are ( regarding color , shape , proportions etc . ) . Other notions of visual relation are not considered in our visual parser . In order to detect the strength of visual connections between information units , detect _ visual _ relation ( { u , u ′ } , ( V , p ) ) takes two units u , u ′ ∈ Ω and a set of properties ( V , p ) ∈ D h Ω , k i and calculates detect _ visual _ similarity ( p ( u ) , p ( u ′ ) ) . This requires that u , u ′ ∈ V . Otherwise ε is returned : detect _ visual _ relation : (cid:18) (cid:18) Ω 2 (cid:19) × D h Ω , k i (cid:19) → { ε , 0 . 0 , . . . , 1 . 0 } , (cid:16)(cid:8) u , u ′ (cid:9) , ( V , p ) (cid:17) 7→ y =    detect _ visual _ similarity p ( u ) , p (cid:0) u ′ (cid:1) ! , if u , u ′ ∈ V ε , else ( 4 . 189 ) We express the degree of visual similarity between two information units as numerical values ∈ { 0 . 0 , . . . , 1 . 0 } . A value of 1 . 0 indicates that both objects are optically identical , whereas 0 . 0 means that they have nothing in common visually . Informal laboratory tests resulted in the following weighted formula : detect _ visual _ similarity : (cid:0) InfoUnitData h k i (cid:1) 2 → { 0 . 0 , . . . , 1 . 0 } , ( d 0 , d 1 ) 7→ (cid:18) α × w p × w d + β × w s + γ × w c α + β + γ (cid:19) , α = 8 , β = 2 , γ = 4 ( 4 . 190 ) w p is a numerical indicator for how similar proportions of d 0 . bounds and d 1 . bounds are . Here , proportions are deﬁned by width and height from Eq . 4 . 81 . w p = proportion _ similarity      width ( d 0 . bounds ) , height ( d 0 . bounds ) , width ( d 1 . bounds ) , height ( d 1 . bounds )      ( 4 . 191 ) 151 Chapter 4 . Prototype The respective formula is : proportion _ similarity ( w 0 , h 0 , w 1 , h 1 ) = 1 − | w 0 h 1 − w 1 h 0 | w 0 h 1 + w 1 h 0 ( 4 . 192 ) As an example , when two objects have exactly the same proportions and hence w 0 = w 1 = w and h 0 = h 1 = h then proportion _ similarity ( w , h , w , h ) gets : (cid:18) 1 − | wh − wh | wh + wh (cid:19) = (cid:18) 1 − 0 2 wh (cid:19) = ( 1 − 0 ) = 1 . 0 In a similar fashion we determine w d which is a numerical indicator for how similar two objects are regarding their dimensions ( or sizes ) : w d = dimension _ similarity     width ( d 0 . bounds ) , height ( d 0 . bounds ) , width ( d 1 . bounds ) , height ( d 1 . bounds )     ( 4 . 193 ) For this calculation we approximate object dimensions by rectangular surface areas width × height ( Eq . 4 . 81 ) . Hence , the respective formula looks slightly diﬀerent than the one in Eq . 4 . 192 : dimension _ similarity ( w 0 , h 0 , w 1 , h 1 ) = 1 − | w 0 h 0 − w 1 h 1 | w 0 h 0 + w 1 h 1 ( 4 . 194 ) Illustrated with an example , when two objects have the same approximated surface areas ( i . e . , w 0 h 0 = w 1 h 1 ) then dimension _ similarity ( w 0 , h 0 , w 1 , h 1 ) will result in : (cid:18) 1 − | w 0 h 0 − w 1 h 1 | w 0 h 0 + w 1 h 1 (cid:19) = (cid:18) 1 − 0 w 0 h 0 + w 1 h 1 (cid:19) = ( 1 − 0 ) = 1 . 0 Another factor that can play an essential role for calculating visual similarities is the similarity of geometrical shapes w s : w s = shape _ similarity ( d 0 . shape , d 1 . shape ) ( 4 . 195 ) As only rectangular and ellipsoidal shapes are used ( see : Eq . 4 . 84 ) we restrict our deﬁnition of shape _ similarity on equality checks for shapes . In concrete terms , if two shapes s 0 , s 1 ∈ Shape are equal then shape _ similarity ( s 0 , s 1 ) returns a similarity value of 1 . 0 . Otherwise shape _ similarity ( s 0 , s 1 ) = 0 . 0 : shape _ similarity : ( Shape × Shape ) → { 0 . 0 , . . . , 1 . 0 } , ∀ s 0 , s 1 ∈ Shape : shape _ similarity ( s 0 , s 1 ) = ( 1 , if s 0 = s 1 0 , else ( 4 . 196 ) 152 4 . 4 . Parsers The last factor included in detect _ visual _ similarity ( Eq . 4 . 190 ) , besides w p ( Eq . 4 . 191 ) , w d ( Eq . 4 . 193 ) and w s ( Eq . 4 . 195 ) , is w c , where c stands for color : w c = color _ similarity ( d 0 . color , d 1 . color ) ( 4 . 197 ) After having conducted several informal experiments with diﬀerent color spaces and weighted formulas we ﬁnally developed the following piecewise deﬁnition of color _ similarity : color _ similarity : ( Color × Color ) → { 0 . 0 , . . . , 1 . 0 } , ∀ c 0 , c 1 ∈ Color : color _ similarity ( c 0 , c 1 ) =    1 , if 0 ≤ ∆ E ( c 0 , c 1 ) < 5 (cid:18) − 1 95 × ∆ E ( c 0 , c 1 ) + 100 95 (cid:19) , if 5 ≤ ∆ E ( c 0 , c 1 ) < 100 0 , else ( 4 . 198 ) ∆ E ( c 0 , c 1 ) , as we use it in Eq . 4 . 198 , is deﬁned as the Euclidean distance be - tween two colors Lab ( c 0 ) , Lab ( c 1 ) in multidimensional L * a * b * color space [ 38 ] . L * a * b * colors were designed to approximate human vision and are therefore perfectly suited for detecting perceivable color similarities . Since there are no simple formulas for conversion between Color ( i . e . , RGB ) and L * a * b * we do not provide a full deﬁnition of Lab here . We rather limit ourselves to . . . ∆ E ( c 0 , c 1 ) = (cid:13) (cid:13) Lab ( c 0 ) − Lab ( c 1 ) (cid:13) (cid:13) 2 Lab : Color →   { 0 , . . . , 100 } × { − 170 , . . . , 100 } × { − 100 , . . . , 150 }   , ( r , g , b ) 7→ ( L ∗ , a ∗ , b ∗ ) ( 4 . 199 ) As an example , let us assume that there are two RGB - colors given : c 0 = ( 255 , 255 , 255 ) and c 1 = ( 0 , 0 , 0 ) Transformed into L * a * b * c 0 becomes Lab ( c 0 ) = ( 100 , 0 , 0 ) and c 1 turns into Lab ( c 1 ) = ( 0 , 0 , 0 ) . The Euclidean distance between Lab ( c 0 ) and Lab ( c 1 ) is . . . ∆ E ( c 0 , c 1 ) = (cid:13)(cid:13) ( 100 , 0 , 0 ) − ( 0 , 0 , 0 ) (cid:13)(cid:13) 2 = 100 ∆ E = 100 falls in section number three in Eq . 4 . 198 . Thus the color _ similarity of black and white is 0 . 0 . For our purposes this makes perfect sense . Finally , let us illustrate the eﬀects of combining these similarity values in an example . Here we follow our deﬁnition from Eq . 4 . 190 . 153 Chapter 4 . Prototype Figure 4 . 27 : Visual parse result illustrated as a network of objects with varying size , proportions , shape and ﬁll color connected by black lines with varying brightness , thickness and opacity . The more similar two objects are the thicker the connecting line and the stronger the line color . Let us assume that eight visual objects are given , seven of type ELLIPSE and one of type RECTANGLE . Elliptical objects shall be arranged in a bow shape gradually morphing from left to right from small , red , horizontal ellipses to big green circles . In contrast to this , object number eight shall be a narrow upright rectangle with light blue ﬁll color . The visual interpretation graph we would get back by applying parse V on these objects is illustrated in Fig . 4 . 27 . In Fig . 4 . 27 weightings are drawn as black lines with varying brightness , thick - ness and opacity . The bigger the weight the thicker the line and the stronger the color . Weights of 1 . 0 , for instance , would be drawn as opaque black bars . Smaller weights are illustrated as thin lines with weak color . This has the op - tical eﬀect of vanishing edges when weights converge towards zero . This also explains why there are no visible connections between the blue rectangle in the middle and the elliptical objects arranged around : Our visual parser recognizes that rectangle and ellipses have nothing in common visually . 4 . 4 . 4 Content Parser Normally spatial parsers do not deal with content of information units . They rather infer object relations from spatial and visual properties than from the ( non - ) verbal information included in hypertext nodes ( Sect . 1 . 3 ) . This , how - ever , does not necessarily mean that it makes no sense or that there is no need 154 4 . 4 . Parsers for evaluating an information unit’s payload . In fact , this was considered al - ready in one of the ﬁrst publications on spatial parsing , in [ 12 ] . But it has never been implemented . Even though analysing contentual relationships contradicts the basic operating principle of spatial parsers , it still can be useful for resolving ambiguities . The importance of disambiguation for successful spatial parsing was pointed out al - ready in Chapter 3 . In order to make use of content to support disambiguation , and hence structure detection , we need an appropriate way to combine visual and contentual analysis . Interpretation systems , as described in Sect . 4 . 2 , to - gether with their linked parsers ( Sect . 4 . 2 . 4 ) are ideally suited for this purpose . All that needs to be done , is to introduce an additional parsing component which is able to detect contentual instead of spatial or visual relations . Such a “content parser” is then coupled with spatial and visual parser by weighted merging , as described in Sect . 4 . 2 . 4 . Except for Φ C and the weighting formula for object relations , content parsers correspond to visual parsers from Sect . 4 . 4 . 3 . Therefore Eq . 4 . 203 to Eq . 4 . 208 are almost identical to our previous deﬁnitions from Eq . 4 . 184 to Eq . 4 . 189 . Provided that content relations shall be detected only when new objects were created , when the content of information units has changed or when objects got deleted . . . Φ C =    CREATE , MODIFY _ CONTENT , DELETE    ( 4 . 200 ) . . . and assuming , analogous to Eq . 4 . 120 and Eq . 4 . 182 , that our content pars - ing algorithm is deﬁned by a function parse C : ( I h Ω i× E h Ω i× D h Ω , k i ) → I h Ω i we can partially reﬁne Eq . 4 . 106 into a content parser model A C h Ω , n , α , β i : A C h Ω , n , α , β i : = A P h Ω , n , α , β , Φ C , parse C i T C h Ω , n , α , β i : = T P h Ω , n , α , β , Φ C , parse C i G C h Ω , n , α , β i : = G P h Ω , n , α , β , Φ C , parse C i ( 4 . 201 ) When applying the same default model parameters as we used in Eq . 4 . 121 and Eq . 4 . 183 we get : A C : = A C h N 0 , 16 , 0 . 95 , 0 . 05 i T C : = T C h N 0 , 16 , 0 . 95 , 0 . 05 i G C : = G C h N 0 , 16 , 0 . 95 , 0 . 05 i ( 4 . 202 ) Illustrated as a blockdiagram , system components A C , T C and G C become what can be seen in Fig . 4 . 28 . 155 Chapter 4 . Prototype     Content Parser  (cid:1829)  (cid:1829)  (cid:1829) fade     + 1 parse (cid:1836)  (cid:1836)  + 1   Figure 4 . 28 : Blockdiagram of content parser model A C as deﬁned in Eq . 4 . 202 Just like parse V in Eq . 4 . 184 , also parse C maps triples ( I , e , D ) to interpreta - tions I ′ and therefore matches the deﬁnition of ϕ from Eq . 4 . 107 : parse C : (cid:0) I h Ω i × E h Ω i × D h Ω , k i (cid:1) → I h Ω i , (cid:0) ( U , A , w ) , e , D (cid:1) 7→ (cid:0) U ′ , A ′ , w ′ (cid:1) ( 4 . 203 ) With Eq . 4 . 204 we ensure that the resulting interpretation graph ( U ′ , A ′ , w ′ ) always includes the latest collection of information units ( or rather their iden - tiﬁers ∈ Ω ) : U ′ =   U ∪ e . objects , if e . operation = CREATE U \ e . objects , if e . operation = DELETE U , else ( 4 . 204 ) Eq . 4 . 205 keeps A ′ consistent with U ′ : A ′ =   A ∪ (cid:18) e . objects 2 (cid:19) ∪   (cid:8) u , u ′ (cid:9) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) u ∈ U ∧ u ′ ∈ e . objects   , if e . operation = CREATE (cid:18) U ′ 2 (cid:19) , if e . operation = DELETE A , else ( 4 . 205 ) 156 4 . 4 . Parsers Apparently , both mappings from U to U ′ ( Eq . 4 . 204 ) and from A to A ′ ( Eq . 4 . 205 ) are identical to those deﬁned in Eq . 4 . 185 and Eq . 4 . 186 . The same applies to the mapping of w to w ′ . Also w ′ together with the included set A recalc can be found again in Eq . 4 . 187 and Eq . 4 . 188 . The only diﬀerence between w ′ of the visual parser and the content parser’s w ′ lies in the function that is used for detecting object relations , now called detect _ content _ relation : w ′ : A ′ → { ε , 0 . 0 , . . . , 1 . 0 } , ∀ a ∈ A ′ : w ′ ( a ) = ( detect _ content _ relation ( a , D ) , if a ∈ A recalc w ( a ) , else ( 4 . 206 ) A recalc = (cid:18) e . objects 2 (cid:19) ∪    (cid:8) u , u ′ (cid:9) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) u ∈ e . objects ∧ u ′ ∈ (cid:0) U \ e . objects (cid:1)    ( 4 . 207 ) Just like the strength of visual relations equated with the degree of visual similarity ( in Eq . 4 . 189 ) also contentual relationships shall depend only on content - related proximity . In concrete terms , only the similarity of content should determine how strong the relation between two information units is . Thus , when two carriers of information include exactly the same content they must have a stronger connection than objects with completely diﬀerent infor - mation payload . Other notions of contentual relation are not considered for our parsing algorithm . In Sect . 4 . 1 . 4 we speciﬁed to use string - based content ( i . e . , text ) in our pro - totypical spatial hypermedia system . According to Eq . 4 . 87 in Sect . 4 . 2 . 2 and Eq . 4 . 103 in Sect . 4 . 3 this is available via d . text , for any d ∈ InfoUnitData h k i . In order to detect the strength of contentual relationships between two carriers of information u , u ′ , detect _ content _ relation ( { u , u ′ } , ( V , p ) ) accepts informa - tion units u , u ′ ∈ Ω and their assigned properties ( V , p ) ∈ D h Ω , k i and calcu - lates the degree of topic related similarity between p ( u ) . text and p ( u ′ ) . text using detect _ topic _ similarity ( p ( u ) . text , p ( u ′ ) . text ) . Like the previous calculation of detect _ visual _ similarity ( p ( u ) , p ( u ′ ) ) in Eq . 4 . 189 this requires that u , u ′ ∈ V . Otherwise ε is used as return value : detect _ content _ relation : (cid:18) (cid:18) Ω 2 (cid:19) × D h Ω , k i (cid:19) → { ε , 0 . 0 , . . . , 1 . 0 } , (cid:16)(cid:8) u , u ′ (cid:9) , ( V , p ) (cid:17) 7→ y =      detect _ topic _ similarity p ( u ) . text , p (cid:0) u ′ (cid:1) . text ! , if u , u ′ ∈ V ε , else ( 4 . 208 ) 157 Chapter 4 . Prototype What really sets the content parser apart from the visual parser is the pairwise detection of thematic similarities , deﬁned by detect _ topic _ similarity . The approach we have chosen for inferring topic - related similarities builds on probabilistic inference and information theory . In detail , generative topic mod - els are used for computing topic distributions over content and divergence func - tions calculate how close such distributions come to each other . The model we have selected for statistical inference is the Latent Dirichlet Allocation ( LDA ) [ 39 ] . For measuring the diﬀerence , or rather divergence , between topic distributions we use the well - known Kullback Leibler ( KL ) divergence [ 40 ] . With both tools at hand , we compute topic distributions for u and u ′ . . . θ 0 = topic _ distribution (cid:0) p ( u ) . text (cid:1) θ 1 = topic _ distribution (cid:0) p ( u ′ ) . text (cid:1) . . . use them as input for a symmetrized KL ( since original KL is asymmetric ) KL symmetric ( θ 0 , θ 1 ) = 1 2 (cid:0) KL ( θ 0 , θ 1 ) + KL ( θ 1 , θ 0 ) (cid:1) ( 4 . 209 ) . . . and ﬁnally we map the result ( which is ≥ 0 ) to value range ] 0 , 1 ] : e − KL symmetric ( θ 0 , θ 1 ) = e − 12 ( KL ( θ 0 , θ 1 ) + KL ( θ 1 , θ 0 ) ) Note , that this value converges towards zero for an increasing divergence . This gives us a numerical indicator for topic distribution similarity and hence an indicator for similarity of text - based content . Thus we can deﬁne : detect _ topic _ similarity : ( String × String ) → { 0 . 0 , . . . , 1 . 0 } , ( s 0 , s 1 ) 7→ e − 12 (cid:16) KL ( ( θ 0 , θ 1 ) + KL ( θ 1 , θ 0 ) (cid:17) , θ 0 = topic _ distribution ( s 0 ) θ 1 = topic _ distribution ( s 1 ) ( 4 . 210 ) In a nutshell , our content parser takes a set of information units with text - based content ( i . e . , documents ) as input , creates a thematic proﬁle for each document , measures the pairwise degree of topic - related similarities between them and ﬁnally delivers that result in form of a complete , undirected , weighted graph , where weights assigned to edges indicate the strength of thematic relationships . A weight of 0 . 0 refers to “documents have nothing in common” whereas a value of 1 . 0 means that “with respect to covered topics both documents are identical” . Initial tests suggest , that the content parser’s performance strongly depends on settings used for LDA model estimation and inference . We assume that quality 158 4 . 4 . Parsers of parser output is mainly determined by ( 1 ) quality and quantity of training corpus ; ( 2 ) number of sampling iterations and ( 3 ) number of topics . From this we conclude , that there is no default conﬁguration which can always provide us with reasonable parse results . Consequently , in order to use the content parser in a productive system it must be tailored to individual user - requirements . 4 . 4 . 5 Temporal Parser In Chapter 3 we identiﬁed three categories of structures that cannot be detected properly by conventional spatial parsers : ( 1 ) ambiguous structures ( Sect . 3 . 1 ) ; ( 2 ) destroyed structures ( Sect . 3 . 2 ) and ( 3 ) temporal structures ( Sect . 3 . 3 ) . For solving the “destroyed structures problem” from Sect . 3 . 2 we suggested in Sect . 4 . 4 . 1 to extend our generic parser model by some short - term memory . For this see our considerations on the subject “fading” on pages 93 – 94 . For the detection of ambiguous ( Sect . 3 . 1 ) and temporal structures ( Sect . 3 . 3 ) , however , it is not suﬃcient to simply extend existing parser models by addi - tional temporal parsing functionality . Instead we need a separate parsing sys - tem with a diﬀerent system architecture than the one described in Sect . 4 . 4 . 1 . We need a parser which can process temporal dependencies , a Temporal Parser . Like spatial and visual parser , also temporal parsers measure the strength of re - lationships between information objects . What diﬀerentiates such new parsing systems from their spatial and visual counterparts is , that they do not operate in geometrical 2d - space or in color space , but in time . Temporal parsers do not parse a canvas or a workspace . They rather analyze streams of edit events in or - der to detect how strongly related objects are . In doing so , however , they do not search for pre - deﬁned activity patterns . Just like our spatial and visual parser , also temporal parsers do not perform pattern matching . Since there is no one natural order in which people create spatial hypertext , it is simply not possible to predict user behaviour . We therefore cannot specify default - activities which were universally valid ( such as , for instance , constructor or destructor patterns for lists , tables etc . ) . Thus , we must limit ourselves to temporal heuristics . In a nutshell , our algorithm design was driven by the following simple rule : Pairs of objects frequently modiﬁed at short time intervals have a stronger tem - poral connection than objects touched infrequently or in long time intervals . Following this principle it becomes possible to recognize temporal dependencies between information objects , even without considering knowledge about system users or context of application . A complete formal deﬁnition of our temporal parsing algorithm can be found on the following pages 160 – 168 . An example is presented on pages 168 – 176 . 159 Chapter 4 . Prototype     Temporal Parser normalize push update _ temporal _ relations   + 1   Figure 4 . 29 : temporal parsers are dynamic systems determined by three core functions : push ( Eq . 4 . 213 ) , update _ temporal _ relations ( Eq . 4 . 214 ) and normalize ( Eq . 4 . 230 ) Our temporal parser transforms ingoing sequences of events e k ∈ E h Ω i ( Eq . 4 . 71 ) into outgoing sequences of interpretations I k ∈ I h Ω i ( Eq . 4 . 90 ) :  0 ,  1 , … ,    Temporal Parser  0 ,  1 , … ,    As illustrated in Fig . 4 . 29 the core of such dynamic systems is determined by three functions : ( 1 ) push ( Eq . 4 . 213 ) ; ( 2 ) update _ temporal _ relations ( Eq . 4 . 214 ) and ( 3 ) normalize ( Eq . 4 . 230 ) . In a nutshell , push adds ingoing events e k ∈ E h Ω i to an internal buﬀer , from which update _ temporal _ relations infers temporal dependencies that are ﬁnally brought into form I k ∈ I h Ω i by normalize . The buﬀers used for this are deﬁned by the following set of event tuples : B h Ω , ∆ k i =   ( e ∆ k , . . . , e 1 , e 0 ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) e k ∈ E h Ω i , k = 0 , 1 , . . . , ∆ k , ∆ k ∈ N 0   = ( E h Ω i ) ∆ k + 1 ( 4 . 211 ) In simple terms B h Ω , ∆ k i can be understood as the set of all non - empty buﬀers of length ∆ k + 1 whose elements are ∈ E h Ω i . Mathematically this corresponds to the ( ∆ k + 1 ) - ary cartesian product ( E h Ω i ) ∆ k + 1 . Buﬀers ( e ∆ k , . . . , e 1 , e 0 ) that include only empty events e k = ( ∅ , ε ) ( for k = 0 , 1 , . . . , ∆ k ) can be identiﬁed by the following subset of B h Ω , ∆ k i : B ε h ∆ k i =    ( e ∆ k , . . . , e 1 , e 0 ) (cid:12) (cid:12)(cid:12)(cid:12) (cid:12) (cid:12)(cid:12) e k = ( ∅ , ε ) , k = 0 , 1 , . . . , ∆ k , ∆ k ∈ N 0    ⊂ B h Ω , ∆ k i ( 4 . 212 ) 160 4 . 4 . Parsers The reason why we explicitly separate these empty buﬀers B ε h ∆ k i from their superset B h Ω , ∆ k i is , that we will later on use them as default settings . For the following deﬁnition of push h Ω , ∆ k i , however , only B h Ω , ∆ k i is relevant . push h Ω , ∆ k i accepts an event buﬀer ( e ∆ k , . . . , e 1 , e 0 ) ∈ B h Ω , ∆ k i and an ingo - ing event e ∈ E h Ω i and maps both to a new buﬀer ( e ′ ∆ k , . . . , e ′ 1 , e ) ∈ B h Ω , ∆ k i , with e ′ k = e k − 1 , for k = 1 , 2 , . . . , ∆ k : push h Ω , ∆ k i : ( B h Ω , ∆ k i × E h Ω i ) → B h Ω , ∆ k i , (cid:16) ( e ∆ k , . . . , e 1 , e 0 ) , e (cid:17) 7→ (cid:0) e ′ ∆ k , . . . , e ′ 1 , e (cid:1) , e ′ k = e k − 1 , k = 1 , 2 , . . . , ∆ k ( 4 . 213 ) In a nutshell , push h Ω , ∆ k i performs a left - shift . That is , we insert a new element at the right end of of the event tuple and remove one from the left . Hence , the buﬀer length remains unchanged . This way push h Ω , ∆ k i turns simple event tuples ( e ∆ k , . . . , e 1 , e 0 ) into ring buﬀers of capacity ∆ k + 1 . Such buﬀers are processed by update _ temporal _ relations h Ω , ∆ k , α i ( Eq . 4 . 214 ) . update _ temporal _ relations ( J , B ) accepts two arguments : J ∈ I h Ω , R + 0 i and B ∈ B h Ω , ∆ k i . J is an interpretation graph with weightings ∈ R + 0 . Note , that this should not be confused with the parser’s ﬁnal result interpretation ( which is ∈ I h Ω , { ε , 0 . 0 , . . . , 1 . 0 } i instead ) . J is rather meant to be an internal structure that is used to keep track of how frequently pairs of objects are modiﬁed . We will see afterwards how that works in detail . The second argument B shall be the latest event buﬀer generated by push h Ω , ∆ k i . That is , we expect B to be an event tuple ( e ∆ k , . . . , e 1 , e 0 ) ∈ B h Ω , ∆ k i with e 0 being the latest edit event . We deﬁne update _ temporal _ relations h Ω , ∆ k , α i as follows : update _ temporal _ relations h Ω , ∆ k , α i : (cid:16) I h Ω , R + 0 i × B h Ω , ∆ k i (cid:17) → I h Ω , R + 0 i , ( J , B ) 7→ trim (cid:16) add _ weights ( J , B ) (cid:17) ( 4 . 214 ) To put it brieﬂy , what happens in Eq . 4 . 214 is , that we infer the latest temporal weightings from buﬀer B , add them to the weights in J ( via add _ weights ( J , B ) ) and ﬁnally cut the resulting values down in order to prevent them from becom - ing arbitrarily large . The latter is achieved by trim which is deﬁned as . . . trim : I h Ω , R + 0 i → I h Ω , R + 0 i , I = ( U , A , w ) 7→ I ′ = (cid:0) U , A , w ′ (cid:1) , w ′ : A → R + 0 , ∀ a ∈ A : w ′ ( a ) =    w ( a ) − w + min ( I ) + 1 . 0 , if (cid:16) w + min ( I ) > 1 . 0 (cid:17) ∧ (cid:0) w ( a ) > 0 . 0 (cid:1) w ( a ) , else ( 4 . 215 ) 161 Chapter 4 . Prototype In short , when the smallest positive weight in I has exceeded a threshold of 1 . 0 ( i . e . , w + min ( I ) > 1 . 0 ) then trim ( I ) reduces all w ( a ) > 0 . 0 by ( w + min ( I ) − 1 . 0 ) . The smallest positive weight w ( a ) in ( U , A , w ) ∈ I h Ω , R + 0 i can be identiﬁed by : w + min : I h Ω , R + 0 i → R + 0 , w + min (cid:16) ( U , A , w ) (cid:17) =   min (cid:16) w ( A ) \ { 0 . 0 } (cid:17) , if (cid:16) w ( A ) \ { 0 . 0 } (cid:17) 6 = ∅ 0 . 0 , else ( 4 . 216 ) The second operation our deﬁnition of update _ temporal _ relations h Ω , ∆ k , α i builds on , is add _ weights h Ω , ∆ k , α i . add _ weights ( J , B ) takes an interpreta - tion graph J = ( U , A , w ) ∈ I h Ω , R + 0 i , analyses the temporal dependencies arising from a given event buﬀer B ∈ B h Ω , ∆ k i and generates a new graph ( U ′ , A ′ , w ′ ) ∈ I h Ω , R + 0 i with ( possibly ) increased temporal weightings : add _ weights h Ω , ∆ k , α i : (cid:16) I h Ω , R + 0 i × B h Ω , ∆ k i (cid:17) → I h Ω , R + 0 i , (cid:16) ( U , A , w ) , ( e ∆ k , . . . , e 1 , e 0 ) (cid:17) 7→ (cid:0) U ′ , A ′ , w ′ (cid:1) ( 4 . 217 ) Provided that e 0 represents the latest edit event , we deﬁne U ′ as . . . U ′ =      U ∪ e 0 . objects , if e 0 . operation = CREATE U \ e 0 . objects , if e 0 . operation = DELETE U , else ( 4 . 218 ) With this deﬁnition we ensure , that graphs ( U ′ , A ′ , w ′ ) ∈ I h Ω , R + 0 i that were generated by add _ weights h Ω , ∆ k , α i always include the latest collection of in - formation units U ′ . Since graphs ∈ I h Ω , R + 0 i are required to be complete , any modiﬁcation of U must be accompanied by the following update of A : A ′ =   A ∪ (cid:18) e 0 . objects 2 (cid:19) ∪   (cid:8) u , u ′ (cid:9) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) u ∈ U ∧ u ′ ∈ e 0 . objects   , if e 0 . operation = CREATE (cid:18) U ′ 2 (cid:19) , if e 0 . operation = DELETE A , else ( 4 . 219 ) Apparently , aside from the fact that both U ′ and A ′ depend on the latest event buﬀer entry e 0 , their deﬁnitions are identical to Eq . 4 . 185 and Eq . 4 . 186 or Eq . 4 . 204 and Eq . 4 . 205 respectively . 162 4 . 4 . Parsers This is not the case for w ′ . Unlike U ′ and A ′ the deﬁnition of w ′ diﬀers funda - mentally from Eq . 4 . 187 and Eq . 4 . 206 , not least because of a diﬀerent target set R + 0 but also because of diﬀerent semantics . In contrary to Eq . 4 . 187 and Eq . 4 . 206 the weighting function w ′ , as we deﬁne it here , assigns to associations a ∈ A ′ absolute rather than relative values . More precisely , temporal weight - ings w ′ ( a ) are rather counters for how frequently pairs of objects a = { u , u ′ } were modiﬁed than relative strength values ∈ { 0 . 0 , . . . , 1 . 0 } . Relative values are ﬁrst generated by function normalize which will be described afterwards on page 166 ( Eq . 4 . 230 ) . We deﬁne w ′ as follows : w ′ : A ′ → R + 0 , ∀ a ∈ A ′ : w ′ ( a ) =               w ( a ) , if   ( e 0 . operation = DELETE ) ∨ ( e 0 . operation = CREATE ∧ a ∈ A )   ∆ w ( a ) , if     ( e 0 . operation = CREATE ) ∧ (cid:16) a ∈ (cid:0) A ′ \ A (cid:1)(cid:17)     w ( a ) + ∆ w ( a ) , else ( 4 . 220 ) In Eq . 4 . 220 we map associations a ∈ A ′ either to w ( a ) , ∆ w ( a ) or w ( a ) + ∆ w ( a ) . Which term we choose depends on the value of e 0 . operation and whether a ∈ A . There are three speciﬁc cases : In case of e 0 . operation = CREATE ( when A ′ ⊇ A ) an explicit distinction should be made between new associations a ∈ ( A ′ \ A ) and a ∈ A . New associations a ∈ ( A ′ \ A ) do not have an assigned value w ( a ) since w is only deﬁned on A . This is why we “initialize” a with w ′ ( a ) = ∆ w ( a ) . If , otherwise , a ∈ A then assigned weights remain unchanged , that is w ′ ( a ) = w ( a ) . The reason for this is , that the creation of new objects should not have a direct impact on relations between objects that already existed . The same applies in case of e 0 . operation = DELETE . When objects were removed , and hence A ′ ⊆ A , weights of remaining associations a ∈ A ′ should not change . Therefore , ∀ a ∈ A ′ : w ′ ( a ) = w ( a ) which results in w ′ ⊆ w . In all other cases , when U ′ = U and thus also A ′ = A , temporal weightings w ( a ) get increased by ∆ w ( a ) , more precisely : ∀ a ∈ A ′ : w ′ ( a ) = w ( a ) + ∆ w ( a ) . This has the eﬀect of strengthening temporal connections . 163 Chapter 4 . Prototype We deﬁne this weighting delta ∆ w ( a ) as . . . ∆ w ( a ) = ( ∆ w ′ ( a ) , a ∈ Def (cid:0) ∆ w ′ (cid:1) 0 , else ( 4 . 221 ) Essentially , ∆ w ′ ( a ) assigns to each association a = { u , u ′ } for which we can ﬁnd at least one unordered pair of events { e 0 , e k } ( 0 ≤ k ≤ ∆ k ) in the event buﬀer , with u ∈ e 0 . objects and u ′ ∈ e k . objects , a weight inferred from the temporal distance between e 0 and e k ( that is , from k ) . We will see afterwards how such weightings are calculated . For all other associations the weighting delta becomes zero , hence ∆ w ( a ) = 0 . We deﬁne ∆ w ′ as a binary relation R ∆ w that assigns weighting deltas ∈ R + 0 to associations a ∈ Σ A ∆ ( ∆ k ) ( see Eq . 4 . 228 ) : ∆ w ′ : (cid:16) Σ A ∆ ( ∆ k ) (cid:17) → R + 0 , ∆ w ′ = R ∆ w ( 4 . 222 ) For assembling R ∆ w we determine for each event buﬀer entry e k ( for k = 0 to k = ∆ k ) the latest temporal connections between e 0 . objects and e k . objects , collect them in binary relations R ′ ∆ w ( k ) and ﬁnally calculate . . . R ′ ∆ w ( 0 ) ∪ R ′ ∆ w ( 1 ) ∪ . . . ∪ R ′ ∆ w ( ∆ k ) Hence , R ∆ w can be deﬁned as : R ∆ w = ∆ k [ k = 0 (cid:16) R ′ ∆ w ( k ) (cid:17) ( 4 . 223 ) Such binary relations R ′ ∆ w ( k ) assign to all a ∈ A ′ ∆ ( k ) ( see Eq . 4 . 226 ) positive real - valued weights ; hence A ′ ∆ ( k ) → R + 0 . The weighting formula used for this depends on two parameters α and k . It is deﬁned as : 2 − αk ( 4 . 224 ) Here , α is a real - valued tuning parameter that determines how temporal weights evolve for an increasing k ≥ 0 . With this determining factor it can be controlled whether object events occurring in long time intervals get more ( α < 0 ) , less ( α > 0 ) or the same weight ( α = 0 ) as events happening at short time intervals . Here we refer to events in discrete time . That is , our temporal weightings are determined by logical order only . The time that really ellapsed between pairs of events is not taken into consideration . This is intended to avoid temporal over - interpretation . 164 4 . 4 . Parsers Thus , when we go back from “present time” ( k = 0 ) to the earliest event the temporal parser can “remember” ( k = ∆ k ) our weighting formula will turn discrete time steps k = 0 , 1 , 2 , . . . , ∆ k into weighting deltas : 1 , 1 2 α , 1 2 2 α , . . . , 1 2 ∆ kα ( for any α ∈ R ) Binary relations formed by R ′ ∆ w ( k ) assign such weighting deltas 2 − αk to all a ∈ A ′ ∆ ( k ) ( see Eq . 4 . 226 ) . Thus , they can be deﬁned as : R ′ ∆ w ( k ) = [ a ∈ A ′ ∆ ( k ) n(cid:16) a , 2 − αk (cid:17)o ( 4 . 225 ) A ′ ∆ ( k ) determines all associations a = { u , u ′ } between objects u ∈ e 0 . objects and u ′ ∈ e k . objects ( i . e . , a ∈ A ∆ ( k ) ) for which there is no more recent event e j in the event buﬀer ( with j < k ) where u ′ ∈ e j . objects ( i . e . , a / ∈ Σ A ∆ ( k − 1 ) ) : A ′ ∆ ( k ) =    a (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)(cid:12) a ∈ A ∆ ( k ) ∧ a / ∈ Σ A ∆ ( k − 1 )    = (cid:16) A ∆ ( k ) \ Σ A ∆ ( k − 1 ) (cid:17) ⊆ A ∆ ( k ) ( 4 . 226 ) With A ∆ ( k ) we identify all { u , u ′ } between objects u that are aﬀected by the latest event in the event buﬀer ( i . e . , u ∈ e 0 . objects ) and objects u ′ for which an event occurred k discrete time steps in the past ( i . e . , u ′ ∈ e k . objects ) : A ∆ ( k ) =    (cid:8) u , u ′ (cid:9) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) u ∈ e 0 . objects ∧ u ′ ∈ e k . objects ∧ u 6 = u ′    ( 4 . 227 ) When we generalize A ∆ ( k ) from Eq . 4 . 227 for full ranges of discrete time steps 0 ≤ k ≤ n so that A ∆ ( 0 ) ∪ A ∆ ( 1 ) ∪ . . . ∪ A ∆ ( n ) then we get for n ≤ ∆ k : Σ A ∆ ( n ) =     n [ k = 0 A ∆ ( k )   , n ≥ 0 ∅ , else ( 4 . 228 ) Eq . 4 . 222 to Eq . 4 . 228 allow to simplify our original deﬁnition of ∆ w ( a ) from Eq . 4 . 221 to : ∆ w ( a ) = ∆ k X k = 0 (cid:18) (cid:12) (cid:12) (cid:12) { a } ∩ (cid:0) A ∆ ( k ) \ Σ A ∆ ( k − 1 ) (cid:1) (cid:12)(cid:12) (cid:12) × 2 − αk (cid:19) ( 4 . 229 ) 165 Chapter 4 . Prototype Expressed in simple terms , update _ temporal _ relations h Ω , ∆ k , α i , as we deﬁned it in Eq . 4 . 214 , counts how frequently pairs of objects { u , u ′ } are modiﬁed and stores these values in a complete graph ∈ I h Ω , R + 0 i . Even though the temporal parser does not build on the generic parser model we deﬁned in Sect . 4 . 4 . 1 , it still has to be compatible with our parser deﬁnition from Sect . 4 . 2 . 4 . Otherwise , it would not be possible to integrate it into our prototype system . Consequently , the temporal parser must accept ( parts of ) ingoing edit steps ( e , D ) ∈ ( E h Ω i × D h Ω , k i ) ( see Eq . 4 . 71 ; Eq . 4 . 85 ) and has to generate temporal interpretations I ∈ I h Ω i ( Eq . 4 . 90 ) as output . The ﬁrst condition is met by our deﬁnition of push h Ω , ∆ k i in Eq . 4 . 213 . The second one is guaranteed to be satisﬁed by the following deﬁnition of normalize : normalize ( I ) accepts interpretation graphs I ∈ I h Ω , R + 0 i , as generated by update _ temporal _ relations h Ω , ∆ k , α i , transforms included temporal weight - ings ( or rather frequency values ) into relative strength values ∈ { 0 . 0 , . . . , 1 . 0 } and provides that result in form of an interpretation I ′ ∈ I h Ω i : normalize : I h Ω , R + 0 i → I h Ω i , ( U , A , w ) 7→ (cid:0) U , A , w ′ (cid:1) , w ′ : A → { 0 . 0 . . . 1 . 0 } , ∀ a ∈ A : w ′ ( a ) =    w ( a ) max (cid:16) w ( A ) (cid:17) , if max (cid:16) w ( A ) (cid:17) > 0 0 , else ( 4 . 230 ) The rationale behind this weight transformation is , that temporal dependen - cies are something relative . This means , unlike spatial , visual and content parsing , where it is ( theoretically ) suﬃcient to view pairs of objects in isola - tion , temporal parsing cannot be performed without considering the context ( i . e . the relations between all objects in U ) . Only when we know which ( of all ) u , u ′ ∈ U were touched most frequently we can infer reasonable strength values ∈ { 0 . 0 . . . 1 . 0 } for all pairs of objects . This is why in Eq . 4 . 230 we map max ( w ( A ) ) to 1 . 0 and w ( a ) < max ( w ( A ) ) to weightings < 1 . 0 . Provided that push h Ω , ∆ k i ( Eq . 4 . 213 ) , update _ temporal _ relations h Ω , ∆ k , α i ( Eq . 4 . 214 ) and normalize ( Eq . 4 . 230 ) are sequentially connected , sharing the same event buﬀer B ∈ B h Ω , ∆ k i and frequency graph J ∈ I h Ω , R + 0 i , we can un - derstand temporal parsers as dynamic systems , that accept ingoing sequences of events e k ∈ E h Ω i and generate ( depending on latest buﬀer entries in B and collected weights in J ) outgoing sequences of interpretations I k ∈ I h Ω i . As with spatial parser ( Eq . 4 . 120 ) , visual parser ( Eq . 4 . 182 ) and content parser ( Eq . 4 . 201 ) also such temporal parsing systems can be described using deter - ministic automata . Such a model with initial state ( B , I ε ) , for B ∈ B ε h ∆ k i ( Eq . 4 . 212 ) , is given in the following Eq . 4 . 231 . For a deﬁnition of the empty interpretation I ε see Eq . 4 . 89 . 166 4 . 4 . Parsers A T h Ω , ∆ k , α i =   S T h Ω , ∆ k i , E T h Ω i , O T h Ω i , T T h Ω , ∆ k , α i , G T h Ω , ∆ k , α i , s init h ∆ k i   , ∆ k ∈ N 0 , α ∈ R S T h Ω , ∆ k i = B h Ω , ∆ k i × I h Ω , R + 0 i E T h Ω i = E h Ω i O T h Ω i = I h Ω i T T h Ω , ∆ k , α i : (cid:0) S T h Ω , ∆ k i × E T h Ω i (cid:1) → S T h Ω , ∆ k i , (cid:16) ( B , J ) , e (cid:17) 7→ (cid:0) B ′ , J ′ (cid:1) , B ′ = push h Ω , ∆ k i ( B , e ) J ′ = update _ temporal _ relations h Ω , ∆ k , α i (cid:0) J , B ′ (cid:1) G T h Ω , ∆ k , α i : (cid:0) S T h Ω , ∆ k i × E T h Ω i (cid:1) → O T h Ω i , (cid:16) ( B , J ) , e (cid:17) 7→ I , I = normalize (cid:0) J ′ (cid:1) , (cid:0) B ′ , J ′ (cid:1) = T T h Ω , ∆ k , α i (cid:16) ( B , J ) , e (cid:17) s init h ∆ k i = ( B , I ε ) ∈ S T h Ω , ∆ k i , B ∈ B ε h ∆ k i ( 4 . 231 ) Illustrated as a block diagram :     Temporal Parser       (cid:1828)  (cid:1828)  + 1 (cid:1836)  (cid:1836)  + 1 normalize push update _ temporal _ relations 167 Chapter 4 . Prototype We can conclusively summarize the behaviour of temporal parsers as follows : Temporal parsers A T h Ω , ∆ k , α i , as they are deﬁned by Eq . 4 . 231 , accept ingoing sequences of edit events E ( 0 . . . k e ) , E ( 0 . . . k e ) = (cid:0) e 0 , e 1 , . . . , e k e (cid:1) , e k ∈ E T h Ω i , k = 0 , 1 , . . . , k e Driven by E ( 0 . . . k e ) they pass through states S ( 0 . . . k e + 1 ) , S ( 0 . . . k e + 1 ) = (cid:0) s 0 , s 1 , . . . , s k e + 1 (cid:1) = (cid:18) B 0 J 0 (cid:19) , (cid:18) B 1 J 1 (cid:19) , . . . , (cid:18) B k e + 1 J k e + 1 (cid:19) ! , s 0 = s init h ∆ k i s k + 1 = T T h Ω , ∆ k , α i ( s k , e k ) , k = 0 , 1 , . . . , k e Sequences of interpretations I ( 0 . . . k e ) are provided as output : I ( 0 . . . k e ) = (cid:0) I 0 , I 1 , . . . , I k e (cid:1) , I k = G T h Ω , ∆ k , α i ( s k , e k ) , k = 0 , 1 , . . . , k e For a better understanding of Eq . 4 . 231 , let us ﬁnally go through an example . As with spatial and visual parser , default parameter settings have emerged also from our practical experience with the temporal parser . Those settings allow us to reﬁne the generic temporal parser model from Eq . 4 . 231 as follows : A T : = A T h N 0 , 6 , 0 . 5 i T T : = T T h N 0 , 6 , 0 . 5 i G T : = G T h N 0 , 6 , 0 . 5 i ( 4 . 232 ) However , for the sake of simplicity , we do not use this conﬁguration for the following demonstration . In order to simplify calculation and thus to keep mathematical expressions as short as possible we rather set . . . Ω = N 0 ; ∆ k = 3 ; α = 1 . 0 Hence , for our sample run the temporal parser becomes . . . A T h N 0 , 3 , 1 . 0 i In brief , this means that ( 1 ) information units are identiﬁed by integers ≥ 0 ; ( 2 ) the parser keeps a maximum of ∆ k + 1 = 4 edit events in “memory” ( Eq . 4 . 211 ) and ( 3 ) pairs of events { e 0 , e k } get weighted with 2 − k ( see Eq . 4 . 224 ) . 168 4 . 4 . Parsers According to Eq . 4 . 231 the initial state s 0 of A T h N 0 , 3 , 1 . 0 i becomes : s 0 = (cid:18) B 0 J 0 (cid:19) = s init h 3 i =   (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1)(cid:17) (cid:0) ∅ , ∅ , ∅ (cid:1)   So we start out with two components , an event buﬀer B 0 with capacity 4 that includes only empty events . . . B 0 = (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1)(cid:17) ∈ B ε h 3 i . . . and an empty frequency graph J 0 : J 0 = I ε = (cid:0) ∅ , ∅ , ∅ (cid:1) ∈ I h N 0 , R + 0 i Let us now assume the following scenario : Three rectangular information units are generated in sequential steps one after the other . For the sake of simplicity , we number them consecutively as 0 , 1 , 2 . Position , alignment , color etc . are of no importance in this example . When all three rectangles exist the shape of objects 1 und 2 shall change from RECTANGLE to ELLIPSE ( that is , both objects are modiﬁed spatially ; for details on this see Eq . 4 . 101 and Eq . 4 . 65 ) . Finally object 1 is deleted . This simple ﬁve - stage editing process can be ap - proximately described with the following sequence of events : E ( 0 . . . 4 ) = ( e 0 , e 1 , e 2 , e 3 , e 4 ) =      (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) , (cid:0) { 1 } , DELETE (cid:1)      Let us now demonstrate how A T h N 0 , 3 , 1 . 0 i reacts to this ingoing sequence of events . We begin by generating the ﬁrst rectangular information unit 0 . . . . . . which is represented symbolically by e 0 = ( { 0 } , CREATE ) . As we know already , single temporal parser runs always take place in three sequential steps : ( 1 ) buﬀering the latest input event e k : B k + 1 = push ( B k , e k ) ; ( 2 ) updating frequency graph J k : J k + 1 = update _ temporal _ relations ( J k , B k + 1 ) and ( 3 ) transforming J k + 1 into I k ∈ I h Ω i : I k = normalize ( J k + 1 ) . 169 Chapter 4 . Prototype In our example , the ﬁrst two steps ( buﬀering e 0 and updating J 0 ) result in : B 1 = push ( B 0 , e 0 ) = (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1)(cid:17) J 1 = update _ temporal _ relations ( J 0 , B 1 ) = (cid:0) { 0 } , ∅ , ∅ (cid:1) Therefore , driven by e 0 = ( { 0 } , CREATE ) , the temporal parser A T h N 0 , 3 , 1 . 0 i switches from it’s initial state . . . (cid:18) B 0 J 0 (cid:19) =   (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1)(cid:17) (cid:0) ∅ , ∅ , ∅ (cid:1)   . . . to a ﬁrst successor state : (cid:18) B 1 J 1 (cid:19) =   (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1)(cid:17) (cid:0) { 0 } , ∅ , ∅ (cid:1)   Normalizing J 1 = ( { 0 } , ∅ , ∅ ) results in an identical I 0 : I 0 = normalize ( J 1 ) = (cid:0) { 0 } , ∅ , ∅ (cid:1) From U ( I 0 ) = { 0 } it becomes obvious , that all the temporal parser has recog - nized so far is a single information unit labeled with 0 . Weighted associations are not included yet in I 0 ; thus A ( I 0 ) = ∅ . This changes with the second edit step when we introduce another rectangular information unit 1 and hence complete the ﬁrst pair of objects { 0 , 1 } . Let us assume the following updated workspace : When we add the creation event for object 1 ( i . e . , e 1 = ( { 1 } , CREATE ) ) to our event buﬀer B 1 we get ( similar to the ﬁrst edit step e 0 ) : B 2 = push ( B 1 , e 1 ) = (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) (cid:17) 170 4 . 4 . Parsers Thus , the ﬁrst two cells of B 2 are now assigned with non - empty events . Using this updated event buﬀer , previous frequency graph J 1 = ( { 0 } , ∅ , ∅ ) becomes : J 2 = update _ temporal _ relations ( J 1 , B 2 ) = { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , (cid:26)(cid:16) { 0 , 1 } , ∆ w (cid:0) { 0 , 1 } (cid:1)(cid:17)(cid:27) ! = { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , (cid:26)(cid:16) { 0 , 1 } , 2 − 1 (cid:17)(cid:27) ! = (cid:18) { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , n(cid:0) { 0 , 1 } , 0 . 5 (cid:1)o(cid:19) Here , the temporal parser has assigned the ﬁrst pair of objects a weighting : { 0 , 1 } is initialized with ∆ w ( { 0 , 1 } ) . Since 1 ∈ e 0 . objects , 0 ∈ e 1 . objects and α = 1 . 0 this initial temporal weight becomes 2 − αk = 2 − k = 2 − 1 = 0 . 5 . For details see Eq . 4 . 220 and Eq . 4 . 229 . Therefore , A T h N 0 , 3 , 1 . 0 i switches from . . . (cid:18) B 1 J 1 (cid:19) =   (cid:16) (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) (cid:17) (cid:0) { 0 } , ∅ , ∅ (cid:1)   . . . to consecutive state : (cid:18) B 2 J 2 (cid:19) =    (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1)(cid:17) (cid:18) { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , n(cid:0) { 0 , 1 } , 0 . 5 (cid:1)o (cid:19)     Because ∆ w ( { 0 , 1 } ) = 0 . 5 is the ﬁrst and only weight in J 2 , it is necessarily also the biggest one . Therefore , the strongest temporal connection in J 2 exists between object 0 und object 1 . Consequently normalize transforms J 2 into the following I 1 : I 1 = normalize ( J 2 ) = (cid:18) { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , n(cid:0) { 0 , 1 } , 1 . 0 (cid:1)o(cid:19) Illustrated graphically I 1 becomes : 171 Chapter 4 . Prototype Like in previous illustrations of interpretation graphs , also here weightings are drawn as black lines with varying brightness , thickness and opacity . The higher weightings are the thicker the connecting line and the stronger the line color . In this simple example weight 1 . 0 is drawn as an opaque black bar . In a similar fashion A T h N 0 , 3 , 1 . 0 i reacts to the creation of the third and last object , symbolized by ( { 2 } , CREATE ) . For this let us assume the following updated information space : Now , the event buﬀer includes all three creation events ( for 0 , 1 and 2 ) : B 3 = push ( B 2 , e 2 ) = (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1)(cid:17) update _ temporal _ relations ( J 2 , B 3 ) leaves the weighting of { 0 , 1 } unchanged and initializes new associations { 0 , 2 } with ∆ w ( { 0 , 2 } ) = 2 − 2 = 0 . 25 and { 1 , 2 } with ∆ w ( { 1 , 2 } ) = 2 − 1 = 0 . 5 : J 3 = update _ temporal _ relations ( J 2 , B 3 ) =   { 0 , 1 , 2 } ,   { 0 , 1 } , { 0 , 2 } , { 1 , 2 }   ,   (cid:16) { 0 , 1 } , w (cid:0) { 0 , 1 } (cid:1)(cid:17) , (cid:16) { 0 , 2 } , ∆ w (cid:0) { 0 , 2 } (cid:1)(cid:17) , (cid:16) { 1 , 2 } , ∆ w (cid:0) { 1 , 2 } (cid:1)(cid:17)     =   { 0 , 1 , 2 } ,   { 0 , 1 } , { 0 , 2 } , { 1 , 2 }   ,   (cid:0) { 0 , 1 } , 0 . 5 (cid:1) , (cid:0) { 0 , 2 } , 2 − 2 (cid:1) , (cid:0) { 1 , 2 } , 2 − 1 (cid:1)     =     { 0 , 1 , 2 } ,     { 0 , 1 } , { 0 , 2 } , { 1 , 2 }     ,     (cid:0) { 0 , 1 } , 0 . 50 (cid:1) , (cid:0) { 0 , 2 } , 0 . 25 (cid:1) , (cid:0) { 1 , 2 } , 0 . 50 (cid:1)        172 4 . 4 . Parsers Thus , A T h N 0 , 3 , 1 . 0 i switches from . . . (cid:18) B 2 J 2 (cid:19) =   (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1)(cid:17) (cid:18) { 0 , 1 } , (cid:8) { 0 , 1 } (cid:9) , n(cid:0) { 0 , 1 } , 0 . 5 (cid:1)o(cid:19)   . . . to successor state : (cid:18) B 3 J 3 (cid:19) =      (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1)(cid:17)   { 0 , 1 , 2 } ,    { 0 , 1 } , { 0 , 2 } , { 1 , 2 }    ,     (cid:0) { 0 , 1 } , 0 . 50 (cid:1) , (cid:0) { 0 , 2 } , 0 . 25 (cid:1) , (cid:0) { 1 , 2 } , 0 . 50 (cid:1)           Now the strongest temporal connections can be found between 0 , 1 and 1 , 2 . Both pairs of objects { 0 , 1 } and { 1 , 2 } have the same maximal weight 0 . 5 . Objects 0 and 2 , however , were not created immediately one after the other but with event ( { 1 } , CREATE ) in between . For this reason , the temporal connection between 0 and 2 is only half as strong as between 0 , 1 and 1 , 2 . This gets also reﬂected by the strength values calculated by normalize ( J 3 ) : I 2 = normalize ( J 3 ) =     { 0 , 1 , 2 } ,    { 0 , 1 } , { 0 , 2 } , { 1 , 2 }    ,     (cid:0) { 0 , 1 } , 1 . 0 (cid:1) , (cid:0) { 0 , 2 } , 0 . 5 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0 (cid:1)       Illustrated graphically : As now all three information units exist ( 0 , 1 and 2 ) they can be modiﬁed . Ac - cording to our editing process described at the beginning , there should be only a single MODIFY - operation : that is , the last two objects 1 and 2 shall change their shape from RECTANGLE to ELLIPSE . Position , size , proportions etc . should remain unaltered . 173 Chapter 4 . Prototype This might look as follows : As deﬁned in Eq . 4 . 101 and Eq . 4 . 65 , altering shapes is treated as spatial mod - iﬁcation ( i . e . , MODIFY _ SPATIAL ) . Thus e 3 = ( { 1 , 2 } , MODIFY _ SPATIAL ) . The updated event buﬀer B 4 no longer contains empty events : B 4 = push ( B 3 , e 3 ) = (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) ! Spatially modifying units 1 and 2 aﬀects all three pairs of objects in J 3 , { 0 , 1 } , { 0 , 2 } and { 1 , 2 } . According to our deﬁnitions from Eq . 4 . 220 their temporal connections must be strengthened as follows : J 4 = update _ temporal _ relations ( J 3 , B 4 ) =   { 0 , 1 , 2 } ,    { 0 , 1 } , { 0 , 2 } , { 1 , 2 }    ,     (cid:16) { 0 , 1 } , w (cid:0) { 0 , 1 } (cid:1) + ∆ w (cid:0) { 0 , 1 } (cid:1) (cid:17) , (cid:16) { 0 , 2 } , w (cid:0) { 0 , 2 } (cid:1) + ∆ w (cid:0) { 0 , 2 } (cid:1)(cid:17) , (cid:16) { 1 , 2 } , w (cid:0) { 1 , 2 } (cid:1) + ∆ w (cid:0) { 1 , 2 } (cid:1)(cid:17)       =   { 0 , 1 , 2 } ,   { 0 , 1 } , { 0 , 2 } , { 1 , 2 }   ,   (cid:0) { 0 , 1 } , 0 . 50 + 2 − 3 (cid:1) , (cid:0) { 0 , 2 } , 0 . 25 + 2 − 3 (cid:1) , (cid:0) { 1 , 2 } , 0 . 50 + 2 − 0 (cid:1)     =   { 0 , 1 , 2 } ,   { 0 , 1 } , { 0 , 2 } , { 1 , 2 }   ,   (cid:0) { 0 , 1 } , 0 . 50 + 0 . 125 (cid:1) , (cid:0) { 0 , 2 } , 0 . 25 + 0 . 125 (cid:1) , (cid:0) { 1 , 2 } , 0 . 50 + 1 . 000 (cid:1)     =    { 0 , 1 , 2 } ,     { 0 , 1 } , { 0 , 2 } , { 1 , 2 }     ,     (cid:0) { 0 , 1 } , 0 . 625 (cid:1) , (cid:0) { 0 , 2 } , 0 . 375 (cid:1) , (cid:0) { 1 , 2 } , 1 . 500 (cid:1)        174 4 . 4 . Parsers A T h N 0 , 3 , 1 . 0 i switches from . . . (cid:18) B 3 J 3 (cid:19) =   (cid:16)(cid:0) ∅ , ε (cid:1) , (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1)(cid:17)   { 0 , 1 , 2 } ,   { 0 , 1 } , { 0 , 2 } , { 1 , 2 }   ,   (cid:0) { 0 , 1 } , 0 . 50 (cid:1) , (cid:0) { 0 , 2 } , 0 . 25 (cid:1) , (cid:0) { 1 , 2 } , 0 . 50 (cid:1)       . . . to : (cid:18) B 4 J 4 (cid:19) =        (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) !    { 0 , 1 , 2 } ,     { 0 , 1 } , { 0 , 2 } , { 1 , 2 }     ,     (cid:0) { 0 , 1 } , 0 . 625 (cid:1) , (cid:0) { 0 , 2 } , 0 . 375 (cid:1) , (cid:0) { 1 , 2 } , 1 . 500 (cid:1)               Now the strongest temporal connection exists between modiﬁed objects 1 , 2 : I 3 = normalize ( J 4 ) =   { 0 , 1 , 2 } ,    { 0 , 1 } , { 0 , 2 } , { 1 , 2 }    ,     (cid:0) { 0 , 1 } , 0 . 4167 (cid:1) , (cid:0) { 0 , 2 } , 0 . 2500 (cid:1) , (cid:0) { 1 , 2 } , 1 . 0000 (cid:1)        Illustrated graphically : The ﬁfth and last step in our sample editing process is deleting object 1 : 175 Chapter 4 . Prototype Pushing the respective event e 4 = ( { 1 } , DELETE ) to our current event buﬀer B 4 results in an overﬂow . This means , the oldest event ( { 0 } , CREATE ) is removed from the buﬀer . Thus B 4 turns into : B 5 = push ( B 4 , e 4 ) = (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) , (cid:0) { 1 } , DELETE (cid:1) ! According to Eq . 4 . 220 DELETE - operations leave the weightings of remaining associations unchanged . This means in our case : J 5 = update _ temporal _ relations ( J 4 , B 5 ) = (cid:18) { 0 , 2 } , (cid:8) { 0 , 2 } (cid:9) , n(cid:0) { 0 , 2 } , 0 . 375 (cid:1)o(cid:19) Thus , A T h N 0 , 3 , 1 . 0 i switches with the last event of our ﬁve - stage editing pro - cess from state . . . (cid:18) B 4 J 4 (cid:19) =         (cid:0) { 0 } , CREATE (cid:1) , (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) !     { 0 , 1 , 2 } ,     { 0 , 1 } , { 0 , 2 } , { 1 , 2 }     ,     (cid:0) { 0 , 1 } , 0 . 625 (cid:1) , (cid:0) { 0 , 2 } , 0 . 375 (cid:1) , (cid:0) { 1 , 2 } , 1 . 500 (cid:1)               . . . to ﬁnal state : (cid:18) B 5 J 5 (cid:19) =   (cid:0) { 1 } , CREATE (cid:1) , (cid:0) { 2 } , CREATE (cid:1) , (cid:0) { 1 , 2 } , MODIFY _ SPATIAL (cid:1) , (cid:0) { 1 } , DELETE (cid:1) ! (cid:18) { 0 , 2 } , (cid:8) { 0 , 2 } (cid:9) , n(cid:0) { 0 , 2 } , 0 . 375 (cid:1)o(cid:19)   Since J 5 includes only a single pair of objects { 0 , 2 } normalize ( J 5 ) results in : I 4 = normalize ( J 5 ) = (cid:18) { 0 , 2 } , (cid:8) { 0 , 2 } (cid:9) , n(cid:0) { 0 , 2 } , 1 . 0 (cid:1)o(cid:19) Illustrated graphically I 4 becomes : 176 Chapter 5 Test As we know from Sect . 1 . 2 lack of clarity is inherently part of spatial hypertext . This makes disambiguation an important core feature of spatial parsers . How - ever , resolving ambiguities in spatial hypertext requires knowledge which only hypertext authors can have . Typically , such knowledge is not encoded in sin - gle spatial hypertext artifacts . Therefore , conventional ( non - adaptive ) parsers cannot include such information into their analysis . Due to this conceptional limitation there are several types of structures that cannot be recognized prop - erly , including : ( 1 ) ambiguous structures ( Sect . 3 . 1 ) ; ( 2 ) destroyed structures ( Sect . 3 . 2 ) and ( 3 ) temporal structures ( Sect . 3 . 3 ) . In order to overcome this issue we suggested in Sect . 3 . 4 to consider not only spatial and visual properties , but also temporal aspects in spatial parser de - signs . A spatial parser that is “aware” of previous structures ( see “fading” in Sect . 4 . 4 . 1 ; pages 93 – 94 ) and “knows” about temporal dependencies between information units ( see temporal parser in Sect . 4 . 4 . 5 ) could ( a ) ﬁlter out discrete structures most likely seen by human users ; ( b ) complete corrupted structures and ( c ) detect associations that are purly temporal . Both , temporal parser as well as fading - feature were implemented in a pro - totypical spatial hypermedia system , strictly following our theoretical system model from Chapter 4 . According to that model , spatial hypermedia systems are compositions of editing systems supporting in the creation of spatial hy - pertext ( Sect . 4 . 1 ) and interpretation systems performing structural analysis ( Sect . 4 . 2 ) . Editing systems are mainly determined by workspace models as described in Sect . 4 . 1 . 3 , whereas interpretation systems are primarily deﬁned by parsing algorithms ( Sect . 4 . 4 ) . 177 Chapter 5 . Test For our research prototype we speciﬁed in Sect . 4 . 1 . 4 several reﬁnements re - garding visual language , object keys , content etc . This has led to default con - ﬁgurations for both workspace model A W ( Eq . 4 . 66 ) as well as for parsers A S ( Eq . 4 . 121 ) , A V ( Eq . 4 . 183 ) , A C ( Eq . 4 . 202 ) and A T ( Eq . 4 . 232 ) . A full block - diagram of our prototypical spatial hypermedia system can be found in the appendix on page 216 . A screenshot of the user interface is given on page 217 . This freely conﬁgurable reference implementation could be used for researching diverse topics , such as parser performance , optimal system conﬁguration , user behaviour etc . In this thesis we focus on a single aspect only , namely , parser performance . More speciﬁcally , we examine synergies between spatial parser ( Sect . 4 . 4 . 2 ) , visual parser ( Sect . 4 . 4 . 3 ) and temporal parser ( Sect . 4 . 4 . 5 ) . Content parsers are not included in our analysis . Initial tests with the content parser from Sect . 4 . 4 . 4 suggested , that using it in a productive system would require adaption to user - requirements . For our investigations of parsing perfor - mance , however , we expect that tuning of parser settings is not required . For this reason we decided to exclude the content parser from our test . A second restriction concerns our previously mentioned implementation of structure fading ( Sect . 4 . 4 . 1 ; pages 93 – 94 ) . Just like the content parser also fading is not included in our performance analysis . The reason for this is as follows : The longer you are restructuring a spatial hypertext the higher the risk of accidentally or unnoticeably destroying structure . Only then it makes sense to include previous object relations into the analysis ( or to reject them if they do not get refreshed ) . Only then it makes sense to include the fading - eﬀect . Or in other words , the fading - feature will show its real added value only after long time use . Thus , for validation , long - term studies should be preferred over short - term tests . In our analysis , however , we build on short surveys . In principle this limitation also applies to the evolution of temporal dependen - cies and therefore on the temporal parser . Most likely , many structures will emerge only after a certain period of time . Nevertheless , there were reasons to believe that the temporal parser would show its beneﬁt also in short - term tests . Perhaps not as obvious as it might be possible after really long working sessions in a productive environment , but still veriﬁable . In Sect . 3 . 4 we claimed , that considering not only spatial and visual properties but also temporal aspects in spatial parser design can lead to a signiﬁcant in - crease in parsing accuracy , detection of richer structures and herewith higher parser performance . What still remains to be done , however , is delivering the proof that such a spatio - temporal parser really performs better than a conven - tional spatial parser . This chapter is intended to change that . 178 5 . 1 . Reference Data Collection We want to show , that spatial parser performance ( i . e . , accuracy ) can be sig - niﬁcantly increased when taking into account not only spatial and visual but also temporal object relations . We expect that the addition of a temporal parser ( as deﬁned in Sect . 4 . 4 . 5 ) will shift machine detected structures ( encoded in interpretations ; Sect . 4 . 2 . 3 ) signiﬁcantly closer to what target users ( knowledge workers with technical back - ground ) intend to express . 5 . 1 Reference Data Collection Parsers as we deﬁned them in Sect . 4 . 4 . 1 and Sect . 4 . 4 . 5 generate formal inter - pretations I ∈ I h Ω i ( Sect . 4 . 2 . 3 ) . Technically , such parse results are complete , weighted graphs of connected information objects . This makes it possible to compare them numerically . However , interpretations generated by parsers do not include information about their accuracy . Therefore , putting them in di - rect relation allows no conclusions regarding diﬀerences in parser performance . This required us to collect reference data . Whether something is structure or not is highly subjective , hence reference interpretations cannot be generated artiﬁcially . There is also no set of standard structures that could be used as a basis for comparison . For this reason we decided to collect our reference data by surveys in a laboratory . This , however , required an adaption of our research prototype . 5 . 1 . 1 Adapted Prototype When linked together , editing systems and interpretation systems realise in - teractive structure creation loops that are driven by user activities . This rep - resents the functional core of spatial hypermedia systems and thus formed the basis for our theoretical system model from Chapter 4 . We mentioned that already on page 47 . Fig . 5 . 1 illustrates that for our prototype . According to that , editing systems accept user interface activities ( such as keyboard or mouse events etc . ) and transform them into edit events e k ∈ E W and workspaces W k ∈ O W ( Eq . 4 . 66 ) . Both e k and W k are then converted into “edit steps” ( e ′ k , D k ) , with e ′ k ∈ E h N 0 i and D k ∈ D h N 0 , 16 i ( Eq . 4 . 71 , Eq . 4 . 85 ) . Interpretation systems react on such ingoing ( e ′ k , D k ) by generating interpretations I k ∈ I h N 0 i ( Eq . 4 . 90 ) . These parse results are ﬁnally transmitted back to presentation level as I ′ k where they are displayed as graphical overlays on the workspace . 179 Chapter 5 . Test Spatial Hypermedia System Interpretation System  ′       ′      Editing System conversion Figure 5 . 1 : When linked together , editing systems and interpretation systems realise inter - active structure creation loops , or visual feedback loops , that are initiated by system users . This is the expected behaviour in productive working environments . This forms a visual feedback - loop where human and machine “interact” to grad - ually develop meaningful visual structure . Although this is the expected be - haviour in a productive working environment it is not what we want when collecting reference data . For this reason , two essential modiﬁcations to our research prototype were needed . Firstly , we enhanced our system with logging - functionality . This is why the adjusted system model illustrated in Fig . 5 . 2 includes , in addition to the already known components , another module labeled with “log” . Plugged in between conversion layer and interpretation system this logging module records ingoing streams of edit steps ( e ′ k , D k ) . This mechanism can be used to store full working sessions in persistent memory ( e . g . , in a log - ﬁle ) . Loading and “replaying” recorded editing processes ﬁnally allows to “simulate” user behaviour in a virtual test environment . This makes it possible to repeat one an the same user session with diﬀerent parser conﬁgurations . Secondly , we had to make sure that test persons were not inﬂuenced by machine generated feedback . This was achieved by deactivating or rather by excluding the interpretation system from the test prototype . Thus , the prototype ap - plication we used in our surveys included no parser functionality . The system model given in Fig . 5 . 3 illustrated that . For the sake of completeness , it should be noted that this stripped - down version of our system model rather describes visual editors with integrated logging functionality than full - ﬂedged spatial hy - permedia systems . For this see also our considerations in Chapter 3 or Sect . 4 . 2 . However , for our survey this was of no importance . 180 5 . 1 . Reference Data Collection Spatial Hypermedia System Interpretation System  ′       ′      Editing System conversion  ′  log    ′ 0  0 ,  ′ 1  1 , … ,  ′      Figure 5 . 2 : Spatial hypermedia system model extended by logging functionality . Streams of edit steps ( e ′ k , D k ) passing the logging system on their way from conversion to interpretation system are recorded in persistent memory . Our prototype application writes them to log - ﬁles . Spatial Hypermedia System  ′      Editing System log  ′ 0  0 ,  ′ 1  1 , … ,  ′      conversion   Figure 5 . 3 : Stripped - down version of our system model from Fig . 5 . 2 without interpretation system . This is rather an advanced visual editor with integrated logging functionality than a fully - ﬂedged spatial hypermedia system . 181 Chapter 5 . Test 5 . 1 . 2 Survey The second challenge , besides adapting our research prototype , was to estab - lish realistic test conditions . This required to ﬁnd persons who were willing to participate in a laboratory test . Only if probands participate voluntarily in a survey , there is a chance to get realistic and therefore useful results . When subjects , however , feel unwell in a given test situation , then free development of thoughts is excluded right from the start , which inevitably falsiﬁes test re - sults . This is especially true for creative processes , such as developing spatial hypertexts . Thus , particular attention had to be paid to ensuring that subjects had , right from the beginning , a positive attitude to their task . There are lots of factors which can have a negative impact on a test person’s motivation , in - cluding biorhythm , stress or test duration . This makes the creation of optimal test conditions a challenge . For our survey we proceeded as follows : Firstly , potential test candidates were asked to attend a small experiment , on a voluntary basis . We did that only on working days with low time pressure and at a biorhythmically optimal time . It turned out that our estimated test duration seemed to play an essential role for probands , when deciding whether to participate or not . An average duration of 20 minutes was accepted by most test persons . Longer tests , however , had a rather deterrent eﬀect . For this reason , and because we believed that such a short timeframe still would be enough for showing the desired temporal eﬀects , we decided to adhere to an average test duration of 20 minutes and an upper time limit of half an hour . In total , we were able to convince 50 persons to join our survey . All participants had a technical background in computer sciences , ranging from Bachelor - to PhD - level . Therefore , it could be assumed that they knew how to use a visual modelling tool . However , it should be pointed out that none of these 50 people had used a spatial hypermedia system before . Once a person had agreed to participate , he was asked to take a seat in a special laboratory room prepared for the test run . Fig . 5 . 4 shows a photo of the setup . The participant sat down in front of a 65 - inches computer monitor ( that was still switched oﬀ at that point in time ) , and was then informed about the basic test conditions . After that , we had to make sure that the test person was familiar with the prototype’s user interface . Simply playing around with or ( even worse ) incorrect usage of the prototype’s visual tools would have unnecessarily falsiﬁed our test results . Even though we had implemented only a small number of common GUI - features in our test application ( such as zooming , panning , scaling etc . ) , we decided to still demonstrate each of those features to every single test person . For these purposes we prepared a simple demo hypertext that was formed from random objects only . These objects neither had any visual nor semantic relation with the hypertext used for the test . During 182 5 . 1 . Reference Data Collection Figure 5 . 4 : experimental setup – core hardware components : wireless keyboard / mouse , mini - PC ( Dual - Core Processor 1 . 65 GHz ; 2GB DDR3 ; HDMI ) , OS : Windows 7 ( 32 Bit ) , 65 - inches LCD - monitor ( diagonal 163 cm ) with an optimal resolution of 1920 × 1080 at 60 Hz demonstration , subjects were requested to actively use each interface feature to ensure that they had really understood its functionality . After probands had explicitly conﬁrmed that there were no open questions regarding interface usage , the actual test hypertext was loaded into the prototype application . Fig . 5 . 5 shows the initial display as seen by our subjects . Each test person was presented 24 rectangular objects , each labeled with a term related to a common subject area . Participants were then asked to re - structure those objects so that the resulting diagram reﬂected their basic comprehension of the given terms and their relations . This means , subjects should re - arrange , Figure 5 . 5 : initial display as seen by subjects 183 Chapter 5 . Test scale , color etc . the given terms to express their individual , structural un - derstanding of the given topic area . Here , participants were explicitly told to continue with their work until the result would make most sense to them . Main design decisions for the sample hypertext in Fig . 5 . 5 included the following considerations : Firstly , we intended to avoid unnecessary cognitive overhead and tried to keep up motivation of test candidates . For these reasons we selected only a relatively small number of terms ( only 24 ) from a common and , to our understanding , easy to understand subject area ( “ﬂora and fauna” ) and translated them into the participant’s native language ( here : German ) . In concrete terms , we took the ﬁrst random Wikipedia - article which included only general , basic knowledge and selected 24 characteristic terms . Another essential design criterion refers to the task’s level of diﬃculty . The given structuring problem should not have a common solution ( in form of clus - ters , trees or tables , for instance ) . Otherwise there would have been the danger of getting results of a single type only . This is why we selected partly ambigu - ous terms which allowed for alternative interpretations . A good example is the term “Bestimmung” , which could mean both “measurement” but also “destiny” . In addition we intended to make sure , that test persons only started interacting with the visual medium when they had already established a ﬁrst structural un - derstanding of the given “ﬂora / fauna” - topic . Interface activities without a real ( structural ) meaning would have led to wrong results ( at least in the speciﬁed timeslot of at maximum half an hour ) . This is why all 24 terms were initially arranged in a two - dimensional , rectangular grid . That grid of terms touched both left and right border of the display , but still left enough space in the top and the bottom region of the screen ( see Fig . 5 . 4 ) . Thus , users did not need to zoom out to view all 24 terms or to create empty workspace . Therefore , we could assume with high probability that test persons would begin structuring right from the start . So , except for purely “cosmetic” changes made to the display ( in order to make it look “nice” ) , most of our participant’s activities must have implied structural meaning . Finally it was intended to avoid , that the initial display suggests a potential solution to the term - structuring problem . To achieve that , object shape and color were chosen as neutral as possible . Thus our grey rectangles should not have any semantic association with the subject “ﬂora / fauna” . In addition , all 24 terms were arranged such that none of them had an immediate semantic relationship with its surrounding neighbors . Thus , the initial spatial layout should not allow for drawing any conclusions about semantic relationships . With this we tried to maximize the visual diﬀerence between initial display and potential solution - hypertexts . 184 5 . 1 . Reference Data Collection Figure 5 . 6 : sample feedback provided by one of our participants Having ﬁnished their structuring task , test persons were ﬁnally asked to tell the researcher explicitly what they intended to express . For this purpose they received a printout of their work and a pen . They were then asked to highlight where they can see associations between objects ( by drawing lines , circles etc . ) . Fig . 5 . 6 shows an example of such a marked printout . Note , that Fig . 5 . 6 in - cludes no explicit numerical information about the strength of object relations . The drawing only describes general connections between ( groups of ) objects . The reason for this lies in spatial hypertext’s implicit nature ( Sect . 1 . 2 ) . Unlike our parsers , humans may ﬁnd it cognitively diﬃcult to express implicit struc - ture as explicit numbers . Thus , precision of human user feedback is necessarily lower than precision of machine - generated feedback . This had signiﬁcant im - pact on our evaluation algorithm that will be discussed in Sect . 5 . 2 . User feedback that we received in this graphical form had to be quantiﬁed . For these purposes we wrote a small visual analysis tool that allowed us to manually transform handwritten user feedback into digital , weighted graphs ; that is , into interpretations I h N 0 i . In these graphs we used numerical weightings > 0 . 0 to express object connections and hence structures . Diﬀerent weightings indicated diﬀerent levels of abstraction . That is , the higher the abstraction - level the smaller the assigned weighting and vice versa . When required , this allowed us to encode multi - level structures . Note , that our spatial parser does the same . This formed the reference data for our automated analysis . Finally , we can summarize the survey - process as follows : First , test persons in - teract with our adapted prototype from Sect . 5 . 1 . 1 to solve a term - structuring task . Corresponding streams of edit steps ( e ′ k , D k ) are recorded in log - ﬁles . Having ﬁnished their assignment participants provide explicit graphical feed - back on their intended structures . This handwritten user feedback is ﬁnally quantiﬁed as reference interpretations I ref . Fig . 5 . 7 illustrates that graphically . 185 Chapter 5 . Test Spatial Hypermedia System  ′    convert Editing System log quantify feedback 1 2 3      ′ 0  0 ,  ′ 1  1 , … ,  ′         (cid:1858) Figure 5 . 7 : Survey - process overview 5 . 2 Virtual Test Run Once we had collected both from a test person , logged edit process ( i . e . , what the participant did ) and reference interpretation ( i . e . , what the participant intended to express ) , we proceeded as follows : Firstly , an interpreter was instantiated that was build from only temporal , spa - tial and visual parser . Fading and implicit merging were deactiated , since those features were not needed for the test run . Once we had a runnable interpreta - tion system , both , reference interpretation graph as well as the recorded stream of edit steps were loaded into memory . The stream was then passed through all three parser components . Expressed formally . . . 29 Virtual Test Studio - main procedure 1 : I ref ← load reference interpretation from ﬁle 2 :   e 0 D 0 ! , e 1 D 1 ! , . . . , e n D n !   ← load edit process from ﬁle 3 : I T , I S , I V ← I ε 4 : for i = 0 to n do 5 : I T ← interprete (cid:0) A T , ( e i , D i ) (cid:1) ⊲ Eq . 4 . 232 6 : I S ← interprete (cid:0) A S h N 0 , 16 , 0 . 0 , 1 . 0 i , ( e i , D i ) (cid:1) ⊲ Eq . 4 . 120 7 : I V ← interprete (cid:0) A V h N 0 , 16 , 0 . 0 , 1 . 0 i , ( e i , D i ) (cid:1) ⊲ Eq . 4 . 182 8 : end for 9 :   ( T 0 , S 0 , V 0 ) , d 0 ! , ( T 1 , S 1 , V 1 ) , d 1 ! , . . . , ( T 230 , S 230 , V 230 ) , d 230 !   ← test    I ref , I T , I S , I V    186 5 . 2 . Virtual Test Run In Alg . 29 single parser runs are symbolized by I ← interprete ( A , ( e i , D i ) ) . Here , A is a parser instance and ( e i , D i ) is the ( i + 1 ) - th step in an edit process . Resulting temporal , spatial and visual interpretations I T , I S , I V were merged together in varying ratios ( T , S , V ) ∈ ∆ 2 with an increment of ﬁve percent . This means , weighting factors T , S , V were multiples of 0 . 05 and summed up to 1 . 0 . Each merge result I merge was then compared with the given reference interpretation I ref . For this comparison we used a statistical divergence function which could tell us numerically how close a merged interpretation graph I merge ( i . e . , the model ) came to the respective reference interpretation graph I ref ( i . e . , our observation ) . The smaller such numerical divergence values were , the closer the parse result came to what a user intended to express . For example , an optimal value of 0 . 0 indicated that model and observation were identical ; that is , our merge result represented exactly what the user had in mind . 30 test : (cid:0) I h Ω i (cid:1) 4 ⇀ List h ∆ 2 × R + 0 i , (cid:0) I ref , I T , I S , I V (cid:1) 7→ list result 1 : list result ← list ε 2 : for i = 0 to 100 step 5 do 3 : for j = 0 to ( 100 − i ) step 5 do 4 : k ← 100 − i − j 5 : I merge ← merge (cid:16) ( I T , I S , I V ) , (cid:0) i / 100 , j / 100 , k / 100 (cid:1)(cid:17) ⊲ Alg . 7 6 : d ← compare (cid:0) I ref , I merge (cid:1) ⊲ Alg . 31 7 : list result ← add (cid:18) list result , (cid:16)(cid:0) i / 100 , j / 100 , k / 100 (cid:1) , d (cid:17) (cid:19) ⊲ Eq . 4 . 92 8 : end for 9 : end for 10 : return list result Our deﬁnition of I h Ω i from Eq . 4 . 90 allows us to identify diﬀerent structure levels , that is , we can distinguish between collections of structures with diﬀerent weight ranges . This makes it possible to iterate through interpretations from the strongest to the weakest associations and to step - by - step extract collections of structures with increasing extension level . We denote the number of such levels as struct _ level _ count and formally deﬁne it as follows : struct _ level _ count : I h Ω i → R + 0 , ( U , A , w ) 7→ (cid:12)(cid:12)(cid:12)(cid:8) w ( a ) (cid:12)(cid:12) a ∈ A ∧ w ( a ) / ∈ { 0 , ε } (cid:9)(cid:12)(cid:12)(cid:12) ( 5 . 1 ) Essentially , struct _ level _ count accepts an interpretation - graph ( U , A , w ) ∈ I h Ω i and determines the number of diﬀerent weightings w ( a ) / ∈ { 0 , ε } assigned to association a ∈ A . Thus , each weight > 0 identiﬁes an extension level of structure . 187 Chapter 5 . Test As an example , for an I sample = ( U , A , w ) ∈ I h { u 0 , u 1 , u 2 } i deﬁned as . . . U = { u 0 , u 1 , u 2 } ; A = (cid:18) U 2 (cid:19) =   { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }   ; w =   (cid:0) { u 0 , u 1 } , 0 . 50 (cid:1) , (cid:0) { u 0 , u 2 } , 0 . 00 (cid:1) , (cid:0) { u 1 , u 2 } , 1 . 00 (cid:1)   ( 5 . 2 ) . . . struct _ level _ count ( I sample ) would identify 2 levels of weightings / ∈ { 0 , ε } . These are : a top - level with weight 1 . 00 and a bottom - level with weight 0 . 50 . Index - based access on these levels can be achieved via struct ( I sample , i ) : struct : (cid:16) I h Ω i × R + 0 (cid:17) → I h Ω , { 0 , 1 } i , (cid:0) ( U , A , w ) , i (cid:1) 7→ (cid:0) U , A , w ′ (cid:1) , w ′ : A → { 0 , 1 } , ∀ a ∈ A : w ′ ( a ) =    0 , if w ( a ) ∈ { 0 , ε } 1 , else if (cid:12)(cid:12) (cid:12) (cid:12)(cid:12)(cid:12)(cid:12) (cid:12)    w (cid:0) a ′ (cid:1) (cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) a ′ ∈ A ∧ w (cid:0) a ′ (cid:1) / ∈ { 0 , ε } ∧ w (cid:0) a ′ (cid:1) < w ( a )    (cid:12)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) ≥ i 0 , else ( 5 . 3 ) Essentially , struct ( I , i ) takes an interpretation I ∈ I h Ω i and a structure level index i ≥ 0 and ﬁlters out connected sub - graphs with weights that are among the ( struct _ level _ count ( I ) − i ) - biggest weightings in I . Results are encoded as binary I h Ω , { 0 , 1 } i . Let us also illustrate this with an example : when we take I sample from Eq . 5 . 2 again , then for structure level indices . . . 0 ≤ i < struct _ level _ count ( I sample ) = 2 . . . struct (cid:0) I sample , i (cid:1) will return : struct (cid:0) I sample , 0 (cid:1) =   { u 0 , u 1 , u 2 } ,   { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }   ,   (cid:0) { u 0 , u 1 } , 1 (cid:1) , (cid:0) { u 0 , u 2 } , 0 (cid:1) , (cid:0) { u 1 , u 2 } , 1 (cid:1)     struct (cid:0) I sample , 1 (cid:1) =   { u 0 , u 1 , u 2 } ,   { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }   ,   (cid:0) { u 0 , u 1 } , 0 (cid:1) , (cid:0) { u 0 , u 2 } , 0 (cid:1) , (cid:0) { u 1 , u 2 } , 1 (cid:1)     For structure indices i ≥ struct _ level _ count ( I sample ) function struct (cid:0) I sample , i (cid:1) would return graphs with zero - weightings only ( i . e . , ∀ a ∈ A : w ′ ( a ) = 0 ) . This case , however is of no relevance for our following deﬁnition of compare . 188 5 . 2 . Virtual Test Run Based on struct _ level _ count ( Eq . 5 . 1 ) and struct ( Eq . 5 . 3 ) we can deﬁne the compare - algorithm used in Alg . 30 ( line 6 ) as follows : 31 compare : (cid:0) I h Ω i × I h Ω i (cid:1) ⇀ R + 0 , (cid:0) I ref , I compare (cid:1) 7→ div Require : struct _ level _ count (cid:0) I ref (cid:1) > 0 ∧ struct _ level _ count (cid:0) I compare (cid:1) > 0 1 : d sum ← 0 2 : i ← struct _ level _ count (cid:0) I compare (cid:1) − 1 ⊲ Eq . 5 . 1 3 : for j = (cid:16) struct _ level _ count (cid:0) I ref (cid:1) − 1 (cid:17) to 0 step − 1 do 4 : d min ← divergence (cid:16) struct (cid:0) I ref , j (cid:1) , struct (cid:0) I compare , i (cid:1)(cid:17) ⊲ Alg . 32 5 : for k = ( i − 1 ) to 0 step − 1 do ⊲ Eq . 5 . 3 6 : d ← divergence (cid:16) struct (cid:0) I ref , j (cid:1) , struct (cid:0) I compare , k (cid:1) (cid:17) 7 : if d < d min then 8 : d min ← d 9 : i ← k 10 : end if 11 : end for 12 : d sum ← d sum + d min 13 : end for 14 : return (cid:16) d sum / struct _ level _ count (cid:0) I ref (cid:1) (cid:17) ⊲ Eq . 5 . 1 This is best explained with an example . Let our previous I sample from Eq . 5 . 2 be our reference interpretation . Let us also assume , that I compare = ( U , A , w ) is deﬁned by . . . U = { u 0 , u 1 , u 2 } ; A = (cid:18) U 2 (cid:19) =    { u 0 , u 1 } , { u 0 , u 2 } , { u 1 , u 2 }    ; w =    (cid:0) { u 0 , u 1 } , 0 . 25 (cid:1) , (cid:0) { u 0 , u 2 } , 0 . 00 (cid:1) , (cid:0) { u 1 , u 2 } , 0 . 75 (cid:1)    ( 5 . 4 ) compare ( I sample , I compare ) traverses both I sample and I compare in a top - down fashion from structures with the strongest associations down to an extension level where all associations are included ( i . e . , all associations a : w ( a ) / ∈ { 0 , ε } ) . It identiﬁes : ( a ) struct ( I compare , 1 ) as the expansion stage which comes the closest to struct ( I sample , 1 ) and ( b ) struct ( I compare , 0 ) as the one coming the closest to struct ( I sample , 0 ) . The resulting divergence value is calculated as . . .   divergence (cid:16) struct (cid:0) I sample , 1 (cid:1) , struct (cid:0) I compare , 1 (cid:1)(cid:17) + divergence (cid:16) struct (cid:0) I sample , 0 (cid:1) , struct (cid:0) I compare , 0 (cid:1)(cid:17)   struct _ level _ count (cid:0) I sample (cid:1) = 0 + 0 ! 2 = 0 2 = 0 compare ( I sample , I compare ) = 0 indicates that Eq . 5 . 4 allows to ﬁlter out all discrete structures that are also encoded in Eq . 5 . 2 . 189 Chapter 5 . Test Our routine for divergence calculation , as we use it in Alg . 31 ( in lines 4 , 6 ) , builds on the Kullback Leibler ( KL ) divergence [ 40 ] and works for any I h Ω i , not only for binary I h Ω , { 0 , 1 } i : 32 divergence : (cid:0) I h Ω i × I h Ω i (cid:1) ⇀ (cid:16) R + 0 ∪ { ε } (cid:17) , (cid:0) ( U , A , w 0 ) , ( U , A , w 1 ) (cid:1) 7→ d 1 : distribution 0 , distribution 1 ← list ε 2 : weightSum 0 , weightSum 1 ← 0 . 0 3 : for all a ∈ A do 4 : if w 0 ( a ) , w 1 ( a ) 6 = ε then 5 : distribution 0 ← add (cid:0) distribution 0 , w 0 ( a ) (cid:1) ⊲ Eq . 4 . 92 6 : distribution 1 ← add (cid:0) distribution 1 , w 1 ( a ) (cid:1) 7 : weightSum 0 ← weightSum 0 + w 0 ( a ) 8 : weightSum 1 ← weightSum 1 + w 1 ( a ) 9 : end if 10 : end for 11 : if empty ( distribution 0 ) = TRUE then ⊲ Eq . 4 . 95 12 : return ε 13 : end if 14 : if weightSum 0 = 0 . 0 then 15 : if weightSum 1 = 0 . 0 then 16 : return 0 . 0 17 : end if 18 : return ε 19 : else if weightSum 1 = 0 . 0 then 20 : return ε 21 : end if 22 : p 0 , p 1 ← list ε 23 : for i = 0 to (cid:0) size ( distribution 0 ) − 1 (cid:1) do ⊲ Eq . 4 . 93 24 : p 0 ← add (cid:0) p 0 , get ( distribution 0 , i ) / weightSum 0 (cid:1) ⊲ Eq . 4 . 92 , Eq . 4 . 94 25 : p 1 ← add (cid:0) p 1 , get ( distribution 1 , i ) / weightSum 1 (cid:1) 26 : end for 27 : return (cid:16) KL symmetric (cid:0) smoothen ( p 0 ) , smoothen ( p 1 ) (cid:1)(cid:17) ⊲ Eq . 4 . 209 The trick here is to treat weighting functions w 0 , w 1 as distributions of weights w 0 ( a ) , w 1 ( a ) over associations a ∈ A . When transformed into ( discrete ) prob - ability distributions p 0 , p 1 they allow for calculating the divergence between ( U , A , w 0 ) and ( U , A , w 1 ) as . . . KL symmetric (cid:0) smoothen ( p 0 ) , smoothen ( p 1 ) (cid:1) Here , KL symmetric represents the symmetrized Kullback Leibler divergence from Eq . 4 . 209 . smoothen ( p ) ensures that p includes no zeros . 190 5 . 2 . Virtual Test Run The following example will give you an impression of the power of Alg . 32 . 0 . 0794 1 . 4083 3 . 7625 7 . 6625 I 0 I 1 I 2 I 3 I 4 d i v e r gen c e Figure 5 . 8 : Five sample interpretation graphs I 0 , . . . , I 4 and their divergence values . Vary - ing brightness of line colors symbolizes diﬀerent weightings . Divergences were calculated between interpretation I 0 on the left and I 1 , I 2 , I 3 , I 4 on the right . Fig . 5 . 8 illustrates ﬁve sample interpretation graphs I 0 , . . . , I 4 , each a network of eight white rectangles . Like in previous illustrations of interpretation graphs , also here varying weights are expressed with visual line properties . The stronger the connection between two rectangles the higher the assigned weighting and the darker the painted line . Line thickness and opacity are the same for all ﬁve illustrations . Right below these graphs , you can see the divergences Alg . 32 calculates between I 0 and I i ( for i ∈ { 1 , . . . , 4 } ) . According to that , . . . divergence ( I 0 , I 1 ) = 0 . 0794 divergence ( I 0 , I 2 ) = 1 . 4083 divergence ( I 0 , I 3 ) = 3 . 7625 divergence ( I 0 , I 4 ) = 7 . 6625 Note , that these values were rounded to four places after the decimal point . 191 Chapter 5 . Test Virtual Test Studio TemporalParser VisualParser    (cid:1858)       S T V SpatialParser merge " T " , " S " , " V " , " d " 0 . 05 , 0 . 95 , 0 . 00 , 7 . 0511 0 . 10 , 0 . 90 , 0 . 00 , 7 . 0511 0 . 15 , 0 . 85 , 0 . 00 , 7 . 0511 . . . 0 . 00 , 0 . 25 , 0 . 75 , 9 . 1955 compare  0  0 ,  1  1 , … ,  (cid:1866)  (cid:1866) Figure 5 . 9 : Overview of the virtual test run In conclusion , the overall test run can be summarized as follows : Firstly , both logged edit process ( i . e . , what the participant did ) and reference interpretation ( i . e . , what the participant intended to express ) are loaded into memory . The recorded sequence of edit steps is then passed through temporal , spatial and visual parser . Resulting interpretations are merged together in varying ratios and with an increment of ﬁve percent . Comparing these mixtures with the given reference interpretation results in numerical divergence values . These values indicate how close merged parse results come to user intention and therefore can be used for evaluation purposes . A graphical overview of the virtual test run can be found in Fig . 5 . 9 . 5 . 3 Analysis Our virtual test run resulted in 50 CSV - lists ( one per test person ) . Each of those lists included 231 tuples of weighting factors for temporal , spatial and visual parser together with the respective divergence value ( the number 231 comes from our chosen weighting factor increment of ﬁve percent ) . 192 5 . 3 . Analysis 100 80 60 40 20 100 80 60 40 20 100 80 60 40 20 ●●●●●●●●●●●●● ●●●●●●●●● ●●● ● ● ● ● ● ● ● ● ●●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ●● ● ● ●● ● ● ● ●● ●●●● ●●● ● ●● ● ●● ●● ● ● ●●●● ● ●●● ● ● ●● ● ● ● ● ● ●●● ● ● ●●●● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●●● ● ● ● ● ● ● ● ● ● ● ● ●●●●●●●●●● ● ●●● ●●●● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●●● ● ● ● ● ● ● ●● ●● ● ● ●● ● ● ● ●●●● ● ● ● ● ● ● ● ●● ● ●● ● ● ● ● ● ● ●●●● ● ● ● ● Temporal Spatial Visual T e m po r a l Spatial V i s u a l 8 9 10 Divergence Figure 5 . 10 : sample ternary plot Demonstrated with an example , each of those 50 tabular listings was of the following form : # 0 " T " , " S " , " V " , " d " # 1 0 . 05 , 0 . 95 , 0 . 00 , 7 . 05113242479466400000 # 2 0 . 10 , 0 . 90 , 0 . 00 , 7 . 20835108739322600000 # 3 0 . 15 , 0 . 85 , 0 . 00 , 7 . 32986400847126800000 . . . # 231 0 . 00 , 0 . 25 , 0 . 75 , 9 . 19552448851569300000 “T” , “S” , and “V” label the weighting factors for temporal , spatial and visual parser by mixed ratios . The divergence of each ratio is labeled as “d” . As an initial step , we illustrated our results as colored ternary diagrams . In ternary plots the ratios of three variables correspond to positions within a tri - angle . As such , they are well suited for visualizing the given triples of weighting factors . Figure 5 . 10 shows an example of such a colored ternary diagram . The colored circles in the triangle represent diﬀerent parser combinations or triples ( T , S , V ) ∈ ∆ 2 and therefore are evenly distributed over the simplex . The triangle’s vertices ( ( 1 , 0 , 0 ) , ( 0 , 1 , 0 ) , and ( 0 , 0 , 1 ) ) are special cases where only spatial , temporal , or visual parser are included . The divergence values d as - 193 Chapter 5 . Test signed to the ratios throughout the triangle are expressed as colors with a color scale ranging from yellow to red . Pure yellow indicates the smallest divergence value whereas pure red the biggest one in a sample ; brighter colors indicate better results . Drawing ternary plots for each of the 50 sample cases has not shown a uniform picture . We could not spot a single connected area of optimal ratios of parser conﬁgurations throughout all 50 diagrams . In contrary , we have indicated various patterns in analyzing the ternary plots . Nevertheless this analysis has provided some important insights regarding the relationship of spatial , visual , and temporal parsers : The more explicit a spatial structure was ( e . g . , in form of lists , trees , mind maps etc . ) the more the optimum has moved towards ( T , S , V ) = ( 0 . 0 , 1 . 0 , 0 . 0 ) and thus put the focus on the spatial parser . The more dominant visual attributes have been used in a meaningful manner ( e . g . , for highlighting diﬀerent object categories etc . ) the more the optimum has been shifted towards ( T , S , V ) = ( 0 . 0 , 0 . 0 , 1 . 0 ) and hence towards the visual parser . In other words , the easier it was for the spatial and visual parsers to detect clear structures , the more weight they have got in the optimal solution . The better visual or spatial heuristics ﬁtted a test person’s individual way of visual expression the lower the required support by the temporal parser . This is the expected behaviour and hence not surprising . It is interesting to note though , that even in such extreme cases pure spatial and visual parser could not outperform the spatio - temporal parser ; that is , there always was at least one temporal mixture which performed at least as good as the best without temporal component . Furthermore , we made the important observation that the impact of the tem - poral parser was higher for more ambiguous and “uncommon” structures . We assume the reason to be in the spatial and visual parser’s limitations and lack of heuristic deﬁnitions . Thus , the temporal parser became important in cases when spatial and visual parser failed to recognize accurate structure . One could argue that the temporal parser complemented spatial and visual parser beyond their limits . To some extent this could eliminate the need for manually tuning parsers to speciﬁc users . Instead , limited precision caused by inadequate parser conﬁgurations or heuristics could be partly compensated by adding our tempo - ral parser . Even though this could not reach the same high level of accuracy as it might be possible with highly customized parsers , the addition of our tempo - ral parser still provided better results than pure spatial or visual parser ; while being completely independent of user preferences and context of application . Although this is the most promising ﬁnding related to our temporal parser it still does not proof our hypothesis from page 179 . Ternary plots are good for initial assessment but do not allow for reliable conclusions about signiﬁcance . A statistical approach is required instead . 194 5 . 3 . Analysis 5 . 3 . 1 Statistical Method To compare spatio - visual and spatio - temporal parser statistically we had to determine optimal merging ratios , with and without temporal component . We regard combinations of temporal , spatial and visual parser as being optimal if they generate results at consistently high level of accuracy . It is neither optimal to constantly produce output of low quality nor to generate perfect results for a single person only . Divergence values rather should be as low as possible while not varying between diﬀerent users . Ideally they are always zero . Since our ternary plots did not show a uniform picture it was not possible to identify single connected areas of optimal ratios . Thus , we had to determine temporal and non - temporal optima numerically rather than visually . Our 50 CSV - lists contained 231 data sets of the following form : (cid:0) ( T , S , V ) , ( d 0 , d 1 , . . . , d 49 ) (cid:1) ∈ (cid:18) ∆ 2 × (cid:16) R + 0 (cid:17) 50 (cid:19) Here , ( T , S , V ) is a merging ratio and ( d 0 , d 1 , . . . , d 49 ) is a sequence of 50 di - vergence values . Let us denote such binary tuples as conﬁguration Candidates . 21 of these 231 candidates include no temporal component ( i . e . , T = 0 ) : C NT 00 = (cid:0) ( 0 . 00 , 1 . 00 , 0 . 00 ) , ( d 0000 , d 0001 , . . . , d 0049 ) (cid:1) C NT 01 = (cid:0) ( 0 . 00 , 0 . 95 , 0 . 05 ) , ( d 0100 , d 0101 , . . . , d 0149 ) (cid:1) . . . C NT 20 = (cid:0) ( 0 . 00 , 0 . 00 , 1 . 00 ) , ( d 2000 , d 2001 , . . . , d 2049 ) (cid:1) For 210 candidates , on the other hand , T is greater than zero : C T 000 = (cid:0) ( 1 . 00 , 0 . 00 , 0 . 00 ) , ( d 00000 , d 00001 , . . . , d 00049 ) (cid:1) C T 001 = (cid:0) ( 0 . 95 , 0 . 05 , 0 . 00 ) , ( d 00100 , d 00101 , . . . , d 00149 ) (cid:1) . . . C T 209 = (cid:0) ( 0 . 05 , 0 . 00 , 0 . 95 ) , ( d 20900 , d 20901 , . . . , d 20949 ) (cid:1) In order to identify temporal and non - temporal “winner” - conﬁgurations we had to make these candidates comparable . For this we used the following trick : We calculated for each C NT ∈ { C NT 00 , . . . , C NT 20 } and C T ∈ { C T 000 , . . . , C T 209 } Median and Standard Deviation of their assigned divergence values and mapped them to value range [ 0 , 1 ] . For this we used the following equations : median mapped = ( median candidate − median min ) / ( median max − median min ) stddev mapped = ( stddev candidate − stddev min ) / ( stddev max − stddev min ) 195 Chapter 5 . Test This allowed us to represent both { C NT 00 , . . . , C NT 20 } and { C T 000 , . . . , C T 209 } as points in { 0 . 0 , . . . , 1 . 0 } 2 . Sorting these two - dimensional vectors in ascending order according to their Euclidean norm resulted in two ranking lists : one for temporal and one for non - temporal conﬁguration candidates . The ﬁrst entries in these lists represented optimal merging ratios . These were . . . non - temporal : ( 0 . 00 , 0 . 45 , 0 . 55 ) with median : 9 . 552966 and stddev : 0 . 964822 and temporal : ( 0 . 75 , 0 . 25 , 0 . 00 ) with median : 8 . 821289 and stddev : 0 . 998641 Note , that in the latter ratio the temporal parser has made the visual parser ob - solete ( i . e . , V = 0 . 00 ) . We assume the reason to be visual over - interpretation of our visual parser . Such over - interpretation can lead to redundancies re - garding correct results but also decreased accuracy due to unintended visual relations . This connection between temporal and visual parser , however , is target of future work ; so we shall not go into any more detail . Let us denote the two “winner” - conﬁgurations as . . . C NT = (cid:0) ( 0 . 00 , 0 . 45 , 0 . 55 ) , D NT (cid:1) ∈ { C NT 00 , . . . , C NT 20 } and C T = (cid:0) ( 0 . 75 , 0 . 25 , 0 . 00 ) , D T (cid:1) ∈ { C T 000 , . . . , C T 209 } For both divergence samples D NT and D T we can assume the following : Assumption 1 : D NT and D T are at least interval - scaled . Divergences be - tween interpretation graphs ( see Alg . 31 , 32 ) are measured in computer bits on a continuous scale . Thus , they are metric data . Note , that our divergence builds on Eq . 4 . 209 which has some of the properties of a metric on the space of probability distributions : KL symmetric ( P , Q ) is non - negative , it becomes zero if and only if the two distributions P , Q are equal and it is symmetric ; that is , KL symmetric ( P , Q ) = KL symmetric ( Q , P ) . However , it does not satisfy the triangle inequality . Hence it is rather a semi - metric than a distance - metric on the space of probability distributions . Such divergences are typically ( though not exclusively ) measured in computer bits . Assumption 2 : D NT and D T are dependent . For each of our 50 test persons we collected ( or rather we measured ) samples under two experimental condi - tions : ( 0 . 00 , 0 . 45 , 0 . 55 ) and ( 0 . 75 , 0 . 25 , 0 . 00 ) . Thus , one could argue that each participant contributed a pair of related scores . Therefore D NT and D T can be regarded as being dependent . Assumption 3 : homogeneity of variance . Having applied Levene’s test ( for Homogeneity of Variance ) on D NT and D T resulted in a p - value = 0 . 7218 , which is non - signiﬁcant for a signiﬁcance level α = 0 . 05 . From this we can conclude that the variances in both experimental conditions are roughly equal . 196 5 . 3 . Analysis Assumption 4 : The distribution of the diﬀerences between D NT and D T is approximately normally distributed . The Shapiro - Wilk test was used to prove this assumption . Considering a signiﬁcance level of α = 0 . 05 , the test was non - signiﬁcant for both D NT ( with a p - value = 0 . 0804695 ) and D T ( where the p - value was 0 . 8747074 ) . This tells us that the distributions of both samples D NT and D T are not signiﬁcantly diﬀerent from a normal distribution . Thus they are probably normally distributed and so are their diﬀerences . Provided that D NT and D T are normally distributed , dependent , metric sam - ples with equal variances , we can analyse them with the paired Student’s t - test . This can be performed either one - or two - tailed . Before collecting our reference data we could not state with certainty that the direction of a ( possible ) diﬀerence in parser performance would only go one way . We could not be sure that the spatio - temporal parser would always perform at least as good as the spatio - visual parser . For this reason , and because we were looking for a more conservative test of signiﬁcance , we decided to perform a two - tailed rather than a one - sided test . Thus , our method of choice was : the two - tailed paired Student’s t - test . With the two - tailed paired ( Student’s ) t - test one can evaluate whether the mean diﬀerence between paired observations is signiﬁcantly diﬀerent from zero . That is , you can determine whether there is a signiﬁcant diﬀerence between the arithmetic means of two variables , such as in our case D NT and D T . 5 . 3 . 2 Result Our null hypothesis H 0 stated that there was no eﬀective diﬀerence between the non - temporal sample mean and the temporal sample mean ; that is , any measured diﬀerence in divergence was only due to chance and thus including the temporal parser had no eﬀect : H 0 : µ NT = µ T or H 0 : µ NT − µ T = 0 Here , µ NT stands for the mean of D NT and µ T represents the mean of D T . The opposite of our null hypothesis H 0 was our experimental ( or alternative ) hypothesis H 1 , which assumed that the means of D NT and D T were not equal ; that is , that including the temporal parser changed the mean . H 1 : µ NT 6 = µ T or H 1 : µ NT − µ T 6 = 0 As a level of signiﬁcance we selected the widely adopted α = 0 . 05 . 197 Chapter 5 . Test Applying the two - tailed paired Student’s t - test on D NT as ﬁrst and D T as second condition resulted in : t = 3 . 0635 , df = 49 , p - value = 0 . 00355 with a 95 percent conﬁdence interval ranging from 0 . 1325554 to 0 . 6380730 From p < α or rather from 0 . 00355 < 0 . 05 we can conclude , that there is a signiﬁcant diﬀerence between the means of D NT and D T ( i . e . , we reject H 0 ) . This gets also reﬂected by the conﬁdence interval . Both , upper bound 0 . 6380730 and lower bound 0 . 1325554 have the same sign , which means that the null ﬁnd - ing of zero diﬀerence lies outside of the conﬁdence interval . From this we can conclude that the diﬀerence is statistically signiﬁcant . The fact that the t - value ( t = 3 . 0635 ) is positive tells us that D NT had a bigger mean than D T and so divergences were lower when using the temporal parser . Even though the result is statistically signiﬁcant , it tells us nothing of whether the eﬀect is substantive ; that is , if it is important in practical terms . For this reason we converted our t - statistics into a standard eﬀect size . Some widely used eﬀect size for the paired - samples t - test is Cohen’s d [ 41 ] or rather d z [ 42 ] , which is calculated from the diﬀerence scores from matched pairs . In order to avoid overestimation of eﬀect sizes we used a more conservative adaption of d z which is known as d rm [ 42 , 43 ] . For our t - statistics we got : | d rm | = 0 . 39 Preferably , eﬀect sizes should be interpreted by comparing them to related eﬀects in literature . Since , however , in our special case there are no such references we decided to use the benchmarks deﬁned in [ 41 ] instead . In [ 41 ] eﬀect sizes are classiﬁed as small ( | d | = 0 . 2 ) , medium ( | d | = 0 . 5 ) , and large ( | d | = 0 . 8 ) . Thus , a | d | - value between 0 . 0 to 0 . 3 could be interpreted as small , if it is between 0 . 3 and 0 . 6 it would be moderate , and an eﬀect size bigger than 0 . 6 could be regarded as a large eﬀect size . According to [ 44 ] medium | d | represents an eﬀect visible to the naked eye , small | d | is noticeably smaller than medium but not trivial , and a large | d | has the same distance above medium as small has below . Our ( conservative ) eﬀect size | d rm | = 0 . 39 lies between 0 . 2 and 0 . 5 and therefore between the thresholds for small and medium eﬀects ( with a slight tendency towards moderate ) . Therefore , as well as being statistically signiﬁcant , our detected eﬀect is non - trivial and recognizable by humans . 198 5 . 3 . Analysis Finally , we can summarise our ﬁndings as follows : On average , divergence from user intention when adding our temporal parser ( M = 8 . 9335 , SE = 0 . 1412 ) was signiﬁcantly lower than when using only spatial and visual parser ( M = 9 . 318871 , SE = 0 . 136446436 ) ; t ( 49 ) = 3 . 0635 and p < 0 . 05 . The 95 percent conﬁdence interval for the mean diﬀerence between the two conditions was 0 . 1325 to 0 . 6380 . The eﬀect size estimate | d rm | = 0 . 39 indicates a non - trivial eﬀect that is recognizable by humans . From this we conclude , that the addition of a temporal parser ( as deﬁned in Sect . 4 . 4 . 5 ) shifts machine detected structures ( encoded in interpretations ; Sect . 4 . 2 . 3 ) signiﬁcantly closer to what target users ( knowledge workers with technical background ) intend to express ( see our initial hypothesis on page 179 ) . Thus , spatial parser performance ( i . e . , accuracy ) can be signiﬁcantly increased when taking into account not only spatial and visual but also temporal object relations . 199 Chapter 5 . Test 200 Chapter 6 Summary , Conclusion and Future Work 6 . 1 Summary and Conclusion We started our discussion of spatio - temporal parsing with a general introduc - tion into the ﬁeld of spatial hypermedia and provided an overview of relevant literature ( Chapter 1 ) . It was shown how spatial hypertext and spatial pars - ing are informally deﬁned ( Sect . 1 . 2 and Sect . 1 . 3 ) , which default - categories of spatial and visual structures have been identiﬁed in literature ( Sect . 1 . 4 ) and what practical implementations of spatial parsers were developed ( Sect . 1 . 5 ) . Chapter 2 provided a formal view on spatial hypertext . According to Sect . 2 . 1 , spatial hypertext languages are sets of spatial hypertext artifacts , which are ﬂat collections of spatial hypertext symbols . This forms our “syntactic view” . Semantics are deﬁned by interpretations ( Sect . 2 . 2 ) . Interpretations are encod - ings of how spatial hypertext can be understood and thus form the semantic complement to spatial hypertext artifacts . Spatial parsers are the linking ele - ment between spatial hypertext artifacts and interpretations . Conventional ( non - adaptive ) parsers are conceptually limited by their under - lying source of information ( i . e . , the spatial hypertext ) . Due to this limitation there are several types of structures that cannot be recognized properly . In Chapter 3 we identiﬁed three categories : ( 1 ) ambiguous structures ( Sect . 3 . 1 ) ; ( 2 ) destroyed structures ( Sect . 3 . 2 ) and ( 3 ) temporal structures ( Sect . 3 . 3 ) . Not recognizing these types of structures limits both quality of parser output and parser performance . 201 Chapter 6 . Summary , Conclusion and Future Work In order to overcome this issue we suggested in Sect . 3 . 4 to consider not only spatial and visual properties , but also temporal aspects in spatial parser de - signs . For the detection of destroyed structures we suggested in Sect . 4 . 4 . 1 to equip parsers with short - term memory ( see “fading” on pages 93 – 94 ) . Detection of ambiguous and temporal structures required a temporal parser ( Sect . 4 . 4 . 5 ) . We claimed that considering not only spatial and visual properties but also tem - poral aspects in spatial parser design can lead to signiﬁcant increase in parsing accuracy , detection of richer structures and thus higher parser performance . Both , temporal parser as well as fading - feature were implemented in a proto - typical spatial hypermedia system , following a theoretical system model which is described in Chapter 4 . According to that model , spatial hypermedia sys - tems are compositions of editing systems supporting in the creation of spatial hypertext ( Sect . 4 . 1 ) and interpretation systems performing structural analysis ( Sect . 4 . 2 ) . Editing systems are mainly determined by workspace models as described in Sect . 4 . 1 . 3 , whereas interpretation systems are primarily deﬁned by parsing algorithms ( Sect . 4 . 4 ) . We designed and implemented algorithms for the detection of spatial ( Sect . 4 . 4 . 2 ) , visual ( Sect . 4 . 4 . 3 ) , content - related ( Sect . 4 . 4 . 4 ) and temporal ( Sect . 4 . 4 . 5 ) object relations . A full blockdiagram of our prototypical spatial hypermedia system can be found in the appendix on page 216 . A screenshot of the user interface is given on page 217 . Under laboratory conditions only synergies between spatial , visual and tempo - ral parser have been examined . Content parser and fading - functionality were not included in our analysis ( for details see page 178 ) . In order to compare spatio - temporal with spatial or visual parser performance reference data were collected by surveys in a laboratory ( Sect . 5 . 1 . 2 ) . In our studies 50 participants were asked to solve a simple term - structuring task using an adapted version of our prototypical spatial hypermedia system ( Sect . 5 . 1 . 1 ) . User activities during a session were recorded in log - ﬁles . Having ﬁnished their assignment subjects were asked to indicate explicitly what they intended to express . That qualitative feedback was then quantiﬁed in order to make it comparable by a machine . With this data at hand we could ﬁnally determine to what extent our spatio - temporal parser performed better than pure spatial or visual parser ( Sect . 5 . 2 ) . To this end , the logged edit process ( i . e . , what the participant did ) was passed through temporal , spatial and visual parser and results were merged together in varying ratios . Comparing these mixtures with the given reference data ( i . e . , what the participant intended to express ) re - sulted in numerical divergence values . These values indicated how close merged parse results came to user intention and therefore could be used for evaluation purposes . Fig . 6 . 1 summarizes that again . It turned out , that in none of the test cases pure spatial or visual parser could outperform the spatio - temporal parser . Instead the spatio - temporal parser 202 6 . 1 . Summary and Conclusion Spatial Hypermedia System Editing System  ′         ′ 0  0 ,  ′ 1  1 , … ,  ′      convert log Virtual Test Studio TemporalParser VisualParser    (cid:1858) 1 2 3 qu a n t i f y       S T V SpatialParser merge " T " , " S " , " V " , " d " 0 . 05 , 0 . 95 , 0 . 00 , 7 . 0511 0 . 10 , 0 . 90 , 0 . 00 , 7 . 0511 0 . 15 , 0 . 85 , 0 . 00 , 7 . 0511 . . . 0 . 00 , 0 . 25 , 0 . 75 , 9 . 1955 compare Figure 6 . 1 : overview of survey - process ( Sect . 5 . 1 . 2 ) + virtual test run ( Sect . 5 . 2 ) rather compensated limitations of conventional parsers and hence provided better results . In order to show that this was not only due to chance , diﬀer - ences between spatio - visual and spatio - temporal parsing accuracy were tested for statistical signiﬁcance . To this end the two - tailed paired Student’s t - test was applied on selected merging ratios , with and without temporal component ( Sect . 5 . 3 . 1 ) . The result was statistically signiﬁcant ( Sect . 5 . 3 . 2 ) . Converted into a standard eﬀect size our statistics indicated a non - trivial eﬀect that is recognizable by humans . Thus , for our target group we have shown that adaption of parsers is not abso - lutely necessary to increase quality of parser output . Instead , limited accuracy caused by inadequate parser conﬁgurations or heuristics can be partly com - pensated by adding a temporal parser . This ﬁnding is especially helpful in cases when spatial or visual parser would fail to recognize accurate structure , but tuning of parsers to individual user proﬁles or context of application is undesirable or even impossible . A good application example includes interfaces for navigating through large and ( possibly ) unknown information spaces , such as the World Wide Web . A widespread practice of navigating the web is text - based search . That is , web - surfers use the output of conventional search engines as shortcuts to doc - uments , possibly continuing their search by further traversing links . Relevant documents are then read and notes are taken on paper or via appropriate ap - plications . Thus , searching and taking notes becomes an iterative process of the user juggling two distinct media or applications . Searching the web for 203 Chapter 6 . Summary , Conclusion and Future Work information and taking notes are nowadays integral components of our daily oﬃce work . Nevertheless , there is nearly no machine support for integrat - ing both tasks , though there are interfaces for explicit text - based search ( e . g . , web - interfaces of search engines ) and tools that support in note - taking ( such as text editors , digital post - its etc . ) . Consequently , the user is forced to frequently translate between formal search terms and informal note taking without com - puter support . This produces cognitive overhead that could be avoided by using appropriate tools : Spatial hypermedia systems including specialized parsers . As mentioned earlier in Chapter 4 ( on page 47 ) and in Sect . 5 . 1 . 1 , spatial hyper - media systems realise visual structure creation loops where human and machine “interact” to gradually develop meaningful visual structure . Provided that web - surfers take their notes in a visual information space ( e . g . , as post - its in a web browser ) we could apply this principle to the aforementioned navigation task . The only diﬀerence to our generic system model would lie in the presentation of system feedback ; that is , how returned parse results are processed on applica - tion level . In our prototypical spatial hypermedia system , interpretations were displayed as graphical overlays on the workspace ( see our considerations on page 91 ) . For demonstration purposes this is completely suﬃcient . However , for more advanced applications , such as the described information navigation service , internal post - processing of parse results is required . For an intelligent browser interface this might work as follows : structures de - tected by the system are not simply displayed as they are ( i . e . , as connecting lines between objects ) . Instead they are used for auto - generating search queries . That is , interpretation graphs are treated as networks of search terms . These pattern - based queries are executed in the background ( e . g . , by some semantic data basis ) . Search results are then added as new elements to the information space ( e . g . , as geometrical objects that are labeled with key terms ) . The user could then select relevant objects and re - arrange , scale , color etc . them to implicitly express another ( reﬁned ) “query - structure” . Obsolete elements are deleted . Once the user has decided on which objects to incorporate into the spatial hypertext and which objects to ignore another interpretation – search – evaluation – cycle starts . Fig . 6 . 2 illustrates that conceptually . This realises natural and intuitively to handle information navigation loops where searching and note - taking are no separate tasks anymore . Users rather gradually discover an information space by “playing around” with text snippets on a 2d - screen . This decreases cognitive load for knowledge workers and hence improves productivity . In a long run this could increase the average quality of collected knowledge while still reducing manpower costs for online research . This apparently requires eﬃcient spatial parsers that do not need to be tuned to users or context of application . Otherwise there is no chance to reach out to a broad audience . Our ﬁndings from this thesis suggest that this is feasible . 204 6 . 2 . Future Work Information Space Browser Interpretation System  ′       ′      Editing System conversion Search Semantic DB Figure 6 . 2 : Enhanced spatial hypermedia system realising information navigation loops Another requirement relates to the computer devices such an information nav - igation service should operate on . Since gesture - based interaction with com - puters has become the de - facto standard way of working with portable devices ( e . g . , smart phones , tablets etc . ) users increasingly tend to organize informa - tion in an intuitive rather than a standardized way . This , however , is more or less ignored by “apps” available for such platforms . Gestures are detected , translated into system commands and forwarded to application - level without undergoing an advanced ( structural ) analysis . Due to this , information regard - ing user intention is inevitably getting lost . Thus spatial parsers might ﬁll a gap between multi - touch interfaces and “app - layer” . Limitied 2d - space and sloppy interface handling by users , however , might limit a conventional spatial parser’s performance . Again , a spatio - temporal parser could solve that problem . 6 . 2 Future Work There are enough reasons to further investigate in parsers , as described in this thesis . The following considerations are intended to provide information about our subsequent plan of action and will give inspiration for further research . Long - Term Studies So far we have analyzed synergy eﬀects between pure spatial , visual and temporal parser only in short - term tests and under controlled conditions . Content parser and fading - functionality were not included in our analysis . As a next step we are planning to integrate all four parsers ( with 205 Chapter 6 . Summary , Conclusion and Future Work activated fading ) into a domain - speciﬁc application for document triage ; that is , for computer - supported examination of documents . This is where we expect the content parser to show its real added value . Such a productive system will ﬁnally make it possible to perform long - term studies outside of the laboratory . This will provide us information about long - term eﬀects of content parser , temporal parser and ( particularly ) fading under real working conditions and thus will reveal our algorithm’s potential of supporting document management tools . If results are positive , we are planning further test runs with probands of diﬀerent cultural backgrounds . This will give us information about our heuristic’s and hence our algorithm’s validity across cultural boundaries . Redundancies Even though spatial , visual and temporal parser analyse dif - ferent attributes with diﬀerent heuristics , they do not necessarily generate re - sults that are disjunct . Our ﬁndings from Sect . 5 . 3 . 1 , for instance , let us assume that there are partial overlaps and hence redundancies between the output of visual and temporal parser . We suspect that , to a certain extent , this also applies to the relation between spatial and temporal or spatial and visual parser . As an example , when users create spatially separated groups of visually uniform objects to express categorical relationships , they inevitably introduce redundancies : on the one hand by putting members of the same category close together and on the other hand by providing them with clear visual identity . The ﬁrst can be exploited by spatial and the latter by visual parsers . When such groupings also change as a whole ( for instance because the user moves or scales them en bloc ) then category membership can not only be inferred from spatial proximity and visual similarity but also from temporal de - pendencies . Thus , there are clear redundancies between the output of spatial , visual and temporal parser . The eﬀects of theses overlappings on parser per - formance , however , still need to be investigated . Furthermore , studies should be conducted ( 1 ) whether there are signiﬁcant diﬀerences in pairwise intersec - tions of spatial , visual and temporal parse results and ( 2 ) what the determining ( heuristic ) parameters are . Granularity Practical experience with our prototypical spatial hypermedia system suggests , that spatial , visual and temporal interpretations vary in their granularity . That is , we assume that there are systematic diﬀerences in struc - tural nuances . Spatial parsing , as we deﬁned and implemented it , can be imagined as the process of “information sculpting” , where hidden information structure is made “visible” by “carving” ( i . e . , removing unwanted associations ) and “modelling” ( i . e . , adding meaningful object connections ) . Depending on how much emphasis you put on diﬀerent structural aspects ( such as spatial , visual , temporal etc . ) complete interpretation - graphs ( i . e . , the “rough mate - rial” ) is sculptured into structures with varying granularity . Our spatial parser , for instance , delivers rather coarsely structured output , whereas visual and 206 6 . 2 . Future Work ( particularly ) temporal parser provide comparatively ﬁnely structured results . Apart from our initial thoughts concerning primary vs . secondary structures in Sect . 1 . 4 ( on page 10 ) this has not been considered yet in our work . Thus , assuming that diﬀerences in structural granularity are signiﬁcant , it is still unknown how great these diﬀerences are . Performance As we know already from Chapter 3 , good spatial parsers do not only generate interpretations of high accuracy and hence produce results of high quality , but they also perform as resource - saving and as fast as possi - ble . Thus , there are two aspects which play an important role in spatial parser design : eﬀectiveness and eﬃciency . In this thesis the focus was put solely on parsing accuracy and therefore on eﬀectiveness . Aspects , such as processing speed and resource consumption were not considered . Even though our proto - typical implementation has been proven to be functional under test conditions ( i . e . , in all test cases parsers terminated in reasonable time ) , their general performance has not been analysed . Although not required for our proof of hy - pothesis , a theoretical analysis of parser performance would be highly beneﬁcial though . Knowing the diﬀerences in eﬃciency between parsers or heuristics al - lows to identify performance bottlenecks . This , in turn , will reveal optimization potentials that were not considered in our original parser designs . Extension We designed and implemented algorithms for the detection of spa - tial ( Sect . 4 . 4 . 2 ) , visual ( Sect . 4 . 4 . 3 ) , content - related ( Sect . 4 . 4 . 4 ) and temporal ( Sect . 4 . 4 . 5 ) object relations . Thus , our parser design covers the recognition of primary spatial structures and secondary visual nuances ( as discussed in Sect . 1 . 4 on page 10 ) , combined with topic - related similarities and temporal dependencies . Although these mixtures cover already a great range of general structures , there is still room for improvement . We suspect that spatial , visual , content - related and temporal properties of spatial hypertext are not the only determining factors for intended information structure . Instead we assume that there are additional indicators for user intention , which may not be as apparent as proximity , similarity etc . , but still contribute signiﬁcantly to a spatial hyper - text’s structural meaning . We expect that exploiting these ( currently unknown ) properties via additional heuristics will not only result in richer structures but also further support disambiguation and therefore enhance structure detection . This , however , requires that potential inconsistencies between individual parse results are compensable . Note , that adding further heuristics automatically increases the risk of logical inconsistencies . What is still unknown is whether there are mutually contradictory heuristics where compensation of inconsisten - cies is not possible . Therefore , both needs to be investigated , ( 1 ) properties of spatial hypertexts that are still unexploited by parsers and ( 2 ) the eﬀects of combining them with spatial , visual , content and temporal object relations . 207 Chapter 6 . Summary , Conclusion and Future Work 208 Bibliography [ 1 ] C . C . Marshall and F . M . Shipman , III , “Spatial hypertext : designing for change , ” Commun . ACM , vol . 38 , no . 8 , pp . 88 – 97 , Aug . 1995 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 208344 . 208350 [ 2 ] F . M . Shipman , III and C . C . Marshall , “Formality considered harmful : Experiences , emerging themes , and directions on the use of formal representations in interactive systems , ” Comput . Supported Coop . Work , vol . 8 , no . 4 , pp . 333 – 352 , Oct . 1999 . [ Online ] . Available : http : / / dx . doi . org / 10 . 1023 / A : 1008716330212 [ 3 ] C . C . Marshall and F . M . Shipman , III , “Searching for the missing link : discovering implicit structure in spatial hypertext , ” in Proceedings of the ﬁfth ACM conference on Hypertext , ser . HYPERTEXT ’93 . New York , NY , USA : ACM , 1993 , pp . 217 – 230 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 168750 . 168826 [ 4 ] F . Shipman and C . Marshall , “Formality considered harmful : Experiences , emerging themes , and directions . ” Department of Computer Science , Univ . of Colorado , Boulder , CO , Technical Report CU - CS - 648 - 93 , 1993 . [ 5 ] F . M . Shipman , III and R . McCall , “Supporting knowledge - base evolution with incremental formalization , ” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ser . CHI ’94 . New York , NY , USA : ACM , 1994 , pp . 285 – 291 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 191666 . 191768 [ 6 ] C . Atzenbeck and D . L . Hicks , “Integrating time into spatially represented knowledge structures , ” in Proceedings of the 2009 International Conference on Information , Process , and Knowledge Management . IEEE Computer Society , 2009 , pp . 34 – 42 . [ Online ] . Available : http : / / dl . acm . org / citation . cfm ? id = 1510519 . 1510546 209 Bibliography [ 7 ] F . M . Shipman , III , H . Hsieh , P . Maloor , and J . M . Moore , “The visual knowledge builder : a second generation spatial hypertext , ” in Proceedings of the 12th ACM conference on Hypertext and Hypermedia , ser . HYPERTEXT ’01 . New York , NY , USA : ACM , 2001 , pp . 113 – 122 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 504216 . 504245 [ 8 ] F . Shipman , R . Airhart , H . Hsieh , P . Maloor , J . M . Moore , and D . Shah , “Visual and spatial communication and task organization using the visual knowledge builder , ” in Proceedings of the 2001 International ACM SIGGROUP Conference on Supporting Group Work , ser . GROUP ’01 . New York , NY , USA : ACM , 2001 , pp . 260 – 269 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 500286 . 500325 [ 9 ] F . M . Shipman , III and C . C . Marshall , “Spatial hypertext : an alternative to navigational and semantic links , ” ACM Comput . Surv . , vol . 31 , no . 4es , Dec . 1999 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 345966 . 346001 [ 10 ] D . Bucka - Lassen , C . Pedersen , and O . Reinert , Cooperative Authoring Using Open Spatial Hypermedia . Aarhus University , Department of Computer Science , 1998 . [ Online ] . Available : http : / / books . google . de / books ? id = CZayZwEACAAJ [ 11 ] L . Francisco - Revilla and F . Shipman , “Parsing and interpreting ambiguous structures in spatial hypermedia , ” in Proceedings of the sixteenth ACM conference on Hypertext and hypermedia , ser . HYPERTEXT ’05 . New York , NY , USA : ACM , 2005 , pp . 107 – 116 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 1083356 . 1083376 [ 12 ] C . C . Marshall , F . M . Shipman , III , and J . H . Coombs , “VIKI : spatial hypertext supporting emergent structure , ” in Proceedings of the 1994 ACM European conference on Hypermedia technology , ser . ECHT ’94 . New York , NY , USA : ACM , 1994 , pp . 13 – 23 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 192757 . 192759 [ 13 ] H . Hsieh and F . Shipman , “Activity links : supporting communication and reﬂection about action , ” in Proceedings of the sixteenth ACM conference on Hypertext and hypermedia , ser . HYPERTEXT ’05 . New York , NY , USA : ACM , 2005 , pp . 161 – 170 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 1083356 . 1083388 [ 14 ] F . M . Shipman , III , C . C . Marshall , and T . P . Moran , “Finding and using implicit structure in human - organized spatial layouts of information , ” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ser . CHI ’95 . New York , NY , USA : 210 Bibliography ACM Press / Addison - Wesley Publishing Co . , 1995 , pp . 346 – 353 . [ Online ] . Available : http : / / dx . doi . org / 10 . 1145 / 223904 . 223949 [ 15 ] E . J . Golin , “Parsing visual languages with picture layout grammars , ” J . Vis . Lang . Comput . , vol . 2 , pp . 371 – 393 , December 1991 . [ Online ] . Available : http : / / dx . doi . org / 10 . 1016 / S1045 - 926X ( 05 ) 80005 - 9 [ 16 ] Handbook of Graph Grammars and Computing by Graph Transformations , Volume 1 : Foundations . World Scientiﬁc , 1997 . [ 17 ] T . Igarashi , S . Matsuoka , and T . Masui , “Adaptive recognition of implicit structures in human - organized layouts , ” in Visual Languages , Proceedings . , 11th IEEE International Symposium on , Sep 1995 , pp . 258 – 266 . [ 18 ] C . C . Marshall and R . A . Rogers , “Two years before the mist : experiences with Aquanet , ” in Proceedings of the ACM conference on Hypertext , ser . ECHT ’92 . New York , NY , USA : ACM , 1992 , pp . 53 – 62 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 168466 . 168490 [ 19 ] F . M . Shipman , III , “Supporting knowledge - base evolution with incremen - tal formalization , ” Ph . D . dissertation , Boulder , CO , USA , 1993 , uMI Or - der No . GAX94 - 06815 . [ 20 ] C . C . Marshall and F . M . Shipman , III , “Spatial hypertext and the practice of information triage , ” in Proceedings of the eighth ACM conference on Hypertext , ser . HYPERTEXT ’97 . New York , NY , USA : ACM , 1997 , pp . 124 – 133 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 267437 . 267451 [ 21 ] C . C . Marshall , F . G . Halasz , R . A . Rogers , and W . C . Janssen , Jr . , “Aquanet : a hypertext tool to hold your knowledge in place , ” in Proceedings of the third annual ACM conference on Hypertext , ser . HYPERTEXT ’91 . New York , NY , USA : ACM , 1991 , pp . 261 – 275 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 122974 . 123000 [ 22 ] F . G . Halasz , T . P . Moran , and R . H . Trigg , “Notecards in a nutshell , ” in Proceedings of the SIGCHI / GI Conference on Human Factors in Computing Systems and Graphics Interface , ser . CHI ’87 . New York , NY , USA : ACM , 1987 , pp . 45 – 52 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 29933 . 30859 [ 23 ] F . M . Shipman , R . J . Chaney , and G . A . Gorry , “Distributed hypertext for collaborative research : The virtual notebook system , ” in Proceedings of the Second Annual ACM Conference on Hypertext , ser . HYPERTEXT ’89 . New York , NY , USA : ACM , 1989 , pp . 129 – 135 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 74224 . 74235 211 Bibliography [ 24 ] T . W . Malone , “How do people organize their desks ? : Implications for the design of oﬃce information systems , ” ACM Trans . Inf . Syst . , vol . 1 , no . 1 , pp . 99 – 112 , Jan . 1983 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 357423 . 357430 [ 25 ] R . Mander , G . Salomon , and Y . Y . Wong , “A pile metaphor for supporting casual organization of information , ” in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , ser . CHI ’92 . New York , NY , USA : ACM , 1992 , pp . 627 – 634 . [ Online ] . Available : http : / / doi . acm . org . zorac . aub . aau . dk / 10 . 1145 / 142750 . 143055 [ 26 ] A . Kidd , “The marks are on the knowledge worker , ” in Conference Companion on Human Factors in Computing Systems , ser . CHI ’94 . New York , NY , USA : ACM , 1994 , pp . 212 – . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 259963 . 260346 [ 27 ] O . Reinert , D . Bucka - Lassen , C . A . Pedersen , and P . J . Nürnberg , “CAOS : a collaborative and open spatial structure service component with incremental spatial parsing , ” in Proceedings of the tenth ACM Conference on Hypertext and hypermedia : returning to our diverse roots , ser . HYPERTEXT ’99 . New York , NY , USA : ACM , 1999 , pp . 49 – 50 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 294469 . 294484 [ 28 ] M . B . Nielsen and P . Ørbæk , “Spatial parsing within the Topos 3d envi - ronment , ” in IN THE FIRST WORKSHOP ON SPATIAL HYPERTEXT , 2001 , p . 1 . [ 29 ] —— , “Finding hyper - structure in space : Spatial parsing in 3d , ” in THE NEW REVIEW OF HYPERMEDIA AND MULTIMEDIA . Taylor & Francis , Inc . , 2001 , pp . 153 – 183 . [ 30 ] K . Nakakoji , Y . Yamamoto , S . Takada , and B . N . Reeves , “Two - dimensional spatial positioning as a means for reﬂection in design , ” in Proceedings of the 3rd conference on Designing interactive systems : processes , practices , methods , and techniques , ser . DIS ’00 . New York , NY , USA : ACM , 2000 , pp . 145 – 154 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 347642 . 347697 [ 31 ] Y . Yamamoto , K . Nakakoji , and A . Aoki , “Spatial hypertext for linear - information authoring : Interaction design and system development based on the ART design principle , ” in Proceedings of the thirteenth ACM conference on Hypertext and hypermedia , ser . HYPERTEXT ’02 . New York , NY , USA : ACM , 2002 , pp . 35 – 44 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 513338 . 513351 212 Bibliography [ 32 ] Y . Yamamoto , K . Nakakoji , Y . Nishinaka , M . Asada , and R . Matsuda , “What is the space for ? : the role of space in authoring hypertext representations , ” in Proceedings of the sixteenth ACM conference on Hypertext and hypermedia , ser . HYPERTEXT ’05 . New York , NY , USA : ACM , 2005 , pp . 117 – 125 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 1083356 . 1083378 [ 33 ] M . Bernstein , “Design note : Neighborhoods in spatial hypertext , ” SIGWEB Newsl . , vol . 6 , no . 1 , pp . 15 – 19 , Feb . 1997 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 278530 . 278532 [ 34 ] F . Shipman , J . M . Moore , P . Maloor , H . Hsieh , and R . Akkapeddi , “Semantics happen : knowledge building in spatial hypertext , ” in Proceedings of the thirteenth ACM conference on Hypertext and hypermedia , ser . HYPERTEXT ’02 . New York , NY , USA : ACM , 2002 , pp . 25 – 34 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 513338 . 513350 [ 35 ] D . Kim and F . M . Shipman , “Interpretation and visualization of user history in a spatial hypertext system , ” in Proceedings of the 21st ACM conference on Hypertext and hypermedia , ser . HT ’10 . New York , NY , USA : ACM , 2010 , pp . 255 – 264 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 1810617 . 1810663 [ 36 ] F . M . S . III and H . wei Hsieh , “Navigable history : a reader’s view of writer’s time . ” The New Review of Hypermedia and Multimedia , vol . 6 , pp . 147 – 167 , 2000 . [ Online ] . Available : http : / / dblp . uni - trier . de / db / journals / nrhm / nrhm6 . html # ShipmanH00 [ 37 ] F . M . Shipman , H . Hsieh , J . M . Moore , and A . Zacchi , “Supporting personal collections across digital libraries in spatial hypertext , ” in Proceedings of the 4th ACM / IEEE - CS joint conference on Digital libraries , ser . JCDL ’04 . New York , NY , USA : ACM , 2004 , pp . 358 – 367 . [ Online ] . Available : http : / / doi . acm . org / 10 . 1145 / 996350 . 996433 [ 38 ] J . Schanda , Colorimetry : Understanding the CIE System . Wiley , 2007 . [ Online ] . Available : https : / / books . google . de / books ? id = uZadszSGe9MC [ 39 ] D . M . Blei , A . Y . Ng , and M . I . Jordan , “Latent dirichlet allocation , ” J . Mach . Learn . Res . , vol . 3 , pp . 993 – 1022 , Mar . 2003 . [ Online ] . Available : http : / / dl . acm . org / citation . cfm ? id = 944919 . 944937 [ 40 ] S . Kullback and R . A . Leibler , “On information and suﬃciency , ” Ann . Math . Statist . , vol . 22 , no . 1 , pp . 79 – 86 , 1951 . 213 Bibliography [ 41 ] J . Cohen , Statistical Power Analysis for the Behavioral Sciences . L . Erlbaum Associates , 1988 . [ Online ] . Available : https : / / books . google . de / books ? id = Tl0N2lRAO9oC [ 42 ] D . Lakens , “Calculating and reporting eﬀect sizes to facilitate cumulative science : A practical primer for t - tests and ANOVAs , ” Frontiers in Psychology , vol . 4 , no . 863 , 2013 . [ Online ] . Available : http : / / www . frontiersin . org / cognition / 10 . 3389 / fpsyg . 2013 . 00863 / abstract [ 43 ] W . P . Dunlap , J . M . Cortina , J . B . Vaslow , and M . J . Burke , “Meta - analysis of experiments with matched groups or repeated measure designs . ” Psychological Methods , vol . 1 , no . 2 , pp . 170 – 177 , 1996 . [ 44 ] J . Cohen , “Quantitative methods in psychology : A power primer , ” Psy - chological Bulletin , vol . 112 , no . 1 , pp . 155 – 159 , 1992 . 214 Appendix 215 Appendix S p a t i a l H y p e r m e d i a S y s t e m c o n v e r s i o n I n t e r p r e t a t i o n S y s t e m E d i t i n g S y s t e m v i e w W o r k s p a c e c o n t r o ll e r     + 1     c o n v e r t _ e v e n t  ′  c o n v e r t _ i n f o _ un i t s    (cid:1845)  m e r g e M o d e l  ′              c o n v e r t _ i n t e r p r e t a t i o n     ′      T e m p o r a l P a r s e r       pu s h upd a t e _ t e m p o r a l _ r e l a t i o n s (cid:1828)  (cid:1828)  + 1 (cid:1836)  (cid:1836)  + 1 n o r m a li z e S p a t i a l P a r s e r  (cid:1845)  (cid:1845)  (cid:1845) f a d e     + 1 p a r s e (cid:1836)  (cid:1836)  + 1 V i s u a l P a r s e r       f a d e     + 1 p a r s e (cid:1836)  (cid:1836)  + 1 C o n t e n t P a r s e r  (cid:1829)  (cid:1829)  (cid:1829) f a d e     + 1 p a r s e (cid:1836)  (cid:1836)  + 1     (cid:1829)      216 Appendix 217