CAMsterdam at SemEval - 2019 Task 6 : Neural and graph - based feature extraction for the identiﬁcation of offensive tweets Guy Aglionby † , Christopher Davis † , Pushkar Mishra ‡ , Andrew Caines † , Helen Yannakoudakis † , Marek Rei † , Ekaterina Shutova * & Paula Buttery † † Department of Computer Science & Technology , University of Cambridge , U . K . { ga384 , ccd38 , apc38 , hy260 , mr472 , pjb48 } @ cam . ac . uk ‡ Facebook AI , London , U . K . pushkarmishra @ fb . com * Institute for Logic , Language and Computation , University of Amsterdam , Netherlands e . shutova @ uva . nl Abstract We describe the CAMsterdam team entry to the SemEval - 2019 Shared Task 6 on offen - sive language identiﬁcation in Twitter data . Our proposed model learns to extract tex - tual features using a multi - layer recurrent net - work , and then performs text classiﬁcation us - ing gradient - boosted decision trees ( GBDT ) . A self - attention architecture enables the model to focus on the most relevant areas in the text . We additionally learn globally optimised em - beddings for hashtags using node2vec , which are given as additional tweet features to the GBDT classiﬁer . Our best model obtains 78 . 79 % macro F1 - score on detecting offensive language ( subtask A ) , 66 . 32 % on categorising offence types ( targeted / untargeted ; subtask B ) , and 55 . 36 % on identifying the target of of - fence ( subtask C ) . 1 Introduction The SemEval - 2019 shared task 6 ( ‘OffensEval’ ) involved three sub - parts : the classiﬁcation of tweets as offensive or not ( subtask A ) , classify - ing whether they are targeted insults or not ( sub - task B ) , and ﬁnally whether the targeted insults are aimed at an individual , group or otherwise ( sub - task C ) . Further details may be found in the shared task report ( Zampieri et al . , 2019b ) . Here we de - scribe CAMsterdam’s competition entry . In recent years , there has been a growing inter - est in the automatic detection of offensive opinions expressed in online texts , including those posted in discussion forums , news article comment sec - tions , and social networks . Such detection is not straightforwardly a matter of identifying texts con - taining obscene words ( Malmasi and Zampieri , 2018 ) ; offensiveness often arises from the con - text , current affairs , world knowledge , the use of acronyms and slang , and the identity of the authors and audience . Therefore the task is a challenging one , but one with real world impact : if measures can be taken to identify and curtail trolling , the toxicity of the internet can to some extent be re - duced . There is evidence that online harassment is connected with oppression , violence and sui - cide ( Dinakar et al . , 2011 ; Sood et al . , 2012 ; Wul - czyn et al . , 2017 ) , and there may moreover be rea - sons for concern about the perpetrator’s wellbeing along with that of the victims ( Cheng et al . , 2017 ) . Our approach to the task extends the work of Mishra et al . ( 2018b ) , who extract features from tweets using an RNN for subsequent use in a gradient - boosted decision tree ( GBDT ) ( Ke et al . , 2017 ) . Firstly , we experiment with changes to the RNN , including the use of self - attention ( Rei and Søgaard , 2019 ) and ELMo embeddings ( Pe - ters et al . , 2018 ) . Secondly , we add additional fea - tures to the GBDT , including globally - optimised hashtag embeddings learned from a graph of tweet contents using node2vec ( Grover and Leskovec , 2016 ) . We show that this method of learning dis - tributional information about hashtags improves performance over just learning their embeddings within a RNN . 2 Related Work There has been much work characterising of - fensive online discourse including hate speech and cyberbullying ( Warner and Hirschberg , 2012 ; Kwok and Wang , 2013 ; Xu et al . , 2013 ; Waseem et al . , 2017 ; Ribeiro et al . , 2018 ) . This work also includes creating datasets for training and eval - uating detection models , for example the Hate Speech Twitter Annotations and Wikipedia Com - ments Corpora ( Waseem and Hovy , 2016 ; David - son et al . , 2017 ; Wulczyn et al . , 2017 ) . Most work has been conducted on English data – tweets in particular – with some extensions to other do - mains ( e . g . hacking forums ( Caines et al . , 2018 ) ) and other languages ( e . g . Arabic ( Mubarak et al . , 2017 ) , Chinese ( Su et al . , 2017 ) , Slovene ( Fiˇser et al . , 2017 ) ) . Automated detection approaches have drawn on traditional document classiﬁcation methods for spam detection and sentiment analysis , and tend to use lexical and syntactic features ( Nobata et al . , 2016 ; Li et al . , 2017 ; Bourgonje et al . , 2018 ) . Ma - chine learning techniques range from logistic re - gression ( Cheng et al . , 2015 ) to support vector machines ( Yin et al . , 2009 ) to neural networks ( Gamb¨ack and Sikdar , 2017 ) . We draw on the work by Mishra and colleagues , who used a character - based recurrent neural net - work to form contextual word representations of out - of - vocabulary words ( Mishra et al . , 2018b ) , and moreover employed graph - based author em - beddings to represent group behaviour within so - cial networks , signiﬁcantly improving abuse de - tection ( Mishra et al . , 2018a ) . In this shared task , we do not have access to author information , but instead adapt the approach by building a graph of the tokens which occur in the training data , a method described in further detail in Section 4 . 4 . 3 Data The OffensEval shared task uses the Offen - sive Language Identiﬁcation Dataset ( OLID ) ( Zampieri et al . , 2019a ) , which hierarchically la - bels tweets according to whether or not they are offensive , whether any offence is targeted , and if so targeted at whom : an individual , a group or oth - erwise . The three subtasks in this shared task cor - respond to predicting labels at each level of gran - ularity . The data is structured to allow this : all tweets presented in subtask B are guaranteed to be offensive , and all of those in subtask C are tar - geted . Tweets were collected by using the Twitter API to search for terms that are frequently associated with offensive behaviour . These included polit - ical keywords , as political content may attract a disproportionate amount of offensive comments . The dataset is evenly split between tweets sourced from these keywords and non - political ones . The authors additionally found that an effective strat - egy for gathering offensive tweets was to search for those ﬂagged by Twitter’s safe search feature . All tweets were anonymised by replacing user - names and URLs with placeholder tokens . Each of the 14 , 100 collected tweets were man - A B C Train Test Total OFF TIN IND 2 , 407 100 2 , 507 OFF TIN OTH 395 35 430 OFF TIN GRP 1 , 074 78 1 , 152 OFF UNT — 524 27 551 NOT — — 8 , 840 620 9 , 460 All 13 , 240 860 14 , 100 Table 1 : Count of tweets in each category of OLID ( Zampieri et al . , 2019a ) . ually annotated by at least two annotators ; where the original two annotators disagreed on a tweet , it was further annotated until agreement reached 66 % . Table 1 presents the number of tweets in each category . 4 Methodology In this section , we extend the model proposed by Mishra et al . ( 2018b ) for offensive language clas - siﬁcation . The architecture uses a 2 - layer RNN , optimised using Adam ( Kingma and Ba , 2015 ) , to predict the class of a given tweet . The pre - softmax activation values from the output layer are given as input to a GBDT for ﬁnal classiﬁcation . Using the GBDT for classiﬁcation was found to give better results compared with predicting from the RNN directly , and allows us to include additional fea - tures into the model . The RNN is initialised with pre - trained word embeddings which are ﬁne - tuned during training . For previously unseen words , we follow Mishra et al . ( 2018b ) in using a neu - ral character - based compositional model to gen - erate plausible embeddings of unseen words . This component is optimised to compose context - aware character embeddings into word - level embeddings that are similar to the pre - trained representations , trained on words for which the embeddings are available . This methodology is effective in gener - ating reasonable quality embeddings in instances where words were deliberately obscured to evade detection . Following common practice in named entity recognition ( Sang and De Meulder , 2003 ) , where ﬁne - grained labels are used to improve perfor - mance on the sequence labeling task , we take advantage of the hierarchical labels available for each tweet . For subtasks A and B we train a model to predict all cascading labels , and sum the prob - abilities of labels under the relevant class to make a ﬁnal prediction . For example , for subtask A the model is trained to predict between 5 classes : not - offensive ( NOT ) , offensive but not targeted ( UNT ) , targeted towards an individual ( IND ) , towards a group ( GRP ) , and towards any other target ( OTH ) . We classify a tweet as offensive if the cumulative probability mass for UNT , IND , GRP , and OTH is greater than NOT . We also introduce several architectural exten - sions to the Mishra et al . ( 2018b ) model . Firstly , we augment the core RNN with ELMo embed - dings and a self - attention mechanism . Secondly , we add both the post - softmax output from the RNN as well as graph - based representations of tweets as input features to the GBDT classiﬁer . We provide details of each extension in the fol - lowing sections . For each subtask , we experiment with combina - tions of the above and additionally tune the RNN type ( between LSTM ( Hochreiter and Schmidhu - ber , 1997 ) and GRU ( Cho et al . , 2014 ) ) , dimen - sion , and batch size , whether to use character n - grams ( n ∈ [ 1 , 4 ] ) , and , when used , the size of self - attention layers . We also run experiments using the unmodiﬁed model to ﬁnd which pre - trained embeddings give the best performance . We compare publicly available embeddings trained using Word2Vec ( Mikolov et al . , 2013 ) , FastText ( Mikolov et al . , 2018 ) , and GLoVe ( Pennington et al . , 2014 ) . 4 . 1 ELMo We use embeddings generated from ELMo con - catenated with pre - trained word embeddings as in - put to the RNN . ELMo generates embeddings on a character level , so does not share the same out - of - vocabulary issue as pre - trained embeddings and is always able to generate a word representation . We used the largest pre - trained model available on - line 1 , and learn a weighted linear combination of its three layers . 4 . 2 Self - attention The model proposed by Mishra et al . ( 2018b ) uses the last hidden state of the RNN as the feature representation for each tweet ; instead , we propose the use of a self - attention mechanism to learn a weighted combination of all intermediate hidden states ( Rei and Søgaard , 2019 ) . The weights ˆ a i for each hidden state h i are learned by passing h i through two dense layers with tanh activation , 1 https : / / allennlp . org / elmo and a further 1 - dimensional dense layer . The ﬁ - nal dense layer has either sigmoid or exponential activation , corresponding to soft or sharp attention respectively . The weights are normalised to sum to 1 , yielding ﬁnal attention values (cid:101) a i , which are used to obtain the ﬁnal sentential representation s = (cid:80) i (cid:101) a i h i . The RNN is then trained using cat - egorical cross - entropy on s passed through a ﬁnal tanh layer . 4 . 3 RNN Prediction This modiﬁcation includes the post - softmax out - put of the RNN as an additional input feature to the decision tree . 4 . 4 node2vec We make use of node2vec to learn low - dimensional continuous representations of hash - tags used in tweets on the basis of whole - tweet contexts . We ﬁrst represent every token ( including all hashtags ) and each tweet as nodes in a graph , with edges formed between tweets and the tokens they contain . node2vec ﬁrst follows a tunable sampling strategy to perform random walks from each node , generating directed acyclic graphs with a maximum out degree of 1 ( i . e . a sequence of nodes ) . It then applies the SkipGram model ( Mikolov et al . , 2013 ) to learn a representation of each node based on its neighbours in the sam - pled sequences . Speciﬁcally , given a graph with nodes V , node2vec maximises the log probability : (cid:80) v ∈ V log ( P ( N s ( v ) | v ) ) , where N s ( v ) is the set of neighboring nodes for node v generated from a sampling strategy s . We train these node2vec representations on two data sets : the OLID training data , and our own scrape of Twitter using rtweet ( Kearney , 2018 ) . We collect this additional data by searching for each of the 24 hashtags which appear at least 10 times in the training set , with at least 1 in 4 oc - currences in tweets labelled offensive . Intuitively , these common and frequently offensive hashtags are a more reliable signal of offensiveness than less frequent hashtags . It remains to be seen whether collecting more tweets with all hashtags in OLID would help , but the strict rate limits on the Twitter API meant that we ran out of time to explore this . We trained 200 - dimensional embeddings on a random sample of 10 , 000 of the resulting tweets . To represent each tweet we sum the embeddings of each hashtag present , and normalised the re - System F1 ( macro ) Vanilla model 0 . 710 Vanilla model + ELMo 0 . 742 Vanilla model + ELMo + self attention 0 . 764 Vanilla model + ELMo + self attention + char . ngrams 0 . 763 Vanilla model + ELMo + self attention + node2vec 0 . 764 Vanilla model + ELMo + self attention + char . ngrams + node2vec 0 . 767 Table 2 : Ablation test for features , with results reported on our held - out development set for subtask A . sulting vector to unit length . These vectors , or a 200 - dimensional 0 - vector for tweets containing no hashtags with trained embeddings , were then con - catenated with the RNN features ( either from self - attention where it was used , or the last hidden state if not ) prior to being input into the GBDT . 5 Results In this section , we present a sample of results ob - tained during model selection , and results on each of the ofﬁcial subtask test sets . Model selection is carried out by evaluating each model on a consis - tent 90 % training and 10 % validation split of the provided training data . Before carrying out model selection , we ran an unmodiﬁed version of Mishra et al . ( 2018b ) ’s model on subtask A and found that 300 - dimensional FastText embeddings trained on Common Crawl gave the best performance 2 . We submitted three models for each of the three subtasks . We submit models that differ in two ways . The ﬁrst is the amount of data they are trained on . Models labelled ALL - DATA are trained on all of the provided data , while models tagged TRAIN - SPLIT are trained on just the 90 % training split , but have a known performance via their re - sults on the development set . It is beneﬁcial to know this as there is a large amount of variance in model results due to stochasticity in the train - ing process . The second way in which the models differ is designed to handle this variance by en - sembling three models via majority vote . Such submissions are labelled with ENSEMBLE , while those only using a single model are labelled BEST . In all three subtasks we ﬁnd that the best per - forming system is that which ensembles three identical models trained on the entire training set . 5 . 1 Subtask A Subtask A concerns classifying a tweet as OFF ( of - fensive ) or NOT ( see Section 3 ) . We experiment 2 https : / / fasttext . cc / docs / en / english - vectors . html with adaptations of the model from Mishra et al . ( 2018b ) to perform a 5 - WAY classiﬁcation be - tween all categories , and select the most effective feature combination for each subtask . We experi - ment with features mentioned in Section 4 : ELMo , self - attention , character n - grams , and node2vec . Results from ablation studies are presented in Ta - ble 2 . We found that the best performing model used features extracted from a RNN that used ELMo embeddings in addition to FastText and compo - sitional character - based word embeddings , with sharp self - attention over a GRU with 256 hidden units trained using a batch size of 64 . These fea - tures were used in a GBDT alongside the 10 , 000 most frequently occurring character n - grams , and node2vec representations of the tweets . Table 3 shows our results for subtask A on the test data . All three submissions use the model ar - chitecture and hyperparameters described above . System F1 Accuracy All NOT baseline 0 . 419 0 . 721 All OFF baseline 0 . 218 0 . 279 TRAIN - SPLIT - BEST 0 . 776 0 . 835 ALL - DATA - ENSEMBLE 0 . 788 0 . 847 ALL - DATA - BEST 0 . 769 0 . 835 Table 3 : Accuracy and macro F1 results on the ofﬁcial subtask A test set . All three models have the same hy - perparameters . 5 . 2 Subtask B Subtask B involves a binary classiﬁcation of whether a tweet is untargeted ( UNT ) or targeted ( TIN ) . Following Subtask A , we maintain a ﬁner grained classiﬁer using a 4 - WAY classiﬁcation ( TIN , IND , GRP , OTH ) , where we classify a tweet as targeted if the probability for TIN is less than the sum of probabilities for the 3 other labels . We re - ran feature selection experiments to op - System F1 Accuracy All TIN baseline 0 . 470 0 . 888 All UNT baseline 0 . 101 0 . 113 TRAIN - SPLIT - BEST 0 . 577 0 . 717 ALL - DATA - ENSEMBLE 0 . 663 0 . 904 TRAIN - SPLIT - ENSEMBLE 0 . 657 0 . 900 Table 4 : Accuracy and macro F1 results on the ofﬁcial subtask B test set . timise for this task . Development experiments showed that the use of character n - grams does not improve performance on this subtask , LSTM per - forms better than a GRU , and that reducing the RNN dimension to 64 and training batch size to 32 is beneﬁcial . These smaller hyperparameter values are likely more suitable due to the smaller amount of available training data . We found that training node2vec using the provided training data , rather than the scraped dataset , gave better representa - tions , with F1 scores on our held - out development set of 0 . 635 for OLID data and 0 . 618 for the ex - tra tweets we obtained from Twitter’s API ( section 4 . 4 ) . Results on the test set are presented in Table 4 , where we once again ﬁnd that the ensemble of classiﬁers trained on all of the data performs best . 5 . 3 Subtask C Subtask C involves classifying the target of an of - fensive tweet as either an individual , group , or other . As this is the last subtask , only classiﬁcation between these three labels is possible : there are no ﬁner - grained labels that can be trained on . We ﬁnd that the best performing model is the same as that in subtask B , except that a GRU is used and the softmax from the RNN is included in the GBDT . Results on the test data are presented in Table 5 . System F1 Accuracy All GRP baseline 0 . 179 0 . 366 All IND baseline 0 . 213 0 . 470 All OTH baseline 0 . 094 0 . 164 ALL - DATA - ENSEMBLE 0 . 554 0 . 704 TRAIN - SPLIT - ENSEMBLE 0 . 544 0 . 709 TRAIN - SPLIT - BEST 0 . 534 0 . 695 Table 5 : Accuracy and macro F1 results on the ofﬁcial subtask C test set . N O T O FF Predicted label NOT OFF T r u e l a b e l 590 30 102 138 Confusion Matrix 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 Figure 1 : Subtask A , ALL - DATA - ENSEMBLE model . 6 Discussion In all subtasks , our best performing submission was an ensemble of three identical models , inde - pendently trained on all of the training data . En - sembling helps to account for the high variance observed during model training , which occurred despite ﬁxing random seeds . Across all subtasks we ﬁnd the inclusion of node2vec features to be helpful . These features offer contextualised representations of hashtags in terms of the tokens they appear with across the corpus , suggesting that features that share infor - mation between tweets are useful in addition to those derived from each individually . We observe that performance drops from sub - task A to C . This could be due to the decreasing amounts of training data , from 13 , 240 instances in Subtask A , to 4 , 400 in subtask B and 3 , 876 in subtask C . Very small amounts of data are avail - able for two classes in particular – untargeted of - fence ( UNT ) with only 524 training instances , and offence targeted at those other than individuals and groups ( OTH ) with 395 . As seen in Figures 1 and 2 , our model achieves high recall for the NOT class ( 0 . 952 ) in subtask A and for TIN ( 0 . 986 ) in subtask B , but low re - call for the other classes OFF ( 0 . 575 ) and UNT ( 0 . 259 ) . Figure 3 shows that in subtask C we per - form worst on the OTH label , with a low recall of 0 . 086 . In all cases , the model shows weakest per - formance on the classes for which we have least training data . Therefore , we expect that model performance would improve given more training instances of the minority classes . Furthermore , in subtask C , the deﬁnition of the ‘other’ class is less clear - cut than the other two cat - T I N U N T Predicted label TIN UNT T r u e l a b e l 210 3 20 7 Confusion Matrix 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 Figure 2 : Subtask B , ALL - DATA - ENSEMBLE model . G R P I N D O T H Predicted label GRP IND OTH T r u e l a b e l 60 16 2 12 87 1 22 10 3 Confusion Matrix 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 Figure 3 : Subtask C , ALL - DATA - ENSEMBLE model . egories GRP and IND , including abstract concepts such as events or issues , and serving as a catch - all for targeted insults against anything other than speciﬁc people or groups of people with a com - mon characteristic . A manual inspection of the data suggests that a large amount of the OTH data includes politically - motivated insults , though sim - ilar language also appears in the two other cate - gories , which may make classiﬁcation harder . 7 Conclusion The CAMsterdam team attempted the OffensE - val tasks taking inspiration from the approach of Mishra and colleagues ( 2018b ) , feeding the pre - softmax activation layer of an RNN into a GBDT to classify tweets into one of the applicable ﬁne - grained classes for each subtask . The probabilities of the ﬁne - grained classes were summed to obtain a probability for the desired class : for instance , in subtask A , we summed the probabilities of UNT , IND , GRP and OTH , and compared this sum with the probability of NOT to classify a tweet as offen - sive or not . We extended the work of Mishra et al . by using ELMo embeddings as additional input to the RNN , and incorporating a self - attention mech - anism following Rei and Søgaard ( 2019 ) . We also used node2vec to train graph - based represen - tations of hashtags , using both tweets from the OLID training set and new data obtained from the Twitter API featuring hashtags frequently found in the offensive subset . We focus on hashtags on the intuition that they are employed by users to reach those interested in similar topics , and are thus indicative of tweet content . Their use encodes this useful information directly , which we show to be useful for classiﬁcation . We take into ac - count the fact that hashtags are used in many posi - tions in a tweet by constructing the graph based on co - occurrence across the whole tweet , rather than only within a small window as other embedding methods do . During development , we found that our best performing models were those formed from an en - semble of three models trained in an identical fash - ion , thereby smoothing random variation in the training process . The results of the test phase show that our model performed in line with expectations set during development , with F1 - scores which de - crease from subtask A to C , and lowest precision and recall on the minority classes . In the future , we will seek to address the im - balance in the training data , inspect the tweets further to analyse the linguistic differences be - tween targeted and untargeted insults , group - and individual - targeted insults and so on . Further ar - chitectural changes include collecting more in - stances of hashtags frequently found in offensive tweets as extra unsupervised data , and we can seek to include author embeddings , a technique found to greatly improve the performance of Mishra et al’s system ( Mishra et al . , 2018a ) . Finally , we would aim to evaluate our model on other offen - sive text classiﬁcation datasets , to discover how well the design generalizes beyond OLID . Acknowledgements The 2nd author is supported by the EPSRC , U . K . The 4th , 5th , 6th and 8th authors are members of the ALTA Institute , supported by Cambridge As - sessment , University of Cambridge . We thank the NVIDIA Corporation for the donation of the Titan GPU used in this research . References Peter Bourgonje , Julian Moreno - Schneider , Ankit Sri - vastava , and Georg Rehm . 2018 . Automatic clas - siﬁcation of abusive language and personal attacks in various forms of online communication . In Lan - guage Technologies for the Challenges of the Digital Age . Springer International Publishing . Andrew Caines , Sergio Pastrana , Alice Hutchings , and Paula Buttery . 2018 . Aggressive language in an on - line hacking forum . In Proceedings of the 2nd Work - shop on Abusive Language Online ( ALW2 ) . Associ - ation for Computational Linguistics . Justin Cheng , Michael Bernstein , Cristian Danescu - Niculescu - Mizil , and Jure Leskovec . 2017 . Any - one can become a troll : Causes of trolling behavior in online discussions . In Proceedings of the 2017 ACM Conference on Computer Supported Coopera - tive Work and Social Computing . Justin Cheng , Cristian Danescu - Niculescu - Mizil , and Jure Leskovec . 2015 . Antisocial behavior in on - line discussion communities . In The 9th Interna - tional AAAI Conference on Web and Social Media ( ICWSM ) . Kyunghyun Cho , Bart van Merrienboer , Caglar Gul - cehre , Dzmitry Bahdanau , Fethi Bougares , Holger Schwenk , and Yoshua Bengio . 2014 . Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation . In Proceed - ings of the 2014 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1724 – 1734 , Doha , Qatar . Association for Computa - tional Linguistics . Thomas Davidson , Dana Warmsley , Michael Macy , and Ingmar Weber . 2017 . Automated Hate Speech Detection and the Problem of Offensive Language . In Proceedings of ICWSM . Karthik Dinakar , Roi Reichart , and Henry Lieberman . 2011 . Modeling the detection of textual cyberbul - lying . In Fifth International AAAI Conference on Weblogs and Social Media . Darja Fi ˇ ser , Toma ˇ z Erjavec , and Nikola Ljube ˇ si ´ c . 2017 . Legal framework , dataset and annotation schema for socially unacceptable online discourse practices in Slovene . In Proceedings of the First Workshop on Abusive Language Online . Bj¨orn Gamb¨ack and Utpal Kumar Sikdar . 2017 . Us - ing convolutional neural networks to classify hate - speech . In Proceedings of the First Workshop on Abusive Language Online . Aditya Grover and Jure Leskovec . 2016 . node2vec : Scalable feature learning for networks . In Proceed - ings of the 22nd ACM SIGKDD International Con - ference on Knowledge Discovery and Data Mining . Sepp Hochreiter and Jrgen Schmidhuber . 1997 . Long Short - Term Memory . Neural Comput . , 9 ( 8 ) : 1735 – 1780 . Guolin Ke , Qi Meng , Thomas Finley , Taifeng Wang , Wei Chen , Weidong Ma , Qiwei Ye , and Tie - Yan Liu . 2017 . Lightgbm : A highly efﬁcient gradient boosting decision tree . In I . Guyon , U . V . Luxburg , S . Bengio , H . Wallach , R . Fergus , S . Vishwanathan , and R . Garnett , editors , Advances in Neural Infor - mation Processing Systems 30 , pages 3146 – 3154 . Curran Associates , Inc . Michael W . Kearney . 2018 . rtweet : Collecting Twitter Data . R package version 0 . 6 . 7 . Diederik P . Kingma and Jimmy Ba . 2015 . Adam : a Method for Stochastic Optimization . In Inter - national Conference on Learning Representations , pages 1 – 13 . Irene Kwok and Yuzhou Wang . 2013 . Locate the hate : Detecting tweets against blacks . In Twenty - Seventh AAAI Conference on Artiﬁcial Intelligence . Tai Ching Li , Joobin Gharibshah , Evangelos E . Pa - palexakis , and Michalis Faloutsos . 2017 . TrollSpot : Detecting misbehavior in commenting platforms . In Proceedings of the 2017 IEEE / ACM International Conference on Advances in Social Networks Anal - ysis and Mining 2017 . Shervin Malmasi and Marcos Zampieri . 2018 . Chal - lenges in Discriminating Profanity from Hate Speech . Journal of Experimental & Theoretical Ar - tiﬁcial Intelligence , 30 : 1 – 16 . Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean . 2013 . Efﬁcient Estimation of Word Repre - sentations in Vector Space . arXiv : 1301 . 3781 [ cs ] . ArXiv : 1301 . 3781 . Tomas Mikolov , Edouard Grave , Piotr Bojanowski , Christian Puhrsch , and Armand Joulin . 2018 . Ad - vances in pre - training distributed word representa - tions . In Proceedings of the International Confer - ence on Language Resources and Evaluation ( LREC 2018 ) . Pushkar Mishra , Marco Del Tredici , Helen Yan - nakoudakis , and Ekaterina Shutova . 2018a . Au - thor proﬁling for abuse detection . In Proceedings of the 27th International Conference on Computational Linguistics , Santa Fe , New Mexico , USA . Associa - tion for Computational Linguistics . Pushkar Mishra , Helen Yannakoudakis , and Ekaterina Shutova . 2018b . Neural character - based composi - tion models for abuse detection . In Proceedings of the 2nd Workshop on Abusive Language Online ( ALW2 ) , Brussels , Belgium . Association for Com - putational Linguistics . Hamdy Mubarak , Kareem Darwish , and Walid Magdy . 2017 . Abusive language detection on Arabic so - cial media . In Proceedings of the First Workshop on Abusive Language Online . Chikashi Nobata , Joel Tetreault , Achint Thomas , Yashar Mehdad , and Yi Chang . 2016 . Abusive lan - guage detection in online user content . In Proceed - ings of the 25th International Conference on World Wide Web . Jeffrey Pennington , Richard Socher , and Christo - pher D . Manning . 2014 . Glove : Global vectors for word representation . In Empirical Methods in Nat - ural Language Processing ( EMNLP ) , pages 1532 – 1543 . Matthew E . Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer . 2018 . Deep contextualized word rep - resentations . In Proc . of NAACL . Marek Rei and Anders Søgaard . 2019 . Jointly Learn - ing to Label Sentences and Tokens . In Proceedings of the Thirty - Third AAAI Conference on Artiﬁcial In - telligence ( AAAI 2019 ) , Honolulu , USA . Manoel Horta Ribeiro , Pedro H . Calais , Yuri A . San - tos , and Wagner Meira J Virg´ılio A . F . Almeid and . 2018 . “Like sheep among wolves” : Characterizing hateful users on Twitter . In Proceedings of WSDM workshop on Misinformation and Misbehavior Min - ing on the Web ( MIS2 ) . Erik F Sang and Fien De Meulder . 2003 . Intro - duction to the conll - 2003 shared task : Language - independent named entity recognition . arXiv preprint cs / 0306050 . Sara Owsley Sood , Elizabeth F . Churchill , and Judd Antin . 2012 . Automatic identiﬁcation of personal insults on social news sites . Journal of the Ameri - can Society for Information Science and Technology , 63 : 270 – 285 . Huei - Po Su , Chen - Jie Huang , Hao - Tsung Chang , and Chuan - Jie Lin . 2017 . Rephrasing Profanity in Chi - nese Text . In Proceedings of the Workshop Work - shop on Abusive Language Online ( ALW ) , Vancou - ver , Canada . William Warner and Julia Hirschberg . 2012 . Detecting hate speech on the World Wide Web . In Proceed - ings of the Second Workshop on Language in Social Media . Zeerak Waseem , Thomas Davidson , Dana Warmsley , and Ingmar Weber . 2017 . Understanding Abuse : A Typology of Abusive Language Detection Subtasks . In Proceedings of the First Workshop on Abusive Langauge Online . Zeerak Waseem and Dirk Hovy . 2016 . Hateful sym - bols or hateful people ? predictive features for hate speech detection on Twitter . In Proceedings of the NAACL Student Research Workshop . Ellery Wulczyn , Nithum Thain , and Lucas Dixon . 2017 . Ex Machina : Personal attacks seen at scale . In Proceedings of the 26th International Conference on World Wide Web . Jun - Ming Xu , Benjamin Burchﬁel , Xiaojin Zhu , and Amy Bellmore . 2013 . An examination of regret in bullying tweets . In Proceedings of the 2013 Con - ference of the North American Chapter of the Asso - ciation for Computational Linguistics : Human Lan - guage Technologies . Dawei Yin , Zhenzhen Xue , Liangjie Hong , Brian D . Davison , April Kontostathis , and Lynne Edwards . 2009 . Detection of harassment on Web 2 . 0 . In Proceedings of the Content Analysis in the WEB 2 . 0 ( CAW2 . 0 ) Workshop at WWW2009 . Marcos Zampieri , Shervin Malmasi , Preslav Nakov , Sara Rosenthal , Noura Farra , and Ritesh Kumar . 2019a . Predicting the Type and Target of Offensive Posts in Social Media . In Proceedings of NAACL . Marcos Zampieri , Shervin Malmasi , Preslav Nakov , Sara Rosenthal , Noura Farra , and Ritesh Kumar . 2019b . SemEval - 2019 Task 6 : Identifying and Cat - egorizing Offensive Language in Social Media ( Of - fensEval ) . In Proceedings of The 13th International Workshop on Semantic Evaluation ( SemEval ) .