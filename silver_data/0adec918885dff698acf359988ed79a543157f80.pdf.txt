Fantastically Ordered Prompts and Where to Find Them : Overcoming Few - Shot Prompt Order Sensitivity Yao Lu † Max Bartolo † Alastair Moore ‡ Sebastian Riedel † Pontus Stenetorp † † University College London ‡ Mishcon de Reya LLP { yao . lu , m . bartolo , s . riedel , p . stenetorp } @ cs . ucl . ac . uk alastair . moore @ mishcon . com Abstract When primed with only a handful of training samples , very large , pretrained language mod - els such as GPT - 3 have shown competitive re - sults when compared to fully - supervised , ﬁne - tuned , large , pretrained language models . We demonstrate that the order in which the sam - ples are provided can make the difference be - tween near state - of - the - art and random guess performance : essentially some permutations are “fantastic” and some not . We analyse this phenomenon in detail , establishing that : it is present across model sizes ( even for the largest current models ) , it is not related to a speciﬁc subset of samples , and that a given good per - mutation for one model is not transferable to another . While one could use a development set to determine which permutations are per - formant , this would deviate from the true few - shot setting as it requires additional annotated data . Instead , we use the generative nature of language models to construct an artiﬁcial development set and based on entropy statis - tics of the candidate permutations on this set , we identify performant prompts . Our method yields a 13 % relative improvement for GPT - family models across eleven different estab - lished text classiﬁcation tasks . 1 Introduction Large pretrained language models ( PLMs , De - vlin et al . , 2019 ; Peters et al . , 2018 ; Raffel et al . , 2020 ; Liu et al . , 2019 ; Yang et al . , 2019 ; Radford et al . , 2019 ) have shown remarkable performance when conditioned with an appropriate textual con - text ( Petroni et al . , 2019 , 2020 ; Jiang et al . , 2020 ; Shin et al . , 2020 ; Davison et al . , 2019 ) . For exam - ple , when conditioned on a long document and a “TL ; DR : ” token , they can generate a summary of said document , and when provided a partial ques - tion ( “The theory of relativity was developed by _ _ ” ) , they can generate the correct answer . Perhaps most strikingly , when primed with a context con - sisting of very few training examples , they produce 0 . 1 0 . 3 0 . 8 1 . 5 2 . 7 6 . 7 13 175 Model Parameters ( Billion ) 50 60 70 80 90 100 SS T - 2 A cc u r a c y ( % ) 0 . 1 0 . 3 0 . 8 1 . 5 2 . 7 6 . 7 13 175 Model Parameters ( Billion ) 50 60 70 80 90 100 S u b j A cc u r a c y ( % ) Figure 1 : Four - shot performance for 24 different sam - ple orders across different sizes of GPT - family models ( GPT - 2 and GPT - 3 ) for the SST - 2 and Subj datasets . text classiﬁcation results that can match those of fully supervised models . This type of few shot set - ting , is commonly referred to as “In - context Learn - ing” ( Brown et al . , 2020 ) . A core component of in - context learning is the text - based prompt that serves as the context . Com - posing a prompt requires : ( i ) text linearisation us - ing a template ; and ( ii ) training sample concate - nation ( See Table 1 for an example ) . It has been established that the structure of the template has a large impact on performance ( Shin et al . , 2020 ; Gao et al . , 2020 ; Schick and Schütze , 2020 ; Jiang et al . , 2020 ) . However , to the best of our knowl - edge , no work has studied the effect of the sample ordering on In - context Learning performance . Perhaps counter - intuitively , we ﬁnd that the right sample order can make as much of a difference as a r X i v : 2104 . 08786v2 [ c s . C L ] 3 M a r 2022 Example trainingset ( thegreatestmusicians , 1 ) ( redundantconcept , 0 ) linearization Review : thegreatestmusicians . Sentiment : positive Review : redundantconcept . Sentiment : negative concatenation Review : thegreatestmusicians . Sentiment : positive . Review : redundant concept . Sentiment : negative OR Review : redundantconcept . Sentiment : negative . Review : thegreatest musicians . Sentiment : positive Table 1 : Procedures for prompt construction . the right template . As can be seen in Figure 1 , some permutations have comparable performance ( over 85 % accuracy ) to supervised training for sen - timent classiﬁcation , while others perform close to random ( around 50 % ) . This order sensitivity is uni - versal across models , and although increasing the model size somewhat addresses it , the problem is still present for some text classiﬁcation tasks ( Subj in Figure 1 ) for models with billions of parameters . In our analysis , we ﬁnd no common denomi - nator between performant sample orders and that they are not transferable across different model sizes and tasks . In a fully - supervised setting , we could rely on a development set to select among sample orders . However , this is not desirable in a few - shot setting where the size of the develop - ment set is very limited , even unavailable ( Perez et al . , 2021 ) . Instead , we use the generative na - ture of language models to construct an unlabelled artiﬁcial development set and refer to it as a prob - ing set . As the probing set is unlabelled , we use the predicted label distribution statistics and pro - pose entropy - based metrics to measure the quality of candidate prompts . Experimental results show that we can achieve on average 13 % relative im - provement across eleven different established text classiﬁcation tasks across all different sizes ( four orders of magnitude ) of PLMs . To summarise , our contributions are as follows : 1 . We study order sensitivity for In - context Learning , which we show is crucial for the success of pretrained language models for few - shot learning . 2 . We propose a simple , generation - based prob - ing method to identify performant prompts without requiring additional data . 3 . Our probing method is universally applica - ble and effective across different sizes of pre - trained language models and for different types of datasets – achieving on average a (cid:36)(cid:86)(cid:86)(cid:88)(cid:80)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20)(cid:29)(cid:3)(cid:51)(cid:72)(cid:85)(cid:80)(cid:88)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:44)(cid:81)(cid:89)(cid:68)(cid:85)(cid:76)(cid:68)(cid:81)(cid:70)(cid:72) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:51)(cid:47)(cid:48) (cid:51)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20) (cid:51)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:21) (cid:51)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:49) (cid:44)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:81)(cid:16)(cid:70)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:79)(cid:72)(cid:68)(cid:85)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:86)(cid:72)(cid:87)(cid:87)(cid:76)(cid:81)(cid:74)(cid:15)(cid:3)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20)(cid:3)(cid:32)(cid:3)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:21)(cid:3)(cid:32)(cid:3)(cid:17)(cid:17)(cid:17)(cid:3)(cid:32)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:21)(cid:23) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) (cid:55)(cid:72)(cid:86)(cid:87) (cid:55)(cid:72)(cid:86)(cid:87) (cid:171) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:55)(cid:72)(cid:86)(cid:87) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:171) Figure 2 : Training sample permutations for the In - context Learning setting . The concatenation of training samples as well as test data transforms the classiﬁca - tion task into a sequence generation task . 13 % relative improvement over a wide range of tasks . 2 Order Sensitivity and Prompt Design In this section , we study the relationship between permutation performance and various factors . For the ease of visualisation , we use a ﬁxed random subset of four samples with a balanced label distri - bution from the SST - 2 dataset and consider all 24 possible sample order permutations . This setup is illustrated in Figure 2 . We also test ﬁve randomly - selected sets of examples and summarised variance statistics in the experiment section ( Section 5 ) . Although beneﬁcial , increasing model size does not guarantee low variance We evaluate the or - der permutations for four different sizes of GPT - 2 ( 0 . 1B – 1 . 5B ) 1 and GPT - 3 ( 2 . 7B – 175B ) . As we can observe in Figure 1 , models can obtain remarkable few - shot performance . We see that the GPT2 - XL ( 1 . 5B ) model can even surpass 90 % accuracy given just four samples . This result is comparable to those of supervised models trained on more than 60 , 000 samples . However , the performance varia - tion of different permutations remain a big issue , especially for “smaller” models . 2 The same model can exhibit nearly perfect behaviour given one sam - ple order , but then fall back to be on par with a random baseline for another . While increasing the model size ( by a few order of magnitudes ) can sometimes alleviate the issue , it still cannot resolve it entirely ( especially if we consider tasks other than SST - 2 ) . In contrast , different initialisations of supervised ﬁne - tuning approaches typically result in less than 1 % standard deviation for their test set performance ( Gao et al . , 2020 ) . 1 We can also refer these models as GPT2 - base , GPT2 - medium , GPT2 - Large , and GPT2 - XL . 2 The smallest model in our experiment is the same size as BERT - base . 1 2 4 8 16 32 N - shot Training Examples 50 60 70 80 90 100 SS T - 2 A cc u r a c y ( % ) GPT2 - Small ( 0 . 1B ) GPT2 - Medium ( 0 . 3B ) GPT2 - Large ( 0 . 8B ) GPT2 - XL ( 1 . 5B ) Figure 3 : Order sensitivity using different numbers of training samples . Adding training samples does not signiﬁcantly reduce variance To further explore the order sen - sitivity of few - shot prompts , we increase the num - ber of training samples and then sample a subset of at most 24 different orderings . 3 We use the GPT2 family models for this experiment . In Figure 3 , we can observe that increasing the number of training samples leads to increases in performance . How - ever , a high level of variance remains , even with a large number of samples and can even increase . Based on this , we draw the conclusion that order sensitivity is likely to be a fundamental issue of In - context Learning regardless of the number of training samples . Performant prompts are not transferable across models We ﬁnd that a speciﬁc permuta - tion’s performance may drop from 88 . 7 % to 51 . 6 % by changing the underlying model from GPT2 - XL ( 1 . 5B ) to GPT2 - Large ( 0 . 8B ) . This suggests that a particular permutation working well for one model does not imply that it will provide good results for another model . To validate this hypothesis , we use all possible order permutations of the four sam - ples as prompts – 24 in total . We then perform prediction conditioned on each of these prompts for different models and calculate the pairwise Spearman’s rank correlation coefﬁcient between the scores . These results are shown in Figure 4 . If there is a common pattern for performant prompts , we should then be able to observe high correlation across models . However , the behaviour of permutations is seemingly random even across 3 Bounded at the lower limit by the total number of samples given , and at the upper limit as there can be up to 64 ! possible orders . 0 . 1 B 0 . 3 B 0 . 8 B 1 . 5 B 2 . 7 B 6 . 7 B 1 3 B 1 7 5 B 175B 13B 6 . 7B 2 . 7B 1 . 5B 0 . 8B 0 . 3B 0 . 1B M o d e l P a r a m e t e r s - 0 . 17 - 0 . 23 - 0 . 35 - 0 . 14 0 . 05 0 . 27 - 0 . 22 1 . 00 - 0 . 24 0 . 01 - 0 . 12 0 . 01 0 . 12 0 . 04 1 . 00 - 0 . 22 - 0 . 10 - 0 . 26 0 . 19 - 0 . 03 0 . 13 1 . 00 0 . 04 0 . 27 0 . 07 - 0 . 11 0 . 10 - 0 . 27 1 . 00 0 . 13 0 . 12 0 . 05 - 0 . 24 0 . 20 - 0 . 04 1 . 00 - 0 . 27 - 0 . 03 0 . 01 - 0 . 14 0 . 23 0 . 08 1 . 00 - 0 . 04 0 . 10 0 . 19 - 0 . 12 - 0 . 35 0 . 09 1 . 00 0 . 08 0 . 20 - 0 . 11 - 0 . 26 0 . 01 - 0 . 23 1 . 00 0 . 09 0 . 23 - 0 . 24 0 . 07 - 0 . 10 - 0 . 24 - 0 . 17 0 1 S p e a r m a n C o rr e l a t i o n Figure 4 : Training sample permutation performance correlation across different models . 0 . 1 B 0 . 3 B 0 . 8 B 1 . 5 B 2 . 7 B 6 . 7 B 1 3 B 1 7 5 B 175B 13B 6 . 7B 2 . 7B 1 . 5B 0 . 8B 0 . 3B 0 . 1B M o d e l P a r a m e t e r s - 0 . 26 - 0 . 20 0 . 09 - 0 . 66 - 0 . 26 0 . 77 - 0 . 54 1 . 00 - 0 . 09 0 . 09 - 0 . 37 0 . 77 - 0 . 49 - 0 . 09 1 . 00 - 0 . 54 - 0 . 49 0 . 03 - 0 . 49 - 0 . 43 - 0 . 49 1 . 00 - 0 . 09 0 . 77 0 . 71 0 . 20 0 . 31 0 . 09 1 . 00 - 0 . 49 - 0 . 49 - 0 . 26 0 . 37 0 . 31 0 . 09 1 . 00 0 . 09 - 0 . 43 0 . 77 - 0 . 66 0 . 26 0 . 09 1 . 00 0 . 09 0 . 31 - 0 . 49 - 0 . 37 0 . 09 - 0 . 31 1 . 00 0 . 09 0 . 31 0 . 20 0 . 03 0 . 09 - 0 . 20 1 . 00 - 0 . 31 0 . 26 0 . 37 0 . 71 - 0 . 49 - 0 . 09 - 0 . 26 0 1 S p e a r m a n C o rr e l a t i o n Figure 5 : Training label pattern permutation perfor - mance correlation across different models . different sizes of the same model . For example , the 175B and 2 . 7B model only has a correlation of 0 . 05 , this means a good permutation for the 2 . 7B model is in no way guaranteed that it will also yield good performance for the 175B model . Performant label orderings are not consistent across models In addition to training example ordering , we also explore label ordering for train - ing prompts . We use all patterns of the above - mentioned full permutations – six different label patterns . 4 We then compute the pairwise Spearman correlation across different models as described in the previous paragraph . As shown in Figure 5 , the behaviour of label orderings is once again seem - ingly random across different sizes of the same model . It is thus not possible to identify a label 4 NNPP , NPNP , NPPN , PNNP , PNPN , PPNN , where P / N respectively denotes positive / negative 51 . 6 85 . 2 SST - 2 Accuracy ( % ) 0 50 100 150 200 250 N u m b e r o f E x a m p l e s positivenegative orginal calibrated 55 60 65 70 75 80 85 SS T - 2 A cc u r a c y ( % ) Figure 6 : Left : Predicted SST - 2 label distribution un - der different prompts . Right : 2 - shot calibrated perfor - mance ( Zhao et al . , 2021 ) of all possible permutations on GPT2 - XL ( 1 . 5B ) . ordering that is performant across different models . Degenerate behaviour of bad prompts We per - form error analysis across performant and non - performant prompts and observe that the majority of failing prompts suffer from highly unbalanced predicted label distributions ( Figure 6 , left ) . An in - tuitive way to address this would be by calibrating the output distribution , along the lines of Zhao et al . ( 2021 ) . However , we ﬁnd that although calibration leads to much higher performance , the variance remains high ( Figure 6 , right ) . 3 Methodology The previous section demonstrates that prompt or - der can have a substantial effect on performance , with some orderings of the same prompts for the same model providing random performance , and other “better” orderings providing performance competitive with supervised approaches . This sug - gests that there could be various ways of selecting prompt orders to achieve better performance , but the challenge is to do so automatically and without the need for additional labels ( e . g . , a development set ) . Hence , in this section , we explore the question of : “How can we automatically generate a ‘prob - ing set’ to ﬁnd performant prompt orderings” ? We approach this by : ( i ) for a randomly - selected set of training samples , we use every possible ordering permutation of this set as candidates ; ( ii ) construct - ing a probing set by querying the language model using all candidate prompts as context ; and ( iii ) use this probing set to identify the best ordering by ranking them using a probing metric . 3 . 1 Sampling from the Language Model to Construct a Probing Set We propose a simple methodology to automati - cally construct a “probing set” , by directly sam - pling from the language model itself . This ap - proach makes it possible to generate probing sets automatically , without access to any additional data . Concretely , given a set of training samples S = { ( x i , y i ) } , i = 1 , · · · , n , where x i and y i denote the sentence and label of the i th training sample . We then deﬁne a transformation T , map - ping each sample into natural language space , such that t i = T ( x i , y i ) . t i is therefore a text sequence of the i th training sample using the template deﬁned by T . In this work , we use a simple transformation function T such that T ( x i , y i ) = input : x i type : y i . This transforms each sample into a standard for - mat sentence , which linearises each element in the set into natural language space deﬁned as S (cid:48) = { t i } , i = 1 , · · · , n . We then deﬁne a full permutation function group of n training samples , F = { f m } , m = 1 , · · · , n ! , where each function f m takes S (cid:48) as input and out - puts c m : the concatenation of a unique permutation . In our case , sampling four training samples at ran - dom gives up to 24 possible ordering permutations of the transformed samples . For each prompt candidate c m , we then sam - ple from the language model to obtain the probing sequence g m ∼ P ( · | c m ; θ ) , where θ denotes the parameters of the pretrained language model . We stop decoding from the language model upon gen - erating the special end - of - sentence token deﬁned by a template , or reach the generation length limit . Our probing set construction method is illustrated in Figure 7 , where the objective is to generate a probing set that shares a similar distribution to the training samples . We run this sampling process for all possible prompt ordering permutations and extract prob - ing samples from them ( T − 1 ( g ) ) . Then gather extracted samples together to form the probing set D = T − 1 ( g 1 ) ⊕ . . . ⊕T − 1 ( g n ! ) . Although the prob - ing set contains predicted label for each sentence , there is no guarantee on the validity of these labels . Therefore , we discard them from the probing set as we are only interested in sampling probes from the language model corresponding to the input distri - bution . 3 . 2 Probing Metrics Once we have constructed a probing set for a given set of samples , we can now use that probing set to identify the best possible prompt ordering for that particular sample set . Here , we explore two (cid:36)(cid:86)(cid:86)(cid:88)(cid:80)(cid:83)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20)(cid:29)(cid:3)(cid:51)(cid:72)(cid:85)(cid:80)(cid:88)(cid:87)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:44)(cid:81)(cid:89)(cid:68)(cid:85)(cid:76)(cid:68)(cid:81)(cid:70)(cid:72) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:51)(cid:47)(cid:48) (cid:42)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:49) (cid:11)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:29)(cid:3)(cid:12)(cid:3)(cid:81)(cid:76)(cid:70)(cid:72)(cid:3)(cid:80)(cid:82)(cid:89)(cid:76)(cid:72)(cid:54)(cid:72)(cid:81)(cid:87)(cid:76)(cid:80)(cid:72)(cid:81)(cid:87)(cid:29)(cid:3)(cid:83)(cid:82)(cid:86)(cid:76)(cid:87)(cid:76)(cid:89)(cid:72) (cid:44)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:76)(cid:81)(cid:16)(cid:70)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)(cid:3)(cid:79)(cid:72)(cid:68)(cid:85)(cid:81)(cid:76)(cid:81)(cid:74)(cid:3)(cid:86)(cid:72)(cid:87)(cid:87)(cid:76)(cid:81)(cid:74)(cid:15)(cid:3)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20)(cid:3)(cid:32)(cid:3)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:21)(cid:3)(cid:32)(cid:3)(cid:17)(cid:17)(cid:17)(cid:3)(cid:32)(cid:83)(cid:85)(cid:72)(cid:71)(cid:76)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:21)(cid:23) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) (cid:171) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:22) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:21) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:20) (cid:171) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:23)(cid:3)(cid:11)(cid:51)(cid:85)(cid:82)(cid:80)(cid:83)(cid:87)(cid:12) (cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:29)(cid:3)(cid:75)(cid:68)(cid:86)(cid:3)(cid:68)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:72)(cid:72)(cid:83)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:81)(cid:87)(cid:82)(cid:3)(cid:92)(cid:82)(cid:88)(cid:85)(cid:3)(cid:70)(cid:82)(cid:81)(cid:86)(cid:70)(cid:76)(cid:82)(cid:88)(cid:86)(cid:81)(cid:72)(cid:86)(cid:86)(cid:54)(cid:72)(cid:81)(cid:87)(cid:76)(cid:80)(cid:72)(cid:81)(cid:87)(cid:29)(cid:3)(cid:83)(cid:82)(cid:86)(cid:76)(cid:87)(cid:76)(cid:89)(cid:72) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:3)(cid:23)(cid:3)(cid:11)(cid:86)(cid:72)(cid:81)(cid:87)(cid:72)(cid:81)(cid:70)(cid:72)(cid:15)(cid:3)(cid:79)(cid:68)(cid:69)(cid:72)(cid:79)(cid:12) (cid:11)(cid:75)(cid:68)(cid:86)(cid:3)(cid:68)(cid:3)(cid:90)(cid:68)(cid:92)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:72)(cid:72)(cid:83)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:81)(cid:87)(cid:82)(cid:3)(cid:92)(cid:82)(cid:88)(cid:85)(cid:3)(cid:70)(cid:82)(cid:81)(cid:86)(cid:70)(cid:76)(cid:82)(cid:88)(cid:86)(cid:81)(cid:72)(cid:86)(cid:86)(cid:15)(cid:3)(cid:20)(cid:12) (cid:42)(cid:72)(cid:81)(cid:72)(cid:85)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:20) (cid:11)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:29)(cid:3)(cid:12)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:72)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:86)(cid:3)(cid:88)(cid:81)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:68)(cid:79)(cid:79)(cid:92)(cid:3)(cid:83)(cid:68)(cid:81)(cid:81)(cid:72)(cid:71)(cid:3)(cid:3)(cid:3)(cid:54)(cid:72)(cid:81)(cid:87)(cid:76)(cid:80)(cid:72)(cid:81)(cid:87)(cid:29)(cid:3)(cid:81)(cid:72)(cid:74)(cid:68)(cid:87)(cid:76)(cid:89)(cid:72)(cid:53)(cid:72)(cid:89)(cid:76)(cid:72)(cid:90)(cid:29)(cid:3)(cid:73)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:86)(cid:3)(cid:80)(cid:88)(cid:79)(cid:87)(cid:76)(cid:83)(cid:79)(cid:72)(cid:3)(cid:72)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:86)(cid:54)(cid:72)(cid:81)(cid:87)(cid:76)(cid:80)(cid:72)(cid:81)(cid:87)(cid:29)(cid:3)(cid:83)(cid:82)(cid:86)(cid:76)(cid:87)(cid:76)(cid:89)(cid:72) (cid:51)(cid:85)(cid:82)(cid:69)(cid:76)(cid:81)(cid:74)(cid:3)(cid:54)(cid:72)(cid:87)(cid:11)(cid:86)(cid:72)(cid:81)(cid:87)(cid:72)(cid:81)(cid:70)(cid:72)(cid:15)(cid:3)(cid:79)(cid:68)(cid:69)(cid:72)(cid:79)(cid:12) (cid:11)(cid:87)(cid:75)(cid:72)(cid:3)(cid:72)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:76)(cid:86)(cid:3)(cid:88)(cid:81)(cid:76)(cid:89)(cid:72)(cid:85)(cid:86)(cid:68)(cid:79)(cid:79)(cid:92)(cid:3)(cid:83)(cid:68)(cid:81)(cid:81)(cid:72)(cid:71)(cid:15)(cid:3)(cid:19)(cid:12)(cid:11)(cid:73)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:86)(cid:3)(cid:80)(cid:88)(cid:79)(cid:87)(cid:76)(cid:83)(cid:79)(cid:72)(cid:3)(cid:72)(cid:81)(cid:71)(cid:76)(cid:81)(cid:74)(cid:86)(cid:15)(cid:3)(cid:20)(cid:12) (cid:171) (cid:11)(cid:81)(cid:76)(cid:70)(cid:72)(cid:3)(cid:80)(cid:82)(cid:89)(cid:76)(cid:72)(cid:15)(cid:3)(cid:20)(cid:12) (cid:55)(cid:85)(cid:68)(cid:76)(cid:81)(cid:23) Figure 7 : Our probing set construction method , showing the various possible ordering permutations of the ran - domly selected training samples , the resulting generation for each permutation , and the concatenation of each into a probing set . Note that we discard the generated labels , as there is no guarantee that these generated labels are correct . methods for selecting the best ordering : Global Entropy ( GlobalE ) , and Local Entropy ( LocalE ) . Global Entropy ( GlobalE ) The motivation be - hind GlobalE is to identify prompts of speciﬁc sam - ple orderings that avoid the issue of extremely un - balanced predictions ( as we have previously es - tablished it as key problem for non - performant prompts ) . We compute the predicted label ˆ y i for data point ( x (cid:48) i , y (cid:48) i ) under context c m as follows : ˆ y i , m = argmax v ∈ V P ( v | c m ⊕ T ( x (cid:48) i ) ; θ ) ( 1 ) For each label v ∈ V ( where V denotes the target label set ) , we compute the label probability over the probing set as : p vm = (cid:80) i 1 { ˆ y i , m = v } | D | ( 2 ) We then use the predicted category label entropy as the GlobalE score for c m as follows : GlobalE m = (cid:88) v ∈ V − p vm log p vm ( 3 ) Local Entropy ( LocalE ) The motivation behind LocalE is that if a model is overly conﬁdent for all probing inputs , then it is likely that the model is not behaving as desired . At the very least , it is poorly calibrated , which could also be an indication of a poor capability to appropriately differentiate be - tween classes . Similar to the GlobalE computation , we calculate the prediction probability of a data point ( x (cid:48) i , y (cid:48) i ) over the target labels v ∈ V under context c m , as follows : p vi , m = P ( x (cid:48) i , y (cid:48) i ) ∼ D ( v | c m ⊕ T ( x (cid:48) i ) ; θ ) , v ∈ V ( 4 ) We then calculate the average prediction entropy per data point as the LocalE score : LocalE m = (cid:80) i (cid:80) v ∈ V − p vi , m log p vi , m | D | ( 5 ) As we now have a way to score each prompt order - ing , based on its effect against the probing set , we can rank each prompt ordering by performance as measured by GlobalE or LocalE respectively . 4 Experimental Setup We use four different sizes of GPT - 2 ( Radford et al . , 2019 ) ( with 0 . 1B , 0 . 3B , 0 . 8B , and 1 . 5B parame - teers ) and two sizes of GPT - 3 ( Brown et al . , 2020 ) ( with 2 . 7B , and 175B parameters ) . Due to limited context window size ( up to 1024 word - pieces for the GPT - 2 series of models ) , we use a 4 - shot setting for all datasets except AGNews and DBPedia . Our experiments are based on the open - source check - points of GPT - 2 models and access to the OpenAI GPT - 3 API . 5 For probing set generation , we restrict the maximum generation length to 128 . We also use sampling with a temperature , t , of 2 , and we also make use of block n - gram repetitions ( Paulus et al . , 2018 ) to encourage diverse generation . We use 24 different permutations for each set of randomly selected training samples and use 5 different sets ( except for GPT - 3 with 175B parame - ters , where we only do two sets with 12 different permutation due to the high monetary cost ) for each experiment , giving a total of 120 runs . We report the mean and standard deviation of the correspond - ing evaluation metric over 5 different sets . For performant prompt selection , we rank candi - date prompts using the LocalE and GlobalE prob - 5 https : / / openai . com / api / SST - 2 SST - 5 DBPedia MR CR MPQA Subj TREC AGNews RTE CB Majority 50 . 9 23 . 1 9 . 4 50 . 0 50 . 0 50 . 0 50 . 0 18 . 8 25 . 0 52 . 7 51 . 8 Finetuning ( Full ) 95 . 0 58 . 7 99 . 3 90 . 8 89 . 4 87 . 8 97 . 0 97 . 4 94 . 7 80 . 9 90 . 5 GPT - 2 0 . 1B 58 . 9 7 . 8 29 . 0 4 . 9 44 . 9 9 . 7 58 . 6 7 . 6 58 . 4 6 . 4 68 . 9 7 . 1 52 . 1 0 . 7 49 . 2 4 . 7 50 . 8 11 . 9 49 . 7 2 . 7 50 . 1 1 . 0 LocalE 65 . 2 3 . 9 34 . 4 3 . 4 53 . 3 4 . 9 66 . 0 6 . 3 65 . 0 3 . 4 72 . 5 6 . 0 52 . 9 1 . 3 48 . 0 3 . 9 61 . 0 5 . 9 53 . 0 3 . 3 49 . 9 1 . 6 GlobalE 63 . 8 5 . 8 35 . 8 2 . 0 56 . 1 4 . 3 66 . 4 5 . 8 64 . 8 2 . 7 73 . 5 4 . 5 53 . 0 1 . 3 46 . 1 3 . 7 62 . 1 5 . 7 53 . 0 3 . 0 50 . 3 1 . 6 Oracle 73 . 5 1 . 7 38 . 2 4 . 0 60 . 5 4 . 2 74 . 3 4 . 9 70 . 8 4 . 4 81 . 3 2 . 5 55 . 2 1 . 7 58 . 1 4 . 3 70 . 3 2 . 8 56 . 8 2 . 0 52 . 1 1 . 3 GPT - 2 0 . 3B 61 . 0 13 . 2 25 . 9 5 . 9 51 . 7 7 . 0 54 . 2 7 . 8 56 . 7 9 . 4 54 . 5 8 . 8 54 . 4 7 . 9 52 . 6 4 . 9 47 . 7 10 . 6 48 . 8 2 . 6 50 . 2 5 . 3 LocalE 75 . 3 4 . 6 31 . 0 3 . 4 47 . 1 3 . 7 65 . 2 6 . 6 70 . 9 6 . 3 67 . 6 7 . 2 66 . 7 9 . 3 53 . 0 3 . 9 51 . 2 7 . 3 51 . 8 1 . 0 47 . 1 4 . 2 GlobalE 78 . 7 5 . 2 31 . 7 5 . 2 58 . 3 5 . 4 67 . 0 5 . 9 70 . 7 6 . 7 68 . 3 6 . 9 65 . 8 10 . 1 53 . 3 4 . 6 59 . 6 7 . 2 51 . 1 1 . 9 50 . 3 3 . 7 Oracle 85 . 5 4 . 3 40 . 5 6 . 3 65 . 2 7 . 6 74 . 7 6 . 1 80 . 4 5 . 4 77 . 3 2 . 3 79 . 4 2 . 4 63 . 3 2 . 9 68 . 4 8 . 0 53 . 9 1 . 3 62 . 5 7 . 4 GPT - 2 0 . 8B 74 . 5 10 . 3 34 . 7 8 . 2 55 . 0 12 . 5 64 . 6 13 . 1 70 . 9 12 . 7 65 . 5 8 . 7 56 . 4 9 . 1 56 . 5 2 . 7 62 . 2 11 . 6 53 . 2 2 . 0 38 . 8 8 . 5 LocalE 81 . 1 5 . 5 40 . 3 4 . 7 56 . 7 7 . 5 82 . 6 4 . 2 85 . 4 3 . 8 73 . 6 4 . 8 70 . 4 4 . 2 56 . 2 1 . 7 62 . 7 8 . 1 53 . 3 1 . 6 38 . 4 5 . 2 GlobalE 84 . 8 4 . 1 46 . 9 1 . 1 67 . 7 3 . 6 84 . 3 2 . 9 86 . 7 2 . 5 75 . 8 3 . 1 68 . 6 6 . 5 57 . 2 2 . 3 70 . 7 3 . 6 53 . 5 1 . 5 41 . 2 4 . 5 Oracle 88 . 9 1 . 8 48 . 4 0 . 7 72 . 3 3 . 3 87 . 5 1 . 1 89 . 9 0 . 9 80 . 3 4 . 9 76 . 6 4 . 1 62 . 1 1 . 5 78 . 1 1 . 3 57 . 3 1 . 0 53 . 2 5 . 3 GPT - 2 1 . 5B 66 . 8 10 . 8 41 . 7 6 . 7 82 . 6 2 . 5 59 . 1 11 . 9 56 . 9 9 . 0 73 . 9 8 . 6 59 . 7 10 . 4 53 . 1 3 . 3 77 . 6 7 . 3 55 . 0 1 . 4 53 . 8 4 . 7 LocalE 76 . 7 8 . 2 45 . 1 3 . 1 83 . 8 1 . 7 78 . 1 5 . 6 71 . 8 8 . 0 78 . 5 3 . 6 69 . 7 5 . 8 53 . 6 3 . 1 79 . 3 3 . 7 56 . 8 1 . 1 52 . 6 3 . 9 GlobalE 81 . 8 3 . 9 43 . 5 4 . 5 83 . 9 1 . 8 77 . 9 5 . 7 73 . 4 6 . 0 81 . 4 2 . 1 70 . 9 6 . 0 55 . 5 3 . 0 83 . 9 1 . 2 56 . 3 1 . 2 55 . 1 4 . 6 Oracle 86 . 1 1 . 5 50 . 9 1 . 0 87 . 3 1 . 5 84 . 0 2 . 7 80 . 3 3 . 3 85 . 1 1 . 4 79 . 9 5 . 7 59 . 0 2 . 3 86 . 1 0 . 7 58 . 2 0 . 6 63 . 9 4 . 3 GPT - 3 2 . 7B 78 . 0 10 . 7 35 . 3 6 . 9 81 . 1 1 . 8 68 . 0 12 . 9 76 . 8 11 . 7 66 . 5 10 . 3 49 . 1 2 . 9 55 . 3 4 . 4 72 . 9 4 . 8 48 . 6 1 . 9 50 . 4 0 . 7 LocalE 81 . 0 6 . 0 42 . 3 4 . 7 80 . 3 1 . 7 75 . 6 4 . 1 79 . 0 5 . 5 72 . 5 5 . 8 54 . 2 4 . 2 54 . 0 2 . 6 72 . 3 4 . 6 50 . 4 1 . 9 50 . 5 0 . 8 GlobalE 80 . 2 4 . 2 43 . 2 4 . 3 81 . 2 0 . 9 76 . 1 3 . 8 80 . 3 3 . 4 73 . 0 4 . 3 54 . 3 4 . 0 56 . 7 2 . 0 78 . 1 1 . 9 51 . 3 1 . 8 51 . 2 0 . 8 Oracle 89 . 8 0 . 7 48 . 0 1 . 1 85 . 4 1 . 6 87 . 4 0 . 9 90 . 1 0 . 7 80 . 9 1 . 4 60 . 3 10 . 3 62 . 8 4 . 2 81 . 3 2 . 9 53 . 4 3 . 1 52 . 5 1 . 4 GPT - 3 175B 93 . 9 0 . 6 54 . 4 2 . 5 95 . 4 0 . 9 94 . 6 0 . 7 91 . 0 1 . 0 83 . 2 1 . 5 71 . 2 7 . 3 72 . 1 2 . 7 85 . 1 1 . 7 70 . 8 2 . 8 75 . 1 5 . 1 LocalE 93 . 8 0 . 5 56 . 0 1 . 7 95 . 5 0 . 9 94 . 5 0 . 7 91 . 3 0 . 5 83 . 3 1 . 7 75 . 0 4 . 6 71 . 8 3 . 2 85 . 9 0 . 7 71 . 9 1 . 4 74 . 6 4 . 2 GlobalE 93 . 9 0 . 6 53 . 2 2 . 1 95 . 7 0 . 7 94 . 6 0 . 2 91 . 7 0 . 4 82 . 0 0 . 8 76 . 3 3 . 5 73 . 6 2 . 5 85 . 7 1 . 0 71 . 8 1 . 9 79 . 9 3 . 3 Oracle 94 . 7 0 . 2 58 . 2 96 . 7 0 . 2 95 . 5 0 . 2 92 . 6 0 . 4 85 . 5 0 . 8 81 . 1 4 . 9 77 . 0 1 . 2 87 . 7 0 . 6 74 . 7 0 . 4 83 . 0 0 . 9 Table 2 : Our main results on subset of the validation set . To ﬁt the data within the GPT - 2 model context win - dow size , we use 1 - shot for DBPedia , 2 - shot for AGNews , 4 - shot for other datasets . All the baseline results are calculated based on 5 different random seeds over 24 train context permutations . LocalE and GlobalE results are calculated based on the top 4 context permutations using our proposed approach . For the GPT - 3 175B , we only use 2 seeds with 12 different permutations due to a limited computation budget . ing metrics over the automatically generated prob - ing set . We then select top k samples ranked by highest entropy values , where k = 4 in our exper - iments , of the available 24 permutations as per - formant prompts . Finally , we use these perfor - mant prompts to evaluate performance on various datasets and demonstrate both better performance and reduced variance . We also provide results for a majority baseline , which always predicts the ma - jority label in the dataset , as a lower - bound of per - formance . We also provide an oracle to show the upper - bound of performance by selecting the top four performant orderings based on prompt perfor - mance on the validation set . 4 . 1 Evaluation Datasets Similar to previous work ( Gao et al . , 2020 ; Zhao et al . , 2021 ) , we use eleven text classiﬁcation datasets ranging from sentiment classiﬁcation to textual entailment . Further details of the datasets are provided in the Appendix . For evaluation , we sub - sample 256 samples of the validation sets for all datasets to control for the GPT - 3 inference costs as it requires the usage of a monetary paid - for API . 5 Results We report experimental results in Table 2 and ob - serve consistent improvements for both LocalE and GlobalE across all tasks . Entropy - based probing is effective for perfor - mant prompt selection regardless of model size We ﬁnd that GlobalE achieves , on average , a 13 % relative improvement across the eleven dif - ferent sentence classiﬁcation tasks in comparison to prompts that do not make use of probing . LocalE provides results slightly inferior to GlobalE , with an average 9 . 6 % relative improvement over the baseline model . Our selected performant prompts also demonstrate considerably lower variance than using all candidate prompts . Ranking using Entropy - based probing is robust In Figure 8 , we visualise the average performance when varying K for the top K prompt selection . K = 24 corresponds to using all sampled prompt orders , which is equivalent to the baseline model performance in Table 2 . We can observe that the slope of curves are negative for all datasets , suggest - ing that our method can rank performant prompts effectively . Though K = 1 can provide good per - formance for most cases , in our experiments , we use K = 4 as preliminary experiments indicated that it yielded stable performance across datasets . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 TopK 30 40 50 60 70 80 90 A cc u r a c y ( % ) SST - 2 SST - 5 DBPediaMRCRMPQASubjTRECAGNewsRTECB Figure 8 : Average performance of different Top K per - mutation selection on GPT2 - Large ( 0 . 8B ) Entropy - based probing is effective across tem - plates We evaluate Entropy - based probing for four different templates similar to Gao et al . ( 2020 ) and Zhao et al . ( 2021 ) ( Table 4 ) for the SST - 2 dataset . Experimental results in Table 3 indicate that Entropy - based probing is valid for different templates . We also observe that the randomness across different templates is similar to Section 2 . These ﬁndings suggest that Entropy - based probing is not sensitive to speciﬁc templates , as it consis - tently provides improvements for all cases . Performant permutation selection is a safe op - tion for In - context Learning We ﬁnd that for models that suffer from high prompt variance , our prompt selection process can show large improve - ments – up to 30 % relative improvement . Fur - thermore , for tasks with low initial prompt perfor - mance variance , our method does not negatively im - pact performance . Our prompt selection provides marginal improvement at worse and on average a 13 % relative improvement in the most cases . Sentence - pair tasks remain challenging for smaller - sized models even with performant per - mutation selection For the CB and RTE datasets , Template 1 Template 2 Template 3 Template 4 GPT - 2 0 . 1B 58 . 9 7 . 8 57 . 5 6 . 8 58 . 1 7 . 4 56 . 6 6 . 6 LocalE 65 . 2 3 . 9 60 . 7 4 . 6 65 . 4 4 . 8 61 . 0 4 . 7 GlobalE 63 . 8 5 . 8 59 . 0 2 . 9 64 . 3 4 . 8 63 . 5 4 . 8 GPT - 2 0 . 3B 61 . 0 13 . 2 63 . 9 11 . 3 68 . 3 11 . 8 59 . 2 6 . 4 LocalE 75 . 3 4 . 6 70 . 0 7 . 2 80 . 2 4 . 2 62 . 2 3 . 4 GlobalE 78 . 7 5 . 2 73 . 3 4 . 5 81 . 3 4 . 1 62 . 8 4 . 3 GPT - 2 0 . 8B 74 . 5 10 . 3 66 . 6 10 . 6 70 . 3 10 . 5 63 . 7 8 . 9 LocalE 81 . 1 5 . 5 80 . 0 5 . 6 73 . 7 6 . 2 71 . 3 4 . 5 GlobalE 84 . 8 4 . 1 80 . 9 3 . 6 79 . 8 3 . 9 70 . 7 5 . 3 GPT - 2 1 . 5B 66 . 8 10 . 8 80 . 4 7 . 6 54 . 5 7 . 9 69 . 1 10 . 5 LocalE 76 . 7 8 . 2 83 . 1 3 . 6 66 . 9 7 . 5 72 . 7 5 . 5 GlobalE 81 . 8 3 . 9 83 . 4 3 . 2 67 . 2 6 . 1 74 . 2 5 . 3 Table 3 : Prompt selection performance of different tem - plates on SST - 2 ID Template Label Mapping 1 Review : { Sentence } Sentiment : { Label } positive / negative 2 Input : { Sentence } Prediction : { Label } positive / negative 3 Review : { Sentence } Sentiment : { Label } good / bad 4 { Sentence } It was { Label } good / bad Table 4 : Different Templates for SST - 2 the performance of GPT - 2 models is not signif - icantly different from that of a random baseline . Despite this , we ﬁnd that our method for identify - ing performant prompts can still provide minimal performance gains , although these are still within the levels of a random guess or majority vote . One reason for this could be that , for these particular sizes of models on these tasks , no good prompt exists . As such , optimising the prompt is not par - ticularly effective in this setting . This is further supported by the observation that prompt selection can considerably improve performance on both CB and RTE at larger model sizes ( particularly so for the GPT - 3 175B parameter model ) . In fact , we ﬁnd that prompt selection using GlobalE improves performance by 4 . 9 % for GPT - 3 175B on CB . This indicates that our method is widely applicable to all model sizes , and across all tasks , as long as they already possess some existing classiﬁcation ability that can be improved through prompt design . Entropy - based probing outperforms using sub - sets of the training data for tuning If one was not to rely on generation , an alternative approach to prompt selection could be to split the ( limited ) training data to form a validation set . To compare GPT - 2 0 . 1B GPT - 2 0 . 3B GPT - 2 0 . 8B GPT - 2 1 . 5B Baseline 58 . 9 7 . 8 61 . 0 13 . 2 74 . 5 10 . 3 66 . 8 10 . 8 LocalE 65 . 2 3 . 9 75 . 3 4 . 6 81 . 1 5 . 5 76 . 7 8 . 2 GlobalE 63 . 8 5 . 8 78 . 7 5 . 2 84 . 8 4 . 1 81 . 8 3 . 9 Split Training Set 62 . 8 5 . 3 64 . 2 6 . 1 75 . 1 6 . 8 71 . 4 7 . 8 Table 5 : Comparing our method with splitting the train - ing set into train and development for SST - 2 . against this approach , we split the 4 - shot training samples ( same setting as in Table 2 ) in half . We then select the top four performing prompts using validation set performance . As can be seen in Ta - ble 5 , this approach consistently outperforms the baseline . However , both Entropy - based probing methods consistently provides better performance across all model sizes . 6 Related Work Uniﬁed Interface Design for NLP Most previ - ous work focuses on shared - parameters models , pretrain on some tasks , then ﬁne - tune for different tasks , e . g . ELMo ( Peters et al . , 2018 ) , BERT ( De - vlin et al . , 2019 ) , etc . Eventually , leading to multi - ple task - speciﬁc models . There has for some time been attempts to design a uniﬁed interface for NLP tasks ( Kumar et al . , 2016 ; Raffel et al . , 2020 ) . In parallel with these works , GPT - 2 ( Radford et al . , 2019 ) shows that appending trigger tokens ( e . g . “TL ; DR” ) at the end of language model input can cause language models to behave like summari - sation models . The zero - shot capability of lan - guage models shows the potential to unify NLP tasks into a language modelling framework where ﬁne - tuning is not necessary to achieve good perfor - mance . Furthermore , GPT - 3 ( Brown et al . , 2020 ) shows that task - agnostic , few - shot performance can be improved by scaling up language models . It can sometimes even become competitive with prior state - of - the - art ﬁne - tuning approaches . Prompt Design for PLMs The core challenge of prompt design is to convert training data ( if it exists ) into a text sequence . Most work on prompt design focuses on how to make prompts more com - patible with language models . Petroni et al . ( 2019 ) uses human effort to design natural language sen - tences and then perform token prediction given the input context . However , hand - crafted templates require signiﬁcant human effort and is likely to end up with sub - optimal performance . Recent work has explored automatic template construction : Schick and Schütze ( 2020 ) uses cloze - style tasks to con - struct templates , Gao et al . ( 2020 ) uses an external language model to generate templates , and Shin et al . ( 2020 ) uses gradient - guided search to ﬁnd templates that maximise performance . Jiang et al . ( 2020 ) uses a mining - based method to create multi - ple diverse templates automatically . Order Sensitivity of Prompt Design Gao et al . ( 2020 ) demonstrated that ﬁnetuning - based ap - proaches are not as order sensitive as In - context Learning . Making use of a standard - size training set , Liu et al . ( 2021 ) used nearest neighbour search to retrieve the most relevant training samples for a speciﬁc test sample . They were successful in retrieving relevant samples and concluded that af - ter retrieving them the order in which they are provided in the prompt has little to no effect on performance . While our study is fundamentally different from theirs in that we do not make use of a standard - size training set , we do come to the opposite conclusion . All previous work on prompt design focuses on the textual quality of the prompt and , to the best of our knowledge , none has studied order sensitivity in detail . True Few - shot Learning Perez et al . ( 2021 ) evaluated few - shot capability of LMs when a held - out validation set is not available . Experimental result suggested that previous work overestimate the few - shot ability of LMs in this ( true few - shot learning ) setting . Our work instead use the gen - erative nature of language models to construct a probing set without relying on held - out examples . We show that our probing method is better than relying on held out examples ( Figure 5 ) and thus enables true few - shot learning . 7 Conclusion We have shown that few - shot prompts suffer from order sensitivity , in that for the same prompt the order in which samples are provided can make the difference between state - of - the - art and random per - formance . In our analysis of the problem , we estab - lished that it is present across tasks , model sizes , prompt templates , samples , and number of training samples . To alleviate this problem , we introduced a novel probing method that exploits the generative nature of language models to construct an artiﬁcial development set . We were able to identity perfor - mant permutations using entropy - based statistics over this set , leading to an on average 13 % im - provement across eleven text classiﬁcation tasks . References Tom B Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , et al . 2020 . Language models are few - shot learners . arXiv preprint arXiv : 2005 . 14165 . Ido Dagan , Oren Glickman , and Bernardo Magnini . 2005 . The pascal recognising textual entailment challenge . In Machine Learning Challenges Work - shop , pages 177 – 190 . Springer . Joe Davison , Joshua Feldman , and Alexander M Rush . 2019 . Commonsense knowledge mining from pre - trained models . In Proceedings of the 2019 Con - ference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer - ence on Natural Language Processing ( EMNLP - IJCNLP ) , pages 1173 – 1178 . Marie - Catherine De Marneffe , Mandy Simons , and Ju - dith Tonhauser . 2019 . The commitmentbank : Inves - tigating projection in naturally occurring discourse . In proceedings of Sinn und Bedeutung , pages 107 – 124 . Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . Bert : Pre - training of deep bidirectional transformers for language under - standing . In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Tech - nologies , Volume 1 ( Long and Short Papers ) , pages 4171 – 4186 . Tianyu Gao , Adam Fisch , and Danqi Chen . 2020 . Making pre - trained language models better few - shot learners . arXiv preprint arXiv : 2012 . 15723 . Minqing Hu and Bing Liu . 2004 . Mining and summa - rizing customer reviews . In Proceedings of the tenth ACM SIGKDD international conference on Knowl - edge discovery and data mining , pages 168 – 177 . Zhengbao Jiang , Frank F Xu , Jun Araki , and Graham Neubig . 2020 . How can we know what language models know ? Transactions of the Association for Computational Linguistics , 8 : 423 – 438 . Ankit Kumar , Ozan Irsoy , Peter Ondruska , Mohit Iyyer , James Bradbury , Ishaan Gulrajani , Victor Zhong , Romain Paulus , and Richard Socher . 2016 . Ask me anything : Dynamic memory networks for natural language processing . In International conference on machine learning , pages 1378 – 1387 . PMLR . Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021 . What makes good in - context examples for gpt - 3 ? arXiv preprint arXiv : 2101 . 06804 . Yinhan Liu , Myle Ott , Naman Goyal , Jingfei Du , Man - dar Joshi , Danqi Chen , Omer Levy , Mike Lewis , Luke Zettlemoyer , and Veselin Stoyanov . 2019 . Roberta : A robustly optimized bert pretraining ap - proach . arXiv preprint arXiv : 1907 . 11692 . Bo Pang and Lillian Lee . 2004 . A sentimental educa - tion : Sentiment analysis using subjectivity summa - rization based on minimum cuts . In Proceedings of the 42nd Annual Meeting of the Association for Com - putational Linguistics ( ACL - 04 ) , pages 271 – 278 . Bo Pang and Lillian Lee . 2005 . Seeing stars : Exploit - ing class relationships for sentiment categorization with respect to rating scales . In Proceedings of the 43rd Annual Meeting of the Association for Compu - tational Linguistics ( ACL’05 ) , pages 115 – 124 . Romain Paulus , Caiming Xiong , and Richard Socher . 2018 . A deep reinforced model for abstractive sum - marization . In International Conference on Learn - ing Representations . Ethan Perez , Douwe Kiela , and Kyunghyun Cho . 2021 . True few - shot learning with language models . arXiv preprint arXiv : 2105 . 11447 . Matthew Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer . 2018 . Deep contextualized word repre - sentations . In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , Volume 1 ( Long Papers ) , pages 2227 – 2237 . Fabio Petroni , Patrick Lewis , Aleksandra Piktus , Tim Rocktäschel , Yuxiang Wu , Alexander H Miller , and Sebastian Riedel . 2020 . How context affects lan - guage models’ factual predictions . In Automated Knowledge Base Construction . Fabio Petroni , Tim Rocktäschel , Sebastian Riedel , Patrick Lewis , Anton Bakhtin , Yuxiang Wu , and Alexander Miller . 2019 . Language models as knowl - edge bases ? In Proceedings of the 2019 Confer - ence on Empirical Methods in Natural Language Processing and the 9th International Joint Confer - ence on Natural Language Processing ( EMNLP - IJCNLP ) , pages 2463 – 2473 , Hong Kong , China . As - sociation for Computational Linguistics . A . Radford , Jeffrey Wu , R . Child , David Luan , Dario Amodei , and Ilya Sutskever . 2019 . Language mod - els are unsupervised multitask learners . In OpenAI Blog . Colin Raffel , Noam Shazeer , Adam Roberts , Katherine Lee , Sharan Narang , Michael Matena , Yanqi Zhou , Wei Li , and Peter J Liu . 2020 . Exploring the lim - its of transfer learning with a uniﬁed text - to - text transformer . Journal of Machine Learning Research , 21 : 1 – 67 . Timo Schick and Hinrich Schütze . 2020 . It’s not just size that matters : Small language mod - els are also few - shot learners . arXiv preprint arXiv : 2009 . 07118 . Taylor Shin , Yasaman Razeghi , Robert L Logan IV , Eric Wallace , and Sameer Singh . 2020 . Autoprompt : Eliciting knowledge from language models with automatically generated prompts . arXiv preprint arXiv : 2010 . 15980 . Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D Manning , Andrew Y Ng , and Christopher Potts . 2013 . Recursive deep mod - els for semantic compositionality over a sentiment treebank . In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631 – 1642 . Ellen M Voorhees and Dawn M Tice . 2000 . Building a question answering test collection . In Proceedings of the 23rd annual international ACM SIGIR confer - ence on Research and development in information retrieval , pages 200 – 207 . Janyce Wiebe , Theresa Wilson , and Claire Cardie . 2005 . Annotating expressions of opinions and emo - tions in language . Language resources and evalua - tion , 39 ( 2 ) : 165 – 210 . Zhilin Yang , Zihang Dai , Yiming Yang , Jaime Car - bonell , Ruslan Salakhutdinov , and Quoc V Le . 2019 . Xlnet : Generalized autoregressive pretrain - ing for language understanding . arXiv preprint arXiv : 1906 . 08237 . Xiang Zhang , Junbo Zhao , and Yann Lecun . 2015 . Character - level convolutional networks for text clas - siﬁcation . Advances in Neural Information Process - ing Systems , 2015 : 649 – 657 . Tony Z Zhao , Eric Wallace , Shi Feng , Dan Klein , and Sameer Singh . 2021 . Calibrate before use : Im - proving few - shot performance of language models . arXiv preprint arXiv : 2102 . 09690 . Dataset Prompt Label Mapping SST - 2 Review : contains no wit , only labored gags Sentiment : negative positive / negative SST - 5 Review : apparently reassembled from the cutting - room ﬂoor of any given daytime soap . Sentiment : terrible terrible / bad / okay / good / great MR Review : lame sweet home leaves no southern stereotype unturned . Sentiment : negative negative / positive CR Review : bluetooth does not work on this phone . Sentiment : negative negative / positive MPQA Review : dangerous situation Sentiment : negative negative / positive Subj Input : too slow , too boring , and occasionally annoying . Type : subjective subjective / objective TREC Question : When did the neanderthal man live ? Type : number description / entity / expression / human / location / number AGNews input : Wall St . Bears Claw Back Into the Black ( Reuters ) . type : business world / sports / business / technology DBPedia input : CMC Aviation is a charter airline based in Nairobi Kenya . type : company company / school / artist / athlete / politics / transportation / building / nature / village / animal / plant / album / ﬁlm / book CB premise : It was a complex language . Not written down but handed down . One might say it was peeled down . hypothesis : the language was peeled down prediction : true true / false / neither RTE premise : No Weapons of Mass Destruction Found in Iraq Yet . hypothesis : Weapons of Mass Destruction Found in Iraq . prediction : False True / False Table 6 : Prompt template and label mapping for different tasks . Notation Description Examples x sentence nice movie y label positive T ( x ) template - based transformation without label Review : nice movie T ( x , y ) template - based transformation Review : nice movie Sentiment : positive T − 1 ( T ( x , y ) ) extract ( sentence , label ) pair from text sequence ( nice movie , positive ) Table 7 : Examples of transformation notations . Dataset # of Classes Avg . Len . Balanced SST - 2 ( Socher et al . , 2013 ) 2 12 . 4 Yes SST - 5 ( Socher et al . , 2013 ) 5 23 . 1 No MR ( Pang and Lee , 2005 ) 2 25 . 7 Yes CR ( Hu and Liu , 2004 ) 2 22 . 1 Yes MPQA ( Wiebe et al . , 2005 ) 2 3 . 9 Yes Subj ( Pang and Lee , 2004 ) 2 28 . 9 Yes TREC ( Voorhees and Tice , 2000 ) 6 11 . 6 No AGNews ( Zhang et al . , 2015 ) 4 53 . 8 Yes DBPedia ( Zhang et al . , 2015 ) 14 65 . 5 Yes CB ( De Marneffe et al . , 2019 ) 3 69 . 7 / 8 . 4 No RTE ( Dagan et al . , 2005 ) 2 55 . 3 / 11 . 9 Yes Table 8 : Statistics of evaluation datasets , average length is calculated based on GPT - 2 sentence - piece length . For sentence - pair tasks , we report each sen - tence’s average length separately . Dataset Synthetic data SST - 2 not sure where to even begin the only real ﬁlm on our watch lists no one will care because it is just one story SST - 5 not a bad documentary , but the story feels tacked on . one that i have never liked and was always too long to understand and not enjoyable in parts . This movie is the opposite of what it pretentious title implies . DBPedia Gweno Mott’s book : Gweno is a New Yorker cartoonist published by Little , Brown , 1995 / 2002 / 2013 . L . Ego Equestrians is North America’s ﬁrst dedicated equine show in Las Vegas . Graphed is a graph visualization package from the GraphViz project . MR a solid ﬁrst ﬁlm for the debut helmer . A good deal more of the material in his previous ﬁlms can be found here but this ﬁlm does not come across [ . . . ] it is so effective and engaging It feels more real And at some point , maybe it was about [ . . . ] CR It works just the same , i just prefer my iPhone 6 . the battery last so long for me it feels like ive already had my phone a year . works great with both phones MPQA this is really going nowhere why does it look so angry ? ? Excellent book and will get a good reputation Subj this will become apparent as it gets older . how about something more subtle to show this girl’s love ? a perfect summary of an episode where the entire series is one massive meta romp , with [ . . . ] TREC Whales can hold 4 gallons . Whaler can also be written as : What whale is named Whalerel ? To a certain degree , how do human eyes perceive colour ? From where does our moon orbit , in Earth’s Solar System ? AGNews Google buys for $ 11bn : A - Z and thesaurus online , music search ; photo service and TV site [ . . . ] Saudi - born billionaire takes $ 5 Billion Hit With Bankrupt . Saudi millionaire Sultan Al - Amoudi said [ . . . ] China’s ’Sesame’ takes over for South Korea in world TV race as US TV loses market dominance . [ . . . ] RTE Premise : The Tuareg are a nomadic people who live in the Sahara desert . Hypothesis : Tuareg are nomadic people who lived in the Sahara desert before the arrival of the Arabs . Premise : In the early 1940s , the United States and the Soviet Union were at war with Germany . Hypothesis : Germany was at war with the United States and Russia . Premise : Water is a precious commodity . Hypothesis : Water is not a precious commodity . CB Premise : In the back corner of Melissa’s classroom her father walked through the door and walked across the front . [ . . . ] Hypothesis : his curiosity was directed towards some , something other than Melissa Premise : Maggie took Gloria out for a drive to the nearby city limits of Fort Myers on Tuesday Hypothesis : he couldn’t bear looking down his nose at all the other houses Premise : There was one in Dallas . When it came out in New Jersey . And there were , [ . . . ] Hypothesis : I would never see that movie Table 9 : Artiﬁcial development set generated by GPT2 - XL ( 1 . 5B ) . We random select three examples per dataset . Long sentences are trimmed due to limited space .