83 Making Sense of the Unknown : How Managers Make Cyber Security Decisions BENJAMIN SHREEVE , University of Bristol , United Kingdom CATARINA GRALHA , NOVA LINCS , Universidade NOVA de Lisboa , Portugal AWAIS RASHID , University of Bristol , United Kingdom JOÃO ARAÚJO and MIGUEL GOULÃO , NOVA LINCS , Universidade NOVA de Lisboa , Portugal Managers rarely have deep knowledge of cyber security and yet are expected to make decisions with cyber security implications for software - based systems . We investigate the decision - making conversations of seven teams of senior managers from the same organisation as they complete the Decisions & Disruptions cyber security exercise . We use grounded theory to situate our analysis of their decision - making and help us explore how these complex socio - cognitive interactions occur . We have developed a goal - model ( using iStar 2 . 0 ) of the teams’ dialogue that illustrates what cyber security goals teams identify and how they operationalise their decisions to reach these goals . We complement this with our model of cyber security reasoning that describes how these teams make their decisions , showing how each team members’ experience , intuition , and understanding affects the team’s overall shared reasoning and decision - making . Our findings show how managers with little cyber security expertise are able to use logic and traditional risk management thinking to make cyber security decisions . Despite their lack of cyber security – specific training , they demonstrate reasoning that closely resembles the decision - making approaches espoused in cy - ber security – specific standards ( e . g . , NIST / ISO ) . Our work demonstrates how organisations and practitioners can enrich goal modelling to capture not only what security goals an organisation has ( and how they can operationalise them ) but also how and why these goals have been identified . Ultimately , non – cyber secu - rity experts can develop their cyber security model based on their current context ( and update it when new requirements appear or new incidents happen ) , whilst capturing their reasoning at every stage . CCS Concepts : • Social and professional topics → Management of computing and information sys - tems ; • Security and privacy → Social aspects of security and privacy ; • General and reference → Evaluation ; Additional Key Words and Phrases : Cyber security decision - making , cyber security risk analysis , goal modelling ACM Reference format : Benjamin Shreeve , Catarina Gralha , Awais Rashid , João Araújo , and Miguel Goulão . 2023 . Making Sense of the Unknown : How Managers Make Cyber Security Decisions . ACM Trans . Softw . Eng . Methodol . 32 , 4 , Article 83 ( May 2023 ) , 33 pages . https : / / doi . org / 10 . 1145 / 3548682 Authors’ addresses : B . Shreeve and A . Rashid , University of Bristol , United Kingdom ; emails : { ben . shreeve , awais . rashid } @ bristol . ac . uk ; C . Gralha , J . Araújo , and M . Goulão , NOVA LINCS , Universidade NOVA de Lisboa , Portugal ; emails : { catarina . gralha , joao . araujo , mgoul } @ fct . unl . pt . This work is licensed under a Creative Commons Attribution International 4 . 0 License . © 2023 Copyright held by the owner / author ( s ) . 1049 - 331X / 2023 / 05 - ART83 https : / / doi . org / 10 . 1145 / 3548682 ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . Corrected Version of Record . V . 1 . 1 . Published October 12 , 2023 . 83 : 2 B . Shreeve et al . 1 INTRODUCTION Managers are key stakeholders when it comes to identifying requirements for systems and often have the final say on strategic decisions , as well as being budgetary gatekeepers . They are usually focused on the operational goals of systems and frequently lack in - depth cyber security knowledge or expertise ( nor should they be expected to have this as it is not part of their role ) . These decisions often have a direct impact in organizational software - based systems , in particular in the way that requirements are identified and prioritised . The confluence of these factors has the potential to impact the prioritisation / de - prioritisation of cyber security ( and other quality properties ) . In this article , we set out to understand what “goals” managers have with regards to cyber security and how these are operationalised as they make decisions , as well as exploring what their reasoning models are that underpin these decisions : Research question : How do managers ( with limited cyber security training ) go about making cyber security decisions ? We address our research question through an in - depth analysis of decision - making by 31 se - nior managers in seven teams playing a tabletop cyber security game , Decisions & Disruptions ( D - D ) , which was designed to study security decision - making [ 12 ] . The organization that we fo - cus on operates in a large - scale high - risk environment . Their decision - making experiences and behaviours are therefore heavily affected by their experiences making decisions within a safety - critical environment . Their decision - making approaches and priorities may well differ from other organizations in less safety - critical environments by often following more traditional , structured , decision , and risk - assessment processes rather than agile ones . We use iStar 2 . 0 goal modelling and develop a model of cyber security reasoning , both emerging from a grounded theory analysis of the discussions that teams have during the game to explore the teams’ decisions and interactions . The use of the iStar 2 . 0 goal modelling is borrowed from re - quirements engineering and helps us to capture what cyber security goals teams identify and how these can be operationalised . Our model of cyber security reasoning then provides insight into how and why teams identify these goals and particular operationalisations—it highlights how the reasoning of the team is developed through interactions amongst individuals as they share their ex - periences and intuition . The iStar 2 . 0 goal model serves to help managers make security decisions , highlighting possible options , whilst the model of cyber security reasoning helps practitioners and academics understand the information and processes involved in the underlying decision - making . The game has been designed to be played with a wide range of stakeholders ( both with and without cyber security experience ) . It has been validated in consultation with a range of cyber security practitioners [ 12 ] . Decisions & Disruptions ( D - D ) challenges teams to act as cyber security advisers to a fictional hydro - electric company . During four rounds of gameplay , teams have to identify which cyber security related investments they should make . They are constrained by a finite budget and a range of valid investments from which to choose . At the end of each round , they suffer predetermined attacks that reflect the investment choices they have made . Our work complements the earlier work by Frey et al . [ 12 ] ( who devised and tested D - D ) by exploring the decision - making of a larger subset of managers from industry ( 31 vs . 4 ) and with a specific focus on decision - making using grounded theory . Grounding our analysis in the teams’ di - alogue helps us to understand how managers make cyber security decisions with limited technical know - how , capturing how reasoning is developed by the teams , in a collaborative way , enabling them to operationalise organisational cyber security goals . It builds on the work by Shreeve et al . [ 33 ] that explored risk thinking patterns of 12 mixed teams from a range of backgrounds using lin - guistic theory . In this article , we analyse the decision - making within a larger subset of managers all from the same organisation . This is important , because all of the participants in our sample are likely to be influenced by the same organisational culture and approaches to decision - making , ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 3 Fig . 1 . Layout of Decisions & Disruptions board . they are also more familiar with working with each other providing a better reflection of decision - making in established teams see Figure 1 . We are also able to compare the performance of the teams in our sample with those of other professionals reported in Shreeve et al . [ 34 ] . Our participants are all part of the senior European management team for a major industrial organisation with over 100 , 000 employees worldwide and , as such , have extensive experience mak - ing strategic decisions . The majority of participants had little to no prior cyber security or general computer science knowledge . We are particularly interested in the operationalisation of cyber security decisions , that is , the process that begins with the identification of a situation that needs to be addressed / responded to all the way through to the actual moment that the decision is made and action taken . Little is currently understood about how such managers go about making these decisions when they rarely have technical or cyber security expertise . Given that managers are often working with a team , how do they collaborate to make decisions ? Does a lack of technical expertise enable managers to employ different decision - making approaches ? Our article makes the following key contributions : • Enriched goal modelling : We demonstrate how goal modelling can be supplemented with insight into the underlying socio - cognitive processes of decision - makers . This helps provide a greater insight to stakeholder perspectives . This combination enables organisations to visu - alise how the goal - driven approach typical to decision - making in organisations is related to the socio - cognitive interactions that occur as teams collaborate to address wicked prob - lems . The enriched goal modelling provides a new way to consider understanding security goals and operationalisations ( and the underlying reasons behind these ) . We demonstrate this through the development of an iStar 2 . 0 goal model and our model of cyber security rea - soning capturing the decision - making of a group of senior managers playing a cyber security game : — We identify the top - level cyber security goals used by managers to secure the organisation in D - D : Human errors prevented , Unauthorised access prevented , and Contextual informa - tion gained . We identify the security qualities they value ( Confidentiality , Data integrity , Response time , and Availability ) , as well as sub - goals and tasks , all of which combine to help teams operationalise their decisions . The cyber security goals identified by these non - cyber security experts are particularly interesting , because they are almost identical in substance to the cyber security priorities espoused as best practice . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 4 B . Shreeve et al . — We develop a model of reasoning that describes how cyber security decision - making devel - ops through the interactions of the team . This is centred on the collective model of under - standing of the team , which is informed by the development and evaluation of information , risk evaluation and resource constraints . It helps to explain the way that the intuition and experience of individuals refines the understanding of the team . This is likely to be particularly useful for system engineers , practitioners , and requirements engineers that are working to support the cyber security decision - making in organisations . The remainder of this article is organised as follows . In Section 2 , we briefly present the D - D game . We explain our research methodology in Section 3 . We then describe our findings in Section 4 . In Section 5 , we explore the existing work related to our findings , and then in Section 6 we discuss how our work builds on these , acknowledging threats to validity . We conclude our article with Section 7 , highlighting some potential future avenues for research . 2 BACKGROUND D - D is a tabletop game that challenges teams to help a fictional organisation identify which secu - rity investments they should make . The game is facilitated by a Game Master ( GM ) and can be run with 2 – 10 players . Games typically last around 60 to 90 minutes , and the GM follows a script to introduce the game and to describe attacks that teams suffer . Teams are presented with a Lego simplification of a hydro - electric company , consisting of a plant site and separate office site . The plant site contains turbines for generating power , a SCADA controller , production database , and PCs , all operating on a local area network . This network is then connected via a router to the internet . The office site is also connected to the internet via a router and consists of another local area network with PCs , a mirror of the production database and server running the organisations website and email server . Teams are informed that , to date , the organisation has made no investments in cyber security software , services , or infrastructure . They are told that they have been hired to work together and help the organisation identify what to invest in . They are also informed that they have four quarters in which to make new security investments with a budget of $ 100 , 000 per each quarter ( any unspent budget rolls over to the next round ) . The board will reconvene at the end of each quarter and tell them what ( if any ) attacks have occurred as a result of their decisions . Teams can ( and should ) discuss all their decisions . This openness to discussion is proactively encouraged by the GM and it is an essential part of the process . Teams are provided with cards representing a number of potential security investments identi - fied by the organisation from which to choose ( see Tables 1 and 2 , reproduced from Reference [ 12 ] ) . Two of these cards , Asset audit and Threat assessment , respectively provide intelligence on known vulnerabilities ( which unlocks the additional cards in Table 2 ) and information on common threat actors . Teams are informed that they will receive this information as soon as they choose to invest in either of these cards , i . e . , they do not have to wait until the end of the round to benefit from this information . There are 33 potential attacks that the teams can suffer during the game , all of which can be negated by timely investment decisions . The attacks are all common attacks and have been vali - dated as typical attacks by Frey et al . [ 12 ] through gameplay with security professionals . The game is described in more detail in Reference [ 12 ] . 3 METHOD 3 . 1 Participant Selection and Data Collection Our research focuses on managers , because they are typically responsible for the majority of op - erational decisions within an organisation . Such decisions often have direct and indirect cyber ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 5 Table 1 . Initial Defences Available to the Players CCTV plant ( $ 50 , 000 ) Surveillance cameras and alarms that will automatically warn security guards of a physical intrusion in the plant . CCTV offices ( $ 50 , 000 ) Surveillance cameras and alarms that will automatically warn security guards of a physical intrusion in the offices . Network monitor plant ( $ 50 , 000 ) An advanced software and hardware solution that monitors all traffic on the plant network and detects ongoing attacks . Network monitor offices ( $ 50 , 000 ) An advanced software and hardware solution that monitors all traffic on the office network and detects ongoing attacks . Firewall plant ( $ 30 , 000 ) A software and hardware solution that monitors and filters unauthorised traffic coming from the Internet to the plant network . Firewall offices ( $ 30 , 000 ) A software and hardware solution that monitors and filters unauthorised traffic coming from the Internet to the office network . Antivirus ( $ 30 , 000 ) A software protection against malware for all PCs ( plant and offices ) . Security Training ( $ 30 , 000 ) Basic security hygiene for all employees ( plant and offices ) . Asset Audit ( $ 30 , 000 ) Detailed evaluation of the company’s infrastructure , reveals and shuts down an open WiFi network on the plant , and un - locks additional defenses ( cf . Table 2 ) . Threat Assessment ( $ 20 , 000 ) Detailed information about possible threats and attacks against the company . Table 2 . Additional Defences Available after an Asset Audit Patches Controller ( $ 30 , 000 ) Upgrade to the firmware of the SCADA controller . Patches PCs ( $ 30 , 000 ) Upgrade to the operating system of all PCs ( plant and offices ) . Patches Server & DBs ( $ 30 , 000 ) Upgrade to the operating system of the server and databases ( plant and offices ) . Encryption PCs ( $ 20 , 000 ) Encryption for all PCs ( plant and offices ) . Encryption Databases ( $ 20 , 000 ) Encryption for all databases ( plant and offices ) . security consequences for software - based systems . For example , managers may recognise the im - portance of some fundamental aspects of cyber security hygiene like training but neglect some others like the security of cyber - physical systems ( such as the SCADA system in D - D ) . These are systems with embedded software and a rang of quality requirements including security , safety , and availability . The dataset used in this article is derived from 31 participants playing the game in seven teams ( four teams of four and three teams of five players ) . All participants worked for the same ma - jor industrial organisation , and all were part of the organisation’s senior European management team . The industry in which this business operates is high risk and production focused . We would therefore expect teams to have a bias in favour of protecting the plant site during their decision - making . A different population may introduce a different bias . The seniority of the managers means that they were responsible for a lot of employees and for vast budgets . They are , therefore , ex - tremely familiar with making risk - based decisions . Again , their experience with handling risk may ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 6 B . Shreeve et al . Fig . 2 . Teams’ prior level of experience . have an influence on their response to the exercise . We were not involved in the recruitment of participants—they were selected and placed into teams by the organisation itself to provide teams that were as balanced as possible . We are therefore unlikely to have introduced any recruitment bias . Potentially , the individual choosing the teams within the organisation did introduce some bias but we are unable to account for this . At the time the game was played , one participant from each team was completing a course on advanced decision - making . As such , those participants had the final say on all decisions made by their team . However , despite this , we did not notice any dominance by any given individual in each team . Each game is run by a separate GM . They all received the same 2 - hour training session about how to run a D - D game from the first author . They were also provided with a script to introduce the game and a tool that produced the scripted attack descriptions from the D - D instruction book [ 35 ] . This ensured that teams received the same experience regardless of GM . In Figure 2 , we summarise the level of experience reported by each participant prior to starting the game . Participants were asked to identify their existing general Computer Science , Cyber Se - curity , and Industrial Control System ( ICS ) experience on a four - point scale : ( 1 ) no particular training , ( 2 ) some technical knowledge , ( 3 ) significant training or practice , and ( 4 ) expert . Teams reported an average familiarity of 1 . 75 for prior cyber security knowledge , suggesting that most teams had some technical knowledge but no significant training . Teams reported a lower aver - age prior level of computer science experience of 1 . 58 . Finally , teams reported the highest level of average prior experience with industrial control systems of 2 . 39 . These figures are likely indicative of the industry in which these managers work . A high propor - tion of participants worked directly on industrial sites with high reliance on ICS and , as a result , we would expect them to have a greater familiarity with ICS . The lowest levels of familiarity reported were in terms of ( more general ) computer science . It is possible that this stems from the use of the term computer science specifically . This term is not often used outside of academia . The first author recognised this during the session and informed the participants that the term was analogous to general computing expertise ( i . e . , dedicated training in coding , networking or specialist tools , and systems ) . It seems plausible that the reported familiarity with cyber security is higher , because the term is more commonly used than computer science . Furthermore , we know that their organisa - tion provided annual web - based cyber security training to all staff . The content of this training is related to general cyber - hygiene . We therefore consider these participants to have a low level ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 7 of cyber security expertise , as reflected in the average reported cyber security experience of 1 . 75 ( suggesting teams have a mixture of participants with no particular training and some with some technical experience ) . 3 . 2 Analysis Approach We have used a multi - stage approach to gather and analyse our data . Step 1 - Data capture : Thirty - one senior managers from the same organisation were divided into seven teams and asked to play through a facilitated D - D session . Audio recordings were taken and transcripts created of gameplay conversations . Games typically lasted 60 – 90 minutes . Step 2 - Development of an iStar 2 . 0 goal model of management decision - making : Most businesses are goal - driven ; to this end , the first two authors worked to develop an iStar 2 . 0 goal model that describes the decisions made by teams during the game , based on a grounded theory analysis of the transcripts of the gameplay . From this , we identify several key decision - making characteristics . Step 3 - Developing of a model of cyber security reasoning : Transcripts of the gameplay have been coded using a grounded theory analysis by both the first and second authors and a model derived that describes how teams go about decision - making and the factors that affected their decision - making . We have used a grounded theory approach for analysing the teams’ transcripts that informs both the development of our iStar 2 . 0 goal model and our model of cyber security reasoning . The iStar 2 . 0 goal model has been chosen , because it is a conceptual model designed for capturing the actions of stakeholders that are necessary to reach specific goals . In this instance , it helps us visualise which cyber security goals the managers in our sample have identified and how they prioritise and think about these goals . Organizations are typically result driven , striving to make choices as quickly and efficiently as possible ; by exploring the decision - making of teams using iStar 2 . 0 we are able to highlight result - driven decision - making tendencies . Our model of cyber security reasoning meanwhile complements this approach by helping us understand how and why teams identify these particular cyber security goals . 3 . 2 . 1 Straussian Grounded Theory . We used grounded theory analysis [ 39 ] to explore how man - agers make cyber security decisions to derive as complete an understanding of the underlying cy - ber security decision - making that these teams exhibit . A grounded theory approach provides us with a more flexible method for exploring the underlying socio - cognitive interactions that make up the teams decision - making . Straussian grounded theory involves the detailed analysis of any data to the extent that no new findings can be identified . Our point of saturation was therefore the number of coding iterations taken before we found no further insights . Generalisation of findings in grounded theory analysis is often complicated because of the detailed nature of the analysis , usually of a specific subset . We have incorporated quantitative data where possible to supplement our grounded theory analysis . This provides us with a richer understanding of the groups under study . The game was designed to study decision - making and is abstracted from real - world scenarios . It was developed and validated with industry representatives [ 12 ] . Similar approaches are often used during wargaming to simulate decision - making . For example , NATO’s Locked Shields exercise [ 1 ] presents a “constructed” reality that is close enough to a realistic situation to be beneficial ( as is the case with D - D ) . The first and second authors led the data analysis process . Audio recordings were taken of all seven teams and transcriptions produced of the teams’ dialogue . An open coding [ 39 ] approach ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 8 B . Shreeve et al . Fig . 3 . Coding sample from team Team 1 . was used to identify patterns within each teams discussion . Coding took place over a number of iterations with coders meeting regularly to compare their coding , updating dimensions where necessary , and adjusting elements in the emerging theory . In Figure 3 , we provide an example of the coding process . The elements of our goal model and our model of cyber security reasoning represent trends observed across the majority of the game sessions , with exceptions noted as necessary . We reached the point of theoretical saturation [ 14 ] when no new concepts where found from the analysis of additional team transcripts—this took six passes of the data . The final step in our data analysis was axial coding [ 39 ] , which involves the identification of relationships between the elements , described as propositions . Our goal model follows the iStar 2 . 0 notation and includes a set of goals , tasks , resources , and qualities . Our model of Cyber Security Reasoning , according to guidelines on generating theories in software engineering [ 36 ] , includes a number of elements : six dimensions relevant to the oper - ationalisation of security goals , as well as a number of propositions describing how dimensions impact one another . 3 . 3 Threats to Validity 3 . 3 . 1 Internal Validity . The game is entirely dependent on the interaction between the Game Master and the team . To try and counter this risk , each Game Master was given the same 2 - hour training by the first author who introduced them to the game and information on how to run it and provided them with scripted answers to common questions that teams were likely to ask . We also provided Game Masters with a web - app that generated a script for them to read out based on the choices made by the teams as the games progressed . We did not note any variation from the provided scripts during their coding of the transcripts . The Game Masters have had little impact on the decision - making of the teams , as intended . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 9 The nature of the data gathering means that there is a chance of an observer effect . Teams were aware of the fact that we were gathering data whilst running the exercise . It is therefore possible that the teams did not interact in a naturalistic way . Unfortunately , this is a side - effect of a controlled study . However , we do know that these teams were flown in from across Europe just to take part in this training , and they therefore took the exercise seriously . 3 . 3 . 2 External Validity . Our study is based on data gathered using D - D . It is important then to question how well this exercise generalises to the wider world . We are reliant on the game to help simulate the type of decision - making that might occur in the real world . The game was developed with testing and validation with security practitioners [ 12 ] . Nonetheless , it is still an approximation—players are presented with a simplified scenario , the attacks are predefined , and the investment options limited . However , the game presents teams with little experience of making these choices with sufficient complexity to elicit realistic decision - making . For example , the game provides teams with a variety of information that they have to negotiate , a finite budget , multi - ple potential valid actions , and unknown consequences . These are all factors that affect decision - making in the real world . We fully acknowledge that our method is unable to emulate many of the complexities and nu - ances that occur during decision - making in a real - world scenario . D - D provides a simplification of the environment , assets , and attacks that are likely to be in play in the real world . We are reassured by the fact that the original game [ 12 ] was developed and tested with cyber security practitioners who felt that the game provided a good approximation of the challenges involved in making cyber security decisions . We note that the exercise has since been adopted and adapted by a public or - ganisation nationwide and has been played by a large variety of organisations with very positive feedback , winning recognition from both the SANS Institute and The National Cyber Awards , and resulting in multiple papers based on insights from the data generated [ 12 , 33 , 34 ] . We acknowledge that D - D is better at eliciting one form of cyber security decision - making— strategic decision - making . Cyber security decision - making occurs in a wide range of circum - stances . For example , the decision - making that occurs whilst a team is handling a major on - going breach is going to be very different to the high - level strategic decision - making made about which cyber security projects should be completed by an organisation and in which order . D - D is much better suited to exploring the latter type of decision - making , in which managers are typically involved . Our findings are therefore likely to be useful to practitioners supporting this type of high - level strategic cyber security decision - making . We are unable to determine how these findings generalise within the organisation from which the sample is drawn . That is , we are unable to determine whether the decision - making demon - strated in our study is absolutely reflective of the decision - making that would occur within the organisation under normal conditions . To try and negate this threat to validity the organisation itself selected the teams to reflect typical project teams within their businesses and charged one team member to act as chair . They were specifically told to treat the exercise like any other work - based project . We are therefore confident that the decisions made are as close to those that the company would make as possible . We are also confident that goal models produced using this approach are helpful for capturing the wider decision - making space . 4 FINDINGS Our findings cover two main areas : a goal model of management decision - making and a model of cyber security reasoning . Both of these models were created through a grounded theory analysis of the teams’ discussions whilst playing D - D . We first introduce our iStar 2 . 0 goal model , describing what security goals teams have identified and how they could operationalise and reach these goals . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 10 B . Shreeve et al . We then introduce our model of cyber security reasoning , which helps capture how teams make their decisions through a number of socio - cognitive interactions and why they identify particular methods of reaching their cyber security goals . 4 . 1 A Goal Model of Management Decision - making We have developed a goal model to show the common decisions that teams in our sample make . This analysis provides us with a broader idea of the goals used by the managers and that lead to the selection of a particular investment during the game . When a player uses a card , it is because they are interested in a particular outcome ( a goal ) . The goal model explores the tensions and concerns that emerge as teams identify , prioritise , and attempt to achieve these goals . The use of a particular card can also prompt the identification of additional goals that were not considered in the beginning . Ultimately , the goal model helps to explore the interrelated nature of the decisions that teams have to make and the impact that such choices have on the organisation’s security . The model was created by analysing the seven teams’ transcripts and finding common goals based on the managers’ dialogues , following an open coding approach . We have used the i * framework to build our model . The i * framework was developed for mod - elling and reasoning about organisational environments and their information systems , covering both agent and goal - oriented modelling [ 42 ] . It focuses on the concept of the intentional actor . Actors , in their organisational environment , are viewed as having intentional properties , such as goals . A goal is a state of affairs that the actor wants to achieve and has a clear - cut criteria of achievement . The i * framework provides the strategic dependency and strategic rationale ( SR ) models . The former specifies the external dependencies among actors , while the latter allows an analysis of goals fulfilment , that being one of our objectives . The framework has evolved to iStar 2 . 0 [ 7 ] , which we use for creating our goal model . We used the piStar tool [ 28 ] to create our iStar 2 . 0 SR model . The tool allows us to change the colour of the elements , which we used to better explain some of the concepts . We are using red to represent misinterpretations from the managers , yellow to represent new goals that appear from the new information gained by using a specific card , and blue to represent new cards and the corresponding tasks that appear from the usage of those cards . The colours are used to improve the understandability of our particular goal model and are not an iStar 2 . 0 standard . For readability purposes , the complete iStar 2 . 0 SR model , derived from the discussions and choices made by all seven management teams while playing the game , was split into three sub - models , one for each of the main sub - goals . The complete model is presented in Appendix A . There is only one actor in the model , named Managers , because the teams were composed of senior managers and they were not dependent on other actors . As such , and for all seven teams , the overall goal stays the same : Company secured . Ultimately , the teams want to guarantee that the company is secured against all types of risk . This ideal state is achieved by addressing three high - level goals : Contextual information gained , Human errors prevented , and Unauthorised access prevented . The first goal is about gaining as much information as possible about the game itself . The second goal is related to addressing human factors that might impact the security of the company . Finally , the third goal concerns preventing illicit access ( both physical and digital ) to the company by unauthorised parties . In addition to these goals , four qualities , related with security , exist within the process of the game : • Confidentiality — The degree to which the system ensures that data are only accessible by those with the proper authorisation to access them . • Data integrity — The degree to which the system prevents unauthorised access or modifi - cation to computer programs or data . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 11 • Response time — The time taken by the system to respond to a user or system request . • Availability — The degree to which the system is operational and accessible when required for use . We identified these qualities based on comments made by the teams when they were reasoning about the game and their choices and define them based on ISO / IEC FDSI 25023 : 2016 [ 19 ] . In the iStar 2 . 0 model , a quality is an attribute for which an actor desires some level of achievement and can guide the search for ways of achieving goals while also serving as criteria for evaluating alternative ways of achieving those goals . 4 . 1 . 1 Contextual Information Gained . Managers tend to approach the first high - level goal , con - textual information gained ( see Figure 4 ) , with three specific sub - goals in mind . They want to know both the threats and the vulnerabilities they could face during the game , hence the goals Threats known and Vulnerabilities known . To fulfil those goals , they have to perform the tasks Assess the threats and Assess the vulnerabilities . In terms of the game context , a player can assess the threats by using the Threat assessment card and can assess the vulnerabilities by using the Asset audit card . Although some teams used the correct card to achieve their specific goal , other teams made incor - rect assumptions about which card was needed to fulfil that same goal . This misinterpretation is represented by the red OR - refinements : Several teams assumed that playing the Asset audit card would provide them with information about threats and that the Threat assessment card would inform them about vulnerabilities . This misinterpretation happened despite the Game Masters specifically asking teams to read the description on these cards carefully to understand the differ - ence between them ( see Figures 9 ( a ) and ( b ) ) . The third specific sub - goal , New options available , is an assumption related with discovering new cards to use during the game . Some teams assumed that , by assessing the vulnerabilities or the threats , they would be able to unlock not only novel information but also specific cards . That assumption was correct for assessing the vulnerabilities but not the threats . That is , when using the Asset audit card , new cards would become available to the teams . Those new cards are represented in blue in the model . The new contextual information gained by using the Threat assessment card is represented in yellow in the model . 4 . 1 . 2 Human Errors Prevented . The second high - level goal , Human errors prevented ( see Fig - ure 5 ) , can be fulfilled by performing the task Educate staff . In terms of the game , this can be done by using the Security training card . If the teams have not used the Threat assessment card first , then their reasoning for playing the Security training is typically only related with the high - level goal , that is , to prevent human errors . However , if the Threat assessment card was used , then teams would have gained more information about the threats and are then able to reason about a more specific goal , which is Phishing prevented . In that sense , the Security training card is used to specif - ically prevent a phishing attack and not only more general human errors . Some teams also assume that playing the Security training card will allow them to fulfil the sub - goal of having Physical infiltration prevented . This incorrect assumption could jeopardise the game , since the goal is not fulfilled by using that particular card . Some quality attributes , related with security , exist within the process of the game . We identi - fied them based on comments made by the teams when they were reasoning about the game and their choices and define them based on ISO / IEC FDSI 25023 : 2016 [ 19 ] . In the iStar 2 . 0 model , a quality is an attribute for which an actor desires some level of achievement . By having the goal Phishing prevented fulfilled , it helps to satisfy the Confidentiality of the system , i . e . , that the data are accessible only to those authorised to access them . 4 . 1 . 3 Unauthorised Access Prevented . Finally , for achieving the third high - level goal , Unautho - rised access prevented ( see Figure 6 ) , the managers typically want to address 10 specific sub - goals : ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 12 B . Shreeve et al . Fig . 4 . Goal Contextual information gained detailed . Fig . 5 . Goal Human errors prevented detailed . Virus / malware prevented , Unusual network activity monitored , Unauthorised data access prevented , DoS and port scanning prevented , Data exfiltration prevented , PC disruption prevented , Controller dis - ruption prevented , Theft prevented , Bugging of equipment prevented , and Server disruption prevented . However , the 10 sub - goals cannot be all be addressed at the same due to budget constraints , so teams need to prioritise them . To illustrate the reasoning behind the decisions , we analyse the dialog of one of the teams . During the second round of the game , Team 6 begins to explore which of these goals is their ultimate priority ( they were deciding between Virus / malware prevented or Unusual network activity monitored ) . They have just been discussing the need for security training ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 13 that would prevent errors , but against this they are concerned about the potential for an intruder gaining access via some form of malware and causing damage to their production facility : Player5 : Training ? Do we build in any human element ? Player1 : Our production is still vulnerable at the moment . Player5 : Okay , right . Controller upgrades . Player1 : You know , without that . . . If that goes [ indicates SCADA controller ] , nevermind anything else . Player5 : Yeah , if that goes , you’re knackered [ indicates unencrypted production data - base ] . Player1 : But the thing is— but the thing is— Player2 : But if you upgrade that - [ Server Upgrade— noted earlier on in the discussion as a potential route into the business via doped emails ] Player3 : And that ? [ Controller Upgrade ] Player2 : And that hasn’t been upgraded [ Antivirus ] . That’s vulnerable anyway [ unen - crypted database ] , isn’t it ? Player5 : But do not forget , when you look at the system as a whole thing , a piece of it and piece of it . . . Because , if we’ve got a vulnerability from , you know , if Nibs up there is the manager and he downloads the , you know , the malware . The goal Virus / malware prevented can be fulfilled by performing the task Install antivirus . In terms of the game , this can be done by using the Antivirus card . For the goal Unusual network activity monitored , the managers’ reasoning is straightforward , thinking they can fulfil the goal by performing the task Install network monitoring . This can be done by using the Network monitoring plant and Network monitoring office cards . However , it is not always clear for the managers which of the cards is more important when they cannot use both due to budget limitations . Yet , they do tend to prioritise the plant , as will be discussed in Section 4 . 2 . 5 . The managers may have the goal Unauthorised data access prevented , but if they have not played the Asset audit card , then they are not able to understand how to fulfil that goal . As such , if the Database encryption card and PC encryption card are not revealed , then managers will not be able to fulfil the goal . The same is valid for the goals PC disruption prevented , Controller disruption prevented , and Server disruption prevented . For these two last goals , managers believe the task Install CCTV , operationalised by the CCTV plant card and the CCTV office card , can be used , to some extent , to fulfil them . If the Threat assessment card was used , then teams would have gained more information about the threats and are then able to reason about two more specific goals : DoS and port scanning pre - vented and Data exfiltration prevented . In that sense , the task Install firewall is performed to fulfil these goals . In terms of the game , this can be done by using the Firewall plant and Firewall office cards . Last , the goals Theft prevented and Bugging of equipment prevent can be fulfilled by performing the task Install CCTV . In the game , this can be done by using the CCTV plant and CCTV office cards . As for the network monitoring , it is not always clear for the managers which of the cards is more important when they cannot use both due to budget limitations . In terms of qualities , we were able to identify four of them based on the managers’ reasoning : Confidentiality , Data integrity , Response time , and Availability . All the specific 10 sub - goals help to satisfy the Confidentiality of the system , i . e . , that the data are accessible only to those authorised to access it . For Data integrity , the goals Virus / malware prevented , Unusual network activity monitored , and Bugging of equipment prevented help to achieve it , i . e . , preventing unauthorised access to or modification of the system and data . The goals Unusual network activity monitored , DoS and port ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 14 B . Shreeve et al . Fig . 6 . Goal Unauthorised access prevented detailed . scanning prevented , PC disruption prevented , Controller disruption prevented , Theft prevented , and Bugging of equipment prevented help to satisfy the Availability of the system , i . e . , that the system is operational and accessible when required for use . Finally , the goal DoS and port scanning prevented help to satisfy the Response time of the system , i . e . , that the time taken by the system to respond to a user or system request is reasonable . 4 . 2 A Model of Cyber Security Reasoning Our grounded theory analysis of the seven teams’ transcripts has resulted in the identification of a range of concepts , categories , and propositions ( see Table 3 ) . We identified the following core concepts during gameplay : discussion of risk by considering potential consequences and the likelihood of these events occurring . The development of many hypothesis about the game state , constantly evolving through reflection / revision and informed by knowledge and speculation about threat actors , attack vectors , and vulnerabilities . A number of factors affected decision - making priorities , including careful consideration of return on security investment and whether teams engaged in more proactive or reactive decision - making . These concepts have then been grouped into six categories—these are key high - level factors that affect cyber security risk decision - making during D - D along with eight propositions that describe how these factors interact and affect one another . From these , we have derived our model of cyber security reasoning ( see Figure 7 ) . This model complements the goal model in Section 4 . 1 , providing further detail and insights into how teams share , derive , and evaluate information to make their decisions and why the teams identify specific cyber security goals . We will start by presenting an overview of our model , and we will explain each part in more detail in the next subsections . The model of cyber security reasoning describes the cyber security decision - making processes exhibited by teams during D - D . The model consists of a central work system [ 2 ] containing the decision - making of the team . We borrow the concept of work systems from information systems , because it helps to separate the socio - cognitive processes of the team ( which exist within the system ) from those of the individual participants ( which exist outside of the work system ) . At the centre of the collective decision - making system is the model of understanding —this rep - resents the teams’ current shared understanding of the situation or scenario being discussed . This ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 15 Table 3 . Overview of Categories , Concepts , and Propositions Concepts A . Consequences B . Likelihood C . Hypothesis D . Threat actors E . Attack vectors F . Vulnerabilities G . Proactive H . Reactive I . Return on security investment J . Reflection / Revision Categories 1 . Model of Under - standing 2 . Information 3 . Risk 4 . Resources 5 . Experience 6 . Intuition Propositions P1 . Previous experience influences the prioritisa - tion of choices and informs the response to attacks during the game P2 . Suggestions are intuitively made where in - complete experience exists P3 . Information gathering improves the model of understanding by increasing contextual awareness and refining assumptions about available choices P4 . Risk is used as a mechanism to evaluate the model of understanding and vice versa P5 . Resource constraints ( finite funding ) and po - tential financial impact emerge from and in - form the model of understanding P6 . The risk of an attack and its potential impact is used to evaluate the use of resources P7 . Evaluation of information informs resource allocation P8 . Information gathering informs risk analysis Fig . 7 . Model of cyber security reasoning . model of understanding is affected by the evaluation of risk , the search for ( and evaluation of ) in - formation , and the evaluation of how best to employ resources . The shared work system is then influenced externally by the experience and intuition that each participant brings to the decision - making process ( assuming they choose to share their experience or intuition ) . We are confident that the trends we have observed are representative of how other teams play D - D : In Figure ? ? , we show a comparison between the decisions made by teams in the original dataset gathered by Frey et al . [ 12 ] . It shows for each team the round in which they decided to play each card : Dataset 2 ( managers ) , which is the dataset reported herein , and Dataset 1 ( managers ) and Dataset 1 ( non - managers ) , which are both reproduced from Frey et al . [ 12 ] . The figure helps to demonstrate the consistency with which teams play the game regardless of mix of players . In terms of broad investment trends during the game , it appears that the majority of teams favour investment in intelligence ( Threat assessment and Asset audit ) and basic cyber security investments ( Firewalls , Security training and Antivirus ) early on in the game , with most teams investing in ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 16 B . Shreeve et al . Fig . 8 . Comparison of choices . these in the first two rounds . Likewise , the majority of teams leave investments in physical se - curity ( CCTV ) and advanced cyber security ( network monitoring ) until later on in the game . The middle section of the game tends to exhibit variation in the investments made as teams collaborate to identify their priorities . It is possible that these trends are artefacts of the game’s design . How - ever , note that the original game was developed and tested by Frey et al . [ 12 ] with cyber security professionals to check that the scenario teams play through was representative of the real world . Frey et al . [ 12 ] use a game score as part of their analysis . They derive this score by establishing how many ( of 33 potential ) common cyber attacks within the game teams have defended against . Table 4 shows the scores from the teams in our sample . It is important to note that in the original paper Frey et al . [ 12 ] note that “in itself , the game score is not an absolute measure of the security skills of the players . ” We include it here to help provide an indication of relative performance of teams . The average score of the management teams we have studied was 28 . 14 , which is slightly higher than the average score of management teams in the original paper ( 27 . 75 ) and just below the average score of the best performing teams of computer scientists ( 28 . 25 ) . More recent work by Shreeve et al . [ 34 ] compares the performance of 208 different teams by player background as they play D - D , ultimately concluding that player background and experience has no statistically significant impact on the performance of a team . 4 . 2 . 1 Model of Understanding . The model of understanding is the core category around which our wider model is developed—it represents the collective decision - making of the team . This is an extremely complex socio - cognitive process that occurs as teams explore and evaluate the range of concepts identified to finally reach a point of action . It is also distinct from the decision - making and understanding of each individual team member , which exist externally to the collective decision - making system as Experience and Intuition . The teams’ model of understanding is always in flux—their understanding changes and evolves consistently as they receive new information , as they speculate and explore ideas . For example , ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 17 Table 4 . Potential Cyber Events Prevented ( Following Scoring Reported in Frey et al . [ 12 ] ) Team Score 1 27 2 29 3 31 4 29 5 27 6 29 7 25 teams often spend a lot of time at the start of the game developing a strategy based on the cards in front of them and assets on the game board—this is their model of understanding . However , once they play the asset audit card they are told about a range of vulnerabilities that exist in the system and a series of associated new investment options that have become available . This new influx of information and change of context ( in the form of the additional cards ) drastically changes the teams’ model of understanding . The model of understanding therefore represents the teams’ current best interpretation of the situation at a particular point in time—Starbuck and Milliken [ 37 ] describe this process of refining understanding as the placing of stimuli into some sort of framework that ( at that moment in time ) best describes the stimuli of interest . The model of under - standing is therefore always in flux , evolving as the team encounters new knowledge ( e . g . , in the form of game / card descriptions ) or when they develop additional information ( e . g . , in the form of hypotheses ) about the scenario at play . Teams start D - D with a limited understanding of the game—they can only speculate about what will happen during the game ( beyond the basic premise described by the game master ) . They can only hypothesise about the potential attacks that exist within the game and they only have access to the initial investments ( until they complete the asset audit and identify additional vulnerabili - ties ) . Participants may have varying levels of technical and cyber security – specific experience and knowledge that affects how teams are able to interpret and evaluate information . As the teams become more familiar with both the game and each other , they start to develop a shared model of understanding , working together to make sense of each situation and identify the best actions to take . As the game evolves , the model of understating inevitably changes . Much of the team’s understanding can be attributed to experience gained defending against attacks in previous rounds ( regardless of whether they are successful or not ) . At the end of each round teams reach a point where they feel they are able to make their investment choices—these decision points represent moments in the conversation where the collective understanding of the team is accepted and action taken . For example , Team 7 starts the game with a clear model of understanding—they think the opti - mum investments are Firewalls for both sites and Antivirus . Player1 : We have to defend because we already got a plan so we got to , we [ want ] to put a firewall in place to protect the plant . GM : Yeah . Player2 : But then again from the office systems we’ve got unauthorised access into plant , uh , system as well . So we need a good firewall in there as well . The firewall will break an outright , uh , access to [ either ] one of the networks , but then again you need antivirus because even with the fire , the firewall you can get unauthorised access to the networks . So I , I would , I would start with these three . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 18 B . Shreeve et al . Fig . 9 . D - D cards for assessing the threats and auditing the assets . The team then develops their model of understanding further by acknowledging that there are a number of other attack vectors that could be exploited even if they put Firewalls and Antivirus in place , and further equally valid alternative investments . Player2 : I think , uh , technical measures are , are a little bit better than the non technical at the first stage . Player3 : Hmm . Player1 : In the short term I think the , uh , the behavioural , uh , measure are better but we need to get the basics , let’s put the basics in place first [ firewalls , antivirus ] . The team then notes that if they were to play the Threat assessment card , then they would be able to identify the priorities for further investments . However , the team decide that it is more important to address the immediate vulnerabilities that exist in not having Firewalls or Antivirus in place : “First , first close the biggest doors . ” 4 . 2 . 2 Information . The information category describes how teams gather , evaluate , and estab - lish the value of information . This includes ( but is not limited to ) the process that results in teams achieving the goal contextual information gained . Teams derive information by sharing informa - tion , developing hypotheses , reflecting on their choices , and by playing the Threat assessment or Asset audit cards . The Threat assessment investment provides information on the threat actors that are likely to target the hydro - electric organisation during the game . Briefly , these are script kiddies , organised crime groups , and nation states . Teams tend to play the Asset audit in the same round as the Threat assessment or in the following round ( see Figure ? ? ) . The Asset audit itself provides teams with an overview of the major vulnerabilities in the current organisational setup and unlocks access to five additional investment cards ( server upgrade , PC upgrade , controller upgrade , PC encryption , and database encryption ) . The introduction of these additional options usually changes the teams model of understanding significantly as Player4 , Team 1 noted after receiving this new vulnerabil - ity information : “So that’s just blown our plan . ” Teams learn from the attacks they suffer , reflecting on the relationship between these and the investment choices they have made ( or have not made ) . Sometimes this information serves to validate their decisions , for example at the end of round 1 Team 2 discovered that their Firewall ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 19 investment had been intercepting scanning attempts from across the world , to which Player3 re - sponded , “Then we did the right thing with putting it there [ at the plant site ] then . ” In other situations attacks result in teams making knee - jerk investments . Information gathering is closely related to other parts of our model of understanding by the following three propositions : P3 . Information gathering improves the model of understanding by increasing contextual awareness and reforming assumptions about available choices . P7 . Evaluation of information informs resource allocation . P8 . Information gathering informs risk analysis . In summary , information gathering improves the model of understanding by increasing con - textual awareness and refining assumptions about available choices . Information from the Threat assessment provides teams with information about potential threat actors that can help them to prioritise the order in which they invest in items . Likewise , the Asset audit reveals information about the vulnerabilities within the organisation , typically altering the investment priorities that the team previously held . Attacks that the team suffers serve as a further source of information , affecting the priority of investments and perceived likelihood of future attacks . There is a subtle difference between the goal model contextual information gained and the broader search for information that informs the development of the model of understanding . In the goal model , managers have specific information that they think they need and set out to discover , provided in the game by the Asset audit and Threat assessment . By contrast , information that is used in decision - making can be much broader . It includes the derivation of all information , not just that which teams have specifically sought out , but information gained from all interactions ( e . g . , from suffering attacks ) . It is important to recognise this difference—it is possible for an en - tirely goal - driven approach to overlook information pertinent to their decision - making , because it did not fall within the specific “goal” boundaries . Decision - makers should bear this in mind— it is often impossible to know exactly which sources of information should be pursued to make decisions , all information is potentially valuable . 4 . 2 . 3 Risk . Risk perception is a key part of cyber security decision - making . Early in the game teams tend to make similar investment choices , often with little clear reasoning or risk evaluation— we refer to these as “no brainers . ” As the game progresses , teams utilise risk thinking to consider potential attack scenarios or attempt to gauge business priorities to help them identify optimum investments . This process helps teams to achieve the goals Unauthorised access prevented and Hu - man errors prevented through careful consideration of the security qualities Confidentiality , Data Integrity , and Availability . No brainers . “No brainers” are choices that seem obvious to the teams , often before attempting to derive any additional information about the organisation’s vulnerabilities or potential threat actors and attack vectors . For many teams , these investments are self - evident and should be made at the earliest opportunity . The same investments are consistently highlighted in this way : fire - wall ( s ) , antivirus , and security training . What is not apparent is whether teams are choosing these investments , because they are just the right choices and no further consideration is necessary or if they are being chosen because they represent the cyber security investments with which they have the most familiarity . It is possible that the majority of individuals ( who have relatively little cyber security experience ) recognise these countermeasures , because they have been consistently advised to implement them on their personal devices over the last 25 years . The reasoning for these early investments is usually extremely brief , for example , Team 5 note “you’ve got to have some fundamentals , such as firewalls”—no further explanation is provided as to why . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 20 B . Shreeve et al . Investment in security training is another “no brainer” that these senior managers readily iden - tify as important . They note that people are at the core of every business and training them helps avoid future security problems . As noted by Player1 , Team 2 , “We learn that the people are al - ways the weakest , so therefore I will go for a basic training . ” Teams note that workers are some of the most powerful assets available to an organisation , and an empowered and knowledgeable employee is the first line of defence against cyber attacks . As such , security training is considered vital and most teams tend to invest in it early on in the game . Teams do not consider CCTV a “no brainer . ” This is despite acknowledging the importance of physical security . Teams state that in an ideal situation they would add CCTV to the current busi - ness . However , several teams assume that the game prioritises cyber attacks over physical attacks . These assumptions are indicative of their mental model of what is and is not “cyber security . ” As Player5 , Team 4 stated , “That we just learned from the threat assessment that it’s all cyber , cyber , cyber and there’s no physical threat . ” This means that , outside of the context of the game teams would consider CCTV a key defence to purchase , and they would add it to both the plant and to the office . However , their assumptions about the game mean that they actively delay investment in CCTV until the later rounds or even neglect to invest in it at all . What - if risk analysis . The teams often use a less formalised “what - if” - style scenario - based form of evaluation to explore risk ( i . e . , direct consequences ) that could potentially arise as a result of making a particular choice . In general , teams tend to prioritise putting defences in place instead of addressing the root cause of the vulnerability . For example , when teams play the Asset audit card in the early rounds and have access to a wider range of patches for known vulnerabilities , they still tend to prioritise defensive investments ( e . g . , firewall , antivirus ) before investing in the known preventive measures like hardware upgrades or patching . That is with the exception of the controller upgrade , which the majority of teams value far beyond any of the other preventive or defensive investments that relate to securing sensitive information on the databases , servers , or PCs . As Team 6 notes : Player4 : The controller upgrade was based on , um , reducing risk of the— Player3 : Yeah , of our production key asset . Teams often structure their decision - making using the information provided by the Threat as - sessment . For example , teams start by evaluating the potential impact that could arise from the sort of attacks utilised by script kiddies and then identify which defences are necessary to prevent those attacks . This type of evaluation is typically performed after the “no brainers” have been purchased . Teams then move on to address the attack vectors utilised by organised criminal groups . Teams tend to accept that there is nothing they can do to prevent nation state attackers and so emphasise repelling the script kiddie and organised criminal groups . The “what - if” - style risk analysis is closely related to the qualities Availability , Data Integrity , Confidentiality , and Response Time that are highlighted in the goal model . Teams often recognise that the risk to an asset is closely aligned with a particular quality . For example , teams often pri - oritise the upgrade of the controller , because they want to ensure that it is always available . There are striking similarities between the way that these managers ( with relatively little cyber security experience ) assess and evaluate cyber security risk and cyber risk thinking best practice highlighted in NIST 800 - 61 [ 25 ] and ISO 27035 [ 17 ] . For example , NIST 800 - 61 [ 25 ] notes several broad actions for handling incidents : preparation ( identifying asset priorities ) , triaging when inci - dents occur , and identification and evaluation of potential counter - actions . The managers in our dataset tend to start off by investing in additional intelligence ( in the form of the Asset audit and Threat assessment ) and then use this information to help them prioritise assets . When teams do suffer cyber events they then refine these plans and work to identify effective counter - actions . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 21 This is potentially indicative that individuals with traditional risk management experience can effectively evaluate cyber security decisions ( within the context of D - D ) . Prioritising investments . Teams tend to prioritise securing the plant first ( see Section 4 . 2 . 5 for more detail ) and then the office . When both office and plant investment options are available , plant defences will be favoured . This is directly related to the way that teams assess risk . Although teams recognise the importance of the office , they consider the risk of having an ill - protected plant to be greater , because the potential consequences could stop business from generating revenue . As Player4 , Team 4 said , “And we chose for the plant , because the plant is more important for the operations than the offices . ” Likewise , encrypting the databases is considered more important than encrypting the PCs . Teams consider the information that is stored in the databases to be more critical to the busi - ness than that which is stored on the PCs . The teams are often concerned that any access to the database by an authorised external entity will have a detrimental impact on the reputation of the company—ultimately with the potential to destroy the business . The risk category is related to other concepts in our model of cyber security reasoning by the following propositions : P4 . Risk is used as a mechanism to evaluate the model of understanding and vice versa . P6 . The risk of an attack and its potential impact is used to evaluate the use of resources . P8 . Information gathering informs risk analysis . In summary , teams use risk analysis to help identify investment priorities . There are a series of common investments made early on in the game—these are “no brainers” with little justification provided as to why they should be purchased first . Teams then develop scenarios to consider the potential consequences of investments being considered . They tend to split the risk analysis be - tween defensive and preventive investments , often with emphasis placed on the plant site prior to investment on the office site . It is interesting to note that teams often dedicate a lot of time to discussing the importance of physical security , and yet they rarely end up purchasing CCTV until much later on in the game if at all . There is a consistent view that physical security is not an integral part of cyber security . 1 4 . 2 . 4 Resources . Closely related to the consideration of risk is the evaluation of resources , that is , how the teams decide which investments to prioritise given a finite budget . There is a close interplay that exists between the identification of new information , evaluation of risk , and budgetary constraints : P5 . Resource constraints ( finite funding ) and potential financial impact emerge from and inform the model of understanding . The ultimate constraint that teams encounter and that informs all of their decision - making is one of finite funding . They have only $ 100 , 000 to spend per round with a range of equally valid investment options . P6 . The risk of an attack and its potential impact is used to evaluate the use of resources . Risk is closely related with the deployment of resources . In particular , the potential financial ramifications of an investment ( i . e . , loss of revenue , potential fines , share price impact ) serves to influence the prioritisation of choices . 1 Please note that we are not claiming that physical security is not important to cyber security , this is consistent with CyBOK ( www . cybok . org ) , we are just reporting on what is in the data . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 22 B . Shreeve et al . P7 . Evaluation of information informs resource allocation . Closely related to the use of risk thinking ( P6 ) is role that information gathering and evaluation plays in the prioritisation of investments . These three propositions are closely aligned , but all emphasise a slightly different aspect of the decision - making process . For example , Team 2 starts to consider the limitations that the budget introduces after exploring what they would ideally purchase : Player2 : So you want to do one of those [ Asset audit / emph ] , maybe , and get the feedback and then we use , choose how we spend the money . Player3 : And the antivirus , and the fire - how much for the firewall ? Yeah . Player1 : Where would you put the firewall ? Production or - Player3 : Production . How much are they ? Player1 : Firewalls are 30K [ per site ] . Player3 : We only have 100 , 000 . Hmm . What’s the most important thing , do we think ? Stopping things coming in through a firewall . Player1 : Yeah , so I was just thinking about where would you put it ? In the office or your plant ? Player3 : For both . Player1 : That’s 60k - Player2 : Protect the plant , wouldn’t you ? Player1 : Yeah , but if you’ve got this linked to the plant [ indicates Office site connected to Plant via internet ] , it doesn’t [ matter ] , it could go on either of those . Player1 : This is on , this is the internet . Player2 : Yeah . Player1 : So you can do 60K to do fire - both firewalls , and still do your threat assessment . That’ll be 80K . The team are forced to rationalise their choices based on the limitations of their budgets . This also affects how teams prioritise the goals they have ( see Section 4 . 1 ) . 4 . 2 . 5 Experience . The experience of individual team members influences the way that teams interpret the game and situations therein . As we have previously discussed , there is a tendency for teams to favour the choices with which they have the most experience ( especially early on in the game ) . Likewise , experience either direct or indirect ( perhaps garnered via the media ) often influences the way that teams respond to any attacks that they suffer . The experience of the individual and the relationship with the collective decision - making pro - cess is captured by the following proposition : P1 Previous experience influences the prioritisation of choices and informs the responses to attacks during the game . Player2 in Team 7 for example , referred to their experience of physical security breaches as justification for purchasing CCTV . Referring to an incident where the organisation they had been working for had hired a penetration tester who surprised them by managing to get onto their site and into their systems with almost no questions asked , “He just , he just asked where he could get in and they just allowed him to get in . ” The experience of players is often reflected in the biases of the team—the managers participating in these games tend to place a greater emphasis on the security of the plant above that of the office . From the teams’ perspective , the business would stop and the company would not be able to generate revenue if the plant was disrupted . As a result of this , these teams sought to protect the plant first . It seems highly likely that this priority ( and consequently their model of understanding ) ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 23 was informed by the nature of the heavy industry from which these teams originated , where an emphasis is placed upon production capabilities . 4 . 2 . 6 Intuition . Intuition helps to explain the way that people react to situations where they do not have complete information . Typically this occurs in two forms : First , people intuitively make assumptions about the nature of the game to try and gain an advantage . For example , some teams will assume that there are always hidden cards waiting to be revealed at the start of the game ( they would be right ) , whilst others assume that all the cards are in play ( for which they are wrong ) . Second , teams will often rely on their “gut instinct” when they are unable to call on other sources of information ( e . g . , from the Threat assessment or Asset audit cards ) or lack suitable experience . Such choices are not based on any conscious decision - making , and the reasoning behind these decisions is rarely expressed . This is captured by proposition P2 : P2 Suggestions are intuitively made where incomplete experience exists . It is important not to overlook the role that intuition and experience plays in the decision - making process . Such factors are hard to capture in a goal - model alone and yet are important in understanding how well teams interact and develop and evaluate information . 5 RELATED WORK 5 . 1 Decision - making Decision - making represents the process by which choices are identified and evaluated . This pro - cess typically starts with the recognition that there is something new that has changed and which needs understanding , some stimuli that as such is not understood entirely [ 37 , 40 ] . Teams playing D - D are constantly identifying new aspects that they need to understand , from speculating about potential attackers to learning about the games rules and mechanisms . Goleman [ 15 ] suggests that people make sense by attempting to place these stimuli into temporary mental frameworks that best describe the stimuli as they are understood at that point in time . Such frameworks are con - stantly being refined as people derive a clearer and clearer understanding of the stimuli . Many of these frameworks are based on best guesses , assumptions , and tested notions ; they are con - stantly changing [ 40 ] . It is important to note that these frameworks can exist both at the individual and team level . That is , an individual can have an understanding of the stimuli that differs from the accepted , shared understanding of the team . Russell et al . [ 31 ] take this iterative idea further by introducing the concept of the learning loop . That is , an iterative process by which the un - derstanding of the unknown is refined . The model of cyber security reasoning we have developed builds on and contributes to the existing decision - making research . The model of understanding describes a socio - cognitive process very similar to those outlined in the sensemaking literature . However , by using a grounded theory approach we are able to offer a more concrete indication of the key factors that affect cyber security decision - making . Organisations often struggle to iden - tify how much they should be investing and where for cyber security prevention , we witnessed this dilemma in our study and our model of decision - making reflects this with risk evaluation and resource constraints representing key factors in cyber security decision - making . This is something that existing decision - making research neglects . The separation of each individual’s experience and intuition and their impact on the collective decision - making are also important contributions , particularly in the context of cyber security where important decisions need to be made quickly . Much of the early cyber security specific work on decision - making was driven by a need to identify how much organisations should invest in cyber security . For example , the Annual Loss ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 24 B . Shreeve et al . Expectancy model [ 23 ] was developed to help organisations quantify their exposure to business risks . This model attempted to gauge the expected impact from a range of cyber incidents occurring within a 12 - month period . It is closely related to the Return on Security Investment [ 6 ] model that tries to help organisations identify the potential return ( in terms of security ) from an investment . Our work highlights just how resource constraints affect decision - making , serving both to force decision - makers to prioritise but also potentially limiting the range and depth to which options are considered . Dor and Elovici [ 9 ] have developed a model that describes the information security investment decision - making process . Their model is derived using grounded theory analysis applied to inter - views with 23 subjects from 20 organisations across nine industries . They asked interviewees to describe how organisations made information security investment decisions . By contrast , we have studied the decision - making process itself as teams make their choices—this provides a different framing of the decision - making process . Despite this , there are some similarities in our findings . Dor and Elovici [ 9 ] reported that the following aspects had a major effect on the decision - making process : risk management processes , decision makers , information security threats , prioritisation and budgeting , and information security awareness . In our model of cyber security reasoning , we highlight how consideration of risk , resources , and information inform the decision - making pro - cess . We have noted that the model of understanding appears to be a key function of cyber security decision - making . Dor and Elovici [ 9 ] meanwhile note that “an understanding of the cyber security threat landscape is one of the basic phases in the decision process . ” These overlaps lend credence to our own work , because it means that the aspects of decision - making that are commonly described by Dor and Elovici’s [ 9 ] subjects are reflected in the real - world analysis of teams decision - making during our study . Moore et al . [ 20 ] report on a survey exploring the factors that influence executives’ cyber secu - rity investment choices . Their work suggests that executives favour the use of frameworks ( e . g . , ISO 27001 [ 18 ] to help them structure their decision - making . They find that executives are more concerned with finding gaps in their organisation’s current systems and infrastructure rather than considering the potential consequences of their choices . The priorities of organisations reflect this tension ; some are driven to get the best value for money ( which may entail doing nothing ) while others are driven to identify and address all know vulnerabilities . In our analysis , we saw slightly different priorities—teams did not refer to or demonstrate structured forms of decision - making ( e . g . , ISO standards [ 17 , 18 ] ) , and whilst they were motivated to find and address vulnerabilities ( owing to the nature of D - D ) , they often prioritised investments in new defensive assets ( e . g . , fire - walls , antivirus ) over preventative investments ( e . g . , patching , training ) that addressed known vul - nerabilities in existing assets . Risk thinking is a key aspect of cyber security decision - making . Individuals making cyber se - curity decisions are heavily influenced by their perception of risk . Work by Nicholson et al . [ 24 ] asked both experts and non - experts within an organisation to identify security priorities . Their work highlights a number of cyber security mismatches . For example , security experts listed their number 1 priority for staff to be “asking for advice , ” and by contrast staff listed “use strong pass - words” as their number 1 priority . In our findings , we observed the role that the risk thinking of individuals played in the overall decision - making of the team . This resulted in the addition of the experience and intuition concepts within our model of understanding . Stevens et al . [ 38 ] provide one of the few studies exploring decision - making in situ . Their work explores whether education in threat modelling has an impact on the quality of cyber security decision - making . They taught 25 participants at New York City Cyber Command a form of for - malised threat modelling and then monitored their performance 120 days later . They found that 20 of the 25 participants were better able to prevent cyber attacks occurring . However , they do ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 25 not explore the decision - making process of their participants . Future work could build on the their work [ 38 ] , potentially using D - D as a means of benchmarking in between - groups studies to explore the impact that different decision - making or threat - modelling methods have on decision - making . 5 . 2 Goal Modelling Existing software engineering research has sought to explore how security requirements engi - neering practices can be improved through the use of goal - modelling approaches . For example , Yu et al . [ 43 ] introduce a tool that looks to automatically identify role - based access control patterns in stakeholder requirements models . Their paper demonstrates just how flexible goal - modelling approaches can be . Their proposed tool helps to ensure that system requirements do not introduce potential authorization issues . Mouratidis and Jurjens [ 22 ] meanwhile introduce their goal - driven security requirements engineering method . Peine et al . [ 27 ] highlight how the software security inspection phase can be improved through the use of goal modelling . They argue that security goals are typically framed as negative goals ( e . g . , avoidance based ) and propose a new model for security - relevant features ( Security Goal Indicator Tree ) that maps negative and non - local goals to more positive ( and concrete ) features that can be verified during the inspection phase of software development . This model associates goals with measurable indicators to ensure this traceability . Other work has explored broader aspects of security engineering that could be improved through the application of goal - modelling techniques . Oladimeji et al . [ 26 ] propose a goal - orientated approach to improve threat modelling during application development by improving the visualisation of threat information . Elahi and Yu [ 10 ] compare how different modelling ap - proaches help decision makers grapple with the tradeoffs that must be accepted in most security decisions . Ponsard et al . [ 29 ] explore the use of goal modelling to improve co - engineering of se - curity and safety requirements in the automotive sector by encouraging consideration of both aspects simultaneously . Our work complements this existing body of work through use of goal modelling to analyse how managers make decisions pertaining to security requirements and goals . Together with the model of cyber security reasoning , this iterative approach—with the model of cyber security reasoning— enriches goal - oriented security requirements engineering by capturing the decision context and tracing how decision - making and reasoning co - evolve over time . 5 . 3 Cyber Security Games and Decision - making Cyber security games are a popular way of raising awareness ( e . g . , References [ 3 , 4 , 8 , 12 , 32 ] ) and educating students ( e . g . , References [ 4 , 16 , 21 ] ) . Other games need players to have experience or technical abilities to take part . Bock et al . [ 4 ] , for example , describe the use of a king - of - the - hill style competition to help get students more involved in cyber security . Beckers and Pape [ 3 ] pro - duce a game that is perhaps the most similar to D - D . Their game challenges participants to explore the risks to a company , develop attacks and then rate them in terms of plausibility . However , their research does not explore the reasoning used by participants as they design and explore the risks associated with these attacks . Closely related to our work is a subset of research that explores decision - making during games , for example , Bornstein et al . [ 5 ] , who use the centipede game to explore whether individuals or groups are primarily concerned with winning . Their findings suggest that neither individuals nor groups are fully motivated by a desire to maximise payout during the game . However , they did find that groups were slightly more inclined to pursue greatest return . Xu et al . [ 41 ] suggest that there are five categories of social interaction that occur during board games : Reflection on gameplay , Strategies , Out - of - game , Game itself , and Chores . Reflection on game - play describes how teams react and reflect following a move . Strategies relate to the plans teams ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 26 B . Shreeve et al . devise before making a move . Out - of - game are those that occur but that indirectly related to the game . They note that the game itself can often form the centre of interactions—commenting on and reacting to the game itself . Finally , chores form a key part of gameplay—these are interactions such as learning the game rules , waiting to take turns , and moving physical parts of the game . Our analysis highlights a number of similar interactions—for example , the way that teams reflect and learn after an attack , how they learn about the way that the game is structured , and how they develop the model of understanding and ultimately arrive at a decision . Gladstein and Reilly [ 13 ] describe how group decision - making changes when made under pres - sure . They suggest that when teams encounter a change in circumstances or external threat then their ability to process information tends to alter , it becomes more constricted and teams tend to implement greater control measures . They become less flexible . Our analysis provides some re - lated insight into the differences in response to information consciously gained ( e . g . , where teams chose to invest in the threat assessment or asset audit ) and information gained unconsciously ( e . g . , as a result of an attack suffered . ) The majority of existing literature on cyber security decision - making emphasises methods for supporting decision - making , be it through tools [ 11 , 30 ] or financial methods of evaluating cy - ber security choices [ 6 , 23 ] . Our work has been motivated by a need to explore how managers with limited cyber security experience make cyber security decisions . Our research provides some clear validation for the work performed by Dor and Elovici [ 9 ] , where they asked participants to de - scribe cyber security investment decision - making processes they had encountered . Our grounded approach attempts to capture the decision - making process itself . Compared with Frey et al . [ 12 ] , who devised and tested D - D , we used different methods to analyse the data from the D - D sessions , such as grounded theory and goal modelling . Furthermore , we have used a different dataset , fo - cusing on managers from the same organisation . Our method complements their observations of team decision - making behaviours during D - D , since our grounded analysis , in combination with the presented goal model , provides a greater level of insight into the underlying socio - cognitive process of decision - making , and the goals that are being considered during that process . It allowed us to develop a model of cyber security reasoning by studying the dialogue of the teams , which pro - vide valuable insight into the way senior managers make cyber security decisions when they have relatively little knowledge or training in the subject matter . The model of cyber security reasoning builds on the work in Shreeve et al . [ 33 ] that uses speech - act theory to explore the way that dia - logue develops during the games reported in the paper by Frey et al . [ 12 ] . By applying a grounded theory approach to a dataset comprising only managers from the same organisation we are able to derive a better understanding of how decision - making occurs . Our findings complement the work by Shreeve et al . [ 34 ] , which explores whether 948 players from different backgrounds make significantly different decisions to one another during D - D . They suggest that no particular player background performs any better than any other ( e . g . , cyber security specialists vs . managers ) . This supports the findings in this article , that non - cyber security specialists are capable of evaluating cyber - security risk . 6 DISCUSSION In this article we have explored the decision - making of senior managers as they play through a cyber security exercise . We have shown how important it is to not only understand their decision - making from a goal orientated perspective ( what they identify as goals and how these could be operationalised ) but also to explore the nuances that affect the socio - cognitive process of collec - tive decision - making ( how and why they make their decisions ) . We have identified three important contributions to our understanding of cyber security decision - making . These can be used in com - bination as the first steps toward an enriched goal - modelling approach ( see Figure 10 ) . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 27 Fig . 10 . Enriched goal - modelling approach . The enriched goal - modelling approach should help practitioners realise the importance of shared understanding of security goals , that is , establishing and maintaining a goal model rep - resenting the organisations current cyber security goals . This could be achieved practically by associating the development and maintenance of a goal model with pre - existing organizational processes that capture similar information . For example , project meeting minutes that capture actions and decisions could be used to help develop and maintain a goal model . Alongside this , and to help them finding a way in the dark , organisations should establish a decision - log that captures how the goal model has been developed and the reasoning behind it , as well as changes to the reasoning over time . Capturing how one iteration of the goal model differs from another and why places these goal models and decision logs at the core of requirements decision - making and tracing process . Used in combination , these two assets empower non - technical and technical decision - makers alike to better appreciate the context in which cyber security decisions are being made , potentially prompting the identification of new ideas and understanding . The effectiveness of goal models is entirely dependent on their maintenance . The enriched goal - modelling approach encourages an iterative relationship between the goal model and decision - log . Integrating the de - velopment of these into existing organisational processes increases both the utility of the goal model and decision logs and the ease with these can be maintained . Future work should set out to explore how best to integrate the development of a goal model with existing organisational processes and to identify what such a decision - making log should look like and how it should function—for example , what sort of information would it need to include and how should it be recorded . Importance of shared understanding of security goals . The interactions between individ - uals and the team are central to the teams decision - making . However , the understanding of each individual is distinct from that of the team , and this understanding is forever changing as new in - formation is found . As individuals interact , they begin to share their knowledge , hypotheses , and concerns , as well as their main security goals , with the rest of the team . The team then works to es - tablish the relative value of each of these contributions . In sharing this information and evaluating the information provided by others , individuals are able to refine their own model of understanding . Furthermore , the group also begins to develop the shared model of understanding and a common set of goals , which ultimately informs the final course of action . Sometimes , it may happen that an individuals model of understanding is misaligned with that of the team . In this case , the prac - tical advice would be for organisations to develop a security culture where team members feel that they are able to readily express their concerns , queries , and ideas , without any ramifications , as it happened in the D - D sessions . In doing so , a wider range of information can be exchanged and evaluated , increasing the chance that an optimum decision is made . Fundamentally , our work ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 28 B . Shreeve et al . suggests that interaction during decision - making is a good thing , with greater levels of interac - tion aiding the teams to explore as many scenarios as possible . There is a clear link between the effectiveness of these discussions and organisational culture : If individuals feel that they are able to contribute without fear of judgement or retribution , then an even greater range of ideas may be explored . Yet this is not to say that the answer is just to explore an infinite number of ideas , since there will always come a point of diminishing returns , where action has to occur and the exploration needs to stop . Takeaway 1 : It is important that a goal model is maintained as a shared , ongoing understanding about security goals and their operationalisations . This should be updated as threats change , new requirements emerge or new incidents happen . Such a model will help teams visualise the current shared model of understanding , making it easier for team members to recognise when their own perspective differs from that of the team , encouraging them to contribute their interpretation and understanding of the situation . Finding a way in the dark . There are striking similarities between many of the decision - making characteristics demonstrated by the teams in our study and the underlying sensemaking theory . In particular , we are able to demonstrate how teams develop their understanding over time through a series of iterations , working to identify and evaluate new information and main goals , as well as potential actions . Furthermore , we note how the process of decision - making is highly re - liant on teams being able to recognise that some piece of information or action is key , or that some goals are more important than others , while Starbuck and Milliken [ 37 ] note that successful exec - utives are particularly adept at noticing subtle changes in their environment and triggering sense - making . These similarities between the sensemaking theory , the model of understanding , and the goal model help to provide some validation for our analysis . More importantly , our work suggests that managers are able to use logic to make reasoned cyber security decisions , without needing extensive cyber security experience . Their methods are very similar to those advocated by cyber security – specific best practice , such as NIST 800 - 61 Revision 2 [ 25 ] and ISO 27035 - 1 : 2016 [ 17 ] . It is important to note that this does not mean that managers can make all cyber security decisions . Instead , it appears that within the confines of a cyber security decision - making exercise , managers are still able to make decisions in the same way that they would make any other risk - related de - cision . However , in the real world there are many other factors that will come into play , and the context is likely to be sufficiently complex that managers will need to call on cyber security experts to help provide valuable information and evaluation . Their propensity for making risk - related de - cisions every day is particularly useful . However , in terms of a practical application , there is an argument to be made for teaching decision - makers about decision - making theory . An appreciation that the decision - making is an ongoing and transient process may encourage decision - makers to explore a wider range of information before making their choices . In this way , they may increase the chance of identifying an optimum decision . Nonetheless , the authors fully acknowledge that there are often time , resources , or other constraints that can affect the amount of consideration available to decision - makers . We would , however , stress that a greater appreciation of the underly - ing theory might help decision - makers to explore a wider array of possibilities and explore more information by being increasingly aware of their own biases . Takeaway 2 : Organisations should establish a decision - log capturing how and why security goals and operational - isations have changed . This could mean developing a framework at an organisational level . This not only facilitates traceable decision - making of security requirements and goals , but also provides context for the live goal - model iden - tified in takeaway 1 . Context is key . In the early stages of the game , teams set out to both increase their contextual understanding , through investment in new sources of intelligence , and to identify and mitigate what they consider to be the biggest threat at the earliest opportunity . It seems likely that teams ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 29 gravitate toward these particular choices , because they are the cyber security defences that they have heard of or with which they have experience . Our findings suggest that managers inform their cyber security decision - making by gathering and developing information about the context within which the decision is being made . They then use this contextual information to help to define the goals they what to achieve , which help them prioritise the actions available to them . They make extensive use of what - if style risk analysis to help them weigh up the potential consequences of selecting ( or not ) a particular course of action . Finally , they are constrained by the finite resources available to them and have to take this into account when analysing potential actions . This scenario also happens in the real world , where the resources , whether time , money , or people , are also limited . The majority of decision - making is driven by a particular goal or a need for action toward that goals . Within a cyber security context this often relates to identification of and triaging of cyber incidents [ 17 , 25 ] . This is reflected in the goal model of team decision - making during D - D . Teams tend to categorise their goals and the associated actions available to them in terms of human errors prevented and unauthorised access prevented . These goals relate directly to actions available to the teams and reflect the design of the D - D exercise . Furthermore , our analysis suggests that teams consider cyber security investments necessary to overcome two key shortcomings : a failure on the part of operators using the system or a failure on the part of the system itself . The managers playing the game often use these categories to help them evaluate investment decisions . This distinction is interesting given the fact that lots of the technical failures that they are considering ( e . g . , a lack of patching ) can often be traced back to a problem with the operator ( in this case , poor systems maintenance ) . This distinction is often found in the real world with organisations attempting to negate the impact of operator error through large - scale cyber security training , the effectiveness of which is often questionable . Negating technical failures is then generally passed on to the organisations’ IT teams ( or provider ) to address . Our experience from running the exercise is that non - technical individuals are perfectly capable of appreciating the need for these technical interventions and that perhaps a stronger cyber security cultural shift is possible within many organisations . Takeaway3 : Non - cybersecurityexpertscanstartthinking aboutcybersecurityriskbyconsidering therisks thatcan be introduced by human error or failure within a system itself . Through this simple reasoning teams can develop their initial cyber security goal model based on their current context ( as per takeaway 1 ) whilst capturing their reasoning ( takeaway 2 ) . 7 CONCLUSION This article has set out to explore the underlying decision process that enables managers with little technical experience to make important ( often technical ) cyber security decisions . Our analysis of their reasoning has resulted in two models that demonstrate how individuals within a team share information and ideas to derive an understanding of potential actions avail - able . These actions are themselves evaluated using risk thinking , budgetary limitations , and secu - rity goals to identify which actions to take in which order . Our findings support the notion that managers with limited cyber security experience are capable of making reasoned cyber security choices . However , we would speculate that in the real world such managers would benefit from an increase in cyber security knowledge ( e . g . , abridged specialist training ) and by including indi - viduals with a greater understanding of cyber security within their teams , who are able to provide further detail and knowledge during decision - making . Our method demonstrates the benefits of using a grounded theory analysis to create a goal model of management decision - making and a model of cyber security reasoning . Together , the models can better capture the socio - cognitive processes in cyber security decision - making . This ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 30 B . Shreeve et al . offers a real benefit for practitioners , because they are able to capture the tension that exists be - tween the goal - oriented thinking at the organisational level and the way that the decision - makers backgrounds and experiences affect the decision - making process . With our enriched goal model approach , non - cyber security experts can develop their cyber security model based on their current context ( and update it when new requirements appear or new incidents happen ) , whilst capturing their reasoning at every stage . Further work is necessary to explore whether managers from other organisations and sectors demonstrate similar decision - making whilst playing D - D . To help understand whether these find - ings are generalizable , future work could study teams both as they play D - D and within their working environment . This would facilitate the comparison of exercise and real - world decision - making approaches within the same teams . Another important topic is to understand the extent to which cultural factors affect the decision - making process . We would suggest that organisations work to develop a cyber security culture where all team members ( regardless of hierarchical posi - tion or cultural background ) feel comfortable with sharing their concerns and ideas—it is only by sharing and discussing ideas that new ( and better ) ideas can be explored . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 8 ACKNOWLEDG E MENTS This paper received funding from the Engineering and Physical Sciences Research Council ( EPSRC ) , with the following funder grant numbers : EP / M002780 / 1 , EP / P011799 / 2 How Managers Make Cyber Security Decisions 83 : 31 APPENDIX A COMPLETE GOAL MODEL In Figure 11 we present the complete iStar 2 . 0 SR model , derived from the discussion and choices made by all seven management teams while playing the game . Fig . 11 . Goal model of management decision - making . ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . 83 : 32 B . Shreeve et al . REFERENCES [ 1 ] CCDCOE . CCDCOE Locked Shields Exercise . 2021 . Retrieved from https : / / ccdcoe . org / exercises / locked - shields / . [ 2 ] Steven Alter . 2013 . Work system theory : Overview of core concepts , extensions , and challenges for the future . J . Assoc . Inf . Syst . ( 2013 ) , 72 . [ 3 ] Kristian Beckers and Sebastian Pape . 2016 . A serious game for eliciting social engineering security requirements . In Proceedings of the IEEE 24th International Requirements Engineering Conference ( RE’16 ) . IEEE , 16 – 25 . [ 4 ] Kevin Bock , George Hughey , and Dave Levin . 2018 . King of the hill : A novel cybersecurity competition for teach - ing penetration testing . In Proceedings of the USENIX Workshop on Advances in Security Education ( ASE’18 ) . USENIX Association , 9 . [ 5 ] Gary Bornstein , Tamar Kugler , and Anthony Ziegelmeyer . 2004 . Individual and group decisions in the centipede game : Are groups more “rational” players ? J . Exp . Soc . Psychol . 40 , 5 ( 2004 ) , 599 – 605 . [ 6 ] Huseyin Cavusoglu , Birendra Mishra , and Srinivasan Raghunathan . 2004 . A model for evaluating IT security invest - ments . Commun . ACM 47 , 7 ( 2004 ) , 87 – 92 . [ 7 ] Fabiano Dalpiaz , Xavier Franch , and Jennifer Horkoff . 2016 . iStar 2 . 0 Language Guide . Retrieved from https : / / arxiv . org / abs / 1605 . 07767v3 . [ 8 ] Tamara Denning , Adam Lerner , Adam Shostack , and Tadayoshi Kohno . 2013 . Control - alt - hack : The design and eval - uation of a card game for computer security awareness and education . In Proceedings of the Conference on Computer and Communications Security ( CCS’13 ) . ACM , 915 – 928 . https : / / doi . org / 10 . 1145 / 2508859 . 2516753 [ 9 ] Daniel Dor and Yuval Elovici . 2016 . A model of the information security investment decision - making process . Comput . Secur . 63 ( 2016 ) , 1 – 13 . [ 10 ] GolnazElahiandEricYu . 2007 . Agoalorientedapproachformodelingandanalyzingsecuritytrade - offs . In Proceedings of the International Conference on Conceptual Modeling . Springer , 375 – 390 . [ 11 ] Katheryn A . Farris , Ankit Shah , George Cybenko , Rajesh Ganesan , and Sushil Jajodia . 2018 . Vulcon : A system for vulnerability prioritization , mitigation , and management . ACM Trans . Priv . Secur . 21 , 4 ( 2018 ) , 16 . [ 12 ] Sylvain Frey , Awais Rashid , Pauline Anthonysamy , Maria Pinto - Albuquerque , and Syed Asad Naqvi . 2017 . The good , the bad and the ugly : A study of security decisions in a cyber - physical systems game . IEEE Trans . Softw . Eng . ( 2017 ) . [ 13 ] Deborah L . Gladstein and Nora P . Reilly . 1985 . Group decision making under threat : The tycoon game . Acad . Manage . J . 28 , 3 ( 1985 ) , 613 – 627 . [ 14 ] Barney G . Glaser and Anselm L . Strauss . 1967 . The Discovery of Grounded Theory : Strategies for Qualitative Research . Aldine de Gruyter , New York . [ 15 ] Daniel Goleman . 1985 . Vital lies . Simple Truths ( 1985 ) , 34 – 36 . [ 16 ] Mark Gondree and Zachary N . J . Peterson . 2013 . Valuing security by getting [ d0x3d ! ] : Experiences with a network security board game . In Proceedings of the 6th Workshop on Cyber Security Experimentation and Test . USENIX , 8 . [ 17 ] ISO . 2016 . ISO 27035 - 1 : 2016 : Information Technology—Security Techniques—Information Security Incident Management . Standard . International Organization for Standardization . [ 18 ] ISO / IEC . 2013 . ISO / IEC 27001 . Technical Report . [ 19 ] ISO . 2016 . ISO / IEC FDIS 25023 : 2016 ( E ) Standard : Systems and Software Engineering—Systems and Software Quality Re - quirements and Evaluation ( SQuaRE ) —Measurement of System and Software Product Quality . ISO , Geneva , Switzerland . [ 20 ] Tyler Moore , Scott Dynes , and Frederick R . Chang . 2015 . Identifying How Firms Manage Cybersecurity Investment . Technical Report . Darwin Deason Institute for Cybersecurity , Southern Methodist University . [ 21 ] John R . Morelock and Zachary Peterson . 2018 . Authenticity , ethicality , and motivation : A formal evaluation of a 10 - week computer security alternate reality game for CS undergraduates . In Proceedings of the USENIX Workshop on Advances in Security Education ( ASE’18 ) . USENIX Association , 11 . [ 22 ] Haralambos Mouratidis and Jan Jurjens . 2010 . From goal - driven security requirements engineering to secure design . Int . J . Intell . Syst . 25 , 8 ( 2010 ) , 813 – 840 . [ 23 ] National Buraeu of Standards , Federal Information Processing Standards Publications ( FIPS PUB ) 65 . 1975 . Guideline for Automatic Data Processing Risk Analysis . [ 24 ] JamesNicholson , LynneCoventry , andPamBriggs . 2018 . Introducingthecybersurvivaltask : assessingandaddressing staff beliefs about effective cyber protection . In Proceedings of the 14th Symposium on Usable Privacy and Security ( SOUPS’18 ) . 443 – 457 . [ 25 ] NIST . 2012 . NIST 800 - 61 Revision 2 : Computer Security Incident Handling Guide . Standard . National Institute of Stan - dards and Technology . [ 26 ] Ebenezer A . Oladimeji , Sam Supakkul , and Lawrence Chung . 2006 . Security threat modeling and analysis : A goal - orientedapproach . In Proceedingsofthe10thIASTEDInternationalConferenceonSoftwareEngineeringandApplications ( SEA’06 ) . Citeseer , 13 – 15 . [ 27 ] HolgerPeine , MarekJawurek , andStefanMandel . 2008 . Securitygoalindicatortrees : Amodelofsoftwarefeaturesthat supports efficient security inspection . In Proceedings of the 11th IEEE High Assurance Systems Engineering Symposium . 9 – 18 . https : / / doi . org / 10 . 1109 / HASE . 2008 . 57 ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 . How Managers Make Cyber Security Decisions 83 : 33 [ 28 ] Joao Pimentel and Jaelson Castro . 2018 . Pistar tool—A pluggable online tool for goal modeling . In Proceedings of the IEEE 26th International Requirements Engineering Conference ( RE’18 ) . IEEE , 498 – 499 . [ 29 ] Christophe Ponsard , Gautier Dallons , and Philippe Massonet . 2016 . Goal - oriented co - engineering of security and safety requirements in cyber - physical systems . In Proceedings of the International Conference on Computer Safety , Reliability , and Security . Springer , 334 – 345 . [ 30 ] Loren Paul Rees , Jason K . Deane , Terry R . Rakes , and Wade H . Baker . 2011 . Decision support for cybersecurity risk planning . Decis . Supp . Syst . 51 , 3 ( 2011 ) , 493 – 505 . [ 31 ] Daniel M . Russell , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . The cost structure of sensemaking . In Pro - ceedings of the Conference on Human Factors in Computing Systems . ACM Press , New York , NY , 269 – 276 . [ 32 ] Adam Shostack . 2014 . Elevation of privilege : Drawing developers into threat modeling . In Proceedings of the USENIX Summit on Gaming , Games , and Gamification in Security Education ( 3GSE’14 ) . [ 33 ] Benjamin Shreeve , Joseph Hallett , Matthew Edwards , Pauline Anthonysamy , Sylvain Frey , and Awais Rashid . 2020 . “So if Mr Blue Head here clicks the link . . . ” : Risk thinking in cyber security decision making . Trans . Priv . Secur . 24 , 1 ( November 2020 ) , 29 . https : / / doi . org / 10 . 1145 / 3419101 [ 34 ] Benjamin Shreeve , Joseph Hallett , Matthew Edwards , Kopo Marvin Ramokapane , Richard Atkins , and Awais Rashid . 2020 . The best laid plans or lack thereof : Security decision - making of different stakeholder groups . IEEE Trans . Softw . Eng . ( 2020 ) . https : / / doi . org / 10 . 1109 / TSE . 2020 . 3023735 [ 35 ] Benjamin Shreeve and Awais Rashid . Decisions & Disruptions . Retrieved January 2022 from https : / / www . decisions - disruptions . org / . [ 36 ] Dag I . K . Sjøberg , Tore Dybå , Bente C . D . Anda , and Jo E . Hannay . 2008 . Building theories in software engineering . In Guide to Advanced Empirical Software Engineering , 312 – 336 . [ 37 ] William H . Starbuck and Frances J . Milliken . 1988 . Executives’ perceptual filters : What they notice and how they make sense . In The Executive Effect : Concepts and Methods for Studying Top Managers , Frances J . Milliken and William H . Starbuck ( Eds . ) . 33 – 65 . [ 38 ] Rock Stevens , Daniel Votipka , Elissa M . Redmiles , Colin Ahern , Patrick Sweeney , and Michelle L . Mazurek . 2018 . The battle for New York : A case study of applied digital threat modeling at the enterprise level . In Proceedings of the 27th USENIX Security Symposium ( USENIX Security’18 ) . USENIX Association , Stanford , CA , 621 – 637 . [ 39 ] Anselm L . Strauss and Juliet M . Corbin . 1998 . Basic of Qualitative Research : Techniques and Procedures for Developing Grounded Theory . Sage . [ 40 ] Karl E . Weick . 1995 . Sensemaking in Organizations . Vol . 3 . Sage . [ 41 ] Yan Xu , Evan Barba , Iulian Radu , Maribeth Gandy , and Blair MacIntyre . 2011 . Chores are fun : Understanding social play in board games for digital tabletop game design . In Proceedings of the Digital Games Research Association Inter - national Conference ( DiGRA’11 ) . [ 42 ] Eric Yu . 1995 . Modelling Strategic Relationships for Process Reengineering . Ph . D . Dissertation . University of Toronto , Canada . [ 43 ] YijunYu , HaruhikoKaiya , HironoriWashizaki , YingfeiXiong , ZhenjiangHu , andNobukazuYoshioka . 2008 . Enforcing a security pattern in stakeholder goal models . In Proceedings of the 4th ACM Workshop on Quality of Protection . 9 – 14 . Received 16 March 2021 ; revised 11 May 2022 ; accepted 20 June 2022 ACM Transactions on Software Engineering and Methodology , Vol . 32 , No . 4 , Article 83 . Pub . date : May 2023 .