The $ Human $ Factors $ of $ Intelligence $ Analysis $ CHAIR Nathan J . McNeese , Arizona State University PANELISTS Robert R . Hoffman , Institute for Human and Machine Cognition Michael D . McNeese , The Pennsylvania State University Emily S . Patterson , The Ohio State University Nancy J . Cooke , Arizona State University Gary Klein , MacroCognition LLC Intelligence analysis ( IA ) has long been a topic of interest for the human factors community , leading to an increased understanding of the analytical process and many new insights . Yet , the scope and breadth of IA is growing and evolving for many different reasons . IA is more dynamic and multi - faceted than it has ever been . The process of IA is changing due to expanding sensor data , new methods of work , new technologies , and new challenges . In addition , the scope and context of IA is greater than ever , including focuses such as healthcare , climate change , and cyber security ( to name a few ) . In response to these changes , a few key questions emerge . Panel discussants will provide insights into how IA is changing , how researchers should adapt to this change , how researchers should acquire access to study IA , and if there are there underlying assumptions and themes of IA that are true across different domains . INTELLIGENCE ANALYSIS What is Intelligence Analysis ? Intelligence analysis is the process of “making inferences from available data” ( Trent , Patterson , & Woods , 2007 ) . This analytical process occurs in a highly cognitive work domain , dependent on the synthesis of similar and disparate information at an individual and / or team level . Many have argued that IA is a sensemaking activity ( Pirolli & Stewart , 2005 ; Baber et al . , 2013 ) . Due to the cognitive demands associated with IA , the Human Factors community has focused on this context and developed a greater understanding of the actual processes associated with IA . Much of the understanding of IA within Human Factors has been a direct result of multiple cognitive task analysis ( CTA ) . A very brief review of IA related CTAs have found : 1 ) analysts’ work does not focus on decision - making ( Hutchins , Pirolli , & Card , 2003 ) , 2 ) the importance of multiple sources of information and teamwork ( Connors et al . , 2004 ) , 3 ) the importance of storytelling and acknowledging biases ( Pirolli & Stewart , 2005 ) , 4 ) the importance of decision support ( Elm et al . , 2005 ) , and 5 ) designing for effective Human Factors driven technology . Key Questions for Panelists • ! What are the biggest current challenges for intelligence analysis ? • ! What are the biggest current challenges for studying intelligence analysis ? • ! How has intelligence analysis changed in the past 10 years ? • ! Are there themes or findings that are transferable across different contexts of IA - healthcare , terrorism , climate change , etc ? • ! Is human factors the right community to study IA ? • ! Where does human factors stand to make the biggest contribution to intelligence analysis right now and in the future ? PANELIST 1 : ROBERT R . HOFFMAN INTELLIGENCE ANALYSIS AND APPLIED EXPERIMENTAL PSYCHOLOGY Current challenges in intelligence analysis include matters of organizational psychology , especially morale issues and the impact of policy constraints . These have been manifest in many of the cognitive task analysis ( CTA ) procedures that I have conducted . Indeed , bias in analytical products is as often due to imposed policy as it is to so - called cognitive bias . Furthermore , the emphasis in recent funded programs on bias mitigation via structured analysis is highly demotivating . The reason is the two basic premises of the programs , that : ( 1 ) cognitive bias is inescapable even for experts , and ( 2 ) some single analytical process will suit all analysts irrespective of their cognitive style . We actually still lack convincing empirical evidence about the nature and extent of bias in intelligence analysis . Experimental psychologists / human factors researchers could contribute here . There are dozens of distinct analytical roles and specializations within the general profession of intelligence analysis . The profession offers many interesting possibilities for the study of the development of proficiency , critical thinking , perceptual skills , and other fundamental cognitive processes ( Hoffman , et al . , 2011 ; Moore and Hoffman , 2011 a , b ) . It would be wise to escape what seems to be an assumption in Human Factors that all intelligence analysis is what might be called " all source analysis " . Proceedings of the Human Factors and Ergonomics Society 59th Annual Meeting - 2015 130 C op y r i gh t 2015 H u m a n F a c t o r s and E r gono m i cs S o c i e t y . D O I 10 . 1177 / 1541931215591027 Another current challenge to intelligence analysis is also a challenge for Human Factors : Coping with the flood of new technologies that are not designed using a human - centered or work - centered philosophy . There are two actionable paths here . One is for cognitive systems engineers to demonstrate and document the value of CTA—and the costs of not doing CTA—in dollar units . The second actionable path is to hammer relentlessly on the root cause of bad technology : The government - mandated procurement process . Current policy requires that procurements be accompanied by a human factors evaluation . That is terribly weak . If the policy were " All software deliverables will be accompanied by convincing empirical evidence that the tools are usable , useful , and understandable , " then many things would change over night . There is a role for academic experimental psychologists who wish to study high - end reasoning or cognitive processes . Economics is perhaps the best analog domain because the ostensive primary task goals involve anticipating individual or aggregate human activity . Other proposed analog domains , such as medical reasoning , are not a best choice . I mention the study of analog domains because a major hurdle for researchers is to obtain a security clearance . Unless and until a human factors scientist has a high level clearance , genuine CTA will not be possible . And as a consequence , no headway could be made against the wind : " If it is not made here , we will not use it . " An alternative actionable path is to establish a collaboration with Information Technology and Security in the commercial sector . Another path is to establish a collaboration with one of the colleges that offer degrees in intelligence analysis . Indeed , I would recommend that human factors scientists who want to explore this domain start by taking some courses at one of the colleges . As I have argued for decades , the CTA researcher must be an " expert apprentice , " and have the time , resources and motivation to learn to conduct the domain tasks at least at the level of the senior apprentice . Most bandwagons eventually catch fire . Unless human factors scientists actually learn to conduct the work that they are wanting to improve , our presentations within our community of practice about experiments conducted in our academic laboratory will have limited impact , however much value they might have for science or its applications . Bio : Dr . Hoffman is currently a Senior Research Scientist at the Florida Institute for Human & Machine Cognition . He is a recognized world leader in cognitive systems engineering and Human - Centered Computing . He is a Fellow of the Association for Psychological Science , Fellow of the Human Factors and Ergonomics Society , Senior Member of the American Association for Artificial Intelligence , and a Fulbright Scholar . His Ph . D . is in experimental psychology from the University of Cincinnati , where he received McMicken Scholar , Psi Chi , and Delta Tau Kappa Honors . PANELIST 2 : MICHAEL D . MCNEESE INTELLIGENT ANALYST WORK AS SOCIALLY DISTRIBUTED COGNITION It has been 30 years since I began research and analysis in USAF command , control , communications , and intelligence work ( C 3 I ) . Clearly the planet has undergone vast change radically transforming human interaction with data , information , and the environment . The ecological relationships resident in transformation has spawned new emergent properties that continuously redefine how mindfulness is embodied within and without socially distributed cognition . This has created a ubiquitous world filled with drastically changed inter - action between the affordances offered by the environment and the effectiveness available within an actor or agent . In turn , the meaning , role , and prescription of ‘intelligence’ and how it can be analyzed requires reexamination . The typical approach to intelligent analyst work focuses on an isolated , individual analyst , inundating with sophisticated ( but often unusable ) tools , which ignore the context of use . If human factors has even been applied in this domain it typically represents a traditional approach that addresses individuals only , produces premature closure aimed at usability issues , and is highly limited owing to the lack of access to classified materials . This approach is inadequate given the high level of interdependencies and interconnectedness that represents ‘intelligence’ activities in socially distributed cognitive worlds . The patterns of the future are becoming extremely complex , ensconced in big data , quickly change and lack resiliency , and have challenging temporal cycles . They are integrated and intertwined within deep layers of the social milieu ( events , information , technology , people , sensors , objects , and context ) . We can see this through examples such as the Boston Marathon bombings , the spread of Ebola ( and the use of diseases as terrorist attacks ) , and how cyber - physical systems will undoubtedly populate climatology ( e . g . , the natural gas exploitation ) , remote - medical practices ( robotic surgery ) , and other domains , which yield new meanings to intelligence work . Potentially , every person is a sensor that has capabilities to gather information ( video , audio , images ) and tweet messages through mobile devices from anywhere at anytime . Concomitantly , web computing makes information seeking and access to distributed remote devices ( sensors , cameras , drones ) almost an afterthought . The role of crowdsourcing , citizen science , and the internet of things has to change our way of thinking about how to access and use patterns underlying intelligence work . The framing and approach of intelligent analyst collaborations needs new theories , analysis methods , and tools to understand much of the hidden knowledge and metadata that comprises intelligence . We have begun studying hidden knowledge as it impacts teamwork in distributed cognition especially under conditions of stress and temporal interdependence . Hidden knowledge will need to be distilled and analyzed through new methods such as machine learning of large data sets , social network analysis , and by traces of inter - action that together produce the new world of human actors engineering in social intelligence work . Bio : Michael McNeese is a Professor at the College of Proceedings of the Human Factors and Ergonomics Society 59th Annual Meeting - 2015 131 Information Sciences and Technology , The Pennsylvania State University , University Park , PA . His primary research foci include distributed cognition , socio - cognitive sciences , intelligent technologies , and interactive simulations . He was a Senior Scientist and Director of Collaborative Systems Technology at the USAF Research Laboratory prior to moving to Penn State in 2000 . He received his Ph . D . in Cognitive Science from Vanderbilt University and was a Visiting Professor at The Ohio State University , Department of Integrated Systems Engineering . Dr . McNeese has over 250 publications in diverse application domains including emergency crisis management ; fighter pilot performance ; human - computer interaction , trust and automation , command and control operations ; cyber - security ; intelligence and image analyst work ; information fusion , and aviation . PANELIST 3 : EMILY S . PATTERSON CRITICALLY ASSESSING ARCHETYPICAL NARRATIVES TO INCREASE PROCESS RIGOR In past research , we identified strategies for increasing the rigor of the process behind an analytic product . These strategies were derived from interviews with National Security Agency analysts where they were asked to compare and contrast two briefings on the same topic , the benefits and challenges of using liquefied natural gas as an energy resource in the United States . The strategies were : hypothesis exploration , information search , information validation , stance analysis , sensitivity analysis , specialist collaboration , information synthesis , and explanation critiquing . The strategy of information synthesis required an extensive knowledge of the domain knowledge in order to “boil down” what was learned into a description which was based upon how similar the insights were to insights typically described for ‘archetypical narratives’ . In the case of the liquefied natural gas example , an example of an archetypical narrative is one where the risks of explosion are magnified by stakeholders who are often biased towards alternative energy sources , potentially for reasons of financially profiting from other options . In contrast , another relevant archetypical narrative is that companies who desire to sell liquefied natural gas without having reasonable safety restrictions placed on them which would reduce their profits may under - estimate risks from transporting a potentially explosive substance . With both of these archetypical narratives , there is the potential for deceptive practices in “spinning” up or down risks as polarized stakeholder groups portray a “stance” towards a critical element of policy decisions . In a forthcoming paper ( Hilligoss et al . , 2015 ) , we have suggested how this dynamic plays out with physicians in the emergency department who “oversell” how sick their patients are in order to have a timely disposition into the hospital setting and with surgical physicians in the hospital setting who “underevalute” the risks of the same patient in order to “block” entry onto their units using “chart biopsies” where they independently evaluate the implications of objective data from the patient chart , particularly in the Surgical Intensive Care Unit ( SICU ) where resources are limited and beds are typically only made available by discharging current patients in the SICU to another hospital unit . Specifically , we recommended practices that have been employed at one hospital to improve transitions across units , action trajectories , negotiation context , structural context , and macro context . We will discuss whether these practices might be useful in the context of intelligence analysis . Bio : Emily S . Patterson , PhD , is an assistant professor in the Health Information Management and Systems ( HIMS ) Division of the School of Health and Rehabilitation Sciences ( HRS ) in the College of Medicine ( COM ) at the Ohio State University ( OSU ) . Her research interests are applying human factors knowledge and methods to improve patient safety and informatics applications . She serves on the editorial board of the Human Factors journal and as an editorial advisory board member for The Joint Commission on Quality and Patient Safety . She has served as a scientific advisor for The Joint Commission , the Society for Hospitalist Medicine , the National Board of Medical Examiners Center for Innovation , and the National Institute of Standards and Technology . PANELIST 4 : NANCY J . COOKE THE CHANGING CONTEXT AND DYNAMICS OF INTELLIGENCE ANALYSIS Whereas a substantial amount of intelligence analysis ( IA ) research has been conducted within human factors , the community must proactively work to stay up to date with current IA trends . As is true for many domains , the intelligence analysis task is changing . A new set of challenges coupled with new techniques and technology have changed the playing field . The first major change in intelligence analysis is that the breadth and scope of the domain is increasing . Intelligence analysis is now taking place in more contexts than ever before . Contexts like healthcare , cyber security , and climate change are now of paramount importance to intelligence analysis , whereas 10 years ago they were not . In addition , intelligence analysts must deal with more information than ever before . The advent of new hard and soft sensors throughout the world has resulted in analysts having to synthesize and make sense of more information than ever before . Also , intelligence analysis is demanding increased collaboration among analysts . Traditionally , intelligence analysis was conducted by individuals , and for the most part still is , but the importance and benefit of teamwork within this domain is being realized as the complexity of the problem space grows . Yet , there are significant issues that need to be addressed in order to answer these new questions . Specifically , in much of our work , we have been faced with limited or no access to analysts . It is fundamental that human factors researchers understand the work , context , and challenges of intelligence analysts before designing technologies or decision aids . An understanding of the work and context should motivate such technologies . This is usually easily available to human factors researchers , but in the intelligence analysis realm it is not . Proceedings of the Human Factors and Ergonomics Society 59th Annual Meeting - 2015 132 Another issue involves simulating the task in the laboratory environment . IA is so knowledge intensive that it is difficult to replicate in the lab with undergraduate participants . We have been identifying other domains that can serve as analogs . One possibility is prediction of box office revenues for movies based on data bases of movie information . Another direction is to develop a high fidelity cyber security environment that can be used in exercises by information assurance graduate students . Overall , the IA task is critical , interesting and challenging to study . Bio : Nancy J . Cooke is a professor and program chair of Human Systems Engineering at Arizona State University and is Science Director of the Cognitive Engineering Research Institute in Mesa , AZ . She is also currently the chair of the National Research Council’s Board on Human Systems Integration and currently chairs a study panel at the National Academies of Science on the Science of Team Science . Dr . Cooke’s research interests include the study of individual and team cognition and its application to the development of cognitive and knowledge engineering methodologies , cognitive task analysis , sensor operator threat detection , homeland security systems , remotely - operated vehicles , cyber security , intelligence analysis , human - robot interaction , healthcare systems , and emergency response systems . PANELIST 5 : GARY KLEIN MACROCOGNITIVE PERSPECTIVE ON INTELLIGENCE ANALYSIS The last ten years have brought significant changes to the field of Intelligence Analysis . The panel organizers have flagged several major challenges that have greatly increased the difficulty of doing IA . For example , the Big Data framework seeks to take advantage of the massive amounts of publicly available data now available . Unfortunately , the emphasis on using the available data may be distracting Intelligence Analysts from the work of making sense of the data . Worse , the effort of tracking trends may be rendering analysts vulnerable to inflection points when the trends no longer hold . Another challenge identified by the panel organizers is the set of cyber - security issues that make it likely that messages and data will be at least partially compromised . The challenge to Intelligence Analysts is to work effectively with partially corrupted systems . There is yet another challenge that emerged in the last decade : a shift in error tolerance that occurred following the 2003 Iraqi invasion , when no Weapons of Mass Destruction ( WMDs ) were found . The rationale for the Iraqi invasion was based on Saddam Hussein’s possession of WMDs . The intelligence community had made a large and public mistake . Ever since , the community has imposed tighter restrictions and critical thinking practices in order to avoid future blunders . Unfortunately , the severity of the safeguards may be hindering the process of gaining insights and making discoveries . The Human Factors community can make contributions to these challenges by providing better accounts of sensemaking in natural settings . Bio : Gary Klein , Ph . D . , author of Sources of Power : How people make decisions , and four other books plus three co - edited volumes , is known for the cognitive models he described , such as the Recognition - Primed Decision ( RPD ) model , the Data / Frame model of sensemaking , the Management By Discovery model of planning in complex settings , and the Triple Path model of insight , the methods he developed , including techniques for Cognitive Task Analysis , the PreMortem method of risk assessment , and the ShadowBox training approach , and the movement he helped to found in 1989 — Naturalistic Decision Making . The company he started in 1978 , Klein Associates , grew to 37 employees by the time he sold it in 2005 . He formed his new company , ShadowBox LLC , in 2014 . ACKNOWLEDGMENT Some of the material presented here was sponsored by Department of Defense and is approved for pubic release , case number : 15 - 315 . REFERENCES Baber , C . , Attfield , S . , Wong , W . , & Rooney , C . ( 2013 ) . Exploring sensemaking through an Intelligence Analysis exercise . In Proceedings of the 11th International Conference on Naturalistic Decision Making ( NDM 2013 ) , Marseille , France . Connors , E . S . , Craven , P . L . , McNeese , M . D . , Jefferson , T . , Bains , P . , & Hall , D . L . ( 2004 ) . An application of the AKADAM approach to intelligence analyst work . In Proceedings of the Human Factors and Ergonomics Society Annual Meeting ( Vol . 48 , No . 3 , pp . 627 - 630 ) . SAGE Publications . Elm , W . , Potter , S . , Tittle , J . , Woods , D . , Grossman , J . , & Patterson , E . ( 2005 , September ) . Finding decision support requirements for effective intelligence analysis tools . In Proceedings of the Human Factors and Ergonomics Society Annual Meeting ( Vol . 49 , No . 3 , pp . 297 - 301 ) . SAGE Publications . Hilligoss B . , Mansfield J . A . , Patterson E . S . , & Moffatt - Bruce , S . D . ( March 2015 ) Collaborating—or “Selling” Patients ? A Conceptual Framework for Emergency Department – to - Inpatient Handoff Negotiations . The Joint Commission Journal on Quality and Patient Safety 41 ( 3 ) , 134 - 143 . Hoffman , R . R . , Henderson , S . , Moon , B . , Moore , D . T . , & Litman , J . A . ( 2011 ) . Reasoning difficulty in analytical activity . Theoretical Issues in Ergonomic Science , 12 , 225 – 240 . Hutchins , S . G . , Pirolli , P . L . , & Card , S . K . ( 2007 ) . What makes intelligence analysis difficult ? A cognitive task analysis . In Expertise Out of Context : Proceedings of the Sixth International Conference on Naturalistic Decision Making ( pp . 281 - 316 ) . Psychology Press . Moore , D . T . and Hoffman , R . R . ( 2011a ) . Sensemaking : A transformative paradigm . American Intelligence Journal , 29 , 26 - 36 . Moore , D . T . and Hoffman , R . R . ( 2011b , November ) . " How mightcritical thinking and structured analytic techniques improve intelligence ? Or . . . " Presentation at the General Intelligence Training Council ( GITC ) / 5 Eyes Intelligence Conference : Collaboration and Innovation in Intelligence Training . Joint Base Anacostia - Bolling , Washington , DC . Pirolli , P . , & Card , S . ( 2005 ) . The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis . In Proceedings of international conference on intelligence analysis ( Vol . 5 , pp . 2 - 4 ) . Proceedings of the Human Factors and Ergonomics Society 59th Annual Meeting - 2015 133 Trent , S . A . , Patterson , E . S . , & Woods , D . D . ( 2007 ) . Challenges for cognition in intelligence analysis . Journal of Cognitive Engineering and Decision Making , 1 ( 1 ) , 75 - 97 . Zelik , D . J . , Patterson , E . S . , & Woods , D . D . ( 2010 ) . Measuring attributes of rigor in information analysis . Macrocognition Metrics and Scenarios : Design and Evaluation for Real - World Teams , 65 - 83 . Proceedings of the Human Factors and Ergonomics Society 59th Annual Meeting - 2015 134