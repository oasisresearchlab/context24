How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries ALLISON WOODRUFF , Google , USA RENEE SHELBY , Google , USA PATRICK GAGE KELLEY , Google , USA STEVEN ROUSSO - SCHINDLER , California State University , Long Beach , USA JAMILA SMITH - LOUD , Google , USA LAUREN WILCOX , Google , USA Generative AI is expected to have transformative effects in multiple knowledge industries . To better understand how knowledge workers expect generative AI may affect their industries in the future , we conducted participatory research workshops for seven different industries , with a total of 54 participants across three US cities . We describe participants’ expectations of generative AI’s impact , including a dominant narrative that cut across the groups’ discourse : participants largely envision generative AI as a tool to perform menial work , under human review . Participants do not generally anticipate the disruptive changes to knowledge industries currently projected in common media and academic narratives . Participants do however envision generative AI may amplify four social forces currently shaping their industries : deskilling , dehumanization , disconnection , and disinformation . We describe these forces , and then we provide additional detail regarding attitudes in specific knowledge industries . We conclude with a discussion of implications and research challenges for the HCI community . Additional Key Words and Phrases : generative AI , knowledge work , industries 1 INTRODUCTION On November 30 , 2022 , OpenAI released a demo of ChatGPT , a chatbot powered by a large language model ( LLM ) 1 . The chatbot’s impressive ability to converse and provide information immediately drew international attention , attracting over one million users in just a few days [ 102 ] . While LLMs had been under active development for several years , and build on technologies that have been researched and used for decades , ChatGPT’s release was heralded as a disruptive moment in which the general population , as well as many technologists , became aware of a significant leap in AI’s capabilities . Since then , the rapid uptake of generative AI systems such as ChatGPT [ 121 ] , Bard [ 2 ] , DALL · E [ 120 ] , Imagen [ 128 ] , and Midjourney [ 106 ] has been accompanied by striking narratives . These include discussion of its increased ability to perform complex tasks and predictions about how generative AI will disrupt knowledge industries ( industries such as law , journalism , software development , and more , in which workers apply knowledge gained through specialized training to engage in non - routine problem solving and develop products and services [ 79 ] ) . These narratives imagine generative AI as a resource that can automate much of the knowledge work currently done by humans , thus having detrimental effects on labor such as eliminating significant numbers of jobs across multiple industries [ 150 ] . However , while initial evidence points to productivity gains when generative AI is used for particular tasks [ 28 , 156 ] , much remains unknown regarding its future impact . This unique moment in the uptake of generative AI offers a timely opportunity to deeply consider expectations of its future use . To better understand how people anticipate generative AI may affect knowledge work in the future , we 1 An LLM is a machine learning model trained on large amounts of data ( e . g . , at the terabyte or petabyte scale ) , with model parameter estimates in the many billions , capable of generating well - structured and stylized natural language output in response to natural language input . 1 a r X i v : 2310 . 06778v1 [ c s . C Y ] 10 O c t 2023 Woodruff et al . conducted three - hour participatory research workshops for seven different knowledge industries , with a total of 54 participants across three US cities . Our contributions are as follows : • We present a novel qualitative study of how knowledge workers in seven professional fields—advertising , busi - ness communications , education , journalism , law , mental health , and software development—expect generative AI may affect their fields in the future . In particular , we explore perceptions of knowledge workers not only regarding how specific tasks or jobs might be automated or otherwise change , but also how and whether generative AI might more broadly shift the nature and structure of work in their industries . • We describe a dominant narrative regarding generative AI that participants across multiple knowledge industries envisioned , of generative AI as a tool to perform menial work under human review , and we also highlight unique perspectives from each industry . • We describe how specific social forces that participants are experiencing in their industries—in parallel to the development of generative AI—create a unique confluence of circumstances that frame participants’ expectations of generative AI’s impact as it intersects with social trends surrounding its deployment and use . In the remainder of the paper , we review relevant background , describe our methodology , present our findings , discuss implications and research challenges for the HCI community , and conclude . 2 BACKGROUND Our research examines knowledge workers’ perceptions of how generative AI will impact their fields . In this section , we provide background on generative AI technologies and knowledge work , as well as research at their intersection , and provide an overview of generative AI narratives as well as public perception of AI . 2 . 1 Generative AI Models Generative AI is a type of machine learning system that generates realistic and credibly human - like content ( e . g . , text , images , code , audio ) in response to an input . These systems are trained on web - scale databases and differ from conventional machine learning ( ML ) systems designed to function as expert systems , marking a shift in the purpose of ML from “problem solving to problem finding” [ 110 , p . 1 ] . The concept of generative AI dates to the 1950s when researchers began exploring the possibility of using computers to produce new content [ 90 , 129 ] . However , it was not until the 1990s and 2000s with further investment into neural networks , interconnected nodes that process and identify patterns from large datasets [ 111 ] , that the field of machine learning gained momentum . The beginning of the so - called “deep learning revolution " [ 111 , p . xxvii ] occurred in 2014 when Alex Krizhevsky and colleagues [ 91 ] used deep neural networks to win an ImageNet image classification challenge . Since then , researchers developed new kinds of neural networks that can generate novel content — including Generative Adversarial Networks [ 65 ] , Recurrent Neural Networks ( RNNs ) [ 107 ] , Variational Autoencoders ( VAEs ) [ 89 ] , and diffusion generation models [ 144 ] — marking technical advances that set the stage for generative AI’s growth . The next significant milestone occurred in 2017 with the development of the modern transformer architecture [ 151 ] that allows for parallelization in which computation is divided into smaller tasks that run simultaneously . Transformer architectures enable generation of detailed and realistic content , and remain the state - of – the - art for a range of generative tasks , including text [ 95 , 127 ] , image [ 47 , 96 ] , and code generation [ 119 ] ; and underpin so - called “foundation models” trained on massive datasets , such as LaMDA [ 148 ] , GPT [ 27 ] , and DALL · E [ 126 ] . The field of generative AI is rapidly evolving ; however , large language models ( e . g . , ChatGPT [ 121 ] , Bard [ 2 ] ) and text - to - image models ( e . g . , Midjourney 2 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries [ 106 ] , DALL · E 2 [ 120 ] , Stable Diffusion [ 3 ] ) are today’s popular modalities . Large language models process and generate text that can be used for a variety of applications , including question and answer interactions , language translation , chatbots , code and text generation , summarization , and language analysis . Text - to - image ( T2I ) systems allow users to generate photorealistic images from free - form and open - ended text prompts . While modalities differ , generative AI systems are marked by three key characteristics : ( 1 ) applicability to generalized rather than specialized use cases ; ( 2 ) production of original content that is often indistinguishable from human content ; and ( 3 ) intuitive and accessible interfaces [ 26 ] . 2 . 2 Knowledge Work Knowledge work 2 concerns specialized labor , the main capital of which is knowledge [ 61 ] ; knowledge workers apply theoretical and analytical knowledge gained through specialized training to engage in non - routine problem solving and develop products and services [ 79 , p . 878 ] . Knowledge work is a characteristic of post - industrial societies [ 30 ] in which capitalist production shifts towards technical knowledge [ 17 , 124 ] . In this way , knowledge work reflects the reconcentration of socioeconomic and political power into institutions that translate information resources into marketable commodities and services [ 108 ] . Knowledge work thus reframes workers as a “capital asset” and locates the responsibility for productivity on individual workers who have autonomy to determine how a particular task should be approached within particular boundaries [ 51 , p . 87 ] . The most defining characteristic of a knowledge worker is their possession of “knowledge , ” not necessarily completion of an education program [ 49 ] , although certain roles or fields may require licensure or credentials ( e . g . , attorneys , medicine ) . As such , knowledge work comprises professions that use information , data , or ideas as “raw material” for “planning , analyzing , interpreting , developing , and creating products and services” [ 72 , p . 511 ] . 2 . 3 Generative AI and the Future of Knowledge Work Generative AI’s ability to enable users to easily generate new content across generalized use cases raises questions about potential macroeconomic impacts on knowledge labor [ 54 ] . Unlike many previous innovations that have impacted physical work such as manufacturing or transportation , generative AI directly implicates professionalized knowledge work [ 26 ] . Discourse on this topic forms a Transformative Narrative —we discuss narratives further in Section 4 . 1— that suggests that generative AI will have substantial impact on knowledge industries . For example , Briggs et al . [ 26 ] identify thirteen kinds of knowledge work activities vulnerable to automation ( e . g . , gathering , organizing , analyzing , and interpreting information ) , estimating that approximately two - thirds of US occupations may experience disruption in how workers do their work . While more research is needed given the rapid pace of change in the field of generative AI , nascent work suggests potential disruption in creative work [ 43 ] , software engineering [ 157 ] , teaching and legal services [ 56 ] , customer service and healthcare [ 62 ] , and marketing [ 33 ] . Novice workers are likely to disproportionately benefit from efficiency increases for particular work tasks [ 116 ] . For instance , introduction of generative AI conversational assistants in customer service roles enhanced worker productivity , with disproportionate increases in the performance of novice customer service agents [ 28 ] . Economists anticipate that occupations experiencing significant automation will be offset by new job creation [ 26 ] , such as new roles to review and manage content created by generative AI systems [ 43 ] . However , appropriate investments in occupational change management are required [ 33 ] , including understanding worker perspectives , a goal that directly guided our participatory research . 2 The term “knowledge worker” was coined by Peter Drucker [ 50 ] in 1959 . 3 Woodruff et al . 2 . 3 . 1 Generative AI Impacts on Worker Tasks . HCI scholars are beginning to examine the impacts of generative AI on different kinds of work tasks . A dominant thread of research focuses on different writing tasks [ 63 , 130 , 138 , 142 , 162 , 164 ] , including marketing slogans [ 35 ] and storytelling [ 131 ] . Generative AI systems can significantly influence what topics users write about and how they are framed [ 78 ] . For instance , when people use a generative AI writing assistant ( e . g . , ChatGPT ) , they write more frequently about topics suggested by the system [ 123 ] . Writing suggestions made by generative AI systems also influence the tone and sentiment of communications [ 10 , 18 ] , including length and how generic the text is [ 11 ] . However , user experience of generative AI systems is not simply passive , but also involves cognitive work to negotiate machine - in - the - loop writing approaches [ 42 , 142 ] . As creative work is not necessarily outcome - focused , but process - focused , there remain gaps in our understanding of the impacts of generative AI in explicitly commodified labor contexts . An emerging thread of HCI scholarship has focused on potential impacts of generative AI on workers in profession - alized settings , examining potential professional impacts of generative AI , including how it may improve knowledge workers’ task efficiency [ 7 , 167 ] . A limited body of research has examined impacts on specific professional sectors , notably creative [ 44 , 68 , 77 ] and educational [ 5 , 85 , 100 ] domains . While some research suggests that , overall , creative professionals are not yet worried about generative AI - related job displacement , they did flag concerns related to wors - ening work quality , an erosion of the creative process , and training data copyright concerns [ 77 ] . Within the education domain , research has focused on how generative AI can support classroom teaching in terms of preparing course materials [ 100 , 135 ] and student learning outcomes [ 85 ] . However , there remains a dearth of research on generative AI’s impacts on professional industries , particularly outside of creative contexts . 2 . 4 Sensationalized Generative AI Narratives The rapid uptake of generative AI systems has been accompanied by a Sensationalized Narrative about how it will disrupt society and work . Building on previous AI narratives , it contains dramatic or even hyperbolic claims ( see critiques : [ 16 , 32 ] ) about topics such as AI sentience ( e . g . , [ 132 ] ) and labor displacement ( e . g . , [ 38 ] ) . Leading figures in AI have framed expectations in evocative terms ( e . g . , [ 104 ] ) , for example , likening AI to “new electricity” to emphasize the expectation that it will disrupt most or all industries [ 114 ] . The media , futurists , and others have also explored generative AI’s potential , pondering for example whether AI could “replace humans” [ 98 ] . Exaggerated claims about machine intelligence envision a global underclass of human workers supplanted by generative AI [ 80 ] , with one headline musing : “Could ChatGPT Write My Book and Feed My Kids ? ” [ 73 ] . While such narratives may draw on claims made by AI developers to predict a worse case scenario for knowledge work ( e . g . , [ 15 , 105 ] ) , they often incorporate evidence in misleading ways ( see critiques : [ 101 , 118 ] ) . Moreover , they rarely engage the perspectives of knowledge workers with expertise in their field . While some argue generative AI is at the peak of inflated expectations [ 45 , 154 ] , sensationalized AI narratives can narrow and close public debate [ 84 ] . In response to the hype cycle [ 81 ] , there have been calls for more measured narratives that create space for publics to meaningfully consider and grapple with the labor questions of generative AI [ 16 , 140 ] ) . This includes consideration of the specific ways generative AI may interact with different kinds of professional work [ 82 ] and also broader knowledge industry dynamics . 4 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries 2 . 5 Public Perception of AI Because the public’s awareness of generative AI is quite recent , little research has been done on public perception of it . However , a fair amount of research has been done on public perception of AI more generally , much of it survey - based [ 8 , 14 , 20 , 31 , 52 , 60 , 83 , 97 , 112 , 115 , 125 , 136 , 147 , 163 , 166 ] . Respondents typically expect AI will have a significant impact on the future , and often anticipate that beneficial effects are possible , with the most favorable impressions in emerging and / or Asian markets and more negative impressions ( particularly recently ) in Western countries such as the US [ 8 , 52 , 60 , 97 , 112 , 115 , 147 , 163 ] . At the same time , AI is neither interpreted as exclusively beneficial nor exclusively disadvantageous , and public response often indicates contradictory emotions [ 20 , 87 , 88 , 109 ] . Job loss ( especially related to robotics and manufacturing ) , increased social isolation , privacy and other social topics have been highlighted as key concerns [ 9 , 52 , 86 – 88 , 125 , 143 ] . In fact , a recent Pew survey found that , among the 37 % of US respondents who indicated they were “more concerned than excited” about the increased presence of AI in daily life , about one in five explicitly mentioned job loss as the main reason for their concern [ 125 ] . 3 METHODOLOGY To explore the expected impact of generative AI applications in knowledge industries , we conducted participatory research workshops with 54 participants from seven knowledge industries in three US cities . While our institution does not have an IRB , we adhere to similarly strict standards . Our research objectives were to learn more about the following : • How do knowledge workers expect generative AI will affect their industries ? • How do knowledge workers view generative AI in relationship to other changes they anticipate in their industry ? 3 . 1 Participants We recruited 7 - 8 participants from each of seven industries ( for 54 in total ) through Gemic , who worked with partners to arrange professional recruiting firms in each city . We chose a wide range of industries—advertising , business communications , education , journalism , law , mental health care , and software development—to elicit diverse perspectives . Approximately half of the participants in each workshop were mid - career central figures in their field , holding roles we expected would be well positioned to speak broadly about each industry , e . g . , teachers for education , reporters for journalism , and attorneys for law . The other half were more specialized , senior , or junior roles in each profession to introduce a greater diversity of perspectives . See Appendix , Table 4 . Screening also aimed to recruit a balanced mix of genders and half non - White participants in each workshop . All participants were compensated the same amount , at industry standard . For a summary of participant information , see Appendix , Table 5 . 3 . 2 Workshops Participatory workshops have a long methodological history in HCI , used frequently in participatory design engage - ments [ 70 , 94 , 133 , 149 ] , living labs [ 46 ] , hackerspaces [ 58 ] , and more . The participatory workshop as a research site and method has roots in participatory action research [ 37 ] . Inspired by participatory action research , we used participatory workshops to engage with specific communities of practice representing knowledge industries . Rather than focusing on a design process or future technological possibilities , our participatory approach centered on the elicitation of nuanced contextual information about each industry , participant perspectives , and generation of use cases for generative AI . This approach was grounded and situated in the participants’ expertise and experiences , and supported by conversation with 5 Woodruff et al . the researchers as experts familiar with technological capabilities and possibilities of generative AI . We thus structured our workshops to include participant - directed educational activities and a mix of probes and provocations to scaffold generative discussion . We held one workshop per industry in July 2023 3 in Columbus , Ohio ; New York City , New York ; and Oakland , California ( for industries in each city , see Appendix , Table 5 ) . These cities were selected as centers of activity for the respective industries , as well to represent a socio - geographic range . Each workshop was held in person for three hours at a third - party facility . Three to four researchers from Google and Gemic moderated each workshop to facilitate and share information about generative AI . Participants and researchers sat together around a large table to facilitate group discussion . Two videographers also attended each workshop and participants were aware that several researchers and staff were in an observation room or viewing remotely . Participants were aware of Google’s involvement in the study . We followed COVID - 19 precautions ( e . g . , all participants and moderators took tests during check - in ) , and refreshments were available throughout the workshops . Before the workshops began , we asked participants to draw a map of their industry as a short pre - work activity ( Appendix : Figures 1 and 2 ) . Workshops ran as shown in Table 1 . Activity Time Arrive , sign - in , COVID - 19 testing , Industry Map Welcome , Introductions , Prior Experience with Generative AI 15 minutes Generative AI Teaching and Q / A 40 minutes Meal Break 20 minutes Change Cards Activity 45 minutes Break 10 minutes Policy Activity and Voting 40 minutes Personal Impact and Wrap - Up 10 minutes Table 1 . Agenda for participatory research workshops . Times are approximate . We began with introductions and expectations for the workshop , and then invited participants to share any prior experiences or impressions of generative AI . We then gave a presentation to provide participants with a common working understanding of generative AI to ground the subsequent activities , allowing a generous amount of time to answer questions . The presentation included a brief overview of how generative AI models learn and generate content , how they differ from other AI models , and key characteristics and risks of generative AI ( Appendix B ) . After a meal break , we introduced participants to an artifact that we designed specifically for the workshop : a large , physical card that we term a change card that encourages participants to reflect on important changes that could happen in their industry in the next one to two years ; changes did not need to be related to generative AI ( Appendix : Figures 3 and 4 ) . Each participant spent about 10 minutes filling out their individual change card ( s ) . We then facilitated a group discussion in which participants shared one or more of their change card ( s ) and responded to each other’s ideas . Following another short break , we invited participants to write down the broad contours of a policy to guide the use of generative AI in their industry ( Appendix : Figures 5 and 6 ) . Participants were again given about 10 minutes to work individually before taking turns presenting their policies in a facilitated discussion . We followed the discussion with an 3 WorkshopstookplaceseveralmonthsaftertheMarch2023releaseofOpenAI’sGPT - 4model , whichisbroadlyconsideredtobeasignificantimprovement over the already impressive original November 2022 release . 6 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries exercise in which participants voted on which aspects of generative AI they find most helpful and most detrimental for their industry . After a brief discussion of this voting activity , in the final minutes of the workshop , participants were encouraged to speak about the potential impact of generative AI outside of their work . Throughout the workshops , we took care to encourage collaborative interpretation , problem - solving , and discussion among participants and moderators , and to make space for all participants to share their ideas and opinions . 3 . 3 Analysis All sessions were recorded and transcribed verbatim with an automated speech - to - text service , and we then manually corrected the transcripts against the original recordings . All artifacts ( 54 industry maps , 140 change cards , and 54 policies ) were collected and archived . We analyzed data from the corrected transcripts and artifacts inductively . Drawing on reflexive thematic analysis approaches [ 22 , 23 ] , four authors reviewed transcripts , in multiple configurations of paired and independent review , and one of these authors conducted comparisons with corresponding artifacts . These four authors engaged in deep and prolonged data immersion and discussion , independent open coding followed by memo writing to generate themes [ 19 ] , and engaged in collaborative discussions in multiple rounds to compare their interpretations of the data reflexively and finalize themes . 3 . 4 Limitations Several limitations of our study methodology should be considered when interpreting this work . First , it carries with it the standard issues attendant with qualitative methodologies and group interviews . We conducted the research in only three US cities with only one group per industry , and our small sample was not statistically representative of the roles or demographics of the professional fields we explored . Our findings should be viewed as a deep exploration of our participants’ perspectives on their industries , but should not be taken as generalizing to their industries as a whole . Second , our choice of teaching content and activities , while appropriate to our research objectives , may have influenced participants , although we tried to minimize any effects through participant - led discussion . Finally , while we confirmed our understanding of participants’ comments during the sessions , and one or more of the authors have experience in most of the industries represented , our interpretations may lack context or nuance that would have been more readily available to members of the same professional categories . 4 FINDINGS In this section , we present our findings . We begin by describing participants’ expectations of generative AI’s impact , including a dominant narrative that emerged across the groups . We then turn to four current social forces that shaped our participants’ perspectives on how generative AI will affect their industries : deskilling , dehumanization , disconnection , and disinformation . Finally , we describe some of the unique perspectives within particular knowledge industries . 4 . 1 Expected Impact of Generative AI In this subsection , we give an overview of participants’ perspectives on how generative AI may impact their industries . 4 We begin by briefly summarizing the participants’ dominant narrative regarding generative AI , which we term the Effort - Saving Tool Narrative ( see Table 2 ) . For ease of comparison , we also briefly summarize the Transformative 4 We note their perspectives were informed by content in the workshop as well as their prior exposure . Almost all participants had heard of generative AI or a specific generative AI system , e . g . , in the press or from colleagues , friends , or family . Many participants also had experience using an app , especially ChatGPT or Midjourney , at least lightly , for either personal purposes ( e . g . , writing a birthday card ) or professional purposes ( e . g . , drafting a memo ) . 7 Woodruff et al . Narrative and the Sensationalized Narrative introduced in Sections 2 . 3 and 2 . 4 , respectively . We introduce these narratives to situate participant data against extant meaning - making discourses , in alignment with reflexive thematic analysis [ 24 , p . 211 ] . In the remainder of this subsection , we describe the Effort - Saving Tool Narrative in more detail . 4 . 1 . 1 Generative AI can automate menial work : “We need to just churn it out” . While a wide range of possible use cases were discussed , our participants’ experience , imagination , and preference centered on the use of generative AI for menial tasks . They characterized these as routine and / or formulaic tasks that they thought could easily be automated , or which they had actually tried in apps like ChatGPT , such as drafting social media content , troubleshooting tickets , leading guided breathwork sessions , or creating lesson plans . “For the tasks that I find to be tedious or taking away from the bigger picture or [ taking away from ] what’s actually on my plate , those to - do items that I don’t really care about , but we need to just churn it out , ChatGPT all the way . ” – A1 5 “I’ve used it to help write release notes . . . I’ll have this list of really boring updates or features that aren’t that sexy , and then they’re like , ‘Just make it sound fun . ’ And that is really time consuming actually . And generative AI is extremely helpful for that . ” – S5 “It does seem useful when you have to sort of pound out outlines that are just very robotic . ” – J7 “Within law firms there’s some work product that you produce that takes a lot of thought and decision making and some creativity to really draft something that is unique in the way that you put it together . There’s other Effort - Saving Tool Narrative — Participants largely envision that it will be realistic and desirable to use generative AI as a tool to perform menial work , subject to human review . Further , they believe that existing guardrails in their industries can be leveraged and augmented to perform such review . They expect certain roles will be impacted , but for most industries they do not anticipate substantial transformation or elimination of a wide range of jobs . In most cases , participants did not anticipate change as broad as that predicted in the Transformative Narrative or the Sensationalized Narrative . Transformative Narrative — Typically shared in technical reports 6 or peer - reviewed papers by think tanks , consulting firms , or academic groups , and echoed in some rigorous news reports , this narrative takes an analytic approach to arguing that generative AI will have broad , substantial impact across industries , jobs , and tasks . Work in this vein often includes projections ( e . g . , % of tasks that can be automated by generative AI , # of jobs affected ) , outlining a range of possibilities , but usually including an exceedingly high upper bound for such estimates . While this narrative is not as catastrophic or exaggerated as the Sensationalized Narrative , it usually predicts transformative change . Sensationalized Narrative — A predominant discourse in social media and many news articles , this narrative makes dramatic or even hyperbolic claims about how generative AI will change / replace human labor in the future . It often draws comparisons between generative AI and previous historic innovations or even “the big bang” ( e . g . , [ 134 ] ) . In some cases this narrative originates from leading figures in AI [ 101 ] who are arguably framing evocative messages for the lay public . However , it often misrepresents expert opinion or incorporates evidence from sources such as the Transformative Narrative in misleading ways and emphasizes anxiety - inducing worst case scenarios [ 118 ] . Table 2 . An overview of three differing narratives regarding generative AI . 5 Throughout the paper , we assign participants pseudonyms that begin with the letter associated with their industry , i . e . , A ( Advertising ) , B ( Business Communications ) , E ( Education ) , J ( Journalism ) , L ( Law ) , M ( Mental Health ) , and S ( Software Development ) . In some cases , we have lightly cleaned the quotes for readability , e . g . , to remove filler words such as “like” or “um” . 6 Due to the recency of the topic , much of the relevant literature appears in pre - prints or white papers . 8 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries tasks that I do on a daily basis that are a lot more formulaic . . . if you’re comparing [ the first ] to say Citizen Kane , [ the second ] is more like an SVU episode where you can throw it together in 10 minutes . ” – L1 Participants were typically enthusiastic about offloading these tasks to generative AI , both because they were tedious and because they felt the time saved would allow them to focus on more meaningful , human aspects of their work . For example , in the mental health group , participants were attracted to the idea of generative AI taking over rote work , such as note - taking or patient intake , thereby increasing their efficiency and freeing up more time to focus on interpersonal work with their clients . “I wish AI could help us with note - taking in any way . That’s the part of our job that I hate the most . It’s so laborious . . . it takes up so much of our time and if there’s anything that could support us with that , that would be amazing . I don’t know how it would do that , but if it could , I would cry for joy . ” – M1 Further , some greatly valued the ability to scale and handle high volumes of work . For example , B6 had recently sent out 350 , 000 emails over a three month period , and imagined generative AI could increase consistency and speed . 4 . 1 . 2 Generative AI is a useful tool : “Maybe a helpmate but certainly not in control” . Consistent with their orientation to the use of generative AI for busywork , participants dominantly oriented to generative AI as a tool for human workers . For example , some participants specified that generative “AI tools should assist” employees , but not “do” their work . Many emphasized generative AI should not go beyond tool status and perform certain kinds of knowledge work , e . g . , generative AI should not be used for decision - making , setting strategic direction , or forming human connections . “I think to use Gen AI as a tool to assist anyone in the legal system is not necessarily a bad thing so long as it remains just that — a tool . ” – L5 ( Policy ) “For tedious tasks , and time consuming aspects of the business , allow yourself to lean on an AI for support . But always push yourself and your team to be the creative ones . ” – A1 ( Policy ) 4 . 1 . 3 Generative AI requires human review : “You’re still gonna need someone to follow up and review it” . Participants in all groups were concerned about generative AI’s potential to make mistakes or produce undesirable output . For example , participants in the advertising and business groups shared concern that generated content might violate brand standards or copyright , and lawyers spoke of the need to attest to the accuracy of legal documents . “I don’t trust it yet because in law of course we gotta go to deep research to make certain that the sources are correct before we would ever use it . ” – L2 “You can’t trust that it’s accurate . So [ that makes ] me hesitant about using it going forward for anything that I take seriously . ” – L1 One participant recounted a news story in which an attorney submitted a legal brief created with ChatGPT , which included “hallucinated” cases : L7 : I haven’t used it at all . But I’m kinda wary of introducing new tech generally . Especially as a litigator , anytime you submit anything to a court , you sign it under what we call Rule 11 . You’re representing it’s true and accurate and you’ve got a good faith argument for whatever you’re doing . And I think you may have heard about that [ case ] where a guy wrote his brief using AI and then the AI generated six cases , citing opinions that 9 Woodruff et al . didn’t even exist apparently . Which to me is mind boggling . L6 : I would’ve won so many cases if I could have done that . . . L7 : That’s right . Exactly . And then this guy , the attorney that did it , he’s kind of . . . a national joke . Accordingly , the overwhelming sentiment in all groups was that humans would need to check most or all of generative AI’s output to ensure its quality . In some fields , participants stipulated that this check must be performed by a qualified professional . “The AI would produce something , and then we would say yay or nay . ” – J5 “ [ Generative AI code ] should never be something that goes to production without human testing and review . ” – S7 “Generative AI can assist attorneys . . . but all its work must be proofed by an individual licensed to practice law . ” – L7 ( Policy ) “A lot of this problematic stuff that we’re hypothesizing is coming out of this idea that AI could be this standalone [ advertising ] team doing every single thing from start to finish and releasing this ad without consent of anyone or something like that . Which I think is still pretty sci - fi . . . ” – A3 “I feel like you’re always gonna need some type of human oversight , right ? No matter how good the technology gets , I just don’t see humans being obsolete < laugh > . Like how’s that possible ? ” – A5 4 . 1 . 4 Existing industry governance structures are amenable to overseeing generative AI : “It would just be part of what we’ve already been doing . ” Participants spoke of new roles , responsibilities , and qualifications to enforce human oversight and monitor generative AI’s use and output in knowledge work . “Training like getting a driver’s license . Once you get the ability and understand the rules you can use [ generative AI ] . ” – A7 ( Policy ) Participants pointed out that many such oversight functions , while new , integrate well in existing industry review structures and policies . For example , lawyers review the work of paralegals or junior associates , business communications undergo legal and compliance approvals , and software development has code review . Participants explained : “There’s oversight right now against a brand voice , tone , style , consistency . Anything that is generated has to go through an approval list . . . [ There are ] checks and balances in place . So I would feel really good about AI helping contribute to that message if it went against those checks and balances . ’ – B4 “Most of our districts already have user agreements which talk about plagiarism , hate speech and those sorts of things . I think it would just fit right into most of our districts’ user agreements . ” – E5 4 . 1 . 5 Certain jobs will be downsized : “A lot of entry level positions will be eliminated” . Participants in most industries anticipate that as generative AI streamlines formulaic work , certain jobs will likely be eliminated . They tended to think of the job risk as fairly narrowly scoped to specific entry - level jobs or jobs with many rote tasks . For example , jobs such as help desk , legal assistant , or product photography were highlighted as being at - risk . “Commercial work I think is done < laugh > . Commercial photoshoots cost hundreds of thousands of dollars , lighting , makeup , all that stuff . [ And ] now you can just type it in . . . instead of paying for production , AI could 10 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries make it all up . They won’t need 99 % of roles on set . Don’t need models , photographer , makeup , set designer , etc . Getting rid of the majority of roles is terrible . ” – J6 ; J6 ( Change Card ) 4 . 1 . 6 Need to evolve and adapt with generative AI : “Let’s evolve with the times , right ? ” While some participants were saddened by the prospect that many would lose their jobs , others felt these changes were a natural evolution of knowledge work , which could bring new opportunities . Those who expressed sadness told us : “I find the notion of job replacement heart - breaking . ” – S2 ( Change Card ) “ [ The client was ] trying to save money [ by using generative AI ] , but it wouldn’t have saved money . And I also felt really sad because they pretty much outright said that their goal was to close three call centers that employed thousands and thousands of people . And it just made me really sad . ” – S5 While others spoke about adapting to inevitable change : “Change is a constant despite humans naturally tending to try and resist it . I am all for change and constant adaptation as long as the baselines of independent thinking and learning is still held as an important skill to possess and have . ” – L5 ( Change Card ) A2 : [ Generative AI ] could eventually replace headshot photography or photo shoots for certain industries . . . A8 : Yes . I wanna wait until I can say , ‘ [ Generate it ] in the vein of Annie Leibovitz , ’ you know ? . . . A2 : Gonna get there . That’s the thing . It’s only gonna get better . So how do you deal with that ? What happens to all those creators , all those jobs ? . . . I’m hopeful that there will always be a space for creative people . . . [ but ] there will be I think a big chunk of those jobs that just kind of go away . Like the simple headshot photographers or the person who does passport photos , things like that . I don’t know . At this point it seems a little bleak and ambiguous , but I could see it happening . . . I feel like the working jobs , the creative jobs , the smaller ones will go away and then it’ll just be more top heavy companies where they’re overseeing the technology . A5 : Isn’t that just evolution ? We went from no machines to machinery and people lost millions of jobs . Is it just not a part of evolving ? I feel like there probably are still some human aspects that could go into AI . . . Is there a human there to say , ‘Oh , this isn’t right . ’ ? Maybe like quality control . Some also emphasized that knowledge workers need to adapt and “reformat their skillset” in order to stay relevant and not get left behind . “ [ To B3 ] So you just graduated ? I would learn to adapt with it and use it rather than ignore it . . . I guess it’s going from a horse to a car , it’s inevitable . . . Rather than ignoring it , just learn to drive . . . How [ can you ] do your job more efficiently and effectively by using the technology to your advantage ? ” – B4 “What if there’s industries that don’t use it . . . then are they just no longer a part of the conversation ? ” – A1 “People will adjust . We are all going to move on . . . I do meet a lot of people , a lot of technologists , my colleagues , coworkers , they get scared by it . But then I tell myself that if you’re scared by the AI itself , then maybe you as a person are not evolving fast enough . . . I think it gives us a new challenge and we should embrace it . We should accept it and then evolve faster , adopt and adjust as well . ” – S1 11 Woodruff et al . “I think that if you’re in the industry , keeping up with these tools and using them as an asset to enhance your work will make you irreplaceable . ” – B3 ( Change Card ) As one concrete example , participants spoke about how upcoming changes would require “prompt engineering” skills to elicit improved outputs from generative AI systems . S5 described this as the next “big thing” and said it is an “art form . . . to massage what you’re saying to ChatGPT to get the right answer in the way that you want . ” 4 . 1 . 7 Not embracing external narratives about disruption : “I don’t think therapists are gonna go away . ” Overall , when compared with current expectations in the Transformative Narrative and the Sensationalized Narrative , the Effort - Saving Tool Narrative is a fairly limited view of expected labor impacts . Many participants expected that even if workers in entry - level or similar roles in their industry were affected , they personally were somewhat unlikely to experience significant impact , feeling confident , for example , that generative AI is unlikely to be skilled enough to replace human professionals within the timeframe of their own careers . While some did acknowledge the potential for industry - wide shifts , particularly in software development , advertising , or business , sentiment such as the following was generally the exception rather than the rule : “As a communicator , it’s a little intimidating how good the bot writers can be , and I know our Bangalore teams are looking at hiring bots or putting them in place rather than hiring humans . So , there’s an excitement factor in terms of cost savings as an executive , but also an intimidation factor as a communicator to see that a whole industry of journalists or people who major in [ communications ] could be replaced to a degree . So , I think specific jobs , organizations , entire industries , the world will be affected by that . ” – B4 “Writers could start to become obsolete in journalism [ because of generative AI ] . . . We could potentially be pushed to the back burner and not relied upon whatsoever to produce content . To be frank , I’m very afraid and believe that I may have to change career paths soon . ” – J5 ( Change Card ) Further , participants in most industries appeared to feel other forces are more disruptive than generative AI . We discuss some of these in Section 4 . 2 and we discuss industry - specific expectations further in Section 4 . 3 . At the same time , participants were somewhat uncertain about both their own projections as well as broader narratives . To bolster their reasoning , they sometimes drew analogies to other resources such as the internet , Google Search , or industry - specific databases , such as LexisNexis in the legal profession . “I see certain things as tools that replaced old tools . This is not really a new tool . I think it’s just an enhancement of something we already have . For example . . . Lexis . ” – L7 Relative to the Sensationalized Narrative or even the more moderate Transformative Narrative , participants tended to take an even more tempered view of likely changes in their respective industries . While some participants were aware of media claims , they approached them with skepticism . In some cases , they literally discounted these narratives by proposing adjustments to reported statistics . At the same time , they were uncertain , and sometimes found the claims worrying even when not fully convinced . “I’ve seen it time and time again where everybody [ in media companies ] runs to the same goal post . Like the pivot to video is the most famous one . It’s exhausting as a journalist and we watch all these people get laid off and then a year later they say , ‘Never mind , it wasn’t the answer we thought it was , back to where we started . ’ < J2 interjects : [ Remember ] podcasting ? < laugh» Yeah , exactly . We’ve all seen it . So I don’t know how ChatGPT 12 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries shakes out in this whole picture , but I do think it’s probably not as insane as some people are making it in terms of the tidal changes that it’ll make to our industry . But it is probably like 60 % of the way there . ” – J3 L4 : Goldman Sachs says that AI will take over three hundred million jobs away in the coming years . 7 L7 : Three hundred million ? L4 : Three hundred million . Moderator : Do you find that plausible ? L7 : So all of the US will be laid off . L4 : Yeah . Three hundred million . . . L2 : And some of the companies like McKinsey who have studied the prognostications of those kinds of things find they’re wrong way more than they’re right . But the scary part is even if it’s fifty million people , it is significant with ripple effects throughout everything . You know , it’s amazing . They usually aren’t right , completely . But the reality is that you get very scared by that headline . . . Talk about anxiety . ‘Hello , am I in the three hundred million who’s not gonna be employed anymore ? ’ Tough . Tough . L4 : It was concerning when I read it . 4 . 2 Social Forces : Deskilling , Dehumanization , Disconnection , and Disinformation We asked participants to describe important changes coming in their industry over the next one to two years . While some of these changes were driven by generative AI , many were not . For example , mental health professionals expect broader legalization of psychedelics will be transformative in their field . In some cases , participants expected that generative AI would interact with other changes to bring about particular impacts on their industry . Most prominently , four existing global and national forces framed participants expectations of generative AI’s impact . Specifically , they anticipated generative AI would amplify the following social forces [ 39 , 159 ] that shape how knowledge workers do their work in their industries : deskilling , dehumanization , disconnection , and disinformation . 4 . 2 . 1 Deskilling : The “Uberfication” of Knowledge Work . Independent of generative AI , several forces are actively shifting revenue and employment in certain knowledge industries . For example , the emergence of remote services , such as BetterHelp and LegalZoom , was accelerated on both the supply and demand side by COVID - 19 , as both providers and clients often desired virtual sessions . Such services provide clients easier access to mental health , legal , or other advice . While these services may reach a larger number of people at a more affordable price , participants argued they provide lower quality service and undermine demand for highly trained professionals . M6 described how telehealth tech startups pose a greater employment threat than generative AI : “Things like BetterHelp are the biggest threat to our job security / livelihood . Because I think it’s an Uberfication of mental health care . One of the things that BetterHelp really advertises is you can text with your therapist , but their actual guidelines are you will get a text a day from your therapist and they have like 24 hours to respond . So people who are using [ BetterHelp ] are actually not that happy with it . ” – M6 The “Uberfication” of work refers to a broader shift in the political economy of how work is “arranged through the use of digital technologies . . . to create ‘platform capitalism’” [ 141 , p . 61 ] . A key element of these labor conditions is 7 Participants appear to be referring to a Goldman Sachs report released in March 2023 [ 26 ] whose findings were also highlighted in a McKinsey report released in June 2023 [ 33 ] . The report states that 300 million full time jobs are at risk of automation , globally . The media covered both reports , sometimes sensationally [ 118 ] , and coverage was often unclear about the geographic scope of the statistic . 13 Woodruff et al . supplanting employees with precarious self - employed workers [ 64 ] . Participants , especially lawyers and journalists , reflected on a significant shift towards contract , freelance , or “permalance” positions ( in which workers work in an extended freelance capacity with an employer ) . Driven by bursty demand for expertise as well as cost - saving measures , these positions are precarious and do not offer the same benefits as full - time employment [ 160 ] . Generative AI may interact with these extant labor trends to further deskill industries or reduce opportunities for highly trained professionals . For example , generative AI could propose advice that less trained human workers could pass on to clients in cheaper online services . Some participants also speculated that non - permanent employment would be easier to replace with generative AI than full - time positions , since few employment protections would be in place . Participants also drew connections between the gig economy , generative AI , and white collar work . J2 has worked as a labor journalist , previously writing about the impact of technology on blue - collar workers . With the rise of generative AI over the past year , his concerns have become more immediate and personal . “As a worker myself . . . I wasn’t too worried about [ the digitization of the workspace ] until now because , you know , they’re digitizing a factory or whatever . . . now it’s actually starting to impact my industry . And all those questions that were arising about factory workers or Uber drivers or whatever , they’re starting to be asked about us [ journalists ] now , to apply to us as well . ” – J2 Participants discussed how these forces can affect their wages and opportunities . For example , M6 discussed how these changes could reduce his wages or even undermine his investment in a specialized career , while also reducing quality of service : “I’m up to my neck in student loans still . Part of me is like , ‘Well , it’s great if BetterHelp can be affordable for people . ’ But what about my job security , my ability to pay off my student loans ? . . . And then the idea of generative AI doing chat . . . I do have concerns that this could be used in a way that would undermine our job security , but also I think actually not provide the level of care for the consumer as well . ” – M6 S7 shared similar concerns that generative AI might make her hard - won skills less valuable and set back her career : “I didn’t really know that I as a girl with a non - traditional background could be an engineer . And I also saw it as a way to make a lot more money than I was making . It was definitely a way for me to double , triple my salary and have access to a life that I could only dream of . And so it is kind of a bummer , even though it feels like a very first world problem , to be like , ‘Oh , now I’m back to potentially in a few years not having a very valuable skillset or a skillset that everyone can have’ . . . It is a little disheartening to be like , ‘Oh , finally ahead . I’m finally at this place I wanted it to be , ’ and now I have to play catch up again . ” – S7 Participants also expressed concern that , given its fitness for menial tasks , generative AI might eliminate many entry - level positions and therefore remove pathways into more senior roles : “I would not be in my job , in the role I have today , if I didn’t start as an SDR [ sales development representative ] . It makes me sad to think these entry level roles may no longer be necessary . . . [ It’s ] upsetting because I think everyone has to start somewhere , and if you don’t have that basic knowledge , how do you grow from there ? ” – S6 ; S6 ( Change Card ) 14 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries “A lot of help desk positions can be eliminated . . . I’m not too happy about that . I got my start on help desk . I didn’t go to school for computers at all . So taking a lot of those jobs away would be really sad cause they’re just a really easy entry into a good field . ” – S4 Participants in fields such as law and mental health also expressed concern that clients might use generative AI themselves in a way that undermines professional expertise , as well as revenue . Participants further expressed concern that clients might unknowingly make poor decisions using generative AI since they do not have appropriate expertise . “Clients won’t need to hire you for their legal advice or defense if AI becomes prominent” – L4 ( Change Card ) L5 : A lot of administrative law is filling out paperwork and doing it for the client . The client comes for you to do it for them so they don’t have to . But ChatGPT might change that concept entirely . Amazingly , a lot of our clients that do [ alcohol , gaming , food stamps ] , they know about [ ChatGPT ] . They come in and they’re like , ‘Well , I did this , I just typed it in and they gave me this . And why is yours better than mine ? ’ < laugh > And it’s hard to explain the nuance between why would I have a different legal perspective on this document than what you got from this database . . . . L2 : Bypass the expense of ( legal counsel ) . . . A person who’s not been involved in litigation has no idea all the things we have to do to protect them . . . AI can’t do that . . . These issues around deskilling , menial work , the gig - economy , and more widespread job loss all arise in the context of broader economic uncertainty in the US . Participants , at times , speculated on how these changes to jobs could potentially be addressed through social welfare approaches like universal basic income , but were not confident governments or employers would meaningfully address these labor changes , or other ethical issues related to generative AI , due to their position operating within a capitalist environment : S7 : I just feel like under capitalism there can be no good AI . . . I’m still figuring out how I truly feel about AI . I don’t think it’s inherently evil or bad , but I think when you’re talking about using it at a company or corporation , the people at the top are always concerned about making a profit and cutting out jobs and whatnot . So I just am like , the end stage of this , no matter how good it can be , it just always feels really icky and bad . S5 : Ideally it’s like the Star Trek universe . S7 : Yeah . S5 : I’d be into that < S7 laughs > , nobody has to work . We’re all like happy . S7 : That would be great . But then there’s no one at the top getting all the profit . S5 : Yeah . 4 . 2 . 2 Dehumanization : “Whose job will it be to find out how to incorporate human nature into the AI ? ” . Replacing human workers with algorithms raises concerns about dehumanization in which the task loses a characteristic of how humans interact with each other [ 59 ] , becoming more sterile and impersonal [ 139 ] . Many participants expressed concern that use of generative AI might in various ways lead to a loss of humanity . One issue was that they felt generative AI does not have the capacity to perform interpersonal work . For example , business communications professionals spoke of the importance of personal touch and authentic human communication , and mental health professionals voiced that generative AI can not establish human - to - human rapport , which is required for therapy to be effective . 15 Woodruff et al . “One of the most powerful things about therapeutic rapport is what we often call unconditional positive regard . I am a human here with you and I am not judging you . And I don’t get much comfort out of a computer not judging me < others laugh > . . . Having unconditional positive regard from a robot doesn’t really change my sense of self very much . So I would say that’s one really simple thing is just the simple fact that I know that this is a human being . ” – M6 “Building rapport with someone is a huge piece to establishing effective [ mental health ] care . I don’t think that that can be done virtually with [ generative AI ] . I personally don’t think it can be . It might be able to < laugh > . ” – M3 Participants also spoke of how the public’s aesthetic standards could shift over time to less natural or less human content . “I believe when AI created content ( articles , videos , infographics , etc . ) begin to seep into our feeds , we will eventually accept its strange aesthetic ( which we call ‘robotic’ , ‘uncanny’ , etc . ) as normal . This could create an entire new aesthetic of digital media as we know it . I’m concerned . ” – J8 ( Change Card ) Participants also feel joy in performing tasks themselves , an emotional experience not provided by using generative AI . The introduction of algorithmic technologies into organizations in dehumanizing ways erodes workers’ sense of autonomy [ 113 , 137 ] and overall job satisfaction [ 92 ] . Participants echoed these insights in the context of the introduction of generative AI into their industries . “From the photography viewpoint for me , they’re replacing actual picture taking with just generating in AI , and the whole reason I like photography is I like holding a camera . I like framing it . I like the interaction with the person and all that . And generative AI just completely gets rid of all that . The human connection . . . ” – J6 “There are folks who get their joy and their sense of meaning from writing code and that’s kind of their thing . . . these are people that spent years mastering this trade . And I think that’s where it gets sad . ” – S2 Moderator : So should [ an undergraduate ] go get a computer science degree where they’re going to do a lot of math and code , or should they go to some prompt engineering boot camp ? . . . S2 : Well , it’s the same question in the context of art school . Should someone go and learn how to paint and all the intricacies involved there ? Or is it futile because a computer can spit out that painting for you ? I don’t think there’s a right answer . . . . S1 : I don’t think it’s a bad time at all for a computer science degree yet . At least for our generation or in my opinion even the next one . . . . S2 : If someone wants to go to school for computer science , because . . . learning and tinkering is fun , they should do it and don’t let the robots stop them . Participants also spoke of the value of human production and creativity . Their comments were reminiscent of the Arts & Crafts movement , which challenged the integrity of mass produced objects , associating them with dehumanization 16 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries and a decline in production standards [ 122 ] . The Arts & Crafts movement valued artisanal production and human craft , even though it was less efficient than the mass production that became common in the industrial age . Similarly , participants spoke about the value of making things by hand , and the high quality and meaning of human - created objects . “I think that there’s potential for real things outside of screens , like actual photos in an album . Like who makes those anymore ? But I think things like that would become almost like sacred and similar to . . . the dumb phone movement straying away from smartphones and screens . I think that there’s gonna be at some point a push towards that . Like the things you could physically touch and make with your hands . . . Wanting the personal touch of knowing it took time and intention and purpose and thoughtfulness to create something . I think there’s real beauty in that . And I guess I don’t really see the beauty in AI . ” – A1 “I think a lot of skilled labor and artisan style jobs are going to come back into fashion and it’ll be very hard for AI to replace them . My boyfriend went to furniture school recently and so he’s a carpenter and a fine furniture maker . And I was just kind of musing about how right now I’m the breadwinner , but I think soon he might be the breadwinner because there’s something about something that’s made by hand , something that is of quality . We live in this fast fashion age where things are just mass produced . And I think there’s a real desire for something that is made with care that will last , that is creative . . . It takes a lot of personal skill and a lot of physical labor to make a table . . . and I have a hard time thinking that generative AI is really gonna be able to replace that . ” – S7 Some participants emphasized that people must retain critical thinking skills as well as the ability to do the type of work that is being offloaded onto generative AI , and that people must not become lazy . “I hope my daughter never discovers [ ChatGPT ] . . . I don’t want it to take away creativity . I want my daughter to think of her own thoughts . Like when she’s doing her studies . That’s really important to me . ” – L3 E6 : It’s kind of like a calculator , right ? They have to learn how to do the math first before they’re allowed to just do it all using the calculator . . . . E7 : You get this Chat thing and all this AI [ that ] just makes kids’ lives easier . And people are like , ‘Well what’s wrong with that ? ’ There’s a lot wrong with that < E2 laughs > . “I also worry about the generational effects of generative AI . Because I think at the very base , it’s another way for people to use their brains less . ” – J8 “I think you need to actively not be lazy , because it’s so helpful . You need to say , ‘Okay , I’m not gonna just let this responsibility fall onto this machine . I’m gonna still really play the biggest role here . . . ’” – A1 At the same time , some recognized a delicate line between being lazy and being efficient , and therefore saving time for more meaningful activities . A7 : I assume I’d be pretty lazy right now if I was in high school and I would just try to take advantage of [ generative AI ] as much as I could . . . You can literally not learn for the rest of your life if you don’t want to now . 17 Woodruff et al . . . . A6 : Is it lazy or is it clever ? Are you learning the long way or are you streamlining the process ? Several participants offered a literal mechanism for retaining humanity in the use of generative AI , proposing a specific quota , such as “at least 80 % of words , photos , everything on our site is created by human minds” or “60 % [ of the job ] needs to be conducted by humans . ” 4 . 2 . 3 Disconnection : “You have to be there” . Feelings of disconnection can manifest in knowledge work , e . g . , new tech - mediated working arrangements can increase feelings of worker isolation [ 152 ] and broader social trends in perceived isolation can exert external pressures on knowledge work practice [ 55 ] . Participants spoke about increased social disconnection , such as the so - called “loneliness epidemic” [ 117 ] stemming in part from COVID - 19 and the corresponding social isolation and increase in remote / virtual work and schooling , as well as other factors , such as escalating phone and social media use or even addiction . They were concerned that generative AI would contribute to further disconnection from physical and social experiences . For example , mental health professionals worried that therapeutic uses of generative AI could have the opposite of intended effects and exacerbate loneliness , even as patients turned to it for comfort : “I hear people talking about the uses of AI [ for mental health ] in the chatbot model , and to a great extent , I’m wildly against it . Because I think that a big part of the reason we have the increase in people needing mental health services is because of disconnection . And I think that while it might really have helped your client in that moment to have a bot to chat to , it’s still not a replacement for human interaction . And I think that that disconnection is a lot of what is driving this [ mental health ] crisis . ” – M6 Our participants also described how good journalism requires being “on the ground” and how the extant rise in freelance and remote work threatens the quality of news production , a trend that could be further exacerbated by the use of generative AI . J8 characterized the future of journalism with generative AI as “just more recycled and disconnected from reality , allowing people more to be separated from what they’re doing instead of fully immersed in it . ” Participants also expressed concern about content becoming increasingly disconnected from reality over time as new generative AIs are trained on layer upon layer of recycled , increasingly non - human content . “As journalists , when we cover things , we are currently on the ground doing reporting , talking to human beings and things like that . And more and more it’s becoming like we’re talking to people over Zoom or we’re not being flown out to places to cover things anymore and we’re hiring freelancers . . . We get a bunch of footage from overseas and then we have to make something from it because we’ve hired freelancers there instead of being on the ground doing it . So it’s this gradual , very gradual disconnection from what we’re covering and what we’re thinking and the actual reality of the world . ” – J8 “ [ News aggregators are ] a homogenization of all the stories . We lose the individual voices of the people who are witnessing or describing , you know ? . . . [ As a reporter ] you still need to experience it , you need to taste it , you need to see it , you need to feel it in order to transcribe those sensations of the human experience to your readers . ” – J1 “I think it’s a lot of dumbing down and recycling that’s happening . I’m worried about the long - term effects of recycling things that have been recycled already with text and images and what that will do to ideas . ” – J8 18 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries 4 . 2 . 4 Disinformation : “I think they call them hallucinations . . . it puts it out so authoritatively” . Disinformation is the intentional spread of false , inaccurate , or misleading information designed to intentionally cause public harm [ 74 ] , and its production is often motivated by “ideology , money , and / or status and attention” [ 103 , p . 27 ] . Participants expressed concern about the role generative AI may play in disinformation , and more broadly in the production of low quality content , particularly in the broader context of US discussion of polarization , culture wars , and media bias . One concern was that since generative AI typically incorporates internet data in its training , its quality would be undermined by existing low - quality content on the internet : “It can’t just pull it from the internet as it is right now because there’s so much misinformation pre - AI . ” – J7 “I [ am ] really concerned about AI learning things all over the internet , just chaotic . But if there’s an AI that collects everything from [ an authoritative source ] . . . I’ll be really excited about it . ” – A4 “Can you tell me where all of these images came from ? Can you tell me where you got this person’s blog post ? Who is that person that wrote it ? A lot of stuff on the internet , especially with Reddit and things , are anonymous and that’s the good and bad thing about them . And so as you put them out into the world , into this product that everyone can use , how do you even begin to really make sure it’s unbiased ? ” – S7 Participants further expressed concern that generative AI would itself proliferate , or would be leveraged to produce , additional low - quality content . They were worried about misinformation and disinformation currently in the media and online , and saw generative AI as a tool that could make it even easier and faster to produce harmful content . They anticipate this will have significant negative social and political repercussions : “ [ I fear ] propaganda would be so undistinguishable that no one’s gonna know what’s real . . . We’re not gonna be able to determine what’s real and what’s fake and it could be the doom of us . ” – A6 “It does seem like a major issue with deep fakes , especially in the realm of pornography , which is what keeps the internet running . There’s already issues with revenge porn , and the notion that you can do this with anybody’s face , anybody’s likeness . . . The worst human urges < laugh > and desires are gonna be generated by the generative AI . ” – J7 “Generative AI just comes at a bad time for us as Americans . . . and for us as journalists . We have such a problem in sensitivity around words like truth and falsehood and what is the truth and objective truth versus subjective truth . ” – J3 Participants were also concerned that media upheaval , caused by wide - ranging factors such as economic or political instability , is currently driving news aggregation and media concentration , thereby eroding the quality of information available to the public and “dumbing down” , homogenizing , or politicizing content . They were concerned generative AI could exacerbate these issues . J2 spoke of media trends that started in Europe : “ [ A change ] that is not caused by generative AI , but that will be made worse probably by it is the further media concentration . That’s caused by billionaires buying media left and right , agglomerating them and altering and then sometimes increasing their editorial lines , to their benefit . . . [ as ] a tool for [ their ] political agenda . . . I believe generative AI might make it even worse because all of a sudden these people will be able to buy and concentrate 19 Woodruff et al . media . If anyone has any ethics issues , well , you know , the door’s right there . And generative AI can do it for even cheaper anyway . . . just buy a newspaper , fire the entire newsroom . . . we’ll just run it by generative AI . ” – J2 4 . 3 Industry Perspectives In the previous sections , we drew themes across the industries we studied . In this section , we provide additional detail for each industry . To illustrate the most salient points and capture the unique character of each discussion , we created composites consistent with the content , language , and tone of responses we received from each group [ 40 , 161 ] , shown in Table 3 . These composites illustrate how themes discussed in previous sections play out across industries ; for example , which roles participants think are most likely to be affected in their industry . 5 DISCUSSION In this section , we build on our participants’ insights to surface key HCI research questions at the intersection of generative AI and knowledge work . Rather than focusing on current user practice or design recommendations for early versions of these systems , we seek to frame larger questions about how generative AI’s impact may be understood and shaped . Some of this work falls squarely in the purview of HCI , but much of it likely requires broader collaboration with other academic disciplines as well as stakeholders such as knowledge workers , policy makers , civil society , and more . 5 . 1 Research Challenges : Human - in - the - Loop Participants overwhelmingly favored a human - in - the - loop ( HITL ) approach ( i . e . , adding human review or oversight ) as a necessary and sufficient remediation for many problems with generative AI . For example , they expected that in their industries , human reviewers could check all of generative AI’s output and correct any inaccuracies or other quality issues . Legal scholars report that regulators have a similar inclination to address a “panoply” of concerns about AI with a “slap a human in it” approach [ 41 ] . However , the HITL literature points out serious , unsolved practical problems that were not apparent to participants . For example , humans make many errors when reviewing algorithmic output and often override algorithms in detrimental ways ; therefore , human oversight policies can provide a false sense of security rather than improving outcomes overall [ 29 , 66 ] . Further , research has shown that effectively configuring human - AI coordination is extremely difficult , so handoffs are often poorly designed and yield harmful results [ 41 , 53 , 67 ] . Additionally , scholars argue that HITL approaches disproportionately hold humans accountable , even when in practice they have very little influence or do not have appropriate skills or time to review , leaving reviewers to shoulder the blame for technical or structural failures [ 13 , 41 , 48 , 53 , 67 , 155 ] . This suggests two main research questions : # 1 . How do we raise awareness of the limitations of HITL ? We believe it is important to exercise caution when applying HITL solutions . Those who are making decisions about mitigations for generative AI ( e . g . , regulators , decision makers in knowledge industries ) should be aware of the current limitations of HITL so they are not overly optimistic about its potential to remediate problems . # 2 . How do we make better HITL systems ? Despite its current limitations , many opportunities exist to improve HITL’s effectiveness . The advent of generative AI particularly highlights the need for HITL approaches that will work well at scale for review of generated text , images , and video . Also , cognitive forcing interventions ( such as asking workers to generate certain preliminary content before being shown generative AI’s output ) can engage analytical rather than heuristic thinking [ 29 ] . Further , 20 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Mental Health deskillingdehumanizationdisconnection We work on one of society’s most important problems : mental health is a national crisis , exacerbated by loneliness . There is a huge shortage of qualified mental health professionals , and therapy requires human - to - human connection which a computer cannot provide , so we feel our jobs are extremely secure against generative AI . However , we worry about telehealth services that provide low quality service but still undermine our job security . Generative AI may be a useful tool for administrative work , simulated talk - therapy training , or as a stopgap when people can’t immediately access a human therapist . Education human review dehumanizationdisconnection We don’t expect generative AI to affect our work deeply . Students already have many ways of cheating , and generative AI is just a newer , better way that we deal with by reviewing their work . We’re worried that generative AI may make students lazy if it’s not used well . We’re also sensitive to overuse of technology and social isolation because of remote schooling during the pandemic . We’re in the middle of restructuring much of our curriculum due to standards - based grading . This gives us more latitude to design new activities , so maybe there are opportunities to work generative AI into our lessons . Law menial tasks toolhuman review Generative AI is a tool that can perform formulaic legal tasks like drafting or research , provided its work is reviewed by qualified attorneys , replacing entry - level and support positions and contributing to job loss . We’ve heard press stories about false citations , which makes us wary of using it , even with human oversight . Generative AI is unlikely to be skilled enough to replace human professionals , and it should never make decisions , or act as lawyer , judge , or jury . However , we anticipate clients will begin to use generative AI tools to do some legal work for themselves , with poor results . Journalism deskillingdehumanizationdisinformation We work in a noble profession and we are already embattled on many fronts , facing misinformation , news aggregators , decreased revenue streams , and more . Generative AI will exacerbate ongoing precari - ous / freelance employment , poor wages , and job loss , and the erosion of journalism as a field . Generative AI makes it easier for low - quality providers to produce mis / disinformation , with harmful effects on society . Generative AI may replace some of the work we most enjoy , like writing or photojournalism . BusinessCommunications toolhuman review need to adapt Generative AI can do a lot of our work , and it will inevitably be adopted in our industry . Companies and employees need to adapt , learn , and “grow with AI” in order to stay relevant and protect job security . Much of our writing is formulaic , and generative AI is a great tool to produce early drafts of routine , high - volume , and / or disposable communications like email notifications . Generative AI will need a lot of human oversight and guidance , especially to make sure it meets compliance and legal standards and is consistent with our brand voice . We can leverage our existing approval structures to check its output . Advertising toolhuman review lose certain jobs Generative AI is well suited to many tasks in the advertising industry . Sadly , certain jobs will go away , most immediately those related to product photography and video production , with layout and copywriting under heavy threat . However , creative oversight will remain in the human purview , and generative AI will be an exciting brainstorming tool . A human check will be required for most generative AI output , especially to make sure it doesn’t violate brand standards or copyright . In fact , new teams may be created to do these checks . Our industry promotes and embraces change , but we also value human craft and we often challenge the quality of digitally produced content and experiences . SoftwareDevelopment need to adapt deskillingdehumanization Generative AI is likely to drive change across most aspects of software development . This includes , for example , the automation of menial and boring tasks , the elimination of many entry - level roles ( which will limit paths for new people to enter the field ) , and the ability of AI to reshape low - code technology solutions and even write production - ready code within serious software companies . We feel uncertainty about the future and pressure to adapt to new advances in generative AI . Some of us worry that the time and education we invested in a lucrative career might be nullified , setting us back to where we started . Some people get into software engineering for the money , but some of us are motivated by our love of tinkering and problem solving , and generative AI may take over a lot of the work that brings us joy . Table 3 . Composites illustrating the most salient points of participants’ expectations regarding the impact of generative AI on their industry , with industries ordered top to bottom by least to greatest expected impact . Under the name of each industry we list the top three most salient themes ( Effort - Saving Tool Narrative – blue ; social forces – red ) , Neither the top three themes nor the composites comprehensively represent all points , e . g . , although deskilling was discussed extensively in Law , it was not one of the top three . 21 Woodruff et al . reviewers could receive specialized training in critically reviewing generative AI’s output ; these review skills might ultimately be at least as valuable as other skills like prompt engineering . Overall , while improved solutions are unlikely to alleviate all concerns with HITL [ 67 ] , additional research and innovative design and development could lead to substantially better outcomes . 5 . 2 Research Challenges : Knowledge Worker Expectations of Impact We observed a significant gap between participants’ expectations of how generative AI might change their field versus broader narratives of disruption offered by the media , technologists , and academics—participants generally took a more limited view of potential impact . This suggests the following research questions : # 3 Why do some knowledge workers feel they will be largely unaffected by generative AI ? Are there certain workers who feel more immune to changes from generative AI ? Is this due to a failure of imagination or lack of awareness , or do knowledge workers have particular understandings of their industries that are not being taken into account in other narratives ? # 4 How do we raise awareness among knowledge workers about the Transformative Narrative ? Improved understanding of how and why generative AI is being positioned as capable of competently performing work at human expert levels would prepare knowledge workers to more meaningfully provide stakeholder input . Further , is it the case that knowledge workers underestimate the scope of what generative AI can do and what it may be used for , and how it may transform not just specific tasks or jobs but industries more generally ? If so , what interventions and transparency artifacts might be most meaningful ? For example , AI systems are largely not yet specialized ; perhaps developing and sharing industry - specific demos would be helpful . 5 . 3 Research Challenges : Deskilling As technologies shift how work is performed , the necessary skill sets of existing and new professions also shift [ 1 ] , creating a paradox of concurrent unemployment and labor shortages [ 12 ] . Consistent with this , participants expressed concern that generative AI might negatively affect the value and development of their skills . This suggests the following research questions : # 5 What training would benefit knowledge workers , to help them reskill for likely changes ? How can we help knowledge workers adapt to the possibility of wide - ranging transformation when there is not yet clarity ? Beyond prompt engineering , training for human review of AI output seems promising , as does development of critical thinking skills and the ability to manage complex , higher - level use cases . Additionally , conventional national policy responses to labor market changes often rely on traditional , secondary education [ 36 ] , which is often inadequate against the pace of technological change [ 145 ] . Reskilling within individual organizations is a more cost - effective and worker - centric strategy to evolve with technological changes in knowledge work [ 75 ] . Future work could explore how to re - or up - skill workers in ways that minimize precarity . # 6 How can we scaffold people into higher level positions , if entry - level pathways disappear ? Who might be most disadvantaged by the potential erosion of entry - level positions ? And in industries that rely on the development of foundational skills , how might the most talented experts arise if they do not work through entry - level tasks ? What systems might support human development of necessary skills , even if generative AI can perform those tasks ? 22 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries 5 . 4 Research Challenges : Dehumanization As a research community primarily studying the interface between humans and computer systems , understanding where these systems are uncomfortably and unacceptably encroaching on people’s inherent sense of humanity should be a key research agenda . To explore dehumanization , we suggest two avenues of inquiry to address the serious concerns raised by our participants : # 7 How can we learn about and protect tasks that bring people joy and meaning , but generative AI can do as well or better than humans ? We should understand not just , as many economists focus on ( e . g . , [ 4 , 165 ] ) , which tasks can be effectively be replaced by AI systems , but also which tasks inherently bring joy and reinforce humanity . By beginning to document these tasks that are meaningful but in some cases can be done as well , or even at higher quality or more efficiently , by AI systems , we can begin to design ways to protect these tasks , or at least make reasoned decisions about when to automate them . This may involve HCI interventions to design systems that highlight or reserve certain work or decisions for humans , or broader questions of regulation to protect certain kinds of work across society . While many utopian visions involve humans who are freed from work by AI and take up new , creative , artistic endeavors , losing the craft , joy , and humanity that exists in current work and problem - solving may have significant downsides . # 8 How can we promote critical thinking and also prevent people from becoming lazy ? Separate from the joy and meaning inherent in certain tasks , our participants also found innate value in performing reasoning and critical thinking . Participants were concerned that AI could reduce or remove tasks that challenge humans or force them to solve problems , thereby leading to a lazy society . While considerable work within the HCI community has explored how human and AI systems can collaborate for higher quality and more creative outcomes [ 34 , 76 , 99 , 146 , 153 ] , this question encourages research into how these collaborations can be designed to support knowledge workers [ 63 ] , as well as the design of systems that directly engage people in problem solving rather than simply providing answers . 5 . 5 Research Challenges : Guardrails Responsible AI has gained significant traction , from published principles to more actionable and / or measurable strategies . While some frequent issues , like explainability and fairness , move closer to having concrete remediations in system design , other broad social issues require additional work beyond engineering and system design , including harms assessments , stakeholder engagements , and increased focus on community outcomes . Considering the social factors prioritized by participants in our study , current responsibility metrics are most relevant to disinformation , and have less to offer regarding deskilling , dehumanization , and disconnection . This leads us to the following questions : # 9 How can we design responsible AI and governance approaches to generative AI that embrace complex global dynamics ? How can responsible AI more fully and holistically consider impact and harm ? Findings from our study highlight the ways in which the impacts of generative AI must be considered with respect to social forces that intersect with conditions of its development , deployment , and use . Thus , an approach to harm or impact analysis that stops at model evaluations ( e . g . , analyzing outputs with respect to pre - determined benchmarks ) will be insufficient . # 10 How can responsible AI assessments more fully incorporate stakeholder input ? 23 Woodruff et al . Responsible AI product assessments often center on anticipating harms from launching a product [ 21 , 25 ] through consideration of how their contextual use may engender harms to users and communities [ 6 ] . Many responsible AI interventions orient towards developer - facing interventions , such as developing AI principles [ 57 ] , educating practitioners to foster ethical awareness [ 93 ] , and moderating generative AI systems through training data mitiga - tions , in - model controls ( e . g . , reinforcement learning ) , and safety classifiers that gate outputs [ 69 ] . However , limited attention has focused on assessing communities’ desired forms and uses of AI . Meaningfully engaging communities of practice [ 158 ] in exploration of these questions , such as through community - based participatory research [ 37 , 71 ] , can inform development of practices that scaffold community engagement into responsible AI practice . Similarly , in a labor context , complicated questions arise regarding how to assess the impact of AI systems that may reduce or drastically change specific jobs . While companies may often consider the needs of an overall business , how should they consider the needs of individual workers , particularly those whose jobs may be cut or changed , and are there ways to directly engage them for input before developing these AI solutions ? And how can we educate or support decision - makers in engaging stakeholders ? 6 CONCLUSIONS The historical context in which technology appears influences how it is ultimately adopted and used . Generative AI has become more available and visible during the confluence of a global pandemic , economic uncertainty , and more . Many knowledge workers in our study situated generative AI in this context , highlighting generative AI as exacerbating the following four social forces : deskilling , dehumanization , disconnection , and disinformation . In other words , rather than seeing generative AI as an independent disruptor of their work or their industry , they positioned generative AI as extending and exacerbating existing forces . This framing raises important new questions and opportunities for exploring and shaping the future impact of generative AI on knowledge workers and their industries . ACKNOWLEDGMENTS We thank our participants for generously sharing their insight and expertise . We thank our partner team at Gemic , including T . J . Foley , Roger Galvez , David Ginsborg , Rebekah Park , and Rohini Shah for their support in the field . We are grateful to our colleagues at Google , including Marian Croak , Jen Gennai , Angela McKay , Anoop Sinha , and Ashley Walker , for supporting this work . REFERENCES [ 1 ] Daron Acemoglu and David Autor . 2011 . Skills , tasks and technologies : Implications for employment and earnings . In Handbook of Labor Economics , David Card and Orley Ashenfelter ( Eds . ) . Vol . 4 . Elsevier , 1043 – 1171 . https : / / doi . org / 10 . 1016 / S0169 - 7218 ( 11 ) 02410 - 5 [ 2 ] Google AI . 2023 . Bard . https : / / ai . google / research / projects / bard [ 3 ] Stability AI . 2022 . Stable Diffusion . https : / / stablediffusionweb . com / [ 4 ] Stefania Albanesi , António Dias da Silva , Juan F . Jimeno , Ana Lamo , and Alena Wabitsch . 2023 . New Technologies and Jobs in Europe . Working Paper 31357 . National Bureau of Economic Research . https : / / doi . org / 10 . 3386 / w31357 [ 5 ] Safinah Ali , Daniella DiPaola , Irene Lee , Jenna Hong , and Cynthia Breazeal . 2021 . Exploring Generative Models with Middle School Students . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 678 , 13 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445226 [ 6 ] Ali Alkhatib . 2021 . To Live in Their Utopia : Why Algorithmic Systems Create Absurd Outcomes . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 95 , 9 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445740 [ 7 ] Riku Arakawa , Hiromu Yakura , and Masataka Goto . 2023 . CatAlyst : Domain - Extensible Intervention for Preventing Task Procrastination Using Large Generative Models . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 157 , 19 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3581133 24 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries [ 8 ] ARM | Northstar . 2017 . AI Today , AI Tomorrow . Awareness and Anticipation of AI : A Global Perspective . [ 9 ] ARM | Northstar . 2020 . AI Today , AI Tomorrow : The Arm 2020 Global AI Survey . [ 10 ] Kenneth C . Arnold , Krysta Chauncey , and Krzysztof Z . Gajos . 2018 . Sentiment Bias in Predictive Text Recommendations Results in Biased Writing . In Proceedings of the 44th Graphics Interface Conference . Association for Computing Machinery , Toronto , Canada , 42 – 49 . [ 11 ] Kenneth C . Arnold , Krysta Chauncey , and Krzysztof Z . Gajos . 2020 . Predictive Text Encourages Predictable Writing . In Proceedings of the 25th International Conference on Intelligent User Interfaces ( Cagliari , Italy ) ( IUI ’20 ) . Association for Computing Machinery , New York , NY , USA , 128 – 138 . https : / / doi . org / 10 . 1145 / 3377325 . 3377523 [ 12 ] David H Autor . 2015 . Why are there still so many jobs ? The history and future of workplace automation . Journal of Economic Perspectives 29 , 3 ( 2015 ) , 3 – 30 . [ 13 ] Edmond Awad , Sydney Levine , Max Kleiman - Weiner , Sohan Dsouza , Joshua B . Tenenbaum , Azim Shariff , Jean - François Bonnefon , and Iyad Rahwan . 2020 . Drivers are blamed more than their automated cars when both make mistakes . Nature Human Behaviour 4 , 2 ( 2020 ) , 134 – 143 . [ 14 ] Luye Bao , Nicole M . Krause , Mikhaila N . Calice , Dietram A . Scheufele , Christopher D . Wirz , Dominique Brossard , Todd P . Newman , and Michael A . Xenos . 2022 . Whose AI ? How different publics think about AI and its social impacts . Computers in Human Behavior 130 ( 2022 ) , 107182 . [ 15 ] Thomas Barrabi . 2023 . AI will create a ‘serious number of losers’ in job market , DeepMind co - founder warns . New York Post . https : / / nypost . com / 2023 / 05 / 10 / ai - will - create - a - serious - number - of - losers - in - job - market - deepmind - co - founder - warns / [ 16 ] Jem Bartholomew and Dhrumil Mehta . 2023 . The Business of Artificial Intelligence . Columbia Journalism Review . https : / / www . cjr . org / tow _ center / media - coverage - chatgpt . php [ 17 ] Daniel Bell . 1976 . The Coming of Post - Industrial Society : A Venture in Social Forecasting . Basic Books , New York , NY . [ 18 ] Advait Bhat , Saaket Agashe , Parth Oberoi , Niharika Mohile , Ravi Jangir , and Anirudha Joshi . 2023 . Interacting with Next - Phrase Suggestions : How Suggestion Systems Aid and Influence the Cognitive Processes of Writing . In Proceedings of the 28th International Conference on Intelligent User Interfaces ( Sydney , NSW , Australia ) ( IUI ’23 ) . Association for Computing Machinery , New York , NY , USA , 436 – 452 . https : / / doi . org / 10 . 1145 / 3581641 . 3584060 [ 19 ] Melanie Birks , Ysanne Chapman , and Karen Francis . 2008 . Memoing in qualitative research : Probing data and processes . Journal of Research in Nursing 13 , 1 ( 2008 ) , 68 – 75 . https : / / doi . org / 10 . 1177 / 1744987107081254 [ 20 ] Blumberg Capital . 2019 . Artificial Intelligence in 2019 : Getting Past the Adoption Tipping Point . [ 21 ] Margarita Boyarskaya , Alexandra Olteanu , and Kate Crawford . 2020 . Overcoming Failures of Imagination in AI Infused System Development and Deployment . arXiv : 2011 . 13416 [ cs . CY ] [ 22 ] Virginia Braun and Victoria Clarke . 2019 . Reflecting on reflexive thematic analysis . Qualitative Research in Sport , Exercise and Health 11 , 4 ( 2019 ) , 589 – 597 . https : / / doi . org / 10 . 1080 / 2159676X . 2019 . 1628806 [ 23 ] Virginia Braun and Victoria Clarke . 2021 . One size fits all ? What counts as quality practice in ( reflexive ) thematic analysis ? Qualitative Research in Psychology 18 , 3 ( 2021 ) , 328 – 352 . https : / / doi . org / 10 . 1080 / 14780887 . 2020 . 1769238 [ 24 ] Virginia Braun and Victoria Clarke . 2022 . Thematic Analysis : A Practical Guide . SAGE , Thousand Oaks , CA . [ 25 ] Philip A . E . Brey . 2012 . Anticipatory ethics for emerging technologies . NanoEthics 6 , 1 ( 2012 ) , 1 – 13 . [ 26 ] Joseph Briggs and Devesh Kodnani . 2023 . The Potentially Large Effects of Artificial Intelligence on Economic Growth . Global Economics Analyst . Goldman Sachs . [ 27 ] Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D . Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert - Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel Ziegler , Jeffrey Wu , Clemens Winter , Chris Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few - Shot Learners . In Advances in Neural Information Processing Systems , H . Larochelle , M . Ranzato , R . Hadsell , M . F . Balcan , and H . Lin ( Eds . ) , Vol . 33 . Curran Associates , Inc . , Vancouver , Canada , 1877 – 1901 . https : / / proceedings . neurips . cc / paper _ files / paper / 2020 / file / 1457c0d6bfcb4967418bfb8ac142f64a - Paper . pdf [ 28 ] Erik Brynjolfsson , Danielle Li , and Lindsey R . Raymond . 2023 . Generative AI at work . Working Paper 31161 . National Bureau of Economic Research . https : / / doi . org / 10 . 3386 / w31161 [ 29 ] Zana Buçinca , Maja Barbara Malaya , and Krzysztof Z . Gajos . 2021 . To Trust or to Think : Cognitive Forcing Functions Can Reduce Overreliance on AI in AI - Assisted Decision - Making . Proceedings of the ACM on Human - Computer Interaction 5 , CSCW1 , Article 188 ( April 2021 ) , 21 pages . https : / / doi . org / 10 . 1145 / 3449287 [ 30 ] Manuel Castells . 2011 . The Rise of the Network Society . John Wiley & Sons , Hoboken , NJ . [ 31 ] Stephen Cave , Kate Coughlan , and Kanta Dihal . 2019 . “Scary Robots” : Examining Public Responses to AI . In Proceedings of the 2019 AAAI / ACM Conference on AI , Ethics , and Society ( Honolulu , HI , USA ) ( AIES ’19 ) . Association for Computing Machinery , New York , NY , USA , 331 – 337 . https : / / doi . org / 10 . 1145 / 3306618 . 3314232 [ 32 ] Noam Chomsky . 2023 . Opinion Guest Essay : The False Promise of ChatGPT . The New York Times ( 8 March 2023 ) . https : / / www . nytimes . com / 2023 / 03 / 08 / opinion / noam - chomsky - chatgpt - ai . html [ 33 ] Michael Chui , Eric Hazan , Roger Roberts , Alex Singla , Kate Smaje , Alex Sukharevsky , Lareina Yee , and Rodney Zemmel . 2023 . The economic potential of generative AI : The next productivity frontier . McKinsey & Company ( 14 June 2023 ) . https : / / www . mckinsey . com / capabilities / mckinsey - digital / our - insights / the - economic - potential - of - generative - ai - the - next - productivity - frontier 25 Woodruff et al . [ 34 ] John Joon Young Chung , Wooseok Kim , Kang Min Yoo , Hwaran Lee , Eytan Adar , and Minsuk Chang . 2022 . TaleBrush : Sketching Stories with Generative Pretrained Language Models . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 209 , 19 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3501819 [ 35 ] Elizabeth Clark , Anne Spencer Ross , Chenhao Tan , Yangfeng Ji , and Noah A . Smith . 2018 . Creative Writing with a Machine in the Loop : Case Studies on Slogans and Stories . In 23rd International Conference on Intelligent User Interfaces ( Tokyo , Japan ) ( IUI ’18 ) . Association for Computing Machinery , New York , NY , USA , 329 – 340 . https : / / doi . org / 10 . 1145 / 3172944 . 3172983 [ 36 ] Allan Collins and Richard Halverson . 2018 . Rethinking education in the age of technology : The digital revolution and schooling in America . Teachers College Press , London . [ 37 ] Ned Cooper , Tiffanie Horne , Gillian R . Hayes , Courtney Heldreth , Michal Lahav , Jess Holbrook , and Lauren Wilcox . 2022 . A Systematic Review and Thematic Analysis of Community - Collaborative Approaches to Computing Research . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 73 , 18 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517716 [ 38 ] Gareth Corfield and Matthew Field . 2022 . Meet ChatGPT , the scarily intelligent robot who can do your job better than you . The Telegraph ( 6 Dec . 2022 ) . [ 39 ] Robert W Cox . 1987 . Production , power , and world order : Social forces in the making of history . Vol . 1 . Columbia University Press , New York . [ 40 ] JohnW . CreswellandCherylN . Poth . 2018 . QualitativeInquiryandResearchDesign : ChoosingamongFiveApproaches ( fourthed . ) . SagePublications , Thousand Oaks , CA . [ 41 ] Rebecca Crootof , Margot E . Kaminski , and W . Nicholson Price II . 2023 . Humans in the Loop . Vanderbilt Law Review 76 ( 2023 ) , 429 – 510 . [ 42 ] Hai Dang , Sven Goller , Florian Lehmann , and Daniel Buschek . 2023 . Choice Over Control : How Users Write with Large Language Models Using Diegetic and Non - Diegetic Prompting . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 408 , 17 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3580969 [ 43 ] Thomas H . Davenport and Nitin Mittal . 2022 . How Generative AI is Changing Creative Work . Harvard Business Review ( 14 November 2022 ) . [ 44 ] Richard Lee Davis , Thiemo Wambsganss , Wei Jiang , Kevin Gonyop Kim , Tanja Käser , and Pierre Dillenbourg . 2023 . Fashioning the Future : Unlocking the Creative Potential of Deep Generative Models for Design Space Exploration . In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI EA ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 136 , 9 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3585644 [ 45 ] Meghan Rimol DeLisi and Catherine Howley . 2023 . Gartner Places Generative AI on the Peak of Inflated Expectations on the 2023 Hype Cycle for Emerging Technologies . Gartner . https : / / www . gartner . com / en / newsroom / press - releases / 2023 - 08 - 16 - gartner - places - generative - ai - on - the - peak - of - inflated - expectations - on - the - 2023 - hype - cycle - for - emerging - technologies [ 46 ] Claudio Dell’Era and Paolo Landoni . 2014 . Living Lab : A methodology between user - centred design and participatory design . Creativity and Innovation Management 23 , 2 ( 2014 ) , 137 – 154 . https : / / doi . org / 10 . 1111 / caim . 12061 [ 47 ] Alexey Dosovitskiy , Lucas Beyer , Alexander Kolesnikov , Dirk Weissenborn , Xiaohua Zhai , Thomas Unterthiner , Mostafa Dehghani , Matthias Minderer , Georg Heigold , Sylvain Gelly , Jakob Uszkoreit , and Neil Houlsby . 2020 . An Image is Worth 16x16 Words : Transformers for Image Recognition at Scale . arXiv : 2010 . 11929 [ cs . CV ] [ 48 ] N . Douer and J . Meyer . 2020 . The Responsibility Quantification Model of Human Interaction With Automation . IEEE Transactions on Automation Science and Engineering 17 , 2 ( 2020 ) , 1044 – 1060 . https : / / doi . org / 10 . 1109 / TASE . 2020 . 2965466 [ 49 ] Rick Dove . 1998 . The Knowledge Worker . Automotive Manufacturing & Promotion 110 , 6 ( 1998 ) , 26 – 28 . [ 50 ] Peter Drucker . 1959 . The Landmarks of Tomorrow . Heineman , New York , NY . [ 51 ] Peter F . Drucker . 1999 . Knowledge - Worker Productivity : The Biggest Challenge . California Management Review 41 , 2 ( 1999 ) , 79 – 94 . https : / / doi . org / 10 . 2307 / 41165987 [ 52 ] Edelman . 2019 . 2019 Edelman AI Survey . [ 53 ] Madeleine Clare Elish . 2019 . Moral crumple zones : Cautionary tales in human - robot interaction . Engaging Science , Technology , and Society 5 ( 2019 ) , 40 – 60 . [ 54 ] Tyna Eloundou , Sam Manning , Pamela Mishkin , and Daniel Rock . 2023 . GPTs are GPTs : An Early Look at the Labor Market Impact Potential of Large Language Models . arXiv : 2303 . 10130 [ econ . GN ] [ 55 ] Ingrid Erickson and Mohammad Hossein Jarrahi . 2016 . Infrastructuring and the Challenge of Dynamic Seams in Mobile Knowledge Work . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 1323 – 1336 . https : / / doi . org / 10 . 1145 / 2818048 . 2820015 [ 56 ] Ed Felten , Manav Raj , and Robert Seamans . 2023 . How will Language Modelers like ChatGPT Affect Occupations and Industries ? arXiv : 2303 . 01157 [ econ . GN ] [ 57 ] Jessica Fjeld , Nele Achten , Hannah Hilligoss , Adam Nagy , and Madhulika Srikumar . 2020 . Principled artificial intelligence : Mapping consensus in ethical and rights - based approaches to principles for AI . Berkman Klein Center Research Publication ( 2020 ) . [ 58 ] Sarah Fox , Rachel Rose Ulgado , and Daniela Rosner . 2015 . Hacking Culture , Not Devices : Access and Recognition in Feminist Hackerspaces . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( Vancouver , BC , Canada ) ( CSCW ’15 ) . Association for Computing Machinery , New York , NY , USA , 56 – 68 . https : / / doi . org / 10 . 1145 / 2675133 . 2675223 26 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries [ 59 ] Megan Fritts and Frank Cabrera . 2021 . AI recruitment algorithms and the dehumanization problem . Ethics and Information Technology 23 ( 2021 ) , 791 – 801 . [ 60 ] Cary Funk , Alec Tyson , Brian Kennedy , and Courtney Johnson . 2020 . Science and Scientists Held in High Esteem Across Global Publics . Pew Research Center ( September 2020 ) . [ 61 ] John Kenneth Galbraith . 2007 . The New Industrial State . Vol . 9 . Princeton University Press , Princeton , NJ . [ 62 ] A . Shaji George and A . S . Hovan George . 2023 . A Review of ChatGPT AI’s Impact on Several Business Sectors . International Innovation Journal 1 ( February 2023 ) , 9 – 23 . https : / / doi . org / 10 . 5281 / zenodo . 7644359 [ 63 ] Katy Ilonka Gero , Tao Long , and Lydia B Chilton . 2023 . Social Dynamics of AI Support in Creative Writing . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 245 , 15 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3580782 [ 64 ] Mareike Glöss , Moira McGregor , and Barry Brown . 2016 . Designing for Labour : Uber and the On - Demand Mobile Workforce . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( San Jose , California , USA ) ( CHI ’16 ) . Association for Computing Machinery , New York , NY , USA , 1632 – 1643 . https : / / doi . org / 10 . 1145 / 2858036 . 2858476 [ 65 ] Ian Goodfellow , Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron Courville , and Yoshua Bengio . 2014 . Generative Adversarial Nets . In Advances in Neural Information Processing Systems , Z . Ghahramani , M . Welling , C . Cortes , N . Lawrence , and K . Q . Weinberger ( Eds . ) , Vol . 27 . Curran Associates , Inc . , Montreal , Canada . https : / / proceedings . neurips . cc / paper _ files / paper / 2014 / file / 5ca3e9b122f61f8f06494c97b1afccf3 - Paper . pdf [ 66 ] Ben Green . 2022 . The Flaws of policies requiring human oversight of government algorithms . Computer Law & Security Review 45 ( 2022 ) , 105681 . https : / / doi . org / 10 . 1016 / j . clsr . 2022 . 105681 [ 67 ] BenGreenandYilingChen . 2019 . ThePrinciplesandLimitsofAlgorithm - in - the - LoopDecisionMaking . ProceedingsoftheACMonHuman - Computer Interaction 3 , CSCW , Article 50 ( 2019 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3359152 [ 68 ] Matthew Guzdial , Nicholas Liao , Jonathan Chen , Shao - Yu Chen , Shukan Shah , Vishwa Shah , Joshua Reno , Gillian Smith , and Mark O . Riedl . 2019 . Friend , Collaborator , Student , Manager : How Design of an AI - Driven Game Level Editor Affects Creators . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3290605 . 3300854 [ 69 ] Susan Hao , Piyush Kumar , Sarah Laszlo , Shivani Poddar , Bhaktipriya Radharapu , and Renee Shelby . 2023 . Safety and Fairness for Content Moderation in Generative Models . arXiv : 2306 . 06135 [ cs . LG ] [ 70 ] Christina N . Harrington , Katya Borgos - Rodriguez , and Anne Marie Piper . 2019 . Engaging Low - Income African American Older Adults in Health Discussions through Community - Based Design Workshops . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 15 . https : / / doi . org / 10 . 1145 / 3290605 . 3300823 [ 71 ] Gillian R . Hayes . 2011 . The Relationship of Action Research to Human - Computer Interaction . ACM Transactions on Computer - Human Interaction 18 , 3 , Article 15 ( Aug . 2011 ) , 20 pages . https : / / doi . org / 10 . 1145 / 1993060 . 1993065 [ 72 ] Judith H . Heerwagen , Kevin Kampschroer , Kevin M . Powell , and Vivian Loftness . 2004 . Collaborative knowledge work environments . Building Research & Information 32 , 6 ( 2004 ) , 510 – 528 . https : / / doi . org / 10 . 1080 / 09613210412331313025 [ 73 ] Stewart Heritage . 2022 . Could ChatGPT write my book — and feed my kids ? The Sunday Times ( 11 Dec . 2022 ) . https : / / www . thetimes . co . uk / article / could - chatgpt - write - my - book - and - feed - my - kids - 7972vx0xp [ 74 ] HLEG . 2018 . A multi - dimensional approach to disinformation : Report of the independent High level Group on fake news and online disinformation . https : / / data . europa . eu / doi / 10 . 2759 / 739290 [ 75 ] Han Hu , Quentin Jadoul , and Angelika Reich . 2021 . How banks can build their future workforce—today . McKinsey & Company ( 17 Aug . 2021 ) . https : / / www . mckinsey . com / industries / financial - services / our - insights / how - banks - can - build - their - future - workforce - today [ 76 ] Angel Hsing - Chi Hwang . 2022 . Too Late to Be Creative ? AI - Empowered Tools in Creative Processes . In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI EA ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 38 , 9 pages . https : / / doi . org / 10 . 1145 / 3491101 . 3503549 [ 77 ] NannaInie , JeanetteFalk , andSteveTanimoto . 2023 . DesigningParticipatoryAI : CreativeProfessionals’WorriesandExpectationsaboutGenerative AI . In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI EA ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 82 , 8 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3585657 [ 78 ] Maurice Jakesch , Advait Bhat , Daniel Buschek , Lior Zalmanson , and Mor Naaman . 2023 . Co - Writing with Opinionated Language Models Affects Users’ Views . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 111 , 15 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3581196 [ 79 ] BrianD . Janz , JasonA . Colquitt , andRaymondA . Noe . 1997 . KnowledgeWorkerTeamEffectiveness : TheRoleofAutonomy , Interdependence , Team Development , and Contextual Support Variables . Personnel Psychology 50 , 4 ( 1997 ) , 877 – 904 . https : / / doi . org / 10 . 1111 / j . 1744 - 6570 . 1997 . tb01486 . x [ 80 ] Jona Jaupi . 2023 . YOU’VE BEEN REPLACED : I’m going to lose my job to an AI – ChatGPT does an hour of my work in seconds . The U . S . Sun ( 24 Jan . 2023 ) . https : / / www . the - sun . com / tech / 7211994 / lose - job - ai - chatgpt - work - hour - seconds / [ 81 ] Ravin Jesuthasan . 2023 . Cutting Through The Hype Cycle Of Generative AI . Forbes ( 19 Aug . 2023 ) . https : / / www . forbes . com / sites / ravinjesuthasan / 2023 / 08 / 19 / cutting - through - the - hype - cycle - of - generative - ai [ 82 ] Bhautik Joshi . 2023 . Is AI Going to Replace Creative Professionals ? Interactions 30 , 5 ( Aug . 2023 ) , 24 – 29 . https : / / doi . org / 10 . 1145 / 3610529 27 Woodruff et al . [ 83 ] Shivani Kapania , Oliver Siy , Gabe Clapper , Azhagu Meena SP , and Nithya Sambasivan . 2022 . “Because AI is 100 % Right and Safe” : User Attitudes and Sources of AI Authority in India . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . ACM , New York , NY , USA , Article 158 , 18 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517533 [ 84 ] Yarden Katz . 2020 . Artificial Whiteness : Politics and Ideology in Artificial Intelligence . Columbia University Press , New York , NY . [ 85 ] Majeed Kazemitabaar , Justin Chow , Carl Ka To Ma , Barbara J . Ericson , David Weintrop , and Tovi Grossman . 2023 . Studying the Effect of AI Code Generators on Supporting Novice Learners in Introductory Programming . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 455 , 23 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3580919 [ 86 ] Patrick Gage Kelley , Celestina Cornejo , Lisa Hayes , Ellie Shuo Jin , Aaron Sedley , Kurt Thomas , Yongwei Yang , and Allison Woodruff . 2023 . " There will be less privacy , of course " : How and why people in 10 countries expect AI will affect privacy in the future . In Nineteenth Symposium on Usable PrivacyandSecurity ( SOUPS2023 ) . USENIXAssociation , Anaheim , CA , 579 – 603 . https : / / www . usenix . org / conference / soups2023 / presentation / kelley [ 87 ] Patrick Gage Kelley , Yongwei Yang , Courtney Heldreth , Christopher Moessner , Aaron Sedley , Andreas Kramm , David T . Newman , and Allison Woodruff . 2021 . Exciting , Useful , Worrying , Futuristic : Public Perception of Artificial Intelligence in 8 Countries . In Proceedings of the 2021 AAAI / ACM Conference on AI , Ethics , and Society ( Virtual Event , USA ) ( AIES ’21 ) . Association for Computing Machinery , New York , NY , USA , 627 – 637 . https : / / doi . org / 10 . 1145 / 3461702 . 3462605 [ 88 ] Patrick Gage Kelley , Yongwei Yang , Courtney Heldreth , Christopher Moessner , Aaron M . Sedley , and Allison Woodruff . 2021 . “Mixture of amazement at the potential of this technology and concern about possible pitfalls” : Public sentiment towards AI in 15 countries . Bulletin of the IEEE Computer Society Technical Committee on Data Engineering 44 , 4 ( 2021 ) , 28 – 46 . [ 89 ] Diederik P . Kingma and Max Welling . 2013 . Auto - encoding Variational Bayes . arXiv : 1312 . 6114 [ stat . ML ] [ 90 ] K . Knill and S . Young . 1997 . Hidden Markov Models in Speech and Language Processing . Springer Netherlands , Dordrecht , 27 – 68 . https : / / doi . org / 10 . 1007 / 978 - 94 - 017 - 1183 - 8 _ 2 [ 91 ] Alex Krizhevsky , Ilya Sutskever , and Geoffrey E Hinton . 2012 . ImageNet Classification with Deep Convolutional Neural Networks . In Advances in Neural Information Processing Systems , F . Pereira , C . J . Burges , L . Bottou , and K . Q . Weinberger ( Eds . ) , Vol . 25 . Curran Associates , Inc . , Lake Tahoe , NV , USA . https : / / proceedings . neurips . cc / paper _ files / paper / 2012 / file / c399862d3b9d6b76c8436e924a68c45b - Paper . pdf [ 92 ] Constantin Lagios , Gaetane Caesens , Nathan Nguyen , and Florence Stinglhamber . 2021 . Explaining the negative consequences of organizational dehumanization . Journal of Personnel Psychology 21 , 2 ( 2021 ) , 86 – 93 . [ 93 ] Benjamin Lange , Amanda McCroskery , Ben Zevenbergen , Geoff Keeling , Sandra Blascovich , Kyle Pedersen , Alison Lentz , and Blaise Agüera y Arcas . 2023 . Engaging Google Teams Through Moral Imagination : A Bottom - Up Approach for Responsible Innovation and Ethical Culture Change in Technology Companies . arXiv : 2306 . 06901 [ cs . CY ] [ 94 ] Christopher A . Le Dantec and Sarah Fox . 2015 . Strangers at the Gate : Gaining Access , Building Rapport , and Co - Constructing Community - Based Research . In Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing ( Vancouver , BC , Canada ) ( CSCW ’15 ) . Association for Computing Machinery , New York , NY , USA , 1348 – 1358 . https : / / doi . org / 10 . 1145 / 2675133 . 2675147 [ 95 ] Mike Lewis , Yinhan Liu , Naman Goyal , Marjan Ghazvininejad , Abdelrahman Mohamed , Omer Levy , Ves Stoyanov , and Luke Zettlemoyer . 2019 . Bart : Denoising sequence - to - sequence pre - training for natural language generation , translation , and comprehension . arXiv : 1910 . 13461 [ cs . CL ] [ 96 ] Ze Liu , Yutong Lin , Yue Cao , Han Hu , Yixuan Wei , Zheng Zhang , Stephen Lin , and Baining Guo . 2021 . Swin transformer : Hierarchical vision transformer using shifted windows . In Proceedings of the IEEE / CVF International Conference on Computer Vision ( Virtual Event , USA ) . 10012 – 10022 . [ 97 ] Lloyd’s Register Foundation . 2020 . World Risk Poll Report 2019 . [ 98 ] Samantha Lock . 2022 . What is AI chatbot phenomenon ChatGPT and could it replace humans ? The Guardian ( 5 Dec . 2022 ) . https : / / www . theguardian . com / technology / 2022 / dec / 05 / what - is - ai - chatbot - phenomenon - chatgpt - and - could - it - replace - humans [ 99 ] Ryan Louie , Andy Coenen , Cheng Zhi Huang , Michael Terry , and Carrie J . Cai . 2020 . Novice - AI Music Co - Creation via AI - Steering Tools for Deep Generative Models . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3313831 . 3376739 [ 100 ] Xinyi Lu , Simin Fan , Jessica Houghton , Lu Wang , and Xu Wang . 2023 . ReadingQuizMaker : A Human - NLP Collaborative System That Supports Instructors to Design High - Quality Reading Quiz Questions . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 454 , 18 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3580957 [ 101 ] Gary Marcus . 2019 . An Epidemic of AI Misinformation . The Gradient ( 30 Nov . 2019 ) . https : / / thegradient . pub / an - epidemic - of - ai - misinformation / [ 102 ] Bernard Marr . 2023 . A Short History Of ChatGPT : How We Got To Where We Are Today . Forbes ( 19 May 2023 ) . https : / / www . forbes . com / sites / bernardmarr / 2023 / 05 / 19 / a - short - history - of - chatgpt - how - we - got - to - where - we - are - today / ? sh = 286b1544674f [ 103 ] Alice E . Marwick and Rebecca Lewis . 2017 . Media Manipulation and Disinformation Online . Report . Data & Society Research Institute . https : / / datasociety . net / library / media - manipulation - and - disinfo - online [ 104 ] Cade Metz . 2023 . ‘The Godfather of A . I . ’ Leaves Google and Warns of Danger Ahead . The New York Times ( 1 May 2023 ) . https : / / www . nytimes . com / 2023 / 05 / 01 / technology / ai - google - chatbot - engineer - quits - hinton . html [ 105 ] David Meyer . 2023 . A . I . ’s threat to jobs is not hypothetical—just ask IBM’s boss . Yahoo Finance . https : / / finance . yahoo . com / news / threat - jobs - not - hypothetical - just - 173432317 . html [ 106 ] Midjourney , Inc . 2022 . Midjourney . https : / / www . midjourney . com / 28 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries [ 107 ] Tomas Mikolov , Martin Karafiát , Lukas Burget , Jan Cernock ` y , and Sanjeev Khudanpur . 2010 . Recurrent neural network based language model . . In Interspeech . ICSA , Makuhari , Chiba , Japan , 1045 – 1048 . [ 108 ] Vincent Mosco . 2008 . Knowledge Workers of the World ! Unite ? Communication , Culture and Critique 1 , 1 ( 02 2008 ) , 105 – 115 . https : / / doi . org / 10 . 1111 / j . 1753 - 9137 . 2007 . 00011 . x [ 109 ] Mozilla . 2019 . We Asked People Around the World How They Feel About Artificial Intelligence . Here’s What We Learned . https : / / foundation . mozilla . org / en / blog / we - asked - people - around - the - world - how - they - feel - about - artificial - intelligence - heres - what - we - learned / [ 110 ] Michael Muller , Lydia B . Chilton , Anna Kantosalo , Charles Patrick Martin , and Greg Walsh . 2022 . GenAICHI : Generative AI and HCI . In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI EA ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 110 , 7 pages . https : / / doi . org / 10 . 1145 / 3491101 . 3503719 [ 111 ] Kevin P . Murphy . 2022 . Probabilistic machine learning : an introduction . MIT Press , Boston , MA . [ 112 ] Lisa - Maria Neudert , Aleksi Knuutila , and Philip N . Howard . 2020 . Global Attitudes Towards AI , Machine Learning & Automated Decision Making : Implications for Involving Artificial Intelligence in Public Service and Good Governance . Technical Report . Oxford Internet Institute . [ 113 ] Gemma Newlands . 2021 . Algorithmic surveillance in the gig economy : The organization of work through Lefebvrian conceived space . Organization Studies 42 , 5 ( 2021 ) , 719 – 737 . [ 114 ] Andrew Ng . 2017 . Andrew Ng : Artificial Intelligence is the New Electricity . Stanford Graduate School of Business . https : / / www . youtube . com / watch ? v = 21EiKfQYZXc [ 115 ] Northeastern University and Gallup . 2018 . Optimism and Anxiety : Views on the Impact of Artificial Intelligence and Higher Education’s Response . [ 116 ] Shakked Noy and Whitney Zhang . 2023 . Experimental evidence on the productivity effects of generative artificial intelligence . Science 381 , 6654 ( 2023 ) , 187 – 192 . https : / / doi . org / 10 . 1126 / science . adh2586 [ 117 ] Office of the Surgeon General . 2023 . Our Epidemic of Loneliness and Isolation : The U . S . Surgeon General’s Advisory on the Healing Effects of Social Connection and Community . https : / / www . hhs . gov / sites / default / files / surgeon - general - social - connection - advisory . pdf [ 118 ] Hodan Omaar . 2023 . Claims About Generative AI Replacing Jobs Are Hyperbolic and Misleading . https : / / datainnovation . org / 2023 / 04 / claims - about - generative - ai - replacing - are - hyperbolic - and - misleading / [ 119 ] OpenAI . 2022 . Codex . https : / / openai . com / codex / [ 120 ] OpenAI . 2022 . DALL - E 2 . https : / / openai . com / dall - e - 2 [ 121 ] OpenAI . 2023 . ChatGPT . https : / / chat . openai . com / [ 122 ] Monica Penick and Christopher Long . 2019 . The rise of everyday design : The arts and crafts movement in Britain and America . Yale University Press , New Haven , Connecticut . [ 123 ] Ritika Poddar , Rashmi Sinha , Mor Naaman , and Maurice Jakesch . 2023 . AI Writing Assistants Influence Topic Choice in Self - Presentation . In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI EA ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 29 , 6 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3585893 [ 124 ] Pasi Pyöriä . 2005 . The concept of knowledge work revisited . Journal of Knowledge Management 9 , 3 ( 2005 ) , 116 – 127 . [ 125 ] Lee Rainie , Cary Funk , Monica Anderson , and Alec Tyson . 2022 . AI and human enhancement : Americans’ openness is tempered by a range of concerns . Technical Report . Pew Research Center . [ 126 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical text - conditional image generation with clip latents . arXiv : 2204 . 06125 [ cs . CV ] [ 127 ] AdityaRamesh , MikhailPavlov , GabrielGoh , ScottGray , ChelseaVoss , AlecRadford , MarkChen , andIlyaSutskever . 2021 . Zero - shotText - to - Image Generation . In International Conference on Machine Learning ( Virtual Event , USA ) . PMLR , 8821 – 8831 . [ 128 ] Google Research . 2022 . Imagen : Text to Image Diffusion Models . https : / / imagen . research . google . [ 129 ] Douglas A . Reynolds . 2009 . Gaussian Mixture Models . Vol . 741 . Springer , Berlin , Germany , 659 – 663 . [ 130 ] Melissa Roemmele and Andrew S . Gordon . 2015 . Creative help : A story writing assistant . In Interactive Storytelling : 8th International Conference on Interactive Digital Storytelling ( ICIDS 2015 ) . Springer , Copenhagen , Denmark , 81 – 92 . [ 131 ] Melissa Roemmele and Andrew S . Gordon . 2018 . Automated Assistance for Creative Writing with an RNN Language Model . In Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion ( Tokyo , Japan ) ( IUI ’18 Companion ) . Association for Computing Machinery , New York , NY , USA , Article 21 , 2 pages . https : / / doi . org / 10 . 1145 / 3180308 . 3180329 [ 132 ] KevinRoose . 2023 . Bing’sA . I . Chat : ‘IWanttoBeAlive’ . TheNewYorkTimes ( 16Feb . 2023 ) . https : / / www . nytimes . com / 2023 / 02 / 16 / technology / bing - chatbot - transcript . html [ 133 ] Daniela K . Rosner , Saba Kawas , Wenqi Li , Nicole Tilly , and Yi - Chen Sung . 2016 . Out of Time , Out of Place : Reflections on Design Workshops as a Research Method . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 1131 – 1141 . https : / / doi . org / 10 . 1145 / 2818048 . 2820021 [ 134 ] Sandeep Sahai . 2023 . Generative AI : A Big Bang Moment For FinTech . Forbes ( 26 July 2023 ) . https : / / www . forbes . com / sites / forbestechcouncil / 2023 / 07 / 26 / generative - ai - a - big - bang - moment - for - fintech [ 135 ] Sami Sarsa , Paul Denny , Arto Hellas , and Juho Leinonen . 2022 . Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models . In Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1 ( Lugano and Virtual Event , Switzerland ) ( ICER ’22 ) . Association for Computing Machinery , New York , NY , USA , 27 – 43 . https : / / doi . org / 10 . 1145 / 3501385 . 3543957 29 Woodruff et al . [ 136 ] Neil Selwyn , Beatriz Gallo Cordoba , Mark Andrejevic , and Liz Campbell . 2020 . AI for social good : Australian public attitudes toward AI and society . Technical Report . Monash Data Futures Institute . [ 137 ] Graham Sewell and Laurent Taskin . 2015 . Out of sight , out of mind in a new world of work ? Autonomy , control , and spatiotemporal scaling in telework . Organization studies 36 , 11 ( 2015 ) , 1507 – 1529 . [ 138 ] Hanieh Shakeri , Carman Neustaedter , and Steve DiPaola . 2021 . SAGA : Collaborative Storytelling with GPT - 3 . In Companion Publication of the 2021 Conference on Computer Supported Cooperative Work and Social Computing ( Virtual Event , USA ) ( CSCW ’21 ) . Association for Computing Machinery , New York , NY , USA , 163 – 166 . https : / / doi . org / 10 . 1145 / 3462204 . 3481771 [ 139 ] Edward H . Shortliffe . 1993 . Doctors , Patients , and Computers : Will Information Technology Dehumanize Health - Care Delivery ? Proceedings of the American Philosophical Society 137 , 3 ( 1993 ) , 390 – 398 . http : / / www . jstor . org / stable / 986999 [ 140 ] EricSiegel . 2023 . TheAIHypeCycleIsDistractingCompanies . HarvardBusinessReview . https : / / hbr . org / 2023 / 06 / the - ai - hype - cycle - is - distracting - companies [ 141 ] Elisabeth Simbürger and Mike Neary . 2016 . Taxi professors : academic labour in Chile , a critical - practical response to the politics of worker identity . Workplace : A Journal for Academic Labor 28 ( 2016 ) , 48 – 73 . https : / / doi . org / 10 . 14288 / workplace . v0i28 . 186212 [ 142 ] Nikhil Singh , Guillermo Bernal , Daria Savchenko , and Elena L . Glassman . 2022 . Where to Hide a Stolen Elephant : Leaps in Creative Writing with Multimodal Machine Intelligence . ACM Transactions on Compututer - Human Interaction ( Feb . 2022 ) , 1 – 53 . https : / / doi . org / 10 . 1145 / 3511599 [ 143 ] Aaron Smith . 2018 . Public Attitudes Toward Computer Algorithms . Pew Research Center ( Nov . 2018 ) . [ 144 ] Yang Song and Stefano Ermon . 2019 . Generative Modeling by Estimating Gradients of the Data Distribution . In Advances in Neural Information Processing Systems , H . Wallach , H . Larochelle , A . Beygelzimer , F . d ' Alché - Buc , E . Fox , and R . Garnett ( Eds . ) , Vol . 32 . Curran Associates , Inc . , Vancouver , Canada , 1 – 13 . https : / / proceedings . neurips . cc / paper _ files / paper / 2019 / file / 3001ef257407d5a371a96dcd947c7d93 - Paper . pdf [ 145 ] Fabian Stephany . 2021 . One size does not fit all : Constructing complementary digital reskilling strategies using online labour market data . Big Data & Society 8 , 1 ( 2021 ) , 20539517211003120 . https : / / doi . org / 10 . 1177 / 20539517211003120 [ 146 ] Minhyang ( Mia ) Suh , Emily Youngblom , Michael Terry , and Carrie J Cai . 2021 . AI as Social Glue : Uncovering the Roles of Deep Generative AI during Social Music Composition . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 582 , 11 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445219 [ 147 ] The European Commission . 2017 . Special Eurobarometer 460 : Attitudes towards the impact of digitisation and automation on daily life . [ 148 ] Romal Thoppilan , Daniel De Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng - Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , YaGuang Li , Hongrae Lee , Huaixiu Steven Zheng , Amin Ghafouri , Marcelo Menegali , Yanping Huang , Maxim Krikun , Dmitry Lepikhin , James Qin , Dehao Chen , Yuanzhong Xu , Zhifeng Chen , Adam Roberts , Maarten Bosma , Vincent Zhao , Yanqi Zhou , Chung - Ching Chang , Igor Krivokon , Will Rusch , Marc Pickett , Pranesh Srinivasan , Laichee Man , Kathleen Meier - Hellstern , Meredith Ringel Morris , Tulsee Doshi , Renelito Delos Santos , Toju Duke , Johnny Soraker , Ben Zevenbergen , Vinodkumar Prabhakaran , Mark Diaz , Ben Hutchinson , Kristen Olson , Alejandra Molina , Erin Hoffman - John , Josh Lee , Lora Aroyo , Ravi Rajakumar , Alena Butryna , Matthew Lamm , Viktoriya Kuzmina , Joe Fenton , Aaron Cohen , Rachel Bernstein , Ray Kurzweil , Blaise Agüera y Arcas , Claire Cui , Marian Croak , Ed Chi , and Quoc Le . 2022 . LaMDA : Language Models for Dialog Applications . arXiv : 2201 . 08239 [ cs . CL ] [ 149 ] Sarina Till , Jaydon Farao , Toshka Lauren Coleman , Londiwe Deborah Shandu , Nonkululeko Khuzwayo , Livhuwani Muthelo , Masenyani Oupa Mbombi , Mamare Bopane , Molebogeng Motlhatlhedi , Gugulethu Mabena , Alastair Van Heerden , Tebogo Maria Mothiba , Shane Norris , Nervo Verdezoto Dias , and Melissa Densmore . 2022 . Community - Based Co - Design across Geographic Locations and Cultures : Methodological Lessons from Co - Design Workshops in South Africa . In Proceedings of the Participatory Design Conference 2022 - Volume 1 ( Newcastle upon Tyne , United Kingdom ) ( PDC ’22 ) . Association for Computing Machinery , New York , NY , USA , 120 – 132 . https : / / doi . org / 10 . 1145 / 3536169 . 3537786 [ 150 ] Chris Vallance . 2023 . AI could replace equivalent of 300 million jobs . BBC News ( 28 March 2023 ) . https : / / www . bbc . com / news / technology - 65102150 [ 151 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N . Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 . Attention is All you Need . In Advances in Neural Information Processing Systems , I . Guyon , U . Von Luxburg , S . Bengio , H . Wallach , R . Fergus , S . Vishwanathan , and R . Garnett ( Eds . ) , Vol . 30 . Curran Associates , Inc . , Long Beach , CA , USA , 1 – 11 . https : / / proceedings . neurips . cc / paper _ files / paper / 2017 / file / 3f5ee243547dee91fbd053c1c4a845aa - Paper . pdf [ 152 ] Gina Vega and Louis Brennan . 2000 . Isolation and technology : The human disconnect . Journal of Organizational Change Management 13 , 5 ( 2000 ) , 468 – 481 . [ 153 ] Mathias Peter Verheijden and Mathias Funk . 2023 . Collaborative Diffusion : Boosting Designerly Co - Creation with Generative AI . In Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems ( Hamburg , Germany ) ( CHI EA ’23 ) . Association for Computing Machinery , New York , NY , USA , Article 73 , 8 pages . https : / / doi . org / 10 . 1145 / 3544549 . 3585680 [ 154 ] GerritDeVynck . 2023 . Everystart - upisanAIcompanynow . Bubblefearsaregrowing . WashingtonPost ( 5Aug . 2023 ) . https : / / www . washingtonpost . com / technology / 2023 / 08 / 05 / ai - hype - bubble - chatgpt / [ 155 ] Ben Wagner . 2019 . Liable , but Not in Control ? Ensuring Meaningful Human Agency in Automated Decision - Making Systems . Policy & Internet 11 , 1 ( 2019 ) , 104 – 122 . [ 156 ] Justin D . Weisz , Michael Muller , Stephanie Houde , John Richards , Steven I . Ross , Fernando Martinez , Mayank Agarwal , and Kartik Talamadupula . 2021 . Perfection Not Required ? Human - AI Partnerships in Code Translation . In 26th International Conference on Intelligent User Interfaces ( College Station , TX , USA ) ( IUI ’21 ) . Association for Computing Machinery , New York , NY , USA , 402 – 412 . https : / / doi . org / 10 . 1145 / 3397481 . 3450656 [ 157 ] Matt Welsh . 2022 . The End of Programming . Commun . ACM 66 , 1 ( Dec . 2022 ) , 34 – 35 . https : / / doi . org / 10 . 1145 / 3570220 30 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries [ 158 ] EtienneWenger , RichardMcDermott , andWilliamM . Snyder . 2002 . CultivatingCommunitiesofPractice . HarvardBusinessSchoolPress , Cambridge , MA , USA . [ 159 ] Gwen White , Thilini Ariyachandra , and David White . 2019 . Big Data , Ethics , and Social Impact Theory – A Conceptual Framework . Journal of Management & Engineering Integration 12 , 1 ( 2019 ) , 9 – 15 . [ 160 ] Brianna Wiest . 2018 . ’Permalancing’ Is The New Self - Employment Trend You’ll Be Seeing Everywhere . Forbes ( 13 June 2018 ) . https : / / www . forbes . com / sites / briannawiest / 2018 / 06 / 13 / permalancing - is - the - new - self - employment - trend - youll - be - seeing - everywhere / ? sh = 74d0a4dca383 [ 161 ] Rebecca Willis . 2019 . The use of composite narratives to present interview findings . Qualitative Research 19 , 4 ( 2019 ) , 471 – 480 . https : / / doi . org / 10 . 1177 / 1468794118787711 [ 162 ] Daijin Yang , Yanpeng Zhou , Zhiyuan Zhang , Toby Jia - Jun Li , and Ray LC . 2022 . AI as an Active Writer : Interaction strategies with generated text in human - AI collaborative fiction writing . In Joint Proceedings of the ACM IUI Workshops , Vol . 10 . CEUR - WS Team , Association for Computing Machinery , Helsinki , Finland , 1 – 11 . [ 163 ] YouGov . 2021 . International Technology Report 2021 : Automation & AI . [ 164 ] Ann Yuan , Andy Coenen , Emily Reif , and Daphne Ippolito . 2022 . Wordcraft : Story Writing With Large Language Models . In 27th International Conference on Intelligent User Interfaces ( Helsinki , Finland ) ( IUI ’22 ) . Association for Computing Machinery , New York , NY , USA , 841 – 852 . https : / / doi . org / 10 . 1145 / 3490099 . 3511105 [ 165 ] Saadia Zahidi . 2023 . The Future of Jobs Report 2023 . World Economic Forum ( 30 April 2023 ) . https : / / www . weforum . org / reports / the - future - of - jobs - report - 2023 [ 166 ] Baobao Zhang and Allan Dafoe . 2019 . Artificial intelligence : American attitudes and trends . Available at SSRN 3312874 ( 2019 ) . [ 167 ] Chengbo Zheng , Dakuo Wang , April Yi Wang , and Xiaojuan Ma . 2022 . Telling Stories from Computational Notebooks : AI - Assisted Presentation Slides Creation for Presenting Data Science Work . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 53 , 20 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517615 31 Woodruff et al . A INDUSTRY & PARTICIPANT DETAILS Industries Brief Overview Recruitment For Roles Advertising Conduct promotional work which aims to sell a project or service Central : Art director , Creative director Secondary : Copywriter , Graphic designer , Illus - trator , Animator , Social media or SEO strategist , Media planner , Account manager BusinessCommunications Manage internal and external messag - ing to audiences such as employees , cus - tomers , stakeholders , the media , or the general public Central : Internal communications director , Communi - cations specialist , Administrative assistant Secondary : HR expert , Content strategist , Cor - porate PR Education Teach students and contribute to their learning and development Central : Middle school & high school teachers , Course instructor or professor ( post - secondary ) Secondary : School principal or assistant princi - pal , Freelance tutor , Reading specialist Journalism Produce and disseminate reports to in - form society on events , people , ideas , and anything else that might be considered “newsworthy” Central : Newspaper reporter , Columnist , Editorial writer Secondary : Copyeditor , Fact checker , Section / Content editor , Newsroom editor / manager , Freelance reporter ( print / online or broadcast ) Law Support and enforce established legal standards ; advocate for clients Central : Junior and senior associates Secondary : Law firm partner , Freelance attor - ney , Paralegal , Law clerk , Public defender Mental Health Support , stabilize , and improve individ - uals’ mental health Central : Psychologist , Therapist , Psychiatrist Secondary : Social worker , Case manager / coordinator , Clinical counselor SoftwareDevelopment Design , program , deploy , and maintain software Central : Junior and senior full - stack developers Secondary : Database engineer , Data scientist , Product manager Table 4 . Overview of how we thought about each industry , including the roles we described as central and secondary shared with our recruitment partners . 32 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Participants Industries Location 𝑛 Age Range Gender Time in Industry Advertising New York City 8 26 – 38 Women : 4 2 - 5 years : 2 Men : 4 6 - 10 years : 1 10 + years : 5 Business Columbus 8 24 – 54 Women : 4 2 - 5 years : 3 Communications Men : 4 6 - 10 years : 1 10 + years : 4 Education Oakland 7 29 – 51 Women : 6 2 - 5 years : 2 Men : 1 6 - 10 years : 1 10 + years : 4 Journalism New York City 8 25 – 42 Women : 5 2 - 5 years : 3 Men : 3 6 - 10 years : 2 10 + years : 3 Law Columbus 8 30 – 64 Women : 4 2 - 5 years : 3 Men : 4 6 - 10 years : 2 10 + years : 3 Mental Health Oakland 8 32 – 50 Women : 5 2 - 5 years : 2 Men : 3 6 - 10 years : 1 10 + years : 5 Software New York City 7 25 – 36 Women : 3 2 - 5 years : 3 Development Men : 4 6 - 10 years : 1 10 + years : 3 Table 5 . Details about the location and participant makeup of each industry group . Gender was self - reported by participants from a range of options , including the option to self - describe . Recruitment was limited to participants who had been in their industry for two or more years . 33 Woodruff et al . B INTRODUCTION TO GENERATIVE AI A key component of our workshops was offering participants a foundation for thinking about generative AI . To this end , early in each workshop we led an education section about 40 minutes in length . We began with a 20 - minute presentation covering : • a shared definition of AI • a very condensed history of AI and generative AI , focusing on key concepts like the early aims in developing AI • a brief , non - technical explanation of what has changed recently with transformer models and LLMs • 15 key concepts regarding characteristics , benefits , and risks of generative AI systems , to refer to throughout the workshop Participants were encouraged to ask questions at any point during the presentation , and then we spent an additional 20 minutes on further questions and discussion . In each workshop , the presentation and Q & A was led by one of two authors , both of whom are researchers who work in AI . We lightly customized materials to each group’s industry . The definition we provided is : “Artificial Intelligence is the ability of a computer or a machine to think or learn , ” and we provided additional color on how we think about the terms : “computer or machine , ” “think , ” and “learn . ” The 15 concepts we shared include the following : Bias — Generative AI tools may reflect social biases that are present in their training data Bland — Generative AI often generates “flat” or generic text , unless explicitly directed to do otherwise Brainstorming — Generative AI tools can create outlines , lists , drafts , possible solutions , and more Emergent Properties — Generative AI models may seem to possess abilities they were not designed to have Falsehoods — Generative AI can fabricate information or sources , or get facts wrong , yet seem confident and compelling Grammatical — Content generated by text - based Generative AI tools can be well - written , using good syntax and avoiding typos Identifies Tacit Structure — Generative AI can uncover steps and processes which were not previously articu - lated Memorization / Privacy Breaches — Generative AI may generate content identical to its training data Mimicry — Generative AI can be asked to mimic genre , tone , phrasing , visual style , or more Non - Deterministic — Generative AI models can give responses which are variable , not consistent . This means that when users input the same or similar prompts , the system may not respond in the same way Provenance Is Unclear — Generative AI tools may not be able to reliably trace specific content back to a direct source in training data Remixes — Generative AI always generates content based on its training data . It can recombine data in unique ways , but is limited to re - mixing training data Safety Not Guaranteed — Generative AI tools may have built - in safety systems to attempt to prevent certain types of content or topics , but these are not infallible Scale / Speed — Generative AI , like other AI and ML systems , is able to consider large amounts of data and handle many tasks , over and over again , extremely quickly 34 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Tweakable — Through “prompt engineering , ” Generative AI tools can often be influenced to generate content in a certain way 35 Woodruff et al . C ARTIFACTS Fig . 1 . E6 ’s industry map for education . During check - in participants were invited to draw a map of their industry or field . 36 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Fig . 2 . M2 ’s industry map for mental health . 37 Woodruff et al . Fig . 3 . One of A4 ’s change cards , discussing their expectations regarding generative AI’s ability to generate still images . We designed change cards to : ( 1 ) scaffold an envisioning process for individual participants about industry futures , through both open - and closed - ended questions about changes they expect ; ( 2 ) elicit reflection on the participant’s feelings about those changes , through an open - ended prompt ; and ( 3 ) capture data that participants could revisit and build on in collaborative discourse and workshop activities . The open - ended prompts on the card enabled each participant to flexibly specify anything they found meaningful to include , while closed - ended questions enabled us to determine concretely who participants thought would be impacted by change , and the drivers of that change . Participants completed change cards individually and then shared them in a facilitated discussion . 38 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Fig . 4 . One of L1 ’s change cards , discussing their expectations regarding quickly shifting demand for legal services . 39 Woodruff et al . Fig . 5 . J5 ’s policy suggests constraints on the use of generative AI in the newsroom . We lightly customized the policy handout to each group’s industry . Participants completed their policy handouts individually and then shared them in a facilitated discussion . 40 How Knowledge Workers Think Generative AI Will ( Not ) Transform Their Industries Fig . 6 . B6 ’s policy suggests generative AI might be used to make compliance review more efficient for high volume corporate communications . 41