Quantifying the Impact and Extent of Undocumented Biomedical Synonymy Supporting Information David R . Blair 1 , 2 , Kanix Wang 1 , 2 , Svetlozar Nestorov 3 , James A . Evans 3 , 4 , Andrey Rzhetsky 1 , 2 , 3 , 5 1 Institute for Genomics and Systems Biology , 2 Committee on Genetics , Genomics , and Systems Biology , 3 Computation Institute , 4 Department of Sociology , 5 Departments of Medicine and Human Genetics , University of Chicago , Chicago , IL , 60637 1 SI Materials and Methods 1 . 1 Re - write and Suppression Rules for the Biomedical Termi - nologies Consistent with previous observations [ 1 , 2 , 3 ] , we noticed that many of the terms con - tained within the UMLS Metathesaurus were inappropriate for natural language - oriented analyses ( ex : database - speciﬁc encodings , machine permutations , non - English language entries , etc . ) . Therefore , prior to generating the terminologies utilized in this study , we subjected the Metathesaurus to a thorough , rule - based ﬁltering , which was an extension of the method outlined in [ 3 ] . Consistent with the previous study [ 3 ] , our set of imple - mented rules can be broken into two categories : re - write and suppression rules . Below , we list each of them explicitly , providing examples when necessary . Re - write Rule 1 : Syntactic inversion . Given that a term contained a comma followed by a space , we split the phrase on the comma and placed the latter fragment at the beginning of the term ( ex : carcinoma , kidney → kidney carcinoma ) . Re - write Rule 2 : Removal of Possessives . All apostrophes were removed from posses - sive nouns ( ex : Addison’s diseases → Addisons disease ) . Re - write Rule 3 : Removal of Angular Brackets . All tokens bracketed by “ < ” and “ > ” were stripped from the terms . Re - write Rule 4 : Removal of Starting / Ending Parenthesis / Brackets . If a term began or ended with a token / tokens in parentheses / brackets , the tokens surrounded by the punctuation were stripped from the term ( ex : nausea ( symptom ) → nausea ) . Re - write Rule 5 : Removal of “NOS . ” The token “NOS , ” a non - speciﬁc designator , was removed from all terms . 1 Re - write Rule 6 : Removal of Punctuation . All internal punctuation was removed from the terms , replaced by either whitespace or the null character , depending on context . Re - write Rule 7 : Term Collapse . If two ( or more ) terms were simple token permuta - tions of one another ( after masking stop tokens 1 and stemming [ 4 , 5 ] ) , they were collapsed into a single term ( ex : disease of the mouth ≡ mouth disease ) . Suppression Rule 1 : Removal of Non - English Terms . All biomedical terms annotated with a language other than English were removed from the dataset . Suppression Rule 2 : Removal of Terms Containing “ @ . ” All terms containing the “ @ ” symbol were removed from the dataset . Suppression Rule 3 : Removal of Single Character Terms . If a term contained a single character after masking stop tokens , it was removed from the dataset . Suppression Rule 4 : Removal of Classiﬁcation Terms . Terms containing the tokens “NEC , ” “not elsewhere classiﬁed , unclassiﬁed , or “without mention” were removed from the dataset , following [ 3 ] . Suppression Rule 5 : Removal of EC Numbers . Terms consisting of Enzyme Classiﬁca - tion ( EC ) numbers were removed from the dataset . Suppression Rule 6 : Removal of Dosage Terms . All terms corresponding to a dosage speciﬁcation were removed from the dataset . Identiﬁcation of dosage terms is de - scribed in [ 3 ] . Suppression Rule 7 : Disallowed Term Types . We removed all terms annotated with the following types : FN , PM , CA2 , CA3 , CCN , CCS , CSY , UCUMAB , UCUMPT , UCUMSY and AD . These rules were applied using the CASPER software [ 3 ] and in - house python scripts . 1 . 2 Description of Normalization Algorithms Used in this Study Below , we brieﬂy describe the normalization algorithms used in this study . Except for MetaMap , all algorithms were written in Python and relied on the Whoosh search and indexing library 2 . Boolean Search : This algorithm normalized mentions by performing a simple AND - query , returning any concept annotated with a term that contained all of tokens constituting the mention of interest . Tokens were stemmed and stop words were 1 http : / / www . nlm . nih . gov / bsd / disted / pubmedtutorial / 020 _ 170 . html 2 https : / / pypi . python . org / pypi / Whoosh / 2 masked . If multiple matching concepts were returned , the one ( s ) with the highest TF - IDF score was ( were ) returned . MetaMap : This algorithm was used according to guidelines provided here 3 . Note , our analyses required the repeated construction of the databases used by MetaMap’s normalization algorithm . The construction of these databases was automated using the DataFileBuilder scripts 4 . Cosine Similarity : This algorithm normalized mentions by computing the cosine sim - ilarities between a mention and all of the terms contained within the terminology , where Cos . Sim . = (cid:126)M · (cid:126)T (cid:107) (cid:126) M (cid:107) × (cid:107) (cid:126) T (cid:107) , and (cid:126)M / (cid:126)T denote the TF - IDF vectors for the mention and term respectively . The concept ( s ) with the highest cosine similarity was ( were ) returned . pairwise Learning - to - Rank ( pLTR ) : This algorithm extends simple cosine similarity by adding a “token synonymy” matrix W to the procedure , which is learned during training through stochastic gradient descent [ 6 ] . This matrix allows tokens that are not exact matches to contribute to the similarity score , both in a positive and negative fashion . More speciﬁcally , the similarity score used to ﬁnd the best concept using this method is : Sim . Score = (cid:126)M (cid:48) W (cid:126)T (cid:107) (cid:126)M (cid:107) × (cid:107) (cid:126)T (cid:107) , where (cid:126)M (cid:48) denotes the transpose of the TF - IDF vector for the mention . Our imple - mentation of the pLTR algorithm closely followed the description in [ 6 ] . Consistent with previous results [ 6 ] , it was the top performer in our analyses . 1 . 3 Estimating the Fraction of Redundant Concept - to - Term Re - lationships It was relatively straightforward to measure the overall eﬀects of synonymy on the named - entity normalization tasks considered in this study . We simply compared the performance of the algorithms listed in previous section before and after removing all of the synonyms from some terminology of interest ( see Table 1 and Figure S1 ) . Although this analysis pro - vided an estimate for the total contribution of synonymy to the normalization tasks , it did not guarantee that every relationship annotated within the terminology was useful . Ob - viously , it was not possible to determine the utility of synonyms that were not mentioned 3 http : / / metamap . nlm . nih . gov / Docs / Metamap13 _ Usage . shtml 4 http : / / metamap . nlm . nih . gov / DataFileBuilder . shtml 3 in the corpora , as it is always possible that a larger , more thorough sample of natural language would in fact contain such mentions . However , we were able to ask a diﬀerent but still important question : “What fraction of the synonyms used by the algorithms in the current analysis are redundant with one another ? ” This analysis is important because it gives us an indication of the eﬃciency of current synonym terminologies , and it also has ramiﬁcations for the utility of the undocumented synonyms inferred to exist in the latter sections of this study . To outline our approach for estimating redundancy , consider the scenario in which the synonyms used during some normalization task were non - redundant . In other words , there was a one - to - one mapping between the concepts returned for some subset of men - tions and the synonyms used by the algorithm for normalization . Let C denote the set of returned concepts for the subset of mentions whose normalization required synonymy , where | C | = N denotes the total number of such mentions . Note , these concepts can be readily identiﬁed for any normalization algorithm and corpus following the procedure outlined in the previous paragraph . Now , given the non - redundancy assumption , the successful return of each concept C i ∈ C required only a single annotated synonym . As - suming that we randomly removed ( without replacement ) some fraction of the synonyms in our terminology ( denoted 1 − ρ ) , the marginal probability that any individual concept - to - synonym mapping remained after sub - sampling is simply ρ . Therefore , the probability that the i th concept ( denoted C i ) remained in C ( denoted C i ∈ C ρ ) is : P ( C i ∈ C ρ ) = ρ . By the linearity of expectation , the expected total number of concepts remaining in C after removing some fraction of synonyms 1 − ρ assuming non - redundancy is : E (cid:2) | C ρ | (cid:3) = N (cid:88) i = 1 P ( C i ∈ C ρ ) = Nρ . ( 1 ) In practice , we generally did not observe a perfectly linear decrease in concept recall as more and more synonyms were removed from a terminology , suggesting some amount of redundancy ( see Figure S1 for examples ) . To illustrate , let K i indicate the number of re - dundant synonyms used by some algorithm during the normalization of i th mention , such that a total of K i + 1 synonyms could in theory be used by the algorithm to return con - cept C i . Upon randomly removing some fraction of concept - to - synonym annotations , the marginal probability that at least one of required synonyms remained in the terminology enabling successful normalization is : P ( C i ∈ C ρ | K i ) = 1 − ( 1 − ρ ) × K i (cid:89) i = 1 ( 1 − ρ ) S S − i , 4 where S is the total number of synonymous relationships in the thesaurus . Given that S is very large ( generally on the order of tens of thousands of synonyms for the terminologies considered in this study ) , the previously probability is well approximated by : P ( C i ∈ C ρ | K i ) ≈ 1 − ( 1 − ρ ) K i + 1 . Now , assume that the numbers of redundant synonyms per mention were generated from some discrete probability distribution ( denoted P ( K i | (cid:126)θ ) for the i th mention ) with support [ 0 , ∞ ) . The probability that C i ∈ C ρ after marginalizing over all possible K i is : P ( C i ∈ C ρ | (cid:126)θ ) ≈ 1 − ( 1 − ρ ) × ∞ (cid:88) K i = 0 ( 1 − ρ ) K i × P ( K i ) . In the present study , we assumed that each K i was sampled i . i . d from a Geometric distri - bution , but we also repeated our analyses using Poisson and Negative Binomial models and obtained similar results ( although the Negative Binomial model had a tendency towards numerical instability ) . In the case of the geometric model , where P ( K i | γ ) = γ ( 1 − γ ) K i , the inﬁnite series in the previous equation can be evaluated analytically to yield : P ( C i ∈ C ρ | γ ) ≈ 1 − ( 1 − ρ ) × ∞ (cid:88) K i = 0 ( 1 − ρ ) K i × P ( K i ) ≈ 1 − γ ( 1 − ρ ) × ∞ (cid:88) K i = 0 (cid:2) ( 1 − ρ ) ( 1 − γ ) (cid:3) K i ≈ 1 − γ ( 1 − ρ ) 1 − ( 1 − ρ ) ( 1 − γ ) . Therefore , the expected total number of concepts remaining in C after removing some fraction of synonyms 1 − ρ given the previously described redundancy model is : E (cid:2) | C ρ | (cid:3) ≈ N (cid:88) i = 1 P ( C i ∈ C ρ | γ ) = N − Nγ ( 1 − ρ ) 1 − ( 1 − ρ ) ( 1 − γ ) , ( 2 ) which is a convex ( sub - linear ) function of the sub - sampled fraction of synonyms . Given that the parameter γ in 2 is known , we can directly estimate : 1 ) the number mentions that were normalized using redundant synonyms , and 2 ) the total number of redundant synonymous relationships paired to the concepts in C . The former is obtained simply by computing the probability that a particular mention - to - concept mapping has zero redundant synonyms , and under the geometric model , this is simply : P ( K i = 0 | γ ) = γ . 5 The latter is estimated by noting that the sum of N geometric random variables is a negative binomial distribution , and therefore , the total number of redundant synonyms paired to the concepts in C ( denoted K = (cid:80) Ni = 1 K i ) is : P ( K | γ ) = (cid:18) K + N − 1 K (cid:19) ( 1 − γ ) K γ N . In Table 1 ( Column 5 ) , we report this value after normalizing it by the total number synonyms paired to the concepts in C , demonstrating that a considerable majority of the annotated relationships do not correspond to the redundant synonyms used by the algorithms in the present analyses . The estimates outlined above assume that γ is known , which is not true in practice . To estimate this parameter from the recall curves in Figure S1 , we assumed that the concept recall probabilities after sampling ( denoted P ( C i ∈ C ρ | γ ) ) were independent of one another . Given the geometric model outlined above , this yields the following simple likelihood for the recall data returned for a particular 1 − ρ sub - sampling experiment : P ( C ρ | γ ) ∝ J (cid:89) j = 1 (cid:18) 1 − γ ( 1 − ρ j ) 1 − ( 1 − ρ j ) ( 1 − γ ) (cid:19) | C ρj | (cid:18) γ ( 1 − ρ j ) 1 − ( 1 − ρ j ) ( 1 − γ ) (cid:19) N − | C ρj | , ( 3 ) where j indexes a total of J independent sub - sampling experiments and N can be directly determined by removing all of the synonyms in the terminology of interest ( as described previously ) . In practice , we estimated γ by maximizing 3 with respect to this parameter . Note , the independence assumption invoked during the speciﬁcation of this likelihood is violated at many levels . For instance , we sampled synonym pairs without replacement , which should theoretically generate a small amount of negative covariance among the returned concepts . Nevertheless , we found that on simulated data with properties similar to our actual terminologies and corpora , the eﬀect was negligible ( the R 2 - value between 1000 uniformly sampled and inferred γ values was 0 . 99 while the slope and intercept for the line - of - best - ﬁt between these quantities was approximately 1 . 0 and 0 . 0 respectively ) . Perhaps more importantly , none of the algorithms considered in this study normalize concepts in an independent fashion . To some extent , they are all ranking algorithms , indicating that the concept returned for any particular mention depends on the other concepts and their annotated synonyms . That said , such correlations should only eﬀect the recall data variance , not its expectation ( due to the linearity of the latter ) , so we believe that our estimator should be relatively consistent in practice . Finally , we would like to note that the pairwise Learning - to - Rank ( pLTR ) method generally yielded the lowest amount of redundant synonymy while MetaMap typically had the highest . This diﬀerence likely reﬂects the distinct approaches underlying these two algorithms . MetaMap performs automatic variant generation during the construction of its database , so it is able to generate a synonym that was previously removed during sub - sampling , creating redundancy . Alternatively , the pLTR algorithm actually learns 6 a matrix of weights during training that allows non - matching tokens to contribute to the similarity score for two phrases . Thus , this “token synonymy” matrix likely beneﬁts from the inclusion of even redundant synonyms , as they potentially allow the algorithm to learn other examples of synonymy that are not currently annotated . That said , we restricted our analysis to unique mentions , and we found that it was easy to over - train the pLTR algorithm ( especially on the NCBI corpus ) , likely due to the limited amount of information available in the training sets . Therefore , we feel that our estimates of redundant synonymy for this algorithm may be inﬂated . 1 . 4 A Corpus - Based Estimate of Semantic Similarity for General - English Words To computationally assess the quality of the harvested headword - synonym pairings , we wanted to measure their overall semantic similarities using a large corpus of natural lan - guage and compare these measurements to those obtained for both known and random pairings . Many methods are available for estimating the semantic similarity shared be - tween two words using large text corpora [ 7 , 8 ] . In the present study , we adapted the method outlined in [ 9 ] due to its simplicity and scalability . Brieﬂy , let C h denote the set of contexts surrounding some headword w h within a large text corpus ( in our case Wikipedia ) , and let C s denote the same for some synonym w s . For simplicity , we deﬁned context as the two ﬂanking tokens occurring before and after each headword / synonym occurrence , ignoring order ( the “bag - of - words” assumption ) . Our estimate of the seman - tic similarity compared the information content of the contexts shared by two words with the total information content of their contexts as follows . First , let I ( C i ) denote the information content of the i th context , where : I ( C i ) = − log P ( C i | Corpus ) . The semantic similarity shared between a headword and its synonym was deﬁned as [ 9 ] : Sem . Sim . ( w h , w s ) = 2 × (cid:80) C i ∈C h ∩C s I ( C i ) (cid:80) C i ∈C h I ( C i ) + (cid:80) C j ∈C s I ( C j ) . ( 4 ) For the sake of brevity , we do not present the formal justiﬁcation for this measurement of similarity and instead direct the interested reader to [ 9 ] . In practice , we found that diﬀer - ent classes of headwords tended to have very diﬀerent background semantic similarities . For example , nouns of high frequency tended to pervasively share semantic similarity with other words simply because of their low information content , making comparisons across diﬀerent headwords diﬃcult . Therefore , we constructed a null , background distribution of semantic similarity for each headword by computing 4 between it and every other word not currently paired with it in our true positive , true negative , and novel synonym pair 7 datasets . We then used the mean ( µ i ) and variance ( σ 2 i ) from this background distribution to standardize the semantic similarities for the word pairs of interest : Sem . Sim . Score ( w h , w s ) = Sem . Sim . ( w h , w s ) − µ i (cid:112) σ 2 i . ( 5 ) The output of the previous equation was reported in the main text and in Figure 3E and 3F . 1 . 5 A Probabilistic Model for Estimating the Extent of Undoc - umented Synonymy In the main text , we outlined a statistical model for inferring the number of concepts ( headwords ) and terms ( synonyms ) that are missing from some set of thesauri . In this section , we further develop our approach by extending the model to multiple , indepen - dent terminologies , and subsequently , we increase its descriptive potential by allowing the annotation rates to vary across concepts and terms that were included within the same dictionary . We also brieﬂy outline our Bayesian approach to inferring the extent of undocumented synonymy given the described models and the observed data , and we demonstrate how our prior distribution over the number of terms per concept ( synonyms per headword ) can used to estimate the total number of such relationships in the language given any possible number of concepts ( headwords ) . 1 . 5 . 1 Extending the Model to Multiple , Independent Terminologies Consistent with the notation used in the main text , consider a set of N (cid:48) concepts that were harvested from a collection of T independent terminologies . Furthermore , let (cid:126)S (cid:48) = (cid:104) S (cid:48) 1 , S (cid:48) 2 , . . . S (cid:48) N (cid:48) − 1 , S (cid:48) N (cid:48) (cid:105) denote the total number of annotated terms speciﬁc to these con - cepts . At this point , it is important to note that not all of the (cid:126)S (cid:48) relationships were annotated by each of the T terminologies . To be included into (cid:126)S (cid:48) , each relationship only had to be annotated by at most one terminology . To encode the annotation status of each concept - to - term relationship across the T thesauri , we used the following nested list ( a list of lists ) . Let C denote the complete list of concepts and terms obtained by combining multiple terminologies , such that C = { R 1 , R 2 , . . . , R N (cid:48) − 1 , R N (cid:48) } . Each R i ∈ C represents the list of terms paired to the i th concept , and to encode the annotation statuses of these relationships , R i contains a total of S (cid:48) i vectors of length T , such that R i = { (cid:126) a i , 1 , (cid:126) a i , 2 , . . . , (cid:126) a i , S (cid:48) − 1 , (cid:126) a i , S (cid:48) } . Finally , each element in (cid:126) a i , j , denoted a i , j , k , indicates whether the j th term of the i th concept was annotated within the k th terminology : a i , j , k = (cid:40) 1 if ( concept i , term j ) ∈ terminology k 0 otherwise . 8 To specify the likelihood for the combined dataset , let 1 − p k(cid:126)θ ( 0 ) denote probability that a concept - to - term relationship was sampled at least once by the lexicographer assigned to the k th terminology and was therefore included into the dictionary . To ease notational burden , we set 1 − p k(cid:126)θ ( 0 ) ≡ p k . With this simpliﬁcation in place , the probability of observing (cid:126)S (cid:48) terms annotated to a total of N (cid:48) concepts , given the latent variables (cid:126)S , φ , and N and the model parameters Θ , is : P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) = (cid:18) N N − N (cid:48) (cid:19) × (cid:20)(cid:18) φ − 1 φ + N (cid:48) − N (cid:19)(cid:18) T (cid:89) k = 1 [ 1 − p k ] (cid:19) φ (cid:21) × . . . . . . (cid:20) N (cid:48) (cid:89) i = 1 (cid:18) S i S i − S (cid:48) i (cid:19)(cid:18) S (cid:48) i (cid:89) j = 1 T (cid:89) k = 1 p a i , j , k k [ 1 − p k ] 1 − a i , j , k (cid:19)(cid:18) T (cid:89) k = 1 [ 1 − p k ] (cid:19) S i − S (cid:48) i (cid:21) , ( 6 ) where Θ = { p k : ∀ k = 1 . . . T } . 1 . 5 . 2 Allowing Annotation Rates to Vary Across Concepts and Terms As discussed in the main text , the coverage of diﬀerent terminologies with respect to the same linguistic domain can vary wildly due to a multitude of factors , including their preference to annotate certain relationships at the expense of others ( see Figure S3 for examples ) and their potentially diﬀering deﬁnitions of synonymy . To account for this variability , we applied an approach that has recently shown promise within the ﬁelds of ecology [ 10 ] and metagenomics [ 11 ] . Speciﬁcally , we assumed that concepts and their terms belonged to diﬀerent classes , and we allowed each to be annotated at a distinct rate by the same terminology . This somewhat agnostic , mixture - modeling approach to accounting for annotation variability is an obvious oversimpliﬁcation , but in practice , we found that our models well described the variation that we observed within our datasets ( see main Figure 2F for example ) and were capable of capturing speciﬁc examples of annotation bias ( see main Figure 2G and Figure S4 ) . Brieﬂy , our mixture model assumes that each concept belongs to one of H components , which in turn harbor their own set of L h term classes . The subscript h associated with the previous variable indicates that those term classes only belong to concepts assigned to the h th component . Thus , our speciﬁc mixture model divides the space of possible synonymous relationships into H × L h components , each with their own unique annotation rate . Let z i denote the class assigned to the i th concept , where z i = h and h ∈ { 1 . . . H } . Similarly , let y i , j denote the class assignment of the j th concept - to - term relationship annotated to the i th concept , where y i , j = l h and l h ∈ { 1 . . . L h } . We assume that concept and term classes were instantiated according to simple categorical models , such that : P ( z i = h | (cid:126)π ) = π h , where (cid:126)π = (cid:104) π 1 , π 2 , . . . , π H − 1 , π H (cid:105) P ( y i , j = l h | z i = h , (cid:126)λ h ) = λ h , l h , where (cid:126)λ h = (cid:104) λ h , 1 , λ h , 2 , . . . , λ L h − 1 , λ L h (cid:105) . 9 Therefore , the joint probability for the class assignments of N (cid:48) concepts and (cid:126)S (cid:48) terms , denoted using z and (cid:126) y respectively , is : P ( z , (cid:126) y | (cid:126)π , Λ ) = N (cid:48) (cid:89) i = 1 P ( z i = h | (cid:126)π ) S (cid:48) i (cid:89) j = 1 P ( y i , j = l h | z i = h , (cid:126)λ h ) ≡ N (cid:89) i = 1 π h S (cid:48) i (cid:89) j = 1 λ h , l h , where Λ = { (cid:126)λ h : ∀ h = 1 . . . H } . To incorporate these classes into the model , let p h , l h , k denote the probability of an - notation for a concept - to - term relationship whose concept belongs to class h and whose term belongs class l h . Furthermore , let (cid:126)ξ i denote the number of undocumented terms that are paired to the i th concept ( that is instantiated with class h ) and belong to each of the L h diﬀerent synonym classes : (cid:126)ξ i = (cid:104) ξ i , 1 , ξ i , 2 , . . . , ξ i , L h − 1 , ξ i , L h (cid:105) , where (cid:80) L h l h = 1 ξ i , l h = S − S i and Ξ = { (cid:126)ξ i : ∀ h = 1 . . . N (cid:48) } . Similarly , let (cid:126)η denote the number of undocumented concepts that belong to each of the H classes : (cid:126)η = (cid:104) η 1 , η 2 , . . . , η H − 1 , η H (cid:105) , where H (cid:88) h = 1 η h = N − N (cid:48) . Each class of undocumented concepts in turn has its own set of unannotated terms , and we let (cid:126)χ denote the total number of undocumented concept - to - term relationships that belong to each concept class : (cid:126)χ = (cid:104) χ 1 , χ 2 , . . . , χ H − 1 , χ H (cid:105) , where H (cid:88) h = 1 χ h = φ . Finally , we introduce a set of H vectors , denoted Ω , where each (cid:126)ω h ∈ Ω contains the number of relationships that belong to each of the L h synonym classes : (cid:126)ω h = (cid:104) ω h , 1 , ω h , 2 , . . . , ω h , L h − 1 , ω h , L h (cid:105) , where L h (cid:88) l h = 1 ω h , l h = χ h . With this notation in place , the full likelihood for the observed concept - to - term relation - ships (cid:126)S (cid:48) , the observed number of concepts N (cid:48) , the various class instantiations for the 10 observed concepts and terms ( z and (cid:126) y respectively ) , and the four sets of latent variables described above is : P ( (cid:126)S (cid:48) , N (cid:48) , z , (cid:126) y , Ξ , (cid:126)η , (cid:126)χ , Ω | N , (cid:126)S , φ , Θ ) = (cid:34)(cid:18) N N − N (cid:48) (cid:19)(cid:18) N − N (cid:48) η 1 , . . . , η H (cid:19) × . . . . . . H (cid:89) h = 1 π η h (cid:18) χ h − 1 χ h − η h (cid:19)(cid:18) χ h ω h , 1 , . . . , ω h , L h (cid:19) L h (cid:89) l h = 1 (cid:18) λ h , l h T (cid:89) k = 1 [ 1 − p h , l h , k ] (cid:19) ω h , gh (cid:35) × . . . . . . (cid:34) S (cid:48) (cid:89) i = 1 π h (cid:18) S i S i − S (cid:48) i (cid:19)(cid:32) S (cid:48) i (cid:89) j = 1 λ h , l h T (cid:89) k = 1 [ p h , l h , k ] a i , j , k [ 1 − p h , l h , k ] 1 − a i , j , k (cid:33) × . . . (cid:32)(cid:18) S i − S (cid:48) i ξ i , 1 , . . . , ξ i , L h (cid:19) S (cid:89) i = 1 (cid:20) λ h , l h T (cid:89) k = 1 [ 1 − p h , l h , k ] (cid:21) ξ i , lh (cid:33)(cid:35) , ( 7 ) where Θ = { (cid:126)p , (cid:126)π , Λ } and (cid:126)p = { p h , l h , k : ∀ h = 1 . . . H , l h = 1 . . . L h , k = 1 . . . T } . 1 . 5 . 3 Model Inference and Undocumented Synonymy Estimation The joint likelihoods deﬁned in [ 6 ] and [ 7 ] can be used to estimate the latent variables of interest ( speciﬁcally (cid:126)S , φ , and N ) using a variety of techniques , and in current study , we took a Bayesian approach and sought the following posterior distribution : P ( (cid:126)S , φ , N | (cid:126)S (cid:48) , N (cid:48) , Θ , Σ ) = P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) × P ( N , (cid:126)S , φ | Σ ) (cid:80) ∞ N = N (cid:48) (cid:80) ∞ φ = N − N (cid:48) (cid:80) ∞ S i = S (cid:48) i , ∀ i = 1 . . . N (cid:48) P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) × P ( N , (cid:126)S , φ | Σ ) . where Σ denotes the set of parameters deﬁning our prior over the variables (cid:126)S , φ , and N . Although this posterior is analytically tractable ( see below for details ) , it is important to note that the model parameters Θ are unknown , rendering it irrelevant in practice . However , by placing a prior distribution over the unknown parameters , we generate a hierarchical model for (cid:126)S (cid:48) and N (cid:48) , and by integrating Θ out of this model , we can obtain a posterior distribution that does not explicitly depend on the unknown parameters : P ( (cid:126)S , φ , N | (cid:126)S (cid:48) , N (cid:48) , Σ , Ψ ) = (cid:90) Θ P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) P ( Θ | Ψ ) d Θ , where Ψ denotes the set of parameters that deﬁne the prior for Θ . Unfortunately , the pre - vious integral is analytically intractable , necessitating an approximate inference strategy . In the present work , we invoked a mean - ﬁeld variational approximation [ 12 ] , which re - casts the intractable integral in terms of optimizing a simple functional over joint posterior space [ 13 ] . 11 Speciﬁcally , let P ( (cid:126)S (cid:48) , N (cid:48) | Σ , Ψ ) denote the likelihood for the observed concepts and terms , marginalized over the model parameters Θ and the latent variables (cid:126)S , φ , and N : P ( (cid:126)S (cid:48) , N (cid:48) | Σ , Ψ ) = (cid:90) Θ ∞ (cid:88) N = N (cid:48) ∞ (cid:88) φ = N − N (cid:48) ∞ (cid:88) S i = S (cid:48) i , ∀ i = 1 . . . N (cid:48) P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) × P ( N , (cid:126)S , φ | Σ ) P ( Θ | Ψ ) d Θ ( 8 ) Now , consider some approximate joint posterior over the model parameters and the latent variables , denoted q ( (cid:126)S , φ , N , Θ ) . Given this approximate distribution , the previous inte - gral can be manipulated to provide a lower bound on the model log - marginal likelihood as follows : ln P ( (cid:126)S (cid:48) , N (cid:48) | Σ , Ψ ) = ln (cid:90) Θ (cid:88) V q ( (cid:126)S , φ , N , Θ ) P ( (cid:126)S (cid:48) , N (cid:48) , (cid:126)S , φ , N , Θ | Σ , Ψ ) q ( (cid:126)S , φ , N , Θ ) d Θ ≥ (cid:90) Θ (cid:90) γ (cid:88) V q ( (cid:126)S , φ , N , Θ ) ln P ( (cid:126)S (cid:48) , N (cid:48) , (cid:126)S , φ , N , Θ | Σ , Ψ ) q ( (cid:126)S , φ , N , Θ ) d Θ , ( 9 ) where V = { N , (cid:126)S , φ } and (cid:80) V abbreviates the three series speciﬁed in 8 . Of course , the previous lower bound becomes exact when q ( (cid:126)S , φ , N , Θ ) ≡ P ( (cid:126)S (cid:48) , N (cid:48) , (cid:126)S , φ , N , Θ | Σ , Ψ ) , but we already know that P ( (cid:126)S (cid:48) , N (cid:48) , (cid:126)S , φ , N , Θ | Σ , Ψ ) cannot be expressed in closed form , necessitating the speciﬁcation of an alternative , approximate posterior . In our applica - tion , we computed the lower bound on the model evidence subject to the constraint that q ( (cid:126)S , φ , N , Θ ) factorizes over the latent variables and the model parameters : q ( (cid:126)S , φ , N , Θ ) = q ( (cid:126)S , φ , N ) q ( Θ ) , ( 10 ) also known as the mean - ﬁeld approximation . Plugging 10 into 9 , taking functional deriva - tives with respect to each term in 10 , and solving for maxima ( subject to the constraint that each function integrates to 1 ) yields a set of interdependent equations for the prob - ability distributions deﬁned in 10 . By cycling through the equations and updating each in turn , one obtains a coordinate - ascent algorithm for computing the functional that op - timizes the lower bound in 9 . Furthermore , upon convergence , standard theory indicates that q ( (cid:126)S , φ , N , Θ ) represents a locally optimal approximation of P ( (cid:126)S (cid:48) , N (cid:48) , (cid:126)S , φ , N , Θ | Σ , Ψ ) in that q ( (cid:126)S , φ , N , Θ ) minimizes the Kullback - Liebler Divergence from the analytical pos - terior subject to the mean - ﬁeld constraint [ 13 ] . By placing independent , conjugate priors over each element of Θ , the joint approximate posterior q ( Θ ) is guaranteed to have a closed - form solution [ 12 ] . Therefore , in order for the lower bound deﬁned in 9 to be computationally tractable , q ( (cid:126)S , φ , N ) must have a closed form solution as well , which is true when the conditional posterior P ( (cid:126)S , φ , N | (cid:126)S (cid:48) , N (cid:48) , Θ , Σ ) can be speciﬁed analytically . To demonstrate that this is true , we must ﬁrst specify our 12 prior for the latent variables (cid:126)S , φ , and N . We assumed that the true number of terms paired to each concept scales geometrically , and we invoked an improper , uniform prior over the total number of concepts . According to these assumptions , the prior model , after collecting like terms and simplifying , is : P ( N , (cid:126)S , φ | Σ ) = γ N ( 1 − γ ) φ − N + N (cid:48) N (cid:48) (cid:89) i = 1 ( 1 − γ ) S i − 1 , ( 11 ) where Σ = { γ } and γ denotes the geometric scaling parameter . In practice , we inferred γ from the data by including it within the lower bound on the marginal likelihood deﬁned in 9 and adding an additional term to the approximate posterior speciﬁed in 10 . With this prior in place , the conditional posterior distribution described at the start of this section , denoted P ( (cid:126) S , φ , N | (cid:126) S (cid:48) , N (cid:48) , Θ , Σ ) , can be speciﬁed in closed form with respect to both the straightforward annotation model deﬁned in the main text and for the mixture - model deﬁned in the previous section . For the sake of simplicity , we perform all subsequent derivations with respect to the simple annotation model ( which is equivalent to a mixture - model with only a single concept and term class ) , and we note that the derivation for the more general model follows a similar procedure , but with the class speciﬁc latent variables { z , (cid:126) y , Ξ , (cid:126)η , (cid:126)χ , Ω } included within the joint posterior ( thus becoming part of the inference problem ) . First , we note that the desired conditional posterior can be computed according to : P ( (cid:126)S , φ , N | (cid:126)S (cid:48) , N (cid:48) , Θ , Σ ) = P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) × P ( N , (cid:126)S , φ | Σ ) (cid:80) ∞ N = N (cid:48) (cid:80) ∞ φ = N − N (cid:48) (cid:80) ∞ S i = S (cid:48) i , ∀ i = 1 . . . N (cid:48) P ( (cid:126)S (cid:48) , N (cid:48) | (cid:126)S , φ , N , Θ ) × P ( N , (cid:126)S , φ | Σ ) . The steps required for the computation of the normalization constant in the denominator of previous equation are somewhat tedious , so for the sake of brevity , we simply note that each summation corresponds to a negative binomial series , and by performing these summations , collecting like terms , and simplifying , we end up with the following , closed form expression for the desired conditional posterior : P ( (cid:126)S , φ , N | (cid:126)S (cid:48) , N (cid:48) , Θ ) = (cid:18) N N − N (cid:48) (cid:19)(cid:18) 1 − γ (cid:81) Tk = 1 [ 1 − p k ] 1 − ( 1 − γ ) (cid:81) Tk = 1 [ 1 − p k ] (cid:19) N (cid:48) + 1 × . . . . . . (cid:34)(cid:18) γ T (cid:89) k = 1 [ 1 − p k ] (cid:19) N − N (cid:48) (cid:18) φ − 1 φ + N (cid:48) − N (cid:19)(cid:18) ( 1 − γ ) T (cid:89) k = 1 [ 1 − p k ] (cid:19) φ + N (cid:48) − N (cid:35) × . . . . . . (cid:34) N (cid:48) (cid:89) i = 1 (cid:18) S i S i − S (cid:48) i (cid:19)(cid:18) 1 − ( 1 − γ ) T (cid:89) k = 1 [ 1 − p k ] (cid:19) S (cid:48) i + 1 (cid:18) ( 1 − γ ) T (cid:89) k = 1 [ 1 − p k ] (cid:19) S i − S (cid:48) i (cid:35) . ( 12 ) All estimates reported reported in the main text were obtained by taking the posterior expectation of the approximate density q ( (cid:126)S , φ , N ) . Table S5 provides these estimates 13 for each of the three datasets considered in this study along with their 99 % conﬁdence intervals , although such intervals are likely an underestimate of the true variability [ 11 ] . Note , for the biomedical terminologies , the estimates of missing synonymy provided in the main text and ﬁgures were adjusted to account for the fact that one term paired to each concept was considered the preferred term while the remainder were assumed to be synonyms . Practically speaking , computing the approximate posterior deﬁned in 10 through al - ternating coordinate ascent was relatively straightforward , barring a few minor issues . First , upon extending the model to multiple headword and synonym classes , the func - tional approximation surface became highly multimodal , and some local modes appeared very inferior when compared to others . To overcome this issue , we developed a series of algorithm initialization strategies , which relied on “seeding” the approximation algo - rithm using parameter values from models of lower complexity [ 14 , 15 ] and performing simulated annealing on the normalization constant of q ( (cid:126)S , φ , N ) to move the algorithm to parameter regimes with greater support [ 16 ] . We found this approach to be very eﬀective on simulated data . Second , although our mixture model allowed us to account for the annotation vari - ability that was observed within our datasets , it was not immediately obvious how many headword and synonym components to include into the model . In practice , we started with the simplest model ( H = 1 , L h = 1 ) and added components in a stepwise manner , keeping the number of synonym classes constant across the various headword components ( i . e . L h = L g ∀ h , g ∈ { 1 , . . . , H } ) . We used the lower bound on the log - marginal like - lihood to select among models with diﬀering dimensionality , and the we found that the most complex model that we tried ( H = 10 , L h = 4 ) performed the best with respect to each dataset . Therefore , all of the results reported in the main text and in Table S5 are for a model with 10 concept ( headword ) components , each with 4 term ( synonym ) classes . The stopping criteria at ( H = 10 , L h = 4 ) was dictated by computational limitations , as larger models quickly became unwieldy in terms of convergence times . 1 . 5 . 4 A More Liberal Estimate for the Extent of Undocumented Synonymy In the previous section , we developed a prior model for the number of undocumented terms ( or synonyms , depending on domain ) , denoted P ( N , (cid:126)S , φ | Σ ) , whose mathematical form was chosen mostly for the sake of convenience . However , one can also view this prior distribution as “generative , ” and after inferring its parameters from the data , this viewpoint can be invoked to provide additional insight into the inherent scale of synonymy given an arbitrary number of concepts . Assume that some ﬁxed set of N concepts accrued terms according to the following simple scheme . Initially , each concept was paired with only a single term , and subsequently , terms were added stochastically to each concept at some constant rate − ln ( γ ) / τ for an undetermined amount of time τ . This scheme produces the same prior distribution as deﬁned in [ 11 ] [ 17 ] , and therefore , the parame - 14 ter γ sets an intrinsic , geometric scale for the number of terms per concept . Assuming an arbitrary number of concepts N and a geometric scaling parameter γ , then the ex - pected number of concept - to - term relationships in the language ( denoted W ) is given by a negative binomial distribution : P ( W | N , γ ) = (cid:18) N + W − 1 W (cid:19) γ N ( 1 − γ ) N − W . ( 13 ) In main Figure 2E , we used the posterior expectation the scaling parameter obtained from the best ﬁtting annotation model to estimate W for a wide range of N . References [ 1 ] Aronson AR ( 2001 ) Eﬀective mapping of biomedical text to the UMLS metathe - saurus : the MetaMap program . Proceedings / AMIA Annual Symposium AMIA Symposium : 17 – 21 . [ 2 ] Xu R , Musen MA , Shah NH ( 2010 ) A comprehensive analysis of ﬁve million UMLS metathesaurus terms using eighteen million MEDLINE citations . AMIA Annual Symposium proceedings / AMIA Symposium AMIA Symposium 2010 : 907 – 911 . [ 3 ] Hettne KM , van Mulligen EM , Schuemie MJ , Schijvenaars BJ , Kors JA ( 2010 ) Rewriting and suppressing UMLS terms for improved biomedical term identiﬁcation . Journal of biomedical semantics 1 : 5 . [ 4 ] Porter MF ( 1997 ) Readings in information retrieval . San Francisco , CA , USA : Mor - gan Kaufmann Publishers Inc . p . 313316 . URL http : / / dl . acm . org / citation . cfm ? id = 275537 . 275705 . [ 5 ] Snowball : A language for stemming algorithms . URL http : / / snowball . tartarus . org / texts / introduction . html . [ 6 ] Leaman R , Doan RI , Lu Z ( 2013 ) DNorm : disease name normalization with pairwise learning to rank . Bioinformatics 29 : 2909 – 2917 . [ 7 ] Ferret O ( 2010 ) Testing semantic similarity measures for extracting synonyms from a corpus . In : Chair ) NCC , Choukri K , Maegaard B , Mariani J , Odijk J , et al . , editors , Proceedings of the Seventh International Conference on Language Resources and Evaluation ( LREC’10 ) . Valletta , Malta : European Language Resources Association ( ELRA ) . [ 8 ] Mihalcea R , Corley C , Strapparava C ( 2006 ) Corpus - based and knowledge - based measures of text semantic similarity . In : Proceedings of the 21st national conference on Artiﬁcial intelligence - Volume 1 . Boston , Massachusetts : AAAI Press , AAAI’06 , p . 775780 . URL http : / / dl . acm . org / citation . cfm ? id = 1597538 . 1597662 . 15 [ 9 ] Lin D ( 1998 ) An information - theoretic deﬁnition of similarity . In : In Proceedings of the 15th International Conference on Machine Learning . Morgan Kaufmann , p . 296304 . [ 10 ] Mao CX , Colwell RK ( 2005 ) Estimation of species richness : Mixture models , the role of rare species , and inferential challenges . Ecology 86 : 1143 – 1153 . [ 11 ] Li - Thiao - T S , Jean - Jacques D , Stphane R ( 2012 ) Bayesian model averaging for esti - mating the number of classes : applications to the total number of species in metage - nomics . Journal of Applied Statistics 39 : 1489 – 1504 . [ 12 ] Wainwright MJ , Jordan MI ( 2008 ) Graphical models , exponential families , and vari - ational inference . Found Trends Mach Learn 1 : 1305 . [ 13 ] Attias H ( 2000 ) A variational bayesian framework for graphical models . In : In Advances in Neural Information Processing Systems 12 . MIT Press , p . 209215 . [ 14 ] Thiesson B , Meek C , Chickering D , Chickering DM , Heckerman D ( 1997 ) Learning mixtures of DAG models . In : In Proc . of the Conf . on Uncertainty in AI . Morgan Kaufmann , Inc , p . 504513 . [ 15 ] Meila M , Heckerman D ( 1998 ) An experimental comparison of several clustering and initialization methods . In : Machine Learning . p . 386395 . [ 16 ] Kirkpatrick S , Gelatt C , Vecchi M ( 1983 ) Optimization by simulated annealing . Sci - ence , Number 4598 , 13 May 1983 220 , 4598 : 671 – 680 . [ 17 ] Kendall DG ( 1949 ) Stochastic processes and population growth . Journal of the Royal Statistical Society Series B ( Methodological ) 11 : 230 – 282 . 16