A Word is Worth a Thousand Pictures : Prompts as AI Design Material CHINMAY KULKARNI , Google , Inc . , United States STEFANIA DRUGA , Google , Inc . , United States MINSUK CHANG , Google , Inc . , United States ALEX FIANNACA , Google , Inc . , United States CARRIE CAI , Google , Inc . , United States MICHAEL TERRY , Google , Inc . , United States Fig . 1 . Large prompt - based text - to - image models enable rapid exploration of a design space , and fluid collaboration . By allowing users to declaratively and quickly create images through text descriptions , these text prompts act as a reflective design material aiding exploration and collaboration . We observe that designers create prompts based on their tacit understanding of the model , and model outputs in turn both spark new ideas and allow rapid refinement of prompts . Recent advances in Machine - Learning have led to the development of models that generate images based on a text description . Such large prompt - based text to image models ( TTIs ) , trained on a considerable amount of data , allow the creation of high - quality images by users with no graphics or design training . This paper examines the role such TTI models can play in collaborative , goal - oriented design . Through a within - subjects study with 14 non - professional designers , we find that such models can help participants explore a design space rapidly and allow for fluid collaboration . We also find that text inputs to such models ( “prompts” ) act as reflective design material , facilitating exploration , iteration , and reflection in pair design . This work contributes to the future of collaborative design supported by generative AI by providing an account of how text - to - image models influence the design process and the social dynamics around design and suggesting implications for tool design . Additional Key Words and Phrases : text - to - image models , deep learning , creativity , design ACM Reference Format : Chinmay Kulkarni , Stefania Druga , Minsuk Chang , Alex Fiannaca , Carrie Cai , and Michael Terry . 2022 . A Word is Worth a Thousand Pictures : Prompts as AI Design Material . In . ACM , New York , NY , USA , 22 pages . https : / / doi . org / XXXXXXX . XXXXXXX Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY © 2022 Association for Computing Machinery . This is the author’s version of the work . It is posted here for your personal use . Not for redistribution . The definitive Version of Record was published in , https : / / doi . org / XXXXXXX . XXXXXXX . 1 a r X i v : 2303 . 12647v1 [ c s . H C ] 22 M a r 2023 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . 1 INTRODUCTION Recent advances in text - to - image models ( TTI models ) , allow users to generate high - quality images based on a text description or “prompt” . In ways similar to large language models ( LLMs ) , where increasing size of models has discontinuous benefits [ 63 ] , the increased size of recent text - to - image models has yielded discontinuous and qualitative differences in the quality of images produced [ 54 ] . The quality of text - to - image models has led to energetic communities of practice , where enthusiasts readily share designs and prompts . In some cases , results obtained from these models are so good that one artist has even won a prestigious art competition [ 17 ] . The image quality obtained by this new generation of text - to - image models enables the research community to rethink significant aspects of the design process in light of these models . For example , questions arise about whether designers could delegate parts of the creative process to a model ; how the nature and the style of creative design change with these models ; and how designers should best share and collaborate on multimodal ( i . e . , text and image ) creative processes with these models available as design resources . Finally , potential new design processes among non - professional designers are particularly interesting , as TTI models allow those without professional training to create high - quality images easily . This paper investigates how the creative design processes of non - professional designers change while using TTI models . Since design practices often emerge through social interactions ( e . g . , designers working together in a studio or sharing their work online ) , we also investigate how social interactions are affected with the introduction of a TTI model . Recent work suggests that generative AI may play a role in influencing social dynamics between pairs of people [ 59 ] . With the advent of “prompting” as a new form of interacting with AI , we build on this emerging body of literature by investigating how prompting may affect social dynamics during collaborative design . Our paper examines the following two research questions : • RQ1 : How does using prompt - based image generation change the design process of non - professional designers , especially compared to current tools for finding appropriate images such as web search ? • RQ2 : How do prompt - based image generation models change collaborative dynamics during design ? Note that while prior work on human - AI co - creative systems has uncovered challenges that frequently arise when users co - create with AI ( e . g . , users must deal with uncertainty in the capabilities of AI capabilities while simultaneously making sense of complex outputs from the system [ 66 ] ) , it is unknown how these challenges manifest when users interact with prompt - based i . e . , TTI models . It is also unclear what other challenges are unique to working with these models and how we might best address them when designing new interfaces for these systems . To address these research questions , we conducted a design study with participants from a large technology company who use prompt - based image models in a non - professional capacity . In our controlled study , participants worked in pairs and created graphic designs with or without the assistance of a prompt - based image generation model . We present results in this paper from our direct observations of the designer pairs , conversations during this design session , and post - study interviews . We also compare the artifacts produced by participants for creativity , completeness , and appropriateness to the design brief . Overall , we found that TTI models change the design process by allowing designers to create images declara - tively , i . e . , through a simple description of the desired image . This declarative design changes existing design practices in two ways . First , because prompts can capture high - level image descriptions , TTI models allow faster exploration of the design space , potentially leading to more creative design . ( At the same time , we acknowledge that not all creative ideas for generating images can be expressed easily , or at all , in words . As new text - guided image - to - image models become more capable , we expect that they will aid exploration even further . ) Second , because prompts are text , prompt - based image generation leads to easier sharing of design ideas , allowing designers to collaborate and build on each others’ work more successfully . 2 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Throughout our study , we observed that prompts played a central role in the design process and collaboration . This leads us to argue that prompts act as a reflective design material in the design process . Specifically , we found that our participants developed a tacit , rather than technical , understanding of how different aspects of prompts ( such as specific keywords ) influence the image generated . In addition , prompts enabled fluid collaborations between participants as they shared , modified , and iteratively improved each others’ prompts . The ability to easily edit and refine an image via a text interface made the design process more fluid , and sharing prompts easily aided collaboration , which uniquely placed prompts as design material in a multimodal creative setting . Prompts also allowed participants to engage in reflective practice with the AI model . Specifically , the text - to - image model outputs made it seem like a somewhat opinionated “design partner” in its preference to generate certain kinds of images , or when the images generated were wildly different from the prompt’s intent or were challenging to modify . Participants leveraged prompts to reflect on the model’s results and engaged in reflective conversations with each other through their prompts , envisioning novel designs they did not foresee [ 21 , 56 ] . This leads us to suggest that prompts act as reflective design materials ( “objects to think with” [ 60 ] ) . In sum , this paper makes the following contributions : • Changes in the design process . We articulate ways in which TTI models change the design process . Specifically , models changed design processes through faster iteration , creating images of novel ideas and unlikely combinations ( e . g . , a giraffe in a Lamborghini ) quickly . They also changed the design process because they rely on indirect manipulation of images ( through text ) . Together , this led to wide - ranging exploration where the models rapidly “filled in” many unspecified details of the images . However , partici - pants also struggled to control low - level factors ( e . g . , cropping , position , text ) in the generated image . In sum , users perceived their work to be significantly more creative when using a TTI model compared to image search . However , external raters found no significant difference . • Changes in collaborative practices . We identify ways prompts changed collaborative dynamics during design . While prompts empowered collaborators to combine multiple people’s disparate ideas fluidly , their non - determinism hindered coordination . In addition , because participants frequently shared images without the prompts that generated them , partners had asymmetric access to TTI models . • Prompts as a design material . Given these empirical results , we conceptualize prompts as a new design material that both enables rapid exploration of a design space and modulates collaboration , but one that is imperfect , especially for fine - grained control . 2 RELATED WORK This paper builds on three areas of related work : large machine - learning models generally , Human - AI collaboration issues , and the use of AI to support creativity and design . We briefly outline significant findings from prior work below and how this paper extends these findings . 2 . 1 Large machine learning models and their use in rapid prototyping Recent advances in deep neural networks have enabled the creation of large language models ( LLMs ) capable of generating highly realistic language output [ 9 , 35 ] . When provided with brief contextual information , such as a textual description of the task , these models can mimic the performance of models specially trained for particular tasks such as classification ( “Classify whether this review is positive or negative " ) , question answering ( “Given the information below , answer the following questions " ) and summarization ( “Summarize this article” ) , i . e . , they act as zero - or few - shot learners for a wide array of problems [ 5 , 36 , 38 ] . Designing the form of contextual information to provide to the model is referred to as prompt programming or prompt engineering [ 64 ] . Our work adds to this rich scholarship by examining how designers can engineer prompts to generate images collaboratively . While 3 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . prior work in this space has generally focused on identifying new capabilities of prompt engineering , our study focuses primarily on how these new capabilities are used . A parallel line of research has explored generative models for images [ 8 , 22 , 31 , 68 ] . Critically , Mansimov et al . [ 39 ] showed that generative image models conditioned on image captions can generate images from natural language input . Leveraging the technological advances in LLMs , a significant number of large prompt - based image - generation models have since been created in the last two years – including DALL·E [ 45 , 50 ] and DALL·E 2 [ 44 , 49 ] , Parti [ 24 , 67 ] and Imagen [ 23 , 54 ] , Stable Diffusion [ 4 , 52 ] , and Midjourney [ 2 ] . Given the ability of these text - to - image models to generate highly detailed images in a vast array of styles based on the user’s prompt , these models present a significant opportunity for application to creative visual tasks [ 6 ] . In this work , we investigate the use of text - to - image model’s impact on collaborative design tasks . 2 . 2 Human - AI co - creation The question of what role AI systems play in mediating communication between collaborators [ 25 ] , and how AI systems can act as teammates has been widely debated [ 58 , 61 ] . Prior work has found that while Human - AI collaboration can improve the abilities of unassisted humans and AI systems without human input , designing such collaborative systems remains challenging [ 65 ] . Particular challenges are a lack of clarity on the capabilities and limitations of AI , the complexity of output of AI systems , and the role of randomness in AI outputs , both of which impede a designerly understanding of AI [ 66 ] . To this literature , we contribute an account of how prompts emerge as a reflective design material that help non - professional designers explore the design space of possibilities , and collaborate with each other . Designing co - creative systems ( as opposed to decision support systems , for instance ) have particular chal - lenges [ 11 ] . Key to our current study is the potential for AI systems to be a “time - waster” that user interfaces may impose a “bottleneck” on creative use of the AI , and that AI provides overwhelming amount / detail of content that distracts or creates choice - overload [ 11 ] , resulting in poor design . This paper enriches this literature by describing how pairs of non - professional designers navigate a text - to - image model . In this respect , they extend our understanding of interacting with multimodal AI co - creation . At the same time , multimodal systems have long been known to improve users’ expressive power and efficiency [ 46 ] , our findings on how AI models such as text - to - image models can modulate expressivity and efficiency . 2 . 3 Collaborative Creativity Support and the use of AI Tools that support creative tasks have been widely studied in the fields of HCI and psychology [ 19 ] , both for individuals and groups , and from both a human - centric perspective and a computational perspective [ 29 ] . Given the focus of this paper on collaborative design , we focus this section on creativity support tools for groups ( see [ 62 ] for an overview of tools for individual support ) . Tools supporting groups collaborating on creative tasks have studied both the creative process and the communities of practice in which such processes are situated [ 1 , 3 , 10 ] . For example , Scratch [ 3 ] supports collaborative game development through a block - based programming language and supports self - directed discovery - based learning among children [ 53 ] . The critical learning mechanism in Scratch beyond self - directed discovery is “re - mixing” or a creative bricolage of other creators’ ideas [ 13 ] . Similarly , online communities , such as Dribbble , allow designers to find and build on collaborators’ ideas as a critical mechanism to improve creative output [ 10 , 40 ] . This paper extends this scholarship by describing how collaborating designers re - mix each others’ ideas when creating AI - assisted images . In recent years , creativity support tools that use AI have been growing in popularity and have been studied in domains such as creative writing [ 12 , 20 ] , music creation [ 26 , 37 , 41 , 59 ] , and drawing [ 14 , 15 , 30 , 43 ] , and design ideation [ 28 , 32 , 48 , 55 ] . In addition , several systems have been designed to support the collaborative generation of creative content . Together , studies of these systems suggest that AI models can shape interactions 4 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY between collaborating partners and individual and group cognitive processes . This work informs our focus on how text - to - image models change collaboration during design and extends the scholarship on how multimodal AI models ( i . e . , using text to generate images ) influence collaboration . 3 TEXT - TO - IMAGE MODEL Participants in our study used a text - to - image model that has not been released to the public . This model , Envisage , is a text - to - image diffusion model that achieves a very high degree of photorealism and a deep level of language understanding ( comparable in quality to DALL - E 2 [ 44 , 49 ] , Imagen [ 23 ] , and Parti [ 24 ] ) . The model is a " diffusion model " . Diffusion models are trained by first destroying training data through the successive addition of noise , and then learning to recover the data by reversing this noising process . After training , a diffusion model can be used to generate data by simply passing sampled noise through the learned de - noising process . To guide the reconstruction trajectory , more recent implementations of diffusion models use text , semantic maps , or other images to condition what possible image should be generated ( reconstructed ) from the space of all possible options , with different probabilities ( also called the latent space ) . Our model uses text to guide reconstruction . In particular , it uses a generic large language model , trained on text - only corpora , for encoding text inputs ( prompts ) , and a specially - trained diffusion model for generating images . While the objective of this paper is not to study a specific TTI model , to help contextualize our results , we note that previous work demonstrated that the Envisage model exhibits state - of - the - art performance on automated metrics ( FID ) , human - rater comparable performance on text - image alignment to the MS - COCO dataset itself , and a high degree of human - perceived photorealism in generated images ( redacted reference ) . While Envisage can often produce legible , correctly spelled text in images , it is not guaranteed to do so . In addition , generated images are constrained to be square and of fixed resolution and size . Participants used Envisage through a web - based user - interface . This web - based UI has one text box for the input text ( prompt ) and generates eight candidate images at a time ( presented in two rows as a 4 𝑥 2 grid . ) Generating these images takes approximately 20 seconds once a prompt is entered . The UI currently does not record a history of past prompts used . Because Envisage uses a random seed as input ( which is not visible to the user ) , users see different image results on consecutive runs of the model , even when providing an identical prompt input . Both the prompt and the generated images are saved , and a unique URL is generated for every image - generation run , allowing easier sharing . ( Visiting this URL reloads the previously generated images . ) The current UI does not have any other collaborative features . Finally , the authors of this paper had no involvement in the creation of the model or the interface used in the study . Our study focused on the practices of non - professional designers . We are motivated to study how practices of non - professional designers might change particularly because TTIs may empower those without professional artistic or design training to create images with a textual description alone rapidly . TTIs may also allow non - professional designers to rapidly prototype , see and borrow from examples , and share multiple designs , accruing benefits that professional designers obtain from these practices [ 16 ] . 3 . 1 Participants Participants in our study were invited from a pool of employees at a large , US - based tech corporation who filled out a survey suggesting that they have used Envisage or similar models in the past . It must be noted here that our study makes a distinction between design practices – i . e . the individual and collaborative cognitive processes common to the task of design , and the practices of professional designers , which are learned through participation in this community of practice . Our paper is focused on the former as we are interested in the effects of TTI models among non - professional designers . 5 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . As a result , we filtered this survey to find only those who had been exposed to these models outside their job responsibilities and who were not professional designers ( such as UX designers , visual designers , etc . ) . Specifically , to target non - professionals , we narrowed our pool to participants who reported that they had interacted with these models as “part of your creative work pipeline” or “out of curiosity ( not work - related ) ” . For practical reasons , recruiting those who had some initial exposure to the model also allowed us to observe the task within the scope of the 1 - hour study . From this pool , we invited 16 participants across the company to participate in our design study . 14 participated ( 11 identified as male , three as female . ) Participants had a variety of job roles , from sales / marketing , software development , and project management . We sought to balance the participant pool to include both tech and non - tech participants . Two participants did not fill out the pre - study or post - study survey but fully participated in our study . We present the results of the survey without these participants . Participants were given a company - internal gift card valued at US $ 30 ) for participating in the study . Two expert visual designers , both identifying as female ( working as UX designers in the company ) , rated participants’ final outputs blind to experimental conditions and participant identity . Because the model was not released to the public ( at the time the study was run ) , we were limited to employees working at our organization . Despite this limitation , the deployment allowed us to gain fruitful insights from people across a range of different job roles , including non - tech roles . As TTI models become more widely available , future work should examine the generalizability of our results . 3 . 2 Study design 3 . 2 . 1 Image Search as a baseline . To find a reasonable baseline condition to compare against how participants used TTIs , we conducted pilot experiments to find existing design practices among non - professional designers . We found that participants overwhelmingly started with searching for images online , and if necessary , editing these images in slide decks or similar software . While reasons varied ( from thinking of returned images as inspiration or as building blocks to be used right away ) , Image Search enables users to find images that depicted what they wanted using high - level , natural language descriptions . Like TTI , Image Search also uses text as input . While a generative image - editing tool might seem like a more natural comparison to generative TTI models than Image Search , which only surfaces pre - existing images , notably none of our pilot participants used generative image - editing tools ( e . g . Adobe Illustrator ) or machine learning - powered image generation ( e . g . GANs ) . Given the complexity of existing image - generation tools like Illustrator relative to TTI , such a comparison might also make this comparison unfair . 3 . 2 . 2 Procedure . Our study was conducted entirely online , with participants using Google Meet . Participants shared their videos so they could see each other and their active window to see each others’ work . In addition to the participant , one or two experimenters joined the video call . Participants were asked to share their browser window to allow both the experimenter and their partner to follow their progress . Before the start of the experiment , participants filled out a short demographic survey after consenting to participation . Before proceeding with the study , we reminded participants that we had no involvement in the creation of the model or the interface used in the study , and that we welcomed their honest reflections throughout the study . Participants were assigned to a design partner at the start of the study . Our study was designed as a within - subjects study with two design sessions . In one design session , in the Image Search condition , participant pairs were allowed only to use Image Search ( with Google Image Search ) – participants could perform an unlimited number of queries , and use resulting images in their invitation . In the other design session , in the Envisage condition , they were additionally allowed to use Envisage ; participants could similarly generate images for an unlimited number of prompts , and use resulting images . Each design session lasted 20 minutes , in which 6 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY participants were asked to create a complete design . The two experimental conditions were counterbalanced , so half the pairs of participants completed designs with Image Search alone first , and the other half completed designs with additional access to Envisage . Throughout the study , participants worked with the same assigned design partner . In the first design session , the pair of participants collaboratively designed a party invitation to the birthday party of Alice from Alice in Wonderland . In the second session , the pair of participants collaboratively designed a party invitation to celebrate the 55th anniversary of the first Moon Landing . Appendix fapp : task - descroption includes both design briefs in full . Because Envisage does not allow the creation of images that include photo - realistic people , participants were told not to use photo - realistic images of people in their design . Further , to respect creator rights and to simulate a realistic design task , participants were also not allowed to use images that were under copyright . ( Images that were public domain or licensed under a Creative Commons license were allowed – the Image Search interface has filters to search for such images . ) This restriction is similar to prior work in this area ( e . g . [ 16 ] . ) In both sessions , participants created their invitations in Google Slides . Using Slides , participants could for instance crop images , compose multiple images into a single composition , and add text . Google Slides does not currently have features to remove backgrounds from images , or perform other image editing , such as adding filters . We chose to use Google Slides rather than a professional tool such as Adobe Illustrator because we wanted to study the practices of non - professional designers . Furthermore , Google Slides is used extensively in the organization we studied , ensuring that all participants would be familiar with how to use it . Participants were told that their designs would be rated for creativity , appropriateness to the design brief , and completeness and that the best designs would receive a prize . After the study , each participant privately filled out a survey self - assessing their design along the dimensions of creativity , appropriateness , and completeness ( based on survey scales adapted from [ 16 ] ) ( Modifications : tailor language to invitations instead of advertisements in the original study , replace adherence to the “client’s theme” with adherence to the theme , omit questions related to graphic design principles such as typographic balance because that was not the focus of our study ) . We also asked participants about their collaborative experience ( based on “relationship conflict” scales from [ 27 ] ) . We also asked two expert designers ( who did not participate in the study and were not involved in the research ) to rate participants’ designs along these dimensions . These raters used the same scales as participants and were blind to the condition . ( Each rater rated all designs produced . ) 3 . 3 Data collection and analysis Our study resulted in pre - study survey data and video recordings of all the design sessions . Recordings were automatically transcribed , and corrected by either of the first two authors . The first two authors analyzed the video transcriptions and noted comments on participants’ non - verbal interactions for the qualitative analyses . The final corpus included 168 pages of transcripts ( 48169 words ) . The first two authors each reviewed the transcript data independently , looking for ways of explaining the experimental conditions . In this process , the authors analyzed each transcript using emic codes that emerged from the study sessions [ 42 , 47 ] . After a final coding frame was developed , the second author coded all the transcripts . If new codes emerged , the first two authors discussed discrepancies in the analyses until they reached an agreement . The final list of codes , their definitions , and examples is included in the appendix . This process was used to develop categories , which were then conceptualized into broad themes after further discussion . The two first authors extracted salient themes from the study transcripts and independently generated hypotheses and points of discussions [ 7 ] . Using these data , the authors participated in two interpretation sessions to arrive at the primary themes reported in this paper . While we are limited by our sample size , we did not observe large differences in participant processes by gender . 7 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . 4 RESULTS In this section , we first present the participants’ design outputs , as well as quantitative results and interaction patterns . Then , in the following sections , we describe how text - to - image models changed the design process , and affected collaborative dynamics during design . Note that even though participants in the Envisage condition were allowed to use images found through using Image Search , only one pair of participants did so . To simplify our description of results , we therefore describe them as results while using Envisage and while using Image Search , even though participants using Envisage always had access to Image Search . 4 . 1 Design Outputs and Quantitative Findings Qualitative results regarding the processes followed by participants is possibly the larger contribution of our work . However , for the sake of completeness and to offer a statistical overview of participant behaviors and preferences , we briefly mention quantitative results below . Nearly all participants spent all the available time during their first session ( regardless of whether they used Image Search or Envisage ) , 𝑀 = 18 . 5 minutes . Many participants used less time in the second design session , regardless of condition , 𝑀 = 14 . 2 minutes , suggesting there was a learning effect in the task . However , there was no significant difference between Image Search and Envisage conditions . When working with their partner , participants followed different collaborative styles , which we briefly de - scribe in Section fsub : collaboration . Participants typically brainstormed about the general theme of their design ( characters from Alice in Wonderland ) , and then started to look for images ( using Image Search ) , or generated images ( using Envisage ) that fit this theme . While some pairs had one screen shared with one of the participants “driving” the integration of images into the final design , while the other looked for images , many pairs worked col - laboratively on editing the prompts to generate images . Finally , some pairs worked in parallel , sharing interesting results with each other . These pairs then collaboratively edited the slide deck to create the final design . Figure ffig : cake - prompts shows some of the final invitations the participants created . Participants’ invitations created in the Image Search condition had an average of 4 images in the design ( 𝑚𝑒𝑑𝑖𝑎𝑛 = 4 ) , while those in the Envisage condition had 2 . 4 images on average ( 𝑚𝑒𝑑𝑖𝑎𝑛 = 2 ) . We discuss possible reasons for this difference in Section fssub : opinionated . Participants self - reported their final design to be more creative when they used Envisage ( 5 - point Likert scale , mean = 3 . 6 ) than when they used Image Search alone ( M = 3 ) . This improvement ( M = 0 . 6 ) was statistically significant ( two - sided paired 𝑡 ( 13 ) = 2 . 65 , 𝑝 = 0 . 02 . ) There was no difference in how complete participants reported their creations to be ( Image Search 𝑀 = 3 . 6 , Envisage 𝑀 = 3 . 2 ) , or how appropriate it was to the design brief ( Image Search 𝑀 = 4 . 2 , Envisage 𝑀 = 4 . 1 ) . On the other hand , external raters did not find any significant differences in the creativity , completeness , or appropriateness of the brief for designs in either condition . In a post - study survey , participants did not note any significant differences in their ability “to manage any relationship tension” in their work group ( paired t - test , 𝑝 = 0 . 19 ) , “to politely include my partner’s ideas in the final design while also preserving my own” ( two - sided paired t - test , 𝑝 = 0 . 27 ) , or “to decide about who should do what in our group , even when we had some differences in opinion” ( two - sided paired t - test , 𝑝 = 0 . 16 ) . However , participants did reveal a preference for using Envisage or a similar model were they “to complete a similar task in the future” ( mean rating = 3 . 8 , median = 4 , on a 1 - 5 Likert scale , 5 = “Strongly prefer to use Envisage / similar model” . ) Given these self - reported preferences for using Envisage and similar models , along with modest differences in the output quality , we focus the rest of this section on the qualitative differences in the processes that participants employed . 8 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY 4 . 2 Interaction Patterns During the study , we observed differences in how participants queried or prompted Image Search and Envisage . Participants understood that Image Search found pre - existing images on the Internet and so used broad queries that they hoped would yield useful results ( e . g . " tea party " . ) If these queries did not yield relevant results , participants searched for related terms instead ( e . g . , " mad hatter " → " hare with a hat " → " crazy top hats " ) . As such , participants ( correctly ) used Image Search as a querying interface . In contrast , participants’ inputs to Envisage could best be described not as queries but as descriptions , such as " Colorful drawing of a Cheshire cat from Alice in Wonderland . The cat is wearing a birthday hat and is on a white background . " Throughout the rest of this paper , we call these input descriptions prompts to distinguish them from queries . Participants wrote increasingly elaborate prompts with Envisage during their design session , especially when the image results were disappointing . For instance , P7 and P8 tried the prompt " Beach party on the moon , on the moon in the Sea of Tranquility . Digital art . " Unfortunately , Envisage did not generate any images for this query , and participants hypothesized this was because the beach party had nudity or other content that led Envisage to block it . ( In actuality , it is likely these images were blocked because Envisage does not generate images with photo - realistic people in them . ) These participants then modified their prompt several times , ending with " A doodle of a beach party of fully suited astronauts on the Moon in the Sea of Tranquility . The Sea of Tranquility has water in it , and some astronauts are surfing in it with surfboards that have the " NASA " logo on them . Digital art . " 4 . 3 How TTI models changed the design process Through rapid image creation and their indirect nature , where images were created through text descriptions , text - to - image models led to new design practices , as outlined below . 4 . 3 . 1 Indirect and rapid image creation through text allowed new creative freedom . Participants noted how creating with Envisage was indirect , as it involves “creating prompts that create images” ( P13 ) . This indirectness and the flexibility of prompt editing allowed participants to rapidly explore the design space of alternatives . This was most apparent when participants used Envisage to take on other ’artist’ personalities , which would otherwise have taken years of practice . P4 noted : “If you made a poster , it [ the poster ] would have had your style associated with it by default because you have to learn [ and develop a particular style ] . . . It is harder to switch between styles . Whereas Envisage , you could just be like ‘1960s poster’ or like in the style of whoever : Picasso” . At the same time , participants felt faster image generation would allow for even more exploration . P3 noted : “Because it takes so long to generate a bunch of different images , I didn’t really move off to , you know , how else that card could look . ” Participants also noted how the model implicitly steered such rapid exploration . Despite this steering , par - ticipants noted how they still remained in control over the “personality” their Envisage creations would have . For instance , P3 quoted above added : “Well , for me the image that it generated was sort of similar to what I envisioned in my mind . . . The way that it turned out is pretty cool . It is definitely not the style that I would have chosen for myself , my own drawings , but like it looks pretty . ” ( We should note that , due to the short term nature of our study , we are unable to study how such model steering impacts participant creativity over the long term . ) Throughout these explorations , participants tended to improve or “optimize” a prompt if they found that at least one of the generated images was helpful . Participants refined their prompts both to bring out aspects they found successful in the initial set of results , and to steer results away from undesired properties . For example , while creating a Cheshire Cat , P9 liked the card design in the results , rather than the cat in the foreground : “ [ I ] kind of like some of these designs . . . " They then updated their prompt to get more of that card design : " Frame with filigree pattern . Circus colors " . 9 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . Fig . 2 . A few of the designs participants created in our study . Top row : Designs without access to prompt - based image model ; Bottom row : Designs with access to prompt - based image model . ( In both conditions , designs shown are ones with the highest overall rating by independent experts . ) 10 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Fig . 3 . A few of the images participants created with Envisage . As can be seen , Envisage does not always generate images that are properly cropped ; participants used prompts such as " . . . framed art " to generate images with better composition ( far right ) . At other points , participants refined their prompts to steer results away from undesired properties . For example , P8 first tried to generate a jovial Cheshire Cat image but remarked that “Those are a little terrifying . " He thus updated the prompt to make the image look less scary and more festive : " Invitation to a birthday party . Alice in Wonderland . Cheshire Cat " . Similarly , participants noticed that with some images that were poorly cropped , they could obtain better results if they appended " framed painting " to their prompt . 4 . 3 . 2 Novel images steered novel ideas . Whereas Image Search surfaced existing images on the Internet , Envisage allowed participants to generate entirely novel images , and allowed them to successfully explore their creative ideas . For example , P5 described hitting a wall with Image Search when he could not find a specific aspect of what he wanted via Image Search , possibly because it did not exist in the real world : “I wanted a picture of a dolphin . . . And I started to Google it . . . One of my problems when I was searching around , is I couldn’t quite get the image I wanted , right ? I wanted to make something new and I couldn’t quite get the right image I wanted . " In contrast , participants were able to use Envisage to create novel combinations of ideas that did not exist , such as a giraffe driving a Lamborghini : “Like ‘a giraffe is driving a Lamborghini’ . . . these are things you can never do . You can never have images , that look reasonable for those online . If you had to do it the old - fashioned way , or be really good at Photoshop or Illustrator . And it would take a lot longer than I have . ” They were also able to apply styles to content from a time period , which would not have been possible in the real world : “ . . . show me ‘the Apollo 11 Landing in the style of Dali’” . In addition to exploring existing creative ideas , surprising image results also spurred participants to go in a different direction . For example , TTI surprises inspired participants to consider aesthetic styles , compositions , or other design choices they hadn’t initially considered : “When I asked Envisage for a doodle of that Envisage blew me away with something that was a different art style than I imagined . That inspired me to seek out stuff in that same art style or to keep asking for doodles . ” Together , participants saw Envisage as a way to support their creativity in ways that were qualitatively different from previous tools . As P6 noted : “it really kind of stirs , my creative juices or whatever whereas like Googling for images does not really stir that . . . ” However , Envisage also occasionally generated non - sensical or clearly flawed images , such as animals with incorrect anatomy or images of the Moon with two “Earths” in the background . Participants contrasted this with Image Search , which offered more predictable results because they were authentic images from the Internet . This , in turn , allowed participants to feel that the resulting images reasonably depicted what was in the images without 11 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . Fig . 4 . A few giraffes driving fancy cars . ( Prompt inspired by participant : " Giraffe is driving a Lamborghini . f2 . 2 " ) . By enabling the rapid realization of novel ideas and unlikely combinations , text - to - image models enable an exploration of the design space and fluid collaboration . closer scrutiny . For example , P5 suggested : “ . . . I trusted the images that I look for are going to look somewhat more sane . . . I am not going to see half of two rabbits” . Participants also saw such predictability as necessary when looking for a specific image . For instance , one pair of designers used public - domain images of the first Moon Landing . For such images , correctness was crucial : “Most of the images we used are very specific . They are images that Envisage cannot generate . ” 4 . 3 . 3 Designing with an opinionated model . As Envisage would sometimes produce unexpected results , the participants often felt the need to guide or work around the model’s limitations . For instance , P3 noted their decision to use the model to generate an image for the entire invitation from a single prompt rather than prompting for each part of the image and compositing them : “I suppose because we knew the limitations of Envisage , in terms of like , composing it for multiple images is , it sort of reduced what we could do with it . ” Other participants were able to avoid design fixation , but with considerable effort . P5 remarked : “It felt like I was fighting it . . . . I felt like it was helpful , but I also felt like I had to massage every word and select every character very carefully not to upset it so that it could generate something I wanted . ” Consistent with prior work , in these and other quotes , participants seemed to ascribe the role of an opinionated design partner to Envisage For instance , Koch et al . described how participants ascribed agency to the AI tool ( with one participant even referring to it as " an eccentric collaborator " ) [ 33 ] . Similarly , in a study of an AI - based co - creation tool that generates sketches to inspire the user as they are actively sketching , users perceived the AI as a “collaborative partner” in the condition when the system communicated with them [ 51 ] . ( Because participants themselves anthropomorphized the model , we characterize it as opinionated , rather than using other terms , such as being biased . ) While prompting with this opinionated model enabled participants to express high - level concepts at rapid speed , participants struggled to systematically control low - level details , such as position , layout , and which letters appear in the text ( note , however , that some participants did use Envisage to generate text in styles that Google Slides did not support , see Figure ffig : cake - choices ) . For instance , P4 wished for “more controllability” : “it is kind of agonizing to keep typing in very different versions of the same thing , and you are like , no , I just want his hand to be , like a little bit farther down . ” Similarly , P5 expressed their frustration with how Envisage sometimes cropped parts of an object in the image : “So this is yeah , with this image , we can go outside the lines and get something that covers more of the screen while it is just focusing on the top hat . . . after a few moments . . . I cannot . ” 12 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY 4 . 4 How text - to - image models changed collaborative dynamics during design Text - to - image models modulated the collaborative practices among participants by creating new ways to flu - idly combine ideas with prompts . At the same time , because prompts were so central to these collaborations , asymmetric access to the prompts changed collaborative roles and exploration . 4 . 4 . 1 Prompts allow participants to fluidly combine ideas . A core aspect of creative collaboration is the ability to combine , re - mix , and try out ideas from multiple people [ 18 ] . However , while using Image Search , participants sometimes discovered that , even when they could agree and combine their ideas , those combinations of ideas were often hard to find within the search results . For instance , one participant noted : “It was easy for us to sort of like agree and collaborate on ideas but then it was hard to find images that match those ideas . ” Similarly , during their design session , P4 said to their partner : “I like the one that you had with the crazy paper vintage background , ” but later was unable to find images of candles in that preferred style : “something about beggars cannot be choosers . ” In contrast to Image Search , with Envisage , participants were both able to combine ideas in their prompts and experiment rapidly with different ways of composing them together . For instance , in this conversation , P7 fluidly added his ideas for fireworks to their prompt about rockets on the moon : P8 Another theme could be something to do with rockets . P7 Oh yeah , or like rocket fireworks . [ Prompt : " Fireworks exploding in the shape of a space shuttle . " ] Furthermore , Envisage allowed participants to see a variety of generated images and choose the ones that best matched their needs . Reacting to a set of Envisage results based on their partner’s query , P6 said : “It [ image on the left ] does not get the idea of the party across . Let’s go with the one on the right because it has like the astronaut has a party hat . ” Finally , even though not this was not the focus of our study , participants often spoke about how they learned tricks for successful prompting socially . For instance , P5 suggested how this process of social learning was fun : “Like , it could be fun , especially when me and my coworkers are all sitting at my desk and people like , oh , take this [ prompt ] and see what it does . ” In many of our design sessions , we saw many such prompt modifications , such as using " . . . framed art " , or particular camera or lens types to mimic in the images generated , such as " . . . Sigma 85mm f1 . 4 " . Once participants shared such prompt tricks with their partner , they often used them in their collaborative design work . 4 . 4 . 2 Asymmetric access to prompts , randomized generation , hinder collaboration . Often , the ability to iterate on a design was weighted towards whichever collaborator had access to the prompt , leading to asymmetric access . This was particularly prominent in situations where participants prototyped prompts in windows that were not shared with their partner , as in this exchange : P1 ( chuckles ) Okay , well I got something which will be sort of , kind of more appropriate maybe . So I’m gonna paste it here P2 ( seeing the results ) Hey ! That’s pretty good . Okay . . . . Yeah , even the Lander is partying ! I think we go with this one . In this situation , even though P1 was able to share an exciting image result with P2 , P2 was not able to iterate on the design because he did not have access to the prompt . In this case , we noticed P2 became increasingly reliant on P1 to create images as the design session progressed . Even with access to prompts , generative models ( including Envisage ) typically use a random seed as input , so users see different image results on consecutive runs of the model , even when providing an identical prompt input . As a result , participants were sometimes unable to replicate previous results reliably , hampering collaboration . 13 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . 4 . 5 Prompts as reflective design material Throughout their design session with Image Search , it seemed that participants merely saw Image Search as a way to find the needed images . In contrast , when participants used Envisage , they displayed a nuanced , functional understanding of how prompts could be used to achieve their design objectives . Moreover , this understanding was not related to the technical aspects of how Envisage worked – not once in our sessions or interviews did participants mention “transformers” , “diffusion models” , or even “deep learning . ” Instead , they spoke about and enacted how Envisage allowed them to rapidly explore a range of artistic possibilities and to collaborate . These observations lead us to characterize prompts as design materials . Below , we describe how participants exhibited a tacit understanding of Envisage and how prompts allowed for exploration and reflection on model actions ( i . e . , images generated ) and reflection in action ( i . e . , through collaboratively editing the prompts ) . Participants used and developed their tacit mental models of Envisage’s design orientation throughout their design process . For instance , P3 noticed how Envisage framed the subjects in its images : “Most of the images that get generated by Envisage always push everything up to the front . ” Sometimes , participants tried to compensate for what they believed the model did not understand . P6 noticed , for instance , “It seems like it does not know what the Cheshire Cat is , " changing their prompt from " An illustration of the Cheshire Cat from ’Alice in Wonderland’ " to " An illustration of a cat with a large face smiling and looking at the camera " . Finally , participants sometimes generated images mostly to test what Envisage might do with a prompt . For instance , P4 said to their partner : “Oh , we could try that with like ‘1969 poster’ or no . . . because the poster will make Imagen try to . . . ? Let’s try that . ‘1969 poster’ . ” Then , examining the results , they decided : “These are like the very artsy side which is probably less what we want . But they are still fun . ” 4 . 5 . 1 Prompts allow rapidly exploring the design space . In their role as reflective design materials , prompts allowed participants to rapidly explore their design’s content , style , and layout . For instance , many participants opened multiple instances of Envisage ( in different browser tabs ) to explore variations of a prompt , such as " Drawing of a Cheshire cat from Alice in Wonderland . Cartoon " , " Drawing of a Cheshire cat from Alice in Wonderland . Psychedelic " , and " Colorful drawing of a Cheshire cat from Alice in Wonderland . Cartoon . " Participants made these decisions with fluidity , interlaying decisions of content and style while navigating the limits of the model : P12 Yeah . . . it might be hard to get Alice eating cake . P11 . . . yeah P12 maybe we could do something with like ‘the cake from Alice in Wonderland’ . P11 Yeah . Yeah . Maybe if we can’t get Alice’s face out of it than we could use Alice’s face . . . like a non copyrighted one from Google . P11 Yeah . And then we could probably just do like , a cake that says ‘eat me’ on it , right ? P12 Hmm , yeah . You have like a style that we want for that ? P11 It definitely , it’s got to be like a cartoon one , at least . So we don’t want it photorealistic . Finally , because Envisage displayed multiple candidates per prompt , participants also could explore their design choices based on the results they obtained ( see Figure ffig : cake - choices ) . 4 . 5 . 2 A lack of distinction between means and ends . A key distinction of robust design materials is their ability to merge “means , ” and “ends” in the design process . As Schon writes , practice in such situations “inquiry is not limited to a deliberation about means which depends on a prior agreement about the ends [ 57 ] . [ They ] do not keep means and ends separate , but define them interactively as they frame a problematic situation . ” Tacitly , perhaps , participants interactively and continuously framed their work throughout the design session . 14 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY ( a ) “Yeah , it’s like it’s still a little bit cropped” ( b ) “Maybe the one on the plate . . . yeah , I think we should crop it around ‘grow”’ ( c ) “Oh , oh . . . that one’s not cropped and it’s still cake . ” Fig . 5 . Envisage allowed participants to rapidly explore the design space by allowing them to see different model interpreta - tions of their prompt . Above , participant reactions to the prompt : " The word ’grow’ made of cake . " For instance , they often chose to dig deeper in the design space when it seemed promising . For instance : P7 ( looking at screen ) Oh we’re getting something ! I will share this specific URL in the chat . P8 I like the fourth one . P7 Yeah . I will start adding some text if you want to keep iterating on this . . . I mean , I am OK , [ if we ] even replace the images that we have if we come up with something more party - like . In other cases , prompts also allowed participants to discover new “ends” through other exploration - based “means , ” e . g . , P4 : “I do not know . I just started trying to add stuff , but I agree . The ones we come up with since are better photos . ” ( This pair of participants replaced images in their final design . ) As noted elsewhere , reflective practice with prompts was far from perfect – limited visibility of prompts between partners and an inability to replicate results even with the same prompt hampered collaboration and exploration . At the same time , framing prompts as design materials offer several opportunities to understand the model - aided design process better and build tools to improve it . 4 . 6 Limitations . Some aspects of our study design complicate the interpretation of our findings . We outline limitations here in three areas : participant composition , study design and analysis , and technology advancements . Our participant pool was drawn among employees of one large US - based corporation , and does not cover the many possible ways that culture and training might have shaped the design process with text - to - image models . For example , they may be more comfortable collaborating remotely , as required in our study . Second , because of their choice to work in a technology firm , it is very likely that they are more familiar with the idea of Artificial Intelligence than the general public . As a result , our findings likely are different from what might be expected with the general public . At the same time , as familiarity with AI grows in the future , it is possible that results with the general public are similar . At the same time , it is possible that our participants were more optimistic about the possibilities of technology , given their choice of employment . Because of company policies and laws , we were prevented from asking about sensitive demographic details such as race or national origin , and are 15 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . unable to report differences among participants on these attributes , and if participants had differing concerns based on their identities . Our study focused on a single design task , which while representative of many tasks that non - professional designers engage in , may offer an incomplete picture of the impact of TTI models on design practices . It was not possible to systematically observe every participant’s prompt attempts , because some of those explorations were in screens that were not shared . Furthermore , our analysis is limited to observable conversations . For the interactions we could observe , observing a designer’s interactions with the model does not definitively indicate their conceptions ; for example , designers who acted in similar ways even when they engaged different mental processes . Since our analysis was episodic rather than longitudinal , we are also unable to discover how design strategies evolve within individual and pairs . Finally , technological advances may lead to an evolution of some of our findings . After we conducted all our participant sessions , but before publication of this paper , new models such as Stable Diffusion were released , and led to advances like editing existing images ( or parts of images ) using textual prompts . Our conceptualization of prompts as design materials may extend to include these additional modalities , but future work should investigate specific ways in which such interactions influence exploration and reflection . 5 DISCUSSION Our work contributes new insights into the use of text - to - image models in the design process by addressing our initial research questions : • RQ1 : How does using prompt - based image generation change the design process ? Our qualitative results show that text - to - image models allow for rapid exploration of the design space , and designers use them as a new form of reflective design material by formulating descriptions of their image ideas , then coming up with scenarios for expressing , testing , and finally refining their prompts either by affirming their initial image ideas or formulating new ones . • RQ2 : How do prompt - based image generation models change collaborative dynamics during design ? Based on the pair collaborations we observed , prompt - based image generation also allows for fluid collaboration and rapid prototyping for the collaborative synthesis of ideas . However , prompt visibility and the non - determinism in current models modulated the effectiveness of such collaboration . Informally , we also observed that participants were delighted both by the surprisingly good images and images that were “hilariously bad” . In addition , many participants reported that their experience with Envisage was more “fun . ” ( P4 ) Below , we discuss some emergent questions based on our findings . 5 . 1 Tool support for prompts as an indirect design material We found that the indirect nature of prompting both supported the design process ( by augmenting creative freedom ) and made it more challenging ( while participants worked on rephrasing prompts to match intent ) . In some ways , prompts occupy a similar role in visual design as HTML did in early web design . By seeing how a webpage was constructed , designers could rapidly adopt good ideas , remix them , and popularize them widely . In such designerly practices , the role of Web browsers was also key – by making “View Source” a universal feature , browsers likely transformed millions of people from web “readers” to web “writers . ” Our work suggests that a similar “View Source” feature would also catalyze visual design . For instance , models could embed prompts as image EXIF data . Such tool support could also allow for more straightforward iteration and remixing and make prompt - based image generation even more accessible . For example , one could imagine mixing a partner’s prompt ( or prompt embedding ) into one’s prompt , creating a hybrid prompt . Finally , since prompts are text , many ideas from text editors and version control may also be relevant . For example , collaborating partners could send each other suggested edits , similar to text editors , or discover good prompting strategies ( such as including clauses 16 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY like " framed art " ) . Other materials such as tutorials or can also aid in this discovery ( already , prompt guides are emerging ) . In addition , we can build on our observation that participants saw prompts as indirect design materials interpreted by opinionated image models . In light of these challenges , future work could empower end - users to control the model properties better . For example , users could swap out back - end models or fine - tune models on specific data ( e . g . , the same base model could have its weights fine - tuned by training on illustrations to help create art or furniture pictures for use by interior designers ) . Low - level properties ( e . g . , position and layout ) were challenging to control and remain an open question . Finally , while participants pushed back on opinionated models through prompt design , it may also be beneficial to develop models that are constrained in their output ( e . g . , not to crop parts of a salient object ) . 5 . 2 Support for iterative design with prompts Prompt - based models are currently being optimized for " one - shot " interactions : each run of the model uses a random seed without the ability to be anchored on prior results . Interestingly , although models have been optimized for single - shot accuracy , users may be treating it more as a thinking tool , working incrementally , rephrasing , steering , and backtracking as a fundamental part of their design process . In the future , supporting iterative prompting as a first - class objective would better allow people to use prompts as flexible design material . For example , users could toggle the random seed on and off depending on whether they were iterating on a design or starting in a new direction . Alternatively , they could bias the model to constrain or broaden exploration . Allowing users to navigate a history of states could also support exploring multiple ideas and backtracking . Since users may spend an inordinate amount of time rephrasing prompts to get the model output they desire , it may be valuable to combat potential design fixation by explicitly supporting the parallel exploration of multiple ideas , a process that is known to improve design results [ 16 ] . A recent study showed that designers can directly interact with concepts in the model latent space by using semantic guidance to steer the diffusion process along several directions which enabled them to perform more sophisticated image composition and editing [ 34 ] . 5 . 3 Multimodal affordances The multi - modality of prompt - based models also creates new affordances . For example , such multimodality might help with greater control . In the current study , participants could not quickly iterate on a promising image result ( e . g . , ask the model to generate more results like Image 2 , but with a bigger birthday cake ) and instead resorted to updating the prompt with the desired property ( e . g . , giant birthday cake ) . Similarly , model support for multimodality might help with better composited images , for instance by moving an object into the background with pointer selection , and extending images for a wider field of view ( with text prompts ) . Such affordances would improve iteration , and help designers express more complex visual concepts . 6 CONCLUSION This paper examines how text - to - image models can influence design processes and collaboration in goal - oriented design . Our results suggest that rather than a simple “magic” moment where designers input a prompt and designs are automatically generated , these models allow for a nuanced reflective practice of exploration , iteration , and collaboration . Our results also suggest that prompts can act as a design material and can support such emergent reflective practices . Finally , our study reveals several opportunities for tool design that build on the notion of prompts as reflective design materials , and suggest future directions for text - to - image model research . Together , they point to a future where designers can use text - to - image models more effectively , resulting in a deeper and more creative practice . 17 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . 7 ACKNOWLEDGMENTS Removed for anonymous review . REFERENCES [ 1 ] 2022 . Dynamicland . https : / / dynamicland . org / . ( Accessed on 09 / 07 / 2022 ) . [ 2 ] 2022 . Midjourney . https : / / www . midjourney . com / home / ( Accessed on 09 / 01 / 2022 ) . [ 3 ] 2022 . Scratch - Imagine , Program , Share . https : / / scratch . mit . edu / . ( Accessed on 09 / 07 / 2022 ) . [ 4 ] Stability AI . 2022 . Stable Diffusion launch announcement — Stability . Ai . https : / / stability . ai / blog / stable - diffusion - announcement ( Accessed on 08 / 31 / 2022 ) . [ 5 ] Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud : Dynamic Context Generation Improves Zero - Shot Reasoning Performance of GPT - 2 . https : / / doi . org / 10 . 48550 / ARXIV . 2103 . 13033 [ 6 ] Rishi Bommasani , Drew A . Hudson , Ehsan Adeli , Russ Altman , Simran Arora , Sydney von Arx , Michael S . Bernstein , Jeannette Bohg , Antoine Bosselut , Emma Brunskill , Erik Brynjolfsson , Shyamal Buch , Dallas Card , Rodrigo Castellon , Niladri Chatterji , Annie Chen , Kathleen Creel , Jared Quincy Davis , Dora Demszky , Chris Donahue , Moussa Doumbouya , Esin Durmus , Stefano Ermon , John Etchemendy , Kawin Ethayarajh , Li Fei - Fei , Chelsea Finn , Trevor Gale , Lauren Gillespie , Karan Goel , Noah Goodman , Shelby Grossman , Neel Guha , Tatsunori Hashimoto , Peter Henderson , John Hewitt , Daniel E . Ho , Jenny Hong , Kyle Hsu , Jing Huang , Thomas Icard , Saahil Jain , Dan Jurafsky , Pratyusha Kalluri , Siddharth Karamcheti , Geoff Keeling , Fereshte Khani , Omar Khattab , Pang Wei Koh , Mark Krass , Ranjay Krishna , Rohith Kuditipudi , Ananya Kumar , Faisal Ladhak , Mina Lee , Tony Lee , Jure Leskovec , Isabelle Levent , Xiang Lisa Li , Xuechen Li , Tengyu Ma , Ali Malik , Christopher D . Manning , Suvir Mirchandani , Eric Mitchell , Zanele Munyikwa , Suraj Nair , Avanika Narayan , Deepak Narayanan , Ben Newman , Allen Nie , Juan Carlos Niebles , Hamed Nilforoshan , Julian Nyarko , Giray Ogut , Laurel Orr , Isabel Papadimitriou , Joon Sung Park , Chris Piech , Eva Portelance , Christopher Potts , Aditi Raghunathan , Rob Reich , Hongyu Ren , Frieda Rong , Yusuf Roohani , Camilo Ruiz , Jack Ryan , Christopher Ré , Dorsa Sadigh , Shiori Sagawa , Keshav Santhanam , Andy Shih , Krishnan Srinivasan , Alex Tamkin , Rohan Taori , Armin W . Thomas , Florian Tramèr , Rose E . Wang , William Wang , Bohan Wu , Jiajun Wu , Yuhuai Wu , Sang Michael Xie , Michihiro Yasunaga , Jiaxuan You , Matei Zaharia , Michael Zhang , Tianyi Zhang , Xikun Zhang , Yuhui Zhang , Lucia Zheng , Kaitlyn Zhou , and Percy Liang . 2021 . On the Opportunities and Risks of Foundation Models . https : / / doi . org / 10 . 48550 / ARXIV . 2108 . 07258 [ 7 ] Virginia Braun and Victoria Clarke . 2006 . Using thematic analysis in psychology . Qualitative research in psychology 3 , 2 ( 2006 ) , 77 – 101 . [ 8 ] Andrew Brock , Jeff Donahue , and Karen Simonyan . 2018 . Large Scale GAN Training for High Fidelity Natural Image Synthesis . CoRR abs / 1809 . 11096 ( 2018 ) . arXiv : 1809 . 11096 http : / / arxiv . org / abs / 1809 . 11096 [ 9 ] Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert - Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel Ziegler , Jeffrey Wu , Clemens Winter , Chris Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few - Shot Learners . In Advances in Neural Information Processing Systems , H . Larochelle , M . Ranzato , R . Hadsell , M . F . Balcan , and H . Lin ( Eds . ) , Vol . 33 . Curran Associates , Inc . , 1877 – 1901 . https : / / proceedings . neurips . cc / paper / 2020 / file / 1457c0d6bfcb4967418bfb8ac142f64a - Paper . pdf [ 10 ] Amy Bruckman . 1998 . Community support for constructionist learning . Computer Supported Cooperative Work ( CSCW ) 7 , 1 ( 1998 ) , 47 – 86 . [ 11 ] Daniel Buschek , Lukas Mecke , Florian Lehmann , and Hai Dang . 2021 . Nine Potential Pitfalls when Designing Human - AI Co - Creative Systems . Workshops at the International Conference on Intelligent User Interfaces ( IUI ) ( 2021 ) . [ 12 ] Elizabeth Clark , Anne Spencer Ross , Chenhao Tan , Yangfeng Ji , and Noah A . Smith . 2018 . Creative Writing with a Machine in the Loop : Case Studies on Slogans and Stories . In 23rd International Conference on Intelligent User Interfaces ( Tokyo , Japan ) ( IUI ’18 ) . Association for Computing Machinery , New York , NY , USA , 329 – 340 . https : / / doi . org / 10 . 1145 / 3172944 . 3172983 [ 13 ] Sayamindu Dasgupta , William Hale , Andrés Monroy - Hernández , and Benjamin Mako Hill . 2016 . Remixing as a pathway to computational thinking . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing . 1438 – 1449 . [ 14 ] Nicholas Davis , Chih - PIn Hsiao , Kunwar Yashraj Singh , Lisa Li , Sanat Moningi , and Brian Magerko . 2015 . Drawing Apprentice : An Enactive Co - Creative Agent for Artistic Collaboration . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition ( Glasgow , United Kingdom ) ( C & C ’15 ) . Association for Computing Machinery , New York , NY , USA , 185 – 186 . https : / / doi . org / 10 . 1145 / 2757226 . 2764555 [ 15 ] Nicholas Davis , Chih - PIn Hsiao , Kunwar Yashraj Singh , Lisa Li , and Brian Magerko . 2016 . Empirically Studying Participatory Sense - Making in Abstract Drawing with a Co - Creative Cognitive Agent . In Proceedings of the 21st International Conference on Intelligent User Interfaces ( Sonoma , California , USA ) ( IUI ’16 ) . Association for Computing Machinery , New York , NY , USA , 196 – 207 . https : / / doi . org / 10 . 1145 / 2856767 . 2856795 [ 16 ] Steven P Dow , Alana Glassco , Jonathan Kass , Melissa Schwarz , Daniel L Schwartz , and Scott R Klemmer . 2010 . Parallel prototyping leads to better design results , more divergence , and increased self - efficacy . ACM Transactions on Computer - Human Interaction ( TOCHI ) 18 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY 17 , 4 ( 2010 ) , 1 – 24 . [ 17 ] Benj Edwards . 2022 . AI wins state fair art contest , annoys humans . https : / / arstechnica . com / information - technology / 2022 / 08 / ai - wins - state - fair - art - contest - annoys - humans / ( Accessed on 09 / 02 / 2022 ) . [ 18 ] Gilles Fauconnier and Mark Turner . 2008 . The way we think : Conceptual blending and the mind’s hidden complexities . Basic books . [ 19 ] Jonas Frich , Lindsay MacDonald Vermeulen , Christian Remy , Michael Mose Biskjaer , and Peter Dalsgaard . 2019 . Mapping the Landscape of Creativity Support Tools in HCI . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 18 . https : / / doi . org / 10 . 1145 / 3290605 . 3300619 [ 20 ] Katy Ilonka Gero and Lydia B . Chilton . 2019 . Metaphoria : An Algorithmic Companion for Metaphor Creation . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3290605 . 3300526 [ 21 ] Maliheh Ghajargar and Mikael Wiberg . 2018 . Thinking with interactive artifacts : Reflection as a concept in design outcomes . Design Issues 34 , 2 ( 2018 ) , 48 – 63 . [ 22 ] Ian Goodfellow , Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron Courville , and Yoshua Bengio . 2020 . Generative Adversarial Networks . Commun . ACM 63 , 11 ( oct 2020 ) , 139 – 144 . https : / / doi . org / 10 . 1145 / 3422622 [ 23 ] Google . 2022 . Imagen : Text - to - Image Diffusion Models . https : / / imagen . research . google / ( Accessed on 08 / 31 / 2022 ) . [ 24 ] Google . 2022 . Parti : Pathways Autoregressive Text - to - Image Model . https : / / parti . research . google / ( Accessed on 08 / 31 / 2022 ) . [ 25 ] Jeffrey T Hancock , Mor Naaman , and Karen Levy . 2020 . AI - Mediated Communication : Definition , Research Agenda , and Ethi - cal Considerations . Journal of Computer - Mediated Communication 25 , 1 ( 01 2020 ) , 89 – 100 . https : / / doi . org / 10 . 1093 / jcmc / zmz022 arXiv : https : / / academic . oup . com / jcmc / article - pdf / 25 / 1 / 89 / 32961176 / zmz022 . pdf [ 26 ] Cheng - Zhi Anna Huang , Hendrik Vincent Koops , Ed Newton - Rex , Monica Dinculescu , and Carrie J . Cai . 2020 . AI Song Contest : Human - AI Co - Creation in Songwriting . ( 2020 ) . https : / / doi . org / 10 . 48550 / ARXIV . 2010 . 05388 [ 27 ] Karen A Jehn and Elizabeth A Mannix . 2001 . The dynamic nature of conflict : A longitudinal study of intragroup conflict and group performance . Academy of management journal 44 , 2 ( 2001 ) , 238 – 251 . [ 28 ] YoungseungJeon , SeungwanJin , PatrickC . Shih , andKyungsikHan . 2021 . FashionQ : AnAI - DrivenCreativitySupportToolforFacilitating Ideation in Fashion Design . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 576 , 18 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445093 [ 29 ] AnnaKantosaloandHannuToivonen . 2016 . Modesforcreativehuman - computercollaboration : Alternatingandtask - dividedco - creativity . In Proceedings of the seventh international conference on computational creativity . 77 – 84 . [ 30 ] Pegah Karimi , Nicholas Davis , Mary Lou Maher , Kazjon Grace , and Lina Lee . 2019 . Relating Cognitive Models of Design Creativity to the Similarity of Sketches Generated by an AI Partner . In Proceedings of the 2019 on Creativity and Cognition ( San Diego , CA , USA ) ( C & C ’19 ) . Association for Computing Machinery , New York , NY , USA , 259 – 270 . https : / / doi . org / 10 . 1145 / 3325480 . 3325488 [ 31 ] Tero Karras , Samuli Laine , and Timo Aila . 2019 . A Style - Based Generator Architecture for Generative Adversarial Networks . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) . [ 32 ] Janin Koch , Andrés Lucero , Lena Hegemann , and Antti Oulasvirta . 2019 . May AI ? Design Ideation with Cooperative Contextual Bandits . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3290605 . 3300863 [ 33 ] Janin Koch , Nicolas Taffin , Michel Beaudouin - Lafon , Markku Laine , Andrés Lucero , and Wendy E . Mackay . 2020 . ImageSense : An Intelligent Collaborative Ideation Tool to Support Diverse Human - Computer Partnerships . Proc . ACM Hum . - Comput . Interact . 4 , CSCW1 , Article 45 ( may 2020 ) , 27 pages . https : / / doi . org / 10 . 1145 / 3392850 [ 34 ] Mingi Kwon , Jaeseok Jeong , and Youngjung Uh . 2022 . Diffusion models already have a semantic latent space . arXiv preprint arXiv : 2210 . 10960 ( 2022 ) . [ 35 ] O Lieber , O Sharir , B Lentz , and Y Shoham . 2021 . Jurassic - 1 : Technical Details and Evaluation , White paper , AI21 Labs , 2021 . URL : https : / / uploads - ssl . webflow . com / 60fd4503684b466578c0d307 / 61138924626a6981ee09caf6 _ jurassic _ tech _ paper . pdf [ 36 ] Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021 . What Makes Good In - Context Examples for GPT - 3 ? https : / / doi . org / 10 . 48550 / ARXIV . 2101 . 06804 [ 37 ] Ryan Louie , Andy Coenen , Cheng Zhi Huang , Michael Terry , and Carrie J . Cai . 2020 . Novice - AI Music Co - Creation via AI - Steering Tools for Deep Generative Models . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3313831 . 3376739 [ 38 ] Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021 . Fantastically Ordered Prompts and Where to Find Them : Overcoming Few - Shot Prompt Order Sensitivity . https : / / doi . org / 10 . 48550 / ARXIV . 2104 . 08786 [ 39 ] Elman Mansimov , Emilio Parisotto , Jimmy Lei Ba , and Ruslan Salakhutdinov . 2015 . Generating Images from Captions with Attention . https : / / doi . org / 10 . 48550 / ARXIV . 1511 . 02793 [ 40 ] Jennifer Marlow and Laura Dabbish . 2014 . From rookie to all - star : professional development in a graphic design social networking site . In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing . 922 – 933 . 19 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . [ 41 ] Jon McCormack , Toby Gifford , Patrick Hutchings , Maria Teresa Llano Rodriguez , Matthew Yee - King , and Mark d’Inverno . 2019 . In a Silent Way : Communication Between AI and Improvising Musicians Beyond Sound . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 11 . https : / / doi . org / 10 . 1145 / 3290605 . 3300268 [ 42 ] Matthew B Miles and A Michael Huberman . 1984 . Drawing valid meaning from qualitative data : Toward a shared craft . Educational researcher 13 , 5 ( 1984 ) , 20 – 30 . [ 43 ] Changhoon Oh , Jungwoo Song , Jinhan Choi , Seonghyeon Kim , Sungwoo Lee , and Bongwon Suh . 2018 . I Lead , You Help but Only with Enough Details : Understanding User Experience of Co - Creation with Artificial Intelligence . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( Montreal QC , Canada ) ( CHI ’18 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3173574 . 3174223 [ 44 ] OpenAI . 2022 . DALL·E 2 . https : / / openai . com / dall - e - 2 / ( Accessed on 08 / 31 / 2022 ) . [ 45 ] OpenAI . 2022 . DALL·E : Creating Images from Text . https : / / openai . com / blog / dall - e / ( Accessed on 08 / 31 / 2022 ) . [ 46 ] Sharon Oviatt and Philip Cohen . 2000 . Perceptual User Interfaces : Multimodal Interfaces That Process What Comes Naturally . Commun . ACM 43 , 3 ( mar 2000 ) , 45 – 53 . https : / / doi . org / 10 . 1145 / 330534 . 330538 [ 47 ] Michael Quinn Patton . 1990 . Qualitative evaluation and research methods . SAGE Publications , inc . [ 48 ] Brian Quanz , Wei Sun , Ajay Deshpande , Dhruv Shah , and Jae - eun Park . 2020 . Machine learning based co - creative design framework . arXiv preprint arXiv : 2001 . 08791 ( 2020 ) . [ 49 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical Text - Conditional Image Generation with CLIP Latents . https : / / doi . org / 10 . 48550 / ARXIV . 2204 . 06125 [ 50 ] Aditya Ramesh , Mikhail Pavlov , Gabriel Goh , Scott Gray , Chelsea Voss , Alec Radford , Mark Chen , and Ilya Sutskever . 2021 . Zero - Shot Text - to - Image Generation . In Proceedings of the 38th International Conference on Machine Learning ( Proceedings of Machine Learning Research , Vol . 139 ) , Marina Meila and Tong Zhang ( Eds . ) . PMLR , 8821 – 8831 . https : / / proceedings . mlr . press / v139 / ramesh21a . html [ 51 ] Jeba Rezwana and Mary Lou Maher . 2022 . Understanding User Perceptions , Collaborative Experience and User Engagement in Different Human - AI Interaction Designs for Co - Creative Systems . In Creativity and Cognition ( Venice , Italy ) ( C & C ’22 ) . Association for Computing Machinery , New York , NY , USA , 38 – 48 . https : / / doi . org / 10 . 1145 / 3527927 . 3532789 [ 52 ] Robin Rombach , Andreas Blattmann , Dominik Lorenz , Patrick Esser , and Björn Ommer . 2022 . High - Resolution Image Synthesis With Latent Diffusion Models . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition ( CVPR ) . 10684 – 10695 . [ 53 ] Ricarose Roque , Natalie Rusk , and Mitchel Resnick . 2016 . Supporting diverse and creative collaboration in the Scratch online community . In Mass collaboration and education . Springer , 241 – 256 . [ 54 ] Chitwan Saharia , William Chan , Saurabh Saxena , Lala Li , Jay Whang , Emily Denton , Seyed Kamyar Seyed Ghasemipour , Burcu Karagol Ayan , S . Sara Mahdavi , Rapha Gontijo Lopes , Tim Salimans , Jonathan Ho , David J Fleet , and Mohammad Norouzi . 2022 . Photorealistic Text - to - Image Diffusion Models with Deep Language Understanding . https : / / doi . org / 10 . 48550 / ARXIV . 2205 . 11487 [ 55 ] Othman Sbai , Mohamed Elhoseiny , Antoine Bordes , Yann LeCun , and Camille Couprie . 2018 . DesIGN : Design Inspiration from Generative Networks . In Proceedings of the European Conference on Computer Vision ( ECCV ) Workshops . [ 56 ] Donald A Schön . 1984 . The architectural studio as an exemplar of education for reflection - in - action . Journal of Architectural Education 38 , 1 ( 1984 ) , 2 – 9 . [ 57 ] Donald A Schön . 1987 . Educating the reflective practitioner : Toward a new design for teaching and learning in the professions . Jossey - Bass . [ 58 ] Isabella Seeber , Eva Bittner , Robert O . Briggs , Triparna de Vreede , Gert - Jan de Vreede , Aaron Elkins , Ronald Maier , Alexander B . Merz , Sarah Oeste - Reiß , Nils Randrup , Gerhard Schwabe , and Matthias Söllner . 2020 . Machines as teammates : A research agenda on AI in team collaboration . Information & Management 57 , 2 ( 2020 ) , 103174 . https : / / doi . org / 10 . 1016 / j . im . 2019 . 103174 [ 59 ] Minhyang ( Mia ) Suh , Emily Youngblom , Michael Terry , and Carrie J Cai . 2021 . AI as Social Glue : Uncovering the Roles of Deep Generative AI during Social Music Composition . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 582 , 11 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445219 [ 60 ] Sherry Turkle . 2005 . The second self : Computers and the human spirit . Mit Press . [ 61 ] Dakuo Wang , Elizabeth Churchill , Pattie Maes , Xiangmin Fan , Ben Shneiderman , Yuanchun Shi , and Qianying Wang . 2020 . From Human - Human Collaboration to Human - AI Collaboration : Designing AI Systems That Can Work Together with People . In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI EA ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 6 . https : / / doi . org / 10 . 1145 / 3334480 . 3381069 [ 62 ] Kai Wang and Jeffrey V Nickerson . 2017 . A literature review on individual creativity support systems . Computers in Human Behavior 74 ( 2017 ) , 139 – 151 . [ 63 ] Jason Wei , Yi Tay , Rishi Bommasani , Colin Raffel , Barret Zoph , Sebastian Borgeaud , Dani Yogatama , Maarten Bosma , Denny Zhou , Donald Metzler , et al . 2022 . Emergent abilities of large language models . arXiv preprint arXiv : 2206 . 07682 ( 2022 ) . [ 64 ] Tongshuang Wu , Michael Terry , and Carrie Jun Cai . 2022 . AI Chains : Transparent and Controllable Human - AI Interaction by Chaining LargeLanguageModelPrompts . In Proceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems ( NewOrleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 385 , 22 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517582 20 Prompts as AI Design Material Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY [ 65 ] Qian Yang . 2020 . Profiling Artificial Intelligence as a Material for User Experience Design . Ph . D . Dissertation . Carnegie Mellon University . [ 66 ] Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020 . Re - Examining Whether , Why , and How Human - AI Interaction Is Uniquely Difficult to Design . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3313831 . 3376301 [ 67 ] JiahuiYu , YuanzhongXu , JingYuKoh , ThangLuong , GunjanBaid , ZiruiWang , VijayVasudevan , AlexanderKu , YinfeiYang , BurcuKaragol Ayan , Ben Hutchinson , Wei Han , Zarana Parekh , Xin Li , Han Zhang , Jason Baldridge , and Yonghui Wu . 2022 . Scaling Autoregressive Models for Content - Rich Text - to - Image Generation . https : / / doi . org / 10 . 48550 / ARXIV . 2206 . 10789 [ 68 ] Jun - Yan Zhu , Taesung Park , Phillip Isola , and Alexei A . Efros . 2017 . Unpaired Image - To - Image Translation Using Cycle - Consistent Adversarial Networks . In Proceedings of the IEEE International Conference on Computer Vision ( ICCV ) . A APPENDIX A . 1 Task Descriptions A . 1 . 1 Design prompt for the “Moon Landing Party” task . Assignment You have been hired to design a poster inviting people to a fun party celebrating the 55th anniversary of the first Moon Landing . You may create multiple versions , and then choose a final design to be sent to invitees . About the Moon Landing Apollo 11 ( July 16 – 24 , 1969 ) was the American spaceflight that first landed humans on the Moon . Commander Neil Armstrong and lunar module pilot Buzz Aldrin landed the Apollo Lunar Module Eagle on July 20 , 1969 . At the event , we will have Moon themed decorations , light refreshments , and very cool Moon - themed things . A . 1 . 2 Design Prompt for the “Alice’s Birthday” task . Assignment You have been hired to design a party invitation to Alice Liddell’s birthday party . You may create multiple versions , and then choose a final design to be sent to all of Alice’s friends . Who is Alice Liddell : Alice is a fictional character and the main protagonist of Lewis Carroll’s children’s novel Alice’s Adventures in Wonderland ( 1865 ) and its sequel , Through the Looking - Glass ( 1871 ) . A child in the mid - Victorian era , Alice unintentionally goes on an underground adventure after accidentally falling down a rabbit hole into Wonderland ; in the sequel , she steps through a mirror into an alternative world . A . 1 . 3 Rules and Requirements . These rules and requirements were presented before each design session . Please make sure your graphic follows these rules ! • You may download and use graphics , images , text etc . as you see fit . • You may not use photos of faces , persons , or groups of people . • Do not use stock images and photos , and any computer generated images of people either . • You may not use [ the organization ] ’s or another company’s logo , copyrighted images , profanity , obscenity or nudity . • Your final output will be evaluated for creativity and completeness . The most creative invitations will get a bonus ! In the Envisage condition , we included this statement below these rules : WHERE APPROPRIATE , USE ENVISAGE IN THIS TASK . 21 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Kulkarni , et al . C o d e D e fi n i t i o n E x a m p l e S e a r c h S t r a t e g i e s H o w p a r t i c i p a n t s q u e r i e d a s e a r c h e n g i n e f o r i m a g e s “ [ L e t m e s ee ] i f I c a n c o m e u p w i t h s o m e t e x t f o r h a pp y b i r t h d a y , . . . A n o t h e r i d e a i s s e a r c h o n G oo g l e f o r t h e m . Y o u s w i t c h o n C r e a t i v e C o mm o n s r i g h t ? . . . w e c a n fi n d s o m e t h i n g g r a b s o m e t h i n g f r o m . ” ( P 1 ) P r o m p t S t r a t e g i e s H o w p a r t i c i p a n t s p r o m p t e d TT I m o d e l t o g e n e r a t e i m a g e s “ y o u s o r t o f n ee d t o s p e n d a l o t o f t i m e g e n e r a t i n g a b u n c h o f d i ff e r e n t i d e a s a n d t r y i n g t o fi g u r e o u t h o w t o m a n i p u l a t e t h e p r o m p t i n o r d e r t o g e t . ” ( P 5 ) O p i n i o n a t e d p a r t n e r I n s t a n c e s w h e n t h e TT I m o d e l p r o d u c e s u n e x p e c t e d r e s u l t s “ L i k e i t ’ s a l w a y s l i k e t h i s i m a g e . . . w h i c h i s a g r e a t p i c t u r e o f a r a bb i t b u t w e w a n t j u s t [ ] s o m e t h i n g t h a t l o o k s L i k e i n A l i c e i n W o n d e r l a n d . . . a n d I d o n ’ t k n o w h o w w e d o t h a t . ” ( P 3 ) ” N o t s u r e h o w t o p u s h t h i s i n t o a d i r e c t i o n t h a t w o u l d m a k e t h e d r a w i n g s m o r e u s e f u l . ” ( P 9 ) C o ll a b o r a t i o n s u pp o r t I n s t a n c e s w h e n TT I m o d e l e n a b l e d c o ll a b o r a t i o n “ M a y b e w e c a n t r y c r e a t i n g a c a r t oo n i m a g e fi r s t . . . . W h a t d o y o u t h i n k w e s h o u l d i n c l u d e i n t h i s ? I t h i n k m a y b e h a v i n g s o m e t h i n g f r o m A l i c e i n W o n d e r l a n d , l i k e t h e C h e s h i r e C a t . ” ( P 6 ) ( s ee i n g r e s u l t s ) “ I g o t p i c t u r e s o f c a r d s , m a y b e w e s h o u l d g e t r i d o f A l i c e i n W o n d e r l a n d a n d s ee i f t h a t h e l p s ” ( P 7 ) A r t i s t i d e n t i t y I n s t a n c e s w h e n TT I m o d e l e n a b l e d p a r t i c i p a n t s t o d e v e l o p t h e i r a r t i s t i c & c r e a t i v e i d e n t i t y “ I t ’ s h a r d t o c o n t r o l [ ] b u t a l s o o n e o f t h e c oo l t h i n g s t h a t i t c a n h e l p y o u i s t o b e c r e a t i v e w i t h c o n t e n t , l i k e , o h , i t ’ s l i k e m a d e a w e i r d c oo l p o s t e r t h i n g . ” ( P 4 ) “ I g u e ss j u s t b e d r o pp i n g s o m e o f t h e s e [ i m a g e s ] i n t o t h e s l i d e s ” ( P 11 ) T a b l e 1 . T h e m a t i c c o d e s a n d e x a m p l e q u o t e s f r o m o u r p a r t i c i p a n t s . P a r t i c i p a n t q u o t e s h a v e b ee n c o rr e c t e d f o r s p ee c h a m b i g u i t i e s a n d t r a n s c r i p t i o n e rr o r s . B T H E M A T I C C O D I N G 22