Towards a Talking Tiny Cognitive Architecture for the Study of Spoken Language Evolution Smitha Kaje Department of Electrical and Computer Engineering Stony Brook University Stony Brook , NY , USA smitha . kaje @ stonybrook . edu George Saviour Department of Electrical and Computer Engineering Stony Brook University Stony Brook , NY , USA george . madathilsaviour @ stonybrook . edu Alex Doboli Department of Electrical and Computer Engineering Stony Brook University Stony Brook , NY , USA alex . doboli @ stonybrook . edu Abstract —Understanding spoken language evolution can offer important insight that is needed to devise intelligent systems with speech capabilities . However , existing work mostly focuses on mathematical and software models that are insensitive to naturalistic conditions , even though such conditions are essential in the evolution of real languages . This paper discusses the implementation of Talking Tiny Cognitive Architecture proposed to study language evolution in more naturalistic conditions . The architecture can generate new words that are verbally communicated to describe environment conditions . It also attempts to understand and learn words verbally communicated by another architecture . Experiments describe the performance of the implementation as an embedded system . Keywords—intelligent embedded systems , language evolution , cognitive architecture , human - computer interaction I . I NTRODUCTION Adding speech capabilities to intelligent systems has received significant attention over time from research communities in dialog systems [ 1 ] , multi - agent systems [ 2 , 20 ] , automated translation [ 3 ] , smart embedded devices , like chatbots [ 4 ] , and more recently Generative Artificial Intelligence ( AI ) , including Large Language Models [ 5 , 6 ] , e . g . , GPT models . Their goal is to offer superior interaction and integration of computing systems and humans , enhanced automation of many human tasks , and improved effectiveness of human - centered activities and businesses , including education and healthcare [ 7 , 18 , 19 ] . Devising human - computer interactions that are like human , verbal communications will likely ease explaining machine decisions to a larger audience , thus increasing the broad public thrust in machine - made decisions [ 8 , 16 ] . A distinct body of work within computational speech generation and linguistics tackles the nature and factors of language evolution [ 9 , 10 ] . Language evolution is often expressed as the stochastic evolutionary dynamics of signaling games having the goal to find the equilibrium in which participating agents associate the same verbal signals to the same objects [ 9 ] . Depending on the associated payoffs , models refer to agents with perfectly aligned interests [ 9 ] , or to agents with imperfect alignments , when agents have different interests , thus without a guarantee of evolving an “optimal” language , in which all agents assign the same signals and objects [ 10 ] . Despite the insight offered into the theory of languages , a main critique of the current work is that language evolution and learning occur in naturalistic conditions that are often not captured by present models [ 11 ] . Based mainly on work in psychology , the extended , embodied , embedded and enactive theory stresses the importance of grounded language acquisition [ 11 ] . For example , experimental evidence shows the importance of multi - modal contextual information to disambiguate spoken language , assess intentions , and optimize perception and language understanding . Moreover , the Theory of Perceptual Symbols suggests that language understanding involves simulating the related scenes by activating perceptual , motor , and emotional experiences [ 12 ] . Understanding language evolution in naturalistic conditions is still challenging , and new , appropriate experimental support must be devised . This paper proposes a novel cognitive architecture , called Talking Tiny Cognitive Architecture ( TTCA ) , meant to support the study of problems on language evolution in naturalistic conditions , like the physical properties of the environment , such as temperature and ambient light . The implementation of the presented TTCA is based on the Cypress’ PSoC 1 embedded system [ 13 , 15 , 17 ] . TTCA can generate new audio signals for words describing new environmental conditions . In addition , it tries to correctly understand and learn the vocabulary of the TTCAs it communicates with . Ambiguities in word understanding can occur . Moreover , the meaning ( semantics ) of words can change depending on the environmental conditions to reduce the size of the word vocabulary by extending the meaning of an existing word to include new conditions or by merging two separate words for situations that often co - occur . TTCA has two separate memory modules , one for its own vocabulary and one for the learned words . Memories are re - organized to reflect recently and frequently used words . The paper presents the performance of the TTCA implemented using the PSoC 1 mixed analog - digital embedded system . This paper structure is as follows . Section II defines the studied problem . Section III discusses TTCA . Section IV details its implementation . Section V offers experimental results . Conclusions and future work end the paper II . PROBLEM DESCRIPTION The proposed problem targets the study of the evolution of a shared verbal language between a group of similar , 979 - 8 - 3503 - 3798 - 3 / 23 / $ 31 . 00 ©2023 IEEE 111 2023 27 t h I n t e r n a ti on a l C on f e r e n ce on S y s t e m T h e o r y , C on t r o l a nd C o m pu ti ng ( I C S T CC ) | 979 - 8 - 3503 - 3798 - 3 / 23 / $ 31 . 00 © 2023 I EEE | DO I : 10 . 1109 / I C S T CC 59206 . 2023 . 10308445 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . intelligent agents that communicate about environmental conditions , like temperature and light . These conditions are possibly inter - linked . As there is no initial , shared language , the agents create their own words to describe environmental conditions , however , they can learn the words of other agents and adopt them if they represent a more effective verbal description . Communication effectiveness refers to the capability of the language to express correctly and unambiguously the intended messages in the shortest amount of time . The agents talk to each other about the conditions of the physical environment in which they operate . They use audio signals ( like spoken words ) to communicate . A word is a sequence of audio signals that are assembled using a set of rules that refer to the ( i ) assembling and ( ii ) length of the words ( e . g . , phonetics ) and ( iii ) the separation of consecutive words ( such as through silent moments ) . An agent talks at random time moments . Each agent has two memory modules : a memory module in which it stores its own vocabulary ( e . g . , the words that it created and used over the latest time window of length L seconds ) , and a second memory for the vocabulary used by the partner agents over the latest time window of length M seconds . The two vocabularies are restructured ( e . g . , reordered ) every T 1 and T 2 seconds , respectively , to store the more frequently used words first . The meaning ( semantics ) of words is as follows . Each word expresses environmental conditions , like temperature and ambient light , that are physically sensed through dedicated sensors . Note that the two agents can operate in the same or in different environments , so that their sensed temperature and ambient light conditions are different . The expressed temperature and ambient light conditions represent discrete values ( e . g . , labels ) , not numerical values . For example , temperature labels might describe situations like blazing , hot , warm , cool , cold , frigid , and so on . A word expresses either one temperature label , or a light condition label , or a combination of the two labels . The number of created labels is unknown , the only known information is that they represent different conditions . Each agent invents its own verbal language in real - time using the following rules : • Language extension : For any new temperature , ambient light , or temperature – light condition , the agent can decide to introduce a new word or extend the meaning of an existing word to include this condition too . This defines a trade - off between the word meaning precision and the vocabulary size . • Purpose : A new word is created to describe a novel temperature , light , or temperature – light condition . The new word is a previously unused audio sequence . • Vocabulary size : The vocabulary keeps only the words that correspond to the Q most recently used words and the R most frequently words . All other ( previously used ) words are forgotten . New words must be created if forgotten conditions occur again . • Vocabulary effectiveness : To reduce the size of its own vocabulary , an agent can decide to combine a word for a temperature condition and a word for an ambient light condition , if the two conditions are often co - occurring . The combined word merges some audio features of the first word with audio features of the second word if the new word does not exist . Each agent attempts to learn the other agent’s vocabulary , e . g . , the meaning of the received words , knowing that they talk about environmental conditions , possibly the same physical conditions . For example , two agents might create two different words to describe the same , current temperature and light conditions , as the words are created by an agent independently of the other agent . During the ( other agent’s ) language learning , an agent must decide to solve the following possible types of ambiguities of what the unknown words might represent : • Word type : Decide if a new word received from another agent represents a temperature or a light value . • Word meaning extension : Decide if a received word has extended its meaning to include a new physical value , i . e . the word previously denoted another temperature or light value , but its meaning was extended by the other agent to include a new value for temperature or light conditions . • Combined word meanings : Decide if a new word is a combination of two previous words to express a joint temperature - light condition , or if it represents a totally new meaning unrelated to the previous two words . • Word learning : Decide to adopt the new word and drop its own word for the same conditions , if the agent considers that it might help the learning process . Decision - making maximizes the correctness and description - capacity of the own vocabulary . III . THE COGNITIVE ARCHITECTURE The proposed Talking Tiny Cognitive Architecture ( TTCA ) senses data from sensors , such as temperature and ambient light , and differentiates the data based on their value ranges to create a self - vocabulary memory ( table ) . Also , it communicates with another system within the same environmental conditions to create a listening vocabulary memory ( table ) while communicating with it . TTCA is based on the cognitive architecture in [ 14 ] and then adjusted in [ 20 ] . Initially , both TTCAs are stationed in the same room in the same environment . Each TTCA learns the other system’s behavior of generating words that denote a temperature , or light , or temperature and light condition . Based on the learnings attained , both TTCAs should predict the words spoken between each other when placed in different environments using Naïve Bayes classifier . A TTCA performs the following operations : ( 1 ) sensing , ( 2 ) learning , and ( 3 ) decision making , as shown in Fig . 1 . The flow chart conceptually describes how the architecture performs the three operations . The learning algorithm has two parts : • Part 1 : On top , its own and neighbors’ vocabulary tables maintain the labels , word encodings as bitstrings , and frequency of each word received by a TTCA . They are used to calculate the conditional probability for the naïve Bayes classification . 2023 27th International Conference on System Theory , Control and Computing ( ICSTCC ) , Timisoara , Romania , October 11 - 13 , 2023 112 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 1 . The processing flow of the cognitive architecture • Part 2 : It improves the data set or frequency tables by re - learning the ranges of temperature and ambient light used for word generation . After listening , it checks if the listened word needs to be entered in the neighbor’s vocabulary table . If the same word label is already present in the neighbor’s table but with a different bit string , it means that the sender architecture has extended the word meaning to include a new value for temperature or light conditions . In this case , it re - adjusts ( relearns ) the ranges for temperature and light . This way it correctly labels the received words , and thereby the learning table will have a smaller number of false positive data . The correctly predicted words will highly have likelihood when compared to the false predicted words , hence improving the accuracy of the system when in different environment . The system follows a continuous learning process if it is in the same environment . As soon as both architectures are no longer in the same environment , they depend on the learning tables for correct prediction . Example : The following bitstring encodings correspond to different ambient conditions : 1010 1001 for DARK _ COLD , 101010 0000 for DARK , 1010 1001 for DARK _ MEDIUM , 0100 1010 for BRIGHT _ COLD , and so on . Note that the bitstrings are communicated as signals in the audio range , hence the “talking” feature of TTCA . The decision algorithm operates in two modes : • Mode = = SAME _ ENVIRONMENT : When both agents are in the same environment , TTCA relies on the sensor values to decide the meaning of received bitstring . We assumed there is an external mechanism to know which mode the agents are operating in , a button can be used to indicate the mode of operation . • In Mode = = DIFFERENT _ ENVIRONMENT : For this mode , TTCA uses a naïve Bayes classifier to predict the meaning of the received bitstring . This node can also be considered as a fallback mechanism . TTCA uses naïve Bayes classifier to predict meaning of the word listened from another TTCA . Bayes’ theorem finds the probability of an event occurring given the probability of another event that has already occurred : P ( A | B ) = P ( B | A ) x P ( A ) / P ( B ) Probability P ( A ) is called priori of A , i . e . , the probability of an event before evidence is seen . The evidence is an attribute value of an unknown instance , i . e . event B . P ( A | B ) is the posteriori probability of B , i . e . , probability of event after evidence is seen . Example : Consider that the receiving agent has received the bitstream 10101001 and needs to predict the label it belongs to ( i . e . meaning ) using the priori probability data ( listening table ) created during the learning process . Prediction computes the probability P ( “DARK _ COLD” ) given the bitstream 10101001 . Using Bayes’ naïve classification : P ( “DARK _ COLD” | 10101001 ) = P ( 10101001 | “DARK _ COLD” ) x P ( “DARK _ COLD” ) / P ( 10101001 ) Assuming that the denominator probability is the same for all labels : P ( “DARK _ COLD” | 10010101 ) = P ( 10010101 | “DARK _ COLD” ) x P ( “DARK _ COLD” ) Similarly , the classifier calculates the best conditional probability for all possible labels , such as DARK , DARK _ MEDIUM , BRIGHT _ COLD , etc . , and selects the one with highest probability as being the most likely one . IV . DETAILED IMPLEMENTATION This section presents the fundamental routines , data structures , sensor interfacing , hardware modules , and performance of the proposed TTCA implementation using Cypress PSoC 1 embedded system [ 13 , 15 , 17 ] . A . Fundamental routines Following are the main routines of the implementation : Routine getLux ( ) reads the outputs of a dual analog - to - digital converter ( ADC ) connected to a light sensor , and converts it to the lux value in a range from 0 to 1000 . Routine read _ temperature ( ) reads a temperature value from the temperature sensor via the I2C module . The value is converted to degrees Celsius . Routine create _ word ( ) generates labels for each read light and temperature value , and creates a bitstring that originates the audio signal of the spoken word . The word encoding describes light – temperature conditions . Routine update _ table ( ) inserts the new word into its own vocabulary memory ( table ) , if the word encoding is new . If it is an existing word , then its frequency is updated . The routine increments the age value associated with the word in the vocabulary table , each time a word is created . Routine quicksort ( ) performs quick sorting for the vocabulary tables based on the frequency values of each word entry in the table . 2023 27th International Conference on System Theory , Control and Computing ( ICSTCC ) , Timisoara , Romania , October 11 - 13 , 2023 113 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Routine remove ( ) eliminates during vocabulary reordering word entries that are below a threshold frequency . Routine speak ( ) outputs the words generated using the connected speakers . A Pulse Width Modulator ( PWM ) module generates the audio signals that drive the speaker . The PWM operates at 1 . 4kHz and is turned off and on based on the 1 and 0 bits of the generated bitstring . Routine blocking _ delay ( ) performs a blocking delay operation . Routine Swap ( ) is used for the reordering algorithm . Routine Part ( ) partitions for the quick sorting method . Routine TimerISR ( ) is an Interrupt Service Routine ( ISR ) , triggered by the timer module every 60 seconds . It initiates the re - ordering operation of the vocabulary . Routine Timer16 _ 1 _ ISR ( ) is an ISR that maintains a clock for the architecture . The timer interrupt is triggered every 100ms and used for the listening operation . Global variable wElapsedTime is incremented for each triggering . Routine Listen ( ) performs the listening operations . It listens for X seconds of duration , for one stamp at a time . At X seconds the routine detects the bit stream that the other TTCA transmits via audio . If the average ADC value of the microphone exceeds more than the loud stamp threshold value of 0x200 , it detects that a loud stamp is transmitted by the other agent , whereas if the average ADC value is less this threshold , a silent stamp is found . Routine check _ if _ labelPresent ( ) creates a label using the agent’s sensed temperature and light values and then checks if this label is in the neighbors’ table . Routine check _ if _ bit _ stream _ match ( ) checks if the bitstring of the received word matches with the bitstring of the word that is already present in the neighbors table . Routine re _ learn _ ranges ( ) is used to re - adjust the ranges of temperature and light values . It generates the bitstring encoding for a word . This reduces the frequency of wrongly predicted words in the learning table , thereby improving the accuracy of the prediction of the naïve Bayes classifier that predicts the meaning of a received word . The routine understands if a listened word is a combination of light and temperature values , or only light , or only temperature . Routine highest _ conditional _ prob ( ) predicts the word based on the received bitstring when not in the same environment . It returns the label of the predicted class . B . Data structures An array is used to store the two vocabulary tables . Each array element is a C language struct with three elements . The two tables have elements to store word encoding , label , frequency and frequency of mismatch as shown in Fig . 2 . C . Sensor Interfacing The following three sensors are interfaced for a TTCA . Temperature Sensor MCP9808 : The sensor has pins VDD , GND , SCL , SDA , A2 , A1 , and A0 connected as follows : Fig . 2 . Vocabulary table structure VDD pin is connected 5V of PSoC 1 , SDA is connected to pin P1 [ 5 ] , and SCL is connected to pin P1 [ 7 ] . A2 , A1 , and A0 are connected to pin GND of PSoC 1 , so that an I2C slave address of 0x18 value is attained . Light Sensor TEMT6000 : The light sensor has pins SIG , GND and VCC connected as follows : pin GND is connected to ground , pin VCC is connected to 5V , and pin SIG to pin P0 [ 7 ] , which is internally configured as an analog input port that connects an input to a Programmable gain amplifier ( PGA ) of PSoC 1 . The PGA output is connected to one of the channels of a dual - channel ADC . Microphone : The speaker is connected to Pulse Width Modulator ( PWM ) output pin P1 [ 4 ] of PSoC 1 . D . Hardware resources Five hardware modules are part of a TTCA . Pulse Width Modulator ( PWM ) : The PWM provides compare outputs to generate single or continuous timing and control signals . It drives the speaker . PWM is placed in the DBC11 programmable digital block of PSoC 1 . The output of the PWM is routed to pin P1 [ 4 ] using the buses . PWM is configured for an output with a 50 % duty cycle signal at a clock frequency of VC3 = 1 . 4Khz , thus an audio signal is generated . Fig . 3 shows the PWM parameters . Programmable Gain Amplifiers ( PGA ) : PGA is mainly used to make multiple general - purpose input - output ( GPIO ) ports accessible to the ADC . Fig . 4 shows the PGA parameters . The used gain is 1 . Two PGAs are used in a TTCA , PGA1 is to interface the microphone , and PGA2 to connect the light sensor . Fig . 3 . PWM module parameters 2023 27th International Conference on System Theory , Control and Computing ( ICSTCC ) , Timisoara , Romania , October 11 - 13 , 2023 114 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 4 . PGA1 and PGA2 parameters Fig . 5 . ADC parameters Fig . 6 . I2C module parameters PGA1 takes inputs from port P0 [ 1 ] , and PGA2 from port P0 [ 4 ] . The PGA outputs are connected to a dual - channel ADC . PGA1 is placed in the programmable analog block ACC00 , and PGA2 in the programmable analog block ACC01 . Analog to Digital Converters ( ADC ) : TTCA uses a dual - channel ADC that connects to both microphone and light sensor to convert the continuous voltage signals to digital signals . Fig . 5 shows the ADC parameters . The dual - channel ADC is placed in the ASC10 and ASD11 programmable analog blocks of PSoC 1 with clock VC1 at 12MHz . It implements a 10 - bit ADC . I2C Module : The I2C module is configured as a master . Fig . 6 shows its parameters . Timer module and LCD : TTCA uses the LCD and a 16 - bit timer module to generate an interrupt every 100ms . It uses DCC12 and DCC13 programmable digital blocks . E . Timing , Memory and Performance Tradeoffs Table I lists the number of clock cycles and data bytes used by the routines of a TTCA . It uses a total of 7252 bytes in ROM ( 45 % of the PSoC 1 memory capacity ) and 188 bytes in RAM ( 25 % of the RAM memory of PSoC 1 ) . TABLE I . NUMBER OF CLOCK CYCLES AND NUMBER OF DATA BYTES USED BY THE ROUTINES Vocabulary size vs . precision : Improving the accuracy of the words requires that the vocabulary size is increased . Based on the computational complexity of the operation , one iteration ( consisting of sensing , word generation , table update , table reorder , speaking , and listening ) has a computation complexity of O ( n x log n ) . As the code executes sequentially , there can be a more significant delay in each operation . V . EXPERIMENTAL RESULTS Fig . 7 shows the generation of loud and silent stamps used to create verbal words corresponding to the associated bitstrings . The right part of Fig . 8 illustrates the verbal communication between two TTCAs operating in the same environment . One TTCA spoke the work DARK MED and the other TTCA listened and correctly understood it . The receiving TTCA was able to perceive correctly because they were in the same environment , hence naïve Bayesian classification worked well . In the left part of Fig . 8 , the sender TTCA extended the meaning of the verbal word for DARK MED , where it considered the temperature value of 8 in the medium category ( indicating a range change ) . But the receiver TTCA still used the same range to understand the received word . Hence , the range adjusting routine of the TTCA was triggered to correct the range . After correction , the TTCA adapted its vocabulary to reflect the change . We observed that when the parameters X ( word length ) , Y ( silent stamp length ) , Z values ( loud stamp length ) where decreased form their initial value of Z = Y = 2s and X = 16s Fig . 7 . Generated loud stamp and silent stamp 2023 27th International Conference on System Theory , Control and Computing ( ICSTCC ) , Timisoara , Romania , October 11 - 13 , 2023 115 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply . Fig . 8 . Incorrect detection with automated triggering of learning and correct detection to Z = Y = 200ms and X = 1 . 6s , even though the detection speed increased , the ADC output of the temperature sensor didn’t settle down early enough , so that the average ADC value sometime resulted in below the threshold of 0x200 . This resulted in TTCA detecting a silent stamp instead of loud stamp . This situation was not observed with parameters Z = Y = 2s and X = 16s . The maximum vocabulary size was 15 , but if this value needs to be increased then the table needs to clear less frequently words based on their frequency count ( parameter Q ) . Thus , parameter Q should be further reduced from value 60 . Otherwise , the less frequent words will unnecessarily consume more re - ordering time . VI . CONCLUSIONS AND FUTURE WORK This paper presents the PSoC 1 embedded system - based implementation of a novel cognitive architecture , called Talking Tiny Cognitive Architecture ( TTCA ) , for the study of language evolution in naturalistic conditions . TTCA can generate verbal words for new environmental situations and attempt to understand and learn the vocabulary of other TTCAs it communicates with . The meaning of words can change to reduce the size of the vocabulary by extending the meaning of an existing word to add new conditions or by merging two words for co - occurring situations . Future work should automatically select the TTCA operation mode without external intervention when they move to other environments . R EFERENCES [ 1 ] H . - H . Huang , T . Nishida , A . Cerekovic , I . Pandzic , and Y . Nakano , “The design of a generic framework for integrating ECA components” , Proc . International Joint Conference on Autonomous Agents and Multiagent Systems , 2008 , pp . 128 – 135 . [ 2 ] A . Doboli and S . Doboli , “A novel agent - based , evolutionary model for expressing the dynamics of creative open - problem solving in small groups” , Applied Intelligence , vol . 51 , pp . 2094 - 2127 , 2021 . [ 3 ] S . Nandasara , Y . Mikami , AIC . Mohideen , and K . G . D . Tharanie , “Automated Language Translation : Opportunities and Impact on the Society” , International Journal of Computer Applications , 178 , July , pp . 41 - 50 , 2009 . [ 4 ] E . Adamopoulou and L . Moussiades , “Chatbots : History , technology , and applications” , Machine Learning with Applications , vol . 2 , 2020 . [ 5 ] H . Wang , J . Li , H . Wu , E . Hovy , and Y . Sun , “Pre - Trained Language Models and Their Applications” , Engineering , 2022 , pp . 2095 - 8099 . [ 6 ] T . Kawahara , K . Inoue and D . Lala , “Intelligent Conversational Android ERICA Applied to Attentive Listening and Job Interview” , arXiv , cs . CL , 2021 . [ 7 ] P . Kenny et al , “Embodied Conversational Virtual Patients” , in D . Perez - Martin and I . Pascual - Nieto , “Conversational Agents and Natural Language Interaction : Techniques and Effective Practices” , Inform . Science Ref . , 2011 . [ 8 ] A . Chatzimparmpas , R . Markins , I . Jusufi , K . Kucher , F . Rossi , and A . Kerren , “The State of the Art in Enhancing Trust in Machine Learning Models with the Use of Visualizations” , Computer Graphics , Wiley , 39 ( 3 ) , pp . 713 - 756 , 2020 . [ 9 ] M . Novak and D . Krakauer , " The evolution of language " , PNAS , vol . 96 , 14 , pp . 8028 - 8033 , July 1999 . [ 10 ] M . Krieger , " Evolutionary dynamics of hyperbolic languages " , PLOS Computational Biology , vol . 19 , 2 , 2023 . [ 11 ] M . Dubova , " Building human - like communicative intelligence : A grounded perspective " , Cognitive Systems Research , vol . 72 , pp . 63 - 79 , 2022 . [ 12 ] L . Barsalou , " Perceptual symbol systems " , Behavioral and Brain Sciences , vol . 22 , 4 , pp . 577 – 660 , 1999 . [ 13 ] A . Doboli and E . Currie , Introduction to Mixed - Signal Embedded Design , Springer , 2010 , ISBN : 978 - 1 - 4419 - 7445 - 7 . [ 14 ] H . Li , F . Jiao , A . Doboli , and S . Doboli , " InnovA : A Cognitive Architecture for Computational Innovation through Robust Divergence and Its Application for Analog Circuit Design " , IEEE Transactions on CADICS , vol . 37 , 10 , pp . 1943 - 1956 , 2018 . [ 15 ] A . Umbarkar , V . Subramanian , and Alex Doboli , " Low - cost sound - based localization using programmable mixed - signal systems - on - chip " , Microelectronics Journal , vol . 42 , Issue 2 , pp . 382 - 395 , 2011 . [ 16 ] R . Yarden C . DSurage , C . Kim , A . Doboli , E . Voisan , and C . Purcaru , " TUKI : A voice - activated information browser " , IEEE Long Island Systems and Applications and Technology Confeence , 2009 , pp . 1 - 5 . [ 17 ] A . Doboli , P . Kane , and D . Van Ess , " Dynamic reconfiguration in a PSoC device " , Proc . International Conference on Field - Programmable Technology , 2009 , pp . 361 - 363 . [ 18 ] C . Ferent , A . Doboli , and Simona Doboli , " An axiomatic model for concept structure description and its application to circuit design " , Knowledge - Based Systems , vol . 45 , pp . 114 - 133 , 2013 . [ 19 ] A . Doboli , A . Umbarkar , S . Doboli , and Joseph Betz , " Modeling semantic knowledge structures for creative problem solving : Studies on expressing concepts , categories , associations , goals and context " , Knowledge - Based Systems , vol . 78 , pp . 34 - 50 , 2015 . [ 20 ] A . Doboli and D . Curiac , " Studying Consensus and Disagreement during problem solving in teams through Leraning and Response Generation Agents Model " , Mathematics , vol . 11 , 12 , 2602 , 2023 . 2023 27th International Conference on System Theory , Control and Computing ( ICSTCC ) , Timisoara , Romania , October 11 - 13 , 2023 116 Authorized licensed use limited to the terms of the applicable license agreement with IEEE . Restrictions apply .