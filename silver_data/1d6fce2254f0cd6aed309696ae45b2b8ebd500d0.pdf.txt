Auxiliary Variables in Mixture Modeling : 3 - Step Approaches Using Mplus Tihomir Asparouhov and Bengt Muth´en Mplus Web Notes : No . 15 Version 8 , August 5 , 2014 1 Abstract This paper discusses alternatives to single - step mixture modeling . A 3 - step method for latent class predictor variables is studied in several diﬀerent settings including latent class analysis , latent transition analysis , and growth mixture modeling . It is explored under violations of its assumptions such as with direct eﬀects from predictors to latent class indicators . The 3 - step method is also considered for distal variables . The Lanza et al . ( 2013 ) method for distal variables is studied under several conditions including violations of its assumptions . Standard errors are also developed for the Lanza method since these were not given in Lanza et al . ( 2013 ) . 2 1 Introduction In mixture modeling , indicator variables are used to identify an underlying latent categorical variable . In many practical applications we are interested in using the latent categorical variable for further analysis and exploring the relationship between that variable and other , auxiliary observed variables . Two types of analyses will be discussed here . The ﬁrst type of analysis is when we use the observed variable as a predictor of the latent categorical variable . The second type of analysis is using the latent categorical variable as a predictor of an observed variable which we call a distal outcome . The standard way to conduct such an analysis is to combine the latent class model and the latent class regression model or the distal outcome model into a joint model which can be estimated with the maximum - likelihood estimator . This will be referred to as the 1 - step method . Such an approach , however , can be ﬂawed because the secondary model may aﬀect the latent class formation and the latent class variable may lose its meaning as the latent variable measured by the indicator variables . Vermunt ( 2010 ) points out several disadvantages of the 1 - step method in the context of predictors ( covariates ) of the latent class variable : However , the one - step approach has certain disadvantages . The ﬁrst is that it may sometimes be impractical , especially when the number of potential covariates is large , as will typically be the case in a more exploratory study . Each time that a covariate is added or removed not only the prediction model but also the measurement model needs to be reestimated . A second disadvantage is that it introduces additional model building problems , such as whether one should decide about 3 the number of classes in a model with or without covariates . Third , the simultaneous approach does not ﬁt with the logic of most applied researchers , who view introducing covariates as a step that comes after the classiﬁcation model has been built . Fourth , it assumes that the classiﬁcation model is built in the same stage of a study as the model used to predict the class membership , which is not necessarily the case . It can even be that the researcher who constructs the typology using an LC model is not the same as the one who uses the typology in a next stage of the study . To avoid such drawbacks several methods have been developed that can independently evaluate the relationship between the latent class variable and the predictor or distal auxiliary variables . One method is to use the pseudo class method see Wang et al . ( 2005 ) , Clark and Muth´en ( 2009 ) , and Mplus Technical Appendices : Wald Test of Mean Equality for Potential Latent Class Predictors in Mixture Modeling ( 2010 ) . With this method the latent class model is estimated ﬁrst , then the latent class variable is multiply imputed from the posterior distribution obtained by the LCA model estimation . Finally the imputed class variables are analyzed together with the auxiliary variable using the multiple imputation technique developed in Rubin ( 1987 ) . We call this method the pseudo class ( PC ) method . The simulation studies in Clark and Muth´en ( 2009 ) , show that the PC method works well when the entropy is large , i . e . , the class separation is large . An alternative 3 - step approach has been developed in Vermunt ( 2010 ) , expanding ideas presented in Bolck et al . ( 2004 ) ; see also Bakk et al . ( 2013 ) . This approach is suitable for exploring relationships between the latent class variable 4 and predictor variables . In this approach the latent class model is estimated in a ﬁrst step using only latent class indicator variables . In the second step the most likely class variable is created using the latent class posterior distribution obtained during the ﬁrst step . In the third step the most likely class is regressed on predictor variables taking into account the misclassiﬁcation in the second step . Methods are also needed to study the relationship between the latent class variable and distal variables . In a recent paper , Lanza ( 2013 ) proposes one such method . Using Bayes theorem , the joint distribution of the latent class variable and the distal variable is represented as a regression of the latent class variable conditional on the distal variable , combined with the marginal distribution of the distal variable . 1 In this paper the 3 - step method for latent class predictor variables is studied in several diﬀerent settings including latent transition analysis and is explored under violations of its assumptions such as with direct eﬀects from predictors to latent class indicators . The 3 - step method is also considered for distal variables . The Lanza et al . ( 2013 ) method for distal variables is studied under several conditions including violations of its assumptions . Standard errors are also developed for the Lanza method since these were not given in Lanza et al . ( 2013 ) . Section 2 presents the Vermunt method for predictors of latent classes and carries out simulation studies of this method . Section 3 extends the method 1 All of the above methods are obtained in the Mplus program using the AUXILIARY option of the VARIABLE command . If an auxiliary variable is speciﬁed as ( R ) the PC method will be used and the variable will be treated as a latent class predictor . If an auxiliary variable is speciﬁed as ( E ) the PC method will be used and the variable will be treated as a distal outcome . If an auxiliary variable is speciﬁed as ( R3STEP ) the 3 - step method will be used and the variable will be treated as a latent class predictor . If an auxiliary variable is speciﬁed as ( DU3STEP ) the 3 - step method will be used and the variable will be treated as a distal variable with unequal means and variances . If an auxiliary variable is speciﬁed as ( DE3STEP ) the 3 - step method will be used and the variable will be treated as a distal variable with unequal means and equal variances . If an auxiliary variable is speciﬁed as ( DCON ) or ( DCAT ) , Lanza’s method for a continuous or categorical distal variable will be used . 5 to arbitrary secondary models . Section 4 presents 3 - step methods for latent transition analysis . Section 5 discusses direct eﬀect violations of the 3 - step method for predictor variables . Section 6 discusses methods for distal outcomes and carries out simulation studies of these methods . Section 7 presents studies of violations of the assumptions for the distal outcome methods . Section 8 concludes . All Appendices are available online at statmodel . com . 2 Predictors of latent classes Brieﬂy described , the 3 - step method for predictors of the latent class variable is as follows . The ﬁrst step is a regular latent class analysis ( LCA ) using only the latent class indicators . In the second step the most likely class variable N , a nominal variable , is created using the latent class posterior distribution obtained during the LCA estimation , i . e . , for each observation , N is set to be the class c for which P ( C = c | U ) is the largest , where U represents the latent class indicators and C is the latent class variable . 2 The classiﬁcation uncertainty rate for N is computed as follows p c 1 , c 2 = P ( C = c 2 | N = c 1 ) = 1 N c 1 (cid:88) N i = c 1 P ( C i = c 2 | U i ) where N c 1 is the number of observations classiﬁed in class c 1 by the most - likely class variable N , N i is the most likely class variable for the i - th observation , C i is the true latent class variable for the i - th observation and U i represents the class indicator variables for the i - th observation . The probability P ( C i = c 2 | U i ) is 2 In Mplus this variable is automatically created using the SAVEDATA command with the option SAVE = CPROB . 6 computed from the estimated LCA model . 3 For example in the case of a 3 - class model the probability p c 1 , c 2 would look like in the top part of Table 1 , where the p c 1 , c 2 is in row c 1 and column c 2 . We can then compute the probability q c 2 , c 1 = P ( N = c 1 | C = c 2 ) = p c 1 , c 2 N c 1 (cid:80) c p c , c 2 N c ( 1 ) where N c is the number of observations classiﬁed in class c by the most - likely class variable N . This shows that N can be treated as an imperfect measurement of C with measurement error deﬁned by q c 2 , c 1 . 4 These values are shown in the middle section of Table 1 . In the third step , the most likely class variable is used as latent class indicator variable with uncertainty rates preﬁxed at the probabilities q c 2 , c 1 obtained in step 2 . That is , the N variable is speciﬁed as a nominal indicator of the latent class variable C with logits log ( q c 2 , c 1 / q c 2 , K ) , where K is the last class . 5 These values are shown in the bottom section of Table 1 . In this way the measurement error in the most likely class variable N is taken into account in the third step . In this ﬁnal step we also include the auxiliary variable . Figure 1 illustrates the third step of the 3 - step method . The measurement relationships between the latent class variable C and the nominal most likely class variable N are ﬁxed according to the logit values in the bottom section of Table 1 , while the parameters of the 3 In Mplus the probability p c 1 , c 2 is automatically computed and can be found in the results section under the title ”Average Latent Class Probabilities for Most Likely Latent Class Membership ( Row ) by Latent Class ( Column ) ” . 4 These probabilities are also computed in Mplus and can be found in the results section under the title ”Classiﬁcation Probabilities for the Most Likely Latent Class Membership ( Column ) by Latent Class ( Row ) ” . 5 These logits are also computed in Mplus and can be found in the results section under the title ”Logits for the Classiﬁcation Probabilities the Most Likely Latent Class Membership ( Column ) by Latent Class ( Row ) ” . 7 multinomial regression of C on the predictor X are estimated . Appendix A shows the Mplus input for the third step and also the input for automatically performing all three steps using the R3STEP option . [ Table 1 about here . ] More details on this approach are available in Vermunt ( 2010 ) where it is referred as Modal ML . Here we will refer to this approach as the 3 - step method . In the Vermunt ( 2010 ) article this 3 - step method was used for latent class predictors . In this article we extend the method to distal outcomes , that is variables that are predicted by the latent class variable . [ Figure 1 about here . ] 2 . 1 Simulation study with a latent class predictor as an auxiliary variable In this simulation study we estimate a 2 - class model with 5 binary indicator variables . The distribution for each binary indicator variable U is determined by the usual logit relationship P ( U = 1 | C ) = 1 / ( 1 + Exp ( τ c ) ) where C is the latent class variable which takes values 1 or 2 and the threshold value τ c is the same for all 5 binary indicators . In addition we set τ 2 = − τ 1 for all ﬁve indicators . We choose three values for τ 1 to obtain diﬀerent level of class separation / entropy . Using the value of τ 1 = 1 . 25 we obtain an entropy of 0 . 7 , 8 with value τ 1 = 1 we obtain an entropy of 0 . 6 , and with value τ 1 = 0 . 75 we obtain an entropy of 0 . 5 . The latent class variable is generated with proportions 43 % and 57 % . In addition to the above latent class model we also generate a standard normal auxiliary variable as a predictor of the latent class variable through the multinomial logistic regression P ( C = 1 | X ) = 1 / ( 1 + Exp ( α + βX ) ) where α = 0 . 3 and β = 0 . 5 . 500 samples of size 500 and 2000 are generated . The data are analyzed using three diﬀerent methods : the PC method , the 3 - step method , and the 1 - step method . Table 2 contains the results of the simulation study for the regression coeﬃcient β . The 3 - step method outperforms the PC method substantially in terms of bias , mean squared error and conﬁdence interval coverage . The loss of eﬃciency of the 3 - step method when compared to the 1 - step method is minimal . The 3 - step method also provides good coverage in all cases . The eﬀect of sample size appears to be negligible within the sample size range used in the simulation study . Further simulation studies are needed to evaluate the performance for much smaller or much larger sample sizes . Appendix B contains an input ﬁle for conducting a simulation study with a latent class predictor auxiliary variable . [ Table 2 about here . ] 9 3 Using Mplus to conduct the 3 - step method with an arbitrary secondary model In many situations it would be of interest to use the 3 - step procedure to estimate a more advanced secondary model that includes a latent class variable . In Mplus , the 3 - step estimation of the distal outcome model and the latent class predictor model can be obtained automatically using the AUXILIARY option of the VARIABLE command as illustrated earlier . However , for more advanced models the 3 - step procedure has to be implemented manually , meaning that each of the 3 steps is performed separately . In this section we illustrate this manual 3 - step estimation procedure with a simple auxiliary model where the latent class variable is a moderator for a linear regression . The joint model , which combines the measurement and the auxiliary models , is visually presented in Figure 2 . [ Figure 2 about here . ] Suppose Y is a dependent variable and X is a predictor and suppose that a 3 - category latent class variable C is measured by 10 binary indicator variables . We want to estimate the secondary model independently of the latent class measurement model part . The secondary model is described as follows Y = α c + β c X + ε where both coeﬃcients α c and β c depend on the latent class variable C . The measurement part of the model is a standard LCA model described by P ( U p = 1 | C ) = 1 / ( 1 + Exp ( τ cp ) ) 10 for p = 1 , . . . , 10 and c = 1 , . . . , 3 . We generate a sample of size 1000 using equal classes and the following parameter values τ 1 p = − 1 , τ 2 p = 1 , τ 3 p = 1 for p = 1 , . . . , 5 , τ 3 p = − 1 for p = 6 , . . . , 10 . The parameters in the secondary model used for generating the data are as follows : X and ε are generated as standard normal and the linear model parameters are as follows α 1 = 0 , α 2 = 1 , α 3 = − 1 , β 1 = 0 . 5 , β 2 = − 0 . 5 , β 2 = 0 . Appendix C contains the input ﬁle for generating this data set . The ﬁrst step in the 3 - step estimation procedure is to estimate the measure - ment part of the joint model , i . e . , the latent class model . Thus in step 1 we estimate the LCA model with the 10 binary indicator variables and without the secondary model . The input ﬁle for this estimation is given in Appendix D along with an explanation of the commands . In step 2 of the estimation we have to determine the measurement error for the most likely class variable N . This measurement error will be used in the last step of the estimation . In the step 1 output ﬁle we ﬁnd the following 3x3 table titled : Logits for the Classiﬁcation Probabilities the Most Likely Latent Class Membership ( Column ) by Latent Class ( Row ) ; see the bottom part of Table 1 . This table contains log ( q c , i / q c , 3 ) , where the probabilities q c 2 , c 1 are computed using formula ( 1 ) . The ﬁnal third step in the 3 - step estimation procedure is estimating the desired auxiliary model where the latent class variable is measured by the most likely class variable N and the measurement error is ﬁxed and pre - speciﬁed to the values computed in Step 2 . The input ﬁle for our example is provided in Appendix E along with explanations of the commands . The estimates obtained in this ﬁnal stage are presented in Table 3 . These estimates are very close to the true 11 parameter values and we conclude that the 3 - step procedure works well for this example . This example also illustrates how Mplus can be used to estimate an arbitrary auxiliary model with a latent class variable in a 3 - step procedure where the measurement model for the latent class variable is estimated independently of the auxiliary model . [ Table 3 about here . ] 4 Estimating latent transition analysis using the 3 - step method In latent transition analysis ( LTA ) , several latent class variables are measured at diﬀerent time points and the relationship between these variables is estimated through a logistic regression . A 3 - step estimation procedure can be conducted for the LTA model where the latent class variables are estimated independently of each other and are formed purely based on the latent class indicators at the particular point in time . This estimation approach is desirable in the LTA context because the 1 - step approach has the drawback that an observed measurement at one point in time aﬀects the deﬁnition of the latent class variable at another point in time . We illustrate the estimation with two diﬀerent examples . The ﬁrst example is a simple LTA model with two latent class variables . The second example is an LTA model with covariates and measurement invariance . To achieve measurement invariance an additional step is required so we illustrate this separately . Note , however , that both examples can easily accommodate covariates . Thus to estimate an LTA model with covariates but without measurement invariance the ﬁrst 12 approach should be used because it is simpler . 4 . 1 Simple LTA For illustration purposes we consider an example with two latent class variables C 1 and C 2 each measured by 5 binary indicators . The coeﬃcient of interest , estimated in the 3 - step approach is the regression coeﬃcient of C 2 on C 1 . We include four input ﬁles in Appendices F , G , H , I to illustrate how the entire process is carried out in Mplus . The input ﬁle in Appendix F is used to generate data according to the true LTA model . The input ﬁle in Appendix G is used to estimate the LCA measurement model for the ﬁrst class variable C 1 and to obtain the most likely class variable N 1 which will be used in step 3 as a C 1 indicator . The measurement error for N 1 is computed using the log ratios as in Section 3 . The input ﬁle in Appendix H is used to estimate the LCA measurement model for the second class variable C 2 and to obtain the most likely class variable N 2 which will be used in step 3 as a C 2 indicator . The measurement error for N 2 is computed using the log ratios as in Section 3 . In real - data applications both Appendices F and G do not need a model statement . We provide model statements here simply to order the classes according to the way we generated the data . The ﬁnal third step is to estimate an LTA model where the variable N 1 is used as a class indicator variable for the ﬁrst latent variable with preﬁxed error rates and the variable N 2 is used as a class indicator variable for the second latent class variable with preﬁxed error rates . This input ﬁle is included in Appendix I . The 3 - step approach produces an estimate of 0 . 645 for the regression of C 2 on 13 C 1 with a standard error of 0 . 175 where the true value is 0 . 5 , i . e . , the estimate is close to the true value . Simulations studies are currently not easy to conduct in Mplus using the manual approach because the log ratios need to be computed for every replication . A small simulation study conducted manually using 10 replications revealed that the average estimate across the 10 replications is 0 . 486 , the coverage was 100 % and the ratio between the average standard errors and standard deviation is 1 . 18 . Thus we conclude that the 3 - step estimator performs well for the LTA model . The above approach can also be used for 3 - step LTA estimation with more than two latent class variables and also with covariates which will be used only in the third step . 4 . 2 LTA with covariates and measurement invariance In addition it is possible to estimate the LCA measurement model under the assumption of measurement invariance which implies that the threshold parameters are equal across time . The approach illustrated in Appendices F - I is inadequate and can not be used to estimate the 3 - step LCA with measurement invariance because the LCA at the diﬀerent time points are estimated in diﬀerent input ﬁles . It is possible however to estimate 3 - step LTA with measurement invariance and we illustrate that with Appendices J - N . We also illustrate in these Appendices how to include a covariate in the 3 - step LTA estimation . Appendix J contains the input ﬁle needed to generate the LTA data with a covariate . Appendix K contains the input ﬁle where the two LCA models at the two time points are estimated in parallel but independently of each other while holding all thresholds equal to obtain the LTA model with measurement 14 invariance . Even though we are interested in an auxiliary model estimation where C 2 is regressed on C 1 , at this point of the estimation we estimate the model without such a regression in line of the 3 - step methodology . The actual regression of C 2 on C 1 will be estimated in the last step of the 3 - step estimation . Thus in this step we estimate a model assuming that C 1 and C 2 are independent . Note that if the measurement invariance is removed from this model the estimation of C 1 and C 2 measurement models would be identical to the one from the previous section where C 1 and C 2 measurement models are estimated independently of each other and in two separate ﬁles . This is because without the measurement invariance the log - likelihood of the joint model will split in two independent parts that can be estimated separately . Appendix L contains the LCA estimation for the C 1 variable separately . With this input we obtain the most likely class variable N 1 and its measurement error . Appendix M contains the LCA estimation for the C 2 variable separately . With this input we obtain the most likely class variable N 2 and its measurement error . Note again that all the parameters in Appendices L and M are held equal to those parameters obtained in Appendix K . At this point , in step 2 , we manually calculate the log ratios from the error tables for N 1 and N 2 as we did in Section 3 . Appendix N contains the ﬁnal third step in this estimation where N 1 and N 2 are used as C 1 and C 2 indicators with parameters ﬁxed at the step 2 log ratios . This input now contains the auxiliary model which contains the regression of C 2 on C 1 as well as the regression of C 1 and C 2 on X . In this particular example the true value for C 1 on C 2 is 0 . 5 and the 3 - step estimate for that parameter is 0 . 63 ( 0 . 19 ) . The true value for C 2 on X is - 0 . 5 and the 3 - step estimate is - 0 . 58 ( 0 . 07 ) . The true value for C 2 on X is 0 . 3 and the 3 - 15 step estimate is 0 . 22 ( 0 . 08 ) . All parameters of the auxiliary model are covered by the conﬁdence intervals obtained by the 3 - step estimation procedure and thus we conclude that the 3 - step method works well for the LTA model with measurement invariance . 5 Simulation studies of omitted direct eﬀects from the latent class predictor auxiliary vari - able In this section we study the ability of the 3 - step method to absorb misspeciﬁcations in the measurement model due to omitted direct eﬀects from a covariate . Vermunt ( 2010 ) suggests that the 3 - step estimation might be a more robust estimation method in that context . We consider two diﬀerent situations : direct eﬀects in LCA and direct eﬀects in Growth Mixture Models ( GMM ) . 5 . 1 Direct eﬀects in LCA Data are generated with 10 binary indicators using the following equations P ( C = 1 | X ) = 1 / ( 1 + Exp ( α + βX ) ) P ( U p = 1 | C ) = 1 / ( 1 + Exp ( τ pc + γ pc X ) ) . The second equation above shows that there are direct eﬀects from X to the indicator variables . For data generation purposes almost all of the parameters γ pc are zero . To vary the magnitude of direct eﬀect inﬂuence we vary the number of 16 non - zero direct eﬀects . All non - zero direct eﬀects γ pc are set to 1 . We generate diﬀerent samples with L direct eﬀects for L = 1 , 2 , . . . , 5 . All non - zero direct eﬀects are in class one . To obtain diﬀerent entropy values we use τ pc = ± 1 . 25 which leads to entropy of 0 . 9 and τ pc = ± 0 . 75 which leads to entropy of 0 . 6 . The values of α and β are as in the previous section . We generate samples of size 2000 . The generated data are analyzed with 3 diﬀerent methods . Method 1 ignores the direct eﬀect in the LCA measurement model and analyzes the regression of C on X using the 3 - step procedure . Method 2 includes the direct eﬀect in the LCA measurement model and analyzes the regression of C on X using the 3 - step procedure . Method 3 is the 1 - step approach which includes the direct eﬀects and estimates the regression of C on X together with the measurement model in one joint model . Table 4 contains the bias and coverage simulation results for the regression parameter β . It is clear from these results that the ability of the 3 - step approach to estimate the correct relationship between C and X is somewhat limited . Method 1 which ignores the direct eﬀects and estimates the β coeﬃcient with the 3 - step approach performs quite poorly when the number of direct eﬀects is substantial but it has good performance when the number of direct eﬀects is small and the entropy is large . Using this method has the fundamental ﬂaw that the latent variable C can not be measured correctly if the covariate X is not included in the model . This is because there is a violation in the identiﬁcation condition for the latent class variable which postulates that the measurement indicators are independent given C . The indicator variables are actually correlated beyond the eﬀect of C through the direct eﬀects from X . Therefore , if there is a suﬃcient number of omitted direct eﬀects the latent class variable can not be measured 17 well only by the indicator variables . That in turn leads to substantial biases in the C on X regression using the 3 - step approach . More extensive discussion on the eﬀects of omitted direct eﬀects in the growth mixture context can be found in Muth´en ( 2004 ) . Method 2 which uses a properly speciﬁed measurement model that includes the direct eﬀects performs much better , however biases are found with this 3 - step method as well when the entropy is 0 . 6 . In contrast , the 3 - step procedure performed very well at that entropy level when direct eﬀects were not present . Method 2 can also suﬀer from incorrect classiﬁcation but to a much smaller extent than Method 1 . In this situation even with all direct eﬀects included the eﬀect of X on U is not captured completely because the measurement model does not include the eﬀect of X on C , which will have to be absorbed by the direct eﬀects . That may lead to misestimation of some of the parameters which in turn will lead to biases in the formation of the latent classes and biases in the auxiliary model estimation . 6 The use of Mplus to carry out this approach is illustrated in Appendix O . The 1 - step approach performs well in all cases . This ﬁnding indicates that the 3 - step approach has a limited ability to deal with direct eﬀects and thus when substantial direct eﬀects are found , those eﬀects should be included in the measurement model for the latent class variable even with the 3 - step approach . In the above simulation study the direct eﬀects are quite large and in many practical applications the direct eﬀect could be much smaller . Further exploration 6 To estimate Method 2 in Mplus the covariate X has to be used in the model as well as in the AUXILIARY option . In Mplus Version 7 this is not be allowed , although within a Montecarlo simulation it is allowed . To easily estimate Method 2 the covariate should be duplicated using the DEFINE command and the duplicate variable should be used in the model . 18 is necessary to evaluate the performance of the 3 - step methods for various levels of direct eﬀect . [ Table 4 about here . ] 5 . 2 Direct eﬀects in growth mixture models The impact of direct eﬀects on the 3 - step estimation can also be seen in the context of growth mixture models ( Muth´en & Shedden , 1999 ; Muth´en , 2004 ; Muth´en & Asparouhov , 2009 ) when the direct eﬀect is not on the observed variables but it is on the growth factors . Consider the following growth mixture model ( GMM ) . Y t = I + S · t + ε t where Y t are the observed variables and I and S are the growth factors which also identify the latent class variable C through the following model I | C = α 1 c + β 1 c X + ξ 1 S | C = α 2 c + β 2 c X + ξ 2 where X is an observed covariate . The above model simply postulates that the latent classes are determined by the pattern of growth trajectory , i . e . , the latent class variable determines the mean of the intercept and the slope growth factors , but individual variation is allowed . The above growth mixture model is essentially the measurement model for the latent class variable C . In this situation we are again interested in estimating with the 3 - step approach the relationship between 19 C and X independently of the measurement model , i . e . , we want to estimate the logistic regression model P ( C = 1 | X ) = 1 / ( 1 + Exp ( α + βX ) ) . We generated 100 samples of size 5000 using the following parameter values : α = 0 , β = 0 . 5 , V ar ( ε t ) = 1 , V ar ( I ) = 1 , V ar ( S ) = 0 . 4 , Cov ( I , S ) = 0 . 2 , α 21 = 1 , α 22 = − 0 . 5 , and t = 0 , 1 , . . . , 4 . We also vary the values of α 1 c to obtain diﬀerent entropy levels . Choosing α 11 = 1 , α 12 = − 1 yields entropy of 0 . 6 . Choosing α 11 = 2 , α 12 = − 2 yields entropy of 0 . 85 . Choosing α 11 = 3 , α 12 = − 3 yields entropy of 0 . 95 . We also want to explore diﬀerent types of direct eﬀects so we generate three diﬀerent types of data . Type 1 uses no direct eﬀects , i . e . , β 1 c = β 2 c = 0 . Type 2 uses the same direct eﬀects across the two classes β 1 c = 1 and β 2 c = 0 . 2 , i . e . , the direct eﬀect is independent of the latent class variable . Type 3 uses diﬀerent direct eﬀects across the two classes β 11 = 1 , β 21 = 0 . 2 and β 12 = β 22 = 0 . As in the LCA simulation study we use diﬀerent estimation methods . Method 1 is a 3 - step method that uses only the growth model as the measurement model , Method 2 use the growth model as the measurement model but includes the direct eﬀects from X to the growth factors . Method 3 is the 1 - step approach using the direct eﬀects and the regression from C on X . The results for the β estimates are presented in Table 5 . Again we see here that Method 1 works well but only if there are no direct eﬀects from X to the measurement model ( Type 1 data ) . The biases for Type 2 and 3 decrease substantially when the the entropy increases but these biases are too high even with entropy of 0 . 85 . Method 2 performed much better than Method 1 , thus 20 including covariates in the measurement model is important here as well , however , the biases are unacceptable when the entropy is 0 . 6 . Method 2 seems to perform better for Type 2 data where the direct eﬀects are independent of C , even though the direct eﬀects are bigger . Method 3 as expected performed well . This method uses the ML estimator for the correctly speciﬁed model . The identiﬁcation of the latent class variable is more complicated in the GMM model than in the LCA model . The local independence assumption of the LCA model is not present in the GMM model . Nevertheless we see the same pattern , if the covariates have direct eﬀects on the measurement model , these eﬀects should be included for the 3 - step approach to work well . More simulation studies are needed to evaluate the impact of the size of the direct eﬀects on the 3 - step estimation . [ Table 5 about here . ] 6 Distal outcome auxiliary variable Turning to the case of a distal outcome , two approaches are studied : the 3 - step method applied to distal outcomes and Lanza’s method . The 3 - step method for a distal outcome uses the approach of Section 3 . For example , Figure 3 without the X variable is exactly the situation considered here . 7 7 In Mplus this can be analyzed using the ”manual” method shown in Section 3 or all 3 steps carried out automatically using either of two auxiliary options . If an auxiliary variable is speciﬁed as ( DU3STEP ) the 3 - step method will be used and the variable will be treated as a distal outcome with unequal means and variances . If an auxiliary variable is speciﬁed as ( DE3STEP ) the 3 - step method will be used and the variable will be treated as a distal outcome with unequal means and equal variances . The equal variance estimation is useful for situations when there are small classes and the distal outcome estimation with unequal variance may have convergence problems due to near zero variance within class . For example , if the distal outcome 21 A new method for the estimation of auxiliary distal outcomes has been proposed in Lanza et al . ( 2013 ) . This method has the advantage over the 3 - step method that it does not allow for the distal outcome to dramatically change the class membership for individual observations . The method can be used with a categorical or a continuous distal outcome . The idea behind the method is that after the LCA model is estimated we can estimate an auxiliary model where the distal outcome X is used as a latent class predictor within a multinomial logistic regression in addition to the the original measurement LCA model . The auxiliary model is used to obtain the conditional distribution P ( C | X ) as well as the marginal distribution P ( C ) . Using also the sample distribution of X one can easily derive the desired conditional distribution P ( X | C ) by applying the Bayes’ theorem P ( X | C ) = P ( X ) P ( C | X ) P ( C ) . ( 2 ) If X is a continuous variable the mean parameters can then be estimated within each class and if it is a categorical variable the probabilities for each category can be estimated within each class . Lanza’s method has a number of limitations . The method can only be used with distal auxiliary variables . In addition the method can not have a latent class measurement model that already includes latent class predictors . The original article by Lanza et al . ( 2013 ) does not include standard error computations . While such standard errors are easy to obtain if the auxiliary variable is categorical using the delta method in ( 2 ) , in the continuous case it is not very clear how to compute is binary this can occur quite easily . However the equal variance option should not be used in general because it may lead to biases in the estimates and the standard error if the equal variance assumption is violated . 22 the standard errors because P ( X ) is the sample distribution . As implemented in Mplus , Lanza’s method uses approximate standard errors for continuous distal outcomes by estimating the mean and variance within each group as well as the within class sample size . Standard errors are then computed as if the mean estimate is the sample mean . For both continuous and categorical distal outcomes Mplus computes an overall test of association using Wald’s test as well as pairwise class comparisons between the auxiliary variable means and probabilities . There is a slight diﬀerence between the continuous distal outcome estimation described in Lanza et al . ( 2013 ) and the method implemented in Mplus . Lanza’s method uses kernel density estimation to approximate the density function for the distal outcome while the method implemented in Mplus uses the sample distribution for the auxiliary variable directly . The two methods , however , should yield similar results . 8 6 . 1 Simulation study with a continuous distal auxiliary outcome : Comparing the 3 - step and Lanza methods In this simulation study we estimate a 2 - class model with 5 binary indicator variables . The distribution for each binary indicator variable U is determined by the usual logit relationship P ( U = 1 | C ) = 1 / ( 1 + Exp ( τ c ) ) 8 If an auxiliary variable is speciﬁed as ( DCON ) Lanza et al . ( 2013 ) method will be used and the variable will be treated as a distal continuous outcome . If an auxiliary variable is speciﬁed as ( DCAT ) Lanza et al . ( 2013 ) method will be used and the variable will be treated as a distal categorical outcome . 23 where C is the latent class variable which takes values 1 or 2 and the threshold value τ c is the same for all 5 binary indicators . In addition we set τ 2 = − τ 1 for all ﬁve indicators . We choose three values for τ 1 to obtain diﬀerent level of class separation / entropy . Using the value of τ 1 = 1 . 25 we obtain an entropy of 0 . 7 , with value τ 1 = 1 we obtain an entropy of 0 . 6 , and with value τ 1 = 0 . 75 we obtain an entropy of 0 . 5 . The latent class variable is generated with proportions 43 % and 57 % . In addition to the above latent class model we also generate a normally distributed distal auxiliary variable with mean 0 in class one and mean 0 . 7 in class 2 and variance 1 in both classes . We apply the PC method , the 3 - step method , Lanza’s method , and the 1 - step method to estimate the mean of the auxiliary variable in the two classes . Table 6 presents the results for the mean of the auxiliary variable in class 2 . We generate 500 samples of size 500 and 2000 and analyze the data with the four methods . It is clear from the results in Table 6 that the 3 - step procedure outperforms the PC procedure substantially in terms of bias , mean squared error and conﬁdence interval coverage . When the 3 - step procedure is compared to the 1 - step procedure it appears that the loss of eﬃciency is not substantial especially when the class separation is good ( entropy of 0 . 6 or higher ) . The loss of eﬃciency can be seen however in the case when the entropy is 0 . 5 and the sample size is 500 . The 3 - step procedure also provides good conﬁdence interval coverage . Lanza’s method appears to be slightly better than the 3 - step method in terms of bias and MSE , but in terms of coverage the 3 - step method appears to be better . The eﬀect of the sample size appears to be negligible in the sample size range 500 - 2000 . Further simulation studies are needed to evaluate the performance of the 3 - step procedure and Lanza’s method for much smaller or much larger sample 24 sizes . Appendix P contains an input ﬁle for conducting a simulation study with a distal auxiliary variable . [ Table 6 about here . ] Next we conduct a simulation study to compare the performance of the two diﬀerent 3 - step approaches . The two approaches diﬀer in the third step . The ﬁrst approach estimates diﬀerent means and variance for the distal variable in the diﬀerent classes while the second approach estimates diﬀerent means but equal variances . The second approach is more robust and more likely to converge but may suﬀer from the mis - speciﬁcation that the variances are equal in the diﬀerent classes . We use the same simulation as above except that we generate a distal outcome in the second class with variance 20 instead of 1 . The results for the mean in the second class are presented in Table 7 . It is clear from these results that the unequal variance 3 - step approach is superior particularly when the class separation is poor ( entropy level of 0 . 6 or less ) . The equal variance approach can lead to severely biased estimates when the class separation is poor and the variances are diﬀerent across classes . The results obtained in this simulation study may not apply if the ratio between the variances is much smaller . Further simulation studies are needed to determine exactly what level of discrepancy between the variances leads to accuracy advantage for the unequal variance 3 - step approach . [ Table 7 about here . ] 25 6 . 2 Simulation study with distal categorical outcome us - ing Lanza’s method In this section we conduct a simulation study to evaluate the performance of Lanza’s method with categorical auxiliary outcome . We generate data from a 3 - class LCA model where the latent class variable is measured by 10 binary variables . In class 1 , P ( U i = 0 | C = 1 ) = 1 / ( 1 + Exp ( τ ) ) for all indicator variables U i . In class 3 , P ( U i = 0 | C = 3 ) = 1 / ( 1 + Exp ( − τ ) ) for all indicator variables U i . In class 2 , P ( U i = 0 | C = 2 ) = 1 / ( 1 + Exp ( τ ) ) for i = 1 , . . . , 5 and P ( U i = 0 | C = 2 ) = 1 / ( 1 + Exp ( − τ ) ) for i = 6 , . . . , 10 . We use two τ values in the generation process . If τ = 0 . 75 the entropy for the LCA model is I = 0 . 5 and if τ = 1 the entropy for the LCA model is 0 . 65 . The class probabilities P ( C = j ) for the 3 - classes are 0 . 32 , 0 . 44 , 0 . 24 respectively . The auxiliary variable X is a categorical variable with 6 categories . The probabilities P ( X = k | C = 1 ) of these 6 categories in class one are : 0 . 18 , 0 . 09 , 0 . 23 , 0 . 23 , 0 . 09 , 0 . 18 . In class 2 these probabilities are 0 . 08 , 0 . 65 , 0 . 05 , 0 . 03 , 0 . 11 , 0 . 08 . In class 3 these probabilities are 0 . 07 , 0 . 11 , 0 . 32 , 0 . 23 , 0 . 09 , 0 . 18 . We generate 100 samples of size N = 200 , N = 500 , and N = 2000 using both entropy levels and analyze the X variable as an auxiliary variable . The results of the simulation are presented in Table 8 . We present the bias and the coverage for category 2 in the 3 diﬀerent classes p 2 j = P ( X = 2 | C = j ) . The results for the remaining categories are similar . The simulation shows that the estimates are unbiased and the coverage is near the nominal level of 95 % . Some small sample size bias can be seen here when N = 200 in particular when the entropy is low I = 0 . 5 . These biases are , however , mostly due to the quality of the estimation of the measurement model which also has estimation biases when 26 the sample and the entropy are small . Overall we conclude that Lanza’s method as well as the standard error method based on the delta method implemented in Mplus works well . Note here that in the categorical distal outcome case Lanza’s method does not rely on the multinomial model assumption . In this case , the multinomial model together with the marginal distribution model for the auxiliary variable yield a saturated bivariate model for the two categorical variables . The estimated joint distribution model for the latent class and the distal outcome variables is the full contingency unrestricted model . Thus there are no underlying assumptions in this case as is the case in the continuous distal outcome situation . [ Table 8 about here . ] 7 Distal outcome estimation failures In this section we discuss diﬀerent situations where the distal outcome estimation methods fail . In Section 7 . 1 we present a simulated example where the 1 - step and the 3 - step methods fail due to change in the latent class variable when the auxiliary variable is added to the latent class measurement model . In Section 7 . 2 we present a simulated example where Lanza’s method fails due to an incorrect multinomial model assumption . 7 . 1 Failure due to change in the latent class variable In this section we describe a distal outcome simulated example that illustrates the potential failure when using the 1 - step and the 3 - step methods . In this example Lanza et al . ( 2013 ) does not fail . This shows that Lanza et al . ( 2013 ) method may be more robust in practical situations . 27 We generate a data set of size N = 5000 according to a two class LCA model with 5 binary indicators U i , i = 1 , . . 5 using P ( U i | C = 1 ) = 0 . 73 and P ( U i | C = 2 ) = 0 . 27 . The two latent classes are equally likely P ( C = j ) = 0 . 5 , for j = 1 , 2 . To that data set we add a continuous variable X which has a bimodal distribution 0 . 75 · N ( 0 , 0 . 01 ) + 0 . 25 · N ( 1 , 0 . 01 ) , i . e . , the bimodal distribution is a mixture of two normal distributions with means 0 and 1 and variance 0 . 01 and with weights 0 . 75 and 0 . 25 . The continuous variable X is generated as an independent variable . The variable is independent of the class indicators U i as well as the latent class variable C . Thus if we analyze the variable X as an auxiliary distal outcome variable we expect to see no signiﬁcant eﬀect from C to X , i . e . , if m j = E ( X | C = j ) is the class speciﬁc mean of X we expect the mean diﬀerence parameter m = m 2 − m 1 to be statistically insigniﬁcant from 0 . In addition we expect the latent class proportions P ( C = 1 ) / P ( C = 2 ) to be near 1 . [ Table 9 about here . ] The results of this analysis are presented in Table 9 . We analyze the simulated data with the four diﬀerent methods available in Mplus , 1 - step , 3 - step with unequal variances , the pseudo class method , and the Lanza et al . ( 2013 ) method . In addition we analyze model with the 3 - step manual procedure described in Section 3 . Both the 1 - step procedure and the 3 - step manual procedures failed . The class allocation changed from equal classes to a ratio of 3 , which corresponds to the bimodal distribution weights suggesting that the latent class variable has changed its meaning and is now used to ﬁt the bimodal distribution of the auxiliary variable and the original measurement model is ignored . This happens because the methods use the maximum - likelihood estimation . Ultimately the log - likelihood 28 will be maximized and in this particular example the log - likelihood beneﬁts more by ﬁtting the distal outcome variable rather than the measurement model . Most importantly , the 1 - step and the 3 - step manual procedures failed in the distal outcome estimation . Both method ﬁnd large and statistically signiﬁcant eﬀect from the latent class variable on the auxiliary distal outcome where such an eﬀect does not exist , according to how the data were generated . This eﬀect was found because the latent class variable meaning changed . Interestingly , the Mplus automated 3 - step procedure did not fail . The diﬀerence between the automated and the manual procedure is in the starting values . The manual procedure will use a number of random starting values , by default Mplus will use 20 , to guarantee that the global maximum is found . On the other hand the automated procedure will not use random starting values and instead will use as starting values only the parameters obtained in the ﬁrst step estimation when the latent class measurement model is estimated separately without the auxiliary variable . Using such starting values it is very likely that a local optimum will be reached that preserves the meaning of the latent class variable from the ﬁrst step if such a local optimum exists . If that local optimum is also a global optimum the manual 3 - step procedure and the automated 3 - step procedure will yield the same result , however , if the local optimum is not a global optimum the two procedures will yield diﬀerent results . In our simulated data set the local optimum is not a global optimum . The log - likelihood obtained with the manual 3 - step procedure is − 770 . 197 and it is much better than local optimum obtained with the automated procedure − 1300 . 201 . There are two issues that we need to address related to local and global optima . First one may ask if it is a good statistical practice to use the local optimum 29 instead of the global optimum . Obviously in this particular example it makes sense , because , the local optimum yields unbiased estimates for the distal outcome model while the global optimum does not . The fact is that it is also a theoretically solid approach . Using a local optimum instead of a global optimum usually is equivalent to adding parameter constraints to the model . In our example we could have added to the model estimation the constraint that the two classes probabilities are between 45 % and 55 % . Given that the LCA class without the auxiliary variable yields almost equal two classes such a parameter constraints seems reasonable . If the parameter constraints are added then the global optimum is unacceptable and the local optimum becomes the global optimum and therefore an acceptable solution . In fact what we obtained in this example as the global optimum is not really the global optimum . Given that the variance of the distal outcome is unconstrained a class allocation where one of the classes has a single observation and a variance of 0 has a likelihood of inﬁnity , i . e . , the log - likelihood doesn’t have a global maximum in a completely unconstrained sense . The second issue we have to address is the fact that a local optimum corresponding to the original latent class model might not exist . This actually is very likely to happen , when the number of classes is large and larger than what is supported by the data , i . e . , when the classes are poorly identiﬁed and the entropy of the step one latent class model is low , and thus the nominal indicator S is a weak class indicator . In that case the 3 - step method simply fails . 9 9 A simple check is implemented in Mplus to verify that this failure does not occur and if it does the method will not report any results because those results are likely to be incorrect similar to the results reported in Table 9 . This consistency check is computed as follows . Each observation is classiﬁed into the most likely class using both the ﬁrst step model and the third step model . If more than 20 % of the observations in step 1 class move to a diﬀerent class in step 3 then the 3 - step estimation is determined to be inconsistent and no results are reported . Because this check is already implemented in Mplus Version 7 . 1 it is safe to use the automatic 30 The Table 9 results also show that the PC method and the Lanza method are more robust estimation methods than the 1 - step and the 3 - step methods . Because these methods do not include new dependent variables in the ﬁnal model estimation , they are less likely to alter the meaning of the latent class variable . Both methods yield the correct result that the eﬀect of the latent class on the auxiliary variable is not statistically signiﬁcant . 7 . 2 Failure due to incorrect multinomial model assump - tions Lanza’s method is based on the underlying assumption that we can estimate the joint distribution of the latent class variable and the auxiliary variable through estimating a multinomial regression model where the latent class variable is regressed on the auxiliary variable . This multinomial model , however , may not hold . In that case , the estimated class speciﬁc means for the auxiliary distal variable might be biased . Note that in the simulation studies in Section 6 . 1 the multinomial model does not hold . Nevertheless we obtained unbiased results . Apparently , the multinomial model is quite robust in recovering the class speciﬁc means for the distal outcome . The multinomial model with K classes has 2 K − 2 model parameters and those are estimated to ﬁt as well as possible to the conditional probabilities P ( C | X ) . Ultimately however , the best multinomial model is estimated to ﬁt the data well and since the conditional mean E ( X | C ) is essentially a ﬁrst order sample statistic we can generally expect that this statistic will be ﬁtted well by the model . This is exactly what the simulations 3 - Step procedure without investigating further the class formation . 31 in Section 6 . 1 illustrate . Even when the multinomial model is not correct the basic sample statistics may be ﬁtted well . Other simulations , not reported here , also conﬁrmed that . For example , generating data from a model where log ( X ) is the true predictor in the multinomial regression rather than X , which is clearly a multinomial model misspeciﬁcation , did not yield bias in the the conditional mean estimates E ( X | C ) . This , however , may not always happen . Consider the following example . We generate data as in the previous section with the exception that the mean of the auxiliary variable is 0 in class 1 and 1 in class 2 , i . e . , the mean of the auxiliary variable changes over classes , which was not the case in the simulation we used in the previous section . Here there is a positive association between the auxiliary variable and the latent class variable . We generate a sample of size N = 1000 . To make sure that any diﬀerence between the methods is not due to the LCA measurement model we adopt a perfect measurement model , i . e . , a model where the latent class variable is measured exactly by one binary indicator . Thus the latent class variable is perfectly measured , i . e . , is observed . In that case we would expect the auxiliary model estimates to be the same as the class speciﬁc sample means for the auxiliary variable which can be explicitly computed now because the latent class variable is observed . In this situation , when the latent class variable is observed , both the 3 - step method and the PC method will always yield the correct results , regardless of how the data set is generated , i . e . , the estimated class speciﬁc means will be the same as the class speciﬁc sample means for the auxiliary variable . This , however , is not true for Lanza’s method which will need to estimate a potentially incorrect multinomial model . When estimating the auxiliary model with our generated data 32 set all three methods , namely , the 3 - step method , the PC method and Lanza’s method yield correct results . This again illustrates that Lanza’s method is fairly robust and can perform well even when the multinomial model does not hold . Next we introduce an outlier in the data set . We add one observation in class 1 with an auxiliary value of 100 . When estimating the auxiliary model with the three methods , the 3 - step method and the PC method yield the correct result , while Lanza’s method does not . In class 1 the sample mean for the auxiliary variable , the 3 - step estimate and the PC estimate are all 1 . 240 . Lanza’s method estimate is 1 . 433 . The problem with Lanza’s method in this example is the fact that the multinomial model does not ﬁt the conditional distribution P ( C | X ) well . This multinomial logit assumption yields biased results for the distal outcome class - speciﬁc means . 7 . 3 Summary In this section we summarize the potential failures of the various distal outcome estimation methods . First , if the measurement model has low entropy that means that the latent class variable is poorly measured and in that case all methods can be expected to fail . The second possible failure is the case when the entropy is relatively high but the latent class variable changes when the auxiliary variable is included in the analysis . In this situation the 1 - step and the 3 - step methods can fail while Lanza’s method and the PC method are more robust . The third possible failure is speciﬁc to Lanza’s method . If the multinomial model is substantially violated , Lanza’s method estimates may be biased . Fortunately this appears to be relatively rare . The 1 - step and the 3 - step methods also have distributional 33 assumptions for the distal outcome . Within each class the distribution of the auxiliary variable is assumed to be normal . If this assumption is violated the latent class may change . This was the case in the example described in Section 7 . 1 . To the above list of possible failures we also need to add the fact that the PC method will tend to be biased unless the entropy is high . 8 Conclusions The new 3 - step approach uniformly outperforms the pseudo - class approach for analyzing the relationship between a latent class variable and an auxiliary variable . If the class separation is good the 3 - step approach has the same eﬃciency as the 1 - step approach . Our simulations seem to indicate that an entropy level of 0 . 6 or higher provides suﬃciently good class separation and in that case we can expect the 3 - step approach to work as eﬃciently as the 1 - step approach . In principle the 1 - step approach can be used in practical applications as well . However , if the latent classiﬁcation changes dramatically when the auxiliary variables are included in the model a detailed analysis should be conducted to determine the cause of the classiﬁcation shift . We illustrated also that if the auxiliary variables are dependent variables as in the case of the distal outcome , both the 1 - step and the 3 - step approach can fail due to the change in the formation of the latent classes . In the case of the distal outcome auxiliary model , Lanza’s method provides a good alternative to the 1 - step and the 3 - step approaches because it will preserve the latent class variable . In the Mplus implementation of the 3 - step methods , multiple predictor variables can be used for the latent class variable and the estimated multinomial 34 model in the third step will include all of the predictor variables . Multiple distal auxiliary variables can also be used , however the distal outcome models are estimated one at a time . The Mplus automatic implementation for the auxiliary variables is limited to the distal outcome model and the latent class predictor model . Other models may be of interest as well , such as for example a distal outcome model where the distal outcome is regressed on the latent class variable and other observed variables . For such models , it is easy to manually set up all the steps of the 3 - step estimation method following the description provided here . The 3 - step procedure can be used with an arbitrary auxiliary model . The examples we presented in this paper used an LCA model as a measurement model for the latent class variable . The Mplus implementation however is very ﬂexible and can use any other latent class model as the measurement model including for example growth mixture models and any type of dependent variables . Lanza’s method as implemented in Mplus can accommodate continuous and categorical distal outcomes , however , it is more limited in terms of the scope of models it can accommodate . The latent class measurement model can be an arbitrary measurement model but the model can not include latent class predictors . Also , Lanza’s method can not be used with an arbitrary auxiliary model . It is important to note , however , that the underlying assumption of Lanza’s method , namely , that the auxiliary model can be estimated indirectly by assuming a multinomial regression model between the latent class variable and the auxiliary variable does not appear to have substantial drawbacks . That is , even when the multinomial regression model does not hold , in most situations Lanza’s method still yields unbiased estimates . 35 9 Acknowledgement We thank Zsuzsa Bakk and Margot Bennink for uncovering an error in an earlier version of this paper . 36 References [ 1 ] Bakk , Z . , Tekle , F . B . , & Vermunt , J . K . ( 2013 ) . Estimating the association betwen latent class membership and external variables using bias adjusted three - step approaches . In T . F . Liao ( ed . ) , Sociological Methodology . Thousand Oake , CA : SAGE publications . [ 2 ] Bolck , A . , Croon M . A . , & Hagenaars , J . A . ( 2004 ) Estimating latent structure models with categorical variables : One - step versus three - step estimators . Political Analysis , 12 , 3 - 27 . [ 3 ] Clark , S . & Muth´en , B . ( 2009 ) . Relating latent class analysis results to variables not included in the analysis . https : / / www . statmodel . com / download / relatinglca . pdf [ 4 ] Lanza S . T . , Tan X . , & Bray B . C . ( 2013 ) . Latent Class Analysis With Distal Outcomes : A Flexible Model - Based Approach . Structural Equation Modeling , 20 , 1 - 26 . [ 5 ] Mplus Technical Appendices : Wald Test of Mean Equality for Potential Latent Class Predictors in Mixture Modeling ( 2010 ) http : / / www . statmodel . com / download / meantest2 . pdf [ 6 ] Muth´en , B . ( 2004 ) . Latent variable analysis : Growth mixture modeling and related techniques for longitudinal data . In D . Kaplan ( ed . ) , Handbook of quantitative methodology for the social sciences ( pp . 345 - 368 ) . Newbury Park , CA : Sage Publications . 37 [ 7 ] Muth´en , B . & Shedden , K . ( 1999 ) . Finite mixture modeling with mixture outcomes using the EM algorithm . Biometrics , 55 , 463 - 469 . [ 8 ] Muth´en , B . & Asparouhov , T . ( 2009 ) . Growth mixture modeling : Analysis with non - Gaussian random eﬀects . In Fitzmaurice , G . , Davidian , M . , Verbeke , G . & Molenberghs , G . ( eds . ) , Longitudinal Data Analysis , pp . 143 - 165 . Boca Raton : Chapman & Hall / CRC Press . [ 9 ] Rubin , D . B . ( 1987 ) Multiple Imputation for Nonresponse in Surveys . New York , J . Wiley & Sons . [ 10 ] Vermunt , J . K . ( 2010 ) Latent Class Modeling with Covariates : Two Improved Three - Step Approaches . Political Analysis , 18 , 450 - 469 . [ 11 ] Wang C - P , Brown CH , Bandeen - Roche K ( 2005 ) . Residual Diagnostics for Growth Mixture Models : Examining the Impact of a Preventive Intervention on Multiple Trajectories of Aggressive Behavior . Journal of the American Statistical Association , 100 , 1054 - 1076 . 38 List of Figures 1 3 - step with regression on a predictor . . . . . . . . . . . . . . . . 40 2 Linear regression auxiliary model . . . . . . . . . . . . . . . . . . 41 39 Figure 1 : 3 - step with regression on a predictor (cid:2) (cid:3) (cid:4) (cid:5)(cid:6)(cid:3)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:4)(cid:11)(cid:12)(cid:8)(cid:6)(cid:2)(cid:13)(cid:9)(cid:14)(cid:11)(cid:9)(cid:15)(cid:6)(cid:16)(cid:17)(cid:4)(cid:18)(cid:10)(cid:16)(cid:16)(cid:6)(cid:5)(cid:6)(cid:4)(cid:10)(cid:14)(cid:6)(cid:11)(cid:2) (cid:7)(cid:16)(cid:14)(cid:6)(cid:15)(cid:10)(cid:14)(cid:7)(cid:8) 40 Figure 2 : Linear regression auxiliary model (cid:2) (cid:3) (cid:4) 41 List of Tables 1 Latent class probabilities , classiﬁcation probabilities , and logits for classiﬁcation probabilities . . . . . . . . . . . . . . . . . . . . . . 43 2 Latent class predictor simulation study : Bias / Mean Squared Error / Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3 Final estimates from the manual 3 - step estimation with linear regression auxiliary model . . . . . . . . . . . . . . . . . . . . . . . 45 4 LCA with direct eﬀects : absolute bias and coverage . . . . . . . . 46 5 GMM with direct eﬀects : absolute bias and coverage . . . . . . . 47 6 Distal outcome simulation study : Bias / Mean Squared Error / Coverage 48 7 Distal outcome simulation study . Comparing equal and unequal variance 3 - step methods : Bias / Mean Squared Error / Coverage . . 49 8 Categorical distal outcome simulation study using Lanza’s method : Absolute Bias ( Coverage ) . . . . . . . . . . . . . . . . . . . . . . . 50 9 Distal outcome simulated example . . . . . . . . . . . . . . . . . . 51 42 Table 1 : Latent class probabilities , classiﬁcation probabilities , and logits for classiﬁcation probabilities Average Latent Class Probabilities for Most Likely Latent Class Membership ( Row ) by Latent Class ( Column ) 1 2 3 1 0 . 839 0 . 066 0 . 095 2 0 . 053 0 . 845 0 . 102 3 0 . 125 0 . 107 0 . 768 Classiﬁcation Probabilities for the Most Likely Latent Class Membership ( Column ) by Latent Class ( Row ) 1 2 3 1 0 . 830 0 . 046 0 . 124 2 0 . 072 0 . 811 0 . 177 3 0 . 099 0 . 094 0 . 807 Logits for the Classiﬁcation Probabilities for Most Likely Latent Class Membership ( Column ) by Latent Class ( Row ) 1 2 3 1 1 . 901 - 0 . 990 0 . 000 2 - 0 . 486 1 . 936 0 . 000 3 - 2 . 100 - 2 . 147 0 . 000 43 Table 2 : Latent class predictor simulation study : Bias / Mean Squared Error / Coverage N Entropy PC 3 - step 1 - step 500 0 . 7 . 13 / . 023 / . 84 . 01 / . 015 / . 95 . 01 / . 014 / . 95 500 0 . 6 . 20 / . 044 / . 59 . 00 / . 019 / . 96 . 01 / . 017 / . 96 500 0 . 5 . 28 / . 083 / . 24 . 02 / . 029 / . 95 . 03 / . 028 / . 97 2000 0 . 7 . 13 / . 019 / . 24 . 00 / . 004 / . 93 . 00 / . 004 / . 94 2000 0 . 6 . 20 / . 042 / . 01 . 00 / . 004 / . 95 . 00 / . 004 / . 94 2000 0 . 5 . 29 / . 085 / . 00 . 01 / . 007 / . 94 . 01 / . 006 / . 95 44 Table 3 : Final estimates from the manual 3 - step estimation with linear regression auxiliary model . Parameter True Value Estimate Standard Error α 1 0 0 . 022 0 . 068 β 1 0 . 5 0 . 490 0 . 067 α 2 1 1 . 083 0 . 072 β 2 - 0 . 5 - 0 . 452 0 . 063 α 3 - 1 - 1 . 078 0 . 070 β 3 0 0 . 092 0 . 059 45 Table 4 : LCA with direct eﬀects : absolute bias and coverage Method 1 Method 2 Number 3 - step 3 - step of excluding including direct direct direct Method 3 eﬀects Entropy eﬀects eﬀects 1 - step 1 0 . 9 0 . 02 ( . 92 ) 0 . 02 ( . 94 ) 0 . 01 ( . 94 ) 2 0 . 9 0 . 04 ( . 88 ) 0 . 00 ( . 94 ) 0 . 01 ( . 94 ) 3 0 . 9 0 . 08 ( . 68 ) 0 . 01 ( . 96 ) 0 . 01 ( . 94 ) 4 0 . 9 0 . 15 ( . 24 ) 0 . 01 ( . 97 ) 0 . 01 ( . 95 ) 5 0 . 9 0 . 25 ( . 04 ) 0 . 00 ( . 94 ) 0 . 01 ( . 95 ) 1 0 . 6 0 . 08 ( . 79 ) 0 . 05 ( . 83 ) 0 . 01 ( . 95 ) 2 0 . 6 0 . 19 ( . 30 ) 0 . 04 ( . 92 ) 0 . 01 ( . 97 ) 3 0 . 6 0 . 38 ( . 00 ) 0 . 01 ( . 92 ) 0 . 01 ( . 97 ) 4 0 . 6 0 . 56 ( . 00 ) 0 . 07 ( . 81 ) 0 . 01 ( . 99 ) 5 0 . 6 0 . 76 ( . 00 ) 0 . 08 ( . 80 ) 0 . 01 ( . 97 ) 46 Table 5 : GMM with direct eﬀects : absolute bias and coverage Method 1 Method 1 Method 1 Method 2 Method 2 Method 3 Entropy Type 1 Type 2 Type 3 Type 2 Type 3 Type 3 0 . 6 0 . 00 ( . 97 ) 0 . 68 ( . 00 ) 0 . 49 ( . 00 ) 0 . 18 ( . 00 ) 0 . 24 ( . 00 ) 0 . 00 ( . 93 ) 0 . 85 0 . 04 ( . 95 ) 0 . 35 ( . 00 ) 0 . 23 ( . 00 ) 0 . 02 ( . 92 ) 0 . 09 ( . 26 ) 0 . 00 ( . 96 ) 0 . 95 0 . 00 ( . 95 ) 0 . 12 ( . 06 ) 0 . 07 ( . 32 ) 0 . 00 ( . 95 ) 0 . 01 ( . 90 ) 0 . 00 ( . 94 ) 47 Table 6 : Distal outcome simulation study : Bias / Mean Squared Error / Coverage N Entropy PC 3 - step Lanza 1 - step 500 0 . 7 . 10 / . 015 / . 76 . 00 / . 007 / . 95 . 00 / . 006 / . 92 . 00 / . 006 / . 94 500 0 . 6 . 16 / . 029 / . 50 . 01 / . 008 / . 94 . 00 / . 007 / . 89 . 00 / . 007 / . 94 500 0 . 5 . 22 / . 056 / . 24 . 03 / . 017 / . 86 . 00 / . 012 / . 80 . 01 / . 012 / . 96 2000 0 . 7 . 10 / . 011 / . 23 . 00 / . 002 / . 93 . 00 / . 002 / . 89 . 00 / . 002 / . 93 2000 0 . 6 . 15 / . 025 / . 03 . 00 / . 002 / . 93 . 00 / . 002 / . 87 . 00 / . 002 / . 94 2000 0 . 5 . 22 / . 051 / . 00 . 00 / . 004 / . 91 . 00 / . 003 / . 80 . 00 / . 003 / . 94 48 Table 7 : Distal outcome simulation study . Comparing equal and unequal variance 3 - step methods : Bias / Mean Squared Error / Coverage N Entropy 3 - step equal variance 3 - step diﬀerent variance 500 0 . 7 . 05 / . 147 / . 95 . 00 / . 099 / . 94 500 0 . 6 . 06 / . 174 / . 96 . 00 / . 099 / . 95 500 0 . 5 . 12 / . 822 / . 93 . 01 / . 101 / . 95 2000 0 . 7 . 05 / . 040 / . 92 . 00 / . 027 / . 92 2000 0 . 6 . 09 / . 056 / . 92 . 00 / . 027 / . 93 2000 0 . 5 . 11 / . 094 / . 95 . 00 / . 029 / . 92 49 Table 8 : Categorical distal outcome simulation study using Lanza’s method : Absolute Bias ( Coverage ) N Entropy p 21 p 22 p 23 200 0 . 5 . 03 ( . 62 ) . 08 ( . 74 ) . 07 ( . 74 ) 200 0 . 65 . 00 ( . 87 ) . 01 ( . 90 ) . 02 ( . 90 ) 500 0 . 5 . 01 ( . 87 ) . 00 ( . 99 ) . 01 ( . 91 ) 500 0 . 65 . 01 ( . 88 ) . 00 ( . 93 ) . 00 ( . 92 ) 2000 0 . 5 . 00 ( . 91 ) . 00 ( . 95 ) . 01 ( . 95 ) 2000 0 . 65 . 00 ( . 93 ) . 00 ( . 95 ) . 00 ( . 95 ) 50 Table 9 : Distal outcome simulated example Method m P - value P ( C = 1 ) / P ( C = 2 ) 1 - Step 0 . 986 0 . 007 2 . 8 3 - Step Manual 0 . 986 0 . 007 2 . 8 3 - Step 0 . 013 0 . 858 1 . 0 PC 0 . 019 0 . 492 1 . 0 Lanza 0 . 019 0 . 492 1 . 0 51