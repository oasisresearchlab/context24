Predictive Sampling for Efficient Pairwise Subjective Image Quality Assessment Shima Mohammadi Instituto Superior TÃ©cnico - Instituto de TelecomunicaÃ§Ãµes Lisbon , Portugal shima . mohammadi @ lx . it . pt JoÃ£o Ascenso Instituto Superior TÃ©cnico - Instituto de TelecomunicaÃ§Ãµes Lisbon , Portugal joao . ascenso @ lx . it . pt ABSTRACT Subjective image quality assessment studies are used in many sce - narios , such as the evaluation of compression , super - resolution , and denoising solutions . Among the available subjective test methodolo - gies , pair comparison is attracting popularity due to its simplicity , reliability , and robustness to changes in the test conditions , e . g . display resolutions . The main problem that impairs its wide accep - tance is that the number of pairs to compare by subjects grows quadratically with the number of stimuli that must be considered . Usually , the paired comparison data obtained is fed into an aggre - gation model to obtain a final score for each degraded image and thus , not every comparison contributes equally to the final quality score . In the past years , several solutions that sample pairs ( from all possible combinations ) have been proposed , from random sampling to active sampling based on the past subjectsâ€™ decisions . This paper introduces a novel sampling solution called P redictive S ampling for P airwise C omparison ( PS - PC ) which exploits the characteristics of the input data to make a prediction of which pairs should be evaluated by subjects . The proposed solution exploits popular ma - chine learning techniques to select the most informative pairs for subjects to evaluate , while for the other remaining pairs , it predicts the subjectsâ€™ preferences . The experimental results show that PS - PC is the best choice among the available sampling algorithms with higher performance for the same number of pairs . Moreover , since the choice of the pairs is done a priori before the subjective test starts , the algorithm is not required to run during the test and thus much more simple to deploy in online crowdsourcing subjective tests . CCS CONCEPTS â€¢ Information systems â†’ Multimedia contentcreation ; â€¢ Com - puting methodologies â†’ Image compression . KEYWORDS Subjective Image Quality Assessment , Pairwise Comparison , Pre - dictive Sampling Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspecificpermission and / or a fee . Request permissions from permissions @ acm . org . MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Â© 2023 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 979 - 8 - 4007 - 0108 - 5 / 23 / 10 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3581783 . 3612443 ACM Reference Format : ShimaMohammadiandJoÃ£oAscenso . 2023 . PredictiveSamplingforEfficient Pairwise Subjective Image Quality Assessment . In Proceedings of the 31st ACM International Conference on Multimedia ( MM â€™23 ) , October 29 - November 3 , 2023 , Ottawa , ON , Canada . ACM , New York , NY , USA , 9 pages . https : / / doi . org / 10 . 1145 / 3581783 . 3612443 1 INTRODUCTION Subjective assessment methodologies and studies are essential for evaluating the visual quality obtained with different image process - ing or computer vision algorithms . All subjective studies rely on human subjects to provide their perception of image quality and provide insights about the visual experience of an image , and mea - sure different image quality aspects , e . g . , in the evaluation of image compression techniques . Nowadays , there are several subjective test methodologies [ 1 ] recognized as reliable but most often a single or double stimulus methodology is used . In such cases , a panel of human subjects is required to attribute scores to each visual stimu - lus in a predefined category scale , and the average scores of all the subjects are reported as mean opinion scores ( MOS ) or differential MOS with respect to a predefined reference . However , the interpretation of the category scales might be differ - ent among the subjects , or the subjects might change their decision during the test , yielding inconsistent labels . For example , subjects may have different opinions about an " Excellent " stimulus , or given another previous stimulus , they might change their opinion . Later on , the collected scores are used as ground - truth to benchmark some objective assessment models , or to train a learning - based objective metric and thus , accurate and reliable scores are essen - tial . Absolute category scale ( ACR ) or double stimulus impairment scale subjective tests fall in this category . Despite their popularity , they have some disadvantages such as lack of sensitivity : limited in their ability to detect small differences in quality , and response bias : scores may be influenced by the subjectsâ€™ personal biases , past experiences , or expectations , which may lead to inaccurate results and thus limits the reliability of the tests . One promising approach to avoid category scales is to present a pair of stimuli ( usually side by side ) and require every subject to select the image which has the highest image quality . This is a rather intuitive and simple approach which can lead to more accu - rate and reliable results [ 2 ] compared to category rating subjective assessment tests . The aforementioned approach is referred to as pairwise comparison ( PC ) and is becoming a rather popular ap - proach for quality assessment of visual media ( images , videos , and 3D models ) . Moreover , subjects in pairwise comparison subjective assessment tests are able to distinguish small differences in quality and are more robust to changes in viewing conditions . 6676 MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Shima Mohammadi and JoÃ£o Ascenso However , a PC test usually comes with a high price of having large numbers of pairs ( and thus a large duration ) . Actually , this number grows quadratically with the number of image stimuli which often results in a long and expensive subjective test . Con - sider an original / reference image that has 15 degraded versions , a complete PC test , where every stimulus is paired with any other stimulus , requires to have ğ‘› ( ğ‘› âˆ’ 1 ) 2 = 105 pairs , where ğ‘› is the num - ber of stimuli ( or degraded images ) . Since in a typical subjective test , one original / reference image is not enough , the duration of PC sub - jective test is rather long . This contradicts ITU recommendations , which specify that a subjective test should not exceed more than 30 minutes , otherwise , it may cause fatigue , yielding in random decision of the subjects [ 3 ] . The preference ( or binary decision ) of the subjects is usually aggregated and translated into a unified scale by using some pref - erence aggregation model . It has been shown that not every pair yields equally useful data when converted to estimated scores and thus the selection ( or sampling ) of a subset of pairs may reduce the duration of the test while still resulting in reliable scores . One way to perform pairwise sampling is by active sampling , where the history of the previous decisions is used in a utility function to select a pair of images for the next trial ( or comparison ) . However , the utility function must be calculated during the subjective test limiting its applicability in many scenarios , especially those which employ simple web platforms ( such as those used in a crowdsourc - ing scenario ) . Moreover , the decision is made based on the previous judgments and does not consider the intrinsic characteristics of the pairs , e . g . difference in quality , and quite often assumes that subjects have to perform the test sequentially or in some form of batches with a specific duration . Theobjectiveofthispaper istoproposeanovelmachinelearning - based approach that is able to either predict the subject preferences given a certain pair of stimuli ( a pair of images ) or to defer the decision to human subjects . defer pairs go to a pairwise compari - son subjective test where sufficient number of subjects rank image quality . On the other hand , the preference for predict pairs is ob - tained from a machine learning model which attempts to estimate the human subjectsâ€™ preferences . As a result , a shorter subjective test could be obtained without any modification to the typical PC subjective assessment methodology , only the a priori selection of the most informative pairs . In a nutshell , our main contributions are as follows : ( 1 ) Propose a novel solution to perform pairwise sampling before the actual subjective assessment test starts , using a machine learning approach . ( 2 ) Exploit image characteristics for the first time , namely with objective quality assessment models , to sample the most infor - mative image pairs and to estimate subjectsâ€™ preferences while still providing a very reliable assessment . ( 3 ) Significantly reduce the length of a pairwise subjective assess - ment test without requiring any processing during the subjec - tive test and thus enable easy deployment in crowdsourcing scenarios or even massively parallel scenarios ( e . g . subjective tests performed in different labs ) . This type of approach is referred to as predictive sampling , provid - ing an alternative yet efficient way to perform pairwise subjective assessment thus overcoming the major disadvantages of previous approaches . The remainder of the paper is organized as follows : section 2 , discusses the related work while section 3 introduces the proposed architecture . The entire training procedure along with the labeling strategy is explained in section 4 . The performance evaluation is presented in section 5 followed by conclusions in section 6 . 2 RELATED WORK Pairwise subjective quality assessment is a powerful methodology to conduct a reliable test [ 2 ] . However , this type of methodology brings a significant burden in terms of the duration of the test and thus it may require significant human resources ( which are costly ) . There are many works that try to overcome this disadvantage and many of them propose intelligent methods to select stimuli for evaluation by human subjects . Several different sampling strategies have been proposed in the literature , which can be categorized as random - based , sorting - based , or active - based sampling , the last one providing much better performance , i . e . duration with respect to reliability . The naive approach is to randomly select pairs for each trial ( im - age pair shown to one subject ) . This approach ignores any statistical dependency on the decisions made by subjects and the data charac - teristics . The sampling strategy of [ 4 ] is based on edges available in random regular or ErdÃ¶s - RÃ©nyi graphs , and then due to incomplete and imbalanced output , HodgeRank algorithm is applied to the paired comparison result to obtain a global ranking . Sorting - based approaches select pairs of images that are more close to each other in terms of quality than pairs of images with different qualities . This type of approach exploits past decisions to select the pairs of images to be evaluated by the subjects and is actually very popular . In [ 5 ] it was proposed a binary tree sorting method where the left and the right sub - tree are judged to be lower and higher in quality respectively and each tree node represents the stimuli to be compared ( e . g . image ) . During the sorting , com - parisons between nodes will be performed by subjects to maintain the tree sorted and balanced . Due to the use of a binary tree , more trials will be conducted between closer tree nodes than between distant nodes . Another popular sorting - based approach is the Swiss system [ 6 ] [ 7 ] . It involves sorting a list of images during multiple iterations by comparing adjacent images in the list . The rule is to avoid comparing any two images more than once . In this approach , the initial list of images is chosen randomly which can introduce some variability in the output . Nowadays , active sampling approaches are considered the most promising , which aim to select a pair ( or a set of pairs ) of images according to previous judgments during the subjective test . The selected pair ( s ) can be evaluated by one or more subjects and their preference is recorded and used to select additional pairs for evalu - ation in the next iteration . In active sampling approaches , a utility function is typically used to measure the information gain that each pair of images will contribute to the overall performance . This helps to select the most informative pairs for evaluation by the subjects , thereby reducing the number of comparisons needed to accurately estimate the underlying preferences . In Hybrid - MST [ 8 ] a hybrid active sampling strategy for pairwise sampling based on Bradley - Terry ( BT ) model was proposed . The 6677 Predictive Sampling for Efficient Pairwise Subjective Image Quality Assessment MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada information gain of each pair is measured , rather than jointly by considering all the pairs at once . The information gain is based on Kullback Lieber Divergence ( KLD ) between the prior distribution of the scores and posterior distribution when possible preferences for each output of the trial are considered . In Hybrid - MST , a hybrid utility function was proposed that can switch between the global maximum information gain and the minimum spanning tree meth - ods . The latter considers pairwise comparison as an undirected graph and enables to have a sequence of pairs with just one it - eration . In ASAP [ 9 ] , information gain is based on a probability weighting function which assigns a higher probability to pairs of images that are close in quality and a lower probability to pairs that are far apart in quality . This approach reduces the computational cost by selectively measuring the information gain for pairs of im - ages that are most likely to provide useful information . However , inferring quality scores are based on message passing and is still rather complex . Information gain measurement in [ 10 ] is similar to other active sampling approaches by calculating KLD between prior and posterior distribution of the quality scores , however , the scores are inferred based on Hodge decomposition to further evaluate any inconsistency in pairwise comparison data . Some other studies boost PC with data obtained from a single ( or double ) stimulus subjective test to avoid doing a complete pairwise comparison test , selecting more informative pairs and thus obtain - ing finer discrimination . In [ 11 ] a fusion strategy is introduced to combine ACR and PC subjective tests by initializing PC with ACR subjective test results to achieve higher accuracy . Furthermore , [ 12 ] introduces a hybrid approach capable of merging MOS and PC tests through a probabilistic model and active sampling approach . They have shown that this type of strategy can effectively reduce the number of trials required for achieving a target accuracy . The reliability of the subjectsâ€™ decisions may also affect the util - ity function calculation . The work of [ 13 ] extends the BT model to eliminate the impact of unreliable subjects . In [ 14 ] it was observed that the human visual system is not able to distinguish subtle differ - ences between two images of very similar quality . Thus , no matter how many times the pair is selected , subjects may not have the cor - rect preference . This highlights the importance of considering the reliability of preference when designing active sampling strategies for pairwise comparison tests and thus adjusting the selection of pairs according to their ambiguity . The speed and reliability of human subjects can affect the effi - ciency of the active sampling process . Moreover , the computational cost of the utility function remains a challenge , particularly in crowd - sourcing scenarios where the server may need to run the active sampling method after every comparison by subjects , being difficult to integrate into existing web frameworks . The coordi - nation of multiple instances of the active sampling algorithm in laboratory environments can also be challenging . This is the main motivation to design a novel sampling approach that is performed before the subjective test . 3 PS - PC ARCHITECTURE A straightforward but lengthy approach in a PC subjective test is to evaluate every possible pair combination of stimuli ( complete test ) . The number of pairs increases quadratically , ğ‘‚ ( ğ‘› 2 ) , with re - spect to the number of stimuli ( degraded images ) resulting in a long and expensive subjective test . The binary decision of each comparison / trial is recorded into a matrix , typically called ğ‘ƒğ¶ğ‘€ ( PC matrix ) which is then converted to scores using some prefer - ence aggregation model . However , it is widely known that not all pairs have the same importance and some could even be discarded . This paper proposes a framework that performs pairwise sampling ( or selection ) based on two aspects : which are the best pairs to be selected for human evaluation and what is the human preference considering the underlying quality of each stimulus of the pair . The proposed predictive sampling framework , codenamed PS - PC 1 , is shown in Fig . 1 has three key parts namely , feature extraction to obtain relevant measures of quality , classifier to select some pairs for the subjective test , and a predictor that estimates the preference between the two stimuli of the pair . For every possible pair combination , the proposed framework will be run for the two stimuli of the pair . The classifier decides whether the pair should go to a subjective test or to the predictor . The predictor is trained to learn the probability of preference of the selected pair based on the features of both stimuli . The classifier decision can be interpreted as defer or predict . In the end , when all pairs are considered , a complete ğ‘ƒğ¶ğ‘€ is obtained which can be used by the preference aggregation model to obtain quality scores . In Fig . 1 the dotted part requires a training procedure that is described in the next section . The proposed PS - PC framework is explained , in summary , as follows : â€¢ Feature extraction and normalization : The features used by both classifier and predictor are obtained from seven full reference image quality assessment ( FR - IQA ) metrics and presented in summary in table 1 . These features represent the perceptual quality between the reference image and the two stimuli of the pair . The JPEG AI quality metrics , which were selected based on a rigorous evaluation done for several image compression and processing solutions ( both conventional and deep learning ) allow capturing the full range of properties associated with the stimuli under evaluation , not only for image compression but also for image super - resolution and denoising [ 15 ] . These quality scores have to be first normalized according to ( 1 ) to be in the same scale [ 16 ] . ğ‘¥ ğ‘ ğ‘ğ‘ğ‘™ğ‘’ğ‘‘ = ğ‘¥ ğ‘˜ âˆ’ ğ‘¥ ğ‘šğ‘–ğ‘›ğ‘˜ ğ‘¥ ğ‘šğ‘ğ‘¥ğ‘˜ âˆ’ ğ‘¥ ğ‘šğ‘–ğ‘›ğ‘˜ ( 1 ) where ğ‘¥ ğ‘˜ stands for the ğ‘˜ ğ‘¡â„ feature , ğ‘¥ ğ‘šğ‘–ğ‘›ğ‘˜ and ğ‘¥ ğ‘šğ‘ğ‘¥ğ‘˜ are the min - imum and the maximum value in the ğ‘˜ ğ‘¡â„ feature respectively . â€¢ Classifier : The classifier receives as input the set of features extracted according to the feature extraction module , for each stimulus of a pair . The objective of the classifier is to perform a binary decision which is to classify as defer : pair must be eval - uated by subjects , or as predict : subjects preference is obtained automatically without human intervention . The decision de - pends on the extracted features for both stimuli of the pair , the selected classifier model , and the ground - truth data . Therefore , for the training of the classifier , the ground - truth labels of defer or predict for each pair are required . The procedure to obtain labels for the ground - truth data is detailed in section 4 . 1 . 1 Available online at https : / / github . com / shimamohammadi / PS - PC 6678 MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Shima Mohammadi and JoÃ£o Ascenso Predictor Classifier Subjective Test Defer Predict PCMA B Preference Aggregation Model Quality Scores Reference Stimulus B Stimulus A JPEG AI Quality Metrics N o r m a li z a t i o n Feature Extraction JPEG AI Quality Metrics A B Figure 1 : The Predictive Sampling Pairwise Comparison ( PS - PC ) framework . Two types of classifiers were selected , Support Vector Machine ( SVM ) [ 17 ] and Extreme Gradient Boosting ( XGboost ) [ 18 ] . Deep neural network architectures were not selected since the amount of training data available was not high , which is typically required for this type of solution . In summary , the two classifiers are presented next : â€“ SVM : SVM finds a hyperplane that separates the data into different classes . The hyperplane is selected to maximize the margin , which is the distance between the hyperplane and the closest data points from each class . SVM uses a tech - nique called kernel trick , where the data is transformed into a higher - dimensional space to make it linearly separable . â€“ XGBoost : XGBoost is an implementation of gradient boost - ing decision trees , a machine learning algorithm that works by iteratively adding models which are combined to cre - ate an overall model with higher accuracy . XGBoost uses a combination of regularized learning objectives , parallel pro - cessing , and tree pruning techniques to prevent overfitting and improve efficiency . â€¢ Predictor : The predictor is responsible to estimate the proba - bility of preferring one stimulus over the other in a pair and is only used when a pair is classified as predict . The output of the predictor is also used during the training process to enable the classifier to perform better decisions . This is explained in more detail in section 4 . 1 . For the predictor , support vector regres - sion ( SVR ) [ 19 ] was used and trained to learn the underlying relationship between the extracted features and the probability of preference from the ground - truth data . SVR can handle both linear and non - linear regression problems and is based on the same principles as the SVM algorithm used for classification . 4 TRAINING PROCEDURE The training details of the proposed framework are described in the following sections including the labeling process to obtain ground - truth data and the classifier and predictor training . 4 . 1 Ground - truth Data Creation To perform the training of the classifier , a dataset with features extracted for each stimulus and the correct labeling of each possible pair with defer or predict is needed . However , these labels are not available and thus a novel procedure to obtain the correct labeling from the results of a pairwise comparison test is proposed . In the next section , the preference aggregation model is presented which is important to understand the labelling procedure . 4 . 1 . 1 Preference Aggregation Model . The preference aggregation model infers scores from the subjectâ€™s preferences of an already available pairwise comparison subjective assessment test . Letâ€™s assume that there is a PC test with ğ‘› stimuli where preferences between pairs of stimuli are arranged in a PC matrix , ğ‘ƒğ¶ğ‘€ . In the ğ‘ƒğ¶ğ‘€ , the diagonal entry is zero since a stimulus cannot be com - pared to itself , and the other entries correspond to the probability of preferences as follows . Let ğ‘ ğ‘–ğ‘— indicate number of times stimuli ğ‘– is preferred over stimuli ğ‘— . As a result , ğ‘ƒğ¶ğ‘€ ğ‘–ğ‘— corresponds to ( 2 ) . ğ‘ƒğ¶ğ‘€ ğ‘–ğ‘— = ğ‘ ğ‘–ğ‘— ğ‘ ğ‘–ğ‘— + ğ‘ ğ‘—ğ‘– ( 2 ) To infer scores from the ğ‘ƒğ¶ğ‘€ , several models were proposed including Bradley - Terry model [ 27 ] , Thurstone - Mosteller ( TM ) [ 28 ] , Borda count [ 29 ] , and many others . In this paper , the BT model is utilized . According to the BT model , the probability of stimulus ğ‘– preferred over stimulus ğ‘— denoted as ğ‘ƒğ‘Ÿ ( ğ‘– > ğ‘— ) is measured as ( 3 ) . ğ‘ƒğ‘Ÿ ( ğ‘– > ğ‘— ) = ğœ‹ ğ‘–ğ‘— = ğœ‹ ğ‘– ğœ‹ ğ‘– + ğœ‹ ğ‘— , s . t . ğ‘˜ âˆ‘ï¸ ğ‘– = 1 ğœ‹ ğ‘– = 1 , ğœ‹ ğ‘– > = 0 ( 3 ) Where ğœ‹ ğ‘– is the score of stimulus ğ‘– . Moreover , the score could also be expressed as Ë† ğ‘  ğ‘– = ğ‘™ğ‘œğ‘” ( ğœ‹ ğ‘– ) . Thus , ğ‘ƒğ‘Ÿ ( ğ‘– > ğ‘— ) could be rewritten as in ( 4 ) . ğœ‹ ğ‘–ğ‘— = 1 1 + ğ‘’ âˆ’ ( Ë† ğ‘  ğ‘– âˆ’ Ë† ğ‘  ğ‘— ) ( 4 ) To estimate each Ë† ğ‘  ğ‘– from the BT model , maximum likelihood esti - mation ( MLE ) is used . The likelihood is defined as in ( 5 ) . ğ¿ ( Ë† ğ‘  | ğ‘ƒğ¶ğ‘€ ) = (cid:214) ğ‘– < ğ‘— ( ğœ‹ ğ‘–ğ‘— ) ğ‘ƒğ¶ğ‘€ ğ‘–ğ‘— ( 1 âˆ’ ğœ‹ ğ‘–ğ‘— ) ğ‘ƒğ¶ğ‘€ ğ‘—ğ‘– ( 5 ) The estimated scores , Ë† ğ‘  = ( Ë† ğ‘  1 , Ë† ğ‘  2 , . . . , Ë† ğ‘  ğ‘˜ ) , follow a multivariate Gauss - ian distribution , and the covariance matrix Ë† Î£ is estimated using the Hessian matrix [ 30 ] . Therefore , the standard deviations are obtained from the covariance matrix . The output of the preference aggregation model is scores Ë† ğ‘  , and standard deviations Ë† ğœ . 4 . 1 . 2 Labelling . In the labeling process , all possible pairs are la - beled as predict or defer . The labeling process requires a dataset where preferences between all pairs are available and thus obtained from a complete pairwise comparison test . The proposed labeling approach , shown in Fig . 2 , involves se - lecting a predict pair and removing the corresponding preferences from the ğ‘ƒğ¶ğ‘€ . This process continues with another predict pair until a stopping point is reached , and then all the remaining pairs are labeled as defer . The stopping point is defined such that only 6679 Predictive Sampling for Efficient Pairwise Subjective Image Quality Assessment MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Table 1 : JPEG AI image quality metrics Quality metric Description IW - SSIM [ 20 ] Extension of SSIM based on information content weighted pooling , where weights are derived from statistical models of natural images . MS - SSIM [ 21 ] Boosts SSIM metric by considering the variations in image resolution and viewing conditions . FSIM [ 22 ] Exploits phase congruency and gradient information to account for local structure and contrast information . PSNR - HVS [ 23 ] Uses DCT basis functions and calculates the maximum distortion that is not visible due to between - coefficient masking . VIF [ 24 ] Distortion measure in the wavelet domain and related to the Shannon mutual information between the degraded and original pristine image . VMAF [ 25 ] Computes the quality score of several quality assessment algorithms which are fused together with an SVM algorithm . NLPD [ 26 ] Uses a Laplacian pyramid decomposition considering different two aspects : local luminance subtraction and local contrast gain control . a certain reduction in the Pearson Linear Correlation Coefficient ( PLCC ) between the inferred scores from the ground - truth data ( pristine ğ‘ƒğ¶ğ‘€ ğºğ‘‡ ) and the ğ‘ƒğ¶ğ‘€ ğ‘ƒ with some selected pairs removed is acceptable . The ğœ‚ parameter defines the target PLCC that should be achieved in the labeling procedure and ranges between 0 . 97 and 1 . Naturally , an ğœ‚ value close to 1 , requires labeling a signifi - cant number of pairs as defer while a value close to 0 . 97 much less number of pairs ( approx . 10 % ) , thus obtaining a much shorter test duration . In general , there are two ways to remove a pair ; setting its value to a constant ( e . g . , 0 . 5 ) , to avoid numerical inconsistency of an incomplete Bradley - Terry model , or using the corresponding value from the predictorâ€™s output . In this case , the predictorâ€™s output is used whenever a pair is selected as predict . However , for the purposes of evaluating labeling approaches , the first option is used ( see section 5 . 2 . 1 ) . Predict pair labelling PCM updating BTmodel BTmodel PLCC computation Stopingcriteria PCMGT PCMP 1st iteration ? N Y Labelremaingpairs as defer Figure 2 : Main steps of the labelling algorithm . The three different methods for labeling are : â€¢ Random - based : The naive approach is to simply select predict pairs assuming equal probability of all pairs . This random se - lection is not the best choice but it may serve as a benchmark . To ensure that the results are not biased , 50 repetitions are performed . â€¢ Entropy - based : Another selection approach is to use entropy , which is a way to measure the amount of uncertainty about an event . The idea is to calculate the entropy of each pair as in ( 6 ) based on the subject preferences and then , select the predict pairs as those that have maximum entropy . In this context , entropy is the average amount of information contained in the pair and maximum entropy is used since it refers to the pairs that subjects were most uncertain about the correct answer , indicating that increasing the number of trials for these pairs may not provide much additional information for improving accuracy . ğ» ğ‘–ğ‘— = âˆ’ ğ‘ ğ‘–ğ‘— log ğ‘ ğ‘–ğ‘— âˆ’ ( 1 âˆ’ ğ‘ ğ‘–ğ‘— ) log ( 1 âˆ’ ğ‘ ğ‘–ğ‘— ) ( 6 ) where ğ‘ ğ‘–ğ‘— refers to the probability of preferring ğ‘– to ğ‘— . â€¢ KLD - based : The most principled approach towards labeling is based on the KLD , where the divergence between two probabil - ity distributions of scores is measured . The idea is to measure the divergence between the prior distribution and posterior distribution , i . e . after a pair is removed . The prior distribution represents the modelâ€™s output probabilities before any pair is re - moved ( obtained from the pristine ğ‘ƒğ¶ğ‘€ ğºğ‘‡ ) , while the posterior distribution represents the modelâ€™s output probabilities after a pair is removed in some iteration of the labeling algorithm ( obtained from ğ‘ƒğ¶ğ‘€ ğ‘ƒ ) . By measuring the KLD between these two distributions , it is possible to identify the pairs that are most informative for improving the modelâ€™s performance . This is because pairs with a low KLD are those that are likely to have the lowest impact on the modelâ€™s output probabilities and by removing the lowest KLD value ( and labeling the pair as predict ) the model performance can be continuously improved . Therefore , at each labeling algorithm iteration , the KLD is com - puted for all possible pairs not previously labeled , to find the minimum KLD value . The inferred scores Ë† ğ‘  of the BT model ( see ( 5 ) ) follow a multivariate Gaussian distribution and hence , KLD must be measured between the two multivariate Gaussian prior and posterior distributions . Since the covariance matrix Ë† Î£ is sin - gular and thus it is not invertible , the following approximation of KLD is used [ 9 ] . Ëœ ğ¾ğ¿ğ· ( ğœ‹ ğ‘”ğ‘¡ , Ë† ğœ ğ‘”ğ‘¡ , ğœ‹ ğ‘ , Ë† ğœ ğ‘ ) = (cid:205) ğ‘›ğ‘– = 1 log Ë† ğœ ğ‘ Ë† ğœ ğ‘”ğ‘¡ âˆ’ ğ‘‘ + (cid:205) ğ‘›ğ‘– = 1 Ë† ğœ ğ‘”ğ‘¡ Ë† ğœ ğ‘ + 1Ë† ğœ ğ‘ ( ğœ‹ ğ‘”ğ‘¡ âˆ’ ğœ‹ ğ‘ ) 2 ( 7 ) In ( 7 ) ğœ‹ ğ‘”ğ‘¡â„ and Ë† ğœ ğ‘”ğ‘¡ are the ground - truth probabilities ( obtained with ( 4 ) ) , and standard deviations , respectively and represent the prior distribution . Also , ğœ‹ ğ‘ and Ë† ğœ ğ‘ are calculated in the same way but for each possible pair and represent the posterior distribution . 4 . 2 Classifier Training The classifier learns to map the features to labels , i . e . the classifier receives a vector of input variables or features ğ‘“ ğ‘˜ , and the corre - sponding category output target or label ğ‘¦ ğ‘– , and learns the mapping between the features ğ‘“ ğ‘˜ , and the label ğ‘¦ ğ‘– , for each training pair ğ‘– ( two degraded images ) . However , for the training of the classifier to be successful , the training set should be balanced . This doesnâ€™t happen with the proposed framework since there are much fewer defer labels when compared to predict labels . To address this class imbalance in the dataset , random oversampling is used on the train - ing set . This technique involves randomly duplicating examples from the minority class until the number of examples in that class is similar to the majority class [ 31 ] . The SVM or XGBoost classifier hyperparameters can also sig - nificantly influence the classifier performance and must be found before training . The SVM hyperparameters considered are : 6680 MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Shima Mohammadi and JoÃ£o Ascenso â€¢ Penalty ğ¶ : This is the regularization parameter that controls the modelâ€™s ability to generalize to new data . A smaller value of ğ¶ will result in a larger margin hyperplane but with more misclassifications of the training data , while a larger value of ğ¶ will result in a smaller margin but fewer misclassifications of the training data . â€¢ Kernel : SVM can use different types of kernels to transform the input data into a higher - dimensional space where it is easier to separate the classes . Some of the popular kernels include linear , polynomial , and radial basis function ( RBF ) . The gamma hyperparameter is specific to the RBF kernel and controls the width of the kernel . The hyperparameters considered in the XGBoost classifier are : â€¢ Max depth : This hyperparameter controls the maximum depth of a tree in the ensemble . A larger value will allow to obtain a more complex model well suited to the training set , but may also lead to overfitting . â€¢ Learning rate : This hyperparameter controls the step size at each iteration while moving towards the minimum of the loss function . A smaller learning rate will lead to slower but more precise convergence , while a larger learning rate will result in faster convergence but may miss the minimum . â€¢ Gamma : This hyperparameter specifies the minimum loss re - duction required to make a partition on a leaf node of a tree ( split ) . â€¢ Regularization lambda : This hyperparameter controls the L2 regularization term strength , the penalty term of the loss func - tion used during model training . The model will be more con - servative ( with more generalization capabilities ) by increasing this parameter value . â€¢ Scale position weight : This hyperparameter is used to adjust the balance of positive and negative class weights ( predict and defer ) in this binary classification problem . The hyperparameters of the classifier are found using grid search which is one of the most popular techniques , where a range of values ( interval ) was defined for each hyperparameter . For the SVM classifier , the penalty and gamma interval was 0 . 05 to 0 . 5 and 0 . 01 to 1 , respectively . The RBF kernel was always used . For the XG - Boost , the intervals are 1 to 4 for max depth , 0 . 05 to 0 . 1 for learning rate , 0 . 01 to 1 for gamma , and 1 to 10 for regularized gamma . The scale position weight parameter was kept fixed according to [ 18 ] : (cid:205) ( Defer instances ) (cid:205) ( Predict instances ) . All possible combinations of the hyperparame - ters inside each interval were evaluated to select the combination that has the highest accuracy . Regarding the SVM classifier , the F1 score ( harmonic mean of the precision and recall ) was used to measure accuracy , while for the XGBoost classifier the area under the ROC ( Receiver Operating Characteristic ) curve was used . 4 . 3 Predictor Training The predictor is responsible to estimate the probability of pref - erence for predict labeled pairs with the SVR regression model . During SVR training , the objective is to find a regression function that accurately estimates the probability of preference using the previously computed features ( see section 3 ) . The dependent vari - able is the probability of preference from the ground - truth data . For each training pair ğ‘– ( two degraded images ) , SVR receives a vector of input variables ( features ) ğ‘“ ğ‘˜ of each stimulus and the corresponding scalar output target ( probability of preference ) ğ‘¦ ğ‘– , and attempts to learn a function which maps ğ‘“ ğ‘˜ to ğ‘¦ ğ‘– . In SVR , a kernel can also be used to map the input data into a high dimensional feature space where data is more linearly correlated with the outputs . In this work , the widely popular RBF kernel was used . 5 PERFORMANCE EVALUATION In this section , the proposed PS - PC framework is thoroughly eval - uated , every component individually but also jointly regarding state - of - the - art . First , the several labeling approaches ( see section 4 . 1 . 2 ) and classifier models ( see section 4 . 2 ) are evaluated . Then , the overall PS - PC solution ( with the best performing labeling and classifier methods ) performance is compared to state - of - the - art al - gorithms . A Cross - dataset evaluation was also performed to assess the PS - PC generalization capabilities along with an ablation study . 5 . 1 Test Conditions This section describes the test conditions , namely the datasets and the procedure used to evaluate the proposed PS - PC framework . 5 . 1 . 1 Datasets . A publicly available dataset called Pairwise Com - parison Image Quality Assessment ( PC - IQA ) 2 was selected [ 32 ] . The PC - IQA dataset was obtained with a crowd - sourcing pairwise subjective test using images obtained from the LIVE [ 33 ] and IVC [ 34 ] datasets . In total , 15 reference images and 15 distorted versions of each reference are present in the dataset , with distortions in - cluding JPEG2000 , JPEG , White Noise , Gaussian Blur , Fast Fading Rayleigh , Locally Adaptive Resolution ( LAR ) Coding , and Blurring . In summary , for each reference , ğ‘› ( ğ‘› âˆ’ 1 ) 2 = 120 pairs are available which sums to 1800 for the complete dataset . This dataset is com - plete ( all pairs are compared ) but imbalanced , which means that each pair was evaluated with a different number of trials ( actual comparisons by subjects ) . For the cross - dataset evaluation , two different datasets obtained using pairwise comparison methodology were used , the TID2013 [ 7 ] and the PieAPP [ 35 ] test set of 2018 . These datasets were not used for training . The TID2013 dataset consists of 25 references , each with 120 degradations and Swiss design was employed to reduce the number of trials ( but all pairs are compared at least nine times ) . The test set of the PieAPP dataset comprises 40 reference im - ages and 15 degraded versions randomly selected from 31 different distortion types . No pairwise sampling method was used and thus itâ€™s a complete and balanced dataset . For the PieAPP dataset , the probability of preference between two stimuli of a pair is available . However , for the TID2013 dataset , only quality scores ranging from 0 to 9 are available . To address this limitation , the probability of preference between each pair of images was calculated with ( 4 ) , which is valid since scores were obtained from a pairwise compari - son subjective test . Note also that a complete pairwise comparison test on the TID2013 and PieAPP datasets requires a total of 178 , 500 pairs and 4 , 800 pairwise comparisons , respectively which is impos - sible to realize in practice without employing a pairwise sampling method . 5 . 1 . 2 Evaluation Procedure . The evaluation procedure is rather straightforward , after the PS - PC algorithm performs the selection of pairs , the probability of preference for the selected defer pairs 2 Available here 6681 Predictive Sampling for Efficient Pairwise Subjective Image Quality Assessment MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada was obtained from the ground - truth data , while for the predict pairs was obtained with the proposed predictor . This avoids performing a subjective assessment test . The evaluation of the PS - PC classifier ( in section 5 . 2 . 2 ) , the com - parison with state - of - the - art ( in section 5 . 2 . 3 ) and the ablation study ( in section 5 . 2 . 4 ) was performed using cross - validation to ensure that the model is tested on data that it has not seen during training and thus the performance evaluation is unbiased and representative . The PC - IQA dataset is split into 5 non - overlapping folds , where each fold is used as a test set while the rest of the data is used as the training set . The result is predicted quality scores for all stimuli contained in the testing fold . Each fold contains three references ( with all the associated degraded images , i . e . stimulus ) and naturally , this process is repeated 5 times , with each one of the 5 folds used exactly once as test data , thus including all 15 reference images . 5 . 2 Experimental Results The performance metrics for all experiments in this section are PLCC and Spearmanâ€™s rank correlation coefficient ( SROCC ) . The correlation is calculated between the ground - truth scores ( obtained from the preference aggregation model ) and the estimated scores of the proposed PS - PC solution unless stated otherwise . 5 . 2 . 1 Labeling Evaluation . The labeling algorithms presented in section 4 . 1 . 2 are evaluated on the entire PC - IQA dataset without any stopping criteria to better understand the performance for a wide range of predict pairs numbers and thus subjective test length . Therefore , the PLCC performance is reported every time that a pair is removed from the ğ‘ƒğ¶ğ‘€ and labeled as predict according to the labeling algorithm . To avoid any bias for the random - based labeling approach , the average results of 50 iterations were used . Fig . 3 compares the three labeling approaches in terms of PLCC and SROCC . The figures show that KLD - based labeling provides the best selection of pairs since PLCC gradually reduces and is always above the other labeling approaches . The experimental results also suggest that , initially , entropy - based labeling has a higher correlation than random - based labeling , but as more pairs are removed , the correlation is worse than the average random - based labeling . 0 250 500 750 1000 1250 1500 1750 Number of predict pairs 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 P L CC Entropy - based labeling KLD - based labeling Random - based labeling 0 250 500 750 1000 1250 1500 1750 Number of predict pairs 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 S R O CC Entropy - based labeling KLD - based labeling Random - based labeling Figure 3 : Labeling algorithm evaluation . 5 . 2 . 2 Classifier Evaluation . To evaluate the two alternatives for the classifier , SVM and XGBoost , five different classifier models were trained . In each model , the ground - truth labels were obtained by having different ğœ‚ = { 0 . 97 , 0 . 98 , 0 . 985 , 0 . 99 , 0 . 995 } in the labeling algorithm which defines the tradeoff between the number of pairs selected as defer ( and thus the subjective test length ) and the accu - racy of the scores in the subjective test . An ideal pairwise sampling framework is expected to have a performance equal to ğœ‚ . The experimental results are shown in Fig . 4 . In this figure , the horizontal axis is the percentage of the number of defer pairs ( that go to the subjective test ) each classifier selects for the complete PC - IQA dataset ( total of 1800 pairs ) . The experimental results show that XGBoost is the best choice . 5 % 10 % 15 % 20 % 25 % Number of defer pairs ( % ) 0 . 88 0 . 90 0 . 92 0 . 94 0 . 96 0 . 98 P L CC PS - PC - KLD - SVM PS - PC - KLD - XGBoost 5 % 10 % 15 % 20 % 25 % Number of defer pairs ( % ) 0 . 82 0 . 84 0 . 86 0 . 88 0 . 90 0 . 92 S R O CC PS - PC - KLD - SVM PS - PC - KLD - XGBoost Figure 4 : Classifier models evaluation . 5 . 2 . 3 State - of - the - art Evaluation . The PS - PC performance evalua - tion was compared to several state - of - the - art algorithms : Hybrid - MST [ 8 ] , HR - Active [ 10 ] , ASAP [ 9 ] , Crowd - BT [ 13 ] , and Swiss - design [ 7 ] are the selected benchmarks . The first three are active sampling methods and the last is a sorting - based method which is of - ten used in subjective image quality assessment studies [ 6 , 7 , 36 , 37 ] . The PS - PC framework uses the probability of preference for defer pairs obtained from the ground - truth data ( the result of multiple trials in a subjective test ) whereas the state - of - the - art methods only perform a single trial for some selected pairs in each iteration of the algorithm . Therefore , the comparison should be based on the number of trials instead of the number of defer pairs . To enable a fair comparison , the number of trials for the defer pairs selected by the PS - PC framework is recorded and summed for each ğœ‚ . This will be the budget of trials for the benchmark pairwise selection methods . It is important to note that benchmarks use the raw decisions of the ground - truth data ( randomly selecting a subject comparison ) and not the probability of preference . Since these raw decisions are obtained randomly , an average of 50 iterations is used . In Fig . 5 , the horizontal axes is the number of trials in percentage where the maximum number of trials is set to ğ‘› ( ğ‘› âˆ’ 1 ) 2 Ã— 15 with 15 being the number of subjects . As shown in the results , for the PLCC correlation measure , PS - PC is the best choice followed by Hybrid - MST and both have far better correlations than Swiss - Design and Crowd - BT . However , if SROCC is considered as the correlation metric , HR - Active followed by Hybrid - MST has higher performance than PS - PC . This is actually because PS - PC was trained based on the PLCC metric and was actually expected . For the training of the PS - PC framework , other performance metrics , such as SROCC ( or weighted SROCC with PLCC ) could have been selected instead . It is ultimately a choice of the subjective test designer . 5 . 2 . 4 Ablation Study Evaluation . The PS - PC framework has both classifier and predictor modules which might have a different im - pact on the overall correlation performance and therefore an ab - lation study to further validate the performance of each proposed module was done . Moreover , a random classifier was integrated in the PS - PC framework to better understand the impact of this module . In summary , the following configurations were considered . â€¢ Classifier only : To individually evaluate the performance of the classifier , the predictor in the PS - PC framework outputs always 6682 MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada Shima Mohammadi and JoÃ£o Ascenso 10 % 15 % 20 % 25 % 30 % 35 % 40 % Number of trials for defer pairs ( % ) 0 . 75 0 . 80 0 . 85 0 . 90 0 . 95 P L CC Hybrid - MST PS - PC - KLD - XGBoost Swiss - Design Crowd - BT ASAPHR - Active 10 % 15 % 20 % 25 % 30 % 35 % 40 % Number of trials for defer pairs ( % ) 0 . 86 0 . 88 0 . 90 0 . 92 0 . 94 0 . 96 S R O CC Figure 5 : PS - PC performance against selected benchmarks . a preference probability of 0 . 5 . This is done to evaluate the performance of the classifier module alone and thus its ability to classify the pairs . â€¢ Predictor only : To individually evaluate the performance of the predictor , the classifier in the PS - PC framework is not present , meaning that every pair is classified as predict . This is done to evaluate the performance of the predictor module alone without the influence of the classifier . â€¢ RndClass + predict : This corresponds to a benchmark where a random classifier is used to classify the pairs , instead of the proposed classifier on top of the proposed predictor . This is done to evaluate the effectiveness of the trained classifier of the PS - PC framework . The ablation study experimental results are shown in Table 2 for different values of ğœ‚ = { 0 . 97 , 0 . 98 , 0 . 985 , 0 . 99 , 0 . 995 } . This ablation study shows that both classifier and predictor play an important role in the overall performance . With just the predictor , PLCC is 0 . 85 whereas with just the classifier goes up to 0 . 94 , naturally at the cost of selecting a high number of pairs . Neither of these solutions is a good choice for pairwise sampling , mostly due to lack of performance or a high number of defer pairs . Moreover , the random classifier and predictor barely improve the performance compared with the predictor only case , which shows the importance of having an accurate classifier . From these results , it is clear that the best option is the proposed PS - PC framework , which has a loss of only 0 . 05 for a target PLCC ğœ‚ of 0 . 97 , which corresponds to the selection of just 8 % of the pairs . This loss can be even further reduced by allowing the selection of more pairs ( as much as 0 . 01 ) . Table 2 : PS - PC ablation study . Module Metric Models ğœ‚ = 0 . 97 ğœ‚ = 0 . 98 ğœ‚ = 0 . 985 ğœ‚ = 0 . 99 ğœ‚ = 0 . 995 Classifier only PLCC 0 . 67 0 . 85 0 . 91 0 . 93 0 . 94 SROCC 0 . 44 0 . 60 0 . 63 0 . 68 0 . 75 Predictor only PLCC 0 . 85 SROCC 0 . 83 RndClass + predict PLCC 0 . 89 0 . 88 0 . 89 0 . 87 0 . 88 SROCC 0 . 85 0 . 85 0 . 85 0 . 86 0 . 86 PS - PC PLCC 0 . 92 0 . 96 0 . 97 0 . 98 0 . 99 SROCC 0 . 87 0 . 90 0 . 92 0 . 922 0 . 94 5 . 2 . 5 Cross - dataset Evaluation . To examine the generalization of the PS - PC framework , the PieAPP and TID2013 datasets 3 ( described in 5 . 1 . 1 ) are used just for testing . None of the images of these datasets were used in the training procedure , only the images of the PC - IQA dataset . In this case , cross - validation was not used and all reference and degraded images of the PC - IQA dataset represent the training set . Moreover , these datasets include very different types of degradations compared to PC - IQA , for example , TID2013 includes 3 Available at PieAPP , and TID2013 different types of noises , transmission errors , contrast changes , other codecs , etc . This is a challenging scenario for PS - PC which has never seen such types of errors . The results are shown in Table 3 . As shown , PS - PC performance is lower for TID2013 and PieApp but not very significantly , using 62 % of the selected pairs in the TID2013 dataset results in 0 . 95 PLCC , while 46 % of the selected pairs in the PieAPP dataset , have a correla - tion of 0 . 89 PLCC . The performance is lower for the PieApp dataset since it includes very different types of degradations , e . g . complex artifacts from computer vision and image processing algorithms . Table 3 : Cross dataset evaluation Dataset Metric Models ğœ‚ = 0 . 97 ğœ‚ = 0 . 98 ğœ‚ = 0 . 985 ğœ‚ = 0 . 99 ğœ‚ = 0 . 995 TID2013 PLCC 0 . 83 0 . 85 0 . 90 0 . 92 0 . 95 SROCC 0 . 82 0 . 83 0 . 90 0 . 93 0 . 95 Defer Pairs 7 % 17 % 35 % 44 % 62 % PieAPP PLCC 0 . 80 0 . 84 0 . 86 0 . 89 0 . 89 SROCC 0 . 44 0 . 49 0 . 53 0 . 60 0 . 62 Defer Pairs 9 % 22 % 26 % 38 % 46 % PC - IQA PLCC 0 . 92 0 . 96 0 . 97 0 . 98 0 . 99 SROCC 0 . 87 0 . 90 0 . 92 0 . 922 0 . 94 Defer Pairs 8 % 11 % 15 % 17 % 22 % 6 CONCLUSIONS AND FUTURE WORK This paper proposes a novel predictive sampling framework based on machine learning to perform pair sampling for a pairwise com - parison subjective test . The objective is to select a subset of pairs without compromising its performance . To achieve this , the PS - PC framework uses JPEG AI image quality metrics to extract features , which were used as input for a classifier and predictor . The classifier determines whether some pair of images should be subjectively eval - uated or not ; in the latter case , a predictor computes the probability of preference between the two stimuli of the pair . The performance evaluation shows that the PS - PC framework outperforms relevant state - of - the - art and that both predictor and classifier contribute to the final performance of the proposed solution . Moreover , the proposed solution selects pairs of images for subjective assessment a priori and does not require to be run during the subjective test and thus much more simple to deploy in crowdsourcing scenarios . As future work in the near - term , a large - scale new pairwise com - parison dataset will be constructed to learn new types of distortions and thus improve the generalization capabilities of this solution . This work is seminal since many different research directions could be followed next , such as the use of deep - learning network architec - tures as well as the exploitation of past subject decisions in this type of framework , for example with reinforcement learning techniques . ACKNOWLEDGMENTS This work is funded by FCT / MCTES through national funds and when applicable co - funded EU funds under the project DARING with reference PTDC / EEI - COM / 7775 / 2020 . REFERENCES [ 1 ] MichelaTestolinaandTouradjEbrahimi . Reviewofsubjectivequalityassessment methodologies and standards for compressed images evaluation . In Applications of Digital Image Processing XLIV , volume 11842 , pages 302 â€“ 315 . SPIE , 2021 . [ 2 ] RafaÅ‚ K Mantiuk , Anna Tomaszewska , and RadosÅ‚aw Mantiuk . Comparison of four subjective methods for image quality assessment . In Computer graphics forum , volume 31 , pages 2478 â€“ 2491 . Wiley Online Library , 2012 . 6683 Predictive Sampling for Efficient Pairwise Subjective Image Quality Assessment MM â€™23 , October 29 - November 3 , 2023 , Ottawa , ON , Canada [ 3 ] Recommendation ITU - T P . 913 . Methods for the subjective assessment of video quality , audio quality and audiovisual quality of internet video and distribution quality television in any environment , 2016 . [ 4 ] Qianqian Xu , Qingming Huang , Tingting Jiang , Bowei Yan , Weisi Lin , and Yuan Yao . Hodgerank on random graphs for subjective video quality assessment . IEEE Transactions on Multimedia , 14 ( 3 ) : 844 â€“ 857 , 2012 . [ 5 ] D Amnon Silverstein and Joyce E Farrell . Efficient method for paired comparison . Journal of Electronic Imaging , 10 ( 2 ) : 394 â€“ 398 , 2001 . [ 6 ] Joe Yuchieh Lin , Rui Song , Chi - Hao Wu , TsungJung Liu , Haiqiang Wang , and C . - C . Jay Kuo . Mcl - v : A streaming video quality assessment database . Journal of Visual Communication and Image Representation , 30 : 1 â€“ 9 , 2015 . [ 7 ] Nikolay Ponomarenko , Lina Jin , Oleg Ieremeiev , Vladimir Lukin , Karen Egiazar - ian , Jaakko Astola , Benoit Vozel , Kacem Chehdi , Marco Carli , Federica Battisti , and C . - C . Jay Kuo . Image database tid2013 : Peculiarities , results and perspectives . Signal Processing : Image Communication , 30 : 57 â€“ 77 , 2015 . [ 8 ] Jing Li , Rafal Mantiuk , Junle Wang , Suiyi Ling , and Patrick Le Callet . Hybrid - mst : A hybrid active sampling strategy for pairwise preference aggregation . In Advances in NeuralInformation Processing Systems , volume 31 . CurranAssociates , Inc . , 2018 . [ 9 ] Aliaksei Mikhailiuk , Clifford Wilmot , Maria Perez - Ortiz , Dingcheng Yue , and RafaÅ‚ K Mantiuk . Active sampling for pairwise comparisons via approximate message passing and information gain maximization . In International Conference on Pattern Recognition ( ICPR ) , pages 2559 â€“ 2566 . IEEE , 2021 . [ 10 ] Qianqian Xu , Jiechao Xiong , Xi Chen , Qingming Huang , and Yuan Yao . Hodger - ank with information maximization for crowdsourced pairwise ranking aggrega - tion . In AAAI Conference on Artificial Intelligence , volume 32 , 2018 . [ 11 ] Suiyi Ling , Jing Li , Anne Flore Perrin , Zhi Li , LukÃ¡Å¡ Krasula , and Patrick Le Callet . Strategy for boosting pair comparison and improving quality assessment accuracy . arXiv preprint arXiv : 2010 . 00370 , 2020 . [ 12 ] Peng Ye and David Doermann . Active sampling for subjective image quality assessment . In IEEE conference on computer vision and pattern recognition , pages 4249 â€“ 4256 , 2014 . [ 13 ] Xi Chen , Paul N Bennett , Kevyn Collins - Thompson , and Eric Horvitz . Pairwise ranking aggregation in a crowdsourced setting . In ACM international confer - ence on Web search and data mining , pages 193 â€“ 202 , New York , NY , USA , 2013 . Association for Computing Machinery . [ 14 ] Zhiwei Fan , Tingting Jiang , and Tiejun Huang . Active sampling exploiting reli - able informativeness for subjective image quality assessment based on pairwise comparison . IEEE Transactions on Multimedia , 19 ( 12 ) : 2720 â€“ 2735 , 2017 . [ 15 ] Michela Testolina , Evgeniy Upenik , JoÃ£o Ascenso , Fernando Pereira , and Touradj Ebrahimi . Performance evaluation of objective image quality metrics on conven - tional and learning - based compression artifacts . In International Conference on Quality of Multimedia Experience ( QoMEX ) , pages 109 â€“ 114 , 2021 . [ 16 ] Fabian Pedregosa , Gael Varoquaux , Alexandre Gramfort , Vincent Michel , Bertrand Thirion , Olivier Grisel , Mathieu Blondel , Peter Prettenhofer , Ron Weiss , Vincent Dubourg , Jake . Vanderplas , Alexandre Passos , David Courna - peau , Matthieu Brucher , Matthieu Perrot , and Edouard Duchesnay . Scikit - learn : Machine learningin Python . Journal ofMachine LearningResearch , 12 : 2825 â€“ 2830 , 2011 . [ 17 ] CorinnaCortesandVladimirVapnik . Support - vectornetworks . Machinelearning , 20 : 273 â€“ 297 , 1995 . [ 18 ] Tianqi Chen and Carlos Guestrin . Xgboost : A scalable tree boosting system . In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD â€™16 , page 785 â€“ 794 , New York , NY , USA , 2016 . Association for Computing Machinery . [ 19 ] Alex J Smola and Bernhard SchÃ¶lkopf . A tutorial on support vector regression . Statistics and computing , 14 : 199 â€“ 222 , 2004 . [ 20 ] Zhou Wang and Qiang Li . Information content weighting for perceptual image quality assessment . IEEE Transactions on image processing , 20 ( 5 ) : 1185 â€“ 1198 , 2010 . [ 21 ] Zhou Wang , Eero . P . Simoncelli , and Alan . C . Bovik . Multiscale structural simi - larity for image quality assessment . In Asilomar Conference on Signals , Systems Computers , volume 2 , pages 1398 â€“ 1402 , 2003 . [ 22 ] LinZhang , LeiZhang , XuanqinMou , andDavidZhang . Fsim : Afeaturesimilarity index for image quality assessment . IEEE Transactions on Image Processing , 20 ( 8 ) : 2378 â€“ 2386 , 2011 . [ 23 ] Nikolay N . Ponomarenko , Flavia Silvestri , Karen O . Egiazarian , Marco Carli , Jaakko Astola , and Vladimir V . Lukin . On between - coefficient contrast masking of dct basis functions . In International Workshop on Video Processing and Quality Metrics for Consumer Electronics , 2007 . [ 24 ] Hamid Rahim . Sheikh and Alan . Bovik . Image information and visual quality . In 2004 IEEE International Conference on Acoustics , Speech , and Signal Process - ing , volume 3 , pages iii â€“ 709 â€“ 12 vol . 3 , Los Alamitos , CA , USA , may 2004 . IEEE Computer Society . [ 25 ] Zhi Li , Anne Aaron , Ioannis Katsavounidis , Anush Moorthy , and Megha Manohara . Toward a practical perceptual video quality metric . https : / / netflixtechblog . com / toward - a - practical - perceptual - video - quality - metric - 653f208b9652 . Accessed : 2023 - 01 - 30 . [ 26 ] Valero Laparra , Johannes BallÃ© , Alexander Berardino , and Eero P Simoncelii . Perceptual image quality assessment using a normalized laplacian pyramid . In Human Vision and Electronic Imaging , pages 43 â€“ 48 . Society for Imaging Science and Technology , 2016 . [ 27 ] Ralph Allan Bradley and Milton E . Terry . Rank analysis of incomplete block designs : I . the method of paired comparisons . Biometrika , 39 ( 3 / 4 ) : 324 â€“ 345 , 1952 . [ 28 ] Louis L Thurstone . A law of comparative judgment . Psychological review , 34 ( 4 ) : 273 , 1927 . [ 29 ] Peter Emerson . The original borda count and partial voting . Social Choice and Welfare , 40 , 02 2013 . [ 30 ] Ralph Allan Bradley . Rank analysis of incomplete block designs : Iii some large - sample results on estimation and power for a method of paired comparisons . Biometrika , 42 ( 3 / 4 ) : 450 â€“ 470 , 1955 . [ 31 ] Guillaume LemaÃ®tre , Fernando Nogueira , and Christos K . Aridas . Imbalanced - learn : A python toolbox to tackle the curse of imbalanced datasets in machine learning . Journal of Machine Learning Research , 18 ( 17 ) : 1 â€“ 5 , 2017 . [ 32 ] Qianqian Xu , Qingming Huang , and Yuan Yao . Online crowdsourcing subjective image quality assessment . In ACM International Conference on Multimedia , MM â€™12 , page 359 â€“ 368 , 2012 . [ 33 ] Hamid . Rahim . Sheikh , M . Farooq . Sabir , andAlan . C . Bovik . Astatisticalevaluation of recent full reference image quality assessment algorithms . IEEE Transactions on Image Processing , 15 ( 11 ) : 3440 â€“ 3451 , 2006 . [ 34 ] Patrick Le Callet and Florent Autrusseau . Subjective quality assessment IRC - CyN / IVC database . [ 35 ] EktaPrashnani , HongCai , YasaminMostofi , andPradeepSen . PieApp : Perceptual image - error assessment through pairwise preference . In IEEE Conference on Computer Vision and Pattern Recognition , pages 1808 â€“ 1817 , June 2018 . [ 36 ] Hui Men , Hanhe Lin , Mohsen Jenadeleh , and Dietmar Saupe . Subjective image quality assessment with boosted triplet comparisons . IEEE Access , 9 : 138939 â€“ 138975 , 2021 . [ 37 ] Shima Mohammadi and JoÃ£o Ascenso . Perceptual impact of the loss function on deep - learning image coding performance . In Picture Coding Symposium , pages 37 â€“ 41 , 2022 . 6684