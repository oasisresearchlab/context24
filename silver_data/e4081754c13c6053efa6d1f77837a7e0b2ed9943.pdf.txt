Topological reversibility and causality in feed - forward networks Bernat Corominas - Murtra 1 , Carlos Rodr´ıguez - Caso 1 , Joaquin Go˜ni 2 and Ricard V . Sol´e 1 , 3 , 4 1 ICREA - Complex Systems Lab , Universitat Pompeu Fabra ( Parc de Recerca Biom ` edica de Barcelona ) . Dr Aiguader 88 , 08003 Barcelona , Spain 2 Functional Neuroimaging Lab . Department of Neurosciences . Center for Applied Medical Research . University of Navarra . Pamplona , Spain 3 Santa Fe Institute , 1399 Hyde Park Road , New Mexico 87501 , USA 4 Institut de Biologia Evolutiva . CSIC - UPF . Passeig Mar´ıtim de la Barceloneta , 37 - 49 , 08003 Barcelona , Spain . Systems whose organization displays causal asymmetry constraints , from evolutionary trees to river basins or transport networks , can be often described in terms of directed paths ( causal ﬂows ) on a discrete state space . Such a set of paths deﬁnes a feed - forward , acyclic network . A key problem associated with these systems involves characterizing their intrinsic degree of path reversibility : given an end node in the graph , what is the uncertainty of recovering the process backwards until the origin ? Here we propose a novel concept , topological reversibility , which rigorously weigths such uncertainty in path dependency quantiﬁed as the minimum amount of information required to successfully revert a causal path . Within the proposed framework we also analytically characterize limit cases for both topologically reversible and maximally entropic structures . The relevance of these measures within the context of evolutionary dynamics is highlighted . Keywords : I . INTRODUCTION Causality is the fundamental principle pervading dy - namical processes . Any set of time - correlated events , from the development of an organism to historical changes , deﬁnes a feed - forward structure of causal re - lations captured by a family of complex networks called directed acyclic graphs ( DAGs ) . Their structure has re - cently attracted the interest of researchers [ 1 – 4 ] since DAGs represent time - ordered processes as well as a broad number of natural and artiﬁcial systems . Examples would include simple electronic circuits [ 5 ] , feed - forward neural [ 6 ] and transmission networks [ 7 ] , river basins [ 8 ] , or even some food webs and chemical structures [ 9 ] . A paradigmatic example of a causal structure is the chart of the relations among states followed by a com - putational process through time . Intimately linked to the topology of the computational chart of consecutive states , a fundamental feature of computations is its de - gree of logical reversibility [ 10 , 11 ] . Indeed , it is said that a process is logically reversible when , if reverting the ﬂow of causality , i . e . going backwards from the computational outputs to their inputs , we can unambiguously recover the causal structure of the process . Roughly speaking , if we have a computer performing a function g : N → N and we can unambiguously determine the input u from the only knowledge of the value v = g ( u ) , we say that the function is logically reversible . Otherwise , if there is uncertainty in determining u from the only knowledge of v , we say that the function is logically irreversible , and thus , additional information is needed to successfully re - construct a given computational path . Analogously , the potential scenarios emerging from an evolutionary process raise similar questions . Within evo - lutionary biology , a relevant problem is how predictable is evolutionary dynamics . In particular , it has been asked what would be the result of going backwards and ”re - playing the tape of evolution” [ 12 , 13 ] . Since this question pervades the problem of how uncertain or pre - dictable is a given evolutionary path , it seems desirable to actually provide a foundational framework . In this paper , we analytically extend the concept of logical reversibility to the study of any causal structure having no cyclic topologies , thereby deﬁning a broader concept to be named topological reversibility . Whereas thermodynamical irreversibility implies thermodynami - cal entropy production [ 14 , 15 ] , topological irreversibil - ity implies statistical entropy production . In general , we will say that a DAG is topologically reversible if we can unambiguously recover a path going backwards from any element to the origin . Genealogies and phylogenies are examples of tree - like structures where a chronological or - der can be established among the events and an unam - biguous reconstruction of the lineage can be performed for every element of the graph [ 16 ] . Following this argu - ment , we will label a graph as topologically irreversible when some uncertainty is observed in the reconstruction of trajectories . As shown below , the entropy presented here weigths the extra amount of information that would be required to recover the causal ﬂow backwards . Information mea - sures are not new in the study of complex networks [ 17 – 23 ] , although such measures accounted for connectivity correlations [ 18 , 19 , 21 , 22 ] or were used to character - ize a Gibbsian formulation of the statistical mechanics of complex networks [ 17 ] . We ﬁnally note that the starting point of our formalism resembles the classical theory of Bayesian networks . However , the particular treatment of reversibility proposed here is qualitatively diﬀerent from the concept of uncertainty used in such a framework and closer to the one described in [ 20 ] . The paper is organized as follows : In section II we pro - vide the basic concepts underlying our analytical deriva - a r X i v : 1 0 07 . 1829v1 [ c ond - m a t . d i s - nn ] 1 2 J u l 2010 2 tions . Section III provides the general mathematical def - inition of topological reversibility and the general expres - sion for the average uncertainty associated to the rever - sion of the causal ﬂow . This is consistently derived from the properties of the adjacency matrix . In section IV we consider two limit cases , ﬁnding the exact analytic form for their entropies and predicting the uncertain conﬁgu - ration . Finally , in section V we outline the generality and relevance of our results in terms of characterizing DAG structure . II . THEORETICAL BACKGROUND The theoretical roots of this paper stem from fun - damental notions of directed graph theory [ 24 , 25 ] , or - dered set theory [ 26 , 27 ] and information theory [ 28 – 31 ] . Speciﬁcally , we make use of Shannon’s entropy which , as originally deﬁned , quantiﬁes the uncertainty associated to certain collections of random events [ 28 , 30 ] . In our framework , the entropy in a given feed - forward graph measures the uncertainty in reversing the causal ﬂow de - picted by the arrows [ 39 ] . A . Directed graphs and orderings Let G ( V , E ) be a directed graph , being V = { v 1 , . . . , v n } , | V | = n , the set of nodes , and E = { (cid:104) v k , v i (cid:105) , . . . , (cid:104) v j , v l (cid:105) } the set of edges - where the order , (cid:104) v k , v i (cid:105) implies that there is an arrow in the following direction : v k → v i . Given a node v i ∈ V , the num - ber of outgoing links , to be written as k out ( v i ) , is called the out - degree of v i and the number of ingoing links of v i is called the in - degree of v i , written as k in ( v i ) . The adjacency matrix of a given graph G , A ( G ) is deﬁned as A ij ( G ) = 1 ↔ (cid:104) v i , v j (cid:105) ∈ E ; and A ij ( G ) = 0 other - wise . Through the adjacency matrix , k in and k out are computed as k in ( v i ) = (cid:88) j ≤ n A ji ( G ) ; k out ( v i ) = (cid:88) j ≤ n A ij ( G ) . ( 1 ) Furthermore , we will use the known relation between the k - th power of the adjacency matrix and the number of paths of length k going from a given node v i to a given node v j Speciﬁcally , ( A ( G ) ) kij = ( k times (cid:122) (cid:125)(cid:124) (cid:123) A ( G ) × . . . × A ( G ) ) ij is the number of paths of length k going from node v i to node v j [ 25 ] . A feed - forward or directed acyclic graph is a directed graph characterized by the absence of cycles : If there is a directed path from v i to v k ( i . e . , there is a ﬁnite sequence (cid:104) v i , v j (cid:105) , (cid:104) v j , v l (cid:105) , (cid:104) v l , v s (cid:105) , . . . , (cid:104) v m , v k (cid:105) ∈ E ) then , there is no directed path from v k to v i . Conversely , the matrix A T ( G ) depicts a DAG with the same underlying structure but having all the arrows ( and thus , the causal ﬂow ) inverted . Given its acyclic nature , one can ﬁnd a ﬁnite value L ( G ) as follows : L ( G ) = max { k : ( ∃ v i , v j ∈ V : ( A ( G ) ) kij (cid:54) = 0 ) } . ( 2 ) It is easy to see that L ( G ) is the length of the longest path of the graph . The existence of such L ( G ) can be seen as a test for acyclicity . However , the use of leaf - removal algorithms [ 32 , 33 ] , i . e . the iterative pruning of nodes without outgoing links , is by far more suitable than the above method , in terms of computational costs . In a DAG , a leaf - removal algorithm removes completely the graph in a ﬁnite number of iterations , speciﬁcally , in L ( G ) iterations - see eq . ( 2 ) . Now we study the interplay between DAGs and order relations . Borrowing concepts from order theory [ 27 ] , we deﬁne the following set : M = { v i ∈ V : k in ( v i ) = 0 } , ( 3 ) to be named the set of maximal nodes of G , by which | M | = m . The set of all paths π 1 , . . . , π s , s ≥ | E | , from M to a given node v i ∈ V \ M is indicated as Π ( G ) . Given a node v i ∈ V \ M , the set of all paths from M to v i is written as Π ( v i ) ⊆ Π ( G ) . Furthermore , we will deﬁne the set v ( π k ) as the set of all nodes participating in this path , except the maximal one . Additionally , one can deﬁne the set of nodes with k out = 0 as the set of minimal nodes of G , to be named µ . Notice that the absence of cycles implies that m ≥ 1 and that the set of minimals µ must also contain at least one element - see ﬁg . ( 1a ) . Attending to the node relations depicted by the ar - rows , and due to the acyclic property , at least one node ordering can be deﬁned , establishing a natural link be - tween order theory and DAGs . This order is achieved by labeling all the nodes with sequential natural numbers and obtaining a conﬁguration such that : ( ∀(cid:104) v i , v j (cid:105) ∈ E ) ( i < j ) . ( 4 ) Accordingly , DAGs are ordered graphs [ 2 ] . However , as order relations imply transitivity , it is not the DAG but its transitive closure what properly deﬁnes the order rela - tion among the elements of V . The transitive closure of G ( see ﬁg . 1b ) , to be written as T ( G ) = ( V T , E T ) is deﬁned as follows : Any pair of nodes v i , v k ∈ V by which there is at least one path going from v i to v k are connected through a link (cid:104) v i , v k (cid:105) in T ( G ) . In this framework , for a given number of maximal nodes , in the transitive closure the addition of a link either creates a cycle or destroys a maximal or minimal node . If the pairs deﬁning the set of links of T ( G ) are conceived as the elements of a set rela - tion E T ⊂ V × V , such a relation satisﬁes the following three properties : i ) (cid:64) (cid:104) v k , v k (cid:105) , ii ) ( (cid:104) v i , v k (cid:105) ∈ E T ) ⇒ ( (cid:104) v k , v i (cid:105) / ∈ E T ) , iii ) ( (cid:104) v i , v k (cid:105) ∈ E T ∧ (cid:104) v k , v j (cid:105) ∈ E T ) ⇒ ( (cid:104) v i , v j (cid:105) ∈ E T ) . 3 a c T ( G ) M µ V \ M b v 1 v 2 v 3 v 4 v 5 v 6 FIG . 1 : Some illustrative DAGs . A topologically irreversible DAG G ( V , E ) , where M denotes the set of maximals , µ the set of minimals and the V \ M set the set of non - maximals ( a ) . The respective transitive closure , T ( G ) is shown in ( b ) , A linear ordering of the set V \ M of G ( V , E ) is displayed in ( c ) where any node of the maximal set is connected to any node of the set V \ M . This is an special structure displaying maximal entropy ( see text ) . The DAG deﬁnition implies that E directly satisﬁes the two ﬁrst conditions whilst the third one ( transitivity ) is only warranted for E T . Thus , only E T holds all require - ments to be an order relation , speciﬁcally , a strict partial order . The transitive closure of a given DAG can be ob - tained by means of the so - called Warshall’s algorithm [ 25 ] . Finally , a subgraph F ( V F , E F ) ⊆ G is said to be lin - early ordered or totally ordered provided that for all pairs of nodes v i , v k ∈ V F such that k < i , then (cid:104) v k , v i (cid:105) ∈ E F . ( 5 ) Let us notice that if we understand E F as a set relation E F ⊂ V F × V F , E F is a strict linear order . If G is linearly ordered and W ⊂ G , we refer to G as a topological sort of W [ 25 ] . B . Uncertainty According to classical information theory [ 28 – 31 ] , let us consider a system S with n possible states , whose oc - currences are governed by a random variable X with an associated probability mass function formed by p 1 , . . . , p n . According to the standard formalization , the uncertainty or entropy associated to X , to be written as H ( X ) , is : H ( X ) = − (cid:88) i ≤ n p i log p i , ( 6 ) which is actually an average of log ( 1 / p ( X ) ) among all events of S , namely , H ( X ) = (cid:104) log ( 1 / p ( X ) ) (cid:105) , where (cid:104) . . . (cid:105) is the expectation or average of the random quantity between parentheses . As a concave function , the en - tropy satisﬁes the so - called Jensen’s inequality [ 29 ] , which reads : (cid:28) log 1 p ( X ) (cid:29) ≤ log (cid:28) 1 p ( X ) (cid:29) ≤ log n , ( 7 ) The maximum value log n is achieved for p i = 1 / n for all i = ( 1 , . . . , n ) . Jensen’s inequality provides an upper bound on the entropy that will be used below . Anal - ogously , we can deﬁne the conditional entropy . Given another system S (cid:48) containing n (cid:48) values or choices , whose behavior is governed by a random variable Y , let P ( s (cid:48) i | s j ) be the conditional probability of obtaining Y = s (cid:48) i ∈ S (cid:48) if we already know X = s j ∈ S . Then , the conditional en - tropy of Y from X , to be written as H ( Y | X ) , is deﬁned as : H ( Y | X ) = − (cid:88) j ≤ n p j (cid:88) i ≤ n (cid:48) P ( s (cid:48) i | s j ) log P ( s (cid:48) i | s j ) . ( 8 ) which is typically interpreted as a noise term in informa - tion theory . Such a noise term can be interpreted as the minimum amount of extra bits needed to unambiguously determine the input set from the only knowledge of the output set . This will be the key quantity of our paper , for it accounts for the dissipation of information in a given process . III . TOPOLOGICAL REVERSIBILITY AND ENTROPY Let us imagine that a node v i ∈ V \ M of a given DAG G , receives the visit of a random walker that follows the 4 a b ? ? v 6 v 6 FIG . 2 : Uncertainty in the reversal of causal ﬂows in a DAG . Notice that more than a pathway , with more or less proba - bility to be chosen , connect maximals from each terminal ( a ) . Given a node ( v 6 ) receiving two inputs , we consider two dif - ferent alternatives to go backwards . The uncertainty in this particular case is obtained by computing h L ( v i ) from eq . ( 14 ) , i . e . , h L ( v 6 ) = log 2 assuming equiprobability in the selection ( b ) . ﬂow chart depicted by the DAG . We only know that it began its walk at a given maximal node and it followed a downstream random path attending to the directions of the arrows to reach the node v i . Suppose also that the global structure of the graph is unknown . What is the uncertainty associated to the followed path ? In other words , what is the amount of information we need , on average , to successfully perform the backward process ? A . The deﬁnition of entropy As we mentioned above , the starting point of our derivation is close to treatment of Bayesian networks [ 34 ] . In our approach , the ﬁrst task is to deﬁne the probabil - ity to follow a given path π k ∈ Π ( v i ) when reverting the process . Let v ( π k ) be the set of nodes participating in the path π k except the maximal ones . Maximal nodes are not included in this set because they are the ends of the path of the reversal process . The probability to chose such a path from node v i by making a random decision at every crossing when reverting the causal ﬂow will be : P ( π k | v i ) = (cid:89) v i ∈ v ( π k ) 1 k in ( v j ) . ( 9 ) Consistently : (cid:88) π k ∈ Π ( v i )   (cid:89) v j ∈ v ( π k ) 1 k in ( v j )   = 1 . As P is a probability distribution , we can compute the uncertainty associated to a reversal of the causal ﬂow , starting the reversion process from a given node v i ∈ V \ M , to be written as h ( v i ) : h ( v i ) = − (cid:88) π k ∈ Π ( v i ) P ( π k | v i ) log P ( π k | v i ) ( 10 ) The overall uncertainty of G , written as H ( G ) , is com - puted by averaging h over all non - maximal nodes , i . e : H ( G ) = − (cid:88) v i ∈ V \ M p ( v i ) (cid:88) π k ∈ Π ( v i ) P ( π k | v i ) log P ( π k | v i ) = (cid:88) v i ∈ V \ M p ( v i ) h ( v i ) . ( 11 ) B . The transition matrix Φ and its relation to the adjacency matrix The main combinatorial object of our approach is not the adjacency matrix but instead a mathematical repre - sentation of the probability to visit a node v i ∈ V \ M starting the backward ﬂow from a given , diﬀerent node v k ∈ V \ M regardless the distance separating them . As we shall see , this combinatorial information can be en - coded in a matrix , to be named transition matrix Φ and we can explicitly obtain it from A ( G ) . We begin by deﬁn - ing V ( Π ( v j ) ) ≡ (cid:91) π k ∈ Π ( v j ) v ( π k ) , ( 12 ) and we can see that : h ( v i ) = − (cid:88) π k ∈ Π ( v i ) P ( π k | v i ) log P ( π k | v i ) = (cid:88) π k ∈ Π ( v i )   (cid:88) v j ∈ v ( π k ) P ( π k | v i ) log ( k in ( v j ) )   = (cid:88) v j ∈ V ( Π i ) log ( k in ( v j ) )   (cid:88) π k : v j ∈ v ( π k ) P ( π k | v i )   = (cid:88) v k ∈ V \ M φ ik ( G ) h L ( v k ) . ( 13 ) Let us explain eq . ( 13 ) and its consequences . First we deﬁne h L ( v i ) as : h L ( v i ) = log ( k in ( v i ) ) . , ( 14 ) where L indicates the amount of local entropy intro - duced in a given node when performing the reversion process - see ﬁg ( 2 ) . Thereby , it is the amount of in - formation needed to properly revert the ﬂow backwards when a bifurcation point is reached having k in possible choices . Secondly , we deﬁne φ ik as the coeﬃcients of a ( n − m ) × ( n − m ) matrix Φ ( G ) = [ φ ik ( G ) ] , i . e . our tran - sition matrix G : φ ij ( G ) = (cid:88) π k : v j ∈ v ( π k ) P ( π k | v i ) . 5 This represents the probability to reach v j starting from v i . Now we derive the general expression for Φ . The derivation allows us to obtain a consistent mathematical deﬁnition of the transition matrix in terms of A ( G ) . We ﬁrst notice two important facts linking paths and the powers of the adjacency matrix that are only generically valid in DAG - like networks . First , we observe that : | Π ( v i ) | = (cid:88) j ≤ L ( G ) (cid:88) l : v l ∈ M ( A T ( G ) ) jil , ( 15 ) being L ( G ) the length of the longest path of the graph as deﬁned by ( 2 ) . Analogously , the number of paths of Π ( v i ) crossing v k , to be written as α ik is : α ik ≡ | { π j ∈ Π ( v i ) : v k ∈ v i ( π j ) } | = (cid:88) j ≤ L ( G ) (cid:0) A T ( G ) (cid:1) j ik . ( 16 ) The above quantities provide the number of paths . To compute the probability to reach a given node , we have to take into account the probability to follow a given path containing such a node , deﬁned in ( 9 ) . To rigorously connect it to the adjacency matrix , we ﬁrst deﬁne an auxiliary , ( n − m ) × ( n − m ) matrix B ( G ) , namely : B ( G ) ij = ( A ij ( G ) )  (cid:88) j ≤ n A ij ( G )   − 1 = A ij ( G ) k in ( v i ) , ( 17 ) where v i , v j ∈ V \ M . From this deﬁnition , we obtain the explicit dependency of Φ from the adjacency matrix , namely [ 40 ] , φ ij ( G ) = (cid:88) k ≤ L ( G ) (cid:0) B T ( G ) (cid:1) k ij . ( 18 ) and accordingly , we have φ ii ( G ) = (cid:0) B T ( G ) (cid:1) 0 ii = 1 . ( 19 ) It is worth to mention that Φ ( G ) resembles the transi - tion matrix related to the concept of information mobil - ity [ 20 ] . In the general case of non - directed graphs , one can assume the presence of paths of arbitrary length , which leads ( using a correction factor tied to the length of the path ) up to an asymptotic form of the transition matrix in terms of the exponential of the adjacency ma - trix . However , the intrinsic ﬁnite nature of the paths in a given DAG makes the above asymptotic treatment non viable . C . The general form of the Entropy Let us now deﬁne the overall entropy in a compact form , only depending on the adjacency matrix of the graph . From eqs . ( 8 , 11 , 13 ) , we obtain H ( G ) = (cid:88) v i ∈ V \ M p ( v i ) (cid:88) v k ∈ V \ M φ ik ( G ) h L ( v k ) . ( 20 ) This is the central equation of this paper . This measure quantiﬁes the additional information ( other than topo - logical one ) to properly revert the causal ﬂow . We ob - serve that this expression is a noise term within stan - dard information theory [ 28 ] . In this equation we have been able to decouple the combinatorial term associated to the multiplicity of paths at one hand , and the par - ticular contribution to the overall uncertainty of every node , at the other hand . The former is fulﬁlled by the matrix Φ , which encodes combinatorial properties of the system , and how they inﬂuence in the computation of the entropies . The latter is obtained from the set of local entropies h L ( v 1 ) , . . . , h L ( v n − m ) . These terms account for the contribution of local topology - i . e . the uncertainty when choosing an incoming link at the node level in the reversion of the causal ﬂow - to the overall entropy . This uncoupling is a consequence of the extensive property of the entropy and , putting aside its conceptual inter - est , simpliﬁes all derivations related to the uncertainties , since we are not forced to compute the complex series arising in the brute - force calculation of entropies . This general expression of the entropy can be simpliﬁed if we assume that ∀ v i ∈ V \ M , p ( v i ) = 1 / ( n − m ) . Therefore , by deﬁning Q ( G ) = (cid:88) v i ∈ V \ M (cid:88) v k ∈ V \ M φ ik ( G ) h L ( v k ) ( 21 ) and thus H ( G ) is expressed as : H ( G ) = 1 n − mQ ( G ) ( 22 ) Finally , we recall that the above entropy is bounded by Jensen’s inequality ( 7 ) i . e . , H ( G ) ≤ 1 n − m (cid:88) v i ∈ V \ M log ( | Π ( v i ) | ) . ( 23 ) Notice that the quantity on the right side of eq . ( 23 ) is the uncertainty obtained by considering all paths from M to v i equally likely to occur . D . Topological reversibility Having deﬁned an appropriate and well grounded en - tropy measure , now we can discuss the meaning of topo - logical ( ir ) reversibility . Let us ﬁrst make a qualitative link with standard theory of irreversible thermodynam - ics , where irreversibility is tied to the parameter of en - tropy production σ s in the entropy balance equation [ 15 ] . Here , σ s = 0 depicts thermodynamically reversible pro - cesses , whereas σ s > 0 appears in irreversible processes [ 14 , 15 ] . Irreversibility is rooted in the impossibility of re - verting the process without generating a negative amount of entropy , which contradicts to the second law of ther - modynamics . Consistently , we will call topologically re - versible those DAG structures such that H ( G ) = 0 . 6 In those structures ( they belong to the set of trees , as we shall see in the following section ) no ambiguity arises when performing the reversion process . On the contrary , a given DAG by which H ( G ) > 0 will be referred to as topologically irreversible . DAGs having H ( G ) > 0 display some degree of uncertainty tak - ing the causal ﬂow backwards , since the reversion pro - cess is subject to some random inevitable decisions . In these cases , H ( G ) is the average of the amount of ex - tra information needed to successfully perform the pro - cess backwards . Similarly , the successful reversion of a thermodynamically irreversible process would imply the ( irreversible ) addition of external energy , or that the re - version of a logically irreversible computation requires an extra amount of external information to solve the ambi - guity arising in rewinding the chain of computations . In this context , for example , reversible computation is de - ﬁned by considering a system of storage of history of the computational process [ 10 ] . Furthermore , we ob - serve that , roughly speaking , we can associate the logical ( ir ) reversibility of a computational process to the topo - logical ( ir ) reversibility of its DAG representation . In our study , the adjective topological arises from the fact that we only use topological information to compute the un - certainty . Thus , we deliberately neglect the active role that a given node can play as , for example , a processing unit , or the diﬀerent weights of the paths . However , it is worth to mention that entropy can be generalized for DAGs where links are weighted by a probability to be chosen in the process of reaching the maximal . IV . LIMIT CASES : MAXIMUM AND MINIMUM UNCERTAINTY Let us illustrate our previous results by exploring two limit cases , namely DAGs having zero or maximal un - certainty . In this section we identify those feed - forward structures which , containing n nodes and without a pre - deﬁned number of links , minimize or maximize the above uncertainties . In this way , for example , a chain having m = 1 will display H ( G ) = 0 , whereas its somehow opposite graph , the star having m = n − 1 will have H ( G ) = log ( n − 1 ) . The derivation of the limit scenar - ios will be more sophisticated , due to the active role of combinatorics in deﬁning the paths . The minimum un - certainties are obtained when the graph G is a special kind of tree , to be described below . Afterwards , we also derive the graph conﬁguration with maximum entropy . The conceptual starting point of this derivation is the graph representation of the linear order . a b FIG . 3 : A topological reversible structure featured by a tree DAG structure , H ( G ) = 0 ( a ) . A topologically irreversible DAG featured by a star DAG with m = n − 1 . Notice that for a star graph H ( G ) = log ( n − 1 ) where n = 7 in this particular case ( b ) . A . Zero Uncertainty : Trees Imagine a random walker exploring a ( directed ) tree containing only a single maximal ( ﬁg . 3a ) . From such a maximal node , there exists only one path to a given node . In the evolutionary context , a single ancestor is at the root of all evolutionary tree [ 35 ] . Thus , the pro - cess of recovering the history of the random walker up to its initial condition is completely deterministic , and no uncertainty can be associated to it - in purely topological terms . Formally , we recognize two deﬁning features on trees , namely : • m = 1 • ( ∀ v i ∈ V \ M ) ( k in ( v i ) = 1 ) . We thus conclude that there is no uncertainty in recover - ing the ﬂow , since the two reported properties are enough to conclude that there is 1 and only 1 path to go from M to any v i ∈ V \ M . This agrees with the intuitive idea that trees are perfect hierarchical structures . This result complements the more standard scenario of the forward , downstream scenario paths followed by a random walker on a tree [ 16 ] . It is worth noting that evolutionary trees , particularly in unicellular organisms , have been found to be a poor representation of the actual evolutionary process [ 36 , 37 ] . B . Maximum Uncertainty Now we consider the maximum entropic scenario . For this purpose , we cut the problem in two pieces : First , we constructively obtain the feed forward graph containing m maximal nodes maximizing H ( G ) . Once we identiﬁed such a feed forward conﬁguration , we ask for the m that maximizes such a quantity . 7 1 . The linear ordering in V \ M . Let G be a feed - forward organized graph containing n nodes , where m of them are maximal . Since for the en - tropy computation all nodes become indistinguishable , let g ( m , n ) be the ensemble of diﬀerent possible feed - forward conﬁgurations containing n nodes , where m of them are maximal . We are looking for a graph , to be written as ˜ G ∈ g ( n , m ) , such that ∀G i ∈ g ( m , n ) : G i ⊆ ˜ G , ( 24 ) i . e . , a graph containing all possible links , preserving the number of maximal nodes . This implies , as deﬁned in section II A , eq . ( 5 ) , that we must add links to the set V \ M until it becomes linearly ordered , attending to a labeling of nodes which respect the ordering depicted by the feed - forward graph ( see ﬁg . 1c ) . Once we have the set of nodes V \ M linearly ordered , we proceed to generate a link from any node v i ∈ M to any node v k ∈ V \ M . We thus obtain a feed forward graph containing m maximal nodes and only 1 minimal node . In the above constructed graph , any new link creates a cycle or destroys a maximal vertex . Furthermore , given two ﬁxed values of m and n , it is straightforward to demonstrate that it maximizes any entropy based on paths : Any feed - forward graph of the ensemble g ( m , n ) other than ˜ G is obtained by removing edges of ˜ G . This edge removal process will necessarily result in a reduction of uncertainty . For the sake of clarity we diﬀerentiate the labeling of M and V \ M when working with ˜ G . Speciﬁcally , nodes v i ∈ V \ M will be labeled sequentially from 1 to n − m respecting the ordering deﬁned in eq . ( 4 ) . This labeling will be widely used in the forthcoming sections . Further - more , we recall that no special labeling other than dif - ferent natural numbers is needed for v k ∈ M , since there will be no ambiguous situations . Given the labeling pro - posed above , and starting from eq . ( 15 ) the number of paths in ˜ G from M to v i ∈ V \ M will be : | Π ( v i ) | = (cid:88) j ≤ L ( G ) (cid:88) l : v l ∈ M ( A T ( G ) ) jil = (cid:88) l : v l ∈ M (cid:88) j ≤ i (cid:18) i j (cid:19) = m  (cid:88) j ≤ i (cid:18) i j (cid:19) = m · 2 i − 1 . ( 25 ) 2 . The explicit form of entropies in the linear ordering of V \ M . We ﬁrst bound H ( ˜ G ) using Jensen’s inequality . Indeed , from eq . ( 7 ) we can derive an upper bound for H ( ˜ G ) , namely H ( ˜ G ) ≤ log m + log 2 2 ( n − m − 1 ) . ( 26 ) We can go further , ﬁrst computing the probabilities deﬁn - ing the matrix Φ ( ˜ G ) . To compute these probabilities , let us suppose we are in node v i ∈ V \ M . The ﬁrst ob - servation is that the probability to reach one maximal is 1 m . What about v 1 , i . e . , the ﬁrst node we ﬁnd after the maximal set ? We observe that , from the node v i , the situation is completely analogous to the situation where there are m + 1 maximal nodes , since the probability to pass through v 1 does not depend on what happens above v 1 . Therefore : φ i 1 = 1 m + 1 . and running the reasoning from v 1 to v i − 1 , we ﬁnd that : φ ik = 1 m + k ( k < i ) . Interestingly , for k < i , φ ik is invariant , no matter the value of i . This leads matrix Φ ( ˜ G ) to be : Φ ( ˜ G ) =   1 0 0 . . . 0 1 m + 1 1 0 . . . 0 1 m + 1 1 m + 2 1 . . . 0 . . . . . . . . . . . . 1 m + 1 1 m + 2 1 m + 3 . . 1   , ( 27 ) and the ﬁnal expression is obtained by observing that h L ( v k ) = log ( m + k − 1 ) , and therefore , inserting it and ( 27 ) into eq . ( 22 ) , we obtain after some algebra : H ( ˜ G ) = n n − m (cid:88) i ≤ n − m f ( v i ) , ( 28 ) where f ( v i ) is a function f : V \ M → R + , f ( v i ) = log ( m + i − 1 ) m + i . ( 29 ) We can see that the value entropy is reduced to the com - putation of the average of f over the set V \ M . If ˜ G contains n nodes , being m of them the maximal ones we will refer to this average as (cid:104) f ( n , m ) (cid:105) , deﬁned as : (cid:104) f ( n , m ) (cid:105) = 1 n − m (cid:88) i ≤ n − m f ( v i ) ( 30 ) 3 . Absolute maxima of entropies What is the relation between n and m maximizing the above entropies ? As we shall see , given a ﬁxed value of n , the absolute maximum is found in the linear ordering above deﬁned at m ∗ = 2 , for graphs sizes n (cid:29) 1 . To support the above claim , let us ﬁrst notice that : Q ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 = Q ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 1 , 8 enabling us to derive the ﬁrst inequality : H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 = 1 n − 2 Q ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 1 > 1 n − 1 Q ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 1 = H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 1 . ( 31 ) Once we demonstrated that H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 > H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 1 , we proceed to demonstrate that H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 > H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 3 . To this end , let us ﬁrst observe a key property of f , de - ﬁned in eq . ( 29 ) . Indeed , we observe that ( ∀ (cid:15) > 0 ) ( ∃ k (cid:15) ) : ( ∀ k > k (cid:15) ) , f ( v k ) < (cid:15) , ( 32 ) provided that n is large enough . From this property , and since (cid:104) f ( n , m ) (cid:105) is an average - see eq . ( 30 ) - we can be sure that ( ∃ n ∗ ) : ( ∀ n > n ∗ ) , log 2 3 > (cid:104) f ( n , 3 ) (cid:105) , ( 33 ) by choosing appropriately n in such a way that we have enough terms lower than a given (cid:15) to obtain the above desired result . Thus , from eq . ( 30 ) and knowing that H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 − H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 3 ∝ log 2 3 − (cid:104) f ( n , 3 ) (cid:105) , ( with proportionally factor equal to n / ( n − 2 ) ) we can conclude that H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 2 > H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = 3 . The general case easily derives from the same reasoning , since : H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = k − H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = k + 1 ∝ log ( k + 1 ) k − (cid:104) f ( n , k + 1 ) (cid:105) , and thus , we can conclude that : ( ∀ k ≤ 2 ) H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = k > H ( ˜ G ) (cid:12)(cid:12)(cid:12) m = k + 1 . ( 34 ) This closes the demonstration that ˜ G containing m = 2 is the most entropic graph provided that n > 14 , according to numerical computations . V . DISCUSSION In this paper we address the problem of quantifying path dependencies using the DAG metaphor . To this goal , we introduce the concept of topological reversibil - ity as a fundamental feature of causal processes that can be depicted by a DAG structure . The intuitive deﬁnition is rather simple : A system formed by an aggregation of causal processes is topologically reversible if we can re - cover all causal paths with no other information than the one provided by the graph topology . If graph topology induces some kind of ambiguity in the backward pro - cess , the graph is said to be topologically irreversible , and additional information is needed to build the back - ward ﬂows . We provided the analytical form of the uncertainty ( the amount of extra information needed ) arising in the rever - sion process by uncoupling the combinatorial information encoded by the graph structure from the contributions of the local connectivity patterns of individual nodes , as de - picted in eqs . ( 22 , 21 ) . It is worth noting that all our results are derived from just two basic concepts : The adjacency matrix of the graph and the deﬁnition of en - tropy . Furthermore , we oﬀer a constructive derivation of the two limit cases , namely trees ( as the reversible ones ) , and linear ordered graphs ( having two maximal nodes ) as the most uncertain ones . According to our results , only a tree DAG is topo - logically reversible . However , beyond this singular case , the quantiﬁcation of topological irreversibility by using the entropy proposed here could provide insights in the characterization of feed forward systems . An illustrative case - study can be found precisely in biological evolution . The standard view of the tree of life involves a direc - tional , upward time - arrow where the genetic structure of a given species ( its genome ) derives from some ancestor after splitting ( speciation ) events . One would think that this classical but too simplistic view of evolution as a tree gives a topologically reversible lineage of genes , changing by mutations and passing from the initial ancestor to current species in a vertical inheritance . However , it has been recently evidenced that the so - called horizontal gene transfer among unrelated species may have had a deep impact in the evolution and diversiﬁcation in microbes [ 37 ] . According to this genetic mechanism the tree - like and thus the logical / topological reversibility is broken by the presence of cross - links between brother species . At the light of these evidences , tree - based phylogenies become unrealistic . In this context , our theoretical ap - proach provides a suitable framework for the characteri - zation of the logical irreversibility of biological evolution and , in general , for any process where time or energy dis - sipation impose a feed - forward chart of events . Further research in this topic will contribute to understand the causal structure of evolutionary processes . Acknowledgments This work was supported by the EU 6 th framework project ComplexDis ( NEST - 043241 , CRC and JG ) , the UTE project CIMA ( JG ) , James McDonnell Foundation ( BCM and RVS ) and the Santa Fe Institute ( RVS ) . We thank Ivan Bezdomny and Complex System Lab mem - bers for fruitful conversations . 9 [ 1 ] G . Csardi , K . J . Strandburg , L . Zalanyi , J . Tobochnik , and P . Erdi , Physica A 374 , 783 ( 2007 ) . [ 2 ] B . Karrer and M . E . J . Newman , Phys Rev Lett 102 , 128701 ( 2009 ) . [ 3 ] S . Lehmann , B . Lautrup , and A . D . Jackson , Phys . Rev . E 68 , 026113 ( 2003 ) . [ 4 ] S . Valverde , R . V . Sol´e , M . A . Bedau , and N . Packard , Phys Rev E Stat Nonlin Soft Matter Phys 76 , 056118 ( 2007 ) . [ 5 ] R . Clay , Nonlinear networks and systems ( John Wiley & Sons Inc , New York , 1971 ) . [ 6 ] S . Haykin , Neural Networks : a Comprehensive Founda - tion ( Prentice - Hall . London , 1999 ) . [ 7 ] H . Frank and I . T . Frisch , Communication , transmission and transportation networks ( Addison - Wesley ( Reading Mass ) , 1971 ) . [ 8 ] I . Rodr´ıguez - Iturbe and A . Rinaldo , Fractal River Basins . Chance and Self - organization ( Cambridge Uni - versity Press . Cambridge . , 1997 ) . [ 9 ] D . Bonchev and D . H . Rouvray , Complexity in Chem - istry , Biology , and Ecology ( Springer , New York . , 2005 ) . [ 10 ] C . H . Bennett , IBM J . Res . Dev . 17 , 525 ( 1973 ) . [ 11 ] R . Landauer , IBM Journal of Research and Development 5 , 183 ( 1961 ) . [ 12 ] W . Fontana and L . W . Buss , Proc Natl Acad Sci U S A 91 , 757 ( 1994 ) . [ 13 ] S . J . Gould , Wonderful Life : The Burgess Shale and the Nature of History ( W . W . Norton & Company . New York , 1990 ) . [ 14 ] S . R . de Groot and P . Mazur , Non - Equilibrium Thermo - dynamics ( North - Holland . Amsterdam , 1962 ) . [ 15 ] G . Lebon , D . Jou , and J . Casas - V´azquez , Understand - ing Nonequilibrium Thermodynamics ( Springer , Berlin , 2008 , 2008 ) . [ 16 ] P . Schuster , Complexity In press ( 2010 ) . [ 17 ] K . Anand and G . Bianconi , Phys . Rev . E 80 , 045102 ( 2009 ) . [ 18 ] M . Dehmer , Appl . Artif . Intell . 22 , 684 ( 2008 ) , ISSN 0883 - 9514 . [ 19 ] M . Dehmer , S . Borgert , and F . Emmert - Streib , PLoS ONE 3 , e3079 ( 2008 ) . [ 20 ] E . Estrada , Phys . Rev . E 80 , 026104 ( 2009 ) . [ 21 ] E . Schneidman , S . Still , M . J . Berry , and W . Bialek , Phys . Rev . Lett . 91 , 238701 ( 2003 ) . [ 22 ] R . V . Sol´e and S . Valverde , in Networks : Struc - ture , Dynamics and Function , Lecture Notes in Physics . ( Springer - Verlag , 2004 ) , pp . 189 – 210 . [ 23 ] R . E . Ulanowicz , Growth and Development : Ecosystems Phenomenology . ( Springer , New York . , 1986 ) . [ 24 ] B . Bollob´as , Modern Graph Theory ( Springer , 1998 ) , cor - rected ed . , ISBN 0387984887 . [ 25 ] J . Gross and J . Yellen , Graph Theory and its applications ( CRC , Boca Raton , Florida , 1998 ) . [ 26 ] J . Kelley , General Topology , Graduate Texts in Mathe - matics , 27 , 1975 ( Van Nostrand , 1955 ) . [ 27 ] P . Suppes , Axiomatic Set Theory ( Dover . New York , 1960 ) . [ 28 ] R . B . Ash , Information Theory ( New York . Dover , 1990 ) . [ 29 ] T . M . Cover and J . A . Thomas , Elements of Information Theory ( John Wiley and Sons . New York , 1991 ) . [ 30 ] A . I . Khinchin , Mathematical Foundations of Information Theory ( Dover , New York , 1957 ) . [ 31 ] C . E . Shannon , Bell System Technical Journal 27 , 379 ( 1948 ) . [ 32 ] M . C . Lagomarsino , P . Jona , and B . Bassetti , in CMSB ( 2006 ) , pp . 227 – 241 . [ 33 ] C . Rodr´ıguez - Caso , B . Corominas - Murtra , and R . V . Sol´e , Mol Biosyst 5 , 1617 ( 2009 ) . [ 34 ] F . V . Jensen , Bayesian Networks and Decision Graphs , Information Science and Statistics ( Springer , 2002 ) . [ 35 ] D . J . Futuyma , Evolution ( Sinauer Associates . Sunder - land , 2005 ) . [ 36 ] T . Dagan , Y . Artzy - Randrup , and W . Martin , Proc Natl Acad Sci U S A 105 , 10039 ( 2008 ) . [ 37 ] T . Dagan and W . Martin , Philos Trans R Soc Lond B Biol Sci 364 , 2187 ( 2009 ) . [ 38 ] N . G . Van Kampen , Stochastic Processes in Physics and Chemistry , Third Edition ( North - Holland Personal Li - brary ) ( North Holland , 2007 ) , 3rd ed . [ 39 ] It is important to notice that the results reported in this paper are independent on the number of connected com - ponents displayed by the DAG . However , we will tac - itly assume that one single connected component link - ing all nodes is present , unless the contrary is indicated . An intuitive statement guides our choice : Two uncon - nected components are causally independent and , there - fore , they must be treated as independent entities . [ 40 ] We observe that matrix B T is the matrix correspond - ing to a Markov process [ 38 ] depicting a random walker walking against the ﬂow