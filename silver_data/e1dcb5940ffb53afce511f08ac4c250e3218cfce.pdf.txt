GENERATIVE PRE - TRAINED TRANSFORMER FOR DESIGN CONCEPT GENERATION : AN EXPLORATION A P REPRINT Qihao Zhu Data - Driven Innovation Lab Singapore University of Technology and Design qihao _ zhu @ mymail . sutd . edu . sg Jianxi Luo Data - Driven Innovation Lab Singapore University of Technology and Design jianxi _ luo @ sutd . edu . sg November 15 , 2021 A BSTRACT Novel concepts are essential for design innovation and can be generated with the aid of data stimuli and computers . However , current generative design algorithms focus on diagrammatic or spatial concepts that are either too abstract to understand or too detailed for early phase design exploration . This paper explores the uses of generative pre - trained transformers ( GPT ) for natural language design concept generation . Our experiments involve the use of GPT - 2 and GPT - 3 for different creative reasonings in design tasks . Both show reasonably good performance for verbal design concept generation . Keywords Early design phase · Idea generation · Generative design · Natural language generation · Generative pre - trained transformer 1 Introduction Design innovation is heavily dependent on high - quality and novel concepts . Concept design activities are divided into two stages : divergence and convergence [ Tschimmel , 2012 ] . Designers must generate a wide range of concepts during the divergence stage before any assessment and selection for convergence to be made . Therefore , much research has been conducted to develop methodologies and tools to aid designers to create design concepts , often with the aid of data and computers [ Chakrabarti et al . , 2011 , Han et al . , 2018 , 2020 ] . Meanwhile , little progress has been made regarding " computer ideation " , i . e . , computers directly and automatically generating ideas , in contrast to computer - aided ideation , i . e . , computers aiding or stimulating human designers to generate ideas . In this study , we introduce a new technique from the ﬁeld of artiﬁcial intelligence ( AI ) – the generative pre - trained transformer ( GPT ) – for automated generation of verbal design concepts . GPTs are language models pre - trained on vast quantities of textual data and can perform a wide range of language - related tasks [ Radford et al . , 2019 , Brown et al . , 2020 ] . Our work experiments the applicability of different GPT models for both problem - driven reasoning and analogy - driven reasoning for design , with customized datasets . 2 Literature Review Recent research on design concept generation can be categorized based on three dimensions : the role of method or tool , the form of concept representation , and the targeted design process stage . A concept generation method or tool can play one of the three roles : as a guide , as a stimulator , or as a generator . A method is considered as guide if it is instructively involved in the generation of design concepts , providing design rules or guidelines to the activities of the designers . For instance , Bonnardel and Didier [ 2020 ] proposed two variants of brainstorming , encouraging designers to focus on the evocation of both the design ideas and the constraints related to the design problem . A stimulator provides inspirational stimuli to provoke designers to conceive new concepts . Goldschmidt a r X i v : 2111 . 08489v1 [ c s . C L ] 16 N ov 2021 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT and Smolkov [ 2006 ] discussed how visual stimuli affect problem solving design performance . Jin and Dong [ 2020 ] extracted 10 design heuristics as stimuli from RedDot award - wining design concepts to help digital designers overcome design ﬁxation . He et al . [ 2019 ] tested the use of word clouds as stimulators to inspire ideation . Meanwhile , some methods can be a guide and a simulator at the same time . Luo et al . [ 2019 ] introduced a computer - aided ideation tool InnoGPS to guide the provision of design stimuli from the patent database by their knowledge distance to the design problem or interest . Fargnoli et al . [ 2006 ] introduced the morphological matrix to guide designers to navigate and combine alternative solutions to each of multiple functions of a product to generate a variety of designs . A concept generator represents a fully automated computational agent that creates new concepts for the interest of designers . One example is function - based design synthesis [ Chakrabarti et al . , 2011 ] . Sangelkar and McAdams [ 2017 ] introduced graph grammar to generate the function structures of the design concepts with potential for computational design synthesis . Kang and Tucker [ 2015 ] proposed a concept generation method based on function - form synthesis . Other generators perform topology optimization and generative visual design [ Vlah et al . , 2020 ] . Oh et al . [ 2019 ] and Nie et al . [ 2021 ] integrate topology optimization and generative adversarial network ( GAN ) to generate concepts for both aesthetic and engineering performance . Ren et al . [ 2013 ] , Burnap et al . [ 2016 ] , and Dogan et al . [ 2019 ] use generative models to create new concepts of vehicle form design . During design activities , concepts can be represented in the forms of abstract diagram , verbal text , or spatial visualization . Guiding or stimulation - based methods can direct designers to generate concepts in either of the three forms , e . g . , simple sketches [ Shah et al . , 2001 , Goldschmidt and Smolkov , 2006 ] , mind - mapping graph [ Shih et al . , 2009 , Yagita et al . , 2011 ] , functional diagram [ Stone et al . , 2000 ] , or textual description [ He et al . , 2019 , Sarica et al . , 2021 ] . Some guides or stimulators may also lead to multiple forms of concept representation as designers may record their perception of ideas in different ways [ Bonnardel and Didier , 2020 , Ilevbare et al . , 2013 , Yilmaz et al . , 2016 ] . On the other hand , for automated tools , the type of concepts to be generated is pre - determined when designing the system , e . g . , the graph grammar - based tools represent new concepts in abstract graphs [ Campbell , 2009 , Sangelkar and McAdams , 2017 ] , while the topology optimization tools generate spatially visualized concepts in the form of 2D images [ Oh et al . , 2019 ] or 3D models [ Nie et al . , 2021 ] . The forms of generated concepts need to ﬁt with design process stages . Pahl and Beitz [ 2007 ] speciﬁed four stages in design processes , including planning and task clariﬁcation , conceptual design , embodiment design , and detail design . For designers , visual stimulators like mood boards [ Ahmed and Boelskifte , 2006 ] and spatial concept generators [ Oh et al . , 2019 , Nie et al . , 2021 ] are mainly useful for embodiment and detail design stages and may cause design ﬁxation if applied in earlier stages [ Viswanathan et al . , 2016 ] . Diagrammatic concepts are represented in a more abstract way that either visualizes the mind map of a design concept [ Shih et al . , 2009 , Yagita et al . , 2011 ] or the relationship between components of function or structure [ Stone et al . , 2000 , Campbell , 2009 ] . They are more suitable for the planning and task clariﬁcation as well as conceptual design stages . Meanwhile , text is also a common modality of recording concepts for early design stages . In typical brainstorming sessions , designers exchange preliminary design ideas verbally and frequently . Chiu and Shu [ 2007 ] investigated how semantic stimuli presented as words affect concept generation . Sarica et al . [ 2021 ] retrieved the terms from a pre - trained technology semantic network as stimuli to generate new concepts in the form of text . Goucher - Lambert and Cagan [ 2019 ] and Camburn et al . [ 2020 ] collected design ideas written in short text from crowdsourcing campaigns . To date , however , there exist no automated tool that is built to generate verbal design concepts . To summarize , we present a taxonomy of concept generation methods or tools in Figure 1 by their roles , concept representation forms and suitable design stages . In this research , we focus on verbal generator using the latest natural language generation ( NLG ) technology . Particularly , we experiment the generative pre - trained transformers from OpenAI to learn design knowledge and reasoning from task - oriented datasets and then generate high ﬁdelity design concept descriptions in natural language . 3 Natural Language Generation ( NLG ) 3 . 1 Text - to - Text and Data - to - Text NLG Natural language generation ( NLG ) is considered as a computer program that generates natural language as output [ Gatt and Krahmer , 2018 ] . According to Gatt and Krahmer [ 2018 ] , depending on the input , there are two major instances of NLG : text - to - text and data - to - text generation . Text - to - text is what takes in existing text as input and then outputs new pieces of text . Examples of text - to - text generation include machine translation ( e . g . , Kenny [ 2019 ] ) , text summarization or simpliﬁcation ( e . g . , Ozsoy et al . [ 2011 ] ) , automatic writing correction ( e . g . , Karyuatry [ 2018 ] ) , paraphrasing ( e . g . , Li et al . [ 2018 ] ) , and so on . On the other hand , data - to - text generation takes in non - linguistic data as input . Applications of data - to - text have been seen in varied ﬁelds , e . g . , generating news based on election data [ Leppänen et al . , 2017 ] , generating personalized suggestions based on user input and web data [ Wanner et al . , 2015 ] . 2 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Figure 1 : Taxonomy of concept generation methods or tools 3 . 2 Transformer for NLG Transformer , ﬁrst introduced by Vaswani et al . [ 2017 ] ) , is the state - of - the - art neural network architecture for natural language processing ( NLP ) and is becoming the dominant for NLG [ Topal et al . , 2021 ] . Comparing to recurrent neural network ( RNN ) and long short - term memory ( LSTM ) , which were the most popular neural network architectures until recently , transformer overcomes the vanishing gradient problem [ Pascanu et al . , 2013 ] , which could cause the failure of maintaining context when processing longer text . Moreover , transformer enables parallel training . With the training data and model architecture become larger in size , it can capture longer sequence features and therefore result in much more comprehensive language understanding and generation [ Brown et al . , 2020 ] . Another signiﬁcant feature of transformer for NLG is that it blurs the boundary between data - to - text and text - to - text NLG models . For instance , Radford et al . [ 2019 ] reports the outstanding performance of the GPT - 2 transformer model from OpenAI for text - to - text generation tasks such as translation and summarization , meanwhile Peng et al . [ 2020 ] shows the model after ﬁne - tuning is also capable of performing data - to - text dialogue generation tasks . Although transformer is a rather new technique in NLP and NLG , some applications have already been seen in different ﬁelds . Amin - Nejad et al . [ 2020 ] use transformer models to generate structured patient information to augment medical dataset . Lee and Hsiang [ 2020 ] use GPT - 2 with ﬁne - tuning to generate patent claims . Fang [ 2021 ] also use GPT to generate ideas for content creators . However , according to a recent review conducted by Regenwetter et al . [ 2021 ] , the application of transformers is still a wide - open space for engineering design tasks . Our work ﬁlls this gap . 3 . 3 Generative Pre - trained Transformer ( GPT ) Now we introduce the most popular series of transformers in NLG tasks : the generative pre - trained transformer [ Radford et al . , 2019 , Brown et al . , 2020 ] , or GPT for short . Later in this paper , we apply and compare the 2nd and 3rd generations of GPT , i . e . , GPT - 2 and GPT - 3 , in design concept generation tasks . GPT - 2 uses the two - step training strategy of pre - training and ﬁne - tuning , following Hinton and Salakhutdinov [ 2006 ] . The workﬂow is shown in Figure 2 ( a ) . During the pre - training step , the model is trained on a massive text dataset called WebText , which is collected from millions of webpages [ Radford et al . , 2019 ] . This results in a comprehensive language model that can perform general language completion tasks . According to OpenAI , the largest GPT - 2 pre - trained model has 1 . 5 billion parameters . For downstream NLP tasks , the pre - trained model then needs to be ﬁne - tuned given a customized and task - oriented dataset . The ﬁne - tuned model is trained through repeated gradient updates using a large dataset of corpus of the example task . This process updates the weights of the pre - trained model and stores them for the use of the target task . However , the large dataset suitable for the target NLP task may be unavailable or difﬁcult to collect . GPT - 3 is the largest language model so far . It is trained on a mixture of datasets containing 400 billion tokens and has a maximum of 175 billion parameters , over a hundred times larger than GPT - 2 . Comparing to its precursor , GPT - 3 can perform a wide range of NLP tasks without the need of ﬁne - tuning . GPT - 3 is capable of few - show learning [ Brown et al . , 2020 ] , in which the model learns from multiple examples of the NLP or NLG task before conducting it . In this 3 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Figure 2 : Training and re - training process of GPT - 2 ( a ) and GPT - 3 ( b ) process , no gradient updates are performed [ Brown et al . , 2020 ] . The training process of GPT - 3 is shown in Figure 2 ( b ) , where the prompts are the task examples given to the model for few - shot learning . For text generation , the implementation of GPT requires several control parameters and can be categorized in three types according to the aimed property of the generated text . The ‘max _ tokens’ ( also called ‘length’ ) , ‘prompt’ ( also called ‘proﬁx’ ) , and ‘stop’ ( also called ‘truncate’ ) control the content and format of the text . These are essential parameters when customizing the task and deﬁning the input of the NLG model . When conditionally sampling with a pre - determined prompt , the model will learn to set up the context and output results based on it . The ‘temperature’ , ‘top - k’ ( only applicable for GPT - 2 ) , and ‘top - p’ parameters control the randomness of the generated text . Higher randomness will result in more varied outputs . Finally , the ‘presence _ penalty’ and ‘frequency _ penalty’ parameters are only applicable for GPT - 3 and control generation repetitiveness . By encouraging new topics and discouraging existing ones , the generated texts are more likely to deviate from the given examples and represent novel concepts . 4 Research Method In this paper , we experiment the applications of different GPT models in different design concept generation tasks . Figure 3 depicts the general framework of our experiments . First , knowledge for the task is the key component of our framework . It is provided through the dataset used for ﬁne - tuning GPT - 2 model , or in the examples of design concepts for few - shot learning of GPT - 3 . Secondly , we take in varied input as the prompt for conditional learning . The input should be customized and consistent with the speciﬁc reasoning we want the model to learn , and output will be the generated design concept description . For instance , for analogy reasoning , the input will be the source and target domains for analogy mapping . Finally , the transformer in the framework can be either a ﬁne - tuned GPT - 2 or the pre - trained GPT - 3 for few - shot learning . Table 1 summarizes the settings for two experiments , in which we explore the capability of GPT for generating concepts by problem - driven reasoning and analogy - driven reasoning . The data we use for knowledge acquirement in both experiments is from the repository of RedDot award - wining designs . The ﬁrst experiment includes three phrases for implementation : preparing the data for the NLG task , ﬁne - tuning the model with the provided dataset , and testing the performance . The ﬁne - tuning phrase is not included for the second experiment because we will be employing GPT - 3 few - shot learning . Table 1 : Experiment Settings Experiment Knowledge for the task Input Transformer Problem - driven reasoning RedDot award - winning design Problem statement , concept category Fine - tuned GPT - 2 Analogy - driven reasoning Examples of design - by - analogy concepts from RedDot award - winning design Target and source domains GPT - 3 few - shot learning 4 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Figure 3 : Experiment Framework 5 Experiments 5 . 1 Problem - Driven Reasoning Given GPT - 2’s capability to generate text based on understanding the context via training and ﬁne - tuning , we experiment its application to generating text of solution ideas for a given problem . Problem - solving in design could be supported by different methods such as analogy and ﬁrst principle . In this experiment we do not constrain GPT - 2’s problem - solving approach . The dataset for model ﬁne - tuning is collected from RedDot’s ofﬁcial website ( https : / / www . red - dot . org / ) , including 14 , 502 product designs from 2011 to 2020 and 1 , 486 design concepts from 2016 to 2020 . Data preparation includes picking out the text description of each design and adding its category name before the description . An example description of a problem - driven design in the RedDot dataset is shown below : “One of the biggest and most common concerns of using public toilets is avoiding dermatosis and bacterial infection that comes from sharing a toilet with others . Clean Seat has a toilet lid that automatically opens when the ﬁrst sensor ( located at the front of the toilet lid ) detects a user approaching . A second sensor then detects the person leaving after using the toilet , prompting the toilet lid to close and lock itself . When the lid is locked , the system kickstarts the self - cleaning function of the toilet . " As shown in the example , the problem is stated in the ﬁrst sentence , followed by the solution idea description . This structure is common in the descriptions of problem - driven design and ideal for GPT to generate solution idea text as the output in response to a problem text as the input . However , not all award - winning designs are problem - driven and often the description does not begin with a problem description . Our hypothesis is that the model can learn from those problem - driven design descriptions ( as the example above ) in the total dataset to execute problem - solving tasks , while also learning from design descriptions of other structures during training . A pre - trained GPT - 2 of 774M parameters is ﬁne - tuned for 4 , 000 steps . Figure 4 reports average loss over the ﬁne - tuning steps . In the generation phrase , the problem Figure 4 : Average loss with training steps when ﬁne - tuning with RedDot data 5 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT statement and the design domain category are both set as input . The problem statement can be a single sentence written by the designer , and the category input can be selected from the categories listed on RedDot ofﬁcial website . Table 2 reports two solutions generated for each of the two design problems in two experiments ( parameters : temperature = 0 . 85 , top - k = 40 , and top - p = 1 ) . The ﬁrst problem statement is from in the example above and the other is from an IF award - winning design ( https : / / ifworlddesignguide . com / entry / 324944 - ema ) , in order to test the model’s capability to generate solution ideas to known versus unknown problems to the model . The ﬁne - tuned GPT - 2 generated many more Table 2 : Problem - driven reasoning experiment : inputs and generated concepts Input Category Problem Statement Generated Solutions PersonalHygiene One of the biggest and most common concerns of using public toilets is avoid - ing dermatosis and bacterial infection that comes from sharing a toilet with others . Solution 1 Clean Seat provides a new and simple solution to this problem . A toilet seat equipped with an auto - level function is used to disinfect the seat after each use . The clean seat deodorises the entire seat , thus dramatically reducing the bacterial load on the back of the toilet bowl . Moreover , the seat has a crotch - level rubber band that provides comfort and personal comfort when using the toilet . This product is designed in a way that it provides a pleasant and personal experience using public toilets . The user can become part of the solution by donating their old clothes to the public toilet maintenance . Solution 2 To deal with this , the Trit objective was to design a toilet that is free of such infections . This was achieved through a very low - pollution level using of organic ﬁlter and antimicrobial ceramic material . The material is not only sustainable but is also highly hygienic . LifeScience Current electrocardio - graph testing involves a large number of wires , making the process time - consuming for doctors and stressful for children . Solution 1 The suction coil is attached to the skin and the image data are transmitted to a tablet via Bluetooth . The spiral design of the coil makes it easy to position the device quickly on the skin during testing . An infrared sensor in the base of the device sends infrared light to the face and indicates the test status via a light ring . This allows doctors to locate the hygienic needle quickly in the event of a failed test result . Solution 2 The way out - of - ofﬁce is also easier without these wires . With a simple hand - type electrocardiogram sensor , a doctor achieves the same results with a lower voltage and reduced energy consump - tion . concepts than the four demonstrated in Table 3 , allowing us to evaluate its performance . For the known problem with a known solution , GPT - 2 can generate many new solution ideas based on the massive knowledge it has acquired from the training . For the unknown problem , it is also capable of comprehending the problem and generating solution ideas . However , as the text lengthens , it is likely to start talking about other features of the design that are unrelated to the given problem . This is not surprising as the design descriptions in the ﬁne - tuning dataset often provide comprehensive elaboration of multiple aspects and the model learnt this well . 5 . 2 Analogy - Driven Reasoning Design - by - analogy is the projection of existing reference in a source domain to address a comparable challenge in the target domain [ Gentner , 1983 , Luo et al . , 2021 ] . It is usually considered as a problem - solving approach . However , when a problem is not speciﬁed , analogy reasoning can also lead to open - ended design concept generation . This experiment is to test the analogy - driven reasoning of the model for concept generation , particularly for the context when a designer aims to draw analogy from a given source domain to generating design concepts in a given target domain but has not established clear analogy mapping across domains to generate speciﬁc new concepts . 6 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT As there are insufﬁcient design - by - analogy examples to ﬁne - tune a GPT - 2 , this experiment employs ﬁve analogy - driven reasoning examples selected from RedDot dataset as prompts for GPT - 3’s few - shot learning . Table 3 shows the source and target domains in each of the ﬁve examples for learning . Before each example is inputted , a structured sentence specifying the source and target domains ( e . g . , “Applying accordion to computer mouse” ) is inserted so that the GPT - 3 may learn to develop ideas based on the input domains . When generating new concepts , we simply need to update the tokens that specify the source and target domains in the input sentence . Table 3 : Analogy - driven reasoning examples used as prompts for GPT - 3 Source Domain Target Domain Link of the example Accordion Computer Mouse https : / / www . red - dot . org / project / ambi - 48504 Cells Building https : / / www . red - dot . org / project / build - fender - 27044 Standing desk Automobile https : / / www . red - dot . org / project / sole - 26525 Folding chair Wheelchair https : / / www . red - dot . org / project / fold - light - wheelchair - 26521 Circuit board Desk https : / / www . red - dot . org / project / cabletread - 46563 Table 4 reports two drone design concepts generated by GPT - 3 , by drawing analogy from the given source domains of lantern and origami in two experiments ( parameters : temperature = 0 . 85 , top - p = 1 , presence _ penalty = 0 . 5 , fre - quency _ penalty = 0 . 5 ) . The model successfully understands both source domains and applies the lighting feature of the lantern and the folding mechanism of origami to drone design . Without being trained with a large amount of analogical design cases , the generated concepts do adhere to analogical reasoning and learn to build a clear analogical mapping between the source and target domains , even when the two given source domains are culture - related and distant from the technical domain of drone . This is because the GPT - 3 is pre - trained on a massive text dataset that includes nearly all possible kinds of scenarios and knowledges and a few examples as prompts are enough for the speciﬁc ’memory’ of the model to be evoked . Furthermore , consistent to the pervious experiment , we also tested for the model’s performance with the input of the same prompt sentences as in the given examples . It turns out GPT - 3 is more likely to repeat the ideas given in the examples given low frequency penalty and presence penalty parameters , but it begins to generate novel texts as the parameters are set to higher values . This reveals another difference between the mechanisms of GPT - 2 and GPT - 3 models when being applied to design concept generation tasks , which will need further investigation . 6 Discussion and Future Works This article has examined the uses of generative pre - trained transformers to generate design concepts . It is demonstrated that by customizing the training data or examples , GPT can perform conceptual design tasks with a reasonable level of competence . This work opens the path to verbal concept generation using NLG , which may possibly be integrated with other approaches for a broader variety of applications and a higher level of automation . For example , the analogy - driven reasoning experiment necessitates source domain data for concept generation and comparison . This may be supplemented with knowledge graphs that provide domain knowledges with a given knowledge distance . Furthermore , given suitable datasets , the generation of design concepts based on varied design heuristics will be possible , such as TRIZ [ Ilevbare et al . , 2013 ] or the 77 design heuristics [ Yilmaz et al . , 2016 ] . However , it should be highlighted that the computer - generated concepts we showcased above were selected from a pool of low - quality results that may not be viable or context relevant . Thus , efﬁcient concept evaluation algorithm is required to ﬁlter the automatically generated design concepts . Such an evaluator should be able to gauge both concept quality and novelty . Furthermore , human assessment should be employed to validate the performances of both the generator and evaluator . 7 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Table 4 : Analogy - driven reasoning experiment : inputs and generated concepts Input SourceDomain TargetDomain Generated Concepts Lantern Drone Concept 1 Focused on the design of portable drone landing pads , Skylight is con - ceived as a portable lantern that allows operators to track ﬂying drones for charging or repair . Developed into different designs that can ﬁt with any situation , Skylight has two main forms : docking stations that are focused on portability and public space ; and lamp - like structures for open areas . Concept 2 D - LIGHT is a decorative drone that is ﬁtted with a lantern inspired by the Chinese ‘paper lantern’ . The drone’s movements control the position and movement of the lantern , which is mounted at its centre . The functional design of D - LIGHT focuses on responsive mechanisms for ﬂying and controlling the lantern . This also enables it to be operated wherever necessary . Origami Drone Concept 1 Aerobowl is inspired by the art of origami . The drone folds like an aerial paper aircraft and is able to fold itself up after landing . It can be launched without any human intervention , for example into lakes or rivers to help with rescue operations ; it then folds its propellers into lightweight aircraft mode before ﬂoating along on the surface of the water like a boat . Concept 2 For centuries , paper folding has evolved into various different forms of art . Inspired by this , PaperDrone is an origami - inspired drone that is designed to have its chassis structure be deformable . The main goal of the design is to minimize the folding part while maintaining its strength and rigidity , mainly focusing on the legs for this feature . There are three feathered blades attached to each leg that can rotate in both directions at certain angles . The foldable body allows it to be very compact when folded , thus making easy storage possible . References Katja Tschimmel . Design thinking as an effective toolkit for innovation . In ISPIM Conference Proceedings , page 1 . The International Society for Professional Innovation Management ( ISPIM ) , 2012 . Amaresh Chakrabarti , Kristina Shea , Robert Stone , Jonathan Cagan , Matthew Campbell , Noe Vargas Hernandez , and Kristin L Wood . Computer - based design synthesis research : an overview . Journal of Computing and Information Science in Engineering , 11 ( 2 ) , 2011 . doi : 10 . 1115 / 1 . 3593409 . Ji Han , Feng Shi , Liuqing Chen , and Peter RN Childs . The combinator – a computer - based tool for creative idea generation based on a simulation approach . Design Science , 4 , 2018 . doi : 10 . 1017 / dsj . 2018 . 7 . Ji Han , Hannah Forbes , Feng Shi , Jia Hao , and Dirk Schaefer . A data - driven approach for creative concept generation and evaluation . In Proceedings of the Design Society : DESIGN Conference , volume 1 , pages 167 – 176 . Cambridge University Press , 2020 . doi : 10 . 1017 / dsd . 2020 . 5 . Alec Radford , Jeffrey Wu , Rewon Child , David Luan , Dario Amodei , Ilya Sutskever , et al . Language models are unsupervised multitask learners . OpenAI blog , 1 ( 8 ) : 9 , 2019 . Tom B Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , et al . Language models are few - shot learners . Advances in neural information processing systems , 2020 . Nathalie Bonnardel and John Didier . Brainstorming variants to favor creative design . Applied ergonomics , 83 : 102987 , 2020 . doi : 10 . 1016 / j . apergo . 2019 . 102987 . Gabriela Goldschmidt and Maria Smolkov . Variances in the impact of visual stimuli on design problem solving performance . Design Studies , 27 ( 5 ) : 549 – 569 , 2006 . doi : 10 . 1016 / j . destud . 2006 . 01 . 002 . Xiaoneng Jin and Hua Dong . New design heuristics in the digital era . In Proceedings of the Design Society : DESIGN Conference , volume 1 , pages 607 – 616 . Cambridge University Press , 2020 . doi : doi . org / 10 . 1017 / dsd . 2020 . 321 . 8 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Yuejun He , Bradley Camburn , Haowen Liu , Jianxi Luo , Maria Yang , and Kristin Wood . Mining and represent - ing the concept space of existing ideas for directed ideation . Journal of Mechanical Design , 141 ( 12 ) , 2019 . doi : 10 . 1115 / 1 . 4044399 . Jianxi Luo , Serhad Sarica , and Kristin L Wood . Computer - aided design ideation using innogps . In IDETC - CIE , volume 59186 , page V02AT03A011 . American Society of Mechanical Engineers , 2019 . Mario Fargnoli , Edoardo Rovida , and Riccardo Troisi . The morphological matrix : Tool for the development of innovative design solutions . In 4th International Conference on Axiomatic design , ICAD , pages 1 – 7 , 2006 . doi : 10 . 1109 / FIE . 1998 . 736828 . Shraddha Sangelkar and Daniel A McAdams . Automated graph grammar generation for engineering design with frequent pattern mining . In IDETC - CIE , volume 58127 , page V02AT03A006 . American Society of Mechanical Engineers , 2017 . doi : 10 . 1115 / DETC2017 - 67520 . Sung Woo Kang and Conrad S Tucker . Automated concept generation based on function - form synthesis . In IDETC - CIE , volume 57076 , page V02AT03A008 . American Society of Mechanical Engineers , 2015 . doi : 10 . 1115 / DETC2015 - 47687 . Daria Vlah , Roman Žavbi , and Nikola Vukašinovi´c . Evaluation of topology optimization and generative design tools as support for conceptual design . In Proceedings of the Design Society : DESIGN Conference , volume 1 , pages 451 – 460 . Cambridge University Press , 2020 . doi : 10 . 1017 / dsd . 2020 . 165 . Sangeun Oh , Yongsu Jung , Seongsin Kim , Ikjin Lee , and Namwoo Kang . Deep generative design : Integration of topology optimization and generative models . Journal of Mechanical Design , 141 ( 11 ) , 2019 . doi : 10 . 1115 / 1 . 4044229 . Zhenguo Nie , Tong Lin , Haoliang Jiang , and Levent Burak Kara . Topologygan : Topology optimization using generative adversarial networks based on physical ﬁelds over the initial domain . Journal of Mechanical Design , 143 ( 3 ) : 031715 , 2021 . doi : 10 . 1115 / 1 . 4049533 . Yi Ren , Alex Burnap , and Panos Papalambros . Quantiﬁcation of perceptual design attributes using a crowd . In DS 75 - 6 : Proceedings of the 19th International Conference on Engineering Design ( ICED13 ) , Design for Harmonies , Vol . 6 : Design Information and Knowledge , Seoul , Korea , 19 - 22 . 08 . 2013 , 2013 . Alexander Burnap , Ye Liu , Yanxin Pan , Honglak Lee , Richard Gonzalez , and Panos Y Papalambros . Estimating and exploring the product form design space using deep generative models . In IDETC - CIE , volume 50107 , page V02AT03A013 . American Society of Mechanical Engineers , 2016 . doi : 10 . 1115 / DETC2016 - 60091 . Kemal Mert Dogan , Hiromasa Suzuki , Erkan Gunpinar , and Myung - Soo Kim . A generative sampling system for proﬁle designs with shape constraints and user evaluation . Computer - Aided Design , 111 : 93 – 112 , 2019 . doi : 10 . 1016 / j . cad . 2019 . 02 . 002 . Jami J Shah , NOE Vargas - Hernandez , Joshua D Summers , and Santosh Kulkarni . Collaborative sketching ( c - sketch ) —an idea generation technique for engineering design . The Journal of Creative Behavior , 35 ( 3 ) : 168 – 198 , 2001 . doi : 10 . 1002 / j . 2162 - 6057 . 2001 . tb01045 . x . Patrick C Shih , David H Nguyen , Sen H Hirano , David F Redmiles , and Gillian R Hayes . Groupmind : supporting idea generation through a collaborative mind - mapping tool . In Proceedings of the ACM 2009 international conference on Supporting group work , pages 139 – 148 , 2009 . doi : 10 . 1145 / 1531674 . 1531696 . Hiroyuki Yagita , Akira Tose , Madoka Nakajima , Sun K Kim , and Takashi Maeno . A validation regarding effectiveness of scenario graph . In IDETC - CIE , volume 54860 , pages 385 – 394 , 2011 . doi : 10 . 1115 / DETC2011 - 48047 . Robert B Stone , Kristin L Wood , and Richard H Crawford . A heuristic method for identifying modules for product architectures . Design studies , 21 ( 1 ) : 5 – 31 , 2000 . doi : 10 . 1016 / S0142 - 694X ( 99 ) 00003 - 4 . Serhad Sarica , Binyang Song , Jianxi Luo , and Kristin L Wood . Idea generation with technology semantic network . AI EDAM , pages 1 – 19 , 2021 . doi : 10 . 1017 / S0890060421000020 . Imoh M Ilevbare , David Probert , and Robert Phaal . A review of triz , and its beneﬁts and challenges in practice . Technovation , 33 ( 2 - 3 ) : 30 – 37 , 2013 . doi : 10 . 1016 / j . technovation . 2012 . 11 . 003 . Seda Yilmaz , Shanna R Daly , Colleen M Seifert , and Richard Gonzalez . Evidence - based design heuristics for idea generation . Design Studies , 46 : 95 – 124 , 2016 . doi : 10 . 1016 / j . destud . 2016 . 05 . 001 . Matthew I Campbell . A graph grammar methodology for generative systems , 2009 . URL http : / / repositories . lib . utexas . edu / handle / 2152 / 6258 . G Pahl and W Beitz . Engineering design - a systematic approach , 2007 . Saeema Ahmed and Per Boelskifte . Investigation of designers intentions and a users’ perception of product character . In NordDesign 2006 . University of Iceland , 2006 . 9 Generative Pre - Trained Transformer for Design Concept Generation : An Exploration A P REPRINT Vimal Viswanathan , Megan Tomko , and Julie Linsey . A study on the effects of example familiarity and modality on design ﬁxation . AI EDAM , 30 ( 2 ) : 171 – 184 , 2016 . doi : 10 . 1017 / S0890060416000056 . I Chiu and LH Shu . Understanding the use of language stimuli in concept generation . In IDETC - CIE , volume 48043 , pages 161 – 172 , 2007 . doi : 10 . 1115 / DETC2007 - 35772 . Kosa Goucher - Lambert and Jonathan Cagan . Crowdsourcing inspiration : Using crowd generated inspirational stimuli to support designer ideation . Design Studies , 61 : 1 – 29 , 2019 . doi : 10 . 1016 / j . destud . 2019 . 01 . 001 . Bradley Camburn , Yuejun He , Sujithra Raviselvam , Jianxi Luo , and Kristin Wood . Machine learning - based design concept evaluation . Journal of Mechanical Design , 142 ( 3 ) : 031113 , 2020 . doi : 10 . 1115 / 1 . 4045126 . Albert Gatt and Emiel Krahmer . Survey of the state of the art in natural language generation : Core tasks , applications and evaluation . Journal of Artiﬁcial Intelligence Research , 61 : 65 – 170 , 2018 . doi : 10 . 1613 / jair . 5477 . Dorothy Kenny . Machine translation . In Routledge Encyclopedia of Translation Studies , pages 305 – 310 . Routledge , 2019 . doi : 10 . 4324 / 9781315678627 . Makbule Gulcin Ozsoy , Ferda Nur Alpaslan , and Ilyas Cicekli . Text summarization using latent semantic analysis . Journal of Information Science , 37 ( 4 ) : 405 – 417 , 2011 . doi : 10 . 1177 % 2F0165551511408848 . Laksnoria Karyuatry . Grammarly as a tool to improve students’ writing quality : Free online - proofreader across the boundaries . JSSH ( Jurnal Sains Sosial dan Humaniora ) , 2 ( 1 ) : 83 – 89 , 2018 . doi : 10 . 30595 / jssh . v2i1 . 2297 . Zichao Li , Xin Jiang , Lifeng Shang , and Hang Li . Paraphrase generation with deep reinforcement learning . In EMNLP , 2018 . Leo Leppänen , Myriam Munezero , Mark Granroth - Wilding , and Hannu Toivonen . Data - driven news generation for automated journalism . In Proceedings of the 10th International Conference on Natural Language Generation , pages 188 – 197 , 2017 . Leo Wanner , Harald Bosch , Nadjet Bouayad - Agha , Gerard Casamayor , Thomas Ertl , Désirée Hilbring , Lasse Johansson , Kostas Karatzas , Ari Karppinen , Ioannis Kompatsiaris , et al . Getting the environmental information across : from the web to the user . Expert Systems , 32 ( 3 ) : 405 – 432 , 2015 . Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . Attention is all you need . In Advances in neural information processing systems , pages 5998 – 6008 , 2017 . M Onat Topal , Anil Bas , and Imke van Heerden . Exploring transformers in natural language generation : Gpt , bert , and xlnet . Accepted to International Conference on Interdisciplinary Applications of Artiﬁcial Intelligence ( ICIDAAI ) 2021 , 2021 . Razvan Pascanu , Tomas Mikolov , and Yoshua Bengio . On the difﬁculty of training recurrent neural networks . In International conference on machine learning , pages 1310 – 1318 . PMLR , 2013 . Baolin Peng , Chenguang Zhu , Chunyuan Li , Xiujun Li , Jinchao Li , Michael Zeng , and Jianfeng Gao . Few - shot natural language generation for task - oriented dialog . in Proceedings of EMNLP 2020 , pages 172 – 182 , 2020 . doi : 10 . 18653 / v1 / 2020 . ﬁndings - emnlp . 17 . Ali Amin - Nejad , Julia Ive , and Sumithra Velupillai . Exploring transformer text generation for medical dataset augmentation . In Proceedings of the 12th Language Resources and Evaluation Conference , pages 4699 – 4708 , 2020 . Jieh - Sheng Lee and Jieh Hsiang . Patent claim generation by ﬁne - tuning openai gpt - 2 . World Patent Information , 62 : 101983 , 2020 . doi : 10 . 1016 / j . wpi . 2020 . 101983 . Jingwu Fang . An Application of Customized GPT - 2 Text Generator for Modern Content Creators . PhD thesis , UCLA , 2021 . Lyle Regenwetter , Amin Heyrani Nobari , and Faez Ahmed . Deep generative models in engineering design : A review . arXiv preprint arXiv : 2110 . 10863 , 2021 . Geoffrey E Hinton and Ruslan R Salakhutdinov . Reducing the dimensionality of data with neural networks . science , 313 ( 5786 ) : 504 – 507 , 2006 . doi : 10 . 1126 / science . 1127647 . Dedre Gentner . Structure - mapping : A theoretical framework for analogy . Cognitive science , 7 ( 2 ) : 155 – 170 , 1983 . doi : 10 . 1016 / S0364 - 0213 ( 83 ) 80009 - 3 . Jianxi Luo , Serhad Sarica , and Kristin L Wood . Guiding data - driven design ideation by knowledge distance . Knowledge - Based Systems , 218 : 106873 , 2021 . doi : 10 . 1016 / j . knosys . 2021 . 106873 . 10