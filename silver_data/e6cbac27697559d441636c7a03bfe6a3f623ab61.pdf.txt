City , University of London Institutional Repository Citation : Dykes , J . ORCID : 0000 - 0002 - 8096 - 5763 , Kerzner , E . , Goodwin , S . , Jones , S . ORCID : 0000 - 0003 - 4789 - 4948 and Meyer , M . ( 2018 ) . A Framework for Creative Visualization - Opportunities Workshops . IEEE Transactions on Visualization and Computer Graphics , 25 ( 1 ) , doi : 10 . 1109 / TVCG . 2018 . 2865241 This is the accepted version of the paper . This version of the publication may differ from the final published version . Permanent repository link : http : / / openaccess . city . ac . uk / 20085 / Link to published version : http : / / dx . doi . org / 10 . 1109 / TVCG . 2018 . 2865241 Copyright and reuse : City Research Online aims to make research outputs of City , University of London available to a wider audience . Copyright and Moral Rights remain with the author ( s ) and / or copyright holders . URLs from City Research Online may be freely distributed and linked to . City Research Online : http : / / openaccess . city . ac . uk / publications @ city . ac . uk City Research Online A Framework for Creative Visualization - Opportunities Workshops Ethan Kerzner , Sarah Goodwin , Jason Dykes , Sara Jones , Miriah Meyer Abstract —Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization . The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings . A number of recent projects , however , report on the use of creative visualization - opportunities ( CVO ) workshops to accelerate the early stages of applied work , eliciting a wealth of requirements in a few days of focused work . Yet , there is no established guidance for how to use such workshops effectively . In this paper , we present the results of two - year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts . Its primary contribution is a framework for CVO workshops that 1 ) identiﬁes a process model for using workshops ; 2 ) describes a structure of what happens within effective workshops ; 3 ) recommends 25 actionable guidelines for future workshops ; and 4 ) presents an example workshop and workshop methods . The creation of this framework exempliﬁes the use of critical reﬂection to learn about visualization in practice from diverse studies and experience . Index Terms —User - centered visualization design , design studies , creativity workshops . 1 I NTRODUCTION Two key challenges in the early stages of applied visualization re - search are to ﬁnd pressing domain problems and to translate them into interesting visualization opportunities . Researchers often discover such problems through a lengthy process of interviews and observa - tions with domain collaborators that can sometimes take months [ 39 , 57 , 81 ] . A number of recent projects , however , report on the use of workshops to characterize domain problems in just a few days of fo - cused work [ 16 , 17 , 18 , 35 , 66 , 89 ] . More speciﬁcally , these work - shops are creative visualization - opportunities workshops ( CVO workshops ) , in which researchers and their collaborators explore a broad space of opportunities for visualization in a domain , and then identify those that are most promising or interesting [ 17 ] . When used effectively , such workshops reduce the time and effort needed for the early stages of applied visualization work , as noted by one participant : “the interpersonal leveling and intense revisiting of concepts made more progress in a day than we make in a year of lab meetings . . . [ the workshop ] created consensus by exposing shared user needs” [ 35 ] . The CVO workshops reported in the literature were derived and adapted from software requirements workshops [ 33 ] and creative problem - solving workshops [ 1 ] to account for the speciﬁc needs of visualization design . These adaptations were necessary because exist - ing workshop guidance did not appropriately emphasize visualization speciﬁcs , such as : the mindset of visualization researchers and col - laborators , characterized by a deep and changing understanding of the domain challenges and relevant visualizations [ 55 ] ; the connection to visualization methodologies that include process and design decision models [ 63 , 81 ] ; and the use of workshop methods that focus on data analysis challenges and visualization opportunities [ 17 ] . The successful use of CVO workshops resulted from an ad hoc process in which researchers modiﬁed existing workshop guidance to meet the needs of their speciﬁc projects and reported the results in varying levels of detail . For example , Goodwin et al . [ 17 ] provide rich details , but with a focus on their experience using a series of work - • Ethan Kerzner and Miriah Meyer are with the University of Utah . E - mail : kerzner @ sci . utah . edu and miriah @ cs . utah . edu . • Sarah Goodwin is with the Royal Melbourne Institute of Technology and Monash University . E - mail : sarah . goodwin @ monash . edu . • Jason Dykes and Sara Jones are with City , University of London . E - mail : [ j . dykes , s . v . jones ] @ city . ac . uk . Manuscript received xx xxx . 201x ; accepted xx xxx . 201x . Date of Publication xx xxx . 201x ; date of current version xx xxx . 201x . For information on obtaining reprints of this article , please send e - mail to : reprints @ ieee . org . Digital Object Identiﬁer : xx . xxxx / TVCG . 201x . xxxxxxx / shops in a collaboration with energy analysts . In contrast , Kerzner et al . [ 35 ] summarize their workshop with neuroscientists in one sen - tence even though it profoundly inﬂuenced their research . Thus , there is currently no structured guidance about how to design , run , and an - alyze CVO workshops . Visualization researchers who are interested in using such workshops must adapt and reﬁne existing guidance from disparate workshop descriptions . In this paper , we — a group of visualization and creativity re - searchers who have been involved with every CVO workshop reported in the literature — reﬂect on our collective experience and offer guid - ance about how and why to use CVO workshops in applied visualiza - tion . More speciﬁcally , this paper results from a two - year international collaboration in which we applied a methodology of critically reﬂec - tive practice [ 7 ] to perform meta - analysis of our collective experience and research outputs from conducting 17 workshops in 10 visualiza - tion contexts [ 16 , 18 , 17 , 34 , 35 , 42 , 66 , 70 , 71 , 89 ] , as well as a review of the workshop literature from the domains of design [ 3 , 14 , 38 , 74 ] , software engineering [ 27 , 31 , 32 , 33 , 47 , 49 , 51 ] and creative problem - solving [ 13 , 19 , 21 , 60 , 68 ] . This paper’s primary contribution is a framework for CVO work - shops . The framework consists of 1 ) a process model that identiﬁes actions before , during , and after workshops ; 2 ) a structure that de - scribes what happens in the beginning , in the middle , and at the end of effective workshops ; 3 ) a set of 25 actionable guidelines for future workshops ; and 4 ) an example workshop and example methods for fu - ture workshops . To further enhance the actionability of the framework , in Supplemental Materials 1 we provide documents about : expanded details of the example workshop ; additional example methods ; and 21 pitfalls we have encountered when planning , running , and analyzing CVO workshops . We tentatively offer a secondary contribution : this work exempli - ﬁes critically reﬂective practice that enables us to draw upon multiple diverse studies to generate new knowledge about visualization in prac - tice . Towards this secondary contribution we include , in Supplemental Materials , an audit trail [ 10 , 41 ] of artifacts that shows how our think - ing evolved over the two - year collaboration . In this paper , we ﬁrst summarize the motivation for creating this framework and describe related work in Sec . 2 and 3 . Next , we de - scribe our workshop experience and reﬂective analysis methods in Sec . 4 and 5 . Then , we introduce the framework in Sec . 6 – 10 . After that , we discuss implications and limitations of the work in Sec . 11 . We conclude with future work in Sec . 12 . 1 http : / / vdl . sci . utah . edu / CVOWorkshops / 2 M OTIVATION AND B ACKGROUND In our experience , CVO workshops provide tremendous value to the applied visualization stakeholders — researchers and the domain spe - cialists with whom they collaborate . CVO workshops provide time for focused thinking about a collaboration , which allows stakeholders to share expertise and explore visualization opportunities . In feedback , one participant reported the workshop was “a good way to stop think - ing about technical issues and try to see the big picture” [ 18 ] . CVO workshops can also help researchers understand analysis pipelines , work productively within organizational constraints , and efﬁciently use limited meeting time . As one participant said : “the structured format helped us to keep on - topic and to use the short time wisely . It also helped us rapidly focus on what were the most critical needs going forward . At ﬁrst I was a little hesitant , but it was spot - on and wise to implement” [ 42 ] . Furthermore , CVO workshops can build trust , rapport , and a feeling of co - ownership among project stakeholders . Researchers and collab - orators can leave workshops feeling inspired and excited to continue a project , as reported by one participant : “I enjoyed seeing all of the in - formation visualization ideas . . . very stimulating for how these might be useful in my work” [ 18 ] . Based on these reasons , our view is that CVO workshops have saved us signiﬁcant amounts of time pursuing problem characterizations and task analysis when compared to traditional visualization design ap - proaches that involve one - on - one interviews and observations . What may have taken several months , we accomplished with several days of workshop preparation , execution , and analysis . In this paper we draw upon 10 years of experience using and reﬁning workshops to propose a framework that enables others use CVO workshops in the future . CVO workshops are based on workshops used for software re - quirements and creative problem - solving [ 17 ] . Software requirements workshops elicit speciﬁcations for large - scale systems [ 33 ] that can be used in requirements engineering [ 32 ] and agile development [ 26 ] . There are many documented uses of such workshops [ 31 , 49 , 50 , 51 ] , but they do not appropriately emphasize the mindset of visualization research that focuses on data and analysis . More generally , creative problem - solving workshops are used to identify and solve problems in a number of domains [ 68 ] . Many frameworks exist for such workshops [ 1 , 13 , 19 , 20 , 38 ] . Meta - analysis of these frameworks reveal common workshop characteris - tics that include : promoting trust and risk taking , exploring a broad space of ideas , providing time for focused work , emphasizing both problem ﬁnding and solving , and eliciting group creativity from the cross - pollination of ideas [ 65 ] . Existing workshop guidance , however , does not completely de - scribe how to use CVO workshops . The key distinguishing feature of CVO workshops is the explicit focus on visualization , which implies three visualization speciﬁcs for effective workshop guidance : • Workshops should promote a visualization mindset – the set of beliefs and attitudes held by project stakeholders , including an evolving understanding about domain challenges and visualiza - tion [ 55 , 81 ] – that fosters and beneﬁts an exploratory and visual approach to dealing with data while promoting trust and rapport among stakeholders [ 83 ] . • Workshops should contribute to visualization methodologies – the research practices and processes of visualization , including process and decision models [ 57 , 63 ] – by creating artifacts and knowledge useful in the visualization design process . • Workshops should rely on methods that explicitly focus on data visualization and analysis . This paper is , in part , about adopting and adapting creative problem - solving workshops to account for these visualization speciﬁcs . 3 R ELATED W ORK Workshops are commonly used in a number of ﬁelds , such as busi - ness [ 20 , 21 , 84 ] and education [ 2 , 8 ] . Guidance from these ﬁelds , however , does not emphasize the role of workshops in a design pro - cess , which is central to applied visualization . Therefore , we focus this section on workshops as visualization design methods . CVO workshops can be framed as a method for user - centered de - sign [ 67 ] , participatory design [ 62 ] , or co - design [ 75 ] because they in - volve users directly in the design process . We draw on work from these ﬁelds that have characterized design methods . Sanders et al . [ 74 ] , for example , characterize methods by their role in the design pro - cess . Biskjaer et al . [ 3 ] analyze methods based on concrete , con - ceptual and design space aspects . Vines et al . [ 87 ] propose ways of thinking about how users are involved in design . Dove [ 15 ] describes a framework for using data visualization in participatory workshops . A number of books also survey existing design methods [ 9 , 38 ] and practices [ 36 , 40 , 76 ] . These resources are valuable for understanding design methods , but do not account for visualization speciﬁcs , such as methodologies that emphasize the critical role of data early in the design process [ 43 ] . CVO workshops can also be framed within existing visualization design process and decision models [ 52 , 57 , 63 , 81 , 86 ] . More specif - ically , CVO workshops focus on eliciting opportunities for visualiza - tion software from collaborators . They support the understand and ideate design activities [ 57 ] or fulﬁll the winnow , cast , and discover stages of the design study methodology’s nine - stage framework [ 81 ] . A number of additional methods can be used in the early stages of applied work . Sakai and Aert [ 72 ] , for example , describe the use of card sorting for problem characterization . McKenna et al . [ 58 ] sum - marize the use of qualitative coding , personas , and data sketches in collaboration with security analysts . Koh and Slingsby [ 37 ] describe workshops that demonstrate a wide range of visualizations to domain collaborators ( that we have adapted for use in CVO workshops as de - scribed in Sec . 8 . 4 ) . And , Roberts et al . [ 69 ] describe a method for ex - ploring and developing visualization ideas through structured sketch - ing . This paper is about how to use these design methods , and others , within structured CVO workshops . Visualization education workshops are also relevant to CVO work - shops . Huron et al . [ 28 ] describe data physicalization workshops for constructive visualization with novices . He et al . [ 22 ] describe work - shops for students to think about the relationships between domain problems and visualization designs . In contrast , we frame CVO work - shops as a method for experienced researchers to pursue domain prob - lem characterization . There are opportunities for many participatory methods , such as constructive visualization [ 29 ] and sketching [ 90 ] , to be integrated into CVO workshops . 4 W ORKSHOP E XPERIENCE AND T ERMINOLOGY To write this paper , we gathered researchers who used workshops on three continents over the past 10 years . Our collective experience in - cludes 17 workshops in 10 contexts : 15 workshops in eight applied collaborations , summarized in Tab . 1 and Tab . 2 ; and two participa - tory workshops at IEEE VIS that focused on creating visualizations for domain specialists [ 70 , 71 ] . The ways in which we use workshops have evolved over 10 years . In three of our projects , we used a series of workshops to explore op - portunities , develop and iterate on prototypes , and evaluate the result - ing visualizations in collaborations with cartographers [ 16 ] , energy an - alysts [ 17 ] , and defense analysts [ 89 ] . In three additional projects , we used a single workshop to jump - start applied collaborations with neu - roscientists [ 35 ] , constraint programmers [ 18 ] , and psychiatrists [ 66 ] . Recently , we used two workshops to explore opportunities for funded collaboration with genealogists [ 34 ] and biologists [ 42 ] . Within our broad experience , we have focused our analysis on workshops that are used in the early stages of applied work or as the ﬁrst in a series of workshops . To describe these workshops , we devel - oped the term CVO workshops because they aim to deliberately and explicitly foster creativity while exploring opportunities for applied visualization collaborations . Focused on CVO workshops , our experience includes the eight workshops in Tab . 2 . Since we analyzed more data than appeared in any resulting publications , including artifacts and experiential knowl - edge , we refer to workshops and their projects by identiﬁers , e . g . , [ P1 ] refers to our collaboration with cartographers . In projects where we ID Year Domain Summary Workshops Result Prim . Supp . Ref . P1 2009 Cartography “Reimagining the legend as an exploratory visualization interface” 3 Paper JD * [ 16 ] P2 2012 Smart Homes Deliver insights into the role of smart homes and new business potential 4 Paper SG JD , SJ , * [ 17 ] P3 2012 Human terrain “develop [ visualization ] techniques that are meaningful in HTA” 3 Paper JD * [ 89 ] P4 2015 Neuroscience Explore problem - driven multivariate graph visualization 1 Paper EK MM , * [ 35 ] P5 2015 Constraint prog . Design performance proﬁling methods for constraint programmers 1 Paper SG * [ 18 ] P6 2017 Psychiatry Support visual analysis of determining or associated factors of suicide 1 Paper * EK , * [ 66 ] P7 2017 Genealogy Discover opportunities to support visual genealogy analysis 1 — * EK , MM , * [ 34 ] P8 2017 Biology Support phylogenetic analysis with visualization software 1 In - progress * EK , MM , * [ 42 ] Table 1 . Summary of the projects in which we have used CVO workshops : six resulted in publications [ P1 —P6 ] , one did not result in active collaboration [ P7 ] , and one is in - progress [ P8 ] . We characterize our involvement in these projects as either the primary researcher or as supporting researchers . The * represents colleagues who were involved in each project but not co - authors of this paper . ID Theme Facil . Partic . Hrs P1 Explore possibilities for enhancing leg - ends with visualizations 1v 3v / 5c 6 P2 Identify future opportunities for utilising smart home data / technologies 2v / 1p 0v / 5c 6 P3 Identify novel visual approaches most suitable for HTA 1v / 1p 7v / 6c 9 P4 Explore shared user needs for visualiza - tion in retinal connectomics 4v 0v / 9c 7 P5 Identify analysis and vis . opportunities for improved proﬁling of cons . prog . 2v / 1c 0v / 10c 7 P6 Understand the main tasks of psychiatric researchers 2v 1v / 6c 3 P7 Explore opportunities for a design study with genealogists 1v 3v / 7c 3 P8 Explore opportunities for funded collab - oration between vis . and bio . 1v / 1c 2v / 12c 7x2 Table 2 . Summary of the CVO workshop used in each project . We describe workshops by their theme , a concise statement the topics ex - plored . We characterize workshop stakeholders as facilitators or par - ticipants categorized by their afﬁliation as ( v ) isualization researchers , ( c ) ollaborators , or ( p ) rofessional facilitators . Our workshops included 5 – 14 participants and ranged in length from half a day to 2 days . used more than one workshop [ P1 – P3 ] , the identiﬁer corresponds to the ﬁrst workshop in the series , unless otherwise speciﬁed . To describe our experience , we developed terminology for the role of researchers involved in each project . The primary researcher is responsible for deciding to use a CVO workshop , executing the it , and integrating its results into a collaboration . Alternatively , supporting researchers provide guidance and support to the primary researcher . We have been involved with projects as both primary and supporting researchers ( see Tab . 1 ) . We also adopt terminology to describe CVO workshops . Work - shops are composed of methods , speciﬁc repeatable activities [ 12 ] . The methods are designed around a theme that identiﬁes the work - shop’s central topic or purpose [ 8 ] . The facilitators plan and guide the workshop and the participants carry out the workshop methods . Typically the facilitators are visualization researchers and participants are domain collaborators . But , visualization researchers can partici - pate [ P1 , P3 ] and collaborators can facilitate [ P5 , P8 ] . We adopted and reﬁned this vocabulary during our reﬂective analysis . 5 R ESEARCH P ROCESS The contributions in this paper arise from reﬂection — the analysis of experiences to generate insights [ 5 , 79 ] . More speciﬁcally , we applied a methodology of critically reﬂective practice [ 7 ] , summarized by Thompson [ 85 ] as “synthesizing experience , reﬂection , self - awareness and critical thinking to modify or change approaches to practice . ” We analyzed our collective experience and our CVO workshop data , which consisted of documentation , artifacts , participant feedback , and research outputs . The analysis methods that we used can be described through the metaphorical lenses of critically reﬂective practice : • The lens of our collective experience — we explored and artic - ulated our experiential knowledge through interviews , discus - sions , card sorting , afﬁnity diagramming , observation listing , and observations - to - insights [ 38 ] . We codiﬁed our experience , individually and collectively , in both written and diagram form . We iteratively and critically examined our ideas in light of work - shop documentation and artifacts . • The lens of existing theory — we grounded our analysis and resulting framework in the literature of creativity and work - shops [ 3 , 1 , 13 , 19 , 21 , 60 , 65 , 68 , 77 , 78 , 82 ] as well as vi - sualization design theory [ 57 , 63 , 80 , 86 ] . • The lens of our learners ( i . e . , readers ) — in addition to intertwin - ing our analysis with additional workshops , we shared drafts of the framework with visualization researchers and we used their feedback to make the framework more actionable and consistent . Our reﬂective analysis , conducted over two years , was messy and iterative . It included periods of focused analysis and writing , followed by reﬂection on what we had written , which spurred additional analy - sis and rewriting . Throughout this time , we generated diverse artifacts , including models for thinking about how to use workshops , written re - ﬂections on which methods were valuable to workshop success , and collaborative writing about the value of workshops . This paper’s Sup - plemental Material contains a timeline of signiﬁcant events in our re - ﬂective analysis and 30 supporting documents that show how our ideas evolved into the following framework . 6 F UNDAMENTALS OF THE F RAMEWORK The framework proposed in this paper describes how and why to use CVO workshops . We use the term framework because what we have created provides an interpretive understanding and approach to prac - tice instead of causal or predictive knowledge [ 30 ] . The framework is a thinking tool to navigate the process of planning , running , and ana - lyzing a workshop , but we note that it cannot resolve every question about workshops because the answers will vary with local experience , preference , and context . In this section we describe a set of factors that contribute to workshop effectiveness , as well as introduce the work - shop process model and structure . We intend for the framework to be complemented by existing workshop resources from outside of visu - alization [ 1 , 8 , 20 , 21 ] . 6 . 1 Tactics for Effective Workshops Reﬂecting on our experience and reviewing the relevant literature [ 65 , 68 , 77 , 78 , 82 ] enables us to identify several key factors that contribute to the effectiveness of workshops : focusing on the topic of visual - ization , data and analysis , while fostering , maintaining , and potentially varying the levels of agency , collegiality , trust , inter - est , and challenge associated with each . We term these factors TACTICs for effective workshops : • ( T ) opic — the space of ideas relevant to data , visualization , and domain challenges in the context of the workshop theme ; • ( A ) gency — the sense of stakeholder ownership in the work - shop contributions , outcomes and the research project ; • ( C ) ollegiality — the degree to which communication and collaboration occur among stakeholders ; • ( T ) rust – the conﬁdence that stakeholders have in each other , the workshop , the design process , and the researcher’s expertise ; Fig . 1 . The framework’s two models are 1 ) a process model ( left ) that describes the common actions before , during , and after workshops ; and 2 ) a structure that describes principles for methods used in the begin - ning , in the middle , and at the end of workshops . In these models , we propose 25 guidelines for future workshops , summarized here . • ( I ) nterest — the amount of attention , energy , and engage - ment to workshop methods by the stakeholders ; • ( C ) hallenge — the stakeholders’ barrier of entry to , and likelihood of success in , workshop methods ; The TACTICs are not independent , consistent , or measurable . The extent to which they are fostered depends upon the context in which they are used , including various characteristics of the workshop — of - ten unknown in advance , although perhaps detectable by facilitators . Yet , selecting methods to maintain appropriate levels of agency , in - terest , and trust — while varying levels of challenge and approaching the topic from different perspectives — likely helps workshops to have a positive inﬂuence on the mindset of stakehold - ers and to generate ideas that move forward the methodology of the project . Hence , we refer to the TACTICs throughout this framework . 6 . 2 Process Model and Structure The framework proposes two models for describing how to use CVO workshops : a process model and a workshop structure . The models were adapted from the extensive literature that describes how to use workshops outside of visualization [ 1 , 8 , 13 , 15 , 20 , 21 , 68 ] . The process model ( Fig . 1 ( left ) ) consists of three stages that de - scribe the actions of using CVO workshops : 1 . Before : deﬁne & design . Deﬁne the workshop theme and de - sign workshop methods , creating a ﬂexible workshop plan . 2 . During : execute & adapt . Perform the workshop plan , adapting it to participants’ reactions in light of the TACTICs , generating workshop output as a set of rich and descriptive artifacts and documentation . 3 . After : analyze & act . Make sense of the workshop output and use it in the downstream design process . Nested within the process is the CVO workshop structure ( Fig . 1 ( right ) ) that identiﬁes key aspects of the methods used in the begin - ning , middle , and end of workshops : 1 . Opening . Establish shared context and interest while pro - moting trust , agency , and collegiality . 2 . Core . Promote creative thinking about the topic , potentially varying challenge to maintain interest . 3 . Closing . Provide time for reﬂection on the topic and promote continued collegiality in the collaboration . The process model and structure are closely connected as shown by the orange box in Fig . 1 . As part of the workshop process , we design and execute a workshop plan . This plan follows the workshop struc - ture because it organizes methods into the opening , core , and closing . In other words , the process is about how we use a workshop ; the struc - ture is about how methods are organized within a workshop . We use the process model and structure to organize the following four sections of this paper . In these sections , we use paragraph - level headings to summarize 25 actionable workshop guidelines . Addition - ally , in Supplemental Materials we include a complementary set of 21 pitfalls that are positioned against these guidelines and the TACTICs to further enhance the actionability of the framework . 7 B EFORE THE W ORKSHOP : D EFINE & D ESIGN Creating an effective CVO workshop is a design problem : there is no single correct workshop , the ideal workshop depends on its intended outcomes , and the space of possible workshops is practically inﬁnite . Accordingly , workshop design is an iterative process of deﬁning a goal , testing solutions , evaluating their effectiveness , and improving ideas . The framework we have developed here is part of this pro - cess . In this section , we introduce four guidelines — summarized in paragraph - level headings — for workshop design . Deﬁne the theme . Just as design starts with deﬁning a problem , creating a CVO workshop starts with deﬁning its purpose , typically by articulating a concise theme . An effective theme piques inter - est in the workshop through a clear indication of the topic . It en - courages a mindset of mutual learning among stakeholders . It also focuses on opportunities that exhibit the appropriate task clarity and information location of the design study methodology [ 81 ] . Examples from our work emphasize visualization opportunities ( e . g . , “enhanc - ing legends with visualizations” [ P1 ] ) , domain challenges ( e . g . , “iden - tify analysis and visualization opportunities for improved proﬁling of constraint programs” [ P5 ] ) , or broader areas of mutual interest ( e . g . , “explore opportunities for a funded collaboration with phylogenetic analysts” [ P8 ] ) . Although we can improve the theme as our understanding of the domain evolves , posing a theme early can ground the design process and identify promising participants . Recruit diverse and creative participants . We recruit partici - pants who have relevant knowledge and diverse perspectives about the topic . We also consider their openness to challenge and poten - tial collegiality . Examples of effective participants include a mix of frontline ana - lysts , management , and support staff [ P4 ] ; practitioners , teachers , and students [ P5 ] ; or junior and senior analysts [ P6 ] . We recommend that participants attend the workshop in - person because remote participa - tion proved distracting in one workshop [ P8 ] . Recruiting fellow - tool builders [ 81 ] as participants should be approached with caution be - cause their perspectives may distract from the topic — this happened in our workshop that did not result in active collaboration [ P7 ] . Design within constraints . Identifying constraints can help win - now the possibilities for the workshop . Based on our experience , the following questions are particularly useful for workshop design : • Who will use the workshop results ? Identifying the primary re - searcher early in the process is critically important because they will be responsible for the workshop and ultimately use its re - sults . In a workshop where we did not clearly identify the pri - mary researcher , the results went unused [ P7 ] . • How many participants will be in the workshop ? We typically recruit 5 - 15 participants — a majority domain collaborators , but sometimes designers and researchers [ P1 , P3 , P6 – P8 ] . • Who will help to facilitate the workshop ? We have facilitated our workshops as the primary researcher , with the assistance of sup - porting researchers or professional workshop facilitators . Do - main collaborators can also be effective facilitators , especially if the domain vocabulary is complex and time is limited [ P5 , P8 ] . • How long will the workshop be ? Although we have run work - shops that range from half a day [ P6 , P7 ] to two days [ P8 ] , these extremes either feel rushed or require signiﬁcant commitment from collaborators . We recommend that an effective workshop lasts about one working day . • Where will the workshop be run ? Three factors are particularly important for determining workshop venue : a mutually conve - nient location , a high quality projector for visualization exam - ples , and ample space to complete the methods . We have had success with workshops at offsite locations [ P2 , P3 ] , our work - places , and our collaborators’ workplaces [ P4 – P6 ] . • What are additional workshop constraints ? Examples include the inability of collaborators to share sensitive data [ P3 , P6 ] and the available funding . Test the methods and materials . Piloting ( i . e . , testing ) methods can ensure that the workshop will generate ideas relevant to the topic while maintaining appropriate levels of interest and challenge . We have piloted methods to evaluate how understandable they are [ P2 , P4 ] , to test whether they create results that can be used in the visualization design methodology [ P6 , P8 ] , to ﬁnd mistakes in their prompts [ P2 , P4 , P6 , P8 ] , and to ensure that the materials are effective — e . g . , sticky notes are the correct size and visualizations are readable on the projector . It is also useful to pilot workshops with proxy participants , such as researchers [ P4 ] or collaborators [ P8 ] . Feedback from collaborators during pilots has helped us to revise the theme , to identify promising participants , and to reﬁne the workshop methods . 8 W ORKSHOP S TRUCTURE AND M ETHODS This section describes guidelines for the methods used in the three phases of the CVO workshop structure ( described in Sec . 6 . 2 ) — the opening , core , and closing . It concludes with a summary of an exam - ple workshop and resources for additional workshop methods . 8 . 1 Workshop Opening The workshop opening communicates the goals and guidelines for par - ticipants , but it can be more than that . It can foster agency by encour - aging self - expression and idea generation . It can encourage colle - giality and trust by promoting open communication , acknowl - edging expertise , and establishing a safe co - owned environment . It can also garner interest by showing that the workshop will be useful and enjoyable . Two guidelines contribute to an effective opening . Set the stage — engage . CVO workshops typically open with a short introduction , reiterating the theme and establishing shared con - text for participants and facilitators . We have introduced workshops as “guided activities that are meant to help us understand : what would you like to do with visualization ? ” [ P4 ] . We have also used graphics that summarize the goals of our project , potentially priming partici - pants to engage with the topic of visualization [ P3 ] . The opening can establish principles for creativity [ 1 , 68 ] , poten - tially fostering trust and collegiality . We used the following principles in one of our workshops [ P2 ] : 1 ) all ideas are valid , express and record them ; 2 ) let everyone have their say ; 3 ) be supportive of others ; 4 ) instead of criticizing , create additional ideas ; 5 ) think ‘pos - sibility’ – not implementation ; 6 ) speak in headlines and follow with detail ; and 7 ) switch off all electronic devices . Introduction presentations should be kept short to maintain in - terest . Passive methods , such as lectures and presentations , can discourage participation at the outset . For example , we started one workshop [ P8 ] with a presentation on the current state of analysis tools . This presentation encouraged participants to passively listen rather than actively explore , establishing a passive mindset that we had to overcome in subsequent methods . An effective opening en - gages participants . Encourage self - expression . We use methods that encourage self - expression to support interpersonal leveling and to act on the cre - ativity principles — all ideas are valid and be supportive of others . Such interpersonal methods help to establish an atmosphere of trust and collegiality among participants and facilitators . They can also provide participants with a sense of agency [ 8 ] . We have used interpersonal methods that ask participants to sketch ideas while suspending judgment [ 71 ] ( see Visual Improv . in Sup - plemental Material ) or to introduce themselves through analogies as a potential primer for creativity ( see Sec . 8 . 4 ) . Overall , we use interper - sonal methods in the opening to engage participants and facilitators , preparing them for the workshop core . 8 . 2 Workshop Core In the workshop core , we harness the active and engaged mindset of participants by encouraging them to explore a wide ideaspace before selecting the more promising ideas . The methods in the core poten - tially generate hundreds of post - it notes , sketches , and other artifacts . Analysis of our experience and relevant literature leads us to suggest ﬁve guidelines for an effective core . Elicit visualization opportunities . We select workshop meth - ods relevant to the topic , asking participants about their current anal - ysis challenges , limitations of existing tools , characteristics of their data , or the ways in which they would like to use visualization . This can be achieved by adding a visualization twist to existing design and workshop methods . In one workshop [ P3 ] , for example , we used a method that “de - veloped user stories , considered relevant datasets , discussed alterna - tive scenarios and sketched solutions with our domain collaborators . In retrospect , this method connected the topic into a more general workshop method , user stories [ 38 ] . Explore , then focus . We organize the core to ﬁrst generate ideas using divergent methods that expand the ideaspace . Then , we evalu - ate ideas using convergent methods that winnow the ideaspace [ 68 ] . Using divergent methods early in the core allows us to consider many possibilities while also promoting agency and maintaining inter - est . Then , convergent methods can narrow the ideaspace to the more promising ideas . Classifying methods as either divergent or convergent risks over - simpliﬁcation as individual methods often include both divergent and convergent aspects . Consider our use of brainstorming [ 68 ] during one workshop [ P1 ] , we asked participants to record “problems and successes associated with the current clients on sticky notes” ( diver - gent ) and then to share the more interesting ideas ( convergent ) . We classify this method as divergent because it creates ideas , despite the convergent discussion . In contrast , a convergent method may only in - volve grouping sticky notes notes from previous methods . Overall , in line with existing workshop guidance [ 1 , 13 , 21 , 68 ] , we judge meth - ods by their intended impact on the ideaspace and organize the core with phases of divergent and convergent methods . Create physical and visual artifacts . We select methods by how they encourage participants to write , draw , or otherwise external - ize their ideas . Externalizing ideas creates artifacts for us to analyze after the workshop . It aids creative thinking because expressing an idea forces the creator to elaborate it [ 78 ] , and promotes idea sharing that encourages collegiality . We consider the artifact materials to be important . sticky notes are particularly useful because they enable participants to group or rank ideas and potentially to discover emergent concepts in the ideas - pace [ 15 ] . We have used sticky notes in almost all of our workshops , often using their color to encode information about which method generated an idea , and their positions to relate , differentiate , or rank ideas . This can help establish consensus . This can aid post - workshop analysis by recording how ideas evolved and were valued throughout the workshop . Additional materials effective for externalizing ideas include handouts with structured prompts , butcher paper , and poster boards . Using whiteboards is tempting , but ideas are easily lost if the boards are erased . We also consider the form of ideas to be important . Effective meth - ods create artifacts relevant to the theme and topic of visualization . This can be achieved through the use of visual language ( See : Wish - ful Thinking in Sec . 8 . 4 ) and by encouraging participants to sketch or draw , such as in storyboarding [ P2 , P4 , P5 ] . We see many opportuni - ties to create visual artifacts using existing methods , such as sketching with data [ 90 ] , constructive visualizations [ 29 ] , or parallel prototyp - ing [ 69 ] approaches . Balance activity with rest . Because continuously generating or discussing ideas can be tiring for participants , we structure workshop methods to provide a balance between activity and rest . Speciﬁcally , we incorporate passive methods that provide time for incubation , the conscious and unconscious combination of ideas [ 78 ] . Passive methods can include short breaks with food and coffee , in - formal discussions over meals , or methods where participants listen to presentations . When using methods that present ideas , asking partici - pants to record their thoughts and reactions can promote interest and maintain a feeling of agency . We have typically used passive methods in full - day workshops [ P2 , P4 , P5 , P8 ] , but we rely on breaks between methods for shorter workshops [ P6 ] . Mix it up . We consider the relationships among methods to be im - portant as we strive to balance exploration with focus and activity with rest , while also using many materials for externalizing ideas . Con - sidering methods that vary these factors can provide different levels of challenge because , for example , methods that require drawing ideas may be more difﬁcult than discussing ideas . Using a variety of methods may also maintain interest because participants may be - come bored if too much time is spent on a speciﬁc idea . Transition smoothly . We avoid potentially jarring transitions be - tween methods to preserve participant interest . Convergent dis - cussions can be used to conclude individual methods by highlighting the interesting , exciting , or inﬂuential ideas . These discussions can promote collegiality by encouraging communication of ideas , agency by validating participants’ contributions , and interest in the ideas generated . Convergent discussions also highlight potentially important ideas for researchers to focus on after the workshop . Convergent methods can also conclude the workshop core by grouping or ranking key ideas . We have used storyboarding to en - courage the synthesis of ideas into a single narrative [ P2 , P4 , P5 ] . We have also asked participants to rank ideas , providing cues for analyz - ing the workshop results [ P3 ] . Convergent methods provide a sense of validation , potentially helping to build trust among researchers and collaborators as we transition to the closing . 8 . 3 Workshop Closing The workshop closing sets the tone for continued collaboration . It is an opportunity to promote collegiality by reﬂecting on the shared creative experience . It allows for analysis that can potentially identify the more interesting visualization opportunities . The following two guidelines apply to effective closings . Encourage reﬂection for validation . We use discussions at the end of workshops to encourage reﬂection , potentially providing vali - dation to participants and generating information valuable for work - shop analysis . We encourage participants to reﬂect on how their ideas have evolved by asking “what do you know now that you did not know this morning ? ” [ P5 ] or ”what will you do differently tomorrow , given what you have learned today ? ” [ P2 ] . Responses to these questions can provide validation for the time committed to the workshop . One participant , for example , reported “I was surprised by how much over - lap there was with the challenges I face in my own work and those faced by others” [ P5 ] . Promote continued collaboration . We conclude the workshop by identifying the next steps of action — continuing the methodol - ogy of the collaboration . We can explain how the ideas will be used to move the collaboration forward , often with design methods as we describe in Sec . 10 . We can also ask participants for feedback about the workshop to learn more about their perceptions of visualization and to evaluate the effectiveness of workshop methods — encouraging the mindset . E - mailing online surveys immediately after a workshop is effective for gathering feedback [ P4 , P8 ] . …take notes… Group discussion Individually… Assume that already exists . What else do you want to KNOW / DO / SEE ? . . . share . . . Share , discuss and iden = fy common themes Think about the aspira7ons for your data… What would you like to KNOW ? What would you like to DO ? What would you like to SEE ? Think of analogies to your domain . What visual aspects do you like / dislike ? In small groups choose an idea . . View examples… Opening Presenta - on ( passive ) Analogy Introduc - on ( ac7ve , divergent ) Wishful Thinking ( ac7ve , divergent ) Barrier Removal ( ac7ve , divergent ) Lunch & Excursion ( passive , divergent ) Visualiza - on Analogies ( passive , divergent ) Storyboarding ( ac7ve , convergent ) Reﬂec - ve Discussion ( ac7ve , convergent ) c l o s i n g c o r e o p e n i n g Describe how your image represents your feelings about the collabora7on . Fig . 2 . The 8 methods of the full - day , example CVO workshop ( left ) with the process of 3 methods summarized graphically ( right ) . The work - shop methods diverge to explore a broad ideaspace before they con - verge to the more promising ideas . Three of the methods are described in the text and the remainder are explained in the Supplemental Mate - rial . The methods can be summarized as : 1 ) the opening presentation establishes creativity principles ; 2 ) an analogy introduction promotes interpersonal leveling ; 3 ) wishful thinking elicits opportunities for visual - ization ; 4 ) barrier removal explores those opportunities further ; 5 ) lunch & excursion provides time for rest and incubation ; 6 ) visualization analo - gies allows speciﬁcation of requirements by example ; 7 ) storyboarding summarizes key ideas in a graphic form ; and 8 ) the reﬂective discus - sion highlights potentially interesting ideas for workshop analysis . This workshop plan is a starting point for future workshops . 8 . 4 Example Workshop & Methods To illustrate the workshop structure , we include an example work - shop , which is shown in Fig . 2 . We selected this example because it has proven effective in three of our projects [ P2 , P4 , P5 ] . Here , we describe three methods of this workshop that we have also used suc - cessfully in additional workshops [ P8 , P6 ] , and we refer to the Sup - plemental Material for descriptions of the remaining ﬁve methods . We emphasize that this is a starting place for thinking about workshops , and encourage that methods be adopted and adapted for local context . To explain the workshop methods we refer to their process — the steps of execution [ 3 ] . This process description abstracts and simpli - ﬁes the methods because during their execution we adapt the process based on participant reactions and our own judgment of the TACTICs . Analogy Introduction We have used this active , interpersonal , and potentially divergent method in the workshop opening . A process of this method , shown in Fig 2 ( right , top ) , starts with a facilitator posing the analogy intro - duction prompt , e . g . , “if you were to describe yourself as an animal , what would you be and why ? ” [ P2 ] . The facilitators and participants then respond to the prompt in turn — expressing themselves creatively . Because everyone responds to the eccentric prompt , this method supports interpersonal leveling that helps to develop trust and col - legiality among stakeholders . Using analogy can prime partici - pants to think creatively [ 19 ] . This method is simple to execute and participants report that it has a profound impact on the workshop because of the leveling that occurs . It helps to establish trust and that all ideas should be accepted and explored [ P4 ] . A more topical alternative requires a little more preparation . We have asked participants to come to the workshop with an image that represents their feelings about the project . Participants have created realistic images , clip - art , and sketches to present and discuss . This visual introductions can help establish the topic of visualization . Wishful Thinking We have used this divergent , active method early in the workshop core . It is based on creativity methods to generate aspirations [ 24 ] . We tai - lored these methods to visualization by prompting participants with a domain scenario and asking questions : “What would you like to know ? What would you like to do ? What would you like to see ? ” One process of this method is shown in Fig . 2 ( right , middle ) . First , we introduce the prompt and participants answer the know / see / do questions individually on sticky notes . Next , participants share ideas in a large group to encourage collegiality and cross - pollination of ideas . Then , participants form small groups and try to build on their responses by selecting interesting ideas , assuming that they have been completed , and responding to the know / see / do questions again — in - creasing the challenge . Finally , we lead a convergent discussion to highlight interesting ideas and to transition to the next method . We encourage participants to record answers to the know / see / do questions on different color sticky notes because each prompt provides information that is useful at different points in the design process . Par - ticipants describe analysis tasks that they would like to do or envisaged insights they would like to know . Asking what participants would like to see is often more of a challenge , but ensures that a topic of visualization is established early . We tailor the prompt to the workshop theme and project goals . For example , we asked energy analysts about long term goals for their project — “aspirations for the Smart Home programme . . . ” They gen - erated forward - thinking ideas , e . g . , to better understand the value of the data [ P2 ] . In contrast , we asked neuroscientists about their current analysis needs — “suppose you are analyzing a connectome . . . ” . They generated shorter term ideas , e . g . , to see neuron connectivity [ P4 ] . Visualization Analogies We have used this divergent , initially passive method later in the workshop core because it promotes incubation while allowing par - ticipants to specify visualization requirements by example . Similar to analogy - based creativity methods [ 19 ] and the visualization aware - ness method [ 37 ] , we present a curated collection of visualizations and ask participants to individually record analogies to their domain and to specify aspects of the visualizations that they like or dislike . We have used this method repeatedly , iteratively improving its process by re - ﬂecting on what worked in a number of our workshops [ P1 – P5 , P8 ] . One process of this method is shown in Fig . 2 ( right , bottom ) . First , we provide participants with paper handouts that contain a representa - tive image of each visualization . ( We have encouraged participants to annotate the handouts , externalizing their ideas [ P4 , P5 , P8 ] . ) Next , we present the curated visualizations on a projector and ask participants to think independently about how each visualization could apply to their domain and to record their ideas . Then , we discuss these visualizations and analogies in a large group . We curate the example visualizations to increase interest and establish participants’ trust in our visualization expertise . We have used visualizations that we created ( to show authority and credibility ) ; those that we did not create ( for diversity and to show knowledge of the ﬁeld ) ; older examples ( to show depth of knowledge ) ; challenging ex - amples ( to stretch thinking ) ; playful examples ( to support engagement and creativity ) ; closely related examples ( to make analogies less of a challenge ) ; and unrelated examples ( to promote more challenging divergent thinking ) . The discussions during this method have expanded the workshop ideaspace in surprising ways , including “what does it mean for leg - ends to move ? ” [ P1 ] , “what does it mean for energy to ﬂow ? ” [ P2 ] , and “what does it mean for neurons to rhyme ? ” [ P4 ] . Because this method is initially passive , it gives participants room to think individ - ually . They reported that it is engaging and inspiring to see the broad possibilities of visualization and discuss how such visualizations apply to their domain . Additional Methods & Resources We introduce the example workshop and methods as starting points for future workshops . The workshop design space is practically inﬁnite and design should be approached with creativity in mind . To help researchers navigate the design space , our Supplemental Material contains a list of 15 example methods that we have used or would consider using in future workshops . For these methods , we de - scribe their process , their inﬂuence on the workshop ideaspace , their level of activity , and their potential impact on the TACTICs for effec - tive workshops . We have also found other resources particularly useful while de - signing workshops . These include books [ 1 , 20 , 21 , 25 , 38 , 59 ] , web - sites [ 48 , 64 ] , and research papers [ 56 , 57 , 73 ] . Although these re - sources target a range of domains outside of visualization , we tailor the workshop methods to encourage a visualization mindset , and to focus on the topic of visualization opportunities . 9 D URING T HE W ORKSHOP : E XECUTE & A DAPT Continuing the CVO workshop process model ( shown in Fig . 1 ) , we execute the workshop plan . This section proposes ﬁve guidelines for workshop execution . Prepare to execute . We prepare for the workshop in three ways : resolving details , reviewing how to facilitate effectively , and checking the venue . We encourage researchers to prepare for future workshops in the same ways . We prepare by resolving many details , such as inviting participants , reserving the venue , ordering snacks for breaks , making arrangements for lunch , etc . Brooks - Harris and Stock - Ward [ 8 ] summarize many practical details that should be considered in preparing for execution . Our additional advice is simply to promote the visualization mindset wherever possible in preparing workshops . We prepare by reviewing principles of effective facilitation , such as acting professional , demonstrating acceptance , providing encourage - ment , and using humor [ 8 , 1 , 20 , 21 , 84 ] . We also assess our knowl - edge of the domain because , as facilitators , we will need to lead discus - sions . Effectively leading discussions can increase collegiality and trust between stakeholders as participants can feel that their ideas are valued and understood . In cases where we lacked domain knowledge , we recruited collaborators to help facilitate [ P5 , P8 ] . We also prepare by checking the venue for necessary supplies , such as a high quality projector , an Internet connection ( if needed ) , and am - ple space for group activity . Within the venue , we arrange the furniture to promote a feeling of co - ownership and to encourage agency — a semi - circle seating arrangement works well for this [ 88 ] . A mistake in one of our workshops was to have a facilitator using a podium , which implied a hierarchy between facilitators and participants , hin - dering collegiality [ 70 ] . Limit distractions . Workshops provide a time to step away from normal responsibilities and to focus on the topic . Accordingly , par - ticipants and facilitators should be focused on the workshop without distractions , such as leaving for a meeting . Communicating with people outside of the workshop — e . g . , through e - mail — commonly distracts participants and facilitators . It should be discouraged in the workshop opening ( e . g . , switch off all electronic devices ) . Principles in the workshop opening , however , should be justiﬁed to participants . Also , facilitators should lead by example at the risk of eroding trust and collegiality . Guide gently . While starting execution , the workshop opening can establish an atmosphere in which participants take initiative in com - pleting methods . It is , however , sometimes necessary to redirect the participants in order to stay focused on the topic . Conversations that deviate from the day’s focus should be redirected . In one workshop [ P4 ] , participants were allowed to discuss ideas more freely and they reported in feedback that “we had a tendency to get distracted [ during discussions ] . ” In a later workshop [ P8 ] , we more conﬁdently guided discussions , and participants reported “we were guided and kept from going too far off track . . . this was very effective . ” . However , guiding participants requires judgment to determine whether a conversation is likely to be fruitful . It also requires us to be sensitive to the TACTICs — e . g . , how would redirecting this con - versation inﬂuence collegiality or agency ? Redirection can be jolting and can contradict some of the guidelines ( e . g . , “all ideas are valid” ) . We may prepare participants for redirection with another guideline during the workshop opening : “facilitators may keep you on track gently , so please be sensitive to their guidance . ” Be ﬂexible . As we guide participants to stay on topic , it is impor - tant to be ﬂexible in facilitation . For example , we may spend more time than initially planned on fruitful methods , or cut short methods that bore participants . Following this guideline can also blur the distinction between par - ticipants and facilitators . In one workshop [ P3 ] , participants proposed a method that was more useful than what was planned . Thus , they became facilitators for this part of the workshop , which reinforced agency and maintained the interest of all stakeholders in the project . In the future , we may explore ways to plan this type of inter - action , perhaps encouraging participants to create their own methods . Adapt tactically . As we guide the workshop , we interpret group dynamics and adapt methods to the changing situation . We can be forced to adapt for many reasons , such as a failing method ( nobody feels like an animal this morning ; sticky notes don’t stick ) , a loss of interest ( there is no energy ; the room is too hot ; we had a tough away day yesterday ) ; a lack of agency ( some participants dominate some tasks ) ; or an equipment failure ( projector does not work ; no WiFi connection to present online demos [ P2 ] ) . Designing the workshop with alternative methods in mind — perhaps with varying degrees of challenge — can ensure that workshop time is used effectively . Record ideas collectively . Remember : conversations are ephemeral and anything not written down will likely be forgotten . We therefore encourage facilitators and participants to document ideas with context for later analysis . Selecting methods to create physical ar - tifacts can help with recording ideas . As described in Sec . 8 , external - izing ideas on sticky notes and structured prompts has been effective in our workshops and addresses the visualization mindset . We are uncertain about the use of audio recording to capture work - shop ideas . Although it can be useful for shorter workshops [ P6 ] , it can require tremendous time to transcribe before analysis [ 43 ] . Also , recording audio effectively can be challenging as participants move around during the methods . It can be useful to ensure that facilitators know that they are ex - pected to help document ideas . A pilot workshop can help with this . In at least one of our projects [ P5 ] , a pilot workshop may have reduced the note taking pressure on the primary researcher during execution . 10 A FTER THE W ORKSHOP : A NALYZE & A CT After the CVO workshop , we analyze its output and use the results of that analysis to inﬂuence the on - going collaboration . Here , we de - scribe ﬁve guidelines for this analysis and action . Allocate time for analysis . Soon . Effective workshops generate rich and inspiring artifacts that can include hundreds of sticky notes , posters , sketches , and other documents . The exact output depends on the methods used in the workshop . Piloting methods can help prepare researchers for the analysis . Regardless , making sense of this output is labor intensive , often requiring more time than the workshop itself . Thus , it is important that we allocate time for analysis , particularly within a day of the workshop , so that we can analyze output while ideas are fresh in our memory . Create a corpus . We usually start analysis by creating a digital corpus of the workshop output . We type or photograph the artifacts , organizing ideas into digital documents or spreadsheets . Through this process , we become familiar with key ideas contained in the artifacts . The corpus also preserves and organizes the artifacts , potentially al - lowing us to enlist diverse stakeholders — such as facilitators and col - laborators — in analysis [ P4 ] . This can help in clarifying ambiguous ideas or adding context to seemingly incomplete ideas . Analyze with an open mind . Because the ideas in the workshop output will vary among projects , there are many ways to analyze this corpus of artifacts . We have used qualitative analysis methods — open coding , mindmapping , and other less formal processes — to group artifacts into common themes or tasks [ P2 , P4 – P7 ] . Quantitative analysis methods should be approached with caution as the frequency of an idea provides little information about its potential importance . We have ranked the themes and tasks that we discovered in analysis according to various criteria , including novelty , ease of development , potential impact on the domain , and relevance to the project [ P2 , P4 – P6 ] . In other cases [ P1 , P3 ] , workshop methods generated speciﬁc requirements , tasks , or scenarios that could be edited for clarity and directly integrated into the design process . We encourage that analysis be approached with an open mind be - cause there are many ways to make sense of the workshop data , in - cluding some approaches that we may not yet have considered . Embrace results in the visualization design process . Simi - larly , there are many ways to integrate the workshop results into the visualization design process and methodology . We have run addi - tional workshops that explored the possibilities for visualization de - sign [ P1 , P2 ] . We have applied traditional user - centered design meth - ods , such as interviews and contextual inquiry , to better understand collaborator’s tasks [ P4 ] . We have created prototypes of varying ﬁ - delity , from sketches to functioning software [ P4 , P5 , P6 ] . And , we have identiﬁed key aims in proposals for funded collaboration [ P8 ] . In all of these cases , our actions were based on the reason why we ran the workshop and the workshop results profoundly inﬂuenced the direction of our collaboration . For example , in our collaboration with neuroscientists , the workshop helped us focus on graph connectivity , a topic that we were able to explore with technology probes and pro - totypes of increasing ﬁdelity , ultimately resulting in new visualization tools and techniques [ P4 ] . Revisit , reﬂect , and report on the workshop . The workshop output is a trove of information that can be revisited throughout ( and even beyond ) the project . It can be used to document the evolution of ideas that occurs throughout applied collaborations . It can also be used to evaluate and validate design decisions in resulting publications by demonstrating that any resulting software fulﬁlls analysis needs iden - tiﬁed by the workshop data [ P1 – P6 ] . In our experience of reﬂecting on the outputs from our own workshops during the development of the ideas in this paper , we also found new insights that we had not seen previously – revisiting workshop output repeatedly throughout a project could continually inspire new ideas and insights . We encourage researchers to reﬂect and report on their experiences using CVO workshops , the ways in which workshops inﬂuence collab - orations , and ideas for future workshops . We hope that this framework is a starting point for research into these topics . 11 D ISCUSSION This section discusses limitations of CVO workshops , the research methodology of critically reﬂective practice , and the way in which we document our analysis . 11 . 1 Limitations of Workshops Our experience across diverse domains — from cartography to neu - roscience — provides evidence that CVO workshops are a valuable method for fostering the mindsets and methodologies of visualization . We argue that they achieve these goals through the use of methods which appropriately emphasize the topic of visualization opportuni - ties , while accounting for ( inter ) personal factors , including colle - giality , agency , challenge , interest , and trust . Yet , workshops may not be appropriate in some scenarios . Because using workshops requires visualization researchers to ask interesting questions and potentially lead discussions about their collaborator’s domain , we caution the use of workshops as the ﬁrst method in a project . Traditional user - centered approaches should be used to learn domain vocabulary and explore the feasibility of collaboration . In the project that did not result in ongoing collaboration [ P7 ] , we lacked the domain knowledge needed to effectively design the workshop . Also , our collaborators were too busy to meet with us before the workshop , which should have been a warning about the nature of the project . Ac - cordingly , we recommend researchers evaluate the preconditions of design studies [ 81 ] in projects where they are considering workshops . We also recognize that workshops may not be well received by all stakeholders . In a full day workshop [ P4 ] , one participant reported that “Overall , it was good , but a bit long and slightly repetitive . ” Similarly , after another full day workshop [ P5 ] , one participant said “there was too much time spent expanding and not enough focus . . . discussions were too shallow and non - speciﬁc . ” However , we can improve work - shops based on this feedback , perhaps by ensuring that the methods are closely related to the topic , and that we facilitate workshops in a way that provides appropriate agency . Nevertheless , both of these workshops were generally well received by stakeholders , allowed us to explore a wide space of visualization opportunities , and to moved the collaborations forward in new and interesting ways . More generally , whether workshops can enhance creativity is an open question [ 65 , 78 ] . Creativity is a complex phenomenon studied from many perspectives , including psychology [ 78 ] , sociology [ 44 ] , and biology [ 53 ] . The results of several controlled experiments indi - cate that group - based methods can reduce creativity [ 4 , 61 ] . Critics of these studies , however , argue that these experiments lack important ecological validity [ 23 , 54 ] . Experimentally testing the relationship between workshops and creativity is beyond the scope of this paper . This paper instead focuses on understanding and communicating how we use CVO workshops in applied collaborations . 11 . 2 Critically Reﬂective Practice Throughout this project , we wrestled with a fundamental question : how can we rigorously learn from our diverse , collective experience ? We ﬁrst examined measurable attributes of workshops , such as their length , number of participants , and ideas generated . However , our workshops were conducted over 10 years in applied settings with no experimental controls . More importantly , it is difﬁcult , if not impossi - ble , to measure how ideas inﬂuence collaborations . Quantitative anal - ysis , we decided , would not produce useful knowledge about how to use CVO workshops . We also considered qualitative research methodologies and meth - ods , such as grounded theory [ 11 ] and thematic analysis [ 6 ] . These ap - proaches focus on extracting meaning from externalized data , but the the most meaningful and useful information about workshops resided in our collective , experiential knowledge . We therefore abandoned analysis methods that ignore ( or seek to suppress ) the role of experi - ence in knowledge generation . We found critically reﬂective practice to be an appropriate ap - proach , providing a methodology to learn from the analysis of experi - ence , documentation , and existing theory , while allowing for the use of additional analysis methods [ 7 , 85 ] . Due to the nature of reﬂec - tion , however , the framework is not exhaustive , predictive , or objec - tive . Nevertheless , it is consistent with our experience , grounded in existing theory , and , we argue , useful for future visualization research . Yet , the use of reﬂective practice may raise questions about this work’s validity . After all , can the framework be validated without ex - perimental data ? We emphasize our choice of the term framework [ 30 ] because we intend for it to be evaluated by whether it provides an in - terpretive understanding of CVO workshops . Our position is that it achieves this goal because it enables us to learn from our experience using workshops on three continents over the past 10 years . For ex - ample , we used the framework to identify and organize 21 pitfalls to avoid in future workshops — they are described in the Supplemen - tal Material . However , this framework is a snapshot of our current understanding of CVO workshops , which will evolve with continued research , practice , and reﬂection . Given that this work results from the subjective analysis of our ex - perience , we recognize that there could also be questions about its trustworthiness . Therefore , to increase the trustworthiness of our re - sults , we provide an audit trail of our work that contains a timeline of our analysis and our experience as well as diverse artifacts , includ - ing comparative analysis of our workshops , presentations outlining the framework , early written drafts of our framework , and structured writ - ten reﬂection to elicit ideas from all of this paper’s co - authors . This audit trail , in Supplemental Material , summarizes and includes 30 of the reﬂective artifacts , culled from the original set to protect the pri - vacy of internal discussions and conﬁdential materials from our do - main collaborators . In future reﬂective projects we plan to establish guidelines that en - courage transparency of reﬂective artifacts through mechanisms to ﬂag documents as on - or off - the - record . Because our research and meta - analysis would have been impossible without well - preserved docu - mentation , we hope that the audit trail inspires future thinking on how to document and preserve the decisions in visualization collaborations . We put forth both the audit trail and our documented use of critically reﬂective practice as secondary contributions . 12 C ONCLUSION AND F UTURE W ORK This paper contributes a framework for using CVO workshops in the early stages of applied visualization research . The framework consists of two models for CVO workshops— a process model and a work - shop structure . The framework also includes 25 actionable guidelines for future workshops , a validated example workshop , and 15 addi - tional example workshop methods . We support the framework with Supplemental Material that includes : extended details about the ex - ample workshop ; additional workshop methods ; 21 pitfalls ; and an analysis timeline and audit trail documenting how we developed the framework during a two year reﬂective collaboration . We hope that this framework inspires others to use and report on CVO workshops in applied visualization research . This framework reveals opportunities for developing CVO work - shop methods that emphasize the visualization mindset . For example , inspired by the Dear Data project [ 45 ] , we could , ask participants to create graphics that reveal something about their daily life in the week before the workshop . The Dear Data Postcard Kit [ 46 ] offers pos - sibilities here , providing materials for sharing graphics of data about weekly behaviours . We also hope to better understand the role of data in CVO work - shops . Visualization methodologies stress the importance of using real data early in collaborative projects [ 43 , 81 ] . However , our work - shops have focused participants on their perceptions of data rather than using real data because working with data is time consuming and unpredictable . In some projects , we incorporated data into the design process by using a series of workshops spaced over weeks or months , providing time for developers to design prototypes between workshops [ P1 – P3 ] . This development between workshops was ex - pensive in terms of time and effort . But time moves on , and tech - nologies and approaches that may provide quick and reliable ways of using data in workshops are emerging , such as high - level visualization design tools , declarative visualization languages , constructive visual - ization [ 29 ] , and sketching [ 90 ] . Additionally , in this paper we focused on workshops to elicit visu - alization opportunities in the early stages of applied work . Exploring how the framework could be inﬂuenced by and extended for work - shops that correspond to other stages of applied work — including the creation and analysis of prototypes , the exploration of data , or in the deployment , training and use of completed systems — may open up opportunities for using creativity in visualization design and research . A CKNOWLEDGMENTS We are grateful to the participants , facilitators , and fellow researchers in all of our workshops . We thank the following people for their feedback and contributions to this work : the anonymous reviewers , Graham Dove , Tim Dwyer , Peter Hoghton , Christine Pickett , David Rogers , Francesca Samsel , members of the Vis Design Lab at the University of Utah , and members of the giCentre at City , Univer - sity of London . This work was supported in part by NSF Grant IIS - 1350896 . R EFERENCES [ 1 ] Creative Problem - Solving Resource Guide . Creative Education Founda - tion , Scituate , MA , 2015 . [ 2 ] L . W . Anderson , D . R . Krathwohl , P . W . Airasian , K . A . Cruikshank , R . E . Mayer , P . R . Pintrich , J . Rathes , and M . C . Wittrock . A Taxonomy for Learning , Teaching , and Assessing : A Revision of Bloom’s Taxnomy of Educational Objectives , Abridged Edition . Pearson , 2000 . [ 3 ] M . M . Biskjaer , P . Dalsgaard , and K . Halskov . Understanding creativity methods in design . In DIS ’17 Proceedings of the 2017 Conference on Designing Interactive Systems . ACM , 2017 . [ 4 ] T . J . Bouchard . Personality , problem - solving procedure , and performance in small groups . Journal of Applied Psychology , 53 ( 1 , pt . 2 ) , 1969 . [ 5 ] D . Boud , R . Keogh , and D . Walker . Reﬂection : Turning Experience into Learning . Routledge Taylor and Francis Group , London , UK , 1985 . [ 6 ] V . Braun and V . Clarke . Using thematic analysis in psychology . Qualita - tive Research in Psychology , 3 ( 2 ) , 2006 . [ 7 ] S . Brookﬁeld . Critically reﬂective practice . Journal of Continuing Edu - cation in the Health Professions , 18 ( 4 ) , 1998 . [ 8 ] J . E . Brooks - Harris and S . R . Stock - Ward . Workshops : Designing and Facilitating Experiential Learning . SAGE Publications , Inc , Thousand Oaks , CA , 1999 . [ 9 ] B . Buxton . Sketching User Experiences : Getting the Design Right and the Right Desing . Morgan Kaufmann , San Francisco , CA , USA , 2010 . [ 10 ] M . Carcary . The research audit trail - enhancing trustworthiness in quali - tative inquiry . The Electronic Journal of Business Research Methods of Business Research Methods , 7 ( 1 ) , 2009 . [ 11 ] J . Corbin and A . Strauss . Grounded theory research : procedures , canons , and evaluative critera . Qualitative Sociology , 13 ( 1 ) , 1990 . [ 12 ] M . Crotty . The Foundations of Social Research . SAGE Publications , Inc , London , UK , 1998 . [ 13 ] E . de Bono . Lateral Thinking for Management . Pelican Books , Middle - sex , England , 1983 . [ 14 ] G . Dove and S . Jones . Using data to stimulate creative thinking in the design of new products and services . In DIS ’14 Proceedings of the 2014 Conference on Designing Interactive Systems . ACM , 2014 . [ 15 ] G . Dove , S . Julie , M . Mose , and N . Brodersen . Grouping notes through nodes : the functions of post - it notes in design team cognition . In Design Thinking Research Symposium , Copenhagen Business School , 2016 . [ 16 ] J . Dykes , J . Wood , and A . Slingsby . Rethinking map legends with visu - alization . IEEE Transactions on Visualization and Computer Graphics , 16 ( 6 ) , 2010 . [ 17 ] S . Goodwin , J . Dykes , S . Jones , I . Dillingham , G . Dove , D . Allison , A . Kachkaev , A . Slingsby , and J . Wood . Creative user - centered design for energy analysts and modelers . IEEE Transactions on Visualization and Computer Graphics , 19 ( 12 ) , 2013 . [ 18 ] S . Goodwin , C . Mears , T . Dwyer , M . Garcia de la Banda , G . Tack , and M . Wallace . What do constraint programming users want to see ? Eex - ploring the role of visualisation in proﬁling of models and search . IEEE Transactions on Visualization and Computer Graphics , 23 ( 1 ) , 2016 . [ 19 ] J . Gordon , William . Synectics - the Developmnent of Creative Capacity . Harper and Row , New York , NY , 1961 . [ 20 ] D . Gray , J . Macanufo , and S . Brown . Gamestorming : a Playbook for Innovators , Rulebreakers , and Changemakers . O’Reilly Media , Se - bastopol , CA , 2010 . [ 21 ] P . Hamilton . The Workshop Book : How to Design and Lead Succesful Workshops . FT Press , Upper Saddle River , NJ , 2016 . [ 22 ] S . He and E . Adar . VizItCards : a card - based toolkit for infovis design education . IEEE Transactions on Visualization and Computer Graphics , 23 ( 1 ) , 2017 . [ 23 ] T . Hewett , M . Czerwinski , M . Terry , J . Nunamaker , L . Candy , B . Kules , and E . Sylvan . Creativity support tool evaluation methods and metrics . In NSF Workshop Report on Creativity Support Tools , 2005 . [ 24 ] M . J . Hicks . Problem Solving and Decision Making : Hard , Soft , and Creative Approaches . Thomson Learning , London , UK , 2004 . [ 25 ] L . Hohmann . Innovation Games : Creating Breakthrough Products Through Collaborative Play . Addison - Wesley , Boston , MA , 2007 . [ 26 ] B . Hollis and N . Maiden . Extending agile processes with creativity tech - niques . IEEE Software , 30 ( 5 ) , 2013 . [ 27 ] J . Horkoff , N . Maiden , and J . Lockerbie . Creativity and goal modeling for software requirements engineering . In C & C ’15 Proceedings of the 2015 ACM SIGCHI Conference . ACM , 2015 . [ 28 ] S . Huron , S . Carpendale , J . Boy , and J . D . Fekete . Using VisKit : A Manual for Running a Constructive Visualization Workshop . In Pedagogy of Data Visualization Workshop at IEEE VIS , 2016 . [ 29 ] S . Huron , S . Carpendale , A . Thudt , A . Tang , and M . Mauerer . Construc - tive Visualization . In DIS ’14 Proceedings of the 2014 Conference on Designing Interactive Systems . ACM , 2014 . [ 30 ] Y . Jabareen . Building a conceptual framework : philosophy , deﬁnitions , and procedure . The International Journal of Qualitative Methods , 8 ( 4 ) , 2008 . [ 31 ] S . Jones , P . Lynch , N . Maiden , and S . Lindstaedt . Use and inﬂuence of creative ideas and requirements for a work - integrated learning system . In IEEE International Requirements Engineering Conference , 2008 . [ 32 ] S . Jones and N . Maiden . RESCUE : An integrated method for specifying requirements for complex socio - technical systems . In J . L . Mate and A . Silva , editors , Requirements Engineering for Sociotechnical Systems . Information Resources Press , Arlington , VA , 2005 . [ 33 ] S . Jones , N . Maiden , and K . Karlsen . Creativity in the speciﬁcation of large - scale socio - technical systems . In Conference on Creative Inven - tions , Innovations and Everyday Designs in HCI , 2007 . [ 34 ] E . Kerzner , A . Lex , and M . Meyer . Utah population database workshop ( workshop , University of Utah ) . unpublished , 2017 . [ 35 ] E . Kerzner , A . Lex , T . Urness , C . L . Sigulinsky , B . W . Jones , R . E . Marc , and M . Meyer . Grafﬁnity : visualizing connectivity in large graphs . Com - puter Graphics Forum , 34 ( 3 ) , 2017 . [ 36 ] J . Knapp , J . Zeratsky , and B . Kowitz . Sprint : How to Solve Big Problems and Test new Ideas in Just Five Days . Simon & Schuster , New York , NY , 2016 . [ 37 ] L . C . Koh , A . Slingsby , J . Dykes , and T . S . Kam . Developing and apply - ing a user - centered model for the design and implementation of informa - tion visualization tools . In Proceedings of the International Conference on Information Visualisation , 2011 . [ 38 ] V . Kumar and V . LaConte . 101 Design Methods : a Structured Approach to Driving Innovation in Your Organization . Wiley , San Francisco , CA , 2012 . [ 39 ] H . Lam , E . Bertini , P . Isenberg , and C . Plaisant . Seven guiding scenarios for information visualization evaluation . IEEE Transactions on Visual - ization and Computer Graphics , 18 ( 9 ) , 2012 . [ 40 ] B . Laural , editor . Design Research : Methods and Perspectives . MIT Press , Cambridge , MA , 2003 . [ 41 ] Y . S . Lincoln and E . Guba . Naturalistic Inquiry . SAGE Publications , Inc , Thousand Oaks , CA , 1985 . [ 42 ] C . Lisle , E . Kerzner , A . Lex , and M . Meyer . Arbor summit workshop ( workshop , University of Utah ) . unpublished , 2017 . [ 43 ] D . Lloyd and J . Dykes . Human - centered approaches in geovisualization design : investigating multiple methods through a long - term case study . IEEE Transactions on Visualization and Computer Graphics , 17 ( 12 ) , 2011 . [ 44 ] T . I . Lubart . Creativity Across Cultures . In R . J . Sternberg , editor , Hand - book of Creativity . Cambridge University Press , Cambridge , UK , 1999 . [ 45 ] G . Lupi and S . Posavec . Dear Data : The Story of a Friendship in Fifty - Two Postcards . Penguin , 2016 . [ 46 ] G . Lupi and S . Posavec . Dear Data Postcard Kit : For Two Friends to Draw and Share ( Postcards ) . Princeton Architectural Press , 2017 . [ 47 ] N . Maiden , S . Jones , K . Karlsen , R . Neill , K . Zachos , and A . Milne . Re - quirements engineering as creative problem solving : a research agenda for idea ﬁnding . In IEEE International Requirements Engineering Con - ference , 2010 . [ 48 ] N . Maiden and J . Lockerbie . Creative Engine . http : / / becreative . city . ac . uk / index . php , 2018 . [ 49 ] N . Maiden , S . Manning , S . Robertson , and J . Greenwood . Integrating creativity workshops into structured requirements processes . In DIS ’04 Proceedings of the Conference on Designing Interactive Systems : Pro - cesses , Practices , Methods , and Techniques . ACM , 2004 . [ 50 ] N . Maiden , C . Ncube , and S . Robertson . Can requirements be creative ? Experiences with an enhanced air space management system . In Interna - tional Conference on Software Engineering , 2007 . [ 51 ] N . Maiden and S . Robertson . Developing use cases and scenarios in the requirements process . In Proceedings of the International Conference on Software Engineering . ACM , 2005 . [ 52 ] G . E . Marai . Activity - centered domain characterization for problem - driven scientiﬁc v isualization . IEEE Transactions on Visualization and Computer Graphics , 24 ( 1 ) , 2018 . [ 53 ] C . Martindale . Biological Bases of Creativity . In R . J . Sternberg , editor , Handbook of Creativity . Cambridge University Press , Cambridge , UK , 1999 . [ 54 ] R . Mayer . Fifty Years of Creativity Research . In R . J . Sternberg , edi - tor , Handbook of Creativity , pages 449 – 460 . Cambridge University Press , Cambridge , UK , 1999 . [ 55 ] N . McCurdy , J . Dykes , and M . Meyer . Action Design Research and Vi - sualization Design . In BELIV ’16 Proceedings of the Sixth Workshop on Beyond Time and Errors on Novel Evaluation Methods for Visualization , 2016 . [ 56 ] E . McFadzean . The creativity continuum : towards a classiﬁcation of cre - ative problem solving techniques . Journal of Creativity and Innovation Management , 7 ( 3 ) , 1998 . [ 57 ] S . McKenna , D . Mazur , J . Agutter , and M . Meyer . Design activity frame - work for visualization design . IEEE Transactions on Visualization and Computer Graphics , 20 ( 12 ) , 2014 . [ 58 ] S . McKenna , D . Staheli , and M . Meyer . Unlocking user - centered design methods for building cyber security visualizations . IEEE Symposium on Visualization for Cyber Security , VizSec 2015 , 2015 . [ 59 ] M . Michalko . Thinkertoys : a Handbook for Creative - Thinking Tech - niques . Ten Speed Press , Emeryville , CA , 2006 . [ 60 ] W . C . Miller . The Creative Edge : Fostering Innovation Where You Work . Basic Books , New York City , NY , 1989 . [ 61 ] B . Mullen , C . Salas , and E . Johnson . Productivity Loss in Brainstorming Groups : A Meta - analytical Integration . Basic and Applied Social Psy - chology , 12 ( 1 ) , 1991 . [ 62 ] M . M . J . Muller and S . Kuhn . Participatory design . Communications of the ACM , 36 ( 6 ) , 1993 . [ 63 ] T . Munzner . A nested model for visualization design and validation . IEEE Transactions on Visualization and Computer Graphics , 15 ( 6 ) , 2009 . [ 64 ] Mycoted Inc . Creativity techniques : A to Z . https : / / www . mycoted . com / Category : Creativity Techniques . [ 65 ] R . S . Nickerson . Enhancing Creativity . In R . J . Sternberg , editor , Hand - book of Creativity . Cambridge University Press , Cambridge , UK , 1999 . [ 66 ] C . Nobre , N . Gehlenborg , H . Coon , and A . Lex . Lineage : visualizing multivariate clinical data in genealogy graphs . IEEE Transactions on Visualization and Computer Graphics , 2018 . [ 67 ] D . A . Norman and S . W . Draper . User Centered System Design ; New Perspectives on Human - Computer Interaction . L . Erlbaum Associates Inc , Hillsdale , NJ , USA , 1986 . [ 68 ] A . Osborn . Applied Immagination : Principles and Procedures of Cre - ative Problem Solving . Charle Scribener’s Sons , New York , USA , 1953 . [ 69 ] J . C . Roberts , C . Headleand , and P . D . Ritsos . Sketching designs using the ﬁve design - sheet methodology . IEEE Transactions on Visualization and Computer Graphics , 22 ( 1 ) , 2016 . [ 70 ] D . H . Rogers , C . Aragon , D . Keefe , E . Kerzner , N . McCurdy , M . Meyer , and F . Samsel . Discovery Jam . In IEEE Vis ( Workshops ) , 2016 . [ 71 ] D . H . Rogers , F . Samsel , C . Aragon , D . F . Keefe , N . McCurdy , E . Kerzner , and M . Meyer . Discovery Jam . In IEEE Vis ( Workshops ) , 2017 . [ 72 ] R . Sakai and J . Aerts . Card sorting techniques for domain characteriza - tion in problem - driven visualization research . In Eurographics Confer - ence on Visualization ( EuroVis ) - Short Papers , 2015 . [ 73 ] E . B . - N . Sanders . Information , insipiration , and co - creation . In Confer - ence of the European Academy of Design , 2005 . [ 74 ] E . B . - N . Sanders , E . Brandt , and T . Binder . A framework for organizing the tools and techniques of participatory design . In PDC ’10 Proceedings of the 11th Biennial Participatory Design Conference , 2010 . [ 75 ] E . B . - N . Sanders and P . J . Stappers . Co - creation and the new landscapes of design . CoDesign : International Journal of CoCreation in Design and the Arts , 4 ( 1 ) , 2008 . [ 76 ] L . Sanders and P . J . Stappers . Convivial Toolbox : Generative Research for the Front End of Design . BIS Publishers , Amsterdam , The Nether - lands , 2013 . [ 77 ] K . R . Sawyer . Group Creativity : Music , Theater , Collaboration . Lawrence Erlbaum Associates , Mahwah , New Jersey , 2003 . [ 78 ] K . R . Sawyer . Explaining Creativity - the Science of Human Innovation . Oxford University Press , New York , NY , 2006 . [ 79 ] D . A . Schon . The Reﬂective Practitioner . Basic Books , 1988 . [ 80 ] M . Sedlmair , P . Isenberg , D . Baur , and A . Butz . Evaluating information visualization in large companies : challenges , experiences and recommen - dations . In BELIV ’10 Proceedings of the 3rd BELIV’10 Workshop : BE - yond time and errors : novel evaLuation methods for Information Visual - ization , 2010 . [ 81 ] M . Sedlmair , M . Meyer , and T . Munzner . Design study methodology : reﬂections from the trenches and the stacks . IEEE Transactions on Visu - alization and Computer Graphics , 18 ( 12 ) , 2012 . [ 82 ] B . Shneiderman , G . Fischer , M . Czerwinski , and B . Myers . NSF Work - shop Report on Creativity Support Tools . National Science Foundation , 2005 . [ 83 ] B . Shneiderman and C . Plaisant . Strategies for evaluating information visualization tools . In BELIV ’06 Proceedings of the 2006 AVI workshop on BEyond time and errors : novel evaluation methods for information visualization , 2006 . [ 84 ] R . B . Stanﬁeld . The Workshop Book : From Individual Creativity to Group Action . New Society Publishers , Gabriola Island , BC , Canada , 2002 . [ 85 ] S . Thompson and N . Thompson . The Critically Reﬂective Practioner . Palgrave Macmillan , New York , NY , 2008 . [ 86 ] M . Tory and T . Moller . Human factors in visualization research . IEEE Transactions on Visualization and Computer Graphics , 10 ( 1 ) , 2004 . [ 87 ] J . Vines , R . Clarke , and P . Wright . Conﬁguring participation : on how we involve people in design . In CHI ’13 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , volume 20 , 2013 . [ 88 ] R . S . Vosko . Where we learn shapes our learning . New Directions for Adult and Continuing Education , 50 ( Summer ) , 1991 . [ 89 ] R . Walker , A . Slingsby , J . Dykes , K . Xu , J . Wood , P . H . Nguyen , D . Stephens , B . L . W . Wong , and Y . Zheng . An extensible framework for provenance in human terrain visual analytics . IEEE Transactions on Visualization and Computer Graphics , 19 ( 12 ) , 2013 . [ 90 ] J . Walny , S . Huron , and S . Carpendale . An exploratory study of data sketching for visual representation . Computer Graphics Forum , 34 ( 3 ) , 2015 .