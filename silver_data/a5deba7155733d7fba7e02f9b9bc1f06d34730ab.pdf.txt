https : / / doi . org / 10 . 1177 / 00220221221093811 Journal of Cross - Cultural Psychology 2022 , Vol . 53 ( 7 - 8 ) 847 – 859 © The Author ( s ) 2022 Article reuse guidelines : sagepub . com / journals - permissions DOI : 10 . 1177 / 00220221221093811 journals . sagepub . com / home / jcc Special issue article Principles and Practices of Methodology and Methods in Cross - Cultural Psychology Ype H . Poortinga 1 and Johnny R . J . Fontaine 2 Abstract Principles of methodology in ( cross - ) cultural psychology are discussed and how these work out in practice . We propose that the frequently mentioned contrasts between context - specificity and universality of psychological functioning , and between qualitative and quantitative research traditions can be transcended by an empirical cycle in which both qualitative methods geared to exploration and quantitative methods geared to testing of hypotheses are acknowledged . We note issues in research due to non - random sampling , lack of psychometric equivalence of data , and nesting of individuals in populations . We argue that concerns about poor reproducibility in psychology cannot be ignored in cross - cultural psychology and make suggestions how research can be improved by treating this not as a threat but as an opportunity to expand cooperation . Keywords reproducibility , empirical cycle , sampling , bias and equivalence , multilevel analyses , qualitative traditions , quantitative traditions , preregistration , adversarial alignment , collaboration “There is only one solution , and it is more accountability across the board . ” Sergey Frolov ( 2021 , Nature , 592 , p . 352 ) Cross - cultural psychology as a ( sub - ) discipline emerged about half a century ago and with it systematic analysis of methodology and methods . An exemplary study from the early period was the work by Segall et al . ( 1966 ) on antecedent conditions of susceptibility for various visual illu - sions . They found differences between populations that supported postulated hypotheses on fea - tures of the natural context . Perhaps most striking is that even for the horizontal - vertical illusion—based on an extremely simple figure consisting of only two line segments , —Segall et al . ( 1966 ) reported invariance ( all populations that were examined showed susceptibility effects ) as well as variation ( the susceptibility for the horizontal - vertical illusion depended on the presence versus absence of broad , horizontal vistas ) . The study followed a quasi - experimental 1 Tilburg University , The Netherlands 2 Department of Work , Organization and Society , Faculty of Psychology and Educational Sciences , Ghent University , Belgium Corresponding Author : Johnny R . J . Fontaine , Departement of Work , Organization and Society , Faculty of Psychology and Eductational Sciences , Ghent University , Henri - Dunantlaan 2 , Ghent 9000 , Belgium . Email : Johnny . Fontaine @ UGent . be 1093811 JCC XXX10 . 1177 / 00220221221093811Journal of Cross - Cultural Psychology Poortinga and Fontaine research - article 2022 848 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) design ( Campbell & Stanley , 1963 ) , with several control features . These included samples from numerous populations , explicit assessment of the independent variable ( i . e . , characteristics of the natural context ) , careful design of the stimulus booklets ( e . g . , a separate color for the line seg - ment that the respondent had to judge ) , checks on understanding of the task , and checks on the consistency of the response pattern of each participant . Such control features that help to rule out alternative explanations are extremely important for cross - cultural psychology , where confound - ing variables are notorious , as we will argue below . The experimental paradigm that Segall et al . ( 1966 ) followed in the design of their study is not the only pathway to plausible and valid knowledge . For example , Whiting ( 1994 ) demonstrated that baby - carrying practices are related to environmental temperature . Whiting’s data came from the Human Relations Area Files ( HRAF ) , a large data base in cultural anthropology ( see www . hraf . yale . edu ) , reporting a wide range of customs and beliefs . In warm climates babies usually are car - ried in slings or shawls close to the mother’s body , while in cold regions babies are held away from the body of the mother , in a cradle or on a carrying board . Average annual temperature explains a fair proportion of the variance in carrying practices , providing a strong causal explanation . A score of texts on design and analysis of cross - cultural studies has been published ( e . g . , Bender & Adams , 2021 ; Brislin et al . , 1973 ; Fischer & Poortinga , 2018 ; Matsumoto & Van de Vijver , 2011 ; Van de Vijver & Leung , 1997 , 2021 ) . Methodological concerns are also dealt with extensively in the two editions of the Handbook of Cross - Cultural Psychology ( Berry , 1997 ; Triandis , 1980 ) . “Good” research need not be recent ; the two empirical studies we mentioned illustrate this . At the same time , major advances have been made and have led to considerable extension of the tools available for design and analysis of research in cross - cultural psychology . Sophisticated texts on psychometric and statistical analysis of large data sets collected on individual respondents nested in populations deserve special mentioning ( e . g . , Hox et al . , 2010 ; Muthén & Asparouhov , 2014 ) . At the same time , many present - day studies are far more open to alternative interpretations than acknowledged by their authors . Contemporary research cannot be evaluated in terms of how much better we can do now , the question is whether or not we meet standards for firmly justifying the validity of claims that are made . Here we review methodological principles of research and com - mon practices , and indicate how—in our view—gains can be made . The Basics In cross - cultural psychology the major theoretical and methodological debate during the last 50 years has been the theme of context - specificity versus universality of psychological function - ing . The debate was fed by imposition of western theories and methods , and understandable reactions in the form of indigenous psychologies by researchers from other parts of the world ( e . g . , Kim et al . , 2006 ; Sinha , 1997 ) . Universality versus specificity has been addressed mainly in ontological terms ; for example , in contrasting positions on the question whether the same basic emotions and cognitive processes exist in all human populations or whether there exist emotions and / or modes of thinking in some populations that are not found in other populations . An over - arching position was formulated by Pike ( 1967 ) who distinguished in the field of linguistics between an emic and an etic perspective , based on the distinction between phonetics ( the study of vocal sounds ) and phonemes ( the sounds found in a particular spoken language ) . Berry ( 1989 ) used this distinction in cross - cultural psychology , arguing that the two perspectives should be applied iteratively to better demarcate and ultimately better integrate the two positions . Such a synthetic view continues to be dismissed by some authors and in a field like emotions research debates are still strong . Barrett et al . ( 2019 ) continue to insist that proclaimed evidence for the universality of basic emotions expressed in the face ( such as happiness and fear ) is insufficient and not convincing . Others report a universal structure of emotion dimensions ( Fontaine et al . , 2013 ) . There are also suggestions that variations in expressions of emotions may be seen as local Poortinga and Fontaine 849 dialects of a common language ( Elfenbein , 2013 ) , or that conventions about expressions ( “dis - play rules” ) of common emotions ( Matsumoto et al . , 2008 ) are the main source of manifest dif - ferences in behavior . It appears to us that controversies gradually tend to fade away , not because the underlying issues have been resolved , but because researchers see little gain in stressing differences between positions that refer to two sides of the same medal . One can approach human populations as being the same or as being different , emphasizing universality of psychological functioning and invariance , or the context - specificity of behavior ( see Berry et al . , 2011 ) . Historically , the contrast between universalism and context specificity has been related to the distinction between so - called quantitative and qualitative research traditions . The methods of indig - enous psychologies and approaches of early cultural psychology that challenged the notion of uni - versal psychological processes and functions ( see , e . g . , Shweder , 1990 ) are largely qualitative , relying on participant observations , interviews , focus groups , and spontaneous observation . In ( comparative ) cross - cultural psychology and the contemporary school of ( North American ) cultural psychology mainly quantitative methods , with standardized psychometric instruments and experi - mental designs , are followed . The position we take here is that the suggested controversy does not make much sense , if it is considered that the main strength of qualitative research lies in discovery or exploration and the main strength of quantitative research lies in verification ( or falsification ) of tentative findings . A single study—qualitative or quantitative—can be limited to either exploration ( pursuing some new idea and interpreting findings ad hoc ) or to verification / falsification of hypoth - eses , but in cumulative research traditions both approaches are needed . A commendable attempt to bridge the contrast between qualitative and quantitative traditions is “mixed methods” research . The basic idea is that research can be improved by drawing on multiple data sources , and methods and methodologies ( e . g . , Bryman , 2015 ; Creswell , 2009 ; Karasz , 2011 ) . The Empirical Cycle We like to suggest a more fundamental way to resolve the traditional contrast between context - specificity versus universality of psychological functioning by introducing the notion of a full empir - ical cycle . One formulation was developed by De Groot ( see De Groot & Spiekerman , 1969 ) . Five phases are distinguished : observation , induction , deduction , testing , and evaluation . The first phase comprises the collection and ordering of empirical materials and the formulation of conjectures , often guided by a theory . The phase of induction entails the specification of hypotheses ; that is , tenta - tive explanations open to empirical examination . During the phase of deduction , methods are derived so that the hypotheses can be formulated as testable predictions about outcomes . During the phase of testing the hypotheses are confronted with new data and it is decided whether these data support or falsify the hypotheses . In the final phase , the outcomes are interpreted in the light of the guiding theory and competing theories . This final phase is likely to inform the next empirical cycle . The beginning of most research in cross - cultural psychology is the surprise that humans of some group beyond our own group behave in ways that we would not expect . Attempts to make sense of such variation cannot but start with exploration . In the absence of strong theories where the results of a study can drive the next study ( as can happen , e . g . , in physics ) , qualitative and quantitative phases will alternate or be combined . A cumulative research tradition needs both exploration and verification ; careful consideration of the empirical cycle can strengthen this research process . Qualitative Research Traditions Indigenous psychologies ( i . e . , local formulations of theory and method for cross - cultural psy - chology ) tend to emphasize qualitative methodology . It is important to recognize that the 850 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) science and practice of psychology as it is reported in handbooks and journals has been derived mainly from western ideas and preoccupations ( Berry et al . , 2011 ) . To enrich this western psychology with other insights and do away with traditional western dominance remain important tasks ( e . g . , Pondicherry Manifesto of Indian Psychology , 2002 ; Silan et al . , 2021 ) . In so far as behavior is shaped by local conceptualizations , local input is essential . An illustration from the area of mental health involves local “idioms of distress , ” that is , local modes of expressing suffering . Hinton et al . ( 2020 ) found in a Cambodian clinic that 54 % of a patient group was bothered by ghost encounters . The extent to which such experiences were reported by patients showed a very high correlation ( r = . 8 ) with severity of PTSD ( Post Traumatic Stress Disorder ) . The need for extensive collaboration is evident , a point that we mention again later on . There are researchers in qualitative traditions who insist that careful data collection and analysis will lead to valid understanding and thus includes verification . Sensitive analysis will more or less guarantee validity of the interpretation of data ( see Bryman , 2015 for a discus - sion ) . Others ask for explicit evidence of “trustworthiness . ” Schwandt et al . ( 2007 , see also Guba , 1981 ) demand credibility ( akin to internal validity in quantitative data analysis ) , trans - ferability ( akin to external validity ) , dependability ( akin to reliability ) , and confirmability ( akin to objectivity ) . There is a wide range of methods and techniques to strengthen the research process . The most important is probably triangulation , the combination of information from multiple observers , methods , theories , and empirical materials ( e . g . , Bryman , 2015 ; Creswell , 2009 ; Denzin & Lincoln , 2017 ) . For example , the research design can specify that “saturation” has to be reached , that is , data collection through interviewing or focus group sessions is to be continued until hardly any novel information on the target topic is forthcoming . The core of the analysis process , that is , the coding of data , can be carried out systematically by following a coding scheme that can help to uncover phenomena contained in the collected information ( Corbin & Strauss , 1990 ) . Computer programs , such as Atlas . ti ( www . atlasti . com ) can facili - tate coding . Despite such important improvements , it has to be mentioned that with qualitative methods the degrees of freedom of interpretation are undefined and thus without formal limits ; ultimately researchers serve as their own standards of validity . Below we will emphasize rep - lication as an important way to strengthen research in cross - cultural psychology . At this point , we note that the methodology of qualitative research is at variance with replicability . When an interview study with ( semi - ) open questions is repeated and leads to different findings , there are hardly criteria by which to decide whether such findings are complementary to or incompatible with the earlier results . Quantitative Research Traditions : The Later Stages of the Empirical Cycle There is a deep entanglement between qualitative and quantitative approaches . An assessment instrument ( e . g . , a set of items ) representing a psychological trait or behavior domain cannot be arrived at only by quantitative methods . Theoretical argument and qualitative research are also needed to identify relevant elements within each context or population . At the same time , inter - pretations of qualitative data cannot validate themselves ; they need to be exposed to and evalu - ated in terms of external standards . The process of discovery in cross - cultural psychology about invariance and variation of behavior across populations usually leads to the formulation of tentative explanations ( hypothe - ses ) that are open to testing . Ideally , the interpretation of findings from a hypothesis testing study is independent of the person of the researcher ; that is , all persons who understand the question and the research methods should derive the same conclusions from a set of raw data . The inde - pendence of interpretation from the person of the researcher can be said to make research “objec - tive . ” The experimental paradigm of psychology is the leading paradigm for the testing of Poortinga and Fontaine 851 hypotheses , also in cross - cultural psychology . The epistemology of the experiment is invariant ; it applies universally . This does not make research straightforward . There are two principles basic to a true experi - ment : subjects / participants should be assigned to experimental conditions with a random proce - dure , and the experimenter should have full control over the conditions or treatments to which participants are subjected ( e . g . , Shadish et al . , 2002 ) . A third principle , particularly relevant in cross - cultural research , is that measurement instruments and procedures used to record the target behavior should be “unbiased” ( i . e . , psychometrically equivalent ) across the populations in a study . All three principles tend to be violated strongly in cross - cultural comparative research , where ( i ) participants are nested in populations , ( ii ) treatment conditions from the past that have led to current behavior usually cannot be observed but only inferred , and ( iii ) measures are noto - riously biased ( see below ) . Outside of a laboratory , in real - life settings , the conditions of a true experiment are hardly ever fully met . When studies are conducted with already existing groups , research is called “quasi - experimental . ” If there are sufficient controls and no plausible alternative explanations of find - ings , a causal relationship between conditions and outcomes can be reasonably inferred ( Shadish et al . , 2002 ) . However , in our field it is often debatable whether all other plausible alternative explanations to a preferred explanation have been accounted for . To begin with , it is a priori unlikely that the score distributions for any given psychological trait in any two ( large ) popula - tions will be exactly the same . The probability that the mean scores in two populations will be precisely equal is distinctly unlikely . The same holds for relationships between variables ; the probability that the observed correlation between two variables will be equal also is unlikely . This implies that finding a ( statistically significant ) difference may be trivial ( Brislin et al . , 1973 ) . Moreover , findings may well be distorted due to bias or lack of equivalence in data ( Malpass & Poortinga , 1986 ) . These two references from the 1970s and 1980s illustrate that weaknesses of design and analysis have been long recognized in cross - cultural psychology . Lessons ( Still to be ) Learned In the extensive literature of the last half century , many methods have been reported to address vulnerabilities in design and analysis of cross - cultural research based on quantitative data . Some of these have been applied in numerous studies , the application of other new methods has had limited impact , probably because of the complexities of design and analysis that they entail . Sampling There has been a tendency to move from studies in two populations to studies including larger numbers of populations . This is an important development . Campbell ( 1964 ) has pointed out that a difference in score distributions between samples drawn from only two populations tends to be essentially uninterpretable , because of numerous potentially confounding factors . As the number of populations is enlarged the effect of a confounding factor affecting one or a few populations accounts for increasingly less variance . A large proportion of studies continues to be based on select samples , often ad hoc student volunteers from a single university or even a single department , to represent the population of a country . The underlying assumption appears to be that members of two populations differ by a constant ( plus some randomly distributed error ) . However , this is an unrealistic assumption . Even the proportion of an age cohort going to university and the degree of over - representation of the more affluent members of a society among students differ across countries . In a review Boehnke et al . ( 2011 ) have provided reasons why completely random samples may not be needed ( or are out of reach ) for answering a research question , but the sampling strategy of a study at 852 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) both the population level ( e . g . , countries ) and the individual level has to be tuned carefully to the research objectives . Effects of some confounds , such as over - representation of the more affluent or the more educated , can be addressed by stratified sampling or propensity score matching ( Austin , 2011 ) . However , the distribution of a confound needs to be known , at least approxi - mately . This also holds for new modes of data collection through internet and social media chan - nels ( e . g . , Gosling & Mason , 2015 ) . Bias and Equivalence There has been considerable progress in the analysis of bias and psychometric equivalence in cross - cultural data sets . Half a century ago , multivariate analysis was limited to simple factor analyses that had to be carried out by hand ( please realize that the common use of computers came after cross - cultural psychology had been established ) . Notions about bias and comparability of data obtained in various populations initially were simple . Often a dichotomous distinction was made between unbiased or psychometrically equivalent data and biased data . When no evidence of bias was found ( a rare occasion ) , unrestricted comparison was possible , while evidence of bias was taken to preclude any valid comparison . Initially , the emphasis was on identifying bias in separate items and either replacing these items or removing the item scores from a data set . Soon sophisti - cated models for statistical analysis of item bias were reported ( Holland & Wainer , 1993 ) . A major step forward was made when hierarchies of levels of equivalence were developed , based on the classical test theory model ( Van de Vijver & Poortinga , 1982 ) or on analysis of covariance structures ( e . g . , Vandenberg & Lance , 2000 ) . Higher levels of equivalence require that more stringent conditions for invariance are met . For example , there are conditions for invariance of structural relationships across a set of populations , called structural equivalence or configural invariance . When these are met this provides evidence that the same hypothetical constructs are being measured . For the interpretation of quantitative differences in scores , condi - tions for full score equivalence or scalar equivalence have to be met that are more stringent . In fact , in very large data sets such conditions tend not to be satisfied . Perhaps some recognized methods are too stringent and may need to be relaxed ( e . g . , Byrne & Van de Vijver , 2010 ; Muthén & Asparouhov , 2014 ) . The specification of psychometric requirements that are both sufficiently precise and not overly strict is still a work in progress ( Boer et al . , 2018 ) . Boer et al . ( 2018 ) men - tion a finding that in in our view is alarming , despite such uncertainties : in a majority of compara - tive studies in cross - cultural psychology the possibility that results can be distorted by a lack of equivalence is ignored . We see this as a serious shortcoming in accountability . In a related development , distinctions were proposed between sources of bias ( Van de Vijver & Leung , 1997 , 2021 ; Van de Vijver & Poortinga , 1982 ) . A common distinction is between item bias ( a single item is affected , e . g . , due to poor translation ) , method bias ( all or most items in an instru - ment are affected ) , and construct bias ( incomplete overlap of the definition of a construct across populations ) . We like to note that method bias is especially difficult to distinguish from valid differ - ences in score distributions , because the bias effect is shared across variables . Notorious instances of this kind of bias are response tendencies , such as acquiescence and extreme responding , and social desirability ( e . g . , He et al . , 2014 ) . The resulting differences are estimates of true differences between populations , but they are invalid as markers of the target domain or construct . For exam - ple , Van Herk et al . ( 2004 ) found that due to differences in acquiescence self - reported product evaluations did not match national sales volumes of certain products . Multilevel Analysis Another topic where distinct progress has been made is multilevel analysis . In a typical study , participants are nested in populations . Advancements in communication and data technology Poortinga and Fontaine 853 have made it possible to collect and analyze large data sets . This has greatly facilitated research designs that can address the nesting of individuals in populations ( i . e . , by treating populations as a random factor , rather than a fixed factor , Fontaine , 2008 ) . An important question in such designs is whether differences between populations can be explained in terms of the same concepts as differences between individuals nested in such populations ( e . g . , Van de Vijver et al . , 2008 ) . In the field of education shifts in concepts across numerous levels are known . A high score of an individual pupil on a vocabulary test signifies a high verbal ability . A high average score at the classroom level is likely to indicate a high proportion of girls ( they tend to do better than boys on verbal ability tests ) . At the school level a high average may indicate that pupils are drawn from an affluent neighborhood , and at country level differences in performance are mainly due to investment in education ( PISA , www . oecd . org / pisa / aboutpisa / ) . Thus , in this example at various levels different concepts are assessed . For our field the question is whether or not there are shifts in psychological constructs when scores of individuals are aggregated to populations ( usually countries ) , or disaggregated from populations to individuals . When there is a monotonic function describing the relationship between phenomena at each of the two levels the relationship is called isomorphic , and it makes sense to use the same explanatory constructs . The question of isomor - phism can be examined by analyzing whether the structure of the interrelationships between variables ( e . g . , items ) is the same at the two levels ( e . g . , Hox et al . , 2010 ) . For psychological ( individual level ) concepts such as personality dimensions and subjective well - being there is some evidence suggesting that they apply to countries as well as to individuals ( Lucas & Diener , 2008 ; McCrae & Terraciano , 2008 ) . There has been discussion on the isomorphism of values in the Schwartz Value Scale ( Fischer et al . , 2010 ; Fischer & Poortinga , 2018 ) . For a complex seven - dimensional model of self - construal ( or selfhood ) that emerged from a large study , Vignoles et al . ( 2016 ) found that statistical criteria for structural isomorphism were met , after results for a few items were removed from the data . So far , the evidence is limited , in part because a sufficient number of cases is needed at the highest level . The Reproducibility Crisis : Threats and Opportunities for Cross - Cultural Psychology Cross - cultural psychology as a field of research is about both differences and invariance of mani - fest behavior and underlying psychological functions and processes . In practice , the literature in cross - cultural psychology is much more about differences between human populations than on how humans living in various ecological and social contexts psychologically are alike . We have mentioned already that researchers tend to turn a blind eye on possible bias and lack of equiva - lence in data that are likely to lead to overestimation of differences . Moreover , scrutiny of the history of the field shows that with each new tradition in research initially big and important differences tend to be reported . When later more carefully designed studies are conducted , these large differences shrink ( Poortinga , 2021 ) . Such a systematic bias in our literature is worrisome . Related to this is the widespread evidence of unwarranted flexibility in the interpretation of find - ings , especially in sciences with less rigid methods than the natural sciences . Fanelli ( 2010 ) found for the “softer” sciences that > 90 % of published studies reported significant findings ( typically p ≤ . 05 ) . Such high levels of insight are simply unbelievable . There has been extensive criticism of the way in which the traditional model of Null Hypothesis Significance Testing ( NHST ) is used . Significant differences ( p ≤ . 05 ) are emphasized . If some but not all hypotheses in a study are supported , a typical interpretation is that the underlying model or theory is “partially supported” by the findings ; while the logic of the experimental approach demands that the model or theory concerned is rejected and after modification retested . Strictly speaking , a theory can be accepted only when none of the relevant hypotheses has to be rejected . At that point claims about validity of the theory are justified , but not when “partial 854 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) support” has been found . It may be noted that the logic of statistical inference is not at stake ( Wasserstein & Lazar , 2016 ) , but the way in which studies are being designed , and the data ana - lyzed and interpreted . In research projects as conducted in cross - cultural psychology , researchers make a string of choices during all stages of a study . They choose which populations to include and how to select respondents . They select the instruments to administer and decide which records to remove from the data base . Implicitly ( by not doing anything ) or explicitly they select analyses on how to rule out effects of possible sources of bias . After the primary data analysis they decide whether or not to conduct additional analyses not specified in the design stage of a study , and whether to not to report additional findings , etc . Increasingly concerns are raised about the consequences of choices researchers make during the various stages of a study ( e . g . , Ioannidis , 2005 ) . Simmons et al . ( 2011 ) refer to such choices as “academic degrees of freedom . ” They warn for “false - posi - tive psychology” where researchers are “more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not” ( p . 1359 ) . There are several publications that address specific transgressions of methodological standards . For example , Wicherts et al . ( 2016 ) address “p - hacking , ” the search for and emphasis on significant differences in designs with mul - tiple variables , and to “harking , ” adding hypotheses after results are known . Cohen ( 1994 ) warns that a high level of significance does not imply that a difference is “large” and should not be interpreted as such . Button et al . ( 2013 ) argue that small samples , more than large samples , lead not only to a smaller probability of detecting a true effect , but also to a larger probability that an observed significant finding will not be found again when the study is replicated . For cross - cul - tural psychology this threat is even more severe , because the probability of a significant finding due to some source of method bias also increases with larger size of samples ( Malpass & Poortinga , 1986 ) . The concern about less than optimal standards in research has led to increasing attention for replication and reproducibility of findings . In psychology , a few large - scale replication projects have raised the alarm even further . In one such project based on 100 studies , the effect sizes in the replication studies were on average only half the magnitude of those in the original studies and fewer than 40 % the original studies were deemed to have been successfully reproduced ( Open Science Collaboration , 2015 ) . In another large - scale project replicating 28 studies each about 60 times across 36 countries and territories , just over half of the original effects were sup - ported ( Klein et al . , 2018 ) . Three of the studies in this project addressed cross - cultural differ - ences , but in none of these three the original differences were replicated . A third replication project covering 13 previously reported effects found support for 10 of the effects reported origi - nally , weak support for 1 effect and 2 effects did not replicate ( Klein et al . , 2014 ) . Both of these negative findings were for priming studies , a form of experimental manipulation also used in cross - cultural psychology ( see Oyserman & Lee , 2008 ) . At this point in time , there is little explicit evidence on the reproducibility of findings in cross - cultural psychology . Both the few available findings and the extensive findings in related fields of science do not augur well ; it is safe to predict that it is only a matter of time before the “replication crisis” will hit cross - cultural psychology . Opportunities for Cross - Cultural Psychology There are two , essentially complementary , reasons for replication research in cross - cultural psy - chology . The first is to expand or seek further validation for previously reported findings , usually differences , between populations . The numerous comparisons between a sample of North American students of European descent and a sample of students of Asian descent elaborating East - West distinctions in social and cognitive functioning is a prime example ( see Cohen & Kitayama , 2019 ; Kitayama & Cohen , 2007 for overviews ) . The second reason for replication is Poortinga and Fontaine 855 to examine to which extent an observed phenomenon occurs uniformly across populations ( e . g . , identifiable subgroups in a population , a trajectory of ontogenetic development , effectiveness of intervention programs , or consequences of discrimination or other adverse conditions ) . A recent example is a replication study by Walter et al . ( 2020 ) seeking confirmation for universal sex dif - ferences in preferences for attractiveness as well as sources of systematic cultural variation . Milfont and Klein ( 2018 ) have reviewed the scope for replication in cross - cultural psychol - ogy . They provide a list of recommendations for various stages of a study . The most important is preregistration . This amounts to entering before data collection in an open register ( such as www . AsPredicted . org ) a description of the theory guiding a study as well as the design , hypotheses , and procedures . Some journals now allow submission of preregistered reports . Such a report is reviewed and on acceptance the full study is published after it has been completed , regardless of the results . Preregistration increases transparency and places constraints on the “academic degrees of freedom” mentioned before ( see Scheel et al . , 2021 ) . It does not impose restrictions on interpretation of unexpected findings , but discrepancies between expectations and outcomes become more transparent . Milfont and Klein ( 2018 ) also point to the major difficulty that in cross - cultural psychology it is impossible to realize precise replication ; not all parameters can be kept invariant across all populations . Moreover , even replications that stay as close as possible to the original studies are open to challenges ( Stroebe , 2019 ) . Lykken ( 1968 ) made a distinction between literal replication and constructive replication ; with the latter only the essential features of a study are retained . Replication in our field is limited largely to constructive replication . This is an essential point , as authors confronted with unexpected results that challenge their theory ( and beliefs ! ) tend to come up with arguments why a replication study that failed to confirm earlier results was not a precise replication and why their original results can be upheld . For us a major promise of replication lies in the advancement of cooperation between research - ers . If you want to challenge a theory or model , it is important to know what evidence its authors will consider as convincing negative evidence . Ellemers et al . ( 2020 ) have suggested to bring researchers with opposing views together to seek “adversarial alignment” in addressing compet - ing conceptual frameworks . The idea is that such a group of researchers together can design a study that allows the direct testing of competing hypotheses . It also places pressure on partici - pants to address opposing views and actively seek harmonization rather than letting debates fade away and traditions grow further apart . Replication projects are never an easy route to go in cross - cultural psychology . Obviously , seeking “adversarial alignment” will add to the complexities . There exists a large volume of research in cross - cultural psychology centering on a theory or instrument developed in the “West” and administered elsewhere ( often in the Majority World ) to seek further validation . In such stud - ies , sometimes including a substantial number of populations , most co - authors have contributed to the collection of data . In this way , they have provided an indispensable but limited input . The kind of collaboration that we envisage will cover all stages of a project , with input from , in prin - ciple , all populations to which the results should apply , and , last but not least , no impositions by a senior researcher , or leading research team . Projects in educational assessment , such as PISA ( www . oecd . org / pisa / aboutpisa ) , have made major steps in the direction of such extensive coop - eration . Another significant step in this direction is the current practice of journals to require endorsement of the full manuscript by all authors of multi - authored papers . This implies that each author accepts full accountability . Conclusion The motto at the top of this article is taken from a discussion in the field of nuclear physics ; it relates to a premature claim that a new nuclear particle ( the Majorana particle ) had been 856 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) identified . This example illustrates that even in fields of science known for strict methodology incorrect claims can occur . Methodology as portrayed in this article presumes that some state - ments about an objective reality have a higher truth value than other statements . Researchers are accountable for making valid , empirically grounded , statements based on sound methodology and valid methods . In this respect cross - cultural psychology has shown progress ; we have better methods of analysis and more insight in how findings can be threatened by bias in data and inter - pretation . At the same time , it is clear that there is ample scope for improvement and more accountability . From a methodological perspective , the next 50 years should not be less interest - ing for cross - cultural psychologists than the past 50 years . Author Note We like to thank an anonymous Reviewer and the Editors of this Special Issue of JCCP for comments on an earlier version of this article . Declaration of Conflicting Interests The author ( s ) declared no potential conflicts of interest with respect to the research , authorship , and / or publication of this article . Funding The author ( s ) received no financial support for the research , authorship , and / or publication of this article . ORCID iD Johnny R . J . Fontaine https : / / orcid . org / 0000 - 0002 - 5684 - 0178 References Austin , P . C . ( 2011 ) . An introduction to propensity score methods for reducing the effects of confounding in observational studies . Multivariate Behavioral Research , 46 ( 3 ) , 399 – 424 . https : / / doi . org / 10 . 1080 / 0 0273171 . 2011 . 568786 Barrett , L . F . , Adolphs , R . , Marsella , S . , Martinez , A . M . , & Pollak , S . D . ( 2019 ) . Emotional expressions reconsidered : Challenges to inferring emotion from human facial movements . Psychological Science in the Public Interest , 20 ( 1 ) , 1 – 68 . https : / / doi . org / 10 . 1177 / 1529100619832930 Bender , M . , & Adams , B . ( 2021 ) . Methods and assessment in culture and psychology . Cambridge University Press . https : / / doi . org / 10 . 1017 / 9781108675475 Berry , J . W . ( 1989 ) . Imposed etics - emics - derived etics : The operationalization of a compelling idea . International Journal of Psychology , 24 ( 6 ) , 721 – 735 . https : / / doi . org / 10 . 1080 / 00207598908247841 Berry J . W . ( Ed . ) . ( 1997 ) . Handbook of cross - cultural psychology ( 2nd ed . , Vols . I – III ) . Allyn & Bacon . Berry , J . W . , Poortinga , Y . H . , Breugelmans , S . M . , Chasiotis , A . , & Sam , D . L . ( 2011 ) . Cross - cultural psychology : Research and applications ( 3rd ed . ) . Cambridge University Press . Boehnke , K . , Lietz , P . , Schreier , M . , & Wilhelm , A . ( 2011 ) . Sampling : The selection of cases for culturally comparative psychological research . In D . Matsumoto & F . J . R . Van de Vijver ( Eds . ) , Cross - cultural research methods in psychology ( pp . 101 – 129 ) . Cambridge University Press . https : / / doi . org / 10 . 1017 / CBO9780511779381 . 007 Boer , D . , Hanke , K . , & He , J . ( 2018 ) . On detecting systematic measurement error in cross - cultural research : A review and critical reflection on equivalence and invariance tests . Journal of Cross - Cultural Psychology , 49 ( 5 ) , 713 – 734 . https : / / doi . org / 10 . 1177 / 0022022117749042 Brislin , R . W . , Lonner , W . J . , & Thorndike , R . M . ( 1973 ) . Cross - cultural research methods . Wiley . Bryman , A . ( 2015 ) . Social research methods ( 5th ed . ) . Oxford University Press . Button , K . S . , Ioannidis , J . P . A . , Mokrysz , C . , Nosek , B . A . , Flint , J . , Robinson , E . S . J . , & Munafo , M . R . ( 2013 ) . Power failure : Why small sample size undermines the reliability of neuroscience . Nature Reviews Neuroscience , 14 ( 5 ) , 365 – 376 . https : / / doi . org / 10 . 1038 / nrn3475 Poortinga and Fontaine 857 Byrne , B . , & Van de Vijver , F . J . R . ( 2010 ) . Testing for measurement and structural equivalence in large - scale cross - cultural studies : Addressing the issue of nonequivalence . International Journal of Testing , 10 ( 2 ) , 107 – 132 . https : / / doi . org / 10 . 1080 / 15305051003637306 Campbell , D . T . ( 1964 ) . Distinguishing differences of perception from failures of communication in cross - cultural studies . In F . S . C . Northrop & H . H . Livingston ( Eds . ) , Cross - cultural understanding : Epistemology in anthropology ( pp . 308 – 336 ) . Harper & Row . Campbell , D . T . , & Stanley , J . C . ( 1963 ) . Experimental and quasi - experimental designs for research . Rand McNally . Cohen , D . , & Kitayama , S . ( Eds . ) . ( 2019 ) . Handbook of cultural psychology ( 2nd ed . ) . Guildford Press . Cohen , J . ( 1994 ) . The earth is round ( p < . 05 ) . American Psychologist , 49 ( 12 ) , 997 – 1003 . https : / / doi . org / 10 . 1037 / 0003 - 066X . 50 . 12 . 1103 Corbin , J . M . , & Strauss , A . ( 1990 ) . Grounded theory research : Procedures , canons , and evaluative criteria . Qualitative Sociology , 13 , 3 – 21 . https : / / doi . org / 10 . 1007 / BF00988593 Creswell , J . W . ( 2009 ) . Research design : Qualitative , quantitative , and mixed methods approaches ( 3rd ed . ) . SAGE . De Groot , A . D . , & Spiekerman , J . A . A . ( 1969 ) . Methodologies : Foundations of inference and research in the behavioral sciences . De Gruyter Mouton . Denzin , N . K . , & Lincoln , Y . S . ( Eds . ) . ( 2017 ) . The SAGE handbook of qualitative research ( 5th ed ) . SAGE . Elfenbein , H . A . ( 2013 ) . Nonverbal dialects and accents in facial expressions of emotion . Emotion Review , 5 ( 1 ) , 90 – 96 . https : / / doi . org / 10 . 1177 / 1754073912451332 Ellemers , N . , Fiske , S . T . , Abele , A . E . , Koch , A . , & Yzerbyt , V . ( 2020 ) . Adversarial alignment enables competing models to engage in cooperative theory building toward cumulative science . PNAS , 117 ( 14 ) , 7561 – 7567 . https : / / doi . org / 10 . 1073 / pnas . 1906720117 Fanelli , D . ( 2010 ) . “Positive” results increase down the hierarchy of the sciences . PLoS One , 5 ( 4 ) , e10068 . https : / / doi . org / 10 . 1371 / journal . pone . 0010068 Fischer , R . , & Poortinga , Y . H . ( 2018 ) . Addressing methodological challenges in culture - comparative research . Journal of Cross - Cultural Psychology , 49 ( 5 ) , 689 – 712 . https : / / doi . org / 10 . 1177 / 0022022117738086 Fischer , R . , Vauclair , C . M . , Fontaine , J . R . J . , & Schwartz , S . H . ( 2010 ) . Are individual - level and country - level value structures different ? Testing Hofstede’s legacy with the Schwartz value survey . Journal of Cross - Cultural Psychology , 41 ( 2 ) , 135 – 151 . https : / / doi . org / 10 . 1177 / 0022022109354377 Fontaine , J . R . J . ( 2008 ) . Traditional and multilevel approaches in cross - cultural research : An integration of methodological frameworks . In F . J . R . Van de Vijver , D . A . Van Hemert , & Y . H . Poortinga ( Eds . ) , Multilevel analysis of individuals and cultures ( pp . 65 – 92 ) . Lawrence Erlbaum . Fontaine , J . R . J . , Scherer , K . R . , & Soriano , C . ( Eds . ) . ( 2013 ) . Components of emotional meaning : A sourcebook . Oxford University Press . Frolov , S . ( 2021 ) . Quantum computing ' s reproducibility crisis : Majorana fermions . Nature , 592 , 350 – 352 . https : / / doi . org / 10 . 1038 / d41586 - 021 - 00954 - 8 Gosling , S . D . , & Mason , W . ( 2015 ) . Internet research in psychology . Annual Review in Psychology , 66 , 877 – 902 . https : / / doi . org / 10 . 1038 / 10 . 1146 / annurev - psych - 010814 - 015321 Guba , E . G . ( 1981 ) . Criteria for assessing the trustworthiness of naturalistic inquiries . Educational Communication and Technology Journal , 29 ( 2 ) , 75 – 91 . He , J . , Van de Vijver , F . J . R . , Espinosa Domínguez , A . , & Mui , P . H . C . ( 2014 ) . Toward a unification of acquiescent , extreme , and midpoint response styles : A multilevel study . International Journal of Cross Cultural Management , 14 ( 3 ) , 306 – 322 . https : / / doi . org / 10 . 1177 / 1470595814541424 Hinton , D . E . , Reis , R . , & De Jong , J . ( 2020 ) . Ghost encounters among traumatized Cambodian refugees : Severity , relationship to PTSD , and phenomenology . Culture , Medicine , and Psychiatry , 44 ( 3 ) , 333 – 359 . https : / / doi . org / 10 . 1007 / s11013 - 019 - 09661 - 6 Holland , P . W . , & Wainer , H . ( Eds . ) . ( 1993 ) . Differential item functioning . Lawrence Erlbaum . Hox , J . , Moerbeek , M . , & Van de Schoot , R . ( 2010 ) . Multilevel analysis : Techniques and applications ( 2nd ed . ) . Routledge . https : / / doi . org / 10 . 4324 / 9780203852279 Ioannidis , J . P . A . ( 2005 ) . Why most published research findings are false . PLoS Medicine , 2 ( 8 ) , e124 . https : / / doi . org / 10 . 1371 / journal . pmed . 0020124 858 Journal of Cross - Cultural Psychology 53 ( 7 - 8 ) Karasz , A . ( 2011 ) . Qualitative and mixed methods research in cross - cultural psychology . In F . J . R . van de Vijver , A . Chasiotis , & S . M . Breugelmans ( Eds . ) , Fundamental questions in cross - cultural psychology ( pp . 214 – 234 ) . Cambridge University Press . https : / / doi . org / 10 . 1017 / CBO9780511974090 . 010 Kim , U . , Yang , K . - S . , & Hwang , K . - K . ( Eds . ) . ( 2006 ) . Indigenous and cultural psychology : Understanding people in context . Springer . https : / / doi . org / 10 . 1007 / 0 - 387 - 28662 - 4 Kitayama , S . , & Cohen , D . ( Eds . ) . ( 2007 ) . Handbook of cultural psychology . Guildford Press . Klein , R . A . , Ratliff , K . A . , Vianello , M . , Adams , R . B . , Bahnik , S . , Bernstein , M . J . , Bocian , K . , Brandt , M . J . , Brooks , B . , Brumbaugh , C . C . , Cemalcilar , Z . , Chandler , J . , Cheong , W . , Davis , W . E . , Devos , T . , Eisner , M . , Frankowska , N . , Furrow , D . , Galliani , E . M . , . . . Nosek , B . A . ( 2014 ) . Investigating varia - tion in replicability : A “Many Labs” replication project . Social Psychology , 45 ( 3 ) , 142 – 152 . https : / / doi . org / 10 . 1027 / 1864 - 9335 / a000178 Klein , R . A . , Vianello , M . , Hasselman , F . , Adams , B . G . , Adams Jr . , R . B . , Alper , S . , Aveyard , M . , Axt , J . R . , Babalola , M . T . , Bahník , Š . , Batra , R . , Berkics , M . , Bernstein , M . J . , Berry , D . R . , Bialobrzeska , O . , Binan , E . D . , Bocian , K . , Brandt , M . J . , Busching , R . , . . . Nosek , B . A . ( 2018 ) . Many labs 2 : Investigating variation in replicability across samples and settings . Advances in Methods and Practices in Psychological Science , 1 ( 4 ) , 443 – 490 . https : / / doi . org / 10 . 1177 / 2515245918810225 Lucas , R . , & Diener , E . ( 2008 ) . Can we learn about national differences in happiness from individual responses ? A multilevel approach . In F . J . R . van de Vijver , D . A . van Hemert , & Y . H . Poortinga ( Eds . ) , Individuals and cultures in multilevel analysis ( pp . 223 – 248 ) . Lawrence Erlbaum . Lykken , D . T . ( 1968 ) . Statistical significance in psychological research . Psychological Bulletin , 70 ( 3 , Pt . 1 ) , 151 – 159 . https : / / doi . org / 10 . 1037 / h0026141 Malpass , R . S . , & Poortinga , Y . H . ( 1986 ) . Strategies for design and analysis . In W . J . Lonner & J . W . Berry ( Eds . ) , Field methods in cross - cultural research ( pp . 47 – 84 ) . SAGE . Matsumoto , D . , & Van de Vijver , F . J . R . ( 2011 ) . Cross - cultural research methods in psychology . Cambridge University Press . Matsumoto , D . , Yoo , S . H . , Fontaine , J . , Anguas - Wong , A . M . , Arriola , M . , Ataca , B . , Bond , M . H . , Boratav , H . B . , Breugelmans , S . M . , Cabecinhas , R . , Chae , J . , Chin , W . H . , Comunian , A . L . , Degere , D . N . , Djunaidi , A . , Fok , H . K . , Friedlmeier , W . , Ghosh , A . , Glamcevski , M . , . . . Grossi , E . ( 2008 ) . Mapping expressive differences around the world : The relationship between emotional display rules and individualism versus collectivism . Journal of Cross - Cultural Psychology , 39 ( 1 ) , 55 – 74 . https : / / doi . org / 10 . 1177 / 0022022107311854 McCrae , R . R . , & Terracciano , A . ( 2008 ) . The five - factor model and its correlates in individuals and cul - tures . In F . J . R . van de Vijver , D . A . van Hemert , & Y . H . Poortinga ( Eds . ) , Multilevel analyses of individuals and cultures ( pp . 249 – 283 ) . Lawrence Erlbaum . Milfont , T . L . , & Klein , R . A . ( 2018 ) . Replication and reproducibility in cross - cultural psychology . Journal of Cross - Cultural Psychology , 49 ( 5 ) , 735 – 750 . https : / / doi . org / 10 . 1177 / 0022022117744892 Muthén , B . , & Asparouhov , T . ( 2014 ) . IRT studies of many groups : The alignment method . Frontiers in Psychology , 5 , 978 . https : / / doi . org / 10 . 3389 / fpsyg . 2014 . 00978 Open Science Collaboration . ( 2015 ) . Estimating the reproducibility of psychological science . Science , 349 ( 6251 ) , aac4716 . https : / / doi . org / 10 . 1126 / science . aac4716 Oyserman , D . , & Lee , S . W . S . ( 2008 ) . Does culture influence what and how we think ? Effects of priming individualism and collectivism . Psychological Bulletin , 134 ( 2 ) , 311 – 342 . https : / / doi . org / 10 . 1037 / 0033 - 2909 . 134 . 2 . 31 Pike , K . L . ( 1967 ) . Language in relation to a unified theory of the structure of human behavior . Mouton . Pondicherry Manifesto of Indian Psychology . ( 2002 ) . https : / / www . infinityfoundation . com / mandala / i _ es / i _ es _ corne _ manifesto _ frameset . htm Poortinga , Y . H . ( 2021 ) . Concept and method in cross - cultural and cultural psychology . Cambridge University Press . https : / / doi . org / 10 . 1017 / 9781108908320 Poortinga , Y . H . , & Van de Vijver , F . J . R . ( 1987 ) . Explaining cross - cultural differences : Bias analysis and beyond . Journal of Cross - Cultural Psychology , 18 ( 3 ) , 259 – 282 . https : / / doi . org / 10 . 1177 / 0022002187018003001 Scheel , A . M . , Schijen , M . R . M . J . , & Lakens , D . ( 2021 ) . An excess of positive results : Comparing the stan - dard psychology literature with registered reports . Advances in Methods and Practices in Psychological Science , 4 ( 2 ) , 1 – 12 . https : / / doi . org / 10 . 1177 / 25152459211007467 Poortinga and Fontaine 859 Schwandt , T . A . , Lincoln , Y . S . , & Guba , E . G . ( 2007 ) . Judging interpretations : But is it rigorous ? Trustworthiness and authenticity in naturalistic evaluation . New Directions for Evaluation , 114 , 11 – 25 . https : / / doi . org / 10 . 1002 / ev . 223 Segall , M . H . , Campbell , D . T . , & Herskovits , K . J . ( 1966 ) . The influence of culture on visual perception . Bobbs - Merrill . Shadish , W . R . , Cook , T . D . , & Campbell , D . T . ( 2002 ) . Experimental and quasi - experimental designs for generalized causal inference . Houghton Mifflin . Shweder , R . A . ( 1990 ) . Cultural psychology—What is it ? In J . W . Stigler , R . A . Shweder , & G . Herdt ( Eds . ) , Cultural psychology : Essays on comparative human development ( pp . 1 – 43 ) . Cambridge University Press . Silan , M . , Adetula , A . , Basnight - Brown , D . M . , Forscher , P . S . , Dutra , N . , & Ijzerman , H . ( 2021 ) . ( 2021 ) . Let’s talk about the “C” word : Colonialism and the challenges of psychological science in the develop - ing world . Observer , 34 ( 6 ) , 64 – 69 . Simmons , J . P . , Nelson , L . D . , & Simonsohn , U . ( 2011 ) . False - positive psychology : Undisclosed flexibil - ity in data collection and analysis allows presenting anything as significant . Psychological Science , 22 ( 11 ) , 1359−1366 . https : / / doi . org / 10 . 1177 / 0956797611417632 Sinha , D . ( 1997 ) . Indigenizing psychology . In J . W . Berry , Y . H . Poortinga , & J . Pandey ( Eds . ) , Handbook of cross - cultural psychology ( Vol . 1 , 2nd ed . , pp . 129 – 169 ) . Allyn & Bacon . Stroebe , W . ( 2019 ) . What can we learn from many labs replications ? Basic and Applied Social Psychology , 41 ( 2 ) , 91 – 103 . https : / / doi . org / 10 . 1080 / 01973533 . 2019 . 1577736 Triandis , H . C . ( Ed . ) . ( 1980 ) . Handbook of cross - cultural psychology ( Vols . I – VI ) . Allyn & Bacon . Van de Vijver , F . J . R . , & Leung , K . ( 1997 ) . Methods and data analysis for cross - cultural research . SAGE . Van de Vijver , F . J . R . , & Leung , K . ( 2021 ) . Methods and data analysis for cross - cultural research ( 2nd ed . ) . Cambridge University Press . https : / / doi . org / 10 . 1017 / 9781107415188 Van de Vijver , F . J . R . , & Poortinga , Y . H . ( 1982 ) . Cross - cultural generalization and universality . Journal of Cross - Cultural Psychology , 13 ( 4 ) , 387 – 408 . https : / / doi . org / 10 . 1177 / 0022002182013004001 Van de Vijver , F . J . R . , Van Hemert , D . A . , & Poortinga , Y . H . ( 2008 ) . Conceptual issues in multilevel models . In F . J . R . van de Vijver , D . A . van Hemert , & Y . H . Poortinga ( Eds . ) , Individuals and cultures in multi - level analysis ( pp . 3 – 26 ) . Lawrence Erlbaum . Van Herk , H . , Poortinga , Y . H . , & Verhallen , T . M . M . ( 2004 ) . Response styles in rating scales : Evidence of method bias in data from six EU countries . Journal of Cross - Cultural Psychology , 35 ( 3 ) , 346 – 360 . https : / / doi . org / 10 . 1177 / 0022022104264126 Vandenberg , R . J . , & Lance , C . E . ( 2000 ) . A review and synthesis of the measurement invariance literature : Suggestions , practices , and recommendations for organizational research . Organizational Research Methods , 3 ( 1 ) , 4 – 70 . https : / / doi . org / 10 . 1177 / 109442810031002 Vignoles , V . L . , Owe , E . , Becker , M . , Smith , P . B . , Easterbrook , M . J . , Brown , R . , Gonzalez , R . , Didier , N . , Carrasco , D . , Cadena , M . P . , Lay , S . , Schwartz , S . J . , Des Rosiers , S . E . , Villamar , J . A . , Gavreliuc , A . , Zinkeng , M . , Kreuzbauer , R . , Baguma , P . , Martin , M . , . . . Bond , M . H . ( 2016 ) . Beyond the ‘east – west’ dichotomy : Global variation in cultural models of selfhood . Journal of Experimental Psychology : General , 145 ( 8 ) , 966 – 1000 . https : / / doi . org / 10 . 1037 / xge0000175 Walter , K . V . , Conroy - Beam , D . , Buss , D . M . , Asao , K . , Sorokowska , A . , Sorokowski , P . , Aavik , T . , Akello , G . , Alhabahba , M . M . , Alm , C . , Amjad , N . , Anjum , A . , Atama , C . S . , Duyar , D . A . , Ayebare , R . , Batres , C . , Bendixen , M . , Bensafia , A . , Bizumic , B . , . . . Zupancic , M . ( 2020 ) . Sex differences in mate preferences across 45 countries : A large - scale replication . Psychological Science , 31 , 408 – 423 . Wasserstein , R . L . , & Lazar , N . A . ( 2016 ) : The ASA’s statement on p - values : context , process , and purpose . The American Statistician , 70 ( 2 ) , 129 – 133 . https : / / doi . org / 10 . 1080 / 00031305 . 2016 . 1154108 Whiting , J . W . M . ( 1994 ) . Environmental constraints on infant care practices . In E . H . Chasdi ( Ed . ) , Culture and human development ( pp . 107 – 134 ) . Cambridge University Press . Wicherts , J . M . , Veldkamp , C . L . S . , Augusteijn , H . E . M . , Bakker , M , van Aert , R . C . M . , & van Assen , M . A . L . M . ( 2016 ) . Degrees of freedom in planning , running , analyzing , and reporting psychologi - cal studies : A checklist to avoid p - hacking . Frontiers in Psychology , 7 , 1832 . https : / / doi . org / 10 . 3389 / fpsyg . 2016 . 01832