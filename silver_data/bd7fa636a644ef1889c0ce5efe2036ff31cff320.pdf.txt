Filtering Offensive Language in Online Communities using Grammatical Relations Zhi Xu Department of Computer Science and Engineering The Pennsylvania State University University Park , PA 16802 zux103 @ cse . psu . edu Sencun Zhu Department of Computer Science and Engineering The Pennsylvania State University University Park , PA 16802 szhu @ cse . psu . edu ABSTRACT Oï¬€ensive language has arisen to be a big issue to the health of both online communities and their users . To the online community , the spread of oï¬€ensive language undermines its reputation , drives users away , and even directly aï¬€ects its growth . To users , viewing oï¬€ensive language brings negative inï¬‚uence to their mental health , especially for children and youth . When oï¬€ensive language is detected in a user message , a problem arises about how the oï¬€ensive language should be removed , i . e . the oï¬€ensive language ï¬ltering problem . To solve this problem , manual ï¬ltering approach is known to produce the best ï¬ltering result . However , manual ï¬ltering is costly in time and labor thus can not be widely applied . In this paper , we analyze the oï¬€ensive language in text messages posted in online communities , and propose a new automatic sentence - level ï¬ltering approach that is able to semantically remove the oï¬€ensive language by utilizing the grammatical relations among words . Comparing with ex - isting automatic ï¬ltering approaches , the proposed ï¬ltering approach provides ï¬ltering results much closer to manual ï¬ltering . To demonstrate our work , we created a dataset by manu - ally ï¬ltering over 11 , 000 text comments from the YouTube website . Experiments on this dataset show over 90 % agree - ment in ï¬ltered results between the proposed approach and manual ï¬ltering approach . Moreover , we show the overhead of applying proposed approach to user comments ï¬ltering is reasonable , making it practical to be adopted in real life applications . 1 . INTRODUCTION Online social networking ( OSN ) websites have enjoyed a great success in recent years . People in OSN websites form social aggregations , called online communities [ 8 ] . These on - line communities have become the new frontier in todayâ€™s so - cial relationships and provide great places for self - expression and the exchange of ideas . Many of them , such as Facebook , have grown to huge communities with millions of registered members 1 . 1 Facebook statistics , at http : / / www . facebook . com / press / info . php ? statistics CEAS 2010 - Seventh annual Collaboration , Electronic messaging , Anti - Abuse and Spam Conference July 13 - 14 , 2010 , Redmond , Washington , US Online communities , being virtual , however , have also en - couraged the use of oï¬€ensive language . The deï¬nition of oï¬€ensive language can be subjective because diï¬€erent view - ers have diï¬€erent feelings about the same content . In this paper , we accept the deï¬nition of oï¬€ensive language as text content including gutter language , sexually explicit mate - rial , racist , graphic violence , or any other content that may be considered oï¬€ensive on social , religious , cultural or moral grounds 2 . Unfortunately , oï¬€ensive language has spread into almost every corner of online communities . A study , done by ScanSafe , shows that up to 80 % of blogs contain oï¬€ensive language [ 5 ] . Posting messages with oï¬€ensive language intentionally has become a major way of cyber - bullying in online commu - nities . To users , oï¬€ensive language can be very harmful to their mental health , especially for children and youth . To the online community , the deluge of oï¬€ensive language undermines the communityâ€™s reputation , drives users away , and even directly aï¬€ects its growth . For example , an iPhone application , Tweetie , was once rejected by Apple company in March 2009 , for bringing oï¬€ensive language posted in the Twitter community to iPhone users . People have realized the problems brought by oï¬€ensive language in online communities . And many eï¬€orts have been made on detecting the existence of oï¬€ensive language within user messages , such as [ 10 ] and [ 3 ] . However , detection alone is not enough to eliminate the hazard caused by oï¬€ensive language . When oï¬€ensive con - tents ( e . g . , oï¬€ensive words ) are detected within a user mes - sage , a question arises naturally about how the detected oï¬€ensive content should be removed from message . The process of removing oï¬€ensive content from user messages is called oï¬€ensive language ï¬ltering . Consider a sentence consisting of a sequence of words . The problem of identi - fying words that should be removed in oï¬€ensive language ï¬ltering is called oï¬€ensive language ï¬ltering problem . In this paper , we propose a sentence - level semantic ï¬lter - ing approach , which utilizes grammatical relations among words to semantically remove oï¬€ensive content in a sen - tence . Speciï¬cally , for each sentence within a user message , we ï¬rst identify oï¬€ensive words , and then extract semantic relations and syntactic relations among words in the sen - tence . Based on the extracted relations , we estimate which words should be removed with those oï¬€ensive words using two heuristic rules , i . e . â€œModiï¬cation Relation Ruleâ€ and 2 The Internet Content Rating Association ( ICRA ) , at http : / / www . icra . org / sitelabel / â€œPattern Integrity Ruleâ€ . To avoid confusion , we use the term â€œ removable â€ to describe the result of our estimation . Words estimated as removable will be deleted from sentence at the end of ï¬ltering . Compared with existing automatic ï¬ltering approaches , such as keyword censoring approach applied on YouTube website and content control approach applied in Microsoft Parental Controls , the proposed semantic ï¬ltering approach is able to remove oï¬€ensive content in a text message thor - oughly while keeping inoï¬€ensive content untouched as much as possible . Further , the readability of ï¬ltered content is guaranteed so as to make our ï¬ltering transparent to reader . Compared with manual ï¬ltering , which outputs optimal ï¬l - tering results , the proposed semantic ï¬ltering approach is fully automatic with close ï¬ltering results . To demonstrate the performance , we have created a dataset containing 11670 user comments collected from YouTube website . For each user comment , we perform both man - ual ï¬ltering and semantic ï¬ltering and then compare their outputs . According to experimental results , the semantic ï¬ltering achieves as high as 90 . 94 % agreement with man - ual ï¬ltering . Meanwhile , the processing speed of semantic ï¬ltering is about 48 . 8 ğ‘šğ‘ ğ‘’ğ‘ per comment , making it prac - tical to be deployed at the server side of online websites . Furthermore , for user side application , we present an imple - mentation of semantic ï¬lter as a Firefox extension , which is able to ï¬lter the user comments on webpages when a user is browsing on OSN websites . We show the advantage of our proposed ï¬ltering extension by comparing it with the â€œ Hide objectionable words â€ function provided by YouTube . 2 . RELATED WORK In this section , we review related work and list some major approaches and methodologies for oï¬€ensive language ï¬lter - ing in online communities . To demonstrate our observations , we present examples of applying diï¬€erent approaches in Ta - ble 1 . Sentences in the table are cited from real user com - ments in YouTube dataset . For mental health of readers , we replaced the oï¬€ensive words by special words . 2 . 1 Keyword Censoring Approach Keyword censoring approaches match words appearing in text messages with oï¬€ensive words stored in the blacklist . Once found , these oï¬€ensive words will be removed , partially replaced ( e . g . , â€œa * * * â€ ) , completely replaced ( e . g . , â€œ * * * * â€ ) , or substituted by family friendly words ( e . g . , â€œniceâ€ ) . Be - cause of its simplicity , keyword based censoring approach has been widely applied in OSN websites , such as YouTube 3 and World of Warcraft 4 . However , the ï¬ltering result is not as desired . Brutally removing words from text message breaks the readability of text messages . Replacing oï¬€ensive words with symbols usually makes it easy to guess the original oï¬€ensive words . The idea of substitution seems tempting , but accurate sub - stitution is usually impractical . Inaccurate substitution will introduce additional issues . For example , in 2001 , Yahoo ! deployed an Email ï¬lter which may automatically alter cer - tain words in emails by family friendly words . This ï¬lter was criticized as a â€œfoolish ï¬lterâ€ by BBC news 5 because of 3 YouTube , at http : / / www . youtube . com 4 World of Warcraft , at www . worldofwarcraft . com / 5 http : / / news . bbc . co . uk / 2 / hi / sci / tech / 2138014 . stm its inaccurate substitution . To demonstrate the shortcoming of keyword censoring ap - proaches , we present examples in Table 1 . According to pre - sented ï¬ltering results , readers can still easily understand what the oï¬€ender wants to say and even be able to infer the removed words . This indicates the failure ï¬ltering because oï¬€ensive opinion has been successfully delivered to victims . Also , removing words from a sentence without considering their context breaks the readability of rest of the sentence . Compared with keyword censoring approaches , our pro - posed semantic ï¬ltering approach is much more sophisti - cated and can achieve thorough ï¬ltering eï¬€ort by utiliz - ing the grammatical relations among words in the sentence . Given a sentence containing both oï¬€ensive and inoï¬€ensive words , not only oï¬€ensive words but also inoï¬€ensive words assisting to express oï¬€ensive opinions will be removed dur - ing our ï¬ltering . In this way , we essentially stop the delivery of oï¬€ensive opinion . And , there will be no way to infer the oï¬€ensive content in original messages after ï¬ltering . 2 . 2 Content Control Approach Content control approaches are usually deployed at user side or ISP side to prevent user from seeing inappropriate content on the Internet . Its ï¬ltering is usually done based on certain criteria , such as URL address , the occurrence of oï¬€ensive words , and topic classiï¬cation . Here our focus is text based criteria . For example , in Table 1 , we present a sentence based content control approach with threshold set as the number of oï¬€ensive words in the sentence . If at least two oï¬€ensive words are detected within a sentence , the ï¬lter will remove the sentence from user message . However , content control approaches are too coarse - grained to be applied in online communities . First of all , oï¬€ender can easily bypass the ï¬ltering as long as knowing the estima - tion criteria . More important , a sentence in user comment may contain both oï¬€ensive and inoï¬€ensive content . Inoï¬€en - sive part may be removed falsely because of oï¬€ensive part , e . g . , the partial oï¬€ensive case shown in Table 1 . Not allow - ing user to post inoï¬€ensive content would easily drive users away and thus aï¬€ect the growth of community . Compared with content control approaches , we provide a ï¬ne - grained ï¬ltering by removing only the smallest syntactic part in the sentence containing oï¬€ensive language . The inof - fensive content in the original message will remain ; thereby , user still has the freedom of speech for posting inoï¬€ensive content . We believe such delicate ï¬ltering will be more ac - ceptable to online communities . 2 . 3 Manual Filtering Approach Manual ï¬ltering is believed to produce the best ï¬ltering result . Basically , user messages are reviewed by community administrator before being posted on the website . As shown in Table 1 , the administrator is able to easily understand what the author wants to express and precisely remove only the oï¬€ensive content within the text . However , manual ï¬ltering is very time and labor consum - ing , making it impossible to be widely applied . For example , in the Sina blog community 6 , the blog administrator will manually review and ï¬lter user comments on some celebri - tiesâ€™ public blogs . Obviously , users would expect a delay between posting a comment on a blog and displaying this 6 Sina Blog Community , at http : / / blog . sina . com . cn Table 1 : Filtering results with diï¬€erent approaches Sentence ( we use ğ‘ğ‘Ÿğ‘¦ğ‘–ğ‘›ğ‘” and ğ‘ğ‘–ğ‘” to denote two oï¬€ensive words ) Partial Oï¬€ensive Absolute Oï¬€ensive Original Comment â€œthis video is ğ‘ğ‘Ÿğ‘¦ğ‘–ğ‘›ğ‘” goodâ€ â€œit is aston martin and you are a ğ‘ğ‘Ÿğ‘¦ğ‘–ğ‘›ğ‘” ğ‘ğ‘–ğ‘” â€ â€œyouâ€™re a ğ‘ğ‘–ğ‘” â€ Keyword Censoring â€œthis video is ğ‘ âˆ— âˆ—âˆ— goodâ€ â€œitâ€™s aston martin and you are a ğ‘ âˆ— âˆ—âˆ— ğ‘ âˆ— âˆ— â€ â€œyouâ€™re a ğ‘ âˆ— âˆ—âˆ— â€ Content Control ( thld = 2 ) â€œthis video is ğ‘ğ‘Ÿğ‘¦ğ‘–ğ‘›ğ‘” goodâ€ â€œ â€ â€œyouâ€™re a ğ‘ğ‘–ğ‘” â€ Manual Filtering â€œthis video is goodâ€ â€œitâ€™s aston martinâ€ â€œ â€ comment on the blogâ€™s webpage . Further , the ï¬ltering to - tally relies on the judgment of the community administrator . Our proposed semantic ï¬ltering approach mimics the pro - cedure of manual ï¬ltering by trying to understand the re - lations among words in order to remove the oï¬€ensive con - tent semantically . In our experiments , we show that the results between our proposed approach and manual ï¬lter - ing are very close ( more than 90 % agreement ) . Moreover , the proposed semantic ï¬ltering approach is fully automatic requiring no interference of administrator . 3 . PROPOSED FILTERING PHILOSOPHY The goal of our semantic ï¬ltering is to achieve ï¬ltering results close to that of manual ï¬ltering . To reach this goal , the foremost thing is to answer the question about how the ï¬ltering should be performed in order to get the desired ï¬ltering results . In this section , we present our answer in three steps . First , we analyze the characteristics of oï¬€ensive text content in user messages . Then , we introduce our ï¬ltering philosophy according to the summarized characteristics . Finally , we show how this philosophy is transformed into heuristic rules applicable in the ï¬ltering process . 3 . 1 Offensive Language Text Content Based on the observation on user comments collected from YouTube website , a sentence in a user message may contain both oï¬€ensive and inoï¬€ensive text content . Oï¬€ensive text content is exposed intentionally with purpose of bringing negative inï¬‚uence to victims ( e . g . , the readers of text mes - sage ) . The victim receives the negative inï¬‚uence by reading the oï¬€ensive part of sentence and understanding the carried oï¬€ensive information . Hence , the information carried by original sentence can be represented as ğ¼ = ğ¼ ğ‘œğ‘“ğ‘“ + ğ¼ ğ‘–ğ‘›ğ‘œğ‘“ğ‘“ . The oï¬€ender reaches his goal when the oï¬€ensive information ğ¼ ğ‘œğ‘“ğ‘“ is delivered to readers . Therefore , to achieve a thorough ï¬ltering , all words used to deliver ğ¼ ğ‘œğ‘“ğ‘“ should be removed . Meanwhile , with respect to free speech , the part with ğ¼ ğ‘–ğ‘›ğ‘œğ‘“ğ‘“ should be saved . 3 . 2 Filtering Philosophy According to the analysis , we propose the philosophy that should be followed in sentence - level oï¬€ensive language ï¬lter - ing : âˆ™ Precisely identify all oï¬€ensive contents and remove them semantically , so that viewers will not notice the existence of oï¬€ensive language in the original sen - tence ; âˆ™ Keep the readability and inoï¬€ensive content in the sentence , so that the author will still be allowed to express his opinion freely as long as it is not oï¬€ensive ; We call this the philosophy of â€œ ï¬ltering instead of block - ing â€ . To the ï¬lter , the philosophy states that : if removing one word will make another word meaningless or confusing to readers , we should consider removing both words to keep the readability of a ï¬ltered sentence ; meanwhile , we only remove words that are aï¬€ected by oï¬€ensive words . For example , in the sentence â€œit is aston martin and you are a crying pigâ€ , suppose â€œcryingâ€ and â€œpigâ€ are two of - fensive words , the sentence can be separated into two parts . The ï¬rst part , â€œit is aston martinâ€ , is inoï¬€ensive ; but the second part , â€œyou are a crying pigâ€ is oï¬€ensive . Therefore , we should remove the second part completely while keep - ing the ï¬rst part . The word â€œandâ€ should also be removed in order to keep the transparency of ï¬ltering as well as the readability of ï¬ltered text content . 3 . 3 Filtering Rules Speciï¬cally , the proposed philosophy is transformed into two heuristic rules to estimate the impact of removing words in a sentence . Rule 1 . ( Modiï¬cation Relation ) in a modiï¬cation rela - tion , if the modiï¬er is determined to be oï¬€ensive , removing modiï¬er solely is enough ; if the head is determined to be of - fensive , both the head and the modiï¬er should be removed . The modiï¬cation relation is a binary semantic relation - ship between two syntactic elements , such as word , phrase , etc . One element is named head and the other is named modiï¬er . The modiï¬er is used to describe the head ( i . e . the modiï¬ed component ) . Semantically , modiï¬ers describe and provide more accurate deï¬nitional meaning for head . As the modiï¬er acts as a complement , the removal of the modiï¬er typically will not aï¬€ect the grammaticality of the construc - tion . For example , in the sentence â€œshe likes red apples . â€ , the adjective â€œredâ€ is used to modify the noun â€œapplesâ€ . Re - moving â€œredâ€ will keep the readability of rest of sentence . We admit that , removing modiï¬ers will lose some informa - tion carried by modiï¬ers . However , if the modiï¬er is deter - mined removable but the head is not , removing modiï¬er will remove only the oï¬€ensive information . Rule 2 . ( Pattern Integrity ) if removing the oï¬€ensive word breaks the integrity of sentenceâ€™s basic pattern , the whole sentence should be removed in order to keep the readability . English sentences and clauses are organized in basic pat - terns , such as â€œSubject - Verbâ€ , â€œSubject - Verb - Objectâ€ , â€œSubject - Verb - Adjectiveâ€ , â€œSubject - Verb - Adverbâ€ , and â€œSubject - Verb - Nounâ€ . Every sentence or clause can be categorized into one pattern . The integrity of basic pattern is essential to the readability of content . For example , the sentence â€œshe sleeps on the sofa . â€ follows â€œSubject - Verbâ€ pattern . If we only remove â€œsleepsâ€ , the rest of the sentence , â€œshe on the sofa . â€ will become nonsense . In the next section we will show details about applying these two rules during the ï¬ltering . 4 . IDENTIFY REMOVABLE CONTENT BY GRAMMATICAL RELATIONS A text message can be decomposed into a sequence of sentences . Each sentence is considered as a unit in ï¬lter - ing . Given a sentence containing both oï¬€ensive words and inoï¬€ensive words , the goal of ï¬ltering is to identify inoï¬€en - sive words which should be removed together with oï¬€ensive words . We deï¬ne the words that should be removed by the ï¬ltering as â€œ removable â€ words . We noticed that manual ï¬ltering can easily achieve this goal because human can easily understand the context of words in a sentence and precisely identify which words should be removed with known oï¬€ensive words . So , we mimic the manual ï¬ltering in that , we extract the grammatical rela - tions among words from sentences and use the proposed ï¬l - tering rules to estimate the impact of removing oï¬€ensive words on other inoï¬€ensive words based on extracted gram - matical relations . Speciï¬cally , the proposed approach includes two steps ( de - tails to be elaborated in the next two subsections ) . In the ï¬rst step , we scan the sentence and see if oï¬€ensive words ex - ist . If exist , we continue to retrieve grammatical information ( i . e . Part - of - Speech tags and typed dependency relations ) among words in the sentence . Using retrieved grammatical information , we create a tree data structure , named RelTree , for the second step estimation . In this second step , we pro - pose a set of estimation functions following the ï¬ltering rules we proposed . Using the RelTree structure and the proposed rules , we then estimate if there are inoï¬€ensive words that should be removed together with those identiï¬ed oï¬€ensive words . The overview idea of our semantic ï¬ltering approach is shown in Algorithm 1 . Within the algorithm , the functions ğ‘ƒğ‘‚ğ‘†ğ‘¡ğ‘ğ‘”ğ‘”ğ‘–ğ‘›ğ‘” and ğ‘‡ğ·ğ‘”ğ‘’ğ‘›ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘œğ‘Ÿ generate Part - of - Speech tags and typed dependency relations , respectively . We use exist - ing NLP ( Natural Language Processing ) tools [ 2 ] to imple - ment these two functions . In the rest of this section , we will focus on the design of two other functions ğ¶ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘’ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ and ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘¡ğ‘’ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ . Note that , in this section , we assume that the ï¬ltering is based on a comprehensive oï¬€ensive lexicon containing all oï¬€ensive words . Words do not appear in the lexicon are considered inoï¬€ensive . We discuss the case of incomplete lexicon separately in Section 6 . 4 . 1 First Step : Grammatical Analysis In the ï¬rst step , we extract two types of grammatical in - formation from a given sentence . One is the Part - of - Speech information associated with every word . The other is the dependency relation among words . Part - of - Speech informa - tion helps us to understand the organization of a sentence , which is essential for keeping the readability when we try to remove words from a sentence . Dependency relations will be used directly to estimate the impact of removing one word on other semantically related words , making the ï¬ltering more â€œmeaningfulâ€ . Combining these two types of informa - tion , we can create a new data structure , called RelTree , for input : a text comment ğ‘‡ , a blacklist of oï¬€ensive words ğµğ‘™ğ‘ğ‘ğ‘˜ğ‘™ğ‘–ğ‘ ğ‘¡ output : a ï¬ltered text comment ğ‘‡ â€² ğ‘‡ â€² â† â€œâ€ ; 1 ğ‘ ğ‘’ğ‘›ğ¿ğ‘–ğ‘ ğ‘¡ â† chunk ğ‘‡ into a list of sentences ; 2 foreach sentence ğ‘  âˆˆ ğ‘ ğ‘’ğ‘›ğ¿ğ‘–ğ‘ ğ‘¡ do 3 scan ğ‘  for oï¬€ensive words using ğµğ‘™ğ‘ğ‘ğ‘˜ğ‘™ğ‘–ğ‘ ğ‘¡ ; 4 if no oï¬€ensive word found then 5 ğ‘‡ â€² â† ğ‘‡ â€² + ğ‘  ; 6 end 7 else 8 ğ‘ƒğ‘‡ğ‘Ÿğ‘’ğ‘’ â† ğ‘ƒğ‘‚ğ‘†ğ‘¡ğ‘ğ‘”ğ‘”ğ‘–ğ‘›ğ‘” ( ğ‘  ) ; / * get parse tree * / 9 ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ â† ğ‘‡ğ·ğ‘”ğ‘’ğ‘›ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘œğ‘Ÿ ( ğ‘  ) ; / * get typed 10 dependency relations * / ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ â† ğ¶ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘’ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ( ğ‘ƒğ‘‡ğ‘Ÿğ‘’ğ‘’ , ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ ) ; 11 / * create RelTree * / ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ â† 12 ğ¸ğ‘ ğ‘¡ğ‘–ğ‘šğ‘ğ‘¡ğ‘’ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ( ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ , ğµğ‘™ğ‘ğ‘ğ‘˜ğ‘™ğ‘–ğ‘ ğ‘¡ ) ; / * estimate using RelTree * / ğ‘  â€² â† remove all words in ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ those 13 are labeled as â€œremovableâ€ ; ğ‘‡ â€² â† ğ‘‡ â€² + ğ‘  â€² ; 14 end 15 end 16 Return ğ‘‡ â€² ; 17 Algorithm 1 : Procedure of Semantic Filtering Figure 1 : A parse tree of a sentence basing on Part - of - Speech tags the next - step estimation . 4 . 1 . 1 Part - of - Speech Tagging Part - of - Speech tagging has been widely used in NLP ap - plications to identify the syntactic properties of lexical items in a sentence , such as word or phrase . Through Part - of - Speech tagging , the sentence can be represented in a tree structure basing on Part - of - Speech tags . We adopt the Penn Treebank tag set [ 4 ] for our Part - of - Speech tagging . An example of Penn Treebank style parse tree is shown in Figure 1 . Here , the leaf nodes are words appearing in the sentence . The non - leaf nodes represent syntactic ele - ments , such as phrases or clauses . Each element consists of the words within its subtree . For example , in Figure 1 , the words â€œisâ€ , â€œastonâ€ , and â€œmartinâ€ constitute a Verb Phrase ( i . e . VP ) node . To avoid showing oï¬€ensive language in this paper , we use two terms , â€œcryingâ€ and â€œpigâ€ , to replace original oï¬€ensive words in this example . Figure 2 : An example of typed dependency graph 4 . 1 . 2 Typed Dependency Relations Typed Dependency is a kind of general relations describ - ing the grammatical dependencies within a sentence , pro - posed by Stanford Natural Language Processing Group [ 6 ] . According to [ 6 ] , each typed dependency includes a depen - dency type and a ( ğ‘”ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘›ğ‘œğ‘Ÿ , ğ‘‘ğ‘’ğ‘ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘›ğ‘¡ ) word pair . For ex - ample , in the sentence â€œyou are a crying pig . â€ , the typed dependency amod ( pig , crying ) means that â€œcryingâ€ is an adjectival modiï¬er of an noun phrase containing â€œpigâ€ . A typed dependency may represent the dependent relations between two syntactic elements , not limited to words only . The typed dependencies in a sentence can be represented as a graph . For example , Figure 2 shows the typed depen - dency relations for the same sentence shown in Figure 1 . We explain the relations appeared in Figure 2 from left to right : the nominal subject relation , nsubj ( martin , it ) , means that â€œitâ€ is the syntactic subject of the clause ( same is nsubj ( pig , you ) ) ; the copula relation , cop ( martin , is ) , means that â€œmartinâ€ is the complement of verb â€œisâ€ ( same is cop ( pig , are ) ) ; the noun compound modiï¬er , nn ( martin , aston ) , means that the noun â€œastonâ€ serves to modify the head noun â€œmar - tinâ€ ; the determiner , det ( pig , a ) , means that â€œtheâ€ is a de - terminer of â€œpigâ€ ; the adjectival modiï¬er , amod ( pig , crying ) , means that â€œcryingâ€ serves as adjectival modiï¬er of â€œpigâ€ ; and the conjunct , conj and ( martin , pig ) , means that the coordinating conjunction â€œandâ€ is used to connect two ele - ments with head â€œmartinâ€ and â€œpigâ€ , respectively . 4 . 1 . 3 Relation Tree ( RelTree ) Both Part - of - Speech and typed dependency relations are utilized in the second step estimation . The parse tree shows the sentence syntactic organization and typed dependency relations provide semantic information among words . To combine both information , we propose a new data structure called RelTree . In a RelTree , as shown in Figure 3 , the leaf nodes are words in the sentence . And the non - leaf node represents either a phrase or a clause inside the sentence . In each non - leaf node , we associate the set of typed dependency relations on the words within its subtree . Each node only contains the typed dependency relations which have not appeared in its subtree nodes . The RelTree data structure is proposed only for the con - venience of oï¬€ensiveness estimation in the next step . Algo - rithm 2 shows the algorithm for RelTree construction . With the parse tree ğ‘ƒğ‘‡ğ‘Ÿğ‘’ğ‘’ given , the computational complexity of algorithm ğ¶ğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘’ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ relies on the post - order traversal and the search in TDset . As the number of relations never exceeds ğ‘ ( ğ‘ âˆ’ 1 ) / 2 , where ğ‘ is the number of words in the sentence , the computational complexity is ğ‘‚ ( ğ‘ 3 ) . The com - putational complexity itself is acceptable . Indeed , there are a lot of ways to improve the eï¬ƒciency in the implementation of this algorithm . 4 . 2 Step Two : Bottom - up Estimation Figure 3 : A RelTree combining the parse tree and typed dependency relations input : a parse tree ğ‘ƒğ‘‡ğ‘Ÿğ‘’ğ‘’ , a set of typed dependency relations ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ output : a RelTree ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ â† ğ‘ƒğ‘‡ğ‘Ÿğ‘’ğ‘’ ; 1 Remove all word nodes in ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ; 2 Traverse ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ in ğ‘ğ‘œğ‘ ğ‘¡ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ foreach node ğ‘› 3 visited do if ğ‘› is a leaf node then 4 n . wordset â† { n } ; / * create word nodes * / 5 end 6 if ğ‘› is not a leaf node then 7 n . wordset â† âˆ… ; 8 foreach direct child node ğ‘ ğ‘– do 9 ğ‘› . ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘ ğ‘’ğ‘¡ â† ğ‘› . ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘ ğ‘’ğ‘¡ âˆª ğ‘ ğ‘– . ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘ ğ‘’ğ‘¡ ; 10 ğ‘› . ğ‘Ÿğ‘’ğ‘™ â† âˆ… ; 11 foreach relation ğ‘‡ ğ‘– ( ğº ğ‘– , ğ· ğ‘– ) in ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ do 12 if ğº ğ‘– âˆˆ ğ‘› . ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘ ğ‘’ğ‘¡ and 13 ğ· ğ‘– âˆˆ ğ‘› . ğ‘¤ğ‘œğ‘Ÿğ‘‘ğ‘ ğ‘’ğ‘¡ then ğ‘› . ğ‘Ÿğ‘’ğ‘™ â† ğ‘› . ğ‘Ÿğ‘’ğ‘™ âˆª ğ‘‡ ğ‘– ( ğº ğ‘– , ğ· ğ‘– ) ; 14 ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ â† ğ‘‡ğ·ğ‘ ğ‘’ğ‘¡ âˆ’ ğ‘‡ ğ‘– ( ğº ğ‘– , ğ· ğ‘– ) ; 15 end 16 end 17 end 18 end 19 end 20 Return ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ; 21 Algorithm 2 : create a RelTree using the parse tree and typed dependency relations In the second step , we ï¬rst use the oï¬€ensive lexicon to identify oï¬€ensive words in the sentence . The leaf node with an oï¬€ensive word will be labeled as â€œremovableâ€ . Starting from leaf nodes , we perform bottom - up estimation through a postorder traversal on the RelTree . For each non - leaf node in the RelTree , we estimate whether it should be removed based on ( 1 ) the associated typed de - pendency relations and ( 2 ) its child nodes within its subtree . If a non - leaf node is estimated to be â€œremovableâ€ , all its de - scendants , including words , within its subtree will also be labeled as â€œremovableâ€ . The meaning of â€œremovableâ€ to a non - leaf node is that all words , phrases , or even clauses within its subtree have been determined to be removed at the end of ï¬ltering . The estimation process includes two steps . We ï¬rst estimate based on typed dependency rela - tions , and then apply a set of heuristic rules as complements . 4 . 2 . 1 Estimation with Typed Dependency Relations Consider a non - leaf node ğ‘› in a RelTree with a set ğ‘› . ğ‘Ÿğ‘’ğ‘™ of typed dependency relations . Each relation describes a se - mantic connection between a ğ‘”ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘›ğ‘œğ‘Ÿ word and a ğ‘‘ğ‘’ğ‘ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘›ğ‘¡ word . Both words are leaf nodes in the subtree rooted at ğ‘› . ğ‘› . ğ‘Ÿğ‘’ğ‘™ could be empty when ğ‘› only has one child node . For each typed dependency relation in ğ‘› . ğ‘Ÿğ‘’ğ‘™ , we study its semantic information and map it to an estimation function we deï¬ned . There are totally 55 typed dependency relations deï¬ned in [ 6 ] , and we map each of them to one estimation function . We show all the mappings in Table 2 . These estimation functions and mapping are created fol - lowing the Modiï¬cation Relation and Pattern Integrity rules . Take the Direct Object ( dobj ) relation for example . In [ 6 ] , the dobj ( G , D ) relation is deï¬ned as : the direct object of a verb phrase , containing governor word ğº , is the noun phrase , containing dependent word ğ· . For example , in a relation ğ‘‘ğ‘œğ‘ğ‘— ( ğ‘¤ğ‘–ğ‘› , ğ‘šğ‘ğ‘¡ğ‘â„ ) , â€œwinâ€ is the governor word and â€œmatchâ€ is the dependent word . According to Pat - tern Integrity rule , we know that â€œSubject - Verb - Objectâ€ is a basic pattern . Therefore , if either the phrase with ğº or phrase with ğ· will be removed because of oï¬€ensiveness , both phrases should be removed together . To formalize , we deï¬ne an estimation function H ( T ) = H ( P ( G ) ) OR H ( P ( D ) ) and map relation ğ‘‘ğ‘œğ‘ğ‘— ( ğº , ğ· ) to it . We use symbol ğ¶ ( ğº ) and ğ‘ƒ ( ğº ) to denote the clause and phrase containing word G as head , respectively . In this esti - mation function , ğ» ( ğ‘‡ ) is the label to be assigned to relation ğ‘‡ and ğ» ( ğ‘ƒ ( ğº ) ) is the label with phrase node containing ğº in the RelTree . For example , in Figure 3 , ğ‘ƒ ( ğ‘ğ‘ ğ‘¡ğ‘œğ‘› ) is the ğ‘ğ‘ƒ node of â€œaston martinâ€ , and ğ¶ ( ğ‘ğ‘ ğ‘¡ğ‘œğ‘› ) is the clause ( i . e . ğ‘† ) node of â€œit is aston martin . â€ . The relation ğ‘‘ğ‘œğ‘ğ‘— will be labeled as â€œremovableâ€ if at least one of these two phrases are labeled as â€œremovableâ€ . Using the estimation function , we generate a label for ev - ery relation associated with node ğ‘› and then for the node itself . If a relation ğ‘‡ ( ğº , ğ· ) of node ğ‘› is estimated and la - beled as â€œremovableâ€ , the two child nodes of ğ‘› , containing word ğº and word ğ· , will be labeled as â€œremovableâ€ . If all relations in ğ‘› . ğ‘Ÿğ‘’ğ‘™ are labeled as â€œremovableâ€ , the node ğ‘› as well as all its descendants , will be labeled as â€œremovableâ€ . 4 . 2 . 2 Estimation with Heuristic Rules Through experiments on YouTube dataset , we realize that ï¬ltering with typed dependency relations may not be enough . Heuristic rules must be applied as complement after typed dependency relation estimation . Applying heuristic rules is necessary mainly because of two reasons . First of all , the typed dependency relation contains some syntactic informa - tion but limited . For example , the possessive ending ( i . e . ğ‘ƒğ‘‚ğ‘† ) tag , which is a quite popular Part - of - Speech tag , is ignored during the typed dependency tagging . Secondly , not all relations between syntactic elements in a sentence can be classiï¬ed into one of typed dependency relations deï¬ned in [ 6 ] . For those uncertain relations , [ 6 ] de - ï¬nes a generic grammatical relation , named ğ‘‘ğ‘’ğ‘ . To prevent confusion to ï¬lter , in the Table 2 , we include ğ‘‘ğ‘’ğ‘ into the Rule H ( T ) = H ( G ) AND H ( D ) which means either ğº or ğ· is labeled removable will not aï¬€ect each other and the label of ğ‘‡ . Because ğ‘‘ğ‘’ğ‘ relation stands for uncertain relation , we have to rely on Part - of - Speech tags in the RelTree for our ï¬ltering . We present several examples of heuristic rules applied in Figure 4 : Estimate a RelTree in a bottom - up man - ner semantic ï¬ltering in Table 3 . Take the ğ‘ğ‘œğ‘›ğ‘— tag node rule as an example . The conjunct relation ( ğ‘ğ‘œğ‘›ğ‘— ) is a type of relation between two syntactic elements connected by a co - ordinating conjunction , such as â€œandâ€ . The parameters of ğ‘ğ‘œğ‘›ğ‘— do not include the coordinating conjunction . However , explicitly , the coordinating conjunction sits between the two parameters of ğ‘ğ‘œğ‘›ğ‘— . If one side is determined removable , the coordinating conjunction should be removed as well . For ex - ample , in the sentence â€œI like A and Bâ€ , if either ğ´ or ğµ is removed , the coordinating conjunction â€œ ğ‘ğ‘›ğ‘‘ â€ should also be removed . 4 . 2 . 3 Estimation Algorithm To estimate and assign labels for all nodes in a RelTree , we perform the estimation also in a bottom - up manner . Fig - ure 4 shows an example estimation process . The number in the circle represents the order of estimation for each node in the RelTree . The dashed nodes are estimated as â€œremov - ableâ€ . For example , the clause node with nsubj ( pig , you ) is estimated as â€œremovableâ€ according to the estimation . Therefore , its two child nodes containing â€œpigâ€ and â€œyouâ€ respectively are both labeled as â€œremovableâ€ . Moreover , the word â€œandâ€ is removable according to the heuristic rule ( i . e . conj tag node rule ) , in order to keep the ï¬ltering transparent to readers . Finally , inoï¬€ensive words , â€œyouâ€ , â€œareâ€ , and â€œaâ€ , are removed with two oï¬€ensive words , â€œcryingâ€ and â€œpigâ€ , in the ï¬ltering . According to Algorithm 2 , each typed dependency rela - tion will appear exactly once in the RelTree . No relation will be checked repeatedly in the estimation . The cleaned sentence after ï¬ltering in this example will be â€œit is aston martin . â€ . As we can see , the result satisï¬es the requirement of our proposed ï¬ltering philosophy . Only the oï¬€ensive part , â€œyou are a crying pigâ€ , is removed . The reader can still get the inoï¬€ensive information . The detailed algorithm for esti - mation process is presented in Algorithm 3 . 5 . APPLICATIONS The proposed semantic ï¬ltering approach can be applied in real - world applications . In this section , we present two types of applications for demonstration . One application is at administrator side where the semantic ï¬ltering approach can help administrators to automatically remove oï¬€ensive language in text messages submitted by users . The other application is at browser side where we implement the se - mantic ï¬lter as a Firefox extension for parental control . Table 2 : The mapping between typed dependency relations and estimation functions . ( please see Section 4 . 2 . 1 for the deï¬nition of notations ) Index Estimation Function Typed Dependency Relation 1 H ( T ) = H ( P ( G ) ) cop , expl , measure , partmod , poss , possessive , preconj , prep / prepc , purpcl , quantmod , rcmod , ref , tmod ; 2 H ( T ) = H ( P ( D ) ) pcomp , pobj , predet ; 3 H ( T ) = H ( C ( G ) ) complm , mark , rel ; 4 H ( T ) = H ( P ( G ) ) OR H ( C ( D ) ) xcomp ; 5 H ( T ) = H ( C ( G ) ) OR H ( P ( D ) ) xsubj ; 6 H ( T ) = H ( G ) OR H ( P ( D ) ) nsubj , nsubjpass ; 7 H ( T ) = H ( G ) AND H ( D ) conj , nn , number , dep ; 8 H ( T ) = H ( G ) aomp , advcl , advmod , agent , amod , appos , attr , aux , auxpass , cc , ccomp , det , neg , num , parataxis , punct ; 9 H ( T ) = H ( G ) OR H ( C ( D ) ) csubj , csubjpass ; 10 H ( T ) = H ( P ( G ) ) OR H ( P ( D ) ) abbrev , dobj , infmod , iobj , prt ; Table 3 : Examples of heuristic rules applied in the proposed semantic ï¬ltering Index Name Rules 1 POS tag node rule IF { its previous noun is removable } THEN { POS tag node will be removable } 2 conj tag node rule IF { both neighbor nodes are removable } THEN { conjunction node will be removable } 3 ADVP - VP rule IF { the current non - leaf node has only two child nodes ; one is ADVP node and the other is VP node } THEN { IF { ADVP node is removable } THEN { VP node will not be aï¬€ected } ; IF { VP node is removable } THEN { ADVP node will also be removable } ; } input : a RelTree RelTree , a blacklist of oï¬€ensive words ğµğ‘™ğ‘ğ‘ğ‘˜ğ‘™ğ‘–ğ‘ ğ‘¡ , output : a labeled RelTree LebelRelTree ğ¿ğ‘’ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ â† ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ; 1 Label all leaf nodes with oï¬€ensive words by 2 â€œremovableâ€ in ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ; Traverse ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ in ğ‘ğ‘œğ‘ ğ‘¡ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ foreach node 3 ğ‘› visited do if ğ‘› is a leaf node then 4 ignore ; / * already labeled * / 5 end 6 if ğ‘› is not a leaf node then 7 if ğ‘› only has one child node then 8 ğ‘› . ğ‘™ğ‘ğ‘ğ‘’ğ‘™ â† ğ‘› . ğ‘â„ğ‘–ğ‘™ğ‘‘ . ğ‘™ğ‘ğ‘ğ‘’ğ‘™ ; 9 end 10 if ğ‘› has more than one child node then 11 Estimate the label for ğ‘› by its associated 12 labels , using proposed estimation function and heuristic rules ; end 13 end 14 end 15 Return ğ¿ğ‘ğ‘ğ‘’ğ‘™ğ‘…ğ‘’ğ‘™ğ‘‡ğ‘Ÿğ‘’ğ‘’ ; 16 Algorithm 3 : estimate nodes in RelTree 5 . 1 Semantic Filter for Administrators in On - line Communities When a user wants to post a text message , he has to ï¬rst send the message to the server and let the server post this message so that other users can see it . Therefore , one im - portant place to eliminate oï¬€ensive language in online com - munities is at the server of online communities . Many online communities have deployed sensor tools , such as swear ï¬l - ter in the World of Warcraft , to detect and remove sensitive words , including oï¬€ensive words . However , as we shown in Section 2 , ï¬ltering without considering semantics of text message turns out to be ineï¬€ective to ï¬ght against oï¬€ensive language . To a server side ï¬ltering tool , three metrics are most im - portant to measure its performance : eï¬€ectiveness , accuracy , and speed . For eï¬€ectiveness , we already show the advantage of applying semantic ï¬ltering in Section 2 . For accuracy and speed , we have implemented an oï¬€ensive language ï¬l - ter in Java using the proposed semantic ï¬ltering approach . Stanford parser [ 2 ] is adapted to perform the Part - of - Speech tagging and generate the typed dependency relations . In the following subsections , we ï¬rst present the details about our collected YouTube dataset , and then present the results of our experiments . 5 . 1 . 1 YouTube Dataset YouTube is a leading video sharing website in the world . Videos on YouTube websites are classiï¬ed into 15 categories , such as Comedy , Entertainment , and Music . For each video webpage , contents contributed by users include the video for viewing , video title , video author ID , video description , and a list of text comments . Each text comment is associated with a user ID and a piece of text content . User ID identiï¬es the author who generates this comment , and text content contains the body of userâ€™s opinion . Our ï¬ltering focuses on the text content of text comments . To build the dataset , we collected text comments from video webpages on YouTube website in the days between September 27 and September 29 , 2009 . For each of 15 cate - gories , we collected the top 20 â€œmost discussedâ€ video web - pages ranked in â€œthis weekâ€ . For each webpage , we collected the ï¬rst 40 text comments . The dataset contains 11670 text comments in total . For each text comment , we did manual ï¬ltering for each sentence in the comment . Specif - ically , the manual ï¬ltering process includes three steps . In the ï¬rst step , we read the comment and chunk it into sen - tences . Then , we identiï¬ed the oï¬€ensive words appearing in the sentence . Finally , for each oï¬€ensive word , we marked the least set of words that should be removed together with it in order to eliminate the oï¬€ensive information . We as - sign the collected YouTube dataset to ï¬ve students for sep - arate manual ï¬ltering . According to the results , 1739 text comments contain oï¬€ensive words . Within these comments , 2063 sentences contain oï¬€ensive words and the total number of unique oï¬€ensive words appeared is 368 . During the manual ï¬ltering , one key question is how to identify oï¬€ensive words . The same as in [ 3 ] , the knowl - edge about oï¬€ensive language in our case is represented by a lexicon of oï¬€ensive words . All words in this lexicon have been determined to be oï¬€ensive and should be prevented from being seen by readers . To estimate a word , our judg - ment is based on a list of oï¬€ensive words provided by [ 1 ] and the wordâ€™s meaning listed in the Urban Dictionary website 7 . All oï¬€ensive words we detected are determined as oï¬€ensive words by these two . 5 . 1 . 2 Accuracy The results of both semantic ï¬ltering and manual ï¬ltering on a sentence will be in one of three types . âˆ™ â€œCleanâ€ : if there is no oï¬€ensive word in the sentence ; âˆ™ â€œSemantic Removingâ€ : there exist oï¬€ensive words in the sentence and some inoï¬€ensive words have to be removed together with those oï¬€ensive words ; âˆ™ â€œKeyword Removing onlyâ€ : there exist oï¬€ensive words in the sentence and removing those oï¬€ensive words would be enough for the ï¬ltering . To compare and measure the accuracy , we apply our pro - posed semantic ï¬ltering approach to process all comments collected in the YouTube dataset , and compare the result with the manual ï¬ltering result on the dataset . We assume that the manual ï¬ltering result represents the optimal ï¬lter - ing result we want to achieve . To understand the diï¬€erence between the ï¬ltering result by human and by our ï¬lter , we manually compare the results of both ï¬ltering , sentence by sentence . The comparison outputs three types of results : âˆ™ if words removed by semantic ï¬ltering are exactly the same as those chosen by manual ï¬ltering , we call it â€œ Correct Filtering â€ ; âˆ™ if more words are removed by semantic ï¬ltering than manual ï¬ltering , we call it â€œ Excessive Filtering â€ ; âˆ™ if fewer words are removed by semantic ï¬ltering than manual ï¬ltering , we call it â€œ Insuï¬ƒcient Filtering â€ ; Excessive ï¬ltering means that there are unnecessary words , carrying inoï¬€ensive information , being falsely removed . In - suï¬ƒcient ï¬ltering means that ï¬ltering is not thorough . According to our comparison , with 2063 sentences con - taining oï¬€ensive words , the number of insuï¬ƒcient ï¬ltering is 58 ( i . e . 2 . 81 % ) , and the number of excessive ï¬ltering is 129 ( i . e . 6 . 25 % ) . To sum up , the overall ratios of accuracy of our implemented semantic ï¬lter is 90 . 94 % . Through reviewing the results , three reasons are responsi - ble for the inaccuracy , which are Informal English Writing , Incorrect Part - of - Speech tagging , and Incorrect Typed De - pendency Analysis . 7 Urban Dictionary , at http : / / www . urbandictionary . com / Informal English Writing is a character of language in the online community . People would like to write text comments on a casual or conversational tone , even with a lot of spelling errors . Luckily , our goal is not to understand the meaning of sentences but the relations among words . In the experiments , we apply the unlexicalized PCFG parser [ 7 ] proposed by Stanford NLP group and our results show some resistance to certain informal writings . For example , for word misuse case , in the Part - of - Speech tags generated from sentence â€œI like to apple you . â€ , â€œappleâ€ will be correctly tagged with as a verb . Another example , for misspelling case , the sentence of â€œI like to eat apple . â€ and â€œI like to ea app . â€ outputs the same Part - of - Speech tagging during our experiments . This is an important reason why we can still achieve such a high overall accuracy mentioned above . However , piling up several sentences casually without us - ing any delimiters , such as â€œ . â€ , â€œ ! â€ , â€œ ? â€ , will make it diï¬ƒcult for the parser to generate correct Part - of - Speech tags and typed dependency relations . Moreover , misspelling of cer - tain sensitive words will confuse the parser ( even human ) . For example , in some text comment , â€œyourâ€ is used to stand for â€œyouâ€™reâ€ . There is no way for us to tell that . Incorrect Part - of - Speech tagging contributes to 69 . 5 % of incorrect ï¬ltering results . The major reason of incorrect tagging is caused by false sentence segmentation . In our experiments , we use the default sentence splitter provided by Stanford parser . Because typed dependency relations are generated based on the result of Part - of - Speech tagging , the incorrect tagging will certainly lead to incorrect ï¬lter - ing result . For example , many incorrect tagging cases are caused by arbitrarily inserting phrases in the pattern of â€œyou ABCD â€ in a sentence . â€œ ABCD â€ usually is a noun phrase or adjective phrase . Because â€œyouâ€ is a sensitive words in tagging , this can easily confuse the Stanford Parser . Typed dependency analysis could be incorrect , even based on correct Part - of - Speech tagging . Especially , when the relation is uncertain , Stanford parser tends to assign a â€œdepâ€ relation which basically means every thing could be possible . In some cases , we can apply heuristic rules mentioned in Section 4 . 2 . 2 as complement . 5 . 1 . 3 Speed The processing speed on masses of text messages is im - portant for ï¬ltering oï¬€ensive language in real online commu - nities . For our proposed ï¬lter , the time consuming part of ï¬ltering is the Part - of - Speech tagging and typed dependency relation generation parts . To measure the time eï¬ƒciency of the implemented ï¬lter , we measure the speed in two cases : one is a normal case and the other is a high - overload case . In the normal case , we use the ï¬lter to process all text com - ments in the collected YouTube dataset . These comments contain both oï¬€ensive comments and inoï¬€ensive comments . In the overload case , we apply the ï¬lter on oï¬€ensive com - ments only . As the dataset is stored in ï¬les on local disk and each webpage is stored in a separate ï¬le , the measured processing time includes that for ï¬le I / O operations . The time cost in each case for processing the same number of comments is listed in Figure 5 . In both cases , the time cost increases almost linearly . In the high - overload case , the time cost is about 231 . 3 ğ‘šğ‘ ğ‘’ğ‘ per comment . In the normal case , the time cost increases much slower because a lot of comments processed are inoï¬€ensive comments . For those inoï¬€ensive comments , no grammatical analysis is needed . 0 300 600 900 1200 1500 1739 0 0 . 5 1 1 . 5 2 2 . 5 3 3 . 5 4x 10 5 Number of Comment Processed T i m e C o s t ( i n m illi s ec o nd ) High OverLoad Case Normal Case Figure 5 : Measurement of Filtering Time Cost in Two Cases Therefore , the average speed is much faster , about 38 . 6 ğ‘šğ‘ ğ‘’ğ‘ per comment . 5 . 2 Firefox Extension for Parental Control We also implemented the semantic ï¬lter as a Firefox ex - tension which can be embedded into Firefox browser to ï¬lter oï¬€ensive language in OSN websites . Brieï¬‚y , our extension consists of three modules , which are Pre - processor , Text An - alyzer , and Post - processor . The Pre - processor module is de - signed for content extraction . After receiving original web - page ( e . g . , a HTML ï¬le ) from a website , it decomposes the content of a webpage and extract its text content posted by community members . The Text Analyzer module applies the proposed semantic ï¬ltering approach to ï¬lter the oï¬€en - sive language in the text content ( Here we are interested in user messages ) . And the Post - processor module modiï¬es the original webpage based on the results of ï¬ltering before showing the webpage in the browser . The biggest challenge to implement the extension is to understand the structure of a webpage , because we are only interested in text contents that are contributed by members of online communities . Admittedly , to segment and label the text content inside HTML elements of a random webpage on Internet is still an open problem . Luckily , OSN websites usually have neat and ï¬xed template for their webpages , such as YouTube , MySpace , and Facebook . All webpages in an OSN website share a limited number of templates . Users have no control over the structure of webpages . For example , if a user wants to post a comment on his friendâ€™s blog , he has to ï¬rst send the text to the website and the website will update his friendâ€™s blog with submitted texts . Based on this observation , we employ the Document Ob - ject Model ( DOM ) to extract the text content we are in - terested in . Each HTML webpage maps to a DOM tree where tags are internal nodes and the actual text , images or hyperlinks are the leaf nodes . For example , Figure 6 shows a comment with its corresponding fragments in the DOM tree . As we can see from Figure 6 , in all webpages on YouTube website , comment body is within the subtree with the â€œwatch - comment - bodyâ€ tag . Situation is the same in other OSN websites . So far , we have considered extracting templates from websites , such as YouTube , Google Search , MySpace blog , Facebook , and Twitter . For example , every user status update on Twitterâ€™s post wall is within a node tagged by â€œentry - contentâ€ . Figure 6 : A YouTube comment and its correspond - ing DOM tree fragment Figure 7 : Comparison between YouTube ï¬lter and our semantic ï¬lter with partial oï¬€ensive sentences To demonstrate the eï¬€ectiveness of semantic ï¬ltering with Firefox extension , we show a comparison of ï¬ltered results between our Firefox extension and YouTubeâ€™s default ï¬lter ( i . e . the â€œHide objectionable wordsâ€ function ) , in Figures 7 and 8 . For better viewing , we put red lines at places with diï¬€erences . As we can see from this comparison , the reader can easily guess the word ï¬ltered by YouTubeâ€™s default ï¬l - ter . With proposed semantic ï¬ltering approach , we provide a â€œtransparentâ€ ï¬ltering . In these two cases , we are able to thoroughly remove the oï¬€ensive parts while keeping the inoï¬€ensive part as much as possible . We have also evaluated the speed of ï¬ltering ordinary video webpages on YouTube websites . During the evalua - tion , we select top 50 most â€œpopularâ€ videos in â€œThis Weekâ€ and records the time cost for processing each webpage . Each webpage contains 10 user comments . According to the ex - periments , the minimum time cost for processing one web - page is 43 ğ‘šğ‘ ğ‘’ğ‘ and the maximum is 2839 ğ‘šğ‘ ğ‘’ğ‘ . The dif - ference of time cost depends on the amount of text as well as the oï¬€ensive words in the webpage . The mean of pro - cessing time is about 752 ğ‘šğ‘ ğ‘’ğ‘ , 50 % webpages requires less than 431 ğ‘šğ‘ ğ‘’ğ‘ ï¬ltering time , and 75 % webpages requires Figure 8 : Comparison between YouTube ï¬lter and our semantic ï¬lter with absolute oï¬€ensive sentences less than 1211 ğ‘šğ‘ ğ‘’ğ‘ . 6 . LIMITATIONS AND COUNTERMEASURES We now discuss ( 1 ) several limitations associated with our semantic ï¬ltering approach as well as a few possible ways oï¬€ender may evade it , and ( 2 ) possible countermea - sures against those evasions . 6 . 1 Offensive Language Detection In this paper , we made an assumption that all oï¬€en - sive opinions are expressed by oï¬€ensive words and we have a comprehensive oï¬€ensive lexicon containing all oï¬€ensive words . Based on this assumption , we adopt a simple word matching approach to identify oï¬€ensive words in the sen - tence to be ï¬ltered . This assumption is made because the fo - cus of our paper is about oï¬€ensive language ï¬ltering instead of detection . Since our ï¬ltering approach depends on detec - tion of oï¬€ensive language , the ï¬ltering might fail if oï¬€ensive language cannot be detected before the ï¬ltering process . To avoid ï¬ltering , oï¬€ender may try to evade the oï¬€ensive lan - guage detection mechanisms . For detection , there are many literatures discussing about detecting oï¬€ensive language in sentence level [ 3 ] or message level [ 10 ] . For oï¬€ensive lexi - con generation , [ 9 ] presents a study . We believe oï¬€ensive language detection a very challenging problem worthy of separate treatment . 6 . 2 Nature Language Process The language used in online communities has its own char - acteristics , compared to the language used in Journal and newspaper . When applying NLP techniques , people would worry about the accuracy because of such characteristics as casual and informal English writing style . As we mentioned in Section 5 . 1 . 2 , we did notice the inaccuracy brought by inaccurate text analysis . On the other hand , we discovered that language in online communities also has many charac - ters suitable for text analysis . First of all , compared with articles or journals , most text messages posted are usually very short . A typical example is the ğ‘šğ‘–ğ‘ğ‘Ÿğ‘œ âˆ’ ğ‘ğ‘™ğ‘œğ‘”ğ‘”ğ‘–ğ‘›ğ‘” ser - vice provided by Twitter 8 which allows users to send brief text updates ( less than 140 characters ) . Secondly , most text messages use spoken English which has very simple and neat grammatical structures , making it easy to achieve high accuracy in text analysis . This phe - nomenon is also called self - identity in social psychology . It states that people actually like to make comments as simple and clear as possible so that readers can understand his / her opinion easily . In our case , self - identity makes the oï¬€ensive comment easier to ï¬lter . If the comment is hard to analyze by a parser , it will probably cause diï¬ƒculty to its human readers as well . 6 . 3 Changes to User Message One concern about the proposed semantic ï¬ltering is the change made to the original text message . Admittedly , re - moving words from original message may cause information loss . Consider the information carried by original user mes - sage as ğ¼ = ğ¼ ğ‘–ğ‘›ğ‘œğ‘“ğ‘“ + ğ¼ ğ‘œğ‘“ğ‘“ . During the ï¬ltering , oï¬€ensive information ğ¼ ğ‘œğ‘“ğ‘“ is okay to be removed , but the inoï¬€ensive information ğ¼ ğ‘–ğ‘›ğ‘œğ‘“ğ‘“ should not be deleted or altered . 8 Twitter , at http : / / twitter . com In semantic ï¬ltering , we are fully aware of the impact of ï¬ltering . As stated in the proposed â€œï¬ltering instead of blockingâ€ philosophy , the semantic ï¬ltering only removes the smallest semantic part which containing oï¬€ensive words in the sentence . Meanwhile , the readability of ï¬ltered sentence will be kept , making ï¬ltering transparent to user . Taking manual ï¬ltering as the standard , we demonstrate the ability to achieving close results by comparison in experiments . 7 . CONCLUSION Oï¬€ensive language is a serious problem facing the online community . In this paper , we proposed a semantic ï¬ltering technique based on the grammatical relations of words in a sentence so that the rest of the ï¬ltered sentence is readable and the existence of oï¬€ensive words in the original sentence is hard to notice . We tested the eï¬€ectiveness of our approach with a large dataset and the results show that our techniques are very eï¬€ective and accurate with little process overhead . Our future work includes looking at the issues described in the discussion section . Moreover , as the most time - consuming part of semantic ï¬ltering is the sentence parsing process , we will examine other light - weighted NLP techniques to speed up sentence parsing . Last but not the lease , we also plan to extend our ï¬ltering approach to support other languages such as Chinese and French . 8 . REFERENCES [ 1 ] Bad word list and swear ï¬lter . Available : http : / / www . noswearing . com / list . php . [ 2 ] The stanford parser : A statistical parser . Available : http : / / nlp . stanford . edu / software / lex - parser . shtml . [ 3 ] M . K . Altaf Mahmud , Kazi Zubair Ahmed . Detecting ï¬‚ames and insults in text . In Proceedings of 6th International Conference on Natural Language Processing , 2008 . [ 4 ] A . Bies , M . Ferguson , K . Katz , R . Macintyre , M . Contributors , V . Tredinnick , G . Kim , M . A . Marcinkiewicz , and B . Schasberger . Bracketing Guidelines for Treebank II Style Penn Treebank Project , 1995 . [ 5 ] J . Cheng . Report : 80 percent of blogs contain â€oï¬€ensiveâ€ content . ars technica , 2007 . [ 6 ] M . - C . de Marneï¬€e and C . D . Manning . Stanford typed dependencies manual , 2008 . [ 7 ] D . Klein and C . D . Manning . Accurate unlexicalized parsing . In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics , 2003 . [ 8 ] H . Rheingold . The virtual community : Homesteading on the electronic frontier . Reading , Massachusetts : Addison - Wesley Publishing Company , 1993 . [ 9 ] J . Sjbergh and K . Araki . A multi - lingual dictionary of dirty words . In Proceedings of the 6th International Conference on Language Resources and Evaluation , 2008 . [ 10 ] E . Spertus . Smokey : Automatic recognition of hostile messages . In Proceedings of the 9th Conference on Innovative Application of AI , 1997 .