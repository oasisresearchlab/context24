A Real - Time Semantic Model for Relevance and Novelty Detection from Group Messages David Fisher Dept . of CS Hofstra University Hempstead , USA dfisher1 @ pride . hofstra . edu Rishabh Choudhary , Member , IEEE Dept . of EECS University of Cincinnati Cincinnati , USA choudhrr @ mail . uc . edu Omar Alsayed , Member , IEEE Dept . of EECS University of Cincinnati Cincinnati , USA alsayeoy @ mail . uc . edu Simona Doboli , Member , IEEE Dept . of CS Hofstra University Hempstead , USA simona . doboli @ hofstra . edu Ali A . Minai , Senior Member , IEEE Dept . of EECS University of Cincinnati Cincinnati , USA minaiaa @ ucmail . uc . edu Abstract —Group brainstorming is a common method to gener - ate ideas for open - ended , complex problems . Groups are known to generate fewer and less novel ideas than an equal number of individuals working separately . One cause of this is the tendency of groups to converge prematurely to a small number of ideas and neglect others . It is known that adding structure to brainstorming in the form of external hints tends to increase group performance . Our goal is to develop a cognitively - inspired feedback system that evaluates ideas in real - time and decides what kind of intervention to make in a group brainstorming session , e . g . , flag an idea for further exploration , move the conversation in a new direction , etc . In this work , we develop a computational model for detecting relevant , novel , and less elaborated ideas from group messages in real - time . The flagged ideas can be fed back into the group discussion for further elaboration . We explore multiple approaches for relevance detection that do not require out - of - domain data : a probabilistic language model , a zero - shot classifier , and a one - class support vector machine . We compute two types of novelty , ( 1 ) absolute novelty with respect to domain knowledge ; and ( 2 ) relative novelty with respect to previously seen ideas within the group . For absolute novelty , we explore methods to represent the domain semantic knowledge in a compressed way for faster computation . We tested our model on a dataset of ideas generated by over 50 groups . It was found that our probabilistic relevance method is the most accurate and that either topic cluster centers or common domain topics offer similar novelty results compared to full domain representation . Index Terms —Novelty , Relevance , Semantic Space , Text Em - bedding , Natural Language Processing , Computational Creativity I . I NTRODUCTION Group ideation is a method employed often for generating new solutions to complex or open - ended problems . Research on group creativity and brainstorming shows that the quantity and creativity of a group output is lower than that of an equal number of individuals thinking on their own [ 1 ] , [ 2 ] . Extensive research has revealed both social and cognitive causes of the group - individual gap [ 1 ] . Individuals generate fewer ideas in groups due to social factors such as fear of judgement , lack Funded by Army Research Office ( No . W911NF - 20 - 1 - 0213 ) . of motivation , and social loafing , or due to cognitive factors such as production blocking due to others’ ideas or premature convergence to a small set of previously uttered ideas [ 1 ] . While most negative social influences can be overcome by using electronic brainstorming , cognitive influences are harder to minimize . Experiments have shown that adding ex - ternal structure and directions can help . For example , external hints requiring participants to focus on different regions of the solution space limit rapid group convergence [ 3 ] , and repeatedly cycling through phases of individual and group ideation eases the effect of production blocking and allows ideas expressed in a group to be further elaborated and com - bined with somebody else’s ideas in the individual phase [ 4 ] . Currently , these interventions are fixed and externally imposed in experimental settings , instead of being dynamically and adaptively identified and introduced in the group discussion as needed . Our research goal is to enhance group ideation and creativity by automatically identifying the appropriate type of feedback and injecting it during group discussions in real - time . However , doing so requires an automatic way to evaluate the value of ideas that have already been generated by the group . In this paper , the focus is on detecting and selecting high - quality , novel , and relevant ideas expressed in a group electronic discussion in a real - time manner . These ideas are meant to be cycled back for further discussion by the group . Recent experimental results by our group [ 4 ] show , on the one hand , that groups which elaborate their ideas more produce a final solution with higher novelty , but on the other , that groups typically neglect a large number of novel ideas , which results in premature convergence of the group onto a small set of 3 to 5 ideas . Thus , the aim of this work is to develop a cognitively - inspired computational model that receives a stream of a groups’ ideas , and flags high - quality ideas . These are defined as novel , relevant , and not fully elaborated . We have recently proposed a cognitively - inspired model to assess novelty from a set of short - text ideas [ 5 ] . The model 978 - 1 - 7281 - 8671 - 9 / 22 / $ 31 . 00 ©2022 IEEE 2022 I n t e r n a t i o n a l J o i n t C o n f e r e n c e o n N e u r a l N e t w o r k s ( I J C NN ) | 978 - 1 - 7281 - 8671 - 9 / 22 / $ 31 . 00 © 2022 I EEE | D O I : 10 . 1109 / I J C NN 55064 . 2022 . 9892268 emulates the process of novelty rating by experts , who first read all ideas and assign a novelty score to each based on its perceived uniqueness in the dataset . The method is inspired by experimental results and computational models of recognition memory and decision making [ 6 ] , [ 7 ] . Recognition of similar ideas is modeled as an accumulator - based decision making process by which both perceptual ( e . g . , words ) and semantic content of an idea are assessed for similarity with past ideas . We have also explored different methods to encode the se - mantics of an idea in the domain space [ 8 ] . The best semantic space was obtained using Universal Sentence Encoder ( USE ) [ 9 ] . Overall , the computational model for novelty assessment is hindered in part by unreliable expert assessment ( e . g . , datasets may consist of thousands of ideas , which makes the recognition of past similarity and frequency very difficult for a human evaluator reading through them sequentially ) , and in part by semantic space embeddings that do not properly encode subtle semantic differences . The present model focuses on detecting novel ideas in real - time based on their semantic similarity to past ideas or relative novelty , and to domain knowledge or absolute novelty . Relative novelty filters out past similar ideas and absolute novelty detects unique ideas relative to domain topics . The computational novelty is a combination of absolute and relative novelty . An external dataset with short descriptions of domain topics encodes the domain knowledge . To reduce the computational burden of computing the semantic similarity between an idea embedding and all domain embeddings , we explore the options of computing absolute novelty using either a select number of representative points ( e . g . , domain topics ) or a set of centroids obtained after clustering domain data . Relevance is a critical issue in assessing creativity . Both irrelevant ideas ( e . g . , “Watching TV” as an idea for a new sport ) as well as novel relevant ideas can have a high absolute novelty score . To distinguish between them , we explore several methods to compute the relevance of an idea to the domain . We focus on methods that do not require labeled data or any auxiliary datasets . Three methods were used for relevance detection : ( 1 ) Probabilistic language model ; ( 2 ) One - class support vector machine ( SVM ) classifier ; and ( 3 ) Zero - shot deep learning - based classifier . The best results were obtained by the probabilistic language model . Furthermore , identifying novel ideas that are fully elaborated will not likely spark further discussions . Thus , we also develop an elaboration metric for evaluating whether an idea is elaborated or not . In this paper , we show the results of our elaboration , rele - vance , and novelty detection models and of their integration in a real - time system . II . B ACKGROUND Novelty detection in text data has been studied before , es - pecially in the context of extracting novel content out of news story streams or First Story Detection ( FSD ) [ 10 ] . Methods include representing text as a vector or via a language model , followed by a distance metric to estimate the novelty of a text . Typical vector representation methods include TF - IDF [ 11 ] , Latent Semantic Indexing ( LSI ) [ 12 ] , and Latent Dirichlet Allocation ( LDA ) [ 13 ] . Methods based on word embeddings enable a more semantically accurate vector representation of text [ 14 ] , [ 15 ] , [ 16 ] , [ 17 ] . Recently , several sentence embed - ding methods have been proposed , either based on the trans - former architectures [ 18 ] , [ 9 ] , [ 19 ] , recurrent neural networks [ 20 ] , [ 21 ] , [ 22 ] , [ 23 ] or recursive networks [ 24 ] . Probabilistic language models represent text as the conditional probability of a text being generated from a collection [ 25 ] , [ 26 ] , [ 27 ] . Non - similarity based novelty measures compare new text to a collection using cumulative TF - IDF [ 27 ] , or an information theoretic approach [ 28 ] . Gamon [ 29 ] represents text as a graph with words as nodes and uses mutual information to weight the connection between two words . The novelty of a text is a function of graph changes ( e . g . , number of new nodes , edges , amount of change in existing edges , etc . ) . Universal sentence embeddings aim to directly capture short text semantics in a vector form and are trained on a diverse set of data - rich tasks such that most do not need further fine - tuning . Such sentence embedding models include : ULMFiT [ 21 ] with a three layer AWD - LSTM network [ 30 ] , InferSent [ 31 ] , Sentence - BERT ( SBERT ) [ 19 ] , and Universal Sentence Encoder ( USE ) [ 9 ] . We have compared the performance of USE , ULMFiT and SBERT embeddings on the task of finding a domain - specific semantic map and found out that USE embeddings performed the best without the need of fine - tuning [ 32 ] . USE has two models , one using the encoder part of the transformer architecture ( USE - T ) [ 33 ] and one based on a deep averaging network ( USE - DAN ) [ 15 ] . Both models are trained on a diverse set of tasks ranging from natural language inference to question answering , to text classification [ 31 ] . USE - DAN performed slightly better than USE - T in [ 32 ] , and hence it is used in this paper . Also , USE - DAN embeds text with linear time complexity . III . M ETHODS The proposed model aims at extracting in real - time ideas expressed in a group discussion that are : ( a ) Novel compared to both the domain of the discussion ( e . g . , absolute novelty ) as well as to previous ideas expressed in the group ( e . g . , relative novelty ) ; ( b ) Relevant to the topic ; and ( c ) Not fully elaborated . The flow of the model is presented in Figure 1 . I ( t ) Domain Data Past Ideas Relevance Elaboration Absolute Novelty Relative Novelty Total Novelty Fig . 1 . Real - Time Feedback Model ( I ( t ) is idea at time t ) . Each idea ( I ( t ) ) passes through the relevance , elaboration , and novelty modules . There is an external collection of short text descriptions from the domain that serve as reference points for detecting novelty and relevance . In this paper , the domain dataset comes from online sources [ 34 ] , [ 35 ] , [ 36 ] . We only address the selection of ideas that could potentially spark further creativity in groups , not the timing of the feedback ( i . e . , when to inject the selected ideas in the discussion flow ) . A . Relevance Module The role of the relevance module is to filter out irrelevant ideas . Depending on the data , relevance can be addressed by multi - class classifiers ( e . g . , SVM , BERT [ 18 ] ) , one - class clas - sifiers ( e . g . , OC - SVM [ 37 ] ) , zero - shot classifiers ( e . g . , [ 38 ] , [ 39 ] ) , or probabilistic language models ( e . g . , [ 26 ] , [ 25 ] ) . In this paper , we compare three classifiers : a probabilistic language model ( PLM ) , a one - class SVM classifier ( OC - SVM ) , and a zero - shot classifier ( ZSC ) based on the BART model [ 40 ] . OC - SVM is the only method that uses only domain data . The PLM model makes use of the frequency of 300K words in the general English language [ 41 ] , and the ZSC model has been pre - trained on the MNLI dataset [ 40 ] . 1 ) Probabilistic Language Model : PLM consists of two language models ( LMs ) , one for the specific domain and one for general English . An idea is evaluated as being either from the specific domain ( P ( text | D ) ) or from general English ( P ( text | G ) ) , with P ( text | ∗ ) computed as follows : P ( text | ∗ ) = (cid:89) w i P ( w i | ∗ ) , with P ( w | ∗ ) = f ∗ w (cid:80) w f ∗ w ( 1 ) where w i is a word in the idea and f ∗ w the frequency of a word in the specific or general domain . The P ( w | ∗ ) needs to be smoothed with P ( w | G ) to account for words not in the specific domain data . Words that do not appear in either specific or general domains are excluded from the computation of P ( w | ∗ ) . We have experimented with different smoothing techniques , with the best results obtained with the Jelinek - Mercer smoothing [ 42 ] : P s ( w | ∗ ) = λ · P ( w | ∗ ) + ( 1 − λ ) · P ( w | G ) ( 2 ) Finally , the relevance of an idea is defined as : R PLM = log ( P ( text | D ) ) − log ( P ( text | G ) ) , where a positive value indicates idea more likely comes from the specific domain . 2 ) One - Class SVM Model : OC - SVM builds a hypersphere around the data and has been used to detect outliers or out - of - domain text [ 43 ] . Our OC - SVM is trained on the specific domain dataset . Each short text is embedded as a 512 - dimensional vector using USE - DAN [ 9 ] , and projected onto a lower dimensional space using principal component analysis ( PCA ) . The retained components preserve 95 % of the explained variance from the original data ( PCA - 95 ) . It was shown that PCA dimensionality reduction performs well with SVM models [ 44 ] . The PCA - 95 vectors obtained from the specific domain data are used for training . The relevance measure of an idea is given by the distance to the decision function : a large positive number indicates the idea is in the specific domain , otherwise , outside . 3 ) Zero - Shot Classifier : ZSCs ( [ 38 ] , [ 39 ] ) can be used to predict whether a text and a chosen label are related or not without any labelled data . We use the BART model [ 40 ] trained as a denoising autoencoder [ 40 ] as a ZSC as follows : Each idea is paired with a small set of human - generated labels selected as high - level features of the specific domain . The output of the model is a probability vector of the idea entailing each of the labels . B . Elaboration The goal of the elaboration module is to filter out fully defined ideas using a soft measure of elaboration , characterized by long and coherent text . First , the semantic coherence ( C ) of an idea is defined as the average similarity between the USE - DAN embeddings of consecutive sentences [ 45 ] : C = 1 n − 1 n − 1 (cid:88) i = 1 sim ( S i , S i + 1 ) ( 3 ) where sim ( · ) = 1 − d ( · ) is the semantic similarity between two embeddings , d ( · ) is the angular distance , and n is the number of sentences . Ideas with one sentence have a coherence of 0 . Then , the elaboration score of an idea ( E ) is computed as a function of both coherence and average sentence length ( ⟨ L ⟩ ) : E = exp (cid:18) − 1 ⟨ L ⟩ · ( 1 + C ) (cid:19) ( 4 ) This function results in values closer to 1 for ideas with long average sentences and high coherence values , and closer to 0 for shorter average sentences and low coherence values . C . Novelty Module The novelty module receives relevant and low - elaborated ideas as well as a representation of the domain and the set of previous ideas generated in the discussion . The novelty of an idea is a combination of relative novelty compared to the group discussion so far and absolute novelty compared to the domain collection . The absolute novelty is needed , especially at the beginning of a discussion , since there is no history of ideas . Thus , relatively mundane ideas can be considered novel simply because they have not been mentioned before . Relative novelty avoids selecting ideas that are too similar to past ideas expressed by the group . 1 ) Absolute Novelty : A domain can be represented as a collection of text describing its main topics or areas . We are not addressing the problem of how to find and select this collection . It could be done by filtering a large collection of web scraped text , or by using curated domain specific databases . In our case , the domain of interest was sports , for which we collected a comprehensive set of sport definitions from the web [ 34 ] , [ 35 ] . A model requirement is to evaluate ideas quickly , which eliminates methods that compare an idea with each text in the domain data . We have developed an adaptive agglomerative clustering method to extract represen - tatives from the domain data ( i . e . , sports definitions ) [ 8 ] . The domain text was encoded with USE - DAN [ 9 ] and projected onto the PCA - 95 space before clustering . The cluster centroids are used to represent the domain . For comparison purposes , we select the top most popular sports as an alternate set of domain representatives [ 36 ] . Let V be the vector embedding of an idea obtained with USE - DAN and projected onto the reduced PCA - 95 space , and D = { D i } the set of M domain representative embeddings . Then , the absolute novelty is the average of the k 1 shortest distances from V to all vectors in D is defined as : N abs = 1 k 1 k 1 (cid:88) j = 1 min k j ( d ( V , D i ) , i = 1 . . . M ) ( 5 ) where d ( · ) is the angular distance and 1 ≤ k 1 ≤ 5 . The reason for using the average of k 1 instead of the smallest distance is to smoothen the novelty values . Typically , the smaller the value of M is , the smaller the value of k 1 . 2 ) Relative Novelty : The relative novelty ( N rel ) is com - puted as in Equation 3 , but as the average of the k 2 shortest distances between the USE - DAN embedding of idea I i and all past ideas embeddings . In this work , we consider the number of past ideas to be relatively small , and thus a comparison between a new idea and all previous ideas will not impose a computational burden to the model . For longer discussions with thousands of ideas , it will be necessary to compress the vectors of past ideas in the same way as the domain data . The total novelty score of an idea is a linear combination of its corresponding relative and absolute novelty scores : N total = c ( t ) · N abs + ( 1 − c ( t ) ) · N rel ( 6 ) where c ( t ) controls the influence of the two components and can be constant or dependent on the number of past ideas . IV . D ATA D ESCRIPTION The data comes from 57 groups of four participants each who generated ideas for coming up with a new sport [ 46 ] . In total , there are 1 , 480 ideas ranging from 1 to 428 words , with an average of 38 words per idea . Each idea is rated by experts with a novelty score between 1 ( not novel ) and 5 ( highly novel ) reflecting the perceived frequency in the entire dataset . A smaller set of 444 ideas was also manually rated for relevance with values between 1 ( not relevant ) to 3 ( highly relevant ) , averaged among three raters . We represent the domain via three datasets of sports defini - tions : 1 ) a Short set [ 35 ] with 877 sports with average lengths of 20 words ; 2 ) a Medium set with 1144 sports with average lengths of 191 words [ 47 ] ; and 3 ) a Long set with 877 sports with 210 words on average per item [ 35 ] . For general English , we use a Kaggle dataset of the 333 , 333 most frequent words extracted from the Google Web Trillion Word Corpus [ 41 ] . The top 21 most popular sports were obtained from [ 36 ] . V . R ESULTS A . Relevance Results The relevance methods ( PLM , OC - SVM and ZSC ) were evaluated in the same way using the average human - rated relevance ( ARR ) for a random subset of 444 ideas . First , the Kendall’s τ coefficient was computed between the computa - tional relevance and ARR values . Then , ARR was mapped to a binary scale : 0 – not relevant – for ARR less than 1 . 5 and 1 – relevant – otherwise ( i . e . , ideas rated by at least two out of three raters as “not relevant” were considered not relevant ) . Then the relevance method was evaluated using the area under the receiver operating characteristics ( AUC ) . 1 ) Probabilistic Language Model – PLM : The LM for the specific domain was trained on the union of the three sports datasets and the LM for the general English domain was trained on the Kaggle dataset ( Equation 1 ) . The ARR dataset was used to estimate the best smoothing coefficient λ ( Equation 2 ) and the R PLM relevance threshold ( θ R ) . The largest Kendall correlation coefficient ( τ K ) between R PLM and ARR was τ K = 0 . 686 for smoothing coefficient λ = 0 . 55 . The AUC for PLM was 0 . 91 . We then computed the best threshold ( θ R ) for R PLM values over which ideas are deemed relevant . The best F 1 macro average value between binary ARR and R PLM values was 0 . 78 and was obtained for θ R = 4 . 2 ( i . e . , ideas with R PLM larger than θ R are relevant ) . Figure 2 shows the scatter plot between computed R PLM and ARR values , and Figure 3 shows the ROC curve . 1 2 3 ARR 0 100 200 300 R P L M Fig . 2 . PLM Relevance ( R PLM ) versus ARR for λ = 0 . 55 and τ K = 0 . 686 . 0 1 False Positive Rate 0 1 T r u e P o s i t i v e R a t e ROC curve ( area = 0 . 91 ) Fig . 3 . ROC of PLM Relevance for λ = 0 . 55 and τ K = 0 . 686 . 2 ) One - Class Support Vector Machine – OC - SVM : The OC - SVM was trained with the union of the three sports datasets embedded with USE - DAN and reduced from 512 to 228 dimensions with PCA - 95 . It correctly classified the training data with an accuracy of 98 % . The ideas were also embedded with USE - DAN and PCA - 95 . We used the distance to decision function as a measure of relevance ( R SV M ) with AUC = 0 . 84 . The Kendall’s τ K coefficient between R SV M and ARR was 0 . 4 . We then estimated the best relevance threshold ( θ R ) in a similar way as for the PLM relevance . The best relevance threshold ( θ R ) was θ R = − 0 . 35 with an F 1 macro average between binary ARR and R SV M values of 0 . 74 . Figure 4 shows the scatter plot between relevance R SV M and ARR values , and Figure 5 shows the ROC curve . 1 2 3 ARR 0 . 8 0 . 0 0 . 8 R SV M Fig . 4 . OC - SVM Relevance ( R SV M ) versus ARR with τ K = 0 . 4 . 0 1 False Positive Rate 0 1 T r u e P o s i t i v e R a t e ROC curve ( area = 0 . 84 ) Fig . 5 . ROC of OC - SVM Relevance with τ K = 0 . 4 . 3 ) Zero - Shot Classifier – ZSC : The ZSC model was pre - sented with ideas paired with the set of domain specific labels : “sport , ” “game , ” “not sport , ” and “not game . ” The model out - put was a probability assignment to these labels . We computed Kendall’s τ K coefficient between ARR and the probability values for each class label . The largest negative correlation was for the label “not sport” . Using 1 − P [ “not sport” ] as a measure of relevance ( R ZSC ) , we obtained an AUC of 0 . 86 and a τ K = 0 . 44 . The relevance threshold ( θ R ) was estimated using binary ARR values and thresholded R ZSC values with the largest F 1 macro average of 0 . 74 for θ R = 0 . 9 . Figure 6 shows the dependence between R ZSC and ARR , and Figure 7 shows the ROC curve . 1 2 3 ARR 0 . 0 0 . 5 1 . 0 R Z S C Fig . 6 . ZSC Relevance ( R ZSC ) versus ARR with τ K = 0 . 44 . Based on these results , the best model was PLM , but the others performed well too . The drawback of PLM is that the domain data must all be relevant , which is not a problem for well - defined domains such as sports . In other cases , PLM or 0 1 False Positive Rate 0 1 T r u e P o s i t i v e R a t e ROC curve ( area = 0 . 86 ) Fig . 7 . ROC of ZSC Relevance with τ K = 0 . 44 . OC - SVM may not perform as well . The advantage of ZSC is that it requires no fine - tuning and it should be reliable for many domains , given that it was pre - trained on large enough datasets . The labels were chosen to describe both the domain and its negation . It would be interesting to explore a keyword extraction method ( e . g . , [ 48 ] ) for label generation . B . Elaboration The elaboration of an idea is computed as in Equation 4 . Figure 8 shows the elaboration ( E ) against the average idea length in words ( ⟨ L ⟩ ) . 1 60 120 < L > 0 . 30 0 . 89 1 . 00 E Fig . 8 . Elaboration ( E ) w . r . t . Average Idea Length ( ⟨ L ⟩ ) – The red line is the average elaboration value ( 0 . 89 ) . The dot size increases with the frequency of the respective E value . Table I shows the characteristics of ideas with elaboration values higher than average ( i . e . , high elaboration ) and those with lower than average values ( i . e . , low elaboration ) . Low elaboration ideas are relatively shorter in terms of average sentence count and have lower average word count and co - herence . Table II shows a sample of high and low elaboration . TABLE I H IGH - V ERSUS L OW - E LABORATION I DEAS # Ideas ⟨ # Sentences ⟩ ⟨ L ⟩ C High Elaboration 1051 3 . 19 18 . 17 0 . 35 Low Elaboration 429 1 . 05 4 . 65 0 . 03 C . Novelty Results 1 ) Absolute Novelty : To measure the novelty of an idea with respect to the domain , a concise semantic representation TABLE II S AMPLE OF H IGH A ND L OW E LABORATION I DEAS Ideas High Elabora - tion This sport requires 5 teams of 3 . There is one goal or basket on one end of a narrow field and the goal is to get teams ball into goal as many times as you can in a 15 minute period . Players can only hold the ball with hands if a ball touches the ground in any way the team must return to the starting end of the field . The team can only pass the ball by tossing or throwing it . Each time a goal is made the team must return to the starting line to begin again . The narrow field causes the teams to inevitably interfere with one another . If a ball is intercepted by another team the team who intercepted the ball automatically gets 1 point . Low Jumping Jack race Elaboration Circle spin The sport will consist of 7 players on each team . Extreme ninja of the domain data is needed , but the domain may contain an enormous amount of text data , in which it would be compu - tationally inefficient to use all corresponding representations as reference points . For the sports domain , we use the set of Top21 most popular sports as a set of representative topics for the domain . The set includes sports such as football , hockey , tennis , etc . Outside a well - defined domain , one must use alternate approaches , such as clustering , for extracting a a set of representative points that cover the semantic space . For this , the domain data is embedded in a semantic vector space . In the case of USE - DAN , the semantic vector space is 512 - dimensional , which is then projected onto a reduced dimensionality space ( PCA - 95 ) . In this space , an agglom - erative clustering method is used , followed by an adaptive algorithm that eliminates or combines low quality clusters based on coherence , cohesion , and information loss measures . The clustering algorithm is detailed in [ 8 ] . In this work , the centroids of the final clusters for each of the three domain datasets are used : 18 clusters for the Short , 20 clusters for the Medium , and 30 clusters for the Long source set . We then study whether our compression techniques are representative of the full space . Table III shows the Spearman correlation coefficient between the absolute novelty ( 5 ) of all ideas in the full semantic space ( N abs ) versus that in the Top21 ( N tabs ) , or centroid space ( N cabs ) . We used k 1 = 5 for the full space , and k 1 = 3 for the Top21 and the centroid spaces . TABLE III C ORRELATION BETWEEN N abs IN F ULL VS C OMPRESSED S PACES Dataset Top (cid:0) N tabs (cid:1) Centroid (cid:0) N cabs (cid:1) Short 0 . 848 0 . 718 Medium 0 . 889 0 . 641 Long 0 . 934 0 . 722 Figure 9 shows the relationship between N abs and N tabs for all ideas computed in the semantic space defined by the Long dataset . Similarly , Figure 10 plots the relationship between N abs and N cabs in the same space . 0 . 2 0 . 3 0 . 4 0 . 5 N abs 0 . 2 0 . 3 0 . 4 0 . 5 N t a b s Fig . 9 . Abs . Novelty in full space ( N abs ) versus Abs . Novelty in Top21 space (cid:0) N tabs (cid:1) with Long dataset ( Spearman Correlation Coefficient , ρ = 0 . 934 ) . 0 . 2 0 . 3 0 . 4 0 . 5 N abs 0 . 2 0 . 3 0 . 4 0 . 5 N c a b s Fig . 10 . Abs . Novelty in full space ( N abs ) versus Abs . Novelty with Centroids (cid:0) N cabs (cid:1) on Long dataset ( Spearman Correlation Coefficient , ρ = 0 . 722 ) . As shown in Figures 9 and 10 , there is stronger correlation between novelty scores when going from the full to Top21 space compared to that from the full to centroids space . However , both spaces appear to encode the novelty well and seem to be good choices for a sparse domain representation . 2 ) Relative Novelty : The relative novelty score was com - puted similarly to the absolute one , but for the ideas expressed in each group , in chronological order . The relative novelty of the first idea in a group was set to 0 . The relative novelty values tended to go down over time , as the group generated less novel ideas . Figure 11 shows an example of relative ( N grel ) and absolute novelty values over time in one group . The absolute novelty was computed against the centroids of the long dataset ( N cabs ) . It can be observed that the relative novelty becomes lower than the absolute novelty over time . D . Real - Time Feedback For the real - time feedback process , ideas in each group are received chronologically . Each idea is evaluated by the relevance module , then by the elaboration module , and lastly , by the novelty module . The novelty module computes the relative novelty compared to all previous ideas and the absolute novelty compared to the specific domain representation . Then the total novelty is calculated according to Equation 5 . The value of the coefficient c ( t ) is varied over time between c 0 and 1 according to : c ( t ) = ( 1 − c 0 ) e − αt + c 0 . We set α = 0 . 2 and vary the value of c 0 from 0 to 1 . As early ideas come in , 1 30 Time 0 . 0 0 . 5 N c a b s , N g r e l N grel N cabs Fig . 11 . Relative Novelty ( N rel ) of Ideas in a Group Compared to Absolute Novelty ( N cabs ) in the Long Dataset . the total novelty depends more on absolute novelty , but later in the discussion the total novelty will weight more on the relative novelty . Table IV shows the largest Kendall’s τ K between total novelty ( N total ) and human - rated novelty ( N rated ) obtained by varying c 0 from 0 to 1 and its corresponding value of c 0 . Human - rated novelty estimates the relative novelty over the entire ideas dataset , which can be very noisy . The coefficients in Table IV , though small , represent a major increase over τ K between absolute novelty ( N abs ) and N rated which range between 0 . 10 − 0 . 11 depending on the domain dataset and the representation . In contrast , the Kendall’s τ between the relative novelty computed using all ideas ( N allrel ) and N rated is τ K = 0 . 198 . Combining group relative novelty with absolute novelty in an adaptive way over time increases the relationship almost twice and makes it closer , or even higher than that obtained by using all ideas . Also , the relationship is strongest in the centroid space followed by the Top21 space . TABLE IV M AX τ K FOR c 0 IN 0 TO 1 I NTERVAL WITH B EST c 0 IN P ARENTHESES max τ K ( N total , N rated ) Full Top Centroids Short 0 . 198 ( 0 . 2 ) 0 . 207 ( 0 . 0 ) 0 . 214 ( 0 . 3 ) Medium 0 . 193 ( 0 . 1 ) 0 . 206 ( 0 . 1 ) 0 . 213 ( 0 . 3 ) Long 0 . 191 ( 0 . 1 ) 0 . 204 ( 0 . 0 ) 0 . 210 ( 0 . 2 ) Figure 12 shows the total novelty of ideas in the same group as the one in Figure 11 . The domain space is that of the centroids from the Short dataset . It can be seen that there are very few ideas in this group that are both relevant and not elaborated ( shown in red ) , and that larger N total ideas tend to correspond to high N rated ( e . g . , N rated of 4 and 5 ) and lower N total tend to have a low N rated ( e . g . , N rated lower than 4 ) . Table V shows the ideas that are relevant and low - elaborated ( red in Figure 12 ) . The smallest total novelty is obtained for the fourth idea , which also has the lowest rated novelty . It is interesting that the relevance and elaboration modules filter a large number of ideas . The real - time feedback can include a subset of these ideas , given that they pass a high - novelty threshold . Revisiting these ideas can enable further elaboration , thus , potentially increasing the overall creativity . 1 30 Time 0 . 2 0 . 5 N t o t a l relev and low elab high rated nov low rated nov Fig . 12 . Total Novelty of Group Ideas Over Time – Red dots correspond to relevant ideas with low elaboration , green dots correspond to ideas with high N rated , and blue dots to ideas with low N rated . TABLE V S AMPLE I DEAS WITH N rated , N cabs , N rel AND N total NOVELTY SCORES Sample Idea N rated N cabs N rel N total Rock tossing contest 5 0 . 462 0 . 431 0 . 447 Roller skating with a cat 5 0 . 407 0 . 378 0 . 388 Crying and running to get to a ball 5 0 . 455 0 . 392 0 . 412 Tweaking and throwing a ball 3 0 . 410 0 . 33 0 . 355 Combining the egg & spoon game with soccer 5 0 . 407 0 . 375 0 . 385 VI . C ONCLUSION The proposed relevance and novelty detection model can accurately extract relevant , less elaborated and novel ideas from messages in group discussions in real - time . This feed - back could increase the creativity throughput of a group . We plan on testing our model in future group experiments . Our proposed model is general and can be adapted to other situations where evaluating text quality based on novelty and relevance is needed . For example , the model could extract a summary of a discussion based on these characteristics . Both novelty and relevance detection are not new problems and have been studied before in different scenarios with models ranging from probabilistic language models to deep neural networks . A novel feature of our model is the introduction of absolute and relative components of novelty . Previous models have studied primarily relative novelty ( e . g . , First Story Detection ) . In addition , we have investigated multiple ways to compress the domain space by comparing most frequent topics versus cluster centroids and have shown that both are accurate alternatives to a full domain representation . R EFERENCES [ 1 ] P . B . Paulus , D . Levine , V . R . Brown , A . A . Minai , and S . Doboli . Modeling ideational creativity in groups : connecting cognitive , neural and computational approaches . Small Group Research , 41 : 688 – 724 , 2010 . [ 2 ] P . B . Paulus and V . R . Brown . Toward more creative and innovative group idea generation : A cognitive - social - motivational perspective of group brainstorming . Social and Personality Psychology Compass , 1 : 248 – 265 , 2007 . [ 3 ] J . Baruah and P . B . Paulus . Category assignment and relatedness in the group ideation process . Journal of Experimental Social Psychology , 47 ( 6 ) : 1070 – 1077 , 2011 . [ 4 ] L . E . Coursey , R . T . Gertner , B . C . Williams , J . B . Kenworthy , P . B . Paulus , and S . Doboli . Linking the divergent and convergent processes of collaborative creativity : The impact of expertise levels and elaboration processes . Frontiers in Psychology , 10 : 699 , 2019 . [ 5 ] S . Doboli , J . Kenworthy , P . Paulus , A . Minai , and A . Doboli . A cognitive inspired method for assessing novelty of short - text ideas . In 2020 International Joint Conference on Neural Networks ( IJCNN ) , pages 1 – 8 , 2020 . [ 6 ] M . Usher and J . L . McClelland . Loss aversion and inhibition in dynamical models of multialternative choice . Psychol Rev . , 111 ( 3 ) : 757 – 769 , 2004 . [ 7 ] G . E . Cox and R . M . Shiffrin . A dynamic approach to recognition memory . Psychological Review , 124 ( 6 ) : 795 , 2017 . [ 8 ] R . Choudhary , O . Alsayed , S . Doboli , and A . A . Minai . Building semantic cognitive maps with text embedding and clustering . In Proceedings of the 2022 World Congress on Computational Intelligence ( WCCI’22 ) . IEEE , 2022 . [ 9 ] D . Cer , Y . Yang , S - Y Kong , N . Hua , N . Limtiaco , R . St . John , N . Constant , M . Guajardo - Cespedes , S . Yuan , C . Tar , B . Strope , and R . Kurzweil . Universal sentence encoder for English . In Proc . of 2018 Conf . on Empirical Methods in Natural Language Processing : System Demonstrations , pages 169 – 174 , 2018 . [ 10 ] Y . Zhang , J . Callan , and T . Minka . Novelty and redundancy detection in adaptive filtering . In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’02 , pages 81 – 88 , New York , NY , USA , 2002 . ACM . [ 11 ] K . S . Jones . A statistical interpretation of term specificity and its application in retrieval . Journal of Documentation , 28 : 11 – 21 , 1972 . [ 12 ] S . Deerwester , S . Dumais , T . Landauer , G . Furnas , and R . Harshman . Indexing by latent semantic analysis . Journal of American Society of Information Science , 41 : 391 – 407 , 1990 . [ 13 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3 : 993 – 1022 , 2003 . [ 14 ] J . Wieting , M . Bansal , K . Gimper , and K . Livescu . Towards universal paraphrastic sentence embeddings . In ICLR 2016 , 2016 . [ 15 ] M . Iyyer , V . Manjunatha , J . Boyd - Graber , and H Daume III . Deep unordered composition rivals syntactic methods for text classification . In Proc . of the 53rd Annual Meeting of the ACL and the 7th Int . JCNLP ( Volume 1 : Long Papers ) , pages 1681 – 1691 , 2015 . [ 16 ] S . Arora , Y . Liang , and T . Ma . A simple but tough - to - beat baseline for sentence embeddings . In ICLR 2016 , 2016 . [ 17 ] K . Ethayarajh . Unsupervised random walk sentence embeddings : A strong but simple baseline . In Proceedings of The Third Workshop on Representation Learning for NLP , pages 91 – 100 , Melbourne , Australia , July 2018 . Association for Computational Linguistics . [ 18 ] J . Devlin , M - W Chang , K . Lee , and K . Toutanova . BERT : Pre - training of deep bidirectional transformers for language understanding . In Proc . of the 2019 Conf . of the North American Chapter of the ACL : Human Language Technologies , Vol . 1 , pages 4171 – 4186 , Minneapolis , Minnesota , 2019 . [ 19 ] N . Reimers and I . Gurevych . Sentence - bert : Sentence embeddings using siamese bert - networks . CoRR , abs / 1908 . 10084 , 2019 . [ 20 ] A . Conneau , D . Kiela , H . Schwenk , L . Barrault , and A . Bordes . Supervised learning of universal sentence representations from natural language inference data . In 2017 Conference on Empirical Methods in Natural Language Processing , pages 670 – 680 , 2017 . [ 21 ] J . Howard and S . Ruder . Universal language model fine - tuning for text classification . In Proc . of the 56th Annual Meeting of the ACL ( Vol . 1 ) , pages 328 – 339 , Melbourne , Australia , 2018 . [ 22 ] M . Peters , M . Neumann , M . Iyyer , M . Gardner , C . Clark , K . Lee , and L . Zettlemoyer . Deep contextualized word representations . In Proc . of the 2018 Conf . of the North American Chapter of the ACL : Human Language Technologies , Volume 1 ( Long Papers ) , pages 2227 – 2237 , New Orleans , Louisiana , 2018 . [ 23 ] T . Ghosal , V . Edithal , A . Ekbal , P . Bhattacharyya , G . Tsatsaronis , and S . S . S . K Chivukula . Novelty goes deep . a deep neural solution to document level novelty detection . In 27th International Conference on Computational Linguistics ( COLING 2018 ) , Santa Fe , New Mexico , USA , pages 2802 – 2813 , 2018 . [ 24 ] R . Socher , A . Perelygin , J . Wu , J . Chuang , C . D . Manning , A . Ng , and C . Potts . Recursive deep models for semantic compositionality over a sentiment treebank . In 2013 Conference on Empirical Methods in Natural Language Processing , pages 1631 – 1642 , 2013 . [ 25 ] J . Allan , C . Wade , and A . Bolivar . Retrieval and novelty detection at the sentence level . In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval , SIGIR ’03 , pages 314 – 321 , 2003 . [ 26 ] C . Zhai and J . Lafferty . Two - stage language models for information retrieval . In Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’02 , pages 49 – 56 , 2002 . [ 27 ] M . Karkali , F . Rousseau , A . Ntoulas , and M . Vazirgiannis . Using temporal IDF for efficient novelty detection in text streams . CoRR , abs / 1401 . 1456 , 2014 . [ 28 ] T . Dasgupta and L Dey . Automatic scoring for innovativeness of textual ideas . In Workshops at the Thirtieth AAAI Conference on Artificial Intelligence , Knowledge Extraction from Text , 2016 . [ 29 ] M . Gamon . Graph - based text representation for novelty detection . Proceedings of the First Workshop on Graph Based Methods for Natural Language Processing , pages 17 – 24 , 2006 . [ 30 ] A . Merity , N . S . Keskar , and R . Socher . Regularizing and optimizing LSTM language models . In 6th Int . Conf . on Learning Representations , ICLR 2018 , Vancouver , BC , Canada , 2018 . [ 31 ] A . Conneau and D . Kiela . Senteval : An evaluation toolkit for universal sentence representations . In http : / / arxiv . org / abs / 1803 . 05449 , 2018 . [ 32 ] R . Choudhary , S . Doboli , and A . A . Minai . A comparative study of methods for visualizable semantic embedding of small text corpora . In 2021 International Joint Conference on Neural Networks ( IJCNN’21 ) , pages 1 – 8 . IEEE , 2021 . [ 33 ] A . Vaswani , N . Shazeer , N . Parmar , J . Uszkoreit , L . Jones , A . N . Gomez , L . Kaiser , and I . Polosukhin . Attention is all you need . In I . Guyon , U . V . Luxburg , S . Bengio , H . Wallach , R . Fergus , S . Vishwanathan , and R . Garnett , editors , Advances in Neural Information Processing Systems 30 , pages 5998 – 6008 . Curran Associates , Inc . , 2017 . [ 34 ] Wikipedia . List of sports . https : / / en . wikipedia . org / wiki / List \ of \ sports . Online ; accessed July 2019 . [ 35 ] List of sports – every sport from around the world . https : / / www . topendsports . com / sport / list / , 2008 . Accessed : 2 / 11 / 2021 . [ 36 ] S . Devano . Top 10 most popular sports in the world . https : / / sportsbrowser . net / most - popular - sports / , 2021 . Accessed : 2021 . [ 37 ] B . Sch¨olkopf , J . C . Platt , J . Shawe - Taylor , A . J . Smola , and R . C . Williamson . Estimating the support of a high - dimensional distribution . Neural computation , 13 ( 7 ) : 1443 – 1471 , 2001 . [ 38 ] P . K . Pushp and M . M . Srivastava . Train once , test anywhere : Zero - shot learning for text classification . arXiv preprint arXiv : 1712 . 05972 , 2017 . [ 39 ] W . Yin , J . Hay , and D . Roth . Benchmarking zero - shot text classification : Datasets , evaluation and entailment approach , 2019 . [ 40 ] M . Lewis , Y . Liu , N . Goyal , M . Ghazvininejad , A . Mohamed , O . Levy , V . Stoyanov , and L . Zettlemoyer . Bart : Denoising sequence - to - sequence pre - training for natural language generation , translation , and compre - hension , 2019 . [ 41 ] R . Tatman . Google web trillion word corpus . https : / / www . kaggle . com / rtatman / english - word - frequency , 2017 . Accessed : 2021 . [ 42 ] F . Jelinek and R . L . Mercer . Interpolated estimation of markov source parameters from sparse data . In Proc . Workshop on Pattern Recognition in Practice , 1980 , 1980 . [ 43 ] K . Xu , T . Ren , S . Zhang , Y . Feng , and C . Xiong . Unsupervised out - of - domain detection via pre - trained transformers . arXiv preprint arXiv : 2106 . 00948 , 2021 . [ 44 ] M . Zhu , J . Zhu , and W . Chen . Effect analysis of dimension reduction on support vector machines . In 2005 International Conference on Natural Language Processing and Knowledge Engineering , pages 592 – 596 , 2005 . [ 45 ] M . Lapata and R . Barzilay . Automatic evaluation of text coherence : Models and representations . In IJCAI , volume 5 , pages 1085 – 1090 . Citeseer , 2005 . [ 46 ] L . E . Coursey , R . T . Gertner , B . C . Williams , J . B . Kenworthy , P . B . Paulus , and S . Doboli . Linking the divergent and convergent processes of collaborative creativity : The impact of expertise levels and elaboration processes . Frontiers in Psychology , 10 : 699 , 2019 . [ 47 ] Wikimedia downloads . https : / / dumps . wikimedia . org . [ 48 ] R . Mihalcea and P . Tarau . Textrank : Bringing order into texts . In the Conference on Empirical Methods in Natural Language Processing ( EMNLP 2004 ) , 2004 .