Criteria for Rigor in Visualization Design Study Miriah Meyer and Jason Dykes Abstract — We develop a new perspective on research conducted through visualization design study that emphasizes design as a method of inquiry and the broad range of knowledge - contributions achieved through it as multiple , subjective , and socially constructed . From this interpretivist position we explore the nature of visualization design study and develop six criteria for rigor . We propose that rigor is established and judged according to the extent to which visualization design study research and its reporting are INFORMED , REFLEXIVE , ABUNDANT , PLAUSIBLE , RESONANT , and TRANSPARENT . This perspective and the criteria were constructed through a four - year engagement with the discourse around rigor and the nature of knowledge in social science , information systems , and design . We suggest methods from cognate disciplines that can support visualization researchers in meeting these criteria during the planning , execution , and reporting of design study . Through a series of deliberately provocative questions , we explore implications of this new perspective for design study research in visualization , concluding that as a discipline , visualization is not yet well positioned to embrace , nurture , and fully beneﬁt from a rigorous , interpretivist approach to design study . The perspective and criteria we present are intended to stimulate dialogue and debate around the nature of visualization design study and the broader underpinnings of the discipline . Index Terms —design study , relativism , interpretivism , knowledge construction , qualitative research , research through design 1 I NTRODUCTION Design study – an approach to applied visualization research [ 96 ] – is now a standard method for conducting visualization inquiry , guided by validation methods [ 78 , 82 ] , process models [ 72 , 74 , 96 ] , scenarios [ 95 ] , and an increasing set of representative examples in the literature [ 9 , 43 , 56 , 62 , 77 , 79 , 84 , 107 , 117 ] . In the context of the wider visualization discipline that is increasingly assessing its practices , the maturing of design study has exposed a series of provocative , open questions that we hear researchers asking : What are the research contributions made through design studies , and do they generalize ? What is the value of speciﬁc solutions ? If a design study is not reproducible , can it be rigorous ? How do we conduct design study research well , and how do we assess it ? Is design study even research ? Underlying these questions is a strong focus in the community on the production of visualization software systems within a design study [ 95 ] . Process and decision models used by design study researchers prescribe steps and considerations to design and validate such tools , resulting in a myriad of validated systems . These open questions , however , highlight a problem being faced by researchers seeking to use design study to learn about and express a broader collection of knowledge : process alone does not provide guidance on important considerations for rigor and the construction of diverse forms of knowledge acquired through design [ 55 , 73 ] . The result over the years has been design studies and their resulting papers that focus on deployed , working software , rather than on taking full advantage of the situated , complex , and nuanced learning that researchers ( can ) acquire through deep engagement with people , data , and technology . In this paper we “separate the criteria from the craft” [ 110 ] to support the broader set of outcomes that can result from design study research . We propose considerations for achieving rigor in , and constructing knowledge through , design study that compliment existing processes . We constructed these considerations from a four - year engagement with the ongoing and interrelated discourses around knowledge generation and rigor in social science , information systems , and design . This debate is deep and extensive , and also contradictory , dynamic , and imperfect . It is as complex , messy , and nuanced as the richly situated contexts in which researchers in these ﬁelds engage . • Miriah Meyer is with the University of Utah . E - mail : miriah @ cs . utah . edu . • Jason Dykes is with City , University of London , E - mail : j . dykes @ city . ac . uk . Manuscript received xx xxx . 201x ; accepted xx xxx . 201x . Date of Publication xx xxx . 201x ; date of current version xx xxx . 201x . For information on obtaining reprints of this article , please send e - mail to : reprints @ ieee . org . Digital Object Identiﬁer : xx . xxxx / TVCG . 201x . xxxxxxx We explore the theoretical underpinnings of design study and offer a new , interpretivist perspective . This perspective emphasizes design as a method of inquiry into complex , situated , dynamic problems , and the knowledge achieved through it as multiple in form , various in range , and inherently subjective and socially constructed . From this perspective , we propose a preliminary set of six criteria for rigor in visualization design study that are intended to guide researchers in constructing , communicating , and assessing rigorous knowledge claims . We explain why each criteria is an important consideration for rigor , and identify methods to augment current practices that might help to achieve them . Our view is that attaining these criteria is challenging and adopting them may require action by the community , so we pose several provocative questions that are intended to explore implications , sharpen views , and stimulate debate about whether and how this new perspective on design study might be achieved . But before we provoke , we ﬁrst attempt to persuade . We develop the theoretical backdrop of our position in Section 2 , summarizing a range of thinking and debate from the social sciences , information systems , and design on the nature of knowledge and the ways in which it is constructed . We position our perspective on design study against this theoretic backdrop through a series of statements on the nature of design study in Section 3 , and then propose six criteria in Section 4 for establishing rigor from this perspective . In Section 5 we select three debatable questions that our perspective opens up – there could be many more – and offer our initial opinions . Finally , we conclude with a call to the community to critique and debate our work , as well as the broader philosophical underpinnings of visualization research . 2 T HEORETICAL B ACKDROP The perspective on design study that we present in this paper is informed by a close reading of literature about rigor in social science , information systems , and design . In this section we provide a brief overview of the main themes and threads of discourse that informed our thinking . 2 . 1 Philosophical Positions The predominant philosophical position in science , computer science , and visualization is that of positivism , which views reality as singular and external , on the basis that it can be objectively known . Posi - tivist research approaches focus on reducing researcher reactivity , and achieving reliability , replicability , and representativeness [ 12 ] . Data are collected and analyzed with the aim of producing an unambigu - ous result that is representative of the single reality . Validity criteria for establishing the truthfulness of results rely on reproducibility and replication [ 16 ] , the achievement of which underlies many positivist approaches . Active discussions on these issues in visualization research focus on the reproducibility of data , data transformations , interactive exploration , algorithms , and software systems [ 49 , 99 ] , as well as the reliability of user studies [ 18 , 106 ] . Discourse in the social sciences and humanities has a long history of critiquing positivist positions [ 12 , 36 , 48 ] , particularly for studies that seek to understand people and their experiences [ 66 ] . These arguments advocate for a relativist position that considers reality to be multiple and mind - dependent [ 102 ] , and the researcher as an active instrument of the research . In contrast to the positivist position , the subjective nature of knowledge is a key component and strength of relativist methodologies [ 34 ] . To support a relativist standpoint , interpretivist approaches view the knowledge that a researcher acquires as socially constructed – rather than objectively determined – and use methods such as dialogical approaches that are spoken , written , and interpreted . Subjectivity is embraced and considered shorthand for the construction of knowledge through interpretation [ 30 ] . Visualization research beneﬁts from both positivist and interpretivist approaches as it involves multiple types of phenomena and context . Many perceptual , cognitive , and computational phenomena can be stud - ied effectively through controlled , empirical studies where objectivity , repeatability , and prediction are valued and efforts are made to remove bias and error . Studying people and their considered , complex , contex - tualized , social reactions to dynamic settings often beneﬁts instead from relativist approaches that involve subjective interpretation of qualitative data [ 30 , 57 , 61 , 63 , 107 , 108 , 113 ] . A key concern , however , is that work that is conducted from one position is judged from another [ 28 ] . Positivists might question research that involves subjectivity or bias . Interpretivists , however , are likely to question research rooted in pos - itivism that does not account for the inherently subjective judgments involved in most knowledge construction [ 30 ] . We argue that the visu - alization community is missing a broadly shared understanding of how research emerging from these very different philosophical positions is undertaken with rigor . 2 . 2 Interpretivist Criteria A considerable challenge for interpretivist research approaches is that of establishing rigor criteria that consider the “creative complexity of the qualitative methodological landscape” [ 110 ] . In their explicit rejection of the positivist notions of rigor , the seminal work of Lincoln and Guba [ 66 ] established interpretivist criteria for judging the trustworthiness of research . The criteria credibility , dependability , conﬁrmability , and transferability are offered as alternatives for scientiﬁc validity and generalizability to instead consider : “How can an inquirer persuade his or her audiences that the ﬁndings of an inquiry are worth paying attention to ? ” [ 66 ] . The underpinnings of , and methods for achieving trustworthiness have been considered , debated , expanded , rejected , and reafﬁrmed extensively in the literature since [ 46 , 80 , 85 , 94 , 101 , 110 ] . The difﬁculty in establishing criteria for qualitative , interpretivist research that is inherently messy , changing , subjective , and context - speciﬁc is in stark contrast to the strong consensus for positivist ap - proaches that aim for validity , reliability , generalizability , and objec - tivity – this tension is in part responsible for the undervaluing and undermining of qualitative work [ 94 , 110 ] . Resolving this tension has led to a proliferation of perspectives on rigor criteria in the literature . For example , Lincoln and Guba subsequently reject much of what was presented in their original work [ 46 ] . Morse calls researchers to reclaim the validity and generalizability constructs of positivist criteria in the qualitative realm [ 80 ] as have others [ 85 , 101 ] . And Tracy provocatively offers eight universal criteria for quality in qualitative studies [ 110 ] , which are much used and routinely critiqued [ 102 ] . In this paper we take small steps into the conversation through a proposal of rigor criteria speciﬁcally applicable to visualization design study . Our development of the criteria was informed in - part by the work and thinking of these social science scholars , and it follows in their tradition of rejecting wholesale assimilation in favor of more nuanced criteria suited to a speciﬁc approach to research . 2 . 3 Design Research The tensions and synergies within and between design and research are considered in a series of related ﬁelds . In the applied ﬁeld of infor - mation systems , scholars grapple with the competing needs of design practice and academic research in the context of developing technology for and within organizations [ 97 ] . Inﬂuenced by design science – a problem - solving paradigm that seeks to analyze , design , implement , and manage information systems [ 54 , 112 ] – Sein et al . propose guid - ing principles through their action design research [ 97 ] methodology . These principles capture a view that the design of information systems should be both guided by a researcher’s intent and shaped by the orga - nizational context , which resonates with the goals of design study [ 96 ] . The principles are useful for considering the role of people and context in shaping visualization artifacts within design study , and for recording and reporting on these effects [ 72 ] . The action design research method , and underlying principles , stem more broadly from action research , an approach that relies on action as a means for developing knowledge [ 51 , 64 ] . As a democratic approach , action research emphasizes researching with people in their everyday , real - world contexts , not on them through a process that cycles between planning an intervention , enacting the intervention , observing changes based on the intervention , and reﬂecting on the changes in order to plan for another cycle . Melrose describes the effects of these cycles on the research process as : “the [ researchers and participants ] make mistakes and learn from them , so the research design and questions are emergent and changeable . . . [ it ] is an unrepeatable journey with unpredictable results and undreamed of conclusions” [ 75 ] . Although action researchers , like other social scientists , question the meaning of rigor for their work , the literature on action research points back to Lincoln and Guba’s original notion of trustworthiness [ 66 ] . An alternative thread of thinking and discourse on the production of knowledge through design comes from the research through design ( RtD ) community . RtD is an approach embraced by design researchers and academics who view design artifacts as experiments in future pos - sibilities and the expression of knowledge a researcher gains about those possibilities [ 38 , 68 , 119 ] . Importantly , RtD emphasizes the production of knowledge by means of design activities [ 103 ] . The - oretical work in RtD examines the nature of knowledge generated through design [ 6 , 21 , 59 , 69 ] , the ways in which design researchers design [ 19 , 20 , 27 , 31 ] , and the relationship of RtD to the goals and values of HCI [ 42 , 50 , 119 , 120 ] . Like relativist positions in social science , RtD strongly rejects posi - tivist approaches to research . Instead , researchers argue for the need to embrace a designerly view of knowledge generation that considers the richness and complexity of the design process , context , and out - comes [ 11 , 41 , 42 , 105 ] . These views place knowledge generation within “speciﬁc , intentional , and non - existing” design contexts [ 105 ] , and re - sult in particular , situated outcomes that are subject to a designer’s unique perspective [ 42 ] . Whereas some RtD researchers argue that methodological standards “threaten to occlude the potency of unique , embodied artifacts in a cloud of words and diagrams” [ 41 ] , others ar - gue for a “philosophical and methodological understanding of what constitutes the rigor and discipline of design practice in order to better support practice” [ 105 ] ( emphasis in original ) . The synergies between design research and social science have led to recent calls in the RtD community for design researchers to more fully and systematically embrace methodological approaches of the social sciences [ 39 , 87 ] . 2 . 4 Visualization Design Study In visualization , design study 1 is deﬁned and described as an applied methodology by Sedlmair et al . [ 96 ] : it is “a project in which visu - alization researchers analyze a speciﬁc real - world problem faced by domain experts , design a visualization system that supports solving this problem , validate the design , and reﬂect about lessons learned in order to reﬁne visualization design guidelines . ” This deﬁnition requires that visualization solutions are designed for a problem that exists in the world , with domain experts and their data . Through the consideration of literature , observations , interviews , and their own experiences , design 1 Visualization design study is not explicitly related to the academic design discipline of design study – we note that our reference to design study throughout this paper is with respect to the visualization community’s deﬁnition . study researchers build an understanding of a problem domain and the inherent analysis questions . They operationalize the domain questions into a data representation and set of tasks [ 37 ] , which guide the design of visualization solutions . Design study researchers purposefully assess their understanding of the domain and the efﬁcacy of their operational - izations and visualization solutions through checks with collaborators , data sets , and existing theory and practice . These assessments can be iterative and multiscale throughout the design process ; small , rapid assessments are embedded in larger , longer - term ones [ 72 ] . Reﬂec - tion , most often at the end of a study [ 76 ] , articulates the learning that occurred to add to the body of visualization knowledge . Researchers conducting design studies often employ existing visu - alization models to guide the methodological structure of the study . Process models such as the nine - stage framework [ 96 ] , the design - activity framework [ 74 ] , or action - design research [ 72 , 97 ] provide guidance for the high - level steps a researcher could take to conduct a design study , with recommendations of speciﬁc methods for each step . Complementing these process models , the nested model [ 82 ] is an often - used design decision model that provides guidance for choos - ing appropriate approaches for validating a visualization system . This model categorizes visualization design decisions at four levels , and identiﬁes validity threats for a designed visualization system at each . Several forms of knowledge contribution can be achieved through de - sign studies [ 96 ] : a characterization of the problem domain , a validated visualization design , and improvements to visualization guidelines . Current guidance emphasizes the importance of reﬂection in establish - ing these claims , which , for design study , “is where research emerges from engineering” [ 96 ] . The visualization community , however , has not reached consensus in the about how to reﬂect , when to reﬂect , or how to improve and judge the quality of the subjective reﬂective process [ 76 ] . The nested model supports testing the validity of ( some ) forms of design study knowledge claims , but it does not provide insight or guidance into reﬂectively generating them . Similarly , design study process models articulate steps to take , but don’t articulate how to pro - duce meaningful , varied , and valuable knowledge , or what the criteria might be to judge the resulting knowledge claims . As a result , there is an emphasis in design studies and their result - ing papers on the validated visualization design – working software appreciated by domain experts – rather than on the situated , complex , subjective , and nuanced learning acquired by visualization researchers through design study . We argue that methods for developing valid visualization systems are more accepted , expected , and utilized than methods for reﬂecting on the processes to establish knowledge claims . Thus , in this work we aim to be more explicit about how visualization researchers can assess their decisions in planning , conducting , and reporting on design study ; what they can learn through design study ; and how others can judge resulting knowledge claims . 3 W ICKED S UBJECTIVE D IVERSE D ESIGN S TUDY In this section we detail a new , interpretivist perspective on visualization design study that extends and deepens the existing deﬁnition . This perspective embraces design as a subjective method for constructing and communicating new knowledge , assuming multiple and mind - dependent realities . We present this perspective through four statements on the nature of design study informed by our interpretation , synthesis , and application of approaches from both the qualitative social sciences and RtD described in Section 2 . For each statement we point to relevant rigor criteria that we explain and discuss in detail in Section 4 . Design study uses design for inquiry and expression . Design study researchers learn through the design process . They design visualization solutions for real - world problems in close collaboration with domain experts in order to approach the problem in possibly new ways , and to learn by doing so . Researchers explore possibilities through broad consideration of design spaces , and express and com - municate much of their learning through design instances and artifacts , such as sketches , prototypes , models , and software systems . Therefore , visualization design study aligns with RtD as “a research approach that employs methods and processes from design practice as a legitimate method of inquiry” [ 120 ] . In line with RtD , much of what a design study researcher learns about the molding of materials – combinations of hardware , software , data , and possibly physical materials – into the developing solution , and the relationship of this solution with the problem , is established through the practice of design . This approach prioritizes ﬁnding solutions to a problem through making and proto - typing over theoretical reasoning [ 19 , 104 ] . What a designer comes to know is frequently expressed implicitly through the design itself : its visual form , its interactive characteristics , and the subtle ways in which materials are shaped to address the problem [ 20 ] . We consider the same to be true of design study researchers . Design study researchers are particularly attuned to opportunities for constructing and testing knowledge through design – ideas , concepts , encodings , interactions , and their combination – and to engage , observe , and collect appropriate evidence to explore these possibilities [ 43 , 55 , 73 ] . Taking the perspective of a visualization as a technology probe [ 60 ] offers opportunities to learn about the relationship of people and data beyond learning about the visualization itself [ 73 ] . Ultimately , design study researchers construct knowledge subjectively through reﬂective critical reasoning based upon experience and evidence established through the study , and against a backdrop of existing knowledge . Design researchers understand that “the whole point of doing re - search is to . . . make knowledge available to others in re - usable form” [ 21 ] . Visualization design study researchers predominately make their knowledge available through written reports . They aim to produce explicit and appropriately scoped expressions of knowledge claims that allow them to be communicated persuasively , effectively , and in ways that resonate with the community . Reports primarily take the form of an academic paper including its prose , ﬁgures , and other constituent parts . Additional forms of effective knowledge expression include imagery , software , digital artefacts and videos with annotations and narrative . Design as a method of inquiry and expression leads us to suggest ﬁve criteria for rigor – that the design process : is INFORMED by existing designs to inspire and understand candidate solutions ; is ABUNDANT in observations , designs , and descriptions ; produces PLAUSIBLE designs and interpretations of design processes ; generates designs and claims that are RESONANT ; and expresses knowledge claims explicitly through TRANSPARENT description and evidence . Design study tackles wicked problems . Design study researchers design artifacts based on their understanding and interpretation of a domain problem . A visualization is thus not only an expression of knowledge , but also a technological representation of a problem expressed through a potential solution . By developing visualization designs in close consideration with domain experts and the context of use – continually reassessing their form , function , and po - tential [ 97 ] – the design study researcher shifts and shapes the solution to effectively address a problem that is of interest to domain experts . The iterative , dynamic shaping of the problem and its expression through the designed solution illustrates the wicked nature [ 90 ] of the problems tackled by design study researchers . Wicked problems are indeterminant , meaning “there are no deﬁnitive conditions or limits to the design problem” [ 11 ] . An important characteristic of wicked problems is that it is “only in terms of a conjectured solution that the problem can be contained within manageable bounds . ” [ 19 ] . The problem deﬁnition is considered a design space just as the solution is , with progress towards deﬁning one affecting the progress of deﬁning the other [ 27 , 71 , 118 ] . Wicked problems have unbounded potential for solutions due to the complexity of design [ 105 ] , the absence of inherent stopping criteria [ 11 ] , and a designer’s articulation of the problem and solution as one of many possible interpretations [ 6 ] . These solutions cannot be assessed as true or false , but rather as good or bad [ 11 ] . Embracing wicked problems as core to design study has several im - plications . First , wicked problems encourage input from both designers and domain experts , shaping designs into solutions that are relevant , meaningful , and interesting . The solutions are inextricably related to the problem , the design approach , and the people , including the design study researcher who is deﬁning both problem and solution in ways that are necessarily interdependent , highly subjective , and ﬂuid . Second , ev - idence of the changing problem and solution , and their regular shaping and shifting , is an indication of a strong collaboration between design study researchers and domain experts working toward a mutually bene - ﬁcial solution . Instability of a problem deﬁnition , identiﬁed through changing focus and expressed through task requirements , is a measure of success for design study [ 96 ] . Third , the design of good solutions requires the consideration of a broad space of possibilities [ 96 , 105 ] . The wicked nature of problems that design study tackles requires two criteria for rigor : An ABUNDANT approach to allow multiple voices and perspectives to shift and shape design problems and consider a broad set of solutions ; and that evidence of the dynamic process is reported in TRANSPARENT ways . Design study is inherently subjective . What design study researchers learn is personal , subjective , and spe - ciﬁc . The situated and inherently wicked nature of the visualization design process means that knowledge acquired through design study can only be understood within the context of its construction . This context includes not only the views and experiences of domain experts , datasets , organizational and social constraints , but also a design study researcher’s own intuition , interests , experiences , and values . The re - searcher has important effects on the artifacts that she produces , the problems she addresses , the activities and reactions she observes and interprets , and the details and knowledge she chooses to report . Visual - izations , and the visualization design process , are not neutral [ 17 , 26 ] . Knowledge constructed in this way is inherently interpreted [ 101 , 102 ] and subject to the many assumptions , values , and commitments that researchers bring to their work [ 8 ] . A relevant position for design study is that the observable world can never be construed devoid of and separate from those that observe it [ 12 ] . Therefore , we argue for a relativist perspective to design study , in which observed realities are accepted as multiple , relative , changing , and mind - dependent [ 24 , 35 , 101 , 102 ] . This position contrasts with positivist approaches that are prevalent in the visualization research community and assume the researcher to be a distant , objective observer of a singular reality . Research that takes a relativist standpoint can draw upon established methods to develop meaningful knowledge from deep engagement in , and description of , the context in which the observations and expe - riences take place . These methods utilize subjectivity to support a researcher in diversifying the perspectives and views she is studying , to better understand the varied viewpoints of her participants , and to recognize her own learning and construction of knowledge [ 34 ] . Design study researchers have signiﬁcant opportunities to adopt appropriate relativist epistemologies from other ﬁelds by investing in methods for generating , reporting , sharing , and using constructed knowledge . Four rigor criteria embrace the inherent subjectivity of design study : understanding and leveraging the role of the researcher through a RE - FLEXIVE design process ; TRANSPARENT communication of her effects ; and the development of PLAUSIBLE claims from observations and analysis that is INFORMED by appropriate epistemology . Design study produces diverse knowledge claims . The knowledge that design study researchers construct varies greatly in topic , form , and range . In line with the perspective developed here , we deﬁne knowledge as something a design study researcher comes to know through an inquiry . Design study researchers’ focus on context - informed development and use of technology allows them to learn various things in multiple ways and at multiple scales about : • visualization idioms : particular graphical representations of data , how well they support activities in particular contexts , and how broadly they might apply • design guidelines and methods : effective ways of developing solutions and undertaking visualization design and design study • problem domains : the relationships between people , data , and technology , situated within a speciﬁc domain . This diversity of topics stems from learning acquired through the practice of design as well as through purposeful examination of the existing world . In this way , design study knowledge construction reﬂects approaches taken in both RtD and the social sciences . The diverse forms of knowledge expression in design study vary from the use of words , mathematical notation , and pseudo - code , to diagrams , imagery , and design artifacts . This broad deﬁnition of knowledge – from design and relativist perspectives on knowledge construction [ 42 , 101 ] – implies that a design study researcher produces a knowledge expression every time an observation is recorded , a sketch is generated , or code is manipulated . In recording details about a situation and a design solution , such as what is said , what is implied , how an encoding is used , and the choices embedded in a successful design , an explicit act of abstraction occurs . The design study researcher decides which details are meaningful , which are not , and how they will be recorded . Whether jotting down observations , sketching design ideas , or manipulating materials like code , data , or other design media , the researcher abstracts details of a situation into a new , interpreted knowledge expression . An important , and contentious , characteristic of knowledge claims concerns their range : the amount of the explainable world to which they apply [ 100 ] . The range can be considered an indication of the generality of the knowledge along a continuum from the particular to the general , and everything in between [ 52 ] . Design study researchers produce knowledge across this range . They produce particular knowl - edge through the design process that focuses on the current problem and context . This knowledge is speciﬁc and situated , such as a detailed and rich description of a domain expert and the ways she uses a visu - alization tool . Design study researchers also construct more general knowledge by engaging in the analytical activity of abstracting details of the situated design context into knowledge with a broader range . This form of more general knowledge is sometimes termed theory . Debates in the social sciences [ 4 , 52 , 102 ] , information systems [ 45 , 100 ] , and RtD [ 59 ] literature offer various perspectives on the point at which knowledge becomes theory . The implication that the general is more valuable than the particular is often subtle , but sometimes explicit : “We do not regard a collection of facts , or knowledge of an individual fact or event , as theory” [ 45 ] . From the relativist perspective , however , even situated , speciﬁc knowledge expressions involve theory , as “there cannot be theory - free knowledge because a person’s understanding of reality is only known through their experiences ( i . e . , knowledge is socially constructed and thus fallible ) ” [ 102 ] . Where theory begins on this continuum is contested , but the most important issue , particularly in the design study research context , is the tension between the ex - planatory potential of the general and the explanatory accuracy of the speciﬁc . Siponen [ 100 ] offers nuanced descriptions of valuable theory types across the range , which include “grand , wide range , middle range , small range , narrow range , very narrow range , and unique” , and notes that narrowly scoped , particular theories , for example , can have great potential for practical impact . Like RtD , design study produces knowledge claims that range from the ultimate particular – the manifestation of a desired reality in a design artifact [ 105 ] – to the middle - range – a more abstracted concept than a particular instance that does not aspire to the generality of theory [ 59 ] . A design study paper often presents knowledge claims across this part of the range . For example , in our paper about a design study with energy analysts [ 43 ] , we offered , among others , the following claims , ordered from the most general to the most speciﬁc : • The explicit use of creativity methods as contributing positively to novel , effective , and well - aligned visualization solutions . • The design concept of data sculpting for interacting with energy - model outputs through a graphical interface . • A software artifact – called demand horizons – that instantiated the data sculpting metaphor for use in comparing the energy consumption of household appliances and scheduling their use . The construction of diverse forms of knowledge through design study is supported by six criteria for rigor : REFLEXIVE and INFORMED practice allows the researcher to recognize learning and develop general concepts ; ABUNDANT evidence is used to develop both speciﬁc and general knowledge ; and TRANSPARENT recording and reporting such that evidence and analysis produce knowledge claims that are both PLAUSIBLE and RESONANT to the broader community . 4 S IX C RITERIA FOR R IGOR Our intention is to develop a set of complimentary criteria that help researchers in making varied , diverse , and appropriate decisions about how to rigorously conduct design study . These criteria , presented in summary in Table 1 of supplemental materials , are drawn from es - tablished criteria and principles in the social sciences and design in support of the interpretivist perspective of design study we present in Section 3 . We are striving to provide guidance on what to achieve in a design study , and providing suggestions for transferring existing methods from cognate disciplines to achieve this , as opposed to dic - tating how it should be done . We leave it to design study researchers to decide , and argue for , how best to achieve these criteria given the speciﬁc people , data , and context involved in a study , and in light of the claims that they make and their own research skills and design expertise . The six rigor criteria we propose are applicable to many of the current approaches used in conducting design study . We note that it is unlikely , and indeed unnecessary , that a single design study can meet them all . Like designers , design study researchers work within constraints ; it is up to the researcher to choose methods and report persuasively , guided by the criteria and informed by the context . It is up to the reader to assess the extent to which a report supports the criteria . The development of these criteria spanned a four - year period of deep engagement with literature about rigor in the social sciences , and to a lesser extent the literature from design . Our investigations began with our discovery of the action design research methodology [ 97 ] , which resonated with our experiences of conducting design study [ 72 ] . This methodology is grounded in seven principles , but ultimately relies on Lincoln and Guba’s notion of trustworthiness [ 66 ] for establishing rigor . As we struggled to pragmatically understand the four trustworthiness criteria – credibility , dependability , conﬁrmability , and transferability – and relate them to design study we engaged with the extensive debates in the social science literature surrounding rigor , trustworthiness , and the tensions between realist and interpretivist perspectives on knowl - edge . Interpretivist perspectives pointed us to Tracy’s eight big - tent criteria [ 110 ] , which provide an extended , and updated view on uni - versal criteria for quality in interpretivist research . The extent of the debates on rigor also encouraged us to develop bespoke criteria for design study informed by these perspectives but speciﬁc and targeted to the research approaches , views , and culture of the visualization commu - nity . Through an iterative , dialogic process of deﬁning and redeﬁning existing criteria , applying them to our work and that of colleagues , our redeﬁnitions slowly took on new views of rigor , settling into the set of six inter - related criteria presented here . In Table 1 of supplemental materials , we list the points of reference from the action design research principles , trustworthiness criteria , and big - tent criteria that informed each proposed criterion for rigor in design study research . 4 . 1 INFORMED Existing knowledge informs design and facilitates new interpretations . It is important to approach design study with a prepared mind [ 40 ] , that is , with a broad awareness of visualization idioms , design guide - lines and methods , and assessment techniques [ 96 ] ; the disciplinary underpinnings of visualization – core topics and area boundaries , onto - logical and epistemological positions , socio - cultural views [ 1 , 91 ] ; and relevant design materials like datasets , code , software , hardware , and physically manipulable materials . Existing knowledge serves as a back - drop against which to grapple with and make sense of the design chal - lenge and the research inquiry , from providing a broad consideration space for designing new solutions , to selecting appropriate methods and for interpreting the nuances of the situation under study . Researchers make sense of the things they observe and experience through relations to existing knowledge , helping to identify and connect the things they learn as they construct new knowledge [ 1 , 12 , 91 ] . Research informed by existing knowledge supports interesting , meaningful , and new insights and interpretations . Besides preparation based on existing literature about visualization , such as textbooks [ 83 ] and academic papers , design practice emphasizes the value of an extensive repertoire of examples to serve as a library of ideas and knowledge from which to pull [ 6 , 20 , 59 ] . A designer uses this knowledge - base when considering options for creating visualizations : the broader the base the more likely the designer is to consider good ones [ 29 , 59 , 93 , 96 ] . Designers draw on existing knowledge not only to directly transfer relevant techniques and methods to the problem at hand , but also to facilitate ideation on possibly new approaches . The abstracted nature of some knowledge , however , contrasts with the speciﬁcity of designing a visualization artifact in a particular context . A guideline like “spatial encoding is most effective” [ 15 , 53 ] cannot inform all the design details of a complex , visualization technique like a curvemap [ 79 ] . Visualization idioms such as overview + detail or the treemap cannot dictate how to speciﬁcally balance the competing needs of designing for complex datasets that provide a partial picture of more complex phenomena , diverse participants , and real - world analysis tasks . Design methods cannot ( and should not [ 2 , 42 , 105 ] ) inform every step that a designer takes when ideating , making , and assessing . Instead , through a preparation for action , a designer “acts on a situation with a regard for all of its richness and complexity , and in a way that is appropriate for the speciﬁcs of that situation” [ 105 ] . Through careful consideration of the context of a situation against a backdrop of existing knowledge a designer shapes the design process and artifacts into new knowledge expressions that are “informed by current theory , creating an ongoing dialog between what is and what might be . ” [ 118 ] . 4 . 2 REFLEXIVE We a   ect the research , and the research a   ects us . Embracing the subjective nature of much of the knowledge estab - lished through design study is essential given its situated , collabora - tive , and wicked characteristics . Doing so requires a reﬂexive per - spective that “embraces not detachment but engagement as the road to knowledge” [ 12 ] . Reﬂexivity [ 34 , 110 ] is explicit and thoughtful self - awareness of a researcher‘s own role in a study , grounded by the perspective that observed realities are multiple and constructed [ 24 , 35 , 101 , 102 ] . While positivism values objectivity and detachment , interpretivism values a focus on how we actively construct our knowl - edge [ 35 ] . Reﬂexivity addresses this by identifying how a researcher’s own biases and motivations shape the research process , inﬂuence par - ticipants and the observations she makes , and how the research process changes her own thinking and actions . Reﬂexivity accounts for , and leverages , the inherent subjectivity of design study researchers . Over the years , reﬂexivity in qualitative research has broadened and evolved [ 34 ] , with a number of uses of reﬂexivity that are particularly relevant for design study : identifying a researcher‘s assumptions , re - actions , emotions , and blind - spots ; developing empathy to enable a researcher to see perspectives other than her own [ 22 ] ; and recognizing moments of learning that can form the basis of more general concepts . Many existing methods for encouraging , supporting , and reporting reﬂexive practice developed in the social sciences are candidates for useful application to design study research . Before beginning a study , reﬂexive researchers can assess both their readiness as well as their biases through reﬂection on questions such as : Why am I doing this research ? Am I prepared ? What are my expectations and assumptions ? What is my moral and ethical stance towards the situation under study ? As the study proceeds , a reﬂexive researcher continually examines her own impact on and within the study , and is sensitive to other participants’ responses to them , as well as to the voices and other sources of information that may be missing . Perspectives from critical theory [ 26 ] , feminism [ 32 ] , and broad consideration of the ethics of the research [ 17 ] provide many other important reﬂexive considerations . Reﬂexive examinations can help ensure shaping of both the design solution and the problem by pointing to opportunities for input from other perspectives [ 72 , 97 ] . Reﬂexivity is encouraged throughout the research process , and can be achieved via observation , reﬂection , note - taking , discussions with colleagues and participants , and open , authentic accounts in reporting . Autoethnography [ 25 , 31 ] is a speciﬁc approach that applies reﬂexive investigation to self - observation . Reﬂexive notes – in the form of a dedicated diary [ 1 ] or as additions to ﬁeld notes – are important as both a tool for supporting reﬂexivity as well as for record - keeping of insights , impacts , and decisions regarding design and research . These notes are a way to capture a researcher‘s impressions of a situation ; her own emotions , responses , hunches , and surprises ; and her self - dialogue about ethical considerations and con - cerns , such as power dynamics and hidden voices [ 17 ] . Often written as a ﬁrst person account , they remind the reader of the presence of the researcher within the study . These ﬁrst - person accounts also emphasize a self - as - instrument perspective , which can allow researchers to use their own experiences and tacit knowledge as a valid source of data to support interpretation of a situation [ 110 ] . Discussions with colleagues are another valuable tool for reﬂexivity . Engaging a critical friend puts the researcher in “a critical dialogue , with researchers giving voice to their interpretations in relation to other people who listen and offer critical feedback to encourage reﬂexivity by challenging each others‘ construction of knowledge . . . providing a theoretical sounding board to encourage reﬂection upon , and explo - ration of , multiple and alternative explanations and interpretations as these emerge in relation to the data and writing” [ 102 ] . Through the solicitation of feedback from a critical friend , a researcher confronts the understandability of her descriptions , the soundness of her reasoning , and the depth of her interpretation . Additionally , alternative views of - fered by a critical friend are a reminder to the researcher that for every constructed view , there are other , alternative interpretations [ 115 ] . De - sign critiques – where a designer engages with other designers through a critical , public dialog about a design artifact – serve a similar , critical function for examining the merits of design artifacts [ 7 ] . Additionally , expressing and explaining constructed knowledge to colleagues through formal structured presentations – whether early in the process when presenting work - in - progress , or later in the form of a pre - paper talk – provides opportunities for critical - friend feedback as a researcher is actively constructing knowledge expressions . The review ( and sometimes rebuttal ) processes for academic papers are another form of critique that can encourage reﬂexive thinking on the part of the researcher . In short , seeking continual , critical feedback from a variety of sources can activate reﬂexivity throughout a design study . 4 . 3 ABUNDANT More is better . Design study is valued for the rich , complex , and varied nature of the contexts in which researchers generate knowledge . This calls for the study itself “to be at least as complex , ﬂexible , and multifaceted as the phenomena being studied . . . it takes a complicated sensing device to register a complicated set of events . ” [ 110 ] . A design study with abundance has rich details ; many voices , datasets , contexts , and designs ; and signiﬁcant time in the ﬁeld . Abundant data that is rich in details and varied in perspectives , supports multiple meaningful interpretations that are nuanced and situated . And a design process that is shaped by many perspectives [ 72 , 97 ] and emerges from many tested alternatives [ 29 ] is likely to lead to better designs . Questions about abundance a researcher can ask include : Did I spend enough time to gather meaningful and diverse data ? Are there enough data and detail to support meaningful claims ? Did I consider enough design alternatives to justify the visualizations ? Are diverse voices used to shape the design and interpretations ? Abundance provides opportunities to uncover , relate , understand , and justify meaningful insights . How much is enough ? Answering this question is complex and reliant on the context and constraints of any individual study ; however , a prevalent theme in the qualitative research literature is when a re - searcher reaches saturation . Saturation occurs when adding more data , perspectives , designs , or contexts leads to no new insights . Even though pragmatic advice on how to reach saturation is scarce , “explaining what saturation means within the context of a study is essential” [ 5 ] . One important research tool that is used widely in interpretive re - search and that can contribute to abundance is thick description , which is “the researcher’s task of both describing and interpreting observed social action ( or behavior ) within its particular context” [ 86 ] . Thick descriptions themselves are an “in - depth illustration that explicates culturally situated meanings and abundant concrete detail” [ 110 ] . They consist of rich , nuanced , and detailed accounts of observed actions and the intentionality of those actions , as well as the thoughts , feelings , and responses of participants to those actions . In contrast to thin descrip - tion , which aims to report observations independently of intentions or context , thick description is purposefully interpretive rather than explanatory [ 23 ] . Thick descriptions are important for design study research as they provide rich evidence of the speciﬁcs of a situation – whether it be of visualization usage , a reaction to a design possibility , a social interaction among group members , or the logging of an in - sight [ 109 ] . These situations can involve a researcher observing others , but they can also include a reﬂexive researcher’s own thoughts on , feel - ings about , and behaviors within the study . This rich , personal evidence supports interpretation and abundant reporting of experiences that allow the researcher and others to construct more general knowledge . Abundant , diverse , and detailed data collection beneﬁts from long - term , sustained collaboration [ 66 , 98 ] , as well as from participatory [ 81 ] and co - design [ 92 ] methods . These approaches build trust , develop agency , and invite interest in the design process , supporting deep en - gagement between the designer and the domain experts [ 67 ] . We have known this engagement to help reveal meaningful contextual insights that can shape the design , at times in profound ways [ 43 ] , as well as to provide nuanced insights into the situation under study [ 73 ] . Creative visualization - opportunity workshops [ 61 ] are a speciﬁc participatory method that can support multivocal abundance , which is the incorpo - ration of multiple and varied voices in the design process to include viewpoints that diverge from those of the majority or with the researcher herself . These workshops also encourage an abundance of ideas for problems and solutions through rapid divergence exercises . Rapid , and parallel [ 43 ] , prototyping supports shaping of the design through an abundance of perspectives and constraints . Quickly trying multiple ideas encourages generative thinking [ 29 ] , while creating op - portunities for participants to provide feedback that shapes a design . Zimmerman points to a need to record these “design moves , the ratio - nale for these moves , and how different hunches did and did not work out” [ 120 ] . Thick description provides a compelling medium . More is better in many ways , but more may also be more difﬁcult to record , process , relate , and communicate . It may take more resources and more time . It may disrupt the creative design process [ 25 ] . While thick description of design decisions and their rationale may provide important information , collecting , creating , and recording more ideas , more data , more explanations , and more designs is a threat to the design process and the effective synthesis of knowledge . Efﬁcient methods for thorough recording in ways that are not disruptive but manage a rich , abundant , and diverse evidence base are essential . Literate visualization [ 116 ] is one approach that aims to make design exposition an integral and efﬁcient part of the visualization design process , with ﬂexible templates for supporting reﬂexive practice and structured documents that aim to address the data management issue . 4 . 4 PLAUSIBLE Knowledge claims are evidenced , appropriate , and persuasive . Plausible knowledge claims made in the context of subjective , inter - pretivist inquiry are supported by sufﬁcient evidence that is compared , related , combined , and linked in appropriate ways . They are expressed explicitly and persuasively , and they are built coherently from evidence through sound justiﬁcations . That is , observations are representative of the phenomena and processes under study , and interpretations – in - cluding those that are expressed through a design concept or artifact – are detailed , thorough , coherent , and congruent with what is experi - enced , observed , and reported . Constructing and reporting plausible knowledge claims requires researchers to provide abundant and com - plementary evidence that is structured and presented in coherent ways . Plausible knowledge claims give others the conﬁdence to use them . The plausibility of particular knowledge claims – a participant used a visualization in this way – is heavily reliant upon a researcher’s use of appropriate design processes and methods of data collection and analysis . Thick description , reﬂexive notes , and careful curation of design artifacts support the recording and reporting of plausible , particular knowledge claims . Interpretivist approaches call for an ex - plication of a researcher’s subjective perspective , such as her point of view , experiences , values , and biases that inﬂuence the way she inter - prets the world and constructs an understanding of it [ 30 ] , emphasizing the interrelationships between plausibility and reﬂexive knowledge construction . The plausibility of more general claims – this is a meaningful vi - sualization design concept – instead relies on reﬂexive , analytical knowledge construction . Researchers generalize from speciﬁc , situated details to broader , more abstracted concepts through a process of ana - lytic generalization [ 36 ] . Polit & Beck describe the process as being one where the researcher “distinguishes between information that is relevant to all ( or many ) study participants , in contrast to aspects of the experience that are unique to particular participants . . . [ it ] is a matter of identifying evidence that supports that conceptualization” [ 85 ] . A predominant method for interpretation and knowledge construction in design study is reﬂection : “a process by which experience is brought into consideration . . . to achieve meaning and the capacity to look at things as potentially other than they appear” [ 10 ] . The nine - stage framework for conducting design studies emphasizes reﬂection as a crucial activity [ 96 ] , but pragmatic guidance in the visualization liter - ature for how and when to reﬂect is sparse , with many variations in reﬂective practices and expectations for documentation among design study researchers [ 76 ] . An interpretivist approach for encouraging and recording reﬂection is that of memo writing . Memos are informal analytic notes that “catch your thoughts , capture the comparisons and connections you make , and crystallize questions and directions for you to pursue” [ 13 ] . While a researcher engages with her materials and observations , memo writing can spur new ideas and insights through a ( reﬂexive ) conversation - with - self . Careful tracking of memos with underlying data can form a rich account of a researcher’s reﬂective analytic process and reasoning , offering evidence in support of the plausibility of a broad range of knowledge claims . Similarly , explicit recording of design decisions and their justiﬁcations through literate visualization supports reﬂection , interpretation , and analysis while also documenting the process [ 116 ] . Using multiple forms of analysis with a diverse set of rich and re - ﬂexive observations strengthens the plausibility of general knowledge claims . A design study researcher might combine contextual inter - views [ 58 ] with a workshop [ 61 ] to establish an initial understanding of a problem domain , using reﬂective transcriptions [ 73 ] to interpret the interviews and open - coding to analyze the outputs of the workshop . She might then ideate on possible visualization solutions through rapid prototyping of storyboards [ 44 ] , reﬁne her ideas based on feedback gathered through speed - dating [ 47 ] , and reﬂexively develop a visualiza - tion software artifact using literate visualization [ 116 ] . Through critical reﬂection on the artifact against the backdrop of existing visualization idioms , she develops a persuasive justiﬁcation for , and rich description of a new visualization technique , appropriately scoped to address some , or all of the problems identiﬁed . Her report includes both a thick de - scription of how people used the visualization tool and an annotated demo of the system . A diverse approach to design study has similarities with crystalliza - tion [ 33 ] . This approach from the social sciences involves contrasting and synthesizing multiple observations , contexts , types of data , meth - ods – which may even rely upon different theoretical frameworks – to understand and present a complex situation under study . The goal of crystallization is “not to provide researchers with a more valid singular truth , but to open up a more complex , in - depth , but still thoroughly partial , understanding of the issue . ” [ 111 ] There is no one way to develop plausible knowledge claims . Design study researchers can , and should be ﬂexible and creative with the methods they employ , while being mindful that the methods and repre - sentation practices are coherent with the study’s goals and constraints . 4 . 5 RESONANT The research inspires understanding and invites action . Research emerges from design study when it “adds to the body of knowledge and allows other researchers to beneﬁt from the work” [ 96 ] . Research that resonates inspires and affects researchers , designers , practitioners , and others who might use the knowledge . It moves , educates , challenges , and changes them , eliciting deeper understanding , empathy , and knowing . Two speciﬁc mechanisms with which design study research can meaningfully impact a visualization audience is through transferability and evocative reports . Not every design study must resonate in the same way , but like any interpretative research , all high - quality design studies must have impact [ 110 ] . Resonant research impacts others in the world . Transferability can occur when a reader believes that the situation under study overlaps in meaningful ways with her own ; supporting , motivating , and inspiring a transfer of knowledge from one context to another [ 36 , 66 , 98 ] . For example , in a design study with neuroscientists , we found similarities in our challenge of gaining consensus with those described in a paper about a design study with energy analysts [ 43 ] . In that paper the authors detailed their use of a workshop to overcome this challenge – we transferred this method to our context , and found it to be effective for working with our collaborators as well [ 62 ] . To support transferability , researchers need to abundantly and re - ﬂexively describe experiences , observations , and abstracted concepts with detailed descriptions and interpretations so that readers can de - termine similarities to and differences from their own contexts [ 101 ] . Using prose , such as thick description , is one effective way to do so . Both researchers and readers “share a responsibility when it comes to assessing the value of a particular set of qualitative research ﬁndings beyond the context and particulars of the original study” [ 14 ] . When evaluating the potential for transferability , a reader can ask : Do the relevant characteristics of the study’s context remind me of others ? Researchers can enhance transferability through rich descriptions of the relevant characteristics of the context that seem important contributors to the knowledge they are claiming . These descriptions facilitate read - ers in making judgments about which contexts are similar enough to transfer [ 85 ] . The use of familiar data sets and data abstractions when demonstrating a new visualization design is likely to facilitate transfer . Evocative reports inspire new understanding , empathy , and action . Inspiration stems from research reports and design artifacts that en - courage the audience to feel , think , interpret , react , or change . Tracy suggests that “like a good song or good piece of pie , an [ evocative ] qual - itative report is not boring . It surprises , delights , and tickles something within us . ” [ 110 ] We have experienced this kind of delight with vari - ous good pieces of a visualization pie : the wobbly topography demos provided by Willett et al . in support of their lightweight relief shearing technique [ 114 ] ; the ﬂuid interactions and elegant encodings used in the UpSet tool [ 65 ] ; the rich , thick descriptions of participant reactions to a personal data system in their homes [ 109 ] ; and Georgia Lupi’s ex - pressive designs of Kaki King’s music shown during her capstone talk at IEEE VIS 2017 [ 70 ] . Sedlmair further suggests that a good problem with which readers can associate makes the value of the design study clear [ 95 ] . Although the predominant focus in qualitative research is on evocative written reports that require creative , complex , and beautiful prose , design study offers additional evocative reporting media like design artifacts that invite interaction and engagement , narrated videos , data stories [ 89 ] , and other forms of imagery , annotation , and narrative . Rich details make an evocative report resonate , just as they allow a knowledge expression to transfer . These details could be thoroughly interpreted descriptions of the research context and observations , the full implementation and realization of a design concept into an arti - fact , or a portfolio of annotated designs . In RtD , annotated portfolios support transfer in evocative ways by communicating a designer’s sub - jective , abstract view of what is interesting across a portfolio of designs . Annotations “modestly and speculatively reach out beyond the particu - lar” [ 6 ] by highlighting similar design characteristics , considerations , and contributions . Explicit links between the annotations and design particulars encourage others to interpret and transfer alternative ideas . In contrast to reports of controlled studies , which strive for precision and neutrality , it is the opportunity for resonance through rich , evoca - tive , reﬂexive , and situated details that makes design study and other interpretive research approaches so compelling . 4 . 6 TRANSPARENT The reporting invites scrutiny . A design study is not reproducible , nor should it be . The relativist perspective of design study considers knowledge to be constructed by the researcher , and to present one of many , plausible mind - dependent realities . Neither observations nor the interpretations derived from them reproduce . Even the same researcher may not develop the same inter - pretations were she to go through the same process . This diversity in potential research outcomes is also a characteristic of RtD where “there is no expectation that others following the same process would produce the same or even a similar ﬁnal artifact” [ 118 ] . Knowledge claims from design study are not subject to the positivist notion of reliability : “applying reliability criteria to qualitative research is incompatible with the belief that theory - free knowledge is unachievable and that realities are subjective , multiple , changing , and mind - dependent” [ 102 ] . Instead , judgements about the quality of the research need to be made in the context of what was done , how it was done , and why it was done . Transparent descriptions of activities , processes , evidence , and claims allow judgments about the other criteria to be made . Where knowledge is particular and constructed through interpreta - tion , richly abundant and reﬂexive descriptions of observations , experi - ences , and the knowledge construction process enable readers to make judgments about their plausibility . These need to be documented in a manner that is thorough and ﬁndable , and invites scrutiny . For design artifacts – an important form of particular knowledge – transparency poses an additional challenge : “much of the value of prototypes as carri - ers of knowledge can be implicit or hidden . They embody solutions , but the problems they solve may not be recognized . ” [ 104 ] While knowl - edge about the speciﬁc visual and interaction techniques embedded within a visualization is visually accessible , the domain problem the visualization is meant to address is not . The RtD community has called for the need for explicit descriptions of this hidden , implicit knowledge to support its transfer [ 21 , 103 , 105 , 118 ] . For visualization , a data and task abstraction [ 82 ] is one established way of communicating implicit knowledge ingrained in a visualization artifact : it is an operationaliza - tion of the problem that the visualization is meant to solve . Reporting a data and task abstraction is thus one way of increasing the transparency of particular knowledge that is embedded in a visualization artifact . For more general knowledge that is constructed from these partic - ulars , the quality of the analysis through which generalizations are achieved is central to plausibility claims . Transparent reporting of the analysis and supporting evidence that provides a sense of verisimilitude and vicariousness enables readers to better determine “if the ﬁndings ring true” [ 98 ] . Furthermore , providing transparent access to underly - ing evidence allows others to perform different analyses , potentially in combination with evidence from another study , to construct different insights , interpretations , and knowledge . Transparent reporting should be self - critical and include errors , failures , analytical dead ends – the joys and mistakes [ 110 ] of the research process – with sincerity and frankness . Reports on design study are typically achieved through an academic paper [ 96 ] , where researchers document their process , their designs , and their evidence in support of knowledge contributions . These ﬁxed - length reports , however , are not “friends” of thick description [ 85 ] and richly reﬂexive details [ 35 ] . Design study papers can be , and increasingly are , supplemented with additional materials that allow for richer details for supporting knowledge claims , including images , software , videos , observations , analysis , ﬁeld notes , reﬂexive notes , and audit trails . With increasing amounts of supplemental materials , however , a tension around transparency builds as making the materials navigable , searchable , and interpretable becomes increasingly difﬁcult . But , academic papers are just one way to report knowledge – might there be others for design study ? We highlight several transparency considerations for each of the other criteria : • INFORMED : justify design decisions with respect to existing knowl - edge ; explicate the theoretical , ontological , and epistemological stance of the research • REFLEXIVE : disclose reﬂexive notes and processes • ABUNDANT : make a rich body of data and evidence available , ﬁnd - able , and interpretable • PLAUSIBLE : provide clear , open , and honest descriptions of analysis processes ; release memos , design expositions , and other reﬂective documents ; report on dead - ends and failures • RESONANT : communicate implicit , hidden knowledge ingrained in artifacts to support transfer ; use problems , datasets , designs and narrative that speak to readers . These considerations emphasize the importance of transparency as a criterion to embrace throughout the design study , not just at the end . 5 Q UESTIONS F OR D EBATE In this paper we offer a perspective and set of criteria for visualization design study . This perspective emerged from our own experiences , wide reading , and ongoing discussions with each other and the broader community . Few of the ideas we present are new in themselves . But in combination , the selection of criteria we present , the identiﬁed means of supporting them , and the perspective they construct , point to new approaches and opportunities for research inquiry conducted with de - sign study . We acknowledge that this perspective has implications , and many open questions remain . Indeed , it is our intention to challenge perspectives , stimulate debate , and expose some of the implicit assump - tions and practices associated with design study . In this section we draw attention to some of these implications with open - ended questions that emerge from the perspective and criteria we propose . Is our ﬁeld prepared for rigorous design study ? Probably not . Visualization courses and textbooks tend not to discuss various ontologies and epistemologies or train visualization researchers in a broad range of methods for design and relativist inquiry [ 88 ] . Fur - thermore , design study already demands a very broad base of skills and knowledge – the abilities to code , wrangle digital data , create , design , and participate effectively in collaborations . Adding the skills and knowledge required to capture , record , and make sense of rich qualitative data may be a stretch for many . Making informed judg - ments about a design study as readers and reviewers will also require knowledge about these methods and their underpinnings , as well as an openness to interpretivist perspectives . Additionally , our current paper + supplementary structure and condensed review times act against the effective generation , exposition , and consideration of the kind of design study we advocate . Embracing a rigorous , interpretivist approach to design study , how - ever , is worth it . Design study can produce a diverse range of knowledge about the complex , messy , nuanced , and evolving relationships of peo - ple with data and technology . These insights are important for guiding visualization innovations that are relevant to the changing ways in which people create and consume visualizations in the world . Further - more , design study provides a means to deeply explore and understand how people relate to data , how data can ( and cannot ) positively inﬂu - ence decisions , and how data are changing society . We need rigorous research that considers the human - side of data science ; visualization design study is one way to do so . We do , however , recognize that advocating for more work , more skills , more time , and more rigor threatens to undermine the now wide - spread acceptance of design study as a valuable means of visualization research inquiry . Our intention is not to make rigorous design study unattainable , but to move the community towards a discussion about what the gold standards might be . Standards for rigor provide an opportunity to develop new , more efﬁcient approaches to design study by allowing us to better understand the trade - offs of various methods . Furthermore , all studies have ﬂaws and limitations ; we need criteria for rigor in order to understand them in the design study context to both improve the research inquiry and guide the review process . Visualization venues and forums increasingly support the discussion of research perspectives , such as the one that we advocate for design study . Related debate at and around the tutorials , panels , keynotes , and workshops held at IEEE VIS in recent years have partly inspired this work and the questions that we pose at the outset . As the visualization community continues to expand and diversify , we encourage colleagues to consider these perspectives , continue these discussions , clarify and develop their theoretical and philosophical underpinnings , read , reach out , and engage in the debate . Doing so will help us better understand , achieve , support , and assess rigor in design study . Are these criteria enough ? No . We offer criteria for planning and making judgments about the rigor in design study . But is rigorous work necessarily of high quality ? To this question we resoundingly answer : No ! Tracy’s big - tent criteria for high - quality qualitative research [ 110 ] heavily inﬂuenced our proposal . While some of these big - tent criteria are captured by those in our list , a number of them are not . Tracy argues that high - quality qualitative work must additionally consider criteria that capture the worthiness , relevance , timeliness , signiﬁcance , morality , and practicality of the research topic , as well as the ethical stance of the research itself . Several ethical considerations that relate to design study but are not yet deeply considered by the visualization community are the procedu - ral ethics associated with working with and focusing on other people ; ethical issues around funding sources and project focus ; and the ethics of exit . This latter consideration raises many interesting questions , but is rarely addressed directly in design study research . Do we leave the ﬁeld in a manner that has improved the knowledge , capabilities , and capacity of those with whom we work ? Are these the most important factors for participants ? Is design study research sustainable and beneﬁ - cial post - study from our collaborators’ perspectives ? Emerging efforts to develop perspectives on the ethics of data visualization [ 17 , 26 , 32 ] offer important , initial considerations for what we consider to be some of the missing criteria for high - quality design study . Does our ﬁeld have adequate disciplinary underpinnings ? No . During the four years we spent constructing the knowledge and ideas for this paper , we were continually surprised and excited about the depth of theorizing and degree of debating that occurs in ﬁelds related to , but outside , visualization . Every set of literature we reviewed about methodologies , rigor , and knowledge pointed us to new issues and com - plexities that we had not yet considered . As we addressed the challenge of saturation we began to wonder : Where is our disciplinary discourse on the philosophical and theoretical underpinnings of visualization ? Within the visualization community , these discussions happen pre - dominantly in informal and ephemeral venues , such as workshops , panels , and magazine articles . This makes understanding and collat - ing the views of the community on such issues as the ontological and epistemological positions of our work , or the nature of visualization theory , a real challenge . Our main publishing venues need ( imperfect , provocative , challenging ) papers that openly discuss and critique these sorts of ideas [ 3 ] . These papers are likely difﬁcult to publish under current reviewing standards as they present opinions and positions that are easily debatable and inherently fallible . We offer this work as one such example . Gregor suggests four questions that arise from considering the knowl - edge and theories that characterize a discipline [ 45 ] : 1 ) What are the core problems and interests , and what are the boundaries ? 2 ) What is theory , how is it composed and expressed , and what does it contribute ? 3 ) How is knowledge acquired , tested , and assessed ? 4 ) What are the socio - political considerations , including ethics , power , inclusion , and degree of consensus on these questions ? The visualization community needs to discuss these questions – publicly , critically , and frequently . 6 C ONCLUSION As a discipline , visualization has foundations in realism ; positivist approaches have enabled us to build an extensive knowledge base about machines , algorithms , and human responses to graphical stimuli . These approaches have contributed to the development of process mod - els [ 72 , 74 , 96 ] for studying people and their long - term problem - inspired interactions with data , and decision models [ 78 , 82 ] that guide us to desired outcomes , such as valid visualization software . The full range of knowledge that we might construct through these deep , complex , sustained , situated collaborations , however , is not currently well sup - ported by the predominant approaches , standpoints , and expectations within our discipline . We want to move away from the situation where the kind of knowledge that can be constructed through applied visu - alization research is questioned because descriptions and context are speciﬁc ; because applying the same process does not produce the same result ; because knowledge is preliminary rather than deﬁnitive ; because the research involves the subjective voice ; because the researcher shifts and shapes the context under study . In short the kind of richly situated and nuanced knowledge that we can establish through design study is incompatible with positivist positions . The perspective developed in this paper addresses this concern by embracing relativism . It is based upon our synthesis of a wide - body of work in related disciplines : we read literature , attended conferences , and engaged with members of these communities . The thinking in these ﬁelds on the nature of knowledge and the ways it is constructed in a whole range of contexts through inquiry and design is overwhelming in its extent and impressive in its depth . It is also consistently contra - dictory , surprisingly dynamic , and gloriously imperfect . The thinking will never be complete . We draw upon this body of work to tackle multiple interrelated aims : To be explicit about what we do in design study , why we do it , and what it allows us to know . To consider the ways in which design and research , theory and practice interrelate . To understand the relationships between the particular and the general , and ensure that we value both kinds of knowledge if we consider them to be legitimate . To help us make informed decisions about legitimacy itself . To explore philosophical positions and provide methodological foundations that can change the ways that we approach , create , assess , and use situated knowledge from design study . We reposition design study as a rich , subjective , and interpretative approach to visualization research inquiry that can be rigorously applied to wicked real - world problems , to construct valuable new knowledge . We argue that when established with rigor , such knowledge comple - ments research undertaken from a positivist perspective , contributing beneﬁcially to the wider discipline . Core to this repositioning are six preliminary criteria that contribute to rigor in visualization design study research , which should be conducted and reported in ways that are INFORMED , REFLEXIVE , ABUNDANT , PLAUSIBLE , RESONANT & TRANSPARENT . The criteria are inherently dynamic , contradictory , and imperfect knowledge constructs . We purposefully scope them narrowly to achieve rigor in design study , and note that they do not completely cover the broader considerations necessary for high - quality research . We spec - ulate , however , that the criteria , and our perspective , may transfer to other methods , approaches , and contexts beyond visualization design study . We hope that they spark dialogue and debate – about design study , applied visualization research , and the underpinnings of the dis - cipline more broadly – and so move our ﬁeld forward in interesting and productive ways . A CKNOWLEDGMENTS This work has been informed by lengthy and active discussions with many colleagues in numerous places over a long period . In particular we thank Nina McCurdy and Jonas L¨owgren for deeply inﬂuential con - tributions to our thinking . We also thank Geraldine Fitzpatrick , Ethan Kerzner , Alex Lex , Julienne Meyer , Torsten M¨oller , Michael Sedlmair , Brett Smith , Jason Wiese , Jo Wood and four engaged and widely in - formed reviewers for provocative critical conversations . Katharine Coles , @ jamesscottbrown and @ antarcticdesign had late effects . R EFERENCES [ 1 ] M . Attia and J . Edge . Be ( com ) ing a reﬂexive researcher : a developmental approach to research methodology . Open Rev . of Ed . Res . , 4 ( 1 ) : 33 – 45 , 2017 . [ 2 ] A . Bigelow , S . Drucker , D . Fisher , and M . Meyer . Reﬂections on how designers design with data . In Proc . 2014 International Working Conf . on Advanced Visual Interfaces - AVI ' 14 . ACM Press , 2014 . [ 3 ] L . Bongshin , K . Isaacs , D . Szaﬁr , G . Marai , C . Turkay , M . Tory , S . Carpendale , and A . Endert . Broadening intellectual diversity in visual - ization research papers . IEEE Comp . Gr . & Apps . , 2019 . [ 4 ] R . Boudon . What middle - range theories are , 1991 . [ 5 ] G . A . Bowen . Naturalistic inquiry and the saturation concept : a research note . Qual . Res . , 8 ( 1 ) : 137 – 152 , 2008 . [ 6 ] J . Bowers . The logic of annotated portfolios : communicating the value of ‘research through design’ . In Proc . Designing Int . Sys . , pp . 68 – 77 . ACM , 2012 . [ 7 ] R . Brath and E . Banissi . Evaluation of visualization by critiques . In IEEE Beyond Time and Errors ( BELIV ) ' 16 . ACM Press , 2016 . [ 8 ] V . Braun and V . Clarke . Successful qualitative research : A practical guide for beginners . Sage : Thousand Oaks , CA , 2013 . [ 9 ] M . Brehmer , S . Ingram , J . Stray , and T . Munzner . Overview : The design , adoption , and analysis of a visual document mining tool for investigative journalists . IEEE TVCG , 20 ( 12 ) : 2271 – 2280 , 2014 . [ 10 ] A . Brockbank and I . McGill . The action learning handbook : powerful techniques for education , professional development and training . Rout - ledge , 2003 . [ 11 ] R . Buchanan . Wicked problems in design thinking . Design Issues , 8 ( 2 ) : 5 – 21 , 1992 . [ 12 ] M . Burawoy . The extended case method . Soc . Theory , 16 ( 1 ) : 4 – 33 , 1998 . [ 13 ] K . Charmaz . Constructing grounded theory : A practical guide through qualitative analysis . Sage : Thousand Oaks , CA , 2006 . [ 14 ] R . J . Chenail . Getting speciﬁc about qualitative research generalizability . Journal of Ethnographic & Qual . Res . , 5 ( 1 ) : 1 – 11 , 2010 . [ 15 ] W . S . Cleveland and R . McGill . Graphical perception : Theory , exper - imentation , and application to the development of graphical methods . Journal of the Am . Stat . Assoc . , 79 ( 387 ) : 531 – 554 , 1984 . [ 16 ] T . D . Cook and D . T . Campbell . The design and conduct of true experi - ments and quasi - experiments in ﬁeld settings . In Research in Organiza - tions : Issues and Controversies . Goodyear , 1979 . [ 17 ] M . Correll . Ethical dimensions of visualization research . arXiv preprint arXiv : 1811 . 07271 , 2018 . [ 18 ] A . Crisan and M . Elliott . How to evaluate an evaluation study ? comparing and contrasting practices in vis with those of other disciplines : Position paper . In IEEE Evaluation and Beyond ( BELIV ) , pp . 28 – 36 . IEEE , 2018 . [ 19 ] N . Cross . Designerly ways of knowing . Design Studies , 3 ( 4 ) : 221 – 227 , 1982 . [ 20 ] N . Cross . Design research : A disciplined conversation . Design Issues , 15 ( 2 ) : 5 – 10 , 1999 . [ 21 ] N . Cross . From a design science to a design discipline : Understanding designerly ways of knowing and thinking . In Design Research Now , pp . 41 – 54 . Springer , 2007 . [ 22 ] M . Dadds . Empathetic validity in practitioner research . Ed . Action Research , 16 ( 2 ) : 279 – 290 , 2008 . [ 23 ] N . K . Denzin . The elephant in the living room : or extending the conver - sation about the politics of evidence . Qual . Res . , 9 ( 2 ) : 139 – 160 , 2009 . [ 24 ] N . K . Denzin and Y . S . Lincoln . Handbook of qualitative research thousand oaks . 1994 . [ 25 ] I . Dillingham , J . Dykes , and J . Wood . A design , analysis and evalua - tion model to support the visualization designer - user . In IEEE Conf . on Information Visualization ( InfoVis ) , 2012 . [ 26 ] M . D¨ork , P . Feng , C . Collins , and S . Carpendale . Critical infovis : ex - ploring the politics of visualization . In ACM Conf . Human Factors - CHI ' 13 . [ 27 ] K . Dorst and N . Cross . Creativity in the design process : co - evolution of problem – solution . Design Studies , 22 ( 5 ) : 425 – 437 , 2001 . [ 28 ] P . Dourish . Implications for design . In SIGCHI Conf . Human Factors , pp . 541 – 550 . ACM , 2006 . [ 29 ] S . P . Dow , A . Glassco , J . Kass , M . Schwarz , D . L . Schwartz , and S . R . Klemmer . Parallel prototyping leads to better design results , more diver - gence , and increased self - efﬁcacy . ACM Conf . Human Factors - CHI ' 10 , 17 ( 4 ) : 1 – 24 , 2010 . [ 30 ] J . Drucker . Humanities approaches to graphical display . Digital Humani - ties Quarterly , 5 ( 1 ) : 1 – 21 , 2011 . [ 31 ] M . Duncan . Autoethnography : Critical appreciation of an emerging art . Int . Jnl . of Qualitative Methods , 3 ( 4 ) : 28 – 39 , 2004 . [ 32 ] C . DIgnazio and L . F . Klein . Feminist data visualization . In Workshop on Visualization for the Digital Humanities ( VIS4DH ) . IEEE , 2016 . [ 33 ] L . L . Ellingson . Engaging crystallization in qualitative research : An introduction . Sage : Thousand Oaks , CA , 2009 . [ 34 ] L . Finlay . Negotiating the swamp : the opportunity and challenge of reﬂexivity in research practice . Qual . Res . , 2 ( 2 ) : 209 – 230 , 2002 . [ 35 ] L . Finlay . outing the researcher : The provenance , process , and practice of reﬂexivity . Qual . Health Res . , 12 ( 4 ) : 531 – 545 , 2002 . [ 36 ] W . A . Firestone . Alternative arguments for generalizing from data as applied to qualitative research . Ed . Researcher , 22 ( 4 ) : 16 – 23 , 1993 . [ 37 ] D . Fisher and M . Meyer . Making Data Visual : A Practical Guide to Using Visualization for Insight . ” O’Reilly Media , Inc . ” , 2017 . [ 38 ] C . Frayling . Research in art and design . RCA Research Papers , 1 ( 1 ) , 1994 . [ 39 ] C . Frayling . Research through Design : Closing Provocations , 2015 . [ 40 ] D . Furniss , A . Blandford , and P . Curzon . Confessions from a grounded theory phd : experiences and lessons learnt . In SIGCHI Conf . Human Factors , pp . 113 – 122 . ACM , 2011 . [ 41 ] B . Gaver and J . Bowers . Annotated portfolios . Interactions , 19 ( 4 ) : 40 – 49 , 2012 . [ 42 ] W . Gaver . What should we expect from research through design ? In SIGCHI Conf . Human Factors , pp . 937 – 946 . ACM , 2012 . [ 43 ] S . Goodwin , J . Dykes , S . Jones , I . Dillingham , G . Dove , A . Duffy , A . Kachkaev , A . Slingsby , and J . Wood . Creative user - centered visualiza - tion design for energy analysts and modelers . IEEE TVCG , 19 ( 12 ) : 2516 – 2525 , 2013 . [ 44 ] S . Greenberg , S . Carpendale , N . Marquardt , and B . Buxton . Sketching user experiences : The workbook . Elsevier , 2011 . [ 45 ] S . Gregor . The nature of theory in information systems . MIS Quarterly , pp . 611 – 642 , 2006 . [ 46 ] E . G . Guba and Y . S . Lincoln . Paradigmatic controversies , contradictions , and emerging conﬂuences . In The Sage handbook of qualitative research ( 3rd ed . ) , pp . 191 – 216 . Sage : Thousand Oaks , CA , 2005 . [ 47 ] B . Hanington and B . Martin . Universal methods of design : 100 ways to research complex problems , develop innovative ideas , and design effective solutions . Rockport Publishers , 2012 . [ 48 ] D . Haraway . Situated knowledges : The science question in feminism and the privilege of partial perspective . Feminist Studies , 14 ( 3 ) : 575 – 599 , 1988 . [ 49 ] S . Haroz . Open practices in visualization research : Opinion paper . In IEEE Evaluation and Beyond ( BELIV ) , pp . 46 – 52 . IEEE , 2018 . [ 50 ] S . Hauser , R . Wakkary , W . Odom , P . - P . Verbeek , A . Desjardins , H . Lin , M . Dalton , M . Schilling , and G . de Boer . Deployments of the table - non - table . In ACM Conf . Human Factors - CHI ' 18 . ACM Press , 2018 . [ 51 ] G . R . Hayes . The relationship of action research to human - computer interaction . ACM Conf . Human Factors - CHI ' 11 , 18 ( 3 ) : 1 – 20 , 2011 . [ 52 ] P . Hedstr¨om , R . Swedberg , and G . Hernes . Social mechanisms : An analytical approach to social theory . Cambridge University Press , 1998 . [ 53 ] J . Heer and M . Bostock . Crowdsourcing graphical perception : using mechanical turk to assess visualization design . In SIGCHI Conf . Human Factors , pp . 203 – 212 . ACM , 2010 . [ 54 ] A . Hevner and S . Chatterjee . Design science research in information systems . In Design research in Information Systems , pp . 9 – 22 . Springer , 2010 . [ 55 ] U . Hinrichs and S . Forlini . In defense of sandcastles : Research thinking through visualization in dh . In Conf . on Digital Humanities . International Alliance of Digital Humanities Organizations ( ADHO ) , 2017 . [ 56 ] U . Hinrichs , S . Forlini , and B . Moynihan . Speculative practices : Utilizing infovis to explore untapped literary collections . IEEE TVCG , 22 ( 1 ) : 429 – 438 , 2015 . [ 57 ] T . Hogan , U . Hinrichs , and E . Hornecker . The elicitation interview technique : capturing people’s experiences of data representations . IEEE TVCG , 22 ( 12 ) : 2579 – 2593 , 2016 . [ 58 ] K . Holtzblatt and S . Jones . Contextual inquiry : A participatory technique for system design . In Participatory design , pp . 177 – 210 . CRC Press , 2017 . [ 59 ] K . H¨o¨ok and J . L¨owgren . Strong concepts . ACM Conf . Human Factors - CHI ' 12 , 19 ( 3 ) : 1 – 18 , 2012 . [ 60 ] H . Hutchinson , W . Mackay , B . Westerlund , B . B . Bederson , A . Druin , C . Plaisant , M . Beaudouin - Lafon , S . Conversy , H . Evans , H . Hansen , et al . Technology probes : inspiring design for and with families . In SIGCHI Conf . Human Factors , pp . 17 – 24 . ACM , 2003 . [ 61 ] E . Kerzner , S . Goodwin , J . Dykes , S . Jones , and M . Meyer . A frame - work for creative visualization - opportunities workshops . IEEE TVCG , 25 ( 1 ) : 748 – 758 , 2019 . [ 62 ] E . Kerzner , A . Lex , C . L . Sigulinsky , T . Urness , B . W . Jones , R . E . Marc , and M . Meyer . Grafﬁnity : Visualizing connectivity in large graphs . Comp . Gr . Forum , 36 ( 3 ) : 251 – 260 , 2017 . [ 63 ] S . Lee , S . - H . Kim , Y . - H . Hung , H . Lam , Y . - a . Kang , and J . S . Yi . How do people make sense of unfamiliar visualizations ? : A grounded model of novice’s information visualization sensemaking . IEEE TVCG , 22 ( 1 ) : 499 – 508 , 2016 . [ 64 ] K . Lewin . Action research and minority problems . Journal of Social Issues , 2 : 34 – 46 , 1946 . [ 65 ] A . Lex , N . Gehlenborg , H . Strobelt , R . Vuillemot , and H . Pﬁster . Upset : visualization of intersecting sets . IEEE TVCG , 20 ( 12 ) : 1983 – 1992 , 2014 . [ 66 ] Y . S . Lincoln and E . G . Guba . Establishing trustworthiness . Naturalistic Inquiry , 289 : 331 , 1985 . [ 67 ] D . Lloyd and J . Dykes . Human - centered approaches in geovisualization design : Investigating multiple methods through a long - term case study . IEEE TVCG , 17 ( 12 ) : 2498 – 2507 , 2011 . [ 68 ] J . L¨owgren . Interaction design , research practices and design research on the digital materials . Under Ytan : Om Designforskning , pp . 150 – 163 , 2007 . [ 69 ] J . L¨owgren . Annotated portfolios and other forms of intermediate - level knowledge . Interactions , 20 ( 1 ) : 30 – 34 , 2013 . [ 70 ] G . Lupi . Data humanism - the revolution will be visualized . [ 71 ] M . L . Maher , J . Poon , and S . Boulanger . Formalising design exploration as co - evolution . In Advances in formal design methods for CAD , pp . 3 – 30 . Springer , 1996 . [ 72 ] N . McCurdy , J . Dykes , and M . Meyer . Action design research and visualization design . In IEEE Beyond Time and Errors ( BELIV ) ' 16 , pp . 10 – 18 . ACM , 2016 . [ 73 ] N . McCurdy , J . Gerdes , and M . Meyer . A framework for externalizing implicit error using visualization . IEEE TVCG , 25 ( 1 ) : 925 – 935 , 2019 . [ 74 ] S . McKenna , D . Mazur , J . Agutter , and M . Meyer . Design activity framework for visualization design . IEEE TVCG , 20 ( 12 ) : 2191 – 2200 , 2014 . [ 75 ] M . J . Melrose . Maximizing the rigor of action research : why would you want to ? how could you ? Field Methods , 13 ( 2 ) : 160 – 180 , 2001 . [ 76 ] M . Meyer and J . Dykes . Reﬂection on reﬂection in applied visualization research . IEEE Comp . Gr . & Apps . , 38 ( 6 ) : 9 – 16 , 2018 . [ 77 ] M . Meyer , T . Munzner , A . DePace , and H . Pﬁster . Multeesum : a tool for comparative spatial and temporal gene expression data . IEEE TVCG , 16 ( 6 ) : 908 – 917 , 2010 . [ 78 ] M . Meyer , M . Sedlmair , P . S . Quinan , and T . Munzner . The nested blocks and guidelines model . Information Visualization , 14 ( 3 ) : 234 – 249 , 2015 . [ 79 ] M . Meyer , B . Wong , M . Styczynski , T . Munzner , and H . Pﬁster . Path - line : A tool for comparative functional genomics . Comp . Gr . Forum , 29 ( 3 ) : 1043 – 1052 , 2010 . [ 80 ] J . M . Morse . Critical analysis of strategies for determining rigor in qualitative inquiry . Qualitative Health Research , 25 ( 9 ) : 1212 – 1222 , 2015 . [ 81 ] M . Muller and S . Kuhn . Participatory design . Commun . ACM , 36 ( 6 ) : 24 – 28 , 1993 . [ 82 ] T . Munzner . A nested model for visualization design and validation . IEEE TVCG , 15 ( 6 ) : 921 – 928 , 2009 . [ 83 ] T . Munzner . Visualization analysis and design . AK Peters / CRC Press , 2014 . [ 84 ] C . Nobre , N . Gehlenborg , H . Coon , and A . Lex . Lineage : Visualizing multivariate clinical data in genealogy graphs . IEEE TVCG , 25 ( 3 ) : 1543 – 1558 , 2019 . [ 85 ] D . F . Polit and C . T . Beck . Generalization in quantitative and qualitative research : Myths and strategies . Int . Jnl . of Nursing Studies , 47 ( 11 ) : 1451 – 1458 , 2010 . [ 86 ] J . G . Ponterotto . Brief note on the origins , evolution , and meaning of the qualitative research concept thick description . The Qualitative Report , 11 ( 3 ) : 538 – 549 , 2006 . [ 87 ] J . Redstr¨om . Research through Design : Opening Provocations , 2019 . [ 88 ] D . Rees and R . S . Laramee . A survey of information visualization books . In Comp . Gr . Forum , vol . 38 , pp . 610 – 646 . Wiley Online Library , 2019 . [ 89 ] N . H . Riche , C . Hurter , N . Diakopoulos , and S . Carpendale . Data - driven storytelling . CRC Press , 2018 . [ 90 ] H . W . Rittel and M . M . Webber . Wicked problems . Man - made Futures , 26 ( 1 ) : 272 – 280 , 1974 . [ 91 ] J . A . Rode . Reﬂexivity in digital anthropology . In SIGCHI Conf . Human Factors , pp . 123 – 132 . ACM , 2011 . [ 92 ] E . B . - N . Sanders . Information , inspiration and co - creation . In Proc . 6th International Conf . of the European Academy of Design . University of the Arts Bremen , 2005 . [ 93 ] D . A . Sch¨on . Educating the reﬂective practitioner . Jossey - Bass , 1987 . [ 94 ] C . Seale . Quality in qualitative research . Qual . Inq . , 5 ( 4 ) : 465 – 478 , 1999 . [ 95 ] M . Sedlmair . Design study contributions come in different guises . In IEEE Beyond Time and Errors ( BELIV ) ' 16 . ACM Press , 2016 . [ 96 ] M . Sedlmair , M . Meyer , and T . Munzner . Design study methodology : Reﬂections from the trenches and the stacks . IEEE TVCG , 18 ( 12 ) : 2431 – 2440 , 2012 . [ 97 ] M . K . Sein , O . Henfridsson , S . Purao , M . Rossi , and R . Lindgren . Action design research . MIS Quarterly , 35 ( 1 ) : 37 – 56 , 2011 . [ 98 ] A . K . Shenton . Strategies for ensuring trustworthiness in qualitative research projects . Education for Information , 22 ( 2 ) : 63 – 75 , 2004 . [ 99 ] C . T . Silva , J . Freire , and S . P . Callahan . Provenance for visualizations : Reproducibility and beyond . Comp . Sci . & Eng . , 9 ( 5 ) : 82 , 2007 . [ 100 ] M . Siponen and T . Klaavuniemi . Updating the philosophy of middle - range theories : Implications for IS . In Pac . Asia Conf . on Info . Sys . , 2018 . [ 101 ] B . Smith . Generalizability in qualitative research : misunderstandings , opportunities and recommendations for the sport and exercise sciences . Qual . Res . in Sport , Exercise and Health , 10 ( 1 ) : 137 – 149 , 2017 . [ 102 ] B . Smith and K . R . McGannon . Developing rigor in qualitative research : problems and opportunities within sport and exercise psychology . Int . Rev . of Sport and Exercise Psychology , 11 ( 1 ) : 101 – 121 , 2017 . [ 103 ] P . Stappers and E . Giaccardi . Research through design . The Encyclopedia of Human - Computer Interaction , 2nd ed . , pp . 1 – 94 , 2017 . [ 104 ] P . J . Stappers . Doing design as a part of doing research . Design Research Now , pp . 81 – 91 , 2007 . [ 105 ] E . Stolterman . The nature of design practice and implications for interac - tion design research . Int . Jnl . of Design , 2 ( 1 ) , 2008 . [ 106 ] P . T . Sukumar and R . Metoyer . Towards designing unbiased replication studies in information visualization . In IEEE Evaluation and Beyond ( BELIV ) , pp . 93 – 101 . IEEE , 2018 . [ 107 ] N . Sultanum , D . Singh , M . Brudno , and F . Chevalier . Doccurate : A curation - based approach for clinical text visualization . IEEE TVCG , 25 ( 1 ) : 142 – 151 , 2019 . [ 108 ] A . Thudt , C . Perin , W . Willett , and S . Carpendale . Subjectivity in personal storytelling with visualization . Information Design Journal , 23 ( 1 ) : 48 – 64 , 2017 . [ 109 ] P . Tolmie , A . Crabtree , T . Rodden , J . A . Colley , and E . A . Luger . “this has to be the cats” - personal data legibility in networked sensing systems . In Proc . 19th ACM Conf . on Computer - Supported Cooperative Work & Social Computing - CSCW ' 16 . ACM Press , 2016 . [ 110 ] S . J . Tracy . Qualitative quality : Eight “big - tent” criteria for excellent qualitative research . Qual . Inq . , 16 ( 10 ) : 837 – 851 , 2010 . [ 111 ] S . J . Tracy . Qualitative research methods : Collecting evidence , crafting analysis , communicating impact . John Wiley & Sons , 2012 . [ 112 ] R . H . Von Alan , S . T . March , J . Park , and S . Ram . Design science in information systems research . MIS Quarterly , 28 ( 1 ) : 75 – 105 , 2004 . [ 113 ] J . Walny , S . Huron , C . Perin , T . Wun , R . Pusch , and S . Carpendale . Active reading of visualizations . IEEE TVCG , 24 ( 1 ) : 770 – 780 , 2018 . [ 114 ] W . Willett , B . Jenny , T . Isenberg , and P . Dragicevic . Lightweight relief shearing for enhanced terrain perception on interactive maps . In ACM Conf . Human Factors - CHI ' 15 , pp . 3563 – 3572 . ACM , 2015 . [ 115 ] H . F . Wolcott . Transforming qualitative data : Description , analysis , and interpretation . Sage : Thousand Oaks , CA , 1994 . [ 116 ] J . Wood , A . Kachkaev , and J . Dykes . Design exposition with literate visualization . IEEE TVCG , 25 ( 1 ) : 759 – 768 , 2019 . [ 117 ] Y . Zhang , K . Chanana , and C . Dunne . Idmvis : Temporal event sequence visualization for type 1 diabetes treatment decision support . IEEE TVCG , 25 ( 1 ) : 512 – 522 , 2019 . [ 118 ] J . Zimmerman and J . Forlizzi . Research through design in hci . In Ways of Knowing in HCI , pp . 167 – 189 . Springer , 2014 . [ 119 ] J . Zimmerman , J . Forlizzi , and S . Evenson . Research through design as a method for interaction design research in hci . In SIGCHI Conf . Human Factors , pp . 493 – 502 . ACM , 2007 . [ 120 ] J . Zimmerman , E . Stolterman , and J . Forlizzi . An analysis and critique of research through design : towards a formalization of a research approach . In Proc . Designing Int . Sys . , pp . 310 – 319 . ACM , 2010 . Table 1 . Criteria , their rationale , and suggested ways in which they might be achieved in rigorous visualization design study . Concepts from the literature that informed these criteria are listed with citations . INFORMED Existing knowledge informs design and facilitates new interpretations . Important as Research informed by existing knowledge supports interesting and meaningful insights and interpretations . Achievable by using text books , academic papers and technical documentation to develop knowledge of visualization and the domain in which you are working ; seeking opportunities to broaden your exposure to a range of design ideas Informed by rich - rigor [ 110 ] ; theory - ingrained artefacts [ 97 ] REFLEXIVE We a   ect the research , and the research a   ects us . Important as Reﬂexivity accounts for , and leverages the inherent subjectivity of design study researchers . Achievable by making reﬂexive note - taking core to research and design activity ; striving to recognize and record moments of learning ; adopting a structured approach to reﬂective questioning ; ﬁnding opportunities and allocating time for critique , and using critical feedback to develop your interpretations – consider using autoethnography , critical friends , design critique , structured presentations of work and ideas in progress , engagement with the rebuttal processes involved in peer review Informed by conﬁrmability [ 66 ] ; sincerity [ 110 ] ; mutually inﬂuential roles , guided - emergence [ 97 ] ABUNDANT More is better . Important as Abundance provides opportunities to uncover , relate , understand , and justify meaningful insights . Achievable by soliciting diverse voices and varied perspectives ; seeking and explaining saturation ; developing thick descriptions of observations and interpretations ; investing in long - term , sustained collaboration ; using participatory and co - design methods , such as creative visualization - opportunity workshops ; prototyping rapidly and in parallel ; explaining and recording as you design with literate visualization Informed by credibility [ 66 ] ; rich - rigor , credibility [ 110 ] ; authentic & concurrent evaluation [ 97 ] PLAUSIBLE Knowledge claims are evidenced , appropriate , and persuasive . Important as Plausible knowledge claims give others the conﬁdence to use them . Achievable by writing memos to develop and capture observations , ideas , and connections ; striving for diversity in analysis and observations ; developing rich accounts of reﬂective analytic process and reasoning by relating memos to observations and each other ; making knowledge claims explicit and persuasive through sound justiﬁcations ; considering crystallization to compare , relate , combine , and link a diverse body of evidence Informed by credibility , dependability [ 66 ] ; rich - rigor , credibility & meaningful coherence [ 110 ] RESONANT The research inspires understanding and invites action . Important as Resonant research impacts others in the world . Achievable by selecting problems to which others will relate ; providing rich , evocative , and situated details of context in reports through thick description ; designing artifacts that invite engagement ; aiming to have a   ect in your communication – move , educate , and challenge those who receive your message ; explaining and demonstrating with narrated videos , data stories , annotated imagery , or annotated portfolios ; speculating on opportunities for transfer Informed by transferability [ 66 ] ; worthy topic , resonance [ 110 ] ; TRANSPARENT The reporting invites scrutiny . Important as Transparent descriptions of activities , processes , evidence and claims allows judgments about the other criteria to be made . Achievable by creating data and task abstractions that contextualize designs ; producing rich , comprehensive reports of the research process that are sincere , frank , and self - critical ; reporting fully and reﬂexively on dead - ends and failures ; using e   ective , creative , and extensive supplementary materials ; developing a thorough , ﬁndable , annotated evidence base to support claims providing an audit trail Informed by dependability , conﬁrmability [ 66 ] ; sincerity [ 110 ]