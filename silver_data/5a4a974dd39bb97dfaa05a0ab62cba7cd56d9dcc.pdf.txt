Proceedings on Privacy Enhancing Technologies ; 2020 ( 4 ) : 175 – 195 Tommi Gröndahl * and N . Asokan * Eﬀective writing style transfer via combinatorial paraphrasing Abstract : Stylometry can be used to proﬁle or deanonymize authors against their will based on writ - ing style . Style transfer provides a defence . Current techniques typically use either encoder - decoder archi - tectures or rule - based algorithms . Crucially , style trans - fer must reliably retain original semantic content to be actually deployable . We conduct a multifaceted eval - uation of three state - of - the - art encoder - decoder style transfer techniques , and show that all fail at semantic retainment . In particular , they do not produce appro - priate paraphrases , but only retain original content in the trivial case of exactly reproducing the text . To mit - igate this problem we propose ParChoice : a technique based on the combinatorial application of multiple para - phrasing algorithms . ParChoice strongly outperforms the encoder - decoder baselines in semantic retainment . Additionally , compared to baselines that achieve non - negligible semantic retainment , ParChoice has superior style transfer performance . We also apply ParChoice to multi - author style imitation ( not considered by prior work ) , where we achieve up to 75 % imitation success among ﬁve authors . Furthermore , when compared to two state - of - the - art rule - based style transfer techniques , ParChoice has markedly better semantic retainment . Combining ParChoice with the best performing rule - based baseline ( Mutant - X [ 34 ] ) also reaches the highest style transfer success on the Brennan - Greenstadt and Extended - Brennan - Greenstadt corpora , with much less impact on original meaning than when using the rule - based baseline techniques alone . Finally , we highlight a critical problem that aﬄicts all current style transfer techniques : the adversary can use the same technique for thwarting style transfer via adversarial training . We show that adding randomness to style transfer helps to mitigate the eﬀectiveness of adversarial training . Keywords : style transfer , style imitation , stylome - try , adversarial stylometry , author proﬁling , proﬁling , deanonymization , model evasion DOI 10 . 2478 / popets - 2020 - 0068 Received 2020 - 02 - 29 ; revised 2020 - 06 - 15 ; accepted 2020 - 06 - 16 . 1 Introduction Freedom of speech and privacy are threatened by ad - vances in artiﬁcial intelligence , including natural lan - guage processing ( NLP ) . In particular , stylometry can be used to identify or proﬁle anonymous authors based on writing style [ 65 , 68 ] . Institutions or individuals can use stylometry to deanonymize whistle - blowers and dis - sidents [ 7 , 8 , 60 ] . Deanonymization can put authors in danger of harassment [ 3 ] or even legal repercussions [ 34 ] . Accordingly , author deanonymization or proﬁling con - stitutes an attack on privacy [ 7 , 24 , 47 , 51 ] . As a defence , the author can use style transfer . This process can consist of several transformations , i . e . changes applied to the input text . Prevalent approaches are based on encoder - decoder networks [ 17 , 43 , 58 , 63 , 64 , 70 , 71 , 73 ] , but more traditional rule - based tech - niques also continue to be used [ 36 , 45 , 61 ] . Importantly , style transfer is distinguished from mere style - speciﬁc generation [ 32 , 35 ] by the requirement of semantic re - tainment : the transformed text should express equiva - lent content to the original . Using both automatic and manual metrics , we con - duct a detailed performance evaluation of three state - of - the - art style transfer techniques based on encoder - decoder networks [ 58 , 63 , 64 ] ( Sections 5 – 6 ) . The aim of these techniques is to produce a style - neutral encod - ing of the original sentence’s content , and then generate the same content in the target style . However , they all fail at producing acceptable paraphrases ( Section 6 . 1 . 1 ) . Semantic retainment only succeeds in the trivial case of reproducing the input . * Corresponding Author : Tommi Gröndahl : Aalto University , Konemiehentie 2 , 02150 Espoo , Finland , E - mail : tommi . grondahl @ aalto . ﬁ * Corresponding Author : N . Asokan : University of Water - loo , 200 University Ave W , Waterloo , ON N2L 3G1 , Canada , E - mail : asokan @ acm . org Eﬀective writing style transfer via combinatorial paraphrasing 176 Such results motivate a reconsideration of alterna - tive approaches , in particular automatic paraphrasing . We propose a novel style transfer technique based on combinatorial paraphrase generation , and style speciﬁc paraphrase selection . The technique , which we call Par - Choice , is inspired by prior work in rule - based style transfer ( Section 2 ) [ 36 – 40 , 45 , 46 , 48 , 61 ] but involves substantial additions to existing techniques . In Section 4 we discuss the paraphrasing algorithms in detail . We compare ParChoice with the three encoder - decoder baselines on four author proﬁling datasets de - rived from original work presenting the baselines ( Sec - tion 6 ) . ParChoice outperforms them all in semantic re - tainment , especially clearly in human evaluation ( Sec - tion 6 . 1 . 1 ) . In style transfer performance , ParChoice sur - passes those baselines that achieve non - negligible se - mantic retainment ( Section 6 . 1 . 2 ) . Additionally apply - ing ParChoice to ﬁve - author style imitation , we achieve up to 75 % imitation success ( Section 6 . 1 . 2 ) . We also compare ParChoice to two rule - based tech - niques that have demonstrated strong performance in prior research [ 36 , 45 ] ( Section 6 . 2 ) . Experimenting on the Brennan - Greenstadt corpus and the Extended - Brennan - Greenstadt corpus [ 7 ] , we demonstrate that ParChoice exerts less semantic changes than either base - line . Furthermore , even though one baseline ( Mutant - X [ 45 ] ) achieves a higher style transfer performance than ParChoice alone , applying them both in succession sig - niﬁcantly improves the performance of both . This com - bined application of ParChoice and Mutant - X also re - tains semantics better than Mutant - X alone . Finally , aﬀecting all state - of - the - art style transfer techniques ( including ParChoice ) we highlight a serious general problem . A strong adversary who is aware of the style transfer technique can employ adversarial train - ing : using the style transfer technique for adding trans - formed examples to the training data . We demonstrate that adversarial training thwarts all three encoder - decoder baseline techniques [ 58 , 63 , 64 ] as well as ParChoice , typically with only a minor nega - tive impact on original proﬁling accuracy ( Section 6 . 3 ) . However , adversarial training fails if paraphrase selec - tion in ParChoice is random , which indicates that the problem can be partly mitigated by conducting the transformations randomly instead of using a speciﬁc tar - get style . We discuss the relation between style transfer and adversarial training , and suggest directions for fu - ture research on this problem ( Sections 6 . 3 – 7 ) . We summarize our contributions below . – We present ParChoice : a style transfer technique based on combinatorial paraphrasing ( Section 4 ) . – By comparing ParChoice with three encoder - decoder baselines [ 58 , 63 , 64 ] and two rule - based baselines [ 36 , 45 ] , we demonstrate that : – ParChoice retains semantic information better than any baseline ( Sections 6 . 1 . 1 , 6 . 2 . 1 ) . – ParChoice ’s style transfer performance exceeds those encoder - decoder baselines that achieve non - negligible semantic retainment ( Section 6 . 1 . 2 ) . – ParChoice signiﬁcantly outperforms both rule - based techniques in semantic retainment , while ParChoice combined with Mutant - X [ 45 ] per - forms the best in style transfer ( Section 6 . 2 ) . – We demonstrate that the adversary can counter style transfer by adversarial training , except if para - phrases are selected randomly ( Section 6 . 3 ) . We dis - cuss possible reasons for this ﬁnding , and propose ways in which it can be taken into account in future work on style transfer . – We make the code for implementing our original contributions available . 1 2 Background Author attribution via stylometry has traditionally fo - cused on standard machine learning ( ML ) algorithms and feature engineering [ 1 , 22 , 33 , 56 , 68 , 74 ] , but deep learning methods have become more prominent in re - cent years [ 4 , 9 , 19 , 67 ] . While there is no unanimous agreement on the most eﬀective features [ 22 , 24 , 33 ] , the Writeprints feature set has been widely applied with success [ 1 – 3 , 15 , 47 , 53 , 74 ] . Properties beyond personal identity have also been detected from writing style , including gender and age [ 61 , 62 ] . We denote the detection of any author attribute as ( author ) proﬁling , deanonymization being a special case . We use the term ( author ) proﬁler for ML classiﬁers used for proﬁling . Mitigating author proﬁling requires style transfer , i . e . transforming writing style but not semantic content . Back - and - forth machine translation provides a simple but highly limited technique [ 3 , 7 , 10 , 14 , 44 ] , as it does not allow targeting or avoiding any particular style . Another classical alternative is rule - based paraphrase replacement from knowledge bases [ 12 , 36 – 40 , 45 , 61 ] , 1 https : / / gitlab . com / ssg - research / mlsec / parchoice / Eﬀective writing style transfer via combinatorial paraphrasing 177 Techniques Transformations applied [ 40 , 46 ] synonym replacement from WordNet [ 45 , 61 ] word embedding neighbour replacement [ 38 ] word replacement from GNU Diction [ 26 ] , hand - crafted rules [ 12 ] synonym replacement from FreeLing [ 54 ] , hand - crafted rules [ 36 ] synonym / hypernym / deﬁnition replacement from WordNet or PPDB , hand - crafted rules Table 1 . Prior rule - based style transfer techniques . which we expand on with ParChoice . Table 1 summa - rizes prior rule - based style transfer techniques . As opposed to rule - based paraphrasing , recent style transfer research has heavily concentrated on sequence - to - sequence mapping via encoder - decoder networks [ 17 , 43 , 58 , 63 , 64 , 70 , 71 , 73 ] . Such techniques aim at pro - ducing a style - neutral encoding of the original sentence , which serves as the input to a style - speciﬁc decoder . Their main diﬀerences concern the training algorithms used to enforce ( i ) the style - neutrality of the latent en - coding , ( ii ) the style - speciﬁcity of the decoding , ( iii ) and semantic retainment . In Section 6 , we evaluate the per - formance of three state - of - the - art techniques that aim at reaching ( i ) – ( iii ) by diﬀerent means [ 58 , 63 , 64 ] . As our results illustrate , none attain all three simultaneously . 3 Problem statement The entities involved in style transfer are the author and the adversary . The author belongs to a class C 1 , which is a set of authors . A special case of such a class is author identity , which is a singleton set containing only the au - thor . The adversary has an author proﬁler P , which is a ML classiﬁer used to proﬁle texts by author class . We denote the predicted class of a text T as P ( T ) . If the au - thor has written T , proﬁling succeeds when P ( T ) = C 1 and fails otherwise . As a defence , the author produces a transformed text T ∗ . She 2 succeeds in style transfer if P ( T ∗ ) 6 = C 1 , and succeeds in imitating another class C 2 6 = C 1 if P ( T ∗ ) = C 2 . Style transfer and imitation are thus assimilated in two - class settings . Adversary models : The adversary can access labeled proﬁler training data , which he uses to train the author 2 For notational convenience , we denote the author as “she” and the adversary as “he” . Architecture Training data Same Diﬀerent Same Query access Architecture access Diﬀerent Data access Surrogate access Table 2 . Author types based on how the author’s surrogate pro - ﬁler relates to the adversary’s author proﬁler . proﬁler P . The labels include the author’s true class C 1 . The adversary also accesses a text written by the author ; this being originally unknown to the adversary . He proﬁles the text with P and receives P ’s prediction of the text’s author class . In the baseline scenario the text is T , i . e . the original unmodiﬁed text . In style transfer scenarios it is T ∗ , i . e . T transformed by the author . We distinguish between two adversary types . The weak adversary has no access to the author’s style trans - fer technique , and trusts the proﬁling result . The strong adversary knows the particular style transfer technique used by the author , and can use the same technique to transform any other text he accesses . To thwart style transfer he can use adversarial training , i . e . re - training the author proﬁler with transformed training data . Assumptions : The author can either perform random transformations , or select transformations to avoid or target a speciﬁc style . For the latter , she needs a sur - rogate proﬁler , which is a ML classiﬁer trained on sur - rogate training data . We distinguish between diﬀerent author types by the surrogate proﬁler’s relation to the adversary’s proﬁler P . If the surrogate proﬁler is the same as P , the au - thor has query access . Alternatively , the surrogate pro - ﬁler can diﬀer from P in model architecture or training data , giving her data access or architecture access , re - spectively . Finally , the weakest author only has access to a surrogate proﬁler that is distinct from P in both ar - chitecture and training data . This surrogate access rep - resents the most realistic use scenario . We summarize the diﬀerent access variants in Table 2 . 4 Design of ParChoice Figure 1 shows an overview of the ParChoice pipeline . It consists of two stages : ( i ) paraphrase generation , which takes an input document and generates a set of para - phrase candidates ( 4 . 1 ) ; and ( ii ) paraphrase selection , which selects the candidate closest to the target writing style ( 4 . 2 ) . In this section , we explain each stage . Eﬀective writing style transfer via combinatorial paraphrasing 178 D Grammaticaltransformations Simple rules WordNet Paraphrase generation D T Paraphraseselection PPDB Typos Simple rules Paraphrase replacement Fig . 1 . ParChoice pipeline 4 . 1 Paraphrase generation Our paraphrase generation stage consists of four mod - ules , which we discuss in 4 . 1 . 1 – 4 . 1 . 3 . We generate the Cartesian product of all transformations , with the aim of producing maximally varied paraphrases . We call this approach combinatorial paraphrasing . 4 . 1 . 1 Grammatical transformations Grammar is a crucial aspect of writing style , and espe - cially important for maintaining content - neutrality in stylometry [ 29 , 30 ] . Yet , prior style transfer approaches have not systematically applied grammatical transfor - mations ( Section 2 ) . A possible reason for this has been the lack of available techniques . We used a recent tool developed by Gröndahl and Asokan , obtaining the same model used in the origi - nal work presenting it [ 23 ] . This technique is based on three tasks : ( i ) generating an abstract representation of Sentence ( category ) Transformations ( category ) John saw Mary . ( active ) Mary was seen by John . ( passive ) John didn’t see Mary . ( negated , active ) Mary wasn’t seen by John . ( negative , passive ) I don’t think ( that ) John saw Mary . ( aﬃrmed , active ) I don’t think ( that ) Mary was seen by John . ( aﬃrmed , passive ) Did John see Mary ? ( question , active ) Was Mary seen by John ? ( question , passive ) Is it ( true ) that John saw Mary ? ( declarative , active ) Is it ( true ) that Mary was seen by John ? ( declarative , passive ) Table 3 . Examples of grammatical transformations ( added preﬁxes in italics ) . the sentence ( “EAT” ) derived from its dependency parse [ 69 ] ; ( ii ) transforming EAT according to targeted gram - matical features ; and ( iii ) generating an English sen - tence from the transformed EAT via a NMT network . The NMT network consists of an encoder and a decoder , both of which are LSTMs . It has been trained to trans - late EATs to English on a large corpus , consisting of 8 . 5 million sentences derived from multiple open - source cor - pora . For further details , we refer to the original paper [ 23 ] . All our transformations target only the main verb of the sentence . We explain the transformations below , and Table 3 shows examples . Voice : We produced both active and passive variants of transitive verbs , which take both a subject and a direct object in the active voice . The direct object of an active clause is expressed as the subject in a passive clause , and the subject of an active clause is expressed in the passive via the preposition by . Negation : In addition to using the negative particle not / n’t , an aﬃrmative sentence can be negated by em - bedding it in a clause that states its falsity . We produced the aﬃrmed version of an originally negated sentence , and wrapped it in the context : I don’t think ( that ) ( . . . ) . The non - contracted variant I do not think ( that ) ( . . . ) was later automatically produced in the paraphrase re - placement stage ( Section 4 . 1 . 2 ) . Questions : To paraphrase a polar ( yes - no ) question , we ﬁrst transformed it to a declarative variant , which we then appended to the preﬁx Is it ( true ) that ( . . . ) . For negative questions , we additionally generated the aﬃrmed declarative variant embedded in Is is not ( true ) that ( . . . ) and Isn’t it ( true ) that ( . . . ) . 4 . 1 . 2 Paraphrase replacement After grammatical transformations we applied para - phrase replacement using simple rules and two external paraphrase corpora : PPDB [ 18 ] and WordNet [ 50 ] . We used the order simple → PPDB → WordNet → simple . Eﬀective writing style transfer via combinatorial paraphrasing 179 The ﬁrst application of simple rules increased the range of inputs for PPDB , and their re - application at the end further expanded the range of paraphrases considered for selection . PPDB was applied before WordNet since it retained semantics better ( Section 6 . 1 . 1 ) , and thus this order was less likely to propagate errors . Simple rules : We manually programmed a small set of rules to produce simple transformations . First , we take the presence or absence of commas as having only a marginal eﬀect on interpretation , and hence allowed commas to be optionally removed . Second , we treated the following as paraphrases : 3 { not , n’t } { am , ’m } { are , ’re } { have , ’ve } { nobody , no - one } { anybody , anyone } { somebody , someone } Third , we replaced equivalent modal auxiliaries . However , some are only equivalent in either an aﬃrmed or a negated context , but not both . The context is negated if the auxiliary precedes a negation ( not / n’t ) , and aﬃrmed otherwise . We therefore distinguished be - tween equivalent modal auxiliary groups in aﬃrmed and negated contexts . We additionally appended ought with the preposition to ( following the negation in negated contexts ) , and conversely removed to if ought was re - placed with another auxiliary . The following sets display the equivalent modal auxiliary groups we used : Aﬃrmed context { might , may , could , can } { should , ought , must } { will , shall } Negated context { can , could } { should , ought , must } { will , shall } PPDB : The Paraphrase Database ( PPDB ) is a par - allel corpus of paraphrases , annotated with additional semantic and syntactic information [ 18 , 55 ] . PPDB - paraphrases have been used for author proﬁling [ 59 ] , indicating that they are relevant for writing style . How - ever , they have been less prevalent in rule - based style transfer than WordNet ( Table 1 ) . This may be due to diﬃculties in their direct application , which we discuss below and help overcome in ParChoice . 3 We only produced the contraction ’ve after a pronoun in { I , you , we , they } , and the contracted negation n’t after an auxiliary in { is , are , was , were , have , has , had , wo ( variant of will ) , must , should , need , ought , could , can , do , does , did } . Syntactic context Phrase Paraphrase [ NN ] restriction constraint [ VB ] co - operate collaborate [ S / VP ] i am sorry to have to i regret to [ S / S ] i am sorry i regret Table 4 . Example PPDB entries . ( NN : noun , VB : verb , S : sentence , VP : verb phrase ) We restricted our use of PPDB to the equivalent class , comprising 245691 paraphrase pairs . We derived these from the “ PPDB - TLDR ” version . 4 However , sim - ply replacing a phrase with a random PPDB - paraphrase easily leads to ungrammaticality due to context eﬀects . We remedied this problem with a grammatical ﬁlter that only allowed entries that ﬁt the syntactic context spec - iﬁed in the PPDB - entry . Examples of PPDB - entries are shown in Table 4 . Single - word paraphrases include the part - of - speech ( POS ) tag , and multi - word paraphrases contain the syn - tactic context in the format [ X / Y ] . X describes the orig - inal phrase , and Y the phrase immediately following it in the original context . Phrases are higher - level syntac - tic objects than words , and receive their grammatical status from their head word [ 11 ] . For example , the ﬁ - nal row of Table 4 is interpreted as i am sorry being paraphrasable as i regret , when followed by a sentence . We obtained the POS - tags and phrase structure of the original sentence with the Spacy parser [ 31 ] . 5 For each word n - gram in the sentence , we detected the largest phrase immediately following it , and used this to restrict paraphrase replacement . For single - word para - phrases we used the POS tag instead . This grammati - cal ﬁltering algorithm drastically reduced ungrammat - ical paraphrases produced via PPDB - replacement , and we believe it to be useful in future work on automatic paraphrasing extending beyond style transfer . WordNet : As a manually built knowledge base of word senses , WordNet [ 50 ] represents possible word meanings along with multiple semantic properties , including syn - onyms . Word senses are stored as uninﬂected lemmas . While WordNet has commonly been used in rule - based style transfer [ 36 , 40 , 45 , 46 , 48 ] , the lemma format is a major limitation in its direct application . In contrast to prior studies , we inﬂected the Word - Net lemmas , signiﬁcantly increasing their range of ap - 4 http : / / paraphrase . org / # / download . 5 https : / / spacy . io / Eﬀective writing style transfer via combinatorial paraphrasing 180 plication . We created a dictionary from lemmas to their surface manifestations with diﬀerent POS and inﬂec - tion tags , deriving these from a large text corpus . 6 We then inﬂected synonyms of the original word based on its POS and inﬂection tag , and produced paraphrase candidates with each inﬂected synonym . For word sense disambiguation [ 52 ] , we used the simple Lesk algorithm from Python’s WSD library . 7 4 . 1 . 3 Typos Typographical errors have demonstrated success at evading text classiﬁcation [ 25 , 42 ] . However , given the vast number of possible misspellings and their varying eﬀects on readability , introducing them randomly is not justiﬁable . We used a simple typo algorithm of option - ally removing an apostrophe , as in you’re → youre . Ad - ditionally , we introduced typos that appear in the tar - get corpus of the surrogate training data . For obtaining these we used the Python port of SymSpell , 8 applying it to the target corpus and storing a dictionary from cor - rect spellings to possible misspellings . We additionally spell - checked the original sentence and included origi - nal typos to this typo dictionary . This allowed either retaining original typos or correcting them , depending on their eﬀects on paraphrase selection . Unlike other paraphrasing mechanisms , typos are reversible via spell - checking . The full paraphrase gener - ation pipeline is not reversible : since a paraphrase could correspond to a very large number of possible inputs , it is practically impossible to ﬁnd the correct input from the paraphrase alone . However , as typos are an impor - tant aspect of stylistic variation [ 1 , 7 , 27 ] , removing them at pre - processing can potentially reduce the accu - racy of author proﬁling . Our empirical results ( Section 6 . 1 . 2 ) indicate that their eﬀectiveness at style transfer varies across datasets , but is usually not the most im - portant factor . 6 We used the POS tagger of NLTK [ 6 ] . We obtained the in - ﬂected lemmas from the same corpus of 8 . 5 million sentences that was used for training the NMT network used for grammat - ical transformations [ 23 ] ( Section 4 . 1 . 1 ) . As the inﬂected variant of a lemma , we chose the most common surface form associated with a lemma - tag combination in the tagged corpus . 7 https : / / github . com / alvations / pywsd 8 https : / / github . com / wolfgarbe / SymSpell 4 . 2 Paraphrase selection We selected the paraphrase candidate by a surrogate proﬁler , which is a local author proﬁler trained on sur - rogate training data ( Section 3 , Table 2 ) . In sentence - level experiments ( Section 6 . 1 ) , we chose the candidate that was assigned the highest diﬀer - ence between target and source class probabilities by the surrogate proﬁler . While this metric assimilates to the lowest source - class probability ( or the highest target - class probability ) in two - class settings , in multi - class settings these probabilities come apart . This allows us to perform imitation instead of mere style transfer ( Sec - tions 3 , 6 . 1 . 2 ) . In document - level experiments ( Section 6 . 2 ) we replicated a genetic algorithm - based paraphrase selec - tion method from our best - performing rule - based base - line technique : Mutant - X [ 45 ] . This selection performs only style transfer instead of imitation . We ﬁrst pro - duced a set of candidates by paraphrasing a random sentence in the document . Following Mutant - X , we then ranked the candidates based on the probability of mis - classiﬁcation ( using query access to the author proﬁler ) , and METEOR score with the original document . The best - performing candidates were then used as inputs for further iterations of the same process . Sections 5 . 3 . 2 and 5 . 3 . 3 further discuss the parameters used for Mutant - X and the document - based ParChoice variant . 5 Experiments In this section we describe the datasets ( 5 . 1 ) , evalu - ation setup ( 5 . 2 ) , and style transfer techniques ( 5 . 3 ) used in our experiments . We compared ParChoice with three encoder - decoder baseline techniques on four two - class sentence - level datasets . We additionally applied ParChoice to multi - author imitation on a ﬁve - class sentence - level dataset . Finally , we compared ParChoice with two rule - based baseline techniques on four multi - class document - level datasets . 5 . 1 Datasets The encoder - decoder baseline techniques [ 58 , 63 , 64 ] use sentences as inputs , and are only applicable to two - class data . The rule - based baselines [ 36 , 45 ] are tailored for multi - author datasets of multi - sentence documents . We used datasets speciﬁcally tailored for the baselines . Par - Eﬀective writing style transfer via combinatorial paraphrasing 181 Dataset Classes Training set size Test set Proﬁler Surrogate size YG female , male 2577862 386678 10000 BA adult , teen 2637850 395676 10000 AB Alice , Bob 25319 3797 1176 TO Trump , Obama 20860 3128 4668 Table 5 . Sentence - based datasets ( size : number of sentences ) . Choice is applicable to all of them , which illustrates its ﬂexibility across diﬀerent use cases . 5 . 1 . 1 Sentence - based datasets We used four two - class corpora , one labeled by gender , one by age , and two by author identity . In the gen - der and age experiments , we replicated the setups of two encoder - decoder baselines [ 58 , 64 ] . We divided each dataset to a larger proﬁler training set , a smaller surro - gate training set ( 15 % of proﬁler training set size ) , and a test set . The original datasets are available on GitHub . 9 Size - related information is presented in Table 5 . Yelp Gender ( YG ) : This dataset consists of restau - rant reviews labeled by gender [ 61 ] . It contains two training sets , which results in partially divergent data / architecture access between the baselines . We dis - cuss this in more detail in Section 5 . 3 . 1 . Blog Age ( BA ) : The blog dataset [ 62 ] contains blog posts labeled by authorship , gender , and age . We exper - imented on age proﬁling . 10 Alice - Bob ( AB ) : We extracted two authors from BA : a female in the age range 13 − 19 , and a male in the age range 23 − 40 . We call them Alice and Bob , respectively . Trump - Obama ( TO ) : This dataset includes speeches by Barack Obama and Donald Trump [ 64 ] . We were able to improve proﬁling accuracy markedly by truncating 9 YG : https : / / github . com / shrimai / Style - Transfer - Through - Back - Translation BA / AB / TO : https : / / github . com / rakshithShetty / A4NT - author - masking / blob / master / README . md 10 While we also experimented with gender , classiﬁcation was heavily biased toward the female class on original data , not achieving > 40 % accuracy on the male class with any of our three classiﬁers . Since the same classiﬁers worked much better with other datasets , this problem seemed to be due to the data itself rather than classiﬁer architectures . These results are in line with those of Shetty et al . [ 64 ] who also received much lower clas - siﬁcation accuracy on gender than on age in the blog dataset . We therefore focused on age in our experiments . the larger class ( Obama ) to the same size as the smaller . We used this balanced variant in our experiments . Multi - class : We created a ﬁve - class dataset by append - ing AB with three additional authors from BA , intro - ducing 7899 + 7270 + 6766 additional training sentences . 5 . 1 . 2 Document - based datasets For document - level experiments , we used the Brennan - Greenstadt corpus ( BG ) and the Extended - Brennan - Greenstadt corpus ( EBG ) [ 7 ] . These corpora have been manufactured speciﬁcally for the purposes of stylom - etry , and contain multiple documents by diﬀerent au - thors . BG contains 12 authors and EBG 45 authors . We used the full BG , and replicated the test settings of Mahmood et al . [ 45 ] by using subsets of 5 and 10 authors from EBG . We additionally experimented on the whole EBG , giving us four datasets altogether : BG , EBG 5 , EBG 10 , and EBG 45 . Following Mahmood et al . [ 45 ] , we used 12 documents from each author for training the proﬁler , and the rest for testing . 5 . 2 Evaluation setup We measured the eﬀectiveness of each technique on two fronts : semantic retainment and style transfer . 5 . 2 . 1 Semantic retainment evaluation We measured semantic retainment using both auto - matic and manual metrics , and conducted a user study with independent evaluators for comparing ParChoice to the encoder - decoder baselines . Automatic evaluation : We calculated the METEOR score [ 5 ] between the original and transformed test sets . METEOR is based on n - gram overlap , and addition - ally considers synonyms and paraphrases . We used the METEOR implementation of the nlg - eval 11 package . Manual evaluation : We manually examined a sub - set of test set transformations , assessing whether they constituted acceptable paraphrases or had errors . For sentence - based data , we evaluated 100 random sen - tences from each two - class dataset ( 50 from each di - rection ) . For document - based data , we manually evalu - ated those sentences that were transformed by all the 11 https : / / github . com / Maluuba / nlg - eval Eﬀective writing style transfer via combinatorial paraphrasing 182 techniques compared ( 81 altogether ) , and combined this evaluation with the rate of transformed sentences per document for each technique . This yields an estimation of how likely the techniques are to retain the original meaning of a sentence in a document , by not transform - ing it or by generating an appropriate paraphrase . User study : We conducted a user study on 20 par - ticipants to evaluate transformations by ParChoice and the encoder - decoder baselines . Of the participants , 25 % were native English speakers . 55 % were female and 45 % male . 60 % were 20 − 30 years old , and 40 % were 30 or older . 90 % had a university degree , most often on the Master’s level ( 65 % ) . In an online questionnaire , each participant was allocated a set of 20 sentences drawn from the YG dataset . They were shown the original sen - tence along with transformed versions by all four imi - tation techniques ( in a random order ) . All users were given diﬀerent sentences to increase variation , resulting in 20 × 20 × 4 = 1600 evaluations altogether . To en - sure the relevance of the evaluation , we only used imita - tions that were non - identical with the original sentence , i . e . not exact reproductions . Participants compared each variant to the original sentence , and rated it on a 0 − 5 scale based on similarity of meaning . 5 . 2 . 2 Style transfer evaluation For sentence - level datasets , we trained three author pro - ﬁlers that represent the state - of - the - art in stylometry ( Section 2 ) . In document - level tests we used the best - performing proﬁler setup from Mahmood et al . [ 45 ] . Proﬁlers : We adopted the most commonly used deep learning text classiﬁcation techniques : long short - term memory networks ( LSTM ) [ 28 ] and convolutional neu - ral networks ( CNN ) [ 41 ] . We used implementations from Shetty et al . [ 64 ] ( LSTM ) and Prabhumoye et al . [ 58 ] ( CNN ) , which also form parts of our baseline style trans - fer techniques ( Section 5 . 3 . 1 ) . Both use words as input features . The source codes are available on GitHub . 12 Writeprints features have exhibited strong perfor - mance in stylometry ( Section 2 ) [ 1 – 3 , 15 , 47 , 53 , 74 ] . For our third sentence - based author proﬁler , we col - lected static Writeprints features [ 74 ] and trained a multilayer perceptron ( MLP ) proﬁler that we call WP . 12 https : / / github . com / shrimai / Style - Transfer - Through - Back - Translation https : / / github . com / rakshithShetty / A4NT - author - masking / blob / master / README . md Static features apply to any user and are thus more gen - eral than dynamic features , which include user - speciﬁc information . We used the following features : number of words , average word length , number of short words ( ≤ 3 ) , number of characters , digit percentage , upper - case character percentage , spacial character percentage , number of letters , number of digits , common charac - ter bigram / trigram percentages , number of hapax - and dislegomena , number of function words , number of POS tags , and number of punctuation markers . Based on a comparative evaluation between ﬁve ML architectures ( MLP , logistic regression , naive Bayes , decision trees , and support vector machines ) , MLP fared the best on our datasets with the static Writeprints features . WP has a single hidden layer of 100 nodes . For document - based datasets , we replicated the test settings of Mahmood et al . [ 45 ] , who used a random for - est classiﬁer trained on static Writeprints - features . This proﬁler had the highest performance in their compara - tive evaluation with other architectures . Proofreading : From 100 sentences of YG , we manu - ally produced additional proofread transformations . The purpose of the proofreading was to ensure semantic re - tainment while changing as little of the transformation as possible . All corrections were made to the direction of the original sentence ; i . e . we did not produce any novel paraphrases . This test evaluates how well the style transfer techniques are able to perform if the author secures semantic retainment by correcting the output . It thus resembles semi - automatic style transfer frame - works like Anonymouth [ 47 ] or AuthorWebs [ 14 ] . Adversarial training We tested the eﬀectiveness of thwarting style transfer via adversarial training on the AB and ﬁve - class datasets , with the LSTM proﬁler . With each style transfer technique , we appended trans - formed variants to the original training set , and re - trained the LSTM with this adversarial training set . We then measured proﬁling accuracy on both the original ( non - transformed ) test set and the transformations per - formed by the technique used for adversarial training . 5 . 3 Style transfer techniques We review the technical details of the baseline tech - niques ( 5 . 3 . 1 – 5 . 3 . 2 ) and ParChoice - variants ( 5 . 3 . 3 ) . Eﬀective writing style transfer via combinatorial paraphrasing 183 Name Architecture access Data access CAE - BA / AB / TO BT CNN YG / BA / AB / TO A 4 NT LSTM BA / AB / TO ParChoice - CNN CNN YG / BA / AB / TO ParChoice - LSTM LSTM BA / AB / TO ParChoice - WP WP YG / BA / AB / TO ParChoice - LR d - YG / BA / AB / TO ParChoice - LR s - - ParChoice - random - - Table 6 . Architecture / data access of sentence - based techniques . 5 . 3 . 1 Encoder - decoder Baselines The main idea behind the encoder - decoder baseline techniques is to generate a style - neutral encoding of the original sentence , which functions as the input to a style - speciﬁc decoder . Some models are available as pre - trained , and the rest we trained ourselves . Pre - trained models and the code for training the baselines are avail - able on the respective projects’ GitHub pages ( linked below ) . The baselines partly diﬀer in their access as - sumptions ( cf . Table 2 ) , as summarized in Table 6 . Cross - aligned autoencoder ( CAE ) : The CAE tech - nique is a style - speciﬁc autoencoder that uses a method called cross - alignment for calibrating encoding distribu - tions [ 63 ] . The encoder produces a latent content vari - able from the input sentence , and the decoder generates the target sentence from this content variable together with a target style feature . CAE does not have query access to any of our author proﬁlers , but has data ac - cess to every dataset except YG ( explanation below ) . We trained CAE for every dataset , using the project’s code from GitHub . 13 Back - translation ( BT ) : As an alternative to cross - alignment , BT produces the latent content variable with a pre - trained MT system [ 58 ] . The original English sen - tence is ﬁrst translated to French , which is then en - coded with the French - English encoder . An English de - coder then produces the target sentence from the encod - ing , and separate decoders are trained to target speciﬁc styles . Style - speciﬁcity is enforced by a CNN , which we also use as one of our author proﬁlers ( Section 5 . 2 . 2 ) . BT trained on YG is provided on the project’s GitHub page . 14 It has been trained with two separate 13 https : / / github . com / shentianxiao / language - style - transfer 14 https : / / github . com / shrimai / Style - Transfer - Through - Back - Translation datasets : one for the classiﬁer and another for the de - coder ( Section 5 . 1 ) . We used the decoder training set to train the other baselines , and the classiﬁer training set for training the proﬁlers . Therefore BT has data access to YG , but CAE and A 4 NT do not . With other datasets we trained BT using the same training data for both the classiﬁer and the generator . A 4 NT : Adversarial Author Attribute Anonymity Neu - ral Translation ( A 4 NT ) [ 64 ] is a style transfer technique based on generative adversarial networks ( GANs ) . A GAN consists of two neural networks , where one ( the classiﬁer ) is trained to classify outputs generated by the other ( the generator ) , which in turn is trained to de - ceive the classiﬁer [ 21 ] . The A 4 NT - generator is trained to produce sentences classiﬁed as the target style by an LSTM , which we also use as one of our author proﬁlers ( Section 5 . 2 . 2 ) . During training , semantic retainment is regulated by the reconstruction probability of the origi - nal sentence via a reverse transformation . We used pre - trained A 4 NT - models for BA and TO , 15 and trained A 4 NT ourselves for YG and AB . While we always used the full dataset for training the initial classiﬁer and generator , hardware limitations re - quired us to truncate YG during the GAN - training phrase . We used a subset of 100000 sentences for this . 5 . 3 . 2 Rule - based baselines We used two rule - based baselines for the document - level tests . The ﬁrst [ 36 ] exhibited leading performance on the PAN2016 Author Obfuscation task [ 57 ] , and the second [ 45 ] achieved state - of - the - art results on the EBG corpus ( Section 5 . 1 . 2 ) . Following Mahmood et al [ 45 ] , we call these PAN2016 and Mutant - X . We implemented both with code from the original projects ( links below ) . PAN2016 : 16 This technique [ 36 ] uses multiple hand - crafted rules along with word replacement from Word - Net and PPDB . Unlike ParChoice , PAN2016 does not conduct either inﬂection or grammatical ﬁltering to in - crease the readability of the output . In addition to synonyms , WordNet - replacement also uses hypernyms and deﬁnitions . Additional hand - crafted rules include e . g . replacing or injecting stopwords , replacing or re - moving punctuation , and expanding contracted forms . 15 https : / / github . com / rakshithShetty / A4NT - author - masking / blob / master / README . md 16 https : / / bitbucket . org / pan2016authorobfuscation / authorobfuscation / src / master / Eﬀective writing style transfer via combinatorial paraphrasing 184 PAN2016 contains its own stylometric feature set ( sim - ilar to Writeprints ) , and calculates the average of these features from the training corpus . It then alters the test document to shift its features closer to this average . Hence , it relies on data access to the original training set , but does not require query access to the proﬁler . Mutant - X : 17 This technique [ 45 ] replaces original words with their word embedding neighbours obtained from a pre - trained Word2Vec [ 49 ] model . The neighbour order is further modiﬁed to shift words of opposite sen - timent ( e . g . good and bad ) away from each other [ 72 ] . Mutant - X repeats random word replacement multiple times , applying a genetic algorithm [ 20 ] to keep the best performing variants after each iteration . Performance is measured as the weighted combined eﬀect of METEOR score and how much original class probability is taken down . For calculating the latter , Mutant - X uses query access to the author proﬁler . We used the same hyper - parameters as Mahmood et al . [ 45 ] : maximally 5 % of document words changed per run ; 100 runs per itera - tion ; maximally 25 iterations ; and 0 . 25 / 0 . 75 weights for METEOR and class probability , respectively . 5 . 3 . 3 ParChoice We implemented ParChoice in Python 3 . Sentence - based variants : To provide a maximally close comparison to the encoder - decoder baselines , we replicated the data / architecture access of BT and A 4 NT by using the CNN and LSTM proﬁlers for paraphrase selection , respectively ( ParChoice - CNN and ParChoice - LSTM ) . We also experimented with black - box access to the WP proﬁler ( ParChoice - WP ) . As a separate sur - rogate proﬁler , we used a logistic regression classiﬁer with word unigrams as input features . We trained two versions of the surrogate proﬁler : one with data ac - cess to the targeted proﬁler’s training data ( ParChoice - LR d ) , and another trained on separate surrogate train - ing data ( ParChoice - LR s ) . For consistency across ex - periments , we always used 15 % of the author proﬁler training data size as the surrogate training data size ( Section 5 . 1 ; Table 5 ) . 18 Finally , we also experimented 17 https : / / github . com / asad1996172 / Mutant - X / 18 In ParChoice - LR s we also used the surrogate training data for obtaining typos ( Section 4 . 1 . 3 ) . To maintain consistency in surrogate data sizes across all experiments , we used a diﬀerent YG surrogate dataset for ParChoice - LR s than the decoder train - ing set used by A 4 NT and CAE , even though both are distinct from the classiﬁer training set ( Section 5 . 3 . 1 , Table 6 ) . The Par - on random paraphrase selection without any surrogate proﬁler ( ParChoice - random ) . Rows 4 − 9 of Table 6 summarize sentence - based ParChoice variants and their data / architecture access . Genetic algorithm : On document - level data , we used the same genetic algorithm as Mutant - X ( Section 5 . 3 . 2 ) , except that instead of changing random words in the document , each run randomly paraphrased one sentence in the document . With the hyperparameters used , this meant that for 25 iterations , 100 new candidates of the document were produced by paraphrasing a single ran - dom sentence . The best candidates were then selected for further iterations , as in Mutant - X . We replicated Mutant - X’s paraphrase selection using a combination of METEOR and query access to the targeted author pro - ﬁler , with 0 . 25 / 0 . 75 weights , respectively ( Section 5 . 3 . 2 ) . ParChoice + Mutant - X : We additionally combined the two best - performing rule - based techniques : Par - Choice and Mutant - X . We ﬁrst ran ParChoice , and then applied Mutant - X only to those documents that had not yet succeeded in style transfer . This combination thus maximized the use of ParChoice , and applied Mutant - X when ParChoice alone was insuﬃcient . Hyperparameters : Initial manual evaluation indi - cated that most semantic problems occurred in long sen - tences with multiple transformations . This motivated an upper limit to transformations per sentence . A limit based on sentence length is problematic for short sen - tences , where even minor transformations are percentu - ally large . Instead , we used a constant edit distance limit of 10 , which allows large changes in short sentences but limits them in long sentences . For computational eﬃciency , we also limited the number of PPDB - and WordNet replacements to 1000 per sentence . Compari - son with larger values indicated that further increasing this number had little to no eﬀect on performance . 6 Evaluation results We present the results on experiments on the sentence - level ( 6 . 1 ) and document - level ( 6 . 2 ) . Raw data and ex - ample transformations are provided in Appendix A . Choice - LSTM variant was trained on the decoder training set , as it replicates the access properties of A 4 NT ( Table 6 ) . Eﬀective writing style transfer via combinatorial paraphrasing 185 Technique YG BA AB TO CAE 19 . 63 21 . 49 6 . 81 4 . 40 BT 20 . 88 17 . 91 5 . 64 4 . 62 A 4 NT 44 . 95 48 . 98 22 . 98 19 . 81 ParChoice - CNN 46 . 09 50 . 70 48 . 61 51 . 20 ParChoice - LSTM 45 . 33 48 . 94 41 . 44 48 . 86 ParChoice - WP 45 . 20 48 . 72 41 . 06 49 . 84 ParChoice - LR d 46 . 00 48 . 59 43 . 02 49 . 17 ParChoice - LR s 45 . 89 48 . 83 45 . 82 50 . 27 Table 7 . METEOR scores between original and transformed sen - tences with all sentence - based style transfer techniques . 6 . 1 Sentence - level experiments ParChoice exhibits a higher semantic retainment than any encoder - decoder baseline ( 6 . 1 . 1 ) . Its style trans - fer performance is higher than that of A 4 NT , which is the only encoder - decoder baseline that achieves non - negligible semantic retainment ( 6 . 1 . 2 ) . 6 . 1 . 1 Semantic retainment METEOR and manual evaluation scores are presented in Tables 7 – 8 , and user study results in Table 9 . METEOR : ParChoice and A 4 NT always clearly out - performed CAE and BT in METEOR . Especially on the smaller datasets ( AB , TO ) , CAE and BT attained very poor scores ( < 10 ) that imply almost no semantic over - lap with the original sentences . A 4 NT performed com - parably to ParChoice in the large datasets ( YG , BA ) , but never exceeded ParChoice - CNN , which was the high - est performing ParChoice - variant . However , in the small datasets ( AB , TO ) A 4 NT’s scores dropped sharply . Dif - ferent ParChoice - variants performed comparably . 19 Un - like A 4 NT , ParChoice achieved high scores ( ∼ 50 ) on both large and small datasets . We also compared METEOR scores with each Par - Choice - module applied alone in the ParChoice - LSTM variant . All achieved scores between 50 and 67 . Sim - ple rules remained the highest , as expected due to the small extent of paraphrases they produce . Typos had the largest range of variation ( 50 − 67 ) , which demon - strates their dependency on the extent to which possible 19 ParChoice - random performed the best overall , but we ex - clude it here because of its lack of targeted paraphrase selection . The METEOR scores of ParChoice - random were 46 . 43 ( YG ) , 49 . 72 ( BA ) , 50 . 54 ( AB ) , and 49 . 88 ( TO ) . Technique YG BA AB TO CAE 2 % 15 % 1 % 0 % BT 3 % 3 % 0 % 0 % A 4 NT 31 % 44 % 16 % 6 % ParChoice - LR s 54 % 59 % 60 % 61 % Table 8 . Manual evaluation : rate of acceptable paraphrases from 100 sentences in each dataset ( 50 to both directions ) , trans - formed with each sentence - based technique . Technique Mean Median ≥ 4 5 CAE 0 . 8 0 5 % 2 % BT 0 . 9 0 8 % 3 % A 4 NT 1 . 7 1 20 % 9 % ParChoice - LR s 2 . 7 3 41 % 24 % Table 9 . User study results : grade statistics from human evalu - ations of meaning similarity from 400 sentences from YG , trans - formed with each sentence - based technique ( grade scale 0 − 5 ) . typos are available in the target class training data ( Sec - tion 4 . 1 . 3 ) . Grammatical transformations , PPDB , and WordNet performed similarly ( in the range 55 − 63 ) , WordNet being systematically slightly higher than the rest . A likely reason for this is METEOR’s bias toward WordNet synonyms as opposed to the kinds of para - phrases produced with grammatical transformations or PPDB . In contrast , in manual evaluation PPDB fared better than WordNet . Manual evaluation : Table 8 presents our manual eval - uation on 100 sentences from each two - class dataset . For practical reasons we limited our manual ParChoice - evaluation to only one variant . We chose ParChoice - LR s for two reasons . First , compared to other variants , it had neither the highest nor lowest overall METEOR score ( Table 7 ) , which indicates that the manual eval - uations are not likely to either over - or underestimate the general performance of ParChoice . Second , it imple - ments the most realistic access assumptions out of all ( non - random ) ParChoice - variants ( Section 3 , Table 6 ) . CAE and BT produced practically no acceptable paraphrases . This was especially true in the small datasets ( AB , TO ) , where imitations bore no resem - blance to the original sentence and simply repeated cer - tain words prevalent in the target corpus . With A 4 NT , sentence reproduction was much more common than anywhere else , but actual paraphrases remained rare . For example , A 4 NT’s acceptable para - phrase rate in BA decreases from 44 % to only 2 % when reproductions are excluded . A 4 NT also generated a Eﬀective writing style transfer via combinatorial paraphrasing 186 Technique YG BA AB TO LSTM CNN WP LSTM CNN WP LSTM CNN WP LSTM CNN WP CAE 0 . 31 0 . 30 0 . 21 0 . 15 0 . 16 0 . 13 0 . 74 0 . 77 0 . 55 0 . 34 0 . 20 0 . 28 BT 0 . 33 0 . 34 0 . 20 0 . 15 0 . 17 0 . 09 0 . 77 0 . 84 0 . 59 0 . 49 0 . 33 0 . 27 A 4 NT 0 . 16 0 . 17 0 . 10 0 . 10 0 . 11 0 . 05 0 . 19 0 . 22 0 . 14 0 . 53 0 . 07 0 . 33 ParChoice - CNN 0 . 39 0 . 49 0 . 19 0 . 21 0 . 35 0 . 08 0 . 26 0 . 39 0 . 16 0 . 13 0 . 21 0 . 12 ParChoice - LSTM 0 . 44 0 . 40 0 . 22 0 . 37 0 . 27 0 . 11 0 . 47 0 . 32 0 . 33 0 . 47 0 . 09 0 . 17 ParChoice - WP 0 . 26 0 . 23 0 . 48 0 . 16 0 . 17 0 . 34 0 . 21 0 . 22 0 . 60 0 . 15 0 . 06 0 . 59 ParChoice - LR d 0 . 39 0 . 40 0 . 16 0 . 28 0 . 29 0 . 11 0 . 26 0 . 25 0 . 29 0 . 32 0 . 09 0 . 17 ParChoice - LR s 0 . 36 0 . 36 0 . 15 0 . 22 0 . 21 0 . 09 0 . 21 0 . 22 0 . 20 0 . 23 0 . 07 0 . 14 ParChoice - random 0 . 12 0 . 12 0 . 08 0 . 04 0 . 05 0 . 01 0 . 10 0 . 11 0 . 09 0 . 09 0 . 03 0 . 09 Table 10 . Author proﬁler accuracy decrease in sentence - based datasets , best ( highest ) scores framed . large number of omissions , reproducing only part of the original sentence without any changes or additions . Such pure omissions were rare with other techniques . These characteristics are likely due to A 4 NT’s training func - tion , which includes a reconstruction loss [ 64 ] ( Section 5 . 3 . 1 ) . In the small datasets ( AB , TO ) A 4 NT’s semantic retainment starkly declined to almost non - existent . ParChoice clearly stood out by producing many acceptable paraphrases . In contrast to the baselines , ParChoice ’s performance was similar across all four datasets . The most prevalent ParChoice - transformation was paraphrase replacement from PPDB or WordNet , most commonly targeting a single word . Typos and grammatical transformations were rare in the manu - ally evaluated test sets , but some were encountered . When PPDB - and WordNet - replacement could be dis - tinguished , PPDB - replacement fared better in seman - tic retainment . Most ParChoice - errors were caused by contextually unsuitable WordNet synonym choice ( e . g . man → mankind ) . Such errors are due to faulty word sense disambiguation ( Section 4 . 1 . 2 ) , improving which is an important challenge for future research . User study : Table 9 presents the user study results . ParChoice clearly outperformed all baselines . As ex - pected , CAE and BT performed especially poorly . The majority of ParChoice - imitations were on the upper half of the six - point scale ( 3 − 5 ) , whereas the majority of all baseline imitations had the lowest grades ( 0 − 1 ) . 6 . 1 . 2 Style transfer We present style transfer results on two - class settings and multi - class author imitation . Two - class tests : To evaluate style transfer success , we measured accuracy decrease : i . e . how much original ac - curacy dropped after style transfer . Table 10 provides Proﬁler YG BA AB TO LSTM 0 . 83 0 . 62 0 . 91 0 . 82 CNN 0 . 82 0 . 63 0 . 93 0 . 64 WP 0 . 75 0 . 59 0 . 82 0 . 74 Table 11 . Original author proﬁling accuracies . these results . Table 11 shows proﬁling accuracies on original test sets with the three proﬁlers ( Section 5 . 2 . 2 ) . A 4 NT’s performance was the weakest everywhere except TO . CAE and BT achieved almost full imitation in AB and the Obama → Trump direction of TO . This was unsurprising since they simply repeated words un - related to the original ( Section 6 . 1 . 1 ) . However , both showed a clear bias toward the Trump class , and failed in the Trump → Obama direction . In large datasets ( YG , BA ) , all ( non - random ) vari - ants of ParChoice outperformed all baselines . This hap - pened even under the weakest access assumptions , i . e . ParChoice - LR s . In small datasets ( AB , TO ) , ParChoice retained similar performance but baselines increased theirs . ParChoice - LR d achieved 5 % better average ac - curacy decrease than ParChoice - LR s , and query access to the author proﬁler ( CNN or LSTM ) increased it 10 % − 20 % . Query access to WP allowed eﬀective black - box evasion of WP , but did not reach the performance of other variants with other proﬁlers . ParChoice - random expectedly took accuracy down the least . We additionally applied each ParChoice module sep - arately on the ParChoice - LSTM variant , and compared accuracy decrease ( Table 12 ) and prediction overlap ( Table 13 ) between the modules on the LSTM proﬁler . All techniques had at least a minor impact . PPDB and WordNet were the most eﬀective overall and had simi - lar success ( 13 % − 20 % ) . Grammatical transformations outperformed them in AB , but were less successful oth - Eﬀective writing style transfer via combinatorial paraphrasing 187 Technique YG BA AB TO Avg . Grammatical 0 . 12 0 . 07 0 . 14 0 . 08 0 . 10 Simple rules 0 . 01 0 . 04 0 . 03 0 . 05 0 . 03 PPDB 0 . 19 0 . 18 0 . 13 0 . 25 0 . 19 WordNet 0 . 15 0 . 20 0 . 13 0 . 23 0 . 18 Typos 0 . 02 0 . 10 0 . 15 0 . 08 0 . 09 All 0 . 44 0 . 37 0 . 47 0 . 47 0 . 46 Table 12 . Proﬁler accuracy decrease with ParChoice modules individually and together ( LSTM proﬁler , ParChoice - LSTM vari - ant ) . Gram . Simple PPDB WordNet Typos Gram . 100 % 93 % 80 % 80 % 89 % Simple 93 % 100 % 83 % 84 % 95 % PPDB 80 % 83 % 100 % 81 % 82 % WordNet 80 % 84 % 81 % 100 % 83 % Typos 89 % 95 % 82 % 83 % 100 % Table 13 . Prediction overlap between ParChoice modules ( com - bined from all datasets , LSTM proﬁler , ParChoice - LSTM variant ) . erwise . Typos had the largest variation , ranging from almost nonexistent in YG ( 2 % ) to being the most ef - fective in AB ( 15 % ) . Simple rules were expectedly the least eﬀective when applied alone ( 1 % − 5 % ) . The most eﬀective techniques ( PPDB and WordNet ) were also the most diverse , having the least prediction overlap with other techniques ( 80 % − 84 % ) and each other ( 81 % ) . Proofreading : To emulate a scenario where the au - thor manually checks the results of style transfer , we proofread 50 transformed sentences from both the male and female test sets of YG . For CAE and BT proof - reading often required reproducing the original sentence due to very poor semantic retainment ( Section 6 . 1 . 1 ) . Proofreading negatively impacted style transfer with all techniques , but markedly less with ParChoice than the baselines ( Table 14 ) . Multi - class tests : We evaluated ﬁve - class author imi - tation to every direction on a blog author dataset ( Sec - tion 5 . 1 ) . Since ParChoice - CNN and ParChoice - LSTM had the best overall performance in two - class settings , Proﬁler CAE BT A 4 NT ParChoice - LR s LSTM 0 . 11 0 . 14 0 . 09 0 . 31 CNN 0 . 12 0 . 11 0 . 09 0 . 26 WP 0 . 09 0 . 09 0 . 08 0 . 10 Table 14 . Proﬁler accuracy decrease on a YG - subset after manual proofreading ; best ( highest ) scores framed . Technique Proﬁler Sourcedecrease Target increase Imitation ParChoice - LSTM LSTM 0 . 39 0 . 29 15 / 20 CNN 0 . 28 0 . 20 1 / 20 ParChoice - CNN LSTM 0 . 21 0 . 13 0 / 20 CNN 0 . 40 0 . 27 7 / 20 Table 15 . Five - class author imitation in the blog author dataset with ParChoice ( query access to LSTM / CNN ) : average source class accuracy decrease , target class accuracy increase , and imi - tation success ( imitation threshold : majority of source class docu - ments assigned to target class ) . we experimented on these variants on the CNN and LSTM proﬁlers . We discarded WP here because it failed to achieve high proﬁling accuracies on the original ﬁve - class test sets . On each author’s test set , we considered both the accuracy decrease of the original class , and the accuracy increase of the target class . Additionally , if the majority of the source author test sentences was as - signed to the target author , we considered imitation to succeed for that source - target pair . Table 15 summarizes the results from all 20 imitation directions . ParChoice - LSTM’s overall performance was superior to ParChoice - CNN’s . ParChoice - LSTM reached the threshold 75 % of the time on the LSTM proﬁler . 6 . 2 Document - level experiments We compare ParChoice to the rule - based PAN2016 [ 36 ] and Mutant - X [ 45 ] baselines ( Section 5 . 3 . 2 ) in semantic retainment ( 6 . 2 . 1 ) and style transfer ( 6 . 2 . 2 ) . ParChoice is markedly better in semantic retainment than either baseline , but Mutant - X remains stronger in style trans - fer . A combination of ParChoice and Mutant - X outper - forms prior rule - based schemes in both style transfer and semantic retainment . 6 . 2 . 1 Semantic retainment We use three measures of document - level semantic re - tainment : ( i ) METEOR score , ( ii ) rate of sentences transformed per document , and ( iii ) manual evaluation of paraphrases in transformed sentences . Originally mis - classiﬁed documents were discarded from the evalua - tion , since they were left unchanged . METEOR : All techniques achieved relatively high METEOR scores ( Table 16 ) , with ParChoice outper - forming PAN2016 ( by 19 − 34 points ) and Mutant - X Eﬀective writing style transfer via combinatorial paraphrasing 188 Technique METEOR BG EBG 5 EBG 10 EBG 45 PAN2016 43 . 17 45 . 93 46 . 96 47 . 15 Mutant - X 56 . 71 57 . 23 53 . 46 56 . 75 ParChoice 77 . 40 65 . 41 66 . 26 69 . 34 ParChoice + Mutant - X 61 . 61 60 . 25 62 . 31 65 . 86 Table 16 . METEOR scores between original and transformed documents from rule - based techniques ( originally misclassiﬁed documents discarded ) . Technique Transformed sentences BG EBG 5 EBG 10 EBG 45 PAN2016 98 % 98 % 98 % 96 % Mutant - X 71 % 72 % 79 % 73 % ParChoice 6 % 25 % 11 % 7 % ParChoice + Mutant - X 43 % 41 % 22 % 14 % Table 17 . Average transformed sentence rates per document ( originally misclassiﬁed documents discarded ) . ( by 8 − 21 points ) . Combining ParChoice with Mutant - X also always retained a higher score than Mutant - X alone ( by 9 − 3 points ) . Transformed sentence rates : PAN2016 transformed almost all sentences per document , Mutant - X a clear majority ( > 70 % ) , and ParChoice only 6 % − 25 % ( Table 17 ) . This is a major divergence among the techniques , as it makes ParChoice much more likely to retain se - mantics by focusing transformations only on a minority of sentences . While the transformed sentence rate in - creased when Mutant - X was applied after ParChoice , it remained signiﬁcantly lower than with Mutant - X alone . Manual evaluation : To ensure fair comparison , we manually evaluated each technique on the same sen - tences . Across all four datasets there were 81 sentences that all techniques had made changes to . Table 18 shows manual evaluation results on these sentences . We provide an error analysis , categorizing errors to four types based on decreasing severity : – Antonym : opposite meaning – Word : non - antonym but diﬀerent meaning – Context : possible paraphrase but wrong context – Grammar : correct paraphrase but wrong grammar Mutant - X produced 19 antonyms across all 81 sentences , including e . g . more → less and easier → harder . While Mutant - X uses sentiment - based neighbour ranking [ 72 ] to avoid antonyms ( Section 5 . 3 . 2 ) , sentiment is only one possible source of antonymity . In contrast , antonyms Technique Acceptable Paraphrases Error count A W C G PAN2016 44 % 0 32 12 1 Mutant - X 32 % 19 62 7 4 ParChoice 60 % 1 20 12 2 ParChoice + Mutant - X 53 % 2 40 16 1 Table 18 . Manual evaluation results from rule - based techniques ( calculated from 81 sentences transformed by all techniques ) . Error types : A = antonym ; W = word ; C = context ; G = grammar . Technique Corpus BG EBG 5 EBG 10 EBG 45 PAN2016 50 % 13 % 32 % 76 % Mutant - X 82 % 60 % 87 % 96 % ParChoice 36 % 47 % 84 % 91 % ParChoice + Mutant - X 82 % 77 % 97 % 100 % Table 19 . Successful style transfer rates of rule - based techniques ( originally misclassiﬁed documents discarded ) . were absent in PAN2016 , and only one was found in Par - Choice : defended → opposed . The most likely source for this error was PPDB . Other word errors were the most common in all techniques , but much rarer in ParChoice than elsewhere . In ParChoice the rate of context errors was the same as in PAN2016 , but their percentage of all errors larger . These included e . g . issue → number , which would be correct in a magazine - related context but not otherwise . All techniques produced a few ( 1 − 4 ) purely grammatical errors , mostly due to inﬂection . Overall , Mutant - X made markedly more semantic errors than either PAN2016 or ParChoice . This result seems to contrast PAN2016 having a lower METEOR score . This may be due to PAN2016 adding words ( such as Additionally ) before sentences , which usually does not negatively impact semantics but brings n - gram over - lap ( and hence METEOR ) down . Applying ParChoice before Mutant - X signiﬁcantly reduced the most fatal errors ( antonym or word error ) produced by Mutant - X . 6 . 2 . 2 Style transfer Table 19 summarizes document - level style transfer per - formance . We deﬁne the successful style transfer rate as the frequency at which an originally correctly classiﬁed document was incorrectly classiﬁed after style trans - fer . Mutant - X had superior performance to PAN2016 and ParChoice across all datasets , although the diﬀer - Eﬀective writing style transfer via combinatorial paraphrasing 189 Technique Original proﬁler Newproﬁler PAN2016 13 % 20 % Mutant - X 60 % 17 % ParChoice 47 % 20 % Table 20 . Style transfer success rates on EBG 5 with the original ( queried ) proﬁler and a new re - trained random forest proﬁler . ence to ParChoice was only minor in EBG 5 and EBG 10 ( 3 % − 5 % ) . However , when Mutant - X was applied after ParChoice , we reached the highest result on all datasets . Given that this combination also achieved signiﬁcantly higher semantic retainment than Mutant - X alone ( Sec - tion 6 . 2 . 1 ) , it constitutes the state - of - the - art solution to document - level style transfer on these datasets . However , we note a problem in assuming query ac - cess to the adversary’s random forest proﬁler . The pro - ﬁler involves randomness in training , and re - training it on the same training data mostly undoes the eﬀect of style transfer on query - access techniques . Table 20 shows this eﬀect on EBG 5 . As PAN2016 does not use query access , it is not vulnerable to this problem . Query access can thus result in highly proﬁler - speciﬁc transfor - mations , which are non - transferable across proﬁlers . Problematically , most style transfer research has so far relied on query access . In particular , with the excep - tion of PAN2016 [ 36 ] , all our baseline techniques were originally applied in query access settings [ 45 , 58 , 63 , 64 ] . Since query access is not a realistic requirement for the author ( Section 3 ) , and given its lack of transferabil - ity to diﬀerent proﬁlers , we recommend moving beyond query access in style transfer research . While we were able to do so successfully on sentence - based data ( Sec - tion 6 . 1 ) , on the document - level it remains a challenge for future work . 6 . 3 Thwarting style transfer via adversarial training To test the eﬀectiveness of adversarial training for coun - tering style transfer , we applied it to every technique on the AB dataset with the LSTM proﬁler . We chose this setting because it achieved a high original test set ac - curacy as well as the highest overall accuracy change ( Section 6 . 1 . 2 , Table 10 ) . Table 21 presents the results . Proﬁling accuracies on original test sets remained high , but were taken down in all cases except two ( A 4 NT and ParChoice - LSTM in the Alice → Bob direction , which Technique Direction Original Transformed CAE A → B 0 . 88 → 0 . 78 0 . 18 → 0 . 90 B → A 0 . 94 → 0 . 79 0 . 16 → 0 . 87 BT A → B 0 . 88 → 0 . 85 0 . 18 → 0 . 78 B → A 0 . 94 → 0 . 88 0 . 11 → 0 . 64 A 4 NT A → B 0 . 88 → 0 . 90 0 . 74 → 0 . 86 B → A 0 . 94 → 0 . 85 0 . 70 → 0 . 64 ParChoice - LSTM A → B 0 . 88 → 0 . 90 0 . 36 → 0 . 88 B → A 0 . 94 → 0 . 88 0 . 52 → 0 . 92 ParChoice - random A → B 0 . 88 → 0 . 79 0 . 74 → 0 . 47 B → A 0 . 94 → 0 . 72 0 . 89 → 0 . 38 Table 21 . LSTM author proﬁler accuracy without → with adversar - ial training , on both original and transformed test sets of AB . increased by 2 % ) . Accuracy on the transformed test set increased drastically with most techniques , and mostly undid the eﬀect of style transfer . 20 The important ex - ception was ParChoice - random , which we discuss below . Our results illustrate a major problem in style trans - fer techniques that rely on the author having query access to the adversary’s proﬁler , or a surrogate pro - ﬁler that accurately approximates its performance . Cru - cially , such access assumptions go both ways : if the author can access / approximate the adversary’s pro - ﬁler locally , the adversary can also access / approximate the author’s local proﬁler for adversarial training . This problem is fundamental to all of our techniques except ParChoice - random , which performs paraphrase selection independently of the proﬁler . In striking contrast to other techniques , adversarial training with ParChoice - random reduced proﬁling accu - racy on both original and transformed sentences . Hence , while ParChoice - random expectedly performed the least eﬀectively in style transfer ( Section 6 . 1 . 2 ) , it was the only technique that could eﬀectively resist adversarial training as a counter - measure . One possible reason for this is the large range of stylistic variants produced by ParChoice ’s paraphrase generation stage , which results in author - speciﬁc stylistic markers becoming less promi - nent in the adversarial training set . Adversarial training is also expected to be more challenging when the number of classes is increased . 20 Apart from ParChoice - random ( discussed separately ) , the only exception was A 4 NT in the Bob → Alice direction , where proﬁling accuracy decreased by 6 % in transformed sentences . Since A 4 NT’s original performance was not strong on AB to be - gin with , and original proﬁling accuracy also decreased in the Bob → Alice direction ( by 9 % ) , we do not take this exception to aﬀect the overall conclusion . Eﬀective writing style transfer via combinatorial paraphrasing 190 Author Original Transformed A1 0 . 75 → 0 . 73 0 . 27 → 0 . 61 A2 0 . 81 → 0 . 76 0 . 44 → 0 . 71 A3 0 . 64 → 0 . 60 0 . 26 → 0 . 50 A4 0 . 71 → 0 . 74 0 . 29 → 0 . 66 A5 0 . 64 → 0 . 72 0 . 35 → 0 . 65 Table 22 . LSTM author proﬁler accuracy without → with adversar - ial training , on both original and transformed ﬁve - class test sets with randomized target authors on ParChoice - LSTM . We produced ParChoice - LSTM imitations with random target classes from the ﬁve - class training set , and ap - pended them to the original ﬁve - class training data . We trained the LSTM proﬁler on this adversarial training data , and tested it against ParChoice - LSTM imitations with randomly selected targets . Results are shown in Table 22 . As predicted , the eﬀectiveness of adversar - ial training was reduced , although still clearly present . However , the adversary could adopt a two - step proﬁling procedure of ﬁrst detecting the imitation target by clas - sifying the transformed document , and then producing the adversarial training set using this target . On the document - level , the eﬀect of adversarial training is diﬃcult to evaluate due to the techniques’ brittleness to re - training the proﬁler . While we were able to bring style transfer performance down on the EBG 5 dataset via adversarial training , this also hap - pened with regular re - training ( Table 20 ) . As discussed in Section 6 . 2 . 2 , we believe this is due to the high proﬁler - speciﬁcity of techniques relying on query ac - cess on the document - level , which remains an important problem for future research . 7 Conclusions and future work We presented ParChoice : a novel style transfer tech - nique based on combinatorial paraphrase generation and style - speciﬁc paraphrase selection . ParChoice con - siderably improves on the state - of - the - art in retaining semantic content . In sentence - level experiments , it out - performed the only encoder - decoder baseline technique with competitive semantic retainment ( A 4 NT ) . On the document - level , combining ParChoice with the best - performing rule - based baseline ( Mutant - X ) increased state - of - the - art performance in both style transfer and semantic retainment . We thus endorse ParChoice as the most viable style transfer technique overall . On data where ParChoice has limited coverage , we recommend combining it with word embedding - based replacement . An important extension of the present work is ap - plying style transfer to more complex proﬁling schemes . In particular , abstaining classiﬁers [ 13 , 16 ] can be used to detect whether the probability of any target class is too low for prediction to be justiﬁed . They could be used to ﬁlter potential cases of style transfer , as these are less likely to give clear target class predictions . These data - points could then be subjected to further scrutiny . Ab - staining classiﬁers have been demonstrated to be bene - ﬁcial for stylometry , and for detecting manually trans - formed documents [ 66 ] . Their eﬀectiveness against au - tomatic techniques remains to be studied . Another major conclusion we draw is that style transfer needs to properly address possible counter - measures . The main challenge is achieving strong style transfer performance whilst preventing the adversary from replicating it by adversarial training . We demon - strated this to be a realistic concern , but propose that its eﬀectiveness can partly be hindered via increased ran - domization in paraphrasing . We will continue to explore this issue in future work . Acknowledgements We thank Andrei Kazlouski and Sam Spilsbury for their help in implementation and running experiments , and Mika Juuti for valuable discussions related to the project . Tommi Gröndahl was funded by the Helsinki Doctoral Education Network in Information and Com - munications Technology ( HICT ) . References [ 1 ] Ahmed Abbasi and Hsinchun Chen . Writeprints : A stylo - metric approach to identity - level identiﬁcation and similarity detection in cyberspace . ACM Transactions on Information and System Security , 26 ( 2 ) : 1 – 29 , 2008 . [ 2 ] Sadia Afroz , Michael Brennan , and Rachel Greenstadt . De - tecting Hoaxes , Frauds , and Deception in Writing Style Online . In Proceedings of the 2012 IEEE Symposium on Security and Privacy , pages 461 – 475 , 2012 . [ 3 ] Mishari Almishari , Ekin Oguz , and Gene Tsudik . Fighting Authorship Linkability with Crowdsourcing . In Proceedings of the second ACM conference on Online social networks , pages 69 – 82 , 2014 . [ 4 ] Douglas Bagnall . Author identiﬁcation using multi - headed recurrent neural networks . In Working Notes of CLEF 2015 - Conference and Labs of the Evaluation Forum , 2015 . Eﬀective writing style transfer via combinatorial paraphrasing 191 [ 5 ] Satanjeev Banerjee and Alon Lavie . METEOR : An auto - matic metric for MT evaluation with improved correlation with human judgments . In Proceedings of the ACL Work - shop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and / or Summarization , pages 65 – 72 , 2005 . [ 6 ] Steven Bird , Ewan Klein , and Edward Loper . Natural Lan - guage Processing with Python : Analyzing Text with the Natural Language Toolkit . O’Reilly , Beijing , 2009 . [ 7 ] Michael Brennan , Sadia Afroz , and Rachel Greenstadt . Ad - versarial stylometry : Circumventing authorship recognition to preserve privacy and anonymity . ACM Transactions on Information and System Security , 15 ( 3 ) : 12 : 1 – 12 : 22 , 2011 . [ 8 ] Michael Brennan and Rachel Greenstadt . Practical Attacks Against Authorship Recognition Techniques . In Proceedings of the Twenty - First Conference on Innovative Applications of Artiﬁcial Intelligence , pages 60 – 65 , 2009 . [ 9 ] Marcelo Luiz Brocardo , Issa Traore , Isaac Woungang , and Mohammad S . Obaidat . Authorship veriﬁcation using deep belief network systems . Communication Systems , 30 ( 12 ) , 2017 . [ 10 ] Aylin Caliskan and Rachel Greenstadt . Translate once , trans - late twice , translate thrice and attribute : Identifying authors and machine translation tools in translated text . In Pro - ceedings of the 2012 IEEE Sixth International Conference on Semantic Computing ( ICSC ) , pages 121 – 125 , 2012 . [ 11 ] Andrew Carnie . Constituent Structure . Oxford University Press , Oxford , 2008 . [ 12 ] Daniel Castro - Castro , Reynier Ortega Bueno , and Rafael Mu noz . Author masking by sentence transformation – notebook for PAN at CLEF . In Working notes of CLEF2017 , 2017 . [ 13 ] C . K . Chow . On optimum recognition error and reject trade - oﬀ . IEEE Transactions on Information Theory , 16 : 41 – 46 , 1970 . [ 14 ] Siobahn Day , James Brown , Zachery Thomas , India Gre - gory , Lowell Bass , and Gerry Dozier . Adversarial Authorship , AuthorWebs , and entropy - based evolutionary clustering . In Proceedings of the 25th International Conference on Com - puter Communication and Networks ( ICCCN ) , pages 1 – 6 , 2016 . [ 15 ] Iqbal Farkhund , Hamad Binsalleeh , Benjamin C . M . Fung , and Mourad Debbabi . Mining writeprints from anonymous e - mails for forensic investigation . Digital Investigation , 7 ( 1 – 2 ) : 56 – 64 , 2013 . [ 16 ] César Ferri , Peter Flach , and José Hernández - Orallo . Dele - gating classiﬁers . In Proceedings of the 21th International Conference on Machine Leaning ( ICML’04 ) , pages 106 – 110 , 2004 . [ 17 ] Zhenxin Fu , Xiaoye Tan , Nanyun Peng , Dongyan Zhao , and Rui Yan . Style transfer in text : Exploration and evaluation . In Proceedings of the AAAI Conference on Artiﬁcial Intelli - gence , pages 663 – 670 , 2018 . [ 18 ] Juri Ganitkevitch , Benjamin Van Durme , and Chris Callison - Burch . PPDB : The paraphrase database . In Proceedings of the North American Chapter of the Association for Compu - tational Linguistics ( NAACL - HLT ) , pages 758 – 764 , 2013 . [ 19 ] Zhenhao Ge and Yufang Sun . Domain speciﬁc author attri - bution based on feedforward neural network language mod - els . In Proceedings of the 5th International Conference on Pattern Recognition Applications and Methods ( ICPRAM ) , pages 597 – 604 , 2016 . [ 20 ] David Goldberg . Genetic Algorithms in Search , Optimization and Machine Learning . Addison - Wesley Longman Publishing Co . , Inc . , Boston , 1989 . [ 21 ] Ian Goodfellow , Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron Courville , and Yoshua Bengio . Generative adversarial networks . In Proceed - ings of the International Conference on Neural Information Processing Systems ( NIPS ) , pages 2672 – 2680 , 2014 . [ 22 ] Jack Grieve . Quantitative authorship attribution : An eval - uation of techniques . Literary and Linguistic Computing , 22 ( 3 ) : 251 – 270 , 2007 . [ 23 ] Tommi Gröndahl and N . Asokan . EAT2seq : A generic frame - work for controlled sentence transformation without task - speciﬁc training . arXiv preprint arXiv : 1902 . 09381 , 2019 . [ 24 ] Tommi Gröndahl and N . Asokan . Text analysis in adver - sarial settings : Does deception leave a stylistic trace ? ACM Computing Surveys , 52 ( 3 ) : 45 : 1 – 45 : 36 , 2019 . [ 25 ] Tommi Gröndahl , Luca Pajola , Mika Juuti , Mauro Conti , and N . Asokan . All you need is “love” : Evading hate speech detection . In Proceedings of the 11th ACM Workshop on Artiﬁcial Intelligence and Security ( AISec’11 ) , pages 2 – 12 , 2018 . [ 26 ] Michael Haardt . GNU Diction , 2005 ( accessed February 24 , 2020 ) . https : / / www . gnu . org / software / diction / . [ 27 ] Thanh Nghia Ho and Wee Keong Ng . Application of stylom - etry to DarkWeb forum user identiﬁcation . In Proceedings of Information and Communications Security , pages 173 – 183 , 2016 . [ 28 ] Sepp Hochreiter and Jürgen Schmidhuber . Long short - term memory . Neural Computation , 9 ( 8 ) : 1735 – 1780 , 1997 . [ 29 ] Charles D . Hollingsworth . Syntactic Stylometry : Using Sen - tence Structure for Authorship Attribution . PhD thesis , University of Georgia , 2012 . [ 30 ] Charles D . Hollingsworth . Using dependency - cased anno - tations for authorship identiﬁcation . In Proceedings of the International Conference on Text , Speech and Dialogue , pages 314 – 319 , 2012 . [ 31 ] Matthew Honnibal and Mark Johnson . An improved non - monotonic transition system for dependency parsing . In Proceedings of Empirical Methods in Natural Language Processing ( EMNLP ) , pages 1373 – 1378 , 2015 . [ 32 ] Zhiting Hu , Zichao Yang , Xiaodan Liang , Ruslan Salakhut - dinov , and Eric P . Xing . Toward controlled generation of text . In Proceedings of the 34th International Conference on Machine Learning , 2017 . [ 33 ] Patrick Juola . Large - scale experiments in authorship attribu - tion . English Studies , 93 ( 3 ) : 275 – 283 , 2012 . [ 34 ] Patrick Juola . Stylometry and immigration : A case study . Journal of Law and Policy , 21 ( 2 ) : 287 – 298 , 2013 . [ 35 ] Mika Juuti , Bo Sun , Tatsuya Mori , and N . Asokan . Stay on - topic : Generating context - speciﬁc fake restaurant reviews . In Proceedings of the 23rd European Symposium on Research in Computer Security ( ESORICS ) , pages 132 – 151 , 2018 . [ 36 ] Georgi Karadzhov , Tsvetomila Mihaylova , Yasen Kiprov , Georgi Georgiev , Ivan Koychev , and Preslav Nakov . The case for being average : A mediocrity approach to style masking and author obfuscation . In Proceedings of the International Conference of the Cross - Language Evaluation Forum for European Languages ( CLEF ) , pages 173 – 185 , 2017 . Eﬀective writing style transfer via combinatorial paraphrasing 192 [ 37 ] Foaad Khosmood . Comparison of sentence - level paraphras - ing approaches for statistical style transformation . In Pro - ceedings of the International Conference on Artiﬁcial Intelli - gence , 2012 . [ 38 ] Foaad Khosmood and Robert Levinson . Automatic natural language style classiﬁcation and transformation . In Proceed - ings of the 2008 BCS - IRSG Conference on Corpus Proﬁling , page 3 , 2008 . [ 39 ] Foaad Khosmood and Robert Levinson . Toward automated stylistic transformation of natural language text . In Proceed - ings of the Digital Humanities , pages 177 – 181 , 2009 . [ 40 ] Foaad Khosmood and Robert Levinson . Automatic synonym and phrase replacement show promise for style transforma - tion . In Proceedings of The Ninth International Confer - ence on Machine Learning and Applications , pages 958 – 961 , 2010 . [ 41 ] Yann LeCun , Léon Bottou , Yoshua Bengio , and Patrick Haﬀner . Gradient - based learning applied to document recog - nition . In Proceedings of the IEEE , pages 2278 – 2324 , 1998 . [ 42 ] Jinfeng Li , Shouling Ji , Tianyu Du , Bo Li , and Ting Wang . Textbugger : Generating adversarial text againstreal - world applications . In Proceedings of Network and Distributed Systems Security ( NDSS ) , 2019 . [ 43 ] Lajanugen Logeswaran , Honglak Lee , and Samy Bengio . Content preserving text generation with attribute controls . In Proceedings of the International Conference on Neural Information Processing Systems ( NIPS ) , 2018 . [ 44 ] Nathan Mack , Jasmine Bowers , Henry Williams , Gerry Dozier , and Joseph Shelton . The best way to a strong defense is a strong oﬀense : Mitigating deanonymization at - tacks via iterative language translation . International Journal of Machine Learning and Computing , 5 ( 5 ) : 409 – 413 , 2015 . [ 45 ] Asad Mahmood , Faizan Ahmad , Zubair Shaﬁq , Padmini Srinivasan , and Fareed Zaﬀar . A girl has no name : Au - tomated authorship obfuscation using Mutant - X . In Pro - ceedings on Privacy Enhancing Technologies ( PETS ) , pages 54 – 71 , 2019 . [ 46 ] Muharram Mansoorizadeh , Taher Rahgooy , Mohammad Aminiyan , and Mahdy Eskandari . Author obfuscation us - ing WordNet and language models – notebook for PAN at CLEF 2016 . In CLEF 2016 Evaluation Labs and Workshop – Working Notes Papers , 2016 . [ 47 ] Andrew W . E . McDonald , Sadia Afroz , Aylin Caliskan , Ariel Stolerman , and Rachel Greenstadt . Use fewer instances of the letter i : Toward writing style anonymization . In Si - mone Fischer - Hübner and Matthew Wright , editors , Privacy Enhancing Technologies . Volume 7384 of Lecture Notes in Computer Science , pages 299 – 318 . 2012 . [ 48 ] Tsvetomila Mihaylova , Georgi Karadjov , Preslav Nakov , Yasen Kiprov , Georgi Georgiev , and Ivan Koychev . SU @ PAN’2016 : Author obfuscation – notebook for PAN at CLEF 2016 . In CLEF 2016 Evaluation Labs and Workshop – Working Notes Papers , 2016 . [ 49 ] Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg Corrado , and Jeﬀrey Dean . Distributed representations of words and phrases and their compositionality . In Proceedings of the International Conference on Neural Information Processing Systems ( NIPS ) , page 3111 – 3119 , 2013 . [ 50 ] George A . Miller . WordNet : A lexical database for English . Communications of the ACM , 38 ( 11 ) : 39 – 41 , 1995 . [ 51 ] Arvind Narayanan , Hristo Paskov , Neil Zhenqiang Gong , John Bethencourt , Emil Stefanov , Eui Chul Richard Shin , and Dawn Song . On the feasibility of internet - scale author identiﬁcation . In Proceedings of the IEEE Symposium on Security and Privacy , pages 300 – 314 , 2012 . [ 52 ] Roberto Navigli . Word sense disambiguation : A survey . ACM Computing Surveys , 41 ( 2 ) : 1 – 69 , 2009 . [ 53 ] Rebekah Overdorf and Rachel Greenstadt . Blogs , twitter feeds , and reddit comments : Cross - domain authorship attri - bution . In Proceedings on Privacy Enhancing Technologies ( PETS ) , pages 155 – 171 , 2016 . [ 54 ] Lluís Padró and Evgeny Stanilovsky . Freeling 3 . 0 : Towards wider multilinguality . In Proceedings of the Language Re - sources and Evaluation Conference ( LREC 2012 ) , pages 2473— - 479 , 2012 . [ 55 ] Ellie Pavlick , Pushpendre Rastogi , Juri Ganitkevitch , Ben - jamin Van Durme , and Chris Callison - Burch . PPDB 2 . 0 : Better paraphrase ranking , ﬁne - grained entailment rela - tions , word embeddings , and style classiﬁcation . In Pro - ceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing ( Short Papers ) , pages 425 – 430 , 2015 . [ 56 ] Martin Potthast , Sarah Braun , Tolga Buz , Fabian Duﬀhauss , Florian Friedrich , Jörg Marvin Gülzow , Jakob Köhler , Win - fried Lötzsch , Fabian Müller , Maike Elisa Müller , Robert Paßmann , Bernhard Reinke , Lucas Rettenmeier , Thomas Rometsch , Timo Sommer , Michael Träger , Sebastian Wil - helm , Benno Stein , Efstathios Stamatatos , and Matthias Hagen . Who wrote the web ? Revisiting inﬂuential author identiﬁcation research applicable to information retrieval . In Nicola Ferro , Fabio Crestani , Marie - Francine Moens , Josiane Mothe , Fabrizio Silvestri , Giorgio Maria Di Nunzio , Claudia Hauﬀ , and Gianmaria Silvello , editors , Advances in Infor - mation Retrieval , pages 393 – 407 . Springer International Publishing , 2016 . [ 57 ] Martin Potthast , Matthias Hagen , and Benno Stein . Author obfuscation : Attacking the state of the art in authorship veriﬁcation . In CLEF 2016 Working Notes , 2016 . [ 58 ] Shrimai Prabhumoye , Yulia Tsvetkov , Ruslan Salakhutdi - nov , and Alan W . Black . Style Transfer Through Back - Translation . In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics ( ACL ) , pages 866 – 876 , 2018 . [ 59 ] Daniel Preotiuc - Pietro , Jordan Carpenter , and Lyle Ungar . Personality driven diﬀerences in paraphrase preference . In Proceedings of the Second Workshop on Natural Language Processing and Computational Social Science , pages 17 – 26 , 2017 . [ 60 ] Press Freedom Index . RSF Index 2018 : Hatred of journalism threatens democracies . https : / / rsf . org / en / rsf - index - 2018 - hatred - journalism - threatens - democracies ( May 1st 2018 ) . [ 61 ] Sravana Reddy and Kevin Knight . Obfuscating gender in social media writing . In Proceedings of Workshop on Natu - ral Language Processing and Computational Social Science , pages 17 – 26 , 2016 . [ 62 ] Jonathan Schler , Moshe Koppel , Shlomo Argamon , and James Pennebaker . Eﬀects of age and gender on blogging . In Proceedings of AAAI Spring Symposium on Computa - tional Approaches for Analyzing Weblogs , 2006 . Eﬀective writing style transfer via combinatorial paraphrasing 193 [ 63 ] Tianxiao Shen , Tao Lei , Regina Barzilay , and Tommi Jaakkola . Style transfer from non - parallel text by cross - alignment . In Proceedings of the International Conference on Neural Information Processing Systems ( NIPS ) , 2017 . [ 64 ] Rakshith Shetty , Bernt Schiele , and Mario Fritz . A 4 NT : Author attribute anonymity by adversarial training of neural machine translation . In Proceedings of the 27th USENIX Security Symposium , pages 1633 – 1650 , 2018 . [ 65 ] Efstathios Stamatatos . A survey of modern authorship attribution methods . Journal of the American Society for Information Science and Technology , 60 ( 3 ) : 538 – 556 , 2009 . [ 66 ] Ariel Stolerman , Rebekah Overdorf , Sadia Afroz , and Rachel Greenstadt . Breaking the closed - world assumption in stylo - metric authorship attribution . In Gilbert Peterson and Sujeet Shenoi , editors , Advances in Digital Forensics X , pages 185 – 205 , Berlin , Heidelberg , 2014 . Springer Berlin Heidelberg . [ 67 ] Kl Surendran , O . P . Harilal , Hrudya Poroli , Prabaharan Poor - nachandran , and N . K . Suchetha . Stylometry detection using deep learning . In Proceedings of Computational Intelligence in Data Mining , pages 749 – 757 , 2017 . [ 68 ] Neal Tempestt , Kalaivani Sundararajan , Aneez Fatima , Yim - ing Yan , Yingfei Xiang , and Damon Woodard . Surveying stylometry techniques and applications . ACM Computing Surveys , 50 ( 6 ) , 2017 . [ 69 ] Louis Tesnière . Èléments de syntaxe structurale . Klincksieck , Paris , 1959 . [ 70 ] Jingjing Xu , Xu Sun , Qi Zeng , Xuancheng Ren , Xiaodong Zhang , Houfeng Wang , and Wenjie Li . Unpaired sentiment - to - sentiment translation : A cycled reinforcement learning approach . In Proceedings of the Association for Computa - tional Linguistics ( ACL ) , pages 979 – 988 , 2018 . [ 71 ] Zichao Yang , Zhiting Hu , Chris Dyer , Eric P Xing , and Tay - lor Berg - Kirkpatrick . Unsupervised text style transfer using language models as discriminators . In Proceedings of the International Conference on Neural Information Processing ( NIPS ) , pages 7287 – 7298 , 2018 . [ 72 ] Liang - Chih Yu , Jin Wang , K . Robert Lai , and Xuejie Zhang . Reﬁning word embeddings using intensity scores for sen - timent analysis . In IEEE / ACM Transactions on Audio , Speech , and Language Processing , pages 671 – 681 , 2018 . [ 73 ] Jake Zhao , Yoon Kim , Kelly Zhang , Alexander M . Rush , and Yann LeCun . Adversarially regularized autoencoders . In Pro - ceedings of the 35th International Conference on Machine Learning , pages 5902 – 5911 , 2018 . [ 74 ] Rong Zheng , Jiexun Li , Hsinchun Chen , and Zan Huang . A framework of authorship identiﬁcation for online messages : Writing style features and classiﬁcation techniques . Journal of the American Society for Information Science and Tech - nology , 57 ( 3 ) : 378 – 393 , 2006 . A Raw results In this appendix we include the raw results from our sentence - based experiments , as well as example trans - formations by ParChoice and all baseline techniques . Two - class experiments : Table 23 displays two - class results for the original test sets and each style transfer direction on every style transfer technique , measured with all three author proﬁlers ( LSTM , CNN , WP ) . Ta - ble 24 shows corresponding results for each ParChoice module applied separately , using the ParChoice - LSTM variant and the LSTM proﬁler . Five - class experiments : Imitation results for each of the 20 author pairs from the ﬁve - class experiments are collected in Table 25 . Successful target author imitation results are written in bold ( higher target author accu - racy than source author accuracy ) . Example transformations : Table 26 shows exam - ple transformations by ParChoice , the encoder - decoder baselines ( rows 1 − 20 ) and the rule - based baselines ( rows 21 − 25 ) . Eﬀective writing style transfer via combinatorial paraphrasing 194 Data Direction Author proﬁler Proﬁler accuracy for source author Original CAE BT A 4 NT ParChoice CNN LSTM WP LR d LR s random YG f → m LSTM 0 . 83 0 . 55 0 . 54 0 . 64 0 . 41 0 . 35 0 . 54 0 . 43 0 . 46 0 . 69 CNN 0 . 75 0 . 44 0 . 43 0 . 57 0 . 21 0 . 28 0 . 46 0 . 28 0 . 32 0 . 57 WP 0 . 71 0 . 50 0 . 55 0 . 57 0 . 49 0 . 44 0 . 21 0 . 54 0 . 54 0 . 60 m → f LSTM 0 . 82 0 . 48 0 . 45 0 . 70 0 . 46 0 . 43 0 . 59 0 . 45 0 . 48 0 . 72 CNN 0 . 88 0 . 59 0 . 53 0 . 73 0 . 45 0 . 56 0 . 71 0 . 56 0 . 59 0 . 82 WP 0 . 78 0 . 56 0 . 54 0 . 72 0 . 61 0 . 60 0 . 32 0 . 64 0 . 65 0 . 74 BA a → t LSTM 0 . 54 0 . 26 0 . 28 0 . 35 0 . 38 0 . 16 0 . 37 0 . 26 0 . 33 0 . 52 CNN 0 . 57 0 . 38 0 . 32 0 . 40 0 . 19 0 . 25 0 . 35 0 . 24 0 . 33 0 . 49 WP 0 . 45 0 . 35 0 . 40 0 . 38 0 . 42 0 . 36 0 . 16 0 . 40 0 . 41 0 . 48 t → a LSTM 0 . 70 0 . 69 0 . 66 0 . 69 0 . 45 0 . 34 0 . 55 0 . 42 0 . 48 0 . 65 CNN 0 . 68 0 . 56 0 . 60 0 . 64 0 . 36 0 . 46 0 . 56 0 . 44 0 . 51 0 . 66 WP 0 . 73 0 . 58 0 . 61 0 . 70 0 . 61 0 . 59 0 . 35 0 . 57 0 . 59 0 . 68 AB A → B LSTM 0 . 88 0 . 18 0 . 18 0 . 74 0 . 54 0 . 36 0 . 63 0 . 56 0 . 62 0 . 74 CNN 0 . 92 0 . 22 0 . 16 0 . 80 0 . 46 0 . 50 0 . 58 0 . 56 0 . 64 0 . 76 WP 0 . 73 0 . 45 0 . 26 0 . 67 0 . 50 0 . 30 0 . 12 0 . 37 0 . 45 0 . 60 B → A LSTM 0 . 94 0 . 16 0 . 11 0 . 70 0 . 76 0 . 52 0 . 78 0 . 75 0 . 78 0 . 89 CNN 0 . 93 0 . 10 0 . 01 0 . 61 0 . 62 0 . 72 0 . 84 0 . 80 0 . 78 0 . 87 WP 0 . 90 0 . 09 0 . 19 0 . 68 0 . 81 0 . 68 0 . 31 0 . 68 0 . 78 0 . 85 TO T → O LSTM 0 . 86 0 . 95 0 . 64 0 . 34 0 . 76 0 . 43 0 . 76 0 . 59 0 . 66 0 . 81 CNN 0 . 60 0 . 88 0 . 60 0 . 46 0 . 36 0 . 52 0 . 57 0 . 53 0 . 55 0 . 58 WP 0 . 75 0 . 61 0 . 85 0 . 46 0 . 63 0 . 58 0 . 14 0 . 58 0 . 60 0 . 67 O → T LSTM 0 . 77 0 . 00 0 . 01 0 . 23 0 . 61 0 . 27 0 . 58 0 . 40 0 . 51 0 . 65 CNN 0 . 67 0 . 00 0 . 01 0 . 68 0 . 50 0 . 57 0 . 58 0 . 57 0 . 58 0 . 63 WP 0 . 73 0 . 31 0 . 09 0 . 36 0 . 62 0 . 57 0 . 16 0 . 56 0 . 61 0 . 64 Table 23 . Author proﬁling accuracies in two - class sentence - based datasets : best ( lowest ) results framed . Technique Direction YG BA AB TO Original ( no transformations ) 0 → 1 0 . 83 0 . 54 0 . 88 0 . 86 1 → 0 0 . 82 0 . 70 0 . 94 0 . 77 Grammatical transformations 0 → 1 0 . 72 0 . 48 0 . 69 0 . 80 1 → 0 0 . 70 0 . 62 0 . 85 0 . 68 Simple rules 0 → 1 0 . 81 0 . 51 0 . 85 0 . 82 1 → 0 0 . 82 0 . 66 0 . 91 0 . 72 PPDB 0 → 1 0 . 65 0 . 37 0 . 73 0 . 64 1 → 0 0 . 62 0 . 51 0 . 84 0 . 50 WordNet 0 → 1 0 . 65 0 . 36 0 . 77 0 . 65 1 → 0 0 . 70 0 . 48 0 . 80 0 . 52 Typos 0 → 1 0 . 79 0 . 39 0 . 79 0 . 82 1 → 0 0 . 82 0 . 65 0 . 74 0 . 65 Table 24 . Author proﬁling accuracies with individual ParChoice modules ( LSTM proﬁler , ParChoice - LSTM variant ) . Class 0 : { female , adult , Alice , Trump } ; Class 1 : { male , teen , Bob , Obama } Eﬀective writing style transfer via combinatorial paraphrasing 195 Source author Technique Authorproﬁler Target author ; proﬁler accuracies with imitated test sets A1 A2 A3 A4 A5 s t s t s t s t s t A1 ParChoice - LSTM LSTM ( 0 . 75 ) − 0 . 27 0 . 51 0 . 28 0 . 35 0 . 26 0 . 32 0 . 27 0 . 30 CNN ( 0 . 82 ) − 0 . 51 0 . 28 0 . 52 0 . 25 0 . 45 0 . 26 0 . 52 0 . 21 ParChoice - CNN LSTM ( 0 . 75 ) − 0 . 43 0 . 32 0 . 43 0 . 22 0 . 42 0 . 14 0 . 43 0 . 14 CNN ( 0 . 82 ) − 0 . 37 0 . 39 0 . 37 0 . 35 0 . 38 0 . 19 0 . 37 0 . 33 A2 ParChoice - LSTM LSTM 0 . 42 0 . 40 ( 0 . 81 ) − 0 . 47 0 . 21 0 . 41 0 . 31 0 . 44 0 . 15 CNN 0 . 53 0 . 33 ( 0 . 82 ) − 0 . 59 0 . 13 0 . 48 0 . 28 0 . 59 0 . 12 ParChoice - CNN LSTM 0 . 61 0 . 18 ( 0 . 81 ) − 0 . 62 0 . 12 0 . 61 0 . 13 0 . 62 0 . 07 CNN 0 . 46 0 . 29 ( 0 . 82 ) − 0 . 46 0 . 26 0 . 46 0 . 19 0 . 46 0 . 25 A3 ParChoice - LSTM LSTM 0 . 25 0 . 57 0 . 24 0 . 51 ( 0 . 64 ) − 0 . 24 0 . 37 0 . 25 0 . 27 CNN 0 . 30 0 . 48 0 . 39 0 . 30 ( 0 . 76 ) − 0 . 36 0 . 32 0 . 38 0 . 24 ParChoice - CNN LSTM 0 . 38 0 . 30 0 . 36 0 . 28 ( 0 . 64 ) − 0 . 43 0 . 15 0 . 43 0 . 14 CNN 0 . 28 0 . 43 0 . 29 0 . 42 ( 0 . 76 ) − 0 . 30 0 . 27 0 . 28 0 . 41 A4 ParChoice - LSTM LSTM 0 . 30 0 . 47 0 . 28 0 . 44 0 . 30 0 . 29 ( 0 . 71 ) − 0 . 28 0 . 32 CNN 0 . 50 0 . 35 0 . 52 0 . 23 0 . 53 0 . 11 ( 0 . 79 ) − 0 . 46 0 . 24 ParChoice - CNN LSTM 0 . 55 0 . 18 0 . 52 0 . 23 0 . 57 0 . 16 ( 0 . 71 ) − 0 . 55 0 . 12 CNN 0 . 31 0 . 29 0 . 31 0 . 34 0 . 31 0 . 33 ( 0 . 79 ) − 0 . 31 0 . 42 A5 ParChoice - LSTM LSTM 0 . 36 0 . 42 0 . 35 0 . 36 0 . 35 0 . 36 0 . 33 0 . 41 ( 0 . 64 ) − CNN 0 . 57 0 . 30 0 . 63 0 . 15 0 . 71 0 . 12 0 . 56 0 . 26 ( 0 . 75 ) − ParChoice - CNN LSTM 0 . 52 0 . 21 0 . 51 0 . 20 0 . 51 0 . 14 0 . 51 0 . 14 ( 0 . 64 ) − CNN 0 . 45 0 . 34 0 . 48 0 . 27 0 . 45 0 . 27 0 . 46 0 . 21 ( 0 . 75 ) − Table 25 . Five - class author imitation results ( s = source author accuracy , t = target author accuracy ) . Successful imitation in bold ( target author accuracy > source author accuracy ) . YG ( female → male ) Original the dinner portions are huge . CAE the drinks are $ 00 . BT the rooms are great . A 4 NT the dinner portions are ultra . ParChoice the supper shares are tremendous . BA ( adult → teen ) Original you feel like killing them but then again they are protected . CAE you feel like then you are them . BT eddy you want to see them , but now they are protégés . A 4 NT you feel like killing them but then again they are . ParChoice you feel like popping them but then again theyre been safeguarded . AB ( Alice → Bob ) Original we are so useless when it comes to bugs - its ridiculous ! CAE so yeah we went to < unk > it ’s < unk > . . . . BT i was fattoria nous , , and de . . . . . A 4 NT we are so far when it comes to me ! ParChoice were so ineﬀectual when it is about microbes its farcical . TO ( Obama → Trump ) Original i can tell you . CAE we ’re going . BT i ’s n’t . A 4 NT i can you disagree ParChoice you might well be told by me . EBG 5 Original They also tend to be somewhat adapted to ﬁre of varying frequencies . PAN2016 They also tended to be somewhat tailor to ﬁre of varying frequencies . Mutant - X They also tend to be somewhat adapted to ﬁreball of aforementioned frequencies . ParChoice they also tend to be somewhat adjusted to a ﬁre of diﬀering frequencies . ParChoice + Mutant - X they also tend to continue somewhat adjusted to a ﬁre of diﬀering frequencies . Table 26 . Style transfer examples ( ParChoice variant in YG / BA / AB / TO : ParChoice - LR s ) .