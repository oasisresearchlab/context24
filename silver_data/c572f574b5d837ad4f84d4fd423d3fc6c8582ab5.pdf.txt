Aggregating Inconsistent Information : Ranking and Clustering Nir Ailon (cid:3) Dept . of Computer Science Princeton University Princeton , NJ Moses Charikar y Dept . of Computer Science Princeton University Princeton , NJ Alantha Newman z Dept . of Computer Science RWTH Aachen Aachen , Germany ABSTRACT We address optimization problems in which we are given contradictory pieces of input information and the goal is to (cid:12)nd a globally consistent solution that minimizes the num - ber of disagreements with the respective inputs . Speci(cid:12) - cally , the problems we address are rank aggregation , the feedback arc set problem on tournaments , and correlation and consensus clustering . We show that for all these prob - lems ( and various weighted versions of them ) , we can obtain improved approximation factors using essentially the same remarkably simple algorithm . Additionally , we almost settle a long - standing conjecture of Bang - Jensen and Thomassen and show that unless NP (cid:18) BPP , there is no polynomial time algorithm for the problem of minimum feedback arc set in tournaments . Categories and Subject Descriptors F . 2 . 0 [ Analysis of Algorithms and Problem Complex - ity ] : General General Terms Algorithms , Theory (cid:3) Email : nailon @ cs . princeton . edu . y Email : moses @ cs . princeton . edu . Supported by NSF ITR grant CCR - 0205594 , DOE Early Career Principal Investigator award DE - FG02 - 02ER25540 , NSF CAREER award CCR - 0237113 , an Alfred P . Sloan Fel - lowship and a Howard B . Wentz Jr . Junior Faculty Award . z Email : alantha @ cs . rwth - aachen . de . Supported in part by the EU within the 6th Framework Programme under contract 001907 ( DELIS ) . Work done while visiting Princeton University , supported by Moses Charikar’s Alfred P . Sloan fellowship . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . STOC’05 , May 22 - 24 , 2005 , Baltimore , Maryland , USA . Copyright 2005 ACM 1 - 58113 - 960 - 8 / 05 / 0005 . . . $ 5 . 00 . Keywords Rank Aggregation , Consensus Clustering , Correlation Clus - tering , Minimum Feedback Arc Set , Tournament 1 . INTRODUCTION The problem of aggregating inconsistent information from many di(cid:11)erent sources arises in numerous contexts and dis - ciplines . For example , the problem of ranking a set of con - testants or a set of alternatives based on possibly con(cid:13)icting preferences is a central problem in the areas of voting and social choice theory . Speci(cid:12)cally , combining k di(cid:11)erent com - plete ranked lists on the same set of n elements into a single ranking , which best describes the preferences expressed in the given k lists , is known as the problem of rank aggrega - tion . This problem dates back to as early as the late 18th century when Condorcet and Borda each proposed voting systems for elections with more than two candidates [ 11 , 8 ] . There are numerous applications in sports , databases , and statistics [ 14 , 17 ] in which it is necessary to e(cid:11)ectively com - bine rankings from di(cid:11)erent sources . Another example of aggregating information is the problem of integrating pos - sibly contradictory clusterings from existing data sets into a single representative cluster . This problem is known as consensus clustering or ensemble clustering and can be ap - plied to remove noise and inconguencies from data sets [ 18 ] or combine information from multiple classi(cid:12)ers [ 30 ] . In the last half century , rank aggregation has been stud - ied and de(cid:12)ned from a mathematical perspective . In partic - ular , Kemeny proposed a precise criterion for determining the \ best " aggregate ranking 1 [ 24 , 23 ] . Given n candidates and k permutations of the candidates , f (cid:25) 1 ; (cid:25) 2 ; : : : ; (cid:25) k g , a Kemeny optimal ranking of the candidates is the ranking (cid:25) that minimizes P ki d ( (cid:25) ; (cid:25) i ) , where d ( (cid:25) j ; (cid:25) k ) denotes 2 the number of pairs of candidates that are ranked in di(cid:11)erent orders by (cid:25) j and (cid:25) k . For example , if (cid:25) j = ( 1 ; 2 ; 3 ; 4 ) and (cid:25) k = ( 2 ; 3 ; 1 ; 4 ) , then d ( (cid:25) j ; (cid:25) k ) = 2 since elements 1 and 2 appear in di(cid:11)erent orders in the two rankings as do elements 1 and 3 . In other words , a Kemeny optimal ranking mini - mizes the number of pairwise disagreements with the given k rankings . Throughout this paper we will slightly abuse terminology and refer to the problem of (cid:12)nding a Kemeny optimal ranking as the Rank - Aggregation problem . 1 Historically known as Kemeny aggregation . 2 The distance function d ( (cid:1) ; (cid:1) ) is known as the Kendall tau distance . More recently , the Rank - Aggregation problem has been studied from a computational perspective . Finding a Ke - meny optimal ranking is NP - hard [ 7 ] and remains NP - hard even when there are only four input lists to aggregate [ 14 ] . This motivates the problem of (cid:12)nding a ranking that ap - proximately minimizes the number of disagreements with the given input rankings . Several 2 - approximation algo - rithms [ 12 , 14 ] are known . In fact , if we take the best of the input rankings , then the number of disagreements be - tween this ranking and the k input rankings is no more than twice optimal . The problem of (cid:12)nding a globally consistent ranking based on possibly con(cid:13)icting pairwise information arises in the well studied problem of feedback arc set in a digraph | speci(cid:12)cally as the feedback arc set problem on tournaments . Throughout the paper , we refer to this problem as Fas - Tournament . A tournament is a directed graph G = ( V ; A ) such that for each pair of vertices i ; j 2 V , either ( i ; j ) 2 A of ( j ; i ) 2 A . The minimum feedback arc set is the smallest set A 0 (cid:18) A such that ( V ; A (cid:0) A 0 ) is acyclic . The size of this set is exactly the minimal number of back - ward edges induced by a linear ordering of V . This problem turns out to be useful in studying Rank - Aggregation , but is also interesting in its own right . For example , imagine a sports tournament where each player plays against every other player once : How should we rank the players based on these possibly non - transitive ( inconsistent ) outcomes ? The complementary problem to (cid:12)nding a minimum feedback arc set is the maximum acyclic subgraph problem , also known as the linear ordering problem . The Rank - Aggregation problem can be cast as a spe - cial case of weighted Fas - Tournament , where the objective is to minimize the total weight of backward edges in a lin - ear order of the vertices . When the weight of edge ( i ; j ) is the fraction of input rankings that order i before j , solving Rank - Aggregation is equivalent to solving this weighted Fas - Tournament instance . The last problem we consider is that of clustering objects based on complete but possibly con(cid:13)icting pairwise infor - mation . An instance of this problem can be represented by a graph with a vertex for each object and a ’ + ’ or a ’ - ’ for each pair of vertices , indicating that two elements should be in the same or di(cid:11)erent clusters , respectively . The goal is to cluster the elements so as to minimize the number of ’ - ’ edges within clusters and ‘ + ’ edges crossing clusters . We re - fer to this problem as Correlation - Clustering ( on com - plete graphs ) . An analog to Rank - Aggregation is known as the Consensus - Clustering problem . In this problem , we are given k clusterings of the same set of n elements . The goal is to (cid:12)nd a clustering that minimizes the number of pairwise disagreements with the given k clusterings . 1 . 1 Previous Work The minimum feedback arc set problem can be approxi - mated to within O ( log n log log n ) in general graphs [ 16 , 28 ] and has ( at least ) the same approximation hardness as the vertex cover problem [ 22 ] , which is 1 . 36 [ 13 ] . More than a decade ago , Bang - Jensen and Thomassen conjectured that the Fas - Tournament problem is NP - hard [ 5 ] . However , for the past decade , no progress has been made on settling this conjecture . In contrast , the minimum feedback vertex set problem on tournaments is NP - hard [ 29 ] and is approx - imable to within 2 . 5 [ 9 ] We are not aware of any approximation for Fas - Tournament that improves on the bound for the general feedback arc set problem . The complementary maximiza - tion problem on tournaments seems to be easier from an approximation standpoint . Arora , Frieze and Kaplan [ 4 ] and Frieze and Kannan [ 19 ] gave PTASs for the maximum acyclic subgraph problem in dense graphs , which implies a PTAS for the problem on tournaments . There are two well - known factor 2 - approximation algo - rithms for Rank - Aggregation . One such approximation is to pick one of the k given permutations at random . We will call this algorithm Pick - A - Perm . The Spearman’s footrule distance between two permutations (cid:25) i and (cid:25) j on n elements is de(cid:12)ned to be : F ( (cid:25) i ; (cid:25) j ) = P nk = 1 j (cid:25) i ( k ) (cid:0) (cid:25) j ( k ) j . The footrule distance is no more than twice the Kemeny dis - tance [ 12 ] and can be computed in polynomial time via a minimum cost matching [ 14 , 15 ] . These observations yield another 2 - approximation . Correlation - Clustering has been studied both on gen - eral and complete graphs . Both minimization and maxi - mizing versions have been investigated . Bansal , Blum and Chawla gave the (cid:12)rst constant factor approximation for the problem of minimizing disagreements on the complete graph [ 6 ] . This factor was improved to 4 by rounding a linear pro - gram [ 10 ] . The weighted version of this problem in which edges have fractional (cid:6) assignments has also been studied . Each edge is assigned fractional values w + ij and w (cid:0) ij rather than a discrete 0 + 0 or 0 (cid:0) 0 label . When the edge weights satisfy the probability constraints ( i . e . w + ij + w (cid:0) ij = 1 for all edges ) , the best previous approximation factor was 7 [ 20 , 6 ] . When the edge weights satisfy the probability and the trian - gle inequality constraints ( see Section 1 . 2 ) , the best previous approximation factor was 3 [ 20 ] . Correlation - Clustering on complete graphs is MAX - SNP - hard [ 10 ] and Consensus - Clustering is NP - hard [ 31 ] . However , Consensus - Clustering is not known to be NP - hard if the number of input clusters is constant [ 18 ] . Anal - ogously to Rank - Aggregation , choosing the best clus - ter out of the given k input clusters ( algorithm Pick - A - Cluster ) is an expected 2 - approximation algorithm and 2 was the best previously known approximation factor for this problem . 1 . 2 Our Results We give improved approximation algorithms for the fol - lowing optimization problems : ( i ) Fas - Tournament , ( ii ) Rank - Aggregation , ( iii ) Correlation - Clustering and ( iv ) Consensus - Clustering . We show that they can all be approximated using essentially the same remarkably simple algorithm . For example , the algorithm for Fas - Tournament , called Fas - Pivot , is as follows : First , we pick a random vertex i to be the \ pivot " vertex . Second , we place all vertices connected to i with an in - edge on the left side of i and all vertices connected to i with an out - edge on the right side of i . We then recurse on the two tournaments induced by the vertices on each side . The analysis of Fas - Pivot yields a 3 - approximation algo - rithm for Fas - Tournament , improving on the best - known previous factor of O ( log n log log n ) . Our analysis relies on a new technique for arguing a lower bound for Fas - Tournament by demonstrating a fractional packing of edge disjoint directed triangles . We apply this algorithm to Rank - Aggregation as follows . We convert the Rank - Aggre - gation instance into a weighted Fas - Tournament instance , which we then convert to an unweighted Fas - Tournament instance using the majority tournament ( see De(cid:12)nition 1 ) . Finally we run Fas - Pivot on this majority tournament . Al - though this algorithm by itself is yet another 2 - approxima - tion , the following is an 11 / 7 - approximation : run both Fas - Pivot and Pick - A - Perm and output the best solution . This improved approximation ratio is due to the fact that each algorithm does well on instances in which the other algorithm does poorly . For Correlation - Clustering and Consensus - Clus - tering we present similar combinatorial algorithms and anal - yses which , interestingly , give results that are analogous to the results for Fas - Tournament and Rank - Aggregation and improve upon previously known approximation factors . A simple lower bound on the value of an optimal solu - tion for weighted Fas - Tournament is to take the sum over all vertices i < j of min f w ij ; w ji g . In contrast , our anal - ysis uses a stronger lower bound based on the weight of directed triangles ( \ bad triangles " ) in the majority graph . Interestingly , the analysis of our simple combinatorial al - gorithm bounds the integrality gap of a natural LP relax - ation for Fas - Tournament . In fact , it demonstrates an LP dual solution based on probabilities of random events oc - curing during the execution 3 . A similar analysis is done for Consensus - Clustering , with a di(cid:11)erent notion of \ bad triplets " . Our analysis is applied to various cases of weighted Fas - Tournament ( resp . weighted Correlation - Clustering ) . More precisely , we analyze the following cases : ( i ) Probability Constraints : w ij + w ji = 1 ( resp . w + ij + w (cid:0) ij = 1 ) for all i ; j 2 V . ( ii ) Triangle Inequality : w ij (cid:20) w ik + w kj ( resp . w (cid:0) ij + w (cid:0) jk (cid:20) w (cid:0) jk ) for all i ; j ; k 2 V . ( iii ) Aggregation : Edge weights are a convex combination of actual permutations ( resp . clusters ) . Constraints ( i ) and ( ii ) are implied in this case . Table 1 summarizes the approximation factors we achieve for the di(cid:11)erent scenarios with the combinatorial algorithms . Additionally , we consider LP relaxations for Fas - Tourna - ment and Correlation - Clustering . After choosing a pivot vertex , instead of deterministically placing vertices on the right or left side ( in Fas - Pivot ) , or in a cluster ( in CC - Pivot ) , we decide randomly based on LP values . This results in vastly improved approximation factors . We state improvements on the approximation guarantees obtainable via our LP rounding techniques based on inequalities that are proven in [ 1 ] . Finally , we show that Fas - Tournament has no polyno - mial time algorithm assuming NP * BPP . The question of NP - hardness of Fas - Tournament has been a long - standing conjecture of Bang - Jensen and Thomassen [ 5 ] . We show a randomized reduction from the problem of (cid:12)nding a mini - mum feedback arc set in general digraphs ( which is known to be NP - hard ) to the special case of tournaments . This proof has been recently derandomized by Noga Alon [ 2 ] , and the conjecture is therefore proven completely . We present the weaker randomized version here . 3 We will not pursue the discussion on the dual LP in this extended abstract . Ordering Clustering UnweightedTournaments 3 ( * ) 3 ( 4 ) [ 10 ] ProbabilityConstraints ( i ) 5 ( * ) 5 ( 9 ) [ 10 , 6 ] TriangleInequality ( ii ) 3 ( * ) N / A ( * * ) ProbabilityConstraints + TriangleInequality ( i , ii ) 2 ( * ) 2 ( 3 ) [ 20 ] Aggregation ( iii ) 11 / 7 ( 2 ) 11 / 7 ( 2 ) Table 1 : The previous best - known factors are shown in parentheses . ( * ) The best - known factor was the O ( log n log log n ) algorithm [ 16 , 28 ] for digraphs . ( * * ) Our techniques cannot directly be applied to weighted Correlation - Clustering with triangle in - equality but no probability constraints . 1 . 3 Organization In Section 2 , we give precise problem statements and de(cid:12) - nitions . In Section 3 , we present Fas - Pivot and analyze its approximation guarantee , introducing the basic ideas we use throughout the paper . In Section 4 , we extend these ideas to approximate weighted Fas - Tournament . In Section 5 , we further extend our techniques to approximate Rank - Aggregation . In Section 6 , we discuss Correlation - Clustering and Consensus - Clustering . In Section 7 , we extend our ideas to round LP’s for Fas - Tournament and Correlation - Clustering . In Section 8 , we prove hard - ness results for Fas - Tournament . In Section 9 we discuss open problems and future work . 2 . PRELIMINARIES AND DEFINITIONS We study the following problems in this paper . In what follows , we (cid:12)x a ground set V = f 1 ; : : : ; n g . Fas - Tournament : ( Minimum Feedback Arc Set in Tour - naments ) We are given a tournament G = ( V ; A ) ( a digraph with either ( i ; j ) 2 A or ( j ; i ) 2 A for all distinct i ; j 2 V ) . We want to (cid:12)nd a permutation (cid:25) on V minimizing the num - ber of pairs i ; j such that i < (cid:25) j and ( j ; i ) 2 A ( back - ward edges w . r . t . (cid:25) ) 4 . In a weighted Fas - Tournament instance , we are given weights w ij (cid:21) 0 for all ordered i ; j 2 V . We want to (cid:12)nd a permutation (cid:25) on V minimizing P i ; j : i < (cid:25) j w ji . Clearly , the unweighted case can be encoded as a 0 = 1 weighted case . Rank - Aggregation : We are given a list of k permuta - tions ( rankings ) (cid:25) 1 ; : : ; (cid:25) k on V . We want to (cid:12)nd a permuta - tion (cid:25) minimizing the sum of distances P ki = 1 d ( (cid:25) ; (cid:25) i ) , where d ( (cid:25) ; (cid:26) ) is the number of pairs i ; j such that i < (cid:25) j but j < (cid:26) i ( the Kemeny distance ) . Correlation - Clustering : Between any two unordered i ; j 2 V we either have a ( + ) or a ( (cid:0) ) relation . We let E + ( resp . E (cid:0) ) denote the set of pairs i 6 = j which are ( + ) - related ( resp . ( (cid:0) ) - related ) . We want to (cid:12)nd disjoint clusters C 1 ; : : : ; C m covering V and minimizing the num - 4 By i < (cid:25) j we mean that (cid:25) ranks i before j . ber of disagreement pairs ( ( + ) pairs in di(cid:11)erent clusters or ( (cid:0) ) pairs in the same cluster ) . In a weighted Correlation - Clustering instance , we assign for each pair i ; j two weights w + ij (cid:21) 0 and w (cid:0) ij (cid:21) 0 . The cost of a clustering will now be the sum of w + ij over all i ; j in di(cid:11)erent clusters , plus the sum of w (cid:0) ij over all i ; j in the same cluster . Clearly , the unweighted case can be encoded as a 0 = 1 weighted case . Consensus - Clustering : We are given a list of k di(cid:11)er - ent clusterings C 1 ; : : : ; C k of V , and we wish to (cid:12)nd one clus - tering C that minimizes P ki = 1 d ( C ; C i ) , where the distance d ( C ; D ) between two clusterings is the number of unordered paris i ; j 2 V that are clustered together by one and sepa - rated by the other . Definition 1 . Given an instance ( V ; w ) of weighted Fas - Tournament , we de(cid:12)ne the unweighted majority tourna - ment G w = ( V ; A w ) as follows : ( i ; j ) 2 A w if w ij > w ji . If w ij = w ji , then we decide ( i ; j ) 2 A w or ( j ; i ) 2 A w arbitrar - ily . Given an instance ( V ; w + ; w (cid:0) ) of weighted Correla - tion - Clustering , we de(cid:12)ne the unweighted majority in - stance ( V ; E + w ; E (cid:0) w ) as follows : ( i ; j ) 2 E + w if w + ij > w (cid:0) ij , and ( i ; j ) 2 E (cid:0) w if w (cid:0) ij > w + ij . If w + ij = w (cid:0) ij , then we decide arbitrarily . Note that although the majority instances depend on the weights of the weighted instances , they are unweighted in - stances . 3 . MINIMUM FEEDBACK ARC SET IN TOURNAMENTS Let G = ( V ; A ) be a Fas - Tournament instance . We present the following algorithm Fas - Pivot for approximat - ing it . Fas - Pivot ( G = ( V ; A ) ) Set V L ! ; ; V R ! ; . Pick random pivot i 2 V . For all vertices j 2 V n f i g : If ( j ; i ) 2 A then Add j to V L ( place j on left side ) . Else ( If ( i ; j ) 2 A ) Add j to V R ( place j on right side ) . Let G L = ( V L ; A L ) be tournament induced by V L . Let G R = ( V R ; A R ) be tournament induced by V R . Return order Fas - Pivot ( G L ) , i , Fas - Pivot ( G R ) . ( Concatenation of left recursion , i , and right recursion . ) Theorem 2 . Algorithm Fas - Pivot is a randomized ex - pected 3 - approximation algorithm for Fas - Tournament . Proof . Let C OPT denote the cost of an optimal solution . Let C PIV denote the cost of Fas - Pivot on G = ( V ; A ) . We want to show that E [ C PIV ] (cid:20) 3 C OPT . An edge ( i ; j ) 2 A becomes a backward edge if and only if there exists a third vertex k such that ( i ; j ; k ) form a di - rected triangle 5 in G and k was chosen as a pivot when all three were input to the same recursive call . Pivoting on k 5 In what follows we will use ( i ; j ; k ) to denote the directed triangle i ! j , j ! k , k ! i . It will be clear from the context whether a triangle is the set of its vertices or its edges . would then place i to its right and j to its left , rendering edge ( i ; j ) backward . In this case , we will charge a unit cost of the backward edge ( i ; j ) to the directed triangle ( i ; j ; k ) . Let T denote the set of directed triangles . For a directed tri - angle t 2 T , denote by A t the event that one of its vertices is chosen as pivot when all three are part of the same recursive call . Let p t denote the probability of event A t . Now we ob - serve , that a triangle t is charged a unit cost exactly when A t occurs , and it can be charged at most once . Therefore , the expected cost of Fas - pivot is exactly E [ C PIV ] = P t 2 T p t . Clearly , if we had a set of edge disjoint triangles , then a lower bound for C OPT would be its cardinality . This is also true fractionally : If f (cid:12) t g t 2 T is a system of nonnegative weights on triangles in T such that for all e 2 A , P t : e 2 t (cid:12) t (cid:20) 1 , then C OPT (cid:21) P t 2 T (cid:12) t . Indeed , consider the following LP relaxation for the problem : minimize P e 2 A x e , subject to x e 1 + x e 2 + x e 3 (cid:21) 1 for edge sets f e 1 ; e 2 ; e 3 g 2 T , and x e (cid:21) 0 for all e 2 A . The solution to this LP clearly lower bounds C OPT . It is easy to show that a packing f (cid:12) t g is a feasible solution to the dual LP , hence a lower bound on the optimal . We will demonstrate such a packing using the probabili - ties p t . Let t = ( i ; j ; k ) be some triangle . Conditioned on the event A t , each one of the 3 vertices of t was the break - ing vertex with probability 1 = 3 , because all vertices input to a recursive call are chosen as pivot with equal probabil - ity . Therefore , any edge e = ( i ; j ) of t becomes a backward edge with probability 1 = 3 ( still , conditioned on A t ) . Let B e denote the event that e becomes a backward edge . Clearly , if A t occured then B e occured if and only if k was the (cid:12)rst chosen pivot among i ; j ; k . Then we get that for all t 2 T and e 2 t , Pr [ B e ^ A t ] = Pr [ B e j A t ] Pr [ A t ] = 1 3 p t : The main observation of this proof is as follows : For two dif - ferent triangles t ; t 0 2 T sharing an edge e , the events B e ^ A t and B e ^ A t 0 are disjoint . Indeed , if e is charged to triangle t , then the endpoints of e are split between two di(cid:11)erent recursive calls , and event A t 0 cannot occur . Therefore , for all e 2 E , X t : e 2 t 1 3 p t (cid:20) 1 : ( 1 ) So f p t = 3 g t 2 T is a fractional packing of T . Thus , C OPT (cid:21) P t 2 T p t = 3 = E [ C PIV ] = 3 , as required . 4 . MINIMUM FEEDBACK ARC SET IN WEIGHTED TOURNAMENTS Let ( V ; w ) be a weighted Fas - Tournament instance . We suggest the following approximation algorithm : construct the unweighted majority tournament G w = ( V ; A w ) and re - turn the ordering generated by Fas - Pivot ( G w ) . We analyze this algorithm . For an edge e = ( i ; j ) 2 A w , we let w ( e ) = w ij , and (cid:22) w ( e ) = w ji = 1 (cid:0) w ( e ) (cid:20) w ( e ) . Fix an optimal solution (cid:25) (cid:3) , and let c (cid:3) ( e ) denote the cost incurred to it by e = ( i ; j ) 2 A w , that is , c (cid:3) ( e ) = w ( e ) if j < (cid:25) (cid:3) i , else c (cid:3) ( e ) = (cid:22) w ( e ) . So C OPT = P e 2 A w c (cid:3) ( e ) . Let T denote the set of directed triangles in G w . For any t = ( e 1 ; e 2 ; e 3 ) 2 T , we de(cid:12)ne c (cid:3) ( t ) = c (cid:3) ( e 1 ) + c (cid:3) ( e 2 ) + c (cid:3) ( e 3 ) , w ( t ) = w ( e 1 ) + w ( e 2 ) + w ( e 3 ) . Finally , let C PIV denote the cost the solution returned by Fas - Pivot ( V ; G w ) . Theorem 3 . For an instance ( V ; w ) of weighted Fas - Tournament , if there exists a constant (cid:11) > 0 such that w ( t ) (cid:20) (cid:11)c (cid:3) ( t ) for all t 2 T , then E [ C PIV ] (cid:20) (cid:11)C OPT , i . e . Fas - Pivot ( G w ) is an expected (cid:11) - approximation solution . Proof . We generalize techniques presented in Section 3 . When FAS - Pivot is run on G w , an edge e 2 A w is heavily charged if it becomes a backward edge , and thus incurs the heavy cost w ( e ) . It is lightly charged if it incurs the light cost (cid:22) w ( e ) . Clearly , e = ( i ; j ) 2 A w is heavily charged if and only if a third vertex k is chosen as pivot when all three i ; j ; k are in the same recursive call , and ( i ; j ; k ) form a directed triangle in G w . We charge this cost to triangle t = ( i ; j ; k ) . Again we consider the set T of directed triangles in G w , and their corresponding events A t with probability p t ( see Section 3 ) . Fix a triangle t 2 T with edges e 1 ; e 2 ; e 3 . Conditioned on A t , each of e 1 ; e 2 and e 3 are equally likely to be heavily charged , so the expected charge of t is 13 p t w ( t ) . The probability that an edge e 2 A w does not incur a heavy cost ( not charged to a triangle t 2 T ) is exactly 1 (cid:0) P t : e 2 t 13 p t : Therefore , E [ C PIV ] = B PIV + F PIV , where B PIV = X t 2 T 1 3 p t w ( t ) F PIV = X e 2 A w 1 (cid:0) X t : e 2 t 1 3 p t ! (cid:22) w ( e ) : We rearrange the sum C OPT = P e 2 T c (cid:3) ( e ) as C OPT = B OPT + F OPT , where B OPT = X t 2 T 1 3 p t c (cid:3) ( t ) F OPT = X e 2 A w 1 (cid:0) X t : e 2 t 1 3 p t ! c (cid:3) ( e ) : Notice that for all e 2 A w , the term ( 1 (cid:0) P t : e 2 t 13 p t ) is nonnegative ( see Section 3 ) . Obviously , F PIV (cid:20) F OPT , because (cid:22) w ( e ) (cid:20) c (cid:3) ( e ) for any e 2 A w . Therefore , if for some (cid:11) > 0 , w ( t ) (cid:20) (cid:11)c (cid:3) ( t ) for all t , then E [ C PIV ] (cid:20) (cid:11)C OPT as required . Lemma 4 . If the weights satisfy the probability constraints ( w ij + w ji = 1 ) , then w ( t ) (cid:20) 5 c (cid:3) ( t ) for all t 2 T . If the weights satisfy the triangle inequality constraints ( w ij (cid:20) w ik + w kj ) , then w ( t ) (cid:20) 3 c (cid:3) ( t ) for all t 2 T . If the weights satisfy the combined constraints , then w ( t ) (cid:20) 2 c (cid:3) ( t ) for all t 2 T . Proof . First assume probability constraints on the weights . In this case , we claim that w ( t ) (cid:20) 5 c (cid:3) ( t ) . Indeed , in this case w ( e ) (cid:21) 1 = 2 for all e 2 A w , and (cid:22) w ( e ) = 1 (cid:0) w ( e ) . Fix a triangle t containing edges e 1 ; e 2 ; e 3 , and assume 1 = 2 (cid:20) w ( e 1 ) (cid:20) w ( e 2 ) (cid:20) w ( e 3 ) (cid:20) 1 : ( 2 ) Clearly , w ( t ) = w ( e 1 ) + w ( e 2 ) + w ( e 3 ) (cid:20) 2 + w ( e 1 ) . Any so - lution has to direct at least one of the edges in t backwards , therefore c (cid:3) ( t ) (cid:21) w ( e 1 ) . Since w ( e 1 ) 2 [ 1 = 2 ; 1 ] , we therefore have w ( t ) (cid:20) 5 c (cid:3) ( t ) . Consequently , FAS - Pivot has an ex - pected approximation ratio of at most 5 on weighted tourna - ment instances with probability constraints on the weights . Assume that in addition to the probability constraints , the weights satisfy the triangle inequality . So w ( t ) (cid:20) 2 . But the optimal solution has to pay the price of at least one backward edge , so c (cid:3) ( t ) (cid:21) w ( e 1 ) + (cid:22) w ( e 2 ) + (cid:22) w ( e 3 ) (cid:21) 2 w ( e 1 ) ( the right inequality follows from the triangle inequality (cid:22) w ( e 2 ) + (cid:22) w ( e 3 ) (cid:21) w ( e 1 ) ) . Finally , w ( e 1 ) (cid:21) 1 = 2 and there - fore c (cid:3) ( t ) (cid:21) 1 and w ( t ) (cid:20) 2 c (cid:3) ( t ) . Consequently FAS - Pivot has an expected approximation ratio of at most 2 on weighted tournament instances with both triangle inequality and probability constraints on the weights . Now we assume that the edge weights satisfy the triangle inequality , but not necessarily the probability constraints . Fix t 2 T with edge weights w ( e 1 ) ; w ( e 2 ) ; w ( e 3 ) . Assume ( 2 ) holds . Showing that c (cid:3) ( t ) (cid:21) w ( e 3 ) will prove the lemma for this case . There are 6 possible ways in which the opti - mal solution can order the vertices of t . For 3 possiblities , e 3 becomes a backward edge , and therefore c (cid:3) ( t ) (cid:21) w ( e 3 ) . The other 3 are analyzed case by case . If e 3 and e 2 are forward edges but e 1 is a backward edge , then c (cid:3) ( t ) = w ( e 1 ) + (cid:22) w ( e 2 ) + w ( e 3 ) (cid:21) (cid:22) w ( e 1 ) + (cid:22) w ( e 2 ) + (cid:22) w ( e 3 ) . But by the tri - angle inequality , (cid:22) w ( e 1 ) + (cid:22) w ( e 2 ) (cid:21) w ( e 3 ) , so c (cid:3) ( t ) (cid:21) w ( e 3 ) , as required . If e 3 and e 1 are forward edges but e 2 is a backward edge , we argue similarly . If e 3 is a forward edge but e 1 ; e 2 are backward edges , then c (cid:3) ( t ) = w ( e 1 ) + w ( e 2 ) + (cid:22) w ( e 3 ) (cid:21) (cid:22) w ( e 1 ) + (cid:22) w ( e 2 ) + (cid:22) w ( e 3 ) , which is , again , at least w ( e 3 ) by the triangle inequality . This completes all the cases . Combining Theorem 3 and Lemma 4 , we get Theorem 5 . Running algorithm Fas - Pivot on G w gives an expected 5 ; 3 and 2 approximation for the probability con - straints case , the triangle inequality constraints case , and the combined constraints case , respectively . 5 . AN IMPROVED APPROXIMATION RATIO FOR RANK AGGREGATION Let f (cid:25) 1 ; : : : ; (cid:25) k g be a Rank - Aggregation instance over some V . Consider the corresponding equivalent weighted Fas - Tournament instance ( V ; w ) ( where w ij is the frac - tion of inputs ranking i before j ) . Clearly , this weight sys - tem f w ij g is a convex combination of acyclic tournaments . Therefore , by linearity , the edge weights obey the probabil - ity constraints and the triangle inequality constraints . Theo - rem 5 shows that we get a 2 approximation for this case , but the additional structure in these instances allows us to im - prove upon this factor . As stated in the introduction , there already exists a well known 2 - approximation algorithm for Rank - Aggregation : Pick - A - Perm ( f (cid:25) 1 ; (cid:25) 2 ; : : : (cid:25) k g ) Output a permutation (cid:25) i chosen uniformly at random from the input permutations . ( In practice , we can pick the permutation (cid:25) i that minimizes the cost , but we use the randomized version for the anal - ysis ) . Let C PAP denote the cost of Pick - A - Perm on the Rank - Aggregation instance . Let G w = ( V ; A w ) be the corresponding unweighted majority tournament . Using no - tation from Section 4 , Let z ( e ) = 2 w ( e ) (cid:22) w ( e ) . We claim that E [ C PAP ] = X e 2 A w z ( e ) : ( 3 ) Indeed , edge e 2 A w becomes a backward ( resp . forward ) edge with probability (cid:22) w ( e ) ( resp . w ( e ) ) , in which case it incurs the cost of w ( e ) ( resp . (cid:22) w ( e ) ) . For a directed triangle t = ( e 1 ; e 2 ; e 3 ) 2 T , we let z ( t ) = z ( e 1 ) + z ( e 2 ) + z ( e 3 ) . The following theorem shows how to analyze a \ convex combi - nation " of Fas - Pivot and Pick - A - Perm : Theorem 6 . If there exist constants (cid:12) 2 [ 0 ; 1 ] and (cid:13) > 0 such that (cid:12)w ( t ) + ( 1 (cid:0) (cid:12) ) z ( t ) (cid:20) (cid:13)c (cid:3) ( t ) for all t 2 T ; and (cid:12) + 2 ( 1 (cid:0) (cid:12) ) (cid:20) (cid:13) ; then the best of Fas - Pivot and Pick - A - Perm is a (cid:13) - approximation for Rank - Aggregation . Proof . We use the notation C OPT ; F OPT ; B OPT ; c (cid:3) ( e ) ; c (cid:3) ( t ) de(cid:12)ned in Section 4 . We rearrange ( 3 ) as E [ C PAP ] = B PAP + F PAP , where B PAP = X t 2 T 1 3 p t z ( t ) F PAP = X e 2 A w ( 1 (cid:0) X t : e 2 t 1 3 p t ) z ( e ) : Clearly , F PAP (cid:20) 2 F OPT , because z ( e ) (cid:20) 2 c (cid:3) ( e ) for any e 2 A w and ( 1 (cid:0) P t : e 2 t 13 p t ) (cid:21) 0 . If we now have (cid:12) ; (cid:13) as in the statement of the theorem , then (cid:12)E [ C PIV ] + ( 1 (cid:0) (cid:12) ) E [ C PAP ] = (cid:12)B PIV + ( 1 (cid:0) (cid:12) ) B PAP + (cid:12)F PIV + ( 1 (cid:0) (cid:12) ) F PAP = X t 2 T 1 3 p t ( (cid:12)w ( t ) + ( 1 (cid:0) (cid:12) ) z ( t ) ) + X e 2 A w 1 (cid:0) X t : e 2 t 1 3 p t ! ( (cid:12) (cid:22) w ( e ) + ( 1 (cid:0) (cid:12) ) z ( e ) ) (cid:20) X t 2 T 1 3 p t ( (cid:12)w ( t ) + ( 1 (cid:0) (cid:12) ) z ( t ) ) + X e 2 A w 1 (cid:0) X t : e 2 t 1 3 p t ! ( (cid:12)c (cid:3) ( e ) + ( 1 (cid:0) (cid:12) ) 2 c (cid:3) ( e ) ) (cid:20) X t 2 T 1 3 p t (cid:13)c (cid:3) ( t ) + X e 2 A w 1 (cid:0) X t : e 2 t 1 3 p t ! (cid:13)c (cid:3) ( e ) = (cid:13)C OPT ; as required . Lemma 7 . For all t 2 T , 3 7 w ( t ) + 4 7 z ( t ) (cid:20) 11 7 c (cid:3) ( t ) : Proof . We want to show that f ( t ) = 3 7 w ( t ) + 4 7 z ( t ) (cid:0) 11 7 c (cid:3) ( t ) (cid:20) 0 ; where ( slightly changing notation ) t = ( w 1 ; w 2 ; w 3 ) and w ( t ) = w 1 + w 2 + w 3 z ( t ) = 2 w 1 ( 1 (cid:0) w 1 ) + 2 w 2 ( 1 (cid:0) w 2 ) + 2 w 3 ( 1 (cid:0) w 3 ) c (cid:3) ( t ) = 1 (cid:0) w 2 + 1 (cid:0) w 3 + w 1 1 = 2 (cid:20) w 1 (cid:20) w j (cid:20) 1 for j = 2 ; 3 w 1 + w 2 + w 3 (cid:20) 2 The proof can be completed by (cid:12)nding the global maxi - mum of f ( t ) on the de(cid:12)ned polytope using standard tech - niques of multivariate calculus . We omit the details from this version . Theorem 8 follows from Theorem 6 and Lemma 7 , using (cid:12) = 3 = 7 and (cid:13) = 11 = 7 : Theorem 8 . The best of Fas - Pivot on G w and Pick - A - Perm is an expected 11 = 7 approximation for Rank - Aggregation . 6 . CORRELATION CLUSTERING AND CONSENSUS CLUSTERING In this section , we show how to apply the techniques presented in Section 3 to Correlation - Clustering and Consensus - Clustering . Disagreements in the output so - lution can also be charged to bad triplets , which will be de - (cid:12)ned shortly . The bad triplets replace the role taken by the directed triangles in tournaments . Let ( V ; E + ; E (cid:0) ) be a Correlation - Clustering instance . Our algorithm CC - Pivot , which is an analog of Fas - Pivot , is de(cid:12)ned as fol - lows : CC - Pivot ( G = ( V ; E + ; E (cid:0) ) ) Pick random pivot i 2 V . Set C = f i g ; V 0 = ; . For all j 2 V ; j 6 = i : If ( i ; j ) 2 E + then Add j to C Else ( If ( i ; j ) 2 E (cid:0) ) Add j to V 0 Let G 0 be the subgraph induced by V 0 . Return clustering C , CC - Pivot ( G 0 ) : As in the analysis of Fas - Pivot , a pair i ; j incurs a unit cost if a third vertex k is chosen as pivot when the triplet ( i ; j ; k ) is in the same recursive call , and there are two ( + ) and one ( (cid:0) ) relations among i ; j ; k ( doesn’t matter in which order ) . A triplet ( i ; j ; k ) is therefore a bad triplet if it has two ( + ) and one ( (cid:0) ) relations 6 . Let T denote the set of ( not necessarily disjoint ) bad triplets . For each t = ( i ; j ; k ) 2 T we de(cid:12)ne A t as the event that all three i ; j ; k are in the same recursive call when the (cid:12)rst one among them was chosen as pivot . Let p t denote the probability of A t . The analysis continues identically to that of Fas - Pivot . Theorem 9 . Algorithm CC - Pivot is a randomized ex - pected 3 - approximation algorithm for Correlation - Clustering . Now let ( V ; w + ; w (cid:0) ) be a weighted Correlation - Clus - tering instance . Unlike weighted Fas - Tournament , we will only consider weight systems that satisfy the probability constraints w + ij + w (cid:0) ij = 1 . We create the unweighted major - ity Correlation - Clustering instance G w = ( V ; E + w ; E (cid:0) w ) 6 A Correlation - Clustering instance with no bad triplets induces a consistent clustering , just as a tournament with no 3 - cycles is acyclic . Our algorithms have an optimal cost of 0 on these instances . and return the clustering generated by CC - Pivot ( G w ) . Us - ing the same analysis as in Section 4 , we can show that this algorithm gives an expected 5 approximation . Triangle inequality constraints in weighted Correlation - Clustering have the following form : for all i ; j ; k , w + ij + w + jk + w (cid:0) ik (cid:20) 2 : ( Equivalently , w (cid:0) ik (cid:20) w (cid:0) ij + w (cid:0) jk . ) Theorem 10 is analogous to Theorem 5 : Theorem 10 . Algorithm CC - Pivot on G w is a 5 ( resp . 2 ) approximation for weighted Correlation - Clustering with probability constraints ( resp . with probability and tri - angle inequality constraints ) . The proof is almost identical to that of Theorem 5 , with \ + + (cid:0) " ( bad ) triplets in G w replacing the role of directed ( bad ) triangles in tournaments . Solving Consensus - Clustering is equivalent to solving weighted Correlation - Clustering with w + ij ( resp . w (cid:0) ij ) as the fractional number of input clusters with a ( + ) ( resp . ( (cid:0) ) ) relation between i and j . This weighted Correlation - Clustering instance obeys both the probability constraints and the triangle inequality constraints , but we can do bet - ter than the 2 approximation guaranteed by Theorem 10 . Analysis almost identical to the one in Section 5 gives an expected 11 = 7 approximation for this case . The CC - Pivot is coupled with Pick - A - Cluster , which is de(cid:12)ned analo - gously to Pick - A - Perm : Simply return a cluster chosen uniformly at random from the list . Theorem 11 . The best of CC - Pivot on G w and Pick - A - Cluster has an expected approximation ratio of at most 117 for Consensus - Clustering . 7 . USING THE PIVOT SCHEME FOR ROUNDING THE LP We show how the techniques introduced above can be used for rounding the LP’s for Fas - Tournament and Corre - lation - Clustering . We consider the LP’s given in Fig - ure 1 [ 27 , 10 ] . Given a solution to the LP , we consider algorithms FasLP - Pivot and CCLP - Pivot ( Figure 1 ) for rounding the solutions for Fas - Tournament and Corre - lation - Clustering , respectively . The main idea of these algorithms is that , after we choose some pivot , we use the LP solution variables to randomly decide where to put all other vertices , instead of deciding greedily . Theorem 12 . FasLP - Pivot returns a ranking with an expected cost of at most 2 : 5 ( resp . 2 ) times the LP so - lution for Fas - Tournament , when the weights satisfy the probability constraints ( resp . the probability constraints and the triangle inequality constraints ) . The best of FasLP - Pivot and Pick - A - Perm returns a ranking with an ex - pected cost of at most 4 = 3 times the LP solution for Rank - Aggregation . CCLP - Pivot returns a clustering with an expected cost of at most 2 : 5 ( resp . 2 ) times the LP solu - tion for Correlation - Clustering , when the weights sat - isfy the probability constraints ( resp . the probability con - straints and the triangle inequality constraints ) . The best of CCLP - Pivot and Pick - A - Cluster returns a ranking with an expected cost of at most 4 = 3 times the LP solution for Consensus - Clustering . Note that these bounds imply bounds on the integrality gaps of the LP relaxation for the di(cid:11)erent cases . Proof . We prove these bounds by reducing the problem to proving global bounds of certain multinomials in high di - mensional polytopes . We start with the analysis of FasLP - Pivot . A similar analysis is done for CCLP - Pivot . Let C PIVLP denote the cost of the ordering returned by the rounding algorithm FasLP - Pivot . We have the notion of pairs i ; j that are charged dangerously and safely . The safe edges are charged when one of their endpoints is chosen as pivot , and the other endpoint is in the same recursive call . The expected cost of pairs that are charged safely in FasLP - Pivot is x ij w ji + x ji w ij ; ( 4 ) which is exactly the contribution to the LP solution . We let c (cid:3) ij denote expression ( 4 ) . So the value of the LP solution is C LP = P i < j c (cid:3) ij . A pair i ; j is charged dangerously when a third vertex k is chosen as pivot , all three i ; j ; k are in the same recursive call , and i ; j are placed on opposite sides of k . The charge is w ij ( resp . w ji ) if j ( resp . i ) is placed on the left side of k and i ( resp . j ) on its right . In either case , we charge this cost to the triplet i ; j ; k . We let T denote the set of all triplets of distinct vertices , and for any t = f i ; j ; k g 2 T we denote by A t the event that all of i ; j ; k are in the same recursive call when the (cid:12)rst one among them is chosen as pivot . Let p t denote the probability of A t . Let B tij denote the event that ( i ; j ) is dangerously charged to triangle t , in that order ( i to the left , j to the right ) . Then we have for any t = f i ; j ; k g , Pr [ A t ^ B tij ] = Pr [ A t ] Pr [ B tij j A t ] = 1 3 p t x ik x kj : ( The 1 = 3 comes from the fact that conditioned on A t , each one of i ; j ; k was equally likely to be the pivot vertex . ) De - note p tij = 13 x ik x kj . So the total expected charge to a triplet t = f i ; j ; k g is p t y ( t ) , where y ( t ) = p tij w ji + p tji w ij + p tjk w kj + p tkj w jk + p tki w ik + p tik w ki : Now we notice that for any t = f i ; j ; k g and t 0 = f i ; j ; k 0 g ( two triplets sharing a pair i ; j ) , the events A t ^ ( B tij _ B tji ) and A t 0 ^ ( B t 0 ij _ B t 0 ji ) are disjoint , because a pair i ; j can be split into two di(cid:11)erent recursion branches only once . Thus , X t : i ; j 2 t p t ( p tij + p tji ) (cid:20) 1 : The above expression is exactly the probability that the pair i ; j is dangerously charged . Therefore , the total expected cost of FasLP - Pivot is E [ C PIVLP ] = B PIVLP + F PIVLP ; where B PIVLP = X t p t y ( t ) F PIVLP = X i < j 1 (cid:0) X t : i ; j 2 t p t ( p tij + p tji ) ! c (cid:3) ij : The following expression is a rearrangement of the sum C LP = P i < j c (cid:3) ij : C LP = B LP + F LP ; where B LP = X t p t X f i ; j g(cid:18) t ( p tij + p tji ) c (cid:3) ij F LP = X i < j 1 (cid:0) X t : i ; j 2 t p t ( p tij + p tji ) ! c (cid:3) ij : LP for weighted Fas - Tournament LP for weighted Correlation - Clustering minimize P i < j ( x ij w ji + x ji w ij ) s . t . minimize P i < j ( x + ij w (cid:0) ji + x (cid:0) ji w + ij ) s . t . x ik (cid:20) x ij + x jk for all distinct i ; j ; k x (cid:0) ik (cid:20) x (cid:0) ij + x (cid:0) jk for all distinct i ; j ; k x ij + x ji = 1 for all i 6 = j x + ij + x (cid:0) ij = 1 for all i 6 = j x ij (cid:21) 0 for all i 6 = j x (cid:0) ij ; x + ij (cid:21) 0 for all i 6 = j FasLP - Pivot ( V ; x ) A recursive algorithm for rounding the LP for weighted Fas - Tournament . Given an LP solution x = f x ij g i ; j 2 V , returns an ordering on the vertices . Set V R = ; ; V L = ; : Pick random pivot i 2 V : For all j 2 V ; j 6 = i : With probability x ji Add j to V L : Else ( With remaining probability x ij = 1 (cid:0) x ji ) Add j to V R : Return order FasLP - Pivot ( V L ; x ) , i , FasLP - Pivot ( V R ; x ) ( concatenation of left recursion , i , and right recursion ) CCLP - Pivot ( V ; x + ; x (cid:0) ) A recursive algorithm for rounding the LP for weighted Correlation - Clustering . Given an LP solution x + = f x + ij g i < j , x (cid:0) = f x (cid:0) ij g i < j , returns a clustering of the vertices . Set C i = ; ; V 0 = ; : Pick random pivot i 2 V : For all j 2 V ; j 6 = i : With probability x + ij Add j to C i : Else ( With remaining probability x (cid:0) ij = 1 (cid:0) x + ij ) Add j to V 0 : Return clustering C i , CCLP - Pivot ( V 0 ; x + ; x (cid:0) ) : Figure 1 : Standard LP relaxations and their corresponding rounding algorithms . So F LP = F PIVLP . We have the following lemma , the proof of which can be found in [ 1 ] : Lemma 13 . If the weight system satis(cid:12)es the probability constraints ( resp . probability constraints and triangle in - equality constraints ) , then for any t 2 T , y ( t ) (cid:20) (cid:28) X f i ; j g(cid:18) t ( p tij + p tji ) c (cid:3) ij ; where (cid:28) = 5 = 2 ( resp . (cid:28) = 2 ) . Therefore , in this case , B PIVLP (cid:20) (cid:28)B LP : Although this just gives yet another 2 approximation al - gorithm for the rank aggregation problem , we can do better there . We couple FasLP - Piv with Pick - A - Perm . The ex - pected value of the Pick - A - Perm algorithm is E [ C PAP ] = X i < j z ij ; where z ij = 2 w ij ( 1 (cid:0) w ij ) . We rearrange this sum as follows : E [ C PAP ] = B PAPLP + F PAPLP ; where B PAPLP = X t p t X f i ; j g(cid:18) t ( p tij + p tji ) z ij F PAPLP = X i < j 0 @ 1 (cid:0) X t : f i ; j g(cid:18) t p t ( p tij + p tji ) 1 A z ij : It is easy to see that F PAPLP (cid:20) 2 F LP ( this is because z ij (cid:20) 2 c (cid:3) ij , and P t : i ; j 2 t p t ( p tij + p tji ) (cid:20) 1 ) . We have the following lemma , ( proof in [ 1 ] ) : Lemma 14 . For all t = f i ; j ; k g , 2 3 y ( t ) + 1 3 X f i ; j g(cid:18) t ( p tij + p tji ) z ij (cid:20) 4 3 X f i ; j g(cid:18) t ( p tij + p tji ) c (cid:3) ij : As a consequence , 23 B PIVLP + 13 B PAPLP (cid:20) 43 B LP : Clearly we have 23 F PIVLP + 13 F PAPLP (cid:20) 43 F LP , and we con - clude that the minimum between FasLP - Pivot and Pick - A - Perm has an expected approximation ratio of at most 43 with respect to the LP cost . We now consider the analysis of CCLP - Pivot on Corre - lation - Clustering and Consensus - Clustering . De(cid:12)ne c (cid:3) ij = x + ij w (cid:0) ij + x (cid:0) ij w + ij ( the LP contribution as well as the ex - pected charge of the safe pairs , which are de(cid:12)ned as above ) . For a triplet t = ( i ; j ; k ) , let B t f i g j denote the event that i ; j was dangerously charged to t , because k is the pivot , i is taken in k ’s cluster and j is placed aside ( the charge is w + ij ) . The probability of B t f i g j conditioned on A t is p t f i g j = 13 x + ki x (cid:0) kj . Let B t f ij g denote the event that i ; j was danger - ously charged to t , because k is the pivot , and both i and j are taken in k ’s cluster ( the charge is w (cid:0) ij ) . The probability of B t f ij g conditioned on A t is p t f ij g = 13 x + ki x + kj . De(cid:12)ne y ( t ) = P f i ; j g(cid:18) t ( p t f i g j + p t f j g i ) w + ij + p t f ij g w (cid:0) ij : For all i 6 = j , P t : f i ; j g(cid:18) t p t ( p t f i g j + p t f j g i + p t f ij g ) (cid:20) 1 ( dis - jointness of events ) . As before , we decompose E [ C PIVLP ] = B PIVLP + F PIVLP , C LP = F LP + B LP , where B PIVLP = X t p t y ( t ) F PIVLP = X i < j 0 @ 1 (cid:0) X t : f i ; j g(cid:18) t p t ( p t f i g j + p t f j g i + p t f ij g ) 1 A c (cid:3) ij : B LP = X t p t X f i ; j g(cid:18) t ( p t f i g j + p t f j g i + p t f ij g ) c (cid:3) ij F LP = X i < j 0 @ 1 (cid:0) X t : f i ; j g(cid:18) t p t ( p t f i g j + p t f j g i + p t f ij g ) 1 A c (cid:3) ij : Lemma 15 . If the weight system satis(cid:12)es the probability constraints ( resp . probability constraints and triangle in - equality constraints ) , then for any t 2 T , y ( t ) (cid:20) (cid:28) X f i ; j g(cid:18) t ( p t f i g j + p t f j g i + p t f ji g ) c (cid:3) ij ; where (cid:28) = 5 = 2 ( resp . (cid:28) = 2 ) . As a result , we get a 5 = 2 approximation for the probability constraints case , and a 2 approximation for the probability and triangle inequality constraints case . For Consensus clustering : Let C PACLP denote the value of Pick - A - Cluster . So E [ C PACLP ] = B PACLP + F PACLP , where B PACLP = X t p t X f i ; j g(cid:18) t ( p t f i g j + p t f j g i + p t f ij g ) z ij F PACLP = X i < j 0 @ 1 (cid:0) X t : f i ; j g(cid:18) t p t ( p t f i g j + p t f j g i + p t f ij g ) 1 A z ij (cid:21) 0 : z ij = 2 w + ij w (cid:0) ij Lemma 16 . For all t = f i ; j ; k g , 2 3 y ( t ) + 1 3 X f i ; j g(cid:18) t ( p t f i g j + p t f j g i + p t f ij g ) z ij (cid:20) 4 3 X f i ; j g(cid:18) t ( p t f i g j + p t f j g i + p t f ij g ) c (cid:3) ij : Therefore , we get a 4 = 3 approximation algorithm for con - sensus clustering . The proofs of Lemmas 15 and 16 can be found in [ 1 ] . This completes the proof of Theorem 12 . 8 . NP - HARDNESS OF FEEDBACK ARC SET ON TOURNAMENTS All the problems referred to in Table 1 in Section 1 . 2 were previously known to be NP - hard except for Fas - Tourna - ment . In this section we show : Theorem 17 . Unless NP (cid:18) BPP , Fas - Tournament has no polynomial time algorithm . Proof . We reduce to Fas - Tournament from Fas - Di - Graph , which is the problem of (cid:12)nding a minimum feedback arc set in a general directed graph . Fas - DiGraph is NP - hard [ 22 ] ( in fact , it is MAX - SNP - hard , see [ 21 , 25 , 26 ] ) . Let G = ( V ; A ) ( with j V j = n ) be an instance of Fas - Digraph . Suppose we could add a set of edges A R to G such that ( V ; A [ A R ) is a tournament , and such that ex - actly half of A R are backward in any ordering (cid:25) of V . Then by solving Fas - Tournament we would be able to recover the feedback arc set of G . This is generally impossible . How - ever , if we add the edges A R randomly ( i . e . for every i ; j such the neither ( i ; j ) nor ( j ; i ) are in A add ( i ; j ) or ( j ; i ) to A R with equal probability ) then for any (cid:25) the expected number of backward edges is half j R j . The variance makes this approach fail . By blowing up G and using a concentra - tion property of the random variable counting the number of backward edges in A R , we can use this construction ( see similar random digraph constructions in [ 25 , 26 ] ) . We pick an integer k = poly ( n ) ( chosen later ) . The blow - up digraph G k = ( V k ; A k ) is de(cid:12)ned as follows : V k = [ v 2 V f v 1 ; : : : ; v k g A k = f ( u i ; v j ) j ( u ; v ) 2 A ; i ; j 2 f 1 ; : : : ; k gg : We observe that the minimum feedback arc set of G k is exactly k 2 times the minimum feedback arc set of G . Indeed , it su(cid:14)ces to consider only rankings (cid:25) on V k that rank the vertices v 1 ; : : : ; v k as one block for all v 2 V ( as explained in [ 2 ] , if v i < (cid:25) v j are not adjacent in the ranking , then either moving v i immediately to the left of v j or moving v j immediately to the right of v i will result in a ranking inducing no more feedback edges than (cid:25) ) . Now we turn G k into a tournament T k = f V k ; A k [ A kR g using the construction de(cid:12)ned above . For a ranking (cid:25) of V k , let f R ( (cid:25) ) denote the number of feedback edges in A kR with respect to (cid:25) . Denote by (cid:22) the expected value of f R ( (cid:25) ) , which is the same for all (cid:25) , and can be e(cid:14)ciently computed . We claim that for k = poly ( n ) , with probability at least 2 = 3 , all rankings (cid:25) satisfy j f R ( (cid:25) ) (cid:0) (cid:22) j = O ( ( nk ) 3 = 2 p log ( nk ) ) . This would imply , using the above observation , that for big enough k = poly ( n ) the size of the minimum feedback arc set of T k can be used to e(cid:14)ciently recover the size of the minimum feedback arc set of G , because ( nk ) 3 = 2 p log ( nk ) = o ( k 2 ) . To prove the claim , for any (cid:12)xed ranking (cid:25) , set a random indicator variable X (cid:25)wz for every non - edge f w ; z g of G k which equals 1 i(cid:11) the edge between w and z in A kR is backward w . r . t . (cid:25) . So f R ( (cid:25) ) = P X (cid:25)wz . A simple ap - plication of Cherno(cid:11) bounds [ 3 ] and union bound ( over all possible ( nk ) ! rankings ) completes the proof of the claim . It follows that unless Fas - Digraph 2 BPP , we cannot solve Fas - Tournament in polynomial time . We wish to thank Noga Alon for ideas signi(cid:12)cantly simpli - fying the proof [ 2 ] . Our initial hardness result was via max - SNP hardness of Fas - DiGraph , and Noga Alon pointed out that the same idea also works with the weaker NP - hardness . 9 . OPEN PROBLEMS AND FUTURE WORK We propose the following directions of research . (cid:15) Fas - Pivot can be thought of as a \ quicksort " heuristic for Fas - Tournament . Can we use other heuristics , such as mergesort ? (cid:15) Can Fas - Pivot and CC - Pivot and their LP rounding analogues be derandomized ? (cid:15) Is Rank - Aggregation NP - Hard for 3 permutations [ 14 , 15 ] ? (cid:15) Is Consensus - Clustering NP - Hard for a constant number of clusters [ 31 , 18 ] ? (cid:15) Can we approximate weighted Correlation - Cluste - ring with triangle inequalities , but no probability con - straints ? 10 . ACKNOWLEDGEMENTS We would like to thank Ravi Kumar and D . Sivakumar for several discussions on these problems . Thanks also to Shuchi Chawla and Tony Wirth for extensive discussions on consensus clustering , to Aristides Gionis for sending us a preprint of their paper [ 20 ] , and to Noga Alon for discussions on the hardness result . 11 . REFERENCES [ 1 ] N . Ailon , M . Charikar , and A . Newman . Proofs of conjectures in ’aggregating inconsistent information : Ranking and clustering’ . Technical Report TR - 719 - 05 , Princeton University , 2005 . [ 2 ] N . Alon . Ranking tournaments ( draft ) . Personal communication , 2004 . [ 3 ] N . Alon and J . H . Spencer . The Probabilistic Method . Wiley , New York , 1992 . [ 4 ] S . Arora , A . Frieze , and H . Kaplan . A new rounding procedure for the assignment problem with applications to dense graph arrangement problems . In Proceedings of the 37th Annual Symposium on the Foundations of Computer Science ( FOCS ) , pages 24 { 33 , Burlington , VT , 1996 . [ 5 ] J . Bang - Jensen and C . Thomassen . A polynomial algorithm for the 2 - path problem in semicomplete graphs . SIAM Journal of Discrete Mathematics , 5 ( 3 ) : 366 { 376 , 1992 . [ 6 ] N . Bansal , A . Blum , and S . Chawla . Correlation clustering . Machine Learning Journal ( Special Issue on Theoretical Advances in Data Clustering ) , 56 ( 1 { 3 ) : 89 { 113 , 2004 . Extended abstract appeared in FOCS 2002 , pages 238 { 247 . [ 7 ] J . Bartholdi , C . A . Tovey , and M . Trick . Voting schemes for which it can be di(cid:14)cult to tell who won the election . Social Choice and Welfare , 6 ( 2 ) : 157 { 165 , 1989 . [ 8 ] J . C . Borda . M(cid:19)emoire sur les (cid:19)elections au scrutin . Histoire de l’Acad(cid:19)emie Royale des Sciences , 1781 . [ 9 ] M . - C . Cai , X . Deng , and W . Zang . An approximation algorithm for feedback vertex sets in tournaments . SIAM Journal on Computing , 30 ( 6 ) : 1993 { 2007 , 2001 . [ 10 ] M . Charikar , V . Guruswami , and A . Wirth . Clustering with qualitative information . In Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science ( FOCS ) , pages 524 { 533 , Boston , 2003 . [ 11 ] M . - J . Condorcet . (cid:19)Essai sur l’application de l’analyse (cid:18)a la probabilit(cid:19)e des d(cid:19)ecisions rendues (cid:18)a la pluralit(cid:19)e des voix . 1785 . [ 12 ] P . Diaconis and R . Graham . Spearman’s footrule as a measure of disarray . Journal of the Royal Statistical Society , Series B , 39 ( 2 ) : 262 { 268 , 1977 . [ 13 ] I . Dinur and S . Safra . On the importance of being biased . In Proceedings of the 34th Annual Symposium on the Theory of Compututing ( STOC ) , pages 33 { 42 , 2002 . [ 14 ] C . Dwork , R . Kumar , M . Naor , and D . Sivakumar . Rank aggregation methods for the web . In Proceedings of the Tenth International Conference on the World Wide Web ( WWW10 ) , pages 613 { 622 , Hong Kong , 2001 . [ 15 ] C . Dwork , R . Kumar , M . Naor , and D . Sivakumar . Rank aggregation revisited . 2001 . Manuscript . [ 16 ] G . Even , J . S . Naor , M . Sudan , and B . Schieber . Approximating minimum feedback sets and multicuts in directed graphs . Algorithmica , 20 ( 2 ) : 151 { 174 , 1998 . [ 17 ] R . Fagin , R . Kumar , and D . Sivakumar . E(cid:14)cient similarity search and classi(cid:12)cation via rank aggregation . In Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data , pages 301 { 312 , San Diego , 2003 . [ 18 ] V . Filkov and S . Skiena . Integrating microarray data by consensus clustering . In Proceedings of International Conference on Tools with Arti(cid:12)cial Intelligence ( ICTAI ) , pages 418 { 425 , Sacramento , 2003 . [ 19 ] A . Frieze and R . Kannan . Quick approximations to matrices and applications . Combinatorica , 19 ( 2 ) : 175 { 220 , 1999 . [ 20 ] A . Gionis , H . Mannila , and P . Tsaparas . Clustering aggregation . In Proceedings of the 21st International Conference on Data Engineering ( ICDE ) , Tokyo , 2005 . To appear . [ 21 ] J . H(cid:23)astad . Some optimal inapproximability results . Journal of the ACM , 48 : 798 { 859 , 2001 . [ 22 ] R . M . Karp . Reducibility among combinatorial problems . In Complexity of Computer Computations , pages 85 { 104 . Plenum Press , New York , 1972 . [ 23 ] J . Kemeny and J . Snell . Mathematical Models in the Social Sciences . Blaisdell , New York , 1962 . Reprinted by MIT Press , Cambridge , 1972 . [ 24 ] J . G . Kemeny . Mathematics without numbers . Daedalus , 88 : 571 { 591 , 1959 . [ 25 ] A . Newman . Approximating the maximum acyclic subgraph . Master’s thesis , Massachusetts Institute of Technology , Cambridge , MA , June 2000 . [ 26 ] A . Newman and S . Vempala . Fences are futile : On relaxations for the linear ordering problem . In Proceedings of the Eighth Conference on Integer Programming and Combinatorial Optimization ( IPCO ) , pages 333 { 347 , 2001 . [ 27 ] C . N . Potts . An algorithm for the single machine sequencing problem with precedence constraints . Mathematical Programming , 13 : 78 { 87 , 1980 . [ 28 ] P . Seymour . Packing directed circuits fractionally . Combinatorica , 15 : 281 { 288 , 1995 . [ 29 ] E . Speckenmeyer . On feedback problems in digraphs . Graph Theoretic Concepts in Computer Science , Lecture Notes in Computer Science , 411 : 218 { 231 , 1989 . [ 30 ] A . Strehl . Relationship - based Clustering and Cluster Ensembles for High - dimensional Data Mining . PhD dissertation , University of Texas at Austin , May 2002 . [ 31 ] Y . Wakabayashi . The complexity of computing medians of relations . Resenhas , 3 ( 3 ) : 323 { 349 , 1998 .