1 Sequence to Sequence Learning with Neural Networks Sequence - to - Sequence Learning with Neural Networks Ilya Sutskever , Oriol Vinyals , Quoc V . Le , NIPS 2014 Introduced by Graham Neubig , NAIST 2014 - 11 - 01 2 Sequence to Sequence Learning with Neural Networks Review : Recurrent Neural Networks 3 Sequence to Sequence Learning with Neural Networks Perceptron f ( ∑ i = 1 I w i ⋅ϕ i ( x ) ) φ “A” = 1 φ “site” = 1 φ “ , ” = 2 φ “located” = 1 φ “in” = 1 φ “Maizuru” = 1 φ “Kyoto” = 1 φ “priest” = 0 φ “black” = 0 0 - 3 00 0 0020 y w 4 Sequence to Sequence Learning with Neural Networks Neural Net ● Combine multiple perceptrons φ “A” = 1 φ “site” = 1 φ “ , ” = 2 φ “located” = 1 φ “in” = 1 φ “Maizuru” = 1 φ “Kyoto” = 1 φ “priest” = 0 φ “black” = 0 y ● Learning of complex functions possible 5 Sequence to Sequence Learning with Neural Networks Recurrent Neural Nets I can eat an apple < / s > I can eat an apple < / s > 6 Sequence to Sequence Learning with Neural Networks Long Short Term Memory [ Hochreiter + 97 ] ● Problem : RNNs suffer from vanishing gradient ● Solution : Create units that decide when to activate 7 Sequence to Sequence Learning with Neural Networks Dialogue State Tracking with RNNs [ Henderson + 14 ] f : features s : slot m : memory p : probability over goals 8 Sequence to Sequence Learning with Neural Networks Sequence - to - Sequence Learning with Neural Networks 9 Sequence to Sequence Learning with Neural Networks Task : Machine Translation ● Mapping from input to output sentence 太郎が花子を 訪問した。 Input Taro visited Hanako . Output 10 Sequence to Sequence Learning with Neural Networks Traditional Method : Phrase - based MT ● Translate phrases , reorder Today I will give a lecture on machine translation . Today 今日は、 I will give を行います a lecture on の講義 machine translation 機械翻訳 . 。 Today 今日は、 I will give を行います a lecture on の講義 machine translation 機械翻訳 . 。 今日は、機械翻訳の講義を行います。 ● Requires alignment , phrase extraction , scoring ( phrase , reordering ) , NP - hard decoding , tuning 11 Sequence to Sequence Learning with Neural Networks Proposed Method : Memorize Sequence , Generate Sequence ● Left - to - right beam search ( size 2 was largely sufficient ) ● Also can use for reranking 12 Sequence to Sequence Learning with Neural Networks Proposed Method : Reversal Trick x x x C B A 13 Sequence to Sequence Learning with Neural Networks Experimental Setup ● Network details ● 160 , 000 / 80 , 000 word input / output ( all other UNK ) ● 4 hidden LSTM layers of 1 , 000 cells ● 1 , 000 dimensional word representations ● Training ● Stochastic gradient descent ● 8 GPUs ( 1 for each hidden layer , 4 for output ) ● 6 , 300 words per second , 10 days total ● Data details ● ~ 340M words of English - French data from WMT14 14 Sequence to Sequence Learning with Neural Networks Results 15 Sequence to Sequence Learning with Neural Networks Learned Phrase Representations 16 Sequence to Sequence Learning with Neural Networks Effect of Length 17 Sequence to Sequence Learning with Neural Networks Examples / Problems with UNK 18 Sequence to Sequence Learning with Neural Networks Addressing the Rare Word Problem in Neural Machine Translation [ Luong + 14 ] ● Copyable model : label unk words ● Positional all model : label word positions ( i = j - d , e i f j ) ● Positional unk : label unk positions en : The unk 1 portico in unk 2 … fr : Le unk n unk 1 de unk 2 . . . en : The < unk > portico in < unk > . . . fr : Le pos 0 < unk > pos −1 < unk > pos 1 de pos n < unk > pos −1 . . . en : The < unk > portico in < unk > . . . fr : Le unkpos 1 unkpos - 1 de unkpos 1 . . . 19 Sequence to Sequence Learning with Neural Networks Results with PosUnk