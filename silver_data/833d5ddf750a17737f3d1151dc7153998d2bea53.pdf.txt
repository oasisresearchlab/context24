This article appeared in a journal published by Elsevier . The attached copy is furnished to the author for internal non - commercial research and education use , including for instruction at the authors institution and sharing with colleagues . Other uses , including reproduction and distribution , or selling or licensing copies , or posting to personal , institutional or third party websites are prohibited . In most cases authors are permitted to post their version of the article ( e . g . in Word or Tex form ) to their personal website or institutional repository . Authors requiring further information regarding Elsevier’s archiving and manuscript policies are encouraged to visit : http : / / www . elsevier . com / copyright Author ' s personal copy Brief article On intuitional stability : The clear , the strong , and the paradigmatic Jennifer Cole Wright * Department of Psychology , College of Charleston , 57 Coming Street , Charleston , SC 29424 , United States a r t i c l e i n f o Article history : Received 22 September 2009 Revised 1 February 2010 Accepted 10 February 2010 Keywords : Intuition Order Effect Cognitive Bias Intuitional Stability a b s t r a c t Skepticism about the epistemic value of intuition in theoretical and philosophical inquiry has recently been bolstered by empirical research suggesting that people’s concrete - case intuitions are vulnerable to irrational biases ( e . g . , the order effect ) . What is more , skeptics argue that we have no way to ‘‘calibrate” our intuitions against these biases and no way of anticipating intuitional instability . This paper challenges the skeptical position , introducing data from two studies that suggest not only that people’s concrete - case intuitions are often stable , but also that people have introspective awareness of this stability , providing a promising means by which to assess the epistemic value of our intuitions . (cid:2) 2010 Elsevier B . V . All rights reserved . 1 . Introduction Intuition—what it is and how , when , and why it works— has recently received renewed attention in philosophy , cognitive science , and psychology . There has been much debate concerning the nature of intuition ( Audi , 2004 ; Bealer , 1999 , 2000 ; Claxton , 1998 ; Huemer , 2006 ; Kornb - lith , 1999 ; Laughlin , 1997 ; Osbeck , 1999 , 2001 ; Parsons , 2000 ; Pust , 2000 ; Sosa , 1999 , 2007a , 2007b ; Williamson , 2007 ; Wisniewski , 1999 ) , as well as what sort of cognitive process intuiting might be or involve ( Cummins , 1998 ; Denes - Raj & Epstein , 1994 ; Dorfman , Shames , & Kilstrom , 1996 ; Epstein , Lipson , Holstein , & Huh , 1992 ; Gendler , 2007 ; Osbeck , 1999 ; Shaﬁr , 1999 ; Sloman , 1996 ) . There has also been debate about what role intuitions might play in logic and mathematics ( Bealer , 2000 ; Bonjour , 1998 ; Casullo , 2003 ; Parsons , 1986 , 2000 ; Sosa , 2006 ; Wright , 2004 ) , epistemology ( Alexander & Weinberg , 2007 ; Bealer , 1992 ; Brown , 2006 ; Nagel , 2007 ; Weinberg , 2007 ; Wil - liamson , 2004 ) , metaphysics ( Bealer , 2002 , 2004 ; Bonjour , 1998 ; Jackson , 1994 , 1998 ; Pust , 2004 ; Sosa , 2000 , 2006 ) , morality ( Audi , 2004 ; Bartsch & Wright , 2005 ; Dancy , 1991 , 2006 ; Haidt & Joseph , 2004 ; Huemer , 2005 ; Jackson , 1998 ; Macnamara , 1991 ) , and a variety of other areas . 1 One such debate concerns the epistemic 2 status of intu - itions . This debate centers around the following question : Is it legitimate , epistemically speaking , for individuals to form beliefs about matters of logic , mathematics , metaphysics , epistemology , morality , etc . on the basis of their intuitions about theoretical principles and / or concrete cases ( involving actual or hypothetical examples ) ? In other words , do intu - itions have some positive epistemic value ? While there are many who endorse an afﬁrmative an - swer to this question ( e . g . , Bealer , 1992 , 1999 , 2000 , 2004 ; Bonjour , 1998 ; Jackson , 1998 ; Pust , 2000 ; D . Sosa , 0010 - 0277 / $ - see front matter (cid:2) 2010 Elsevier B . V . All rights reserved . doi : 10 . 1016 / j . cognition . 2010 . 02 . 003 * Tel . : + 1 843 953 8196 ; fax : + 1 843 953 7151 . E - mail address : wrightjj1 @ cofc . edu . 1 For instance , intuition has been implicated in linguistics ( Chomsky , 1988 ; Devitt , 2006 ; Hintikka , 2001 ) , rapid judgment and decision making ( Grifﬁn & Tversky , 1992 ; Hammond , 1996 ; Kahneman & Tversky , 1982 ; Klienmutz , 1990 ; Plessner , Betsch , & Betsch , 2007 ; Sloman , 1996 ) , insight and problem - solving ( Bowers , Farvolden , & Mermigis , 1995 ; Bowers , Regehr , & Balthazard , 1990 ; Dorfman et al . , 1996 ; Sternberg & Davidson , 1995 ) , implicit learning ( Reber , 1989 , 1993 ) , expertise ( Dreyfus & Dreyfus , 1986 , 1991 ) , social cognition ( Haidt , 2001 ; Osbeck , 2001 ; Seung , 1993 ) , scientiﬁc theory - building ( Goldman & Pust , 1997 ; Monsay , 1999 ) , and even medicine ( King & Appleton , 1997 ; Miller , 1995 ; Ubel & Loewenstein , 1997 ) . 2 It is important to note that this concern about intuition’s ‘epistemic’ status could be targeting several things , including intuition’s rational , justiﬁcatory , and / or evidential status . Thanks to John Bengson for clarifying this issue . Cognition 115 ( 2010 ) 491 – 503 Contents lists available at ScienceDirect Cognition journal homepage : www . elsevier . com / locate / COGNIT Author ' s personal copy 2006 ; E . Sosa , 1999 , 2005 , 2006 ; Williamson , 2004 ; cf . Os - beck , 1999 , 2001 ) , an increasing number of philosophers , cognitive scientists , and psychologists express a deep skep - ticism about intuition’s epistemic value ( see , e . g . , Cum - mins , 1998 ; Denes - Raj & Epstein , 1994 ; Gendler , 2007 ; Hintikka , 1999 , 2001 ; Machery , Mallon , Nichols , & Stich , 2004 ; Nichols & Knobe , 2007 ; Nichols , Stich , & Weinberg , 2003 ; Nisbett , Peng , Choi , & Norenzayan , 2001 ; Redelmeier & Shaﬁr , 1995 ; Weinberg , 2007 ; Weinberg , Nichols , & Stich , 2001 ) . In fact , whereas extreme skepticism about perception and memory might be considered somewhat ‘academic’ ( D . Sosa , 2006 ) , skepticism about intuition is thought by many ( e . g . , Machery et al . , 2004 ; Nichols & Knobe , 2007 ; Nichols et al . , 2003 ) to have serious implica - tions for philosophical methodology . This skepticism has recently been fortiﬁed by empirical research showing that concrete - case intuitions are vulner - able to irrational biases . Swain , Alexander , and Weinberg ( 2008 ) , for example , found that people’s responses to con - crete cases were vulnerable to an ‘order effect’ ( Tversky & Kahneman , 1974 ) . Speciﬁcally , Swain et al . ( 2008 ) found that participants’ concrete - case judgments about the True - Temp case ( a much discussed thought - experiment in contemporary epistemology in which a man is unwittingly led , through a ‘brain rewiring’ , to form true beliefs about the current temperature ; see Lehrer , 1990 ) were signiﬁ - cantly inﬂuenced by what case they had previously consid - ered . Participants were more likely to say that True - Temp knew ( as opposed to ‘merely believed’ ) that the tempera - ture was 71 (cid:3) if they had just previously read the case about Dave , a man who formed the true belief that the next coin he ﬂipped would land heads because he had a ‘special feel - ing’ right before he ﬂipped the coin , and they were less likely to say that True - Temp knew if they had just previ - ously read the case about Karen , a woman who formed a true belief about how to create a poisonous gas on the ba - sis of reading an article about it in a top scientiﬁc journal . Based on these ﬁndings , Swain et al . ( 2008 ) concluded that , to the extent that people’s concrete - case intuitions are inﬂuenced by irrational biases such as one’s previously elicited intuitions , they do not possess the sort of epistemic status that they have heretofore been taken to possess . They further concluded that the instability of intuitions demonstrated by their study ( and others : e . g . , Machery et al . , 2004 ; Weinberg et al . , 2001 ) brings into question our reliance on intuitions as sources of evidence for theo - retical / philosophical positions , writing ‘we contend that this instability undermines the supposed evidential status of these intuitions , such that philosophers [ and others ] who deal in intuitions can no longer rest comfortably in their armchairs’ ( 2008 , 1 ) . Is such a strong conclusion warranted ? Some have ar - gued that it is not , either due to a variety of methodological and conceptual difﬁculties ( none of which will be touched upon here – for a discussion of some of these issues , see Laio ( 2008 ) and elsewhere ) or on the grounds that Swain et al . ( 2008 ) hardly provide a deﬁnitive demonstration of intuitional instability , having found it in only one particu - lar case . However , the true weight of the Swain et al . ( 2008 ) challenge is not that all ( or even most ) intuitions are unstable , but rather that we have no way of ‘‘calibrat - ing” our intuitions , no way of anticipating the conditions under which our concrete - case intuitions will be vulnera - ble to irrational biases , such as the order effect ( for more on this worry , see Weinberg , 2007 ) . This being the case , an adequate response to Swain et al . ’s challenge needs to do more than simply demonstrate the stability of some ( or even most ) intuitions – it needs to identify a reliable method by which to track that stability and provide insight into why certain intuitions , but not others , are stable . In the absence of this , the epistemic legitimacy of consulting our intuitions remains open to skepticism . The goal of the two studies reported here was to take up the challenge . Their guiding hypothesis was twofold : ( 1 ) that only some intuitions ( that is , intuitions about certain sorts of cases ) are vulnerable to intuitional instability and that people are implicitly aware of which cases these will be , and ( 2 ) that several potentially reliable methods for tracking intuitional instability exist – among them , the introspectively accessed conﬁdence and belief strength of those doing the intuiting . 2 . Study 1 2 . 1 . Methods 2 . 1 . 1 . Participants One hundred and eighty - eight undergraduate college students ( 87 males , 101 females ; dominantly Caucasian ) from the University of Wyoming participated in this study . Participants were recruited through the Introduction to Psychology research pool and received research credit for their participation . Being dominantly college freshman , the assumption was that the participants had received lit - tle to no explicit philosophical training ( though this ques - tion was not asked ) . 2 . 1 . 2 . Materials and procedure Participants received a randomized series of the Swain et al . ( 2008 ) cases as ‘ﬁller tasks’ while participating in one of two larger , unrelated studies . The set included the True - Temp case , the Coin - Flip case , the Fake - Barn case , and the Testimony case ( see Appendix ) , all four of which were presented to participants in a counterbalanced order . After reading each case , participants were asked whether the subject in the case knew a speciﬁc proposition ( e . g . , for True - Temp , whether the temperature was 71 (cid:3) ) , to which participants answered YES or NO . They were then asked to rate how conﬁdent they were about their answer ( 0 = not very conﬁdent to 5 = very conﬁdent ) . 2 . 2 . Results Preliminary note : There were no gender differences found and so all analyses to follow were collapsed across gender . Swain et al . ( 2008 ) had found that participants were more likely to judge that True - Temp really knew the tem - perature if the case was immediately preceded by Coin - Flip and less likely to do so if it was immediately preceded by Testimony . A similar pattern emerged in this study . Exam - 492 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy ining those cases in which True - Temp was the second case participants considered , being directly preceded by one of the other three cases ( KTxx , DTxx , or STxx ) , the results re - vealed that participants were signiﬁcantly more likely to attribute knowledge to True - Temp when it immediately followed Coin - Flip ( 55 % ) than when it immediately fol - lowed either Testimony ( 40 % ) or Fake - Barn ( 26 % ) , v 2 ( 2 , N = 143 ) = 8 . 25 , p = . 016 ( Fig . 1 ) . A similar trend emerged for Fake - Barn : participants were ( marginally ) less likely to count Suzy’s mental state as knowledge when the case immediately followed either Testimony or Coin - Flip ( 40 % and 39 % , respectively ) than when it immediately followed True - Temp ( 59 % ) : v 2 ( 2 , N = 144 ) = 4 . 91 , p = . 086 ( Fig . 2 ) . Participants’ judgments about Testimony and Coin - Flip , on the other hand , did not display vulnerability to the order effect . Participants were equally likely to attribute knowledge in Testimony , regardless of which case imme - diately preceded ( 79 – 84 % ) , v 2 ( 2 , N = 139 ) = . 50 , p = . 77 . Likewise , participants were equally likely to fail to attri - bute knowledge in Coin - Flip , regardless of which case immediately preceded ( 0 – 6 % ) , v 2 ( 2 , N = 133 ) = 2 . 50 , p = . 29 ( Fig . 3 ) . Of central importance is the fact that participants’ themselves introspectively tracked this intuitional stabil - ity . Paired sample t - tests revealed that participants were signiﬁcantly more conﬁdent in their judgments about Coin - Flip ( V = 4 . 4 , SE = . 06 ) and Testimony ( V = 4 . 5 , SE = . 06 ) than they were in their judgments about True - Temp ( V = 3 . 9 , SE = . 09 ) and Fake - Barn ( V = 3 . 9 , SE = . 08 ) , t s ( 187 ) = 5 . 4 to 6 . 7 , p s < . 001 , while their conﬁdence did not signiﬁcantly differ between the two stable and two unstable cases , 3 t ( 187 ) = 1 . 6 , p = . 11 and t ( 187 ) = . 27 , p = . 79 , respectively . And this was true regardless of order in which the cases were presented . Participants expressed higher levels conﬁ - dence in their judgments for Coin - Flip and Testimony than for True - Temp and Fake - Barn whether they were the ﬁrst Attributions of Knowledge in True - Temp 0 . 0 % 10 . 0 % 20 . 0 % 30 . 0 % 40 . 0 % 50 . 0 % 60 . 0 % 70 . 0 % 80 . 0 % After Testimony After Fake - Barn After Coin - Flip % o f P a r t i c i p a n t s Don ' t Know Know Fig . 1 . Attributions of knowledge in True - Temp . Attributions of Knowledge in Fake - Barn 0 . 0 % 10 . 0 % 20 . 0 % 30 . 0 % 40 . 0 % 50 . 0 % 60 . 0 % 70 . 0 % After Coin - Flip After True - Temp After Testimony % o f P a r t i c i p a n t s Don ' t Know Know Fig . 2 . Attributions of knowledge in Fake - Barn . 3 Here I am using ‘‘stable / unstable cases” as shorthand for cases that elicit stable vs . unstable intuitions – that is , strictly speaking , it is the intuitions that are stable ( or unstable ) , not the cases . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 493 Author ' s personal copy cases considered ( V = 4 . 6 , SE = . 17 and V = 4 . 4 , SE = . 12 vs . V = 3 . 7 , SE = . 17 and V = 3 . 8 , SE = . 17 , respectively ) or the last cases considered ( V = 4 . 5 , SE = . 12 and V = 4 . 5 , SE = . 12 vs . V = 3 . 9 , SE = . 20 and V = 3 . 9 , SE = . 18 , respec - tively , Fig . 4 ) . Thus , it would appear that participants’ con - ﬁdence served as an introspective indicator of intuitional stability . To further explore the relationship between stability and conﬁdence , nominal logistic regressions were per - formed to see if participants’ conﬁdence levels could be used to predict which case was being considered . Partici - pants’ conﬁdence was regressed as a covariate over the cases ( 1 = True - Temp , 2 = Fake - Barn , 3 = Coin - Flip , 4 = Testi - mony ) , with each case functioning as the reference case . Each model revealed conﬁdence to be a strong predictor of stable vs . unstable cases , X 2 ( 3 , N = 188 ) = 26 . 8 , p < . 001 . Speciﬁcally , the results show that conﬁdence was a sig - niﬁcant predictor of whether the case being considered was stable ( Testimony or Coin - Flip ) or unstable ( True - Temp or Fake - Barn ) . For every 1 unit increase in participants’ conﬁdence , the odds of the case being Testimony ( over True - Temp ) increased by 203 % ( or a factor of 2 . 03 ) , X 2 ( 1 ) = 9 . 6 , p = . 002 , and the odds of the case being Coin - Flip ( over True - Temp ) increased by 273 % , X 2 ( 1 ) = 15 . 4 , p < . 001 . Changes in conﬁdence did not distinguish be - tween True - Temp and Fake - Barn , X 2 ( 1 ) = . 134 , p = . 714 . Likewise , for every 1 unit increase in participants’ conﬁ - dence , the odds of the case being Fake - Barn ( over Testi - mony ) decreased by 53 % , X 2 ( 1 ) = 7 . 7 , p = . 005 , but changes in conﬁdence did not distinguish between Testimony and Coin - Flip , X 2 ( 1 ) = 1 . 24 , p = . 266 . Framed in terms of probability , as participants’ conﬁ - dence increased , the probability that the case being con - sidered was either Testimony or Coin - Flip increased signiﬁcantly , from around 5 % at a conﬁdence of ‘1’ to about 30 % ( Testimony ) to 60 % ( Coin - Flip ) at a conﬁdence of ‘7’ , and the probability that the case being considered was True - Temp or Fake - Barn decreased signiﬁcantly , from about 40 % ( Fake - Barn ) to 50 % ( True - Temp ) at ‘1’ to around 5 % at ‘7’ . The case probabilities merged and be - came approximately equal at a conﬁdence level of ‘4’ ( Fig . 5 ) . 2 . 3 . Discussion In line with Swain et al . ( 2008 ) , this ﬁrst study found participants’ knowledge attributions in the True - Temp case to be unstable and their ﬂuctuation to be dependent upon which case had been previously considered . The same was true for the Fake - Barn case . And , also in line with Swain et al . , both Testimony and Coin - Flip remained Reported Confidence in Judgments 3 . 0 3 . 3 3 . 5 3 . 8 4 . 0 4 . 3 4 . 5 4 . 8 Testimony Karen Coin - flip Dave True - temp Charles Fake - barn Suzy Cases 0 - 5 po i n t sca l e 1st case read Last case read Fig . 4 . Reported conﬁdence in judgments . Attributions of Knowledge in Testimony and Coin - Flip 0 0 . 2 0 . 4 0 . 6 0 . 8 1 Don ' t Know Don ' t Know Know Know Testimony Coin - Flip Testimony Coin - Flip % o f p a r t i c i p a n t s After Testimony After True - Temp After Fake - Barn After Coin - Flip Fig . 3 . Attributions of knowledge in Testimony and Coin - Flip . 494 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy stable across the counterbalanced order in which they were presented . Importantly , participants seemed to be introspectively tracking this instability , reporting signiﬁcantly more conﬁ - dence when considering cases that elicited stable judg - ments than when considering cases that elicited unstable judgments , regardless of order of presentation . As the re - sults from the logistic regressions reﬂect , the lower partic - ipants’ conﬁdence , the more likely the case being considered displayed instability – the higher their conﬁ - dence , the more likely it displayed stability . Why would participants be vulnerable to bias in only two of the four cases ? One reasonable explanation is that , when considering True - Temp and Fake - Barn , peo - ple’s intuitions about them were less clear ( if , indeed , they had any intuitions about them at all ) . If so , then it would make sense for participants to turn elsewhere , such as to the case that they had just previously consid - ered , for information that would help to determine their judgment . For example , when considering whether or not True - Temp ’s mental state should count as knowledge , perhaps participants who saw Coin - Flip ﬁrst were more inclined to say ‘yes’ because it looks a lot more like knowledge than a ‘special feeling’ . On the other hand , it looks a lot less like knowledge than testimony from a top scientiﬁc journal . In short , under circumstances where our intuitions are not as clear , it would be natural for us to bring other information to bear on our judgments . This could also explain why participants’ knowledge attributions were not inﬂuenced by the preceding cases for either Testimony or Coin - Flip . As Swain et al . ( 2008 ) noted , these cases are ‘clear cases’ – or what we might call paradigmatic cases – of having ( or failing to have ) knowl - edge . Arguably , Testimony is the sort of case that most peo - ple ( people with a reasonable degree of conceptual competence 4 ) would agree is an instance of ‘knowledge’ , just as Coin - Flip is the sort of case that most would agree fails to be an instance of ‘knowledge’ . It is not surprising to ﬁnd that people’s intuitions stabilize around paradigmatic cases – cases that are clear instances of our concepts – and so are not vulnerable to the sorts of biasing factors that Swain and colleagues argue undermines intuition’s evidential status . In order to investigate intuitional stability in more depth , a second study was conducted that expanded upon Study 1 in three ways . First , it introduced additional cases for participants to consider ; second , it introduced belief strength as an additional introspective measure of stabil - ity . Research on attitude and belief strength has found strongly held beliefs to be more stable over time , more resistant to change , and less sensitive to contextual inﬂu - 4 It is important to distinguish here between conceptual competence and accuracy . While the hope is that most of the time these two will go together – that is , the competent use of our concepts will usually result in us getting things right – it seems nonetheless possible for them to come apart . We could envision two cultures , for instance ( one whose beliefs about the nature of the universe are grounded by contemporary scientiﬁc / philosoph - ical theory and another whose beliefs are grounded in ancient mythological lore ) that might employ the concept ‘knowledge’ differently . Taking Coin - Flip as an example , while the ﬁrst culture would hold that this clearly fails to count as an instance of knowledge , the latter might hold that it just as clearly counts , since Dave’s ‘‘special feeling” indicates the presence of a psychic ability ( or something along those lines ) . While we may certainly want to say that the latter culture fails to adequately grasp the concept of knowledge ( and , as such , their use of the concept in Coin - Flip is mistaken ) , we may nonetheless want to grant them conceptual competence , given that it seems reasonable to attribute knowledge to Coin - Flip when your belief system holds that psychic abilities ( the presence of which is indicated by a ‘‘special feeling” ) exist . Especially since what we are interested in here is people’s intuitional stability , not accuracy , this issue seems important to keep in mind . Indeed , such variation in underlying belief systems may help to explain the cultural variability in intuitions found by Machery et al . ( 2004 ) and elsewhere . 1 2 3 4 5 6 7 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 Confidence Score P r obab ili t y Testimony Coin Flip Fake Barn True Temp Fig . 5 . Case probabilities at each level of conﬁdence . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 495 Author ' s personal copy ences ( for reviews see Krosnick & Petty , 1995 ; Petty & Kro - snick , 1995 ) . Thus it was hypothesized that belief strength might serve as another good introspective indicator of stability . Lastly , perceived consensus was introduced as a ( rough ) proxy for ‘paradigmaticity’ . The hypothesis here was that participants would be likely to view clear ( paradigmatic ) cases as the sorts of cases everyone would agree upon – therefore , the more paradigmatic the case under consider - ation , the higher the degree of peer consensus they should report . The claim is not that perceived consensus would serve as a measure of actual paradigmaticity ( which may involve factors outside of mere agreement ) , but rather that would provide important insight into how paradigmatic people perceive the cases they are considering to be . 3 . Study 2 3 . 1 . Methods 3 . 1 . 1 . Participants One hundred and eighty - one undergraduate college students ( 33 males , 148 females ; dominantly Caucasian ) from the College of Charleston participated in this study . Participants were recruited through the Introduction to Psychological Science research pool and received research credit for their participation . Ninety - three percentage of the participants had no philosophical training , 6 % had ta - ken or were currently were enrolled in Introduction to Phi - losophy , and 1 % in some other undergraduate philosophy course . 3 . 1 . 2 . Materials and procedure This time participants were presented with three differ - ent sets of cases , nine cases in total ( see Appendix ) . Two of the sets involved cases in epistemology , expanding upon the cases considered in Study 1 ( Set 1 : Perception , True - Temp , and Coin - Flip ; Set 2 : Testimony , Farmer , and Guess ) and one set involved cases in ethics 5 ( Set 3 : Break - Promise , Hide - Bombers , Sell - iPod ) . Once again , the cases were pre - sented to the participants in a counterbalanced order , though this time the counterbalancing occurred both within sets ( e . g . , Perception / True - Temp / Coin - Flip , True - Temp / Coin - Flip / Perception . . . ) and between sets ( e . g . , Set1 / Set2 / Set3 , Set2 / Set3 / Set1 . . . ) . It was anticipated that six of these cases ( Perception , Coin - Flip , Testimony , Guess , Break - Promise , and Sell - iPod ) would elicit stable judgments and the other three would elicit unstable judgments . After reading an epistemology case , participants were asked whether the subject in the case knew a speciﬁc prop - osition , to which participants answered YES or NO . After reading an ethics case , they were asked whether the action performed in the case was morally wrong , to which they answered YES or NO . Once again , participants were asked to rate on a Likert scale ( this time , a 7 - point scale in order to provide a neutral midpoint ) how conﬁdent they were about their answer ( 1 = not very conﬁdent to 7 = very con - ﬁdent ) . Participants were also asked to rate on a 7 - point Likert scale how strongly they believed their answer ( 1 = not very strongly to 7 = very strongly ) . Finally , partici - pants were asked a perceived consensus question : If 100 other College of Charleston students were asked the same question , how many do you think would give the same an - swer you did ? ( 1 = none of them to 7 = all 100 of them ) . The order of these questions was counterbalanced between participants . 3 . 2 . Results 3 . 2 . 1 . Preliminary note There were no gender differences or differences be - tween participants with vs . without philosophical training , so analyses reported below were collapsed across these groups . In addition , all analyses conducted with partici - pants’ conﬁdence in Study 1 were replicated and partici - pants’ conﬁdence and belief strength ratings were highly correlated across all nine cases ( r s = . 86 to . 99 , p s < . 001 ) , so for the sake of brevity analyses with conﬁdence are not reported below . Of the nine cases that participants considered , six ( as anticipated ) elicited stable intuitions . For Perception , Coin - Flip , Testimony , Guess , Sell - iPod , and Break - Promise , the or - der of presentation did not matter . Participants dominantly attributed knowledge in Perception ( 80 – 90 % ) and Testi - mony ( 84 – 87 % ) and failed to attribute knowledge in Coin - Flip ( 3 % ) and Guess ( 0 – 7 % ) , regardless of order . Participants also dominantly judged the action to be morally wrong in Sell - iPod ( 100 % ) and not wrong in Break - Promise ( 0 – 3 % ) , regardless of order . Examining the pattern of participants’ answers when each of these cases was immediately pre - ceded by the other cases in its set revealed no signiﬁcant variation for any of them , X 2 s ( 1 , N s = 57 – 61 ) = 0 . 0 to 1 . 05 , p s = . 31 – . 99 . All of these cases were perceived by partici - pants as being highly paradigmatic ( in the sense that par - ticipants reported a high degree of agreement in their peers ) : M s = 5 . 6 – 6 . 5 ( SEs = . 06 – . 09 ) . Two of the remaining cases elicited unstable judg - ments : True - Temp and Hide - Bombers . Examining the cases in which True - Temp was directly preceded by one of the other two cases , the results showed that participants were signiﬁcantly more likely to say that True - Temp knew the temperature immediately after reading Coin - Flip ( 84 % ) than after reading Perception ( 57 % ) , X 2 ( 1 , N = 61 ) = 5 . 4 , p = . 020 . Likewise , when reading Hide - Bombers , partici - pants were marginally more likely to say that what Hilda did was morally wrong immediately after reading Sell - iPod ( 55 % ) than after reading Break - Promise ( 32 % ) , X 2 ( 1 , N = 60 ) = 3 . 2 , p = . 073 ( Fig . 6 ) . These two cases were seen as signiﬁcantly less paradigmatic than either the stable ‘yes’ or the stable ‘no’ cases : M s . 4 . 9 and 5 . 2 ( SE s = . 08 – . 09 ) , t s ( 174 – 179 ) = 6 . 4 – 13 . 3 , p s < . 001 . The ﬁnal case , Farmer , was an interesting case . Examin - ing participants’ knowledge attributions revealed that it was not unstable , in the sense of demonstrating an order effect , X 2 ( 1 , N = 61 ) = . 008 , p = . 93 , but neither was it para - digmatic – as with the unstable cases , participants were strongly divided over whether or not the Farmer knew 5 Zamzow and Nichols ( in press ) found that conﬁdence tracked instabil - ity in a set of classic ethical dilemmas ( Bystander , Scan , Transplant ) and so the inclusion of some ethical cases in Study 2 seemed prudent . 496 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy his cow was in the ﬁeld , approximately 1 / 3rd saying he did know and 2 / 3rd saying he did not ( Fig . 6 ) . This fact was nicely reﬂected in participants’ reports of paradigmaticity , which for Farmer fell signiﬁcantly in be - tween their reported paradigmaticity for the stable vs . unstable epistemology cases : paired - sample t - tests showed perceived consensus for Farmer ( M = 5 . 3 , SE = . 09 ) to be lower than their perceived consensus for the stable - yes ( Perception / Testimony ) and stable - no ( Coin - Flip / Guess ) epis - temology cases ( M s = 6 . 0 / 5 . 9 and 5 . 6 / 6 . 4 , SE s = . 07 – . 09 , respectively ) , t s ( 178 ) = 2 . 0 – 7 . 7 , p s from . 05 to < . 001 , and yet higher than the unstable ( True - Temp ) epistemology case ( M = 4 . 9 , SE = . 08 ) , t ( 177 ) = 5 . 2 , p < . 001 ( Fig . 7 ) . Interestingly , participants’ belief strength showed a similar pattern : paired - sample t - tests revealed that partic - ipants’ belief strength for Farmer ( M = 5 . 9 , SE = . 09 ) was sig - niﬁcantly lower than for the stable - yes ( Perception / Testimony ) and stable - no ( Coin - Flip / Guess ) epistemology cases ( M s = 6 . 5 / 6 . 3 and 6 . 4 / 6 . 7 , SE s = . 05 – . 07 , respectively ) , t s ( 178 ) = 3 . 5 – 9 . 2 , p s = < . 001 , but also signiﬁcantly higher than for the unstable ( True - Temp ) case ( M = 5 . 4 , SE = . 10 ) , t ( 178 ) = 5 . 3 , p < . 001 ( Fig . 7 ) . Given that participants’ intro - spective judgments appear to be locating Farmer in be - tween the stable and unstable cases , it will be heretofore referred to as an ‘‘intermediate” case . More generally , a within - subjects ANOVA with stability ( stable - yes , unstable / intermediate , stable - no ) and set ( epist1 , epist2 , ethics ) as within - subjects factors revealed that participants’ belief strength was signiﬁcantly higher for the stable cases than for the unstable / intermediate cases across all three sets , F ( 2 , 346 ) = 87 . 7 , p < . 001 , g 2 = . 34 . Importantly , this suggests that the same general rela - tionship between stability and conﬁdence also holds for stability and belief strength – and that it does so across multiple sets of cases , both epistemological and ethical . But does this mean that belief strength , like conﬁdence , can be used to predict case ? To investigate this , nominal logistic regressions ( separate for each set ) were performed with belief strength as the covariate over case ( Set 1 : 1 = Perception , 2 = Coin - Flip , 3 = True - Temp ; Set 2 : 1 = Testi - mony , 2 = Guess , 3 = Farmer ; Set 3 : 1 = Sell iPod , 2 = Break - Promise , 3 = Hide - Bombers ) . Attributions of Knowlege / Wrongness 10 . 0 % 30 . 0 % 50 . 0 % 70 . 0 % 90 . 0 % After Perception After Coin Flip After Selling iPod After BreakingPromise After Testimony After Guessing True - Temp True - Temp Hide - Bombers Hide - Bombers Farmer Farmer Case / Order % o f p a r t i c i p a n t s Yes No Fig . 6 . Attributions of knowledge / wrongness in True - Temp , Hide - Bombers , and Farmer . Comparing Paradigmaticity and Belief Strength Btw Farmer & Other Stable / Unstable Cases 0 1 2 3 4 5 6 7 8 Paradigmaticity Belief Strength L eve l o f B e li e f S t r e ng t h / P a r a d i g m a t i c i t y Perception / Testimony True Temp Farmer Coin Flip / Guessing Fig . 7 . Paradigmaticity and belief strength between Farmer vs . Stable / unstable Cases . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 497 Author ' s personal copy For Set 1 , belief strength was a strong predictor of stable vs . unstable cases , X 2 ( 2 , N = 179 ) = 62 . 1 , p < . 001 . For every 1 unit increase in participants’ belief strength , the odds of the case being Perception ( over True - Temp ) increased by 302 % ( or a factor of 3 . 02 ) , X 2 ( 1 ) = 31 . 7 , p < . 001 , and the odds of the case being Coin - Flip ( over True - Temp ) increased by 272 % , X 2 ( 1 ) = 28 . 7 , p < . 001 . As expected , belief strength was not predictive between Perception and Coin - Flip , X 2 ( 1 ) = . 30 , p = . 584 . Framed in terms of probability , as participants’ belief strength increased , the probability that they were consid - ering True - Temp dropped signiﬁcantly , from almost 100 % at a belief strength of ‘1’ to around 10 % at a belief strength of ‘7’ . Likewise , as belief strength increased , the probability that they were considering either Perception or Coin - Flip in - creased , from almost 0 % at ‘1’ to around 45 % at ‘7’ . The case probabilities merged and became approximately equal be - tween ‘5’ and ‘6’ ( Fig . 8 ) . For Set 2 , belief strength was a strong predictor of all three cases , X 2 ( 2 , N = 180 ) = 31 . 5 , p < . 001 . For every 1 unit increase in participants’ belief strength , the odds of the case being Testimony ( over Farmer ) increased by 148 % , X 2 ( 1 ) = 6 . 7 , p = . 010 , and the odds of the case being Guess ( over Farmer ) increased by 292 % , X 2 ( 1 ) = 20 . 7 , p < . 001 . And for every 1 unit increase in participants’ belief strength , the odds of the case being Guess ( over Testimony ) increased by 197 % , X 2 ( 1 ) = 8 . 2 , p = . 004 . As participants’ belief strength increased , the probabil - ity that they were considering Farmer dropped signiﬁ - cantly , from around 85 % at a belief strength of ‘1’ to around 20 % at a belief strength of ‘7’ . Likewise , as belief strength increased , the probability that they were consid - ering Guess or Testimony increased , from around 0 % ( Guess ) to 15 % ( Testimony ) at ‘1’ to around 30 % ( Testimony ) to 50 % ( Guess ) at ‘7’ . The case probabilities in this set never fully merged ( Fig . 9 ) . Finally , for Set 3 , belief strength was once again a strong predictor of stable vs . unstable cases , X 2 ( 2 , N = 176 ) = 73 . 8 , p < . 001 . For every 1 unit increase in participants’ belief strength , the odds of the case being Sell - iPod ( over Hide - Bombers ) increased by 903 % , X 2 ( 1 ) = 21 . 0 , p < . 001 , and the odds of the case being Break - Promise ( over Hide - Bomb - ers ) increased by 411 % , X 2 ( 1 ) = 21 . 3 , p < . 001 . Belief strength was not predictive between Sell - iPod and Break Promise , X 2 ( 1 ) = 2 . 5 , p = . 110 . As participants’ belief strength increased , the probability that they were consid - ering Hide - Bombers decreased , from almost 100 % at a belief strength of ‘1’ to around 10 % at ‘7’ , while the probability of the case being either Sell - iPod or Break - Promise increased from almost 0 % at ‘1’ to around 45 % at ‘7’ . The case proba - bilities merged and became approximately equal around ‘6’ ( Fig . 10 ) . Participants’ perception of paradigmaticity was also predictive of case in all three sets . In Set 1 , every 1 unit in - crease in peer consensus increased the odds that the case being Perception ( over True - Temp ) by 470 % , X 2 ( 1 ) = 37 . 3 , p < . 001 , and increased the odds that the case was Coin - Flip ( over True - Temp ) by 195 % , X 2 ( 1 ) = 10 . 5 , p = . 001 . It also de - creased the odds that the case being considered was Coin - Flip ( over Perception ) by 42 % , X 2 ( 1 ) = 15 . 7 , p < . 001 . In Set 2 , every 1 unit increase in consensus increased the odds of the case being Testimony ( over Farmer ) by 162 % , X 2 ( 1 ) = 10 . 0 , p = . 002 , and increased the odds of the case being Guess ( over Farmer ) by 238 % , X 2 ( 1 ) = 22 . 6 , p < . 001 . It also increased the odds that the case being con - sidered was Testimony ( over Guess ) by 147 % , X 2 ( 1 ) = 4 . 7 , p = . 035 . Finally , in Set 3 every 1 unit increase in consensus in - creased the odds of the case being Sell - iPod ( over Hide - Bombers ) by 353 % , X 2 ( 1 ) = 29 . 2 , p < . 001 , and increased the odds of the case being Break - Promise ( over Hide - Bomb - ers ) by 413 % , X 2 ( 1 ) = 32 . 6 , p < . 001 . Consensus was not pre - Fig . 8 . Set 1 case probabilities at each level of belief strength . 498 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy dictive between Sell - iPod and Break - Promise , X 2 ( 1 ) = . 44 , p = . 51 . On a ﬁnal note , when either conﬁdence or belief strength are entered into logistic regression equations alongside paradigmaticity ( multicollinearity issues make it problematic to enter conﬁdence and belief strength to - gether ) , each variable remains predictive of stable vs . unstable cases in Sets 1 and 3 ( p s between < . 001 and . 042 ) , while only paradigmaticity is signiﬁcant in Set 2 ( p = . 001 for paradigmaticity , p = . 20 for conﬁdence ; p = . 019 for paradigmaticity , p = . 11 for belief strength ) , perhaps because Set 2 contains the intermediate case . Thus , paradigmaticity , on the one hand , and conﬁdence / be - lief strength , on the other , appear to be independently pre - dictive of intuitional instability . 4 . General discussion The worry introduced by Swain et al . ( 2008 ) is that phi - losophers’ reliance on intuitions in argumentation for / against particular theses and theoretical positions is prob - lematic because at least some of those intuitions are epi - stemically vulnerable to irrational biases like the order effect . This worry gets its teeth not primarily because of Fig . 9 . Set 2 case probabilities at each level of belief strength . 1 2 3 4 5 6 7 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 Belief Strength P r obab ili t y Farmer Guess Testimony Fig . 10 . Set 3 case probabilities at each level of belief strength . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 499 Author ' s personal copy the sheer number of intuitions that could be vulnerable , but more importantly because of our supposed inability to anticipate ( and protect against ) this vulnerability . The thought is that we lack reliable methods by which to track intuitional instability – and , therefore , we cannot know when our intuitions are being negatively impacted by it and when they are not . Contrary to this claim , the studies reported here suggest that there are ways for us to anticipate intuitional instabil - ity – in fact , several different ( though related ) ways . For one , the participants in both studies clearly experienced more conﬁdence in their answers when considering stable cases than when considering unstable cases , regardless of whether those cases involved the application of epistemo - logical or ethical concepts . In addition , participants had signiﬁcantly stronger beliefs ( or , held their beliefs more strongly ) about the stable cases than about the unstable cases . Indeed , both conﬁdence and belief strength were good predictors of whether the case being considered was stable or unstable . This is interesting because while conﬁdence seems a more purely cognitive construct – the degree to which you experience conceptual clarity or certainty – be - lief strength is often treated as more of an affective con - struct , sometimes being employed in research paradigms as a proxy for things like ‘attitude extremity’ and ‘emo - tional intensity’ ( e . g . , Wright , Cullum , & Schwab , 2008 ) . And it seems possible for a person to have a high degree of conﬁdence in a belief they do not hold particularly strongly : my son and I could both be highly conﬁdent in our shared belief that the Pittsburg Steelers emerged as the best team in the NFL in 2009 , but because he is such an avid football fan , he might hold that belief much more strongly ( in the sense that it would be more important to him , etc . ) than I . It also seems that people could be very conﬁdent in x and believe very strongly in x for different rea - sons : someone could be very conﬁdent in his belief that our country should make healthcare reform its top priority because of a variety of expert ﬁnancial analyses he’d read , but then hold this belief very strongly because of a politi - cal / philosophical belief that people deserve equal access to healthcare . These potential differences between the two constructs aside , both clearly ( and similarly ) tracked with intuitional stability . As mentioned above , one important factor behind the stability of particular cases may be their relative paradig - maticity – that is , the degree to which they represent clear instances of the concept ( s ) in question . In the epistemolog - ical cases participants considered , the concept in question was ‘knowledge’ : whether the subjects knew or did not know some particular proposition . And some things strike us as clear examples of knowledge ( e . g . , beliefs gained through direct perceptual observation under ideal condi - tions ) , while some things strike us as clearly not knowledge ( e . g . , randomly guessing the answer to a question , even if you happened to guess the correct answer ) . In the ethical cases participants were asked whether or not an action was morally wrong . Here again , some things strike us as clearly morally wrong ( e . g . , stealing something of value that is not yours for frivolous reasons ) , just as some things strike us as clearly not morally wrong ( e . g . , breaking a promise involving a minor obligation because a loved one is in danger ) . When considering cases such as these , it is less likely that outside factors , such as cases previously considered , will inﬂuence our judgments than when we consider difﬁcult borderline ( or just otherwise confusing ) cases . Importantly , participants displayed awareness of para - digmaticity ( at least insofar as perceived consensus serves as a legitimate measure ) . The degree of peer consensus that participants reported was strongly related to case sta - bility and participants’ peer consensus reports accurately identiﬁed between the stable , intermediate , and unstable cases . The stable cases were viewed as being the sorts of cases everyone would agree upon , whereas the unstable and intermediate cases were viewed as more open for dis - agreement ( the unstable cases even more so than the inter - mediate case ) . Collectively , these results suggest two things . First , they suggest that people are able to introspectively track – and thus potentially protect against – their vulnerability to ( at least some forms of ) bias . If those intuitive judgments peo - ple feel less conﬁdent and strongly about are more vulner - able to potentially biasing ‘‘outside inﬂuences” ( or if those cases that are vulnerable to bias are cases that people feel less conﬁdent and strongly about ) , then we can take care with the circumstances under which we elicit intuitions about those cases ; we can control exposure to potentially biasing inﬂuences . We can also treat such intuitive judg - ments with caution , granting them less epistemic weight in philosophical / theoretical discourse . Importantly , I would argue that most philosophers and scientists already do this , treating clear / strong intuitions ( especially their own ) more seriously than unclear / weak ones . Perhaps such efforts could be made more thoughtful and explicit , but I doubt that this would require any drastic changes to cur - rent philosophical / theoretical practice . Second , the results suggest that the more paradigmatic the case , the less vulnerable it will be to ( at least some forms of ) bias . Again , this seems relatively unsurprising . Clear cases of any particular concept are precisely that : clear cases . Our judgments about them , barring substantial conceptual revolution , are unlikely to change . Of course , philosophy is often most interesting ( and of most value ) when it is working ‘‘at the margins” , wrestling with un - clear and borderline cases . And this raises Swain et al . ’s ( 2008 ) worry once again : does this render a potentially extensive area of philosophical debate epistemically vul - nerable , philosophers being unable to rely on their intu - itions without worry of bias ? This is an important consideration ( especially when dif - ﬁcult , non - paradigmatic cases are often where philoso - phers’ rely most heavily on their intuitions ) , but it seems unlikely to represent an insurmountable problem for sev - eral reasons . First , philosophers clearly can ( and do ) have clear / strong intuitions about non - paradigmatic cases . Such cases , while perhaps vulnerable to bias for the general pop - ulation of reasonably conceptually competent people ( such as the participants in the studies reported here ) , may none - theless be stable for most philosophers . After all , philoso - phers receive extensive training designed speciﬁcally to reﬁne and enhance their conceptual mastery . Such training 500 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy gives philosophers a greater capacity for discrimination when it comes to concept application ( e . g . , whether some - thing counts as an instance of knowledge ) and , therefore , they may be able to see difﬁcult cases more clearly , and more difﬁcult cases clearly , than the philosophical novice – not unlike learning the difference between Quercus rubra ( Northern Red Oak ) and Quercus alba ( Pin Oak ) , which thereafter gives one the ability to distinguish between trees that before that seemed indistinguishable . What is more , the very process of engaging in philo - sophical discourse may ultimately generate new concep - tual clarity where before there was conceptual confusion . 6 That is , the practice of philosophical and theo - retical discourse itself may expand and reﬁne our range of conceptual competence , both because of the learning that occurs in the individual and also because of the collective advancement that results for the discipline . Of course , it is important to note that what conﬁdence and belief strength track with is intuitional stability – not intuitional accuracy . Research suggests that people are notoriously overconﬁdent in their judgments across a wide variety of contexts ( Arkes , 2001 ; Einhorn & Hogarth , 1978 ; Kahneman & Klein , 2009 ) . And , more to the point , simply having clear / strong intuitions does not guarantee that they are also veridical : intuitions are not infallible ( and few , if any , philosophers think that they are ) . Thus , we must be careful not to mistake high degrees of conﬁdence / belief strength as being indicators that we have gotten it right . What is more , every scientist and philosopher must at some point encounter the line between looking for the the - ory that best ﬁts one’s data and looking at the data in a way that best ﬁts one’s theory . The latter is always a danger – and , likewise , there is always the danger that people’s intu - itions will be biased by the very training and theoretical advancement that resulted in their heightened conceptual clarity . But , this was not the problem for philosophical intuition that was raised by Swain et al . ( 2008 ) – and thus , not the problem the studies reported here were designed to address . And the good news is that whatever epistemi - cally suspect reasons ( e . g . , unwarranted theoretical com - mitments ) for intuitional stability that may exist , intuitional instability is one worry that we do not need to be too worried about . Appendix A A . 1 . Study 1 Cases COIN - FLIP : Dave likes to play a game with ﬂipping a coin . He sometimes gets a ‘‘special feeling” that the next ﬂip will come out heads . When he gets this ‘‘special feel - ing” , he is right about half the time , and wrong about half the time . Just before the next ﬂip , Dave gets that ‘‘special feeling” , and the feeling leads him to believe that the coin will land heads . He ﬂips the coin , and it does land heads . TRUE - TEMP : One day Charles was knocked out by a fall - ing rock ; as a result his brain was ‘‘rewired” so that he is always right whenever he estimates the temperature where he is . Charles is unaware that his brain has been al - tered in this way . A few weeks later , this brain rewiring leads him to believe that it is 71 degrees in his room . Apart from his estimation , he has no other reasons to think that it is 71 degrees . In fact , it is 71 degrees . FAKE - BARN : Suzy looks out the window of her car and sees a barn near the road , and so she comes to believe that there’s a barn near the road . However , Suzy doesn’t realize that the countryside she is driving through is currently being used as the set of a ﬁlm , and that the set designers have constructed many Fake - Barn facades in this area that look as though they are real barns . In fact , Suzy is looking at the only real barn in the area . TESTIMONY : Karen is a distinguished professor of chemistry . This morning , she read an article in a leading scientiﬁc journal that mixing two common ﬂoor disinfec - tants , Cleano Plus and Washaway , will create a poisonous gas that is deadly to humans . In fact , the article is correct : mixing the two products does create a poisonous gas . At noon , Karen sees a janitor mixing Cleano Plus and Wash - away and yells to him , ‘‘Get away ! Mixing those two prod - ucts creates a poisonous gas ! ” A . 2 . Study 2 Cases A . 2 . 1 . Set 1 : epistemic vignettes CLEAR YES ( Perception ) : Pat walks into her kitchen dur - ing the day when the lighting was good and there was nothing interfering with her vision . She sees a red apple sitting on the counter , where she had left it after buying it at the grocery store the day before . As she leaves home , she tells her son , Joe , that there is a red apple sitting on the kitchen counter and to make sure to pack it with his lunch . CLEAR NO ( Coin - Flip ) : Dave likes to play a game with ﬂipping a coin . He sometimes gets a ‘‘special feeling” that the next ﬂip will come out heads . When he gets this ‘‘spe - cial feeling” , he is right about half the time , and wrong about half the time . Just before the next ﬂip , Dave gets that ‘‘special feeling” , and the feeling leads him to believe that the coin will land heads . He ﬂips the coin , and it does land heads . NOT CLEAR ( True - Temp ) : Suppose Charles undergoes brain surgery by an experimental surgeon who invents a small device which is both a very accurate thermometer and a computational device capable of generating thoughts . The device , called a tempucomp , is implanted in Charles’ head so that the very tip of the device , no larger than the head of a pin , sits unnoticed on his scalp and acts as a sensor to transmit information about the temperature to the computational system of his brain . This device , in turn , sends a message to his brain causing him to think of the temperature recorded by the external sensor . As - sume that the tempucomp is very reliable , and so his thoughts are correct temperature thoughts . All told , this is a reliable belief - forming process . Charles has no idea that the tempucomp has been inserted in his brain , is only slightly puzzled about why he thinks so obsessively about the temperature , but never checks a thermometer to deter - 6 Perhaps philosophical training actually expands the range of paradig - maticity – that is , through philosophical and theoretical advancement , cases that were once non - paradigmatic become paradigmatic ( or cases that are non - paradigmatic for some become paradigmatic for others ) . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 501 Author ' s personal copy mine whether these thoughts about the temperature are correct . He accepts them unreﬂectively , another effect of the tempucomp . Thus , at a particular moment in time he thinks and accepts that the temperature is 71 degrees – and it is , in fact , 71 degrees . A . 2 . 2 . Set 2 : epistemic vignettes CLEAR YES ( Testimony ) : Karen is a distinguished profes - sor of chemistry . This morning , she read an article in a leading scientiﬁc journal that mixing two common ﬂoor disinfectants , Cleano Plus and Washaway , will create a poi - sonous gas that is deadly to humans . In fact , the article is correct : mixing the two products does create a poisonous gas . At noon , Karen sees a janitor mixing Cleano Plus and Washaway and yells to him , ‘‘Get away ! Mixing those two products creates a poisonous gas ! ” CLEAR NO ( Guess ) : Laura’s math teacher asks everyone to perform a difﬁcult math problem . Laura realizes that she has no idea how to do the problem and so she just sits there and doodles . After about a minute , the math teacher asks Laura to report to the class what answer she had got - ten . Not knowing what else to do , Laura blurts out ‘‘35” as a completely random guess . As it turns out , this is the correct answer and the teacher congratulates Laura for a job well done . NOT CLEAR ( Farmer ) : Farmer Field is concerned about his prize cow , Daisy , whom he put out into a ﬁeld to graze earlier that morning . In fact , he is so concerned that he goes out to the ﬁeld to check on her periodically . Standing by the gate , he sees in the distance , behind some trees , a white and black shape that he recognizes as his favorite cow . He goes back home and tells his friend , the dairyman , that he knows that Daisy is in the ﬁeld , grazing happily . Yet when the dairyman leaves to go home , he walks by the ﬁeld and notices that even though Daisy is in fact in the ﬁeld just as Farmer Field thought , she is actually napping in a hollow , behind a bush , well out of sight of the gate ( and of Farmer Field ) . He then also spots a large piece of black and white cardboard that has got caught in a tree , making it look like Daisy is standing there . A . 2 . 3 . Set 3 : ethical vignettes CLEAR NO ( Break - Promise ) : Fred promises his girlfriend that he will meet her for lunch at 12 pm on Wednesday at their favorite café . Wednesday at 11 : 45 am , on his way to the café , Fred runs into his grandfather , who is out for a stroll . They exchange hellos , and then suddenly Fred’s grandfather clutches his chest and falls to the ground unconscious . An ambulance arrives minutes later to take Fred’s grandfather to the hospital . Fred accompanies his grandfather to the hospital , even though he knows that doing so means that he will be breaking his promise to have lunch with his girlfriend . CLEAR YES ( Sell - iPod ) : Laura and Suzy are roommates . Laura asks Suzy if she has seen her new iPod , which she had worked an extra job over the summer to be able to af - ford . Suzy did recently see it under a pile of papers on the bookshelf . But Suzy lies to Laura , telling her that she hasn’t seen it . She thinks that if Laura doesn’t ﬁnd it on her own in a day or two , she can take it down to the pawn shop and get $ 100 for it , which would provide her with beer money for the week . UNCLEAR ( Hide - Bombers ) : Martha hides her Jewish neighbors in her basement during the Nazi occupation of France . A German soldier comes to her door one afternoon and asks her if she knows where her neighbors have gone . Martha knows that her neighbors are wanted by the Ger - mans for bombing a German - only schoolyard and killing several children , injuring others . Martha lies to the soldier , telling them no , she hasn’t seen them recently , but she be - lieves that they ﬂed the country . References Alexander , J . , & Weinberg , J . ( 2007 ) . Analytic epistemology and experimental philosophy . Philosophy Compass , 2 ( 1 ) , 56 – 80 . Arkes , H . R . ( 2001 ) . Overconﬁdence in judgmental forecasting . In J . S . Armstrong ( Ed . ) , Principles of forecasting : A handbook for researchers and practitioners ( pp . 495 – 516 ) . Boston : Kluwer Academic . Audi , R . ( 2004 ) . The good and the right : A theory of intuition and intrinsic value . Princeton University Press . Bartsch , K . , & Wright , J . C . ( 2005 ) . Towards an intuitionist account of moral development [ commentary ] . Behavioral and Brain Sciences , 28 , 546 – 547 . Bealer , G . ( 1992 ) . The incoherence of empiricism . Aristotelian Society : Supplementary Volume , 66 , 99 – 138 . Bealer , G . ( 1999 ) . Intuition and the autonomy of philosophy . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 201 – 239 ) . Lanham : Rowman and Littleﬁeld . Bealer , G . ( 2000 ) . A theory of the a priori . Paciﬁc Philosophical Quarterly , 811 , 1 – 30 . Bealer , G . ( 2002 ) . Model epistemology and the rationalist renaissance . In T . Gendler ( Ed . ) , Conceivability and possibility ( pp . 71 – 125 ) . Oxford : Oxford University Press . Bealer , G . ( 2004 ) . The origins of modal error . Dialectica : International Journal of Philosophy of Knowledge , 581 , 11 – 42 . Bonjour , L . ( 1998 ) . In defense of pure reason . Cambridge : Cambridge University Press . Bowers , K . , Farvolden , P . , & Mermigis , L . ( 1995 ) . Intuitive antecedents of insight . In S . Smith & T . Ward ( Eds . ) , The creative cognition approach . Cambridge : Bradford / MIT Press . Bowers , K . , Regehr , G . , & Balthazard , C . ( 1990 ) . Intuition in the context of discovery . Cognitive Psychology , 22 , 72 – 100 . Brown , J . ( 2006 ) . Contextualism and warranted assertibility manoeuvres . Philosophical Studies , 130 , 407 – 435 . Casullo , A . ( 2003 ) . A priori justiﬁcation . Oxford : Oxford University Press . Chomsky , N . ( 1988 ) . The minimalist program . Cambridge , MA : The MIT Press . Claxton , G . ( 1998 ) . Investigating human intuition : Knowing without knowing why . The Psychologist , 115 , 217 – 220 . Cummins , R . ( 1998 ) . Reﬂections on reﬂective equilibrium . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry . Lanham : Rowman and Littleﬁeld . Dancy , J . ( 1991 ) . Intuitionism . In P . Singer ( Ed . ) , A companion to ethics . Cambridge : Blackwell Publishing . Dancy , J . ( 2006 ) . Ethics without principles . Oxford : Oxford University Press . Denes - Raj , V . , & Epstein , S . ( 1994 ) . Conﬂict between intuitive and rational processing : When people behave against their better judgment . Journal of Personality and Social Psychology , 665 , 819 – 829 . Devitt , M . ( 2006 ) . Intuitions in linguistics . British Journal for the Philosophy of Science , 57 ( 3 ) , 481 – 513 . Dorfman , J . , Shames , V . , & Kilstrom , J . ( 1996 ) . Intuition , incubation , and insight : Implicit cognition in problem solving . In G . Underwood ( Ed . ) , Implicit cognition ( pp . 257 – 296 ) . Oxford : Oxford University Press . Dreyfus , H . , & Dreyfus , S . ( 1986 ) . Mind over machine : The power of human intuition and expertise in the era of the computer . New York : The Free Press . Dreyfus , H . , & Dreyfus , S . ( 1991 ) . Towards a phenomenology of moral expertise . Human Studies , 14 , 229 – 250 . Einhorn , H . J . , & Hogarth , R . M . ( 1978 ) . Conﬁdence in judgment : Persis - tence of the illusion of validity . Psychological Review , 85 , 395 – 416 . Epstein , S . , Lipson , A . , Holstein , C . , & Huh , E . ( 1992 ) . Irrational reaction to negative outcome : Evidence for two conceptual systems . Journal of Personality and Social Psychology , 62 , 328 – 339 . 502 J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 Author ' s personal copy Gendler , T . ( 2007 ) . Philosophical thought experiments , intuitions , and cognitive equilibrium . Midwest Studies in Philosophy , 31 ( 1 ) , 68 – 89 . Goldman , A . , & Pust , J . ( 1997 ) . Philosophical theory and intuitional evidence . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 179 – 200 ) . Lanham : Rowman and Littleﬁeld . Grifﬁn , D . , & Tversky , A . ( 1992 ) . The weighing of evidence and the determinants of conﬁdence . Cognitive Psychology , 243 , 411 – 435 . Haidt , J . ( 2001 ) . The emotional dog and its rational tail : A social intuitionist approach to moral judgment . Psychological Review , 108 ( 4 ) , 814 – 834 . Haidt , J . , & Joseph , C . ( 2004 ) . Intuitive ethics : How innately prepared intuitions generate culturally variable virtues . Daedalus , 55 – 66 . Hammond , K . ( 1996 ) . Human judgment and social policy . New York : Oxford University Press . Hintikka , J . ( 1999 ) . The emperor’s new intuitions . Journal of Philosophy , 96 ( 3 ) , 127 – 147 . Hintikka , J . ( 2001 ) . Intuitionistic logic as epistemic logic . Synthese , 127 ( 1 – 2 ) , 7 – 19 . Huemer , M . ( 2006 ) . Ethical intuitionism . Palgrave Macmillian . Jackson , F . ( 1994 ) . Metaphysics by possible cases . Monist , 771 , 93 – 111 . Jackson , F . ( 1998 ) . From metaphysics to ethics : A defence of conceptual analysis . Oxford : Oxford University Press . Kahneman , D . , & Klein , G . ( 2009 ) . Conditions for intuitive expertise : A failure to disagree . American Psychologist , 64 ( 6 ) , 515 – 526 . Kahneman , D . , & Tversky , A . ( 1982 ) . On the study of statistical intuitions . Cognition , 11 , 123 – 141 . King , L . , & Appleton , J . ( 1997 ) . Intuition : A critical review of the research and rhetoric . Journal of Advanced Nursing , 26 , 194 – 202 . Klienmutz , B . ( 1990 ) . Why we will use our heads instead of formulas : Towards an integrative approach . Psychological Bulletin , 1073 , 296 – 310 . Kornblith , H . ( 1999 ) . The role of intuition in philosophical inquiry : An account with no unnatural ingredients . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 129 – 142 ) . Lanham : Rowman and Littleﬁeld . Krosnick , J . A . , & Petty , R . E . ( 1995 ) . Attitude strength : An overview . In R . E . Petty & J . A . Krosnick ( Eds . ) , Attitude strength : Antecedents and consequences ( pp . 1 – 24 ) . Hillsdale , NJ : Erlbaum . Laio , M . ( 2008 ) . A defense of intuitions . Philosophical Studies , 140 ( 2 ) , 247 – 262 . Laughlin , C . ( 1997 ) . The nature of intuition : A neuropsychological approach . In R . Davis - Floyd & P . Arvidson ( Eds . ) , Intuition : The inside story ( pp . 19 – 38 ) . New York : Routledge . Lehrer , K . ( 1990 ) . Theory of knowledge . Westview Press . Machery , E . , Mallon , R . , Nichols , S . , & Stich , S . ( 2004 ) . Semantics , cross - cultural style . Cognition , 923 , 1 – 12 . Macnamara , J . ( 1991 ) . The development of moral reasoning and the foundation of geometry . Journal for the Theory of Social Behavior , 212 , 125 – 150 . Miller , V . ( 1995 ) . Characteristics of intuitive nurses . Western Journal of Nursing Research , 173 , 305 – 316 . Monsay , E . ( 1999 ) . Intuition in the development of scientiﬁc theory and practice . In R . Davis - Floyd & P . Arvidson ( Eds . ) , Intuition : The inside story ( pp . 103 – 120 ) . New York : Routledge . Nagel , J . ( 2007 ) . Epistemic intuitions . Philosophy Compass , 2 ( 6 ) , 792 – 819 . Nichols , S . , & Knobe , J . ( 2007 ) . Moral responsibility and determinism : The cognitive science of folk intuitions . Nous , 41 ( 4 ) , 663 – 685 . Nichols , S . , Stich , S . , & Weinberg , J . ( 2003 ) . Metaskepticism : Meditations in ethno - epistemology . In S . Luper ( Ed . ) , The skeptics ( pp . 227 – 247 ) . Ashgate Publishing . Nisbett , R . E . , Peng , K . , Choi , I . , & Norenzayan , A . ( 2001 ) . Culture and systems of thought : Holistic versus analytic cognition . Psychological Review , 1082 , 291 – 310 . Osbeck , L . ( 1999 ) . Conceptual problems in the development of a psychological notion of ‘intution’ . Journal for the Theory of Social Behavior , 293 , 229 – 250 . Osbeck , L . ( 2001 ) . Direct apprehension and social construction : Revisiting the concept of intuition . Journal of Theoretical and Philosophical Psychology , 212 , 118 – 131 . Parsons , C . ( 1986 ) . Intuition in constructive mathematics . In J . Butterﬁeld ( Ed . ) , Language , mind , and logic ( pp . 211 – 229 ) . Cambridge : Cambridge University Press . Parsons , C . ( 2000 ) . Reason and intuition . Synthese , 1253 , 299 – 315 . Petty , R . , & Krosnick , J . ( Eds . ) . ( 1995 ) . Attitude strength : Antecedents and consequences . Hillsdale , NJ : Lawrence Erlbaum Associates . Plessner , H . , Betsch , C . , & Betsch , T . ( Eds . ) . ( 2007 ) . Intuition in judgment and decision making . Mahwah , NJ : Lawrence Erlbaum . Pust , J . ( 2000 ) . Intuitions as evidence . New York : Garland . Pust , J . ( 2004 ) . On explaining knowledge of necessity . Dialectica , 58 ( 1 ) , 71 – 87 . Redelmeier , D . , & Shaﬁr , E . ( 1995 ) . Medical decision making in situations that offer multiple alternatives . JAMA , 273 , 302 – 305 . Reber , A . ( 1989 ) . Implicit learning and tacit knowledge . Journal of Experimental Psychology : General , 1183 , 219 – 235 . Reber , A . ( 1993 ) . Implicit learning and tacit knowledge : An essay on the cognitive unconscious . New York : Oxford University Press . Seung , T . ( 1993 ) . Intuition and construction . New Haven : Yale University Press . Shaﬁr , E . ( 1999 ) . Philosophical intuitions and cognitive mechanisms . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 59 – 74 ) . Lanham : Rowman and Littleﬁeld . Sloman , S . ( 1996 ) . The empirical case for two systems of reasoning . Psychological Bulletin , 1191 , 3 – 22 . Sosa , D . ( 2006 ) . Scepticism about intuition . Philosophy , 81 , 633 – 647 . Sosa , E . ( 1999 ) . Minimal Intuition . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 257 – 270 ) . Lanham : Rowman and Littleﬁeld . Sosa , E . ( 2000 ) . Replies . Nous , 10 , 38 – 42 . Sosa , E . ( 2005 ) . A defense of intuitions . In M . Bishop & D . Murphy ( Eds . ) , Stich and his critics . Blackwell Publishers . Sosa , E . ( 2007a ) . Intuitions : Their nature and epistemic efﬁcacy . Grazer Philosophische Studien , 74 , 51 – 67 . Sosa , E . ( 2007b ) . Experimental philosophy and philosophical intuition . Philosophical Studies , 132 , 99 – 107 . Sternberg , R . J . , & Davidson , J . E . ( Eds . ) . ( 1995 ) . The nature of insight . Cambridge : Bradford / MIT Press . Swain , S . , Alexander , J . , & Weinberg , J . ( 2008 ) . The instability of philosophical intuitions : Running hot and cold on true - temp . Philosophy and Phenomenological Research , 76 ( 1 ) , 138 – 155 . Tversky , A . , & Kahneman , D . ( 1974 ) . Judgment under uncertainty : Heuristics and biases . Science , 185 , 1124 – 1130 . Ubel , P . , & Loewenstein , G . ( 1997 ) . The role of decision analysis in informed consent : Choosing between intuition and automaticity . Social Science and Medicine , 445 , 647 – 656 . Weinberg , J . ( 2007 ) . How to challenge intuitions empirically without raising skepticism . Midwest Studies in Philosophy , 31 ( 1 ) , 318 – 343 . Weinberg , J . , Nichols , S . , & Stich , S . ( 2001 ) . Normativity and epistemic intuitions . Philosophical Topics , 291 – 2 , 429 – 460 . Williamson , T . ( 2004 ) . Philosophical ‘intuitions’ and skepticism about judgment . Dialectica , 58 , 109 – 153 . Wisniewski , E . ( 1999 ) . The psychology of intuition . In M . DePaul & W . Ramsey ( Eds . ) , Rethinking intuition : The psychology of intuition and its role in philosophical inquiry ( pp . 45 – 58 ) . Lanham : Rowman and Littleﬁeld . Wright , C . ( 2004 ) . Intuition , entitlement , and the epistemology of logical laws . Dialectica , 58 ( 1 ) , 155 – 175 . Wright , J . C . , Cullum , J . , & Schwab , N . ( 2008 ) . The cognitive and affective dimensions of moral conviction : Implications for tolerance and interpersonal behaviors . Personality and Social Psychology Bulletin , 34 ( 11 ) , 1461 – 1476 . Zamzow , J . , & Nichols , S . ( in press ) . Variations in ethical intuitions . Philosophical Issues . J . C . Wright / Cognition 115 ( 2010 ) 491 – 503 503