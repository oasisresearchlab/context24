Challenges to Adversarial Interplay Under High Uncertainty : Staged - World Study of a Cyber Security Event DISSERTATION Presented in Partial Fulfillment of the Requirements for the Degree Doctor of Philosophy in the Graduate School of the Ohio State University By Matthieu Branlat , B . S . , M . S . Graduate Program in Industrial and Systems Engineering The Ohio State University 2011 Dissertation Committee : David D . Woods , Advisor Philip J . Smith Anish Arora Copyright by Matthieu Branlat 2011 ii Abstract The vulnerability of critical and valued digital infrastructures and the difficulty of defending networks against attacks are a growing concern throughout domains . While numerous efforts exist to improve cyber defense through technological advances , human - centered research to uncover and address the difficulties experienced by network defenders is recent and still limited . Moreover , understanding cyber security , a fundamentally adversarial domain , requires investigations of the interrelated defense and attack processes , but such studies are rare . The dissertation presents results from a staged - world study of an adversarial cyber security exercise . This daylong exercise involved forty participants divided into an outside attacking team and a defending team operating in a simulated production environment . The first objective is to identify critical skills and forms of expertise of cyber security as a domain of practice . Designed by cyber security experts , the exercise allowed for the investigation of core dimensions of cyber events , which have seen limited empirical study in past work on cyber defense : ( 1 ) decision - making in cyber defense ; ( 2 ) network security within larger production structures and processes ; ( 3 ) decision - making in cyber attack ; and ( 4 ) interplay of attack and defense . The second objective of the research is to discuss the approach designed and implemented in order to capture and analyze the cyber event observed . Challenges result especially from the scale of the processes to be tracked ( attack and defense ; iii number of participants ; distribution of participants in teams , roles and space ; duration of the exercise ) . The study we conducted aimed at exploring the domain of cyber security with an emphasis on the methodological dimensions of such investigation . Given the partially novel character of the research , a critical account of choices made , successes and pitfalls experienced aims at informing future advancements in the domain . The third objective is to connect this study of the particular domain of cyber security to other studies of work in real - world situations . Relevant theoretical frameworks include : decision - making under uncertainty , distributed anomaly response , joint activity , perception of intent , and more generally Resilience Engineering . Making this link allows for the discussion of potential directions to improve cyber defense , as well as to further develop these theoretical frameworks . Cyber security , because of its nature and the typical challenges associated , constitutes a rich environment for such purposes . iv To my parents , and to Jennifer and Quentin v Acknowledgements This document is the result of 5 years of learning and practice of research in the Cognitive Systems Engineering Laboratory under the guidance of Dr . David Woods . I am extremely grateful to Dave for the ample mentorship , and for the numerous and exciting opportunities I was given throughout this time of intellectual growth . Dr . Philip Smith has been an essential contributor to this experience from its very beginning . I highly benefitted from his expertise , teaching and approach to the field and to research in general . I am also very grateful to Dr . Anish Arora who has provided his enriching perspective on the particular research described here as well as on other recent projects . While a member of CSEL , I benefitted from the friendship and precious exchanges with a number of colleagues , among them Michael Smith , Dan Zelik and Emily Patterson . Special thanks to Alex Morison who , in addition , has been an essential collaborator to the research described here , from its initial steps . This research was possible thanks to the opportunity and support given by cyber security experts from the Idaho National Laboratory under the supervision of Gary Finco , and to the collaboration of David Gertman and Katya Le Blanc from the Human Factors group at INL . I am also very grateful to the forty participants of the exercise who accepted our presence and allowed for extensive recording . Finally , none of that would have been possible without the tremendous support from my family throughout the years . Thank you especially to Judith and Rodney Hild . vi Vita May 1976 ………………………… Born in Saint - Denis , Reunion Island ( France ) 1998 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . B . S . , Computer Science , University of Le Havre ( France ) 1999 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . M . S . , Computer Science , specialized in Information and Library Science , University of Caen ( France ) 1999 – 2005 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Junior consultant in information and library science , doXulting , Paris , France 2006 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . M . S . , Ergonomics , specialized in Cognitive Ergonomics , Conservatoire national des arts et métiers ( Paris , France ) 2006 – 2011 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Graduate Research Associate , Department of Industrial and Systems Engineering , The Ohio State University Publications Ames , A . , Branlat , M . , Murphy , R . R . , Woods , D . D . , Valasek , J . , & Zourntos , T . ( 2008 ) . Human - Cyber - Physical Systems for Emergency Response . Robotics and Cyber - Physical Systems . Special Session , IEEE / RSJ 2008 International Conference on Intelligent Robots and Systems ( IROS08 ) , Nice , France , 24 September 2008 . Branlat , M . ( 2009 ) . Developing the resilience of fire operations : a study of accident investigation reports . Columbus , OH : Cognitive Systems Engineering Laboratory , Institute for Ergonomics , The Ohio State University . Prepared for the Fire Department of New York . Branlat , M . , Anders , S . , Woods , D . D . , & Patterson , E . S . ( 2008 ) . Detecting an Erroneous Plan : Does a System Allow for Effective Cross - Checking ? In E . Hollnagel , C . P . Nemeth , & S . W . A . Dekker ( Eds . ) , Resilience Engineering Perspectives : Remaining Sensitive to the Possibility of Failure ( pp . 247 - 258 ) . Adelshot , UK : Ashgate . vii Branlat , M . , Fern , L . , Voshell , M . , & Trent , S . ( 2009 ) . Understanding Coordination Challenges in Urban Firefighting : A Study of Critical Incident Reports . Proceedings of the 52nd Annual Meeting of the Human Factors and Ergonomics Society . San Antonio , TX , Oct . 2009 . Branlat , M . , Morison , A . M . , Finco , G . J . , Gertman , D . I . , Le Blanc , K . , & Woods , D . D . ( 2011 ) . A study of adversarial interplay in a cybersecurity event . In S . M . Fiore & M . Harper - Sciarini ( Eds . ) , Proceedings of the 10th International Conference on Naturalistic Decision Making ( NDM 2011 ) . Orlando , FL , 31 May – 3 June 2011 . Orlando , FL : University of Central Florida . Branlat , M . , & Woods , D . D . ( 2010 ) . How do Systems Manage Their Adaptive Capacity to Successfully Handle Disruptions ? A Resilience Engineering Perspective . Proceedings of the 2010 AAAI Fall Symposium Series - Complex Adaptive Systems . Arlington , VA . Smith , M . W . , Branlat , M . , Stephens , R . J . , & Woods , D . D . ( 2008 ) . Collaboration Support Via Analysis of Factions . NATO RTO HFM - 142 Symposium on Adaptability in Coalition Teamwork , Copenhagen , Denmark , 21 – 23 April 2008 . Stephens , R . J . , Woods , D . D . , Branlat , M . , & Wears , R . L . ( 2011 ) . Colliding Dilemmas : Interactions of Locally Adaptive Strategies in a Hospital Setting . In Erik Hollnagel & E . Rigaud ( Eds . ) , Proceedings of the Fourth Resilience Engineering Symposium , 8 - 10 June 2011 , Sophia - Antipolis , France . Presses de l’Ecole des Mines . Woods , D . D . , & Branlat , M . ( 2010 ) . Hollnagel’s test : being “in control” of highly interdependent multi - layered networked systems . C ognition , Technology & Work , 12 ( 2 ) , 95 - 101 . Woods , D . D . , & Branlat , M . ( 2011 ) . Basic Patterns in How Adaptive Systems Fail . In E . Hollnagel , J . Pariès , D . D . Woods , & J . Wreathall ( Eds . ) , Resilience Engineering in Practice ( pp . 127 - 144 ) . Farnham , UK : Ashgate . Fields of Study Major Field : Industrial and Systems Engineering Specialization in Cognitive Systems Engineering Minor Field : Health Systems Minor Field : Information Analysis viii Table of content Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ii Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v Vita . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi List of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi List of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xii Chapter 1 . Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 1 . 1 . Relevance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1 . 2 . Study conducted . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 1 . 3 . Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 3 . 1 . Objective 1 : Developing knowledge of cyber security as a domain of practice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 3 . 2 . Objective 2 : Proposing and discussing a methodological and theoretical framework for the domain of cyber security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1 . 3 . 3 . Objective 3 : Relating cyber security to other work domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 Chapter 2 . Background and Literature Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 . 1 . Domain of cyber security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2 . 2 . Literature and current approaches : insights and limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2 . 2 . 1 . Descriptions of cyber attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2 . 2 . 2 . Network defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2 . 3 . Informing the study through related themes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Chapter 3 . Study conducted . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3 . 1 . Exercise observed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3 . 1 . 1 . Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 3 . 1 . 2 . Participants , teams’ organization and preparation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 3 . 1 . 3 . Physical environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3 . 1 . 4 . Exercise fidelity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3 . 2 . Data collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 ix 3 . 2 . 1 . Preparation and objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3 . 2 . 2 . Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 3 . 2 . 3 . Data collected . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3 . 3 . Data analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3 . 3 . 1 . From first insights to detailed analyses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3 . 3 . 2 . Challenges with the primary data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 3 . 3 . 3 . Transcribing the activity : defining observables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 3 . 3 . 4 . Focusing the transcription process : defining scope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3 . 3 . 5 . Tracing Red and Blue processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 3 . 3 . 6 . More representation problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 Chapter 4 . Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 . 1 . Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 . 1 . 1 . General network architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 4 . 1 . 2 . Red team’s main goals and tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 4 . 1 . 3 . Blue team’s main goals and tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4 . 1 . 4 . Description of the events . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4 . 1 . 5 . Representing teams’ activities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 4 . 2 . Cyber attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 4 . 2 . 1 . Red team’s activity during the exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 4 . 2 . 2 . Dynamics of cyber attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 4 . 2 . 3 . Challenges to cyber attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 4 . 3 . Cyber defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 4 . 3 . 1 . Blue team’s activity during the exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 4 . 3 . 2 . Defending a network : core processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4 . 3 . 3 . Dynamics of cyber defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4 . 3 . 4 . A critical artifact : the network map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84 4 . 3 . 5 . Critical challenges of cyber defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 4 . 4 . Cyber event : the interplay of attack and defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 4 . 4 . 1 . Contrasting perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96 4 . 4 . 2 . Interplay during the exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101 Chapter 5 . Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 5 . 1 . Main findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 5 . 1 . 1 . Domain of cyber security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 x 5 . 1 . 2 . Methodological aspects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 5 . 1 . 3 . Implications for other fields of research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111 5 . 2 . Relevance of the Resilience Engineering conceptual framework . . . . . . . . . . . . . . . . . . . . 114 5 . 2 . 1 . Parallel views on cyber security and safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 5 . 2 . 2 . A control problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116 5 . 3 . Towards resilient cyber defense . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 5 . 3 . 1 . Sensemaking , anticipation and the adversarial nature of cyber security : adapting in time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118 5 . 3 . 2 . Impact of event : adapting in a complex environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 5 . 3 . 3 . Design seeds : collaborative network representation space . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131 5 . 4 . Limitations of the research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 5 . 4 . 1 . Methodology and data collected . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 5 . 4 . 2 . Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 5 . 5 . Moving forward : conditions and choices for future studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 5 . 5 . 1 . Type of study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139 5 . 5 . 2 . Improving data collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 5 . 5 . 3 . Themes of investigation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144 5 . 6 . Concluding remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 xi List of Tables Table 1 . 1 – Transcription of the parallel activity of the Red and Blue teams during a cyber security adversarial exercise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Table 3 . 1 – Initial themes of investigation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 Table 3 . 2 – Observables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 Table 3 . 3 – Sample view of transcript of activity in the network room . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 Table 3 . 4 – Sample view of table representing Red and Blue teams’ focus of attention . . 46 Table 4 . 1 – Critical challenges in attack activities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 Table 4 . 2 – Critical challenges in defense activities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 xii List of Figures Figure 3 . 1 – Environment of the exercise observed . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Figure 3 . 2 – Red vs . Blue exercise : attacking vs . maintaining production . . . . . . . . . . . . . . . . . . . . . . . . . 22 Figure 3 . 3 – Working space of the Red team . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 Figure 3 . 4 – Working space of the Blue team . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 Figure 3 . 5 – Location of fixed cameras in Red and Blue spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Figure 3 . 6 – Timeline representation of recordings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 Figure 3 . 7 – Summary of transcription strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 Figure 4 . 1 – General network architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 Figure 4 . 2 – Nested network philosophy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 Figure 4 . 3 – Graphical representation of Red team’s activity on the network . . . . . . . . . . . . . . . . . . . 61 Figure 4 . 4 – Red team : establishing a path towards a goal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 Figure 4 . 5 – Red team : fumbling about in the dark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66 Figure 4 . 6 – Graphical representation of Blue team’s defense activity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 Figure 4 . 7 – Potential sources of activity on the network . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 Figure 4 . 8 – Network defense processes supported by the network map ( number of observations in a total of 76 instances captured from 07 : 00 to 17 : 00 ) . . . . . . . . . . . . . . . . . . . . . . . . . 87 Figure 4 . 9 – Cyber security from an attack perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 Figure 4 . 10 – Cyber security from a defense perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97 Figure 4 . 11 – Interplay : Blue team’s perception of attack activity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 Figure 5 . 1 – ‘Candy security’ approach to network security : building a solid rampart 114 Figure 5 . 2 – Nested network security approach : increasing sense of security . . . . . . . . . . . . . . . . 115 1 Chapter 1 . Introduction The short episode reproduced below occurred about 2 hours before the end of a Red vs . Blue cyber security exercise that constituted the basis for the study described in this document . To a large extent , this event represents the culminating point of the exercise : the attacking team ( Red ) manages to disrupt the process the defending team ( Blue ) attempted to protect all day long . The representation is the parallel transcription of the activity of each team occurring in two physically separated spaces . The text is carefully positioned on each side according to the order of communications on both sides . At the end of this episode , both teams share an understanding of the outcome of the exercise , i . e . , of the Red team’s victory . Red space 16 : 55 : 00 Team members are working behind computers on their respective tasks , either alone or in pairs . RM6 is looking at a couple windows on his screen , RINL1 is next to him , suggesting where he can click . Blue space , Process control room 16 : 55 : 00 PROCLEAD : “Is there another remote ? . . . ” He turns around and says : “Somebody… We got another remote desktop on here . Do you guys know how to look at these ? ” SYS5 approaches : “What’s that ? ” PROCLEAD : “There’s another remote desktop going on over here…” PROC1 joins them . All three look at the screen for a little while . PROC1 : “What do you guys need ? ” PROCLEAD types and clicks , others look on attentively . PROCLEAD : “This is from 234 . ” They look at menu options . PROCLEAD : ”Is this to a different machine ? ” . He’s suddenly surprised : “Oh that’s… oh , they just closed…ah…” They smile . PROCLEAD : “Did you see that ? ” SYS5 : “Yeah . ” PROCLEAD : “They’re… They’re getting in , right ? ” PROC1 : “So is there a VNC running or something like that ? ” 2 RM6 turns back to the team : “Hey , starting now ! …” Team members go on with their tasks . A new colored window pops up . RM6 : “Hey ! We got in ! We got this ! ” RLEAD : “Stop something , then ! . . . now , hold on , hold on… Let’s not go crazy…” Team members chuckle . RLEAD , RM1 , RM2 , and RM9 quickly gather behind RM6’s screen . RM3 and RM8 join them shortly after . All look attentively at the screen while RM6 interacts with it . Somebody says : “uh… They aren’t getting… yeah… No status . ” RLEAD : “It’s not responding . ” RM6 moves his mouse , gets a response on the screen . Somebody says : “There we go…” RLEAD asks RM9 : “So now… You’re the electrical guy , what do you want to do ? ” RM3 : “Kill it ! ” and he chuckles . Somebody : “Trip some breakers . ” RLEAD : “You just close them ? ” RM9 : “You should be able to say… trip . . . There should be another button… okay…” RLEAD : “Trip both of those . ” RM9 : “Yeah…” 16 : 57 : 00 RM6 trips 2 breaks . RM1 : “Green means that it’s… working ? ” RLEAD : “Open… that would be my guess . ” RM9 confirms . RLEAD : “Green is the safest state… Red means it’s energized…” People discuss electrical color codes . RINL1 : “So what cameras did you guys find ? ” RLEAD : “We found the one pointing over…” RM8 asks RM3 : “Why don’t you check it ? ” RM3 sits at his computer : “Why , is something going on ? ” They chuckle . RINL1 leaves the room . The team discusses what might be going on . RM8 explains that they might be able to see what’s happening in the Blue room through a small window visible from the staircase . RM3 adds : “The camera’s not working . ” Several team members are still behind RM6’s screen . RLEAD : “Should we trip all those ? ” RM9 : “Yeah ! ” RLEAD : “But all they gotta do is reenergizing them , right ? ” RM9 : “Yeah , I mean they close them back in…” Team members discuss what to do over RM6’s screen . RLEAD goes to RM3 : “What are you seeing ? Are they freakin’ out ? ” RM3 : “I can’t see [ … ] Now why isn’t that working anymore ? ” RINL1 comes back in the room . RLEAD asks RINL1 : “So , is the camera out of power as well ? ” RINL1 : “I don’t know , but the lights are off…” Everybody bursts out laughing . RLEAD : “Seriously ? ? ? So those are real breakers , then…” PROCLEAD : “Now we can’t connect to the remote computer . ” PROC1 : “Oh no , I’m saying they’re taking control of this machine , and…” He pauses and adds : “No , they’re taking control of this machine with VNC and then using remote desktop . ” SYS5 : “Can you ping it ? Can you see if you can ping that… ? ” PROC1 walks to NIDS1 who was working in the room . PROCLEAD : “I can ping the machine…” SYS5 : “You can ping it but you can’t…” 16 : 57 : 00 Lights shut off . PROCLEAD : “Ohhhhh… Son of a gun ! … Can you believe that ? ” They laugh . PROCLEAD : “Ahhh… That was them ! It had to be them…” BINL2 goes to the process machines . Somebody asks : “Did they kill this too ? ” BINL2 confirms : “They killed the process equipment…” Table 1 . 1 – Transcription of the parallel activity of the Red and Blue teams during a cyber security adversarial exercise 3 Interestingly , these 3 or so minutes capture several important characteristics and core challenges associated with the domain of cyber security : - It is very collaborative ( on both sides ) , as suggested by the number of different roles involved in the exchanges . - It is fundamentally adversarial , but it is also characterized by very little visibility of what is occurring on the other side . - It largely consists of acting in a highly uncertain environment where it is difficult to make sense of what the situation is , thereby complicating decision - making . Moreover , the episode offers important insights about the challenges associated with the study of cyber security events : - It raises the question of how to capture participants’ activities in order to conduct detailed analyses of processes at play . - It requires the capacity to capture different streams of action simultaneously ( between teams , within teams ) . - It raises the issue of the representation of what occurs so that it is intelligible by an audience ( including the analyst him - or herself ) . - It raises the question of what to simplify about the complexity encountered ( in this case , only one stream of activity in the Blue space is represented , although other roles operating in other rooms participated actively in the defense process ) . Importantly , the episode related is only the concretization of actions conducted on both sides throughout the day : it cannot by itself describe how both teams reached this point . In particular , it does not capture how the attacking team progressed to create the opportunity to disrupt the process . On the other side it does not really describe how much the defending team was aware of this progress , nor how it attempted to hinder it . 4 This document will address these various issues by describing in detail the research conducted and the course of events throughout the day . Such accounts will allow for the description and discussion of essential characteristics of the domain of cyber security and of its investigation . 1 . 1 . Relevance The continuously growing connectivity of systems creates increasingly complex digital infrastructures that enable critical and valued services . This source of performance also constitutes a source of vulnerability to cyber threats , a growing concern expressed in military , financial and industrial domains . In particular , the potential impact of cyber attacks on critical infrastructures and services societies depend on daily is worrying . Industrial control systems , seldom designed with cyber security in mind , also exist in a competitive economical context in which proprietary information becomes decisive . These various characteristics make industries high - value targets for cyber terrorism ( Finco , Lee , Miller , Tebbe and Wells , 2007 ) . Importantly , cyber security experts observe that , at the same time , the knowledge cost for hackers is getting considerably lower ( Goodall , Lutters and Komlodi , 2004 ; Clarke and Knake , 2010 ) , especially because of the increasing availability of information , documentation and even ready - to - use software . On the other hand , cyber defense remains a highly demanding task . Numerous efforts exist to improve cyber defense , typically focused on the search for technological solutions . But in spite of the recognized challenge and importance of developing knowledge of this critical domain , human - centered research to uncover and address the difficulties experienced by network defenders is recent and still limited . Moreover , understanding cyber security , a fundamentally adversarial domain , requires 5 investigations of the interrelated defense and attack processes , but such studies are rare . While research has produced models of cyber attack or defense processes , simultaneous investigations of both processes do not appear to exist ( studies usually rely more or less explicitly on hypothesized attacker or defender behavior ) . Such research is needed to influence the design of the joint systems facing cyber attacks . 1 . 2 . Study conducted The research described in this document stems from an on - going collaboration between the Cognitive Systems Engineering Laboratory ( CSEL ) at the Ohio State University and the Idaho National Laboratory ( INL ) . It consists of a large - scale staged - world study of an adversarial cyber security exercise . The exercise was part of a weeklong training organized by INL for the energy sector and aimed at raising awareness about cyber security . Forty people coming from this industrial domain participated in the exercise , among which a majority were IT specialists ( with various competences such as database or network management ) . Some participants had pre - existing knowledge in cyber security , but no participant was an expert in this domain . The environment of the exercise consisted of the simulation of a typical industrial facility in charge of producing some product and relying on a large network in order to control the production of the physical process ( see Figure 4 . 1 ) . During the 12 - hour competitive Red vs . Blue exercise , the Red team attempted to take advantage of the openness of the network in order to attack it from the outside and , ultimately , perturb the process . On the other hand , the Blue team operated within the organization and was in charge of protecting the network and , ultimately , of maintaining the production ( see Figure 4 . 1 ) . 6 The study conducted is a staged - world study ( Woods and Hollnagel , 2006 , Chap . 5 ) based on a found scenario designed by domain experts from INL . It actually does not rely on a typical scripted scenario to provide interesting learning situations for participants . It rather consists of a high validity exercise environment ( configuration of network and assets , production and organizational environment ) in which the activity of the Red team serves as the main pacer and source of perturbations for the Blue team . Data capture involved 4 observers with relevant knowledge background ( 2 Cognitive System Engineers with computer science background and 2 Human Factors specialists with energy sector expertise ) . Observers were distributed in the various physical spaces to capture teams’ activities through hand notes . They were supplemented by various fixed and targeted audio / video recording devices . Analyses implemented a process - tracing methodology ( Woods , 1993 ) based on the transcription of physical behavior and verbal communications recorded on each side . Preparatory work based on domain literature initially informed the study and its methodology by identifying domain characteristics . These anticipated characteristics also allowed for the identification of relevant literature , such as that related to distributed anomaly response or adversarial interplay . The relevant literature provided a theoretical framework for the various phases of the study . 1 . 3 . Objectives 1 . 3 . 1 . Objective 1 : Developing knowledge of cyber security as a domain of practice Our main motivation was to develop knowledge about decision - making in cyber security , in particular to identify critical skills and forms of expertise in relation to the 7 nature of the domain . Given the limited number of available publications about cyber security in the field of Cognitive Systems Engineering and in related human - centered research , the first objective is to develop knowledge of cyber security as a domain of practice . This means revealing essential characteristics of cyber events , uncovering and analyzing typical challenges practitioners are confronted with in the real - world situations they face , and enabling the development of richer models of expert behavior . Importantly , due to the nature of the domain and of the exercise we observed for the study , we are considering both sides of cyber events , i . e . , attack as well as defense . While models of expert network defense have been proposed ( although limited ) , little research has been devoted to what attackers actually do , the type of challenges they face , what is easy or difficult for them , etc . Moreover , given the adversarial nature of cyber events , understanding attack and defense will likely benefit from considering their interplay , rather than as disjointed processes . Further developing knowledge of those essential aspects of cyber security will , in our mind , offer richer insights and directions about how to improve cyber defense . In addition to the study of core processes of cyber defense , the context of the exercise allowed for the investigation of other fundamental dimensions of cyber events : ( 1 ) Network defense in the general production context : how network security exists within larger organizational structures and processes ( 2 ) The interplay of attack and defense : adversarial interactions at the intersection of two perspectives ( 3 ) Cognitive account of cyber attack : how attackers make decisions , what challenges they typically face , etc . 8 1 . 3 . 2 . Objective 2 : Proposing and discussing a methodological and theoretical framework for the domain of cyber security The study we conducted aimed at exploring the domain of cyber security with an emphasis on the methodological and theoretical dimensions of such investigation . Research themes and methodological choices were informed by preparatory analyses and previous studies conducted in comparable domains , including design and management of exercises , challenges in intelligence analysis ( e . g . , in the perception of an adversary’s intent ) ; and challenges to cooperative activity . The exercise represented a challenging observational environment because of the scale of the processes to be tracked ( attack and defense , number of participants , the distribution of participants in teams , roles and space , the duration of the exercise ) . Typical ethnographic approaches do not extend easily to the scale and scope of the research described here ( Hughes , King , Rodden and Andersen , 1994 ) , requiring methodological adaptations in order to “shape the conditions of observations” ( Woods and Hollnagel , 2006 , Chap . 5 ) . A distributed observation strategy was designed and implemented . Data captured constituted disjointed perspectives or limited snapshots of the activity of the various roles engaged in the exercise . A central challenge to the analysis of the data was to construct coherent accounts from the diverse perspectives and how they related to each other from the multiple threads of observation . Ultimately , there is no single perspective that can provide an exact account of what happened during the exercise . Observations are , therefore , interpretations organized around a few observable events that constitute landmarks . They are teased out from the interactions of participants within their respective teams , and from the perceived interplay between 9 attacking and defending teams . An important objective of the research is to describe and reflect on the approach we designed and implemented in order to capture and analyze the cyber event we observed . To our knowledge , there is simply no publicly available observational study of adversarial event in the context of cyber security , and the study described is novel in nature . It is therefore important to document our research process so that it is available to a research community , and to do so in a critical way . An ambition of the dissertation is to inform a methodological and theoretical framework for future research ( conducted by us or others ) in the cyber security domain or in domains presenting similar characteristics and challenges : what type of investigations would be needed , what theoretical framework ( s ) could be leveraged , what methodologies could be implemented , etc . 1 . 3 . 3 . Objective 3 : Relating cyber security to other work domains The third objective is to connect this study of the particular domain of cyber security to other studies of work in real - world situations . Making this link allows for the discussion of potential directions to improve cyber defense , as well as to further develop related theoretical frameworks . Relevant research includes : decision - making under uncertainty , distributed anomaly response , joint activity , perception of intent , and more generally Resilience Engineering . From the perspective of cyber security as a domain of practice , we believe that recent advances in the Resilience Engineering framework ( Hollnagel , Woods and Leveson , 2006 ) can inform ways in which cyber defense can be better supported . More specifically , the objective is to improve cyber defense by leveraging resilient processes and identifying points of brittleness throughout cyber defense ( e . g . , representations of 10 network and network activity , collaborative processes , organizational structure and mechanisms , etc . ) . From our perspective , cyber security , because of its nature and the typical challenges associated with it , constitutes a rich environment that can enable us to advance the theoretical framework of Resilience Engineering . An objective of this project is to further investigate and develop principles underlying resilient control architectures . Resilience Engineering is a fairly recent theoretical framework ( although it partially builds on other , more established research fields ) . Previous work in domains such as emergency response has been instrumental in describing basic dynamics in work systems ( seen as complex adaptive systems ) and core principles of resilient control ( Woods and Branlat , 2011 , 2010 ) . The research described in this document aims at investigating how results from previous studies conducted under the Resilience framework might inform the study of cyber events and how new constructs might be needed to better account for and address the situations encountered . 11 Chapter 2 . Background and Literature Review 2 . 1 . Domain of cyber security The US Computer Emergency Readiness Team ( CERT ) defines a cyber security incident as “any real or suspected adverse event in relation to the security of computer systems or computer networks” 1 . This general definition covers a domain characterized by a particularly large diversity of situations : from an individual personal computer corrupted by a virus and simply used as a ‘zombie’ spreading email spam , to the potential disruption of public infrastructures or implementation of cyber warfare . This also suggests that , as a domain of practice , cyber security corresponds to a wide variety of situations . Personal computer users are practitioners when they , more or less expertly , use various ways to protect their own data and equipment . Similarly , in many businesses , regular , non - specialized Information Technology personnel hold such responsibilities . However , in the context of this document , we will consider expert practitioners that belong to organizations confronted with cyber security issues at a fairly high rate and at a large scale . But even in this case , many different situations can be observed . In a context such as an academic institution , a security specialist simultaneously fulfills other roles , including serving as administrator for networks and systems . Typically , in such settings , cyber security experts have significant authority and 1 CERT® / CC : Computer Security Incident Response Team FAQ , available at http : / / www . cert . org / csirts / csirt _ faq . html 12 autonomy to act on the network or its assets upon recognition of an incident or threat . In large organizations , such as the industrial setting the exercise simulated , roles are more fragmented because of the need to have sufficient coverage of the network ( types of competence and scope ) . In the first case , security experts hold more responsibility , but have more intimate knowledge of the network , its components and services through the various functions they fulfill . In the second case , security experts are essentially analysts whose role is to produce reports intended for network owners who will make final decisions about how to manage the network . Role distribution also introduces new challenges and requirements in coordination , as we will describe in following sections . Also , incidents are themselves very diverse . Consider , for instance , their temporal scale : some events span over minutes or hours , while others require understanding of months of interaction ( reconnaissance , scanning , preparation , etc . ) . Organized attackers ( e . g . , state - sponsored ) typically spend a lot of time on preparation and only launch attacks when they have sufficient knowledge about their target . The event we observed corresponds to a shorter , daylong event , but can be seen as the active attack phase following a longer preparation phase . Industrial settings are potentially confronted with the variety of situations described , i . e . , with individual attackers attempting to steal sensitive personnel data or with a competitor - sponsored group interested in causing more serious disruptions . 2 . 2 . Literature and current approaches : insights and limitations Unsurprisingly , research in the domain focuses on providing security rather than increasing threats ; most of the literature , therefore , focuses on the defensive side of cyber security . Other publications aim at increasing knowledge about attacking behavior . In 13 this general context , studies of cyber security that explicitly investigated both sides of cyber events as well as their interplay seem rare ( I am actually not aware of any publicly available study of that kind ) . 2 . 2 . 1 . Descriptions of cyber attack In order to improve the understanding of the domain and of the requirements for cyber defense , cyber attacks have been described based on after - the - fact investigations or expert interviews ( e . g . , Clarke and Knake , 2010 ) . These accounts are informed interpretations at best , since available data often are scarce and highly ambiguous ( Arbaugh , Fithen and McHugh , 2000 ) . Studies have focused on defense relying more or less explicitly on hypothesized attacker behavior . A notable exception is Jonsson and Olovsson’s study ( 1997 ) of cyber attack dynamics , but this study is based on assumptions that limit its realism . Important limitations exist related to the current descriptions of cyber attack . First , they are not based on actual analyses of attack as a domain of practice , and the limited validity of experimentations makes results debatable . Importantly , challenges to cyber attack do not seem to constitute a core theme of investigation , as attack behavior seems to be the main concern . Similarly , hackers are rarely described as members of teams , and the distributed nature of cyber attack is not investigated . As the initial vignette illustrates ( see Table 1 . 1 ) , there remains much to learn about what it means in terms of challenges , distributed decision - making , additional capabilities , parallel processes , etc . Models of cyber attack are developed and used mostly for supporting the reactive nature of cyber defense , especially for designing “better” technology ( more elaborate , richer algorithms ) . The adversarial nature of cyber security and the co - adaptive 14 processes between attack and defense seem to be overlooked in the literature . One notable exception is the description of deception defensive strategies such as the use of honeypots . Honeypots are used to lure attackers into isolated areas of the network where they cannot disturb the real network and can even be analyzed while they operate . 2 . 2 . 2 . Network defense Technocentric approaches Common publications are how - to resources that focus on the technological dimensions of the domain and associated knowledge and skills ( e . g . , firewall management or cryptography ) . In this type of literature , technological elements like firewalls , the historic and still dominant approach to security ( Cheswick , Bellovin , and Rubin , 2003 ) , represent the core of the solution and practitioners are expected to follow good practices in their use in order to ensure network security . Such approaches are mostly preventive and aim at reducing vulnerabilities on the network . Other typical approaches are more reactive and aim at addressing the detection of events , their analysis and management . Because of its criticality as the initial step in the response process , the task of intrusion detection is the focus of a large amount of research and development efforts ( e . g . , Kruegel , Valeur and Vigna , 2005 ) . These approaches are essentially technological , e . g . , related to the development of more elaborate algorithms of intrusion detection . One of the most used family of tools in cyber defense , Intrusion Detection Systems , aim at supporting analysts by helping them focus their attention on what really matters within overwhelming amounts of data . They basically rely on extensive sets of rules describing legitimate or illegitimate elementary 15 network activity , and on the capacity to generate corresponding alerts . Many publications point out the unsatisfying nature of these tools ( e . g . , Allen et al . , 1999 ; Bace and Mell , 2001 ) , including the generation of large amounts of false positives and false negatives and alerts , the principal element of support of analysts’ work , that are ambiguous and end up being discarded . A large amount of technology - oriented research and development aims at improving such systems in order to automatically provide analysts with an accurate , integrative diagnosis about what’s happening on the network ( Kruegel et al . , 2005 ) . Recently , collaborations between technology - centered and human - centered researchers under the label of cyber situational awareness ( Jajodia , Liu , Swarup and Wang , 2010 ; Tadda , 2008 ) propose a mixed approach to decision - making in cyber security . However , it remains largely focused on technological solutions in order to either process information to provide situation awareness to the analysts , or to model and replicate human cognitive processes to reach autonomous situation awareness . Ultimately , these are classic approaches to the design of automation with the affirmed goal of supporting human systems’ performance . It is commonly believed that the solution to the challenges of data analysis ( such as data overload ) consists of some kind of automated intelligent system that combines processing with logical powers through various pre - encoded rules and learning mechanisms . While these approaches may offer valuable conceptual and practical results , they are at risk of falling to the same “ironies of automation” and other forms of brittleness described for decades in research fields such as Cognitive Systems Engineering and related domains ( Bainbridge , 1983 ; Smith , McCoy and Layton , 1997 ; Guerlain et al . , 1999 ; Hollnagel and Woods , 2005 ; Woods and Hollnagel , 2006 ; Smith , Geddes and Beatty , 2008 ) . For anticipated , known problems and stable environments , these systems might work as designed ; but for unanticipated 16 situations , outside of the systems’ design envelope ( situations likely to arise in rapidly evolving domains like cyber security ) , human operators’ expertise at making sense of the situations and solving problems is not supported appropriately and might even be impaired . Anthropocentric approaches Various authors recognize that , in spite of significant technological progress , human agents continue to be key elements of network security ( Goodall , 2008 ) . Based in part on cognitive task analysis methods , detailed accounts of the work of network defense analysts exist ( e . g . , Biros and Eppich , 2001 ; Goodall et al . , 2004 ; D’Amico , Whitley , Tesone , O’Brien and Roth , 2005 ; D’Amico , Goodall , Tesone and Kopylec , 2007 ; D’Amico and Whitley , 2008 ) . This body of research is , for instance , at the heart of the concerns explored during the annual VizSec ( Visualization for Cyber Security ) conferences , where researchers describe ways to support network analysts through advanced visualizations of the network . Research conducted by D’Amico and colleagues ( 2005 and subsequent ) have combined different methods of knowledge elicitation and capture : “structured interviews , observations , review of critical incidents , and hypothetical scenario construction” ( ibid . ) . However , these publications are not very explicit about how these methodologies were used . In particular , observations do not appear to be observations of particular cyber events , but rather of the daily activity of network analysts ( probably while conducting concurrent interviews ) . An interesting aspect of their methodology , though , is the utilization of hypothetical scenario construction as a tool for knowledge elicitation about domain practices and challenges . While allowing for the capture of typical dimensions of the domain , such methodology avoids issues of confidentiality and sensitivity that plague ecological investigations of 17 cyber security . One limitation of these efforts is that they are largely focused on the single network analysis perspective within the larger context of cyber security . An important difference with the research described here is the time frame considered . We observed a 12 - hour simulated cyber event , while these publications describe processes extending potentially over weeks or months . Some of the important activities analysts engage in will , therefore , be out of the scope of this research ( e . g . , analyses conducted to profile attackers and share knowledge with the greater network defense community ) . A multi - year investigation of security management by IT professionals was conducted in recent years by a group of researchers at the University of British Columbia ( Botta et al . , 2007 ) . From these investigations , a set of publications exists that describes the collaborative nature of cyber defense ( Botta , Muldner , Hawkey and Beznosov , 2010 ; Werlinger , Muldner , Hawkey and Beznosov , 2010 ) and explores its processes within the larger organizational framework ( Hawkey , Muldner and Beznosov , 2008 ; Werlinger , Hawkey and Beznosov , 2009 ; Werlinger , Hawkey , Botta and Beznosov , 2009 ) . However , these studies appear to be based on semi - structured interviews as the essential method of investigation . While interviews are valuable tools for discovery and detailed analysis , they also represent limitations that call for additional methodological approaches . Interestingly , this body of research covers several organizational types ( e . g . , academic , government and private ) , allowing for the description of the diverse domain of cyber defense over a broad spectrum . 2 . 3 . Informing the study through related themes The research described contributes to a broader effort to conduct a work domain analysis of cyber security , in particular through conducting Cognitive Task Analyses of 18 key roles involved in cyber defense . Previous work has focused essentially on the work of network analysts , and , to a large extent , through interviews only . The research described here , by its wider focus ( adversarial , attack , large organizational context ) and as an account of an actual event ( cyber security exercise ) , aims at making critical additions to these efforts . But in spite of its novel character , especially for the domain of cyber security , numerous classic Cognitive Systems Engineering ( or related ) themes investigated in other domains can inform our conceptual framework . The typical framework for analysis of cyber events , and for the search for improvements , is that of one operator monitoring a network ( the process ) through a set of sensors ( network activity capture ) and displays ( network activity analysis software ) in order to maintain the network in a satisfactory functional state . A cyber attack then represents a set of perturbations the operator needs to detect , understand and act upon in order to respond and recover . This situation is analogous to classic process - control situations . There are , therefore , insights to gain from this analogy ( typical challenges , patterns and potential solutions ) . Relevant themes potentially include : data overload , sensemaking , anomaly detection , anomaly response , supervisory control , human - automation interaction , expert systems , etc . However , several problems or limitations with this analogy require a different framework for analysis : - As with classic process - control , in most settings ( especially large settings like industrial facilities ) , the operator is actually a team of operators . Not one single agent holds all the knowledge about and has all access to the network . As a result , the response to a cyber event is a result of various perspectives , types of expertise and concerns ( goals , things at stake , priorities ) . Cyber security situations are , therefore , informed by the literatures on teamwork , collaboration and 19 coordination . We will especially borrow from the themes of distributed problem solving ( Smith , Spencer and Billings , 2007 ) and distributed anomaly response ( Patterson and Woods , 2001 ) . - Networks exist within larger work systems pursuing goals and managing constraints that are wider ( e . g . , production ) than those only related to security . This is a source of classic trade - offs described in the literatures of Resilience Engineering ( Hollnagel et al . , 2006 ) and High - Reliability Organizations ( Weick and Sutcliffe , 2001 ) . - Cyber events are fundamentally adversarial events . They should , therefore , be analyzed as co - adaptive processes , rather than from one single perspective , and pose the problem of how each side perceives and adapts to the adversary’s actions ( Jervis , 2002 ; Mundutéguy and Darses , 2007 ; Zimmerman , 2008 ; Trent , Smith , Zelik , Grossman and Woods , 2009 ) . These various points are sources for new themes of investigation and also of new methodological challenges and goals . Some will be described in this document . 20 Chapter 3 . Study conducted 3 . 1 . Exercise observed 3 . 1 . 1 . Overview The central part of this study corresponds to observations we conducted during a daylong cyber security exercise . This exercise was part of a weeklong cyber security training organized by the Idaho National Laboratory and designed for the U . S . Department of Energy . It is especially focused on the vulnerability to cyber threats of infrastructures of the energy sector and explores issues associated with supervisory control and data acquisition ( SCADA ) systems used throughout the industry . Such systems are large computerized and networked systems that connect everything related to the monitoring and control of industrial facilities : individual sensors , automated controllers , operators’ process control applications , control rooms , sub - stations ( potentially outside the main facility ) , clients’ applications , etc . Although these systems are usually not designed with cyber security in mind , advances in connectivity and computerization make them much more connected than they used to be a few decades ago . For instance , remote ( potentially wireless ) access to distant facilities is now common and improves or facilitates many daily operations . The main goals of this type of training , which INL conducts on a regular basis , include : - increasing awareness around issues of cyber security , 21 - supporting understanding of the nature of threats , - providing knowledge about resources for cyber attack and defense , and - supporting understanding of the challenges of conducting or responding to an attack . In addition to providing general information about the domain , a key purpose of the training is to prepare participants for the 12 - hour Red vs . Blue exercise that concludes the week , especially by providing them with the necessary technical knowledge . The environment of the exercise consists of the simulation of a typical industrial facility in charge of producing some product ( physical process ) . INL cyber security experts built up an elaborate technological and organizational environment based on extensive experience in assessing network vulnerabilities ( particularly in SCADA systems ) and in conducting training exercises ( INL , 2008 ) . Figure 3 . 1 – Environment of the exercise observed 22 The organization relies on a large network in order to control the production of the physical process . This network includes assets directly related to the control of the process ( e . g . , sensors and data servers ) , but also more general assets that constitute the underlying infrastructure for corporate services ( e . g . , various servers providing standard IT services ) . This general network is connected to the Internet in order to support necessary exchanges with the outside , for instance , with customers or suppliers . During the 12 - hour competitive Red vs . Blue exercise , the Red team attempted to take advantage of the openness of the network in order to conduct an attack from the outside and , ultimately , perturb the process . On the other hand , the Blue team , operating within the organization , was in charge of protecting the network and , ultimately , of maintaining the production . Figure 3 . 2 – Red vs . Blue exercise : attacking vs . maintaining production 23 3 . 1 . 2 . Participants , teams’ organization and preparation Forty people participated in the training . Participants were members of various companies related to energy production and distribution ( a majority of asset owners and vendors ) . They were mostly IT specialists ; many had cyber security - related knowledge , but they were not cyber security experts . The split between Red and Blue teams occurred about 2 days prior to the exercise . Ten participants were chosen by INL instructors to constitute the Red team , in an effort especially to mix organizations represented , for instance , so that colleagues would have a chance to share perspectives after the event . Red team members were also chosen to ensure that the attacking team would have enough technical skills to conduct an attack . In such a setting in which there is no scenario per se , the quality of the exercise indeed depends on the capacity of the Red team to accomplish a minimum amount of progress . The Blue team was composed of the thirty remaining participants . Both teams , separately and secretly , used the time preceding the exercise to self - organize and define roles and goals , essentially based on self - declared individual areas of expertise and interests . On the Blue side , this process led to the distribution of tasks into 6 groups supporting the larger objectives of production and cyber defense : process control , network administration , systems administration , applications , mid - level management and management . This functional distribution largely mirrors how companies running industrial facilities would organize the various IT services supporting production . It was also probably a result of the physical layout of the Blue space that the team had been able to visit during the preparation for the exercise ( see paragraph below ) . 24 Both sides also used this time to discuss and devise strategies and tactics , in order to be able to start implementing them as soon as possible once the exercise started . Members of the Blue team were given a network map in advance and had a chance to get familiar with the network’s general configuration , to start identifying vulnerabilities and actions to address them , to devise communication protocols to request changes to the management and facility owners ( played by a White Cell during the exercise ) , etc . In addition to participants , INL instructors fulfilled a few key roles in the development and conduction of the exercise : - Remote supervision of the general process , especially through various technological means allowing them to monitor the activity of both teams on the network . - Direct supervision on each side : two or three instructors were permanently assigned to each team and served as strategic , tactical and technical advisors . On the attacking side , instructors were especially in charge of introducing pacers in the form of trophies handed to the Red team in order to structure their activity and help them identify targets . - Role playing of a White Cell representing the facility owners , the ultimate decision - makers with whom the Blue team would have to interact in order to implement actions . 3 . 1 . 3 . Physical environment The Red team shared a single room organized to allow for collaboration within the team ( central oval table , shared resources such as large displays ) while also allowing for 25 individual activity for more specific tasks ( a few individual workstations ) . People sitting around the central table used their personal laptops . Figure 3 . 3 – Working space of the Red team The Blue team , on the other hand , was split into different adjacent rooms the purposes of which were mirrored by the team’s organization into sub - teams ( see Figure 3 . 4 ) . As with the Red space , each room was organized to allow for collaboration within the corresponding sub - team . However , exchanges between members of different sub - teams required physical movement to the appropriate space . 26 Figure 3 . 4 – Working space of the Blue team Both the Blue and Red spaces were closed to the outside in order to prevent participants from physically intruding into the adversary’s space and gaining some advantage . This has been a concern in previous exercises as well as in real working environments . 3 . 1 . 4 . Exercise fidelity As a simulation of a cyber security context and event , the exercise’s design and conduction characterizes its fidelity : 27 - The exercise is a high - fidelity simulation for the type of industrial domain targeted , in terms of : o the Red team and Blue team networks , o Blue team corporate organizational structure , and o to a lesser extent , Blue team physical environment . - Based on discussions with cyber security experts and literature review , other important dimensions are more disputable , in particular : o participants are not domain experts , although supervised by experts , o the restriction to a 12 - hour time frame , altering the base rate of hacking that often takes place over the course of weeks or months ( especially for such large industrial systems ) , o Blue team’s limited knowledge of its network prior to the event , o Blue’s awareness that their network is under attack , and o Blue’s lack of prior response plan . Overall , the exercise can be considered a faithful simulation of an active phase of attack on a large industrial production facility . This phase would follow a long and stealthier preparation phase , aimed at building sufficient prior knowledge and potentially at planting initial seeds to support attack ( e . g . , ‘social engineering’ ) . The active attack could be triggered by hackers getting indications that their presence is starting to be detected , leading them to take action before a window of opportunity closes . The defending team would , therefore , expect to be confronted with malignant activity on its network and with threats to its sensitive information and processes . 28 With the afore - mentioned limitations in mind , we expect that the processes , dynamics and challenges we observed during its course are largely representative of actual active attacks and responses to these attacks in large industrial production facilities . 3 . 2 . Data collection 3 . 2 . 1 . Preparation and objectives The initial motivation of the study was to develop knowledge about decision - making in cyber security , in particular to identify critical skills and expertise needed in this domain . We identified additional research themes , informed by preparatory analyses and previous studies conducted in comparable domains : - design and management of exercises ( team’s expertise at conducting exercises to reach learning objectives ) , following the learning laboratory approach ( Voshell and Woods , 2009 ) , - perception of intent , especially related to challenges in intelligence analysis ( Trent , Patterson and Woods , 2007 ; Trent et al . , 2009 ) , to the management of uncertainty and co - adaptive processes , and - dimensions of cooperative activity , such as distributed problem solving ( Smith et al . , 2007 ) and challenges to cooperative activity ( Branlat , Fern , Voshell and Trent , 2009 ; Woods and Branlat , 2011 ) . Table 3 . 1 summarizes the themes of investigation : 29 Theme of investigation Particular interest Decision - making in cyber security - Critical skills and expertise - Decision challenges Perception of intent - Management of uncertainty - Co - adaptive processes Cooperative activity - Distributed problem solving - Types of cooperative activity - Challenges to cooperative activity Design and management of exercises Expertise at designing and conducting exercises to reach learning objectives Table 3 . 1 – Initial themes of investigation 3 . 2 . 2 . Methodology To fulfill the objectives described above , we wanted to capture how participants made decisions and solved problems collaboratively during the exercise . We also wanted to be able to relate activities occurring in parallel is different physical spaces , especially to look at the relation between the Red and Blue teams’ actions ( how actions and decisions on one side influenced or impacted situation on the other ) . The cognitive orientation of our research required that we devise some way of capturing aspects of individual as well as distributed cognition . During the days preceding the exercise , we were able to describe our study and its objectives , as well as some of the methods we typically use in our research to have access to and interpret cognitive processes . Our presence as external observers was globally accepted , as well as the fact that we would capture the event through various recording mechanisms ( see section below ) . On the other hand , we had to remain as unobtrusive as possible in order not to disrupt the course of the exercise or the actions of participants . As a consequence , it was essentially not possible to conduct even minimal concurrent interviews to better 30 understand the bases for participants’ decisions and actions . We , therefore , relied on ethnographic methodologies that emphasize unobtrusive observations , through the capture and analysis of various aspects of behavior such as communications , physical behavior and instances of collaborative activity ( e . g . , team members gathering to discuss a problem ) . Communications , especially , are useful manifestations of people’s cognition by revealing aspects such as their concerns , focus of attention , state of understanding , or attempts at solving problems . Communications have been utilized extensively in ethnographic studies of cognition , particularly in the investigation of team performance , since they occur more naturally as a central element of cooperative activity ( Falzon , 1991 , 1994 ; Hutchins and Klausen , 1996 ; Cooke , 2002 ; Cooke , Salas , Kiekel and Bell , 2006 ; Patterson , Watts - Perotti and Woods , 1999 ) . Communications can especially be used after the fact to apply process - tracing techniques in order to analyze cognitive processes and challenges ( Woods , 1993 ; Patterson and Woods , 2001 ; Branlat , 2009 ; Branlat et al . , 2009 ) . The exercise represented a challenging observational environment because of the scale of the processes to be tracked ( attack and defense , number of participants , the distribution of participants in teams , roles and space , the duration of the exercise ) , but the team has built up experience and techniques for studies of large scale exercises ( Voshell and Woods , 2009 ; Trent et al . , 2007 ; Trent et al . , 2009 ) . Observers were distributed to match the distribution of participants in teams , roles and space : 1 observer with the Red team , 3 with different groups within the Blue team . To observe participant behavior and collect data , we relied on 2 types of means : fixed cameras for constant recordings in 4 rooms where more critical activity was anticipated ( see Figure 3 . 5 ) and more targeted and opportunistic data capture decided upon individually ( observer hand notes , audio and video portable recording devices ) . 31 Figure 3 . 5 – Location of fixed cameras in Red and Blue spaces Because of the physical layout of the Blue space , separations into functionally - defined rooms and the limited observation resources , the three observers in the Blue space were distributed according to the expected importance of each area in the network defense . Observers were able to move across spaces , for instance , to follow movements of particular roles or cover additional areas . However , because of the importance and difficulty of maintaining sufficient understanding for a specific set of roles related to a function / space , it was perceived as valuable to favor continuous observations of the 32 same roles . The usual configuration was , therefore : one observer in the Systems / Servers room , one observer in the Network room ( myself ) and one observer in the management areas . For the same main reason , the observer appointed to the Red space stayed in this location for almost the entire exercise . Distributed observations of multiple participants , roles , and teams allowed for the coverage of a large part of the physical environments but did not directly capture the interactions across activities and perspectives . To assess interactions across the different perspectives , the observation team held regular briefings throughout the exercise ( Voshell and Woods , 2009 ) . These cross - briefings helped to identify connections between perspectives and cued observers about potentially interesting events to anticipate . Briefings between the observers located with Blue team and the observer located with the Red team were especially important because , by nature of the exercise , the Red team was the principal pacer of the event . Note that similar challenges were experienced during the subsequent analysis : it was necessary to construct coherent accounts from the various perspectives and determine how they relate to one another from the multiple threads of observation . Additional observational challenges derive from the nature of cyber events . The environment is virtual , making actions difficult to observe . Moreover , effects of actions are not immediately experienced and are often uncertain ( including to the actors themselves , as we will discuss later ) . Ultimately , there is no single perspective ( from a participant or an observer ) that can provide an exact account of what happened during the exercise . A synthesis , therefore , relies on interpretations organized around a few observable events that constitute landmarks . These interpretations are constructed from 33 the interactions of participants within their respective teams and from the perceived interplay between Red and Blue teams . 3 . 2 . 3 . Data collected The data collected consist of : - Audio / Video recordings from the fixed cameras . Cameras were connected to laptops and continuously recorded during the entire exercise ( minus breaks during the exercise and a computer crash ) . They were positioned and oriented according to expectations of areas of rich activity and to constraints of the space ( especially possibilities to position laptops and view angles afforded ) . Given our interest in collaborative processes , collaboration - oriented areas ( such as the oval tables in different spaces ) were the main targets . The position of fixed cameras was rarely modified . One exception is the camera in the Network room , initially positioned to capture exchanges around the table , but repositioned after a few hours to better capture the numerous interactions around the network map displayed on the wall nearby . - Hand notes describing the activity observed , sometimes including reflective comments . The nature of the notes varied significantly between observers . They are usually a good source to identify particular events or landmarks . - Audio recordings from the recording pens used to take notes . These were used in two different ways : sometimes opportunistically , to target particular aspects of the situations ; sometimes as a “background” recording mechanism , relying on the synchronization with hand notes to provide indication of the evolution of the situation . 34 - Audio / Video recordings from handheld video camera recorders ( camcorders ) . These recordings were used essentially for targeted capture of punctual events such as moments of interaction between participants . The different recordings were synchronized ( to the best of our ability ) and represented into a single timeline ( see Figure 3 . 6 ) . The recordings are plotted relative to their type , location , time of creation and duration . Types include : - fixed cameras ( thin numbered arrows ) , - camcorder recordings ( thick indigo lines , < x > F < nn > labels ) , and - audio recordings ( thick maroon lines , < x > P < nn > labels ) . In addition , a few landmarks are identified and represented by vertical areas . Besides the breaks , during which there was no activity , the light green areas are two episodes during which the Red team managed to turn the lights off in the Blue space . Due to their physical and transversal nature , these events were essential elements of the synchronization of the various recordings . Importantly , they are , in the case of the exercise , clear manifestations of Red’s overall success ( it was clear on both sides ) . 35 Figure 3 . 6 – Timeline representation of recordings 36 The purpose of this representation is mainly to facilitate the analytical process by allowing the quick identification of which recordings are available at a given time and place and in relation to what event . We will describe this use of the diagram in the following section . The representation also provides a sense of where the interests of the observers and actions concentrated . 3 . 3 . Data analysis This section offers a detailed account of the approach followed for the study and the various analytical products generated . This serves several key methodological purposes this document aims at addressing : - Giving the reader a sense of the challenges related to the analysis of an event presenting relatively uncommon characteristics for an ethnographic approach : o it is adversarial by nature , and o it is of particularly large scope ( duration , participants highly distributed in a number of teams and roles ) . - Presenting the choices made in the face of these challenges . - Informing future equivalent studies , by us as well as others ; especially in order to be better prepared , thereby reducing the challenges experienced and facilitating the analytical process . 3 . 3 . 1 . From first insights to detailed analyses Initial findings ( Branlat et al . , 2011 ) were based on observations and insights captured through hand notes during and after the exercise , as well as on various meetings that 37 occurred after the exercise ( especially between Alex Morison who observed the Red team and myself who observed the Blue team’s Network group ) . This initial phase can be considered the ”open” observations phase described in the methodological framework proposed by Guérin and colleagues ( 2007 ) . It was framed by preparatory work based on the literature on the domain of cyber security . This was the starting point for a more detailed work analysis in the form of more ”systematic” observations that were supported by the possibility to visit and re - visit the recordings captured . Systematic observations typically follow a research plan that aims at addressing specific hypotheses through defining what needs to be collected ( i . e . , observables ) and how the collection should be conducted . Because of the exploratory nature of this particular study , we did not have specific hypotheses , but rather themes of investigation ( see Table 3 . 1 ) that aimed at framing the discovery process . The findings presented in this document are a result of the systematic analysis of the audio / video data we collected . The following sections describe the analytical process we followed . 3 . 3 . 2 . Challenges with the primary data We were able to produce numerous notes and recordings of the exercise and cover a large part of the activities . The recordings aimed at capturing elements representative of cognitive processes , such as communications , at the individual as well as at the team levels . Recordings especially aimed at balancing the absence of possibility to interview participants during or after the exercise . Unfortunately , the quality of the recordings was impaired by environmental conditions , initial choices and relatively low - tech means . In many cases , particularly for the fixed cameras , the audio is simply unusable due to the amount of interactions and / or distance between people and the microphone . 38 Background noise was especially difficult to avoid in the Blue space , which was less contained than the Red room . Also , fixed cameras represent a particular visual perspective that depends on room space , location of camera and camera angle . For instance , the camera in the Network room was repositioned after a few hours when it became clear that the network map was going to be an interesting artifact in the activity . As a result , it is possible to see how central the map is , but other interesting sources of activity are hidden , such as actions on the Intrusion Detection Systems ( see Figure 3 . 5 ) . In the end , adopting a particular viewpoint for a long period of time represents a compromise between multiple , potentially conflicting objectives of the investigation . 3 . 3 . 3 . Transcribing the activity : defining observables Given the nature and amount of data collected , it was important to find means to facilitate the analytical process . One of the main initial problems with the audio / video content was the impossibility to efficiently search and find particular elements of interest , such as activities related to a specific role or to a specific element of the network during a certain period of time . It , therefore , appeared necessary to create a detailed description of the exercise through transcription in a text format . This description would serve as the baseline data for more in - depth analyses . Importantly , data in such format could be re - examined over time and used for various analytical purposes . The transcription process aimed at describing what was occurring in the various spaces in enough details in order to allow for subsequent analyses that correspond to various research purposes . Given the nature of our primary data , the basic elements of activity were the verbal communications and the physical actions of participants . Because it is not possible to account for everything happening , observables , i . e . , the perceivable 39 elements of interest of the activity captured in the data , were defined . These observables , described in Table 3 . 2 , were chosen in order to allow for the investigation of the themes described previously ( see Table 3 . 1 ) . Type Observable Investigation theme Comments Recording / Time Recording and relative position of element Participants’ roles What participant does / says what ? General INL supervisors’ roles Design and management of exercises What supervisor does / says what ? Technical elements of information ( e . g . , IP addresses , networks ) Decision - making in cyber security , Cooperative activity Manifestation of focus of attention Verbal exchanges Explanations , hypotheses Decision - making in cyber security , Perception of intent , Cooperative activity Access to sensemaking processes : what they know , understand , expect at the time Movements between rooms Cooperative activity , Decision making in cyber security What role comes when , to be correlated with events Physical actions Interactions over collaborative artifacts Cooperative activity , Decision making in cyber security Especially network maps ( who participates , what are they looking at ) Table 3 . 2 – Observables Given the uncertainty or ambiguity characterizing the actions observed , the transcription process already relies on interpretation . It was , therefore , necessary to keep detailed account of where in the recordings the elements were observed . Such information would especially allow for the re - examination of the primary material in order to validate interpretations . 40 The transcription’s level of detail varied depending on the situation and on what the recordings afforded . For instance , verbal communications were transcribed into actual quotes when possible and when judged interesting ( e . g . , a participant reflecting on the situation and sharing his insights with others ) . Other times , word - for - word transcription was judged unnecessary when it was simply important to note the general content of an information exchange . Often , the quality of the recording did not afford sufficient access into actions and verbal exchanges to be transcribed into a detailed account . The following table offers a sample view of the transcript for the recordings made in the Network room . In order not to disclose too many details about the framework of the exercise , technical elements of information were sanitized and made generic . In the transcripts we used for in - depth analyses , we noted as much technical detail as we could gather or understand from the context . … 1 : 17 : 00 NLEAD suggests putting an ACL ( Access Control List ) at the level of the Border Router [ points to the network diagram while discussing blocking Class B with NIDS2 ] . ~ 1 : 17 : 30 NIDS group interacts with NLEAD about things to block . NIDS3 goes to NetMap to describe the situation . NIDS1 and NIDS3 discuss over the map ( aspects of IDS configuration ) . NIDS2 is tempted to block the whole class B and discusses this idea with NLEAD . They agree to request that change . 1 : 17 : 30 NIDS1 and NIDS2 converse over the NetMap . 1 : 18 : 45 NLEAD wants to know if they have a list of source IP . NIDS2 replies “right now , it’s just XX . XXX . XX . YYY” . He asks NLEAD if he wants to block the whole class B . 1 : 21 : 25 NIDS1 and NIDS2 discuss what they see on IDS screen . They see XX . XXX . XX . ZZZ ( “server IP” ) . NIDS1 : “we shouldn’t even be seeing that” . … Table 3 . 3 – Sample view of transcript of activity in the network room 41 Numerous writing conventions were devised and used throughout the transcription process in order to facilitate information retrieval ( e . g . , find data related to a specific role ) . References to participants were especially anonymized and code names representing their roles were used systematically ( e . g . , NIDS1 : member 1 of the Intrusion Detection System group in the Network room ) . Note that the time indicated corresponds to the relative position in the corresponding recording file ( this file is noted previously in the document ) . 3 . 3 . 4 . Focusing the transcription process : defining scope The data collection process produced dozen of hours of recordings . Many of these recordings were of poor audio and / or video quality and did not afford detailed descriptions . Focusing the transcription process consisted of identifying the moments and locations of activity that were necessary in order to analyze the dynamics at play during the event : time span , areas of higher interest , relationships with activity occurring in parallel in other areas . First , our initial analyses suggested that it was important to get enough detailed information throughout the day in order to understand how teams on both sides progressed . Although we had identified some episodes of interest in the hand notes while conducting observations , a richer understanding of the events throughout the day was needed to better indentify key events and understand teams’ activities . It was , therefore , judged inappropriate to focus on a limited number of episodes chosen a priori in the recordings . However , initial analyses also showed that actions that followed the ‘lights off’ events ( about 2 hours before the end of the exercise ) were less meaningful : 42 teams on both sides shared a sense of the Red team’s global success , and subsequently performed a variety of minor tasks ( minor for our purposes ) , essentially fishing for additional points . We , therefore , interrupted the transcription process at that time . Two specific areas appeared of higher interest and are the ones that the transcription process focused on : - the Red space , especially because actions on the Red side constituted the base line of the exercise , in the absence of an actual scenario , and - the Network room in the Blue space . The Network team appeared as the most pivotal team in our initial findings . It is also the room In which I conducted most of my direct observations during the exercise , giving me more familiarity with events and roles that proved quite useful during the transcription process . Importantly , both these spaces had been equipped with fixed cameras and turned out to be the ones benefitting from a relatively higher recording quality . The fixed cameras for these two rooms constituted the backbones for the transcription processes for the activities occurring in the Red and Blue spaces . Because it was important to describe cooperative activities and team dynamics ( e . g . , functional relationships with sub - teams ) within the Blue team , the transcription of activities in the Network room could not be seen in total isolation from activities occurring in other rooms . When possible , recordings captured in other rooms were partially transcribed to better describe events happening over multiple rooms . For instance , during a particular episode , a member of the Network room detected suspicious activity , discussed it with other members of the room , then walked to the System room in order to alert this other group and discuss the issue and its implications . In such a case , I would initially be transcribing the corresponding recording file in the 43 Network room , then follow the member by switching to the appropriate System room recording to transcribe the interaction episode there , and finally resume the transcription on the first Network room recording . In some instances , recording from the fixed camera did not allow for sufficient observability ( image and / or sound ) , therefore , for the transcription of activities . When they were available and when they provided better observability ( e . g . , through higher recording quality ) , targeted recordings from handheld audio / video devices were used to complement fixed camera recordings . One typical example of such a situation in the Network room was when interactions occurred in front of the network map , but discussions were covered by conversations going on closer to the fixed camera microphone . If I happened to be closer to the activity of interest and using a handheld device , the corresponding recording would be used to attempt to transcribe the interaction . The general use of the various recordings for the transcription process is summarized in Figure 3 . 7 . Note that such a strategy was made possible by the synchronization process described previously , and that the synchronization required sufficient precision to be useful . In addition to the graphic representation ( see Figure 3 . 6 ) , an Excel sheet was created that allowed the calculation of ( 1 ) the time of day from a given time position in a given recording file ; and ( 2 ) time positions in all potential recording files at a given time of day . Both means were very instrumental in implementing and facilitating this transcription strategy . 44 Figure 3 . 7 – Summary of transcription strategy 3 . 3 . 5 . Tracing Red and Blue processes The transcription process produced dozens of pages organized into two separated files for Red and Blue teams , detailing their activities in their respective spaces . This process produced separated perspectives for each team , constituting a limited account of a fundamentally adversarial event . The ambition was , therefore , to use this reference data to present Red and Blue activities in parallel and chronological order , in order to understand how they evolved across spaces as the exercise unfolded . More specifically , since Red actions constituted the baseline scenario for the exercise , such a representation aimed at highlighting Blue responses to Red’s actions on the network . Similarly , we wanted to understand how actions and responses on the Blue side impacted Red’s ability to conduct their strategy and potentially required that the attacking team adapt 45 their plans . In other words , the ambition of this new representation of the reference data was to construct a new perspective of the events to support the analysis . Such perspective does not exist in real events because no actor or observer is in a position to have access to both attacking and defense side simultaneously . The observables chosen ( see Table 3 . 2 ) allowed for the capture of the elements of interest on each side at a given time , particularly through verbal exchanges during which participants communicated about elements of concern or about actions they were implementing . In other words , the transcription process allowed us to trace teams’ focus of attention in the context of on - going events . This constituted the methodology of implementation of a process - tracing approach ( Woods , 1993 ; Branlat , 2009 ) that aimed at situating cognition and analyzing teams’ decisions and actions in context . The other key dimensions of the process - tracing approach ( “goal” and ”knowledge” ) were not described explicitly because they were not systematically captured by the observables used for the transcription . Participants would sometimes communicate about their actions in terms of goals , but such occurrences were not common throughout the exercise . These dimensions are , therefore , a product of the analytical process and need to be constructed from a more advanced interpretation of the data . The outcome of this process is a large table capturing Red and Blue parallel activities in terms of their focus of attention . Here , also , technical elements of information were sanitized and made generic in order not to disclose too many details about the framework of the exercise . 46 ATTENTIONAL FOCUS RED BLUE / NETWORK TEAM TIME Role ( s ) Focus Actions / Comments Role ( s ) Focus Actions / Comments … 8 : 17 : 59 – RED02 ~ 0 : 56 : 20 RM3 , RLEAD Border network server ( AA . BB . CC ) Confusion , discuss IP . XX vs . YY . RLEAD wants people to search for exploits and target this box . 8 : 18 : 10 – NETW01 ~ 1 : 15 : 45 NLEAD , NIDS2 Machine IP1 , SSH ( IP1 on network N1 , IP2 on network N2 ) NLEAD wonders if IP1 is target of port scans . NIDS2 confirms , adds IP2 was scanned earlier . 8 : 18 : 50 – NETW01 ~ 1 : 16 : 25 NET team IP3 , XX . XXX . XX network Discuss need to block box , or even full XX . XXX . XX range . 8 : 23 : 50 – NETW01 ~ 1 : 21 : 25 NIDS1 , NIDS2 SOURCE : XX . XXX . XX . Z Members see in IDS XX . XXX . XX . Z ( “server IP” ) and seem confused about what that might be . 8 : 25 : 10 – NETW01 ~ 1 : 22 : 45 NIDS2 SOURCE : XX . XXX . XX network Sees activity from XX . XXX . XX . 8 : 25 : 25 – NETW01 ~ 1 : 23 : 00 NIDS2 , NIDS3 Mail server , AA . BB . CC network Detect activity toward / from AA . BB . CC ( mail server ) . 8 : 26 : 10 – NETW01 ~ 1 : 23 : 45 NIDS1 SOURCE : XX . XXX . XX . Y DEST : FTP server Suspicious activity from XX . XXX . XX . Y to FTP server . 8 : 27 : 31 – RED02 ~ 1 : 05 : 52 RM6 Border network server , AA . BB . CC . ZZ Finds machine , finds out DNS port ( 53 ) is open … Table 3 . 4 – Sample view of table representing Red and Blue teams’ focus of attention 3 . 3 . 6 . More representation problems Although the large table described above provided a parallel view of activities on both sides and some insight into action - response type of dynamics that were at the heart of the analyses , it was quickly recognized that , as a representation of events , it suffered 47 from important limitations . This representation essentially uses time as the main frame of reference to describe the sequence of elements of activity . Although time is definitely a critical dimension of analysis , important characteristics of events observed are hidden ( therefore , unavailable for analysis ) by the purely chronological representation . The general activity was indeed highly distributed in space ( e . g . , separation of Red and Blue teams ) and across sub - teams and roles . This implies that it is fundamentally a non - linear process . In particular , elements of activity might be related ( such as in a sequence of actions conducted by a specific role or on a specific machine ) or unrelated ( such as parallel actions going on in different locations about different issues ) . Additionally , related actions might occur over large time frames , for instance , when issues related to a machine focus participants’ attention for half of the afternoon . Interestingly , capturing the relationships between elements of activity corresponds to more advanced analyses that allow us to get better insight into other dimensions of the process - tracing approach than solely teams’ focus of attention ( especially relative to the knowledge dimension of the approach ) . It , therefore , appeared useful to represent teams’ activities in a graphical form that better afforded the representation of parallel and sequential activities . This led to the design of a set of visualizations that are presented and described in the following section and that constitute the most advanced analytical representations of the data in this study . These new representations were built through two intermediary textual representations that ( 1 ) slightly focused the long table representation described in the previous section by selecting only action - related elements ; ( 2 ) used an outliner type of representation to describe related elements through points and sub - points and cross references . 48 Chapter 4 . Findings This chapter will describe the findings based on the data captured and analyzed following the methods presented previously . It will start by giving an overview of what happened during the exercise and of the representations designed to give an account of the teams’ activities . The two subsequent sections will provide details on each team’s actions and decisions in order to describe the corresponding nature and challenges of their activities . A last section will describe how the network was the environment of their interplay , and what it suggests about essential dimensions of the domain of cyber security . 4 . 1 . Overview 4 . 1 . 1 . General network architecture The general organization , represented in Figure 4 . 1 below , is that of a network that supports and organizes various assets and services in the context of industrial production ( a process ) . Some of these resources are directly related to the process , such as sensors and controllers , control interfaces and data storage ( process control network ) . Other resources exist in support of the organization itself and include administrative data and processes or other management assets and services . In order to accomplish their missions , especially to connect with clients and partners or benefit from outside 49 services , the general network is connected to the Internet and protected by various means such as firewalls . In the context of the exercise , as in many real situations , this necessary openness to the outside is what attackers ( represented by the red network on the left ) try to take advantage of to get initial access to the network and progress towards their mission targets ( in our case , process - sensitive networks and assets ) . The network defense team ( blue computers in the figure ) operates within the network to hinder attackers’ efforts and protect the process . Figure 4 . 1 – General network architecture The network configuration implements a “nested network” architecture in which more external networks ( closer to the internet ) represent layers that communications need to be carried through in order to reach more internal networks ( closer to the process ) . 50 Figure 4 . 2 – Nested network philosophy DMZ ( demilitarized zone ) networks are used for public services such as web or FTP . Such configuration allows for exchanges with the outside to be as limited as possible to the DMZ , thereby protecting the corresponding networks from direct exposure to external connections . 4 . 1 . 2 . Red team’s main goals and tasks The general goal of the Red team was to defame , perform reconnaissance , invade , and eventually break or destroy the physical process of the Blue team . Any activities were fair game ( e . g . , hacking , destroying machines , physically invading the Blue team area ) ; ingenuity and potential for damage were encouraged . Despite the method of access , the essential goal of the Red team was to connect the red team network to the blue team network with sufficient permission ( e . g . , root access ) with the end result being the ability to modify the internal network , processes , and external connections . The Red team conducted two main tasks : - Gaining access to the Blue network , through trial and error processes of identifying machines and services and matching available exploits ( small scripts that take advantage of know vulnerabilities for those particular components ) . From the Red team perspective , any machine and any service ( e . g . , ssh ) is a potential point of access given the large availability of exploits . 51 - Taking advantage of access , either to act on the network ( reconnaissance and reconfiguration ) to get further access ( e . g . , connect to high - value machines or sub - networks ) , or to conduct malicious actions on corrupted machines ( e . g . , steal data , or interfere with the process as illustrated in the initial vignette ) . Attempts to gain access were distributed between team members depending on their area of expertise ( e . g . , database or system administration ) . 4 . 1 . 3 . Blue team’s main goals and tasks The Blue team as a whole pursued two interrelated goals during the exercise : maintaining production while preventing hackers from gaining access and from acting on their network ( e . g . , stealing or corrupting data , interfering with process production ) . First , despite the potential disruptions , the team needed to maintain the process that supported the organization’s production and service activities . Second , the Blue team needed to provide security on their local network . This involved preventing illegitimate activity by removing potential vulnerabilities and stopping illegitimate access when discovered . Prior to the exercise , the Blue team self - organized into a work structure composed of several groups and a management hierarchy . Because of the focus of our analyses ( see previous section ) , this section will largely concentrate on results from the Network group ( 8 people ) , while highlighting relationships with other groups constituting the Blue team . The Network group pursued two primary goals : - Identifying and managing network vulnerabilities , including network points of access ( open ports and firewall rules ) and network paths ( connections between sub - networks or machines ) . These vulnerabilities were primarily managed by 52 attempting to modify ‘weak’ firewall rules in order to ‘tighten’ internal and external access . - Detecting intrusions , monitoring network activity through the analysis of traces generated by network exchanges , in order to identify illegitimate or abnormal access . Traces represent an immense amount of protocol - level activity , and the vast majority of these correspond to normal and legitimate traffic generated by the numerous services running and accessed on the network . Two interrelated tasks supported these goals : - Developing knowledge of the network , whether through actively probing the network or passively monitoring its traffic to discover its extent , components and characteristics . The two previous goals necessitate substantial knowledge of the network , especially of typical network activity , a general result amply described in the literature ( e . g . , Goodall et al . , 2004 ) . - Investigating suspicious activity , analyzing in greater depth traces of potentially illicit activity or activity from unexpected sources ( as illustrated in the introductory vignette ) . Incomplete knowledge constituted a considerable source of uncertainty for such investigations , e . g . , when unknown but legitimate activity was initially considered suspicious , investigated , and ultimately explained . Explaining activity required frequent collaboration within Blue team , often to disambiguate sources of activity . 53 4 . 1 . 4 . Description of the events Prior information As mentioned previously , the Blue team had been given some documentation about the network and process two days prior to the exercise . One such item was a network map representing the network topology and providing various elements of information about the network configuration and assets : servers’ names and IP addresses , firewall rules , etc . Conscious about the criticality of this representation as a source of information , INL instructors had carefully indicated and emphasized that the map was “accurate” ( suggesting the information provided was correct , but incomplete ) . Initial operations The Blue team started operating about 07 : 00 . Their first tasks consisted of producing and submitting ”request for change” forms in order to address vulnerabilities ( e . g . , related to network configuration ) identified during the preparation for the exercise . To supplement this process , groups in the various rooms conducted additional intelligence actions and vulnerability assessment : scanning sub - networks to discover additional assets , checking the configuration of firewalls , checking servers’ versions and associated vulnerabilities , etc . The general team’s strategy was , therefore , to quickly provide higher security by ‘tightening’ sub - networks’ and servers’ configurations , limiting access to the network as much as possible . Additionally , members of the Intrusion Detection group configured their systems to start monitoring the network , and members of the Process sub - team conducted operations to allow for the beginning of production . The Red team started about 30 min later ( by design of the exercise ) . During preparation days , one member had managed to steal a documentation packet given to the Blue team 54 ( which was fair game for the context of the exercise ) . The Red team , therefore , started with a significant knowledge of the network they were to intrude in , of potential targets and of vulnerabilities they could exploit . INL instructors provided the first ‘trophies’ , tactical objectives that required that the Red team succeed in : - gathering information about the company and its internet facing services , - identifying potential entry points , and - initiating access and establishing presence . Morning The Red team experienced several significant successes . Notable ones are : - The first access to a server ( anonymous FTP connection ) occurred about an hour after the beginning of the exercise . - About the same time , a member managed to perform an ‘SQL inject’ on a web server . He took advantage of a specific vulnerability in the design of a help form to interact with the web application and the corresponding database . This access was instrumental in two major ways : o it gave the Red team access to sensitive data stored in the database , ultimately allowing them to retrieve usernames and encrypted passwords , and o a member uploaded a script to the web server that allowed for more advanced access on the machine and for the consolidation of this access ( the connection was lost at lunch time ) . During the morning , the Blue team divided their efforts between : - pursuing efforts to do reconnaissance on the network and reduce vulnerabilities identified , and 55 - identifying , investigating and responding to suspicious activity , especially related to connections on the web server . The Blue team experienced little to no success in implementing the actions they thought were necessary to address vulnerabilities : repeatedly , facility owners ( White Cell ) do not allow them to make modifications on the basis that the modifications are not correctly justified and threaten production goals . Early afternoon Access established in the morning allowed the Red team to reach two servers that , by configuration of the network , had more direct access to the Process network and assets . Various members were able to connect to these servers and establish their presence , e . g . , by creating new users . Red team members essentially tunneled connections , hopping from machines they had access to , and gaining access to more sensitive assets such as a data server ( creating some damage to potentially sensitive data ) and an operator’s workstation . Blue team’s activity is globally more focused on incident response . The team is able to detect intrusions and attack activities , but is still not given the possibility to respond by the measures they would like to implement . The team shares a sense of loss of control and of frustration due to lack of authority . They start implementing adversarial measures to impair the Red team’s progress . Late afternoon After the afternoon break , the Red team resumed their activities and a member was ultimately able to get access to an operator’s graphic interface presenting electric circuit 56 breaks . After consulting with his team , he switched two of the breaks , which resulted in electricity ( especially lights ) being turned off in parts of the Blue space . Late afternoon , the Blue team is aware of Red’s presence in all areas of the network , including production - sensitive ones . They have little doubt of Red’s success in the exercise , and the moment when lights are switched off comes as a vivid but not entirely surprising manifestation of the overall failure to defend the network . 4 . 1 . 5 . Representing teams’ activities The previous chapter concluded with the short description of a graphical representation designed to represent the non - linear nature of the activity both teams engaged in . This section will provide greater details of the representation . We will then analyze the activity of both teams in detail in the next sections through the use of this design ( see Figure 4 . 3 , Figure 4 . 6 and Figure 4 . 11 ) . Purpose The representation ultimately aims at describing what teams on both sides did to pursue their goals and to respond to what they were encountering . Since the network constitutes the shared environment for the decisions and actions of both teams , the analysis focuses on how elements of network activity ( e . g . , traffic ) were produced and interpreted on both sides . These elements are symptoms of activities conducted on each side , but are not observable directly in their virtual environment . They serve as proxies to the participants in the exercise as well as to us , outside observers . Because of the nature of cyber security and of the difference in goals between attack and defense , the focus of analysis is particularly on the production of network activity on the Red team’s 57 side , while it is more on the interpretation of network activity on the Blue side . In a sense , this corresponds to a network - centric representation of activity seen from an attack or a defense perspective . Frames of reference The representation has two dimensions : ( 1 ) time , and ( 2 ) location on the network relative to the process . This second dimension is a result of the nested network architecture discussed in the section above . It also corresponds to the fact that , by design of the exercise ( points attribution ) , the ultimate center of attention for both teams is the process : the Blue team wants to protect it , while the Red team wants to disturb it . The closer the Red team gets to the process , the closer they are to an overall success , which suggests a sense of network depth . The various trophies handed by INL supervisors to frame the attacking strategy and structure the Red team’s activity essentially convey the same sense of gradual access from the outside in ( where the most “in” levels correspond to the process - related networks and assets ) . The other frames of reference are related to the nature of the elements of activity represented : ( 3 ) type of action ( this will especially vary between representations of Blue or Red teams’ activities ) , ( 4 ) source and destination of the actions that occur between two hosts , and ( 5 ) relationship between elements of activity , particularly their sequential nature ( e . g . , action A is followed by action B ) . 58 The last frame of reference allows for the non - linear representation of parallel units of activity . These constitute coherent events that will be called episodes in the following parts of the document . In the majority of cases , these episodes are a sequence of elements of activity related to a particular machine on the network ( e . g . , different connection attempts ) . In other cases , they correspond to a sequence of actions conducted by a particular role ( e . g . , the same action attempted on different machines ) . Dependence on observations An important characteristic of the representation proposed is that it is constructed from the elements gathered during observations ( essentially through the analysis of communications ) . In other words , it does not exhaustively depict what teams did , as it is highly dependent on what members and supervisors of the exercise verbalized . Note that an interesting consequence of the participants’ general lack of domain expertise is that they probably verbalized significantly more than experts would have in similar situations : asking for information or confirmation , pointing out unclear phenomena , discussing strategy and tactics explicitly , etc . Also , gaps were not rare between the time an action was conducted and the time it was verbalized . Members would , for instance , announce their intention to conduct some action , which might , therefore , be actually implemented minutes later . Or , they would announce something that happened earlier without being more specific , communications simply indicative of past actions or events . Gaps in time and other ambiguous indications of time required interpretations and judgment calls in the construction of the representations . Usually , in the absence of evidence , events were simply associated with the time they were verbalized , indicating their past or future nature in the events’ descriptions . 59 4 . 2 . Cyber attack This section will describe in greater detail what occurred during the exercise from the perspective of the Red team . Inferences will be made from the description of the nature of cyber attack and about core challenges teams of attackers face . 4 . 2 . 1 . Red team’s activity during the exercise The following figure presents actions conducted by the Red team on the network , which are of three main types : - Intelligence actions ( e . g . , scanning a network or searching for open ports on a machine to discover potential vulnerabilities and targets ) , - Access to machines ( connections and other vulnerability exploits ) , and - Changes made to assets of the network ( changes in network or system configuration or changes in data ) . Such actions correspond to the detectable part of the activity of the Red team , i . e . , the part of their activity that the Blue team could intercept , identify and analyze . The intelligence actions visible in the figure represent only a part of all the intelligence conducted by the Red team ; they correspond to the instances that were captured through communications . It seems that members didn’t necessarily communicate about what intelligence they were conducting , unless for particular reasons ( e . g . , being asked or being successful ) . For instance , access - related actions ( successful or not ) seem to have triggered more systematic verbalizations . The examples of intelligence actions represented here , nonetheless , illustrate the general process underlying the Red team’s behavior . 60 Two elements of activity are represented in addition to the types of action on the network : - Sources for the actions ( their location relative to the process - sensitive networks and assets ) , and - Losses of connections . Here again , differences exist in how systematically these elements were verbalized and , therefore , captured in the data . While events such as losses of access were often communicated , participants seldom indicated their full path to the machines they had gained access to . Besides the few occurrences where they did provide such information , sources were mostly inferred from the context and the tracking of previous actions . Sources were not represented when data were too ambiguous or , in several instances , when their representation would have overloaded the figure without providing much more insight into the course of events ( e . g . , in episode R4 , the SQL inject is an operation conducted through a web form from the outside ) . Other potentially important aspects of their activity , such as collaborative phases within the team , do not correspond to the particular purpose and focus of this representation , but will be discussed in relation to particular episodes visible on the figure . Also , in order to give more details about the activity on the attacking side and facilitate the understanding of what happened during the exercise , a short comment was given for each element represented . 61 Figure 4 . 3 – Graphical representation of Red team’s activity on the network 62 4 . 2 . 2 . Dynamics of cyber attack Basic pattern of attack The recurring pattern of attack illustrated by the episodes represented in Figure 4 . 3 is the following : ( 1 ) through some intelligence phase , the team discovers a vulnerability on the network , ( 2 ) members attempt to exploit it , ( 3 ) one member gets access , ( 4 ) access can be used to : a . conduct further intelligence , b . get further access , and c . compromise host to do damage ( e . g . , data ) or secure presence ( e . g . , modify system’s settings ) . ( 5 ) eventually , access is lost , often unintentionally ( e . g . , a bad operation kills the connection ) or as a result of Blue team’s actions ( e . g . , the host is rebooted ) . Point ( 4 ) of the pattern is where the most variation occurs : members are not always able to implement the 3 types of actions afforded by access to a machine . Episode R4 is an example where all these types of actions are implemented ; Episode R18 is an example where access to a data server was only used to make modifications to sensitive corporate data . This pattern shows two important characteristics of cyber attack dynamics : - A sequential nature of activity that is expressed in two different ways : 63 o ordered : actions depend on the execution of others ( e . g . , getting access requires that some intelligence was conducted and attempts were made ) , o path dependent : potential actions and access depend on what the current location affords due to the configuration of the networks and their assets ( e . g . , access to machine A will afford different actions and further access than access to machine B ) . - A recursive nature of processes underlying progression in the network : intelligence affords access , which in turn allows for more intelligence , compromising actions and eventually more access . A sense of progress ( and success ) The Red team’s success can be seen generally as their capacity during the exercise to establish a path between their network and process - sensitive assets . They do so by identifying vulnerabilities and implementing steps toward their goal . Figure 4 . 4 – Red team : establishing a path towards a goal 64 Besides giving some insight into the turn of events in the particular exercise observed and more generally into patterns of cyber attack , the representation of Red’s activity ( see Figure 4 . 3 ) offers a visual sense of the Red team’s overall progress , and ultimately success , during the exercise . The figure shows a general shift from areas of the network corresponding to its more external layers to areas more directly related to the process . This shift simultaneously concerns the general focus of attention as well as the more specific location of machines accessed and sources of actions ( note how the A and S symbols shift downward from morning to afternoon on the figure ) . Progress in cyber attack can therefore be seen as corresponding to 4 highly intertwined dimensions : ( 1 ) improved knowledge , which includes better identification and operational definition of valuable targets of attack , valuable in terms of further access ( 2 ) and / or capacity to do damage ( 3 ) , ( 2 ) improved access , especially through better identifying vulnerabilities ( 1 ) , ( 3 ) improved compromising actions to the network and its assets , which depends on the capacity to gain access with sufficient user credentials , and ( 4 ) improved presence on the target network ( suggested by the source of actions becoming more internal to the network as the exercise unfolded ) ; improved presence also benefited the team as a whole , as it allowed more than one member to use the paths established . Collaboration within the team We have chosen to represent the activity of the team as a whole , without giving details about the participation of each role . However , operations generally occurred as successions of more or less collaborative phases , triggered by various events : 65 - Most of the time , individual roles or small teams ( a few members ) were operating in parallel on various tasks . Operations were distributed between team members depending on their interests and areas of expertise ( e . g . , database or system administration ) . - When one of these smaller units accomplished a significant success ( e . g . , gained access to a machine or retrieved user credentials ) , a sudden expansion to a larger group ( or even to the whole Red team ) occurred . The success would be discussed in terms of its strategic or tactical significance and ultimately led to some collective decision about what to do next . This decision might imply adapting tasks and roles to seize the new opportunities provided by the success . - Advances managed by small units ended up benefiting the whole team . Secured presence established to server S1 ( episodes R4 , R11 ) late morning or to servers BS1 and BS2 ( episodes R15 and R16 ) is a prime example of such progress . It created opportunities for several members to connect to these servers in the afternoon and conduct various operations ( i . e . , the team progresses as a whole ) . - Similarly to successes , negative events such as lost connections would usually be communicated ( speaking out loud to the whole team ) and often discussed . Particularly when they affected multiple members and seemed to correspond to actions conducted by the Blue team , they also triggered collective decisions on what to do with the remaining access ( e . g . , creating pressure to ”do something” while it was still possible , as in episodes R22 and R24 ) . Besides verbal communications , the team took advantage of different means in order to share information . They especially used a large screen on which current knowledge of the network could be displayed through the progressive construction of a network map 66 with annotations and a wiki page used both as a repository of information retrieved and to document the team’s progress . 4 . 2 . 3 . Challenges to cyber attack Fumbling about in the dark If Figure 4 . 3 and Figure 4 . 4 give a sense of progress through the network , they risk giving a false sense of incremental advances towards a well - defined goal and through a pre - identified general path . In spite of the fact that the Red team was able to acquire a network map , which gave them considerable knowledge of potential vulnerabilities and targets , their general process is more akin to a laborious exploration in the dark , as illustrated by Figure 4 . 5 below . Figure 4 . 5 – Red team : fumbling about in the dark 67 The discovery of an asset or sub - network only allows for the exploration of a limited , local virtual space , giving a partial perspective on the whole network . The general situation is one of a gradual discovery of vulnerabilities , network configuration and potential targets , i . e . , of the implementation of sequences of steps that might contribute to a path towards goal - related assets . This corresponds to a type of behavior that is opportunistic and based on trial - and - error , not entirely planful . This pattern of behavior in the Red team relates to the difficulty of maintaining strategic planning while focusing on tactical or technical challenges . In particular , gaining access was often difficult and required considerable technical skill and focus . More strategic goals subsequently became secondary . Potential for detection and urge to act The adversarial environment was the source of trade - offs between efficiency and exposure to detection while choosing courses of actions . Since the Red team was well aware of the Blue team’s work monitoring the network , secondary goals included avoiding detection . An important characteristic of cyber attack is that it occurs in an environment that is constantly being monitored for the type of activity attacks entail ( by design , in the context of the exercise ) . Different types of activity generate different types of traces that are more or less easy to detect . Time appeared to be a critical dimension here : time - intensive sets of actions seem more vulnerable to detection . When the Red team thought it was detected , for instance , when a machine they had access to was rebooted , the team felt the pressure to ”do something” while it was still possible ( episodes R22 and R24 ) . This type of pressure created further threats to their strategic goals as compromising actions are typically more detectable and risk revealing their presence . Progressing in the network through various actions , therefore , implies 68 the risk of being detected and denied opportunities to conduct the attacking plan . On the other hand , because of the nature of networks and network assets , and because of the need for networks to be partially opened in order to provide valuable services , there are always opportunities for attackers to get in somewhere ( this point will be discussed in later sections as a fundamental aspect of digital infrastructures for which providing security requires an appropriate mindframe ) . Challenges to collaboration In spite of the Red team’s general success , a few events were representative of difficulties to fully coordinate efforts : - During episode R15 , some members started conducting vulnerability scans from the machine they had gained access to ( especially because this server had access to the process network ) . At some point , other members initiated a discussion about the benefit of conducting such actions and about the risk of being detected and loosing valuable access on this server . They were surprised ( and upset ) to learn that scans had already been partially conducted , indicating both a lack of general knowledge of what others were doing and important differences between strategies . - At the end of episode R22 , a member operating on a server produced various damages to services that seemed related to the process , in part because of a general pressure to act in the face of detection fears . The exact nature of these services is not clear , but the member’s actions did not really impair the process . Another member was later in a position to impair the process , but it seems ( from the assessment of one of the INL supervisors ) that the damaged services were instrumental in spoiling this opportunity . 69 Such dynamics are similar in nature to the basic “working at cross - purposes” pattern described by Woods and Branlat ( 2011 ) based on studies conducted in other domains . They also correspond to coordination breakdowns occurring as a result of adaptations ( here to opportunities in the environment rather than to disturbances ) made in the context of time pressure . Summary : challenges of cyber attack Challenge Source Tactical vs . Strategic trade - off Tendency to focus on access and exploit from technical / tactical perspective Efficiency vs . Detectability trade - off Actions on the network are more or less efficient and visible Working at cross - purposes Actions by different members conflict , hindering their respective efforts Table 4 . 1 – Critical challenges in attack activities 4 . 3 . Cyber defense This section presents the perspective of the Blue team by describing in detail their actions during the exercise . Inferences will be made from that description about the nature of cyber defense and about core challenges to it . 4 . 3 . 1 . Blue team’s activity during the exercise The same design principles and frames of reference were used to build a graphical representation of the actions on the defensive side . As mentioned in section 4 . 1 . 5 , the focus of analysis for network defense is more on the interpretative side , as opposed to the 70 more active progress pursued by attackers . The figure , therefore , presents actions conducted by the Blue team as a result of network activity they detected . However , to conduct their various response and intelligence tasks , the Blue team was also a source of activity on the network ( which suggests that Blue’s activity is not purely interpretative ) . Various types of defensive actions , therefore , needed to be represented , in particular to highlight their intertwined nature . Actions are of three main types : ( 1 ) Detections of suspicious network activity : a . traffic ( e . g . , a machine sending data to an outside host ) , b . vulnerability scanning ( e . g . , network scanning ) , and c . compromising actions ( e . g . , connections or changes to network ) . ( 2 ) Further investigation of such activity ( e . g . , through collaborative phases ) ( 3 ) Actions on the network : a . reconnaissance actions ( e . g . , network scanning ) , and b . perturbation of Red progress . Importantly , note that responses such as changes to network configurations were not represented . The main reason is that very few were implemented in the context of the exercise that emphasized the role of asset owners as ultimate decision makers in the actual realization of any changes on the network . These processes will nonetheless be discussed in further sections . Here again , differences exist in how systematically these elements were verbalized and , therefore , captured in the data . Also , collaborative aspects of their activity were not represented , but they will be discussed in relation to particular episodes visible on the figure . 71 Figure 4 . 6 – Graphical representation of Blue team’s defense activity 72 4 . 3 . 2 . Defending a network : core processes A case of distributed anomaly response In its general mission to protect production through defending the network , the activity of the Blue team can be seen as a typical example of anomaly response conducted by a joint cognitive system 2 . The team monitors a process ( network activity ) that is characterized by a large number of micro - events that are not directly observable . Defense relies on technology that provides sensing capabilities covering the whole network , and data analysis capabilities generating alarms about suspicious activity . These alarms trigger cognitive processes of anomaly response ( Woods and Hollnagel , 2006 , Chapter 8 ; Christoffersen , Woods and Blike , 2007 ; Klein , Pliske , Crandall and Woods , 2005 ) : - The first issue is whether an alarm corresponds to an actual anomaly in the process or to a phenomenon that requires other explanations ( e . g . , sensor failure or particular process phase ) . - If it is indeed an anomaly , actions aim at making sense of it : what it means relative to process , and to the larger mission . - Finally , the issue is about how to respond appropriately given the understanding of the anomaly and its impact , and of the effect of the response action itself . Although described in a linear way , these processes are part of a cognitive cycle of anomaly response ( Woods and Hollnagel , 2006 , Chap . 8 ) . 2 see the definition of JCS in Woods and Hollnagel , 2006 73 The generic pattern observed in the Blue team’s activity mirrors the description of anomaly response as outlined above : - Suspicious events ( potential ‘intrusions’ ) were detected through traces of activity or alarms generated by the Intrusion Detection System . - This detection triggered investigations aimed at validating whether these events related to cyber attacks . - Investigations led to either the realization of the validity of the traffic , or decisions regarding an appropriate response . The introductory vignette ( see Table 1 . 1 ) illustrates the first two points and how processes of anomaly detection and investigation are impaired by high uncertainty . Knowledge building and proactive management of vulnerabilities Building knowledge of the network is an essential means by which network defenders reduce the uncertainty concerning activity observed on the network . Authors have described how processes of network defense require ample knowledge of the network , i . e . , of its configuration and its assets ( Goodall et al . , 2004 ) . As described for anomaly response ( Christoffersen et al . , 2007 ) , roles in charge of monitoring the process ( here , network activity ) need to have an understanding of what normal and typical behavior is in the particular operational context . Such knowledge of baseline activity allows for the identification of anomalies ( suspicious activity on the network ) , first defined essentially by contrast to the baseline . Fine knowledge of the network and its assets ( e . g . , characteristics of services running on a server ) is also required in phases of investigation and response , as will be described in the following section . In addition , the Blue team’s general strategy relied on efforts to reduce vulnerabilities on the network ( e . g . , overly permissive network access rules or outdated versions of 74 applications and services for which exploits are more easily found ) . Such efforts were triggered by attacks identified or , especially initially , by the active search for vulnerabilities in networks or particular machines . Both aspects of network knowledge led the Blue team to conduct a variety of intelligence or reconnaissance actions on the network throughout the exercise ( e . g . , episode B3 in Figure 4 . 6 ) and required that they be able to capture and share the knowledge acquired . The existence of this second stream of activity and the highly intertwined nature of both processes of anomaly response and knowledge building were characteristic of the activity on the defense side . The resulting dynamics and challenges of cyber defense will be discussed in subsequent sections . Highly distributed activity and collaboration needs In settings such as the one simulated in the exercise , the large scale of the network demands that network defense be managed as a team of sufficient size , thereby distributing operations across roles fulfilling various tasks and holding various perspectives on the network . In addition to dividing up the operations between sub - teams , members in charge of different functions constituted specific resources for other members . As an example , the System sub - team requested that a member of the Network Reconnaissance group scan some machines after they were patched to make sure vulnerabilities had been addressed . Similarly , the Intrusion Detection group was tasked with monitoring specific machines or networks when members from other teams observed suspicious traffic and wanted to validate its legitimacy . While they increase the capability of the team as a whole by providing different forms of competence and reducing the scope of responsibility for each role , distributed operations require that actors coordinate their efforts to reach higher - level mission goals 75 ( Klein , Feltovich , Bradshaw and Woods , 2005 ; Branlat et al . , 2009 ) . This means that members of the Blue team needed , during the exercise , to have sufficient understanding of each others’ roles and the functional interdependencies between them , as well as the resulting coordination needs particular events would generate . The example below is extracted from the data and illustrates these points . 08 : 06 : 40 SYS1 comes back to network room , and asks who’s in charge of Intrusion Detection Systems . NIDS1 answers “we are” , SYS1 goes to IDS group . SYS1 : “these 3 servers right here , they’re not in this facility , and we don’t yet have administrative access to them . They’re all running vulnerable versions of SSH . I’ve asked [ NRECON1 ] to give me a complete scan on them , but , I mean , you need to watch traffic for those , because they’re open all the way to the outside . ” NIDS1 : “which ones are you talking about ? ” SYS1 : “ [ BS1 ] , [ BS2 ] and [ S3 ] . They’re all running an old version of SSH . ” After his departure , NIDS1 and NIDS2 review the info , and seem to be configuring the corresponding rules in the IDS , based on servers IP addresses . Coordination also required means to support processes such as information exchanges and collaborative problem solving , as illustrated by the following example . 08 : 36 : 05 NIDS1 “they’ve got a shell on [ S1 ] . ” [ FTP server ] “We probably need to designate a runner to go between the groups , then . ” As suggested by both these examples , coordination processes were primarily supported by verbal communication , facilitated by the physical co - location or proximity of team members . Poster - size network maps displayed in various locations also played a critical role in supporting coordination throughout the exercise ( support of coodination will be discussed in details in section 4 . 3 . 4 ) . Other artifacts were available ( e . g . , whiteboards – which were scarcely used ) or were created ( e . g . , task list in the Systems room ) , but were overall less critical during the operations . 76 4 . 3 . 3 . Dynamics of cyber defense Central question : is the activity observed legitimate or illegitimate ? Faced with large amounts of activity traces on the network , the defensive team needs to distinguish between valid traffic and traffic indicative of attack processes . In cyber defense , anomalies correspond to undesirable activity on the network . The operational definition of undesirability depends on the context : it could correspond , for instance , to data exchanges with the outside , to vulnerability scans on servers , or to data exchanges with a sensitive database . Characteristics of network traffic ( type , source , target , or other aspects such as volume of exchange ) define what might be considered suspicious activity . Upon detection , events were communicated to others ( one or more team members ) by announcing some or all of their main characteristics : type of events ( represented by symbols T , I , A , A and C in Figure 4 . 6 ) , target ( represented by the vertical location of these symbols in the representation ) and source ( symbol S ) . This announcement often served as a first step investigation , as it prompted first discussions about the event , e . g . , a confirmation of the relevance of the traces ( if they were observed by others ) . Investigations ( symbol X ) followed that often took the form of discussions attempting to determine the validity of the traffic observed . A particular group within the Network sub - team was specifically in charge of detecting intrusions on the network . Their activity was supported by the use of Intrusion Detection Systems producing various alerts based on the analysis of network traffic . However , depending on the nature of suspicious events , they were sometimes initially detected by other sub - teams as well . For instance , members of the Systems sub - team detected access gained to and processes running on servers ( e . g . , episodes B23 and B38 ) . 77 The primary characteristic used for determining the legitimacy of network activity was its source , indicated by its IP address . However , in the context of large industrial networks , sources of activity are potentially numerous ( see Figure 4 . 7 ) . Figure 4 . 7 – Potential sources of activity on the network This required that the Blue team be able to distinguish between valid and unwanted sources . Until proven otherwise , traffic originating from unknown sources , especially from outside the network , was considered resulting from the Red team’s activity ( e . g . , episodes B1 and B2 in Figure 4 . 6 ) . The short exchange below ( extracted from the data ) occurred during the early part of the exercise between two members of the Network team , Intrusion Detection group . NIDS3 wonders whether to report some traffic he sees . NIDS1 mentions some of that traffic may not always be the Red team since INL people run scripts to simulate regular traffic . 78 This exchange shows how unknown activity is generally considered illegitimate . In this case , though , one participant reminded his teammate that the exercise was designed to simulate various sources of traffic that defense teams would encounter in real settings . Investigation means More elaborate investigations considered the relationships between the characteristics of traffic observed , i . e . , the type of activity in relation to its source and / or target . When unknown , understanding such relationships involved seeking out information about the source and target machines , in particular about services these machines provide . These investigations aim at addressing whether the activity is to be expected in the context of the network and its assets . The following example ( part of episode B21 in Figure 4 . 6 ) is illustrates such investigation occurring into the form of verbal exchange . 10 : 41 : 46 NIDS1 “ [ BOX1 ] looks like it’s been tipped” NRECON4 asks what he means . He explains ( inaudible ) , they discuss it . He looks at NetMap , and says : “oh , that’s valid traffic , then…” NIDS2 : “that’s SQL , they said they’re patching… ? ” NIDS1 : “yeah , it’s valid…” [ He was alerted that traffic went from this box to DS3 . ] … 10 : 45 : 26 SYS2 arrives in NET room . NIDS1 was discussing with NRECON4 the ‘suspicious / valid’ traffic . He asks SYS2 if they’re patching [ BOX1 ] , because he sees traffic from it to [ DS3 ] . She’s not sure ; she goes back to SYS room to find out . 10 : 45 : 46 NIDS1 and NIDS2 look at the various ports for the traffic NIDS2 is seeing . NIDS1 explains that’s what NRECON4 is trying to find out ( ports 139 and 445 ) . He recognizes port 1443 , Microsoft SQL = > “you would expect” . He’s not sure why the other ports are used . Several aspects of this exchange are worth noting about processes conducted in order to determine legitimacy of traffic : 79 - They require knowledge of the network configuration and assets , but also specific knowledge of services ( e . g . , ports typically used by some applications ) . - They are collaborative , within and across teams ( members of two groups of the Network team , member of the Systems team ) . - They require knowledge and understanding of actions conducted by other teams : here , patching one machine ( to reduce vulnerability ) generates temporary unusual ( i . e . , suspicious ) traffic while services are restarted . We will discuss these different points further in following sections . In some cases , especially when discussions were not conclusive , the Blue team attempted to investigate further by using diagnostic actions . The following exchange corresponds to a portion of episode B16 . 09 : 48 : 41 SYS6 and SYS1 come to NLEAD with NIDS3 . NLEAD explains “there’s a linux device on the network” ( [ BOX245 ] ) . SYS6 and SYS1 wonder what network it is , and go to NetMap . NLEAD joins them . SYS1 wonders if it’s a backtrack CD . NIDS1 replies it’s not . SYS1 proposes to SSH it or telnet it [ diagnostic action ] . … 10 : 21 : 11 NRECON1 wonders if there’s anything that would be important , but not too dangerous [ ? ] , to scan . NRECON1 and NRECON4 wonder about [ BOX245 ] ( confirm number with NIDS2 ) . NRECON1 offers to scan that , but NDS2 replies they don’t know what it is . NRECON1 wonders if box is part of the process . NIDS1 “nmap is probably safe as long as you’re not trying to fingerprint the OS” … 10 : 36 : 36 NIDS2 reiterates that he sees a lot of traffic and wonders if they’ve ever figured out what [ BOX245 ] was . NIDS1 asks if it’s over 4343 . NIDS agrees . NIDS1 tries to think about what 4343 might be , in terms of communication between machines . He wonders if it’s somewhere , something that’s not listed . In this case , the machine discussed is a machine they tried to identify all day long , since it was associated with unexplained traffic . Team members discussed the merits and risks 80 associated with the various means at their disposal ( direct connection or scanning ) to obtain more information about this machine . It is not sure whether the Blue team members actually implemented these actions , but in any case , the absence of knowledge about this machine continued to disturb the team . Ultimately , our data do not indicate that the machine was actually used by the Red team ; it was probably a user or service of which the Blue team was not aware . Outcome of investigations Such investigations about the validity of network activity led to two types of outcomes : ( 1 ) the realization of its legitimacy , which resolved the anomaly detection process – the symbol R in Figure 4 . 6 , or ( 2 ) additional efforts in order to : a . investigate the consequences of the anomaly at a higher mission level ( also represented by the symbol X ) , b . decide on an appropriate response ( not represented because this rarely led to actual actions on the network ) . The second type of outcome is described in the next paragraph . The first type of outcome corresponds to activity that had been initially considered suspicious but turned out not to be related to attack . This activity was not discarded immediately because of insufficient understanding of the situation . Examples of issues resulting in this insufficiency are : improper configuration of the network by INL ( e . g . , episode B2 ) ; network knowledge issues ( e . g . , episode B14 ) ; and unknown activity conducted by a Blue member and improperly characterized ( e . g . , episodes B3 , B33 , B44 ) . These are all forms of uncertainty network defense faces during operations . The last type of issue will be developed in greater detail in a subsequent section about coordination challenges . 81 Typical response to events Once cyber events were identified with sufficient understanding and certainty , the team attempted to respond to them through actions on the network . These actions were intended to correct vulnerabilities revealed by the attacks , and ultimately at impairing the Red team’s presence and progression . However , this phase of anomaly response was where the Blue team was also faced with the difficulty of providing security within a production environment . As designed in the exercise , the Blue team was not the owner of the network ; they did not have authority to implement the changes they thought were needed to respond to attacks . Their task relative to the response was to transmit requests to a White Cell through the management chain . The White Cell was played by INL instructors and aimed at simulating company IT services in charge of the network , i . e . , the roles that typically decide on the network configuration choices . Requests for change had to be supported by evidence of the attacks observed and justification for the desired changes . This architecture was built into the exercise in order to simulate real production settings ( at least , in the industrial domain ) , and emphasize both the need and difficulty to document and produce evidence of cyber events . During the course of the exercise , the Blue team transmitted dozens of requests for change to the White Cell in order to address vulnerabilities or attacks identified . Close to none were actually accepted for implementation . The main reason for these rejections seemed to be insufficient evidence . Responses are not represented in Figure 4 . 6 because they rarely led to concrete actions on the network , and , as a result , had no observable impact on the Red team’s activity . The motivation behind requests for change was primarily to restrict traffic to a minimum ; these requests were essentially attempts to block access to addresses that 82 appeared to be the source of suspicious traffic ( e . g . , episodes B2 , B16 ) and to disconnect machines that appeared under attack ( e . g . , episode B35 and B38 – several requests were made to shut down servers BS1 and BS2 ) . However , attempts to reduce the openness of the network ( s ) were defined by the extent to which the Blue team knew and understood the configuration of the network and its assets . These decisions were made based on what made sense to the team , given their limited knowledge of the entire operational environment . The following example extracted from the data ( episode B9 in Figure 4 . 6 ) captures difficulties : 08 : 36 : 05 NIDS1 “they’ve got a shell on [ S1 ] . ” [ FTP server ] 08 : 37 : 10 NRECON2 and NLEAD come behind NIDS1 . NIDS1 explains the traces he has , how you can see the payload . Decision to shut down the FTP server . 08 : 39 : 10 APP2 asks if he can just restart FTP server . 08 : 42 : 41 SYS6 arrives in SYS room and explains rootkit on FTP server , talks about what can be done in relation to regulatory data : FTP can be shut down , webserver can’t . 08 : 45 : 20 NLEAD and APP1 meet over NetMap . APP1 mentions they shut FTP server down . NLEAD to APP1 : “the FTP process isn’t critical . ” APP1 shakes his head [ inaudible exchange ] . Wonders if there’s anything else they should do . … 10 : 15 : 31 WINL2 comes and yells about FTP server being down . SYS1 was in the room , asks “which FTP ? ” WINL2 “the external anonymous access , we can’t turn that off . ” SYS1 “we can’t turn that off ? . . . ” WINL2 “no… uh uh… you gotta get that back up . . . we got people out there that get documents out of it…” They move to SYS room . The series of exchanges corresponds to one event during which the Blue team implemented changes on the network . Verbal exchanges capture the rationale behind the decision , which is made collaboratively between several members of 3 different sub - 83 teams ( Network , Systems , Applications ) . Later , an instructor from INL playing the role of a White Cell member ( WINL2 ) irrupted in the Blue space and protested strongly against the measure taken to restrict access , claiming that the action of shutting anonymous FTP access to server S1 was inappropriate relative to production - related goals , since customers used that service . Hacking techniques to impede the Red team’s progression Because of its lack of effect , the typical response channel described above quickly became a source of frustration for the Blue team , which never managed to produce sufficient justification ( evidence ) for the changes requested . Consider the following exchange : 14 : 08 : 41 SYS1 arrives , asking for “IDS or firewall team” He would like to get logs of [ BS1 , BS2 or S3 ] servers , of the port scans coming in from the 2 boxes . He holds a USB flash drive to get the logs . NRECON4 asks him to confirm what he wants SYS1 : “from those 2 boxes… to the rest of the network” NRECON4 mentions they were already given to TEAMDEP on a thumb drive . SYS1 asks her to confirm by using NetMap . 14 : 09 : 46 SYS1 comes back , wondering if she can grab more logs . He wants to request corporate to shut them off . NRECON4 replies that she’s already requested a shutdown of SSH on these machines . SYS1 : “well , they’re inside , now ; they already got reverse [ telnet ] and stuff… they’ve also got this firewall [ shows on NetMap ] , so we can’t even ping [ ? ] it now . ” TEAMDEP arrives in room and asks if they can ARP - poison the 3 IPs . SYS1 : “possibly” TEAMDEP : “so , if anybody tries to respond back , [ … ] comes back in our control” SYS1 : “possibly” TEAMDEP “so it just cuts their communication” Conversation follows / goes on in SYS room ( short ) . They mention using Backtrack . 14 : 10 : 56 TEAMDEP is back , explains value of ARP - poisoning for regaining control 14 : 13 : 26 TEAMDEP : “just ARP - poison crap that we don’t have control of” 84 In the afternoon , the team was faced with highly suspicious activity related to two servers , BS1 and BS2 ( see episodes B35 and B38 in Figure 4 . 6 ) , to which they did not have access ( neither physical nor virtual ) . The previous exchange captures the response decided upon in this situation ( episode B38 ) . ARP - poisoning is a common type of cyber attack . It consists of sending out network packets ( ARP messages ) in order to perturb ( e . g . , intercept or stop ) traffic to a network or host . It can , for instance , be used to conduct classic ‘denial - of - service’ attacks . Interestingly , the Blue team used the same set of tools used by the Red Team to conduct this attack . Several aspects of this event are worth noting : - It was the first instance of an adversarial strategy on the Blue side , as opposed to the more usual reactive response behavior . - The same strategy was used later against another box ( episode B48 ) . - It is explicitly described as a control issue by the actors themselves . - It is uncertain whether it had the desired effect since the Red team’s progress was not hampered ( see episodes R15 , R16 , R18 in Figure 4 . 3 ) . - On the Blue side , it was a source of difficulty in the detection of suspicious activity since ARP - poisoning produced ambiguous activity on the network ( see episode B44 ) . 4 . 3 . 4 . A critical artifact : the network map During observations in the Network room , it quickly became evident that the large network map displayed on the wall ( see Figure 3 . 4 ) would be used as an important collaborative artifact , not only at the level of the Network team , but also for interactions within the Blue team as a whole . Uses of the network map were therefore carefully 85 tracked throughout the day in order to analyze what they revealed about cooperative process of cyber defense . Members of the Blue team were given printouts of network maps prior to the exercise so that they could start preparing and acquiring knowledge about the network . At the beginning of the exercise , they were also given larger poster - size prints of these maps to be displayed on walls if desired . Participants rapidly took advantage of these large prints and intentionally put them in locations where they would be available to other team members . Since we were interested in collaboration dynamics , I paid careful attention to and took detailed notes on the interactions in front of the map displayed in the Network room ( in which I was the main observer ) . Since the importance of the map was confirmed throughout the morning , the decision was also made to reorient the fixed camera in this room to better capture interactions . The choice of this new perspective hindered our ability to record interactions around the table ( the initial area of focus for collaborative processes ) , but facilitated the detailed a posteriori analysis of a large number of interactions . The product of this analysis is a large table describing the uses of the network map . In addition to timestamps ( in order to retrieve episodes in the video files ) , the table details for each use observed : ( 1 ) roles involved , ( 2 ) actions conducted , ( 3 ) corresponding cognitive functions ( see details below ) , and ( 4 ) comments on the episode ( e . g . , forms of interactions ) . Support of exchanges of information The first obvious use of the network map was to facilitate the exchange of information . In particular , team members used it to supplement and clarify their verbal descriptions . 86 Several instances were observed where a participant would raise an issue to people present in the room , receive little response , then walk to the map and repeat the same announcement while pointing to the corresponding elements of concern on the map . As a physical artifact , the network map supported additional forms of interaction by allowing participants to communicate efficiently elements of information through : ( 1 ) Gestural deixis : typically , participants would point at network elements ( e . g . , specific machine or sub - network ) and use hand movements to trace a path , e . g . , to explain what the Red team would have access to if they managed to gain access to a particular machine . ( 2 ) Body position relative to the map : given the large size of the map displayed on the wall , participants had to stand in front of the area of the network they were communicating about ( especially if they were using forms of gestural deixis ) . In this context , a team member’s body position relative to the map corresponds to a source of observability of his or her focus of attention . It is a type of information that is useful in collaborative environments , since it indicates general areas of concern to others and helps to reduce ambiguities that arise during verbal exchanges ( e . g . , what network a machine referred as “IP 87” belongs to ) . Although less critical and less rich as a whole than verbal communication , gestural deixis and body position relative to the map were very supportive of information exchange . By creating a space for exchange and increasing observability , the network map also supports “voice loop” dynamics ( Patterson et al . , 1999 ) in which nearby members not directly involved in the exchanges might become participants in the conversations ( e . g . , to add new elements they are concerned about ) . These characteristics 87 correspond to important proprieties of the artifact , which might get lost in other forms of representation of network knowledge . Network defense processes supported by the network map Figure 4 . 8 gives an overview of uses of the network map relative to network defense processes . Figure 4 . 8 – Network defense processes supported by the network map ( number of observations in a total of 76 instances captured from 07 : 00 to 17 : 00 ) A general ‘Collaboration’ category was used to simply distinguish interactions from individual uses of the network map . In addition , the cognitive functions observed and captured in the table were grouped into 5 larger categories that mirror the network defense processes described in the previous section ( one episode often corresponded to more than one category ) : ( 1 ) knowledge building processes : gap detection , validation , capture , ( 2 ) use of knowledge captured : information seeking , ( 3 ) investigation of events : explanations , hypothesis exploration , 0 10 20 30 40 50 60 Response Investigation Knowledge use Coordination Knowledge building Collaboration 88 ( 4 ) response to events : problem - solving , planning , tasking , ( 5 ) coordination processes : information sharing , cross - checks , maintaining common - ground . The graph shows that a vast majority of instances were collaborative . Importantly , the graph also shows that all types of network defense processes were observed a significant number of times during the utilization of the network map . The number of observations provides compelling evidence that the network map constituted a critical artifact in support of decisions made and actions conducted by the Blue team . The numerous instances during which participants from other teams came into the network room specifically to meet over the map is another indicator of the importance of this artifact in the entire defense process . Mainly , it served as both an easily available repository of knowledge about the network , and as a support for the exploration of interpretations of events as well as of potential actions . The network map as a key artifact for the analysis of the event An analysis of how the network map was used throughout the day turned out to be quite fruitful . Through the investigation of types of functions it supported , it provided rich insights into the distributed decision making process on the defensive side : - cognitive functions at the individual level ( e . g . , verification of knowledge ) , for the purposes of a particular role , - cognitive functions at the team or sub - team level ( e . g . , hypothesis exploration , collaborative problem - solving ) , and - collaborative functions to support the distribution of tasks across multiple roles ( e . g . , establishing and maintaining common ground ) . 89 Interestingly , the observability it supports ( described above ) was used at times during video analyses as I was trying to document participants’ focus of attention . I also used it extensively as a knowledge repository during my own analyses of the verbal communication . Both qualities were very useful to disambiguate data , understand motives , notice potential mistakes , etc . 4 . 3 . 5 . Critical challenges of cyber defense Making sense of network activity Central to the reactive nature of their activity , defenders need to adapt their plans of action based on what they understand about the attack . Unfortunately , various forms of uncertainty associated with network activity make processes of sensemaking ( Klein , Moon and Hoffman , 2006 ) particularly challenging : - Defenders cannot observe Red’s actions directly , but only through traces of network activity . - Elementary traces of activity are often ambiguous , i . e . , the same traces can mean different things . - Furthermore , these traces are incomplete accounts of Red’s behavior , especially since Blue mostly has access to data presented by technological systems that filter and interpret basic network activity . - Meaningful units of attack activity are also scattered : they are based on multiple micro - events that require different perspectives to be analyzed as a whole ( a process labeled correlation in the literature – e . g . , a central topic of Kruger et al . , 2005 ) . 90 - Finally , these challenges exist in an incompletely known and evolving environment , where knowledge is key to understanding activity traces . The introductory episode ( see Table 1 . 1 ) is an interesting example of difficulties related to uncertainty on the defensive side : members of the defensive team definitely had a sense of what is going on , but their understanding of events was quite limited . Even when the lights were turned off , there was a doubt whether or not it was due to Red’s actions . Operating in a production context Providing network security while maintaining production was a fundamental trade - off that the network group had to manage . Essentially , this trade - off is about network access . From the perspective of providing security , characteristics of network configuration such as open ports , weak external firewall rules , susceptible services , and unprotected network paths between internal sub - networks , represent vulnerabilities that need to be eliminated . However , from the perspective of maintaining production , these same network properties facilitate network - based activities . Network access is necessary in order to maintain production . Therein lies the trade - off : when is a service , an open port , or a weak firewall rule , too much of a vulnerability even though it will impact production ? Note that the capacity to observe this trade - off at play is a result of the design of the exercise , its scale and scope , and the emphasis established by INL instructors ( as in the episode B9 detailed in a previous section ) . Providing evidence in order to take action In addition to explicitly managing the security / production trade - off , justification of the chosen balance was required . For example , although an open port was a potential 91 vulnerability , closing the port required proof that the action would not disrupt production or proof that the vulnerability out - weighed production pressure . The following example is a short dialogue between a member of the Intrusion Detection group and a supervisor from INL . It corresponds to episode B1 in Figure 4 . 6 . 09 : 25 : 51 NIDS2 asks BINL2 why they can’t block [ Network , class B ] BINL2 replies : “lack of evidence , we don’t know for sure that’s part of the attack” . He adds : “they wanna keep the services accessible to the world as much as possible” , like in any real business . BINL2 emphasizes lack of evidence . Moreover , as suggested by the example , what constitutes sufficient evidence for action is difficult to define and this was , as a result , a source of trouble and frustration for the Blue team throughout the exercise . The following example ( related to episode B13 ) is an exchange between two members of the Network team in an attempt to provide evidence for vulnerability scans conducted from the outside . 08 : 50 : 25 NLEAD comes back and gives NIDS1 a flash drive so that he collects the evidence of what he was talking about . NIDS1 : “all these scans ? ” NLEAD : “from the outside ? . . . ” NIDS1 : “because you’re gonna get those all day long everyday on the internet side . That’s why I was saying it’s kinda hard when you’re monitoring on the internet side , I mean…” NLEAD : “it got in…” NIDS1 : “not necessarily , [ inaudible ] ” The example shows difficulties associated with the nature of evidence . Most large organizations ( industrial , academic or governmental ) experience more or less continual suspicious activity from outside sources . This cannot be used as single evidence of attack , and measures of protection of the network ( detrimental to other goals ) cannot be based solely on capturing such activity . More generally , the production and use of 92 evidence in network defense suffers from the same early detection ( “early warning” ) problems as other domains ( Woods , 2009 ) : evidence is often ambiguous and uncertain when sought early and proactively ; it is usually clearer after the fact , once an adverse event has occurred and can be traced back to earlier events . What constitutes evidence becomes a subject of debate and negotiation because of the impact of corresponding measures on production goals . This issue is at the heart of difficulties ( and frustration ) experienced throughout the day , captured by the following exchange : 11 : 04 : 56 SYS4 calls NRECON1 [ intense activity phase ] SYS4 and NRECON1 go to NetMap and SYS4 explains vulnerabilities [ in terms of path ] . SYS4 and SYS6 think firewall rules need to be modified to account for this . 11 : 06 : 46 NIDS1 joins them and explains they’ll have to be able to provide justification – in the form of evidence ( show payload , … ) NRECON1 replies they’re trying to prevent : “wait you’ve been attacked , then you show them , that’s the mode they’re in” Coordinating activities While pursuing the goal of providing network security , the Network group was constantly at risk of working at cross - purposes . Network security required the network group to engage in two tasks : network discovery and intrusion detection . These tasks were in fact conducted by two distinct subgroups . Interactions between processes of network discovery and intrusion detection occurred each time the network discovery subgroup actively probed the network ( e . g . , for discovering open ports ) . Traces of their activity would appear in the network analysis tools and require that the intrusion detection subgroup be able to identify them as legitimate . Usually , the network discovery subgroup would anticipate the issue and take advantage of physical collocation by announcing their actions and IP address in order to be recognized as a 93 legitimate source of traffic – the source IP address of the activity is a critical differentiator of its legitimacy . In some cases , coordination attempts were simply missed due to ambient noise or focused attention ( e . g . , episode B18 ) . Episode B3 ( see Figure 4 . 6 ) is an interesting example of coordination efforts and requirements : the person performing vulnerability scans on the network ( Network Reconnaissance group ) was very careful to announce his actions to his team members , especially those in charge of monitoring the network ( IDS group ) . However , a member of the System sub - team detected his activity and came to inquire about the suspicious traces . Although in this case the problem was resolved fairly quickly , it illustrates how the need to manage interdependencies had been anticipated and acted upon , but at a scale that was too small ( functional interdependencies with other groups had been overlooked ) . Consider the following exchange : 09 : 43 : 56 TEAMDEP comes to see how NIDS is doing . NIDS3 asks him if they really have to all these scannings ( “we’re scanning ourselves…” ) TEAMDEP wonders : “what are we scanning ? Oh , are we doing a full scan [ … ] ? ” NIDS3 to NRECON1 “are you still scanning ? ” NRECON1 : “yes” NIDS3 : “do we really want to scan ? Because that’s giving us false positives…” TEAMDEP : “Whitelist his IP so it won’t come up” NRECON1 : “Well… I just gotta get the data for these guys [ Systems ] , and I’ll be done” This exchange illustrates the conflicts between network reconnaissance and intrusion detection and one technical solution proposed to address them ( related to actions seen in episode B3 ) . Although the use of a white list based on members’ IP addresses seemed like an interesting temporary solution , one can wonder if that is really a viable answer to coordination needs given the dynamic character of processes ( e . g . , members sometimes 94 change networks to fulfill their tasks ) , and the possibility of Blue team machines being corrupted . As an aside , this example also restates the importance of understanding behavior in order to identify illegitimate activity on the network , that is , the question of legitimacy of traffic goes beyond that of users ( although it might be a reasonable first approximation ) . Capturing knowledge of a complex and evolving operational environment Defenders must know a network that is not directly observable . Network analysts therefore rely on representations of the network to conduct their activities . These representations risk being stale ( the network is dynamic ) and incomplete ( e . g . , partially known active services ) . This means the team must capture the knowledge generated while discovering the network , a costly additional task in the face of time pressure . The Blue team used the network map extensively throughout the exercise : this critical artifact constituted a basis for a variety of individual and collaborative actions and decisions . In spite of its incompleteness , the map remained unmodified during the first half of the exercise . This meant knowledge of the network was evolving , but , without an updated map , activities were conducted based on outdated knowledge of the network . An INL instructor suggested explicitly in the morning to capture knowledge about the network and to update the representation . The value of this task was recognized and acted upon only during the second half of the exercise – most likely because of difficulties in pursuing competing tasks or goals that required updated information on the network . Our interpretation is that , due to lack of resources and time pressure , higher priority was put earlier on activities for discovering and reducing vulnerabilities on the network . 95 Various issues arise related to the utilization of a physical artifact to capture network knowledge . Although the team had been told multiple times that the network representation was “accurate” ( although incomplete ) , this accuracy actually reflected the situation at the beginning of the exercise . If modifications had been made during the day to the network configuration ( e . g . , firewall rules ) it might have become challenging to provide and update annotations of these changes . Also , annotations are to a large extent constrained by what is represented on the map , and the representation of other elements of the network could be particularly difficult . As an example , the identification of machines under investigation at a given time might be better supported through list - type representations . Summary : challenges of cyber defense Challenge Source Making sense of network activity The low observability , uncertainty , dispersed nature of traces of activity constitute barriers to sensemaking processes Security vs . Production trade - off Limiting network access to increase security may reduce production capability Evidence : uncertain early vs . clear after the fact Defining sufficient evidence to modify network configuration and reduce access Network discovery vs . Intrusion detection trade - off Traffic generated for network discovery has a similar signature to illegitimate traffic from an attacker Maintaining an up - to - date representation of the network Capturing network knowledge is necessary , but resources might be devoted to other urgent tasks Table 4 . 2 – Critical challenges in defense activities 96 4 . 4 . Cyber event : the interplay of attack and defense 4 . 4 . 1 . Contrasting perspectives We have presented the attacking and defending sides separately . To some extent , this is due to the linear nature of the written document . But more importantly , there is no single perspective on the events that captures both sides simultaneously . A cyber event is nonetheless fundamentally adversarial and therefore needs to be analyzed through the interplay of both sides’ decisions and actions . The interplay plays out in the network itself , which can be seen generically as a highly organized medium that connects clients and providers of services . Network activity becomes the central frame of reference to study actors’ decisions and actions . The following figures adopt a network - centric view to contrast the attack and defense perspectives . This contrast aims at highlighting important similarities and differences . The figures are simplified representations of the processes the Red and Blue teams engaged in throughout the exercise , as described in the previous sections . For each perspective , a number of their actions represent sources of network activity ( represented by the red arrows pointing to the types of network activity ) . Also , each side operates with the knowledge that some other actors exist on the network , which are an important part of their own activity but of which they have limited knowledge or observability ( these other actors are presented by the gray elements in the figures ) . 97 Figure 4 . 9 – Cyber security from an attack perspective Figure 4 . 10 – Cyber security from a defense perspective 98 Similar activity Cyber attackers and defenders share the same technological environment – the network and its applications – and , to a large extent , require very similar competences and frames of mind . In addition , some of the primary tasks that both sides conduct are the same , for instance : identifying and understanding network vulnerabilities and vulnerable machines ; developing and maintaining sufficient knowledge of the network ; understanding network activity . Through similar tools and actions , both sides generate similar - looking activity traces on the network . Perception of actions from the other side Interestingly , both sides are conscious of the other side’s presence , and act accordingly . The way in which they conduct their activity integrates the threat that the other side’s actions represent to their own mission : the Red team knows the network is monitored , and the Blue team knows the types of actions attackers are trying to implement . However , unlike in adversarial situations like games and sport , neither side is in a position to actually observe the other directly . Each side therefore relies on what can be observed or experienced on the network . Such information allows them to infer the other’s behavior and take corresponding measures ( e . g . , adapt their plan ) . Our data show that , on both sides , inferences can be correct or not . Probably due to lack of observability , a large amount of inferences are in fact not correct . The general tendency on both sides seems to be to interpret unexplained adverse events as results of the other team’s actions . However , the means for perceiving actions through network activity are usually different . On the Blue team , members were actively monitoring the network for signs of attacks in preparation ( intelligence ) or actual compromising actions . Unless they are able 99 to get inside information about network activity , attackers perceive defensive actions as disturbances of their general progression ( e . g . , losses of or new challenges to re - establish connections ) . During the exercise , the Red team generally interpreted such events as resulting from defensive actions ( e . g . , machine rebooted , rules tightened ) , suggesting that the Blue team had detected their activity . Goals and challenges Analysts on the defensive side monitor network activity to detect anomalous traffic . They are essentially concerned with being able to distinguish between legitimate and illegitimate activity . However , due to scale and low observability , they have necessarily limited and / or fragmented knowledge of the potential sources of activity . To develop knowledge of their network , they use both active ways to probe the network and passive ways to monitor the traffic . Active probing constitutes another source of activity , one that , in addition , appears quite similar to hacking – a source of interaction and goal conflicts within the Blue team . As attackers probe the network with similar traffic , using similar tools in the same space , it becomes difficult for network analysts to efficiently sort the traces generated , and their own activity risks providing a mask to the traffic they want to detect . The main tactic used to recognize suspicious exploratory traffic is the identification of the source IP addresses . IP - based recognition nonetheless represents a brittle mechanism : it assumes an extensive low - level knowledge of the network as well as relative network stability ; and it relies heavily on human memory and string recognition for a type of information that is probably not the most conducive to these cognitive processes . Defenders experience a challenging situation of data overload where few mechanisms efficiently support the necessary organization of network traffic , context sensitivity , and control of attention ( i . e . , focusing and reorienting ) . 100 From the perspective of the Red team , gaining and maintaining access means establishing a connection to the target network . It boils down to a minimum of one connection to the Blue network ; ultimately making the Red network part of the Blue network as it was described by one of the INL cyber security experts . However , it goes beyond the common statement that attackers “only need to be right once” , which is an approximation assuming that an established connection will remain available . Their main concern is being detected while doing so , and about jeopardizing further opportunities to carry out their mission . The network , as the environment in which the interactions play out , evolves as a result of teams’ actions . Changes include purposeful modifications of network configuration by the Blue team , but also unintended effects by the Red team leading to loss of access , as observed during the exercise . What is almost certain for attackers is that they will gain some type of access . A more important and challenging activity is the strategic planning of future actions to maximize effects relative to their goals in an unknown and dynamic network ( e . g . , securing access , moving forward in the network , or corrupting services ) . Goal conflicts emerge especially from limited strategic planning prior to access , limited knowledge of effects of actions , and time pressure resulting from perception of detection . From the perspective of the Blue team , the main goal of network security is to prevent or break such connections , based on investigations of potential vulnerabilities and network traffic . Frequent guidance to address this challenge is the tightening of firewall rules ( Cheswick et al . , 2003 ) ; the so - called “candy security” model , influential since the early 90s . However , one of the core characteristics of cyber defense which differentiates it from attack , is that defense occurs within a production environment . This means that defense needs to manage a balance between security and production goals , and be both 101 willing to sacrifice production and capable of justifying it when needed . Moreover , since attackers’ access will necessarily occur , then this model is not sufficient . In part , attacks could come from inside the network , as illustrated by the recent Stuxnet worm . According to debriefings with the instructors , the best Blue teams do not alter firewall rules 3 . One of the issues noted with the focus on firewalls is that it can lead to a false sense of security , while the network should really be monitored as if it were always externally connected ( Canavan , 2001 , chap . 12 ) . 4 . 4 . 2 . Interplay during the exercise We have already described how the perception of the other side’s actions is key on both sides . In particular , teams conduct their respective activities by integrating their understanding of the other side’s actions . This section will describe what the data captured illustrate about the interplay of attack and defense . Ideally , the representation used to describe the activity of both teams separately ( see Figure 4 . 3 and Figure 4 . 6 ) would have been used to show the dynamics of adaptation to actions on both sides . However , as described previously , the difficulty of the Blue team to actually implement any of the measures they judged necessary makes such representation only partially relevant . In the context of the exercise , what was observed was mostly one team ( Blue ) reacting to another’s actions ( Red ) . Only this aspect of the interplay will be represented , others will be discussed through illustrations from the data . 3 This was an intriguing statement as it contrasted vividly with what we had observed during the exercise . We were unfortunately unable to further investigate its full meaning . This will however constitute an interesting insight we could explore in future efforts . 102 Red’s perception of Blue activity Overall , the Red team tended to assume that disturbances to their processes were the result of the defending team’s actions , based on sufficient knowledge of the means and plans for attack ( i . e . , detection ) . However , Blue conducted few actions that had an impact on Red’s progress . Essentially , such actions corresponded to machines’ being rebooted or shut down temporarily . But for the most part , access gained was available for significant periods of time or quickly re - gained ( see episodes R4 - R11 , and R12 - R15 in Figure 4 . 3 ) . Red was able to establish its presence in the network without being significantly delayed by Blue’s efforts . Interestingly , the Red team was not aware of the difficulties the Blue team experienced in obtaining the changes they requested . Since disturbances were nonetheless perceived as indications of detection and actions by Blue , they created sources of urge to “do something” before all access was completely lost . The text below is an excerpt of exchange in the Red room illustrating such issues on the attacking side ( it corresponds to episode R22 ) . This example illustrates how the perception of Blue’s actions , accurate or not , emphasizes the trade - offs Red needs to manage , in part by urging them to make a decision and potentially act , thereby also making them more visible to the defense . 103 14 : 20 : 44 Discussion about whether Blue has found out things and taken them down [ not totally clear ] . RM6 mentions he’s still connected , though . [ two more users added to servers for backdoor . ] 14 : 22 : 14 RM1 says “that’s funny , somebody found me… they’re connecting to me on port 80 . ” 14 : 22 : 44 RM6 asks RLEAD if he wants him to shut down their app . RLEAD asks the group : “what do you guys think ? ” People discuss whether to shut down app or to monitor more . Some remark they’re loosing and RM3 remarks they’re being shut down . He adds : “kill it ! ” 14 : 23 : 59 RM3 notes he’s lost connection . … 14 : 33 : 44 After discussion , a decision is made to kill one of the SCADA processes . 14 : 30 : 14 RLEAD points out ( “Hang on ! ” ) that , before they do anything that makes them known , they have to realize it is their only connection at the moment … 14 : 35 : 14 They’re RDPing the box – RM6 , RM9 want to kill all RDP processes [ Remote Desktop Protocol ] RINL1 “if they’re close to figuring out what’s going on , you might as well break it . ” Similarly , the Red team sometimes experienced ambiguous phenomena ( e . g . , peculiar results from intelligence actions ) . Once again , unexplained events tended to be attributed to Blue . As an example , a machine was discovered in the afternoon ( part of episode R15 ) that had not been seen before and seemed to have plenty of vulnerabilities to exploit . The first impression was that it was suspicious ( “too obvious” ) and could very well be a honeypot , i . e . , the implementation of a deception strategy to lure the Red team into an inconsequential network space . Blue’s perception of Red activity Figure 4 . 11 aims at representing how much the Blue team knew about the Red team’s actions throughout the day . 104 Figure 4 . 11 – Interplay : Blue team’s perception of attack activity 105 The figure plots both teams’ actions using the same representation features as before in an attempt to show the parallel progression on both sides . For simplicity and clarity purposes , only a selection of episodes extracted from Figure 4 . 3 and Figure 4 . 6 is represented from each perspective , and items were sometimes slightly reorganized ( moved vertically ) from the original figures . Episodes selected on the Red side are those that were particularly instrumental in the team’s progression . Episodes selected on the Blue side are primarily those that could be related to these critical actions of the Red team . The figure , based essentially on the communications captured in the Red room and in the Network space , is difficult to build . More precisely , it is not always obvious how to relate events from both sides because of the ambiguity with which actions are communicated upon ( e . g . , limited information , complexity of network configuration , redundancy of machine names , time gaps between actions and communication ) . Numerous interpretations are therefore required based on the context in which these actions occur . The figure nonetheless does allow for a general understanding of the Blue team’s awareness of the situation . It highlights that the defensive team was able to detect the most important advances and established connections by the attackers ( IP1 , IP2 , IP6 and IP8 ) . Windows of opportunity : outpacing the other side One of the characteristics that emerge is the delay between the initial events and their detection ( at least how it surfaces during conversations captured ) . If the delays observed in the figure correspond to actual latencies in the detection process ( often in the half - hour range ) , this suggests that an attacking team commonly has a window of opportunity during which they can implement various actions before being detected and potentially disconnected . On the other hand , Red’s progression is hindered by the 106 fact that they are ‘fumbling in the dark’ , i . e . , access gained to a particular machine does not translate immediately into further access to more sensitive data or assets . The intelligence or compromising actions Red is required to perform to build further knowledge or secure access for their strategic purposes risks uncovering them . This means that Blue also has a window of opportunity to act during which more signs of Red’s presence become available . The situation therefore resembles a chasing game between the teams , Red being most often in a position to set the pace . In the next section , we will discuss what implications the findings described here have on our understanding of the domain of cyber security . We will focus particularly on implications for understanding and improving cyber defense . 107 Chapter 5 . Discussion 5 . 1 . Main findings The analyses resulted in the identification of core characteristics about the domain of cyber security . These characteristics impact the process of cyber defense and attack , as well as their investigation . Findings will be summarized here , focusing on those that are more fundamental or surprising . The implications of these findings will be extended to other fields of research , especially to those interested in decision making in complex work environments , such as Cognitive Systems Engineering and Resilience Engineering . 5 . 1 . 1 . Domain of cyber security Uncertainty and complexity On each side , high levels of uncertainty impair the conduct of operations . Uncertainty exists because of the necessarily incomplete knowledge of the network : it is an evolving large - scale environment . Uncertainty results also from the low observability resulting from the fact that the network is a virtual environment . In particular , actions of others ( adversaries or team members ) are only visible through micro - events on the network . Elementary traces of activity are fragmented and ambiguous : one specific network packet exchanged may correspond to different meanings when put in context . These various forms of uncertainty make it challenging to make sense of actions 108 observed and anticipate future actions . The capacity to understand the situations experienced is nonetheless essential both for the management of adversarial interplay and for cooperative activity . Furthermore , the potential impact of actions on a large and complex network is difficult to evaluate or anticipate . On both sides , uncertainty is at the heart of challenges to successfully manage the trade - offs described in Table 4 . 1 and Table 4 . 2 ( e . g . , understanding efficiency and detectability on the attacking side , critical trade - offs between security and production goals on the defensive side ) . The introductory vignette ( see Table 1 . 1 ) illustrates in a nutshell several of these points about uncertainty on both sides of the exercise : in spite of efforts by both teams to make sense of what they each observe on the network , their respective understanding of the situation at hand remains limited . Joint activity Successful joint activity rarely comes for free , since it relies on coordinative tasks that add to the functions roles must fulfill ( Klein , Feltovich et al . , 2005 ; Branlat et al . , 2009 ) . In the type of setting simulated by the exercise , defense is highly distributed between teams and roles . Defense processes therefore require appropriate management of functional interdependencies in order to support the achievement of common goals , and avoid or resolve goal conflicts ( ibid . ) . Similarly , the attack we observed relied on a team of participants who provided a variety of competencies useful in the domain of cyber security . While this diversity among the Red team can act in support of progress , it creates additional demands for the coordination of actions . In particular , unmanaged coordination risks jeopardizing the chosen strategy . 109 Adversarial nature Cyber security is adversarial and requires each side to adapt their operations , to a large extent through the perception of the other side’s actions . However , attack and defense participate in a fundamentally asymmetric relationship . From the perspective of the defense , the main task is to make sense of the attacking team’s behavior . From the perspective of the attacking team , this is an important but secondary objective . Members of the Red team are indeed more focused on understanding the unknown environment so that they can make progress . In a sense , the other side’s perception underlies their activity as well , but more as a potential for hindering their progress . In addition , both teams are not equal when faced with inadequate knowledge or actions . The defending team cannot afford to have an approximate understanding of the situation or an inadequate response implementation . On the other hand , the attacking team will have numerous opportunities to do damage . The implementation of a pre - defined strategy is what can be difficult for them , but their process is more opportunistic by nature . 5 . 1 . 2 . Methodological aspects Multiplicity of perspectives The first methodological implication of functional distribution and adversarial context is that no single perspective can really describe the event , i . e . , can simultaneously provide an understanding of how the event unfolds and account for the complexity of the dynamics at play on each side . This is true for participants , for instructors , as well as for outside observers . The multiplicity of perspectives raises important questions about how to capture , analyze and synthesize adversarial events . Distributed observations offer greater capabilities to capture parallel activities in physically separate locations . 110 However , such an approach also implies additional challenges that result from the compartmentalized nature of the observations . First , distributed observations necessitate the ability to build sufficient understanding of the development of the event during observations in order to focus more efficiently on events of greater interest . Similarly , subsequent analyses require the ability to synchronize and confront the fragmented perspectives captured in order to construct a coherent account of events . Uncertainty Much the same as participants in the exercise , observers are faced with challenges associated with the high uncertainty characteristic of cyber security . This is further reinforced by the computer - supported nature of cyber security as a domain of practice , in which an important part of participants’ actions is not easily observable . Means to reduce uncertainty are required both : ( 1 ) during observations , e . g . , through briefings and cross - checks between observers ; and ( 2 ) during subsequent analyses , e . g . , by supplementing data captured during observations with other information about the exercise and its environment ( for instance , central artifacts like the network map ) . Such means are particularly useful to disambiguate communications captured . Conditions of observation Human - centered researchers typically like to “stage” the situation they are observing by designing and introducing probes that correspond to their research objectives ( Woods and Hollnagel , 2006 , Chap . 5 ) . This approach was not possible in the context of this project . However , in this staged - world study , we highly benefited from the INL instructors’ expertise in designing and conducting cyber security exercises ( we could not have built such a rich and face - valid environment ourselves ) . As observers , we 111 nonetheless did “shape the conditions of observation” ( ibid . ) through the methodological and data collection choices ( e . g . , camera positions ) . Importantly , the exercise was part of a weeklong cyber security training in which we were , as observers , embedded from the beginning ( documentation was sent to participants prior to the training ) . These preparatory phases were very instrumental in helping us build our expectations concerning how situations might develop . This preparation allowed us to focus our attention on areas of higher expected value and to make adjustments throughout the day when surprises or opportunities arose . An important characteristic of the exercise observed is that participants were not cyber security experts . Since we were interested in studying the nature of expertise in this domain and in identifying core challenges requiring better support , it can be argued that the findings presented here are limited by the design of the study . However , a counterargument is that non - expert participants actually help by making critical elements of the domain more observable : they verbalize more , their struggle is apparent , etc . Because experts are more fluent at their tasks , they rely on more internalized processes , and deal apparently easily with challenges they face ( these are just part of ‘normal work’ ) . In other words , simply observing experts would have been quite difficult and less eventful ; observations of experts would have had to be supplemented with other techniques such as concurrent or subsequent interviews . 5 . 1 . 3 . Implications for other fields of research Cyber security shares core characteristics with other work domains . Observing how operators manage typical challenges in this domain , therefore , helps inform the larger set of work environments faced with similar challenges . 112 Management of uncertainty in distributed anomaly response An integral part of operators’ activity ( on both sides ) is about building and maintaining knowledge of the network , i . e . , of the operational environment . On the defensive side , such knowledge is critical to building an understanding of baseline network activity and to supporting anomaly detection . By identifying potential vulnerabilities and paths attackers could exploit , defenders were able to anticipate perturbations and focus their attention on areas of higher interest . Anticipatory and attentional processes in turn help reduce difficulties associated with data overload in large - scale environments . The distributed nature of work on the defensive side is a source of uncertainty because network activity is fragmented into different perspectives about the network ( e . g . , network configuration and systems management ) . Interestingly , it also reduces uncertainty by allowing operators to take advantage of the collaborative nature of their work environment . Collaborative processes help to confirm and discuss suspicious activity observed , thereby supporting processes of detection and of investigation . These processes correspond especially to resilient cross - check mechanisms through which operators validate their perception of the situations they face ( Patterson , Woods , Cook and Render , 2007 ; Branlat , Anders , Woods and Patterson , 2008 ) . Joint activity Observations conducted in cyber security emphasize the important difference between distributed cognition and group mind . In this highly distributed work environment , figures such as those presented in the previous section are necessary simplifications made in order to describe teams’ activity . Without making these simplifications , the dynamics would be overwhelmingly complex and detailed , and would be difficult to represent and understand . However , it is also necessary to recognize and account for the 113 complexity of the underlying joint activity in order not to oversimplify . Oversimplifying the distributed nature of work would , for instance , risk missing the trade - offs and goal conflicts that arise from the variety of perspectives on the task at hand . On the other hand , investigating these core tensions makes it possible to improve design and support joint activity . Design directions might be tailored as different domains experience different difficulties and rely on different forms of coordinative activity ( e . g . , results from computer - supported collaborative work might not translate directly for first responders who experience different environmental constraints ) . As a whole , though , designing for distributed work requires taking into consideration the different perspectives involved and the means supporting their interaction . Adversarial nature Domains involving adversarial dynamics can be essentially competitive ( e . g . , military operations , games like chess , or cyber security ) or occur in mixed cooperative - competitive environments ( e . g . , driving , board or card games ) . In all cases , activities exist in the context of their interplay , and the interplay cannot be understood by focusing on its isolated parts ( e . g . , solely considering the ‘anomaly response’ side of cyber defense ) . In particular , the interplay corresponds to continuous co - adaptive processes : actions in an adversarial situation address particular events , thereby solving a particular problem , but also transform the system in ways that might create new opportunities for the adversary . 114 5 . 2 . Relevance of the Resilience Engineering conceptual framework 5 . 2 . 1 . Parallel views on cyber security and safety The first and still frequently held view on network security has been labeled ‘candy security’ because of its ‘hard crust , soft inside’ design . The central idea is to protect the network from the outside by essentially reinforcing the barrier between the network and the Internet . A highly controlled access gateway ( e . g . , managed by a firewall ) then allows for only the necessary , well - identified exchanges with the outside . Figure 5 . 1 – ‘Candy security’ approach to network security : building a solid rampart From a safety standpoint , this view is similar to focusing on erecting a strong barrier around a hazard in order to avoid exposure to it ( see for instance Woods and Grossman , 2002 ) . In this view , the stronger the barrier , the safer people will be . The second view , often held in large organizations such as the one simulated in the exercise , is referred to as ‘nested network security’ . The central idea is to implement a sort of Russian doll architecture in which the most sensitive networks and assets are the interior most elements . In this view , layers closer to the outside are more exposed , while 115 layers further from the outside are more secure . Ideally , access from one layer to another is strictly managed through a rich understanding of the communication that needs to occur between layers ( e . g . , by using firewalls ) . The utilization of DMZ sub - networks further enforces the isolation of more sensitive networks and assets by exposing only the least sensitive ( e . g . , web services ) . Figure 5 . 2 – Nested network security approach : increasing sense of security Ultimately , while this view is more sophisticated and certainly creates more challenges for attackers , it only corresponds , in my mind , to an elaborate version of the candy security approach . From a safety standpoint , it appears to mirror common reification fallacies of the Swiss - cheese metaphor ( Reason , 1990 ; Woods , Dekker , Cook , Johannesen and Sarter , 2010 ) . The main motivation behind implementations of this strategy is to identify and plug the holes in the various layers of the structure in order to prevent them from aligning and creating the conditions for adverse events . Efforts made to reduce vulnerabilities are not to be disregarded , but problems arise when such efforts are the unique strategy for providing security . As was described in the domain of safety , basing security solely on patching the holes in the Swiss - cheese layers does not work because of the fundamental characteristics of real - world systems : 116 - There will always be ‘unpatched’ holes because systems and their environments are dynamic in nature ; they evolve as they adapt to changing constraints and opportunities . - Patching a hole transforms the system in place , creating new vulnerabilities ( which may remained unnoticed until an attack occurs ) . These two points relate to what authors interested in systems’ safety have described as “Maginot line mentality” ( Lagadec , 2009 ) . These views on security / safety ultimately make strong assumptions about the stability of their environment and on the knowledge they have of well - defined disruptions . This mindset results in seeking safety essentially through technological solutions ( because predictability allows algorithms to be designed and assessed ) and human competence is not critical beyond the implementation of good practices . Additionally , we have described in a previous section how efforts directed towards reducing vulnerabilities are at the heart of trade - offs with production - related goals . As with issues of safety , a change of mindset is therefore necessary to go beyond these unsatisfactory views on network security . Such a change includes acknowledging that disruptions that fall outside the known envelope of functioning for the system will occur , and that it will be necessary to address them efficiently in order to avoid undesirable consequences . This mindset underlies the Resilience Engineering conceptual framework , making it a relevant lens through which to think about network security . 5 . 2 . 2 . A control problem Since disturbances will occur that challenge the way systems normally operate , it becomes necessary to think of organizations seeking network security as adaptive 117 systems . Because of the scale and high degree of functional interdependencies ( in the network configuration or in the distribution of tasks ) , such organizations are also complex systems . As complex adaptive systems , they need to manage trade - offs in the face of uncertainty , complexity and production pressures . Difficulties in the management of these trade - offs risk exposing the organizations to the three basic patterns identified in domains sharing similar core characteristics ( Woods and Branlat , 2011 ) : ( 1 ) They need to adapt so as to keep up with the pace of events . ( 2 ) They need to adapt while managing interdependencies and avoiding working at cross - purposes . ( 3 ) They need to modify their response strategies when these prove ineffective . These basic patterns define high - level goals in the context of cyber security , which will be explored in the following section . These high - level goals represent what it means to “be in control” ( Hollnagel and Woods , 2005 ; Woods and Branlat , 2010 ) in the domain of cyber defense . Based on the description of the activities on the attacking and defensive sides and of their interplay , and in order to avoid the three basic patterns of adaptive failure , being in control means : - anticipating how adverse events may evolve in order to take advantage of the window of opportunity on the defensive side ( see section 4 . 4 . 2 ) , - understanding and managing the impact of adverse events on the system ( network , production ) , and - understanding and managing the impact of the response on production goals Note how these goals were enunciated for the domain of cyber security , but actually correspond to classic characteristics of expert behavior in any domain . 118 5 . 3 . Towards resilient cyber defense From the understanding of what in means to be in control , it is now possible to discuss ways to amplify control for cyber defense ( Hollnagel and Woods , 2005 ; Woods and Branlat , 2010 ) . Resilience Engineering emphasizes how resilient control is related to adaptive capacity and its management ( Woods and Branlat , 2011 , 2010 ) . Amplifying control essentially means transforming systems so as to help them avoid “failure [ s ] to adapt or adaptations that fail” ( Dekker , 2003 ) , i . e . , situations where adaptations are not successful , either because systems fail to recognize the need for adaptation , or because the adaptive processes themselves produce undesired consequences ( see also Woods and Shattuck , 2000 ) . This section will explore potential directions of investigation and development to support cyber defense in avoiding maladaptive patterns based on principles underlying resilience ( Woods and Branlat , 2011 ) . Note that all of the sub - sections are ultimately related to the general problem of managing uncertainty . The last sub - section will then describe how some of these insights can inform the design of a collaborative network representation space that aims at supporting resilient cyber defense . 5 . 3 . 1 . Sensemaking , anticipation and the adversarial nature of cyber security : adapting in time Sensemaking In our case , the detection of elementary and potentially suspicious traces of activity does not seem to be the main problem , apart from the latency described previously ( see section 4 . 4 . 2 ) . The bigger issues are determining what actually happens , i . e . , what it 119 means in terms of purposeful actions perpetrated by the Red team . In a description of nurses’ challenges in detecting sepsis , Klein , Pliske and colleagues ( 2005 ) explain : “the underlying problem [ . . . ] was inferred from a set of different kinds of symptoms” . The general idea is that each symptom in itself , taken in isolation , is ambiguous or insufficient in order to infer the general problem . Isolated symptoms nonetheless raise suspicion . A set of symptoms corresponds to a pattern relevant to the domain of work and recognized by the expert practitioner ( it is more difficult for the novice ) . The authors add : “She detected the problem from the very first glance , when she saw that the baby’s color was off and its skin was mottled . The additional symptoms fit a mental model , an explanatory scheme , of how sepsis is manifested . ” In other words , detecting a meaningful phenomenon from its dispersed symptoms does not equate correctly adding up elements gathered separately . It results from the construction of meaning through a “mental model” that builds on initial cues , guides further actions and evolves as more indications become available . Such processes are further complicated by the fact that anomaly response is highly distributed in the case of cyber defense . One of the associated issues ( for both teams ) was how to keep track of the general evolution of the situation . Initially , mid - level managers on the Blue team had planned that monitoring the overall progress would be part of their responsibilities while the various groups and actors focused on their specialized areas of competence . However , the activity of these two people was rapidly overwhelmed by other managerial tasks ( essentially transmitting piles of ‘request for change’ forms to the White Cell ) . As a result , nobody in the Blue space was in charge of maintaining and sharing the general understanding of the situation . An interesting difference appears between activities on each side : the Red team conducted short 120 briefings on the situation from time to time ( sometimes prompted by INL instructors ) , while the Blue them did very few ( if any ) of these . It is likely that the co - location of Red - team members , as opposed to the spatial distribution of Blue team members , created the conditions for this difference . Similar activities nonetheless occurred in the Blue space around the network map , but were limited to the team members participating in the exchanges . Supporting cyber defense : Multiple perspectives are required to efficiently make sense of situations at hand . These perspectives are defined by the type of competences required to understand particular aspects of the situation ( e . g . , network or database activity ) , but also by their more tactical or strategic focus . Supporting cyber defense then means supporting each of these perspectives as well as their interaction . Anticipation Anticipation is the fundamental projective dimension of human cognition , and a characteristic of expert behavior . For anticipation to be accurate , it requires a sufficient understanding of the situation at hand . As a form of feed - forward control , anticipation is especially critical to keep with the pace of events , by avoiding failures to adapt in time , before perturbations cascade . In the adversarial context of cyber security , anticipation means understanding and making projections regarding what the other side is targeting . In the context of cyber defense , this includes : - vulnerabilities , especially described in terms of targets and paths , - patterns of attack , in order to foresee particular elements of network activity ( and validate the current mental model of the situation ) , and 121 - the attackers’ intent , in order to identify their plan and specific targets of interest . On the defensive side , team members had an understanding of a variety of vulnerabilities and potential scenarios for attack ( e . g . , paths ) . As with competitive games such as chess , each of these vulnerabilities could be exploited by the attack , but the observation of traces of activity permits a narrowing down of the space of possibilities 4 . Discussions from within the Blue team regularly consisted of trying to anticipate what the attackers would do next , based on the defenders’ understanding of the situation . Typical examples of such discussions consisted of collaborative hypothesis exploration in front of the network map . One member would for instance explain how successions of vulnerabilities identified in assets’ and networks’ access constituted a path that the attacking team could follow to get from the outside to the sensitive assets in the process network . Such discussions would focus attention on the elements associated with the vulnerability path , especially for the Network Intrusion Detection sub - team in charge of monitoring network activity . 4 Note that games like chess do not constitute a very satisfactory analogy for cyber security , particularly because of core differences in terms of observability of the game and of asymmetries between each side . 122 Supporting cyber defense : The notion of path , whether a path actually taken by attackers or a potential path based on their current access , as well as network’s connectivity and vulnerabilities , constitutes an interesting leverage point to support anticipation in cyber defense . During the exercise , participants frequently made use of this characteristic of navigation in a network . However , they did so essentially in the form of temporary discussions based on knowledge constructed ‘in their head’ from mental simulations supported by the network map . In order to further support these processes , cognition could be distributed into other forms , in particular by giving cyber defenders the means to navigate the network in order to identify paths and capture those relevant to the situations at hand . Perception of intent Cyber security is an adversarial domain , which implies that participants are engaged in co - adaptive processes based on the perception of each other . In a study of how police officers conduct traffic stops , a potentially hostile and perilous situation , Zimmerman ( 2008 ) explains how these practitioners assess and make sense of the situations based on subtle “behavioral cues” . From these elements of activity , “the officer must derive the thoughts , motivation , plans and future actions of that person” . Based on the construction of this understanding , officers conduct their operations by building expectations and adapting their own behavior ( Zimmerman refers to the Data / Frame model , which is coherent with our description of sensemaking above ) . In this context , though , actors are in direct interaction with each other . Mundutéguy and Darses ( 2007 ) describe how more mundane driving situations involve ample anticipative and adaptive behavior based on the perception of others’ actions and inferences about their motives . 123 These inferences support the management of direct or indirect interactions , and are critical to driving safety . Several aspects of these situations are particularly noteworthy : - Adaptations will be based on these inferences , whether they are accurate or not ( a result also described in Trent et al . , 2009 in the context of intelligence analysis ) . - Especially when there is uncertainty about the other actors , their behavior will be interpreted in the light of stereotypes associated with the group ( s ) they seem to belong to ( a result long described in social psychology through attribution theory ) . - As with Zimmerman’s account above , the understanding constructed is transient and dynamic , and orients expectations and information seeking mechanisms . Similar mechanisms appear to be at play in the context of cyber security , but with important differences , especially in terms of observability ( or lack thereof ) : each side in cyber security can only observe traces or effects of behavior , not the behavior itself . As a whole , it is unsure whether we can talk about perception of intention in the case of Red’s perception of Blue’s actions . Data do not suggest that members of the Red team think of Blue in terms of strategy or adapt their own activity by projecting future defensive actions . They seem to mainly use their understanding of Blue’s operations to project their own actions , especially to anticipate losses of access and opportunities . The situation can be described from a defense perspective as a control problem where a primary goal is to avoid being outpaced by events . If the attacking team is given ample time without being hindered in their progress , it will be able to conduct a variety of actions , multiplying its opportunities to establish connections or compromise assets . Falling behind the curve therefore means that adverse events can grow exponentially into a cascade of disturbances that will spread thin defensive efforts and resources . This 124 also means that , for the defensive team , being in control requires responses based on the anticipation of Red’s actions . Unlike what was described about the Red team , data support the idea that the perception of the other team’s intention , because of its anticipatory nature , is a central element of network defense . 09 : 57 : 41 NIDS2 and NIDS3 see some activity on screen . NIDS1 looks from behind . He’s giving some hypotheses based on what activity looks like . “if you look at the payload , it’s just a joke” . He thinks that it could be a strategy to generate noise and obscure more important activity ( “obscure an important message from us” ) “The next 3 , they’re trying to tip over the web server itself or they might actually be generating a lot of noise…” Relative to the perception of intent and the corresponding challenges , the Blue and Red teams observed in the exercise appear to be in asymmetrical position : - It is an essential part of the Blue team’s need to identify and make sense of Red ' s behavior in order to adapt their defensive plan . - It is a more secondary concern for the Red team , which is more focused on exploring the network to fulfill their goals . Understanding Blue ' s behavior essentially serves to build explanations of difficulties to reach targets or lost connections . By itself , this asymmetry appears as a source of greater challenges for the defensive team . That being said , it is probably due to the fact that defense was primarily reactive during the exercise observed . If a team adopts a more elaborate adversarial defense strategy , it seems likely that the attacking team would face equivalent challenges that may hinder its progression . 125 Supporting cyber defense : previous sections have described how the attacking team is “fumbling about in the dark” ( see section 4 . 2 . 3 and introductory vignette ) and how this hinders their pursuit of strategic goals . An adversarial defensive strategy could consist of actively probing sources of suspicious activity . By giving the attacking team the impression that they have been detected , network defense would put them under pressure to act , thereby forcing them to reveal more of their presence ( or sacrifice it entirely ) 5 . Such a strategy essentially means taking advantage of the understanding of typical challenges of attack and of toughening their trade - offs . One difficulty would be to ensure that such a strategy does not compromise legitimate network usage , including network defense itself . Section 4 . 3 . 3 describes how the Blue team’s use of ARP - poisoning as an adversarial strategy created ambiguous network activity and was a source of confusion for the network analysts . 5 . 3 . 2 . Impact of event : adapting in a complex environment An important aspect of cyber defense is what exactly a cyber event ( real or perceived as such ) means in terms of threats to the mission and requirements for the response . This section will discuss various issues related to the difficult understanding of threats’ and response actions’ impact . 5 From the perspective of Signal Detection Theory , this corresponds to making weak signals standout more relative to the ‘noise’ of the environment ( separate further Noise and Signal + Noise curves ) , thereby reducing uncertainty . 126 Impact in a complex system and environment The complexity with which the Blue team needs to cope is two - fold : it exists in the network itself , i . e . , in the operational environment , but also in the response system , i . e . , within the defensive team and organization it belongs to . The general progression process of the Red team was described previously : access gained to a machine is a source of new opportunities to conduct intelligence or disruptive actions and to obtain further access . The numerous relationships between assets on the network , therefore , risk creating the conditions for a cascade of disturbances . On the other hand , these relationships are defined by network configuration and are part of the knowledge the defensive team possesses and maintains of the network . They correspond to path dependencies that can be utilized by defense to understand , anticipate and / or hinder the attack’s progress . A previous section describes how cyber defense is distributed and how this creates challenges for successfully coordinating operations among the team . However , authors note that neither guidelines , nor technology appropriately support the highly collaborative nature of cyber defense ( Werlinger et al . , 2010 ) . Part of the response to these challenges traditionally lies in the expertise of practitioners and such capacity is expected ( often implicitly ) by the organizations to which they belong . The management of functional interdependencies is a central issue identified by the framework of Resilience Engineering . One of the issues highlighted by the exercise concerns the scale of response to events , where ‘response’ is understood widely from the detection phase to the actual response . The central question is : what constitutes an appropriate unit of adaptive behavior , i . e . , what role ( s ) should be implicated in the response when an event occurs ? Team members might be involved because : 127 - they need to participate in the response because of their particular role and form of competence : to understand the nature of the event ( e . g . , correlation ) or to act upon it , - functional interdependencies require that they participate in a coordinated response , e . g . , to devise a common plan , or - they simply need to be informed : the event is of interest for their role ; their tasks are related to actions planned and will therefore experience effects from the response . Different types of events correspond to different demands in terms of scale of response , for which there is an appropriate match . The appropriateness of this match can be discussed in relation to the maladaptive patterns identified by Woods and Branlat ( 2011 ) . - If the scale is too small , i . e . , members of the team that should have been involved do not participate in the response : o uncoordinated parts of the system risk working at cross - purposes , and o larger phenomena might be missed , creating risks to adapt inappropriately or undermine the need to adapt ( risk of stale adaptive processes ) . - If the scale is too large , and all members participating in the response did not need to be involved , resources are unnecessarily committed and the system is slowed down by higher costs of coordination ( risk of falling behind the tempo if new disturbances arise ) . 128 Supporting cyber defense : The scale of response is an important determinant of the activity , and needs to be managed . It is an indicator of resilient or brittle adaptive process . Systems built around sharing all information with every single role commit a fallacy relative to this issue : they assume that , since people have ( technical ) access to information , they will see it and recognize that they are concerned by an event ( even when it is occurring outside of the regular boundaries of their role ) . Rather than relying on agents directly experiencing the event , it puts the burden of the choice of scale on the external agents and risks putting them in a situation of data overload . A more supportive approach would consist of highlighting interdependencies between roles , thus making them more visible . This would help agents understand the impact of their actions on other roles because of the functional relationships with these roles . Impact in a production environment Throughout the exercise , the Blue team tried to implement changes they thought were needed in order to respond to events they perceived . Due to the design of the exercise , they needed to produce ‘request for change’ forms that were transmitted , along with the evidence they had gathered , to the White cell , which represented the network owners . Almost systematically , changes were not implemented and the rejection was motivated by lack of sufficient evidence . In addition , such responses typically arrived after significant amounts of time had passed . During the process , mid - level management in the Blue team was busy transmitting requests and responses . They quickly experienced a workload bottleneck , when this became their primary task . This situation led them to abandon their roles as supervisors , who were supposed to keep track of the team’s progress and difficulties . The bottleneck illustrates issues associated with purely 129 hierarchical control structures : operators more directly in contact with the controlled process lack authority and autonomy , and the required transmission of information between layers of the system is inefficient and is a source of bottlenecks . Because of the limited window of opportunity the defensive team has in order to act upon detected adverse events , it is important that the decision making process occur without delay . Similarly to other domains related to emergency response , cyber defense would benefit from implementing polycentric control architectures ( Ostrom , 1999 ; Woods and Branlat , 2010 ) . This research emphasizes that lower echelons , through their more specific set of competences and direct contact with the controlled process than remote managers , develop a much finer knowledge of the process behavior . This knowledge allows them to detect anomalies early , thereby making them more able to adjust their actions to meet security or safety goals . That being said , both purely centralized and decentralized approaches are likely to fail ( Andersson and Ostrom , 2008 ) ; they simply fall victim to different forms of adaptive challenges . In the domain of cyber security , in particular , systematically reducing vulnerabilities identified is not a viable strategy since it threatens other , production - related , goals . Such decisions therefore need to result from negotiations that confront security and production goals . Discussions with cyber security experts revealed how the management of the security vs . production trade - off can be complicated by factors that are outside of the sole context of the event , and even counterintuitive . In some situations , security goals are purposefully abandoned to meet larger objectives . For instance , from the perspective of the CERT ( Computer Emergency Readiness Team ) , situations exist where organizations maintain open access in spite of their knowledge of on - going attacks . When attacks are unusual , sacrifices are made to allow more elaborate forensics and investigations to be 130 conducted ( e . g . , by FBI or others ) in order to learn from the events ( e . g . , about the attackers or about an innovative strategy ) . The knowledge produced serves the longer - term security goals of a larger community rather than an effective response to the unique events experienced . More commonly , the idea of systematically patching systems in the face of threats is far from obvious or convenient in actual production settings . Organizations typically use custom - designed applications to fulfill their particular needs . And often , these tailored applications have been developed on specific platforms at a given time and have hardly evolved since . Patching or updating the underlying platforms would risk preventing the applications from working correctly . For service purposes , organizations knowingly accept vulnerabilities associated with older platforms for which fixes exist . Since the time to actually address these vulnerabilities is typically long ( months or years are required to develop new versions of the custom applications ) , the cost of disruptions due to improper security is perceived as smaller than the cost associated with the disruption of services . Supporting cyber defense : Cyber defense requires the implementation of a polycentric decision architecture . Such an architecture empowers layers of the system in direct contact with the controlled process while more distant layers are in charge of both monitoring the evolution of the situation and the coordination of operations . In particular , the management of trade - offs between security and production goals needs to be the result of negotiation between these perspectives . Because of the complex nature of these trade - offs , negotiation processes need to be more direct and better supported , not simply through exchanges of information along the management line . 131 5 . 3 . 3 . Design seeds : collaborative network representation space So far , generic principles have been described that fit the cyber security domain . We can look at more specific design seeds in the context of cyber security . The network map offers an interesting leverage point . Arguably , expert network defense teams would know their network much better than the team we have observed , and , therefore , be in a better position to understand situations and respond appropriately . That being said , observations of non - domain specialists greatly emphasized the requirements and challenges associated with network knowledge . Applying classic principles of distributed cognition , it is valuable to rely on external cognitive support rather than solely on experts’ ‘knowledge in the head’ . As described in section 4 . 3 . 4 , the network map served as a key element of the “articulation of cooperative work” ( Schmidt , 1994a , 1994b ; Schmidt and Simonee , 1996 ) , i . e . , of the interaction processes necessary in the highly distributed work of cyber defense carried by the Blue team . The map provided support for the various “modes of interaction” , i . e . , “formation of reciprocal awareness” , “directing attention” and “negotiation” by facilitating the “confrontation and combination of perspectives” ( ibid . ) necessary to address the complexity of phenomena encountered and of operations . A shared digital network representation that would further support the defense and cooperative processes is , therefore , an interesting candidate for the exploration of design seeds to improve cyber defense . Multiple perspectives Schmidt ( 1994a ) describes the notion of perspective in the context of distributed work as “a particular – local and temporary – conceptualization of the field of work” . Multiple 132 perspectives are necessary to provide the diverse conceptual views ( structural and functional properties , representations ) of the multifaceted work situation . In other words , the different roles engaged in distributed operations , such as in cyber defense , are not all interested in and focused on the same aspects of the situation . Designing for multiple perspectives , therefore , requires taking into consideration the different goals , functions , information and representation requirements associated with various roles . Smith and colleagues ( Smith , et al . , 1995 ; Smith , et al . , 2007 ) have investigated this dimension of cooperative work in the domain of air traffic management , for which various entities involved in flight planning ( and replanning ) require different types and representations of information to carry out their respective tasks . A computer network and its activity are prime examples of complex phenomena that cannot be observed from a single ( all - encompassing ) perspective without risking committing oversimplifications ( Smith , Branlat , Stephens and Woods , 2008 ; Feltovich , Spiro and Coulson , 1989 ) . The network map used extensively by the Blue team during the exercise corresponds to one perspective focused on network configuration ( logical organization of networks , machines in sub - networks , machines’ IP addresses , firewall rules ) . However , numerous other aspects of the network and its assets were not represented , e . g . , physical location of machines , application versions , MAC addresses , volume of traffic , etc . Also , as a physical artifact , the network map essentially represented static information ; it is not adapted to the dynamic nature of network activity ( e . g . , traffic volume ) . Finally , the scale of the network ( the large amount of objects of interest ) calls for multiple representations at different levels of detail . Once again , no single perspective can simultaneously provide a general sense of information available and capture enough detail . Users of the representations need to be able to shift 133 between levels of detail and abstraction depending on their focus of attention and information needs ( Woods and Watts , 1997 ) . The different perspectives on the network represent different ways to characterize the information that a defending team might need to acquire during an event to conduct their operations . Since multiple perspectives cannot simply add to one another and can even conflict ( e . g . , physical location vs . logical organization of network assets , highly detailed view vs . global picture ) , it becomes necessary to have multiple representations for the various ways to visualize and seek information in the network . These representations can then constitute a space that needs to be organized in order to facilitate a meaningful navigation , i . e . , coherent transitions between perspectives ( Smith et al . , 2008 ) . As a collaborative space , attention must be given to means for interaction in order to support the confrontation of perspectives . The analysis of interactions around the network map ( see Section 4 . 3 . 4 ) highlighted the variety and importance of ways with which team members exchange information . Approaches might include ways to annotate representations , and ways to discuss visualizations remotely . During remote discussions , ways should be found to allow for actions similar to pointing and hand movements . On - going understanding and operations Supporting detection , investigation and collaboration processes could consist in representing within network visualizations the state of understanding as well as where operations are conducted . In the first case ( representing the state of understanding ) , a network map could for instance highlight where actions of attackers have been detected ( whether suspicious 134 and requiring investigation , or confirmed ) , i . e . , what assets appear to be targets of attacks or to host established connections . Also , a visualization of outside sources of suspicious activity would allow for confirmation processes to occur in time and throughout the team ( note that this means a different perspective , where the representation goes beyond the network boundaries ) . In the second case ( representing on - going operations ) , the objective would be to allow team members to visualize what actions ( e . g . , investigations ) they are conducting on the network in response to suspicious activity or to gather knowledge of vulnerabilities . Such information would be useful to limit coordination breakdowns and support the understanding of network activity . Also , seen in relation to the visualization described above , this would allow team members to identify areas that require attention ( e . g . , suspicious activity not investigated yet because resources are already committed on other tasks ) . Visualizing paths to understand potential impact The notion of path is an important dimension of network defense , characterizing both the attacking team’s progress and a potential sequence of actions they could take . Such information especially allows for the anticipation of suspicious activity and for the management of the team’s focus of attention . Supporting the construction and visualization of paths towards sensitive network assets would permit a more fruitful exploration of : - vulnerabilities in network configuration and assets , - potential targets based on current progress by attackers ( e . g . , what other assets are accessible from a given position ) , and 135 - impact of security measures on production - related services ( e . g . , verify that the transmission of service - related packet is still possible if changes are made ) . Critical limitations to this approach The first limitation results from the fact that enriching a space of network representations by providing multiple perspectives requires a great deal of knowledge capture . Moreover , it risks increasing significantly the difficulties in updating knowledge of the network ( especially since volatile type of information such as the representation of on - going operations was suggested ) . This therefore creates the need to simplify the knowledge capture process in order to avoid creating a workload bottleneck . Automating or semi - automating some of the processes of information retrieval and representation constitute potential directions to explore . The second limitation is an ironic consequence of the nature and use of a computer - supported technology that offers great capabilities . Because of the sensitivity of the information captured and potential capabilities , such technology becomes a highly valuable target in itself . Getting access to it ( trough a specific plan or by chance ) risks putting attackers at a serious advantage . Also , defense could become dependent on such capabilities and therefore greatly hindered if attackers managed to impair their use . 5 . 4 . Limitations of the research 5 . 4 . 1 . Methodology and data collected We were able to produce numerous notes and recordings of the exercise and document most of the activities . The recordings aimed at capturing elements representative of cognitive processes , such as communications , at the individual as well as at the team 136 levels . Extensive recordings seemed especially useful because of the inability to interview participants during or after the exercise . Unfortunately , the quality of the recordings was impaired by environmental conditions and relatively low - tech means available . In many cases , particularly for the fixed cameras , the audio is simply unusable due to the amount of conversation and / or distance between people and the microphone . Background noise was especially difficult to avoid in the Blue space , which was less contained than the Red room . Recordings also depended on data collection choices made a priori , based on expectations concerning where and when relevant activity would occur ( e . g . , collaborative phases ) . The positioning of a fixed camera captures a specific visual perspective that depends on room space , location of camera and camera angle . For instance , the camera in the Network room was repositioned after a few hours when it became clear that the network map was going to be a critical artifact in the defense activity . As a result , it is possible to see how central the map is , but other interesting sources of activity are obscured , such as actions on the Intrusion Detection Systems . In the end , adopting a specific viewpoint for a long period of time is a compromise between multiple , potentially conflicting , objectives of the investigation . In general , observers experienced difficulties to focus attention . Observers , especially in the Blue space , were experiencing data overload . The novel nature of the study , relative unfamiliarity with the situations observed and unobservable nature of many of the processes at play sometimes impaired our capacity to direct our attention to what mattered . Both of these points illustrate that data gathering is victim of the fundamental efficiency - thoroughness trade - off ( Hollnagel , 2009 ) . 137 5 . 4 . 2 . Findings Observer’s perspective : the Network sub - team I was personally in the Network room most the time . The findings regarding cyber defense described previously therefore partially result from what I was able to observe and understand during the exercise : they are mostly focused on network issues . While the activity in the network room is central to the larger defense effort , activity of participants in the other rooms and their relation to network analysis are important contributors to defense processes . Conversations with cyber security experts emphasized the criticality of correlation processes in network defense , a point also made in various publications ( e . g . , Krueger et al . , 2005 ) . Such processes are a typical way in which analysts reduce the uncertainty associated with elementary traces of suspicious activity , by logically associating isolated elements into a coherent whole indicating an attack ( such as a known pattern of attack ) . This document describes aspects of these critical interdependent processes , but does not fully explain how other groups of the Blue team fulfilled their various roles . Exercise as a basis for the study of cyber security This exercise constituted one particular instance of a cyber event . Real - world working conditions are extremely diverse ; they range from the type of large - scale networks exemplified by the exercise , to smaller and less critical networks in which only a few individuals ( sometimes one person ) are in charge of all the network support . This can change significantly the decision - making processes and management of uncertainty , whether related to sensemaking processes or to decisions on actions to implement in the 138 face of threats . Important issues of authority or autonomy are experienced quite differently across situations . While the exercise constituted a high - fidelity simulation at many levels and involved real cyber attack and defense , other dimensions do not reflect real - world conditions . First , we were interested in modeling network defense expertise . But the exercise’s participants were not domain experts , although most had significant domain - relevant knowledge . Additionally , the tempo of the exercise was a result of practical training constraints . The tempo of real attacks varies from minutes or hours to weeks or months , depending on factors such as motivation and skill level of attackers , and level of vulnerability of the network . Also , attackers often operate during times of lower activity , such as night shifts , during which resources for defense are more scarce and the management is often absent , and thus unable to help with strategic decisions . Another important difference lies in the knowledge the defending team has of its network at the beginning of the exercise compared with real network security experts . Usually , these experts have a significant familiarity with the network they protect , although this familiarity has limitations . Such knowledge allows them to identify unusual network traffic much more efficiently than the participants we observed ( Goodall et al . , 2004 ) . The emphasis on network discovery in our description is therefore debatable ( recent conversations with cyber security experts suggest that it is reasonable to assume a large part of a network is unknown in large networks – hence needs in discovery processes – though much less in smaller organizations ) . Finally ( but this list is not exhaustive ) , we were only observers of the exercise and had no control over the events . We were not in a situation to test hypotheses by introducing probing mechanisms , as is usually possible in staged - world studies . More particularly , 139 the ‘informativeness’ of such exercises is very dependent on the participants because , ultimately , it is their actions and decisions that shape the nature and unfolding of the event , not a pre - established scenario ( although guidance from training supervisors balanced this to some extent ) . Importantly , the main objectives of the exercise are about supporting participants’ learning and higher awareness of cyber security issues . The exercise is not designed to facilitate the analysis of cyber events ( attack or defense behavior ) . Our findings are based on the observations captured and are therefore influenced by their characteristics , i . e . , their value as well as their limitations . In spite of the limitations described above , our results are coherent with results presented in the literature ; they also expand them and place them in larger theoretical frameworks from which the study of cyber security is likely to benefit . 5 . 5 . Moving forward : conditions and choices for future studies One of the primary goals of the study and of this dissertation is to document and use this experience for future studies , both from a methodological and a theoretical standpoint . This section presents what could be done , in my mind , to further investigate the domain of cyber security and reduce or avoid the limitations described above . 5 . 5 . 1 . Type of study As an observational study of an exercise , which we did not design , this research is descriptive by nature . But descriptive approaches are not sufficient : other forms of work analysis should be implemented to complement and contrast the findings described in the literature and in this document ( Potter , Roth , Woods and Elm , 2000 ) . 140 When possible , interviews are a convenient means to collect valuable data , since they do not require elaborate settings . In order not to repeat studies based on semi - structured interviews , a first approach could consist of using knowledge elicitation methods such as walkthroughs or critiquing techniques ( Miller , Patterson and Woods , 2006 ; Mollo and Falzon , 2004 ) . In the first case , domain experts could be walked through a particular event and asked to explain what they would do as the situation unfolds . This method facilitates gathering aspects of decision - making such as information requirements and potential challenges . In the second case , the event and the response of the defensive side could be presented as a whole , and experts would be asked to react from their perspective as to how the situation was managed . An issue with this technique , as opposed to the first one , is that giving insight about the outcome of the event can orient participants’ judgment of the performance . A solution would be to give only a partial description of events , in a way that combines both methods . More observational studies of cyber defense ( or cyber security in general ) are nonetheless needed . As with other sensitive and / or low - predictability domains , real events are likely to be difficult to observe . In particular , it seems difficult to observe the activity of a real team of hackers . It therefore seems valuable to follow a stage - world study approach typical of Cognitive Systems Engineering ( Woods and Hollnagel , 2006 , Chap . 5 ; Voshell and Woods , 2009 ) , which would consist of conducting investigations through experiments designed to favor ecological validity of the critical domain dimensions described throughout the document . Results from our investigations stress the importance of scale ( system , time ) on validity , in particular of the large spectrum of network defense functions and processes . Additionally , production pressure is an essential element of network security , since the network primarily exists to support 141 services ( as with safety , security is not really a priority , but rather a desirable characteristic ) . Also , cyber security is adversarial by nature , and this constitutes a fundamental requirement for any research study that would like to investigate co - adaptive attack and defense processes . Finally , to address the trade - off between expert and non - expert participants ( see section 5 . 1 . 2 ) , an interesting solution would be an intermediary situation where teams are constituted of a mix of both types of expertise level . This was partially the case in the exercise we observed , since some participants had pre - existing knowledge of cyber security . In the Network room , for instance , a member of the Intrusion Detection Systems group had some familiarity with the processes and tools of intrusion detection . As a result , other group members frequently checked with him as to what they were observing and interpreting of network activity . Such exchanges were very valuable to us and provided insights into the activity of these members . The exercise observed here could serve as a baseline scenario for the different types of methods outlined above , either more or less directly or in order to craft fictional scenarios that could be used as alternatives during experimentations . 5 . 5 . 2 . Improving data collection This research has relied on communications as the primary data for analysis , and data collection was designed accordingly while addressing constraints of the situation . Given that more observational studies are needed , potentially in more controlled settings , this section aims at describing what would constitute valuable information for a similar simulation . 142 Before the simulation starts Before observing groups such as Network analysis teams , one should be familiar with the network environment ( IDS applications , network itself , etc . ) in order to better identify and understand what they struggled with and focused on . In particular , such a pre - existing knowledge would support more accurate interpretations of communications that are often laconic ( e . g . , IP address to designate a particular machine and the corresponding services ) . Also , understanding what the Blue team perceives or not from the Red team’s activity necessitates knowing how they could be detected ( e . g . , their IPs ) . A solid initial understanding of each person ' s role also facilitates observations and making sense of participants’ actions . In our case , it was largely reconstructed from observations and recordings after the fact ( sometimes only partially and with difficulty ) . Note that this was the case for initial tasks , though , rather than roles for the day . If possible , it would be valuable to negotiate in advances the conduction of limited interviews during the exercise . These verbal protocols would allow experimenters to capture more targeted elements related to decision - making and reduce the ambiguity or uncertainty of observations . During the simulation During early observations , it is important to further capture roles quickly to better make sense of behavior and decisions ( and better direct attention to what matters ) . Initial hours , before events fully unfold , seem favorable : participants appear more laid - back , there is more potential to interrupt , interruptions have only minor consequences , and participants are not yet too committed . Also , providing a rich base knowledge of roles and tasks helps understand how roles evolve throughout the event . This evolution is 143 likely to be indicative of demands , especially unanticipated . If concurrent interviews were agreed upon , they can be restricted to the roles that are more prominently in charge . Judging by our observations , such people are not numerous and are rapidly identifiable . Moments of lull usually constitute appropriate times to question these participants . In order to capture communications , better quality audio recordings are critical . This may mean having better equipment , but , more importantly , this means placing microphones more appropriately . In particular , due to the potential for parallel conversations to occur , multiple microphones can help cover a room better . In the Red space , for instance , analyses would have benefitted from having two microphones , one of each corner of the room . Interestingly , video capture is also very helpful to analyze audio recordings : it helps identify who is speaking to whom , who pays attention to the conversation , etc . Such elements are critical for analyses in highly collaborative environments , but they are harder , if not impossible , to gather from the audio only . Targeted video is valuable for interactions around particular artifacts such as computer screens or the network map . Without such means , many important interactions were missed in the Red space because of the fixed perspective of the camera . Besides communications , more traces of activity would have constituted valuable information . This is especially true of the attacking team’s activity because it represented the baseline against which the relevance , effectiveness or limitations of the Blue team’s actions could be understood . For instance , some of the Red team’s intelligence actions were captured through dialog . But members didn ' t necessarily communicate extensively about what intelligence they were conducting ( they did when they were successful , and 144 access - related events seem to have generated more verbalization ) . Unfortunately , basic computer logs could be quite overwhelming . After the simulation To complement the data gathered and the initial insights from observations , interviews of targeted roles ( as described above ) are valuable . The latter could take the form of a hotwash immediately following the simulation . Representations such as those presented in the previous chapter could be generated semi - automatically from the traces of activity . Experimenters would have to identify the most relevant traces and , importantly , the relationships . Being able to build such a representation early in the analytical process would help generate a general understanding of the way events unfolded , in order to make sense of actions and decisions on both sides . 5 . 5 . 3 . Themes of investigation The research conducted confirmed the relevance of some of the initial themes of investigation and uncovered new directions for future research . The highly collaborative nature of cyber defense makes the domain a very rich field of investigation for distributed anomaly response . The interesting dimensions of anomaly response in the cyber security exercise include : - Types of cooperative activity ( working according to roles – synchronization – collaborative problem solving ) and management of transitions between them 6 . 6 This theme stems from unpublished research initiated by D . Woods , P . Smith , M . Branlat and A . Morison in the context of disaster response . Simulation settings such as the one described in this document and the general domain of network security appear as interesting candidates for its 145 - Scale of response : this is an aspect of the management of functional interdependencies relative to the demands faced by the system . Ultimately , it is about what constitutes appropriate units of adaptation for the situations encountered . As such , it appears as a potential control parameter for the development of resilient control architectures . The recent framework of Resilience Engineering could be further developed through studies of cyber security because of core characteristics of the domain : - Its adversarial nature makes it a prime candidate for studies of co - adaptive processes . Although the scale of the exercise was challenging , it was still very manageable compared to more traditional adversarial domains such as military operations or foreign policy . Investigations of adversarial interplay serve theoretical purposes , but could also generate interesting paths to improve cyber defense by better including these notions into defense strategies and technological support . - In part , the exercise and the difficulties of the defensive team within the general organizational context illustrated challenges associated with purely hierarchical decision structures , and the failure to implement polycentric control ( Woods and Branlat , 2010 ) . In relation to the two themes above , means to implement and support polycentric control could be investigated through similar studies . - Finally , more resilient networks could also be networks that are easier to reconfigure in order to pursue ( or momentarily sacrifice ) the provision of their core services when faced with disruptive events . This capability requires two capacities that could constitute themes of investigation : detailed exploration , but the data gathered in this study did not afford an opportunity to pursue this direction . 146 o the capacity to evaluate the impact of events on the networks’ core missions , and o margins of maneuver ( Woods and Branlat , 2011 ) , for instance to bring new resources to bear or to modify mission priorities . 5 . 6 . Concluding remarks The study is an exploration of the domain of cyber security from a human - centered perspective . While many researchers have previously studied aspects of decision - making in cyber security , research covering a similar scope as the one presented in this document , studying cyber security as a whole , is severely lacking ( or is not easily available ) . In spite of the limitations described above , the research documented here emphasizes important characteristics of the domain that are under - represented in the literature : - cyber security is adversarial , - cyber security is highly collaborative , and - cyber security occurs in an operational environment where it is not the first priority , but a highly desired feature of a larger system pursuing production goals with which it can conflict . These core characteristics are especially important on the defensive side . Consideration of these dimensions is needed in order to develop further knowledge of the domain , and design and conduct future studies . Overlooking or oversimplifying them risks undermining results obtained . However , integrating these dimensions is challenging , from the design of a study to the analysis and interpretation of its results . We were fortunate to benefit from the ability of domain experts to set up a rich and coherent 147 simulation environment . The study was initiated with wide themes of investigation in mind , in a way that was probably too ambitious . As the analysis progressed , the focus shifted more and more towards methodological issues as revealed by the difficulties encountered in relation to the data captured : - How can data be captured at such a scale to support the investigation ? - How can the analysis proceed to address the scale of operations and parallel activities ? - How can an account of the events observed be created to reveal their complexity while being usable ? This dissertations describes the successes and pitfalls associated with the choices made in the research . While the data captured did not allow for a detailed investigation of all the themes initially envisioned , the results still confirmed their relevance . The methodological insights developed here can serve future purposes to better address these important questions . The domain of cyber security is challenging but appears particularly rich to further develop knowledge of numerous classic Cognitive Systems Engineering and advance the newer Resilience Engineering agenda . 148 References Allen , J . , Christie , A . , Fithen , W . , Mchugh , J . , Pickel , J . , & Stoner , E . ( 2000 ) . State of the Practice of Intrusion Detection Technologies ( CMU / SEI - 99 - TR - 028 , CMU / SEI ) . Pittsburgh , PA : Software Engineering Institute , Carnegie Mellon University . Andersson , K . , & Ostrom , E . ( 2008 ) . Analyzing decentralized resource regimes from a polycentric perspective . Policy Sciences , 41 ( 1 ) , 71 - 93 . Arbaugh , W . , Fithen , W . , & McHugh , J . ( 2000 ) . Windows of vulnerability : a case study analysis . Computer , 33 ( 12 ) , 52 - 59 . Bace , R . G . , & Mell , P . ( 2001 ) . Intrusion detection systems . Gaithersburg , MD : U . S . Dept . of Commerce , Technology Administration , National Institute of Standards and Technology . Bainbridge , L . ( 1983 ) . Ironies of automation . Automatica , 19 ( 6 ) , 775 - 780 . Biros , D . P . , & Eppich , T . ( 2001 ) . Human Element Key to Intrusion Detection . Signal , 55 ( 12 ) , 31 – 34 . Botta , D . , Muldner , K . , Hawkey , K . , & Beznosov , K . ( 2010 ) . Toward understanding distributed cognition in IT security management : the role of cues and norms . Cognition , Technology & Work , 13 ( 2 ) , 121 - 134 . Botta , D . , Werlinger , R . , Gagné , A . , Beznosov , K . , Iverson , L . , Fels , S . , & Fisher , B . ( 2007 ) . Towards understanding IT security professionals and their tools . Proceedings of the 149 3rd symposium on Usable privacy and security , SOUPS ’07 ( pp . 100 – 111 ) . New York , NY , USA : ACM . Branlat , M . ( 2009 ) . Developing the resilience of fire operations : a study of accident investigation reports . Columbus , OH : Cognitive Systems Engineering Laboratory , Institute for Ergonomics , The Ohio State University . Prepared for the Fire Department of New York . Branlat , M . , Anders , S . , Woods , D . D . , & Patterson , E . S . ( 2008 ) . Detecting an Erroneous Plan : Does a System allow for Effective Cross - Checking ? In E . Hollnagel , C . P . Nemeth , & S . W . A . Dekker ( Eds . ) , Resilience Engineering Perspectives : Remaining Sensitive to the Possibility of Failure ( pp . 247 - 258 ) . Adelshot , UK : Ashgate . Branlat , M . , Fern , L . , Voshell , M . , & Trent , S . ( 2009 ) . Understanding Coordination Challenges in Urban Firefighting : A Study of Critical Incident Reports . In Proceedings of the 52nd Annual Meeting of the Human Factors and Ergonomics Society . San Antonio , TX , Oct . 2009 . Branlat , M . , Morison , A . M . , Finco , G . J . , Gertman , D . I . , Le Blanc , K . , & Woods , D . D . ( 2011 ) . A study of adversarial interplay in a cybersecurity event . In S . M . Fiore & M . Harper - Sciarini ( Eds . ) , Proceedings of the 10th International Conference on Naturalistic Decision Making ( NDM 2011 ) . May 31st to June 3rd , 2011 , Orlando , FL . Orlando , FL : University of Central Florida . Canavan , J . E . ( 2001 ) . Fundamentals of Network Security . Artech House telecommunications library . Boston : Artech House . 150 Cheswick , W . R . , Bellovin , S . M . , & Rubin , A . D . ( 2003 ) . Firewalls and Internet Security : Repelling the Wily Hacker . Addison - Wesley professional computing series ( 2nd ed . ) . Boston : Addison - Wesley . Christoffersen , K . , Woods , D . , & Blike , G . ( 2007 ) . Discovering the events expert practitioners extract from dynamic data streams : the modified unit marking technique . Cognition , Technology & Work , 9 ( 2 ) , 81 - 98 . Clarke , R . A . , & Knake , R . ( 2010 ) . Cyber War : The Next Threat to National Security and What to Do About It ( First Edition . ) . Ecco . Cooke , N . J . ( 2002 ) . Team Communication Analysis : Exploiting the Wealth . Human Factors and Ergonomics Society Annual Meeting Proceedings , 46 , 289 . Cooke , N . J . , Salas , E . , Kiekel , P . A . , & Bell , B . ( 2004 ) . Advances in Measuring Team Cognition . In E . Salas & S . M . Fiore ( Eds . ) , Team cognition : understanding the factors that drive process and performance ( pp . 83 - 106 ) . Washington , DC : American Psychological Association . D’Amico , A . , Goodall , J . , Tesone , D . , & Kopylec , J . ( 2007 ) . Visual Discovery in Computer Network Defense . Computer Graphics and Applications , IEEE , 27 ( 5 ) , 20 - 27 . D’Amico , A . , Whitley , K . , Tesone , D . , O’Brien , B . , & Roth , E . ( 2005 ) . Achieving cyber defense situational awareness : a cognitive task analysis of information assurance analysts . Human Factors and Ergonomics Society Annual Meeting Proceedings ( Vol . 49 , pp . 229 – 233 ) . 151 D’Amico , A . , & Whitley , K . ( 2008 ) . The Real Work of Computer Network Defense Analysts . In VizSEC 2007 : Proceedings of the Workshop on Visualization for Computer Security . Springer - Verlag , Sacramento , CA . Dekker , S . ( 2003 ) . Failure to adapt or adaptations that fail : contrasting models on procedures and safety . Applied Ergonomics , 34 ( 3 ) , 233 - 238 . Falzon , P . ( 1991 ) . Cooperative dialogues . In J . Rasmussen , B . Brehmer , & J . Leplat ( Eds . ) , Distributed decision making : Cognitive models for cooperative work ( pp . 145 - 190 ) . Chichester , UK : Wiley . Falzon , P . ( 1994 ) . Dialogues fonctionnels et activité collective [ Functional Dialogues and Collective Activities ] . Le Travail Humain , 57 ( 4 ) , 299 - 312 . Feltovich , P . J . , Spiro , R . J . , & Coulson , R . L . ( 1989 ) . The Nature of Conceptual Understanding in Biomedicine : The Deep Structure of Complex Ideas and the Development of Misconceptions . In D . Evans & V . Patel ( Eds . ) , Cognitive Science in Medicine : Biomedical Modeling . Cambridge , MA : MIT Press . Finco , G . , Lee , K . , Miller , G . , Tebbe , J . , & Wells , R . ( 2007 ) . Cyber Security Procurement Language for Control Systems Version 1 . 6 . INL Critical Infrastructure Protection / Resilience Center , Idaho Falls , USA . Goodall , J . R . ( 2008 ) . Introduction to Visualization for Computer Security . In J . R . Goodall , G . Conti , & K . Ma ( Eds . ) , VizSEC 2007 : Proceedings of the Workshop on Visualization for Computer Security ( pp . 1 - 17 ) . Berlin , Heidelberg : Springer . 152 Goodall , J . R . , Lutters , W . G . , & Komlodi , A . ( 2004 ) . I know my network . In Proceedings of the 2004 ACM conference on Computer supported cooperative work - CSCW ' 04 ( p . 342 ) . Presented at the 2004 ACM conference , Chicago , Illinois , USA . Guérin , F . , Laville , A . , Daniellou , F . , Duraffourg , J . , & Kerguelen , A . ( 2007 ) . Understanding and transforming work . The practice of ergonomics . Paris , France : ANACT . Guerlain , S . A . , Smith , P . J . , Obradovich , J . H . , Rudmann , S . , Strohm , P . , Smith , J . W . , Svirbely , J . , et al . ( 1999 ) . Interactive Critiquing as a Form of Decision Support : An Empirical Evaluation . Human Factors : The Journal of the Human Factors and Ergonomics Society , 41 ( 1 ) , 72 - 89 . Hawkey , K . , Muldner , K . , & Beznosov , K . ( 2008 ) . Searching for the Right Fit : Balancing IT Security Management Model Trade - Offs . IEEE Internet Computing , 12 ( 3 ) , 22 - 30 . Hollnagel , E . ( 2009 ) . The ETTO Principle : Efficiency - Thoroughness Trade - Off - Why Things That Go Right Sometimes Go Wrong . Farnham , UK : Ashgate . Hollnagel , E . , & Woods , D . D . ( 2005 ) . Joint Cognitive Systems : Foundations of Cognitive Systems Engineering . Boca Raton , FL : Taylor & Francis / CRC Press . Hollnagel , E . , Woods , D . D . , & Leveson , N . ( Eds . ) . ( 2006 ) . Resilience Engineering : Concepts and Precepts . Adelshot , UK : Ashgate . Hughes , J . , King , V . , Rodden , T . , & Andersen , H . ( 1994 ) . Moving out from the control room . Proceedings of the 1994 ACM conference on Computer supported cooperative work – CSCW ’94 ( pp . 429 - 439 ) . Chapel Hill , NC , 1994 . 153 Hutchins , E . , & Klausen , T . ( 1996 ) . Distributed cognition in an airline cockpit . In Y . Engeström & D . Middleton ( Eds . ) , Cognition and Communication at Work ( pp . 15 - 34 ) . Cambridge , UK : Cambridge University Press . INL ( 2008 ) . Common Cyber Security Vulnerabilities Observed in Control System Assessments by the INL NSTB Program ( No . INL / EXT - 08 - 13979 ) . Idaho Falls , ID : Idaho National Laboratory . Prepared for the U . S . Department of Energy . Jajodia , S . , Liu , P . , Swarup , V . , & Wang , C . ( Eds . ) . ( 2010 ) . Cyber Situational Awareness : Issues and Research . Advances in Information Security ( Vol . 46 ) . New York , NY : Springer . Jervis , R . ( 2002 ) . Signaling and perception : Drawing inferences and projecting images . In K . R . Monroe ( Ed . ) , Political psychology ( pp . 293 – 314 ) . Mahwah , NJ : Lawrence Erlbaum . Jonsson , E . , & Olovsson , T . ( 1997 ) . A Quantitative Model of the Security Intrusion Process Based on Attacker Behavior . IEEE Transactions on Software Engineering , 23 , 235 – 245 . Klein , G . A . , Feltovich , P . J . , Bradshaw , J . M . , & Woods , D . D . ( 2005 ) . Common ground and coordination in joint activity . In W . B . Rouse & K . R . Boff ( Eds . ) , Organizational simulation ( pp . 139 - 184 ) . Hoboken , N . J . : Wiley - Interscience . Klein , G . , Moon , B . , & Hoffman , R . R . ( 2006 ) . Making Sense of Sensemaking 2 : A Macrocognitive Model . Intelligent Systems , IEEE , 21 ( 5 ) , 88 - 92 . Klein , G . , Pliske , R . , Crandall , B . , & Woods , D . D . ( 2005 ) . Problem detection . Cognition , Technology & Work , 7 ( 1 ) , 14 - 28 . 154 Kruegel , C . , Valeur , F . , & Vigna , G . ( 2005 ) . Intrusion detection and correlation : challenges and solutions . New York , NY : Springer . Lagadec , P . ( 2009 ) . A New Cosmology of Risks and Crises : Time for a Radical Shift in Paradigm and Practice . Review of Policy Research , 26 ( 4 ) , 473 - 486 . Miller , J . E . , Patterson , E . S . , & Woods , D . D . ( 2006 ) . Elicitation by Critiquing as a Cognitive Task Analysis Methodology . Cognition , Technology , and Work , 8 , 1 - 13 . Mollo , V . , & Falzon , P . ( 2004 ) . Auto - and allo - confrontation as tools for reflective activities . Applied Ergonomics , 35 ( 6 ) , 531 - 540 . Mundutéguy , C . , & Darses , F . ( 2007 ) . Perception et anticipation du comportement d’autrui en situation simulée de conduite automobile [ Perception and anticipation of others’ behaviour in a simulated car driving situation ] . Le Travail Humain , 70 ( 1 ) , 1 . Ostrom , E . ( 1999 ) . Coping with Tragedies of the Commons . Annual Reviews in Political Science , 2 ( 1 ) , 493 - 535 . Patterson , E . S . , Watts - Perotti , J . , & Woods , D . D . ( 1999 ) . Voice loops as coordination aids in space shuttle mission control . Computer Supported Cooperative Work : CSCW : An International Journal , 8 ( 4 ) , 353 - 71 . Patterson , E . S . , & Woods , D . D . ( 2001 ) . Shift Changes , Updates , and the On - Call Architecture in Space Shuttle Mission Control . Computer Supported Cooperative Work ( CSCW ) , 10 ( 3 ) , 317 - 346 . Patterson , E . S . , Woods , D . D . , Cook , R . I . , & Render , M . L . ( 2007 ) . Collaborative cross - checking to enhance resilience . Cognition , Technology & Work , 9 ( 3 ) , 155 - 162 . 155 Potter , S . , Roth , E . M . , Woods , D . D . , & Elm , W . C . ( 2000 ) . Bootstrapping multiple converging cognitive task analysis techniques for system design . In J . M . Schraagen , S . F . Chipman , & V . L . Shalin ( Eds . ) , Cognitive task analysis ( pp . 317 - 340 ) . Mahwah , NJ : Lawrence Erlbaum Associates , Inc . Reason , J . T . ( 1990 ) . Human Error . Cambridge [ England ] : Cambridge University Press . Schmidt , K . ( 1994a ) . Cooperative work and its articulation : Requirements for its Computer Support . Le Travail Humain , 57 ( 4 ) , 345 – 366 . Schmidt , K . ( 1994b ) . Modes and mechanisms of interaction in cooperative work ( No . DK - 666 ) . Roskilde , Denmark : Risø National Laboratory . Schmidt , K . , & Simonee , C . ( 1996 ) . Coordination mechanisms : Towards a conceptual foundation of CSCW systems design . Computer Supported Cooperative Work ( CSCW ) , 5 ( 2 - 3 ) , 155 - 200 . Siegel , D . A . , Reid , B . , & Dray , S . M . ( 2006 ) . IT security : protecting organizations in spite of themselves . interactions , 13 , 20 – 27 . doi : 10 . 1145 / 1125864 . 1125885 Smith , P . J . , Geddes , N . D . , & Beatty , R . ( 2008 ) . Human - centered design of decision support systems . In A . Sears & J . A . Jacko ( Eds . ) , Handbook of Human - Computer Interaction ( 2nd ed . ) . Mahwah , NJ : Lawrence Erlbaum Associates . Smith , P . J . , McCoy , C . E . , & Layton , C . ( 1997 ) . Brittleness in the design of cooperative problem - solving systems : The effects on user performance . IEEE Transactions on Systems , Man and Cybernetics , Part A , 27 ( 3 ) , 360 - 371 . Smith , P . J . , McCoy , E . , Orasanu , J . , Billings , C . , Denning , R . , Rodvold , M . , Van Horn , A . , et al . ( 1995 ) . Cooperative problem - solving activities in flight planning and 156 constraints for commercial aircraft . In IEEE International Conference on Systems , Man and Cybernetics , 1995 . Intelligent Systems for the 21st Century ( Vol . 5 , pp . 4563 - 4568 vol . 5 ) . Smith , P . J . , Spencer , A . , & Billings , C . ( 2007 ) . Strategies for designing distributed systems : case studies in the design of an air traffic management system . Cognition , Technology & Work , 9 ( 1 ) , 39 - 49 . Tadda , G . ( 2008 ) . Measuring performance of cyber situation awareness systems . In Information Fusion , 2008 11th International Conference on ( pp . 1 - 8 ) . Trent , S . A . , Patterson , E . S . , & Woods , D . D . ( 2007 ) . Challenges for cognition in intelligence analysis . Journal of Cognitive Engineering and Decision Making , 1 ( 1 ) , 75 – 97 . Trent , S . A . , Smith , M . W . , Zelik , D . , Grossman , J . , & Woods , D . D . ( 2009 ) . Reading Intent and Other Cognitive Challenges in Intelligence Analysis . In R . McDermott & L . Allender ( Eds . ) , Advanced Decision Architectures for the Warfigher : Foundations and Technology ( pp . 307 - 321 ) . Partners of the Army Research Laboratory Advanced Decision Architectures Collaborative Technology Alliance . Voshell , M . , & Woods , D . D . ( 2009 ) . P lanning Support for Running Large Scale Exercises as Learning Laboratories . Columbus , OH : Cognitive Systems Engineering Laboratory , Institute for Ergonomics , The Ohio State University . Prepared for the Army Research Laboratory . Weick , K . E . , & Sutcliffe , K . M . ( 2001 ) . Managing the Unexpected : Assuring High Performance in an Age of Complexity ( 1st ed . ) . Jossey - Bass . 157 Werlinger , R . , Hawkey , K . , & Beznosov , K . ( 2009 ) . An integrated view of human , organizational , and technological challenges of IT security management . Information Management & Computer Security , 17 ( 1 ) , 4 - 19 . Werlinger , R . , Hawkey , K . , Botta , D . , & Beznosov , K . ( 2009 ) . Security practitioners in context : Their activities and interactions with other stakeholders within organizations . International Journal of Human - Computer Studies , 67 ( 7 ) , 584 - 606 . Werlinger , R . , Muldner , K . , Hawkey , K . , & Beznosov , K . ( 2010 ) . Preparation , detection , and analysis : the diagnostic work of IT security incident response . Information Management & Computer Security , 18 ( 1 ) , 26 - 42 . Woods , D . D . ( 1993 ) . Process - tracing methods for the study of cognition outside of the experimental psychology laboratory . In G . A . Klein , J . Orasanu , R . Calderwood , & C . E . Zsambock ( Eds . ) , Decision making in action : Models and methods ( pp . 228 - 251 ) . Norwood , N . J . : Ablex Publishing Corporation . Woods , D . D . ( 2009 ) . Escaping failures of foresight . Safety Science , 47 ( 4 ) , 498 - 501 . Woods , D . D . , & Branlat , M . ( 2010 ) . Hollnagel’s test : being ‘in control’ of highly interdependent multi - layered networked systems . Cognition , Technology & Work , 12 ( 2 ) , 95 - 101 . Woods , D . D . , & Branlat , M . ( 2011 ) . Basic Patterns in How Adaptive Systems Fail . In E . Hollnagel , J . Pariès , D . D . Woods , & J . Wreathall ( Eds . ) , Resilience Engineering in Practice ( pp . 127 - 144 ) . Farnham , UK : Ashgate . Woods , D . D . , Dekker , S . W . A . , Cook , R . I . , Johannesen , L . L . , & Sarter , N . B . ( 2010 ) . Behind Human Error ( 2nd Edition ) . Aldershot , UK : Ashgate . 158 Woods , D . D . and Grossman , J . ( 2002 ) . Performance Experts in Safety ( PEXiS ) : Behind Human Error ( see Get Started / The W - hole Exercise ) . Electronic course . Available at url : http : / / csel . eng . ohio - state . edu / productions / pexis Woods , D . D . , & Hollnagel , E . ( 2006 ) . Joint Cognitive Systems : Patterns in Cognitive Systems Engineering . Boca Raton , FL : Taylor & Francis / CRC Press . Woods , D . D . , & Shattuck , L . G . ( 2000 ) . Distant Supervision – Local Action Given the Potential for Surprise . Cognition , Technology & Work , 2 ( 4 ) , 242 - 245 . Woods , D . D . , & Watts , J . C . ( 1997 ) . How Not To Have To Navigate Through Too Many Displays . In M . G . Helander , T . K . Landauer , & P . Prabhu ( Eds . ) Handbook of Human - Computer Interaction , 2nd edition . Amsterdam , The Netherlands : Elsevier Science . Zimmerman , L . A . ( 2008 ) . Making Sense of Human Behavior : Explaining How Police Officers Assess Danger During Traffic Stops . In J . M . Schraagen , L . Militello , T . Ormerod , & R . Lipshitz ( Eds . ) , Naturalistic Decision Making and Macrocognition ( pp . 121 - 140 ) . Aldershot , England : Ashgate .