Multi - Task Identiﬁcation of Entities , Relations , and Coreference for Scientiﬁc Knowledge Graph Construction Yi Luan Luheng He Mari Ostendorf Hannaneh Hajishirzi University of Washington { luanyi , luheng , ostendor , hannaneh } @ uw . edu Abstract We introduce a multi - task setup of identifying and classifying entities , relations , and coref - erence clusters in scientiﬁc articles . We cre - ate S CI ERC , a dataset that includes annota - tions for all three tasks and develop a uni - ﬁed framework called Scientiﬁc Information Extractor ( S CI IE ) for with shared span rep - resentations . The multi - task setup reduces cascading errors between tasks and leverages cross - sentence relations through coreference links . Experiments show that our multi - task model outperforms previous models in scien - tiﬁc information extraction without using any domain - speciﬁc features . We further show that the framework supports construction of a sci - entiﬁc knowledge graph , which we use to ana - lyze information in scientiﬁc literature . 1 1 Introduction As scientiﬁc communities grow and evolve , new tasks , methods , and datasets are introduced and different methods are compared with each other . Despite advances in search engines , it is still hard to identify new technologies and their relationships with what existed before . To help researchers more quickly identify opportunities for new combina - tions of tasks , methods and data , it is important to design intelligent algorithms that can extract and organize scientiﬁc information from a large collec - tion of documents . Organizing scientiﬁc information into structured knowledge bases requires information extraction ( IE ) about scientiﬁc entities and their relationships . However , the challenges associated with scientiﬁc IE are greater than for a general domain . First , an - notation of scientiﬁc text requires domain expertise which makes annotation costly and limits resources . 1 Data and code are publicly available at : http : / / nlp . cs . washington . edu / sciIE / Figure 1 : Example annotation : phrases that refer to the same scientiﬁc concept are annotated into the same coreference cluster , such as MORphological PAser MORPA , it and MORPA ( marked as red ) . In addition , most relation extraction systems are de - signed for within - sentence relations . However , ex - tracting information from scientiﬁc articles requires extracting relations across sentences . Figure 1 il - lustrates this problem . The cross - sentence relations between some entities can only be connected by entities that refer to the same scientiﬁc concept , including generic terms ( such as the pronoun it , or phrases like our method ) that are not informa - tive by themselves . With co - reference , context - free grammar can be connected to MORPA through the intermediate co - referred pronoun it . Applying ex - isting IE systems to this data , without co - reference , will result in much lower relation coverage ( and a sparse knowledge base ) . In this paper , we develop a uniﬁed learning model for extracting scientiﬁc entities , relations , and coreference resolution . This is different from previous work ( Luan et al . , 2017b ; Gupta and Man - ning , 2011 ; Tsai et al . , 2013 ; G´abor et al . , 2018 ) which often addresses these tasks as independent a r X i v : 1808 . 09602v1 [ c s . C L ] 29 A ug 2018 components of a pipeline . Our uniﬁed model is a multi - task setup that shares parameters across low - level tasks , making predictions by leveraging context across the document through coreference links . Speciﬁcally , we extend prior work for learn - ing span representations and coreference resolution ( Lee et al . , 2017 ; He et al . , 2018 ) . Different from a standard tagging system , our system enumerates all possible spans during decoding and can effectively detect overlapped spans . It avoids cascading errors between tasks by jointly modeling all spans and span - span relations . To explore this problem , we create a dataset S CI - ERC for scientiﬁc information extraction , which includes annotations of scientiﬁc terms , relation categories and co - reference links . Our experiments show that the uniﬁed model is better at predict - ing span boundaries , and it outperforms previous state - of - the - art scientiﬁc IE systems on entity and relation extraction ( Luan et al . , 2017b ; Augenstein et al . , 2017 ) . In addition , we build a scientiﬁc knowledge graph integrating terms and relations extracted from each article . Human evaluation shows that propagating coreference can signiﬁ - cantly improve the quality of the automatic con - structed knowledge graph . In summary we make the following contribu - tions . We create a dataset for scientiﬁc information extraction by jointly annotating scientiﬁc entities , relations , and coreference links . Extending a previ - ous end - to - end coreference resolution system , we develop a multi - task learning framework that can detect scientiﬁc entities , relations , and coreference clusters without hand - engineered features . We use our uniﬁed framework to build a scientiﬁc knowl - edge graph from a large collection of documents and analyze information in scientiﬁc literature . 2 Related Work There has been growing interest in research on au - tomatic methods for information extraction from scientiﬁc articles . Past research in scientiﬁc IE addressed analyzing citations ( Athar and Teufel , 2012b , a ; Kas , 2011 ; Gabor et al . , 2016 ; Sim et al . , 2012 ; Do et al . , 2013 ; Jaidka et al . , 2014 ; Abu - Jbara and Radev , 2011 ) , analyzing research com - munity ( Vogel and Jurafsky , 2012 ; Anderson et al . , 2012 ) , and unsupervised methods for extracting sci - entiﬁc entities and relations ( Gupta and Manning , 2011 ; Tsai et al . , 2013 ; G´abor et al . , 2016 ) . More recently , two datasets in SemEval 2017 and 2018 have been introduced , which facilitate research on supervised and semi - supervised learn - ing for scientiﬁc information extraction . SemEval 17 ( Augenstein et al . , 2017 ) includes 500 para - graphs from articles in the domains of computer science , physics , and material science . It includes three types of entities ( called keyphrases ) : Tasks , Methods , and Materials and two relation types : hyponym - of and synonym - of . SemEval 18 ( G´abor et al . , 2018 ) is focused on predicting relations be - tween entities within a sentence . It consists of six relation types . Using these datasets , neural mod - els ( Ammar et al . , 2017 , 2018 ; Luan et al . , 2017b ; Augenstein and Søgaard , 2017 ) are introduced for extracting scientiﬁc information . We extend these datasets by increasing relation coverage , adding cross - sentence coreference linking , and removing some annotation constraints . Different from most previous IE systems for scientiﬁc literature and gen - eral domains ( Miwa and Bansal , 2016 ; Xu et al . , 2016 ; Peng et al . , 2017 ; Quirk and Poon , 2017 ; Luan et al . , 2018 ; Adel and Sch¨utze , 2017 ) , which use preprocessed syntactic , discourse or corefer - ence features as input , our uniﬁed framework does not rely on any pipeline processing and is able to model overlapping spans . While Singh et al . ( 2013 ) show improvements by jointly modeling entities , relations , and coref - erence links , most recent neural models for these tasks focus on single tasks ( Clark and Manning , 2016 ; Wiseman et al . , 2016 ; Lee et al . , 2017 ; Lam - ple et al . , 2016 ; Peng et al . , 2017 ) or joint entity and relation extraction ( Katiyar and Cardie , 2017 ; Zhang et al . , 2017 ; Adel and Sch¨utze , 2017 ; Zheng et al . , 2017 ) . Among those studies , many papers as - sume the entity boundaries are given , such as ( Clark and Manning , 2016 ) , Adel and Sch¨utze ( 2017 ) and Peng et al . ( 2017 ) . Our work relaxes this constraint and predicts entity boundaries by optimizing over all possible spans . Our model draws from recent end - to - end span - based models for coreference res - olution ( Lee et al . , 2017 , 2018 ) and semantic role labeling ( He et al . , 2018 ) and extends them for the multi - task framework involving the three tasks of identiﬁcation of entity , relation and coreference . Neural multi - task learning has been applied to a range of NLP tasks . Most of these models share word - level representations ( Collobert and Weston , 2008 ; Klerke et al . , 2016 ; Luan et al . , 2016 , 2017a ; Rei , 2017 ) , while Peng et al . ( 2017 ) uses high - order cross - task factors . Our model instead propagates cross - task information via span representations , which is related to Swayamdipta et al . ( 2017 ) . 3 Dataset Our dataset ( called S CI ERC ) includes annotations for scientiﬁc entities , their relations , and corefer - ence clusters for 500 scientiﬁc abstracts . These ab - stracts are taken from 12 AI conference / workshop proceedings in four AI communities from the Se - mantic Scholar Corpus 2 . S CI ERC extends pre - vious datasets in scientiﬁc articles SemEval 2017 Task 10 ( SemEval 17 ) ( Augenstein et al . , 2017 ) and SemEval 2018 Task 7 ( SemEval 18 ) ( G´abor et al . , 2018 ) by extending entity types , relation types , rela - tion coverage , and adding cross - sentence relations using coreference links . Our dataset is publicly available at : http : / / nlp . cs . washington . edu / sciIE / . Table 1 shows the statistics of S CI - ERC . Annotation Scheme We deﬁne six types for an - notating scientiﬁc entities ( Task , Method , Metric , Material , Other - ScientiﬁcTerm and Generic ) and seven relation types ( Compare , Part - of , Conjunc - tion , Evaluate - for , Feature - of , Used - for , Hyponym - Of ) . Directionality is taken into account except for the two symmetric relation types ( Conjunction and Compare ) . Coreference links are annotated between identical scientiﬁc entities . A Generic en - tity is annotated only when the entity is involved in a relation or is coreferred with another entity . Annotation guidelines can be found in Appendix A . Figure 1 shows an annotated example . Following annotation guidelines from Qasem - iZadeh and Schumann ( 2016 ) and using the BRAT interface ( Stenetorp et al . , 2012 ) , our annotators perform a greedy annotation for spans and always prefer the longer span whenever ambiguity occurs . Nested spans are allowed when a subspan has a relation / coreference link with another term outside the span . Human Agreements One domain expert anno - tated all the documents in the dataset ; 12 % of the data is dually annotated by 4 other domain experts to evaluate the user agreements . The kappa score for annotating entities is 76 . 9 % , relation extraction is 67 . 8 % and coreference is 63 . 8 % . 2 These conferences include general AI ( AAAI , IJCAI ) , NLP ( ACL , EMNLP , IJCNLP ) , speech ( ICASSP , Interspeech ) , machine learning ( NIPS , ICML ) , and computer vision ( CVPR , ICCV , ECCV ) at http : / / labs . semanticscholar . org / corpus / Statistics S CI ERC SemEval 17 SemEval 18 # Entities 8089 9946 7483 # Relations 4716 672 1595 # Relations / Doc 9 . 4 1 . 3 3 . 2 # Coref links 2752 - - # Coref clusters 1023 - - Table 1 : Dataset statistics for our dataset S CI ERC and two previous datasets on scientiﬁc information extraction . All datasets annotate 500 documents . Comparison with previous datasets S CI ERC is focused on annotating cross - sentence relations and has more relation coverage than SemEval 17 and SemEval 18 , as shown in Table 1 . SemEval 17 is mostly designed for entity recognition and only covers two relation types . The task in SemEval 18 is to classify a relation between a pair of entities given entity boundaries , but only intra - sentence re - lations are annotated and each entity only appears in one relation , resulting in sparser relation cover - age than our dataset ( 3 . 2 vs . 9 . 4 relations per ab - stract ) . S CI ERC extends these datasets by adding more relation types and coreference clusters , which allows representing cross - sentence relations , and removing annotation constraints . Table 1 gives a comparison of statistics among the three datasets . In addition , S CI ERC aims at including broader coverage of general AI communities . 4 Model We develop a uniﬁed framework ( called S CI IE ) to identify and classify scientiﬁc entities , relations , and coreference resolution across sentences . S CI IE is a multi - task learning setup that extends previous span - based models for coreference resolution ( Lee et al . , 2017 ) and semantic role labeling ( He et al . , 2018 ) . All three tasks of entity recognition , re - lation extraction , and coreference resolution are treated as multinomial classiﬁcation problems with shared span representations . S CI IE beneﬁts from expressive contextualized span representations as classiﬁer features . By sharing span representations , sentence - level tasks can beneﬁt from information propagated from coreference resolution across sen - tences , without increasing the complexity of infer - ence . Figure 2 shows a high - level overview of the S CI IE multi - task framework . 4 . 1 Problem Deﬁnition The input is a document represented as a sequence of words D = { w 1 , . . . , w n } , from which we de - rive S = { s 1 , . . . , s N } , the set of all possible MORPA MORPA is a a fully implemented parser parser MORphological Parser MORPA MORPA is a fully implemented parser developed for … … , the MORphological Parser MORPA is provided with a … MORphological MORPA is is provided with NULL Hyponym - of Used - for NULL Method Task NULL Sentences BiLSTM outputs Span Representations Entity Recognition + Span Features Coreference Resolution Relation Extraction … … parser MORPA MORphological MORphological Parser MORPA … … … Figure 2 : Overview of the multitask setup , where all three tasks are treated as classiﬁcation problems on top of shared span representations . Dotted arcs indicate the normalization space for each task . within - sentence word sequence spans ( up to a rea - sonable length ) in the document . The output con - tains three structures : the entity types E for all spans S , the relations R for all pair of spans S × S , and the coreference links C for all spans in S . The output structures are represented with a set of dis - crete random variables indexed by spans or pairs of spans . Speciﬁcally , the output structures are deﬁned as follows . Entity recognition is to predict the best entity type for every candidate span . Let L E represent the set of all possible entity types including the null - type (cid:15) . The output structure E is a set of random variables indexed by spans : e i ∈ L E for i = 1 , . . . , N . Relation extraction is to predict the best relation type given an ordered pair of spans ( s i , s j ) . Let L R be the set of all possible relation types including the null - type (cid:15) . The output structure R is a set of random variables indexed over pairs of spans ( i , j ) that belong to the same sentence : r ij ∈ L R for i , j = 1 , . . . , N . Coreference resolution is to predict the best an - tecedent ( including a special null antecedent ) given a span , which is the same mention - ranking model used in Lee et al . ( 2017 ) . The output structure C is a set of random variables deﬁned as : c i ∈ { 1 , . . . , i − 1 , (cid:15) } for i = 1 , . . . , N . 4 . 2 Model Deﬁnition We formulate the multi - task learning setup as learning the conditional probability distribution P ( E , R , C | D ) . For efﬁcient training and inference , we decompose P ( E , R , C | D ) assuming spans are conditionally independent given D : P ( E , R , C | D ) = P ( E , R , C , S | D ) ( 1 ) = N (cid:89) i = 1 P ( e i | D ) P ( c i | D ) N (cid:89) j = 1 P ( r ij | D ) , where the conditional probabilities of each random variable are independently normalized : P ( e i = e | D ) = exp ( Φ E ( e , s i ) ) (cid:80) e (cid:48) ∈ L E exp ( Φ E ( e (cid:48) , s i ) ) ( 2 ) P ( r ij = r | D ) = exp ( Φ R ( r , s i , s j ) ) (cid:80) r (cid:48) ∈ L R exp ( Φ R ( r (cid:48) , s i , s j ) ) P ( c i = j | D ) = exp ( Φ C ( s i , s j ) ) (cid:80) j (cid:48) ∈ { 1 , . . . , i − 1 , (cid:15) } exp ( Φ C ( s i , s j (cid:48) ) ) , where Φ E denotes the unnormalized model score for an entity type e and a span s i , Φ R denotes the score for a relation type r and span pairs s i , s j , and Φ C denotes the score for a binary coreference link between s i and s j . These Φ scores are further decomposed into span and pairwise span scores computed from feed - forward networks , as will be explained in Section 4 . 3 . For simplicity , we omit D from the Φ functions and S from the observation . Objective Given a set of all documents D , the model loss function is deﬁned as a weighted sum of the negative log - likelihood loss of all three tasks : − (cid:88) ( D , R ∗ , E ∗ , C ∗ ) ∈D (cid:110) λ E log P ( E ∗ | D ) ( 3 ) + λ R log P ( R ∗ | D ) + λ C log P ( C ∗ | D ) (cid:111) where E ∗ , R ∗ , and C ∗ are gold structures of the en - tity types , relations , and coreference , respectively . The task weights λ E , λ R , and λ C are introduced as hyper - parameters to control the importance of each task . For entity recognition and relation extraction , P ( E ∗ | D ) and P ( R ∗ | D ) are computed with the deﬁnition in Equation ( 2 ) . For coreference resolution , we use the marginalized loss follow - ing Lee et al . ( 2017 ) since each mention can have multiple correct antecedents . Let C ∗ i be the set of all correct antecedents for span i , we have : log P ( C ∗ | D ) = (cid:80) i = 1 . . N log (cid:80) c ∈ C ∗ i P ( c | D ) . 4 . 3 Scoring Architecture We use feedforward neural networks ( FFNNs ) over shared span representations g to compute a set of span and pairwise span scores . For the span scores , φ e ( s i ) measures how likely a span s i has an entity type e , and φ mr ( s i ) and φ mc ( s i ) measure how likely a span s i is a mention in a relation or a coreference link , respectively . The pairwise scores φ r ( s i , s j ) and φ c ( s i , s j ) measure how likely two spans are associated in a relation r or a coreference link , respectively . Let g i be the ﬁxed - length vec - tor representation for span s i . For different tasks , the span scores φ x ( s i ) for x ∈ { e , mc , mr } and pairwise span scores φ y ( s i , s j ) for y ∈ { r , c } are computed as follows : φ x ( s i ) = w x · FFNN x ( g i ) φ y ( s i , s j ) = w y · FFNN y ( [ g i , g j , g i (cid:12) g j ] ) , where (cid:12) is element - wise multiplication , and { w x , w y } are neural network parameters to be learned . We use these scores to compute the different Φ : Φ E ( e , s i ) = φ e ( s i ) ( 4 ) Φ R ( r , s i , s j ) = φ mr ( s i ) + φ mr ( s j ) + φ r ( s i , s j ) Φ C ( s i , s j ) = φ mc ( s i ) + φ mc ( s j ) + φ c ( s i , s j ) The scores in Equation ( 4 ) are deﬁned for entity types , relations , and antecedents that are not the null - type (cid:15) . Scores involving the null label are set to a constant 0 : Φ E ( (cid:15) , s i ) = Φ R ( (cid:15) , s i , s j ) = Φ C ( s i , (cid:15) ) = 0 . We use the same span representations g from ( Lee et al . , 2017 ) and share them across the three tasks . We start by building bi - directional LSTMs ( Hochreiter and Schmidhuber , 1997 ) from word , character and ELMo ( Peters et al . , 2018 ) embed - dings . For a span s i , its vector representation g i is con - structed by concatenating s i ’s left and right end points from the BiLSTM outputs , an attention - based soft “headword , ” and embedded span width features . Hyperparameters and other implementa - tion details will be described in Section 6 . 4 . 4 Inference and Pruning Following previous work , we use beam pruning to reduce the number of pairwise span factors from O ( n 4 ) to O ( n 2 ) at both training and test time , where n is the number of words in the document . We deﬁne two separate beams : B C to prune spans for the coreference resolution task , and B R for rela - tion extraction . The spans in the beams are sorted by their span scores φ mc and φ mr respectively , and the sizes of the beams are limited by λ C n and λ R n . We also limit the maximum width of spans to a ﬁxed number W , which further reduces the num - ber of span factors to O ( n ) . 5 Knowledge Graph Construction We construct a scientiﬁc knowledge graph from a large corpus of scientiﬁc articles . The corpus includes all abstracts ( 110k in total ) from 12 AI conference proceedings from the Semantic Scholar Corpus . Nodes in the knowledge graph correspond to scientiﬁc entities . Edges correspond to scientiﬁc relations between pairs of entities . The edges are typed according to the relation types deﬁned in Sec - tion 3 . Figure 4 shows a part of a knowledge graph created by our method . For example , Statistical Machine Translation ( SMT ) and grammatical error correction are nodes in the graph , and they are con - nected through a Used - for relation type . In order to construct the knowledge graph for the whole corpus , we ﬁrst apply the S CI IE model over sin - gle documents and then integrate the entities and relations across multiple documents ( Figure 3 ) . Extracting nodes ( entities ) The S CI IE model extracts entities , their relations , and coreference Abstract ( 1 ) < latexit sha1 _ base64 = " plPMi3PhbjdexTOfOHuoBb / buP8 = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mXbjZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJrhkLeAgWDdWjIS + YB1 / cpf7nSemNI / kI8xi5oVkJHnAKQEjDexKH9gU0ltfgyIUspp7PrCrTt2ZA68StyBVVKA5sL / 6w4gmIZNABdG65zoxeClRwKlgWbmfaBYTOiEj1jNUkpBpL53fnuEzowxxEClTEvBc / T2RklDrWeibzpDAWC97ufif10sguPZSLuMEmKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4Aq5qUJg = = < / latexit > < latexit sha1 _ base64 = " plPMi3PhbjdexTOfOHuoBb / buP8 = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mXbjZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJrhkLeAgWDdWjIS + YB1 / cpf7nSemNI / kI8xi5oVkJHnAKQEjDexKH9gU0ltfgyIUspp7PrCrTt2ZA68StyBVVKA5sL / 6w4gmIZNABdG65zoxeClRwKlgWbmfaBYTOiEj1jNUkpBpL53fnuEzowxxEClTEvBc / T2RklDrWeibzpDAWC97ufif10sguPZSLuMEmKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4Aq5qUJg = = < / latexit > < latexit sha1 _ base64 = " plPMi3PhbjdexTOfOHuoBb / buP8 = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mXbjZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJrhkLeAgWDdWjIS + YB1 / cpf7nSemNI / kI8xi5oVkJHnAKQEjDexKH9gU0ltfgyIUspp7PrCrTt2ZA68StyBVVKA5sL / 6w4gmIZNABdG65zoxeClRwKlgWbmfaBYTOiEj1jNUkpBpL53fnuEzowxxEClTEvBc / T2RklDrWeibzpDAWC97ufif10sguPZSLuMEmKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4Aq5qUJg = = < / latexit > < latexit sha1 _ base64 = " plPMi3PhbjdexTOfOHuoBb / buP8 = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mXbjZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJrhkLeAgWDdWjIS + YB1 / cpf7nSemNI / kI8xi5oVkJHnAKQEjDexKH9gU0ltfgyIUspp7PrCrTt2ZA68StyBVVKA5sL / 6w4gmIZNABdG65zoxeClRwKlgWbmfaBYTOiEj1jNUkpBpL53fnuEzowxxEClTEvBc / T2RklDrWeibzpDAWC97ufif10sguPZSLuMEmKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4Aq5qUJg = = < / latexit > Abstract ( 2 ) < latexit sha1 _ base64 = " oH + E80xlkwVGYgNSnJz + yJi1Lw8 = " > AAAB + 3icbVBNS8NAEN3Ur1q / Yj16WSxCvZSkCIqnihePFewHtKFstpt26WYTdifSEvpXvHhQxKt / xJv / xk2bg7Y + GHi8N8PMPD8WXIPjfFuFjc2t7Z3ibmlv / + DwyD4ut3WUKMpaNBKR6vpEM8ElawEHwbqxYiT0Bev4k7vM7zwxpXkkH2EWMy8kI8kDTgkYaWCX + 8CmkN76GhShMK / WLwZ2xak5C + B14uakgnI0B / ZXfxjRJGQSqCBa91wnBi8lCjgVbF7qJ5rFhE7IiPUMlSRk2ksXt8 / xuVGGOIiUKQl4of6eSEmo9Sz0TWdIYKxXvUz8z + slEFx7KZdxAkzS5aIgERginAWBh1wxCmJmCKGKm1sxHZMsBBNXyYTgrr68Ttr1muvU3IfLSuMmj6OITtEZqiIXXaEGukdN1EIUTdEzekVv1tx6sd6tj2VrwcpnTtAfWJ8 / rR + UJw = = < / latexit > < latexit sha1 _ base64 = " oH + E80xlkwVGYgNSnJz + yJi1Lw8 = " > AAAB + 3icbVBNS8NAEN3Ur1q / Yj16WSxCvZSkCIqnihePFewHtKFstpt26WYTdifSEvpXvHhQxKt / xJv / xk2bg7Y + GHi8N8PMPD8WXIPjfFuFjc2t7Z3ibmlv / + DwyD4ut3WUKMpaNBKR6vpEM8ElawEHwbqxYiT0Bev4k7vM7zwxpXkkH2EWMy8kI8kDTgkYaWCX + 8CmkN76GhShMK / WLwZ2xak5C + B14uakgnI0B / ZXfxjRJGQSqCBa91wnBi8lCjgVbF7qJ5rFhE7IiPUMlSRk2ksXt8 / xuVGGOIiUKQl4of6eSEmo9Sz0TWdIYKxXvUz8z + slEFx7KZdxAkzS5aIgERginAWBh1wxCmJmCKGKm1sxHZMsBBNXyYTgrr68Ttr1muvU3IfLSuMmj6OITtEZqiIXXaEGukdN1EIUTdEzekVv1tx6sd6tj2VrwcpnTtAfWJ8 / rR + UJw = = < / latexit > < latexit sha1 _ base64 = " oH + E80xlkwVGYgNSnJz + yJi1Lw8 = " > AAAB + 3icbVBNS8NAEN3Ur1q / Yj16WSxCvZSkCIqnihePFewHtKFstpt26WYTdifSEvpXvHhQxKt / xJv / xk2bg7Y + GHi8N8PMPD8WXIPjfFuFjc2t7Z3ibmlv / + DwyD4ut3WUKMpaNBKR6vpEM8ElawEHwbqxYiT0Bev4k7vM7zwxpXkkH2EWMy8kI8kDTgkYaWCX + 8CmkN76GhShMK / WLwZ2xak5C + B14uakgnI0B / ZXfxjRJGQSqCBa91wnBi8lCjgVbF7qJ5rFhE7IiPUMlSRk2ksXt8 / xuVGGOIiUKQl4of6eSEmo9Sz0TWdIYKxXvUz8z + slEFx7KZdxAkzS5aIgERginAWBh1wxCmJmCKGKm1sxHZMsBBNXyYTgrr68Ttr1muvU3IfLSuMmj6OITtEZqiIXXaEGukdN1EIUTdEzekVv1tx6sd6tj2VrwcpnTtAfWJ8 / rR + UJw = = < / latexit > < latexit sha1 _ base64 = " oH + E80xlkwVGYgNSnJz + yJi1Lw8 = " > AAAB + 3icbVBNS8NAEN3Ur1q / Yj16WSxCvZSkCIqnihePFewHtKFstpt26WYTdifSEvpXvHhQxKt / xJv / xk2bg7Y + GHi8N8PMPD8WXIPjfFuFjc2t7Z3ibmlv / + DwyD4ut3WUKMpaNBKR6vpEM8ElawEHwbqxYiT0Bev4k7vM7zwxpXkkH2EWMy8kI8kDTgkYaWCX + 8CmkN76GhShMK / WLwZ2xak5C + B14uakgnI0B / ZXfxjRJGQSqCBa91wnBi8lCjgVbF7qJ5rFhE7IiPUMlSRk2ksXt8 / xuVGGOIiUKQl4of6eSEmo9Sz0TWdIYKxXvUz8z + slEFx7KZdxAkzS5aIgERginAWBh1wxCmJmCKGKm1sxHZMsBBNXyYTgrr68Ttr1muvU3IfLSuMmj6OITtEZqiIXXaEGukdN1EIUTdEzekVv1tx6sd6tj2VrwcpnTtAfWJ8 / rR + UJw = = < / latexit > Abstract ( m ) < latexit sha1 _ base64 = " PuH458bIm0iyjkYW01I + k4X1XVk = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mX7iZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJnjIWsBBsG6sGJG + YB1 / cpf7nSemNI / CR5jFzJNkFPKAUwJGGtiVPrAppLe + BkUoZDV5PrCrTt2ZA68StyBVVKA5sL / 6w4gmkoVABdG65zoxeClRwKlgWbmfaBYTOiEj1jM0JJJpL53fnuEzowxxEClTIeC5 + nsiJVLrmfRNpyQw1steLv7n9RIIrr2Uh3ECLKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4ABtWUYg = = < / latexit > < latexit sha1 _ base64 = " PuH458bIm0iyjkYW01I + k4X1XVk = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mX7iZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJnjIWsBBsG6sGJG + YB1 / cpf7nSemNI / CR5jFzJNkFPKAUwJGGtiVPrAppLe + BkUoZDV5PrCrTt2ZA68StyBVVKA5sL / 6w4gmkoVABdG65zoxeClRwKlgWbmfaBYTOiEj1jM0JJJpL53fnuEzowxxEClTIeC5 + nsiJVLrmfRNpyQw1steLv7n9RIIrr2Uh3ECLKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4ABtWUYg = = < / latexit > < latexit sha1 _ base64 = " PuH458bIm0iyjkYW01I + k4X1XVk = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mX7iZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJnjIWsBBsG6sGJG + YB1 / cpf7nSemNI / CR5jFzJNkFPKAUwJGGtiVPrAppLe + BkUoZDV5PrCrTt2ZA68StyBVVKA5sL / 6w4gmkoVABdG65zoxeClRwKlgWbmfaBYTOiEj1jM0JJJpL53fnuEzowxxEClTIeC5 + nsiJVLrmfRNpyQw1steLv7n9RIIrr2Uh3ECLKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4ABtWUYg = = < / latexit > < latexit sha1 _ base64 = " PuH458bIm0iyjkYW01I + k4X1XVk = " > AAAB + 3icbVBNS8NAEN34WetXrEcvi0Wol5KIoHiqePFYwX5AG8pmu2mX7iZhdyItIX / FiwdFvPpHvPlv3LQ5aOuDgcd7M8zM82PBNTjOt7W2vrG5tV3aKe / u7R8c2keVto4SRVmLRiJSXZ9oJnjIWsBBsG6sGJG + YB1 / cpf7nSemNI / CR5jFzJNkFPKAUwJGGtiVPrAppLe + BkUoZDV5PrCrTt2ZA68StyBVVKA5sL / 6w4gmkoVABdG65zoxeClRwKlgWbmfaBYTOiEj1jM0JJJpL53fnuEzowxxEClTIeC5 + nsiJVLrmfRNpyQw1steLv7n9RIIrr2Uh3ECLKSLRUEiMEQ4DwIPuWIUxMwQQhU3t2I6JnkIJq6yCcFdfnmVtC / qrlN3Hy6rjZsijhI6Qaeohlx0hRroHjVRC1E0Rc / oFb1ZmfVivVsfi9Y1q5g5Rn9gff4ABtWUYg = = < / latexit > . . . < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > . . . < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > . . . < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > < latexit sha1 _ base64 = " BD1XKLi2MLyNy / k + DR9W3roijvs = " > AAAB7XicbVBNS8NAEJ3Ur1q / qh69LBbBU0lEUDwVvHisYD + gDWWz2bRrN9mwOxFK6H / w4kERr / 4fb / 4bt20O2vpg4PHeDDPzglQKg6777ZTW1jc2t8rblZ3dvf2D6uFR26hMM95iSirdDajhUiS8hQIl76aa0ziQvBOMb2d + 54lrI1TygJOU + zEdJiISjKKV2n0ZKjSDas2tu3OQVeIVpAYFmoPqVz9ULIt5gkxSY3qem6KfU42CST6t9DPDU8rGdMh7liY05sbP59dOyZlVQhIpbStBMld / T + Q0NmYSB7Yzpjgyy95M / M / rZRhd + 7lI0gx5whaLokwSVGT2OgmF5gzlxBLKtLC3EjaimjK0AVVsCN7yy6ukfVH33Lp3f1lr3BRxlOEETuEcPLiCBtxBE1rA4BGe4RXeHOW8OO / Ox6K15BQzx / AHzucPubePMA = = < / latexit > Document - level KGs Scientiﬁc KG Merging SciIE < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > SciIE < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > SciIE < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > < latexit sha1 _ base64 = " dkMVQqBbljsC87ORSph5l08iusY = " > AAAB9XicbVDLSgNBEJz1GeMr6tHLYBA8hV0RFE8BEfQW0TwgWcPspDcZMju7zPSqYcl / ePGgiFf / xZt / 4 + Rx0MSChqKqm + 6uIJHCoOt + OwuLS8srq7m1 / PrG5tZ2YWe3ZuJUc6jyWMa6ETADUiiookAJjUQDiwIJ9aB / MfLrD6CNiNUdDhLwI9ZVIhScoZXuWwhPaHh2y8X15bBdKLoldww6T7wpKZIpKu3CV6sT8zQChVwyY5qem6CfMY2CSxjmW6mBhPE + 60LTUsUiMH42vnpID63SoWGsbSmkY / X3RMYiYwZRYDsjhj0z643E / 7xmiuGZnwmVpAiKTxaFqaQY01EEtCM0cJQDSxjXwt5KeY9pxtEGlbcheLMvz5PacclzS97NSbF8Po0jR / bJATkiHjklZXJFKqRKONHkmbySN + fReXHenY9J64Izndkjf + B8 / gC0ypKa < / latexit > Figure 3 : Knowledge graph construction process . Figure 4 : A part of an automatically constructed scientiﬁc knowledge graph with the most frequent neighbors of the scientiﬁc term statistical machine translation ( SMT ) on the graph . For simplicity we denote Used - for ( Reverse ) as Uses , Evaluated - for ( Reverse ) as Evaluated - by , and replace common terms with their acronyms . The original graph and more examples are given Figure 10 in Appendix B . clusters within one document . Phrases are heuris - tically normalized ( described in Section 6 ) using entities and coreference links . In particular , we link all entities that belong to the same coreference cluster to replace generic terms with any other non - generic term in the cluster . Moreover , we replace all the entities in the cluster with the entity that has the longest string . Our qualitative analysis shows that there are fewer ambiguous phrases using coref - erence links ( Figure 5 ) . We calculate the frequency counts of all entities that appear in the whole cor - pus . We assign nodes in the knowledge graph by selecting the most frequent entities ( with counts > k ) in the corpus , and merge in any remaining entities for which a frequent entity is a substring . Assigning edges ( relations ) A pair of entities may appear in different contexts , resulting in differ - ent relation types between those entities ( Figure 6 ) . For every pair of entities in the graph , we calculate the frequency of different relation types across the whole corpus . We assign edges between entities by selecting the most frequent relation type . 6 Experimental Setup We evaluate our uniﬁed framework S CI IE on S CI - ERC and SemEval 17 . The knowledge graph for detection object detection face detection human detection pedestrian detection action detection 1237 585 258 124 90 87 1297 510 177 84 57 63 With Coref . Without Coref . Figure 5 : Frequency of detected entities with and without coreferece resolution : using coreference reduces the frequency of the generic phrase detec - tion while signiﬁcantly increasing the frequency of speciﬁc phrases . Linking entities through corefer - ence helps disambiguate phrases when generating the knowledge graph . C o n j u n c t i o n U s e d f o r U s e d f o r ( R e v e r s e ) 0 20 40 60 80 80 10 4 # R e l a ti on T r i p l e s MT - ASR H y p o n y m o f C o n j u n c t i o n U s e d f o r U s e d f o r ( R e v e r s e ) 0 10 20 30 25 4 2 2 CRF - GM Figure 6 : Frequency of relation types between pairs of entities : ( left ) automatic speech recognition ( ASR ) and machine translation ( MT ) , ( right ) con - ditional random ﬁeld ( CRF ) and graphical model ( GM ) . We use the most frequent relation between pairs of entities in the knowledge graph . scientiﬁc community analysis is built using the Se - mantic Scholar Corpus ( 110k abstracts in total ) . 6 . 1 Baselines We compare our model with the following base - lines on S CI ERCdataset : • LSTM + CRF The state - of - the - art NER sys - tem ( Lample et al . , 2016 ) , which applies CRF on top of LSTM for named entity tagging , the approach has also been used in scientiﬁc term extraction ( Luan et al . , 2017b ) . • LSTM + CRF + ELMo LSTM + CRF with ELM O as an additional input feature . • E2E Rel State - of - the - art joint entity and re - lation extraction system ( Miwa and Bansal , 2016 ) that has also been used in scientiﬁc lit - erature ( Peters et al . , 2017 ; Augenstein et al . , 2017 ) . This system uses syntactic features such as part - of - speech tagging and depen - dency parsing . • E2E Rel ( Pipeline ) Pipeline setting of E2E Rel . Extract entities ﬁrst and use entity results as input to relation extraction task . • E2E Rel + ELMo E2E Rel with ELM O as an additional input feature . • E2E Coref State - of - the - art coreference sys - tem Lee et al . ( 2017 ) combined with ELM O . Our system S CI IE extends E2E Coref with multi - task learning . In the SemEval task , we compare our model S CI IE with the best reported system in the SemEval leaderboard ( Peters et al . , 2017 ) , which extends E2E Rel with several in - domain features such as gazetteers extracted from existing knowledge bases and model ensembles . We also compare with the state of the art on keyphrase extraction ( Luan et al . , 2017b ) , which applies semi - supervised methods to a neural tagging model . 3 6 . 2 Implementation details Our system extends the implementation and hyper - parameters from Lee et al . ( 2017 ) with the follow - ing adjustments . We use a 1 layer BiLSTM with 200 - dimensional hidden layers . All the FFNNs have 2 hidden layers of 150 dimensions each . We use 0 . 4 variational dropout ( Gal and Ghahramani , 2016 ) for the LSTMs , 0 . 4 dropout for the FFNNs , and 0 . 5 dropout for the input embeddings . We model spans up to 8 words . For beam pruning , we use λ C = 0 . 3 for coreference resolution and λ R = 0 . 4 for relation extraction . For constructing the knowledge graph , we use the following heuris - tics to normalize the entity phrases . We replace all acronyms with their corresponding full name and normalize all the plural terms with their singular counterparts . 7 Experimental Results We evaluate S CI IE on S CI ERC and SemEval 17 datasets . We provide qualitative results and human evaluation of the constructed knowledge graph . 7 . 1 IE Results Results on SciERC Table 2 compares the result of our model with baselines on the three tasks : en - tity recognition ( Table 2a ) , relation extraction ( Ta - ble 2b ) , and coreference resolution ( Table 2c ) . As evidenced by the table , our uniﬁed multi - task setup 3 We compare with the inductive setting results . Dev Test Model P R F1 P R F1 LSTM + CRF 67 . 2 65 . 8 66 . 5 62 . 9 61 . 1 62 . 0 LSTM + CRF + ELMo 68 . 1 66 . 3 67 . 2 63 . 8 63 . 2 63 . 5 E2E Rel ( Pipeline ) 66 . 7 65 . 9 66 . 3 60 . 8 61 . 2 61 . 0 E2E Rel 64 . 3 68 . 6 66 . 4 60 . 6 61 . 9 61 . 2 E2E Rel + ELM O 67 . 5 66 . 3 66 . 9 63 . 5 63 . 9 63 . 7 S CI IE 70 . 0 66 . 3 68 . 1 67 . 2 61 . 5 64 . 2 ( a ) Entity recognition . Dev Test Model P R F1 P R F1 E2E Rel ( Pipeline ) 34 . 2 33 . 7 33 . 9 37 . 8 34 . 2 35 . 9 E2E Rel 37 . 3 33 . 5 35 . 3 37 . 1 32 . 2 34 . 1 E2E Rel + ELM O 38 . 5 36 . 4 37 . 4 38 . 4 34 . 9 36 . 6 S CI IE 45 . 4 34 . 9 39 . 5 47 . 6 33 . 5 39 . 3 ( b ) Relation extraction . Dev Test Model P R F1 P R F1 E2E Coref 59 . 4 52 . 0 55 . 4 60 . 9 37 . 3 46 . 2 S CI IE 61 . 5 54 . 8 58 . 0 52 . 0 44 . 9 48 . 2 ( c ) Coreference resolution . Table 2 : Comparison with previous systems on the development and test set for our three tasks . For coreference resolution , we report the average P / R / F1 of MUC , B 3 , and CEAF φ 4 scores . S CI IE outperforms all the baselines . For entity recognition , our model achieves 1 . 3 % and 2 . 4 % relative improvement over LSTM + CRF with and without ELM O , respectively . Moreover , it achieves 1 . 8 % and 2 . 7 % relative improvement over E2E Rel with and without ELM O , respectively . For rela - tion extraction , we observe more signiﬁcant im - provement with 13 . 1 % relative improvement over E2E Rel and 7 . 4 % improvement over E2E Rel with ELM O . For coreference resolution , S CI IE outper - forms E2E Coref with 4 . 5 % relative improvement . We still observe a large gap between human - level performance and a machine learning system . We invite the community to address this challenging task . Ablations We evaluate the effect of multi - task learning in each of the three tasks deﬁned in our dataset . Table 3 reports the results for individual tasks when additional tasks are included in the learning objective function . We observe that per - formance improves with each added task in the objective . For example , Entity recognition ( 65 . 7 ) beneﬁts from both coreference resolution ( 67 . 5 ) and relation extraction ( 66 . 8 ) . Relation extrac - Task Entity Rec . Relation Coref . Multi Task ( S CI IE ) 68 . 1 39 . 5 58 . 0 Single Task 65 . 7 37 . 9 55 . 3 + Entity Rec . - 38 . 9 57 . 1 + Relation 66 . 8 - 57 . 6 + Coreference 67 . 5 39 . 5 - Table 3 : Ablation study for multitask learning on S CI ERC development set . Each column shows results for the target task . tion ( 37 . 9 ) signiﬁcantly beneﬁts when multi - tasked with coreference resolution ( 7 . 1 % relative improve - ment ) . Coreference resolution beneﬁts when multi - tasked with relation extraction , with 4 . 9 % relative improvement . Results on SemEval 17 Table 4 compares the results of our model with the state of the art on the SemEval 17 dataset for tasks of span identiﬁcation , keyphrase extraction and relation extraction as well as the overall score . Span identiﬁcation aims at identifying spans of entities . Keyphrase classiﬁ - cation and relation extraction has the same setting with the entity and relation extraction in S CI ERC . Our model outperforms all the previous models that use hand - designed features . We observe more signiﬁcant improvement in span identiﬁcation than keyphrase classiﬁcation . This conﬁrms the bene - ﬁt of our model in enumerating spans ( rather than BIO tagging in state - of - the - art systems ) . More - over , we have competitive results compared to the previous state of the art in relation extraction . We observe less gain compared to the S CI ERC dataset mainly because there are no coference links , and the relation types are not comprehensive . 7 . 2 Knowledge Graph Analysis We provide qualitative analysis and human evalua - tions on the constructed knowledge graph . Scientiﬁc trend analysis Figure 7 shows the his - torical trend analysis ( from 1996 to 2016 ) of the most popular applications of the phrase neural net - work , selected according to the statistics of the extracted relation triples with the ‘Used - for’ rela - tion type from speech , computer vision , and NLP conference papers . We observe that , before 2000 , neural network has been applied to a greater per - centage of speech applications compared to the NLP and computer vision papers . In NLP , neural networks ﬁrst gain popularity in language modeling 1 , 995 2 , 000 2 , 005 2 , 010 2 , 015 0 0 . 2 0 . 4 0 . 6 Language Modeling Machine Translation POS Tagging 1 , 995 2 , 000 2 , 005 2 , 010 2 , 015 0 0 . 2 0 . 4 0 . 6 Speech Recognition Speech Synthesis Speaker Recognition 1995 2000 2005 2010 2015 0 0 . 2 0 . 4 Object Recognition Object Detection Image Segmentation Figure 7 : Historical trend for top applications of the keyphrase neural network in NLP , speech , and CV conference papers we collected . y - axis indicates the ratio of papers that use neural network in the task to the number of papers that is about the task . 0 20 40 60 80 100 84 86 88 90 92 Pseudo - recall % P r ec i s i on % With Coref . Without Coref . Figure 8 : Precision / pseudo - recall curves for human evaluation by varying cut - off thresholds . The AUC is 0 . 751 with coreference , and 0 . 695 without . and then extend to other tasks such as POS Tag - ging and Machine Translation . In computer vision , the application of neural networks gains popularity in object recognition earlier ( around 2010 ) than the other two more complex tasks of object detec - tion and image segmentation ( hardest and also the latest ) . Knowledge Graph Evaluation Figure 8 shows the human evaluation of the constructed knowl - edge graph , comparing the quality of automatically generated knowledge graphs with and without the coreference links . We randomly select 10 frequent scientiﬁc entities and extract all the relation triples that include one of the selected entities leading to 1 . 5k relation triples from both systems . We ask four domain experts to annotate each of these ex - Span Indentiﬁcation Keyphrase Extraction Relation Extraction Overall Model P R F1 P R F1 P R F1 P R F1 ( Luan 2017 ) - - 56 . 9 - - 45 . 3 - - - - - - Best SemEval 55 54 55 44 43 44 36 23 28 44 41 43 S CI IE 62 . 2 55 . 4 58 . 6 48 . 5 43 . 8 46 . 0 40 . 4 21 . 2 27 . 8 48 . 1 41 . 8 44 . 7 Table 4 : Results for scientiﬁc keyphrase extraction and extraction on SemEval 2017 Task 10 , comparing with previous best systems . tracted relations to deﬁne ground truth labels . Each domain expert is assigned 2 or 3 entities and all of the corresponding relations . Figure 8 shows preci - sion / recall curves for both systems . Since it is not feasible to compute the actual recall of the systems , we compute the pseudo - recall ( Zhang et al . , 2015 ) based on the output of both systems . We observe that the knowledge graph curve with coreference linking is mostly above the curve without corefer - ence linking . The precision of both systems is high ( above 84 % for both systems ) , but the system with coreference links has signiﬁcantly higher recall . 8 Conclusion In this paper , we create a new dataset and develop a multi - task model for identifying entities , relations , and coreference clusters in scientiﬁc articles . By sharing span representations and leveraging cross - sentence information , our multi - task setup effec - tively improves performance across all tasks . More - over , we show that our multi - task model is better at predicting span boundaries and outperforms previ - ous state - of - the - art scientiﬁc IE systems on entity and relation extraction , without using any hand - engineered features or pipeline processing . Using our model , we are able to automatically organize the extracted information from a large collection of scientiﬁc articles into a knowledge graph . Our analysis shows the importance of coreference links in making a dense , useful graph . We still observe a large gap between the perfor - mance of our model and human performance , con - ﬁrming the challenges of scientiﬁc IE . Future work includes improving the performance using semi - supervised techniques and providing in - domain features . We also plan to extend our multi - task framework to information extraction tasks in other domains . Acknowledgments This research was supported by the Ofﬁce of Naval Research under the MURI grant N00014 - 18 - 1 - 2670 , NSF ( IIS 1616112 , III 1703166 ) , Allen Dis - tinguished Investigator Award , and gifts from Allen Institute for AI , Google , Amazon , and Bloomberg . We are grateful to Waleed Ammar and AI2 for sharing the Semantic Scholar Corpus . We also thank the anonymous reviewers , UW - NLP group and Shoou - I Yu for their helpful comments . References Amjad Abu - Jbara and Dragomir Radev . 2011 . Co - herent citation - based summarization of scientiﬁc pa - pers . In Proc . Annual Meeting of the Association for Computational Linguistics : Human Language Tech - nologies . volume 1 , pages 500 – 509 . Heike Adel and Hinrich Sch¨utze . 2017 . Global normal - ization of convolutional neural networks for joint en - tity and relation classiﬁcation . In Proc . Conf . Empir - ical Methods Natural Language Process . ( EMNLP ) . pages 1723 – 1729 . Waleed Ammar , Dirk Groeneveld , Chandra Bhagavat - ula , Iz Beltagy , Miles Crawford , Doug Downey , Ja - son Dunkelberger , Ahmed Elgohary , Sergey Feld - man , Vu Ha , et al . 2018 . Construction of the litera - ture graph in semantic scholar . In Proc . Conf . North American Assoc . for Computational Linguistics : Hu - man Language Technologies ( NAACL - HLT ) , ( Indus - try Papers ) . pages 84 – 91 . Waleed Ammar , Matthew Peters , Chandra Bhagavat - ula , and Russell Power . 2017 . The ai2 system at semeval - 2017 task 10 ( scienceie ) : semi - supervised end - to - end entity and relation extraction . In Proc . Int . Workshop on Semantic Evaluation ( SemEval ) . pages 592 – 596 . Ashton Anderson , Dan McFarland , and Dan Jurafsky . 2012 . Towards a computational history of the ACL : 1980 - 2008 . In Proc . ACL Special Workshop on Re - discovering 50 Years of Discoveries . pages 13 – 21 . Awais Athar and Simone Teufel . 2012a . Context - enhanced citation sentiment detection . In Proc . Conf . North American Assoc . for Computational Lin - guistics : Human Language Technologies ( NAACL - HLT ) . pages 597 – 601 . Awais Athar and Simone Teufel . 2012b . Detection of implicit citations for sentiment detection . In Proc . ACL Workshop on Detecting Structure in Scholarly Discourse . pages 18 – 26 . Isabelle Augenstein , Mrinal Das , Sebastian Riedel , Lakshmi Vikraman , and Andrew McCallum . 2017 . Semeval 2017 task 10 : ScienceIE - extracting keyphrases and relations from scientiﬁc publications . In Proc . Int . Workshop on Semantic Evaluation ( Se - mEval ) . Isabelle Augenstein and Anders Søgaard . 2017 . Multi - task learning of keyphrase boundary classiﬁcation . In Proc . Annu . Meeting Assoc . for Computational Linguistics ( ACL ) . pages 341 – 346 . Kevin Clark and Christopher D . Manning . 2016 . Improving coreference resolution by learning entity - level distributed representations . CoRR abs / 1606 . 01323 . Ronan Collobert and Jason Weston . 2008 . A uniﬁed architecture for natural language processing : Deep neural networks with multitask learning . In Proc . Int . Conf . Machine Learning ( ICML ) . pages 160 – 167 . Huy Hoang Nhat Do , Muthu Kumar Chandrasekaran , Philip S Cho , and Min Yen Kan . 2013 . Extracting and matching authors and afﬁliations in scholarly documents . In Proc . ACM / IEEE - CS Joint Confer - ence on Digital libraries . pages 219 – 228 . Kata G ´ abor , Davide Buscaldi , Anne - Kathrin Schu - mann , Behrang QasemiZadeh , Ha ¨ ıfa Zargayouna , and Thierry Charnois . 2018 . Semeval - 2018 Task 7 : Semantic relation extraction and classiﬁcation in sci - entiﬁc papers . In Proc . Int . Workshop on Semantic Evaluation ( SemEval ) . Kata Gabor , Haifa Zargayouna , Davide Buscaldi , Is - abelle Tellier , and Thierry Charnois . 2016 . Se - mantic annotation of the ACL anthology corpus for the automatic analysis of scientiﬁc literature . In Proc . Language Resources and Evaluation Confer - ence ( LREC ) . Kata G ´ abor , Ha ¨ ıfa Zargayouna , Isabelle Tellier , Davide Buscaldi , and Thierry Charnois . 2016 . Unsuper - vised relation extraction in specialized corpora using sequence mining . In International Symposium on In - telligent Data Analysis . Springer , pages 237 – 248 . Yarin Gal and Zoubin Ghahramani . 2016 . A theoret - ically grounded application of dropout in recurrent neural networks . In Proc . Annu . Conf . Neural In - form . Process . Syst . ( NIPS ) . Sonal Gupta and Christopher D Manning . 2011 . An - alyzing the dynamics of research by extracting key aspects of scientiﬁc papers . In Proc . IJCNLP . pages 1 – 9 . Luheng He , Kenton Lee , Omer Levy , and Luke Zettle - moyer . 2018 . Jointly predicting predicates and argu - ments in neural semantic role labeling . In ACL . Sepp Hochreiter and J¨urgen Schmidhuber . 1997 . Long short - term memory . Neural computation 9 ( 8 ) : 1735 – 1780 . Kokil Jaidka , Muthu Kumar Chandrasekaran , Beat - riz Fisas Elizalde , Rahul Jha , Christopher Jones , Min - Yen Kan , Ankur Khanna , Diego Molla - Aliod , Dragomir R Radev , Francesco Ronzano , et al . 2014 . The computational linguistics summarization pilot task . In Proc . Text Analysis Conference . Miray Kas . 2011 . Structures and statistics of citation networks . Technical report , DTIC Document . Arzoo Katiyar and Claire Cardie . 2017 . Going out on a limb : Joint extraction of entity mentions and relations without dependency trees . In Proc . Annu . Meeting Assoc . for Computational Linguistics ( ACL ) . volume 1 , pages 917 – 928 . Sigrid Klerke , Yoav Goldberg , and Anders Søgaard . 2016 . Improving sentence compression by learning to predict gaze . In HLT - NAACL . Guillaume Lample , Miguel Ballesteros , Sandeep Sub - ramanian , Kazuya Kawakami , and Chris Dyer . 2016 . Neural architectures for named entity recognition . In Proc . Conf . North American Assoc . for Compu - tational Linguistics ( NAACL ) . Kenton Lee , Luheng He , Mike Lewis , and Luke S . Zettlemoyer . 2017 . End - to - end neural coreference resolution . In EMNLP . Kenton Lee , Luheng He , and Luke Zettlemoyer . 2018 . Higher - order coreference resolution with coarse - to - ﬁne inference . In NAACL . Yi Luan , Chris Brockett , Bill Dolan , Jianfeng Gao , and Michel Galley . 2017a . Multi - task learning for speaker - role adaptation in neural conversation mod - els . In Proc . IJCNLP . Yi Luan , Yangfeng Ji , Hannaneh Hajishirzi , and Boyang Li . 2016 . Multiplicative representations for unsupervised semantic role induction . In Proc . Annu . Meeting Assoc . for Computational Linguistics ( ACL ) . page 118 . Yi Luan , Mari Ostendorf , and Hannaneh Hajishirzi . 2017b . Scientiﬁc information extraction with semi - supervised neural tagging . In Proc . Conf . Empirical Methods Natural Language Process . ( EMNLP ) . Yi Luan , Mari Ostendorf , and Hannaneh Hajishirzi . 2018 . The uwnlp system at semeval - 2018 task 7 : Neural relation extraction model with selectively in - corporated concept embeddings . In Proc . Int . Work - shop on Semantic Evaluation ( SemEval ) . pages 788 – 792 . Makoto Miwa and Mohit Bansal . 2016 . End - to - end re - lation extraction using lstms on sequences and tree structures . In Proc . Annu . Meeting Assoc . for Com - putational Linguistics ( ACL ) . pages 1105 – 1116 . Nanyun Peng , Hoifung Poon , Chris Quirk , Kristina Toutanova , and Wen - tau Yih . 2017 . Cross - sentence n - ary relation extraction with graph lstms . Trans . Assoc . for Computational Linguistics ( TACL ) 5 : 101 – 115 . Matthew Peters , Waleed Ammar , Chandra Bhagavat - ula , and Russell Power . 2017 . Semi - supervised se - quence tagging with bidirectional language models . In Proc . Annu . Meeting Assoc . for Computational Linguistics ( ACL ) . volume 1 , pages 1756 – 1765 . Matthew E . Peters , Mark Neumann , Mohit Iyyer , Matt Gardner , Christopher Clark , Kenton Lee , and Luke Zettlemoyer . 2018 . Deep contextualized word repre - sentations . In NAACL . Behrang QasemiZadeh and Anne - Kathrin Schumann . 2016 . The ACL RD - TEC 2 . 0 : A language resource for evaluating term extraction and entity recognition methods . In LREC . Chris Quirk and Hoifung Poon . 2017 . Distant su - pervision for relation extraction beyond the sen - tence boundary . In Proc . European Chapter Assoc . for Computational Linguistics ( EACL ) . pages 1171 – 1182 . Marek Rei . 2017 . Semi - supervised multitask learning for sequence labeling . In Proc . Annu . Meeting As - soc . for Computational Linguistics ( ACL ) . Yanchuan Sim , Noah A Smith , and David A Smith . 2012 . Discovering factions in the computational lin - guistics community . In Proc . ACL Special Workshop on Rediscovering 50 Years of Discoveries . pages 22 – 32 . Sameer Singh , Sebastian Riedel , Brian Martin , Jiaping Zheng , and Andrew McCallum . 2013 . Joint infer - ence of entities , relations , and coreference . In Proc . of the 2013 workshop on Automated knowledge base construction . ACM , pages 1 – 6 . Pontus Stenetorp , Sampo Pyysalo , Goran Topi ´ c , Tomoko Ohta , Sophia Ananiadou , and Jun’ichi Tsu - jii . 2012 . Brat : a web - based tool for nlp - assisted text annotation . In Proc . European Chapter Assoc . for Computational Linguistics ( EACL ) . pages 102 – 107 . Swabha Swayamdipta , Sam Thomson , Chris Dyer , and Noah A . Smith . 2017 . Frame - semantic parsing with softmax - margin segmental rnns and a syntactic scaf - fold . CoRR abs / 1706 . 09528 . Chen - Tse Tsai , Gourab Kundu , and Dan Roth . 2013 . Concept - based analysis of scientiﬁc literature . In Proc . ACM Int . Conference on Information & Knowl - edge Management . ACM , pages 1733 – 1738 . Adam Vogel and Dan Jurafsky . 2012 . He said , she said : Gender in the ACL anthology . In Proc . ACL Special Workshop on Rediscovering 50 Years of Discoveries . pages 33 – 41 . Sam Wiseman , Alexander M . Rush , and Stuart M . Shieber . 2016 . Learning global features for coref - erence resolution . In HLT - NAACL . Yan Xu , Ran Jia , Lili Mou , Ge Li , Yunchuan Chen , Yangyang Lu , and Zhi Jin . 2016 . Improved rela - tion classiﬁcation by deep recurrent neural networks with data augmentation . In Proc . Int . Conf . Compu - tational Linguistics ( COLING ) . pages 1461 – 1470 . Congle Zhang , Stephen Soderland , and Daniel S . Weld . 2015 . Exploiting parallel news streams for unsuper - vised event extraction . TACL 3 : 117 – 129 . Meishan Zhang , Yue Zhang , and Guohong Fu . 2017 . End - to - end neural relation extraction with global op - timization . In Proc . Conf . Empirical Methods Natu - ral Language Process . ( EMNLP ) . pages 1730 – 1740 . Suncong Zheng , Feng Wang , Hongyun Bao , Yuexing Hao , Peng Zhou , and Bo Xu . 2017 . Joint extrac - tion of entities and relations based on a novel tag - ging scheme . In Proc . Annu . Meeting Assoc . for Computational Linguistics ( ACL ) . volume 1 , pages 1227 – 1236 . A Annotation Guideline A . 1 Entity Category • Task : Applications , problems to solve , sys - tems to construct . E . g . information extraction , machine reading system , image segmentation , etc . • Method : Methods , models , systems to use , or tools , components of a system , frameworks . E . g . language model , CORENLP , POS parser , kernel method , etc . • Evaluation Metric : Metrics , measures , or entities that can express quality of a sys - tem / method . E . g . F1 , BLEU , Precision , Recall , ROC curve , mean reciprocal rank , mean - squared error , ro - bustness , time complexity , etc . • Material : Data , datasets , resources , Corpus , Knowledge base . E . g . image data , speech data , stereo images , bilingual dictionary , paraphrased questions , CoNLL , Panntreebank , WordNet , Wikipedia , etc . • Evaluation Metric : Metric measure or term that can express quality of a system / method . E . g . F1 , BLEU , Precision , Recall , ROC curve , mean reciprocal rank , mean - squared error , robustness , compile time , time complex - ity . . . • Generic : General terms or pronouns that may refer to a entity but are not themselves infor - mative , often used as connection words . E . g model , approach , prior knowledge , them , it . . . A . 2 Relation Category Relation link can not go beyond sentence boundary . We deﬁne 4 asymmetric relation types ( Used - for , Feature - of , Hyponym - of , Part - of ) , together with 2 symmetric relation types ( Compare , Conjunction ) . B always points to A for asymmetric relations • Used - for : B is used for A , B models A , A is trained on B , B exploits A , A is based on B . E . g . The TISPER system has been designed to enable many text applications . Our method models user proﬁciency . Our algorithms exploits local soothness . • Feature - of : B belongs to A , B is a feature of A , B is under A domain . E . g . prior knowledge of the model genre - speciﬁc regularities of discourse structure English text in science domain • Hyponym - of : B is a hyponym of A , B is a type of A . E . g . TUIT is a software library NLP applications such as machine trans - lation and language generation • Part - of : B is a part of A . . . E . g . The system includes two models : speech recognition and natural language under - standing We incorporate NLU module to the sys - tem . • Compare : Symmetric relation ( use blue to denote entity ) . Opposite of conjunction , com - pare two models / methods , or listing two op - posing entities . E . g . Unlike the quantitative prior , the qualita - tive prior is often ignored . . . We compare our system with previous sequential tagging systems . . . • Conjunction : Symmetric relation ( use blue to denote entity ) . Function as similar role or use / incorporate with . E . g . obtained from human expert or knowl - edge base NLP applications such as machine trans - lation and language generation A . 3 Coreference Two Entities that points to the same concept . • Anaphora and Cataphora : We introduce a machine reading system . . . The system . . . The prior knowledge include . . . Such knowledge can be applied to . . . • Coreferring noun phrase : We develop a part - of - speech tagging sys - tem . . . The POS tagger . . . A . 4 Notes 1 . Entity boundary annotation follows the ACL RD - TEC Annotation Guideline ( Qasem - iZadeh and Schumann , 2016 ) , with the exten - tion that spans can be embedded in longer spans , only if the shorter span is involved in a relation . 2 . Do not include determinators ( such as the , a ) , or adjective pronouns ( such as this , its , these , such ) to the span . If generic phrases are not involved in a relation , do not tag them . 3 . Do not tag relation if one entity is : • Variable bound : We introduce a neural based approach . . Its beneﬁt is . . . • The word which : We introduce a neural based approach , which is a . . . 4 . Do not tag coreference if the entity is • Generically - used Other - ScientiﬁcTerm : . . . advantage gained from local smooth - ness which . . . We present algorithms ex - ploiting local smoothness in more aggres - sive ways . . . • Same scientiﬁc term but refer to different examples : We use a data structure , we also use an - other data structure . . . 5 . Do not label negative relations : X is not used in Y or X is hard to be applied in Y B Annotation and Knowledge Graph Examples Here we take a screen shot of the BRAT interface for an ACL paper in Figure 9 . We also attach the original ﬁgure of Figure 3 in Figure 10 . More examples can be found in the project website 4 . 4 http : / / nlp . cs . washington . edu / sciIE / Figure 9 : Annotation example 1 from ACL Figure 10 : An example of our automatically generated knowledge graph centered on statistical machine translation . This is the original ﬁgure of Figure 4 .