Will Admins Cope ? Decentralized Moderation in the Fediverse Ishaku Hassan Anaobi 1 , Aravindh Raman 2 , Ignacio Castro 1 , Haris Bin Zia 1 , Dami Ibosiola 1 , and Gareth Tyson 1 , 3 1 Queen Mary University of London , 2 Telefonica Research , 3 Hong Kong University of Science and Technology ( GZ ) Abstract As an alternative to Twitter and other centralized social networks , the Fediverse is growing in popularity . The recent , and polemical , takeover of Twitter by Elon Musk has exacerbated this trend . The Fediverse includes a growing number of decentralized social networks , such as Pleroma or Mastodon , that share the same subscription protocol ( ActivityPub ) . Each of these decentralized so - cial networks is composed of independent instances that are run by diﬀerent administrators . Users , however , can interact with other users across the Fediverse regardless of the instance they are signed up to . The growing user base of the Fediverse creates key challenges for the ad - ministrators , who may experience a growing burden . In this paper , we explore how large that overhead is , and whether there are solutions to alleviate the burden . We study the overhead of moderation on the administrators . We observe a diversity of administrator strategies , with evidence that administrators on larger instances strug - gle to ﬁnd suﬃcient resources . We then propose a tool , WatchGen , to semi - automate the process . 1 Introduction The Fediverse encompasses a group of increasingly pop - ular platforms and technologies that seek to provide greater transparency and openness on the web . [ 18 , 30 , 34 , 13 ] . Well known Fediverse platforms include mi - croblogging services ( e . g . Pleroma [ 38 ] , Mastodon [ 33 ] ) and video sharing platforms ( e . g . PeerTube [ 37 ] ) . The acquisition of Twitter by Elon Musk [ 11 ] has exacerbated this popularity with a large migration of Twitter users to the Fediverse [ 8 ] . In Fediverse social networks , individuals or organisa - tions can install , own , and manage their own indepen - dent servers , also known as instances [ 15 , 54 ] . For these instances to interact , they rely on federation [ 41 ] , whereby instances interconnect in a peer - to - peer fash - ion to exchange posts . Note that this allows for users to exchange content across platforms . This results in a physically decentralized model that is logically intercon - nected where users can interact globally . Unfortunately , this creates challenges for instance administrators , as activities on one instance impact others via federation . For example , recent work has shown that hateful ma - terial generated on one instance can rapidly spread to others [ 53 ] . To overcome this , most Fediverse social network im - plementations have in - built federation policies . These policies enable administrators to create rules to ban or modify content from instances that matches certain rules , e . g . banning content from a particular instance or as - sociating it with warning tags . Although a powerful tool , this imposes an additional overhead on adminis - trators [ 26 , 14 , 6 ] . Thus , we argue it is vital to better understand this process , and propose ways to improve it . This paper examines administrator activities in the Fe - diverse . We focus on Pleroma , a federated microblogging platform with similar functionality to Twitter . We col - lect a large - scale dataset covering 10 months : this in - cludes 1 , 740 instances , 133 . 8k users , 29 . 9m posts , asso - ciated metadata , and importantly , the policies setup by the administrators . We ﬁnd that instances are often “un - derstaﬀed” , with the majority of instances only having a single administrator , and recruiting no other moderators to assist , despite many having over 100K posts . This leads us to conjecture that some administrators may be overwhelmed . Indeed , we ﬁnd that instance adminis - trators often take many months before applying policies against other instances , even in cases where they exhibit clearly controversial traits ( e . g . posting a large number of hate words ) . We therefore turn our attention to the policy conﬁgu - rations employed . We observe a growing number of in - stances enacting a wide range of policy types . Common are ‘maintenance’ policies , such as those which automat - ically delete older posts ( ObjectAgePolicy ) , as well as those aimed at preventing the spread of certain content ( e . g . HashtagPolicy , which ﬂags up posts with certain hashtags ) . We further observe a range of bespoke policies created by administrators , via the SimplePolicy , which can be conﬁgured to trigger a range of actions based on certain rules ( e . g . blocking all connections from certain instances ) . The laborious nature of this moderation work leads us to explore automated techniques to assist admin - istrators . We build a set of models to predict administra - tor actions . We embed them in WatchGen , a tool that can propose a set of instances for administrators to focus their moderation eﬀorts on . To the best of our knowl - edge , this is the ﬁrst study of Fediverse administrators . We make the following observations : 1 a r X i v : 2302 . 05915v1 [ c s . S I ] 12 F e b 2023 1 . We ﬁnd a diverse range of 49 policies used by admin - istrators , capable of performing various management and moderation tasks . Despite this , we see that 66 . 9 % of instances are still running , exclusively , on the default policies alone ( Section 4 ) . 2 . The number of administrators does not grow pro - portionately with the number of posts ( Section 5 ) . This seems to impact moderation . For example , it takes an average of 82 . 3 days for an administrator to impose a policy against an instance after it ﬁrst encounters it , even for well - known and highly con - troversial ones ( e . g . gab . com [ 5 ] ) . 3 . Intuitive features , such as the number of mentions and frequent use of hate words , are good indica - tors that an instance will later have a policy applied against it ( Section 6 ) . This suggests that there are key traits that garner more attention by moderators . 4 . We show that it is possible to predict ( F1 = 0 . 77 ) which instances will have policies applied against them ( Section 6 ) and design WatchGen , a tool that ﬂags particular instances for administrators to pay special attention to . 2 Pleroma : Overview Pleroma is a lightweight decentralized microblogging server implementation with user - facing functionality sim - ilar to that of Twitter . In contrast to a centralized social network , Pleroma is a federation of multiple indepen - dently operated servers ( aka instances ) . Users can reg - ister accounts on these instances and share posts with other users on the same instance , or on diﬀerent in - stances . Through these instances , users are able to reg - ister accounts and share posts ( called statuses ) to other users on the same instance , other Pleroma instances , or instances from other Fediverse platforms , most notably Mastodon . Federation . We refer to users registered on the same instance as local , and users on diﬀerent instances as re - mote . A user on one instance can follow another user on a separate instance . Note that a user registered on their local instance does not need to register with the re - mote instance to follow the remote user . When the user wants to follow a user on a remote instance , the local instance subscribes to the remote user on behalf of the local user using an underlying subscription protocol ( Ac - tivityPub [ 2 ] ) . This process of peering between instances in the Fediverse is referred to as federation . The federated network includes instances from Pleroma and other platforms ( e . g . Mastodon ) that sup - port the same subscription protocol ( ActivityPub ) . Ac - cordingly , Pleroma instances can federate and target their policies at non - Pleroma instances . The resulting network of federated instances is referred to as the Fedi - verse ( with over 23k servers [ 16 ] ) . Policies . Policies aﬀect how instances federate with each other through diﬀerent rule - action pairs . These al - low certain actions to be executed when a post , user , or instance matches pre - speciﬁed criteria . For example , the SimplePolicy can perform a range of actions when a re - mote instance matches certain criteria such as reject ing connections . Note , there are numerous in - built policies , but tech - savvy administrators can also write their own bespoke policies . Administrators . Instances are hosted and managed by specialized users called administrators . By default , the creator of an instance will take on the role of the admin - istrator , however , it is also possible to delegate such re - sponsibilities to multiple others . Instance administrators are responsible for carrying out the day - to - day adminis - trative tasks on the instances . These include managing the front - end , users , uploads , database , emoji packs and carrying out administrative email tasks . The instance administrator is also responsible for accepting new user registrations and removing users where necessary . The administrator updates and backs - up the instance , set the terms of service and retains the ability to shutdown the instance . One essential responsibility of the instance ad - ministrator is the moderation of content ( although they can also assign the role to other users called moderators ) . This can make instance administration a cumbersome task , and administrators a very important part of the Fediverse . 3 Data Collection Instance & Administrator Dataset . Our mea - surement campaign covers 16th Dec 2020 – 19th Oct 2021 . We ﬁrst compile a list of Pleroma instances by crawling the directory of instances from distsn . org and the - federation . info . We then capture the list of instances that each Pleroma instance has ever federated with using each instance’s Peers API . 1 Note , this includes both Pleroma and non - Pleroma instances . In total , we identify 9 , 981 instances , out of which 2 , 407 are Pleroma and the remainder are non - Pleroma ( e . g . Mastodon ) . We then collect metadata for each Pleroma instance every 4 hours via their public API . 2 We record the list of administrators and any delegated moderators . We also obtain the number of users on the instance , the number of posts , the enabled policies , the applied policies as well as the instances targeted by these policies , and other meta information . From the 2 , 407 Pleroma instances , we are able to gather data from a total of 1 , 740 instances ( 72 . 28 % ) . 1 (cid:104) instance . uri (cid:105) / api / v1 / instance / peers 2 (cid:104) instance . uri (cid:105) / api / v1 / instance / 2 For the remaining 667 instances : 65 . 1 % have non ex - istent domains , 17 . 9 % are not found ( 404 status code ) , 6 . 4 % instances has private timelines ( 403 ) , 4 . 5 % result in Bad Gateway ( 502 ) , 1 . 3 % in Service Unavailable ( 503 ) , and under 1 % return Gone ( 410 ) . User Timelines . Users in Pleroma have three time - lines : ( i ) a home timeline , with posts published by the accounts that the user follows ( local and remote ) ; ( ii ) a public timeline , with all the posts generated within the local instance ; and ( iii ) the whole known network , with all posts that have been retrieved from remote instances that the local users follow . Note , the whole known net - work is not limited to remote posts that a particular user follows : it is the union of remote posts retrieved by all users on the instance . We use the public Timeline API 3 to gather posts data from 819 instances ( the remaining 912 instances have either no posts or unreachable public timelines ) . Ethics . Our dataset covers Pleroma instances and their administrators . We exclusively focus on the policies that these administrators set , and do not investigate other aspects of administrator behavior ( e . g . the posts they share ) . All data is available via public APIs . We empha - size that administrators , themselves , are the ones who control access to these APIs . Hence , the administrators covered in this paper consent for others to use this data . Further , the policies studied do not work on a per - user granularity and , thus , we cannot infer anything about individual users . All data is anonymized before usage , and it is stored within a secure silo . 4 Exploring Policy Conﬁgura - tions Policy Footprint . We ﬁrst quantify the presence of policies across instances . In total , we observe 49 unique policy types . From our 1 . 74k Pleroma instances , we re - trieve policy information from 93 . 2 % of instances ( the re - mainder do not expose their policies ) . These cover 94 . 2 % of the total users and 94 . 5 % of all posts . Figure 1 shows the distribution of the top 15 policy types enabled by the administrators across instances and the percentage of users signed up within those instances as well as the posts on the instances . We see a wide range of policies with diverse functionalities and varying coverage based on which metric is considered . For instance , whereas the ObjectAgePolicy ( which performs an action on a post once it reaches a certain age ) is installed on 74 . 8 % of in - stances , this only covers 52 . 4 % of the users . In contrast , the KeyWordPolicy ( which performs an action on any posts containing a given keyword ) covers 18 . 8 % of users , but just 3 % instances . Critically , there is a highly un - even distribution of policies , with the the top - 5 covering 3 (cid:104) instance . uri (cid:105) / api / v1 / timelines / public ? local = true 0 10 20 30 40 50 60 70 80 Percentage ( % ) NormalizeMarkup EnsureRePrepended ActivityExpirationPolicyForceBotUnlistedPolicyAntiLinkSpamPolicyKeywordPolicy MediaProxyWarmingPolicyAntiFollowbotPolicyOthersHellthreadPolicyStealEmojiPolicyNoOpPolicySimplePolicyHashtagPolicyTagPolicyObjectAgePolicy P o li c i es Users Posts Instances Figure 1 : The top 15 policies and percentage of instances that use each policy ( sorted by the percentage of in - stances ) . 92 . 3 % of all instances , 73 . 6 % of users and 88 . 8 % of the posts . Default Policies . Default policies come auto - enabled with new installations . Prior to version 2 . 3 . 0 in March , 2021 , only the ObjectAgepolicy and NoOpPolicy are enabled by default . Since version 2 . 3 . 0 , the TagPolicy and HashtagPolicy are also enabled with a new instal - lation ( or upgrade ) . 66 . 9 % of instances only have these default policies running . Relying solely on default poli - cies may indicate several things . For example , adminis - trators maybe unaware of management and moderation functionalities , unable to use them or simply not have suﬃcient time . Alternatively , they may actively choose not to use them . Note , while the TagPolicy allows tagging user posts as sensitive ( default : nsfw ) , the Hashtagpolicy allows the tagging of hashtags ( e . g . nsfw sensitive ) . We ﬁnd 54 . 6 % and 34 . 3 % of instances enabling these policies respectively . The other Pleroma default policy is the NoOpPolicy . This allows any content to be imported . This describes the default state of a new instance . In - terestingly , we see administrators paying more attention to this policy : 89 . 7 % of the instances have actively dis - abled it . 4 This suggests that administrators are aware and concerned about importing undesirable content . Non - Default Policies . Non - default policies are those that instance administrators have to actively enable . In - stances with these policies may indicate a more proactive administrator . We ﬁnd 45 non - default policies during our data collection period . The most powerful policy available is the SimplePolicy , enabled on 28 . 8 % of instances . This policy allows administrators to apply a wide range of actions against speciﬁc instances ( e . g . gab . com ) . The most impactful and common is the reject action . 5 56 . 9 % of instance that enable the SimplePolicy employ the reject action . Interestingly , although we see only 4 Note , this is overridden if a user enabled any other policy . 5 This blocks all connections from a given instance 3 28 . 8 % of instances with the SimplePolicy enabled , its application aﬀects 85 . 4 % of users and 90 . 3 % of the posts on the Pleroma platform . We see noteworthy instances being amongst the top targets of this policy ( e . g . kiwi - farms . cc and anime . website ) , which are all commonly understood to share controversial material . Interest - ingly , only 18 . 5 % of instances with the SimplePolicy applied against them are from the Pleroma platform ( the most are from Mastodon [ 39 ] ) . This means that 81 . 5 % of the recipients are from federated instances outside of Pleroma . Policy Growth . We next look at how the use of poli - cies has changed over time . We conjecture that the longer administrators run their instances , the more experienced they become . As such , we expect to see greater appli - cation of policies . Here we focus on the 5 most popu - lar policies as they account for 92 . 3 % of the instances , 73 . 6 % of users and 88 . 8 % of the posts . For complete - ness , we include the sum of the other less popular poli - cies too . Figure 2 presents the percentage of instances that activate each policy over time . Across our measure - ment period , we observe a growth of 40 % in the total number of policies used . This suggests that the use of policies is becoming more common . 28 . 5 % of these poli - cies are introduced by new instances coming online , with newly installed default policies , e . g . ObjectAgepolicy , TagPolicy and HashtagPolicy . The remainder are in - stantiated by pre - existing instance administrators that update their policies , suggesting a relatively active sub - set of administrators . We also inspect the growth on individual instances . Overall , 42 % of instances add policies during our mea - surement period . Of these instances , 52 . 3 % enable only one extra policy and we see only a small minority ( 1 . 9 % ) enabling in excess of 5 new policies ( e . g . chaos . is en - ables 13 and poa . st 12 ) . A closer look at these instances show they mostly add common policies . However , we also see a wide range of other less common policies ( e . g . KeywordPolicy ) . In contrast , the use of the SimplePolicy , with the most ﬂexible range of moderation actions , has remained relatively stable . Actions under the SimplePolicy have instance - wide eﬀect and can eﬀectively control instance federation . Overall , we only see 28 . 8 % of instances en - abling this policy , without much growth across the mea - surement period ( as seen in Figure 2 ) . This could im - ply that administrators are unaware of this policy , do not have time to moderate their instances at this level or maybe ﬁnd this policy too blunt ( not ﬁne - grained enough ) . The latter could lead to other issues , which ad - ministrators seek to avoid ( e . g . collateral damage [ 22 ] ) . It is also worth noting that the SimplePolicy is one of the most complex , and administrators potentially shy away from these more labour - intensive policies . We argue that the diversity of policies could potentially overwhelm ( volunteer ) instance administrators ( see Sec - 2020 - 12 2021 - 01 2021 - 02 2021 - 03 2021 - 04 2021 - 05 2021 - 06 2021 - 07 2021 - 08 2021 - 09 2021 - 10 2021 - 11 0 10 20 30 40 % o f I n s t a n ces ObjectAgePolicy TagPolicy HashtagPolicy SimplePolicy NoOpPolicy Others Figure 2 : Time series showing the percentage of instances ( Y - axis ) that use the 5 most popular Pleroma policies . We include the sum of all the remaining policies as “Oth - ers” . 1 2 3 4 5 6 7 8 12 13 16 # of Administrators 0 10 20 30 40 50 60 70 % o f i n s t a n c e s Figure 3 : Instances ( % ) by number of administrators . tion 5 ) . This suggest that they require further support to automate this process ( see Section 6 ) . 5 Characterising Administrators 5 . 1 Distribution of Administrators Number of Administrators Per - Instance . We ob - serve a total of 2 , 111 unique administrators from 1 , 633 instances ( 93 . 8 % of 1 . 74k ) . 6 Figure 3 presents the dis - tribution of the number of administrators per instance . Although a majority of instances ( 71 . 6 % ) are managed by a single administrator , we also see some instances with a larger number of administrators ( e . g . rakket . app : 16 and poa . st : 13 ) . Administrator Workload . We next test if the number of administrators increases proportionately to the num - ber of posts . We treat this as a rudimentary proxy for how much moderation must take place on an instance . Figure 4 presents the distribution of posts on instances 6 The remaining instances do not publish their administrator ( s ) information . 4 1 2 3 4 5 6 7 8 12 13 16 # of Administrators 10 0 10 1 10 2 10 3 10 4 10 5 10 6 P o s t s Figure 4 : Box plot of the number of posts per instances with diﬀerent number of administrators . vs . the number of administrators . Generally , we ﬁnd that instances with more posts do have more administrators on average , e . g . instances with multiple administrators have more posts , with a ratio of 6 : 1 . However , this is driven by a few instances ( e . g . poa . st ) . Table 3 summarizes the top 10 instances that see the largest growth in administrators . Many of them are small instances with under 1000 users , and a proportionately small number of posts . This suggests that administrator growth does not necessarily occur on the instances that need it the most . To test if the number of administrators grow proportionately to the number of posts , Figure 5 plots the growth of administrators vs . the growth of posts on each individual instance during our data collection pe - riod . We see that a growth in posts on a given instance does not necessarily correspond to the recruitment of new administrators . In fact , only 6 . 9 % of instances record a growth in administrators during this period . Overall , there is a weak correlation ( Spearman coeﬃcient of 0 . 19 for the number of posts vs . number of administrators ) . In total , we see a 60 . 3 % increase in the number of posts , but just a 35 . 6 % growth in administrators . Unsurpris - ingly , instances that grow their administrator pool do become more active . On average , instances with a grow - ing number of administrators have 1 . 5x more policies than other instances . Speciﬁcally , looking at the policy with the most impact ( reject ) , these instances apply it 1 . 8x more than others . Interestingly , instances with an increasing number of administrators also have 4x more policies applied against them . 5 . 2 Administrators’ Response Lag The previous section has shown that administrators face a growing moderation workload . To study this workload , we now look at how long it takes administrators to ap - ply polices against particular instances . We focus on the SimplePolicy as this is clearly geared towards moder - ation , has instance - wide targeting , and lists the target instances . For each SimplePolicy against a given in - 0 200 400 600 800 1000 1200 1400 1600 Instances 10 0 10 1 10 2 10 3 10 4 10 5 10 6 P o s t G r o w t h Post growth 0 1 2 3 4 5 6 A d m i n G r o w t h Admin growth Figure 5 : Per instance growth in the number of admin - istrators ( Y2 - axis ) and posts ( Y1 - axis ) . Individual in - stances are on the X - axis , sorted by the number of posts . 0 50 100 150 200 250 # of Days 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 CD F All moderated Top10 moderated Bottom10 moderated Figure 6 : CDF showing the distribution of days from federation to moderation for all moderated instances . We also show results for the top 10 and bottom 10 instances , based on the number of policies applied against them . stance , we compute the lag between the date of the imple - mentation of the policy and the date when the targeted instance was ﬁrst federated with . This is a rudimentary proxy for how long it took an administrator to identify the problem . We temper our analysis with the fact that there could be many reasons for this delay , which we have limited vantage on . Policy Creation Delay . Figure 6 presents the distri - bution of delays ( as deﬁned above ) . Note , we exclude the 55 % of federations that occurred before the beginning of our data collection ( as we cannot know their times - tamp ) . We plot the delay distributions for applying poli - cies against : ( i ) All instances ; ( ii ) “Controversial” in - stances with the most policies applied against them ( top 10 ) ; and ( iii ) “Benign” instances with the fewest policies against them ( bottom 10 ) . It takes administrators an average of 82 . 3 days to apply any form of policy against other instances . Although , on average , it takes more time for a policy to be applied on the “bottom 10” instances than the ”top 10” instances ( 74 . 7 and 59 . 5 days respectively ) , we see that there is a noticeable lag ( almost 3 months ) between federation occurring and policies being imposed . This may suggest 5 ne ck bea r d . xyz an i m e . w eb s i t e ba r aag . ne t pa w oo . ne t s i nb l r . c o m s w i tt e r . a t k i w i f a r m s . cc hu m b l r . s o c i a l f r ee s pee c he x t r e m i s t . c o m gab . c o m 0 50 100 150 200 250 300 # o f d ays Figure 7 : Box plot showing the distribution of the num - ber of days from federation to the imposition of policies for the top 10 instances with the most policies applied against them . that administrators ﬁnd it diﬃcult to keep - up with the need to rapidly identify instances that justify policy im - position . Delay for Controversial Instances . We next extract the top 10 instances that receive the most policies tar - geted against them . For each one , Figure 7 plots the distribution of delays ( i . e . how long it takes other in - stances to impose a policy against them ) . In - line with expectations , we see that administrators take less time to apply policies against instances like gab . com , known for its right - wing stance ( average of 19 days ) . However , we see much longer delays for other controversial instances that are less well - known ( e . g . neckbeard . xyz ) , averag - ing up to 98 . 4 days . These instances are quite active , with signiﬁcant growth in posts during our measurement period ( e . g . neckbeard . xyz : 789 . 4k and kiwifarms . cc : 469 . 2k ) . With other instances such as anime . website posting “lolicon” ( suggestive art depicting prepubescent females ) , it is expected that policies would be swift , how - ever , we see a very wide breadth of delays . The diverse nature of these administrator reactions indicates that any future automated moderation tools should be specialized to the preferences of individual administrators . 5 . 3 Administrators & Moderators Moderation Delegation . As administrators are re - sponsible for a wide range of activities , they can dele - gate the task of content moderation to select individuals . These accounts are referred to as moderators . Of our 1 . 74k instances , 47 % of them ( 819 ) expose information in our dataset . From these , only 12 % ( 98 ) of instances have assigned the role of moderator to any other accounts . Of these , 73 . 5 % ( 72 ) of the instances have the administra - tor also doubling as a moderator , while 29 . 6 % ( 29 ) of the instances assign the entire moderator role to an account that is not the administrator . This implies that only 3 . 5 % of instances have dedicated account ( s ) assigned the role of moderator . O b j e c t A ge P o li cy T ag P o li cy H a s h t ag P o li cy S i m p l e P o li cy N o O p P o li cy H e ll t h r ead P o li cy S t ea l E m o ji P o li cy A n t i F o ll o w bo t P o li cy M ed i a P r o xy W a r m i ng P o li cy K e y w o r d P o li cy A n t i L i n k S pa m P o li cy F o r c e B o t U n li s t ed P o li cy A c t i v i t y E x p i r a t i on P o li cy E n s u r e R e P r epended N o r m a li z e M a r k up Policies 0 5 10 15 20 25 % o f I n s t a n ces No additional moderators Additional moderators Figure 8 : The percentage of instances that enable the top 15 most popular policies . We separate instances into two groups : ( i ) Instances without additional moderators ; and ( ii ) instances with additional moderators outside of the administrator set . Are moderators helpful ? We conjecture that in - stances with dedicated moderators outside of their ad - ministrator team might be swifter in the application of policies . Figure 8 shows the percentage of instances that enable the 15 most popular policies ( Figure 1 ) . We present two bars for each policy : ( i ) Instances with additional moderators ( who are not an administra - tor ) ; and ( ii ) Instances without additional moderators . There is a broadly similar distribution across these two groups . However , we notice that instances without ad - ditional moderators have approximately 3x more of the NoOpPolicy conﬁgured . Recall , this is the default state of an instance and allows any content to be imported . This begins to suggest that instances with additional moderators do pay greater attention to policies . We expand this analysis in Figure 9 , where we show the number of SimplePolicy actions and the delay to apply a policy after federation ( in days ) for instances in the two groups . We use the SimplePolicy for this anal - ysis as it is the only moderation policy with instance - wide targeting and a list of targeted instance domains . The plot shows that instances with moderators take less time ( average 103 days ) to impose a SimplePolicy af - ter federation , compared to instances without dedicated moderators ( average 111 days ) . The ﬁgure also shows a marked diﬀerence in the number of instances that apply the SimplePolicy . Only 38 % of the instances with ded - icated moderators apply no SimplePolicy actions , com - pared to 70 % for those without . This conﬁrms that in - stances with additional moderators are more proactively moderated . 6 10 0 10 1 10 2 # of SimplePolicy actions 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 CD F Additional moderators ( policy ) Additional moderators ( days ) 10 0 10 1 10 2 # of Days No additional moderators ( policy ) No additional moderators ( days ) Figure 9 : CDF of the number of SimplePolicy actions per instance ( X1 - axis ) and the lag ( in days ) for instances to impose a policy after federation ( X2 - axis ) . We sepa - rate instances into ( i ) those with dedicated moderators ; and ( ii ) those without dedicated moderators . 6 WatchGen : Automating Mod - eration Our results indicate that moderation is labor - intensive . We now explore techniques to assist administrators . We propose WatchGen , 7 a tool that recommends to admin - istrators a “watchlist” of instances that may require fed - erated moderation . This watchlist must be on a per - instance basis , as diﬀerent administrators may have vary - ing views on what is considered appropriate for the in - stance they manage . WatchGen , helps administrators to more proactively identify instances requiring attention with regards to content moderation . We build Watch - Gen by compiling a large feature set for each instance , and experimenting with a number of classiﬁcation models to ﬂag instances that are more likely to require attention . Feature Selection . We ﬁrst extract features for each instance . These features include information about user ( e . g . number of users ) and administrator activities with respect to moderation ( e . g . number of rejected in - stances ) . We also extract features from post content ( e . g . number of hate words in posts ) . We experiment with a total of 38 features ( see Table 5 ) . Through extensive manual experimentation , we distil this down to the 16 most determinant features ( highlighted in Table 5 ) . Model Training . Next , we train multiple machine learning models using the sklearn library , and Grid - SearchCV within 5 - fold cross - validation to ﬁnd the opti - mal hyper - parameter settings . We detail below the hy - perparameters for each model . Logistic Regression ( LR ) . We only tune the C hyper - parameter . This regularization parameter controls how closely the model ﬁts to the training data . We test for best value of ”C” using the values { 0 . 001 , 0 . 01 , 0 . 1 , 1 , 7 https : / / github . com / anaobi / WatchGen . git 10 , 100 , 1000 } . Multilayer Perceptron ( MLP ) . We tune three hy - perparameters : ( i ) hidden layer - size : dictates the num - ber of hidden layers and nodes in each layer . We use a single hidden layer with varying hidden layer - sizes { 10 , 50 , 100 } ; ( ii ) activation function : determines the type of non - linearity introduced into the model . We employ 3 activation functions { relu , tanh , logistic } ; and ( iii ) learn - ing rate : we tune how the initial learning rate parameter changes in ﬁnding the optimal model using { constant , invscaling , adaptive } . Random Forest ( RF ) . We tune 2 hyperparameters . ( i ) n estimators : the number of independent trees ( es - timators ) . We test using 3 values { 5 , 50 , 250 } ; and ( ii ) max depth : the depth of the trees . We test for best result using 6 diﬀerent depths { 2 , 4 , 8 , 16 , 32 , None } . Gradient Boosted Trees ( GB ) . We tune three hy - perparameters . ( i ) n estimators : The number of inde - pendent trees ( estimators ) . We test with 4 value { 5 , 50 , 250 , 500 } ; ( ii ) max depth : The depth of the trees . We test with 5 values { 1 , 3 , 5 , 7 , 9 } . ( iii ) Learning rate : This impacts the speed and granularity of the model training . We test 5 values { 0 . 01 , 0 . 1 , 1 , 10 , 100 } . 6 . 1 Generating a Global Watchlist Task . We ﬁrst assume a WatchGen central broker that compiles a global pool of training data , collected from all instances through their public APIs ( similar to us in Section 3 ) . We use this global pool of training data , with an 80 : 20 split , to predict if a given instance will be subject to any policy ( by any other instance ) . We then produce a ‘watchlist’ of instances that may be worthy of attention . To investigate how long it would take to garner suﬃ - cient data to train WatchGen , we also train several mod - els on datasets covering increasing time windows . We ﬁrst train on one month of data and increase the train - ing dataset by one month at a time ( up to 9 months ) . For our test dataset , we use the data remaining after the training snapshot . Results . Table 1 summarizes the result with the global pool of training data ( 80 : 20 split ) with Random Forest being the best performing model ( f1 = 0 . 77 ) . Recall , that we also run experiments with a training set based on varying time windows . Figure 10 presents the f1 scores based on the size ( duration ) of the training set . We observe that it takes at least 5 months for a model to achieve its best score ( e . g . Gradient Boosted Trees is month 5 and Random Forest in month 7 ) . Note that the training sets are diﬀerent from Table 1 and hence the scores diﬀer . Feature Importance . We next inspect which features are most important . This sheds insight into which char - acteristics are most related to triggering policies . We use 7 m on t h1 m on t h2 m on t h3 m on t h4 m on t h5 m on t h6 m on t h7 m on t h8 m on t h9 Algorithm 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 f 1 - sc o r e LR MLP RF GB Figure 10 : Time series of f1 - scores for the Logistic Re - gression , Multi - Layer Perceptron , Random Forest and Gradient Boosted Trees models . Note that we exempt month 10 as this leaves insuﬃcient test data . Algorithm Acc . Prec . Recall f1 score Logistic Regression 0 . 86 0 . 85 0 . 34 0 . 49 Multi - Layer Perceptron 0 . 57 0 . 34 0 . 42 0 . 53 Random Forest 0 . 92 0 . 88 0 . 68 0 . 77 Gradient Boosted Trees 0 . 89 071 0 . 71 0 . 71 Table 1 : WatchGen performance results when using global training pool and the full feature set . the in - built functions for feature importance . Figure 11 presents the feature importance for the explainable mod - els . We see that the top 3 features ( transformed post , av - erage number of mentions in a post , and number of posts on an instance ) are all related to the number of posts on an instance . This suggests that the likelihood of an in - stance having a policy applied against it is closely related to the amount of content its users post . In other words , the more users and posts on an instance , the higher the probability of having a policy applied against it . This is expected as such instances are likely to attract more attention . Features such as the number of mentions and hate words in the posts also play an important role . This is in - line with prior work that observed how mentions and quote retweets result in more attention [ 17 ] . To better understand the importance of these secondary metrics , we retrain the model without the two top features ( num - ber of posts and transformed posts ) . We show the results in Table 4 . Conﬁrming our prior assertion , we retain rel - atively good performance . For Random Forest , we attain an f1 of 0 . 62 ( vs . 0 . 77 with the full feature set in Table 5 ) . This conﬁrms that these other factors play an important role in determining if an instance has a policy applied against it . In other words , in addition to the size of an instance , other features are required to obtain a fairly good prediction of instances being subject to any policy . 6 . 2 Generating a Local Watchlist Task . Our prior WatchGen models assume a central pool of training data , aggregated from all instances . This may be infeasible in practice due to the decentralized na - ture of the Fediverse . Hence , we next investigate how well our best model ( Random Forest ) performs when de - centralizing the training process . For each instance , we extract its federated peers and exclusively build a lo - cal training set from their data ( using the features high - lighted in Table 5 ) . For each pair of instances , we tag whether or not a directed policy is imposed , i . e . each in - stance only considers the policies it locally sees . Finally , each instance trains its own local model using the ﬁrst 8 months of data ( and tests on the last 2 ) . This creates one independent model per - instance . Based on this , Watch - Gen predicts whether a policy will be applied against the instance . Results . Figure 12 presents the distribution of perfor - mance metrics per - instance . As expected , we observe an overall performance drop compared to the prior task based on a global model . Instances attain an aver - age f1 score of 0 . 55 . This is largely due to the sig - niﬁcant reduction in per - instance training data . That said , we observe a wide array of performances across the instances : 42 . 6 % of instances achieve above 0 . 6 f1 , with a tail of 8 . 3 % attaining below 0 . 4 f1 . We ﬁnd that performance is impacted by the training set size . Instances that perform relatively well ( > = 0 . 6 f1 ) , tend to be larger ( i . e . more posts and users ) . For example , 65 . 4 % of the best performing instances ( > = 0 . 6 f1 ) have a local post count of over 50k ( e . g . neckbeard . xyz and freespeechextremist . com ) . In contrast , only 4 . 4 % of instances that perform poorly ( < 0 . 6 f1 ) have over 50k posts ( e . g . princess . cat and sleepy . cafe ) . This im - plies that as instances grow , their local performance will improve . The above experiments show that instances can use these locally trained models to generate a per - sonalized watchlist of instances they peer with . Thus , we argue that these automatically compiled lists can helps administrator pay attention to these instances . 7 Related Work Social Network Studies . Extensive work has been carried out in the area of online social networks . How - ever , most of these are on centralized social networks ( e . g . Facebook and Twitter ) [ 29 , 31 , 19 , 28 , 3 , 36 ] . A number of these look at the anatomy of social graphs [ 23 ] and moderation challenges [ 20 ] . Others look into areas ranging from the evolution of user activities to demo - graphics [ 32 , 45 ] . In contrast to Pleroma , these social networking platforms tend to rely on central ( commer - cial ) administrators and moderators [ 48 ] . Fediverse and Decentralized Web . Only a small set 8 0 . 00 0 . 05 0 . 10 0 . 15 0 . 20 0 . 25 Importance reject _ deletes hashtag _ avg quaran _ inst fed _ time _ rem mentions _ countnsfw hate _ avg media _ removalurl _ counturl _ avgusersposts mentions _ avg posts _ tr F e a t u r e s Logistic Regression ( a ) Logistic Regression 0 . 000 0 . 025 0 . 050 0 . 075 0 . 100 0 . 125 0 . 150 0 . 175 Importance reject _ deletes quaran _ inst media _ removalnsfw fed _ time _ rem hashtag _ avg hate _ avg url _ counturl _ avg mentions _ countusers mentions _ avg posts _ tr posts F e a t u r e s ( b ) Random Forest 0 . 00 0 . 05 0 . 10 0 . 15 0 . 20 0 . 25 Importance reject _ deletesnsfw media _ removal quaran _ inst hate _ avg hashtag _ avg fed _ time _ rem url _ count mentions _ counturl _ avgusers posts _ tr posts mentions _ avg F e a t u r e s ( c ) Gradient Boosted Trees Figure 11 : Feature importance for our explainable models . 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 Scores 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 C D F Accuracy precision recall f1 Figure 12 : CDF of per - instance performance for Random Forest trained on data from local and federated instances . of studies have focused on the Fediverse or Decentralized Web applications . Raman et al . looked at the challenges in the Fediverse , with a particular focus on the infras - tructure and resilience of Mastodon [ 39 ] . Trautwein et al . studied the Inter Planetary File System ( IPFS ) , a decen - tralized storage solution [ 44 ] . Guidi et al . and Datta et al . studied the structure , data management , and privacy aspects of decentralized social networks [ 7 , 1 ] . Recent works have examined the standardization of related pro - tocols [ 27 , 35 ] . Bielenberg et al . analyzed the growth , topology and server reliability of Diaspora ( a decentral - ized social network ) [ 4 ] . Similarly , Zignani et al . studied the evolution of the Mastodon social graph [ 55 ] . Our work diﬀers in that we focus on exploring administrator actions within the Fediverse . Online Moderation . Prior work has investigated the roles that volunteer moderators play in platforms like Twitch [ 51 ] . Text - based content classiﬁcation and ﬁlter - ing has been extensively studied too . These include com - putational techniques to detect cyberbullying [ 12 , 49 , 10 ] , anti - social posting [ 43 , 25 , 42 , 52 ] , and hate speech [ 9 , 46 , 40 , 50 , 21 , 47 , 24 ] . These models have proven eﬀec - tive in reducing the workload of human moderators . For example , Cheng et . al . [ 25 ] use random forest and logis - tic regression classiﬁers to predict whether a user will be banned , reducing the manual load on moderators . Simi - larly , Zia et al . [ 53 ] look at detecting the spread of toxic posts speciﬁcally in Pleroma ( although not administra - tor reactions ) . In our prior work , we also studied the use of federation policies [ 22 ] . Here , we build on this , with a focus on the actions undertaken by administrators . We further propose WatchGen to assist administrators . To the best of our knowledge , this is the ﬁrst large - scale study of administrator activities in the Fediverse . We hope that this can further contribute to the wider un - derstanding of moderation in other platforms . 8 Conclusion and Discussion We have studied instance administrators in a popular Fe - diverse platform , Pleroma . Although 66 . 9 % of instances are still running on default policies , we observe an up - take of more sophisticated management functions . We ﬁnd evidence that some administrators may become over - whelmed with the growing number of posts and users they must manage . For instance , it takes an average of 82 . 3 days for administrators to apply any policy against a newly federated instance . Another sign of the over - head is that just 3 . 5 % of instances share the load across multiple moderators . This lack of moderators may come with challenges : instances with fewer moderators tend to employ less sophisticated policy strategies ( e . g . 70 % of them apply no SimplePolicy actions ) . To alleviate this , we have proposed WatchGen , a tool that identi - ﬁes instances in need of closer attention . We show that WatchGen can predict which instances will later have a policy imposed ( f1 = 0 . 77 ) . Our study opens up a number of lines of future work . First , we wish to expand our work to cover other Fedi - verse platforms , e . g . Mastodon or PeerTube . Second , we plan to experiment with alternate feature sets that can better identify instances that will later require policy at - tention . Through this we hope to improve WatchGen and pilot its deployment . Last , we want to perform a qualita - tive study to better understand the subjective opinions of administrators that underlie these trends . We conjec - ture that such qualitative insights might be invaluable for improving WatchGen . 9 Acknowledgements This research was supported by EPSRC grants EP / S033564 / 1 , EP / W032473 / 1 , UKRI DSNmod ( REPHRAIN EP / V011189 / 1 ) , and EU Horizon Frame - work grant agreement 101093006 ( TaRDIS ) . References [ 1 ] D . A , B . S , V . L - H , S . T , and R . K . Decentralized online social networks . In : Furht B ( ed ) Handbook of social network technologies and applications . In Springer , page 349 – 378 , 2010 . [ 2 ] ActivityPub . https : / / www . w3 . org / TR / activitypub / , 2018 . [ 3 ] Y . - Y . Ahn , S . Han , H . Kwak , S . Moon , and H . Jeong . Analysis of topological characteristics of huge online social networking services . In In Proceedings of the 16th international conference on World Wide Web , page 835 – 844 , 2007 . [ 4 ] B . Ames , H . Lara , G . Anthony , S . Dan , and Z . Hong - gang . The growth of Diaspora – A decentralized online social network in the wild . In INFOCOM Workshops , 2012 . [ 5 ] N . A . Arnold , B . Steer , I . Hafnaoui , H . A . Parada G , R . J . Mondrag´on , F . Cuadrado , and R . G . Clegg . Mov - ing with the times : Investigating the alt - right network gab with temporal interaction graphs . Proceedings of the ACM on Human - Computer Interaction , 5 ( CSCW2 ) : 1 – 17 , 2021 . [ 6 ] R . Ashwin , R . Paul , and B . Ceren . Quick , community - speciﬁc learning : How distinctive toxicity norms are maintained in political subreddits . In Proceedings of the 14th International AAAI Conference on Web and Social Media , ICWSM 2020 , pages 557 – 568 , 2020 . [ 7 ] G . B , C . M , P . A , and R . L . Managing social contents in decentralized online social networks : a survey . In Online Social Networks and Media , volume 7 , pages 12 – 29 , 2018 . [ 8 ] H . Bin Zia , J . HE , A . Raman , I . Castro , N . Sastry , and G . Tyson . Flocking to mastodon : Tracking the great twitter migration . In Arxiv , 2023 . [ 9 ] P . Burnap and M . L . Williams . Hate speech , machine classiﬁcation and statistical modelling of information ﬂows on Twitter : Interpretation and communication for policy decision making . In In Internet , Policy and Poli - tics Conference , Oxford , United Kingdom , 2014 . [ 10 ] Z . C , V . Y , and M . F . Aggressive , repetitive , intentional , visible , and imbalanced : Reﬁning representations for cy - berbullying classiﬁcation . In In Proceedings of the 14th International AAAI Conference on Web and Social Me - dia , ICWSM 2020 , page 808 – 819 , 2020 . [ 11 ] J . Cox . 30 , 000 new users signed up for mastodon after elon musk bought twitter . https : / / www . vice . com / en / article / n7npd7 / 30000 - new - users - signed - up - for - mastodon - after - elon - musk - bought - twitter , 2022 . [ 12 ] K . Dinakar , R . Reichart , and H . Lieberman . Modeling the detection of Textual Cyberbullying . In In The Social Mobile Web , pages 11 – 17 , 2011 . [ 13 ] T . V . Doan , T . D . Pham , M . Oberprieler , and V . Baj - pai . Measuring Decentralized Video Streaming : A Case Study of DTube . In IFIP Networking 2020 , pages 118 – 126 , 2020 . [ 14 ] C . Eshwar , S . Mattia , S . Anirudh , and G . Eric . The bag of communities . In Advances in Neural Information Processing Systems , pages 3175 – 3187 , 2017 . [ 15 ] M . Farokhmanesh . A beginner’s guide to Mastodon , the hot new open - source Twitter clone . https : / / www . theverge . com / 2017 / 4 / 7 / 15183128 / mastodon - open - source - twitter - clone - how - to - use , 2017 . [ 16 ] T . Federation . https : / / the - federation . info / , 2019 . [ 17 ] K . Garimella , I . Weber , and M . De Choudhury . Quote rts on twitter : Usage of the new feature for political discourse . In Proceedings of the 8th ACM Conference on Web Science , pages 200 – 204 , 2016 . [ 18 ] B . Guidi , M . Conti , A . Passarella , and L . Ricci . Manag - ing social contents in Decentralized Online Social Net - works : A survey . Online Social Networks and Media , 2018 . [ 19 ] K . H . , C . Lee , H . Park , , and M . S . What is twitter , a social network or a news media ? In In Proceedings of the 19th International Conference on World wide web , WWW ’10 , page 591 – 600 , 2010 . [ 20 ] D . Ibosiola , I . Castro , G . Stringhini , S . Uhlig , and G . Tyson . Who watches the watchmen : Exploring com - plaints on the web . In The World Wide Web Conference , pages 729 – 738 , 2019 . [ 21 ] W . Iqbal , M . H . Arshad , G . Tyson , and I . Castro . Ex - ploring crowdsourced content moderation through lens of reddit during covid - 19 . In Proceedings of the 17th Asian Internet Engineering Conference , pages 26 – 35 , 2022 . [ 22 ] H . A . Ishaku , R . Aravindh , C . Ignacio , Z . H . Bin , D . C . Emiliano , S . Nishanth , and T . Gareth . Exploring content moderation in the decentralised web : The pleroma case . In CoNEXT 2021 - Proceedings of the 17th International Conference on emerging Networking EXperiments and Technologies , pages 328 – 335 , 2021 . [ 23 ] U . J . , K . B . , B . L . , and C . Marlow . The anatomy of the facebook social graph . In arXiv preprint arXiv : 1111 . 4503 , 2011 . [ 24 ] R . T . Javed , M . E . Shuja , M . Usama , J . Qadir , W . Iqbal , G . Tyson , I . Castro , and K . Garimella . A ﬁrst look at covid - 19 messages on whatsapp in pakistan . In 2020 IEEE / ACM International Conference on Advances in Social Networks Analysis and Mining ( ASONAM ) , pages 118 – 125 . IEEE , 2020 . [ 25 ] C . Justin , D . - N . - M . Cristian , and L . Jure . Antisocial be - havior in online discussion communities . In Proceedings of the 9th International Conference on Web and Social Media , ICWSM 2015 , pages 61 – 70 , 2015 . [ 26 ] L . J . Kai , C . K . Ta , and L . C . Laung . A collusion - resistant automation scheme for social moderation sys - tems . In Conference on Human Factors in Computing Systems - Proceedings , pages 1157 – 1162 , February 2016 . [ 27 ] P . Khare , M . Karan , S . McQuistin , C . Perkins , G . Tyson , M . Purver , P . Healey , and I . Castro . The web we weave : Untangling the social graph of the ietf . In Proceedings of the International AAAI Conference on Web and Social Media , volume 16 , pages 500 – 511 , 2022 . [ 28 ] R . Kumar , J . Novak , and A . Tomkins . Structure and evolution of online social networks . In In Link mining : models , algorithms , and applications . Springer . , page 337 – 357 , 2010 . 10 [ 29 ] T . A . L . , M . P . J . , and P . M . A . Social structure of facebook networks . In Physica A : Statistical Mechanics and its Applications , page 4165 – 4180 , 2012 . [ 30 ] L . C . Lucio , G . Sergio , and T . Andrea . Understanding the growth of the fediverse through the lens of mastodon . In Applied Network Science , volume 6 , 2021 . [ 31 ] C . M . , H . H . , B . F . , and G . P . K . Measuring user in - ﬂuence in twitter : The million follower fallacy . In In Proceedings of the 5th International Conference on Web and Social Media , ICWSM ’10 . , 2010 . [ 32 ] L . Manikonda , Y . Hu , and S . Kambhampati . Analyz - ing user activities , demographics , social network struc - ture and user - generated content on Instagram . In arXiv preprint arXiv : 1410 . 8099 ( 2014 ) , 2014 . [ 33 ] Mastodon . https : / / joinmastodon . org , 2016 . [ 34 ] Z . Matteo , Q . Christian , G . Alessia , G . Sabrina , and R . G . Paolo . Mastodon content warnings : Inappropriate contents in a microblogging platform . In Proceedings of the 13th International Conference on Web and Social Media , ICWSM 2019 , pages 639 – 645 , 2019 . [ 35 ] S . McQuistin , M . Karan , P . Khare , C . Perkins , G . Tyson , M . Purver , P . Healey , W . Iqbal , J . Qadir , and I . Castro . Characterising the ietf through the lens of rfc deploy - ment . In Proceedings of the 21st ACM Internet Mea - surement Conference , pages 137 – 149 , 2021 . [ 36 ] S . A . Myers , A . Sharma , P . Gupta , and J . Lin . Infor - mation network or social network ? The structure of the Twitter follow graph . In In Proceedings of the 23rd Inter - national Conference on World Wide Web , page 493 – 498 , 2014 . [ 37 ] PeerTube . https : / / joinpeertube . org , 2018 . [ 38 ] Pleroma . https : / / pleroma . social / , 2018 . [ 39 ] A . Raman , S . Joglekar , E . D . Cristofaro , N . Sastry , and G . Tyson . Challenges in the decentralised web : The mastodon case . In ACM IMC , pages 217 – 229 , October 2019 . [ 40 ] A . H . Razavi , D . Inkpen , S . Uritsky , and S . Matwin . Oﬀensive language detection using multi - level classiﬁca - tion . In In Canadian Conference on Artiﬁcial Intelli - gence . Springer , pages 16 – 27 , 2010 . [ 41 ] L . Schwittmann , C . Boelmann , M . Wander , and T . Weis . SoNet – Privacy and Replication in Federated Online So - cial Networks . In Distributed Computing Systems Work - shops , 2013 . [ 42 ] S . O . Sood , E . F . Churchill , and J . Antin . Automatic identiﬁcation of personal insults on social news sites . In Journal of the American Society for Information Science and Technology , page 270 – 285 , 2012 . [ 43 ] C . Stevie , L . Zhiyuan , and D . C . Munmun . This post will just get taken down” : Characterizing removed pro - eating disorder social media content . In 2009 6th IEEE Consumer Communications and Networking Conference , CCNC 2009 , pages 1157 – 1162 , 2009 . [ 44 ] D . Trautwein , A . Raman , G . Tyson , I . Castro , W . Scott , M . Schubotz , B . Gipp , and Y . Psaras . Design and eval - uation of ipfs : a storage layer for the decentralized web . In Proceedings of the ACM SIGCOMM 2022 Conference , pages 739 – 752 , 2022 . [ 45 ] B . Viswanath , A . Mislove , M . Cha , and K . P . Gummadi . On the evolution of user interaction in facebook . In In Proceedings of the 2nd ACM workshop on Online social networks . , page 37 – 42 , 2010 . [ 46 ] W . Warner and J . Hirschberg . Detecting hate speech on the world wide web . In In Proceedings of the Second Workshop on Language in Social Media . Association for Computational Linguistics , pages 19 – 26 , 2014 . [ 47 ] Z . Waseem and D . Hovy . Hateful symbols or hateful people ? predictive features for hate speech detection on twitter . In In Proceedings of the North American Chapter of the Association for Computational Linguis - tics ( NAACL - HLT ) , pages 88 – 93 , 2016 . [ 48 ] E . Wauters , V . Donoso , and E . Lievens . Optimizing transparency for users in social networking sites . info , 2014 . [ 49 ] J . - M . Xu , B . Burchﬁel , X . Zhu , and A . Bellmore . An Examination of Regret in Bullying Tweets . In In Pro - ceedings of the North American Chapter ofthe Associa - tion for Computational Linguistics ( NAACL - HLT ) , page 697 – 702 , 2011 . [ 50 ] Z . Xu and S . Zhu . Filtering oﬀensive language in online communities using grammatical relations . In In Pro - ceedings of the Seventh Annual Collaboration , Electronic Messaging , Anti - Abuse and Spam Conference , pages 1 – 10 , 2010 . [ 51 ] W . D . Yvette . Volunteer Moderators in Twitch Micro Communities . pages 1 – 13 , 2013 . [ 52 ] H . B . Zia , I . Castro , and G . Tyson . Racist or sexist meme ? classifying memes beyond hateful . In Proceed - ings of the 5th Workshop on Online Abuse and Harms ( WOAH 2021 ) , pages 215 – 219 , 2021 . [ 53 ] H . B . Zia , A . Raman , I . Castro , I . H . Anaobi , E . De Cristofaro , N . Sastry , and G . Tyson . Toxicity in the decentralized web and the potential for model shar - ing . ACM SIGMETRICS , 2022 . [ 54 ] M . Zignani , S . Gaito , and G . P . Rossi . Follow the “Mastodon” : Structure and Evolution of a Decentral - ized Online Social Network . In ICWSM , 2018 . [ 55 ] M . Zignani , S . Galto , and G . P . Rossi . Follow the ”Mastodon” : Structure and evolution of a decentralized online social media . In ICWSM , pages 541 – 550 , 2018 . A Appendix 11 Policy Description % Instances % Users % Posts Growth in Inst . % Growth in Inst ObjectAgePolicy Applies action based on post age 74 . 80 57 . 00 65 . 30 352 73 . 50 % TagPolicy Applies policies to individual users based on tags 58 . 50 39 . 40 31 . 30 509 707 . 40 % HashtagPolicy List of hashtags to apply actions against 36 . 40 16 . 20 21 . 20 479 15 , 833 . 00 % SimplePolicy Wide range of actions applied against instances 28 . 80 39 . 70 36 . 30 83 30 . 70 % NoOpPolicy Default state of an instance 11 . 50 5 . 90 3 . 70 - 98 - 63 . 70 % StealEmojiPolicy List of hosts to steal emojis from 7 . 00 6 . 10 5 . 40 29 80 . 50 % HellthreadPolicy Performs action when a threshold of mentions is reached 6 . 50 10 . 90 19 . 80 21 42 . 80 % AntiFollowbotPolicy Stops bots from following users on the instance 4 . 50 6 . 20 6 . 90 13 40 . 60 % MediaProxyWarmingPolicy Crawls attachments using their MediaProxy URLs 3 . 60 7 . 00 8 . 30 16 72 . 70 % KeywordPolicy Matches a pattern in a post for an action to be taken 23 . 00 19 . 40 10 . 00 9 36 . 00 % ForceBotUnlistedPolicy Makes all bot posts to disappear from public timelines 2 . 70 7 . 00 5 . 50 27 675 . 00 % AntiLinkSpamPolicy Rejects posts from likely spambots by rejecting posts from new users that contain links 2 . 70 6 . 70 6 . 80 12 85 . 70 % ActivityExpirationPolicy Sets a default expiration on all posts made by users of the local instance . 1 . 30 1 . 20 0 . 73 11 366 . 60 % EnsureRePrepended Rewrites posts to ensure that replies to posts with subjects do not have an identical subject 1 . 30 0 . 40 1 . 80 6 66 . 60 % NormalizeMarkup processes messages through an alternate pipeline 0 . 9 4 . 2 1 . 4 6 150 % Table 2 : The top 15 policies applied by administrators with the percentage of instances applying the policies . It shows the percentage of users and posts on the instances applying them , and their growth during our measurement period . Instances Admingrowth # Admins Users UserGrowth Posts PostGrowth Hatecount URLcount MentionsCount HashtagCount nsfw MediaRemoval FederatedTimelineRemoval Reject Quaran - tined disqordia . space 6 8 53 33 55 . 5k 5 . 1k NA NA NA NA 3 2 15 71 17 poa . st 5 13 9 . 7k 9 . 46k 1 . 14m 453 . 3k 78 . 2k 19 . 5k 60 . 8k 20 . 1k 4 3 2 1 0 pleroma . nobodyhasthe . biz 5 6 128 79 20 . 5k 1 . 12k 42 . 8k 2 . 6k 42 . 2k 2 . 2k 0 1 0 2 0 pleroma . pt 4 7 450 448 24 . 9k 1 . 8k 449 75 246 29 8 5 0 1 pleroma . foxarmy . ml 4 5 8 7 40 7 NA NA NA NA 0 0 0 0 0 varishangout . net 4 7 924 856 98 . 5k 2 . 6k 4 1 0 . 0 3 0 3 9 6 0 mindset . rage . lol 3 5 10 8 635 444 NA NA NA NA 0 0 0 0 0 neckbeard . xyz 3 13 2k 1 . 22k 1 . 34m 789 . 4k 883 136 607 177 0 0 0 2 0 fedi . absturztau . be 2 4 900 463 775 . 8k 327k 12 . 9k 1 . 9k 9 . 5k 2 . 4k 3 0 0 14 12 childpawn . shop 2 3 183 176 3 . 8k 441 NA NA NA NA 0 0 0 0 0 Table 3 : Top 10 Instances with the largest increase in number of administrators during our measurement period . Algorithm Acc . Prec . Recall F1 score Logistic Regression 0 . 73 0 . 24 0 . 20 0 . 21 Multi - Layer Perceptron 0 . 81 0 . 00 0 . 05 0 . 10 Random Forest 0 . 87 0 . 69 0 . 57 0 . 62 Gradient Boosted Trees 0 . 87 0 . 73 0 . 54 0 . 62 Table 4 : WatchGen performance results using global training pool and excluding post features ( number of posts and transformed posts ) . 12 Feature # Description # Representation Number Users Number of users registered on an instance Count 133 . 8k posts Number of posts by users on an instance Count 29 . 9m hate count Number of hate words on an instance from hatebase . org Count 36m url count Number of URLs in user posts on an instance Count 4 . 8m reject Number of instances to completely reject any ﬂow of material from Count 8 . 7k nsfw Number of instances to tag all user posts as ”Not Safe For Work” Count 934 media removal Number of instances to remove media from ” Count 630 federated timeline removal Number of instances to un - list all user posts from the federated timeline Count 2 . 4k posts tr Transformed number of posts using Box Cox transformation Count 2 . 8k reject deletes Number of instances to remove all banners from Count 158 quaran inst Number of instances where private ( DMs , followers - only ) activities will not be sent Count 1k mentions count Number of mentions in user posts on an instance Count 24m hate avg Average number of hate words on an instance from hatebase . org Count 1 . 5 url avg Average number of URLs in user posts on an instance Count 0 . 2 hashtags avg Average number of hashtags in user posts on an instance Count 0 . 3 mentions avg Average number of mentions in user posts on an instance Count 0 . 8 hashtags count Number of hashtags in user posts on an instance Count 7m hate percent Average percentage of hate words in a post from hatebase . org Percentage 2 . 2 % url percent Average percentage of URLs in user posts on an instance Percentage 8 . 4 % hashtags percent Average percentage of hashtags in user posts on an instance Percentage 6 . 6 % mentions percent Average percentage of mentions in user posts on an instance Percentage 2 . 5 % followers Number of followers of users on an instance Count 169k following Number of remote users that users on an instance follow Count 8 . 9k reblogs count Number of reblogs by users on an instance Count 7 . 2k replies count Number of posts replied by users on an instance Count 24 . 5k users tr Transformed number of users using Box Cox transformation Count 1 . 3k hate tr Transformed number of hate count using Box Cox transformation Count 4 . 3k url tr Transformed number of url count using Box Cox transformation Count 3k accept Number of instances to accept all material from Count 635 report removal Number of instances to remove all reports from Count 91 avatar removal Number of instances to remove all avatars from Count 266 banner removal Number of instances to remove all banners from Count 291 followers only Number of instances that user posts are only seen by their followers Count 99 active halfyear Number of active users in half a year Count 9 active month Number of active users in a month Count 7 hash ftr Number of hashtags to remove activities from the federated timeline Count 7 hash rej Number of of hashtags to reject activities from Count 6 hash sen Number of hashtags to mark activities as sensitive Count 365 Table 5 : Summary of all extracted features used for model training . 13