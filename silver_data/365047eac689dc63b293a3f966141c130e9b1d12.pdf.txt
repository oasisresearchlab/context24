1 Beyond Citations : Measuring Novel Scientific Ideas and their Impact in Publication Text Sam Arts * Department of management , strategy and innovation Faculty of economics and business KU Leuven sam . arts @ kuleuven . be Nicola Melluso Department of management , strategy and innovation faculty of economics and business KU Leuven nicola . melluso @ kuleuven . be Reinhilde Veugelers Department of management , strategy and innovation faculty of economics and business KU Leuven reinhilde . veugelers @ kuleuven . be ABSTRACT New scientific ideas fuel economic progress , yet their identification and measurement remains challenging . In this paper , we use natural language processing to identify the origin and impact of new scientific ideas in the text of scientific publications . To validate the new techniques and their improvement over traditional metrics based on citations , we first leverage Nobel prize papers that likely pioneered new scientific ideas with a major impact on scientific progress . Second , we use literature review papers that typically summarize existing knowledge rather than pioneer new scientific ideas . Finally , we demonstrate that papers introducing new scientific ideas are more likely to become highly cited by both publications and patents . We provide open access to code and data for all scientific papers up to December 2020 . Keywords : natural language processing ; science ; novelty ; impact ; breakthrough ; Nobel ; Microsoft Academic Graph JEL codes : O , 30 , O31 , O32 , O33 , I23 * Corresponding author Financial support from KU Leuven Grant 3H200208 is gratefully acknowledged , as are comments from participants at the 2023 NBER - SI - SSF workshop , the WOEPSR23 Conference , DRUID23 , and REGIS Summer School 2023 , and particularly from Pierre Azoulay , Chiara Franzoni , Dietmar Harhoff , Rodrigo Ito , Fabio Montobbio . 2 1 . Introduction New scientific ideas drive scientific progress , technological innovation , and economic prosperity ( Bush , 1945 ; Mokyr , 2002 ) . It is hard to overstate the importance of new scientific discoveries such as the transistor , magnetic resonance imaging , polymerase chain reaction or carbon nanotubes . Despite the importance of new scientific ideas , scholars face difficulties to identify and measure novel scientific ideas and to trace their diffusion and impact . To measure new scientific ideas and the novelty of scientific papers , prior work has traditionally relied on their patterns of citations to prior papers ( Uzzi et al . , 2013 ; Wang et al . , 2017 ; Wu et al . , 2019 ) . Yet , this approach has important limitations . Citations only capture prior art but not the scientific content and contribution of the paper itself . Thus , citations presumably cannot accurately identify new scientific ideas − and measure the novelty − in the content of a paper . Moreover , as a measure of impact , citations may not always reflect prior art and intellectual influence . Surveying 9 , 000 academics from 15 different fields , Teplitskiy et al . ( 2022 ) illustrate that more than half of cited papers actually had either a minor or very minor intellectual influence . In this paper , we circumvent the use of citations and build on the work of Kuhn ( 1970 ) in which he argues that scientific ideas are embedded in the text of scientific literature , and therefore new scientific ideas can only be identified through shifts in language . We use Natural language processing ( NLP ) techniques to harness the text of scientific publications and identify both the origin and the impact of new scientific ideas . Prior work started to explore the use of NLP to detect new scientific ideas in the text of scientific publications ( e . g . Azoulay et al . 2011 ; Boudreau et al . , 2016 ; Iara et al . , 2018 ; Chai & Menon , 2019 ; Cheng et al . , 2023 ) . However , this line of research generally provides no large scale validation of the text metrics , and neglects to analyze whether these text metrics represent a significant improvement over traditional citation - based metrics . Finally , there is no open access to code and data . Open access to code , data and new metrics could perhaps foster a broader adoption of text metrics . The current manuscript aims to fill these gaps in the literature . We use the titles and abstracts of all scientific publications covered in the latest version of Microsoft Academic Graph ( MAG ) , which arguably covers the largest corpus of scientific work published in the entire history from 1780 until 2020 , and has the advantage of being open access ( Martín - Martín et al . , 2021 ; Lin et al . , 2023 ) . To detect new scientific ideas and measure the novelty of a paper at the time of publication , we identify unigrams ( keywords ) , bigrams ( two consecutive words ) , trigrams ( three consecutive words ) , and 3 pairwise keyword combinations that appear for the first time in history in the title or abstract of a scientific paper . For instance , we identify the first paper in history introducing “ transistor ” , “ confocal microscopy ” , “ polymerase chain reaction ” , or the pairwise word combination of “ carbon” and “nanotube ” . Alternatively , we measure the novelty of scientific papers based on the text similarity with prior papers . To do so , we use SPECTER , a pre - trained document - level embedding of scientific documents , which has the advantage of being able to account for synonyms , polysemy , and the context of words ( Cohan et al . , 2020 ) . To measure the impact or influence of new scientific ideas , we count the number of papers reusing the new keywords , bigrams , trigrams , or keyword combinations . For instance , 152 , 047 papers reuse “ transistor ” , 43 , 785 papers reuse “ confocal microscopy ” , 209 , 968 papers reuse “ polymerase chain reaction ” , and 131 , 888 papers reuse the pairwise word combination of “ carbon ” and “ nanotube ” . To validate the text metrics and their improvement over traditional measures based on citations , we collect scientific publications linked to the Nobel Prize . These papers likely introduced new scientific ideas with a major impact on scientific progress . The Nobel Prize also allows us to validate whether the new scientific ideas of Nobel prize papers captured by our text metrics correspond with the scientific contributions described in the prize motivation of the Nobel prize committee . As an additional validation and robustness check , we collect literature review papers which typically summarize existing scientific knowledge rather than pioneer new scientific insights . Finally , as a first use case of the new metrics , we demonstrate that papers pioneering new scientific ideas are more likely to become highly cited by both papers and patents . The validation studies support the use of NLP to identify new scientific ideas and measure the novelty of papers at the time of publication , and to measure the impact of these new ideas on later scientific work . Moreover , the results illustrate the improvement of the new text metrics over the traditional metrics based on paper citations . To facilitate further research , we provide open access to all our data ( https : / / zenodo . org / record / 8283353 , DOI : 10 . 5281 / zenodo . 8283353 ) and code ( https : / / github . com / nicolamelluso / science - novelty ) . 2 . Identifying the Origin and Impact of New Scientific Ideas in Publication Text 2 . 1 Data collection We collect all scientific publications from the latest version of Microsoft Academic Graph ( MAG ) , and concatenate the title and abstract of each paper . Because there is only a title and no abstract available for 29 % of the publications , we illustrate in Appendix E the robustness 4 of the metrics in case we discard abstracts and exclusively rely on titles . Next , we process the text with the following steps : tokenization , lemmatization , stop word removal , chunking , baseline removal , and vectorization . Appendix B provides a more detailed description of data collection and processing . We use all publications published between 1880 and 1900 to construct a baseline dictionary and restrict the analysis to papers published between 1901 and 2020 ( n = 72 , 245 , 396 ) . The entire cleaned vocabulary contains 20 , 953 , 136 unique unigrams ( keywords ) , 114 , 939 , 991 unique bigrams , and 341 , 735 , 389 unique trigrams . 2 . 2 Text metrics for novelty First , we calculate new _ word as the number of unique unigrams of a paper that appear for the first time in history . Hence , we identify the first paper using keywords such as “ transistor ” or “ fullerene ” . Second , we calculate new _ bigram as the number of unique bigrams of a paper that appear for the first time in history . For instance , we identify the first paper using bigrams such as “ confocal microscopy ” or “ electron tunneling ” . Third , we compute new _ trigram as the number of unique trigrams of a paper that appear for the first time . Hence , we identify the first paper introducing trigrams such as “ scanning tunnel microscopy ” or “ polymerase chain reaction ” . Fourth , we compute new _ word _ comb as the number of unique pairwise keyword combinations of a paper that appear for the first time . Contrary to ngrams , the location and order of the keywords in the paper does not matter . For instance , we identify the first paper using keyword combinations such as “ carbon nanotube ” or “ x - ray diffraction ” . Papers published between 1880 and 1900 are used as a baseline dictionary and we exclude ngrams or word combinations that appear only once in the entire corpus of papers . Finally , we create the SPECTER document - embedding vector of every paper in MAG and calculate cosine _ max as one minus the maximum pairwise cosine similarity between the focal paper and all prior papers published in the preceding 5 years . This measure reflects the semantic distance between the focal paper and the prior paper from the entire population that is closest in scientific content . Papers which score among the highest ( top 1 % ) on cosine _ max include the paper linked to the 1983 Nobel prize in Medicine awarded to Barbara McClintock for the discovery of mobile genetic elements or the 1976 paper by Leon Chua on memristors . 2 . 3 Text metrics for impact of new scientific ideas To assess the influence of novel scientific ideas on subsequent scientific work , we analyze the frequency with which these ideas are incorporated into the text of publications . First , we compute new _ word _ reuse as the number of new keywords introduced by the focal paper weighted by the number of later papers that reuse these keywords . For paper p , 5 𝑛𝑒𝑤 _ 𝑤𝑜𝑟𝑑 _ 𝑟𝑒𝑢𝑠𝑒 𝑝 = ∑ ( 1 + 𝑢 𝑖 ) 𝑛𝑖 = 1 with n equal to the number of new keywords introduced by paper p and 𝑢 𝑖 equal to the number of future papers which reuse the new keyword i . For instance , 152 , 047 publications reuse “ transistor ” and 32 , 305 reuse “ fullerene ” . While new _ word measures the novelty of a paper at the time of publication , new _ word _ reuse measures the extent to which the new scientific ideas introduced by the focal paper influence subsequent scientific work . Second , we calculate new _ bigram _ reuse as the number of new bigrams introduced by the focal paper weighted by the number of subsequent papers which reuse these particular bigrams . For instance , 43 , 785 papers reuse bigram “ confocal microscopy ” and 4 , 759 papers reuse bigram “ electron tunneling ” . Third , we calculate new _ trigram _ reuse as the number of new trigrams introduced by the focal paper weighted by the number of subsequent papers which reuse these trigrams . For instance , 209 , 968 papers reuse “ polymerase chain reaction ” and 17 , 914 papers reuse “ scanning tunnel microscopy ” . Finally , we compute new _ word _ comb _ reuse as the number of new keyword combinations weighted by the number of subsequent papers that reuse these keyword combinations . For instance , 131 , 888 papers reuse “ carbon nanotube ” and 519 , 239 papers reuse “ x - ray diffraction ” . Interestingly , we find that papers reusing new keywords are approximately 53 times more likely to cite the paper which introduced the keyword for the first time compared to a matched control group of papers from the same journal , year , volume and issue that do not reuse the new keyword ( 0 . 95 % versus 0 . 02 % ) . We find similar results for new word combinations . Nevertheless , the overall rate of citation among papers reusing new scientific ideas is surprisingly low . Scientific papers perhaps cite only the most recent and closely related papers , and not necessarily the older foundational papers that pioneered a new scientific insight that they directly or indirectly build on . We find supportive evidence for this in our data as discussed in Appendix C . These results highlight that citations and text metrics offer distinct perspectives on the reuse and influence of scientific ideas . 2 . 4 Traditional metrics for novelty Prior research traditionally relies on paper citations to measure the novelty of a paper . First , Uzzi et al . ( 2013 ) define novelty as an atypical combination of prior knowledge . We follow Uzzi et al . ( 2013 ) and compare the observed frequency of any pair of cited journals and the frequency of that pair of cited journals that would have occurred by chance using a Configuration Null Model , creating a normalized z - score that measures for any pair of cited journals the ( a ) typicality . Next , we calculate for each focal paper uzzi as the 10 th percentile of 6 the z - scores for all pairs of journals cited by the focal paper , i . e . focusing on the most novel or atypical combinations introduced by the focal paper . Lower values of uzzi indicate more novel papers and higher values of uzzi indicate less novel papers . Second , Wang et al . ( 2017 ) define novelty of a focal paper as the sum of the distance of first - time ever combinations of journals of the cited papers . We closely follow their approach and first identify all pairs of journals cited together for the first time in history . Next , we calculate the distance for each new pair of cited journals based on their co - citation frequencies . Finally , we calculate wang as the sum of the distance for new combinations of cited journals . Finally , Funk & Owen - Smith ( 2017 ) introduce a metric that characterizes if a paper is disruptive or consolidating . A focal paper is assumed to be more disruptive if the papers that cite the focal paper do not cite the focal paper’s predecessors , i . e . the papers cited by the focal paper . A paper is considered consolidating if it is mostly cited together with its predecessors . In contrast to uzzi and wang , cd is not a direct measure for the novelty of a paper , but a measure of the nature of its impact . cd is based on the citations received from subsequent papers and thus cannot identify the novelty of a paper at the time of publication . We nonetheless include the measure in our analyses given its increasing use in the science of science community ( e . g . Wu et al . , 2019 ; Park et al . , 2023 ) . 3 . Descriptive Statistics Table A . 1 in Appendix displays summary statistics at the level of new ngrams or word combinations . Overall , 7 , 305 , 080 new keywords , 32 , 104 , 336 new bigrams , 75 , 573 , 271 new trigrams and about 1 . 1 billions new word combinations have been introduced between 1901 and 2020 . As expected , most new ngrams or word combinations are reused by only a few subsequent papers , but a small minority are reused extensively . The most impactful in the entire history include the word “ transistor ” pioneered in 1948 and reused by 152 , 047 publications , the bigram “ confocal microscopy ” appearing for the first time in 1981 and reused by 43 , 785 papers , the new trigram “polymerase chain reaction” emerging in 1986 and reused by 209 , 968 papers , and the new word combination “ carbon nanotube ” originating in 1991 and reused by 131 , 888 papers . Table 1 displays summary statistics at the paper level . Only a subset of papers score on novelty . Around 7 . 9 % of all papers introduce a new keyword , 27 . 4 % a new bigram , 46 . 9 % a new trigram , and 51 . 7 % a new word combination . The average ( median ) paper introduces 0 . 1 ( 0 ) new words , 0 . 4 ( 0 ) new bigrams , 1 . 0 ( 0 ) new trigrams , and 15 . 6 ( 1 ) new word 7 combinations . While the number of new word combinations might seem large , notice that the average paper has 858 unique keyword pairs so that the average and median share of new word combinations per paper is only 1 . 8 % and 0 . 1 % respectively . As expected , the summary statistics illustrate the very large skew for all text - based novelty metrics , and underscore the importance to control for text length when analyzing the novelty of a paper . ‘Table 1’ As an illustration , Figure 1 displays the average number of new word combinations pioneered by papers by fields of study from 1901 to 2020 . The figure shows a large heterogeneity in scientific novelty across different fields of study and over time . For example , fields such as Biology , Chemistry or Physics show the highest rate of scientific novelty compared to other fields . The time trends also highlight the historical evolution of scientific fields such as the many new scientific discoveries in Computer Science after 1960 . As illustrated in Figure A . 1 in Appendix , the large heterogeneity in scientific novelty is also persistent at the more granular subfield level . ‘Figure 1’ As demonstrated in Table A . 2 of the Appendix , a strong positive correlation exists among the various text - based novelty metrics , indicating that the novel scientific ideas introduced in a paper are frequently captured by multiple text metrics simultaneously . 1 Because of this high co - occurrence , we construct an additional binary indicator new _ gram _ bin equal to 1 for papers introducing a new word and / or new bigram and / or new trigram . There is also a high co - occurrence between new ngrams and word combinations . Among all papers introducing a new ngram , 75 % also introduce a new word combination . Conversely , among all papers introducing a new word combination , 79 % also introduce a new ngram . Interestingly , the average correlations between our new text metrics and the traditional citation - based novelty metrics are very low , as shown in Table A . 2 . This finding indicates that our text metrics assess the novelty of papers in a distinct manner when compared to traditional metrics based on citations . 1 One might suspect that the correlation between the novelty metrics is positive by construction in case new words inflate the number of new bigrams , trigrams , or new word combinations , or when new bigrams inflate the number of new trigrams . However , among all bigrams introduced by papers between 1901 and 2020 , only 6 . 9 % include a new word , among all trigrams only 8 . 8 % include a new word or a new bigram , and among all new word combinations only 7 . 1 % include a new word . As such , the number of new bigrams , trigrams and new word combinations of a paper do not change significantly after excluding those with overlapping ngrams . Moreover , our main findings do not change if we use exclusive categories . Results not displayed but available from the authors . 8 Finally , we look at summary statistics for the metrics accounting for the impact of new scientific ideas as measured by their reuse in later publications . As show in Table 2 , the average ( median ) value for new _ word _ reuse is 7 . 7 ( 0 ) , for new _ bigram _ reuse 12 . 2 ( 0 ) , for new _ trigram _ reuse 9 . 4 ( 0 ) , and for new _ word _ comb _ reuse 776 ( 2 ) . The descriptive statistics again illustrate the very large skew in the reuse of new scientific ideas , with only a small minority of novel papers being very impactful . 4 . Nobel Prize Papers Nobel prize papers arguably pioneered new scientific ideas , and especially new ideas with a major impact on scientific progress . Therefore , they serve as validation to assess the efficacy of our text metrics in identifying new scientific ideas and measuring their influence on subsequent scientific work . As a first validation , we scrape the motivation for each prize from the Nobel prize website which includes a clear rationale of the specific contributions made by the laureates to their respective fields . We test whether the new scientific ideas of Nobel prize papers captured by our text metrics correspond with the scientific contributions described in the prize motivation . As a second validation , we use a case - control study design and test the ability of all text and traditional metrics to correctly distinguish the Nobel prize papers from matched control papers . Our assumption is that Nobel prize papers are more likely to introduce new scientific ideas , particularly new ideas that significantly influence subsequent scientific research , in comparison to the matched control papers . 4 . 1 Data We collect publications linked to Nobel prizes in Chemistry , Physics and Physiology or Medicine from Li et al . ( 2019 ) . Nobel prize papers refer to the publications that have been recognized by the Nobel prize committee as significant contributions to their respective fields and have led to the awarding of a Nobel Prize to at least one of the co - authors . Next , we match each Nobel prize paper to one control paper not linked to any Nobel prize but published in the same year , journal , volume and issue as the Nobel prize paper . In case of multiple matching control papers , we randomly sample one 2 . Matching on journal , year , volume and issue arguably controls for differences across scientific fields and time . 2 In case the journal issue of the Nobel prize publication is not available , we match on journal , year and volume . In case the journal volume of the Nobel prize publication is not available , we match on journal and year . 9 Our sample includes 501 Nobel prize papers published between 1906 and 2010 linked to 220 Nobel prizes awarded between 1912 and 2016 3 . Together , these Nobel prize papers introduced 226 new words , 938 new bigrams , 1 , 628 new trigrams and 40 , 052 new keyword combinations . For each Nobel prize award , we download the online summary page that describes the award , the short motivation for the prize and a summary of the scientific contribution for which the laureates obtained the prize . We process the text of each award page following the exact same procedure adopted for papers and remove explicit references to the title of the corresponding Nobel prize papers ( see Appendix B ) . Reassuringly , we find that 82 % of the new words , 71 % of the new bigrams , 67 % of the new trigrams and 74 % of new word combinations pioneered by Nobel prize papers are also mentioned in the summary page of each corresponding Nobel prize . Similarly , among the Nobel prize papers introducing at least one new ngram or word combination , 93 % have at least one corresponding new keyword , 89 % at least one corresponding new bigram , 92 % at least one corresponding trigram , and 98 % at least one corresponding new word combination in the respective Nobel prize motivation . This finding illustrates the ability of our text metrics to identify new scientific ideas in the full population of scientific publications . ‘Table 2’ Table 2 presents examples of Nobel Prizes , including the short prize motivation , a corresponding paper , and an instance of a new scientific idea introduced by this paper as identified by our text metrics . This new scientific idea is also reflected in the Nobel Prize motivation . We briefly discuss some examples here . William Shockley , John Bardeen , and Walter Brattain shared the 1956 Nobel prize in Physics “for their research on semiconductors and the discovery of the transistor effect” . One of the corresponding papers published in 1948 in Physical Review was the first to introduce the keyword “ transistor ” , reused by 152 , 047 subsequent papers . In 1986 , Gerd Binnig and Heinrich Rohrer won the Nobel prize in Physics “for their design of the scanning tunneling microscope” . The corresponding paper published in 1982 in Physical Review Letters was the first to introduce the trigram “ scanning tunnel microscopy ” , reused by 17 , 914 papers . The 1993 Nobel prize in chemistry was awarded to Kary Mullis " for his invention of the polymerase chain reaction method " . The corresponding paper published in 1986 in Cold Spring Harbor symposia on quantitative biology introduced for the first time the trigram “ polymerase chain reaction ” reused by 3 144 papers linked to Nobel prizes in Chemistry , 148 papers linked to Nobel prizes in Physics , and 209 papers linked to Nobel prizes in physiology or Medicine 10 209 , 968 subsequent papers . As a final example , in 2001 , the Nobel prize in Chemistry was awarded to William Knowles and Ryoji Noyori " for their work on chirally catalysed hydrogenation reactions " . The corresponding paper published in 1968 in Tetrahedron introduced for the first time the combination of the words “ chiral ” and “ synthesis ” reused by 34 , 820 papers . 4 . 2 Descriptive results Table 3 shows descriptive statistics for Nobel prize papers and matched control papers . Both the text and the traditional citation - based metrics can distinguish Nobel prize papers from control papers with a t - test significant at p = 0 . 000 . The only exceptions are wang ( significant at p = 0 . 084 ) and cosine _ max ( p = 0 . 231 ) . All text metrics measuring novelty at the time of publication ( new _ word , new _ bigram , new _ trigram , and new _ word _ comb ) outperform the traditional novelty measures based on citations ( i . e . wang and uzzi ) in terms of both t - statistic and Cohen’s d ( i . e . mean difference between Nobel prize and control papers divided by the pooled standard deviation ) . Given that Nobel prize papers are arguably more likely to pioneer new scientific insights , these findings provide supportive evidence that text metrics are ( better ) able to identify new scientific ideas and measure the novelty of papers at the time of publication . Looking among all metrics for assessing the novelty of papers at the time of publication , new _ word _ comb seems to perform best in identifying Nobel prize papers . As expected , particularly the text metrics accounting for the impact of new scientific ideas ( new _ word _ reuse , new _ bigram _ reuse , new _ trigram _ reuse , new _ word _ comb _ reuse ) can distinguish Nobel prize papers from control papers and outperform the ( text ) metrics capturing novelty at the time of publications in terms of t - statistic and Cohen’s d . Each of the text metrics accounting for the impact of new ideas also outperforms cd , i . e . the disruptiveness index based on citations . Among all metrics , new _ word _ comb _ reuse performs best in identifying Nobel prize papers . Considering that Nobel Prize papers are recognized for pioneering new scientific ideas with a major impact , our findings demonstrate that our text metrics , which account for the reuse of new ideas , effectively capture the influence and impact of the novel scientific ideas introduced by the focal paper . ‘Table 3’ 4 . 3 Regressions Table 4 displays results from logit regressions with a binary indicator for Nobel prize paper as outcome . Regressions allow us to control for factors confounding the relationship between 11 scoring on novelty , its reuse and receiving a Nobel prize . A first important control is the number of unique words , bigrams , and trigrams of a paper ( i . e . the text length of each paper ) , and whether a paper has an abstract available , given that longer papers might mechanically score higher on the text metrics . In parallel , we control for the number of cited _ papers and the number of cited _ journals given that papers citing more ( journals ) might be more likely to cite new or atypical combinations of journals ( Fontana et al . , 2020 ) . Finally , we include fixed effects for publication year and field of study to account for the arguably important differences across fields and time 4 . To evaluate the performance of the different metrics to correctly classify Nobel prize and control papers , we calculate precision , recall , and area under the curve ( AUC ) . Precision measures the share of predicted Nobel prize papers that are correctly classified . Recall is the share of real Nobel prize papers that are correctly identified . AUC varies between 0 . 5 ( no predictive power ) and 1 ( perfect classification ) . Finally , the average marginal effect of each metric is calculated as the increase in the likelihood of being an Nobel prize paper corresponding with a one standard deviation increase in the particular metric . ‘Table 4’ The regression results in Table 4 are largely in line with the descriptive statistics in Table 3 . All text metrics measuring novelty at the time of publication are significant at the 1 % level and outperform the baseline model including only control variables in terms of predictive power ( AUC ) . The only exceptions are new _ word , significant at the 5 % level , and cosine _ max , not significant at the conventional 5 % level . Also wang cannot distinguish Nobel prize papers from control papers . Uzzi is statistically significant but generally performs worse than the text metrics for novelty ( except new _ word ) . In line with the descriptive statistics , new _ word _ comb has the strongest discriminatory power of all novelty measures with a precision of 67 . 06 % , a recall of 72 . 27 % and an AUC of 0 . 73 . A one standard deviation increase in new _ word _ comb increases the likelihood of being an Nobel prize paper with 25 % . By contrast , uzzi , i . e . the best performing traditional metric based on citations , has a precision of 63 . 97 % , a recall of 69 . 75 % and an AUC of 0 . 70 . A one standard deviation decrease in uzzi ( with lower values on uzzi meaning higher novelty ) increases the likelihood of being an Nobel prize paper with 5 % . Exclusively relying on information available at the time of publication , new _ word _ comb correctly identifies 72 . 27 % of the Nobel prize papers , i . e . a significantly larger share than the traditional novelty measures . 4 We obtain the field of study for each paper from Färber & Ao ( 2022 ) , which consists of 292 different fields . 12 Binary versions of the text metrics ( new _ gram _ bin and new _ word _ comb _ bin ) are also significant but generally perform worse . This finding suggest that Nobel prize papers typically include multiple new ngrams or word combinations and that count measures better capture the novelty a paper compared to binary indicators . If we include all text metrics together ( column 16 ) , new word becomes statistically insignificant at conventional levels . Using all text metrics together compared to exclusively using new _ word _ comb provides a small increase in precision and AUC , indicating improved overall model performance and more accurate positive predictions . Nevertheless , this leads to a reduction in recall , indicating that the model might be less proficient in identifying Nobel Prize papers . This result suggests again that new _ word _ comb is perhaps our best proxy for novelty of a paper at the time of publication . The text metrics measuring the influence or impact of new scientific ideas on subsequent scientific publications generally outperform the ( text ) metrics measuring novelty at the time of publication . This finding is reassuring given that Nobel prize papers likely cover new scientific ideas with a major impact on subsequent literature . Comparing all measures together , including cd measuring the disruptiveness of a paper based on received citations , we find that new _ word _ comb _ reuse has the strongest ability to correctly identify Nobel prize papers with a precision of 71 . 03 % , a recall of 75 . 21 % and an AUC of 0 . 77 . A one standard deviation increase in new _ word _ comb _ reuse increases the likelihood of being an Nobel prize paper with 26 % . By contrast , cd has a precision of 65 . 48 % , a recall of 69 . 33 % and an AUC of 0 . 72 . A one standard deviation increase in cd increases the likelihood of being an Nobel prize paper with 10 % . Including all text - based metrics together compared to exclusively using new _ word _ comb _ reuse ( column 17 ) , the precision and AUC slightly improve but the recall decreases . Together , the results suggests that new _ word _ comb _ reuse is perhaps our best proxy capturing the impact of new scientific ideas pioneered by the focal paper . While the text metrics show a relative accuracy in predicting Nobel Prize papers , it is evident that they are far from perfect . Likewise , Nobel prize papers are not a perfect validation set for novelty . On the one hand , a significant share of the predicted Nobel prize papers are in fact control papers , i . e . false positives . Nevertheless , control papers might also introduce new scientific ideas , but simply did not receive a Nobel prize , and are therefore not necessarily false positives for novelty . For example , one control paper by Paul Dirac published in Proceedings of the Royal Society of London in 1925 ( in the same year , journal , volume and issue as the paper linked to the Nobel prize awarded to Edward Victor Appleton ) introduced for the first time the bigram “ quantum mechanic ” . On the other hand , there are also Nobel prize papers missed by the text metrics , i . e . false negatives . To give one example , 13 Andre Geim and Konstantin Novoselov were awarded the 2010 Nobel Prize in Physics “for their groundbreaking experiments regarding graphene” , a two - dimensional material with unique properties . While Geim and Novoselov accomplished to isolate this material in its purest form , i . e . a single layer of carbon atoms arranged in a two - dimensional lattice , the term “ graphene” was introduced before by chemists Hans - Peter Boehm , Ralph Setton , and Eberhard Stumpp in 1986 . This example is a reminder that Nobel prize selection is based on new scientific ideas with big impact and not necessarily on novelty per se . 5 . Robustness As a second validation and robustness check , we collect a large sample of literature review papers and a matched control sample of original non - review papers . Our assumption is that review papers typically summarize existing scientific knowledge rather than introducing novel scientific ideas ( Wu et al . , 2019 ) . Put differently , we assume control papers are more likely to pioneer new scientific insights compared to review papers . As outlined in Appendix D , the findings for literature review papers are largely in line with the Nobel prize validation . Given that the large majority of all scientific papers are arguably not very novel ( e . g . Uzzi et al . , 2013 ; Wang et al . , 2017 ) , it is perhaps not surprising that the text metrics have less predictive power to distinguish review papers from matched control papers compared to distinguishing Nobel prize papers from matched control papers . Because we only have titles and no abstract for a significant share of all papers , this might introduce bias . We controlled for this potential bias by including a binary indicator for whether an abstract is available and for the text length of a paper . As an additional robustness check , we recalculate all text metrics for the full population of papers by using exclusively the title of a paper . Details can be found in Appendix E . Our main findings do not change suggesting that titles already contain useful information to identify new scientific ideas and their impact on later work . But , the overall predictive power of the text metrics based on titles is lower illustrating that abstracts contain valuable complementary information . 6 . New Scientific Ideas Fuel Scientific and Technological Progress The desire to identify papers that pioneer novel scientific ideas stems from their higher potential for major impact ( e . g . , Uzzi et al . , 2013 ; Wang et al . , 2017 ) . Persistent concerns exist regarding the science ( funding ) system ' s inadequate support for novel research , potentially leading to missed opportunities for scientific breakthroughs ( Azoulay et al . , 2011 ; 14 Alberts et al . , 2014 ; Franzoni et al . , 2022 ) . In Appendix F , we demonstrate that papers introducing new scientific ideas are indeed more likely to become highly cited by both papers and patents . Moreover , the text metrics capturing the novelty of a paper at the time of publication generally outperform the traditional novelty measures in terms of predicting which paper ultimately becomes highly cited in papers or patents . 7 . Discussion and Conclusion New scientific ideas are a key driver of scientific progress and economic prosperity , yet their identification and measurement remains difficult . To be able to analyze the dynamics of scientific progress , it is important to identify the papers pioneering new scientific insights and measure their influence on subsequent literature . Prior work has traditionally relied on citations to measure the novelty - or relatedly atypicality or disruptiveness - of scientific papers . However , citations only capture prior art and not the scientific contribution of the paper itself , and the majority of citations do not signal meaningful intellectual prior art . Therefore , citations arguably cannot accurately identify new scientific ideas at the time of publication nor measure the influence of these new scientific ideas on later work . In this paper , we apply text mining to harness and vectorize the rich scientific content of papers , to identify new scientific ideas at the time of publication , and to measure the impact of new scientific ideas on the subsequent literature . We validate the use of text metrics to identify new scientific ideas and measure the novelty of papers at the time of publication , and to measure the influence of these new ideas on later scientific work . We also illustrates the improvement of the text metrics over the traditional metrics based on citations . Among all metrics capturing the novelty of a paper at the time of publication , new keyword combinations seems to have the strongest discriminatory power to identify Nobel prize and literature review papers . This measure perhaps also best proxies the conventional view that new scientific ideas result from a new recombination of prior knowledge and ideas ( Nelson & Winter , 1982 ; Weitzman , 1998 ; Azoulay et al . , 2011 ; Uzzi et al . , 2013 ; Boudreau et al . , 2016 ; Wang et al . , 2017 ) . Moreover , taking into account the number of later papers which reuse the same keyword combinations provides a measure for the intellectual impact of new ideas that outperforms all other metrics in terms of identifying Nobel prize papers . Nevertheless , novel papers typically score on multiple text metrics simultaneously . We advise future users to experiment with different metrics to check the robustness of their findings . Interestingly , the new text metrics capturing the impact of new ideas only weakly correlate with citation - based measures for impact . As we illustrated in the manuscript , papers 15 typically tend to cite more recent and perhaps more closely related prior work , and not necessarily every older foundational paper that they directly or indirectly build upon . As such , our text metrics and data offer a new perspective for studying the diffusion and impact of new scientific ideas , independent from relying solely on paper citations , which might be influenced by biases ( e . g . , Teplitskiy et al . , 2022 ) . Despite the many advantages , the use of text also has a number of important limitations that future users should carefully take into consideration . We provide a detailed overview of limitations and suggestions for future work in Appendix G . Nevertheless , a key contribution of the new text measures compared to prior approaches is that they can provide new indicators for the two main stages of scientific progress , i . e . the discovery of new scientific ideas versus the later use and diffusion of these very same ideas . This opens up new avenues to study not only the emergence of new scientific ideas but also the diffusion and influence of those ideas . 8 . References Alberts , B . , Kirschner , M . W . , Tilghman , S . , & Varmus , H . ( 2014 ) . Rescuing US biomedical research from its systemic flaws . Proceedings of the National Academy of Sciences , 111 ( 16 ) , 5773 - 5777 . Allan , J . , Wade , C . , & Bolivar , A . ( 2003 ) . Retrieval and novelty detection at the sentence level . In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval ( pp . 314 - 321 ) . Arts , S . , Hou , J . , & Gomez , J . C . ( 2021 ) . Natural language processing to identify the creation and impact of new technologies in patent text : Code , data , and new measures . Research Policy , 50 ( 2 ) , 104144 . Azoulay , P . , Graff Zivin , J . S . , & Manso , G . ( 2011 ) . Incentives and creativity : evidence from the academic life sciences . The RAND Journal of Economics , 42 ( 3 ) , 527 - 554 . Boudreau , K . J . , Guinan , E . C . , Lakhani , K . R . , & Riedl , C . ( 2016 ) . Looking across and looking beyond the knowledge frontier : Intellectual distance , novelty , and resource allocation in science . Management science , 62 ( 10 ) , 2765 - 2783 . Bush , V . ( 1945 ) . Science , the Endless Frontier : A Report to the President . US Government Printing Office . Chai , S . , & Menon , A . ( 2019 ) . Breakthrough recognition : Bias against novelty and competition for attention . Research Policy , 48 ( 3 ) , 733 - 747 . Cheng , M . , Smith , D . S . , Ren , X . , Cao , H . , Smith , S . , & McFarland , D . A . ( 2023 ) . How New Ideas Diffuse in Science . American Sociological Review , 88 ( 3 ) , 522 - 561 . Cohan , A . , Feldman , S . , Beltagy , I . , Downey , D . , & Weld , D . S . ( 2020 ) . SPECTER : Document - level Representation Learning using Citation - informed Transformers . In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics ( pp . 2270 - 2282 ) . de Price , D . J . S . ( 1963 ) . Little science , big science . New York : Columbia University Press . Färber , M . , & Ao , L . ( 2022 ) . The Microsoft Academic Knowledge Graph enhanced : Author name disambiguation , publication classification , and embeddings . Quantitative Science Studies , 3 ( 1 ) , 51 - 98 . 16 Fontana , M . , Iori , M . , Montobbio , F . , & Sinatra , R . ( 2020 ) . New and atypical combinations : An assessment of novelty and interdisciplinarity . Research Policy , 49 ( 7 ) , 104063 . Franzoni , C . , Stephan , P . , & Veugelers , R . ( 2022 ) . Funding risky research . Entrepreneurship and Innovation Policy and the Economy , 1 ( 1 ) , 103 - 133 . Funk , R . J . , & Owen - Smith , J . ( 2017 ) . A dynamic network measure of technological change . Management Science , 63 ( 3 ) , 791 - 817 . Iaria , A . , Schwarz , C . , & Waldinger , F . ( 2018 ) . Frontier knowledge and scientific production : Evidence from the collapse of international science . The Quarterly Journal of Economics , 133 ( 2 ) , 927 - 991 . Kuhn , TS ( 1970 ) . The Structure of Scientific Revolutions . University of Chicago Press . Li , X . , & Croft , W . B . ( 2008 ) . An information - pattern - based approach to novelty detection . Information Processing & Management , 44 ( 3 ) , 1159 - 1188 . Li , J . , Yin , Y . , Fortunato , S . , & Wang , D . ( 2019 ) . A dataset of publication records for Nobel laureates . Scientific data , 6 ( 1 ) , 1 - 10 . Lin , Z . , Yin , Y . , Liu , L . , & Wang , D . ( 2023 ) . SciSciNet : A large - scale open data lake for the science of science research . Scientific Data , 10 ( 1 ) , 315 . Mokyr , J . 2002 . The Gifts of Athena : Historical Origins of the Knowledge Economy . Princeton and Oxford : Princeton University Press Nelson , R . R . , & Winter , S . G . ( 1982 ) . An Evolutionary Theory of Economic Change . Cambridge , MA : Belknap Press of Harvard University Press . Park , M . , Leahey , E . , & Funk , R . J . ( 2023 ) . Papers and patents are becoming less disruptive over time . Nature , 613 ( 7942 ) , 138 - 144 . Teplitskiy , M . , Duede , E . , Menietti , M . , & Lakhani , K . R . ( 2022 ) . How status of research papers affects the way they are read and cited . Research Policy , 51 ( 4 ) , 104484 . Uzzi , B . , Mukherjee , S . , Stringer , M . & Jones , B . , ( 2013 ) . Atypical combinations and scientific impact . Science , 342 ( 6157 ) , 468 - 47 . Veugelers , R . , & Wang , J . ( 2019 ) . Scientific novelty and technological impact . Research Policy , 48 ( 6 ) , 1362 - 1372 . Wang , J . , Veugelers , R . , & Stephan , P . ( 2017 ) . Bias against novelty in science : A cautionary tale for users of bibliometric indicators . Research Policy , 46 ( 8 ) , 1416 - 1436 . Weitzman , M . L . ( 1998 ) . Recombinant growth . The Quarterly Journal of Economics , 113 ( 2 ) , 331 - 360 . Wu , L . , Wang , D . , & Evans , J . A . ( 2019 ) . Large teams develop and small teams disrupt science and technology . Nature , 566 ( 7744 ) , 378 - 382 . 17 Figure 1 : Scientific Novelty by Field of Study and Year Notes : Paper - level average number of new word combinations by fields of study and year ( n = 72 , 245 , 396 papers published between 1901 and 2020 . Fields are top down ordered by the overall number of publications . We use the enhanced version of the field of study classification of MAG papers from Färber & Ao ( 2022 ) . Table 1 : Summary Statistics Paper Level Mean St . Dev . Min p25 p50 p75 p95 Max Skew new _ word _ bin 0 . 079 0 . 270 0 . 000 0 . 000 0 . 000 0 . 000 1 . 000 1 . 000 3 . 123 new _ word 0 . 101 0 . 409 0 . 000 0 . 000 0 . 000 0 . 000 1 . 000 80 . 000 8 . 227 new _ word _ reuse 7 . 771 970 . 990 0 . 000 0 . 000 0 . 000 0 . 000 3 . 000 2 , 090 , 130 . 000 751 . 813 new _ bigram _ bin 0 . 274 0 . 446 0 . 000 0 . 000 0 . 000 1 . 000 1 . 000 1 . 000 1 . 015 new _ bigram 0 . 444 0 . 958 0 . 000 0 . 000 0 . 000 1 . 000 2 . 000 127 . 000 4 . 474 new _ bigram _ reuse 12 . 211 409 . 431 0 . 000 0 . 000 0 . 000 2 . 000 19 . 000 774 , 893 . 000 524 . 390 new _ trigram _ bin 0 . 469 0 . 499 0 . 000 0 . 000 0 . 000 1 . 000 1 . 000 1 . 000 0 . 126 new _ trigram 1 . 046 1 . 652 0 . 000 0 . 000 0 . 000 2 . 000 4 . 000 161 . 000 2 . 891 new _ trigram _ reuse 9 . 419 156 . 016 0 . 000 0 . 000 0 . 000 5 . 000 29 . 000 405 , 122 . 000 664 . 905 new _ gram _ bin ( NG ) 0 . 545 0 . 498 0 . 000 0 . 000 1 . 000 1 . 000 1 . 000 1 . 000 - 0 . 182 new _ word _ comb _ bin ( NC ) 0 . 517 0 . 500 0 . 000 0 . 000 1 . 000 1 . 000 1 . 000 1 . 000 - 0 . 066 new _ word _ comb 15 . 627 63 . 136 0 . 000 0 . 000 1 . 000 11 . 000 71 . 000 41 , 357 . 000 35 . 981 new _ word _ comb _ reuse 776 . 310 46 , 174 . 210 0 . 000 0 . 000 2 . 000 55 . 000 943 . 000 107 , 813 , 032 . 000 677 . 375 cosine _ max 0 . 411 0 . 126 0 . 006 0 . 334 0 . 418 0 . 498 0 . 603 0 . 989 - 0 . 413 wang 0 . 234 5 . 740 0 . 000 0 . 000 0 . 000 0 . 000 0 . 946 24 , 478 . 506 2 , 260 . 271 uzzi 46 . 199 310 . 509 - 445 . 270 - 6 . 025 0 . 428 12 . 518 183 . 332 102 , 810 . 925 27 . 819 cd 0 . 004 0 . 066 - 1 . 000 - 0 . 002 0 . 000 0 . 000 0 . 025 1 . 000 0 . 858 abstract 0 . 713 0 . 453 0 . 000 0 . 000 1 . 000 1 . 000 1 . 000 1 . 000 - 0 . 940 word 33 . 192 25 . 448 1 . 000 9 . 000 32 . 000 49 . 000 75 . 000 567 . 000 1 . 240 bigram 14 . 967 12 . 713 0 . 000 4 . 000 13 . 000 22 . 000 38 . 000 663 . 000 1 . 435 trigram 13 . 710 12 . 174 0 . 000 4 . 000 11 . 000 20 . 000 36 . 000 634 . 000 1 . 620 cited _ papers 16 . 571 26 . 252 0 . 000 0 . 000 8 . 000 25 . 000 58 . 000 24 , 483 . 000 31 . 479 cited _ journals 8 . 071 13 . 244 0 . 000 0 . 000 3 . 000 13 . 000 30 . 000 24 , 479 . 000 191 . 987 Notes : n = 72 , 245 , 396 papers published between 1901 and 2020 . p25 , p50 , p75 and p95 are respectively the 25 th , 50 th , 75 th and 95 th percentile . The skewness ( skew ) of the distributions is the measure of the asymmetry of the probability distribution of a real - valued random variable about its mean . A positive skewness indicates that the distribution has a long right tail , while a negative skewness indicates a long left tail . 18 Table 2 : Examples of Nobel Prizes Prize Short Prize Motivation Paper New ngram or word combination Physics 1920 Discovery of anomalies in nickel steel alloys Guillaume , C . E . ( 1919 ) . The anomaly of the nickel steels . Proceedings of the Physical Society of London , 32 ( 1 ) , 374 . anomaly , nickel ( 554 ) Physics 1936 Discovery of the positron Anderson , C . D . ( 1933 ) . The positive electron . Physical review , 43 ( 6 ) , 491 . positron ( 94 , 146 ) Medicine 1952 Discovery of streptomycin , the first antibiotic effective against tuberculosis Schatz , A . , Bugle , E . , & Waksman , S . A . ( 1944 ) . Streptomycin , a substance exhibiting antibiotic activity against gram - positive and gram - negative bacteria . ∗ . Proceedings of the Society for Experimental Biology and Medicine , 55 ( 1 ) , 66 - 69 . streptomycin ( 23 , 334 ) Physics 1956 Researches on semiconductors and discovery of the transistor effect Bardeen , J . , & Brattain , W . H . ( 1948 ) . The transistor , a semi - conductor triode . Physical Review , 74 ( 2 ) , 230 . transistor ( 152 , 047 ) Physics 1959 Discovery of the antiproton Chamberlain , O . , Segrè , E . , Wiegand , C . , & Ypsilantis , T . ( 1955 ) . Observation of antiprotons . Physical Review , 100 ( 3 ) , 947 . antiproton ( 5 , 023 ) Medicine 1963 Discoveries concerning the ionic mechanisms involved in excitation and inhibition in the peripheral and central portions of the nerve cell membrane Eccles , J . C . , Fatt , P . , & Koketsu , K . ( 1954 ) . Cholinergic and inhibitory synapses in a pathway from motor - axon collaterals to motoneurones . The Journal of physiology , 126 ( 3 ) , 524 . inhibitory _ synapsis ( 2 , 199 ) Physics 1965 Fundamental work in quantum electrodynamics , with deep - ploughing consequences for the physics of elementary particles Feynman , R . P . ( 1949 ) . Space - Time Approach to Quantum Electrodynamics . Physical Review , 76 ( 6 ) . electrodynamics ( 653 ) Medicine 1970 Discoveries concerning the humoral transmitters in the nerve terminals and the mechanism for their storage , release and inactivation Von Euler , U . S . , & Hillarp , N . Å . ( 1956 ) . Evidence for the presence of noradrenaline in submicroscopic structures of adrenergic axons . Nature , 177 ( 4497 ) . noradrenaline , release ( 8 , 388 ) Medicine 1979 development of computer assisted tomography Hounsfield , G . N . ( 1973 ) . Computerized transverse axial scanning ( tomography ) : Part 1 . Description of system . The British journal of radiology , 46 ( 552 ) , 1016 - 1022 . sensitive , tomography ( 11 , 498 ) Physics 1986 Fundamental work in electron optics , and for the design of the first electron microscope Binnig , G . , Rohrer , H . , Gerber , C . , & Weibel , E . ( 1982 ) . Surface studies by scanning tunneling microscopy . Physical review letters , 49 ( 1 ) , 57 . scanning _ tunnel _ microscopy ( 17 , 914 ) Medicine 1990 Discoveries concerning organ and cell transplantation in the treatment of human disease Thomas , E . D . , Lochte , H . L . , Cannon , J . H . , Sahler , O . D . , & Ferrebee , J . W . ( 1959 ) . Supralethal whole body irradiation and isologous marrow transplantation in man . The Journal of clinical investigation , 38 ( 10 ) , 1709 - 1716 . remission , transplantation ( 15 , 977 ) Chemistry 1993 Invention of the polymerase chain reaction ( PCR ) method Mullis , K . , Faloona , F . , Scharf , S . , Saiki , R . , Horn , G . , & Erlich , H . ( 1986 ) . Specific enzymatic amplification of DNA in vitro : the polymerase chain reaction . In Cold Spring Harbor symposia on quantitative biology ( Vol . 51 , pp . 263 - 273 ) polymerase _ chain _ reaction ( 209 , 968 ) Chemistry 1995 Work in atmospheric chemistry , particularly concerning the formation and decomposition of ozone Molina , M . J . , & Rowland , F . S . ( 1974 ) . Stratospheric sink for chlorofluoromethanes : chlorine atom - catalysed destruction of ozone . Nature , 249 ( 5460 ) , 810 - 812 . chlorine , stratosphere ( 817 ) Medicine 1997 Discovery of Prions - a new biological principle of infection Prusiner , S . B . ( 1982 ) . Novel proteinaceous infectious particles cause scrapie . Science , 216 ( 4542 ) , 136 - 144 . prion , protein ( 13 , 513 ) Chemistry 2001 Work on chirally catalysed hydrogenation reactions Nozaki , H . , Takaya , H . , Moriuti , S . , & Noyori , R . ( 1968 ) . Homogeneous catalysis in the decomposition of diazo compounds by copper chelates : Asymmetric carbenoid reactions . Tetrahedron , 24 ( 9 ) , 3655 - 3669 . chiral , synthesis ( 34 , 820 ) Physics 2005 Contribution to the quantum theory of optical coherence Glauber , R . J . ( 1963 ) . The quantum theory of optical coherence . Physical Review , 130 ( 6 ) , 2529 . optical _ coherence ( 50 , 175 ) Physics 2007 Discovery of Giant Magnetoresistance Baibich , M . N . , Broto , J . M . , Fert , A . , Van Dau , F . N . , Petroff , F . , Etienne , P . , & Chazelas , J . ( 1988 ) . Giant magnetoresistance of ( 001 ) Fe / ( 001 ) Cr magnetic superlattices . Physical review letters , 61 ( 21 ) , 2472 . giant _ magnetoresistance ( 3 , 950 ) Medicine 2007 Discoveries of principles for introducing specific gene modifications in mice by the use of embryonic stem cells Thomas , K . R . , & Capecchi , M . R . ( 1987 ) . Site - directed mutagenesis by gene targeting in mouse embryo - derived stem cells . Cell , 51 ( 3 ) , 503 - 512 . gene _ target ( 7 , 188 ) Medicine 2009 Discovery of how chromosomes are protected by telomeres and the enzyme telomerase Szostak , J . W . , & Blackburn , E . H . ( 1982 ) . Cloning yeast telomeres on linear plasmid vectors . Cell , 29 ( 1 ) , 245 - 255 . telomere _ sequence ( 468 ) Medicine 2016 Discoveries of mechanisms for autophagy Takeshige , K . , Baba , M . , Tsuboi , S . , Noda , T . , & Ohsumi , Y . ( 1992 ) . Autophagy in yeast demonstrated with proteinase - deficient mutants and conditions for its induction . The Journal of cell biology , 119 ( 2 ) , 301 - 311 . autophagy , genetic ( 3 , 396 ) Notes : 20 illustrative examples of Nobel prizes , a corresponding paper , and a new ngram or word combination introduced by the paper and found in the corresponding Nobel prize motivation page . Bigrams and trigrams are separated by the underscore ( e . g . ‘gene _ target’ is a bigram ) , new word combinations are separated by the comma ( e . g . ‘chiral , synthesis’ is a new word combination ) . The reuse by later papers is shown between brackets . 19 Table 3 : Descriptive Statistics Nobel Prize versus Control Papers Mean Stdev Min Max Mean Stdev Min Max Cohen ' s d t Pr ( | T | > | t | ) Nobel prize papers ( n = 501 ) Control papers ( n = 501 ) new _ word _ bin 0 . 297 0 . 458 0 . 000 1 . 000 0 . 184 0 . 388 0 . 000 1 . 000 - 0 . 268 - 4 . 247 0 . 0000 * * * new _ word 0 . 253 0 . 425 0 . 000 2 . 197 0 . 137 0 . 334 0 . 000 1 . 609 - 0 . 302 - 4 . 780 0 . 0000 * * * new _ word _ reuse 1 . 478 2 . 735 0 . 000 12 . 342 0 . 572 1 . 548 0 . 000 9 . 128 - 0 . 408 - 6 . 457 0 . 0000 * * * new _ bigram _ bin 0 . 639 0 . 481 0 . 000 1 . 000 0 . 433 0 . 496 0 . 000 1 . 000 - 0 . 421 - 6 . 661 0 . 0000 * * * new _ bigram 0 . 766 0 . 717 0 . 000 3 . 178 0 . 456 0 . 59 0 . 000 2 . 303 - 0 . 472 - 7 . 471 0 . 0000 * * * new _ bigram _ reuse 3 . 155 2 . 962 0 . 000 11 . 284 1 . 564 2 . 211 0 . 000 9 . 496 - 0 . 609 - 9 . 633 0 . 0000 * * * new _ trigram _ bin 0 . 750 0 . 433 0 . 000 1 . 000 0 . 645 0 . 479 0 . 000 1 . 000 - 0 . 232 - 3 . 666 0 . 0000 * * * new _ trigram 1 . 105 0 . 829 0 . 000 3 . 466 0 . 752 0 . 685 0 . 000 2 . 708 - 0 . 464 - 7 . 343 0 . 0000 * * * new _ trigram _ reuse 3 . 140 2 . 349 0 . 000 9 . 793 1 . 964 1 . 916 0 . 000 8 . 755 - 0 . 549 - 8 . 685 0 . 0000 * * * new _ gram _ bin ( NG ) 0 . 828 0 . 377 0 . 000 1 . 000 0 . 721 0 . 449 0 . 000 1 . 000 - 0 . 260 - 4 . 112 0 . 0000 * * * new _ word _ comb _ bin ( NC ) 0 . 840 0 . 367 0 . 000 1 . 000 0 . 691 0 . 463 0 . 000 1 . 000 - 0 . 359 - 5 . 676 0 . 0000 * * * new _ word _ comb 2 . 880 1 . 947 0 . 000 7 . 674 1 . 959 1 . 846 0 . 000 6 . 569 - 0 . 486 - 7 . 685 0 . 0000 * * * new _ word _ comb _ reuse 6 . 950 3 . 908 0 . 000 15 . 245 4 . 343 3 . 767 0 . 000 13 . 853 - 0 . 679 - 10 . 748 0 . 0000 * * * cosine _ max 0 . 407 0 . 124 0 . 028 0 . 725 0 . 397 0 . 145 0 . 024 0 . 961 - 0 . 076 - 1 . 198 0 . 2312 wang 0 . 036 0 . 167 0 . 000 1 . 389 0 . 019 0 . 138 0 . 000 1 . 530 - 0 . 109 - 1 . 730 0 . 0840 * uzzi 6 . 949 0 . 751 6 . 207 8 . 505 7 . 157 0 . 771 6 . 307 9 . 748 0 . 274 4 . 329 0 . 0000 * * * cd 0 . 097 0 . 209 - 0 . 522 0 . 974 0 . 042 0 . 145 - 0 . 500 0 . 966 - 0 . 307 - 4 . 858 0 . 0000 * * * Notes : n = 1 , 002 papers of which 501 Nobel prize papers and 501 matched control papers . Each Nobel prize paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . Cohen ' s d is the mean difference between award and control papers divided by the pooled standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 Table 4 : Likelihood of Nobel prize Paper ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) ( 13 ) ( 14 ) ( 15 ) ( 16 ) ( 17 ) ( 18 ) ( 19 ) ( 20 ) new _ word 0 . 418 * - 0 . 201 - 0 . 133 ( 0 . 225 ) ( 0 . 253 ) ( 0 . 258 ) new _ word _ reuse 0 . 164 * * * 0 . 066 * 0 . 066 * ( 0 . 037 ) ( 0 . 039 ) ( 0 . 040 ) new _ bigram 0 . 985 * * * 0 . 420 * * 0 . 414 * * ( 0 . 176 ) ( 0 . 207 ) ( 0 . 205 ) new _ bigram _ reuse 0 . 287 * * * 0 . 116 * * 0 . 111 * * ( 0 . 040 ) ( 0 . 046 ) ( 0 . 047 ) new _ trigram 1 . 110 * * * 0 . 768 * * * 0 . 787 * * * ( 0 . 184 ) ( 0 . 202 ) ( 0 . 202 ) new _ trigram _ reuse 0 . 343 * * * 0 . 179 * * * 0 . 168 * * * ( 0 . 052 ) ( 0 . 059 ) ( 0 . 059 ) new _ word _ comb 0 . 613 * * * 0 . 464 * * * 0 . 467 * * * ( 0 . 096 ) ( 0 . 113 ) ( 0 . 113 ) new _ word _ comb _ reuse 0 . 324 * * * 0 . 234 * * * 0 . 231 * * * ( 0 . 037 ) ( 0 . 040 ) ( 0 . 040 ) cosine _ max - 0 . 440 - 1 . 331 * - 1 . 294 * ( 0 . 718 ) ( 0 . 733 ) ( 0 . 732 ) new _ gram _ bin ( NG ) 0 . 481 * * ( 0 . 242 ) new _ word _ comb _ bin ( NC ) 0 . 920 * * * ( 0 . 249 ) wang 0 . 279 0 . 052 0 . 027 ( 0 . 517 ) ( 0 . 505 ) ( 0 . 554 ) uzzi - 0 . 305 * * - 0 . 303 * * - 0 . 357 * * * ( 0 . 123 ) ( 0 . 125 ) ( 0 . 132 ) cd 2 . 504 * * * 2 . 141 * * * ( 0 . 573 ) ( 0 . 603 ) ll - 580 . 2 - 578 . 4 - 570 . 7 - 561 . 8 - 547 . 7 - 560 . 3 - 554 . 8 - 557 . 4 - 528 . 6 - 580 . 0 - 578 . 1 - 572 . 9 - 580 . 0 - 577 . 0 - 566 . 0 - 542 . 4 - 514 . 8 - 577 . 0 - 538 . 5 - 505 . 8 pseudor2 0 . 093 0 . 095 0 . 107 0 . 121 0 . 143 0 . 124 0 . 132 0 . 128 0 . 173 0 . 093 0 . 096 0 . 104 0 . 093 0 . 098 0 . 115 0 . 152 0 . 195 0 . 098 0 . 158 0 . 209 Precision ( % ) 63 . 76 64 . 44 65 . 20 67 . 00 68 . 45 64 . 99 68 . 52 67 . 06 71 . 03 63 . 80 63 . 67 65 . 43 64 . 08 63 . 97 65 . 48 68 . 36 71 . 25 63 . 83 69 . 11 71 . 40 Recall ( % ) 69 . 12 68 . 91 68 . 49 69 . 96 69 . 75 67 . 86 69 . 96 72 . 27 75 . 21 68 . 49 68 . 49 70 . 38 69 . 33 69 . 75 69 . 33 70 . 80 72 . 90 69 . 33 71 . 43 73 . 95 AUC 0 . 6977 0 . 7007 0 . 7102 0 . 7281 0 . 7466 0 . 7279 0 . 7389 0 . 7332 0 . 7733 0 . 6982 0 . 7012 0 . 7140 0 . 6977 0 . 7021 0 . 7220 0 . 7515 0 . 7862 0 . 7020 0 . 7558 0 . 7947 Marginal Effects ( % ) 3 . 55 8 . 08 14 . 06 16 . 15 18 . 31 15 . 92 24 . 82 25 . 5 - 1 . 30 4 . 36 8 . 27 0 . 97 - 5 . 07 9 . 80 Notes : Logit regression , robust standard errors between brackets . n = 1 , 002 papers of which 501 Nobel prize papers and 501 matched control papers . Each Nobel prize paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . All models include publication year and field of study fixed effects , and additionally control for whether the paper has an abstract available , text length ( number of unigrams , bigrams and trigrams in the title and abstract of the paper ) , and the number of unique papers and journals cited by the focal paper . Auc is area under the ROC curve . Marginal effects are calculated as the % increase in the likelihood of being a Nobel prize paper associated with an increase in the metric with one standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 20 Online Appendix Appendix A Figure A . 1 : Scientific Novelty by Selected Subfields of Physics and Year Notes : Paper - level average number of new word combinations for a subset of 4 subfields of Physics and year ( n = 1 , 227 , 396 papers published between 1901 and 2020 ) . Subfields are top down ordered by the overall number of publications . We use the enhanced version of the field of study classification of MAG papers from Färber & Ao ( 2022 ) . Table A . 1 : Summary Statistics New Ngrams or Word Combinations Reuse # Mean Std . Dev . Min p25 p50 p75 p95 Max Skew new _ word 7 , 305 , 080 75 . 857 2 , 943 . 038 1 1 3 7 77 2 , 090 , 129 243 . 493 new _ bigram 32 , 104 , 336 26 . 479 569 . 071 1 1 2 8 60 685 , 806 359 . 330 new _ trigram 75 , 573 , 271 8 . 005 141 . 931 1 1 2 4 21 346 , 190 677 . 104 new _ word _ comb 1 , 129 , 014 , 727 48 . 676 1 , 101 . 705 1 1 2 9 81 2 , 322 , 860 240 . 320 Notes : Summary statistics for new ngrams or word combinations introduced from 1901 to 2020 . # is the number of units ( e . g . there are 7 , 305 , 080 new words introduced for the first time from 1901 to 2020 that are reused at least once ) . p25 , p50 , p75 and p95 are respectively the 25 th , 50 th , 75 th and 95 th percentile . The skewness ( skew ) of the distributions is the measure of the asymmetry of the probability distribution of a real - valued random variable about its mean . A positive skewness indicates that the distribution has a long right tail , while a negative skewness indicates a long left tail . 21 Table A . 2 : Correlation matrix ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) ( 13 ) ( 14 ) ( 15 ) ( 16 ) ( 17 ) ( 18 ) ( 19 ) ( 20 ) ( 21 ) ( 22 ) ( 1 ) new _ word _ bin 1 . 00 ( 2 ) new _ word 0 . 85 1 . 00 ( 3 ) new _ word _ reuse 0 . 03 0 . 05 1 . 00 ( 4 ) new _ bigram _ bin 0 . 22 0 . 21 0 . 01 1 . 00 ( 5 ) new _ bigram 0 . 28 0 . 32 0 . 03 0 . 76 1 . 00 ( 6 ) new _ bigram _ reuse 0 . 03 0 . 05 0 . 07 0 . 05 0 . 11 1 . 00 ( 7 ) new _ trigram _ bin 0 . 17 0 . 15 0 . 01 0 . 37 0 . 33 0 . 03 1 . 00 ( 8 ) new _ trigram 0 . 23 0 . 24 0 . 02 0 . 42 0 . 54 0 . 07 0 . 67 1 . 00 ( 9 ) new _ trigram _ reuse 0 . 04 0 . 05 0 . 04 0 . 06 0 . 11 0 . 23 0 . 06 0 . 14 1 . 00 ( 10 ) new _ gram _ bin ( NG ) 0 . 27 0 . 23 0 . 01 0 . 56 0 . 42 0 . 03 0 . 86 0 . 58 0 . 06 1 . 00 ( 11 ) new _ word _ comb _ bin ( NC ) 0 . 22 0 . 20 0 . 01 0 . 39 0 . 34 0 . 03 0 . 46 0 . 42 0 . 05 0 . 51 1 . 00 ( 12 ) new _ word _ comb 0 . 27 0 . 40 0 . 04 0 . 26 0 . 52 0 . 09 0 . 21 0 . 46 0 . 10 0 . 20 0 . 24 1 . 00 ( 13 ) new _ word _ comb _ reuse 0 . 03 0 . 07 0 . 12 0 . 02 0 . 10 0 . 16 0 . 02 0 . 07 0 . 11 0 . 01 0 . 02 0 . 24 1 . 00 ( 14 ) cosine _ max 0 . 07 0 . 07 0 . 00 0 . 10 0 . 11 0 . 01 0 . 08 0 . 06 0 . 01 0 . 11 0 . 13 0 . 07 0 . 01 1 . 00 ( 15 ) wang 0 . 00 0 . 00 0 . 00 0 . 00 0 . 00 0 . 00 0 . 01 0 . 01 0 . 00 0 . 01 0 . 01 0 . 00 0 . 00 0 . 00 1 . 00 ( 16 ) uzzi - 0 . 01 - 0 . 01 0 . 00 - 0 . 01 - 0 . 01 0 . 00 - 0 . 03 - 0 . 03 0 . 00 - 0 . 02 - 0 . 01 - 0 . 02 0 . 00 0 . 00 - 0 . 03 1 . 00 ( 17 ) cd 0 . 01 0 . 02 0 . 01 0 . 02 0 . 04 0 . 02 0 . 01 0 . 03 0 . 02 0 . 01 0 . 01 0 . 03 0 . 03 0 . 02 0 . 00 0 . 04 1 . 00 ( 18 ) abstract 0 . 14 0 . 12 0 . 00 0 . 26 0 . 22 0 . 01 0 . 38 0 . 32 0 . 03 0 . 40 0 . 43 0 . 15 0 . 01 0 . 12 0 . 02 - 0 . 07 - 0 . 03 1 . 00 ( 19 ) words 0 . 18 0 . 19 0 . 00 0 . 30 0 . 33 0 . 01 0 . 37 0 . 42 0 . 03 0 . 37 0 . 35 0 . 38 0 . 02 0 . 07 0 . 03 - 0 . 09 - 0 . 03 0 . 68 1 . 00 ( 20 ) bigrams 0 . 17 0 . 17 0 . 00 0 . 30 0 . 34 0 . 01 0 . 36 0 . 42 0 . 03 0 . 36 0 . 31 0 . 33 0 . 01 0 . 03 0 . 02 - 0 . 08 - 0 . 04 0 . 61 0 . 94 1 . 00 ( 21 ) trigrams 0 . 15 0 . 16 0 . 00 0 . 28 0 . 31 0 . 01 0 . 37 0 . 45 0 . 03 0 . 36 0 . 29 0 . 32 0 . 01 0 . 01 0 . 02 - 0 . 08 - 0 . 04 0 . 59 0 . 92 0 . 94 1 . 00 ( 22 ) cited _ papers 0 . 01 0 . 01 0 . 00 0 . 05 0 . 03 - 0 . 01 0 . 10 0 . 07 0 . 00 0 . 10 0 . 07 0 . 02 - 0 . 01 - 0 . 04 0 . 31 - 0 . 11 - 0 . 07 0 . 33 0 . 35 0 . 34 0 . 33 1 . 00 ( 23 ) cited _ journals 0 . 01 0 . 00 0 . 00 0 . 04 0 . 02 - 0 . 01 0 . 09 0 . 06 0 . 00 0 . 09 0 . 07 0 . 01 - 0 . 01 - 0 . 04 0 . 50 - 0 . 14 - 0 . 07 0 . 32 0 . 35 0 . 36 0 . 35 0 . 87 Notes : n = 72 , 245 , 396 papers published between 1901 and 2020 22 Table A . 3 : Descriptive Statistics Literature Review versus Control Papers Mean Stdev Min Max Mean Stdev Min Max Cohen ' s d t Pr ( | T | > | t | ) Literature review papers ( n = 49 , 523 ) Control papers ( n = 49 , 523 ) new word _ bin 0 . 038 0 . 192 0 . 000 1 . 000 0 . 067 0 . 250 0 . 000 1 . 000 0 . 129 20 . 225 0 . 0000 * * * new _ word 0 . 028 0 . 145 0 . 000 1 . 946 0 . 052 0 . 203 0 . 000 2 . 398 0 . 135 21 . 291 0 . 0000 * * * new _ word _ reuse 0 . 064 0 . 347 0 . 000 7 . 106 0 . 135 0 . 584 0 . 000 9 . 001 0 . 147 23 . 152 0 . 0000 * * * new _ bigram _ bin 0 . 220 0 . 414 0 . 000 1 . 000 0 . 297 0 . 457 0 . 000 1 . 000 0 . 178 27 . 948 0 . 0000 * * * new _ bigram 0 . 176 0 . 349 0 . 000 3 . 332 0 . 264 0 . 441 0 . 000 3 . 091 0 . 222 34 . 896 0 . 0000 * * * new _ bigram _ reuse 0 . 388 0 . 822 0 . 000 8 . 483 0 . 610 1 . 120 0 . 000 10 . 289 0 . 226 35 . 546 0 . 0000 * * * new _ trigram _ bin 0 . 475 0 . 499 0 . 000 1 . 000 0 . 541 0 . 498 0 . 000 1 . 000 0 . 131 20 . 682 0 . 0000 * * * new _ trigram 0 . 464 0 . 543 0 . 000 2 . 639 0 . 582 0 . 618 0 . 000 3 . 401 0 . 202 31 . 857 0 . 0000 * * * new _ trigram _ reuse 0 . 922 1 . 098 0 . 000 7 . 668 1 . 167 1 . 286 0 . 000 9 . 730 0 . 205 32 . 258 0 . 0000 * * * new _ gram _ bin ( NG ) 0 . 547 0 . 498 0 . 000 1 . 000 0 . 613 0 . 487 0 . 000 1 . 000 0 . 134 21 . 027 0 . 0000 * * * new _ word _ comb _ bin ( NC ) 0 . 631 0 . 483 0 . 000 1 . 000 0 . 666 0 . 472 0 . 000 1 . 000 0 . 074 11 . 708 0 . 0000 * * * new _ word _ comb 1 . 310 1 . 272 0 . 000 7 . 846 1 . 696 1 . 575 0 . 000 8 . 193 0 . 270 42 . 460 0 . 0000 * * * new _ word _ comb _ reuse 2 . 182 1 . 936 0 . 000 9 . 881 2 . 742 2 . 438 0 . 000 14 . 182 0 . 254 40 . 014 0 . 0000 * * * cosine _ max 0 . 398 0 . 147 0 . 012 0 . 960 0 . 407 0 . 141 0 . 016 0 . 973 0 . 058 9 . 051 0 . 0000 * * * wang 0 . 176 0 . 525 0 . 000 7 . 679 0 . 090 0 . 335 0 . 000 6 . 874 - 0 . 195 - 30 . 746 0 . 0000 * * * uzzi 6 . 967 0 . 782 6 . 148 12 . 718 7 . 040 0 . 883 6 . 090 12 . 718 0 . 087 13 . 690 0 . 0000 * * * cd 0 . 005 0 . 05 - 0 . 221 0 . 195 0 . 009 0 . 049 - 0 . 220 0 . 205 0 . 083 13 . 136 0 . 0000 * * * Notes : n = 99 , 046 papers of which 49 , 523 literature review papers and 49 , 523 matched control papers published between 1901 and 2010 ( n = 48 , 265 unique control papers , with 921 control papers matched with more than one review paper ) . Each literature review paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . Cohen ' s d is the mean difference between award and control papers divided by the pooled standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 Table A . 4 : Likelihood of Literature Review Paper with ex - ante Metrics ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) ( 13 ) new _ word - 0 . 508 * * * - 0 . 151 * * * - 0 . 146 * * * ( 0 . 042 ) ( 0 . 043 ) ( 0 . 043 ) new _ bigram - 0 . 404 * * * - 0 . 209 * * * - 0 . 216 * * * ( 0 . 019 ) ( 0 . 021 ) ( 0 . 021 ) new _ trigram - 0 . 178 * * * - 0 . 058 * * * - 0 . 069 * * * ( 0 . 015 ) ( 0 . 016 ) ( 0 . 016 ) new _ word _ comb - 0 . 288 * * * - 0 . 249 * * * - 0 . 249 * * * ( 0 . 008 ) ( 0 . 009 ) ( 0 . 009 ) cosine _ max - 0 . 433 * * * - 0 . 320 * * * - 0 . 264 * * * ( 0 . 052 ) ( 0 . 052 ) ( 0 . 052 ) new _ gram _ bin ( NG ) - 0 . 103 * * * ( 0 . 017 ) new _ word _ comb _ bin ( NC ) - 0 . 077 * * * ( 0 . 021 ) wang 0 . 306 * * * 0 . 282 * * * 0 . 286 * * * ( 0 . 020 ) ( 0 . 021 ) ( 0 . 021 ) uzzi - 0 . 091 * * * - 0 . 066 * * * - 0 . 071 * * * ( 0 . 010 ) ( 0 . 010 ) ( 0 . 010 ) ll - 60961 - 60885 - 60744 - 60892 - 60336 - 60925 - 60943 - 60954 - 60834 - 60915 - 60240 - 60810 - 60085 pseudor2 0 . 111 0 . 113 0 . 115 0 . 112 0 . 121 0 . 112 0 . 112 0 . 112 0 . 113 0 . 112 0 . 122 0 . 114 0 . 124 Precision ( % ) 65 . 15 65 . 26 65 . 47 65 . 17 65 . 87 65 . 13 65 . 23 65 . 17 65 . 27 65 . 15 65 . 95 65 . 23 66 . 16 Recall ( % ) 69 . 15 69 . 27 69 . 39 69 . 15 69 . 38 69 . 14 69 . 19 69 . 14 68 . 96 69 . 16 69 . 64 69 . 06 69 . 55 AUC 0 . 7192 0 . 7203 0 . 7220 0 . 7199 0 . 7273 0 . 7197 0 . 7195 0 . 7193 0 . 7210 0 . 7198 0 . 7285 0 . 7213 0 . 7307 Marginal Effects ( % ) - 1 . 92 - 3 . 44 - 2 . 22 - 8 . 77 - 1 . 34 - 1 . 09 - 0 . 78 2 . 89 - 1 . 63 Notes : Logit regression , robust standard errors between brackets . n = 99 , 046 papers of which 49 , 523 literature review papers and 49 , 523 matched control papers published between 1901 and 2010 ( n = 48 , 265 unique control papers , with 921 control papers matched with more than one review paper ) . Each literature review paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity are log transformed after adding 1 for measures with 0 values . All models include publication year and field of study fixed effects , and additionally control for whether the paper has an abstract available , text length ( number of unigrams , bigrams and trigrams in the title and abstract of the paper ) , and the number of unique papers and journals cited by the focal paper . Auc is area under the ROC curve . Marginal effects are calculated as the % increase in the likelihood of being a literature review paper associated with an increase in the metric with one standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 23 Table A . 5 : Descriptive Statistics Nobel Prize versus Control Papers ( only titles ) Mean Stdev Min Max Mean Stdev Min Max Cohen ' s d t Pr ( | T | > | t | ) Nobel prize papers ( n = 501 ) Control papers ( n = 501 ) new _ word _ bin 0 . 086 0 . 280 0 . 000 1 . 000 0 . 038 0 . 191 0 . 000 1 . 000 - 0 . 200 - 3 . 159 0 . 002 * * * new _ word 0 . 065 0 . 217 0 . 000 1 . 609 0 . 029 0 . 148 0 . 000 1 . 099 - 0 . 193 - 3 . 055 0 . 002 * * * new _ word _ reuse 0 . 403 1 . 541 0 . 000 11 . 090 0 . 131 0 . 756 0 . 000 8 . 087 - 0 . 225 - 3 . 560 0 . 000 * * * new _ bigram _ bin 0 . 369 0 . 483 0 . 000 1 . 000 0 . 273 0 . 446 0 . 000 1 . 000 - 0 . 206 - 3 . 261 0 . 001 * * * new _ bigram 0 . 299 0 . 413 0 . 000 1 . 609 0 . 212 0 . 360 0 . 000 1 . 609 - 0 . 225 - 3 . 563 0 . 000 * * * new _ bigram _ reuse 1 . 421 2 . 199 0 . 000 10 . 203 0 . 761 1 . 491 0 . 000 8 . 205 - 0 . 351 - 5 . 562 0 . 000 * * * new _ trigram _ bin 0 . 481 0 . 500 0 . 000 1 . 000 0 . 375 0 . 485 0 . 000 1 . 000 - 0 . 215 - 3 . 400 0 . 001 * * * new _ trigram 0 . 413 0 . 470 0 . 000 2 . 079 0 . 298 0 . 403 0 . 000 1 . 792 - 0 . 262 - 4 . 150 0 . 000 * * * new _ trigram _ reuse 1 . 343 1 . 713 0 . 000 8 . 637 0 . 835 1 . 312 0 . 000 7 . 803 - 0 . 333 - 5 . 272 0 . 000 * * * new _ gram _ bin ( NG ) 0 . 641 0 . 480 0 . 000 1 . 000 0 . 503 0 . 500 0 . 000 1 . 000 - 0 . 281 - 4 . 444 0 . 000 * * * new _ word _ comb _ bin ( NC ) 0 . 697 0 . 460 0 . 000 1 . 000 0 . 491 0 . 500 0 . 000 1 . 000 - 0 . 428 - 6 . 769 0 . 000 * * * new _ word _ comb 1 . 084 0 . 901 0 . 000 4 . 025 0 . 728 0 . 878 0 . 000 3 . 689 - 0 . 400 - 6 . 338 0 . 000 * * * new _ word _ comb _ reuse 3 . 935 3 . 037 0 . 000 11 . 780 2 . 323 2 . 747 0 . 000 10 . 077 - 0 . 557 - 8 . 810 0 . 000 * * * wang 0 . 036 0 . 167 0 . 000 1 . 389 0 . 019 0 . 138 0 . 000 1 . 530 - 0 . 109 - 1 . 730 0 . 084 uzzi 6 . 949 0 . 751 6 . 207 8 . 505 7 . 157 0 . 771 6 . 307 9 . 748 0 . 274 4 . 329 0 . 000 * * * cd 0 . 097 0 . 209 - 0 . 522 0 . 974 0 . 042 0 . 145 - 0 . 500 0 . 966 - 0 . 307 - 4 . 858 0 . 000 * * * Notes : n = 1 , 002 papers of which 501 Nobel prize papers and 501 matched control papers . Each Nobel prize paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . Cohen ' s d is the mean difference between award and control papers divided by the pooled standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 Table A . 6 : Likelihood of Nobel prize Paper ( only titles ) ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) ( 11 ) ( 12 ) ( 13 ) ( 14 ) ( 15 ) ( 16 ) ( 17 ) ( 18 ) ( 19 ) ( 20 ) new _ word 1 . 209 * * * 0 . 781 0 . 959 * ( 0 . 457 ) ( 0 . 486 ) ( 0 . 494 ) new _ word _ reuse 0 . 231 * * * 0 . 182 * * 0 . 193 * * * ( 0 . 071 ) ( 0 . 075 ) ( 0 . 075 ) new _ bigram 0 . 901 * * * 0 . 294 0 . 314 ( 0 . 228 ) ( 0 . 252 ) ( 0 . 256 ) new _ bigram _ reuse 0 . 255 * * * 0 . 124 * * 0 . 130 * * ( 0 . 046 ) ( 0 . 051 ) ( 0 . 052 ) new _ trigram 0 . 830 * * * 0 . 607 * * * 0 . 622 * * * ( 0 . 205 ) ( 0 . 219 ) ( 0 . 219 ) new _ trigram _ reuse 0 . 269 * * * 0 . 150 * * 0 . 143 * * ( 0 . 057 ) ( 0 . 066 ) ( 0 . 068 ) new _ word _ comb 0 . 749 * * * 0 . 625 * * * 0 . 673 * * * ( 0 . 117 ) ( 0 . 124 ) ( 0 . 129 ) new _ word _ comb _ reuse 0 . 267 * * * 0 . 211 * * * 0 . 200 * * * ( 0 . 033 ) ( 0 . 035 ) ( 0 . 036 ) new _ gram _ bin ( NG ) 0 . 826 * * * ( 0 . 177 ) new _ word _ comb _ bin ( NC ) 1 . 116 * * * ( 0 . 182 ) wang 0 . 478 0 . 179 0 . 378 ( 0 . 555 ) ( 0 . 538 ) ( 0 . 498 ) uzzi - 0 . 380 * * * - 0 . 372 * * * - 0 . 370 * * * ( 0 . 120 ) ( 0 . 123 ) ( 0 . 129 ) cd 2 . 308 * * * 2 . 082 * * * ( 0 . 555 ) ( 0 . 564 ) ll - 592 . 7 - 588 . 6 - 586 . 7 - 583 . 8 - 574 . 9 - 584 . 3 - 580 . 5 - 569 . 2 - 554 . 7 - 581 . 1 - 572 . 8 - 592 . 3 - 587 . 6 - 580 . 1 - 561 . 9 - 543 . 8 - 587 . 5 - 555 . 6 - 534 . 7 pseudor2 0 . 0729 0 . 0793 0 . 0822 0 . 0868 0 . 1013 0 . 0860 0 . 0921 0 . 1101 0 . 1320 0 . 0911 0 . 1042 0 . 0736 0 . 0810 0 . 0926 0 . 1212 0 . 1491 0 . 0811 0 . 1312 0 . 1643 Precision ( % ) 61 . 32 61 . 64 62 . 24 65 . 94 65 . 85 63 . 98 63 . 93 65 . 09 67 . 47 65 . 40 63 . 71 61 . 87 61 . 81 64 . 45 67 . 32 69 . 45 61 . 96 67 . 33 70 . 21 Recall ( % ) 68 . 28 67 . 86 67 . 86 69 . 96 68 . 07 66 . 81 67 . 02 69 . 33 71 . 01 68 . 70 69 . 33 69 . 54 68 . 70 69 . 33 71 . 85 71 . 64 69 . 12 71 . 43 69 . 33 AUC 0 . 6707 0 . 6783 0 . 6815 0 . 6926 0 . 7064 0 . 6885 0 . 6951 0 . 7128 0 . 7370 0 . 6957 0 . 7035 0 . 6717 0 . 6828 0 . 6968 0 . 7247 0 . 7523 0 . 6827 0 . 7356 0 . 7640 Marginal Effects ( % ) 5 . 18 6 . 43 7 . 84 10 . 76 8 . 20 9 . 32 14 . 66 16 . 65 8 . 98 11 . 8 1 . 71 - 6 . 45 9 . 32 Notes : Logit regression , robust standard errors between brackets . n = 1 , 002 papers of which 501 Nobel prize papers and 501 matched control papers . Each Nobel prize paper is matched to one randomly selected control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity are log transformed after adding 1 for measures with 0 values . All models include publication year and field of study fixed effects , and additionally control for text length ( number of unigrams , bigrams and trigrams in the title of the paper ) , and the number of unique papers and journals cited by the focal paper . Auc is area under the ROC curve . Marginal effects are calculated as the % increase in the likelihood of being a Nobel prize paper associated with an increase in the metric with one standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 24 Table A . 7 : Descriptive Statistics Top Cited versus Control Papers Mean Stdev Min Max Mean Stdev Min Max Cohen ' s d t Pr ( | T | > | t | ) Top - cited papers ( n = 216 , 434 ) Control papers ( n = 216 , 434 ) new word _ bin 0 . 166 0 . 372 0 . 000 1 . 000 0 . 117 0 . 322 0 . 000 1 . 000 - 0 . 141 - 46 . 361 0 . 0000 * * * new _ word 0 . 138 0 . 327 0 . 000 3 . 497 0 . 093 0 . 267 0 . 000 2 . 565 - 0 . 149 - 49 . 057 0 . 0000 * * * new _ word _ reuse 0 . 503 1 . 344 0 . 000 13 . 167 0 . 264 0 . 851 0 . 000 12 . 573 - 0 . 212 - 69 . 684 0 . 0000 * * * new _ bigram _ bin 0 . 517 0 . 500 0 . 000 1 . 000 0 . 385 0 . 487 0 . 000 1 . 000 - 0 . 267 - 87 . 945 0 . 0000 * * * new _ bigram 0 . 528 0 . 585 0 . 000 3 . 871 0 . 357 0 . 496 0 . 000 3 . 258 - 0 . 314 - 103 . 436 0 . 0000 * * * new _ bigram _ reuse 1 . 619 1 . 967 0 . 000 12 . 850 0 . 905 1 . 408 0 . 000 10 . 680 - 0 . 417 - 137 . 269 0 . 0000 * * * new _ trigram _ bin 0 . 773 0 . 419 0 . 000 1 . 000 0 . 625 0 . 484 0 . 000 1 . 000 - 0 . 327 - 107 . 567 0 . 0000 * * * new _ trigram 1 . 016 0 . 707 0 . 000 4 . 143 0 . 720 0 . 661 0 . 000 3 . 434 - 0 . 434 - 142 . 630 0 . 0000 * * * new _ trigram _ reuse 2 . 318 1 . 715 0 . 000 12 . 255 1 . 487 1 . 435 0 . 000 10 . 340 - 0 . 526 - 172 . 972 0 . 0000 * * * new _ gram _ bin ( NG ) 0 . 831 0 . 375 0 . 000 1 . 000 0 . 704 0 . 456 0 . 000 1 . 000 - 0 . 304 - 99 . 852 0 . 0000 * * * new _ word _ comb _ bin ( NC ) 0 . 847 0 . 360 0 . 000 1 . 000 0 . 757 0 . 429 0 . 000 1 . 000 - 0 . 229 - 75 . 300 0 . 0000 * * * new _ word _ comb 2 . 701 1 . 668 0 . 000 9 . 318 2 . 116 1 . 621 0 . 000 8 . 868 - 0 . 356 - 116 . 955 0 . 0000 * * * new _ word _ comb _ reuse 5 . 001 2 . 869 0 . 000 16 . 468 3 . 549 2 . 637 0 . 000 17 . 423 - 0 . 527 - 173 . 373 0 . 0000 * * * cosine _ max 0 . 398 0 . 133 0 . 014 0 . 973 0 . 401 0 . 134 0 . 012 0 . 970 0 . 019 6 . 392 0 . 0000 * * * wang 0 . 209 0 . 569 0 . 000 7 . 190 0 . 070 0 . 288 0 . 000 7 . 203 - 0 . 308 - 101 . 303 0 . 0000 * * * uzzi 6 . 739 0 . 739 5 . 791 12 . 718 6 . 872 0 . 814 6 . 002 12 . 718 0 . 171 56 . 380 0 . 0000 * * * cd 0 . 052 0 . 202 - 0 . 905 1 . 000 - 0 . 048 0 . 268 - 0 . 836 0 . 990 - 0 . 422 - 138 . 843 0 . 0000 * * * Notes : n = 432 , 868 papers of which 216 , 434 top - cited papers ( above the 99 th percentile in terms of citations among papers from same journal and year ) and 216 , 434 matched control papers published between 1901 and 2010 . Each top - cited paper is matched to one randomly selected non - top - cited control paper published in the same year , journal , volume and issue . We only keep papers published in journals with at least 100 papers in the year of publication . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . Cohen ' s d is the mean difference between award and control papers divided by the pooled standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 Table A . 8 : Likelihood of Top Cited with ex - ante Metrics ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) ( 13 ) new _ word 0 . 368 * * * 0 . 075 * * * 0 . 081 * * * ( 0 . 011 ) ( 0 . 012 ) ( 0 . 012 ) new _ bigram 0 . 535 * * * 0 . 255 * * * 0 . 254 * * * ( 0 . 007 ) ( 0 . 008 ) ( 0 . 008 ) new _ trigram 0 . 739 * * * 0 . 613 * * * 0 . 601 * * * ( 0 . 006 ) ( 0 . 007 ) ( 0 . 007 ) new _ word _ comb 0 . 285 * * * 0 . 160 * * * 0 . 161 * * * ( 0 . 004 ) ( 0 . 004 ) ( 0 . 004 ) cosine _ max - 0 . 311 * * * - 0 . 630 * * * - 0 . 600 * * * ( 0 . 025 ) ( 0 . 026 ) ( 0 . 026 ) new _ gram _ bin ( NG ) 0 . 560 * * * ( 0 . 009 ) new _ word _ comb _ bin ( NC ) 0 . 238 * * * ( 0 . 011 ) wang 0 . 562 * * * 0 . 540 * * * 0 . 524 * * * ( 0 . 010 ) ( 0 . 010 ) ( 0 . 010 ) uzzi - 0 . 125 * * * - 0 . 092 * * * - 0 . 070 * * * ( 0 . 005 ) ( 0 . 005 ) ( 0 . 005 ) ll - 285576 - 285028 - 282510 - 278796 - 282191 - 285500 - 283779 - 285348 - 283650 - 285202 - 276411 - 283447 - 274571 pseudor2 0 . 0482 0 . 0500 0 . 0584 0 . 0708 0 . 0594 0 . 0484 0 . 0541 0 . 0489 0 . 0546 0 . 0494 0 . 0787 0 . 0553 0 . 0848 Precision ( % ) 59 . 70 60 . 12 61 . 45 62 . 47 61 . 14 59 . 73 60 . 01 59 . 68 60 . 82 59 . 74 63 . 41 60 . 80 64 . 38 Recall ( % ) 61 . 73 61 . 37 61 . 04 63 . 16 62 . 54 61 . 76 63 . 35 62 . 08 58 . 74 61 . 84 63 . 21 58 . 92 62 . 10 AUC 0 . 6435 0 . 6464 0 . 6588 0 . 6753 0 . 6605 0 . 6439 0 . 6523 0 . 6447 0 . 6489 0 . 6453 0 . 6849 0 . 6499 0 . 6906 Marginal Effects ( % ) 2 . 57 6 . 76 11 . 74 10 . 95 - 0 . 97 5 . 49 2 . 22 5 . 95 - 2 . 27 Notes : Logit regression , robust standard errors between brackets n = 432 , 868 papers of which 216 , 434 top - cited papers ( above the 99 th percentile in terms of citations among papers from same journal and year ) and 216 , 434 matched control papers published between 1901 and 2010 . Each top - cited paper is matched to one randomly selected non - top - cited control paper published in the same year , journal , volume and issue . We only keep papers published in journals with at least 100 papers in the year of publication . All measures except binary indicators and the metrics based on cosine similarity are log transformed after adding 1 for measures with 0 values . All models include publication year and field of study fixed effects , and additionally control for whether the paper has an abstract available , text length ( number of unigrams , bigrams and trigrams in the title and abstract of the paper ) , and the number of unique papers and journals cited by the focal paper . Auc is area under the ROC curve . Marginal effects are calculated as the % increase in the likelihood of being a top - cited paper associated with an increase in the metric with one standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 1 25 Table A . 9 : Descriptive Statistics Top Cited by Patents versus Control Papers Mean Stdev Min Max Mean Stdev Min Max Cohen ' s d t Pr ( | T | > | t | ) Top - cited papers by patents ( n = 385 , 525 ) Control papers by patents ( n = 385 , 525 ) new word _ bin 0 . 222 0 . 416 0 . 000 1 . 000 0 . 159 0 . 366 0 . 000 1 . 000 - 0 . 160 - 70 . 305 0 . 0000 * * * new _ word 0 . 185 0 . 368 0 . 000 3 . 258 0 . 129 0 . 312 0 . 000 2 . 996 - 0 . 164 - 71 . 831 0 . 0000 * * * new _ word _ reuse 0 . 630 1 . 426 0 . 000 13 . 751 0 . 379 1 . 034 0 . 000 13 . 061 - 0 . 201 - 88 . 405 0 . 0000 * * * new _ bigram _ bin 0 . 587 0 . 492 0 . 000 1 . 000 0 . 463 0 . 499 0 . 000 1 . 000 - 0 . 251 - 110 . 046 0 . 0000 * * * new _ bigram 0 . 617 0 . 600 0 . 000 4 . 007 0 . 449 0 . 542 0 . 000 3 . 638 - 0 . 293 - 128 . 742 0 . 0000 * * * new _ bigram _ reuse 1 . 786 1 . 950 0 . 000 13 . 560 1 . 162 1 . 577 0 . 000 11 . 791 - 0 . 352 - 154 . 435 0 . 0000 * * * new _ trigram _ bin 0 . 812 0 . 391 0 . 000 1 . 000 0 . 699 0 . 458 0 . 000 1 . 000 - 0 . 264 - 115 . 713 0 . 0000 * * * new _ trigram 1 . 095 0 . 695 0 . 000 3 . 871 0 . 855 0 . 685 0 . 000 3 . 850 - 0 . 349 - 153 . 103 0 . 0000 * * * new _ trigram _ reuse 2 . 409 1 . 641 0 . 000 12 . 255 1 . 782 1 . 508 0 . 000 11 . 446 - 0 . 398 - 174 . 740 0 . 0000 * * * new _ gram _ bin ( NG ) 0 . 874 0 . 332 0 . 000 1 . 000 0 . 777 0 . 416 0 . 000 1 . 000 - 0 . 257 - 113 . 006 0 . 0000 * * * new _ word _ comb _ bin ( NC ) 0 . 896 0 . 305 0 . 000 1 . 000 0 . 817 0 . 387 0 . 000 1 . 000 - 0 . 227 - 99 . 739 0 . 0000 * * * new _ word _ comb 3 . 013 1 . 574 0 . 000 9 . 322 2 . 479 1 . 642 0 . 000 9 . 251 - 0 . 332 - 145 . 823 0 . 0000 * * * new _ word _ comb _ reuse 5 . 407 2 . 648 0 . 000 17 . 182 4 . 203 2 . 684 0 . 000 17 . 311 - 0 . 452 - 198 . 329 0 . 0000 * * * cosine _ max 0 . 396 0 . 128 0 . 011 0 . 980 0 . 394 0 . 130 0 . 013 0 . 980 - 0 . 013 - 5 . 578 0 . 0000 * * * wang 0 . 159 0 . 484 0 . 000 7 . 302 0 . 095 0 . 353 0 . 000 9 . 632 - 0 . 152 - 66 . 599 0 . 0000 * * * uzzi 6 . 115 0 . 137 0 . 298 9 . 227 6 . 128 0 . 159 0 . 243 10 . 082 0 . 084 37 . 003 0 . 0000 * * * cd 0 . 011 0 . 107 - 1 . 000 0 . 999 0 . 001 0 . 077 - 1 . 000 0 . 991 - 0 . 101 - 44 . 201 0 . 0000 * * * Notes : n = 771 , 050 papers of which 385 , 525 top - cited papers ( above the 99th percentile in terms of patent citations among papers published in the same year ) and 385 , 525 matched control papers published between 1901 and 2010 . Each top - cited paper is matched to one randomly selected non - top - cited control paper published in the same year , journal , volume and issue . All measures except binary indicators , the metrics based on cosine similarity and cd are log transformed after adding 1 for measures with 0 values . Cohen ' s d is the mean difference between award and control patents divided by the pooled standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 10 Table A . 10 : Likelihood of Top Cited by Patents with ex - ante Metrics ( 1 ) ( 2 ) ( 3 ) ( 4 ) ( 5 ) ( 6 ) ( 8 ) ( 9 ) ( 10 ) ( 11 ) ( 12 ) ( 13 ) ( 14 ) new _ word 0 . 301 * * * 0 . 071 * * * 0 . 076 * * * ( 0 . 007 ) ( 0 . 008 ) ( 0 . 008 ) new _ bigram 0 . 400 * * * 0 . 191 * * * 0 . 193 * * * ( 0 . 005 ) ( 0 . 005 ) ( 0 . 005 ) new _ trigram 0 . 492 * * * 0 . 378 * * * 0 . 373 * * * ( 0 . 005 ) ( 0 . 005 ) ( 0 . 005 ) new _ word _ comb 0 . 266 * * * 0 . 174 * * * 0 . 179 * * * ( 0 . 003 ) ( 0 . 003 ) ( 0 . 003 ) cosine _ max - 0 . 106 * * * - 0 . 417 * * * - 0 . 451 * * * ( 0 . 020 ) ( 0 . 020 ) ( 0 . 020 ) new _ gram _ bin ( NG ) 0 . 422 * * * ( 0 . 008 ) new _ word _ comb _ bin ( NC ) 0 . 289 * * * ( 0 . 009 ) wang 0 . 273 * * * 0 . 262 * * * 0 . 272 * * * ( 0 . 007 ) ( 0 . 007 ) ( 0 . 007 ) uzzi - 0 . 487 * * * - 0 . 440 * * * - 0 . 483 * * * ( 0 . 019 ) ( 0 . 019 ) ( 0 . 019 ) ll - 512545 - 511671 - 509067 - 506955 - 507742 - 512530 - 511029 - 512062 - 511602 - 512124 - 503244 - 511259 - 501843 pseudor2 0 . 0409 0 . 0426 0 . 0474 0 . 0514 0 . 0499 0 . 0410 0 . 0438 0 . 0418 0 . 0427 0 . 0417 0 . 0583 0 . 0433 0 . 0609 Precision ( % ) 57 . 61 58 . 02 59 . 07 59 . 41 59 . 17 57 . 61 57 . 90 57 . 66 57 . 90 57 . 71 60 . 64 57 . 97 60 . 98 Recall ( % ) 65 . 81 64 . 94 63 . 22 64 . 45 65 . 16 65 . 80 67 . 20 66 . 41 64 . 81 65 . 97 64 . 02 65 . 02 63 . 88 AUC 0 . 6255 0 . 6293 0 . 6391 0 . 6461 0 . 6441 0 . 6256 0 . 6311 0 . 6273 0 . 6288 0 . 6273 0 . 6577 0 . 6302 0 . 6616 Marginal Effects ( % ) 2 . 43 5 . 41 8 . 03 10 . 11 - 0 . 32 3 . 77 2 . 39 2 . 74 - 1 . 71 Notes : Logit regression , robust standard errors between brackets . n = 771 , 050 papers of which 385 , 525 top - cited papers ( above the 99th percentile in terms of patent citations among papers published in the same year ) and 385 , 525 matched control papers published between 1901 and 2010 . Each top - cited paper is matched to one randomly selected non - top - cited control paper published in the same year , journal , volume and issue . All measures except binary indicators and the metrics based on cosine similarity are log transformed after adding 1 for measures with 0 values . All models include publication year and field of study fixed effects , and additionally control for whether the paper has an abstract available , text length ( number of unigrams , bigrams and trigrams in the title and abstract of the paper ) , and the number of unique papers and journals cited by the focal paper . Auc is area under the ROC curve . Marginal effects are calculated as the % increase in the likelihood of being a top - cited paper associated with an increase in the metric with one standard deviation . * * * p < 0 . 01 , * * p < 0 . 05 , * p < 0 . 1 26 B . Data collection and processing We collect all publications from the latest version of Microsoft Academic Graph ( MAG ) , dated 06 . 12 . 2021 via Azure Data Share ( Sinha et al . , 2015 ) . 5 MAG contains about 270 , 000 , 000 records including books , book chapters , conference proceedings , datasets , journal articles , papers , repositories , theses and preprints . We restrict the sample to journal publications and published conference proceedings ( 103 , 117 , 246 records ) , referred to as “publications” in the remainder of the paper . We remove 3 , 571 , 940 publications with duplicate titles , abstracts or Digital Object Identifiers ( DOI ) , 5 , 838 , 367 publications with non - English source 6 , 11 , 881 , 805 publications with a non - English title , 3 , 303 , 938 publications with a non - English abstract 7 , and 29 , 320 records of retracted publications . In addition , we face two significant issues concerning the publication date in MAG . First , for 16 , 267 , 071 publications which report the 1 st of January as date of publication , the exact day of publication may be unclear . Given that this is a significant share of the sample , we double check these publication dates with both CrossRef and Scopus using the DOI of the publication ( Martín - Martín et al . , 2021 ; Visser et al . , 2021 ) . 63 % of MAG records with 1st January as publication date have no DOI and cannot be matched to either CrossRef or Scopus . Among the matched records , 87 % also have the 1st of January as publication date in CrossRef or Scopus while the remaining 13 % have a different date . We keep the 1 st of January as date of publication in case of agreement between MAG and CrossRef or Scopus . In case of disagreement , we replace the publication date in MAG with the publication date in Scopus and / or CrossRef . In case of disagreement between Scopus and CrossRef , we use the publication date from CrossRef , which turned out to be more accurate after a manual inspection of a randomly selected sample of 100 papers . Finally , we remove the publications that exist only in MAG ( and not in CrossRef or Scopus ) with the indicative publication date as 1st January , due to the uncertainty in their publication date . The second issue with the recorded dates in MAG is that there is both an ‘online’ date and a publication in print date that are not necessarily the same . Publications are made available online on the publisher’s website before the date of the print issue or after the date of the print issue for older publications . We take the earliest date as the date of publication because this date is the closest to the scientific discovery . 5 Microsoft ( 2022 ) , Microsoft Academic Graph , URL : https : / / www . microsoft . com / en - us / research / project / microsoft - academic - graph / , last accessed 31 . 10 . 2022 6 For non - English sources , we use the language information about the URL , where the record is retrieved , available in MAG’s Table ‘Paper Urls’ from the official data schema . 7 We use fasttext , a language detection python package to determine the language of the record ( Joulin et al . , 2016 ) . 27 Next , we process the title and abstracts of these publications . For every publication , the abstract is only available as an inverted index in MAG , which we convert back to the original abstract 8 . Next , we concatenate title and abstract . Because there is only a title and no abstract available for 29 % of the publications , we illustrate in Appendix E the robustness of all metrics and findings in case we discard abstracts and exclusively rely on titles . Next , we process the text with the following steps : tokenization , lemmatization , stop word removal , chunking , baseline removal , and vectorization . First , we lowercase the text and tokenize it to words ( or unigrams ) 9 . Second , we apply lemmatization to each word using the WordNetLemmatizer from the NLTK library in Python so that we are left with a collection of lemmas representing the scientific content of the publication . Third , we remove : natural stop words 10 , a manually compiled list of 33 , 764 very common words unrelated to the scientific content of a publication 11 , words composed only by numbers , one character words and punctuations . The final list of removed stop words consists of 67 , 150 words . In addition , for each publication , we perform chunking by extracting bigrams ( two consecutive words ) and trigrams ( three consecutive words ) . For bigrams we keep the ones without any stop word and for trigrams we only keep those without any stop word or with a stop word in the middle of the trigram . Finally , we create a vector representation of the scientific content ( title and abstract not processed ) of every publication using SPECTER , a pre - trained document - level embedding of scientific documents that is pretrained on a Transformer language model tailored to scientific text . SPECTER is currently arguably the best performing document - level embedding of scientific papers and outperforms other embedding models such as doc2vec or SciBERT on different benchmark tasks . For every publication , we create a vector of 768 dimensions using Huggingface Transformers Library 12 and the instructions from the open source repository of the model ( Wolf et al . , 2019 ) . 13 8 Inverted indexes store information about each word in a body of text , i . e . they map the content of the body of text to their relative location . This includes the number of occurrences a word is found and its position of occurrence . 9 We use the following regular expression : [ a - z0 - 9 ] [ a - z0 - 9 - ] * [ a - z0 - 9 ] + | [ a - z0 - 9 ] to tokenize the text . 10 We remove all stop words which we define as : ( i ) numbers or words referring to numbers written in full ( i . e . one , two , etc . ) ; ( ii ) single character words ; ( iii ) natural stop words collected from the NLTK Python library ( 127 words ) , natural stop words collected from Gensim Python library ( 337 words ) , natural stop words collected from Spacy Python library ( 326 words ) ( Srinivasa - Desikan , B . , 2018 ) ( iv ) words referring to days and months ( i . e . Monday , July , etc . ) ; and ( vi ) words referring to cities ( i . e . New York , London , etc . ) , countries ( i . e . USA , Europe , etc . ) , first names ( i . e . John , Marie , etc . ) and institutions ( i . e . Nasa , Yale , etc . ) retrieved from Wikidata ( 8 , 570 words ) . 11 We compile a list with the most frequently occurring words in publications . Using an iterative approach where three people independently review this list , we identify and exclude ( i ) non - scientific keywords unrelated to the scientific content of papers ( e . g . , abstract , university , journal , publication ) ; and ( ii ) mistakenly combined words resulting from the tokenization process ( e . g . , improvementthat , includeoper ) . We maintain the frequently occurring keywords related to the scientific content of the publication ( e . g . , patient , chemical , virus ) . 12 https : / / huggingface . co / allenai / specter 13 https : / / github . com / allenai / specter 28 In the remainder of the paper , we use all publications published between 1880 and 1900 to construct a baseline dictionary and restrict the analysis to papers published between 1901 and 2020 ( n = 72 , 245 , 396 ) . The entire cleaned vocabulary contains 20 , 953 , 136 unique unigrams ( keywords ) , 114 , 939 , 991 unique bigrams , and 341 , 735 , 389 unique trigrams . The average and median number of unique keywords per publication is 33 and 32 , the average and median number of unique bigrams per publication is 15 and 13 , and the average and median number of unique trigrams per publication is 14 and 11 . C . Citations to Papers Introducing New Scientific ideas We randomly sample 10 , 000 new keywords that are reused at least 10 times by subsequent papers and identify the 1 , 903 , 819 papers reusing these new keywords . We match each of the 1 , 903 , 819 reusing papers to one randomly selected paper that does not reuse the specific new keyword but is published in the same journal , year , volume and issue as the paper that reuses the keyword . In case the journal issue is not available , we match on journal , year and volume . In case the journal volume is not available , we match on journal and year . Papers reusing new keywords are approximately 53 times more likely to cite the paper which introduced the keyword for the first time compared to a matched control group of papers from the same journal , year , volume and issue that do not reuse the new keyword ( 0 . 954 % versus 0 . 018 % ) . In parallel , we randomly sample 10 , 000 new keyword combinations that are reused at least 10 times by subsequent papers and identify the 1 , 260 , 854 papers reusing these new keyword combinations . We match each of the 1 , 260 , 854 reusing papers to one randomly selected paper that does not reuse the specific new keyword combination but is published in the same journal , year , volume and issue as the paper that reuses the keyword combination . In case the journal issue is not available , we match on journal , year and volume . In case the journal volume is not available , we match on journal and year . We find that papers reusing new keyword combinations are approximately 20 times more likely ( 0 . 386 % versus 0 . 019 % ) to cite the paper pioneering the new keyword combination relative to their matched control group . Among the papers reusing new keywords in the first 5 , 20 , or 50 years after publication , respectively 18 . 0 % , 6 . 7 % , and 2 . 0 % cite the paper pioneering the new keyword . In parallel , among papers reusing new keyword combinations within the first 5 , 20 , or 50 years after publication , respectively 6 . 6 % , 2 . 8 % , and 0 . 9 % cite the paper pioneering the new keyword combinations . 29 D . Literature Review Papers As a second validation , we collect a large sample of literature review papers and a matched control sample of original non - review papers . Our assumption is that review papers typically summarize prior scientific findings rather than pioneering new scientific insights themselves . Thus , we assume review papers are less likely to introduce new scientific ideas relative to the matched control papers ( Wu et al . , 2019 ) . Or put differently , we assume control papers are more likely to pioneer new scientific insights compared to review papers . Nevertheless , the large majority of all scientific papers are perhaps not very original or novel and only cover a small incremental advance over the pre - existing body of scientific knowledge ( e . g . Uzzi et al . , 2013 ; Wang et al . , 2017 ) . Therefore , in contrast to the Nobel prize papers that arguably cover very original and novel scientific ideas , we expect the average control paper in our sample to score relatively low on novelty . As such , it is arguably more difficult for the metrics to distinguish review papers from control papers compared to distinguishing Nobel prize papers from control papers . This makes review papers a less convincing validation test . Moreover , in contrast to Nobel prize papers , the average control paper in our sample is particularly unlikely to introduce new scientific ideas with a major impact . As such , we will focus the validation on the different ex ante metrics capturing novelty at the time of publication . Besides the different drawbacks compared to the Nobel prize validation , the advantage is that we can collect a large sample of review papers across all fields of study and not exclusively focus on a small sample of Nobel prize papers that likely cover very original new scientific insights conditional on having a huge impact on later work . Data We identify all scientific papers in history which have both the keywords “literature” and “review“ somewhere in their title . Next , we use the same case - control study design as for Nobel prize papers and match each review paper to one control paper , i . e . a regular paper that does not mention the keyword “literature” nor “review” in its title or abstract , but is published in the same year , journal , volume and issue as the literature review paper 14 . In case of multiple matching control papers , we randomly sample one . Matching on journal , year , volume and issue controls for differences across scientific fields and time . Because certain journals exclusively publish review papers , we also exclude papers ( both review and matched control papers ) published in journals that mention “literature” or “review” in the journal name ( e . g . 14 In case the journal issue of the literature review paper is not available , we match on journal , year and volume . In case the journal volume of the review paper is not available , we match on journal and year . 30 Journal of Economic Literature ) . Given our research design , eliminating false negative review papers is more desirable than covering the entire population of review papers . Finally , we test the ability of all metrics to correctly distinguish review papers from control papers . Our sample includes 49 , 523 review papers published between 1901 and 2010 and 49 , 523 matched control papers . Results Table A . 3 shows descriptive statistics for the review versus control papers . All text metrics indicate that review papers have a significantly lower novelty than control papers with a t - test significant at p = 0 . 000 . By contrast , review papers are more novel according to the traditional measures capturing novelty at the time of publication based on paper citations ( wang and uzzi ) . This is likely driven by the fact that review papers cover a broader and more interdisciplinary set of references to prior papers resulting in more novel and atypical combinations of cited journals and thus a significantly higher novelty score according to wang and uzzi . It is precisely for this reason that review papers are typically not included when analyzing novelty using uzzi or wang ( e . g . Wang et al . , 2017 ) . As predicted , Cohen’s d is much lower compared to the Nobel prize validation illustrating that the difference in novelty between review papers and matched control papers is significantly smaller compared to the difference between Nobel prize papers and matched control papers . Nevertheless , in line with the Nobel prize validation , new _ word _ comb performs best in distinguishing review papers from matched control papers at the time of publication in terms of both t - statistic and Cohen’s d . Table A . 4 shows the result of logit regressions with a binary indicator for review paper as outcome . The findings from the regression analysis are largely in line with the descriptive statistics . All new text metrics indicate that review papers have a significantly lower novelty than control papers . However , as expected , the overall predictive power of the metrics to distinguish review papers from regular papers is lower than for Nobel prize papers , and the differences between the different metrics are very small . Similarly , the difference in performance between the models including text metrics and the baseline model are very small . In contrast to Nobel prize papers , cosine _ max becomes significant illustrating how literature review papers are indeed less novel . Nevertheless , in line with the validation for Nobel prize papers , new _ word _ comb again seems to perform best overall with a precision of 65 . 87 % , a recall of 69 . 38 % , and AUC of 0 . 73 . A one standard deviation increase in new _ word _ comb decreases the likelihood of being a review paper with 8 . 77 % . 31 E . Text metrics exclusively based on titles Abstracts are not available for a significant fraction of papers in MAG . This might introduce bias in the text metrics and analyses . We tried to control for this bias by including in all regressions a binary indicator for whether an abstract is available . We also control for the text length of a paper ( number of unigrams , bigrams and trigrams ) as this might influence the probability of introducing a new ngram or word combination . As an additional robustness check , we recalculate all text metrics ( except the metric based on embeddings , i . e . cosine _ max ) for the full population of MAG papers by using exclusively the title of a paper , which is available for all papers in our sample . We use the new text metrics based on titles to replicate the Nobel prize validation 15 . Tables A . 5 and A . 6 display the descriptive statistics and regressions . Our main findings do not change . Not surprisingly , the overall predictive power of the text metrics exclusively based on titles is lower illustrating that paper abstracts contain additional useful information to identify new scientific ideas and the impact of those ideas on later work . F . Top - cited papers We test in this section whether papers introducing new scientific ideas are indeed more likely to become highly cited by subsequent papers and patents . To this end , we collect a large sample of highly cited papers and matched control papers that are not highly cited . 16 Data First , we calculate for every paper in MAG the total number of citations received from later papers until 2021 . Next , we identify top - cited papers as papers that received more citations than the 99 th percentile of papers published in the same journal and year . To avoid bias , we exclude papers published after 2010 and papers from journals with less than 100 papers published in a given year . We follow the same case - control study design as for Nobel prize papers and randomly sample for every top - cited paper one non - top - cited control paper 15 We find similar results for the validation based on literature review papers and for the top cited papers . Results not shown but available from the authors . 16 Given the very large number of publications in our sample and the small likelihood to become a top cited paper , we sample all top cited papers and a matched control group of non - top cited papers and use logit models to predict the likelihood of being a top cited paper . We find similar results using linear probability models to predict the likelihood to become top cited using the entire sample of publications , i . e . by including all non - top cited papers . 32 published in the same year , journal , volume and issue 17 . Matching on journal , year , volume and issue controls for differences across scientific fields and time . The final sample includes 216 , 434 top - cited papers and 216 , 434 matched control papers . Second , we calculate for every paper in MAG the total number of citations received from patents until 2021 using data from Marx & Fuegi ( 2020 ) . We identify papers top cited by patents as papers that received more citations than the 99 th percentile of papers published in the same year . Due to the limited frequency of citations from patents , we opt to compare papers with all papers from the same year , rather than restricting the comparison to papers within the same journal and year . To avoid bias , we exclude papers published after 2010 . Each paper top cited by patents is matched to one randomly selected non - top - cited control paper published in the same year , journal , volume and issue . The final sample includes 385 , 525 top - cited papers and 385 , 525 matched control papers . Results Tables A . 7 and A . 8 show descriptive statistics and regressions for papers top cited by later papers versus control papers . With the exception of cosine _ max , all ex ante novelty measures are significantly higher for top - cited papers compared to matched control papers ( i . e . t - test significant at p = 0 . 000 ) . Given that top - cited papers are arguably more likely to introduce new scientific ideas with a major impact on later scientific publications , it is reassuring that the text metrics accounting for the impact of new scientific ideas as measured by their reuse in future papers outperform the ( text ) metrics capturing novelty at the time of publications in terms of t - statistic and Cohen’s d . As illustrated in Table A . 8 , papers introducing new scientific ideas at the time of publication are indeed more likely to eventually become a top - cited paper . Moreover , most text metrics capturing novelty at the time of publication ( i . e . new _ bigram , new _ trigram , new _ word _ comb ) better predict the likelihood of becoming a top - cited paper compared to the traditional novelty metrics based on citations ( i . e . uzzi and wang ) . In parallel , Tables A . 9 and A . 10 show descriptive statistics and regressions for papers top cited by patents versus control papers . The results are in line with the results for top cited by papers . As shown in Table A . 10 , papers introducing new scientific ideas at the time of publication are indeed more likely to extensively serve as prior for technological progress as captured by patent citations . Moreover , all text metrics capturing novelty at the time of 17 In case the journal issue of the top cited paper is not available , we match on journal , year and volume . In case the journal volume of the top cited paper is not available , we match on journal and year . 33 publication ( except cosine _ max ) better predict the likelihood of becoming a top - cited paper in patents compared to the traditional novelty metrics based on citations ( i . e . uzzi and wang ) . G . Limitations of Text Metrics and Suggestions for Future work First and foremost , unlike citations , text data is unstructured and messy and especially for older papers the title and abstract are sometimes recovered through optical character recognition ( OCR ) which might introduce mistakes and bias . Given that we rely on Microsoft Academic Graph , our metrics and findings are greatly affected by the quality of this source data . We invite others to replicate our metrics and findings on other ( perhaps better curated ) publication databases such as the Web of Science or Scopus . Yet , the key disadvantage of alternative databases is that they typically do not provide open access . Second , although lemmatization accounts for different spellings of the same word , it does not correct all spelling errors and does not account for synonyms ( different words with the same meaning ) and homonyms ( same word with different meanings ) . The use of paper - level embeddings does account for synonyms , homonyms , and the order and context of words in the text of publications , but the metric that we developed in this paper based on embeddings did not perform well to identify novelty . This maybe came as a surprise given that we used SPECTER , currently perhaps the best performing document - level embedding of scientific papers . This metric is arguably better suited to measure the similarity between publication documents than to identify new scientific ideas ( Beltagy et al . , 2019 ; Cohan et al . , 2020 ; Erhardt et al . , 2022 ) . Another limitation is that new scientific ideas and concepts might get a certain label only after the pioneering paper is published , or the pioneering paper might simply not use this label , or not use it in its title or abstract . In such cases , we might not identify the first paper pioneer a new scientific idea or concept and wrongly assign the new idea to a related paper published after the pioneering paper . In addition , because of open access data restrictions , we unfortunately could only use the titles and abstracts of scientific publications while other sections − introduction , conclusion , description of contribution relative to prior papers – most likely contain additional relevant information to identify the creation and impact of new scientific ideas . Besides limitations related to the use of text , another restriction is related to the sample of publications included in our sample . Ideally , every scientific publication in history should be included in the analysis in order to trace the scientific frontier over time and assign 34 a new scientific insight to the right paper . We relied on Microsoft Academic Graph , which is arguable the largest database of scientific publications going back in history and has the major advantage of including titles and abstracts of all publications and being open access which is not the case for other publication databases such as the Web of Science or Scopus . This allows us to openly share the text metrics that we developed . Although Microsoft Academic Graph does not provide any new updates after December 2021 , OpenAlex took over its role and the MAG paper identifiers are compatible with the paper identifiers in OpenAlex . That being said , MAG arguably does not include every single paper published in history and might be more messy and less reliable than other publication databases . In particular , an important limitation is that we were unable to use a significant number of publications because we could not recover the full publication date . We advise future users to further clean measurement errors , experiment with different alternative metrics , to control for whether the paper has an abstract available , to control for the text length of a paper , and to control for differences across different fields of study and over time . A fruitful opportunity for follow on research is to more carefully disentangle the text of publications and leverage more advanced NLP tools . This could involve employing part - of - speech ( POS ) tagging , Named Entity Recognition ( NER ) or phrase mining techniques , to discern the most coherent and contextually relevant phrases from the content of a publication . Such an approach could facilitate a deeper understanding of the construct of an new scientific idea and could help in operationalizing it more effectively . Specifically , POS - tagging can help to refine ngrams or word combinations which might contain verbs , adjectives , or adverbs , patterns that may be considered as noise or spurious signals of a new scientific idea . NER can help to differentiate the words , bigrams and trigrams and categorize them for instance into research questions , methods , data , findings , and scientific contributions . This would allow a more detailed and comprehensive identification of the specific types of new scientific insights or novel contributions of each paper and offer richer data to study different aspects of scientific progress ( Luo et al . , 2022 ; Cheng et al . , 2023 ; Leahey et al . , 2023 ; Shi & Evans , 2023 ) . References Beltagy , I . , Lo , K . , & Cohan , A . ( 2019 ) . SciBERT : A Pretrained Language Model for Scientific Text . In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ( EMNLP - IJCNLP ) ( pp . 3615 - 3620 ) . 35 Erhardt , S . , Ghosh , M . , Buunk , E . , Rose , M . E . , & Harhoff , D . ( 2022 ) . Logic Mill - A Knowledge Navigation System . ArXiv , abs / 2301 . 00200 . Marx , M . , & Fuegi , A . ( 2020 ) . Reliance on science : Worldwide front‐page patent citations to scientific articles . Strategic Management Journal , 41 ( 9 ) , 1572 - 1594 . Joulin , A . , Grave , E . , Bojanowski , P . , Douze , M . , Jégou , H . , & Mikolov , T . ( 2016 ) . Fasttext . zip : Compressing text classification models . arXiv preprint arXiv : 1612 . 03651 . Leahey , E . , Lee , J . , & Funk , R . J . ( 2023 ) . What types of novelty are most disruptive ? . American Sociological Review , 88 ( 3 ) , 562 - 597 . Luo , Z . , Lu , W . , He , J . , & Wang , Y . ( 2022 ) . Combination of research questions and methods : A new measurement of scientific novelty . Journal of Informetrics , 16 ( 2 ) , 101282 . Martín - Martín , A . , Thelwall , M . , Orduna - Malea , E . , & Delgado López - Cózar , E . ( 2021 ) . Google Scholar , Microsoft Academic , Scopus , Dimensions , Web of Science , and OpenCitations’ COCI : a multidisciplinary comparison of coverage via citations . Scientometrics , 126 ( 1 ) , 871 - 906 . Shi , F . , & Evans , J . ( 2023 ) . Surprising combinations of research contents and contexts are related to impact and emerge with scientific outsiders from distant disciplines . Nature Communications , 14 ( 1 ) , 1641 . Sinha , A . , Shen , Z . , Song , Y . , Ma , H . , Eide , D . , Hsu , B . J . , & Wang , K . ( 2015 ) . An overview of Microsoft academic service ( mas ) and applications . In Proceedings of the 24th international conference on world wide web , 243 – 246 . Srinivasa - Desikan , B . ( 2018 ) . Natural Language Processing and Computational Linguistics : A practical guide to text analysis with Python , Gensim , spaCy , and Keras . Packt Publishing Ltd . Visser , M . , van Eck , N . J . , & Waltman , L . ( 2021 ) . Large - scale comparison of bibliographic data sources : Scopus , web of science , dimensions , crossref , and microsoft academic . Quantitative Science Studies , 2 ( 1 ) , 20 – 41 . Wolf , T . , Debut , L . , Sanh , V . , Chaumond , J . , Delangue , C . , Moi , A . , Cistac , P . , Rault , T . , Louf , R . , Funtowicz , M . , et al . ( 2019 ) . Huggingface’s transformers : State - of - the - art natural language processing . arXiv preprint arXiv : 1910 . 03771 .