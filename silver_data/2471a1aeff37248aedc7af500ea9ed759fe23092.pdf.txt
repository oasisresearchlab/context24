I . I NTRODUCTION There is a growing need within engineering education to un - derstand more completely how students learn and how to effec - tively teach them . While cognitive gains are an important outcome of engineering education , students need to have both the will and the skill to succeed ( Pintrich and De Groot , 1990 ) . An evaluation of changes to both will and cognition is needed to understand how student learning can be facilitated or hindered in engineering edu - cation . This paper addresses the need to analyze will through the devel - opment and validation of an instrument measuring task - specific self - concepts . A task - specific self - concept is any variable concern - ing the understanding an individual has of him or herself for a given task . Understanding of self is what leads to the desire , or lack there of , to perform a given task . Four task - specific self - concepts were investigated—self - efficacy , motivation , outcome expectancy , and anxiety—with self - efficacy as the central focus . Self - efficacy refers to an individuals’ judgment of their capability to organize and execute courses of action for a given task ( Bandura , 1986 ; 1997 ) . According to self - efficacy theory , the level of self - efficacy for a given task is influenced by other task - specific self - concepts including motivation , outcome expectancy , and anxiety or self - doubt toward the task ( Pintrich and Schunk , 2002 ) . For the domain of engineering , the effect of self - efficacy on learning can be more pronounced because of the frequent uses of design tasks as part of an engineering learning experience . Engi - neering design tasks in this study refer to the applied or practical component of engineering , which consists of several processes used in devising a system , a component , or a protocol to meet an identified need . The importance of design tasks as part of engi - neering education relates directly to preparing students for in - dustrial demands ( Auyang , 2004 ; Duderstadt , 2008 ; Grinter , 1994 ; Society for the Promotion of Engineering Education , 1930 ) . While some engineering fields do not necessarily de - mand hands - on design task ability , the use of design tasks , and hence engineering design knowledge , is recommend by ABET ( the U . S . accreditation body for computing , engineering , and technology ) . The engineering design self - efficacy instrument development and validation were guided by three research questions : 1 . How well do the items in the instrument represent the en - gineering design task in eliciting the task - specific self - concepts of self - efficacy , motivation , outcome expectancy , and anxiety ? 2 . How well does the instrument predict differences in the self - efficacy held by individuals with a range of engineering experiences ? Measuring Engineering Design Self - Efficacy A DAM R . C ARBERRY AND H EE - S UN L EE Tufts University M ATTHEW W . O HLAND Purdue University B ACKGROUND Self - concept can influence how an individual learns , but is often overlooked when assessing student learning in engineering . P URPOSE ( H YPOTHESIS ) To validate an instrument designed to measure individuals’ self - concepts toward engineering design tasks , three research questions were investigated : ( a ) how well the items in the instrument represent the engineering design process in eliciting the task - specific self - concepts of self - efficacy , motivation , outcome expectancy , and anxiety , ( b ) how well the instrument predicts differ - ences in the self - efficacy held by individuals with a range of engineering experiences , and ( c ) how well the responses to the instrument align with the relationships conceptualized in self - efficacy theory . D ESIGN / M ETHOD A 36 - item online instrument was developed and administered to 202 respon - dents . Three types of validity evidence were obtained for ( a ) representativeness of multi - step engineering design processes in eliciting self - efficacy , ( b ) the instrument’s ability to differentiate groups of individuals with different levels of engineering experience , and ( c ) relationships between self - efficacy , motivation , outcome expectancy , and anxiety as predicted by self - efficacy theory . R ESULTS Results indicate that the instrument can reliably identify individuals’ engineering design self - efficacy ( (cid:2) (cid:3) 0 . 967 ) , motivation ( (cid:2) (cid:3) 0 . 955 ) , outcome expectancy ( (cid:2) (cid:3) 0 . 967 ) , and anxiety ( (cid:2) (cid:3) 0 . 940 ) . One - way ANOVA identified statistical differences in self - efficacy between high , intermediate , and low experience groups at the (cid:4) (cid:5) 0 . 05 level . Self - efficacy was also shown to be correlated to motivation ( 0 . 779 ) , outcome expectancy ( 0 . 919 ) , and anxiety ( (cid:6) 0 . 593 ) at the (cid:4) (cid:5) 0 . 01 level . C ONCLUSIONS The study showed that the instrument was capable of identifying individuals’ self - concepts specific to the engineering design tasks . K EYWORDS assessment , engineering design , self - efficacy January 2010 Journal of Engineering Education 71 3 . How well are responses to the instrument aligned with the relationships among the task - specific self - concepts as con - ceptualized in self - efficacy theory ? In the following sections , we will describe how each research ques - tion was addressed through the development and validation of the engineering design self - efficacy instrument . We first define three sources of validity evidence and connect them to previous research conducted on task - specific self - efficacy related to engineering . We then describe each source of validity to formulate each research question , describe participants based on their engineering experi - ence , and construct a theoretical framework . Finally , we present re - sults regarding each research question and discuss limitations and potential future uses of the instrument . II . S OURCESOF V ALIDITY E VIDENCE Validation is an evaluation of how adequately an instrument measures what it is intended to measure so that inferences and ac - tions resulting from the data on the instrument can be justified ( Messick , 1989 ; Moskal , Leydens , and Pavelich , 2002 ) . The devel - opment of the engineering design self - efficacy instrument was guided by three sources of validity evidence recommended by the measurement community ( American Educational Research Associ - ation , American Psychological Association , and National Council on Measurement in Education , 1999 ) : content , criterion , and con - struct validity . A . Content Validity Content validity concerns the extent to which a measurement adequately samples a specific domain represented in an instrument ( Carminer and Zeller , 1979 ; Messick , 1989 ; Moskal , Leydens , and Pavelich , 2002 ) . Content validity can be difficult to obtain because prediction of ability , attitudinal , and affective variables cannot be directly observed ( Wilson , 2005 ) . This makes adequate sampling of the intended domain difficult . Two examples of content validity regarding engineering - related self - efficacy were found in the litera - ture . Baker , Krause , and Purzer ( 2008 ) constructed two scales to represent expert views and options of two open - ended questions about tinkering and technical skills . Using the responses of these questions , they were able to develop tinkering and technical self - efficacy scales . Quade ( 2003 ) reviewed literature , interviews of com - puter science graduates , and analysis of the skill set required for an introductory computer science course to represent the computer science domain . Using these sources of content , she was able to develop a computer science self - efficacy scale for first - year computer science majors . Both instruments used content validity as a way to validate the appropriateness of items used in the instrument to represent specific domains . In this study , content validity is used to show how well the developed items adequately represent the engineering design domain in eliciting task - specific self - concepts . B . Criterion - Related Validity Criterion - related validity concerns the ability of an instrument to predict an externally related criterion ( Carminer and Zeller , 1979 ; Messick , 1989 ; Moskal , Leydens , and Pavelich , 2002 ) . The use of criterion - related validity is mainly to correlate scores obtained from an instrument with a current or future event defined as a rele - vant criterion . Identifying a relevant criterion to the latent or hidden variable an instrument attempts to measure is challenging . One self - efficacy study that employed criterion - related validity was Quade’s ( 2003 ) computer science self - efficacy study . The selected criterion was whether students passed the introductory computer science course . The assumption was that students with high com - puter science self - efficacy coming into the class were more likely to pass the course than those who came into the course with low computer science self - efficacy . Using this criterion , Quade ( 2003 ) validated the computer science self - efficacy instrument . In this study , the external relevant criterion for engineering design self - efficacy is an individuals’ experience in engineering . Engineering experience was chosen as a relevant criterion based on self - efficacy theory described in the next section . C . Construct Validity Construct validity concerns how well an instrument is designed to measure theoretically identified relationships between latent variables ( Carminer and Zeller , 1979 ; Messick , 1989 ; Moskal , Leydens , and Pavelich , 2002 ) . Common use of construct validity is to counteract a situation lacking a clear domain or an adequate criterion ( Cronbach and Meehl , 1955 ) . For example , many self - efficacy studies base their entire validation evidence on Bandura’s four sources of self - efficacy . According to Bandura’s Self - Efficacy Theory ( 1986 ; 1997 ) , self - efficacy is shaped by 1 ) performance accomplishments or mastery experiences , 2 ) vicarious experiences , 3 ) verbal or social persuasions , and 4 ) physiological states . These four sources affect individuals’ perfor - mance by mediating the goals they set for themselves , the amount of effort they expend , their persistence , and resilience to failures ( Bandura , 1994 ) . Two such studies employing construct validity in this fashion include Richardson ( 2008 ) and Hutchinson , Follman , and Bodner ( 2006 ) . Richardson ( 2008 ) conducted a study on tinker - ing self - efficacy , which framed two self - report instruments within Bandura’s sources of self - efficacy . Hutchinson and her colleagues ( 2006 ) used Bandura’s sources of self - efficacy to develop an instru - ment to analyze factors influencing the self - efficacy beliefs of first - year engineering students in terms of overall academic efficacy and engineering milestone efficacy . Both instruments used Bandura’s self - efficacy theory to analyze the extent to which their instrument was connected appropriately to the theory . Construct validity can be investigated for how it is linked to other sources of validity evidence . For example , Quade’s ( 2003 ) computer science self - efficacy study used construct validity in con - junction with content and criterion - related validity . In her study , a panel of experts analyzed how each item is related to Bandura’s sources of self - efficacy . For this study , a similar approach was taken ; however , unlike the other three construct validated studies de - scribed , this study uses self - efficacy theory as a basis for establishing relationships among four task - specific self - concepts—self - efficacy , motivation , outcome expectancy , and anxiety . Self - efficacy is often connected to outcome expectancy and causal attribution . Outcome expectancy is an individual’s beliefs about the contingency between behavior and an anticipated out - come ( Pintrich and Schunk , 1996 ) . According to expectancy - value theory , expectation for success combined with actual successes raises an individual’s desire to perform a given activity ( Atkinson , 1957 ; Atkinson and Feather , 1966 ; Atkinson and Raynor , 1974 ) , resulting in increased self - efficacy . Contemporary versions of expectancy - value theory further separate expectancy and value into differing motives for achievement . Eccles and Wigfield ( Eccles , 1983 ; 1993 ; 72 Journal of Engineering Education January 2010 Wigfield , 1994 ; Wigfield and Eccles , 2000 ) characterize expectancy as whether one can accomplish the task ( expectancy for success ) , while value deciphers why such a task should be undertaken based on attainment value ( importance of doing the task well for oneself ) , intrinsic value ( interest and enjoyment in performing the task ) , util - ity value ( perceived usefulness of the task toward future goals ) , and cost belief ( perceived negatives of doing the task toward what could have been done instead ) ( Pintrich and Schunk , 2002 ) . Self - efficacy affects both expectancy and value by influencing what endeavors are undertaken in accordance with perceived capability and expectancy for success . Therefore , the possibility exists for an individual to have high efficacy beliefs , but low outcome expectations . Fear of failure ( anxiety ) and actual failures are the typical causes of low levels of self - efficacy . Self - efficacy beliefs also influence causal attributions toward success and failure . Self - efficacy contributes to the relationship between attributions and motivation , which influences subsequent performance expectancies ( Bandura , 1995 ; Schunk , 1991 , 1994 ; Weiner , 1986 ) . Judgments based on past successes and failures af - fect whether that experience warrants future engagement ( Vogt , 2003 ) . An individual’s self - efficacy relates to the underlying reasons for why success or failure resulted in a subsequent effort level . For instance , success due to luck rarely leads to a belief that warrants future similar actions . People who regard themselves as having high self - efficacy attribute their failures to insufficient effort . Those who regard themselves as having low self - efficacy attribute their failures to low ability ( Pintrich and Schunk , 1996 ) . In sum , these three sources of validity evidence together can strengthen the quality of the engineering design self - efficacy instru - ment . These validation considerations can provide a full analysis of the instrument in terms of representativeness of the domain of interest , connection to criterion regarding engineering experience , and theoretical relationships . III . R ESEARCH M ETHODS A . Instrument Design A 36 - item online instrument was developed and tested for con - tent , construct , and criterion validity . Content validity concerns the representation of the engineering design process . The engineering design process is the activity that governs all engineering design . Within the process are important steps for efficient and effective engineering design ; however , there is no consensus on what exactly constitutes the engineering design process . Similarity across various models exists in that the engineering design process is not simply sequential , but rather an iterative process that loops ( Ball and Ormerod , 1995 ; Ennis and Gyeszly , 1991 ) . Specific terms for steps , the order of the steps , and the available pathways through the models vary from one model to another . For this study , the model referenced is an eight - step process proposed in the Massachusetts Department of Education ( DoE ) Science and Technology / Engineering Curriculum Framework ( Figure 1 ) ( Massachusetts DoE , 2001 / 2006 ) . Massachusetts was the first state to officially integrate engineering content into their state standards . Such standards have been and continue to be very influential in affecting many levels of education throughout the United States . The Massachusetts Department of Education model was developed with substantial expertise from several groups , including the Massachusetts Technology Education / Engineering Collaborative ( MassTEC ) , the Technology Education Association of Massachusetts Inc . ( TEAM ) , and professional engineers , uni - versity faculty , and Massachusetts’ practitioners ( led by Ioannis Miaoulis , President and Director of Museum of Science , Boston ) . The steps provided in the model are aligned with others , providing conceptual ( though not semantic ) equivalence across expert opinion as to what comprises the engineering design process . This model was used to develop items to represent the engi - neering design task . The model conceptually aligns with other rec - ognized models differing only based on the exact words or phrases used and the way in which the looping nature is depicted or drawn ( note : the sequential or cyclic nature of the model is not addressed in the methods and analysis chosen for the study ) . Using the chosen model , a nine - item scale was developed for each task - specific self - concept . The first item reports the respondent’s self - conception toward conducting engineering design ( item one of Figure 2 ) . This item represents a respondent’s engineering design ( ED ) score . The remaining eight items represent each step ( subdimensions ) of the chosen engineering design process— identify a design need , research a design need , develop design solutions , select the best possible design , construct a prototype , test and evaluate a design , communicate a design , and redesign ( items two through nine of Figure 2 ) . Exclusion of any one subdimension would cause the instrument to fail on fully rep - resenting the engineering design domain as defined by our chosen engineering design process . An average of these eight items repre - sents a respondent’s engineering design process ( EDP ) score . Overall , the nine items regarding engineering design and each step of the engineering design process ensure that the engineering de - sign domain is fully represented . Criterion - related validity was addressed using respondent engineering experience . The assumption was made that individuals with more engineering experience are more likely to have higher engineering design self - efficacy than those with less engineering experience . Participants self - reported their engineering experi - ence by choosing one of the five categories provided : professor of engineering or engineering education , engineer , engineering student ( graduate ) , engineering student ( undergraduate ) , engineering education student , non - engineer with a science background , non - engi - neer without a science background . The evidence supports that the January 2010 Journal of Engineering Education 73 Figure 1 . The engineering design process ( Massachusetts DoE , 2001 / 2006 ) . instrument has criterion validity if individuals with varying de - grees of engineering experience can be differentiated as presumed . Construct validity was addressed by determining how the task - specific self - concepts relate to how the theory predicts . Hypothe - sized responses were developed for each group using the theoretical relationships of motivation , outcome expectancy , and anxiety drawn from self - efficacy and expectancy - value theory . The resulting instrument ( Appendix ) measured the four task - specific self - concepts , including self - efficacy ( measured as confi - dence ) ( Bandura , 1997 , p . 382 ) , on a scale consisting of nine Likert - type items scored on a 100 - point range with ten - unit intervals . A 0 to 100 response format was used because it is a stronger predic - tor of performance than a five - interval Likert scale ( Pajares , Hartley , and Valiante , 2001 ) based on an individual’s common un - derstanding of being typically scored in school on a 100 - point scale . Additional , demographic information pertaining to age , educa - tion , profession , and engineering experience was gathered to develop criteria for engineering experience . Gender information was not collected from the greater population to maintain engineering ex - perience as the guiding criterion ; however , gender’s known influ - ence on the self - efficacy of engineering students ( Besterfield - Sacre , Moreno , Shuman , and Atman , 2001 ; Felder et al . , 1995 ; Hackett et al . , 1992 ; Schaefers , Epperson , and Nauta , 1997 ; Schmidt et al . , 2001 ) made it a validity concern . Gender information was therefore gathered from a small subset of the population consisting of under - graduate and graduate engineering students ( N (cid:3) 64 ) in to investi - gate if items for task - specific self - concepts function differently be - tween male and female groups . B . Participants Three hundred and sixty - seven individuals responded to an e - mail soliciting them to test the engineering design self - efficacy instrument . One hundred and thirty - seven responses were excluded because the respondents did not complete the entire instrument . Twenty - eight responses were excluded because the respondents rated each item with the same score across a given task - specific self - concept ( although this could be their actual beliefs , the chance of the respondent trying to quickly complete the instrument warrants their removal ) . The remaining 202 respondents ranged in age from 21 – 62 years old ( M (cid:3) 26 . 69 (cid:7) 8 . 15 ) . The overall population of respondents consisted of individuals with diverse engineering experiences : 12 engineering or engineering education professors , 26 engineers , 7 engineering education graduate students , 28 engi - neering graduate students , 60 engineering undergraduate students , 32 non - engineers with science backgrounds and 37 non - engineers without science backgrounds . Variability in engineering expertise was deliberately sought within the sample to ensure variability in the engineering design self - efficacy groups as well as to identify the ex - tremes . Gender information was collected for only a subset ( N (cid:3) 64 ) of the student population . Among the subset of students who pro - vided gender information 26 ( 18 undergraduate and 8 graduate ) were female and 38 ( 25 undergraduate and 13 graduate ) were male . C . Data Collection and Analysis Data were collected using an online surveying tool . The survey took respondents an average of five minutes to complete . Individu - als were solicited to participate in the survey through e - mail listings available to the researchers . A subset of engineering students at a small private institution was later solicited to test the instrument specifically on its intended population and to conduct an analysis of gender influence on the survey responses . Results from the survey were then pooled for further analysis . The Statistical Package for the Social Sciences ( SPSS ) was used to calculate correlations and re - liability coefficients , conduct factor analysis , and analysis of variance ( ANOVA ) . Using the respondents’ self - reported engineering experience , each respondent was classified as having high , intermediate , or low task - specific self - efficacy . An individual who has high self - efficacy toward a task is confident about their abilities , is motivated by the task , seeks and expects success , and has little to no anxiety toward the task ; while an individual who has low self - efficacy toward a task has no confidence in their abilities , is unmotivated by the task , expects failure , and has a high level of anxiety toward the task ( Pintrich and Schunk , 1996 ) . Between the extremes are respondents who cannot be classified under either . These individuals who fall between the high and low self - efficacy were identified as having intermediate self - efficacy . An individual who has intermediate self - efficacy toward a task is moderately confident in his or her abilities , is motivated by 74 Journal of Engineering Education January 2010 Figure 2 . Generic scale used to represent the engineering design domain . the task , but unsure of the possibility of success , and has slight to moderate anxiety toward the task . IV . R ESULTS A . How Well do the Items in the Instrument Represent the Engineering Design Task in Eliciting the Task - Specific Self - Concepts of Self - Efficacy , Motivation , Outcome Expectancy , and Anxiety ? The representativeness of engineering design by the engineering design process steps was tested in three steps . The first step was to test the inter - item reliability among the eight individual engineer - ing design process steps—items two through nine of the self - efficacy , motivation , outcome expectancy , and anxiety scales—for each of the four task - specific self - concepts . Each set of items for a given task - specific self - concept was analyzed separately . The Cronbach’s (cid:2) values for self - efficacy ( 0 . 967 ) , motivation ( 0 . 955 ) , outcome expectancy ( 0 . 967 ) , and anxiety ( 0 . 940 ) showed a high reliability among the eight steps for a given task - specific self - concept . A sub - set of engineering students was additionally tested to ensure that the reliability of the instrument was not affected by a respondent’s gen - der . Relatively similar Cronbach’s (cid:2) values seen in Table 1 for females , males , and the overall subset ensure that gender does not affect the overall reliability of the instrument . These high reliability coefficients among the eight engineering design steps for the gen - der and non - gendered analysis show overall agreement of individuals across the eight steps for each of the four task - specific self - concepts . High inter - item reliabilities suggested that the observed items were capable of being reduced to fewer factors through factor analysis . Exploratory factor analysis was used to identify the number of factors present among the eight steps of the engineering design process for each of the four task - specific self - concepts ( items two through nine in Figure 2 for questions one through four in the Appendix ) . Factor analysis for each task - specific self - concept revealed one factor per task - specific self - concept determined using only factors with eigenvalues greater than one ( Rummel , 1970 ) . These factors were labeled the engineering design process ( EDP ) ( one per task - specific self - concept ) . An EDP factor score , therefore , refers to a calibrated average of the eight individual engineering design process steps ( items two through nine in Figure 2 ) for each separate task - specific self - concept . Additionally , confirmatory factor analysis was used for each individual step of the engineering design process across the four task - specific self - concepts ( for example , a respondent’s ‘identify a need’ score for each of the four task - specific self - concepts ) to ensure item consistency . Factor analysis of each individual step also revealed one factor per item determined using only factors with eigenvalues greater than one . Each factor was labeled using the identical name of the step— identify a design need , research a design need , develop design solutions , select the best possible design , construct a prototype , test and evaluate a design , communicate a design , and redesign . The final step was conducted to check the extent to which the new EDP factor scores for each of the four task - specific self - concepts represented overall engineering design ( ED ) . ED scores were obtained from the first item of the scale referring to conduct engineering design ( item one in Figure 2 for questions one through four in the Appendix ) . Pearson correlations for self - efficacy ( 0 . 890 ) , motivation ( 0 . 882 ) , outcome expectancy ( 0 . 888 ) , and anxiety ( 0 . 791 ) were all significantly correlated ( (cid:4) (cid:8) 0 . 01 ) suggesting that responses were consistent between ED scores and EDP factor scores . These results indicate that the engineering design process steps obtained from the Massachusetts Science and Technology / Engineering Curriculum Framework consistently and reliably represent engineering design in measuring all four task - specific self - concepts . The possibility exists for the instrument to be modified to ask respondents to rank their self - efficacy , motivation , outcome expectancy , and anxiety only toward engineering design . The use of the factored score across eight items to measure each task - specific self - concept is more beneficial in statistical analyses because of the increased variations among subjects . B . How Well does the Instrument Predict Differences in the Self - Efficacy Held by Individuals with a Range of Engineering Experience ? Engineering experience was tested as a criterion by hypothesiz - ing that individuals with high levels of engineering experience should have overall high levels of engineering design self - efficacy , while individuals with low levels of engineering experience should have low levels of engineering design self - efficacy . Participants were first grouped based on their engineering self - identifications . Each engineering self - identification was confirmed by matching each individual’s responses to questions about their undergradu - ate degree and current profession ( if applicable ) . Respondents were regrouped into the three levels of engineering design self - efficacy—high self - efficacy , intermediate self - efficacy , and low self - efficacy - based on their engineering experience . The following groups resulted : High Self - Efficacy ( N (cid:3) 73 ) —respondents with engineering degrees and firsthand engineering experience ( professors of engineering and engineering education , engineers , engineering and engineering education graduate students ) January 2010 Journal of Engineering Education 75 Table 1 . Gender - specific reliability analysis of the four task - specific self - concepts . Intermediate Self - Efficacy ( N (cid:3) 92 ) —current learners of engineering ( engineering undergraduate students and non - engineers with science backgrounds ) Low Self - Efficacy ( N (cid:3) 37 ) —non - engineers with little to no engineering experience ( non - engineers without a science background ) A one - way ANOVA was conducted to compare mean ED scores on self - efficacy , motivation , outcome expectancy , and anxiety toward engineering design for the three groups . There were statisti - cally significant effects on all four task - specific self - concepts at the (cid:4) (cid:5) 0 . 05 level for the three groups [ F self - efficacy ( 2 , 199 ) (cid:3) 79 . 16 , (cid:4) (cid:5) 0 . 001 ) ; F motivation ( 2 , 199 ) (cid:3) 71 . 73 , (cid:4) (cid:5) 0 . 001 ) ; F expectancy ( 2 , 199 ) (cid:3) 77 . 91 , (cid:4) (cid:5) 0 . 001 ) ; F anxiety ( 2 , 199 ) (cid:3) 8 . 76 , (cid:4) (cid:5) 0 . 001 ) ] . Post hoc comparisons using the Tukey HSD test indicate that the mean scores for self - efficacy , motivation , outcome expectancy , and anxiety ( Table 2 ) were significantly different ( (cid:4) (cid:8) 0 . 001 ) among all three groups with two exceptions : 1 ) the High Self - Efficacy and Inter - mediate Self - Efficacy groups were significant ( (cid:4) (cid:3) 0 . 042 ) for anx - iety and 2 ) the Intermediate Self - Efficacy and Low Self - Efficacy groups were not significant for anxiety ( (cid:4) (cid:3) 0 . 055 ) . A one - way ANOVA was also conducted to compare mean EDP scores for self - efficacy , motivation , outcome expectancy , and anxiety for the three groups . Again , statistically significant differ - ences existed for all four task - specific self - concepts at the (cid:4) (cid:5) 0 . 05 level among the three groups [ F self - efficacy ( 2 , 199 ) (cid:3) 63 . 84 , (cid:4) (cid:5) 0 . 001 ) ; F motivation ( 2 , 199 ) (cid:3) 51 . 13 , (cid:4) (cid:5) 0 . 001 ) ; F expectancy ( 2 , 199 ) (cid:3) 57 . 15 , (cid:4) (cid:5) 0 . 001 ) ; F anxiety ( 2 , 199 ) (cid:3) 11 . 47 , (cid:4) (cid:5) 0 . 001 ) ] . Post hoc comparisons using the Tukey HSD test indicated that the mean scores for self - efficacy , motivation , outcome expectancy , and anxiety ( Table 3 ) were significantly different ( (cid:4) (cid:8) 0 . 001 ) for all three groups with two exceptions : 1 ) the High Self - Efficacy and Interme - diate Self - Efficacy groups were significant ( (cid:4) (cid:3) 0 . 003 ) for anxiety and 2 ) the Intermediate Self - Efficacy and Low Self - Efficacy groups were not significant for anxiety ( (cid:4) (cid:3) 0 . 117 ) . Taken together , these criterion results suggest that self - efficacy , motivation , outcome expectancy , and anxiety toward engineering design match an individual’s level of engineering design self - efficacy . ED and EDP scores for self - efficacy , motivation , and expectancy displayed decreasing average scores as engineering experience decreases . Conversely , ED and EDP scores for anxiety increase as engineering experience decreases . C . How Well are Responses to the Instrument Aligned with the Relationships Among the Task - Specific Self - Concepts as Conceptualized in Self - Efficacy Theory ? Correlations between self - efficacy with motivation , outcome expectancy , and anxiety were calculated to investigate relationships among the four task - specific concepts . Motivation , expectancy , and anxiety were all significantly correlated ( (cid:4) (cid:8) 0 . 01 ) to self - efficacy con - firming theoretical predictions . Motivation ( 0 . 779 ) and outcome ex - pectancy ( 0 . 919 ) were positively correlated to self - efficacy . This does not imply that individuals with low self - efficacy toward engineering design could not be motivated or successful in engineering , but with their current knowledge and beliefs they would not be inclined . Con - versely , anxiety ( (cid:6) 0 . 593 ) was negatively correlated to self - efficacy . Anxiety’s lower magnitude correlation to self - efficacy suggests that high self - efficacy and extensive engineering experience do not neces - sarily eliminate anxiety completely . V . D ISCUSSION The results of this study demonstrate three important findings about measuring engineering design self - efficacy . First , the engi - neering design process steps used in this study can represent engi - neering design when measuring task - specific self - concepts such as self - efficacy , motivation , outcome expectancy , and anxiety . The Massachusetts DoE model was chosen based on concurrent validity with other similar engineering design process models . Because there is no consensus on an engineering design process , other engineering 76 Journal of Engineering Education January 2010 Table 3 . Mean EDP scores with standard deviations for experience analysis . Table 2 . Mean ED scores with standard deviations for experience analysis . design process models could be tested using the same methods to investigate their content validity . The steps should factor load on one factor and correlate well to an overall engineering design item . Second , engineering design self - efficacy is highly dependent on engineering experiences . This is evident in significant differences in task - specific self - concepts among high , intermediate , and low engineering experience groups . According to Bandura’s sources of self - efficacy , individuals can build their self - efficacy through engineer - ing experience . Opportunities for mastery experiences , vicarious experiences , social persuasion , or positive and negative physiological states within engineering design may not naturally occur unless the individual has had some sort of experience . The possibility does exist for negative experiences , but then those individuals are likely not to persist in engineering . Finally , motivation , outcome expectancy , and anxiety were shown to relate to self - efficacy toward engineering design . High correlations between self - efficacy and the other three task - specific self - concepts confirm the theoretical connections in this study . This means that the instrument accurately represents the theory postu - lates . Overall , the instrument has been validated as a general engi - neering design instrument . Of interest for further validation of the engineering design self - efficacy instrument would be comparing differences between genders and among engineering disciplines and experiences , student classes , students who transferred into an undergraduate engineering program , and engineering graduate students pursuing design - related research versus those pursuing technical research . The instrument could also be extended to include more task - specific self - concepts such as task incentive and attribu - tion to failure to further establish construct validity . VI . C ONCLUSIONS The instrument tested in this study can provide a tool for educa - tors to gather information about engineering design self - efficacy . The results indicate that the developed instrument validly and reli - ably measures an individual’s self - efficacy toward engineering design . The potential uses of the engineering design self - efficacy instrument include an analysis of student change in will or drive over a given period of time , identifying students that need additional classroom support , and as a base for grouping students specifically for design projects . In general , knowing an individual’s self - efficacy serves as a useful complement to their cognitive gains . Under - standing how self - efficacy affects student learning can facilitate the development of intervention strategies to improve learning . Further research is needed to identify various task - specific self - concepts and to investigate how these relate to cognitive learning outcomes in en - gineering education . These relationships can be measured and un - derstood better if and only if more instruments are developed . The more instruments there are aimed to analyze student will , the more precisely engineering educators will be able to assess the effects of conative outcomes on learning . A CKNOWLEDGMENTS This material is based upon work supported by the National Sci - ence Foundation under Grant No . 0835981 . The authors would also like to recognize Chris Rogers , Director of the Tufts University Center for Engineering Education and Outreach ; Dale Baker , Arizona State University ; and Chris Swan , Tufts University , for their assistance in reviewing this study . R EFERENCES American Educational Research Association , American Psychological Association , and National Council on Measurement in Education . 1999 . Standards for educational and psychological testing . Washington , DC : American Educational Research Association . Atkinson , J . W . 1957 . Motivational determinants of risk - taking behavior . Psychological Review 1 ( 6 ) : 359 – 72 . Atkinson , J . W . , and N . T . Feather . 1966 . A theory of achievement motivation . New York : John Wiley and Sons . Atkinson , J . W . , and J . O . Raynor , eds . 1974 . Motivation and achievement . Washington , DC : Hemisphere . Auyang , S . Y . 2004 . Engineering—An endless frontier . Cambridge , MA : Harvard University Press . Baker , D . , S . Krause , and S . Y . Purzer . 2008 . Developing an instrument to measure tinkering and technical self - efficacy in engineering . In Proceedings of the 2008 American Society for Engienering Education Annual Conference and Exposition . Pittsburgh , PA . Ball , L . J . , and T . C . Ormerod . 1995 . Structured and opportunistic pro - cessing in design : A critical discussion . International Journal of Human - Computer Studies 43 ( 1 ) : 131 – 51 . Bandura , A . 1986 . Social foundations of thought and action : A social cognitive theory . Englewood Cliffs , NJ : Prentice - Hall . Bandura , A . 1994 . Self - efficacy . In Encyclopedia of Human Behavior , ed . V . S . Ramachaudran , 71 – 81 . New York : Academic Press . Bandura , A . 1995 . Self - efficacy in changing societies . New York : Cambridge University Press . Bandura , A . 1997 . Self - efficacy : The exercise of control . New York : W . H . Freeman and Company . Besterfield - Sacre , M . , M . Moreno , L . Shuman , and C . J . Atman . 2001 . Gender and ethnicity differences in freshmen engineering student attitudes : A cross - institutional study . Journal of Engineering Education 90 ( 4 ) : 477 – 89 . Carminer , E . G . , and R . A . Zeller . 1979 . Reliability and validity assessment . Thousand Oaks , CA : Sage Publications . Cronbach , L . J . , and P . E . Meehl . 1955 . Construct validity in psycho - logical tests . Psychological Bulletin 52 : 281 – 302 . Duderstadt , J . 2008 . Engineering for a changing world : A roadmap to the future of engineering practice , research , and education . Ann Arbor , MI : The Millennium Project , The University of Michigan . Eccles , J . S . 1983 . Expectancies , values , and academic behaviors . In Achievement and achievement motivation , ed . J . T . Spence , 75 – 146 . San Francisco , CA : Freeman . Eccles , J . S . 1993 . School and family effects on the ontogeny of children’s interests , self - perceptions , and activity choice . In Nebraska symposium on motivation , ed . J . Jacobs , 40 : 145 – 208 . Lincoln : University of Nebraska Press . Ennis , C . W . , and S . W . Gyeszly . 1991 . Protocol analysis of the engi - neering systems design process . Research in Engineering Design 3 ( 1 ) : 15 – 22 . Felder , R . M . , G . N . Felder , M . Mauney , C . E . Hamrin , and E . J . Dietz . 1995 . A longitudinal study of engineering student performance and reten - tion . III . Gender differences in student performance and attitudes . Journal of Engineering Education 84 ( 2 ) : 151 – 63 . January 2010 Journal of Engineering Education 77 Grinter , L . 1994 . Report of the Committee on evaluation of engineer - ing education . Journal of Engineering Education 83 ( 1 ) : 74 – 94 . Hackett , G . , N . E . Betz , J . M . Casas , and I . A . Rocha - Singh 1992 . Gender , ethnicity , and social cognitive factors predicting the academic achievement of students in engineering . Journal of Counseling Psychology 39 ( 4 ) : 527 – 38 . Hutchinson , M . A . , D . K . Follman , and G . M . Bodner . 2006 . The factors affecting first - year engineering students’ self - efficacy beliefs . Journal of Engineering Education 95 ( 1 ) : 39 – 47 . Massachusetts Department of Education . 2001 / 2006 . Massachusetts science and technology / engineering curriculum framework . Malden , MA : Massachusetts Department of Education . Messick , S . 1989 . Validity . In Educational measurement , ed . R . L . Linn , 13 – 103 . Washington , DC : The American Council on Education and the National Council on Measurement in Education . Moskal , B . M . , J . A . Leydens , and M . J . Pavelich . 2002 . Validity , relia - bility and the assessment of engineering education . Journal of Engineering Education 91 ( 3 ) : 351 – 54 . Pajares , F . , J . Hartley , and G . Valiante . 2001 . Response format in writ - ing self - efficacy assessment : Greater discrimination increases prediction . Measurement and Evaluation in Counseling and Development 33 ( 4 ) : 214 – 21 . Pintrich , P . R . , and E . V . De Groot . 1990 . Motivational and self - regulated learning components of classroom academic performance . Journal of Educational Psychology 82 ( 1 ) : 33 – 40 . Pintrich , P . R . , and D . H . Schunk . 1996 . Motivation in education . Englewood Cliffs , NJ : Prentice - Hall . Pintrich , P . R . , and D . H . Schunk . 2002 . Motivation in education : Theory , research , and applications . Upper Saddle River , NJ : Prentice - Hall . Quade , A . 2003 . Development and validation of a computer science self - efficacy scale for CS0 courses and the group analysis of CS0 student self - efficacy . In Proceedings of the 2003 International Conference on Informa - tion Technology : Computers and Communications . Las Vegas , NV . Richardson , A . L . 2008 . Tinkering interactions on freshman engineer - ing design teams . In Proceedings of the 2008 American Society for Engineering Education Annual Conference and Exposition . Pittsburgh , PA . Rummel , R . J . 1970 . Applied factor analysis . Evanston , IL : Northwestern University Press . Schaefers , K . G . , D . L . Epperson , and M . M . Nauta . 1997 . Women’s career development : Can theoretically derived variables predict persistence in engineering majors ? Journal of Counseling Psychology 44 ( 2 ) : 173 – 83 . Schmidt , J . , R . W . Lent , L . Schmidt , P . Mead , and D . Bigio . 2001 . Social cognitive career theory as an approach to understanding retention in engineering majors . In Proceedings of the 2001 American Society of Engi - neering Education Annual Conference and Exposition . Albuquerque , NM . Schunk , D . 1991 . Self - efficacy and academic motivation . Educational Psychologist 26 ( 3 ) : 207 – 31 . Schunk , D . 1994 . Self - regulation of self - efficacy and attributions in academic settings . In Self - regulation of learning and performance : Issues and educational implications , eds . D . H . Schunk and B . J . Zimmerman , 75 – 99 . Hillsdale , NJ : Lawrence Erlbaum and Associates . Society for the Promotion of Engineering Education . 1930 . Report of the investigation of engineering education , 1923 – 1929 ( Vol . 1 ) . Pittsburgh , PA : F . L . Bishop University of Pittsburgh . Vogt , C . 2003 . An account of women’s progress in engineering : A social cognitive perspective . Journal of Women and Minorities in Science and Engineering 9 ( 3 / 4 ) : 217 – 38 . Weiner , B . 1986 . An attributional theory of achievement , motivation , and emotion . Psychological Review 92 ( 4 ) : 548 – 73 . Wigfield , A . 1994 . The role of children’s achievement values in the self - regulation of their learning outcomes . In Self - regulation of learning and performance : Issues and educational applications , eds . D . H . Schunk and B . J . Zimmerman , 101 – 124 . Hillsdale , NJ : Lawrence Erlbaum Associates . Wigfield , A . and J . S . Eccles . 2000 . Expectancy - value theory of moti - vation . Contemporary Educational Psychology 25 ( 1 ) : 68 – 81 . Wilson , M . 2005 . Constructing measures : An item response modeling approach . Mahwah , NJ : Lawrence Erlbaum Associates . A UTHORS ’ B IOGRAPHIES Adam R . Carberry is a doctoral candidate in Engineering Educa - tion in the Tufts University Math , Science , Technology , and Engi - neering Education program . He holds an M . S . in Chemistry from Tufts University and a B . S . in Material Science Engineering with a minor in Chemistry from Alfred University . He is currently work - ing at the Tufts University Center for Engineering Education and Outreach as a research assistant and manager of the Student Teacher Outreach Mentorship Program ( STOMP ) . Address : Tufts University Center for Engineering Education and Outreach , 474 Boston Ave . , Curtis Hall , Medford , MA , 02155 ; telephone : ( (cid:9) 1 ) 617 . 627 . 5888 ; fax : ( (cid:9) 1 ) 617 . 627 . 4760 ; e - mail : adam . carberry @ tufts . edu . Hee - Sun Lee is an assistant professor in the Education Depart - ment at Tufts University . She earned her Ph . D . degree in Science Education and an M . S . degree in Physics from the University of Michigan , Ann Arbor . She is currently affiliated with the Tech - nology Enhanced Learning in Science Center at the University of California , Berkeley , and the Wright Center for Science Education at Tufts University . Address : Tufts University , Department of Education , Paige Hall , Medford , MA , 02155 ; telephone : ( (cid:9) 1 ) 617 . 627 . 6356 ; fax : ( (cid:9) 1 ) 617 . 627 . 3901 ; e - mail : heesun . lee @ tufts . edu . Matthew W . Ohland is an associate professor of Engineering Education at Purdue University . He holds a Ph . D . in Civil Engi - neering from the University of Florida and M . S . degrees in Me - chanical Engineering and Materials Engineering from Rensselaer Polytechnic Institute and in Engineering and Religion from Swarthmore College . He was previously Associate Professor of General Engineering at Clemson University . As a National Science Foundation Postdoctoral Fellow , he was the Assistant Director of the Southeastern University and College Coalition for Engineering Education . He is past President of Tau Beta Pi , has been recog - nized with best paper awards in multiple conferences and the Journal of Engineering Education , and has received teaching awards from both Clemson and Purdue . Address : School of Engineering Education , Purdue University , Neil Armstrong Hall of Engineering , Room 1305 , 701 West Stadium Avenue , West Lafayette , IN , 47907 ; telephone : ( (cid:9) 1 ) 765 . 496 . 1316 ; fax : ( (cid:9) 1 ) 765 . 494 . 5819 ; e - mail : ohland @ purdue . edu . 78 Journal of Engineering Education January 2010 A PPENDIX January 2010 Journal of Engineering Education 79