1238 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 Enhancement of Group Perception via a Collaborative Brain – Computer Interface Davide Valeriani ∗ , Riccardo Poli , and Caterina Cinel Abstract — Objective : We aimed at improving group per - formance in a challenging visual search task via a hybrid collaborative brain – computer interface ( cBCI ) . Methods : Ten participants individually undertook a visual search task where a display was presented for 250 ms , and they had to decide whether a target was present or not . Local temporal correlation common spatial pattern ( LTCCSP ) was used to extract neural features from response - and stimulus - locked EEG epochs . The resulting feature vectors were extended by including response times and features extracted from eye movements . A classiﬁer was trained to estimate the con - ﬁdence of each group member . cBCI - assisted group deci - sions were then obtained using a conﬁdence - weighted ma - jority vote . Results : Participants were combined in groups of different sizes to assess the performance of the cBCI . Results show that LTCCSP neural features , response times , and eye movement features signiﬁcantly improve the accu - racy of the cBCI over what we achieved with previous sys - tems . For most group sizes , our hybrid cBCI yields group decisions that are signiﬁcantly better than majority - based group decisions . Conclusion : The visual task considered here was much harder than a task we used in previous research . However , thanks to a range of technological en - hancements , our cBCI has delivered a signiﬁcant improve - ment over group decisions made by a standard majority vote . Signiﬁcance : With previous cBCIs , groups may per - form better than single non - BCI users . Here , cBCI - assisted groups are more accurate than identically sized non - BCI groups . This paves the way to a variety of real - world appli - cations of cBCIs where reducing decision errors is vital . Index Terms —Brain – computer interfaces ( BCIs ) , deci - sion making , electroencephalography . I . I NTRODUCTION A . Decision Making in Groups G ROUP decision making has been studied for decades , as understanding its processes and dynamics has important Manuscript received June 26 , 2015 ; revised March 18 , 2016 and June 26 , 2016 ; accepted August 4 , 2016 . Date of publication August 10 , 2016 ; date of current version May 15 , 2017 . This work was supported by the Defence and Security PhD programme through the Defence Science and Technology Laboratory . This paper was awarded at the 7th Interna - tional IEEE / EMBS Conference on Neural Engineering , and supported by Grant Labex NUMEV ANR - 10 - LABX - 20 , and by the National Science Foundation . Asterisk indicates corresponding author . ∗ D . Valeriani is with the Brain Computer Interfaces and Neural Engi - neering Laboratory , School of Computer Science and Electronic En - gineering , University of Essex , Colchester CO4 3SQ , U . K . ( e - mail : dvaler @ essex . ac . uk ) . R . Poli and C . Cinel are with the Brain Computer Interfaces and Neural Engineering Laboratory , School of Computer Science and Electronic Engineering , University of Essex . Digital Object Identiﬁer 10 . 1109 / TBME . 2016 . 2598875 implications in many ﬁelds , including psychology , economics , and politics [ 1 ] – [ 3 ] . Groups have many advantages compared to individuals . For example , they have augmented action capabilities : thanks to the joint forces of its members , a group can do things that are be - yond the strength or endurance of a single individual . Similarly , one would expect groups to show increased cognition and in - telligence . Indeed , extensive literature has shown that making decisions in groups can be powerful ( see , for example , [ 4 ] – [ 7 ] ) and can be superior to making individual decisions in many different contexts , including settings where individuals are in - volved in visual tasks [ 8 ] . However , it is not always obvious whether or not a group decision can outperform individual decisions , and it actually seems that in many cases , group performance , though typically better than average individual performance , does not exceed the performance of the best member of the group [ 7 ] , [ 9 ] . How well a group performs depends on a large number of factors , including group cohesiveness , norms within the group , leader - ship , perceived expertise , stress , timing , and the type of task or decision to be made . All of these , and much more , can affect a member’s contribution in the group , which in turn can make a collective decision better or worse than individual independent decisions [ 5 ] , [ 7 ] , [ 8 ] , [ 10 ] – [ 12 ] . How dramatic this effect can be is shown , for example , in stud - ies adopting the well - known Asch experimental paradigm [ 13 ] , where individuals are involved in a very simple perceptual task ( e . g . , assessing whether two lines have the same length ) . Here , in the case of discrepancies , the inﬂuence of a group can be so strong that individuals often end up giving the incorrect response to align with the group , even if they know it is incorrect . Despite all the negative effects that a group can have on an individual’s decision process , as discussed above , there are still many reasons why a group decision is desirable and advanta - geous : group decision making , for example , allows pooling of information ( e . g . , [ 14 ] ) . In previous research [ 15 ] , we have suggested that , in circum - stances where group decisions are hampered , a system would be desirable that could provide the advantages of groups ( e . g . , pooling of information ) while avoiding their pitfalls , many of which are caused by the direct interaction of the group mem - bers . We have , therefore , proposed and tested the idea that group decisions can be improved by estimating the conﬁdence and combining the independent decisions of noninteracting mem - bers of a group . As we will discuss in Section I - C , this was demonstrated through a collaborative brain – computer interface 0018 - 9294 © 2016 IEEE . Personal use is permitted , but republication / redistribution requires IEEE permission . See http : / / www . ieee . org / publications standards / publications / rights / index . html for more information . VALERIANI et al . : ENHANCEMENT OF GROUP PERCEPTION VIA A COLLABORATIVE BRAIN – COMPUTER INTERFACE 1239 ( cBCI ) with individuals engaged in decisions associated with a simple visual matching task . In this paper , we will extend this system in a number of ways , and we will apply it to a much harder and important visual search task . B . Visual Search Visual search is an important perceptual process involving visually scanning the environment in search for an item of inter - est . We perform visual search tasks on a daily basis , e . g . , when looking for a particular item in a drawer containing many dif - ferent objects or scanning our home for misplaced keys . Visual search , in the form of looking for a suspect or a potential terror - ist within a crowd or in surveillance video , is also a key element of policing and counter intelligence . Despite there being clear evolutionary advantages in animals quickly identifying danger - ous elements in the environment , humans invariably ﬁnd visual search tasks slow , taxing , and difﬁcult to carry out ( although performance varies across different people , contexts and details of the task performed , as well as with the experience and age of the observer [ 16 ] ) . Given the important role of visual search , it is not surprising that experimental visual search paradigms have been extensively used in the study of perception and visual attention for more than 30 years [ 17 ] . In a typical experiment , observers are asked to look at a display containing a number of different items and establish whether a speciﬁc target item is or is not present in the scene among many different distractor items . Visual search experiments usually follow two main ap - proaches [ 18 ] : the percent correct method , where the display is presented to an observer for a limited amount of time fol - lowing which a decision about the presence or absence of the target is made , and the speed - based method , where the display is presented to the observer until he / she reaches a decision . In the former , the accuracy of the decisions made is used to evaluate the performance , while in the latter , performance is evaluated using response times ( RTs ) . C . Collaborative Brain – Computer Interfaces A brain – computer interface ( BCI ) is a communication and / or control system that allows the user to interact with the world through the recording and analysis of the user’s brain activity . This technology has been tested in a large variety of applications , most typically to allow people with severe motor disabilities to communicate and operate actuators of different kinds [ 19 ] – [ 23 ] . In the last few years , however , BCIs have been developed also for the cognitive augmentation of able - bodied individuals , e . g . , to improve human decision accuracy or speed [ 24 ] – [ 26 ] . More recently , cBCIs , i . e . , BCIs where data from multiple users are integrated to achieve a common purpose , have also been proposed for improving the perceptual or cognitive per - formance of groups of users . Studies and applications of cB - CIs include systems for a movement planning task [ 27 ] , visual discrimination between rapidly presented pictures of cars and faces [ 28 ] , [ 29 ] , detecting the onset of visual stimuli presented on a black background [ 30 ] , joint 2 - D cursor control [ 31 ] , rapid discrimination of airplanes in aerial images of urban environ - ments [ 32 ] , and group decision making for a simple visual - matching task [ 15 ] . In particular , in [ 15 ] , participants had to decide whether or not two sets of 2 - D shapes were identical . These were pre - sented for a very short time , thus making individual ( non - BCI ) decisions difﬁcult and often erroneous . Our approach was un - usual in relation to previous cBCI studies in that we exploited not only neural data but also behavioral measures of conﬁdence . That is , in addition to EEG , we recorded the RTs , as these are inﬂuenced by , and thus can reveal , the conﬁdence in a deci - sion [ 33 ] . Being based on both neural and behavioral features , our system was , thus , a hybrid cBCI . Candidate neural features were extracted from EEG via spatiotemporal principal compo - nent analysis ( PCA ) . We then optimally selected , combined , and used neural and behavioral features extracted during a decision to estimate the objective level of conﬁdence of each observer making that decision . To perform feature selection and parameter identiﬁcation , we used information on whether the response of our observers in each decision was correct or incorrect , on the assumption that participants were on average less conﬁdent in erroneous decisions than in correct ones . 1 The reasoning behind this as - sumption is that a rational observer is more likely to give an incorrect response when the perceptual processes leading to the decision do not provide all the necessary information to take the correct decision , hence making the user uncertain . On the other hand , it is reasonable to assume that the conﬁdence with which an observer takes a decision would be higher for most of the “correct” trials . 2 Finally , group decisions were determined by a weighted - majority algorithm , which dynamically weighed individual de - cisions based on each observer’s estimated conﬁdence . Results showed that cBCI - assisted group decisions obtained in this manner were almost always statistically better than those obtained by identically sized ( non - BCI ) groups adopting the majority rule . That is , while all previous cBCIs had been able to improve either speed or accuracy over single non - BCI users , for the ﬁrst time , the system developed in [ 15 ] provably al - lowed cBCI - assisted groups to make more accurate decisions than groups performing the same tasks by traditional means . D . Contributions Previous research on cBCIs suggests that in the future , these systems could be applied in various real - world situations to enhance individual or group performance , particularly in cases where critical decisions have to be made very rapidly ( e . g . , in defense ) or with high level of conﬁdence ( e . g . , in air trafﬁc control ) . Many such systems would work equally well for people with impaired communication and motor control capabilities as for able - bodied operators . The present study represents another step toward moving cBCIs out of the lab . 1 This was unlike previous cBCI and BCI research ( see previous section ) where systems are trained to classify EEG data to infer the intended response of an observer ( e . g . , target or not - target ) . 2 In preliminary work [ 34 ] , we actually put this interpretation to the test by verifying whether the opposite interpretation would yield signiﬁcantly different results . Results of joint decisions were exceptionally bad when we adopted this alternative criterion , conﬁrming our original line of reasoning . 1240 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 More speciﬁcally , we propose a cBCI for improving group decisions based on visual perception . Like the cBCI in [ 15 ] , this is a hybrid system in that it uses both the responses of the users and EEG and physiological measurements in order to produce better group decisions . This paper extends the framework proposed in [ 15 ] along four main directions . First , we investigate whether a cBCI approach can be applied to a visual search task that is perceptually and cognitively dif - ferent from the visual matching task previously tested . The high perceptual load ( due to the large number of nontargets presented in each display ) , the difﬁculty of discriminating between targets and nontargets ( due to the shared features between the target and the nontargets ) , and the fast presentation of each display render decisions very hard in this task . The choice of a dif - ferent and more challenging task is important because , while in [ 15 ] , we identiﬁed a reasonable way of obtaining and ex - ploiting correlates of the individual degrees of conﬁdence in decisions , it remained unclear whether the approach would gen - eralize to other perceptual tasks and what performance level a cBCI could deliver in such cases . To the best of our knowledge , every cBCI study reported in the literature used only one task ( or a group of very similar tasks ) . Thus , exploring these issues is an important research goal for cBCI and the fact that here , too , cBCI - assisted groups are more accurate than identically sized non - BCI groups represents a major stepping stone toward that goal . Second , we improve our conﬁdence estimators by replac - ing the spatiotemporal PCA we used previously to extract the neural features from the EEG data with a local temporal corre - lation common spatial pattern ( LTCCSP ) ﬁlter [ 35 ] . The orig - inal form of common spatial pattern ( CSP ) ﬁltering has been adopted in several BCI applications for its marked ability to capture important aspects of the data [ 36 ] – [ 38 ] , but it does not include temporal information , which is quite important in studies based on event - related potentials ( ERPs ) . This is why researchers ( e . g . , [ 39 ] – [ 42 ] ) have recently developed forms of CSP that consider temporal variability , LTCCSP being one of them . LTCCSP allowed us to both increase the accuracy ( thanks to the inclusion of temporal information ) and reduce the num - ber of neural features required by the system ( from the 24 PCA components used originally ) , thereby promoting generalization and speed ( see below ) . Third , the adoption of LTCCSP has allowed us to extend the information provided in input to the system . In [ 15 ] , we could only use features extracted from response - locked epochs as we found in preliminary explorations that an increase of the fea - ture vector size would cause the classiﬁer to overﬁt the training data . However , thanks to the signiﬁcant reduction of number of features allowed by LTCCSP , here it has been possible to pro - vide the system with both stimulus - locked and response - locked representations of the ERPs . Stimulus - locked epochs allow to better capture the exogenous and endogenous components trig - gered by the stimulus [ 43 ] . These include the perception of task difﬁculty [ 44 ] and the processes of evaluation and categoriza - tion of the stimulus and context updating typically associated with the P300 [ 45 ] . Both are part of the decision making pro - cess and are expected to correlate with the decision conﬁdence . This could , thus , complement the information extracted from the response - locked ERP representation ( that captures well late endogenous components [ 43 ] and that we already used in [ 15 ] ) and further improve our conﬁdence estimates [ 43 ] . Fourth , as LTCCSP is more than one order of magnitude faster than PCA , the speed of the system has much increased compared to our previous cBCI . The ability to produce outputs within a reasonable time window is a prerequisite for online systems to be applied in everyday life where responsiveness is needed [ 46 ] . So , while the speed up is not so important in our ofﬂine validation of the system , this is an added bonus as it makes the cBCI ready for future online experimentation . This paper is an invited extended version of a paper presented at the 7th IEEE EMBS Neural Engineering Conference [ 47 ] . II . M ETHODS A . Participants We collected data from ten healthy volunteers ( six males , av - erage age = 28 . 5 , SD = 6 . 0 ) with normal or corrected - to - normal vision who gave written informed consent to take part in the ex - periment . The research received UK’s MoD and University of Essex ethical approval in July 2014 . B . Stimuli and Tasks In this study , we adopted a combination of the percent cor - rect and the speed - based visual search methods described in Section I - B . In particular , each display in the visual search task was shown for a short time ( as in the percent correct approach ) . Then , we asked the observers to make their decisions as rapidly as possible ( as in the speed - based approach ) . Therefore , both accuracy and speed were measured . We used this approach as it is a more realistic representation for the type of applications we are interested in . Participants , comfortably seated at about 80 cm from an LCD screen , were asked to undertake an experiment consisting of eight blocks of 40 trials , for a total of 320 trials . Each trial ( see Fig . 1 ) started with the presentation of a ﬁxation cross in the middle of the screen for 1 s ( which allowed EEG signals to return to baseline after the response from previous trials ) . This was followed by a display containing a set of 40 bars , either green [ RGB ( 0 , 1 , 0 ) ] or red [ RGB ( 1 , 0 , 0 ) ] , vertical or horizontal , on a black background , for 250 ms . Then , a mask ( black and white 24 × 14 checkerboard ) was presented for 250 ms . The participants task was to decide , as quickly as possible , whether or not there was a vertical red bar , the target , among the vertical green , horizontal green , and horizontal red bars , the distractors . They clicked the left mouse button with the index ﬁnger to signal the presence of the target , and the right mouse button with the middle ﬁnger to signal its absence . RTs were recorded . The mouse was always controlled with the right hand ( RT differences between using the nonpreferred hand over the preferred one are typically very small [ 48 ] ) . The position of the bars was randomly selected ( without al - lowing overlaps between bars ) within a rectangular screen re - gion subtending approximately 17 . 7 ◦ horizontally and 11 . 9 ◦ vertically . Bars subtended approximately 1 . 09 ◦ in their longer VALERIANI et al . : ENHANCEMENT OF GROUP PERCEPTION VIA A COLLABORATIVE BRAIN – COMPUTER INTERFACE 1241 Fig . 1 . Sequence of stimuli presented in the trials of our experiment . dimensions and 0 . 36 ◦ in their shorter dimension . The num - ber of distractors of each type was also randomly selected , but ensuring that at least one instance of each type was present in the display . Targets ( red vertical bars ) were presented in 25 % of trials . The random displays used in the experiment were precom - puted and stored so that identical sequences of stimuli were used for all participants . This was done in order to make it possible to test ofﬂine the beneﬁts of combining the decisions of different participants to form group decisions . Brieﬁng , preparation of participants , and task practice ( two blocks of ten trials each ) took approximately 45 min , while the actual experiment lasted approximately 25 min . C . Data Acquisition and Preprocessing RTs were measured by time - stamping the clicks of an ordi - nary USB mouse . As indicated in [ 15 ] , this produces a maximum jitter of 14 ms , which is negligible when compared with even the shortest RTs . Eye movements were recorded by using a Jazz eye tracker that provided data at a sampling rate of 2 kHz . The eye tracker was safely placed on the forehead of the participant to record horizontal and vertical eye movements . Neural data were recorded from 64 electrode sites using a BioSemi ActiveTwo EEG system . Each channel was refer - enced to the mean of the electrodes placed on each earlobe . The recorded data were sampled at 2048 Hz and then bandpass ﬁl - tered between 0 . 15 and 40 Hz with a 14 677 - tap ﬁnite impulse response ( FIR ) ﬁlter obtained by convolving a windowed low - pass ﬁlter with a windowed high - pass ﬁlter . Artifacts caused by eye - blinks and other ocular movements were removed by us - ing a standard subtraction algorithm based on correlations . The data were then low - pass ﬁltered with an optimal 820 - tap FIR ﬁlter designed with the Remez exchange algorithm [ 49 ] with a passband of 0 – 6 Hz and a stopband of 8 – 1024 Hz . Consistently with our previous study [ 15 ] , the data were ﬁnally downsam - pled to a sampling rate of 16 Hz , since this still allows detecting meaningful variations ( e . g . , P300s ) in the EEG data . 3 The EEG data were segmented into two types of epoch —response - locked and stimulus - locked—and detrended . 3 As suggested by one reviewer , we have veriﬁed that it is possible to slightly improve the performance of the cBCI ( 0 . 06 % of average relative improvement on group sizes 1 – 10 ) by increasing the sampling rate to 32 Hz . However , this has the signiﬁcant disadvantage of increasing feature extraction time from 17 to 49 s . Response - locked epochs lasted 1500 ms and started 1000 ms before the user’s response . Stimulus - locked epochs also lasted 1500 ms but started in synchrony with the presentation of the stimulus . 4 Each epoch was thus represented by 48 samples from each of the 64 available channels , i . e . , a total of 3072 values . It should be noted that the average RT across participants is just above 900 ms . So , in most trials , the response - and stimulus - locked epochs do overlap ( albeit to different degrees ) . How - ever , the stimulus - locked epochs are still very different from the response - locked ones and , so , together they carry more infor - mation than each type on its own . D . Relabelling In order to estimate the decision conﬁdence via machine learning algorithms , we would need to have ground - truth in - formation on the actual conﬁdence with which the decisions in an appropriate training set were made . However , this informa - tion is not directly available . We could ask a participant to rate his or her degree of conﬁdence in a decision , but this measure would likely be biased and not objective . Therefore , we adopted the same approach used in [ 15 ] that associates conﬁdence to correctness . Speciﬁcally , we have rela - beled all the trials in the training set where the decision made by a participant was correct ( independently from the presence or absence of the target ) as “conﬁdent” ( − 1 label ) and the trials where the decision was incorrect as “nonconﬁdent” ( + 1 label ) . As indicated in Section I - C and veriﬁed in [ 15 ] and [ 34 ] , this is a reasonable approximation . That is , our cBCI predicts whether a user gave a conﬁdent ( correct ) or a nonconﬁdent ( incorrect ) response , and not whether the response of the user was target or not - target . E . Feature Extraction We used neural , behavioral , and physiological features to identify the conﬁdence of the user in the decision made in each trial of our experiment . 1 ) Neural Features : CSPﬁlteringprojects themultichan - nel EEG data into a low - dimensional spatial subspace in such a way to maximize the variance of the different classes of the signals . While the standard CSP algorithm uses only the global spatial covariances to build the transformation matrix , LTCCSP 4 For efﬁciency , the ﬁnal low - pass ﬁltering and downsampling mentioned above were carried out on the epochs themselves . These were extended by 400 ms , ﬁltered , and then trimmed back to 1500 ms to avoid transient effects . 1242 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 also considers temporally local information in the variance mod - eling . In particular , it introduces a weight matrix to impose larger coefﬁcients on patterns that are similar within a local temporal range τ ( that we empirically set to ten samples ) . For a detailed explanation of the LTCCSP method , the reader can refer to [ 35 ] . In this work , we have used LTCCSP to extract features from a standard two - classes task where we wanted to discriminate be - tween correct and incorrect decisions . Therefore , the LTCCSP ﬁlter maximized the variance between the neural signals asso - ciated with these two classes . For each subject , we have applied LTCCSP to the response - and stimulus - locked epochs of the training set to obtain two projection matrices ( W Rlckd and W Slckd , respectively ) . Then , we have transformed the original EEG data to the new feature space where the columns of the resulting matrices are organized in such a way that the ﬁrst and the last columns of each have the maximum and the minimum difference in terms of variance , respectively . To obtain maximum efﬁciency and generalization , we took the decision to start from the smallest number of features and increase this number if required . So , we chose only the ﬁrst and the last columns of each matrix and we used their variances as neural features to represent decision conﬁdence . As this worked well , we did not have to revisit this decision . Therefore , we have used four LTCCSPs in total as neural features . 2 ) Response Times : We used RT as a behavioral feature that can indicate the conﬁdence of the user in each decision . As suggested in [ 33 ] and empirically veriﬁed in [ 15 ] , shorter RTs tend to be more frequently associated with correct decisions ( i . e . , where the user is more conﬁdent ) than to incorrect ones . 3 ) Eye Movements : We used the vertical component of the eye movement recorded by our eye tracker to extract phys - iological features as this also includes information about the occurrence of eye blinks . Four different features were extracted : 1 ) the total distance covered by the eyes along the verti - cal axis during the stimulus presentation ( 250 ms time window ) ; 2 ) the standard deviation of the vertical eye movements dur - ing the stimulus and the mask presentation ( 500 ms ) ; 3 ) the mean of the numerical derivative of the vertical eye movements during the stimulus and the mask presentation ( 500 ms ) ; 4 ) the mean of the derivative signal in a 500 - ms time window centered on the response . We chose these features as they seem to be the most effective as conﬁdence indicators based on preliminary results [ 50 ] . F . Making Group Decisions In collaborative decision making , different approaches can be followed to combine the answers of multiple participants to obtain a group’s decision . Voting systems seem to be the most appropriate for distributed cBCI , i . e . , where each user has his own BCI sub - system . In [ 27 ] , a support vector machine ( SVM ) classiﬁer was used to predict the answer of each participant . The SVM predictions were then weighted according to each user’s training accuracy to build group decisions . A similar approach has been used in [ 29 ] and [ 30 ] where , instead of using a weighted majority , a second - layer SVM has been used to transform the outputs of the individual SVMs into group decisions . In [ 28 ] , individual en - sembles of linear classiﬁers were trained for the participants . Their outputs were then combined using a weighted sum where the weights were optimally determined based on the perfor - mance of the users on the training set . Eckstein et al . [ 28 ] also tested a form of performance - adjusted majority vote where dif - ferent thresholds were applied to the outputs of individual clas - siﬁers to convert them into votes , the thresholds , again , having been chosen based on training set performance . Our cBCI uses a similar approach ( a weighted majority rule ) to build the group’s decision although , unlike [ 27 ] – [ 30 ] , it does not predict the user decision ( in our system this is already known from the user’s behavioral responses ) but the user conﬁdence in that decision . Also , unlike [ 27 ] , [ 29 ] , [ 30 ] , and the optimal linear classiﬁer in [ 28 ] , in determining group decisions , our system does not weight different users differently based on their training accuracy . 5 Finally , while we , too , use a linear combination to integrate evidence across multiple users , as discussed later in our system , the weights are adjusted independently for every decision . More speciﬁcally , the weights associated with each user in the group are computed from an estimation of his or her conﬁdence in a particular decision given by a linear regressor . These weights are then multiplied by the individual decisions gathered from each participants of a group to build the ﬁnal decision as follows : d group = sign ( w 1 · d 1 + w 2 · d 2 + · · · + w n · d n ) ( 1 ) where sign is the sign operator , n is the group’s size , d i = { − 1 , 1 } is the decision of participant i = 1 , . . . , n , and w i ∈ R + is the weight associated with the conﬁdence of participant i in the current decision . The cBCI is responsible for computing the w i ’s . In case of ties ( i . e . , d group = 0 ) , a random decision is made . The w i ’s have been computed using the least angle regression ( LARS ) [ 51 ] method . In our cBCI , LARS has to predict the conﬁdence in a decision , which is given by f = (cid:2) j a j · x j + (cid:3) ( 2 ) where a j for j = 1 , 2 , . . . and (cid:3) are constant coefﬁcients ( to be identiﬁed via a training set ) and x j are the features represent - ing an epoch ( two LTCCSP neural features extracted from the response - locked epoch , two LTCCSP neural features extracted from the stimulus - locked epoch , the RT and four features ex - tracted from the eye movements ) . Note that in [ 15 ] , 24 PCA - based neural features and the RTs were used to train two different classiﬁers , the outputs of which were then combined to obtain a conﬁdence estimator . However , in this work , we found that this added complexity was not necessary . Hence , here , neural , behavioral , and physiological features have been combined in a single linear model , which further reduced the free parameters in our cBCI . Once a conﬁdence estimate , f i , is available for a particular decision of participant i , we compute the weights used in ( 1 ) for 5 We think that a system that gives identical chances to individuals having the same conﬁdence is more likely to be seen as acceptable , and thus be adopted , by future end users . VALERIANI et al . : ENHANCEMENT OF GROUP PERCEPTION VIA A COLLABORATIVE BRAIN – COMPUTER INTERFACE 1243 that decision using the following negative exponential weighting function : w i = exp ( − 2 . 5 − f i ) . ( 3 ) This function was chosen based on prior experience [ 15 ] and was motivated by the desire to allow conﬁdent users to count substantially more than uncertain users in the group’s decision . In order to ensure that results were not affected by overﬁtting , we made use of tenfold cross - validation so that the estimation of the system’s performance and the feature - extraction / machine - learning elements of the cBCI ( namely , LTCCSP ﬁltering and LARS ) were always performed on independent datasets . Hence , in each fold , we used 90 % of the trials for training and the remaining 10 % for testing . The same nonoverlapping sets were built for each participant . G . Group Simulation We applied our method to the (cid:3) 10 n (cid:4) groups of size n that could be assembled with our ten participants , for n = 2 , 3 , . . . , 10 . For each group , we computed the errors made by the group when the decision was made according to both the majority rule ( i . e . , w i of ( 1 ) are the same for all the group’s members ) and our conﬁdence - based method in ( 1 ) – ( 3 ) . For comparison , for the latter , we considered not only our current cBCI ( based on LTCCSP features , RT , and eye movements features ) but also a version based on 24 PCA components selected as in [ 15 ] and RT , a version based on LTCCSP features and RT ( to establish the impact on the performance of the features extracted from the eye movements ) , and two versions that used only the RT or the RT and the eye movements features to estimate the conﬁdence . Then , for each group size , we averaged the errors made by the different groups . To test if the observed differences in error rates using different methods were statistically signiﬁcant , we compared the error distributions within each group size by using the one - tailed Wilcoxon signed - rank test with the Bonferroni correction . We have chosen this paired - data test since all methods ( i . e . , Majority and the four conﬁdence - based cBCIs ) were applied to the same groups . III . R ESULTS A . Individual Performance Since the main aim of this study was to improve human performance , we start by looking at the errors of each participant in the visual search task used in our experiment . As shown in Fig . 2 , participants had very different individual levels of performance , with error rates ranging from 6 . 25 % to 35 . 63 % . The average error rate ( the solid line in the ﬁgure ) was 21 . 0 % with a standard deviation of 9 . 2 % . For comparison , in [ 15 ] , the average error rate for a visual matching task was 12 . 5 % , corroborating the hypothesis that the visual search task used here would be signiﬁcantly harder . B . Group Performance Fig . 3 shows the mean decision - error rate for different group sizes using the majority rule as well as our conﬁdence - based Fig . 2 . Participant mean errors averaged over 320 trials . The solid line represents the average errors across participants . Fig . 3 . Average percentage of errors versus group size for group de - cisions made by : 1 ) the majority rule , 2 ) an RT - based decision system , 3 ) an RT - and eye - based decision system , 4 ) a cBCI using PCA neural features and RTs , 5 ) a cBCI using LTCCSP neural features and RTs , and 6 ) a cBCI using LTCCSP neural features , RTs , and eye movements features . The y - axis uses a logarithmic scale . TABLE I N UMERICAL R EPRESENTATION OF THE P LOTS IN F IG . 3 GroupSize Majority RT RT + Eyes PCA + RT LTCCSP + RT LTCCSP + RT + Eyes 1 21 . 00 21 . 00 21 . 00 21 . 00 21 . 00 21 . 00 2 21 . 00 13 . 83 13 . 88 15 . 28 13 . 94 14 . 17 3 12 . 60 12 . 31 12 . 23 12 . 22 12 . 26 12 . 15 4 12 . 60 9 . 09 9 . 01 9 . 80 9 . 05 9 . 01 5 9 . 21 8 . 66 8 . 58 8 . 70 8 . 52 8 . 40 6 9 . 21 7 . 32 7 . 28 7 . 99 7 . 11 7 . 07 7 7 . 66 7 . 10 7 . 05 7 . 20 6 . 96 6 . 81 8 7 . 66 6 . 38 6 . 47 7 . 25 6 . 08 6 . 05 9 6 . 72 6 . 28 6 . 28 6 . 59 6 . 13 5 . 97 10 6 . 72 5 . 62 5 . 94 6 . 56 5 . 62 5 . 94 The best results for each group size are showed in boldface , while the worst are shown in italics . methods . Table I provides a numerical representation of the same information . As we found in [ 15 ] , also for a visual search task , a reason why conﬁdence - based rules perform better than the simple majority rule is that they remove ties ( which are otherwise resolved with 1244 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 TABLE II S TATISTICAL C OMPARISON OF M ETHODS FOR G ROUP D ECISIONS FOR D IFFERENT G ROUP S IZES Group size Comparison 2 3 4 5 6 7 8 9 Is RT better than Majority ? 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0063 Is PCA + RT better than Majority ? 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 2284 Is LTCCSP + RT + Eyes better than Majority ? 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0026 Is LTCCSP + RT + Eyes better than RT ? 0 . 9773 0 . 0000 0 . 0266 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0264 Is LTCCSP + RT + Eyes better than RT + Eyes ? 0 . 9811 0 . 0001 0 . 4176 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0116 Is LTCCSP + RT + Eyes better than LTCCSP + RT ? 0 . 9548 0 . 0001 0 . 2921 0 . 0000 0 . 1362 0 . 0000 0 . 2810 0 . 0599 Is LTCCSP + RT + Eyes better than PCA + RT ? 0 . 0000 0 . 0724 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0000 0 . 0107 Sample size 45 120 210 252 210 120 45 10 Thetablereportsthe p - valuesreturnedbytheone - tailedWilcoxonsigned - ranktestwhencomparingtheperformanceofgroupsofdifferentsizesadopting different decision methods ( i . e . , Majority , conﬁdence - based using PCA neural features and RTs , conﬁdence - based using LTCCSP neural features , RTs andeyesfeatures , conﬁdence - based usingLTCCSPneuralfeaturesandRTs , conﬁdence - based usingRTsandeyesfeatures , andconﬁdence - based using only RTs ) . The number of groups of each size that could be assembled with our ten participants is indicated in the last row of the table . p - values below the Bonferroni - corrected statistical signiﬁcance level 0 . 05 / 7 = 0 . 0071 are in boldface . a random decision ) in even - sized groups . Indeed , as we can see both in Table I and Fig . 3 , the difference in performance for such groups is usually much greater than for odd - sized groups . However , all our conﬁdence - based systems , but particularly the cBCI based on LTCCSP , RTs , and eye movements features , manage to augment human decision - making performance also with odd - sized groups ( with statistically signiﬁcant differences , as we discuss later in this section ) . We have also veriﬁed one of our previous ﬁndings [ 15 ] : the performance of the cBCI system using only behavioral ( RT ) features was worse than when using a combination of neural and behavioral features for most group sizes . The p - values of the Wilcoxon tests performed to compare the error distributions across different methods are reported in Table II . Sample sizes ( the number of groups of each size ) are indicated in the last row of the table . It is clear that for all group sizes , our new LTCCSP - based cBCI yields group decisions that are signiﬁcantly better than traditional ( majority - based ) group decisions . Also , for many group sizes , such decisions are sig - niﬁcantly better than those made using a PCA - based cBCI . The PCA - based cBCI is also signiﬁcantly better than majority , as we found in [ 15 ] , but it is never better than the LTCCSP - based cBCI . Finally , let us analyze the decision times . Fig . 4 shows the average time required by groups of different sizes to make a decision , i . e . , the time needed by the slowest member of the group to respond . The plot clearly shows that groups increase decision times by up to 70 % . However , as we did in [ 15 ] , group RTs can be shortened by allowing only the fastest respondents to contribute in the group’s decision . With this technique , there are many choices that allow cBCI - assisted groups to be both faster and more accurate than single individuals . For instance , by allowing only the fastest two respondents in groups of ﬁve to decide in our LTCCSP - based cBCI , error rates are halved , while RTs are approximately 200 ms shorter than for an average individual . C . Performance Across Tasks To gather some preliminary evidence on the degree of per - formance improvement ( or otherwise ) that our cBCI can deliver Fig . 4 . Average time needed for groups of different size to reach a decision . This is equal to the average RT of the slowest participant in each group . The plot also shows the standard deviation of each group size . across tasks , in Fig . 5 , we compare the results obtained in [ 15 ] with the less challenging visual matching task described in Section I - C and the results of the present work with a more difﬁ - cult visual search task . For a fairer comparison , in either case , we report the results obtained with majority ( solid lines ) and PCA - based cBCIs ( dashed lines ) using the same number of principal components . We have plotted these data using a semilogarith - mic scale as this makes it possible to compare the relative im - provements across systems ( equal distances along the ordinates correspond to equal improvement percentages ) . For reference , we also report the results of our best method : the LTCCSP - based cBCI that also exploits eye movements ( black dotted line ) . The most apparent feature in the ﬁgure is that the lines repre - senting the visual matching task ( blue ) and those representing the visual search task ( red ) run almost parallel , indicating that both majority and the PCA - based cBCI provide the same rela - tive beneﬁts as the group size varies . Of course , the cBCI lines are below the majority lines ( as we have already discussed ) . However , the distances between the solid and the dashed lines of each color follow a very similar proﬁle . This indicates that VALERIANI et al . : ENHANCEMENT OF GROUP PERCEPTION VIA A COLLABORATIVE BRAIN – COMPUTER INTERFACE 1245 Fig . 5 . Comparison of the results obtained in [ 15 ] with a visual match - ing task ( blue lines ) and the results of the present work with a visual search task ( red lines ) obtained with majority ( solid lines ) and PCA - based cBCIs ( dashed lines ) . The black dotted line represents the results of the LTCCSP - based cBCI that also exploits eye movements in the visual search task . The ordinate axis uses a logarithmic scale . Fig . 6 . Average processing time required to train a classiﬁer ( left , times inseconds ) andtoclassifyatrial ( right , timesinmicroseconds ) forthetwo feature - extraction methods considered in the paper . the relative beneﬁts obtained by the cBCI over majority at each group size are comparable across the two tasks . Indeed , the av - erage ( across group sizes ) increase in performance brought by the PCA - based cBCI is 8 . 6 % for visual matching and 8 . 7 % for visual search . These results corroborate the hypothesis ( testing which was one of our aims ) that our approach to obtaining and exploit - ing correlates of decision conﬁdence with a cBCI does indeed generalize to tasks of different nature and difﬁculty . D . Speed of the System We also measured the processing time needed to extract neu - ral features and to train the classiﬁer using the LTCCSP - based cBCI and the PCA - based cBCI . Tests were executed on an Intel i7 - 4930K workstation with 32 - GB RAM running Ubuntu 14 . 04 . Only one CPU core of the 6 available was used . As shown in Fig . 6 ( left ) , when using LTCCSP , the cBCI is more than one order of magnitude faster than with PCA at extracting features and training the classiﬁer for conﬁdence prediction . With LTCCSP , this takes less than 18 s as opposed to the 5 + min required when using PCA . This makes the system ready to be used almost immediately after the acquisition of a training set . We should note that , as shown in Fig . 6 ( right ) , the time needed by a trained classiﬁer ( whether LTCCSP - based or PCA - based ) to predict the decision conﬁdence on an unseen trial is truly negligible for both feature sets . E . ERP Analysis We complemented these results with an ERP analysis . Since we use neural signals to estimate the conﬁdence in a decision , we focused our analysis on the differences in the statistical dis - tributions of ERPs for correct and incorrect responses . Also , since our cBCI uses both stimulus - locked and response - locked epochs , we show results in both representations . The only dif - ference between the data used by the cBCI and the data used in this analysis is that in the latter , we downsampled the data to 64 Hz ( instead of 16 Hz ) for better visualization . Fig . 7 shows the stimulus - locked and response - locked grand averages of a representative subset of the 64 electrode sites used for EEG recording ( i . e . , Fz , Cz , Pz , Oz , C3 , C4 , P3 , and P4 ) . The p - values from a two - tailed Wilcoxon signed - rank test for paired samples , which compared the mean individual ERPs for the two classes obtained are also shown . The ﬁrst three rows of Fig . 8 report scalp maps representing the grand averages for the correct and incorrect trials and their differences at 600 ms after stimulus presentation and 250 ms before the response . The last row shows scalp maps of the p - value of the Wilcoxon test used to compare the ERPs in the two classes . It is clear that statistically signiﬁcant differences are present at many electrode sites in both stimulus - locked and response - locked representations . IV . D ISCUSSION Our cBCI combines neural , behavioral , and physiological features to estimate the decision conﬁdence of multiple users for the purpose of achieving better group decisions in a visual search task . The task was very difﬁcult , involving detecting a target in a set of 40 random distractors , where targets could only be recognized by a conjunction of two features ( color and orientation ) , and so there was no pop - out effect . The system relies on an approach for obtaining and exploiting correlates of the individual degrees of conﬁdence in decisions that we had previously trialed in a cBCI with a much simpler and cognitively different visual matching task [ 15 ] , with very encouraging results . Based on that experience , here we have redesigned our system to further improve its performance in terms of both accuracy and speed . A . Main Findings Results indicate that the approach proposed in [ 15 ] does gen - eralize across tasks . More speciﬁcally , for almost all group sizes , our new cBCI yields group decisions that are statistically sig - niﬁcantly better than both traditional ( majority - based ) group decisions and group decisions made by a PCA - based cBCI . Also , LTCCSP ﬁltering provided not only an improvement in decision accuracy but also a signiﬁcant reduction of the training 1246 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 Fig . 7 . Stimulus - locked ( left ) and response - locked ( right ) grand averages for channels Fz , Cz , Pz , Oz , C3 , C4 , P3 , P4 and corresponding temporal proﬁle of the p - values of the two - tailed Wilcoxon signed - rank test ( black ) comparing participant - by - participant averages for all recordings in each error class : correct ( blue ) and incorrect ( red ) . time with respect to the PCA - based system we used in [ 15 ] . While speed is not so important in an ofﬂine validation , its fast training and execution time make our cBCI “online - ready , ” which is an added advantage of our design . Further increases in accuracy were provided by the exploita - tion of eye movements in estimating decision conﬁdence and by the fact that , for the ﬁrst time , we were able to provide the cBCI with both a stimulus - locked and a response - locked ERP representation , without overﬁtting . The stimulus - locked ERP representation [ see Fig . 7 ( left ) ] al - lows the cBCI to see in full resolution [ 43 ] and , thus , exploit differences in exogenous and endogenous ERPs associated with the processing and evaluation of the stimulus . In this represen - tation , major differences between correct and incorrect trials occur at approximately 600 ms after stimulus onset , where a slow positive wave ( a P300 in the centro - parietal channels ) has a statistically signiﬁcantly greater amplitude for the correct than the incorrect decisions . This is likely to be due to the fact that when a trial is particularly hard and , hence , users being unsure of their decision , the amplitude of the P300 is reduced [ 45 ] , reﬂecting a more elaborate decision process . Signiﬁcant differences between the ERPs elicited in correct and incorrect trials are also present in the response - locked anal - ysis [ see Fig . 7 ( right ) ] . Here , the traditional stimulus - locked ERPs associated with early visual processing ( such as the P1 , N1 , P2 , and N2 ) are almost completely absent due to the blur - ring effect associated with wide RT distributions ( see [ 43 ] for details ) and the preprocessing taking place in the system ( in par - ticular , the detrending of the epochs ) . However , it is apparent that the ﬁnal phases of the decision - making process ( i . e . , a few hundred milliseconds before the response ) are associated with different amplitudes for correct and incorrect trials , particularly for posterior and occipital channels . These ﬁndings are also conﬁrmed by the scalp maps in Fig . 8 , which also indicate that there is complementarity between the stimulus - locked and the response - locked representations : the former shows statistically signiﬁcant differences in the anterior , central , and parietal areas , and the latter carries statistically VALERIANI et al . : ENHANCEMENT OF GROUP PERCEPTION VIA A COLLABORATIVE BRAIN – COMPUTER INTERFACE 1247 Fig . 8 . Scalp maps of the grand averages of the EEG activity recorded 600 ms after stimulus onset ( ﬁrst column ) and 250 ms before the re - sponse ( second column ) . Rows represent the activity for correct and incorrect trials ( ﬁrst two rows ) , the difference between them ( third row ) and the p - values obtained by using the Wilcoxon test over the two sets ( last row ) . signiﬁcant evidence in the parietal and occipital channels . This corroborates our assumption that both representations are useful to estimate decision conﬁdence . Finally , the comparison between the error rates achieved by both majority and a PCA - based cBCI in the visual matching task of [ 15 ] and the error rates yielded by corresponding systems in the visual search task used here indicated that the beneﬁts of cBCI are similar across tasks and group sizes . B . Limitations In this study , we recorded data from participants performing the experiment individually and then simulated group decisions . A drawback of this approach is that it does not consider the im - pact that collaboration and , in general , being in a group can have on an individual’s behavior and cognitive processing , and , ulti - mately , on neural activity . The interaction in a real environment would most likely change the neural signals , thereby affecting the performance of a cBCI . While this is certainly true , due to the well - known inefﬁ - ciencies of groups induced by communication ( discussed in Section I - A ) , we feel that a cBCI such as our , where users are not allowed to interact , could potentially be superior to one where interactions are allowed . Taking this into consideration , we have recently carried out an online experiment with pairs of interacting users . Preliminary results have shown that allowing people to interact signiﬁcantly reduces their individual performance as well as group perfor - mance in the decision task . However , statistically signiﬁcant improvements are still obtained when using our cBCI . These early results suggest that , despite the changes in the neural sig - nals due to the interaction , the cBCI is still able to extract and exploit conﬁdence correlates . C . Future Work There are multiple promising future research directions . For instance , additional features could be extracted from biological signals and used to further improve the quality of our conﬁdence estimates . Physiological measures such as heart rate , breathing frequency , and skin conductance can complement our current feature set and lead to even more accurate results . Also , real - world stimuli could be used to test the performance of the cBCI out of the lab . 6 Furthermore , in future research , we plan to cor - roborate our ofﬂine ﬁndings with an online experiment , where two to three participants will simultaneously make decisions on identical or closely related tasks with real - world stimuli . V . C ONCLUSION We developed a cBCI that estimates the decision conﬁdence of multiple users from a combination of neural , behavioral , and physiological features . The cBCI achieves signiﬁcantly bet - ter group decision compared to equally sized non - BCI - assisted groups and our previous PCA - based cBCI . This implies that our approach to making decisions based on a measure of conﬁdence generalizes to different settings . We have also signiﬁcantly re - duced the training time of the system , making another step toward its practical applicability . This research paves the way to a variety of real - world ap - plications of cBCIs where reducing decision errors is vital . For instance , in defense or medical diagnosis applications , the im - provements in decision accuracy yielded by a cBCI could mean saving human lives . Similarly , in ﬁnancial decision making or trading applications , cBCIs could save millions . 6 In recent research [ 50 ] , we have explored the use of natural stimuli ( par - ticipants were asked to search for a polar bear in an Arctic environment with hundreds of penguins ) obtaining very encouraging results , but further corrobo - ration is required . 1248 IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING , VOL . 64 , NO . 6 , JUNE 2017 R EFERENCES [ 1 ] H . A . Simon , “Theories of decision - making in economics and behavioral science , ” Amer . Econ . Rev . , vol . 49 , no . 3 , pp . 253 – 283 , 1959 . [ 2 ] R . R . LauandD . P . Redlawsk , “Advantagesanddisadvantagesofcognitive in political heuristics making , ” Amer . J . Political Sci . , vol . 45 , no . 4 , pp . 951 – 971 , 2001 . [ 3 ] S . Plous , The Psychology of Judgement and Decision Making . New York , NY , USA : McGraw - Hill , 1993 . [ 4 ] J . H . Davis , “Group decision and social interaction : A theory of social decision schemes , ” Psychol . Rev . , vol . 80 , pp . 97 – 125 , 1973 . [ 5 ] N . L . Kerr et al . , “Bias in judgment : Comparing individuals and groups , ” Psychol . Rev . , vol . 103 , no . 4 , pp . 687 – 719 , 1996 . [ 6 ] P . R . Laughlin et al . , “Groups perform better than the best individuals on letters - to - numbers problems , ” Org . Behavior Human Decision Processes , vol . 88 , no . 2 , pp . 605 – 620 , 2002 . [ 7 ] N . L . Kerr and R . S . Tindale , “Group performance and decision making , ” Annu . Rev . Psychol . , vol . 55 , no . 1 , pp . 623 – 655 , 2004 . [ 8 ] R . D . Sorkin et al . , “Signal - detection analysis of group decision making , ” Psychol . Rev . , vol . 108 , no . 1 , pp . 183 – 203 , 2001 . [ 9 ] D . Gigone and R . Hastie , “Proper analysis of the accuracy of group judg - ments , ” Psychol . Bull . , vol . 121 , no . 1 , pp . 149 – 167 , 1997 . [ 10 ] D . Kahneman and S . Frederick , “Representativeness revisited : Attribute substitution in intuitive judgment , ” in Heuristics and Biases : The Psy - chology of Intuitive Judgment . Cambridge , U . K . : Cambridge Univ . Press , 2002 . [ 11 ] L . Branson et al . , “When two heads are worse than one : Impact of group style and information type on performance evaluation , ” J . Bus . Behavioral Sci . , vol . 22 , no . 1 , pp . 75 – 84 , 2010 . [ 12 ] B . Newell et al . , Straight Choices : The Psychology of Decision Making . Hove , U . K . : Psychology Press , 2007 . [ 13 ] S . E . Asch , “Effectsofgrouppressureuponthemodiﬁcationanddistortion of judgments , ” in Groups , Leadership , and Men . Pittsburgh , PA , USA : Carnegie Press , 1951 , pp . 222 – 236 . [ 14 ] G . Stasser and W . Titus , “Pooling of unshared information in group de - cision making : Biased information sampling during discussion , ” J . Pers . Social Psychol . , vol . 48 , no . 6 , pp . 1467 – 1478 , 1985 . [ 15 ] R . Poli etal . , “Collaborativebrain - computerinterfaceforaidingdecision - making , ” PLoS One , vol . 9 , no . 7 , p . e102693 , 2014 . [ 16 ] S . Hahn et al . , “Aging and visual search : Automatic and con - trolled attentional bias to threat faces , ” Acta Psychol . , vol . 123 , no . 3 , pp . 312 – 336 , 2006 . [ 17 ] M . P . Eckstein , “Visual search : A retrospective , ” J . Vision , vol . 11 , no . 5 , pp . 1 – 36 , 2011 . [ 18 ] J . M . Wolfe , “Guided Search 2 . 0 A revised model of visual search , ” Psychonomic Bull . Rev . , vol . 1 , no . 2 , pp . 202 – 238 , 1994 . [ 19 ] L . A . Farwell and E . Donchin , “Talking off the top of your head : Toward a mental prosthesis utilizing event - related brain potentials , ” Electroen - cephalography Clin . Neurophysiol . , vol . 70 , no . 6 , pp . 510 – 523 , 1988 . [ 20 ] J . R . Wolpaw et al . , “An EEG - based brain - computer interface for cur - sor control , ” Electroencephalography Clin . Neurophysiol . , vol . 78 , no . 3 , pp . 252 – 259 , 1991 . [ 21 ] G . Pfurtscheller et al . , “Brain - computer interface—A new communica - tion device for handicapped persons , ” J . Microcomput . Appl . , vol . 16 , pp . 293 – 299 , 1993 . [ 22 ] N . Birbaumer et al . , “A spelling device for the paralysed , ” Nature , vol . 398 , pp . 297 – 298 , 1999 . [ 23 ] J . R . Wolpaw and D . J . McFarland , “Control of a two - dimensional move - ment signal by a noninvasive brain - computer interface in humans , ” Proc . Nat . Acad . Sci . United States Amer . , vol . 101 , no . 51 , pp . 17849 – 17854 , 2004 . [ 24 ] L . Parra and C . Spence , “Response error correction - a demonstration of improvedhuman - machineperformanceusingreal - time EEGmonitoring , ” IEEE Trans . Neural Syst . Rehabil . Eng . , vol . 11 , no . 2 , pp . 173 – 177 , Jun . 2003 . [ 25 ] A . D . Gerson et al . , “Cortically - coupled computer vision for rapid im - age search , ” IEEE Trans . Neural Syst . Rehabil . Eng . , vol . 14 , no . 2 , pp . 174 – 179 , Jun . 2006 . [ 26 ] Y . Huang et al . , “A framework for rapid visual image search using single - trial brain evoked responses , ” Neurocomputing , vol . 74 , no . 12 , pp . 2041 – 2051 , 2011 . [ 27 ] Y . Wang and T . - P . Jung , “A collaborative brain - computer interface for improving human performance , ” PloS One , vol . 6 , no . 5 , p . e20422 , 2011 . [ 28 ] M . P . Eckstein et al . , “Neural decoding of collective wisdom with multi - brain computing , ” NeuroImage , vol . 59 , no . 1 , pp . 94 – 108 , 2012 . [ 29 ] P . Yuan et al . , “A collaborative brain - computer interface for accelerating human decision making , ” in Proc . Int . Conf . Universal Access Human - Comput . Interact . , 2013 , pp . 672 – 681 . [ 30 ] P . Yuan etal . , “StudyonanonlinecollaborativeBCItoaccelerateresponse to visual targets , ” in Proc . Annu . Int . Conf . IEEE Eng . Med . Biol . Soc . , 2012 , pp . 1736 – 1739 . [ 31 ] R . Poli et al . , “Towards cooperative brain - computer interfaces for space navigation , ” in Proc . Int . Conf . Intell . User Interfaces , 2013 , pp . 149 – 160 . [ 32 ] A . Matran - Fernandez et al . , “Collaborative brain - computer interfaces for theautomaticclassiﬁcationofimages , ”in Proc . 6thInt . IEEE / EMBSConf . Neural Eng . , 2013 , pp . 1096 – 1099 . [ 33 ] R . D . Luce , Response Times : Their Role in Inferring Elementary Mental Organization . Oxford , U . K . : Oxford Univ . Press , 1986 . [ 34 ] R . Poli et al . , “Improving decision - making based on visual perception via a collaborative brain - computer interface , ” in Proc . IEEE Int . Multi - Disciplinary Conf . Cognitive Methods Situation Awareness Decision Sup - port , 2013 , pp . 1 – 8 . [ 35 ] R . Zhang et al . , “Local temporal correlation common spatial patterns for single trial EEG classiﬁcation during motor imagery , ” Comput . Math . Methods Med . , vol . 2013 , p . 591216 , 2013 . [ 36 ] H . Ramoser et al . , “Optimal spatial ﬁltering of single trial EEG during imagined hand movement , ” IEEE Trans . Rehabil . Eng . , vol . 8 , no . 4 , pp . 441 – 446 , Dec . 2000 . [ 37 ] C . S . DaSalla et al . , “Single - trial classiﬁcation of vowel speech im - agery using common spatial patterns , ” Neural Netw . , vol . 22 , no . 9 , pp . 1334 – 1339 , 2009 . [ 38 ] N . Robinson and A . Vinod , “EEG - based classiﬁcation of fast and slow hand movements using wavelet - CSP algorithm , ” IEEE Trans . Biomed . Eng , vol . 60 , no . 8 , pp . 2123 – 2132 , Aug . 2013 . [ 39 ] Y . Zhang et al . , “Regularized CSP with Fisher’s criterion to improve classiﬁcation of single - trial ERPs for BCI , ” in Proc . 9th Int . Conf . Fuzzy Syst . Knowl . Discovery , 2012 , pp . 891 – 895 . [ 40 ] D . J . Krusienski et al . , “Common spatio - temporal patterns for the P300 speller , ” in Proc . 3rd Int . IEEE EMBS Conf . Neural Eng . , 2007 , pp . 421 – 424 . [ 41 ] K . Yu et al . , “Bilinear common spatial pattern for single - trial ERP - based rapid serial visual presentation triage , ” J . Neural Eng . , vol . 9 , no . 4 , p . 046013 , 2012 . [ 42 ] Y . Tu etal . , “Single - trial detectionofvisualevokedpotentialsbycommon spatialpatternsandwaveletﬁlteringforbrain - computerinterface , ”in Proc . 35th Annu . Int . Conf . IEEE Eng . Med . Biol . Soc . , 2013 , pp . 2882 – 2885 . [ 43 ] R . Poli et al . , “Reaction - time binning : A simple method for increasing the resolving power of ERP averages , ” Psychophysiology , vol . 47 , no . 3 , pp . 467 – 485 , 2010 . [ 44 ] M . G . Philiastides et al . , “Neural representation of task difﬁculty and decision making during perceptual categorization : A timing diagram , ” J . Neurosci . , vol . 26 , no . 35 , pp . 8965 – 8975 , 2006 . [ 45 ] J . Polich , “Task difﬁculty , probability , and inter - stimulus interval as de - terminants of P300 from auditory stimuli , ” Electroencephalography Clin . Neurophysiol . / Evoked Potentials , vol . 68 , no . 4 , pp . 311 – 320 , 1987 . [ 46 ] O . Tonet et al . , “Deﬁning brain - machine interface applications by match - ing interface performance with device requirements , ” J . Neurosci . Meth - ods , vol . 167 , no . 1 , pp . 91 – 104 , 2008 . [ 47 ] D . Valeriani et al . , “A collaborative brain - computer interface to improve human performance in a visual search task , ” in Proc . 7th Int . IEEE EMBS Neural Eng . Conf . , 2015 , pp . 218 – 223 . [ 48 ] M . Peters and J . Ivanoff , “Performance asymmetries in computer mouse control of right - handers , and left - handers with left - and right - handed mouse experience , ” J . Motor Behavior , vol . 31 , pp . 86 – 94 , 1999 . [ 49 ] J . H . McClellan et al . , “A computer program for designing optimum FIR linearphasedigitalﬁlters , ” IEEETrans . AudioElectroacoust . , vol . AU - 21 , no . 6 , pp . 506 – 526 , Dec . 1973 . [ 50 ] D . Valeriani et al . , “A collaborative brain - computer interface for improv - ing group detection of visual targets in complex natural environments , ” in Proc . 7th Int . IEEE EMBS Neural Eng . Conf . , 2015 , pp . 25 – 28 . [ 51 ] B . Efron and T . Hastie , “Least angle regression , ” Ann . Statist . , vol . 32 , no . 2 , pp . 407 – 499 , 2004 . Authors’ photographs and biographies not available at the time of pub - lication .