Embodying an Interactive AI for Dance Through Movement Ideation Benedikte Wallace University of Oslo Oslo , Norway benediwa @ ifi . uio . no Clarice Hilton Goldsmiths University of London UK Kristian Nymoen University of Oslo Oslo , Norway Jim Torresen University of Oslo Oslo , Norway Charles Patrick Martin Australian National University Canberra , Australia Rebecca Fiebrink Creative Computing Institute , University of the Arts London UK ABSTRACT What expectations exist in the minds of dancers when interacting with a generative machine learning model ? During two workshop events , experienced dancers explore these expectations through im - provisation and role - play , embodying an imagined AI - dancer . The dancers explored how intuited flow , shared images , and the concept of a human replica might work in their imagined AI - human inter - action . Our findings challenge existing assumptions about what is desired from generative models of dance , such as expectations of realism , and how such systems should be evaluated . We further advocate that such models should celebrate non - human artefacts , focus on the potential for serendipitous moments of discovery , and that dance practitioners should be included in their development . Our concrete suggestions show how our findings can be adapted into the development of improved generative and interactive ma - chine learning models for dancers’ creative practice . CCS CONCEPTS • Applied computing → Performing arts ; • Human - centered computing ; KEYWORDS generative AI , embodiment , reflexive thematic analysis , dance ACM Reference Format : Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink . 2023 . Embodying an Interactive AI for Dance Through Movement Ideation . In Creativity and Cognition ( C & C ’23 ) , June 19 – 21 , 2023 , Virtual Event , USA . ACM , New York , NY , USA , 11 pages . https : / / doi . org / 10 . 1145 / 3591196 . 3593336 1 INTRODUCTION Generative artificial intelligence ( AI ) has over the last five years seen substantial improvements in creative fields such as visual arts [ 26 ] and music [ 14 ] . Today , generative AI models like DALL - E 2 [ 47 ] and This work is licensed under a Creative Commons Attribution International 4 . 0 License . C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 979 - 8 - 4007 - 0180 - 1 / 23 / 06 . https : / / doi . org / 10 . 1145 / 3591196 . 3593336 GPT - 3 [ 9 ] have made it possible to generate detailed visual artworks or write a lengthy text on a topic of one’s choice without requiring prior skill or knowledge with AI , visual art or creative writing . While the potential of these models can be viewed as a means of democratizing artistic fields , there also exist concerns among the creative practitioners in these fields regarding their future job security [ 30 ] . Dance communities have so far not been affected in the same way , but the availability of large datasets of dance movements [ 35 ] and recent improvements in generative AI indicate that the generation of highly realistic and versatile dance movement without the aid of animators or dancers is not far behind . However , exactly how dancers themselves might want to use generative AI is not yet so clear . In this work , we employ a practice - based approach with elements drawn from speculative design to examine what a group of dance practitioners and choreographers might expect and want from working with a generative model of dance . Including creators in the development and evaluation of genera - tive models is an important aspect of creating useful and interesting creative AI [ 56 ] . But as of today , there are still various computa - tional bottlenecks that make real - time interaction with a generative movement model impractical . These include post - processing of motion capture data , the inference of the generative model as well as visualisation of the output . State - of - the - art movement models are still developing when it comes to generating output that can achieve the realism and expressivity of human dance [ 35 ] . To examine the potential future of generative AI as a tool for dancers in the process of dance creation , we therefore chose to forego the use of any AI model in our study , instead utilizing role - play and generalising the concept of a potential generative AI with the term AI - dancer . In our workshops , the participants themselves take on the role of an AI - dancer and are paired with a human coun - terpart for whom they are asked to act as a creative catalyst in an improvisation task . The workings of such a dance model are intentionally left mostly open to interpretation by the participants beyond the idea that the model can observe the movements of a dancer and respond with movements of its own . The participants’ embodiment of this imagined AI - dancer allows us to bring about discussions with participants around what the aim of a movement generation model for dance should be without limiting their reflec - tions to a specific technology or approach . When it comes to bodily practices , insights are partly embodied and can be challenging to put into words [ 18 ] . Having participants embody the AI themselves by taking on the role of an imagined AI - dancer in collaboration 454 C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink with a human partner can illuminate which aspects of AI in dance should be prioritized in the future development of interactive and generative tools . This paper presents the findings from two workshop events de - signed to explore what expectations , hopes and fears exist in the minds of the participants regarding the use of generative AI in the process of dance creation . While building on an extensive back - ground in the study of technology in dance , this work presents to our knowledge the first use of an embodied variant of specula - tive design in exploring emerging generative AI methods in dance practice . This work provides insight into an embodied view of gen - erative AI for dance that exposes the importance of the concepts of intuition , shared images and surprise . In the following sections , we present our workshop design including bodystorming sessions and discussions with participants . Through our reflexive thematic analysis , we shed light on elusive moments of ideation , identifying challenges that might arise when human dancers translate their practices with other people into interactions with AI . We then present suggestions as to how these idea - inspiring interactions between participants during improvisation might be approximated or augmented using AI , describing how some of the dancers’ expe - riences and goals might be translated into new types of technical formulations for dance AI systems that go beyond simple mimicry of human motion patterns . 2 RELATED WORK Human - computer interaction in dance goes back several decades , with pioneers such as choreographer Merce Cunningham taking part in the development of software for visualising dance in the 1980s [ 52 ] . With the proliferation of machine learning in more recent years , we have seen growth in the field of computational support for dance [ 62 ] . Research into AI systems in the context of movement practices shows great promise for the use of AI in inter - active installations using gesture recognition [ 28 , 32 , 36 ] , analysis and classification of movement qualities [ 17 ] or mapping movement to the control of various media such as sound and video [ 16 , 45 ] . In this work , we will focus on generative AI . Generative AI is not a single kind of neural network architecture or method . Rather it refers to a way of using AI to create , wherein the AI itself produces an output which is similar , but not identical to its training data or learning environment . Specifically , we will focus on data - driven generative AI . In this way we aim to differentiate between program - matic generation of dance [ 43 ] and models which learn to generate dance from dance datasets , with little or no interference from a human being . It is this data - driven approach to generative AI which has seen immense advancements in image and text generation over the last 5 years and recently also within dance generation , from the work of Crnkovic et al . [ 13 ] in 2016 to the recent publication by Li et al . [ 35 ] presenting a generative model for dance which can produce realistic dance movement in a variety of styles . One of the benefits of data - driven deep learning models is their ability to learn complex correlations in the data without the devel - oper of the system having to decide on explicit mappings between the model’s input and what it generates . Instead , the model learns these mappings , or an approximation of them , from the data . While these data - driven dance generation systems are currently some - what slow ( compared to the near instantaneous responsiveness of a human dancer ) and require large datasets , we are likely on the cusp of seeing data - driven generative models in real - time interactive applications . Many generative movement models are imagined to be used to automatically generate choreography for virtual avatars such as Hatsune Miku [ 41 ] or to produce expressive emotes in games [ 34 , 35 ] . Another commonly cited future goal for AI - generated dance is for use in dance creation and performance [ 5 ] . However , the ways that different dance communities might themselves wish to use such methods , and the criteria against which they would evaluate an AI - dancer’s quality and usefulness , are not yet clear . The most widely adopted methods for evaluation of generative movement models consist mainly of quantitative metrics such as preference ratings [ 60 ] , beat synchronicity and comparisons to other models [ 35 ] . While these methods shed light on the models’ abilities to generate realistic dance movements , a closer engagement with dance practitioners is needed to better understand generative AI’s potential use in a dancer’s creative practice . Previous work on technology’s effect on kinaesthetic creativity [ 27 ] ( the body’s ability to enact alternate future possibilities through movement ) provides insights into the importance of awareness around how different aspects of a technological paradigm can affect the users’ creative flow [ 11 ] . In Sturm and Ben - Tal’s work [ 56 ] on bringing generative music models back to practitioners , they argue for a multifaceted approach to evaluating a generative model for use in co - creation . Having creative practitioners engage with emerging technologies through experimentation and discussions [ 19 ] can lead to unexpected insights into the opportunities and challenges presented by AI systems that quantitative measures can not capture . As there exist a multitude of methods , datasets , and models—as well as few if any suitable real - time generative models to work with—we propose that a practice - based role - playing scenario using methods from speculative design might allow us to probe dancers’ experience without the limitations of the current state - of - the - art models . In speculative design , fiction and potential futures are used to explore emerging technologies [ 2 ] and possible future research areas [ 37 ] . By engaging participants of our study in embodiment ex - ercises and discussion we employ elements from speculative design to develop a critical discourse about the future use of generative AI in dance . 3 METHODS AND MATERIALS 3 . 1 Participants We held two workshops , the first in London , England and the sec - ond in Oslo , Norway . Six dancers ( 4 female , 2 male ; average age 29 . 83 ) took part in the workshops , three in each event . Participants were recruited through several online channels such as mailing lists and our personal network . They were not compensated for participation but were supplied with food and beverages during the event . Prior to the workshop participants filled in a form describing their age , gender , years of dance experience and preferred dance style . Participants all have extensive experience in dance , both as performers and dance composers ( average years of experience 17 ; 455 Embodying an Interactive AI for Dance Through Movement Ideation C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA standard deviation 11 . 37 ) . All participants noted an interest in con - temporary dance , but several also reported various other styles such as Turkish folk dance , jazz , and dance theatre . Participants were also asked to what degree improvisation plays a role in their creative practice , to which all responded it was an important part . The participants’ responses are detailed in Table 1 along with the participant ID number used throughout this paper . 3 . 2 Workshop structure During each workshop , participants took part in an introduction to the workshop and generative AI models for dance , and two bodystorming sessions with discussion sessions in between . Each is detailed further in the following sections . The workshops took place over approximately 4 hours each with 5 - 10 minute breaks between bodystorming sessions and a 30 minute break for lunch . 3 . 2 . 1 Introduction session . The workshops began with a 30 - minute presentation describing the first author’s previous work on move - ment generation models . Participants were shown how the gen - erative movement models were trained and what their generated output may look like ( see Figure 1 ) . This allowed for a shared base - line of understanding of the current state of generative models in dance before participants began the bodystorming activities . Specif - ically , participants were shown examples of output generated by a mixture density recurrent neural network ( MDRNN ) trained using a supervised learning approach on an open access dataset containing 164 one - minute motion capture recordings of improvised dance [ 61 ] . The MDRNN is a sequence prediction model which combines a recurrent neural network consisting of LSTM cells [ 25 ] and a Mixture Density Network ( MDN ) [ 4 ] . This modelling approach allows for a large variety in the generated data and has previously been applied to musical sketches in two dimensions as part of a smartphone app [ 40 ] , to sketches [ 24 ] , handwriting [ 23 ] , as well as motion capture data [ 59 ] . The introduction session focused on giving participants a general understanding of how an AI - dancer can be constructed by learn - ing to estimate future movement based on a dataset of examples and observations of the current input . It was not a requirement for participants to understand the inner workings of an MDRNN or any other data - driven approach to movement generation . As part of this general overview , we also discussed what the AI - dancer actually “sees” when learning to generate a movement sequence . As dance involves multifactorial sensing of the environment , the space , other bodies or objects , sounds , and one’s biological affor - dances and limitations , a complex interweaving of past and present impressions affect the movements a dance artist conveys during improvisation and choreographic exploration . The current state - of - the - art movement generation models naturally do not have this complex sensory capability or inner life to draw inspiration from . Instead , most movement generation models receive a series of joint positions or similar positional information created using motion capture data or extracted from video as their input . Such a model can not “see” facial expressions , skin or clothes . All it has access to is the movements of a skeletal representation of the dancer . By discussing the view of an AI - dancer’s “perspective” , we invited the dancers to connect with how the sensory , somatic aspects of their experience impact their improvisation . 3 . 2 . 2 Bodystorming session . In the bodystorming session , dancers were invited to explore the process of improvisation in the context of dance creation through embodiment exercises . The participants were asked to take turns taking on the role of the AI , receiving input in the form of movement from their partner and responding in the way they might expect or hope a generative AI would respond to inspire and further innovation . The participant currently role - playing as the AI was given a coloured headband to represent their role as the AI - dancer , and the other took on the role of the human input to the AI . As there were three participants in each workshop , one would observe while the other two were moving . When the current improvisation ended the observer would take the place of one of the pair . This way each person experienced both roles , AI - dancer and human input , in each of the two bodystorming sessions . Improvisation plays a large role in the creation process for many contemporary choreographers [ 49 ] and is a familiar practice for the participants . As opposed to other improvisation settings , the dancers here have two clear roles . The role of AI implies that the dancer should produce movements to provide inspiration and con - tribute to the ongoing improvisation led by their partner . We ex - plored this dynamic of embodying AI using two exercises , both intended to mimic common ways we imagine AI being used by dancers and choreographers in the ideation stage of dance compo - sition . We also asked participants to imagine the AI - dancer as a visualisation projected onto a wall or on to a movable screen instead of having a physical body . While using a free exploration approach to the bodystorming exercises could reveal interesting views on the form and use of an AI - dancer , this more structured approach allows us to root the exercises in the not - so - distant future . The first exercise was a motion continuation exercise . Here , each participant acting as the AI would observe a short movement se - quence produced by their partner and would attempt to complete the movement sequence . This exercise imitates one way in which the movement repertoire of a trained model might be used , by prompting a trained model using a movement sequence and having it predict the continuation of the sequence . The second exercise was a pair improvisation of free movement . In this exercise the participant embodying the AI should take inspiration from their partner’s movement and respond in a way they feel would comple - ment their partner’s performance . This exercise mimics how one might use a generative AI for improvisation in real time . Each pair spent between 5 and 10 minutes in improvisation before switching roles . Each exercise thereby lasted around 25 minutes . 3 . 2 . 3 Discussion session . After each movement exercise , partici - pants were invited to reflect on the bodystorming experience . These sessions were loosely structured to precipitate reflection on the movement exercises . We aimed to promote discussion around how an AI - dancer might play a role in their practice as well as explore what aspects of the interactions participants felt worked well and which worked less well . The following non - exhaustive list of ques - tions was used to guide our discussions : • What do you find most important in how your partner ( the AI - dancer ) responds to you ? • If you have previous experience with group / pair improvisa - tion , what aspects make such co - creation sessions successful or unsuccessful ? 456 C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink ID Age Experience Preferred styles P1W1 29 10 Contemporary dance , dance theatre , communitarian dance . P2W1 39 > 30 Modern and contemporary . P3W1 39 > 30 Turkish folk dance , tap dance , lindy hop , contemporary , Laban / Bartenieff Movement practices P1W2 34 > 20 Contemporary , modern and jazz P2W2 20 6 Contemporary dance P3W2 18 8 Contemporary jazz Table 1 : All participants responded to a questionnaire at the beginning of the workshops . This table details their self - reported experience , age and the dance styles they were most interested in . ( a ) Training a movement model with supervised learning ( b ) Examples of generated movement sequences Figure 1 : During the introduction presentation , participants were shown how a generative AI model was trained and what movements it learned to produce . • As the AI - dancer , where was your attention focused on the other person ? • Do you have any thoughts on how a generative AI could be useful to you in your practice ? 3 . 3 Data collection The movement and discussion sessions were recorded using two video cameras mounted on tripods . The videos from the London workshop were automatically transcribed using YouTube’s auto - matic captioning function applied to privately uploaded videos and manually reviewed by the authors before removal from YouTube . The discussion sessions in Oslo were held in Norwegian . Videos from these sessions were transcribed and translated by the first au - thor . We also took notes during both discussion and bodystorming sessions . The data was stored on encrypted servers according to local data security practices . 3 . 4 Data analysis For analysis , we chose to use a reflexive thematic analysis ( R - TA ) approach [ 7 ] . R - TA allowed the authors to develop and interpret patterns in the qualitative dataset while drawing on our own experi - ences and knowledge . The discussion session transcripts were coded by the first author using an open - coding scheme . Then , the analysis was performed through the following steps : first , the transcripts were read through several times to get a sense of their content . This was followed up by iteratively assigning codes to each tran - script . As new codes arose , the previously coded data was reviewed again until no new codes were added . This resulted in 34 initial codes . A systematic grouping of these codes into categories and sub - categories was performed , resulting in 6 code groups : Improvi - sation strategies , introspection , challenges for an AI - dancer , what is wanted from an AI - dancer , affecting an AI - dancer and curiosity about AI . A final revision of all transcripts ensured that the latest codes were sufficient to cover the data in all transcripts . The code groups , their descriptions and example quotes were then reviewed and discussed by the authors . Analysis was primarily conducted by the lead author , a PhD researcher working in AI generated dance movements but not a dance practitioner . Through engaging with the data from coding , three themes were conceptualized . These are presented in the following section . The video recordings of the bodystorming sessions were also revisited during the analysis of the transcripts to examine specific moments referred to by participants but were not further analysed . Partic - ipants’ identities were encoded by number and workshop ID to 457 Embodying an Interactive AI for Dance Through Movement Ideation C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Figure 2 : A group discussion was held between each bodystorming session . reflect their participation in the London ( 1 ) or Oslo ( 2 ) workshop . P1W1 thereby refers to participant 1 in the London workshop . 4 REFLEXIVE THEMES We define three themes through the process of reflexive thematic analysis . The first theme , beyond replica , relates to the concepts of embodied experience and the potential associated with an AI - dancer which produces artifacts that are beyond human ability . Our second theme is intuiting flow , encapsulating the dancers’ descrip - tions of elusive moments of non - verbal communication that allow them to predict their partners’ intentions and the challenges this may introduce for an AI - dancer . Lastly we introduce the theme building and breaking shared images to describe how participants’ experiences and culture allow them to build rapport with one an - other as well as surprise each other by deviating from their partner’s expectations . This theme in many ways lies at the cross - section of the two prior themes and reflects their interaction . Figure 4 shows how we link the most prominent discussion topics distilled from the coding process to the themes presented below . 4 . 1 Beyond replica “Does the AI get tired ? Tiredness changed the way of movement , the rhythm and the expression . And that gives the next step for the choreography . ” - P1W1 This theme aims to encapsulate the concepts relating to the body and the limitations and affordances participants envision when interacting with a non - human form . Many of the concerns the dancers expressed are closely related to an AI - dancer’s lack of embodied experience . One participant points out how their bodily experience becomes part of the improvisation in meaningful ways . Participants question how exhaustion , restrictions in physical space and the occurrence of mistakes could be fully exploited by the AI the way it is by humans : “ [ . . . ] to make mistakes [ is ] important in the creative process . And I feel like AI usually tries to find the correct answer [ . . . ] ” - P2W1 . An AI - dancer , trained to generate stylistically perfect and increasingly realistic movement sequences , might be a poor reflection of the way human dancers learn , create and explore movement . Perfection and precision are not necessarily the source of creative inspiration , nor the aim . As one participant explains it : “ I always believe that we need to make mistakes . And [ . . . ] when I saw this [ referring to the training of the AI ] you improve it and then the AI is going to be better . I feel like , yeah that’s the idea of human progress , but on the other hand it’s like why do we need to think like this ? ” - P2W1 Exactly how the participants should imagine the AI - dancers’ presence in the physical world was discussed in the workshop introduction sessions . Participants were asked to imagine the AI - dancer as a visualisation on a large screen . This impacted their improvisation in various ways . Participants did not touch each other , and spent the majority of time facing each other as though separated by a screen . The lack of a physical body , with its innate limitations , is also seen by the participants as a possible affordance of an AI - dancer . As one participant explains : “ Our body is our freedom but at the same time it’s limited , it’s our limitation . ” - P3W1 While the embodied experience of the dancers shapes their interactions and experience there are some interesting possibilities afforded by the AI - dancer not conforming to the bio - mechanical limits or shape of a human body . Some of the mistakes the AI - dancer makes may break with what is possible for a human , such as limbs growing or shrinking and distorting into strange angles and shapes . As the participants point out , this does not need to be a hindrance , instead , it can invite the dancer to attempt to translate these abstract shapes or impossible movements into their bodies : “ Even if it is bio - mechanically not possible to produce , we as an artist get a lot of inspiration just by seeing that ” - P1W1 . These observations prompted further reflections in the authors’ discussions regarding the utility of AI as going beyond replica . An AI - dancer does not need to always look human , and several of the participants mention wanting the AI to “ go beyond that ” - P3W1 . While co - creating with someone who has a similar movement reper - toire as oneself may be “ frictionless ” - P1W2 and feel “ safe ” - P3W2 , the challenge introduced by collaborating with something alien 458 C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink Figure 3 : The dancers pair up and move together in an improvisation task where one participant ( wearing a colored headband ) takes on the role of an AI - dancer , reacting to the input of their partner . can be a source of innovation . As participant P3W2 notes when discussing the AI generating movements that would not be possible to mimic : “ I would take that as a challenge . ” The body forms a lens through which the many possible movements appear . Any poten - tial movement is filtered through this lens of the physical body , its limitations and affordances . In the participants’ discussions , we discover a concern about how they would be able to relate to an AI - dancer given the AI’s lack of a body . The dancers express a feeling which seems akin to alienation when talking about how an AI would not have access to many of the sensory experiences that form the dancers’ improvisation . Simultaneously , we encounter in the participants a curiosity for what kinds of movements might arise from an agent which does not necessarily share our physical limitations . 4 . 2 Intuiting flow “It happens all the time when you move together , you read the intention before movement comes” . - P3W1 Our second theme emerges from the many moments of intuition , kinaesthetic awareness and the lightning - fast prediction that are displayed by the participants during their improvisation . While the first movement prompt ( in which the AI - dancer continues the movement begun by the human input ) resulted in participants standing facing each other throughout most of the improvisation ( without having been given explicit directions to do so ) , the dancers utilised the space in new ways during the second session ( in which AI - dancer and human improvise together ) , changing their orienta - tion and at times not facing each other . Still , despite the increase in activity and loss of eye contact , the participants were able to inter - pret their partner’s movements and co - create . As one participant explained : “ I didn’t need to see the full movement that she performed to understand what she would do next . ” - P1W1 Other senses such as sound and kinaesthesia play a role in their communication : “ by the first less - than - second that I saw her , or I felt her energy , I know what she will do . So I can follow ” - P1W1 . Participants describe tuning in to their partner’s movement intentions , a skill which is fundamental in improvisation and emerges through training and experience . It was difficult for the dancers to explain exactly their predic - tions of their partner’s intentions as well as their own internal decision - making process . As one participant expressed it : “ we can - not consciously understand it , but still at the moment that we intend to do something , in our energy level , it can be flow or weight , at any time something is changing . That’s why we can understand ” - P3W1 . The lack of conscious decision - making is crucial to upholding the flow of the improvisation due to the speed at which the interpretations are happening . Participant P3W1 clarifies : “ You have to somehow learn not to think about [ your actions ] , but to act intuitively . To train your senses , train your intention , attention and everything . Because it happens in maybe less than a second ” . The goal of this approach is further explained by another participant as a means to uphold the flow , or rhythm , of the improvisation : “ [ . . . ] if we have to name something as an aim , as an objective , I would say it is to not drop the rhythm that we are building ” - P1W1 . The terms “ uphold the flow ” and “ don’t drop the rhythm ” were used by participants to explain what they were experiencing when trying to keep the improvi - sation moving . One of the ways the participants did this was by intuiting their partner’s movements . This intuition often relies on eye contact , but when their partner is not in view the participants explain that the sound of their partner played an important part of determine their energy . The participants also describe “ filling the empty space ” - P1W2 left by their partner’s movements . This may refer to concrete assumptions such as observing their partner moving a limb upwards indicating that their next steps will involve moving that limb downwards , but it is also referred to as a more intangible sense of what is “missing” in the improvisation . The dancers report that , in the moment , they are not fully con - scious of how they are making creative decisions . The skills in - volved in the improvisation process are acquired through years of training , practising awareness of the space , their partner’s energy , intent and their own body . Several comments were made clarifying that while their choice of words seemed to imply something meta - physical , they did not necessarily mean that this was the case , but that the experience in some ways defies explanation . Participants are aware of the challenge of formalising these tacit experiences in a way that could be useful for developing an AI - dancer . Participant P1W1 concludes with the following : “ [ . . . ] so imagine how to teach that to AI . Because I think I am not even able to explain what we are [ doing ] ” . 459 Embodying an Interactive AI for Dance Through Movement Ideation C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Figure 4 : We distil three themes , intuiting flow ( in yellow ) , beyond replica ( in blue ) and building and breaking shared images ( in green ) . This image gives an overview of the most prominent concepts related to each theme . The concept of shared imagery lies in the cross section , affected by both the notion of prediction , inherent to intuiting flow , and the novelty that emerges from going beyond replica . 4 . 3 Building and breaking shared images “We take each other’s movement languages and sort of make them our own . ” - P2W2 Ourfinalthemedescribesthecomplexactofcommunicationthroughmovementthatparticipantsdisplayedinthebodystormingsessions . This is perhaps most clear in the participant’s descriptions of shared images . These images exist in the mind of the dancer , having been formed by their experiences through , and separate from , dance . Their interactions consist of an ongoing communication of these images . In some interactions , these shared images stem from pop - culture references , shared history or even internal jokes . However , an important aspect of the participants’ improvisations was how they chose to interpret their partner’s movement , either symbol - ically , accepting their partner’s image , or purely kinaesthetically , without taking into account the historical or social connotations of the movement . These choices are personal , immediate and sub - jective . These shared images and individual interpretations are inseparable from the dancers themselves , as participant P2W1 puts it : “ what we created right now , it’s not separated from who we are or our background or how we grow up . We have all our own memories and everything , it’s subjective . It’s so personal and individual ” . While observing both bodystorming exercises , we noted that the dancers were frequently using strategies of mirroring and shadowing simi - lar to how these concepts are explained by Blackwell et al . in the context of musical co - improvisation [ 6 ] . The dancers would move in similar ways , but would rarely mimic their partner’s movements directly . Instead , their movements were often inspired by their part - ner , taking on certain characteristics such as the trajectories of the arms or mirroring their use of space , but altering it in a way to bring some new aspect into play : “ I try to really capture something , but out of it I try to do something new ” - P3W1 . For example , this could be seen when one participant created long lines with their arm movements which were then transferred to their partner’s movements but shifted from arm movement to movement of the feet . One challenge here is to achieve a balance between the novelty of a dancer’s movements and likeness to what their partner was already doing , as pointed out by P1W1 : “ My aim as an AI was to give something new , probably not surprising , but it was something new , an expansion of that input ” . This strategy of mirroring and expan - sion lead to a pull between converging and diverging movement similarity . In both roles , the dancers found themselves consciously or unconsciously incorporating elements of their partner’s move - ments . 460 C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink Many interesting moments of humour and play arose through the process of building and breaking these shared images . For exam - ple , participants elaborated on their partner’s perhaps unintended movements in a way that would distil certain aspects and exag - gerate them . In one such moment , participant P3W1 assumed a specific position and noted “ [ . . . ] immediately for me it was like a two - dimensional image , like Egyptian culture and then my next move - ment immediately was something related to Egyptian dance . [ . . . ] I was aware that an AI probably will not take that input , but as a human , I did [ . . . ] . ” Two of the participants further pointed out how they became aware of all the shared references , or “common images” , they have with each other . Participant P2W1 explained : “ We have common images that we share with each other from our history and who we are and this keeps evolving . ” She went on to summarize this as “ the AI is reacting , but not maybe looking for a communication , that’s a human thing . ” . While the AI may be able to measure a mul - titude of movement qualities and features , “ [ . . . ] still it’s not enough to create the image that we can perceive ” - P3W1 , participants raise doubts regarding whether an AI would ever be able to learn this : “ as humans we have emotions and stories of things that are happening to us when we want to dance and that isn’t happening to the AI , or maybe it is , but I think it’s not . ” - P3W1 While the above points indicate that the familiarity which devel - ops through communication between two individuals is an essential aspect of the improvisation and creation process , many interesting moments occurred when the expectations of a shared image were proven wrong . This moment of surprise seems to reset the impro - visation or shift its direction . The ability of their partner to be able to take their improvisation in a new direction was appreciated and used both as a strategy in their improvisations and presented as one of the elements that made an improvisation enjoyable . The partici - pants themselves were the ones to decide when to end a particular improvisation session and when to change roles . This allowed us to explore what made them decide that they were done . In one ses - sion , after a few minutes of improvisation , one of the participants in the role of input proclaimed that they were “ empty ” - P2W2 . In the following discussion session , we prompted the participant to reflect on what their AI - embodying partner could have done to keep the improvisation going . “ [ . . . ] If [ P3W2 ] brought something completely new , almost like do the opposite of what I would do , then maybe more inspiration would come . ” The concept of novelty was mentioned explicitly by both groups as a crucial part of what their partners can contribute to open “ a way out when you are out of creativity ” - P1W2 and avoid getting stuck “ in a loop ” - P3W1 . 5 IMPLICATIONS FOR GENERATIVE AI IN DANCE We turn to examine our findings in the context of current methods in generative AI for movement and identify some concrete areas of focus for the development and use of generative AI in dance practice . We then discuss the limitations of this study and suggest future research directions . 5 . 1 Predictability and surprise Novelty is a central aspect of our understanding of creativity , both in humans and in computer systems [ 51 , 53 ] . A necessary counterpoint to novelty and surprise is the notion of predictability . Participants build a rapport which we describe as a shared image , an understand - ing of what they are creating together . This shared image helps the participants predict what their partner might do next and where the improvisation is going . The complex interaction between the dancers , their interpretations and their shared experience pinpoints some interesting potential obstacles for generative AI in dance—in particular , the challenge of teaching an AI to emulate the dancers’ accumulation of experiences and the individual idiosyncrasies they foster . Training an AI - dancer on a single dancer’s archive , making it true to the individual’s movement repertoire—similar to what has been done within AI - generated drum patterns [ 58 ] , musical control interfaces [ 38 ] and embodied instruments [ 39 ] —could increase the likelihood that the AI - generated movements are familiar in the images they might communicate to the dancer [ 44 ] . Participants further describe that their interpretations of their partner’s movements can be either literal or coloured by culture and association . Allowing users to shift the AI - dancer’s interpre - tation of a movement sequence from cultural interpretations to quantitative interpretations during improvisation would be an in - teresting feature for an interactive AI - dancer . We can imagine an AI - dancer trained on a rich archive of dance styles and traditions to be able to recognize the similarity between a given pose and its semantic , ethnographic roots in addition to recognising physical similarities between poses . This would however require the con - struction of a larger and more varied dance dataset than what is currently available , for example by combining data sets such as the AIST dance database [ 57 ] , which contains examples of hip hop , ballet jazz , waacking and more , with smaller datasets such as folk dance datasets [ 1 ] . Additionally , this would require annotation of these datasets using methods for measuring both content similarity [ 42 ] and similarity in movement quality [ 17 ] . The ability to surprise their partners by changing the shared im - age and thereby the “direction” of the improvisation is a reoccurring topic in the dancers’ descriptions of what keeps them interested in the interaction . This change in direction , or “flow” , may manifest in various ways , through amount of movement , shifts in dynamics and energy or use of space . When participants are able to surprise each other and change the “shared image” of the improvisation , it injects new energy into the interaction . If an AI - dancer could extract salient aspects of a dancer’s movement and expand on it in surprising ways , perhaps these serendipitous moments could also be brought about in human - AI interaction . Creating an AI - dancer that avoids too much imitation and repetition seems more likely to produce an engaging creative input for the dancer . 5 . 2 Leveraging AI glitches While the potential for AI to be non - human in its movements and shape is seen partly as a challenge , it is also seen as a positive aspect . When imagining a collaboration with an AI - dancer , the participants express a desire for an AI - dancer which exploits its non - humanness in favour of an AI which is a mere replica . As one participant put it , it would be a “ waste ” to have a non - embodied agent be constrained by similar physical limitations as humans . This further ties into the notion of mistakes having value . When the participants experience fatigue or simply misstep , these unintentional movements shape 461 Embodying an Interactive AI for Dance Through Movement Ideation C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA the improvisation , sometimes in ways the participants appreciate . The mistakes can cause a break in the flow of the improvisation , allowing it to shift and making room for new directions . The idea that an AI - dancer would be trained with the aim of achieving per - fect mimicry is seen by participants as less interesting for their practice and potentially as a threat to their craft . The training of any AI necessarily requires some measure of quality or a goal state to be defined . Our theme beyond replica challenges the view that a high - fidelity replica of a human dancer should be the goal for a generative model of dance . Instead , the potential for an AI - dancer to produce non - human movements sparks the imagination of the par - ticipants . Approaches such as hierarchical reinforcement learning [ 31 ] attempt to model the intrinsic motivation inherent in curios - ity . These approaches could lend themselves better to producing models that prioritise novelty and challenge our expectations . To transform the impossible movements produced by an AI - dancer into something the body can do , an expansion of interpreta - tion is required as the dancer must attempt to translate the abstract movements through their bodies . In this way , the process would be similar to how dancers and performance artists might use inanimate objects in performances or their creative process [ 20 ] . Exploiting an apparent limitation or boundary to promote creativity as with Oblique Strategies by Brian Eno and Peter Schmidt [ 15 ] is a familiar strategy in many creative fields . When interacting with strange virtual agents [ 3 ] , or bodies with unfamiliar morphologies [ 22 ] we can experience a broadening of our own movement qualities . Leveraging the absurd nature of AI - generated art has also been explored in other contexts , such as text generation [ 54 ] . The task of co - creation with an unpredictable and strange agent becomes transmodal , as the dancer must attempt to imbue the artefacts with meaning and movement . This transmodality can be likened to tasks such as converting text to images [ 48 ] , or creating drum patterns using a Chopin étude [ 55 ] . Rather than merely teaching AI to emulate human dancers , more valuable interactions with generative AI could involve the gen - eration of unexpected and even unrealistic movement sequences . Leveraging the model’s lack of physical restraints may give rise to novel moments of inspiration and prove to be one way that generative AI can contribute to a dancer’s creative practice . 5 . 3 Intangible moments In our discussion , there were many occasions where the participants struggled to put into words exactly what they were thinking and why they responded the way they did to their partner , simply explaining that they were acting on intuition . These intangible moments of interpretation and response are made possible due to the participant’s years of improvisation practice . Bresnahan [ 8 ] describes improvisation in dance as embodied and extended agency , referring to Clark’s embodied and extended mind theory [ 12 ] . The complexities involved in formalising these interactions are a clear challenge for building an AI - dancer that can foster kinaesthetic creativity and contribute to dance creation . The most common approach to evaluating AI - generated dance is through audience ratings of pre - generated video clips , not through real - time interactions . While ratings and comparison are arguably good approaches for comparing model performance [ 34 ] or un - derstanding audience perception of AI - generated movement [ 60 ] , our theme of intuiting flow suggest that bringing the dancers and AI - dancer together in movement is essential in getting access to these nameless , embodied perspectives that are inherent to the experience of creation and interaction in dance and can be difficult to articulate or describe algorithmically . The intuitive responses between participants point to obstacles for an AI - dancer which go beyond the technical challenges of real - time feedback and large , var - ied datasets . It points to the importance of the enactive , embodied experience inherent to the dancers’ interactions . The implications of an enactivist philosophy of mind [ 21 ] applied to generative AI may take the form of additional sensor data and the development of mappings between this data and meaningful dimensions of the generated movements [ 29 ] . Bringing the dancers into the development process through the choice of a generative model , its input parameters , training data and visualisation would further allow insight into the expressive nature of dance . The results of such research can also prove beneficial in human - robot interaction and the development of virtual agents [ 10 , 33 ] , as the ability to efficiently convey emotions through expressive movement may aid in establishing trust . 6 LIMITATIONS AND FUTURE WORK An important aspect to consider in using methods from specula - tive design is that it is impossible to completely separate our ideas about the future of technology from our ideas about the present state of that technology . Discussions with participants are undoubt - edly coloured by their existing biases towards AI , both positive and negative . The participants were aware that the workshops would centre around AI - generated dance and while none of the participants reported previous experience using dance - generation systems . However it can be presumed by their choice to participate in the workshop that they have some interest in the topic of AI and technology in dance . From this we might assume that the par - ticipants are largely open to the idea of AI , or at least technology , having a place in dance practice . As AI - generated dance becomes more flexible , realistic and available the way text and image gener - ation has , we may see a shift in sentiment towards integrating AI into dance practice . The potential dichotomy between technology and the embodied , ephemeral nature of dance has been at the centre of several debates [ 46 ] , and it is easy to imagine that an influx of generative AI for dance would be met with critique from many dance communities and scholars . There is in general a lack of longi - tudinal studies on tools for ideation and enhancing creativity [ 50 ] . As such , we hope to extend this work to examine the sentiment towards AI - generated dance across diverse dance communities as technology evolves . We further acknowledge that the relatively small amount of participants in this work causes limited perspec - tives . Future work involving more participants may reveal different results . 7 CONCLUSION This work aims to explore the participant’s expectations , hopes and fears regarding generative AI in dance . Through examining this , we hope to clarify how a generative movement model could play 462 C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA Benedikte Wallace , Clarice Hilton , Kristian Nymoen , Jim Torresen , Charles Patrick Martin , and Rebecca Fiebrink a part in the creative practice of dancers . Participants graciously shared their insights allowing us to gain a better understanding of how dancers would want to interact with generative AI . Through embodying AI in speculative ideation and discussion , we identify various challenges that can arise when human dancers translate practices with other people into interactions with an AI - dancer . By implementing an embodied variant of speculative design we gained access to the participants reflections on an emergent branch of generative AI dance . This approach proved beneficial to study the experience of engaging with nascent technologies . Our findings result in the development of three themes , intuiting flow , beyond replica and building and breaking shared images . The subsequent implications for generative AI in dance practice can be summarised as the following three points which we consider to be of particular importance to the future development of interac - tive and generative AI models of dance : Leaning into the potential non - human artefacts created by AI - generated dance , developing systems that allow for serendipitous moments of discovery and bringing dance practitioners into the process of developing and evaluating generative movement models . Leveraging these concepts would not be possible without the facilitation of interdisciplinary forums . Bringing together creative practitioners and AI develop - ers through interaction and reflection sessions can be beneficial for both parties . In addition to improving current approaches in generative and interactive AI , it also brings practitioners in “under the hood” of AI , increasing their understanding of how the models work . This could empower practitioners to influence the develop - ment and use of AI in creative domains , bridging the gap between art and technology and perhaps furthering both . ACKNOWLEDGMENTS The authors would like to thank the participants for contributing their time and insight . We would also like to thank the reviewers who through their feedback have improved this work . This work was partially supported by the Research Council of Norway through its Centres of Excellence scheme , project number 262762 . REFERENCES [ 1 ] Andreas Aristidou , Efstathios Stavrakis , and Yiorgos Chrysanthou . 2012 . Dance Motion Capture Database of the University of Cyprus . University of Cyprus . http : / / dancedb . cs . ucy . ac . cy [ 2 ] JamesAuger . 2013 . Speculativedesign : craftingthespeculation . DigitalCreativity 24 , 1 ( 2013 ) , 11 – 35 . [ 3 ] Alexander Berman and Valencia James . 2015 . Kinetic dialogues : enhancing creativity in dance . In Proceedings of the 2nd International Workshop on Movement and Computing . ACM , 80 – 83 . [ 4 ] Christopher M . Bishop . 1994 . Mixture density networks . Technical Report . Aston University , Birmingham , UK . http : / / publications . aston . ac . uk / 373 / [ 5 ] Daniel Bisig . 2022 . Generative Dance - a Taxonomy and Survey . In Proceedings of the 8th International Conference on Movement and Computing . ACM , 1 – 10 . [ 6 ] Tim Blackwell , Oliver Bown , and Michael Young . 2012 . Live Algorithms : towards autonomous computer improvisers . In Computers and creativity . Springer , 147 – 174 . [ 7 ] VirginiaBraunandVictoriaClarke . 2019 . Reflectingonreflexivethematicanalysis . Qualitative research in sport , exercise and health 11 , 4 ( 2019 ) , 589 – 597 . [ 8 ] Aili Bresnahan . 2014 . Improvisational artistry in live dance performance as embodied and extended agency . Dance Research Journal 46 , 1 ( 2014 ) , 85 – 94 . [ 9 ] Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , et al . 2020 . Language models are few - shot learners . Advances in neural information processing systems 33 ( 2020 ) , 1877 – 1901 . [ 10 ] SarahJaneBurton , Ali - AkbarSamadani , RobGorbet , andDanaKulić . 2016 . Laban movementanalysisand affectivemovementgenerationfor robotsandother near - living creatures . In Dance Notations and Robot Motion . Springer , 25 – 48 . [ 11 ] Yves Candau , Jules Françoise , Sarah Fdili Alaoui , and Thecla Schiphorst . 2017 . Cultivating kinaesthetic awareness through interaction : Perspectives from so - matic practices and embodied cognition . In Proceedings of the 4th International Conference on Movement Computing . ACM , 1 – 8 . [ 12 ] Andy Clark . 2008 . Supersizing the mind : Embodiment , action , and cognitive exten - sion . New York : Oxford University Press . [ 13 ] Luka Crnkovic - Friis and Louise Crnkovic - Friis . 2016 . Generative Choreography using Deep Learning . In Proceedings of the Seventh International Conference on Computational Creativity . [ 14 ] Prafulla Dhariwal , Heewoo Jun , Christine Payne , Jong Wook Kim , Alec Radford , and Ilya Sutskever . 2020 . Jukebox : A generative model for music . arXiv preprint arXiv : 2005 . 00341 ( 2020 ) . [ 15 ] BrianEno . 2001 . ObliqueStrategies . https : / / www . enoshop . co . uk / product / oblique - strategies . html [ 16 ] Sarah Fdili Alaoui . 2019 . Making an interactive dance piece : Tensions in integrat - ing technology in art . In Proceedings of the 2019 on designing interactive systems conference . 1195 – 1208 . [ 17 ] Sarah Fdili Alaoui , Jules Françoise , Thecla Schiphorst , Karen Studd , and Frédéric Bevilacqua . 2017 . Seeing , Sensing and Recognizing Laban Movement Qualities . In Proceedingsofthe2017CHIConferenceonHumanFactorsinComputingSystems . ACM , 4009 – 4020 . [ 18 ] Sarah Fdili Alaoui , Thecla Schiphorst , Shannon Cuykendall , Kristin Carlson , Karen Studd , and Karen Bradley . 2015 . Strategies for embodied design : The value and challenges of observing movement . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition . 121 – 130 . [ 19 ] Rebecca Fiebrink , Daniel Trueman , N Cameron Britt , Michelle Nagai , Konrad Kaczmarek , Michael Early , MR Daniel , Anne Hege , and Perry R Cook . 2010 . To - ward understanding human - computer interaction in composing the instrument . In ICMC . [ 20 ] Andrés Galeano and Joanna Matuszak . 2014 . Performing with Objects . PAJ : A Journal of Performance and Art 36 , 3 ( 2014 ) , 102 – 111 . https : / / www . jstor . org / stable / 26386709 [ 21 ] Shaun Gallagher . 2017 . Enactivist interventions : Rethinking the mind . Oxford University Press . [ 22 ] Petra Gemeinboeck and Rob Saunders . 2017 . Movement matters : How a robot becomes body . In Proceedings of the 4th international conference on movement Computing . 1 – 8 . [ 23 ] Alex Graves . 2013 . Generating sequences with recurrent neural networks . arXiv preprint arXiv : 1308 . 0850 ( 2013 ) . [ 24 ] David Ha and Douglas Eck . 2017 . A neural representation of sketch drawings . In International Conference on Learning Representations . [ 25 ] SeppHochreiterandJürgenSchmidhuber . 1997 . LongShort - termMemory . Neural computation 9 ( 12 1997 ) , 1735 – 80 . https : / / doi . org / 10 . 1162 / neco . 1997 . 9 . 8 . 1735 [ 26 ] David Holz . 2022 . Midjourney . https : / / www . midjourney . com / [ 27 ] Stacy Hsueh , Sarah Fdili Alaoui , and Wendy E Mackay . 2019 . Understanding kinaesthetic creativity in dance . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . 1 – 12 . [ 28 ] Mikhail Jacob and Brian Magerko . 2015 . Viewpoints ai . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition . 361 – 362 . [ 29 ] Mauri Kaipainen , Niklas Ravaja , Pia Tikka , Rasmus Vuori , Roberto Pugliese , Marco Rapino , and Tapio Takala . 2011 . Enactive systems and enactive media : embodied human - machine coupling beyond interfaces . Leonardo 44 , 5 ( 2011 ) , 433 – 438 . [ 30 ] Hyung - Kwon Ko , Gwanmo Park , Hyeon Jeon , Jaemin Jo , Juho Kim , and Jinwook Seo . 2023 . Large - scale text - to - image generation models for visual artists’ creative works . In Proceedings of the 28th International Conference on Intelligent User Interfaces . 919 – 933 . [ 31 ] Tejas D Kulkarni , Karthik Narasimhan , Ardavan Saeedi , and Josh Tenenbaum . 2016 . Hierarchical deep reinforcement learning : Integrating temporal abstraction and intrinsic motivation . Advances in neural information processing systems 29 ( 2016 ) . [ 32 ] Meha Kumar , Duri Long , and Brian Magerko . 2020 . Creativity Metrics for a Lead - and - Follow Dynamic in an Improvisational Dance Agent . In Proceedings of the Eleventh International Conference on Computational Creativity . [ 33 ] Jina Lee and Stacy Marsella . 2006 . Nonverbal Behavior Generator for Embodied Conversational Agents . In Proceedings of the 6th International Conference on Intelligent Virtual Agents ( Marina Del Rey , CA ) ( IVA’06 ) . Springer - Verlag , Berlin , Heidelberg , 243 – 255 . https : / / doi . org / 10 . 1007 / 11821830 _ 20 [ 34 ] Jiaman Li , Yihang Yin , Hang Chu , Yi Zhou , Tingwu Wang , Sanja Fidler , and Hao Li . 2020 . Learning to generate diverse dance motions with transformer . arXiv preprint arXiv : 2008 . 08171 ( 2020 ) . [ 35 ] Ruilong Li , Shan Yang , David A Ross , and Angjoo Kanazawa . 2021 . Ai choreog - rapher : Music conditioned 3d dance generation with aist + + . In Proceedings of the IEEE / CVF International Conference on Computer Vision . 13401 – 13412 . 463 Embodying an Interactive AI for Dance Through Movement Ideation C & C ’23 , June 19 – 21 , 2023 , Virtual Event , USA [ 36 ] Lucas Liu , Duri Long , Swar Gujrania , and Brian Magerko . 2019 . Learning move - ment through human - computer co - creative improvisation . In Proceedings of the 6th International Conference on Movement and Computing . 1 – 8 . [ 37 ] Clara Mancini , Yvonne Rogers , Arosha K Bandara , Tony Coe , Lukasz Jedrzejczyk , Adam N Joinson , Blaine A Price , Keerthi Thomas , and Bashar Nuseibeh . 2010 . Contravision : exploring users’ reactions to futuristic technology . In Proceedings of the SIGCHI conference on human factors in computing systems . 153 – 162 . [ 38 ] Charles Patrick Martin . 2022 . Performing with a Generative Electronic Music Controller . Joint proceedings of the ACM IUI Workshops ( 2022 ) . [ 39 ] Charles Patrick Martin , Kyrre Glette , Tønnes Frostad Nygaard , and Jim Torresen . 2020 . Understanding musical predictions with an embodied interface for musical machine learning . Frontiers in artificial intelligence 3 ( 2020 ) , 6 . [ 40 ] Charles Patrick Martin and Jim Torresen . 2018 . RoboJam : A musical mixture density network for collaborative touchscreen interaction . In Int’l . Conference on Computational Intelligence in Music , Sound , Art and Design . Springer , 161 – 176 . [ 41 ] Crypton Future Media . 2007 . Who is Hatsune Miku ? https : / / ec . crypton . co . jp / pages / prod / virtualsinger / cv01 _ us [ 42 ] Meinard Müller and Tido Röder . 2006 . Motion templates for automatic classi - fication and retrieval of motion capture data . In Proceedings of the 2006 ACM SIGGRAPH / Eurographics symposium on Computer animation . Eurographics Asso - ciation , 137 – 146 . [ 43 ] A Michael Noll . 2016 . Early Digital Computer Art at Bell Telephone Laboratories , Incorporated . Leonardo 49 , 1 ( 2016 ) , 55 – 65 . [ 44 ] Mariel Pettee , Chase Shimmin , Douglas Duhaime , and Ilya Vidrin . 2019 . Beyond Imitation : Generative and Variational Choreography via Machine Learning . 10th International Conference on Computational Creativity ( 2019 ) . [ 45 ] Nicola Plant , Clarice Hilton , Marco Gillies , Rebecca Fiebrink , Phoenix Perry , Carlos González Díaz , Ruth Gibson , Bruno Martelli , and Michael Zbyszynski . 2021 . Interactive Machine Learning for Embodied Interaction Design : A tool and methodology . In Proceedings of the Fifteenth International Conference on Tangible , Embedded , and Embodied Interaction . 1 – 5 . [ 46 ] Richard Povall . 1998 . Technology is with us . Dance Research Journal 30 , 1 ( 1998 ) , 1 – 4 . [ 47 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical text - conditional image generation with clip latents . arXiv preprint arXiv : 2204 . 06125 ( 2022 ) . [ 48 ] Aditya Ramesh , Mikhail Pavlov , Gabriel Goh , Scott Gray , Chelsea Voss , Alec Radford , MarkChen , andIlyaSutskever . 2021 . Zero - shottext - to - imagegeneration . In International Conference on Machine Learning . PMLR , 8821 – 8831 . [ 49 ] Susanne Ravn . 2020 . Investigating dance improvisation : from spontaneity to agency . Dance Research Journal 52 , 2 ( 2020 ) , 75 – 87 . [ 50 ] Christian Remy , Lindsay MacDonald Vermeulen , Jonas Frich , Michael Mose Biskjaer , and Peter Dalsgaard . 2020 . Evaluating creativity support tools in HCI research . In Proceedings of the 2020 ACM designing interactive systems conference . 457 – 476 . [ 51 ] Graeme Ritchie . 2007 . Some Empirical Criteria for Attributing Creativity to a Computer Program . Minds and Machines 17 ( 2007 ) , 76 – 99 . [ 52 ] Thecla Schiphorst . 2013 . Merce Cunningham : Making dances with the computer . Merce Cunningham : Creative elements ( 2013 ) , 79 – 98 . [ 53 ] Jürgen Schmidhuber . 2006 . Developmental robotics , optimal artificial curiosity , creativity , music , and the fine arts . Connection Science 18 , 2 ( 2006 ) , 173 – 187 . [ 54 ] Nikhil Singh , Guillermo Bernal , Daria Savchenko , and Elena L Glassman . 2022 . Where to hide a stolen elephant : Leaps in creative writing with multimodal machine intelligence . ACM Transactions on Computer - Human Interaction ( 2022 ) . [ 55 ] Nahre Sol . 2022 . I used CHOPIN to program DRUMS . The results were kind of amazing . https : / / youtu . be / wY1dIY - - UDY ? t = 366 [ 56 ] Bob L Sturm and Oded Ben - Tal . 2017 . Taking the models back to music practice : evaluating generative transcription models built using deep learning . Journal of Creative Music Systems 2 , 1 ( 2017 ) . [ 57 ] Shuhei Tsuchida , Satoru Fukayama , Masahiro Hamasaki , and Masataka Goto . 2019 . AIST Dance Video Database : Multi - genre , Multi - dancer , and Multi - camera Database for Dance Information Processing . In Proceedings of the 20th Inter - national Society for Music Information Retrieval Conference , ISMIR 2019 . Delft , Netherlands . [ 58 ] GabrielVigliensoni , LouisMcCallum , andRebeccaFiebrink . 2020 . Creatinglatent spaces for modern music genre rhythms using minimal training data . ( 2020 ) . [ 59 ] Benedikte Wallace , Charles P . Martin , Jim Torresen , and Kristian Nymoen . 2020 . Towards Movement Generation with Audio Features . In Proceedings of the 11th International Conference on Computational Creativity . [ 60 ] Benedikte Wallace , Charles P Martin , Jim Tørresen , and Kristian Nymoen . 2021 . Learning Embodied Sound - Motion Mappings : Evaluating AI - Generated Dance Improvisation . In Creativity and Cognition . 1 – 9 . [ 61 ] Benedikte Wallace , Kristian Nymoen , Charles P . Martin , and Jim . Tør - resen . 2019 . DeepDance : Motion capture data of improvised dance . https : / / doi . org / 10 . 5281 / zenodo . 5838179 . [ 62 ] Qiushi Zhou , Cheng Cheng Chua , Jarrod Knibbe , Jorge Goncalves , and Eduardo Velloso . 2021 . Dance and Choreography in HCI : A Two - Decade Retrospective . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems . 1 – 14 . 464