The diﬀerence between “signiﬁcant” and “not signiﬁcant” is not itself statistically signiﬁcant ∗ Andrew Gelman † Hal Stern ‡ August 22 , 2006 Abstract It is common to summarize statistical comparisons by declarations of statistical signiﬁcance or non - signiﬁcance . Here we discuss one problem with such declarations , namely that changes in statistical signiﬁcance are often not themselves statistically signiﬁcant . By this , we are not merely making the commonplace observation that any particular threshold is arbitrary—for example , only a small change is required to move an estimate from a 5 . 1 % signiﬁcance level to 4 . 9 % , thus moving it into statistical signiﬁcance . Rather , we are pointing out that even large changes in signiﬁcance levels can correspond to small , non - signiﬁcant changes in the underlying variables . The error we describe is conceptually diﬀerent from other oft - cited problems—that statistical signiﬁcance is not the same as practical importance , that dichotomization into signiﬁcant and non - signiﬁcant results encourages the dismissal of observed diﬀerences in favor of the usually less interesting null hypothesis of no diﬀerence , and that any particular threshold for declaring signiﬁcance is arbitrary . We are troubled by all of these concerns and do not intend to minimize their importance . Rather , our goal is to bring attention to what we have found is an important but much less discussed point . We illustrate with a theoretical example and two applied examples . Keywords : multilevel modeling , multiple comparisons , replication , statistical signif - icance 1 Introduction A common statistical error is to summarize comparisons by statistical signiﬁcance and then draw a sharp distinction between signiﬁcant and non - signiﬁcant results . The approach of summarizing by statistical signiﬁcance has a number of pitfalls , most of which are covered in standard statistics courses but one that we believe is less well known . We refer to the fact that changes in statistical signiﬁcance are not themselves signiﬁcant . By this , we are not ∗ We thank Howard Wainer , Peter Westfall , and an anonymous reviewer for helpful comments and the National Science Foundation for ﬁnancial support . † Department of Statistics and Department of Political Science , Columbia University , New York , gelman @ stat . columbia . edu , www . stat . columbia . edu / ∼ gelman ‡ Department of Statistics , University of California , Irvine , sternh @ uci . edu , www . ics . uci . edu / ∼ sternh 1 merely making the commonplace observation that any particular threshold is arbitrary—for example , only a small change is required to move an estimate from a 5 . 1 % signiﬁcance level to 4 . 9 % , thus moving it into statistical signiﬁcance . Rather , we are pointing out that even large changes in signiﬁcance levels can correspond to small , non - signiﬁcant changes in the underlying variables . We shall illustrate with three examples . This article does not attempt to provide a comprehensive discussion of signiﬁcance testing . There are several such discussions ; see , for example , Krantz ( 1999 ) . Indeed many of the pitfalls of relying on declarations of statistical signiﬁcance appear to be well known . For example , by now practically all introductory texts point out that statistical signiﬁcance does not equal practical importance . If the estimated eﬀect of a drug is to decrease blood pressure by 0 . 10 with a standard error of 0 . 03 , this would be statistically signiﬁcant but probably not important in practice ( or so we suppose , given our general knowledge that blood pressure values are typically around 100 ) . Conversely , an estimated eﬀect of 10 with a standard error of 10 would not be statistically signiﬁcant , but it has the possibility of being important in practice . As well , introductory courses regularly warn students about the perils of strict adherence to a particular threshold ( the point mentioned above regarding 5 . 1 % and 4 . 9 % signiﬁcance levels ) . Similarly most statisticians and many practitioners are familiar with the notion that automatic use of a binary signiﬁcant / non - signiﬁcant decision rule encourages practitioners to ignore potentially important observed diﬀerences in favor of the usually less interesting null hypothesis . Thus , from this point forward we focus only on the less widely known but equally important error of comparing two or more results by comparing their degree of statistical signiﬁcance . 2 Theoretical example : comparing the results of two exper - iments Consider two independent studies with eﬀect estimates and standard errors of 25 ± 10 and 10 ± 10 . The ﬁrst study is statistically signiﬁcant at the 1 % level , and the second is not at all statistically signiﬁcant , being only one standard error away from 0 . Thus it would be tempting to conclude that there is a large diﬀerence between the two studies . In fact , however , the diﬀerence is not even close to being statistically signiﬁcant : the estimated diﬀerence is 15 , with a standard error of √ 10 2 + 10 2 = 14 . Additional problems arise when comparing estimates with diﬀerent levels of information . Suppose in our example that there is a third independent study with much larger sample size that yields an eﬀect estimate of 2 . 5 with standard error of 1 . 0 . This third study attains 2 the same signiﬁcance level as the ﬁrst study , yet the diﬀerence between the two is itself also signiﬁcant . Both ﬁnd a positive eﬀect but with much diﬀerent magnitudes . Does the third study replicate the ﬁrst study ? If we restrict attention only to judgments of signiﬁcance we might say yes , but if we think about the eﬀect being estimated we would say no , as noted by Utts ( 1991 ) . In fact , the third study ﬁnds an eﬀect size much closer to that of the second study , but now because of the sample size it attains signiﬁcance . Declarations of statistical signiﬁcance are often associated with decision making . For example , if the two estimates in the ﬁrst paragraph concerned eﬃcacy of blood pressure drugs , then one might conclude that the ﬁrst drug works and the second does not , making the choice between them obvious . But is this obvious conclusion reasonable ? The two drugs do not appear to be signiﬁcantly diﬀerent from each other . One way of interpreting lack of statistical signiﬁcance is that further information might change one’s decision recommen - dations . Our key point is not that we object to looking at statistical signiﬁcance but that comparing statistical signiﬁcance levels is a bad idea . In making a comparison between two treatments , one should look at the statistical signiﬁcance of the diﬀerence rather than the diﬀerence between their signiﬁcance levels . 3 Applied example : homosexuality and the number of older brothers and sisters The paper , “Biological versus nonbiological older brothers and men’s sexual orientation , ” ( Bogaert , 2006 ) , appeared recently in the Proceedings of the National Academy of Sciences and was picked up by several leading science news organizations ( Bower , 2006 , Motluk , 2006 , Staedter , 2006 ) . As the article in Science News put it : The number of biological older brothers correlated with the likelihood of a man being homosexual , regardless of the amount of time spent with those siblings during childhood , Bogaert says . No other sibling characteristic , such as number of older sisters , displayed a link to male sexual orientation . We were curious about this—why older brothers and not older sisters ? The article referred back to Blanchard and Bogaert ( 1996 ) , which had the graph and table shown in Figure 1 , along with the following summary : Signiﬁcant beta coeﬃcients diﬀer statistically from zero and , when positive , in - dicate a greater probability of homosexuality . Only the number of biological 3 Wald Predictor β SE statistic p e β Initial equation Number of older brothers 0 . 29 0 . 11 7 . 26 0 . 007 1 . 33 Number of older sisters 0 . 08 0 . 10 0 . 63 0 . 43 1 . 08 Number of younger brothers − 0 . 14 0 . 10 2 . 14 0 . 14 0 . 87 Number of younger sisters − 0 . 02 0 . 10 0 . 05 0 . 82 0 . 98 Father’s age at time of proband’s birth 0 . 02 0 . 02 1 . 06 0 . 30 1 . 02 Mother’s age at time of proband’s birth - 0 . 03 0 . 02 1 . 83 0 . 18 0 . 97 Final equation—number of older brothers 0 . 28 0 . 10 8 . 77 0 . 003 1 . 33 Figure 1 : From Blanchard and Bogaert ( 1996 ) : ( a ) mean numbers of older and younger brothers and sisters for 302 homosexual men and 302 matched heterosexual men , ( b ) logistic regression of sexual orientation on family variables from these data . The graph and table illustrate that , in these data , homosexuality is more strongly associated with number of older brothers than with number of older sisters . However , no evidence is presented that would indicate that this diﬀerence is statistically signiﬁcant . 4 older brothers reared with the participant , and not any other sibling character - istic including the number of nonbiological brothers reared with the participant , was signiﬁcantly related to sexual orientation . The conclusions appear to be based on a comparison of signiﬁcance ( for the coeﬃcient of the number of older brothers ) with nonsigniﬁcance ( for the other coeﬃcients ) , even though the diﬀerences between the coeﬃcients do not appear to be statistically signiﬁcant . One cannot quite be sure—it is a regression analysis and the diﬀerent coeﬃcient estimates are not independent—but based on the picture we strongly doubt that the diﬀerence between the coeﬃcient of the number of older brothers and the coeﬃcient of the number of older sisters is signiﬁcant . Is it appropriate to criticize an analysis of this type ? After all , the data are consistent with the hypothesis that only the number of older brothers matters . But the data are also consistent with the hypothesis that only the birth order ( the total number of older siblings ) matters . ( Again we cannot be certain but we strongly suspect so from the graph and the table . ) Given that the 95 % conﬁdence level is standard ( and we are pretty sure the paper would not have been published had the results not been statistically signiﬁcant at that level ) , it is appropriate that the rule should be applied consistently to hypotheses consistent with the data . We are speaking here not as experts in biology but rather as statisticians : the published article and its media reception suggest unquestioning acceptance of a result ( only the number of older brothers matters ) which , if properly expressed as a comparison , would be better described as “suggestive . ” For example , the authors could have written that the sexual preference of the men in the sample is statistically signiﬁcantly related to birth order and , in addition , more strongly related to number of older brothers than number of older sisters , but with the latter diﬀerence not being statistically signiﬁcant . 4 Applied example : health eﬀects of low - frequency electro - magnetic ﬁelds The issue of comparisons between signiﬁcance and non - signiﬁcance is of even more concern in the increasingly common setting where there are a large number of comparisons . We illustrate with an example of a laboratory study with public health applications . In the wake of concerns about the health eﬀects of low - frequency electric and magnetic ﬁelds , Blackman et al . ( 1988 ) performed a series of experiments to measure the eﬀect of electromagnetic ﬁelds at various frequencies on the functioning of chick brains . At each of 5 0 100 200 300 400 500 Frequency of magnetic field ( Hz ) E s t . t r ea t m en t e ff e c t 0 . 0 0 . 2 0 . 4 Estimates with statistical significance 0 100 200 300 400 500 0 . 0 0 . 2 0 . 4 Estimates – standard errors Frequency of magnetic field ( Hz ) E s t . t r ea t m en t e ff e c t Figure 2 : ( a ) Estimated eﬀects of electromagnetic ﬁelds on calcium eﬄux from chick brains , shaded to indicate diﬀerent levels of statistical signiﬁcance , adapted from Blackman et al . ( 1988 ) . A separate experiment was performed at each frequency . ( b ) Same results presented as estimates ± standard errors . As discussed in the text , the ﬁrst plot , with its emphasis on statistical signiﬁcance , is misleading . several frequencies of electromagnetic ﬁelds ( 1 Hz , 15 Hz , 30 Hz , . . . , 510 Hz ) , a randomized experiment was performed to estimate the eﬀect of exposure , compared to a control con - dition of no electromagnetic ﬁeld . The estimated treatment eﬀect ( the average diﬀerence between treatment and control measurements ) and the standard error at each frequency were reported . Blackman et al . ( 1988 ) summarized the estimates at the diﬀerent frequencies by their statistical signiﬁcance , using a graph similar to Figure 2a with diﬀerent shading indicating results that are more than 2 . 3 standard errors from zero ( that is , statistically signiﬁcant at the 99 % level ) , between 2 . 0 and 2 . 3 standard errors from zero ( statistically signiﬁcant at the 95 % level ) , and so forth . The researchers used this sort of display to hypothesize that one process was occurring at 255 , 285 , and 315 Hz ( where eﬀects were highly signiﬁcant ) , another at 135 and 225 Hz ( where eﬀects were only moderately signiﬁcant ) , and so forth . The estimates are all of relative calcium eﬄux , so that an eﬀect of 0 . 1 , for example , corresponds to a 10 % increase compared to the control condition . The researchers in the chick - brain experiment made the common mistake of using statis - tical signiﬁcance as a criterion for separating the estimates of diﬀerent eﬀects , an approach that does not make sense . At the very least , it is more informative to show the estimated treatment eﬀect and standard error at each frequency , as in Figure 2b . This display makes the key features of the data clear . Though the size of the eﬀect varies , it is just about 6 0 100 200 300 400 500 0 . 0 0 . 2 0 . 4 Multilevel estimates – standard errors Frequency of magnetic field ( Hz ) E s t i m a t ed t r ea t m en t e ff e c t Figure 3 : Multilevel estimates and standard errors for the eﬀects of magnetic ﬁelds , partially pooled from the separate estimates displayed in Figure 2 . The standard errors of the original estimates were large , and so the multilevel estimates are pooled strongly toward the common average which is near of 0 . 1 . always positive and typically not far from 0 . 1 . What should one do instead ? One natural idea is to ﬁt a model in which the eﬀect is a smooth function of frequency . The data , however , appear to jump around quite a bit and we do not have the scientiﬁc expertise to justify the appropriateness of such a model . Another way to handle the large number of related experiments in a single data analysis is to ﬁt a multilevel model of the sort used in meta - analysis . If at each frequency j , we label the estimated eﬀect and standard error as y j and σ j , then the simplest multilevel model is y j ∼ N ( θ j , σ 2 j ) , θ j ∼ N ( µ , τ 2 ) , and the resulting Bayesian estimates for the eﬀects θ j ( using a ﬂat prior distribution on µ and τ ) are partially pooled toward the average of all the data ( see , for example , Gelman et al . , 2003 , chapter 5 , for more discussion of models of this type ) . The posterior estimates and standard errors are shown in Figure 3 . Some might object to this exchangeable model for the experiments at diﬀerent frequencies , but this is consistent with the original Blackman et al . analysis , which also makes this assumption of exchangeability . ( That is to say , neither of the analyses distinguish between the experiments based on the underlying frequency . ) Our simple hierarchical model is not intended to be deﬁnitive , merely a model that we believe improves upon the separate judgments of statistical signiﬁcance for each experiment . A subject - matter expert can perhaps use Figure 3 ( rather than Figure 2a ) to formulate further hypotheses and models . The multilevel analysis can be seen as a way to estimate the eﬀects at each frequency j , without setting apparently “non - signiﬁcant” results to zero . Some of the most dramatic 7 features of the original data as plotted in Figure 2a—for example , the negative estimate at 480 Hz and the pair of statistically - signiﬁcant estimates at 405 Hz—do not stand out so much in the multilevel estimates , indicating that these features could be explained by sampling variability and do not necessarily represent real features of the underlying parameters . 5 Discussion It is standard in applied statistics to evaluate inferences based on their statistical signiﬁcance at the 5 % level . There has been a move in recent years toward reporting conﬁdence intervals rather than p - values , and the centrality of hypothesis testing has been challenged , but even when using conﬁdence intervals it is natural to check whether they include zero . Statistical signiﬁcance , in some form , is a way to assess the reliability of statistical ﬁndings . However , as we have seen , comparisons of the sort , “X is statistically signiﬁcant but Y is not , ” can be misleading . References Blackman , C . F . , Benane , S . G . , Elliott , D . J . , House , D . E . , and Pollock , M . M . ( 1988 ) . Inﬂuence of electromagnetic ﬁelds on the eﬄux of calcium ions from brain tissue in vitro : a three - model analysis consistent with the frequency response up to 510 Hz . Bioelectromagnetics 9 , 215 – 227 . Blanchard , R . , and Bogaert , A . F . ( 1996 ) . Homosexuality in men and number of older brothers . American Journal of Psychaitry 153 , 27 – 31 . Bogaert , A . F . ( 2006 ) . Biological versus nonbiological older brothers and men’s sexual orientation . Proceedings of the National Academy of Sciences 103 , 10771 – 10774 . Bower , B . ( 2006 ) . Gay males’ sibling link : men’s homosexuality tied to having older broth - ers . Science News 170 ( 1 ) , 3 . Gelman , A . , Carlin , J . B . , Stern , H . S . , and Rubin , D . B . ( 2003 ) . Bayesian Data Analysis , second edition . London : CRC Press . Krantz , D . H . ( 1999 ) . The null hypothesis testing controversy in psychology . Journal of the American Statistical Association 94 , 1372 – 1381 . Motluk , A . ( 2006 ) . Male sexuality may be decided in the womb . New Scientist , online edition , 26 June . 8 Staedter , T . ( 2006 ) . Having older brothers increases a man’s odds of being gay . Scientiﬁc American , online edition , 27 June . Utts , J . M . ( 1991 ) . Replication and meta - analysis in parapsychology ( with discussion ) . Statistical Science 6 , 363 – 403 . 9