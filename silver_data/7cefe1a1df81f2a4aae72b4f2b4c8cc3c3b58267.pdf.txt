Asynchronous Collaboration Systems for Evolving Information Shaun Wallace Brown University Rhode Island , USA shaun _ wallace @ brown . edu ABSTRACT Iaimtounderstandhowindividualsmaybemotivatednon - financially to collaborate in maintaining evolving information asynchronously . I have developed two systems , Drafty and Sketchy , that provide evidence of achieving this goal at differing timescales . In Drafty , unpaid contributors voluntarily update a tabular dataset of Com - puter Science professor profiles at a multi - year timescale . In Sketchy , university students simultaneously sketch and co - inspire each other during voluntary UI / UX sketching activities at a sub - hour timescale . I seek to integrate lessons from both systems to develop a theoret - ical framework that uses a feedback cycle to provide users with practical random examples from evolving information to motivate new contributions . I will further develop this theoretical framework by extending Drafty to generate insights to automatically attract visitors and create the Virtual Readability Lab ( VRL ) to help users improvetheirreadingperformancethroughpersonalizedreadabilitytestsanddeepenourunderstandingofinformationdesignhumanperformance . Both systems will give users the agency to seek ran - domizedinsightswithinanaturalisticsettingtomotivatecontinuouscontributionstoeachsystem’sevolvinginformation . CCS CONCEPTS • Human - centered computing → Human computer interac - tion ( HCI ) ; Computer supported cooperative work ; Asynchro - nous editors ; • Information systems → Crowdsourcing ; Data cleaning ; Incomplete data . KEYWORDS evolving information , asynchronous collaboration , crowdsourcing , unpaid contributors ACM Reference Format : Shaun Wallace . 2022 . Asynchronous Collaboration Systems for Evolving Information . In CHI Conference on Human Factors in Computing Systems Extended Abstracts ( CHI ’22 Extended Abstracts ) , April 29 - May 5 , 2022 , New Orleans , LA , USA . ACM , NewYork , NY , USA , 5pages . https : / / doi . org / 10 . 1145 / 3491101 . 3503803 1 RESEARCH SITUATION In my research , I focus on developing and deploying systems to maintain evolving sets of information . The critical question is how Permission to make digital or hard copies of part or all of this work for personal or classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation onthefirstpage . Copyrightsforthird - partycomponentsofthisworkmustbehonored . Forallotheruses , contacttheowner / author ( s ) . CHI’22ExtendedAbstracts , April29 - May5 , 2022 , NewOrleans , LA , USA ©2022Copyrightheldbytheowner / author ( s ) . ACMISBN978 - 1 - 4503 - 9156 - 6 / 22 / 04 . https : / / doi . org / 10 . 1145 / 3491101 . 3503803 to use contributors’ interest in the data to motivate further contribu - tions . Ihavedevelopedtwowebapplicationstostudythisquestionat different timescales . Drafty , a smarter Wiki for maintaining tabular data in the familiar form of a freely editable spreadsheet [ 34 , 37 ] . Drafty hosts a tabular dataset of computer science professor profiles maintained through unpaid contributions in the wild . The second is Sketchy , which allows instructors to bring any sketching task to a UI / UX classroom where students can simultaneously create and up - date their sketches while co - inspiring each other through the “Peek” feature [ 33 ] . Each system demonstrates how users can be motivated to make small unpaid contributions to maintain and grow evolving information . I am a fifth - year Ph . D . candidate in the Department of Computer ScienceofBrownUniversityadvisedbyJeffHuang . Ihavecompleted the required coursework and passed the necessary comprehensive exams consisting of research and programming comps . I have also reached the residency requirement at my university . My projected thesis proposal date is Summer 2022 , and my projected graduation date is Fall 2022 . I began my graduate career at Brown University as a part - time Master’s student in 2014 . I started the Ph . D . program in Fall 2017 as a full - time student . From Spring 2018 and on , I have been a part - time Ph . D . student working full - time as the Lead Systems Programmer for Brown University’s Computer Science Department . During the summer of 2019 , I completed a research internship at the Adobe Creative Intelligence Lab under the supervision of Zoya Bylinskii . 2 CONTEXT AND MOTIVATION The data around us is dying [ 12 , 25 ] . Not all data is static , some data evolvesovertimeduetotemporalandexternalfactors [ 34 ] . Forexam - ple , Universityclosuresandmaskrequirementsduringthepandemic can change rapidly [ 1 ] . Whereas the course a university offers in Fall 2019 will not change . While we have studied how to quickly and cheaplycollectaccuratedata , thelifecycleofthisdatareliesonmain - tenance to ensure its accuracy over time [ 34 ] . There are numerous collective Peer Production and Citizen Science efforts to build these types of evolving datasets , such as FLOSS , Wikis , and Knowledge Graphs . These datasets , powered by human - collaboration , have life cycles where data is collected , matures , and eventually dies [ 13 ] . The coming death of specific datasets is well documented on popular platforms like Wikipedia [ 12 , 13 , 19 , 27 ] . Wikipedia and WikiData , for example , rely on a few users making the majority edits per article or topic [ 13 , 16 , 25 ] . When editors leave , data can rapidly become out - of - date . There is even a Wikipedia project [ 39 ] dedicated to absent or retired editors with more than 1000 edits . These former ed - itors often possessed valuable domain expertise lacking among paid crowdworkers [ 27 , 34 ] . Extending the life of data requires perpetual humanattention . Externaltemporalfactorscausedatatodecay , thus , destroying its utility [ 34 ] . To overcome this , past work has employed CHI’22ExtendedAbstracts , April29 - May5 , 2022 , NewOrleans , LA , USA Wallace paid - crowdworkers in crowd - powered systems [ 4 ] or allowed users to compare their performance in online tests with others to motivate voluntary participation [ 26 ] . Based on my experience with three diverse systems , I have be - gun extracting general principles for promoting data maintenance of evolving information through cyclical feedback mechanisms be - tween systems and their users [ 30 , 32 , 33 , 35 , 37 ] . I intend to develop these into a framework for developing asynchronous collaboration systemsforevolvinginformation . Ihavetworesearchgoalstoextend this theoretical framework . First , I will extend Drafty to continu - ously attract and engage users by automatically providing random insights , or DataBaits , after each unpaid contribution . The second is to develop the Virtual Readability Lab building on my suite of remote readability tests , where unpaid users are provided randomly designed text within personalized readability tests to understand how to individuate text . 3 PRELIMINARY WORK 3 . 1 Drafty : Maintaining Tabular Data My first effort to maintain evolving information began by develop - ing Drafty in 2015 . Drafty hosts a publicly editable spreadsheet of Computer Science faculty profiles [ 37 ] . While paid crowdworkers originallycollectedthisdataset [ 23 , 34 ] , theinitialeffortstomaintain itwithinourresearchlabprovedunsuccessfulduetotimeconstraintsandthegrowingcomplexityandsizeoftheinformation . Over time , we conducted two case studies to observe paid crowdworkers and unpaid contributors’ ability to improve the accuracy of the data . Our resultsshowevidencethatunpaidcontributorseditedfrequentlyandweremoreaccurate , especially for information requiring domain - specific knowledge [ 34 ] . 3 . 1 . 1 Description and Lessons Learned Developing the Theoretical Framework . Unpaid Users . Attracting interested visitors to make unpaid contributions is necessary to extend the information’s maintenance phase . When Drafty was created , we made posts across various CS forums and websites ( Reddit CompSci , Hacker News , and TheGrad - Cafe ) toinformandattractaninitialuserbaseinterestedinComputer Science . All subsequent visitors to Drafty was generated through organic search traffic or other means we did not control . Evolving Information . Drafty hosts a publicly editable tabular dataset over 6 , 000 academic profiles of Computer Science tenure track faculty from the United States and Canada [ 37 ] . Each academic profile is a row in a spreadsheet . The columns corresponds to a pro - fessor’s affiliated university , the year they joined as faculty , subfield area of expertise , and where they received their Bachelors , and Ph . D . degrees . This information of Computer Science faculty is valuable to the community , and powers one ranking within the meta - ranker CS Open Rankings [ 31 ] . External Temporal Factors . The information in a Computer Science professor’s academic profile that is not static is their full name , the university they are employed at , the year they joined their current university , and their subfield area of expertise ( i . e . , primary research area ) . The external factors that cause the data to change include a professor moving universities , a new hire at a university , a professor retiring or leaving to go to an industry position , or chang - ingtheirsubfieldareaofexpertise . Thus , theseexternalfactorscause the data to change annually due to tenure appointments or hiring season , or slower if a professor changes their primary research field . We have found it unlikely that a tenure track faculty would receive a new Bachelors’s or Doctorate . Randomized Examples to Motivate Contributions . Our ini - tial version of Drafty would solicit users to review and fix data matching their interests [ 37 ] . Drafty derives a user’s interests from their interactions ( i . e . , clicks , searches , and edits ) . Drafty first selects rows the user is interested in and then randomly a row and value to propose a value to fix . Selecting values at random ensures a user is not asked to fix the same row of data multiple times . TheRewardtoMotivateEngagement . Theinitialintentionof Drafty was that the community’s interest in the data was sufficient motivation to maintain it [ 34 , 37 ] . While asking users to fix data matching their interests provided accurate edits , this reward did not provide enough immediate utility to the user to motivate frequent edits . 3 . 2 Sketchy and the Peek Feature Students during a sketching task can benefit from seeing related ex - amples ; however , thesecanbedifficulttocollectandmaintain [ 15 , 29 , 33 ] . We also observed people physically peeking at their neighbor’s sketches in real - time to gain ideas [ 33 ] . To create this behavior in a digitalenvironment , wedevelopedaweb - baseddrawingapplication , Sketchy , where users sketch in virtual rooms and use the Peek func - tionality to gain ideas from their peers’ sketches in real - time [ 33 ] . Peek allows students to co - create the inspirational stimuli needed to conduct a helpful sketching activity , thus eliminating the need for a professor to collect and maintain prior sketching examples . 3 . 2 . 1 Description and Lessons Learned Developing the Theoretical Framework . Unpaid Users . Sketchy’s users consist of university students from a user experience and user design class . The students volun - tarily participated in sketching activities during a break at a lab and right after class . Students did not receive a grade , and a few students were randomly awarded a gift card to a local restaurant . Thus the participationwasvoluntary , andstudentscouldleaveitanytime . Our pilot studies used to reward the students whose sketches were voted most inspirational by other students with gift cards . However , we noticed this gamification produced adverse behaviors from specific students trained to game the system . Thus the most beneficial behav - iors are exhibited when student participation was entirely voluntary with a small motivator in the form of a gift card raffle . EvolvingInformation . ThesketchproducedbyauserinSketchy is the information . Sketchy automatically stores and synchronizes everyone’s sketches as series of XY points and color per stroke . This enables one user’s sketch to be seen by another user on - demand in real - time , as a form of digital peeking . Prior work shows individuals can benefit from seeing examples of other sketches during sketching activities [ 15 , 29 , 33 ] . It is difficult for an instructor to collect enough relatedsketchexamplesbeforerunningasketchingactivity . Through the Peek feature , Sketchy provides a mechanism to quickly collect and share sketches as inspirational stimuli to users in real - time . AsynchronousCollaborationSystemsforEvolvingInformation CHI’22ExtendedAbstracts , April29 - May5 , 2022 , NewOrleans , LA , USA External Temporal Factors . Sketchy was developed to run hy - bridremoteandin - personUI / UXsketchingtasksinclassrooms . Over time relevant examples for a given sketching task will change due to various factors . For example , a sketching task from 20 years ago might not include designing a wireframe for a responsive web page on desktops , tablets , and phones . Over time different users’ under - standing of icons and their meaning will gradually shift for different age groups [ 2 ] , thus necessitating a different set of inspirational examples to design icons . Overcoming these factors is complex , and Sketchy assumes that the current group of users can co - inspire their peers during the sketching process . RandomizedExamplestoMotivateContributions . InSketchy , users sketch on their device during voluntary sketching activities and can freely peek ( i . e . , view another person’s sketch ) at their peers’ in - progress sketches . These sketches are selected randomly and will not show users the same sketch twice unless they view all other sketches . Our pilot studies explored using Machine Learning models to recommend the most inspirational sketch . However , this choice frustratedusersbecausetheywantedtoseeavarietyofsketches . The development of the digital Peek feature was informed by our qual - itative observations of people physically peeking during in - person sketching tasks to gain inspiration . The Peek feature enables stu - dents to rapidly co - inspire and creates sketches in real - time . This instant co - creation of inspirational stimuli allows teachers to theo - retically run any sketching task without the need to collect previous sketching examples to assist students’ individual creative processes . TheRewardtoMotivateEngagement . Sketchy’susersarestu - dents in UI / UX classes with an intrinsic interest and motivation to develop their design skills . Peek provides the reward mechanism to increase users’ overall creativity and satisfaction with their final sketch [ 33 ] . Peekdeliversamethodforuserstoseeanothersketchde - velopinreal - timeandcopyotherusers’ideas . Thisallowsuserstosee if their ideas are in other sketches and compare their sketches’ qual - ity in real - time . Prior research shows that this comparison method can motivate user engagement [ 26 ] . 4 THESIS STATEMENT Motivation The life cycle of information follows the phases of growth , maturity , and decline . While paying crowdworkers can enable the growth phase , humans must continuously sustain the maturity phase as information evolves . Thesis Statement Providinguserswithindividualrandomexamplestheycanuseimme - diately motivates them to interact continuously with and contribute new information . This thesis develops these ideas through a series of asynchronous collaboration systems where users’ unpaid contri - butions extend the maturity phase of evolving information . 5 PROPOSED WORK The proposed work will apply the theoretical concepts , the who , what , when , where , and why of the theoretical framework ( see Sec - tion § 5 . 1 ) , for asynchronous collaboration systems by extending Drafty [ 34 , 37 ] and developing the Virtual Readability Lab using my remote readability tests [ 3 , 30 , 32 , 35 , 36 , 38 ] . 5 . 1 Theoretical Concepts for Asynchronous Collaboration Systems for Evolving Information UnpaidUsers ( who ) : Theuserswillbeinterestedinthesystem’s information , proving beneficial to their daily lives or activities , thus attracting users to interact with the system voluntarily . These users are considered unpaid contributors and will likely have the domain expertise required to maintain domain - specific knowledge [ 34 ] that paid crowdworkers often lack [ 7 , 10 ] . While paying crowdworkers can help collect information to bootstrap a system , paying them continuouslytomaintaininformationisnotfeasible [ 34 ] . Thismight be due to varying levels of motivation [ 22 ] and effort [ 5 ] , malicious crowdworkers [ 11 ] , andinsufficientdomainexpertise [ 28 ] . Asystem can decrease vandalism by providing users with accurate informa - tion and immediate insights , thus creating a mutually beneficial feedback cycle between the user and the system [ 34 , 37 ] . Evolving Information ( what ) : The system contains informa - tion that is interesting and valuable to users , evolves due to external factors , andisdifficulttocollectandmaintainbyasingleperson [ 37 ] . Not all data is static ; to maintain its accuracy and benefit over time , it is necessary for groups of people to collectively engage with the information to improve its quality [ 34 ] . Static data does not require continuousreview , anditcanbecollectedonceandthenimmediately verifiedtoimproveitsaccuracy [ 34 ] . Theinformationitselfshouldbe important to its community of unpaid contributors , thus providing benefits outside the system’s confines . This will motivate users to visit and interact with the system to maintain its information . External Temporal Factors ( when ) : External factors outside the system cause information to become out - of - date . These factors are temporal , as the accuracy of some data is long - lived while others canchangerapidly . Understandingwhatfactorscausedatatochange is vital to understanding when users might change it and inform integrating new features and reward mechanisms [ 34 ] . Developing rewards that focus on evolving information instead of static will ben - efit the system . Understanding these external factors and designing a system and reward mechanisms to react to them is one method to maintain information [ 33 , 34 ] . RandomizedExamplestoMotivateContributions ( where ) : Auser , notthesystem , caninitiatearandomexamplefromthesystem during their natural information seeking behaviors [ 37 ] . The ran - dom example can contain a recommendation or insight derived from the system’s evolving information to help the user , and it should be useful within and outside the system . If the number of possi - ble random examples is high , they can be filtered using an unpaid contributor’s interests or prior behaviors [ 37 ] . A random example provided in the moment can influence a user’s next action to help them continuously engage and provide accurate and useful informa - tion for other users [ 6 , 33 ] . The random example should appeal to their intrinsic and altruistic motivations [ 33 – 35 ] . Random examples provideameanstoimplicitlymatchsubjectiveinformationrequiringdomain - specific knowledge , with the domain expertise and interests ofunpaidcontributorstoofferadiversesetofinterpretations [ 34 , 35 ] . TheRewardtoMotivateEngagement ( why ) : Thesystemshould rewardtheuserforcompletingtherandomizedexamplestomotivatetheusertovisit , engage , and contribute new information . Paying CHI’22ExtendedAbstracts , April29 - May5 , 2022 , NewOrleans , LA , USA Wallace crowdworkers is a common extrinsic motivator [ 14 , 24 ] . This be - comes less practical over time due to financial constraints , time , and data integrity [ 17 ] . Therefore , users must be continuously attracted and motivated to engage with the system to maintain accurate in - formation . In contrast to gamified systems where users are awarded reputation points or badges for participation [ 18 ] , the reward to engage users must be instrinsic [ 20 , 21 ] and provide them with immediate insights or recommendations they can use outside of the system . To overcome external temporal factors causing data to evolve , these rewards need to create a feedback cycle that is bene - ficial for the user and the information [ 34 ] . Thus , the reward should be tightly coupled to user’s implicit interactions , providing almost instantaneous motivation to contribute . These contributions create high - quality sources of information for the community . 5 . 2 Extending Drafty : DataBaits Drafty requires a constant flow of visitors to visit , review data , and make unpaid contributions in the form of edits to maintain its evolv - ing information . My previous research shows unpaid contributors can make accurate edits across data types requiring varying levels of domain expertise [ 34 , 37 ] . While asking users to fix data matching their interests produces highly accurate edits , users only completed the request 9 % of the time . Thus , Drafty requires a mechanism to motivate voluntary user contributions while not interrupting them during their natural information - seeking tasks . If a platform was as popularasWikipediaorWikiData , itcouldrelyonitspopularityand real - world usage to attract visitors . While my theoretical framework couldapplytoWikipediaandWikiData , ithasbeendevelopedbyand for researchers and developers who maintain smaller , less popular platforms to maintain evolving information . IwillextendDraftywithanewfeaturenamedDataBaits , tocontin - uously attract and engage users by automatically providing random insights generated from Drafty’s information after each edit . Drafty will tweet each DataBait with a link back to Drafty to continuously track users and understand if DataBaits can increase their engage - ment with Drafty . A DataBait is a statistic wrapped in sentence form . First , it takes a set of sample inputs from a tabular dataset . From Drafty’s CS Professors dataset , it could use the columns “SubField” and “JoinYear” and the value “Human - Computer Interaction . ” This would produce a statistic about the change over time in the number ofprofessorswhospecializeinHuman - ComputerInteraction : “Over the past 25 years , the total number of CS professors who specialized in Human - Computer Interaction increased 10 times . ” I have devel - oped 15 different types of DataBaits covering ordinal and time - series data and historical events as inputs to ensure users see a random variety of insights . 5 . 3 Extending Remote Readability Tests : The Virtual Readability Lab I have developed a suite of remote readability tests to study users’ font preferences , reading speed , and reading comprehension while randomly changing the text’s design [ 3 , 32 , 35 , 36 , 38 ] . Users are pro - vided font recommendations after completing a remote readability test . These tests serve as the basis to develop the Virtual Readabil - ity Lab ( VRL ) . How to personalize information design to augment human reading performance is the research question . One novel contribution to date is that our tests normalize font size based on human perception [ 36 ] . Collecting enough information to accomplish this is daunting , as there are over 800 , 000 publicly available digital fonts . This in - formation becomes out - of - date and less useful with the creation of new fonts , device types , and the ever - changing default fonts of software , browsers , andoperatingsystems . Whilethedigitalreading population currently skews younger , this population will continue to grow and diversify in age . My preliminary work [ 36 ] shows that age is an essential factor when personalizing font choice in combi - nation with other research [ 8 , 9 ] . Maintaining and developing this set of evolving information can benefit typographers , designers , and readers better understand how to manipulate information design to augment reading performance . My preliminary work recruits paid crowd workers to bootstrap this process . However , to build an extensive set of digital reading data , it will be necessary to attract visitors to voluntarily similar to LabInTheWild [ 26 ] . While the Virtual Readability Lab will allow userstocomparetheirresultswithothers , itwillalsopersonalizeeach readabilitytestwithrandomizedexamplesfromauser’spriorresults . This way , every readability test will personalize the next , thus moti - vatinguserstotaketeststocontributenewinformationcontinuously . 6 CONCLUSION My research focuses on developing and deploying asynchronous collaboration systems in the wild to maintain evolving informa - tion . These systems will provide random examples to the individual users that can help them immediately , thus motivating them to con - tribute new information continuously . These contributions create high - quality sources of information for the community . For exam - ple , Drafty’s information helps power CS Open Rankings . Further - more , Sketchy has empowered remote sketching activities during the COVID - 19 pandemic . By attracting continuous contributions , the underlying information overcomes its temporal constraints to remain relevant and attract the attention of new users . REFERENCES [ 1 ] BryanAlexander . 2020 . Thelittlespreadsheetthatcould , anddid : crowdsourcing COVID - 19 , higher education , data , and stories . https : / / bryanalexander . org / research - topics / the - little - spreadsheet - that - could - and - did - crowdsourcing - covid - 19 - higher - education - data - and - stories / . ( Accessedon04 / 12 / 2021 ) . [ 2 ] Abdullah X Ali , Erin McAweeney , and Jacob O Wobbrock . 2021 . Anachronism byDesign : UnderstandingYoungAdults’PerceptionsofComputerIconography . InternationalJournalofHuman - ComputerStudies 151 ( 2021 ) , 102599 . [ 3 ] RachelVBall , DaveBMiller , ShaunWallace , KathlynCamargoMacias , Mahmoud Ibrahim , ErnestoRobalinoGonzaga , OlgaKarasik , DekaiRRohlsen - Neal , Sarah Barrientos , Edward A Ross , et al . 2021 . Optimizing Electronic Health Records Through Readability . In Proceedings of the International Symposium on Human FactorsandErgonomicsinHealthCare . SAGEPublications , LosAngeles , CA , 65 – 70 . [ 4 ] Michael S Bernstein . 2013 . Crowd - powered systems . KI - Künstliche Intelligenz 27 , 1 ( 2013 ) , 69 – 73 . [ 5 ] MichaelSBernstein , GregLittle , RobertCMiller , BjörnHartmann , MarkSAcker - man , DavidRKarger , DavidCrowell , andKatrinaPanovich . 2010 . Soylent : aword processorwithacrowdinside . In Proceedingsofthe23ndannualACMsymposium onUserinterfacesoftwareandtechnology . ACM , NewYork , NY , USA , 313 – 322 . [ 6 ] AnaCaraban , EvangelosKarapanos , DanielGonçalves , andPedroCampos . 2019 . 23waystonudge : Areviewoftechnology - mediatednudginginhuman - computer interaction . In Proceedings of the 2019 CHI Conference on Human Factors in ComputingSystems . ACM , NewYork , NY , USA , 1 – 15 . [ 7 ] John Joon Young Chung , Jean Y Song , Sindhu Kutty , Sungsoo Hong , Juho Kim , andWalterSLasecki . 2019 . Efficientelicitationapproachestoestimatecollective crowdanswers . ProceedingsoftheACMonHuman - ComputerInteraction 3 , CSCW ( 2019 ) , 1 – 25 . AsynchronousCollaborationSystemsforEvolvingInformation CHI’22ExtendedAbstracts , April29 - May5 , 2022 , NewOrleans , LA , USA [ 8 ] Jonathan Dobres , Bryan Reimer , and Nadine Chahine . 2016 . The effect of font weight and rendering system on glance - based text legibility . In Proceedings of the 8th International Conference on Automotive User Interfaces and Interactive VehicularApplications . ACM , ACM , NewYork , NY , USA , 91 – 96 . [ 9 ] JonathanDobres , BenjaminWolfe , NadineChahine , andBryanReimer . 2018 . The effectsofvisualcrowding , textsize , andpositionaluncertaintyontextlegibility ataglance . Appliedergonomics 70 ( 2018 ) , 240 – 246 . [ 10 ] Anca Dumitrache . 2015 . Crowdsourcing disagreement for collecting semantic annotation . In Proc . ESWC . Springer , NewYork , NY , USA , 701 – 710 . [ 11 ] Ujwal Gadiraju , Ricardo Kawase , Stefan Dietze , and Gianluca Demartini . 2015 . Understanding Malicious Behavior in Crowdsourcing Platforms : The Case of Online Surveys . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems ( Seoul , Republic of Korea ) ( CHI ’15 ) . Association for Computing Machinery , New York , NY , USA , 1631 – 1640 . https : / / doi . org / 10 . 1145 / 2702123 . 2702443 [ 12 ] AaronHalfaker , RStuartGeiger , JonathanTMorgan , andJohnRiedl . 2013 . The riseanddeclineofanopencollaborationsystem : HowWikipedia’sreactiontopop - ularityiscausingitsdecline . AmericanBehavioralScientist 57 , 5 ( 2013 ) , 664 – 688 . [ 13 ] Benjamin Mako Hill and Aaron Shaw . 2020 . Wikipedia and the End of Open Collaboration . Wikipedia 20 ( 2020 ) . [ 14 ] AniketKittur , JeffreyVNickerson , MichaelBernstein , ElizabethGerber , Aaron Shaw , JohnZimmerman , MattLease , andJohnHorton . 2013 . Thefutureofcrowd work . In Proceedings of the 2013 Conference on Computer Supported Cooperative Work . ACM , NewYork , NY , USA , 1301 – 1318 . [ 15 ] ChinmayKulkarni , StevenPDow , andScottRKlemmer . 2014 . Earlyandrepeated exposure to examples improves creative work . In Design thinking research . Springer , NewYork , NY , USA , 49 – 62 . [ 16 ] NatalieKupferbergandBridgetMcCrateProtus . 2011 . Accuracyandcompleteness ofdruginformationinWikipedia : anassessment . JournaloftheMedicalLibrary Association : JMLA 99 , 4 ( 2011 ) , 310 . [ 17 ] Winter Mason and Duncan J . Watts . 2009 . Financial Incentives and the “PerformanceofCrowds” . In ProceedingsoftheACMSIGKDDWorkshoponHuman Computation ( Paris , France ) ( HCOMP ’09 ) . ACM , New York , NY , USA , 77 – 85 . https : / / doi . org / 10 . 1145 / 1600150 . 1600175 [ 18 ] Arpit Merchant , Daksh Shah , Gurpreet Singh Bhatia , Anurag Ghosh , and PonnurangamKumaraguru . 2019 . Signalsmatter : understandingpopularityand impactofusersonstackoverflow . In TheWorldWideWebConference . ACM , New York , NY , USA , 3086 – 3092 . [ 19 ] MarcMiquel - Ribé , CristianConsonni , andDavidLaniado . 2021 . WikipediaEditor Drop - Off . ( 2021 ) . [ 20 ] MeredithRingelMorris , JeffreyP . Bigham , RobinBrewer , JonathanBragg , Anand Kulkarni , Jessie Li , and Saiph Savage . 2017 . Subcontracting Microwork . In Proceedingsofthe2017CHIConferenceonHumanFactorsinComputingSystems ( Denver , Colorado , USA ) ( CHI ’17 ) . ACM , New York , NY , USA , 1867 – 1876 . https : / / doi . org / 10 . 1145 / 3025453 . 3025687 [ 21 ] Meredith Ringel Morris , Jaime Teevan , and Katrina Panovich . 2010 . What Do PeopleAskTheirSocialNetworks , andWhy ? : ASurveyStudyofStatusMessage Q & A Behavior . In Proceedings of the SIGCHI Conference on Human Factors in ComputingSystems ( Atlanta , Georgia , USA ) ( CHI’10 ) . ACM , NewYork , NY , USA , 1739 – 1748 . https : / / doi . org / 10 . 1145 / 1753326 . 1753587 [ 22 ] BabakNaderi . 2018 . Motivationofworkersonmicrotaskcrowdsourcingplatforms . Springer , NewYork , NY , USA . [ 23 ] Alexandra Papoutsaki , Hua Guo , Danae Metaxa - Kakavouli , Connor Gramazio , Jeff Rasley , Wenting Xie , Guan Wang , and Jeff Huang . 2015 . Crowdsourcing fromScratch : APragmaticExperimentinDataCollectionbyNoviceRequesters . In Proceedings of the Third AAAI Conference on Human Computation and Crowdsourcing ( HCOMP ) . AAAI , MenloPark , CA , USA , 140 – 149 . [ 24 ] Alexander J . Quinn and Benjamin B . Bederson . 2011 . Human Computation : A Survey and Taxonomy of a Growing Field . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Vancouver , BC , Canada ) ( CHI’11 ) . AssociationforComputingMachinery , NewYork , NY , USA , 1403 – 1412 . https : / / doi . org / 10 . 1145 / 1978942 . 1979148 [ 25 ] Sam Ransbotham and Gerald C Kane . 2011 . Membership turnover and collab - orationsuccessinonlinecommunities : Explainingrisesandfallsfromgracein Wikipedia . MisQuarterly 35 ( 2011 ) , 613 – 627 . [ 26 ] Katharina Reinecke and Krzysztof Z Gajos . 2015 . LabintheWild : Conducting large - scaleonlineexperimentswithuncompensatedsamples . In Proceedingsofthe 18thACMconferenceoncomputersupportedcooperativework & socialcomputing . ACM , NewYork , NY , USA , 1364 – 1378 . [ 27 ] SoumyaSarkarandAnimeshMukherjee . 2021 . WhenExpertiseGoneMissing : UncoveringtheLossofProlificContributorsinWikipedia . In TowardsOpenand TrustworthyDigitalSocieties : 23rdInternationalConferenceonAsia - PacificDigital Libraries , ICADL 2021 , Virtual Event , December 1 – 3 , 2021 , Proceedings . Springer Nature , Basingstoke , UnitedKingdom , 291 . [ 28 ] LindaSee , AlexisComber , CarlSalk , SteffenFritz , MarijnvanderVelde , Christoph Perger , ChristianSchill , IanMcCallum , FlorianKraxner , andMichaelObersteiner . 2013 . Comparing the quality of crowdsourced data contributed by expert and non - experts . PloSone 8 , 7 ( 2013 ) , e69958 . [ 29 ] PaoSiangliulue , JoelChan , KrzysztofZGajos , andStevenPDow . 2015 . Providing timely examples improves the quantity and quality of generated ideas . In Proceedingsofthe2015ACMSIGCHIConferenceonCreativityandCognition . ACM , NewYork , NY , USA , 83 – 92 . [ 30 ] Shaun Wallace , Zoya Bylinskii , Jonathan Dobres , Bernard Kerr , Sam Berlow , Rick Treitman , Nirmal Kumawat , Kathleen Arpin , Dave B . Miller , Jeff Huang , andBenD . Sawyer . 2022 . TowardsIndividuatedReadingExperiences : Different Fonts Increase Reading Speed for Different Individuals . ACM Transactions on Computer - HumanInteraction ( TOCHI ) ( 2022 ) , 1 – 54 . [ 31 ] Shaun Wallace , Long Do , Alice Marbach , and Jeff Huang . 2020 . CS Open Rankings . Brown University . Retrieved September 22 , 2021 from https : / / drafty . cs . brown . edu / csopenrankings / [ 32 ] ShaunWallace , JonathanDobres , andBenDSawyer . 2021 . ConsideringtheSpeed andComprehensionTrade - OffinReadingMediatedbyTypography . Journalof Vision 21 , 9 ( 2021 ) , 2249 – 2249 . [ 33 ] Shaun Wallace , Brendan Le , Luis A Leiva , Aman Haq , Ari Kintisch , Gabrielle Bufrem , LindaChang , andJeffHuang . 2020 . Sketchy : Drawinginspirationfrom the crowd . Proceedings of the ACM on Human - Computer Interaction 4 , CSCW2 ( 2020 ) , 1 – 27 . [ 34 ] Shaun Wallace , Alexandra Papoutsaki , Neilly H Tan , Hua Guo , and Jeff Huang . 2021 . Case Studies on the Motivation and Performance of Contributors Who Verify and Maintain In - Flux Tabular Datasets . Proceedings of the ACM on Human - ComputerInteraction 5 , CSCW2 ( 2021 ) , 1 – 25 . [ 35 ] ShaunWallace , RickTreitman , JeffHuang , BenDSawyer , andZoyaBylinskii . 2020 . AcceleratingAdultReaderswithTypeface : AStudyofIndividualPreferencesand Effectiveness . In ExtendedAbstractsofthe2020CHIConferenceonHumanFactors inComputingSystems . ACM , NewYork , NY , USA , 1 – 9 . [ 36 ] Shaun Wallace , Rick Treitman , Nirmal Kumawat , Kathleen Arpin , Jeff Huang , BenSawyer , andZoyaBylinskii . 2020 . IndividualDifferencesinFontPreference & Effectiveness as Applied to Interlude Reading in the Digital Age . Journal of Vision 20 , 11 ( 2020 ) , 412 – 412 . [ 37 ] ShaunWallace , LucyVanKleunen , MarianneAubin - LeQuere , AbrahamPeterkin , Yirui Huang , and Jeff Huang . 2017 . Drafty : Enlisting Users to be Editors who MaintainStructuredData . In ProceedingsoftheFifthAAAIConferenceonHuman ComputationandCrowdsourcing ( HCOMP ) . AAAI , MenloPark , CA , USA , 187 – 196 . [ 38 ] AleenaWatsonandShaunWallace . 2021 . ImprovingReadingOutcomesUsing DigitalReadingRulersforReadersWith & WithoutDyslexia . JournalofVision 21 , 9 ( 2021 ) , 2650 – 2650 . [ 39 ] Wikipedia . 2021 . Missing Wikipedians . Wikimedia Foundation , Inc . Re - trieved September 30 , 2021 from https : / / en . wikipedia . org / wiki / Wikipedia : Missing _ Wikipedians