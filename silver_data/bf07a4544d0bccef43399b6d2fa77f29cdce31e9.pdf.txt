444 Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs CHI - HSIEN ( ERIC ) YEN , Computer Science , University of Illinois at Urbana - Champaign , USA HAOCONG CHENG , Information Sciences , University of Illinois at Urbana - Champaign , USA GRACE YU - CHUN YEN , Computer Science , University of Illinois at Urbana - Champaign , USA BRIAN P . BAILEY , Computer Science , University of Illinois at Urbana - Champaign , USA YUN HUANG , Information Sciences , University of Illinois at Urbana - Champaign , USA Causal knowledge is of interest in many areas , such as statistics and machine learning , as it allows people and algorithms to predict outcomes and make data - driven decisions . Researchers in CSCW have proposed tools and workflows to externalize causal knowledge or beliefs from a group of people ; however , most of the generated causal diagrams lack a deeper understanding of the causal mechanisms or could not capture diverse beliefs . By integrating narratives with causal diagrams , we implemented an interactive system that allows users to 1 ) write narratives to rationalize their perceived causal relationships , 2 ) visualize their causal models using directed diagrams , and 3 ) review and utilize others’ causal diagrams and narratives . We conducted a user study ( N = 20 ) to learn how participants leveraged this integrated approach to externalize their perceived causal models for a given application context . Our results showed that the approach implemented in our tool enabled the externalization of users’ causal beliefs ( e . g . , how and why a causal relationship might occur ) , allowed blind spots of individuals’ causal reasoning to be revealed ( e . g . , learning new ideas from peers ) , and inspired their causal reasoning ( e . g . , revising or adding new causal relationships ) . We also identified the individual differences in people’s causal beliefs and observed the impacts of showing others’ causal models when one is building his / her causal diagram and narratives . This work provides practical design implications for developing collaborative tools that facilitate capturing and sharing causal beliefs . CCS Concepts : • Human - centered computing → Empirical studies in collaborative and social com - puting ; Empirical studies in HCI . Additional Key Words and Phrases : Causal Beliefs ; Causal Diagrams ; Explanatory Narratives ; Knowledge Externalization ; Knowledge Sharing ACM Reference Format : Chi - Hsien ( Eric ) Yen , Haocong Cheng , Grace Yu - Chun Yen , Brian P . Bailey , and Yun Huang . 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs . Proc . ACM Hum . - Comput . Interact . 5 , CSCW2 , Article 444 ( October 2021 ) , 27 pages . https : / / doi . org / 10 . 1145 / 3479588 Authors’ addresses : Chi - Hsien ( Eric ) Yen , cyen4 @ illinois . edu , Computer Science , University of Illinois at Urbana - Champaign , Urbana , Illinois , USA ; Haocong Cheng , haocong2 @ illinois . edu , Information Sciences , University of Illinois at Urbana - Champaign , Champaign , Illinois , USA ; Grace Yu - Chun Yen , yyen4 @ illinois . edu , Computer Science , University of Illinois at Urbana - Champaign , Urbana , Illinois , USA ; Brian P . Bailey , bpbailey @ illinois . edu , Computer Science , University of Illinois at Urbana - Champaign , Urbana , Illinois , USA ; Yun Huang , yunhuang @ illinois . edu , Information Sciences , University of Illinois at Urbana - Champaign , Champaign , Illinois , USA . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . © 2021 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . 2573 - 0142 / 2021 / 10 - ART444 $ 15 . 00 https : / / doi . org / 10 . 1145 / 3479588 Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 2 Chi - Hsien ( Eric ) Yen et al . 1 INTRODUCTION Causal knowledge and beliefs play a central role in people’s reasoning [ 60 , 66 ] , learning [ 21 , 63 ] , and decision - making [ 25 , 31 ] . While the topic of causality has a long research history in philosophy and psychology , it is attracting increasing interest in many application domains , such as statistics , machine learning , and artificial intelligence , due to open - source datasets and advanced causal inference frameworks [ 49 , 61 , 69 ] . With causal knowledge , people and algorithms are able to perform counterfactual reasoning , predict outcomes of actions more reliably , and make better decisions [ 37 , 50 ] . For example , while data may show a correlation that one medical treatment has a higher success rate than another treatment , knowing that a confounding factor , e . g . , disease severity , causally affects both “treatment choice” and “success rate” enables one to better compare and choose the best treatment [ 38 ] . How to collect causal knowledge or causal beliefs remains an open question . Externalizing causal knowledge from data has been challenging due to technical constraints and the complex nature of causal relationships . Researchers have attempted to learn causal structures from data and made breakthroughs with statistical methods and artificial intelligence tools [ 49 , 61 ] ; however , many challenges remain . For example , algorithms cannot provide explanations to a relationship that is discovered from data because machines do not understand the semantic meaning of the variables and do not have the real world knowledge [ 69 ] . On the other hand , people who have domain expertise or relevant personal experiences in the real - world can provide tacit knowledge , the internalized knowledge from one’s own experience [ 18 , 33 ] , to help explain why and how certain relationships are formed . Judea Pearl – known for developing mathematical frameworks for causal inference – has said : “You are smarter than your data . Data do not understand causes and effects ; humans do” ( The Book of Why , 2018 ) [ 50 ] . In this paper , we focus on advancing knowledge of the practices and effects of externalizing and sharing causal beliefs 1 across people , both of which are necessary steps for collaborative causal reasoning . Our first research goal is to understand and analyze individual differences when people use diagrams and narratives to externalize causal beliefs . Researchers in the CSCW and HCI communities have developed different types of collaborative tools to collect causal knowledge and beliefs from a group of people . For example , Berenberg and Bagrow developed crowdsourcing algorithms that allowed crowd workers on Amazon Mechanical Turk to generate a large - scale causal attribution network collectively , and the proposed algorithms were efficient for updating existing relationships [ 8 ] . However , most prior work only focused on the causal diagram but not on collecting or analyzing narratives where people can provide relevant causal beliefs . We aim to collect the causal beliefs of people through the integration of diagrams and narratives and analyze the characteristics and differences in the language used in narratives . Our second research goal is to identify the impacts of showing others’ causal beliefs to people when they develop and represent their own causal reasoning using diagrams and narratives . Literature has shown that sharing causal knowledge and beliefs may mitigate biases caused by limited cognitive capacities of individuals , e . g . , Heuer [ 34 ] recommended that sharing and collecting as many hypotheses as possible from a group of people could enable a less biased intelligence analysis . Similarly , causal reasoning involves generating alternative causal hypotheses based on personal beliefs ; therefore , investigating the effects of sharing causal knowledge and beliefs is an important research aspect for collaborative causal reasoning . Willett et al . developed a web - based tool and tested different strategies to collect crowd workers’ explanations of data visualization with high quality and diversity ; however , the targeted relationships were not causal , and the system did 1 As causality is difficult to prove , we consider causal beliefs in this paper that refers to how people believe or understand causal relationships in the real world , regardless of whether the understanding is proved to be true . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 3 not integrate narrative with causal diagrams [ 70 ] . As literature has demonstrated that graphical diagrams are effective to support causal reasoning and knowledge transfer [ 23 , 42 , 72 ] , we aim to understand the process and effects when people use diagrams and narratives to reason with others’ causal beliefs . To achieve the two study goals , we designed and built a system , CausalIDEA , which allows people to construct a causal diagram and provide explanatory narratives for each causal relationship they hypothesize . They can also review others’ causal models to find unconsidered relationships and modify their own diagrams . Given the design , we also explore how different cues may inspire an individual’s causal reasoning processes , i . e . , graphical cues from causal diagrams , textual cues from narratives , and inspiration prompts that users can request in the system . We recruited 20 participants to use our system and externalize their causal beliefs for a given application context . We provided a data schema of an application context instead of actual data sets because we focus on people’s existing causal beliefs rather than how people identify causal relation - ships from data . The results showed that having users draw causal diagrams and write narratives can reveal their tacit knowledge and diverse hypotheses , such as positive and negative correlations between the same pair of variables . Furthermore , participants often rationalize the same correlations differently and imply hidden mediating or confounding variables in their narratives . Such diverse perspectives could help people overcome blind spots and biases and consider alternative hypothe - ses [ 34 ] . Indeed , we found that after reviewing others’ causal narratives , participants discovered new causal relationships that they failed to include at the beginning and thus increased the number of causal links in their own diagrams . In addition , our study demonstrated how participants could utilize different cues while constructing , reviewing , and modifying causal diagrams . For example , the complexity of a peer’s causal diagram impacted participants’ perceptions of diagram usefulness and narrative quality . Based on the findings , we provide several design implications and future research directions for extending our tool to support collaborative causal reasoning applications , such as understanding how non - experts would perceive the causal effects of a policy change , or collecting domain knowledge from members of a community to assist in analyzing social data about the community . Our research makes several contributions to the CSCW and HCI communities : ( 1 ) we discover and demonstrate the benefits of extracting causal beliefs through a design that integrates causal diagrams and narratives ; ( 2 ) we show how sharing causal beliefs through the integrated approach promotes users to utilize and incorporate others’ causal beliefs into their own causal reasoning ; and ( 3 ) we discuss new research opportunities and provide design implications for developing collaborative tools for capturing and sharing causal beliefs or causal knowledge . 2 RELATED WORK 2 . 1 Extracting Causal Knowledge from Individuals and Groups Many knowledge sharing systems such as Wikipedia , Opinion Space , and Yahoo Answer are built with the belief that “everyone knows something” [ 2 , 24 ] . Causal knowledge , the knowledge that people acquire through learning or life experiences about how events or variables might causally influence each other , could potentially be learned from people [ 60 ] . Prior works have attempted to extract causal knowledge from a large collection of documents . Gordon et al . [ 28 ] developed statistical information retrieval approaches to extract causal rela - tionships from millions of personal stories on web blogs . They showed that the learned causal information improves machine performance in commonsense causal reasoning . However , as ac - knowledged in their work , the causal information is mostly left implicit in personal blogs . That is , instead of using explicit causative words such as cause , effect , or consequence , many sentences Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 4 Chi - Hsien ( Eric ) Yen et al . use implicit causal verbs to describe a causal chain , e . g . , “The sun melted his wings . ” Such implicit causal relationships need semantics analysis and background knowledge to be inferred [ 27 ] , and studies showed that there is a limited amount of causal knowledge that can be extracted from the documents even when more data is used [ 28 ] . Researchers have also utilized computational methods or human annotations to find causal relationships from other sources of knowledge bases , such as Wikipedia [ 32 ] and WordNet lexical database [ 27 ] . However , these approaches are limited because these sources are not created specif - ically to describe causal relationships ; therefore , many causal chains are still implicitly implied . Besides , there is no efficient way to communicate with the knowledge base creators and ask them to provide causal knowledge specifically about a dataset . Therefore , these methods are limited to the domain of the existing knowledge base and cannot be easily applied when a specific dataset is being analyzed . To directly extract causal knowledge from a crowd , Bongard et al . utilized an interactive survey to crowdsource possible causes of behavioral outcomes [ 14 ] . When answering questions about several personal health habits , the survey respondents compared their answers to other groups with higher or lower BMI and created new health behavior questions that they believed their answers would differ and explain the BMI differences . Their results suggest that people can collectively uncover many of the factors known to contribute to obesity from health literature . Berenberg and Bagrow [ 8 ] further developed a crowdsourcing workflow that also utilized an interactive survey to build a large causal network from a crowd . In each micro - task , a crowd worker was given a causal path and refined it by adding , deleting , or reordering the nodes of the causal chain . Their studies show that this iterative pathway refinement approach is more efficient than single - link tasks , where a crowd worker only validates a single link at a time , while the generated causal links are of similar quality . However , their study did not allow workers to give explanations to a causal link or generate an individual causal diagram to reflect their full knowledge . Our tool and study explore how causal diagrams and narratives could be used to externalize causal knowledge . 2 . 2 Understanding People’s Mental Models and Beliefs Research in psychology , reasoning , memory , and many other related fields has explored the mech - anisms of how people conceptualize and store knowledge about how things work . One of the commonly used techniques is mental models , which is generally defined as an internal repre - sentation of external reality , such as a technology system [ 19 , 36 ] . Mental models are commonly represented as diagrams , where the structure is analogous to the structure of the target system . In the context of causality , Causal Model Theory hypothesizes that people base causal reasoning on causal models , where causal relations in the world are represented as directed acyclic diagrams [ 60 , 66 ] . People could then use the model to mentally simulate and predict the causal outcomes and make decisions [ 67 ] . This theory can be considered as a special case of mental models , where the target system is a part of the real world , and the mental model represents how a person believes each event or variable might causally affect each other in reality . Based on these theories , researchers have been investigating the characteristics of people’s mental models or beliefs . For example , Norman had observed several traits about mental models , such as being incomplete , unstable , or even unscientific , which means mental models may include knowledge or beliefs that could be invalid [ 46 ] . Based on Causal Model Theory , Rozenblit and Keil found that people often possess only the skeleton of causal knowledge ( the connections between causes and effects ) but do not necessarily understand the underlying causal mechanisms [ 55 ] . Built on this literature , our study focuses on the causality context and explores the characteristics and individual differences of the causal models externalized through diagrams and narratives . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 5 2 . 3 Drawing and Sharing Causal Knowledge Many existing tools , such as Microsoft Visio , Gliffy , and Lucid Chart , enable users to easily draw their mental models as graphical diagrams . These tools often provide various node shapes and arrow styles to help people better illustrate their models . However , these generic diagramming tools are not specifically designed for causal reasoning , and therefore lacking the flexibility or efficiency in diagramming and sharing causal knowledge . To address these issues , some expert tools were built for organizing and sharing knowledge among groups of people [ 1 ] . For collective causal knowledge , there have been works that utilized mental models , also called cognitive maps [ 4 ] , to capture the causal beliefs held by domain experts or employees in an organization . For example , Boland et al . [ 11 ] developed SPIDER , a system where managers could create individual cognitive maps and share them to support communication and distributed decision - making . Pfaff et al . [ 51 – 53 ] held workshops where domain experts were gathered to collectively create causal diagrams , while crowds were tasked to quantify the weights of the causal links . Besides causal diagrams , other forms of knowledge sharing have also been extensively studied in the visual analytics domain . For example , the hypothesis - evidence matrix [ 26 , 34 ] , where all possible hypotheses and evidence are matched and analyzed in a table , has been widely used for collaborative intelligence analysis ( e . g . , CACHE [ 10 ] , SAVANT [ 29 , 30 ] , ManyInsights [ 15 ] , SRS [ 54 ] ) . Studies have shown that sharing a hypothesis window between analysts could significantly increase task performance [ 29 ] . Zhao et al . [ 72 ] utilized a concept map to support knowledge transfer in asynchronous collaborative analysis , which helped increase the awareness of prior reasoning progress and insights . Willet et al . [ 71 ] developed CommentSpace , an interactive data visualization system with a threaded discussion area where analysts can use tags ( hypothesis , question , to - do ) and links ( evidence - for , evidence - against ) in their comments . They found that participants who can use tags in the comments generated more replies , implying that tags encourage discussion among the collaborators . The above literature shows that causal diagrams are beneficial for knowledge sharing and collaborative analysis for domain experts . However , little is known about how members of the general public externalize their causal beliefs through causal diagrams and narratives and how they react to others’ causal models while modifying their own . As everyone acquires causal beliefs through their own experiences and may have valuable tacit knowledge worth being externalized [ 60 ] , our study fills this research gap and studies how various cues help a general user perform these causal reasoning processes . 3 SYSTEM DESIGN We designed a system , CausalIDEA ( Causal Inspiration Data rEAsoning ) , to explore and investigate techniques for users to externalize and share their beliefs about causal relationships in a dataset . Figure 1 shows the main user interface of our system . The system was implemented as a Web application using the Python Django framework , a Postgres database , and D3 . js . Our system enables the following reasoning scenarios : Construct a causal diagram . Prior works show that graphical diagrams are effective for rea - soning and knowledge sharing ; therefore , to better support users to externalize their beliefs about possible causal relationships , we designed a set of features for intuitive diagram construction and revision . The Variable List ( A ) shows all the available variables as circles , color - coded by their stakeholder , e . g . , in Figure 1 , variables related to the reporter are orange while the variable related to the police agency is green . A user can drag a variable and drop it into the Causal Diagram Panel ( B ) . They can then draw an arrow from the edge of one variable to another , expressing a belief Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 6 Chi - Hsien ( Eric ) Yen et al . A B C D “Inspire Me” Pop - up window E “Add a New Variable” Pop - up window F Fig . 1 . The user interface of CausalIDEA showing the data schema used in the user study . The main features of the user interface are : ( A ) Variable List , ( B ) Causal Diagram Panel , ( C ) Causal Narrative Panel , ( D ) Action Bar , ( E ) Pop - up window for “Inspire Me” button , ( F ) Pop - up window for “Add a New Variable” button . Users can drag variables from ( A ) into ( B ) and draw arrows between any two variables . All narrative blocks for each arrow are shown in ( C ) . When a user clicks a button in ( D ) , the corresponding pop - up window , ( E ) or ( F ) , will slide in on the top of the page and gray out the background . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 7 that the first variable causally impacts the latter . This interaction design reinforces the causal order principle : users find it easiest to attend to the source object prior to the effect object [ 22 ] . A user can add a new variable to the diagram by selecting “Add a New Variable” in the Action Bar ( D ) . The user can then enter a name , data type , description , and stakeholder for the variable ( F ) . Users can also draw as many arrows as desired between the variables , as well as arrows that are opposite to an existing arrow to capture a bi - directional relationship . At any time , users can drag the variables in the panel to re - position nodes and organize the graphical layout . Provide tacit knowledge . Narratives are critical to perspective making during community knowledge sharing [ 12 ] ; thus , our design provides a narrative block for each arrow in the diagram to capture detailed beliefs and rationales from the users . Between the Causal Diagram Panel ( B ) and the Causal Narrative Panel ( C ) , each arrow corresponds to one narrative block , and the system auto - creates or deletes the narrative block with the corresponding arrow to ensure they are consistent with the causal diagrams . The interface also highlights the associated arrow when a participant is writing a narrative . Within a narrative block , a text box is provided for the user to elaborate on their belief about the causal relationship , such as why and how the causal variable might influence the effect variable . Under the text box , a user can use the slider to specify how strong they believe the causal relationship is on a 5 - point scale from weak ( 1 ) to strong ( 5 ) . While the rating is subjective , the feature allows the user to capture beliefs about the relative strengths of different relationships in the diagram . Request a machine - generated inspiration . As we found in our pilot study that users some - times got stuck without any guiding features , we designed an on - demand inspirational prompt to stimulate new ideas through the use of cognitive primes [ 56 ] . Users can click the “Inspire Me” button in the Action Bar ( D ) to get a machine - generated inspiration prompt ( E ) . The prompt shows a question in natural language that asks whether a variable might directly influence another , e . g . , “Do you think it is possible that the event category ( Category ) might directly influence the length of the event text provided by the reporter ( Text Length ) ” To generate a natural language prompt , our system stores phrases for each variable ( e . g . , “the event category” for Category ) to fill out the template of the question . Users may choose “Yes , ” “The Other Way Around , ” or “No” to respond to an inspiration prompt . When the user chooses “Yes” or “The Other Way Around , ” the system adds an arrow with the specified direction into the diagram and a narrative block that the user can write into as described above . If the user selects “No , ” the system prompts the user to provide their rationale and then generates a new inspiration and presents it . The two variables in the question are randomly chosen with the criterion that there are no direct arrows between the two variables in the diagram . We decided to implement it using random choices rather than suggesting relationships based on actual data or how many previous participants had drawn to avoid biasing users toward a dataset or other participants’ reasoning outcomes . Review others’ causal diagrams and narratives . Prior research has shown that an individual may be biased or have blind spots during reasoning [ 34 ] ; therefore , we provide other people’s beliefs in our design to help users expand or revise their diagrams . Figure 2 shows the interface for reviewing the causal diagrams and narratives generated by other users . When a user clicks on one of the tabs on the top ( A ) , the causal diagram and the narratives created by that person will be shown in the Diagram Panel ( B ) and the Narrative List ( C ) . Users cannot modify a peer’s causal diagram or narratives . Instead , they can react to each of the narratives by ( 1 ) marking the narrative as something they have not considered before , ( 2 ) upvote or downvote the narrative , or ( 3 ) leave a comment . The panel for reviewing other users’ diagrams ( Figure 2 ) is juxtaposed next to the user’s own in - progress diagram ( Figure 1 ) to enable visual comparison and further construction of their own diagram based on this comparison . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 8 Chi - Hsien ( Eric ) Yen et al . Fig . 2 . The interface for reviewing other people’s causal models in CausalIDEA : ( A ) Peer List , ( B ) Diagram Panel , and ( C ) Narrative List . Users can click on one of the tabs in ( A ) , which brings the peer’s causal diagram and narratives in ( B ) and ( C ) respectively . Users cannot modify the graph or narratives , but are allowed to mark , upvote , downvote , or comment on each of the peer narratives . 4 USER STUDY We conducted a user study to evaluate the effects of the tool on how users reason and describe their knowledge about possible causal relations in a data schema . The study was designed to answer two research questions : RQ1 : How does the integration of narratives and causal diagrams promote our understanding of people’s externalization of causal beliefs ? RQ2 : What are the effects of reviewing others’ causal beliefs in the integrated representation on people’s causal reasoning ? 4 . 1 Data Schema We developed a data schema , including variable names , types , and meta - descriptions , for the participants to use to reason with the system . We chose to use data schema instead of showing an actual data set for two reasons . First , as we focus on people’s existing causal beliefs instead of how they identify causal relationships from data patterns , providing data schema is sufficient for our research questions . Second , people may be influenced by the data when externalizing causal beliefs . For example , if the data shows a negative correlation between two variables , people could be inclined to think of ways to explain such a trend instead of coming up with a possible hypothesis Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 9 Name Type Possible Values Description Replied binary True / False Whether the police replied to the report Category categorical “Drugs / Alcohol” , “Noise Disturbance” , “Harassment / Abuse” , etc . The event type of the safety report Month categorical 1 , 2 , . . . , 12 The month when the safety report was submitted Hour categorical 0 , 1 , . . . , 23 The hour in a day when the safety report was submitted Has Location binary True / False Whether the reporter shared their location Text Length numerical Non - negative integers Length of the event description written by the reporter , measured in # of characters Anonymous binary True / False Whether the reporter chose to remain anonymous to the police Table 1 . Reasoning Task Material : the preset variables given in a community safety app context . that suggests a positive correlation . Similar approaches , i . e . , providing a data schema , were used in prior studies to collect people’s causal beliefs and knowledge [ 3 , 8 ] . To generate a realistic data schema , we adapted it from a real data set that was generated from a smartphone safety app . The safety app provides two - way communication between individuals and security teams . Using the app , a person who experiences an incident such as harassment or disruptive noise can report the incident to the security team and receive assistance through the in - app chat feature . When submitting a report , the user selects an event category , writes a description of the event , enters the date and location , and chooses whether to provide their name or remain anonymous to the security team . A security staff member can then reply to the report through the in - app chatting function . We chose the schema for this data set because safety and security is a common yet critical aspect of our daily lives . Reasoning about this data schema does not require specific domain expertise ; therefore , we can observe how a non - expert would use this system . Second , this data set contains many possible causal relationships that the data itself cannot explain . For example , quantitative analysis on the data has shown that whether a safety report is replied to is affected by reporter anonymity and event category [ 43 ] . However , data analysis alone cannot explain why people display such behavior . Our system allows this localized knowledge to be captured and represented in the diagram . Seven variables for this data schema were chosen for the study : Replied , Category , Anonymous , Month , Hour , Has Location , and Text Length . Table 1 summarizes the meta - descriptions of these variables . This table was available to the participants during the study ; however , the actual dataset was not provided to avoid directing their attention to statistical details , which was not the focus of the study . We made it clear to the participants that their task in the study was to externalize as many possible causal relationships that they believed exist without needing to perform any actual data analysis . In addition , they could add any new variables without considering whether the variable could be easily captured in the dataset . The goal of this study is to understand people’s causal beliefs and how they externalize their beliefs through our system . 4 . 2 Participants Twenty participants ( 11 women , 9 men ) were recruited through flyers , social networks , and online forums . The only inclusion criterion is that they must be at least 18 years old and have basic fluency in English . As our intended users are members of the general public , we did not require Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 10 Chi - Hsien ( Eric ) Yen et al . the participants to have statistics knowledge . We also did not require any expertise or familiarity with causal inference as causal beliefs are naturally learned and possessed by every member of the general public . The participants aged from 18 to 53 years old ( Median = 21 ) , holding or pursuing college or advanced degrees ( 12 bachelor’s , 7 master’s , and 1 doctoral ) with different majors ( five computer science , three information sciences , three biology , and the others are from art , advertising , math , etc . ) . All the participants reported basic data reasoning experience . They all had used at least one of the popular data visualization tools ( Excel : 17 , Python : 10 , R : 8 , Tableau : 2 ) and reported that they understood descriptive statistics ( mean , median , and standard deviation ) . Nineteen participants reported familiarity with regressions . Three participants had used a similar safety reporting app . 4 . 3 Procedure The study was conducted individually either in the laboratory or online if meeting in person was not possible . Each participant first worked through a tutorial for the tool , where a data schema of an application context different from the actual task was used . We demonstrated each feature and asked the participants to practice using each feature ( i . e . , draw an arrow , write a narrative , use “Inspire Me , ” and add a new variable ) . During the tutorial session , we encouraged them to write a narrative with an explanation ( why X influences Y ) and an example ( what is the trend between X and Y ) to help them get an idea of what can be written . After the practice session , the safety app context and the data schema we described in Sec . 4 . 1 were introduced , and two main tasks were given . In Task 1 , participants constructed a causal diagram and wrote narratives for the safety app data schema . We asked them to draw all the causal relationships that they believed exist based on their prior experience and knowledge . Again , we provided a data schema because we focused on their causal beliefs rather than how they could identify causal relationships from data . They could use “Inspire Me” or add new variables at any time . During the task , we did not comment on the validity of their causal hypotheses , but only answered questions about the interface or the data schema . We also did not proactively ask the participants to write explanations or examples while they were writing narratives because we did not want to bias them . Participants continued Task 1 until they felt they had captured all the relationships of interest and then proceeded to the second task . In Task 2 , participants reviewed the peers’ causal diagrams and modified their own diagrams if desired . For this task , the first eight participants ( P01 - P08 ) received the same causal diagram , which was adapted from a diagram constructed in a pilot test . The following twelve participants ( P09 - P20 ) received three causal diagrams : the same diagram from the pilot test and two additional diagrams selected from the prior eight participants , P02’s and P07’s diagrams ( refer to Figure 6 ) . From the visual aspect , P02’s diagram is the most complex as it contains more intersecting arrows , while P07’s diagram has the fewest nodes and arrows . We wanted to observe how such differences in the graph complexity may influence participants’ behavior . Participants were able to see the diagram and all narratives and strength ratings for each arrow on each shared diagram . Note that the participants did not see the diagrams from all previous participants ; they could only see the diagrams we showed . Participants were then interviewed for us to learn more about their experiences with the tool . The interview questions covered their strategies , e . g . , “What is your overall strategy for constructing your causal diagram ( reviewing others’ causal diagrams and modifying yours ) in Task 1 ( Task 2 ) ? ” and the benefits or drawbacks of different features , e . g . , “Did you find using ‘Inspire Me’ helpful or not helpful ? Why ? ” Follow - up questions were asked to get deeper insights besides simple binary answers . To reduce the effect of response biases , we created an open and casual interview conversation and often reminded the participants that we were looking for honest feedback and that criticisms were Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 11 always welcome . On average , the whole study session took 1 . 5 hours to complete . The participants were compensated with 10 dollars per hour at the end of the interview . 4 . 4 Data Analysis The data collected in our study include the causal diagrams , the narratives , the audio and screen recordings taken during the tasks and post - study interviews , and the action logs . We conducted a content analysis on the narratives to understand the characteristics of the text . Two authors first met and discussed the criteria of each label dimension . They then independently labeled the same subset of the narratives and compared the outcome together to resolve the inconsistency and refine the criteria , repeating this process until the inter - rater reliability reached a moderate or high agreement for each dimension ( final Cohen’s Kappa [ 17 ] ranges from 0 . 5 to 0 . 8 ) . Afterward , the two authors divided the remaining narratives evenly and coded them independently . We also conducted a thematic analysis on the interview transcriptions using the inductive coding approach [ 64 ] . First , two authors familiarized themselves with the data by carefully watching the video recordings and reading the transcriptions . Then , they completed open coding on two participants’ data independently and then met to share and discuss their codes . With a refined coding strategy , one author kept coding the remaining participants’ data and met regularly with the other author to discuss the patterns and emerging codes , such as “grouping similar variables in the diagram , ” “using ‘Inspire Me’ when running out of ideas , ” “getting new ideas from peer diagrams , ” etc . Finally , the two authors discussed the codes and worked together to group the codes into overarching themes that are related to one of the two research questions , such as “Diagramming Helped Structure Reasoning Processes , ” “Writing Narratives Improved Reasoning , ” “Prompts Led to New Causal Relationships and Contemplation . ” 5 RESULTS We first overview the diagrams and narratives created by the participants . Figure 3 shows four examples of the causal diagrams created by P08 , P10 , P13 , and P16 in Task 1 . These examples demonstrate how participants used various numbers of variables and arrows to represent their causal beliefs . On average , each participant drew 11 . 8 arrows ( median = 11 , std = 4 . 7 ) and included 7 . 7 variables ( median = 7 , std = 2 . 0 ) before looking at others’ diagrams and narratives . Figure 4 shows the histograms of the number of arrows ( left figure ) and the number of variables ( right figure ) included in each causal diagram . The distributions imply that the complexity of the perceived causal relationships varied . Also , as participants were instructed to write a narrative for each arrow , we collected 236 narratives in Task 1 . 5 . 1 Using Narrated Diagrams for Causal Beliefs Externalization ( RQ1 ) For RQ1 , we analyzed the diagrams and narratives created by the participants to characterize the captured causal beliefs , and we used the interview responses to understand how our design affected participants’ externalization process with the tool . 5 . 1 . 1 Causal Beliefs Externalized Through the Integration of Narratives and Diagrams . We analyzed the content of the narratives and the diagrams created by the participants in Task 1 . Since the narratives are meant to be used by the participants to explain their diagram , they are expected to contain causal hypotheses about the associated variables based on the person’s experience and knowledge . Given the exploratory nature of our study , we refrained from judging the correctness or plausibility of the narratives . Instead , we examined the connections between the narratives and the corresponding relationships ( arrows ) drawn in the diagram . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 12 Chi - Hsien ( Eric ) Yen et al . P08’s diagram P13’s diagram P16’s diagram P10’s diagram Fig . 3 . Examples of causal diagrams constructed by four participants in Task 1 . Providing Greater Specificity for a Relationship . We analyzed how the narratives explained the nodes and edges in the diagram based on three binary attributes : ( i ) HasExample : whether the narrative provides a specific relationship pattern , such as a positive or a negative correlation between two variables ; ( ii ) HasExplanation : whether the narrative explains why the causal relationship exists ; and ( iii ) IsRelevant : whether the narrative is comprehensible and relevant to the associated causal relationship . Table 2 lists examples of the narratives provided by the participants and the labels we gave . Note that to be labeled true for HasExample , the narrative has to give a specific trend such as “noise disturbance happens during late hours more often . ” On the other hand , statements like “Different 0 1 2 3 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # of arrows ( Task 1 ) # o f pa r t i c i pan t s 0 2 4 6 8 4 5 6 7 8 9 10 11 12 # of variables ( Task 1 ) # o f pa r t i c i pan t s Fig . 4 . The histogram of the number of arrows ( left ) and variables ( right ) in the causal diagrams generated by the participants in Task 1 . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 13 Narrative HasExample HasExplanation IsRelevant ( Hour → Category ) : Different types of incidents happen during dif - ferent times of the day ( P01’s H02 ) False False True ( Anonymous → Replied ) : If a person chooses to be not anonymous , police would be more likely to reply ( P06’s H01 ) True False True ( Hour → Replied ) : The police might have some data or experience telling them the events that happened during certain time of a day could be more severe . ( P08’s H02 ) False True True ( Category → Replied ) : The police are most likely to respond to a category that is more serious , e . g . , they would respond to a sexual assault over a noise complaint . ( P13’s H04 ) True True True ( Text Length → Replied ) : Police will reply to the reporter . ( P09’s H02 ) False False False Table 2 . Narrative samples from our study and their labels . HasExample is True if the narrative describes a specific relationship pattern ; HasExplanation is True if the narrative explains why the the causal relationship exists by involving another factor ( e . g . , “short staffed , ” “more serious” ) . The last narrative was rated irrelevant because it does not describe how Text Length may influence Replied . types of incidents happen during different time” are too vague to be labeled true . To be labeled true for HasExplanation , the narrative must involve a third variable to explain the underlying reason of why the relationship occurs . For example , “police are most likely to respond to a category that is more serious” involves a third variable , Event Seriousness , to explain why Category could influence Replied , so it is labeled true for HasExplanation . Out of 236 narratives , 222 ( 94 % ) are labeled true for IsRelevant . Furthermore , among all the relevant narratives , 90 % provide examples , 84 % provide explanations , 78 % provide both examples and explanations , while only 4 % provide neither . The high percentages of the informative narratives demonstrate that it is promising to externalize rich causal beliefs from people relevant to the arrows in a causal diagram . Below , we further present the unique benefits brought out through the collected causal beliefs . Externalizing Local or Relevant Knowledge . Users externalized local knowledge through their explanations . For example , P02 wrote , ( Month → Category ) : “depend on the month of the year there might be a higher number of events that will happen ; for example at the beginning of the March people might send in more noise complains around unofficials” ( P02’s H13 ) . “Unofficial” is a large student event held in March in the participant’s local area . Therefore , people out of this community , even if they are data experts , may not pick up this data pattern or understand it before acquiring this knowledge . Another example is ( Month → Hour ) : “For example , due to COVID lots of people are more impoverished and more desperate so these few months all hours are considered to be unsafe with other people as robbing of houses can occur , and people jumping others that are jogging or walking at night . ” ( P16’s H05 ) . This participant related the knowledge about COVID - 19 to the public safety context and suggested that the timing of crime activities may change during a pandemic . Regardless of whether the pattern exists 2 , these narratives bring relevant knowledge into the context . Revealing Missing Variables From the Diagrams . Using the system , participants could add related variables into the reasoning scenario either explicitly or implicitly . The explicit way is to 2 According to [ 13 ] , after - school crime spike was reduced because of stay - at - home order . In addition , while minor offenses decrease during pandemic , serious crimes such as homicide and intimate partner violence remained constant or increased , which suggests a relationship between Month and Category in our reasoning scenario . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 14 Chi - Hsien ( Eric ) Yen et al . use the “Add a New Variable” feature and connect the new variable to other variables . Out of 20 participants , 8 ( 40 % ) added new variables into the diagram using this approach ( see P10’s , P13’s , and P16’s diagram in Figure 3 ) . On average , each participant added 1 . 1 new variables . The most common added variables were Reporter Gender ( N = 3 ) , Officer Motivation ( N = 2 ) , and Availability of Officers ( N = 2 ) , all of which were related to the data schema . Participants could also implicitly reveal related hidden variables , such as mediators or con - founders , through the narratives that are labeled true for HasExplanation ( 81 % of all narratives ) . For example , P06 wrote , ( Category → Text Length ) : “The higher the severity of a situation could call for more information , making the text length greater” ( P06’s H05 ) . Here , Severity of the event is implied to be a mediating factor from Category to Text Length . Another example is , ( Anonymous → Replied ) : “People who choose to reveal their identity will have a higher chance of getting replies because it is more serious” ( P02’s H03 ) . Here , the implied variable , Severity of the event , affects both Anonymous and Replied . Implying Perceived Causal Strength . When analyzing the content of how participants de - scribe a possible causal relationship , one prominent feature is that they used a variety of probability words ( modal verbs ) to indicate the uncertainty of the statement , e . g . , might , may , likely . We ex - tracted the common probability words the participants used in their narratives . The most commonly used probability word is might ( n = 56 ) , followed by may ( n = 47 ) , would ( n = 45 ) , likely ( n = 42 ) , and a few more such as will , can , could , etc . As the participants also specified the strength of their belief from weak to strong on a five - point scale , we used a Kruskal Wallis test to analyze the relationship between the ratings and the probability words used ( if used > 25 times ) in the narratives . The results revealed a significant relationship between word choice and strength ratings ( 𝜒 2 = 17 . 27 , 𝑝 < 0 . 01 ) . A post - hoc test using Mann - Whitney tests with Bonferroni correction showed the significant difference between the narratives with would and might ( p < 0 . 05 ) . Might was the most commonly used word to describe uncertainty ; however , when would was used the strength rating increased significantly ( median = 3 vs . 4 ) . This finding illustrates the opportunity to assess people’s causal belief strength based on their narratives . For example , when explicit strength ratings are not available , such as in the applications where narratives are collected from blogs or social media , belief strength may be inferred from the word choices and allow researchers to better understand people’s beliefs . Surfacing Potential Biases . While generating hypotheses , some participants reported thinking about what the data should look like and what the data actually looks like . For example , P04 wrote , ( Reporter Gender → Replied ) : “Ideally , gender should not make a difference in whether or not there is a reply , but real - world evidence [ outside of this app ] suggests otherwise . ” ( P04’s H18 ) . This subject held two causal models : one that the actual data may look like , and the other one for an ideal world . The deviation of the two models is not only about causal hypotheses but also related to the values held by the person ( e . g . , reporter gender should not affect police response ) and potential bias ( e . g . , not trusting the fairness of the police ) . Other examples that might reveal potential biases are : ( Reporter Gender → Text Length ) : “Women are usually more descriptive while men usually favor brevity” ( P12’s H02 ) , and ( Reporter Gender → Category ) : “More females report disturbances . It’s a cultural thing to be honest . Females are taught one of two things : don’t say anything , or always ask for help . Men are taught to be macho” ( P18’s H11 ) . While there is no right or wrong in making hypotheses itself , the results show that our design collected participants’ beliefs , potentially revealing their implicit social biases or stereotypes . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 15 Fig . 5 . The heatmap shows how many participants generated an arrow from one variable to another in Task 1 . Through our system , one can easily find what causal relationships are more commonly perceived and how such beliefs are divided for some relationships . Capturing Common and Rarely Perceived Causal Relationships . In Figure 5 , we show a heat map of how many participants generated an arrow from one variable to another 3 . From this figure , the top three popular arrows were ( Text Length → Replied ) : 17 ( 85 % ) participants , ( Anonymous → Replied ) : 15 ( 75 % ) participants , and ( Has Location → Replied ) : 14 ( 70 % ) partici - pants . The result reflects that most participants believed some factors affect whether the police respond to a safety report . One reason why Replied is more commonly considered in this scenario may be that it is the final destination of the causal chains . Therefore , the participants may focus on thinking about what factors might influence the final causal outcome . Another reason may be that Replied is the only variable associated with the stakeholder , Police Agency ; therefore , the single green variable on the interface caught people’s attention while reasoning . Following these top three common arrows is a group of nine arrows that were generated by about half of the participants ( 8 to 12 participants ) . These arrows are causal relationships that may be considered more “controversial” in a way that half of the participants believed they exist , while the other half did not . However , it is also possible that some participants did not draw the arrows just because they did not think of it , not that they disagreed with it . The remaining 24 arrows were generated by five or fewer participants . Nevertheless , these arrows still provide valuable opportunities : signaling a unique insight , a mistake , or a bi - directional relationship . First , these causal narratives may come from a unique view of the participants that most people do not think of . It would be beneficial to surface this narrative for other people to review and determine whether it makes sense . Second , these arrows could indicate human mistakes , such as accidentally drawing the arrow in a reverse direction . The matrix - like Figure 5 could help one identify inaccurate arrows . Third , when both directions are drawn , it indicates a possible bi - directional relationship . For example , 11 participants generated the arrow ( Anonymous → Has Location ) , while four generated the reversed one ( Has Location → Anonymous ) . Both directions are possible because a report provider can configure these two settings in any order . Providing Different Rationales for the Same Relationship . Narratives can reveal alterna - tive hypotheses for the same causal relationship . We take the most frequently added arrow ( Text Length → Replied ) as an example . Out of the 17 narratives , 12 narratives hypothesized that there is a positive correlation , i . e . , longer reports are more likely to be replied to , while three suggested the opposite , i . e . , longer reports are less likely to be replied to . Even when the participants hypothesized the same correlation direction , their reasons can also differ . Among the 12 participants who hypothesized a positive correlation for ( Text Length → Replied ) , four explained that longer reports would be more likely to get replies because more 3 To simplify the table , we included only the arrows between the initial seven variables , but not the arrows from or to a newly added variable created by a participant . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 16 Chi - Hsien ( Eric ) Yen et al . information and details are given , e . g . , “If the reporter provided a lot of details , the police are more likely to reply” ( P01’s H03 ) . Another two explained that longer text would invoke more attention from the police , e . g . , “usually the longer the text is , the more attention police will give to the tip” ( P02’s H02 ) . There were also other reasons given , e . g . , “Reporters use less than two words may not get reply because two words cannot convey reasonable information , they just try to play with the agencies” ( P11’s H03 ) . The three participants who hypothesized a negative correlation also had different reasons , e . g . , “if a person is explaining or describing the event with a long text then maybe the event isn’t urgent” ( P08’s H03 ) , and “Lengthy text messages might make cops prioritize shorter text messages because they don’t feel like reading it . ” ( P15’s H11 ) . 5 . 1 . 2 CausalIDEA’s Interaction Design Promoting Structured and Enriched Causal Reasoning . We conducted a thematic analysis on the post - study interview responses to understand how the system design , including the diagram drawing , narrative writing , and inspirational prompts , supported the externalization of causal beliefs . Diagramming Helped Structure Reasoning Processes . Sixteen participants expressed that the process of creating a causal diagram helped their externalization of causal beliefs . First , the participants often used the causal diagram as a visual aid to organize variables based on semantic similarities . Some participants organized the diagram based on the color of the variables , which represented different stakeholders . For example , P02 placed the only variable in green , Replied , in the center and the other variables in orange around it . Some other participants organized their diagrams by importance or semantic similarity . For example , P17 , who also placed the variable Replied in the center , explained that he did so because he thought getting replies from the police was the main purpose of the safety app . P08 further grouped the variables belonging to the same stakeholder as shown in Figure 3 , and reasoned within - and between - group relationships in an alternative order . Second , the causal diagram helped their overall reasoning by providing a big picture and allowing a visual connection . For example . P04 said , “ if we put two words together [ on the diagram ] , then we can think , ‘oh , maybe there’s some relationship between them . ’ . . . If there are only text without the graph , I think it’s more difficult for me to think . ” P17 considered the causal relationships to or from a variable while dragging it into the causal diagram , as he explained , “if I drag Category , I could think like , how does the category cause someone to be anonymous , just kind of as I’m doing it . And it’s a nice visual way to kind of think about it , versus . . . this right hand column on its own [ narrative list ] . There’s no visual kind of connection to it . ” Third , participants also used causal diagrams to help them remember what relationships they had considered . P18 said , “ you can see how they can be connected , and what connections I’ve already made between them . ” P10 also mentioned that by moving variables from the left list to the diagram panel one by one , he could easily remember what variables had been considered and what had not . Writing Narratives Improved Reasoning . Eight participants mentioned that the major benefit of writing narratives was that it allowed them to think more deeply about a causal relationship . P13 said , “Writing [ narratives ] really makes me think more about [ the causal relationship ] and makes me really put in a good reason for why that should be a relationship . That’s what makes you think harder about the reason you’re putting the relationship . ” Similarly , P14 said that “knowing I’m going to have to write something makes me really think about if I can come up with a concrete example in order to explain my thought process . ” By writing narratives , she became more decisive about whether a relationship actually existed . However , despite these benefits , two participants ( P09 , P11 ) found it difficult to write down their reasons when creating a causal relationship . P09 said , “because I am not good at explain myself , it’s hard for me to like thinking and writing in the same time . ” Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 17 Prompts Led to New Causal Relationships and Contemplation . When clicking the “Inspire Me” button , a prompt will appear with a relationship in the form of “Do you think X might influence Y ? ” This feature was frequently used by the participants ( mean = 12 . 2 , median = 7 , std = 14 . 2 ) . While the inspiration prompt was randomly generated by the system , all 20 participants found “Inspire Me” beneficial in building their causal diagrams . First , when they ran out of ideas , the prompt could trigger them to think of a pair of variables that they may not have thought about . Fourteen ( 70 % ) participants mentioned that they used “Inspire Me” after they ran out of ideas , similar to “using a hint on a game , ” as described by P18 . P14 further explained , “So first I started doing the relationships that I noticed immediately . . . after I ran out of ones I could think of , then I started using the inspire me tool to , like , give me ideas . ” The prompt could trigger a chain of ideas , as P20 explained , “once I get a new idea [ from ‘Inspire Me’ ] , I start writing down why I think the ideas are relevant . While writing that down , I think of other ideas , so then I forget about ‘Inspire Me’ because I already have all these ideas in my head now . ” Second , participants found reading the textual prompts generated by “Inspire Me” helped make their causal reasoning process easier . For example , P12 mentioned , “although it doesn’t consider any semantics of the things it picks , it definitely helps . I get to know what doesn’t make sense and what does in a question form rather than looking at the graph . ” Third , for participants whose overall strategy was adding as many relationships as possible , “Inspire Me” was a good tool to help them make sure they did not miss considering a relationship . P09 mentioned that the prompt helped him identify relationships between variables that were not close to each other on the diagram . P02 said , “I will always go through all the ‘Inspire Me’ tips . I’m just always [ want ] to make sure I didn’t miss anything or just help me to think better . ” However , frustrations and challenges also existed when using “Inspire Me . ” Since the prompts were always generated unless all variables were connected , six participants found it frustrating when they encountered repeating questions multiple times . For example , P10 , who was asked about the same relationship that he thought did not exist three times , said , “I wasn’t really expecting too much from the ‘Inspire Me’ , and it seems to be not quite useful , especially when it gets to like the third time of the same pair together . ” P08 and P16 also found reasoning randomly generated pairs of variables less efficient , as P08 elaborated , “I want to focus on one variable first , so I was thinking the same thing . I was able to think of the related [ variables ] really quickly , but if I jump from here to there randomly , then I will spend maybe twice of time . ” In addition , we did not observe any participants modifying their existing narratives after using the “inspire me” button , which is what we expected as the prompt only asked about relationships not in the diagram yet . 5 . 2 Effects of Sharing Causal Beliefs via Narrated Diagrams ( RQ2 ) For RQ2 , we first report how the participants modified their diagrams in Task 2 , where others’ causal models were provided to them ( Figure 6 ) . Then , we used their post - study interview responses to understand how they reasoned with the provided causal models in Task 2 . 5 . 2 . 1 Explicit Effects of Reviewing Others’ Diagrams and Narratives . More Arrows Were Added . After completing Task 2 , the average number of arrows in the participants’ diagrams became 14 . 6 ( median = 14 . 5 , std = 5 . 0 ) , increasing by 2 . 8 from Task 1 ( mean = 11 . 8 , median = 11 , std = 4 . 7 ) . A paired samples Wilcoxon test shows that the number of arrows significantly increased ( p < 0 . 01 ) . The average number of variables in the diagram is 7 . 95 in Task 2 ( median = 7 , std = 1 . 9 ) , which is 0 . 25 higher than Task 1 ( mean = 7 . 7 , median = 7 ) . Only four participants added one variable , and one participant added two variables in Task 2 . The results indicate that participants could think of new causal relationships after reviewing peers’ causal models . Although some participants added new variables , most of the new relations were drawn between existing variables . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 18 Chi - Hsien ( Eric ) Yen et al . Peer 1 ( from pilot study ) Peer 2 ( generated by P02 ) Peer 3 ( generated by P07 ) Fig . 6 . Reasoning Task Material : the peer diagrams provided in our study . The narratives were also shown to the participants on the interface , which were omitted in this figure . Compared to their original diagram , there were three types of relationship revisions on the causal diagram : adding a completely new one ( 51 cases across all participants ) , modifying an existing one ( 10 cases where the arrow directions were modified ; 2 cases where the narratives were modified ) , or deleting one ( 2 cases ) . As most of the revisions are newly added relationships ( 78 % ) , the result suggested that the main effect of reviewing others’ causal models on diagrams is adding new causal relationships . Among the 51 newly added relationships , 44 ( 86 % ) were arrows that also appeared in the peer diagrams that the participants were given , whereas in task 1 , only 58 % arrows the participants drew also appeared in the peer diagrams . The percentage difference further supported that peer causal beliefs had a large influence in helping users find missed causal relationships . Relationship Directions Changed . The second effect is that participants would re - think and change the direction of the relationship , especially when they saw a peer drew a reversed arrow . There are seven cases where they changed the relationship from one - directional to bi - directional after agreeing that the two variables could affect each other . In another three cases , participants were able to identify their own incorrect direction and fixed it . For example , P14 created an arrow in Task 1 : ( Text Length → Hour ) : “If it happens later at night they might be tired or intoxicated and less likely to type a lengthy response” ( P14’s H07 ) . After seeing the reversed arrow in others’ diagrams , P14 realized that the narrative was indeed describing the reverse direction and fixed it . 5 . 2 . 2 Ways of Utilizing Others’ Diagrams and Narratives . We observed the participants’ interaction with the tool during Task 2 and asked about their strategies and experiences of completing Task 2 in the interview . Many of the participants ( 80 % ) reported that by reviewing others’ causal diagrams and narratives , they could think about the data from a different perspective . Using thematic analysis , we found three main themes on how they utilized others’ diagrams during the task . Assessing Usefulness Based on Complexity . The majority of the 12 participants who were provided with all three peer diagrams , shown in Figure 6 , found the diagram with the most content helped them the most by guiding them to think through additional possible causal relationships . Peer 2 , the diagram with the most arrows , was found to be the most useful , as P13 explained , “I Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 19 feel like Peer 2 [ is most useful ] because they just have more information . They clearly thought about more connections that might have been associated with this system . . . . even if you don’t agree with the connections , it’s useful because you get to see that connection and choose to agree or disagree . ” However , having many arrows in a diagram also has a negative effect as some participants found it messy and confusing , which hindered their thought process or even degraded their perceived quality of others’ diagrams . P10 , who preferred more arrows but not too many , commented , “you have an impression of whether this whole graph [ by Peer 2 ] makes sense or not [ by looking at it ] , as they probably just connect everything randomly . Such negative impressions could make participants more resistant to agreeing with others’ narratives . P12 once disagreed with a narrative written by Peer 2 but later found out that the narrative was actually similar to one of his own narratives . After he realized that , he explained , “the more connection they had , the more reluctant for me to accept any of them . For example , just now I even conflict my own statement . I guess I just feel generally negative towards this person’s [ Peer 2 ] work , even so far to conflict my own . ” Prioritizing Relationships for Consideration . A common strategy of the participants was to review the differences between their own diagrams and the peer diagrams . For example , P11 , who did not use all the preset variables when creating her own causal diagram , started by reviewing those variables’ relationships that the peers drew . Another strategy was to focus on the relationships they found the most important . P09 explained , “if there’s just the text without the diagram , I think I would just read from the top to the bottom . And with the diagram , it helped me to decide which one to start . Just like , in Peer 2’s diagram , I will start from the reply . ” Assisting Decisions to Modify Causal Diagrams . While reviewing others’ causal beliefs , all participants tried to compare the arrows and narratives between their own and peers’ diagrams . When an arrow is found on only one side , they would reason why and used the narratives to decide whether the arrow makes sense . More than half of the participants mentioned that reading narratives written by others allowed them to find new ideas that they had not considered before . In fact , peer’s narratives were shown to be more effective than “Inspire Me” in 18 cases , where a participant declined an “Inspire Me” prompt in Task 1 about one relationship , but then agreed the relationship does exist in Task 2 and added it in their own diagram . P20 explained why she preferred reviewing peer diagrams rather than using “Inspire Me , ” “the peer diagrams are actually more helpful [ than using ‘Inspire Me’ ] because reading their explanations also helped me think about my own explanations , and they helped me understand why a certain correlation would exist or would not exist . ” Note that even when they did not agree with the narratives , they may still come up with new ideas to rationalize the causal relationships . P17 and P20 both added an arrow despite disagreeing with its narrative written by peers . P20 explained , “even if the explanation they gave doesn’t make sense , the correlation itself could make more sense just with a different explanation . It , again , would be something that I hadn’t considered before , but I would end up putting it in my diagram . ” However , an important finding is that agreeing with a peer’s narrative alone did not always result in adding that relationship to the participant’s own diagram ; they also considered relationship strength or importance when adding arrows . As evidence , in all cases where they clicked to upvote a narrative ( a feature in Figure 2 - C ) and did not have that arrow in their diagram at the time , only 44 % of the cases ended up adding that arrow into their diagram . P09 , P13 , and P15 , all explained that they would not add all relationships with which they agreed , but only relationships with which they strongly agreed . P13 elaborated his strategy a little bit further , “for example , these [ relationships ] I didn’t include these into my graph . . . mostly because . . . I agreed that there might be an interaction there , but it was such a weak interaction that I didn’t even think putting week on the sidebar would be worth putting it on . ” Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 20 Chi - Hsien ( Eric ) Yen et al . 6 DISCUSSION AND FUTURE WORK Our study discovered and demonstrated the unique benefits of extracting and sharing causal beliefs through integrating causal diagrams and narratives . By situating our findings with prior work , we provide design suggestions and future research directions of collaborative causal reasoning systems . 6 . 1 Causal Diagram’s Insufficiency for Capturing People’s Causal Beliefs Prior work has shown the value of using diagrams to capture people’s causal knowledge and beliefs , e . g . , to generate collective knowledge [ 3 , 8 ] , support knowledge transfer [ 72 ] , or facilitate collaborative reasoning [ 16 ] . In this study , each participant wrote narratives in their own language to explain each of their perceived causal relationships while drawing a causal diagram . Our results suggest that causal diagrams alone are not enough to fully understand or utilize people’s causal knowledge and beliefs . Insufficiencies of causal diagrams include the loss of local or relevant knowledge , missing important hidden variables , failing to notice diverse causal beliefs , and difficulty incorporating others’ diagrams . Furthermore , the narratives enable more opportunities to understand people’s causal knowledge and beliefs . For example , natural language processing ( NLP ) techniques have been used to extract causal relationships from blogs or Wikipedia and to enable machine learning of commonsense and real - world knowledge [ 27 , 28 ] . With our integrated approach with diagrams , NLP techniques can be applied to identify missing hidden variables from the explanations in the narratives , e . g . , mediating factors or confounding factors , and suggest ways to expand the causal diagrams accordingly . Besides detecting hidden variables , the word usage in a narrative provides an additional lens to understand people’s perceived causal strength and how they describe causality . For example , we find that the usage of probability words could be correlated with their perceived causal strength . This finding is aligned with the existing work in quantifying probabilistic expressions [ 44 , 47 ] . Studies also showed that word usage could be different across groups of people ; for example , women are more likely to use words that express uncertainty than men even when they are equally confident [ 40 , 41 ] . Future work is needed to further explore the linguistic characteristics of the causal narratives . We demonstrated that by integrating diagrams and narratives , the system could extract rich and detailed causal beliefs from a group of people , which could enable many future collaborative reasoning applications . For example , public policymakers may utilize such systems to collect and understand how the general public perceives a possible policy change and its effects on citizens’ daily lives . Social data analysts may utilize such systems to understand unexpected data patterns that could be explained by community members ( e . g . , the user behavior data of online social forums may be better explained by forum users ) . Many recent works in citizen science [ 59 ] have shown promising results where a group of laypeople was able to provide insights for governments or experts , such as finding possible causal factors to obesity [ 14 ] . Our integrated design could be extended and utilized as a crowdsourcing causal knowledge platform , which could be helpful for government or social data analysts . 6 . 2 Collecting Diverse Beliefs and Mitigating Potential Biases Identifying characteristics and patterns of individuals’ reasoning is another important research aspect of social computing . Prior work has studied people’s diverse opinions in various domains , such as product reviews [ 68 ] , political issues [ 45 ] , news credibility assessment [ 9 ] , and world beliefs [ 20 ] . We collected the causal beliefs of people and analyzed their characteristics and differences across participants , which contributes new understandings towards the diverse causal knowledge Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 21 and beliefs across people . Our results demonstrated that participants had different views in causal beliefs , which could occur on many aspects : relationship’s existence , direction , correlation pattern , rationale , or strength . Future work should investigate how to effectively identify and visualize the common ground and discrepancies of the views held by individuals or groups , such that people can develop mutual understanding and others’ unique contexts . Research has also shown that causal explanations can affect social bias ; for example , providing causal information impacts one’s implicit biases against overweight people [ 62 ] . We find that some participants showed their biases or stereotypes when constructing a causal diagram , especially when they were reasoning with demographic attributes like gender ( e . g . , “women are more descriptive , ” “men are taught to be macho” ) . It is worth exploring if measuring and understanding social biases through the causal perspective could be a feasible approach . A potential scenario could be , giving people a scenario of a character requesting to get promoted at work and asking them to use variables like age , gender , skills , etc . , to draw a causal diagram to explain what may influence this character’s success , and see if biased beliefs or perceived causal strength would be revealed . In our study , all the causal hypotheses were not tested and thus may be inaccurate . By comparing the actual data and people’s causal diagrams , inaccurate or biased beliefs can be revealed . In fact , our results showed that many of our participants believed there would be a negative correlation between the anonymity of safety reports and police agencies’ response rates , i . e . , our participants thought that anonymous reports were less likely to receive responses . However , according to [ 43 ] , which conducted a system log analysis of a safety app , anonymous reports were actually more likely to be responded to in a safety app . As we only provided data schema but not an actual dataset , we were able to observe such discrepancies between causal beliefs and real - world datasets . This observation leads to new future research directions , such as studying how people react to such a discrepancy between their initial hypothesis and data patterns and resolve it during causal reasoning . Alternatively , the externalized causal knowledge or beliefs can also help data analysts perform a more robust causal analysis . Prior work has shown that an analyst often chooses the first hypothesis that appears to be good enough without further considering other possible hypotheses [ 34 ] . The diverse causal beliefs from a group of people may encourage analysts to realize and look into overlooked factors or hypotheses . Future work can also include utilizing actual datasets to validate the causal diagrams and narratives externalized by people . For example , data analysis algorithms can search from the collected causal beliefs to recommend potential confounding or mediating factors that an analyst may miss . Furthermore , while our study shows promising results that sharing peer causal beliefs is effective in helping people to find missed causal relationships and expand their causal models , our results also show that very few people changed their existing narratives after reviewing others’ beliefs , even when those beliefs conflicted with their own . Psychology theories have also described a phenomenon called belief perseverance [ 6 ] , where a person maintains their initial beliefs even when contradicting information is provided to them . Such beliefs might even be strengthened when others try to debunk the belief with firm evidence , which is known as the backfire effect [ 58 ] . It is valuable to study how people resolve conflicts when they find that many people provide a causal belief that contradicts his / hers or when real - world data supports a contradicting relationship . Future work may also investigate what factors and strategies may encourage or suppress causal belief changes . Unlike resisting changes and clinging to one’s own beliefs , other social - psychological theories explain a groupthink phenomenon , where people tend to agree with the majority within a group or community . Such effects may be driven by the desire for harmony or cohesiveness in the group or the fear of facing conflict [ 35 ] . As our participants did not need to communicate directly with Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 22 Chi - Hsien ( Eric ) Yen et al . the authors of peers’ diagrams , such a phenomenon was not apparent in our study . However , we still found that the peer diagrams influenced participants when revising their diagrams . If a crowd - powered causal reasoning system is created to collect diverse causal beliefs , the groupthink effect might lead the crowd to create coherent , low - diverse , albeit potentially biased collective beliefs . Future studies may explore how to present others’ beliefs when one user builds their diagrams to mitigate potential biases . 6 . 3 Design Implications While there are existing diagramming tools ( e . g . , Microsoft Visio , Gliffy , etc . ) , which allow users to create diagrams and mental models , and text - based tools ( e . g . , Microsoft Word , Microsoft Excel , etc . ) , which allow users to externalize causal knowledge and beliefs as narratives , our study utilized and evaluated an integrated design that allowed users to quickly visualize a causal model with narratives associated to each causal relationship . As demonstrated from our study’s results and the discussion above , the main takeaway is that future tools should adopt the integrated approach of narratives and diagrams for diagramming and sharing causal mental models . In the remainder of this section , we elaborate on the design implications based on our study results . 6 . 3 . 1 Promoting Individual Reasoning . Allowing participants to provide coupled narratives to their causal relationships was shown to be crucial for belief externalization and sharing in our study , e . g . , the narratives could capture individuals’ detailed causal beliefs and reasoning , which achieved the design goal for this feature . Without narratives , existing diagramming tools ( e . g . , Gliffy or Microsoft Visio ) will fall short of revealing diverse rationales from different people . Nevertheless , while most narratives in our study provide concrete examples or explanations , a fraction of them do not ( 10 % have no examples and 16 % have no explanations ) . Some participants reported that they found it challenging to write narratives as sometimes the idea was hard to explain , suggesting that future design may provide scaffolding features to efficiently support users’ externalization of narratives . Studies have shown that scaffolding techniques improve knowledge expression [ 48 ] and reasoning [ 7 ] . As we have identified the key aspects of how people’s narratives can vary , one design possibility is to explicitly structure the narrative text box with related prompts , e . g . , example , explanation , hidden variables , strength , to facilitate writing and reasoning . Many participants shared that drawing their diagrams helped their reasoning processes , which followed our design goals for the diagramming panel . However , challenges still emerge when the number of nodes and edges increases when the graph becomes complicated and messy . Be - sides applying existing diagram representation techniques , such as reducing crossing arrows and clutters [ 5 , 39 ] , our findings suggest that diagrams should also be organized based on semantic similarities and causal roles . For example , semantically close variables could be grouped so that users can think about within - group and between - group relationships easily . The causal destination variables in a diagram could be placed at a user - preferred position such as on the side or at the center . As the spatial layout is a crucial element in making diagrams more comprehensible , Future tools may evaluate effective designs that can automatically organize the spatial layout of a causal diagram based on these rationales . Besides causal diagrams , designers may also explore other representation forms of causal rela - tionships . For example , a matrix can also be used to represent a set of directional edges between nodes , using rows to represent starting nodes and columns to represent ending nodes . With this visualization , one could quickly see which relationships are not yet considered ; similarly , in our design , participants used diagrams to spot missing arrows . A matrix may appear less cluttered than causal diagrams when the number of edges is large , which some participants mentioned as a Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 23 drawback of causal diagrams . However , compared to matrices , diagrams have several advantages . For example , one can quickly identify causal chains ( three or more variables connected in a dia - gram ) and identify the variables with many arrows going out or into them . In addition , based on existing theories in psychology research , humans naturally develop a mental model of real - world causal - effect relationships as causal diagrams and use the mental model to predict and perform counterfactual reasoning [ 60 ] . Thus , it is intuitive for users to use diagrams in the context of causal reasoning , which was also frequently appraised by our participants . Designers may consider using these different forms of representation , especially when the number of nodes and edges are large , or combine multiple visualizations to leverage the benefits of each . We also strongly recommend that designers provide inspirational prompts in systems for causal belief externalization . Inspirations and example exposure effect have been studied extensively in the creative work domain [ 57 , 65 ] . Many participants found that the inspiration cues were beneficial , which supported the design goal of this feature , even when the prompted variables were randomly selected . One of the main benefits the participants mentioned is that the prompt allowed them to get inspired when they ran out of ideas . The finding echos the Prepared Mind theory [ 56 , 57 ] , which suggests that stimuli will be the most effective when reasoning reaches an impasse . However , we also observed that if the prompts were declined a few times in a row , people might deem the prompts not useful anymore and believe there were no other possible relationships . From our participants’ interview responses , we suggest designers improve the inspirational prompts by prioritizing the variables based on reasoning progress or other people’s knowledge . First , participants mentioned that they reasoned with one variable at a time and found it distracting when the prompts asked about different parts of the diagram . A less disruptive method would be prompting users to think about the relationships that connect to the arrow they recently created . Second , if many peers had drawn the same causal relationship , that relationship was perceived as more plausible and could be prioritized . The inspiration prompts can also show others’ narratives to make them more effective , as we found a peer’s narrative could be more useful than “Inspire Me” in our study . 6 . 3 . 2 Supporting Collaborative Reasoning . Literature in intelligence analysis has shown that sharing reasoning artifacts could improve collaborative reasoning as individuals have limited cognitive capacities and biases [ 29 , 30 , 34 ] . Our results echoed some of the findings from the prior literature , e . g . , after looking at peers’ diagrams , people often realized that they had missed certain causal relationships when they initially drew the diagrams by themselves . Thus the goal of providing peer causal beliefs to help users revise their diagrams was fulfilled . Our study shows that the integration of causal diagrams and narratives is effective when interpreting others’ causal beliefs , as narratives play a critical role for people to understand why others believe a causal relationship might exist . However , when many people’s diagrams are collected , it would be impossible to review them one by one . Future designs may provide visualization of aggregated causal beliefs from a large number of users’ causal diagrams , which can enable users to digest and utilize a group’s causal beliefs efficiently . For example , Figure 5 could show how frequently a causal relationship is perceived in a matrix . Another design suggestion is to aggregate the diagrams and use arrow width to represent how many people have drawn that arrow . Users can then quickly compare their diagram and others’ to search for relevant narratives for inspiration . Our study also shows that some participants would perceive others’ rationales as having lower quality if the peers’ causal diagrams were too complicated . Future designs may consider allowing users to control the display of the diagrams to customize the level of complexity . For example , many participants pointed out they would like to focus on the arrows that were different from theirs . Then , a potential design could be allowing users to customize the number of arrows to be Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 24 Chi - Hsien ( Eric ) Yen et al . displayed at a time , beginning with the arrows presenting different relationships first . Another possible design approach suggested by one of our participants was prioritizing the arrows were generated earlier by their peers , as people may come up with the most salient causal relationships first . 6 . 4 Limitations and Future Work This work has several limitations . First , we conducted interviews with participants to gather qualitative data and learn about the strategies users developed when using the tool . These results should be regarded as preliminary given the limited interaction users had with the tool and data schema . Second , our participants possessed similar backgrounds , i . e . , college or graduate students with limited safety domain knowledge . It would be interesting to study the differences in the causal beliefs externalized by different stakeholders , e . g . , active app users , police officers , app designers , and those with different domain expertise . Differences in causal beliefs between different categories of users may suggest potential group biases or deficiencies in the data . Third , our system collects the causal beliefs from the users , and we do not have evidence to support which hypotheses were confirmed in the real world or how testing these hypotheses in the tool would affect subsequent exploration of causal relationships in the tool . Data and machine intelligence could be implemented to validate the hypotheses that users propose in the tool . Future research can build on our findings to integrate crowd and machine intelligence to enable novel data analytic features and tools . Finally , our participants could review other peers’ causal beliefs but could not discuss the diagrams or communicate with their peers . Prior work has demonstrated the benefits of discussion and proposed designs that support communication in reasoning [ 30 , 42 , 71 ] . Future work may explore how discussion can be better supported with the integrated design . 7 CONCLUSION Little work has studied the effects and benefits of using diagrams and narratives together to externalize people’s causal knowledge and beliefs . We implemented an interactive system that allows users to write narratives for each causal relationship , draw a directed causal diagram with inspirational prompts , and review others’ causal diagrams and narratives . Our user study with 20 participants showed that the integrated approach allowed people to externalize local or relevant causal beliefs for an application scenario , imply missing variables from the diagram , and reveal potential biases , which would not be captured if diagrams alone were used . In addition , our thematic analysis identified the effects of using the interaction designs of our system on promoting causal knowledge and beliefs externalization and several approaches that participants utilized to review others’ causal knowledge and beliefs . Based on our findings , we discussed the new research opportunities enabled by the integrated approach and design implications for future collaborative causal knowledge and beliefs sharing systems . 8 ACKNOWLEDGMENTS The authors would like to thank the anonymous reviewers for their efforts and valuable comments . REFERENCES [ 1 ] Mark S Ackerman , Juri Dachtera , Volkmar Pipek , and Volker Wulf . Sharing knowledge and expertise : The cscw view of knowledge management . Computer Supported Cooperative Work ( CSCW ) , 22 ( 4 - 6 ) : 531 – 573 , 2013 . [ 2 ] Lada A Adamic , Jun Zhang , Eytan Bakshy , and Mark S Ackerman . Knowledge sharing and yahoo answers : everyone knows something . In Proceedings of the 17th international conference on World Wide Web , pages 665 – 674 , 2008 . [ 3 ] Payam Aminpour , Steven A Gray , Antonie J Jetter , Joshua E Introne , Alison Singer , and Robert Arlinghaus . Wisdom of stakeholder crowds in complex social – ecological systems . Nature Sustainability , 3 ( 3 ) : 191 – 199 , 2020 . [ 4 ] Robert Axelrod . Structure of decision : The cognitive maps of political elites . Princeton university press , 2015 . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 25 [ 5 ] Carlo Batini , Enrico Nardelli , and Roberto Tamassia . A layout algorithm for data flow diagrams . IEEE Transactions on Software Engineering , ( 4 ) : 538 – 546 , 1986 . [ 6 ] Roy F Baumeister and Kathleen D Vohs . Encyclopedia of social psychology , volume 1 . Sage , 2007 . [ 7 ] Dani Ben - Zvi . Scaffolding students’ informal inference and argumentation . In Proceedings of the Seventh International Conference on Teaching Statistics , pages 1 – 6 . International Statistical Institute Voorburg , the Netherlands , 2006 . [ 8 ] Daniel Berenberg and James P Bagrow . Efficient crowd exploration of large networks : The case of causal attribution . Proceedings of the ACM on Human - Computer Interaction , 2 ( CSCW ) : 1 – 25 , 2018 . [ 9 ] Md Momen Bhuiyan , Amy X Zhang , Connie Moon Sehat , and Tanushree Mitra . Investigating differences in crowd - sourced news credibility assessment : Raters , tasks , and expert criteria . Proceedings of the ACM on Human - Computer Interaction , 4 ( CSCW2 ) : 1 – 26 , 2020 . [ 10 ] Dorrit Billman , Gregorio Convertino , Jeff Shrager , P Pirolli , and J Massar . Collaborative intelligence analysis with cache and its effects on information gathering and cognitive bias . In Human Computer Interaction Consortium Workshop , 2006 . [ 11 ] Richard J Boland Jr , Anil K Maheshwari , Dov Te’eni , David G Schwartz , and Ramkrishnan V Tenkasi . Sharing perspectives in distributed decision making . In Proceedings of the 1992 ACM conference on Computer - supported cooperative work , pages 306 – 313 , 1992 . [ 12 ] Richard J Boland Jr and Ramkrishnan V Tenkasi . Perspective making and perspective taking in communities of knowing . Organization science , 6 ( 4 ) : 350 – 372 , 1995 . [ 13 ] John H Boman and Owen Gallupe . Has covid - 19 changed crime ? crime rates in the united states during the pandemic . American journal of criminal justice , 45 ( 4 ) : 537 – 545 , 2020 . [ 14 ] Josh C Bongard , Paul DH Hines , Dylan Conger , Peter Hurd , and Zhenyu Lu . Crowdsourcing predictors of behavioral outcomes . IEEE Transactions on Systems , Man , and Cybernetics : Systems , 43 ( 1 ) : 176 – 185 , 2012 . [ 15 ] Yang Chen , Jamal Alsakran , Scott Barlowe , Jing Yang , and Ye Zhao . Supporting effective common ground construction in asynchronous collaborative visual analytics . In 2011 IEEE Conference on Visual Analytics Science and Technology ( VAST ) , pages 101 – 110 . IEEE , 2011 . [ 16 ] Haeyong Chung , Seungwon Yang , Naveed Massjouni , Christopher Andrews , Rahul Kanna , and Chris North . Vizcept : Supporting synchronous collaboration for constructing visualizations in intelligence analysis . In 2010 IEEE Symposium on Visual Analytics Science and Technology , pages 107 – 114 . IEEE , 2010 . [ 17 ] Jacob Cohen . A coefficient of agreement for nominal scales . Educational and psychological measurement , 20 ( 1 ) : 37 – 46 , 1960 . [ 18 ] Harry Collins . Tacit and explicit knowledge . University of Chicago Press , 2010 . [ 19 ] Kenneth James Williams Craik . The nature of explanation , volume 445 . CUP Archive , 1952 . [ 20 ] Claudia Dalbert , Isaac M Lipkus , Hedvig Sallay , and Irene Goch . A just and an unjust world : Structure and validity of different world beliefs . Personality and Individual Differences , 30 ( 4 ) : 561 – 577 , 2001 . [ 21 ] David Danks . Unifying the mind : Cognitive representations as graphical models . Mit Press , 2014 . [ 22 ] Adam Darlow , Gideon Goldin , and Steven Sloman . Causal interactions . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 1655 – 1664 , 2014 . [ 23 ] Matthew W Easterday , Vincent Aleven , and Richard Scheines . Tis better to construct than to receive ? the effects of diagram tools on causal reasoning . Frontiers in artificial intelligence and applications , 158 : 93 , 2007 . [ 24 ] Siamak Faridani , Ephrat Bitton , Kimiko Ryokai , and Ken Goldberg . Opinion space : a scalable tool for browsing online comments . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 1175 – 1184 , 2010 . [ 25 ] Rocio Garcia - Retamero and Ulrich Hoffrage . How causal knowledge simplifies decision - making . Minds and Machines , 16 ( 3 ) : 365 – 380 , 2006 . [ 26 ] Charles F Gettys , Carol Manning , Tom Mehle , and Stanley D Fisher . Hypothesis generation : A final report of three years of research . Technical report , OKLAHOMA UNIV NORMAN DECISION PROCESSES LAB , 1980 . [ 27 ] RoxanaGirju . Automaticdetectionofcausalrelationsforquestionanswering . In ProceedingsoftheACL2003workshopon Multilingual summarization and question answering - Volume 12 , pages 76 – 83 . Association for Computational Linguistics , 2003 . [ 28 ] Andrew S Gordon , Cosmin A Bejan , and Kenji Sagae . Commonsense causal reasoning using millions of personal stories . In Twenty - Fifth AAAI Conference on Artificial Intelligence , 2011 . [ 29 ] Nitesh Goyal and Susan R Fussell . Effects of sensemaking translucence on distributed collaborative analysis . In Proceedings of the 19th ACM Conference on Computer - Supported Cooperative Work & Social Computing , pages 288 – 302 , 2016 . [ 30 ] Nitesh Goyal , Gilly Leshed , Dan Cosley , and Susan R Fussell . Effects of implicit sharing in collaborative analysis . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 129 – 138 , 2014 . [ 31 ] York Hagmayer and Cilia Witteman . Causal knowledge and reasoning in decision making . In Psychology of Learning and Motivation , volume 67 , pages 95 – 134 . Elsevier , 2017 . Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . 444 : 26 Chi - Hsien ( Eric ) Yen et al . [ 32 ] Kazuaki Hanawa , Akira Sasaki , Naoaki Okazaki , and Kentaro Inui . A crowdsourcing approach for annotating causal relation instances in wikipedia . In Proceedings of the 31st Pacific Asia Conference on Language , Information and Computation , pages 336 – 345 , 2017 . [ 33 ] Richard T Herschel , Hamid Nemati , and David Steiger . Tacit to explicit knowledge conversion : knowledge exchange protocols . Journal of knowledge management , 5 ( 1 ) : 107 – 116 , 2001 . [ 34 ] Richards J Heuer . Psychology of intelligence analysis . Center for the Study of Intelligence , 1999 . [ 35 ] Irving L Janis . Groupthink . IEEE Engineering Management Review , 36 ( 1 ) : 36 , 2008 . [ 36 ] Philip Nicholas Johnson - Laird . Mental models : Towards a cognitive science of language , inference , and consciousness . Number 6 . Harvard University Press , 1983 . [ 37 ] James M Joyce . The foundations of causal decision theory . Cambridge University Press , 1999 . [ 38 ] Steven A Julious and Mark A Mullee . Confounding and simpson’s paradox . Bmj , 309 ( 6967 ) : 1480 – 1481 , 1994 . [ 39 ] Corey Kosak , Joe Marks , and Stuart Shieber . Automating the layout of network diagrams with specified visual organization . IEEE Transactions on Systems , Man , and Cybernetics , 24 ( 3 ) : 440 – 454 , 1994 . [ 40 ] Robin Lakoff . Language and woman’s place . Language in society , 2 ( 1 ) : 45 – 79 , 1973 . [ 41 ] Campbell Leaper and Rachael D Robnett . Women are more likely than men to use tentative language , aren’t they ? a meta - analysis testing for gender differences and moderators . Psychology of Women Quarterly , 35 ( 1 ) : 129 – 142 , 2011 . [ 42 ] Narges Mahyar and Melanie Tory . Supporting communication and coordination in collaborative sensemaking . IEEE transactions on visualization and computer graphics , 20 ( 12 ) : 1633 – 1642 , 2014 . [ 43 ] Shufan Ming , Ryan DW Mayfield , Haocong Cheng , Ke - Rou Wang , and Yun Huang . Examining interactions between community members and university safety organizations through community - sourced risk systems . Proceedings of the ACM on Human - Computer Interaction , 5 ( CSCW1 ) : 1 – 23 , 2021 . [ 44 ] Frederick Mosteller and Cleo Youtz . Quantifying probabilistic expressions . Statistical Science , pages 2 – 12 , 1990 . [ 45 ] Sean A Munson and Paul Resnick . Presenting diverse political opinions : how and how much . In Proceedings of the SIGCHI conference on human factors in computing systems , pages 1457 – 1466 , 2010 . [ 46 ] Donald A Norman . Some observations on mental models . Mental models , 7 ( 112 ) : 7 – 14 , 1983 . [ 47 ] Bernie J O’Brien . Words or numbers ? the evaluation of probability expressions in general practice . The Journal of the Royal College of General Practitioners , 39 ( 320 ) : 98 – 100 , 1989 . [ 48 ] Eira Wyn Patterson . Structuring the composition process in scientific writing . International journal of science education , 23 ( 1 ) : 1 – 16 , 2001 . [ 49 ] Judea Pearl . Causality . Cambridge university press , 2009 . [ 50 ] Judea Pearl and Dana Mackenzie . The book of why : the new science of cause and effect . Basic Books , 2018 . [ 51 ] Mark S Pfaff , Jill L Drury , and Garly L Klein . Crowdsourcing mental models using desim ( descriptive to executable simulation modeling ) . In international conference on natualistic decision making , McLean , VA , 2015 . [ 52 ] Mark S Pfaff , Jill L Drury , and Gary L Klein . Modeling knowledge using a crowd of experts . In Proceedings of the Human Factors and Ergonomics Society Annual Meeting , volume 60 , pages 183 – 187 . SAGE Publications Sage CA : Los Angeles , CA , 2016 . [ 53 ] Mark S Pfaff , Gary L Klein , and Jill D Egeth . Characterizing crowdsourced data collected using desim ( descriptive to executable simulation modeling ) . In Proceedings of the Human Factors and Ergonomics Society Annual Meeting , volume 61 , pages 178 – 182 . SAGE Publications Sage CA : Los Angeles , CA , 2017 . [ 54 ] William A Pike , Richard May , Bob Baddeley , Roderick Riensche , Joe Bruce , and Katarina Younkin . Scalable visual reasoning : Supporting collaboration through distributed analysis . In 2007 International Symposium on Collaborative Technologies and Systems , pages 24 – 32 . IEEE , 2007 . [ 55 ] Leonid Rozenblit and Frank Keil . The misunderstood limits of folk science : An illusion of explanatory depth . Cognitive science , 26 ( 5 ) : 521 – 562 , 2002 . [ 56 ] Colleen M Seifert , David E Meyer , Natalie Davidson , Andrea L Patalano , and Ilan Yaniv . Demystification of cognitive insight : Opportunistic assimilation and the prepared - mind hypothesis . 1994 . [ 57 ] Pao Siangliulue , Joel Chan , Krzysztof Z Gajos , and Steven P Dow . Providing timely examples improves the quantity and quality of generated ideas . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition , pages 83 – 92 , 2015 . [ 58 ] Craig Silverman . The backfire effect : More on the press’s inability to debunk bad information . Columbia Journalism Review , 2011 . [ 59 ] Jonathan Silvertown . A new dawn for citizen science . Trends in ecology & evolution , 24 ( 9 ) : 467 – 471 , 2009 . [ 60 ] Steven Sloman . Causal models : How people think about the world and its alternatives . Oxford University Press , 2005 . [ 61 ] Peter Spirtes , Clark N Glymour , Richard Scheines , and David Heckerman . Causation , prediction , and search . MIT press , 2000 . [ 62 ] Bethany A Teachman , Kathrine D Gapinski , Kelly D Brownell , Melissa Rawlins , and Subathra Jeyaram . Demonstrations of implicit anti - fat bias : the impact of providing causal information and evoking empathy . Health psychology , 22 ( 1 ) : 68 , Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 . Narratives + Diagrams : An Integrated Approach for Externalizing and Sharing People’s Causal Beliefs 444 : 27 2003 . [ 63 ] Joshua B Tenenbaum , Charles Kemp , Thomas L Griffiths , and Noah D Goodman . How to grow a mind : Statistics , structure , and abstraction . science , 331 ( 6022 ) : 1279 – 1285 , 2011 . [ 64 ] David R Thomas . A general inductive approach for qualitative data analysis . 2003 . [ 65 ] Luis A Vasconcelos and Nathan Crilly . Inspiration and fixation : Questions , methods , findings , and challenges . Design Studies , 42 : 1 – 32 , 2016 . [ 66 ] Michael R Waldmann . Knowledge - based causal induction . Psychology of Learning and Motivation , 34 : 47 – 88 , 1996 . [ 67 ] Michael R Waldmann and Keith J Holyoak . Predictive and diagnostic learning within causal models : Asymmetries in cue competition . Journal of Experimental Psychology : General , 121 ( 2 ) : 222 , 1992 . [ 68 ] Mengting Wan and Julian McAuley . Modeling ambiguity , subjectivity , and diverging viewpoints in opinion question answering systems . In 2016 IEEE 16th international conference on data mining ( ICDM ) , pages 489 – 498 . IEEE , 2016 . [ 69 ] Jun Wang and Klaus Mueller . The visual causality analyst : An interactive interface for causal reasoning . IEEE transactions on visualization and computer graphics , 22 ( 1 ) : 230 – 239 , 2015 . [ 70 ] Wesley Willett , Jeffrey Heer , and Maneesh Agrawala . Strategies for crowdsourcing social data analysis . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 227 – 236 , 2012 . [ 71 ] Wesley Willett , Jeffrey Heer , Joseph Hellerstein , and Maneesh Agrawala . Commentspace : structured support for collaborative visual analysis . In Proceedings of the SIGCHI conference on Human Factors in Computing Systems , pages 3131 – 3140 , 2011 . [ 72 ] Jian Zhao , Michael Glueck , Petra Isenberg , Fanny Chevalier , and Azam Khan . Supporting handoff in asynchronous collaborative sensemaking using knowledge - transfer graphs . IEEE transactions on visualization and computer graphics , 24 ( 1 ) : 340 – 350 , 2017 . Received January 2021 ; revised April 2021 ; accepted June 2021 Proc . ACM Hum . - Comput . Interact . , Vol . 5 , No . CSCW2 , Article 444 . Publication date : October 2021 .