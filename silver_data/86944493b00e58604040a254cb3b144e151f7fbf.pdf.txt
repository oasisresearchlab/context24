A SEQUENTIAL ELIMINATION ALGORITHM FOR COMPUTING BOUNDS ON THE CLIQUE NUMBER OF A GRAPH Bernard Gendron D´epartement d’informatique et de recherche op´erationnelle and Centre de recherche sur les transports Universit´e de Montr´eal C . P . 6128 , succ . Centre - ville Montr´eal , Qu´ebec H3C 3J7 Alain Hertz D´epartement de math´ematiques et de g´enie industriel ´Ecole Polytechnique de Montr´eal C . P . 6079 , succ . Centre - ville Montr´eal , Qu´ebec H3C 3A7 and GERAD 3000 , chemin de la Cˆote - Sainte - Catherine Montr´eal , Qu´ebec H3T 2A7 Patrick St - Louis D´epartement d’informatique et de recherche op´erationnelle Universit´e de Montr´eal C . P . 6128 , succ . Centre - ville Montr´eal , Qu´ebec H3C 3J7 December 2007 Abstract We consider the problem of determining the size of a maximum clique in a graph , also known as the clique number . Given any method that computes an upper bound on the clique number of a graph , we present a sequential elimination al - gorithm which is guaranteed to improve upon that upper bound . Computational experiments on DIMACS instances show that , on average , this algorithm can reduce the gap between the upper bound and the clique number by about 60 % . We also show how to use this sequential elimination algorithm to improve the computation of lower bounds on the clique number of a graph . ii 1 Introduction In this paper , we consider only undirected graphs with no loops or multiple edges . For a graph G , we denote V ( G ) its vertex set and E ( G ) its edge set . The size of a graph is its number of vertices . The subgraph of G induced by a subset V ′ ⊆ V ( G ) of vertices is the graph with vertex set V ′ and edge set { ( u , v ) ∈ E ( G ) | u , v ∈ V ′ } . A complete graph is a graph G such that u and v are adjacent , for each pair u , v ∈ V ( G ) . A clique of G is an induced subgraph that is complete . The clique number of a graph G , denoted ω ( G ) , is the maximum size of a clique of G . Finding ω ( G ) is known as the clique number problem , while ﬁnding a clique of maximum size is the maximum clique problem . Both problems are NP - hard [ 6 ] . Many algorithms , both heuristic and exact , have been designed to solve the clique number and maximum clique problems , but ﬁnding an optimal solution in relatively short computing times is realistic only for small instances . The reader may refer to [ 3 ] for a survey on algorithms and bounds for these two problems . An upper bound on the clique number of a graph is useful in both exact and heuristic algorithms for solving the maximum clique problem . Typically , upper bounds are used to guide the search , prune the search space and prove optimality . One of the most famous upper bounds on the clique number of a graph G is the chromatic number , χ ( G ) , which is the smallest integer k such that a legal k - coloring exists ( a legal k - coloring is a function c : V ( G ) → { 1 , 2 , . . . , k } such that c ( u ) 6 = c ( v ) for all edges ( u , v ) ∈ E ( G ) ) . Finding the chromatic number is known as the graph coloring problem , which is NP - hard [ 6 ] . Since χ ( G ) ≥ ω ( G ) , any heuristic method for solving the graph coloring problem provides an upper bound on the clique number . Other upper bounds on the clique number will be brieﬂy discussed in Section 4 ( for an exhaustive comparison between the clique number and other graph invariants , see [ 1 ] ) . In this paper , we introduce a sequential elimination algorithm which makes use of the closed neighborhood N G ( u ) of any vertex u ∈ V ( G ) , deﬁned as the subgraph of G induced by { u } ∪ { v ∈ V ( G ) | ( u , v ) ∈ E ( G ) } . Given an arbitrary upper bound h ( G ) on ω ( G ) , the proposed algorithm produces an upper bound h ∗ ( G ) based on the computation 1 of h ( N G ′ ( u ) ) for a series of subgraphs G ′ of G and vertices u ∈ V ( G ′ ) . Under mild assumptions we prove that ω ( G ) ≤ h ∗ ( G ) ≤ h ( G ) . As reported in Section 4 , our tests on DIMACS instances [ 9 ] show that embedding a graph coloring heuristic ( i . e . , h ( G ) is an upper bound on χ ( G ) produced by a heuristic ) within this sequential elimination algorithm reduces the gap between the upper bound and ω ( G ) by about 60 % . In Section 2 , we present the sequential elimination algorithm in more details and we prove that it provides an upper bound on the clique number of a graph . In Section 3 , we discuss how the sequential elimination algorithm can also be used to improve the computation of lower bounds on the clique number . We present computational results on DIMACS instances in Section 4 , along with concluding remarks . 2 The Sequential Elimination Algorithm Assuming h ( G ′ ) is a function that provides an upper bound on the clique number of any induced subgraph G ′ of G ( including G itself ) , the sequential elimination algorithm is based on computing this upper bound for a series of subgraphs G ′ of G . By computing this upper bound for the closed neighborhood N G ( u ) of each vertex u ∈ V ( G ) , one can easily get a new upper bound h 1 ( G ) on ω ( G ) , as shown by the following proposition . Proposition 1 ω ( G ) ≤ max u ∈ V ( G ) h ( N G ( u ) ) ≡ h 1 ( G ) . Proof : Let v be a vertex in a clique of maximum size of G . This implies that N G ( v ) con - tains a clique of size ω ( G ) . Hence , ω ( G ) = ω ( N G ( v ) ) ≤ h ( N G ( v ) ) ≤ max u ∈ V ( G ) h ( N G ( u ) ) . (cid:4) Now let s be any vertex in V ( G ) , and let G s denote the subgraph of G induced by V ( G ) \ { s } . We then have ω ( G ) = max { ω ( N G ( s ) ) , max u ∈ V ( G s ) ω ( N G s ( u ) ) } . This equality is often used in branch and bound algorithms for the computation of the clique number of G ( see for example [ 12 ] ) . By using function h to compute an upper bound on the clique number of N G ( s ) as well as on the clique number of the closed neighborhoods of the vertices of G s , we can obtain another upper bound h 2 s ( G ) on ω ( G ) , as demonstrated by the following proposition . 2 Proposition 2 ω ( G ) ≤ max { h ( N G ( s ) ) , max u ∈ V ( G s ) h ( N G s ( u ) ) } ≡ h 2 s ( G ) ∀ s ∈ V ( G ) . Proof : Consider any vertex s ∈ V ( G ) . If s belongs to a clique of size ω ( G ) in G , then ω ( G ) = ω ( N G ( s ) ) ≤ h ( N G ( s ) ) ≤ h 2 s ( G ) . Otherwise , there is a clique of size ω ( G ) in G s . By Proposition 1 applied to G s , we have ω ( G ) = ω ( G s ) ≤ max u ∈ V ( G s ) h ( N G s ( u ) ) ≤ h 2 s ( G ) . (cid:4) Given the graph G s , one can repeat the previous process and select another vertex to remove , proceeding in an iterative fashion . This gives the sequential elimination algo - rithm of Figure 1 , which provides an upper bound h ∗ ( G ) on the clique number of G . Sequential elimination algorithm 1 . Set G ′ ← G , G ∗ ← G and h ∗ ( G ) ← 0 ; 2 . Select a vertex s ∈ V ( G ′ ) ; If h ∗ ( G ) < h ( N G ′ ( s ) ) then set h ∗ ( G ) ← h ( N G ′ ( s ) ) and G ∗ ← G ′ ; 3 . If h ∗ ( G ) < max u ∈ V ( G ′ ) h ( N G ′ ( u ) ) then set G ′ ← G ′ s and go to 2 ; Else STOP : return h ∗ ( G ) and G ∗ . Figure 1 . The sequential elimination algorithm Notice that the sequential elimination algorithm also returns the subgraph G ∗ of G for which h ∗ ( G ) was updated last . This subgraph will be useful for the computation of a lower bound on ω ( G ) , as shown in the next section . Proposition 3 The sequential elimination algorithm is ﬁnite and its output h ∗ ( G ) is an upper bound on ω ( G ) . Proof : The algorithm is ﬁnite since at most | V ( G ) | − 1 vertices can be removed from G before the algorithm stops . Indeed , if the algorithm enters Step 2 with a unique vertex s in V ( G ′ ) , then h ∗ ( G ) ≥ h ( N G ′ ( s ) ) = max u ∈ V ( G ′ ) h ( N G ′ ( u ) ) at the end of this Step , and the stopping criterion of Step 3 is satisﬁed . 3 Let W ⊆ V ( G ) denote the set of vertices that belong to a maximum clique in G and let G ′ denote the remaining subgraph of G when the algorithm stops . If W ⊆ V ( G ′ ) , then we know from Proposition 1 applied to G ′ that ω ( G ) = ω ( G ′ ) ≤ max u ∈ V ( G ′ ) h ( N G ′ ( u ) ) ≤ h ∗ ( G ) . So assume W ∩ ( V ( G ) \ V ( G ′ ) ) 6 = ∅ . Let s be the ﬁrst vertex in W that was removed from G , and let G ′′ denote the subgraph of G from which s was removed . Just after removing s , we have ω ( G ) = ω ( G ′′ ) = ω ( N G ′′ ( s ) ) ≤ h ( N G ′′ ( s ) ) ≤ h ∗ ( G ) . Clearly , h ∗ ( G ) cannot decrease in the remaining iterations , which yields the conclusion . (cid:4) Under the mild assumption that the upper bound function h is increasing , i . e . , h ( G ′ ) ≤ h ( G ) whenever G ′ ⊆ G , we can order the bounds determined by the last three propositions and compare them to h ( G ) , the upper bound computed on G itself . Proposition 4 Let s the be the vertex selected at the ﬁrst iteration of the sequential elimination algorithm . If h is an increasing function , then we have ω ( G ) ≤ h ∗ ( G ) ≤ h 2 s ( G ) ≤ h 1 ( G ) ≤ h ( G ) . Proof : The ﬁrst inequality , ω ( G ) ≤ h ∗ ( G ) , was proved in Proposition 3 . To prove the second inequality , h ∗ ( G ) ≤ h 2 s ( G ) , consider the iteration of the sequential elimi - nation algorithm where h ∗ ( G ) was updated last . If this last update happened at the ﬁrst iteration , we have h ∗ ( G ) = h ( N G ( s ) ) ≤ h 2 s ( G ) . Otherwise , let s ′ be the vertex selected for the last update of h ∗ ( G ) , and let G ∗ denote the subgraph in which s ′ was selected . We have N G ∗ ( s ′ ) ⊆ N G s ( s ′ ) which gives h ∗ ( G ) = h ( N G ∗ ( s ′ ) ) ≤ h ( N G s ( s ′ ) ) ≤ max u ∈ V ( G s ) h ( N G s ( u ) ) ≤ h 2 s ( G ) . The inequality h 2 s ( G ) ≤ h 1 ( G ) follows from the fact that G s is a subgraph of G . Indeed , h 2 s ( G ) = max { h ( N G ( s ) ) , max u ∈ V ( G s ) h ( N G s ( u ) ) } ≤ max { h ( N G ( s ) ) , max u ∈ V ( G s ) h ( N G ( u ) ) } = max u ∈ V ( G ) h ( N G ( u ) ) = h 1 ( G ) . Finally , the inequality h 1 ( G ) ≤ h ( G ) is a direct conse - quence of the hypothesis that h is increasing , since the closed neighborhood of any vertex of G is an induced subgraph of G . (cid:4) If h is not increasing , the relationships above between the diﬀerent bounds do not necessarily hold . Consider , for instance , the following upper bound function : 4 h ( G ) = ( χ ( G ) if | V ( G ) | ≥ 4 | V ( G ) | otherwise . Using this function on a square graph ( 4 vertices , 4 edges , organised in a square ) gives h ( G ) = χ ( G ) = 2 , while the upper bound computed on the closed neighborhood of any vertex u gives h ( N G ( u ) ) = | V ( N G ( u ) ) | = 3 > h ( G ) , which implies h ∗ ( G ) = h 2 s ( G ) = h 1 ( G ) = 3 > 2 = h ( G ) . Nonetheless , even when h is not increasing , it is easy to modify the bound deﬁnitions to obtain the result of the last proposition . For instance , one can replace each bound h ( N G ′ ( u ) ) by min { h ( G ) , h ( N G ′ ( u ) ) } . In practice , this implies that we add computing time at the start of the sequential elimination algorithm to determine h ( G ) , only to prevent an event that is unlikely to happen . This is why we chose not to incorporate this safeguard into our implementation of the sequential elimination algorithm . To fully describe the sequential elimination algorithm , it remains to specify how to select the vertex s to be removed at every iteration . Since the sequential elimination algorithm updates the value of h ∗ ( G ) by setting h ∗ ( G ) ← max { h ∗ ( G ) , h ( N G ′ ( s ) ) } , we select the vertex s that minimizes h ( N G ′ ( u ) ) over all u ∈ V ( G ′ ) . Figure 2 illustrates all bounds when using h ( G ) = | V ( G ) | . We indicate the value h ( N G ′ ( u ) ) for every graph G ′ and for every vertex u ∈ V ( G ′ ) . We obviously have h ( G ) = 7 . As shown in Figure 2a , h ( N G ( a ) ) = 5 , h ( N G ( b ) ) = h ( N G ( c ) ) = 4 , and h ( N G ( u ) ) = 2 for u = d , e , f , g , and we therefore have h 1 ( G ) = 5 . Also , we see from Figure 2b that h ( N G b ( a ) ) = 4 , h ( N G b ( c ) ) = 3 , h ( N G b ( u ) ) = 2 for u = d , e , f , and h ( N G b ( g ) ) = 1 , and this gives an upper bound h 2 b ( G ) = 4 . The sequential elimination algorithm is illustrated in Figure 2c . The black vertices correspond to the selected vertices . At the ﬁrst iteration , one can choose s = d , e , f or g , say d and this gives value 2 to h ∗ ( G ) . Then vertices e , f and g are removed without modifying h ∗ ( G ) . Finally , the algorithm selects one of the three vertices in the remaining graph G ′ , say a , and stops since h ∗ ( G ) is set equal to 3 = h ( N G ′ ( a ) ) = h ( N G ′ ( b ) ) = h ( N G ′ ( c ) ) . The ﬁnal upper bound is therefore h ∗ ( G ) = 3 , which corresponds to the size of the maximum clique . 5 2 2 2 4 4 2 5 c b a f g e d 2 2 1 3 2 4 c a d 2 2 2 4 4 2 5 c b a d f g e f g e 2 2 2 4 3 5 c b a f g e 2 2 3 3 5 c b a f g 2 3 3 4 c b a g 3 3 3 c b a ( a ) graph G ( b ) graph G b ( c ) illustation of the decomposition algorithm Figure 2 . Illustration of the upper bounds Notice that if h ( G ) = | V ( G ) | , then the sequential elimination algorithm always chooses a vertex with minimum degree in the remaining graph . Hence , it is equivalent to the procedure proposed by Szekeres and Wilf [ 14 ] for the computation of an upper bound on the chromatic number χ ( G ) . For other upper bounding procedures h , our sequential elimination algorithm possibly gives a bound h ∗ ( G ) < χ ( G ) . For example , assume that h is a procedure that returns the number of colors used by a linear coloring algorithm that orders the vertices randomly and then colors them sequentially according to that order , giving the smallest available color to each vertex . We then have h ( G ) ≥ χ ( G ) . However , for G equal to a pentagon ( the chordless cycle on ﬁve vertices ) , h ( N G ( u ) ) = 2 for all u ∈ V ( G ) , which implies χ ( G ) = 3 > 2 = h ∗ ( G ) = h 1 ( G ) = h 2 s ( G ) for all s ∈ V ( G ) . Given a graph G with n vertices and m edges , the computational complexity of the sequential elimination algorithm is O ( n 2 T ( n , m ) ) , where T ( n , m ) is the time taken to compute h ( G ) on G . Since h 1 ( G ) and h 2 s ( G ) can both be computed in O ( n T ( n , m ) ) , signiﬁcant improvements in the quality of the upper bounds need to be observed to justify this additional computational eﬀort . Our computational results , presented in Section 4 . 1 , show that this is indeed the case . Before presenting these results , we will see how to use the sequential elimination algorithm to also improve the computation of lower bounds on the clique number of a graph . 6 3 Using the Sequential Elimination Algorithm to Com - pute Lower Bounds In this section we show how to exploit the results of the sequential elimination algorithm to compute lower bounds on the clique number of a graph . To this end , we make use of the following proposition . Proposition 5 Let h ∗ ( G ) and G ∗ be the output of the sequential elimination algorithm . If h ∗ ( G ) = ω ( G ) , then G ∗ contains all cliques of maximum size of G . Proof : Suppose there exists a clique of size ω ( G ) in G that is not in G ∗ , and let t ∗ be the iteration where h ∗ ( G ) was updated last . At some iteration t ′ , prior to t ∗ , some vertex s ′ belonging to a maximum clique of G was removed from some graph G ′ ⊆ G . Hence h ∗ ( G ) ≥ h ( N G ′ ( s ′ ) ) ≥ ω ( N G ′ ( s ′ ) ) = ω ( G ) at the end of iteration t ′ . Since h ∗ ( G ) is updated ( increased ) at iteration t ∗ , we have h ∗ ( G ) > ω ( G ) at the end of iteration t ∗ , a contradiction . (cid:4) Notice that when h ∗ ( G ) > ω ( G ) , it may happen that ω ( G ∗ ) < ω ( G ) . For example , for the left graph G of Figure 3 , with h ( G ) = | V ( G ) | , the sequential elimination algorithm ﬁrst selects s = a or b , say a , and h ∗ ( G ) is set equal to 3 . Then b is removed without changing the value of h ∗ ( G ) . Finally , one of the 6 remaining vertices is selected , the bound h ∗ ( G ) is set equal to 4 , and the algorithm stops since there are no vertices with h ( N G ′ ( u ) ) > 4 in the remaining graph G ′ . Hence G ∗ has 6 vertices and ω ( G ∗ ) = 2 < 3 = ω ( G ) . According to Proposition 5 , this is possible only because h ∗ ( G ) = 4 > 3 = ω ( G ) . a b 4 4 4 4 4 3 3 6 b 4 4 4 4 4 2 5 4 4 4 4 4 4 Figure 3 . A graph G with ω ( G ∗ ) < ω ( G ) 7 In order to obtain a lower bound on ω ( G ) , Proposition 5 suggests to determine G ∗ , and to run an algorithm ( either exact or heuristic ) to get a lower bound on the clique number of G ∗ . Clearly , the size of such a clique is a lower bound on the clique number of G . This process is summarized in Figure 4 , where ℓ ( G ) is any known procedure that computes a lower bound on the clique number of a graph G , while ℓ ∗ ( G ) is the new lower bound produced by our algorithm . Lower bounding procedure 1 . Run the sequential elimination algorithm on G to get G ∗ ; 2 . Set ℓ ∗ ( G ) ← ℓ ( G ∗ ) . Figure 4 . Algorithm for the computation of a lower bound on ω ( G ) When G ∗ is small enough , an exact algorithm can be used at Step 2 to determine ω ( G ∗ ) , while it can be too time consuming to use the same exact algorithm to compute ω ( G ) . However , for many instances , the iteration where h ∗ ( G ) is updated last is reached very early , as will be shown in the next section , and using an exact algorithm at Step 2 is often not realistic . We will observe in the next section that even if ℓ is a heuristic lower bounding function , it often happens that ℓ ∗ ( G ) = ℓ ( G ∗ ) > ℓ ( G ) . Notice that such a situation can only happen if ℓ is not a decreasing function ( i . e . , ℓ ( G ′ ) is possibly larger than ℓ ( G ) for a subgraph G ′ ⊂ G ) . This is illustrated with ℓ equal to the well - known greedy algorithm MIN [ 7 ] described in Figure 5 ; we then use the notation ℓ ( G ) = MIN ( G ) . Procedure MIN Set G ′ ← G and K ← ∅ ; While G ′ 6 = ∅ do Set s ← argmax u ∈ V ( G ′ ) \ K | N G ′ ( u ) | ; Set G ′ ← N G ′ ( s ) and K ← K ∪ { s } ; Return | K | . Figure 5 . Greedy lower bounding algorithm for the clique number 8 Algorithm MIN applied on the graph G of Figure 6 returns value 2 , since vertex a has the largest number of neighbors and is therefore chosen ﬁrst . The sequential elimination algorithm with h ( G ) = | V ( G ) | ﬁrst chooses s = b , c or d , say b , which gives value 2 to h ∗ ( G ) . Then c , d and a are removed without changing the value of h ∗ ( G ) . Finally , one of the vertices e , f or g is selected , which gives h ∗ ( G ) = 3 , and the algorithm stops . Hence , G ∗ is the triangle induced by vertices e , f and g , and procedure MIN applied to this triangle returns value 3 . In summary , we have ℓ ∗ ( G ) = ℓ ( G ∗ ) = 3 > 2 = ℓ ( G ) . Notice also that even if MIN and h are not very eﬃcient lower and upper bounding procedures ( since ℓ ( G ) = 2 < 3 = ω ( G ) < 6 = h ( G ) ) , they help getting better bounds . In our example , we have ℓ ∗ ( G ) = ℓ ( G ∗ ) = 3 = h ∗ ( G ) , which provides a proof that ω ( G ) = 3 . e a b c d g f Figure 6 . A graph G with ℓ ∗ ( G ) > ℓ ( G ) 4 Computational Results The objective of our computational experiments is twofold . First , we analyze the ef - fectiveness of the sequential elimination algorithm when using diﬀerent upper bound functions h . Second , we present the lower bounds obtained by running several maximum clique algorithms ( exact and heuristic ) on the graph G ∗ resulting from the sequential elimination algorithm ( using an eﬀective upper bound function h ) . All our tests were performed on 93 instances used in the second DIMACS challenge [ 9 ] . Most instances come from the maximum clique section , though we also included a few instances from the graph coloring section , since we use graph coloring heuristics as upper bound func - tions . The characteristics of the selected instances can be found in the next subsection . 4 . 1 Computing Upper Bounds Since the sequential elimination method produces a bound h ∗ ( G ) with a signiﬁcant in - crease in computing time when compared to the computation of h ( G ) , we did not use 9 hard - to - compute upper bound functions like Lovasz’ theta function [ 10 , 11 ] ( which gives a value between the clique number and the chromatic number ) . Although there is a polynomial time algorithm to compute this bound , it is still time - consuming ( even for relatively small instances ) and diﬃcult to code . The most trivial bounds we tested are the number of vertices h a ( G ) = | V ( G ) | and the size of the largest closed neighborhood h b ( G ) = max u ∈ V ( G ) | V ( N G ( u ) ) | . Apart from these loose bounds , we obtained tighter bounds by computing upper bounds on the chromatic number with three fast heuristic methods . The simplest is the linear coloring algorithm ( which we denote h c ( G ) ) , which consists in assigning the smallest available color to each vertex , using the order given in the ﬁle deﬁning the graph . The second graph coloring method we tested is DSATUR [ 4 ] ( denoted h d ( G ) ) , a well - known greedy algorithm which iteratively selects a vertex with maximum saturation degree and assigns to it the smallest available color , the saturation degree of a vertex u being deﬁned as the number of colors already used in N G ( u ) . Finally , the last method we tested ( denoted h e ( G ) ) starts with the solution found by DSATUR and runs the well - known tabu search algorithm Tabucol [ 8 , 5 ] , performing as many iterations as there are vertices in the graph ( which is a very small amount of iterations for a tabu search ) . Let G be a graph with n vertices and m edges . As mentioned at the end of Section 2 , the computational complexity of the sequential elimination algorithm is O ( n 2 T x ( n , m ) ) , where T x ( n , m ) is the time taken to compute h x ( G ) on G ( and x is any letter between a and e ) . The functions h x ( G ) deﬁned above can easily be implemented so that T a ( n , m ) ∈ O ( n ) , T b ( n , m ) ∈ O ( m ) , T c ( n , m ) ∈ O ( m ) , T d ( n , m ) ∈ O ( n 2 ) , and T e ( n , m ) ∈ O ( n 3 ) . The last bound is easily derived , since Tabucol is initialized with DSATUR , which gives the bound h d ( G ) ≤ n , and a neighbor solution is obtained by changing the color of one vertex . Thus , the neighborhood is explored in time O ( nh d ( G ) ) , and since we perform n iterations , we obtain a worst - case complexity of O ( n 2 h d ( G ) ) ⊆ O ( n 3 ) . Tables 1 and 2 give the detailed results obtained when using the sequential elimination algorithm with these ﬁve upper bound functions . The ﬁrst column ( Problem ) indicates the name of the problem instance taken from the DIMACS site ; the second column ( W ) 10 gives the size of the largest known clique ; the remaining columns indicate the upper bounds h x ( G ) and h ∗ x ( G ) computed by each of the ﬁve functions on the original graph and when using the sequential elimination algorithm . To analyze these results , we use the following improvement ratio , which is a value in the interval [ 0 , 1 ] : I x = h x ( G ) − h ∗ x ( G ) h x ( G ) − W . A value of 0 indicates that the bound h ∗ x ( G ) does not improve upon h x ( G ) , while a value of 1 corresponds to the case where h ∗ x ( G ) = W , i . e . , the maximum possible improvement ( if W is indeed the clique number ) is achieved by the sequential elimination algorithm . We have discarded the cases where the upper bound function applied to G already found a maximum clique , since then there is no possible improvement to be gained by using the sequential elimination algorithm . Table 3 displays the improvement ratios ( in % ) averaged for each family of graphs and for all instances . The ﬁrst column ( Problem ) indicates the family of graphs , each being represented by the ﬁrst characters identifying them , followed by a star ( * ) . The remaining columns show the average improvement for the ﬁve upper bound functions . Our initial conjecture was that the improvement would be inversely correlated to the quality of the upper bound function , i . e . , the worst the function , the more room for im - provement there is , hence the most improvement should be obtained . The results do not verify this conjecture , since the best upper bound functions show better improvements than the worst ones . Indeed , the worst functions , h a ( G ) and h b ( G ) , display improve - ments of 50 % and 43 % , respectively , while the best functions , h c ( G ) , h d ( G ) and h e ( G ) , reach improvements of 55 % , 60 % and 64 % , respectively . Even among the graph coloring algorithms , we observe an inverse relationship , i . e . , as the eﬀectiveness of the method increases , the improvement values also increase . At ﬁrst , we thought this phenomenon might be due to the fact that for some families of graphs average improvements were reaching 100 % , thus inﬂuencing the overall average improvement more than it should . But a similar progression can be observed for most families of graphs . Another explana - 11 Linear DSATUR | V ( G ) | max u ∈ V ( G ) | V ( N G ( u ) ) | coloring DSATUR + Tabucol Problem W h a ( G ) h ∗ a ( G ) h b ( G ) h ∗ b ( G ) h c ( G ) h ∗ c ( G ) h d ( G ) h ∗ d ( G ) h e ( G ) h ∗ e ( G ) brock200 1 21 200 135 166 114 59 42 53 38 47 35 brock200 2 12 200 85 115 54 36 19 31 17 30 16 brock200 3 15 200 106 135 76 45 28 39 24 35 23 brock200 4 17 200 118 148 90 49 32 43 29 41 27 brock400 1 27 400 278 321 226 102 75 93 68 89 62 brock400 2 29 400 279 329 229 100 74 93 68 90 62 brock400 3 31 400 279 323 227 103 75 92 68 83 63 brock400 4 33 400 278 327 228 100 74 91 68 90 62 brock800 1 23 800 488 561 345 144 96 137 88 128 80 brock800 2 24 800 487 567 347 144 96 134 88 122 81 brock800 3 25 800 484 559 346 143 96 133 87 123 80 brock800 4 26 800 486 566 346 148 96 136 87 124 81 c - fat200 - 1 12 200 15 18 15 12 12 15 12 14 12 c - fat200 - 2 24 200 33 35 33 24 24 24 24 24 24 c - fat200 - 5 58 200 84 87 84 68 58 84 58 83 58 c - fat500 - 1 14 500 18 21 18 14 14 14 14 14 14 c - fat500 - 10 126 500 186 189 186 126 126 126 126 126 126 c - fat500 - 2 26 500 36 39 36 26 26 26 26 26 26 c - fat500 - 5 64 500 93 96 93 64 64 64 64 64 64 c1000 9 68 1000 875 926 814 319 283 305 266 276 238 c125 9 34 125 103 120 100 57 49 52 44 47 41 c2000 5 16 2000 941 1075 518 226 120 210 110 198 102 c2000 9 77 2000 1759 1849 1625 592 519 562 492 492 442 c250 9 44 250 211 237 200 98 86 92 78 82 71 c4000 5 18 4000 1910 2124 1028 402 215 377 200 365 186 c500 9 57 500 433 469 408 184 156 164 144 149 131 dsjc1000 5 15 1000 460 552 263 127 68 115 61 109 57 dsjc500 5 13 500 226 287 134 72 39 65 35 61 33 gen200 p0 9 44 44 200 168 191 161 76 63 62 53 44 44 gen200 p0 9 55 55 200 167 191 161 80 68 71 60 62 55 gen400 p0 9 55 55 400 337 376 320 127 110 102 81 55 55 gen400 p0 9 65 65 400 337 379 321 136 118 118 99 65 65 gen400 p0 9 75 75 400 337 381 322 143 124 118 103 75 79 hamming10 - 2 512 1024 1014 1014 1006 512 512 512 512 512 512 hamming10 - 4 40 1024 849 849 724 128 121 85 71 85 70 hamming6 - 2 32 64 58 58 54 32 32 32 32 32 32 hamming6 - 4 4 64 23 23 8 8 5 7 5 7 5 hamming8 - 2 128 256 248 248 242 128 128 128 128 128 128 hamming8 - 4 16 256 164 164 110 32 27 24 17 24 16 johnson16 - 2 - 4 8 120 92 92 68 14 13 14 13 14 13 johnson32 - 2 - 4 16 496 436 436 380 30 29 30 29 30 29 johnson8 - 2 - 4 4 28 16 16 8 6 5 6 5 6 5 johnson8 - 4 - 4 14 70 54 54 42 20 17 17 14 14 14 keller4 11 171 103 125 76 37 18 24 17 22 15 keller5 27 776 561 639 459 175 50 61 49 59 43 keller6 59 3361 2691 2953 2350 781 126 141 122 141 118 Table 1 : Upper bounds obtained with ﬁve upper bound functions h x ( G ) 12 Linear DSATUR | V ( G ) | max u ∈ V ( G ) | V ( N G ( u ) ) | coloring DSATUR + Tabucol Problem W h a ( G ) h ∗ a ( G ) h b ( G ) h ∗ b ( G ) h c ( G ) h ∗ c ( G ) h d ( G ) h ∗ d ( G ) h e ( G ) h ∗ e ( G ) latin square 10 . col 90 900 684 684 636 213 144 132 108 119 105 le450 15a . col 15 450 25 100 18 22 15 17 15 17 15 le450 15b . col 15 450 25 95 17 22 15 16 15 16 15 le450 15c . col 15 450 50 140 29 30 15 23 15 23 15 le450 15d . col 15 450 52 139 29 31 15 24 15 23 15 le450 25a . col 25 450 27 129 26 28 25 25 25 25 25 le450 25b . col 25 450 26 112 25 27 25 25 25 25 25 le450 25c . col 25 450 53 180 39 37 25 29 25 29 25 le450 25d . col 25 450 52 158 38 35 25 28 25 28 25 le450 5a . col 5 450 18 43 7 14 5 10 5 10 5 le450 5b . col 5 450 18 43 7 13 5 9 5 9 5 le450 5c . col 5 450 34 67 12 17 6 10 5 9 5 le450 5d . col 5 450 33 69 12 18 5 12 5 11 5 MANN a27 126 378 365 375 363 135 135 140 137 135 131 MANN a45 345 1035 1013 1032 1011 372 370 369 367 363 353 MANN a81 1100 3321 3281 3318 3279 1134 1134 1153 1146 1135 1124 MANN a9 16 45 41 42 39 18 18 19 18 18 17 p hat1000 - 1 10 1000 164 409 84 69 24 52 20 52 19 p hat1000 - 2 46 1000 328 767 289 148 89 109 76 109 74 p hat1000 - 3 68 1000 610 896 554 230 160 187 134 187 132 p hat1500 - 1 12 1500 253 615 126 95 33 74 28 74 27 p hat1500 - 2 65 1500 505 1154 451 213 133 157 113 157 112 p hat1500 - 3 94 1500 930 1331 840 326 231 270 195 270 194 p hat300 - 1 8 300 50 133 28 29 11 22 9 21 9 p hat300 - 2 25 300 99 230 90 56 34 42 29 42 28 p hat300 - 3 36 300 181 268 166 85 59 69 51 69 49 p hat500 - 1 9 500 87 205 46 45 16 32 13 32 13 p hat500 - 2 36 500 171 390 152 87 54 66 46 66 45 p hat500 - 3 50 500 304 453 279 131 94 108 78 107 76 p hat700 - 1 11 700 118 287 62 53 19 40 16 40 16 p hat700 - 2 44 700 236 540 213 114 71 85 60 85 59 p hat700 - 3 62 700 427 628 389 171 120 143 102 141 100 san1000 15 1000 465 551 400 47 21 24 16 15 15 san200 0 7 1 30 200 126 156 108 49 32 42 30 31 30 san200 0 7 2 18 200 123 165 113 35 24 23 18 18 18 san200 0 9 1 70 200 163 192 156 92 75 73 70 70 70 san200 0 9 2 60 200 170 189 161 86 75 75 63 62 60 san200 0 9 3 44 200 170 188 161 73 65 64 53 48 44 san400 0 5 1 13 400 184 226 155 29 14 21 13 21 13 san400 0 7 1 40 400 262 302 224 81 54 59 43 45 40 san400 0 7 2 30 400 260 305 217 67 49 47 36 30 30 san400 0 7 3 22 400 254 308 203 59 42 29 26 22 22 san400 0 9 1 100 400 345 375 325 163 138 135 116 109 100 sanr200 0 7 18 200 125 162 100 52 36 47 32 42 30 sanr200 0 9 42 200 167 190 158 82 70 74 64 69 59 sanr400 0 5 13 400 178 234 108 62 33 56 29 50 27 sanr400 0 7 21 400 259 311 201 91 64 83 58 78 53 Table 2 : Upper bounds obtained with ﬁve upper bound functions h x ( G ) 13 Problem I a ( % ) I b ( % ) I c ( % ) I d ( % ) I e ( % ) brock * 41 40 45 47 50 c - fat * 93 23 100 100 100 c * 27 27 30 32 33 dsjc * 56 54 54 56 57 gen * 20 20 33 47 100 hamming * 25 25 38 62 67 johnson * 29 35 31 43 25 keller * 30 31 83 37 47 latin * 27 8 56 57 48 le * 96 93 99 100 100 MANN * 6 5 2 19 45 p hat * 66 63 62 64 66 san * 36 29 61 79 100 sanr * 39 40 44 47 48 ALL 50 43 55 60 64 Table 3 : Average improvement for each family of graphs tion would be that if two functions show diﬀerent results when applied to G but identical results when embedded into the sequential elimination algorithm , then the improvement would be better for the best function because the denominator is smaller . When we look at the detailed results , however , we notice that in general , the better the function , the better the results obtained by the sequential elimination algorithm . Computing times are reported in Tables 4 and 5 . The times needed to compute h x ( G ) and h ∗ x ( G ) appear in columns T x and T ∗ x , respectively . All times are in seconds and were obtained on an AMD Opteron ( tm ) 275 / 2 . 2 GHz Processor . A zero value means that the bound was obtained in less than 0 . 5 seconds , while times larger than 10 hours ( i . e . , 36000 seconds ) are reported as “ > 10h” . It clearly appears that the best upper bounds are obtained with the most time consuming procedures . For example , for the c2000 5 instance , Tabucol makes it possible to compute h ∗ e ( G ) = 102 while h ∗ a ( G ) = 941 , h ∗ b ( G ) = 518 , h ∗ c ( G ) = 120 , and h ∗ d ( G ) = 110 , but such an improvement requires an increase of the computing time from 0 second for h ∗ a ( G ) and several minutes for h ∗ b ( G ) , h ∗ c ( G ) , and h ∗ d ( G ) , to more than 5 hours for h ∗ e ( G ) . Given the computational complexity analysis performed earlier , these experimental results can be easily explained , since the sequential elimination with Tabucol requires a worst - case time of O ( n 5 ) . 14 Linear DSATUR | V ( G ) | max u ∈ V ( G ) | V ( N G ( u ) ) | coloring DSATUR + Tabucol Problem n m T a T ∗ a T b T ∗ b T c T ∗ c T d T ∗ d T e T ∗ e brock200 1 200 14834 0 0 0 0 0 0 0 0 0 6 brock200 2 200 9876 0 0 0 0 0 0 0 0 0 1 brock200 3 200 12048 0 0 0 0 0 0 0 0 0 3 brock200 4 200 13089 0 0 0 0 0 0 0 0 0 3 brock400 1 400 59723 0 0 0 1 0 1 0 5 0 92 brock400 2 400 59786 0 0 0 1 0 1 0 3 0 71 brock400 3 400 59681 0 0 0 1 0 0 0 4 0 82 brock400 4 400 59765 0 0 0 1 0 1 0 5 0 66 brock800 1 800 207505 0 0 0 10 0 6 0 63 2 1466 brock800 2 800 208166 0 0 0 10 0 6 0 33 3 855 brock800 3 800 207333 0 0 0 8 0 6 0 32 2 669 brock800 4 800 207643 0 0 0 9 0 7 0 54 2 786 c - fat200 - 1 200 1534 0 0 0 0 0 0 0 0 0 0 c - fat200 - 2 200 3235 0 0 0 0 0 0 0 0 0 0 c - fat200 - 5 200 8473 0 0 0 0 0 0 0 0 0 1 c - fat500 - 1 500 4459 0 0 0 0 0 0 0 0 0 0 c - fat500 - 10 500 46627 0 0 0 0 0 0 0 1 0 19 c - fat500 - 2 500 9139 0 0 0 0 0 0 0 0 0 0 c - fat500 - 5 500 23191 0 0 0 0 0 0 0 0 0 3 C1000 9 1000 45079 0 0 0 16 0 20 0 162 9 12241 C125 9 125 6963 0 0 0 0 0 0 0 0 0 1 C2000 5 2000 999836 0 0 0 153 0 100 0 803 30 20034 C2000 9 2000 1799532 0 0 0 119 0 134 0 1522 141 > 10h C250 9 250 27984 0 0 0 0 0 0 0 1 0 37 C4000 5 4000 4000268 0 1 0 1454 0 909 1 6906 178 > 10h C500 9 500 112332 0 0 0 2 0 2 0 11 1 1115 DSJC1000 5 1000 249826 0 0 0 18 0 12 0 83 2 880 DSJC500 5 500 62624 0 0 0 1 0 1 0 5 0 42 gen200 p0 9 44 200 17910 0 0 0 0 0 0 0 1 0 11 gen200 p0 9 55 200 17910 0 0 0 0 0 0 0 1 0 8 gen400 p0 9 55 400 71820 0 0 0 2 0 1 0 19 0 53 gen400 p0 9 65 400 71820 0 0 0 1 0 1 0 13 0 104 gen400 p0 9 75 400 71820 0 0 0 1 0 1 0 6 0 630 hamming10 - 2 1024 518656 0 0 0 6 0 6 0 57 4 3189 hamming10 - 4 1024 434176 0 0 0 6 0 5 0 394 1 3102 hamming6 - 2 64 1824 0 0 0 0 0 0 0 0 0 0 hamming6 - 4 64 704 0 0 0 0 0 0 0 0 0 0 hamming8 - 2 256 31616 0 0 0 0 0 0 0 0 0 12 hamming8 - 4 256 20864 0 0 0 0 0 0 0 1 0 5 johnson16 - 2 - 4 120 5460 0 0 0 0 0 0 0 0 0 0 johnson32 - 2 - 4 496 107880 0 0 0 1 0 1 0 3 0 22 johnson8 - 2 - 4 28 210 0 0 0 0 0 0 0 0 0 0 johnson8 - 4 - 4 70 1855 0 0 0 0 0 0 0 0 0 0 keller4 171 9435 0 0 0 0 0 0 0 0 0 1 keller5 776 225990 0 0 0 3 0 20 0 164 0 2157 keller6 3361 4619898 0 0 0 269 0 11518 1 > 10h 14 > 10h Table 4 : Computing times in seconds obtained with ﬁve upper bound functions h x ( G ) 15 Linear DSATUR | V ( G ) | max u ∈ V ( G ) | V ( N G ( u ) ) | coloring DSATUR + Tabucol Problem n m T a T ∗ a T b T ∗ b T c T ∗ c T d T ∗ d T e T ∗ e latin square 10 . col 900 307350 0 0 0 4 0 10 0 109 5 2207 le450 15a . col 450 8168 0 0 0 0 0 0 0 0 0 1 le450 15b . col 450 8169 0 0 0 0 0 0 0 0 0 1 le450 15c . col 450 16680 0 0 0 0 0 0 0 0 0 2 le450 15d . col 450 16750 0 0 0 0 0 0 0 0 0 2 le450 25a . col 450 8260 0 0 0 0 0 0 0 0 0 1 le450 25b . col 450 8263 0 0 0 0 0 0 0 0 0 1 le450 25c . col 450 17343 0 0 0 1 0 0 0 1 0 3 le450 25d . col 450 17425 0 0 0 1 0 0 0 1 0 2 le450 5a . col 450 5714 0 0 0 0 0 0 0 0 0 0 le450 5b . col 450 5734 0 0 0 0 0 0 0 0 0 0 le450 5c . col 450 9803 0 0 0 0 0 0 0 0 0 0 MANN a27 378 70551 0 0 0 0 0 0 0 2 0 86 MANN a45 1035 533115 0 0 0 9 0 10 0 83 5 10104 MANN a81 3321 5506380 0 0 0 293 0 361 1 9544 177 > 10h MANN a9 45 918 0 0 0 0 0 0 0 0 0 0 p hat1000 - 1 1000 122253 0 0 0 30 0 14 0 45 0 144 p hat1000 - 2 1000 244799 0 0 0 191 0 77 0 569 1 3176 p hat1000 - 3 1000 371746 0 0 0 33 0 26 0 390 1 4209 p hat1500 - 1 1500 284923 0 1 0 145 0 70 0 298 1 862 p hat1500 - 2 1500 568960 0 1 0 953 0 366 0 3408 2 22368 p hat1500 - 3 1500 847244 0 0 0 145 0 131 0 2325 4 30069 p hat300 - 1 300 10933 0 0 0 0 0 0 0 0 0 2 p hat300 - 2 300 21928 0 0 0 2 0 1 0 3 0 17 p hat300 - 3 300 33390 0 0 0 1 0 1 0 3 0 29 p hat500 - 1 500 31569 0 0 0 2 0 1 0 3 0 11 p hat500 - 2 500 62946 0 0 0 12 0 6 0 25 0 171 p hat500 - 3 500 93800 0 0 0 3 0 4 0 21 0 262 p hat700 - 1 700 60999 0 0 0 7 0 4 0 12 0 42 p hat700 - 2 700 121728 0 0 0 47 0 20 0 107 0 733 p hat700 - 3 700 183010 0 0 0 15 0 11 0 90 1 1075 san1000 1000 250500 0 0 0 6 0 28 0 133 0 397 san200 0 7 1 200 13930 0 0 0 0 0 0 0 0 0 2 san200 0 7 2 200 13930 0 0 0 0 0 0 0 0 0 5 san200 0 9 1 200 17910 0 0 0 0 0 0 0 1 0 16 san200 0 9 2 200 17910 0 0 0 0 0 0 0 0 0 14 san200 0 9 3 200 17910 0 0 0 0 0 0 0 1 0 6 san400 0 5 1 400 39900 0 0 0 0 0 1 0 4 0 11 san400 0 7 1 400 55860 0 0 0 0 0 1 0 6 0 82 san400 0 7 2 400 55860 0 0 0 0 0 1 0 10 0 43 san400 0 7 3 400 55860 0 0 0 0 0 1 0 18 0 10 san400 0 9 1 400 71820 0 0 0 1 0 1 0 7 0 446 sanr200 0 7 200 13868 0 0 0 0 0 0 0 0 0 4 sanr200 0 9 200 17863 0 0 0 0 0 0 0 0 0 9 sanr400 0 5 400 39984 0 0 0 1 0 0 0 3 0 12 sanr400 0 7 400 55869 0 0 0 1 0 1 0 3 0 51 Table 5 : Computing times in seconds obtained with ﬁve upper bound functions h x ( G ) 16 4 . 2 Computing Lower Bounds In this section , we present the results obtained when computing lower bounds using G ∗ , the graph obtained at the iteration where h ∗ ( G ) was updated last in the sequential elimination algorithm . We use DSATUR ( h d ( G ) ) as upper bound function , since it shows a good balance between solution eﬀectiveness and computational eﬃciency . We tested four maximum clique algorithms to compute lower bounds : • An exact branch - and - bound algorithm , dfmax [ 9 ] ( available as a C program on the DIMACS ftp site [ 2 ] ) , performed with a time limit of ﬁve hours . We denote the lower bound obtained by this algorithm when applied to G and G ∗ as l a ( G ) and l a ( G ∗ ) , respectively . • A very fast greedy heuristic , MIN [ 7 ] ( already described in Section 3 ) . We denote the lower bounds obtained by this algorithm when applied to G and G ∗ as l b ( G ) and l b ( G ∗ ) , respectively . • The penalty - evaporation heuristic [ 13 ] , which , at each iteration , inserts into the current clique some vertex i , removing the vertices not adjacent to i . The removed vertices are penalized in order to reduce their potential of being selected to be inserted again during the next iterations . This penalty is gradually evaporating . We denote the lower bounds obtained by this algorithm when applied to G and G ∗ as l c ( G ) and l c ( G ∗ ) , respectively . • An improved version of the above penalty - evaporation heuristic , summarized in Figure 7 . We denote the lower bounds obtained by this algorithm when applied to G and G ∗ as l d ( G ) and l d ( G ∗ ) , respectively . Improved penalty - evaporation heuristic 1 . Set IP E ( G ) ← 0 and G ′ ← G ; 2 . Run the penalty - evaporation heuristic on G ′ to get a clique K ; If | K | > IP E ( G ) then set IP E ( G ) ← | K | ; 3 . For all u ∈ K do Run the penalty - evaporation heuristic on N G ′ ( u ) to get a clique K ′ ; If | K ′ | > IP E ( G ) then set IP E ( G ) ← | K ′ | , K ← K ′ , and restart Step 3 ; 17 4 . Remove K from G ′ ( i . e . , set G ′ equal to the subgraph induced by V ( G ′ ) \ K ) ; If G ′ is not empty then go to 2 else STOP : return IP E ( G ) . Figure 7 . Improved penalty - evaporation heuristic [ 13 ] The results obtained on the same instances as in Section 4 . 1 are presented in Tables 6 and 7 . Of the 93 instances , we removed those where G and G ∗ coincide , which left 72 instances . The ﬁrst column ( Problem ) indicates the name of each problem ; the second and third columns show the number of vertices in G ( n ) and G ∗ ( n ∗ ) , respectively ; the fourth column ( W ) gives the size of the largest known clique ; the ﬁfth and sixth columns ( l a ( G ) and l a ( G ∗ ) ) show the results obtained by dfmax ( with a time limit of ﬁve hours ) when applied to G and G ∗ , respectively ( a + sign indicates the algorithm was stopped because of the time limit , so G or G ∗ might contain a clique of size larger than the given value ) ; the remaining columns give the lower bounds generated by the three maximum clique heuristic methods , when applied to G and G ∗ . Column l a ( G ∗ ) indicates that dfmax has determined ω ( G ∗ ) within the time limit of ﬁve hours for 41 out the 72 instances . By comparing columns W , l a ( G ) and l a ( G ∗ ) on these instances , we observe that ω ( G ∗ ) = ω ( G ) = W in 38 cases , while ω ( G ∗ ) < ω ( G ) in one case ( instance p hat1500 - 1 ) and ω ( G ∗ ) = W and ω ( G ) is not known in two cases ( instances c - fat500 - 10 and san200 0 9 1 ) . We do not report computing times since the aim of the experiments is to compare the quality of the lower bounds on G and G ∗ . We ﬁnd however interesting to mention that for 22 of the 38 instances with ω ( G ∗ ) = ω ( G ) , dfmax has determined the clique number , both in G and G ∗ , in less than 1 second . For the 16 other instances , the decrease in computing time is in average equal to 47 % . For the 31 instances for which ω ( G ∗ ) is not known , we deduce from columns W , l a ( G ∗ ) and l d ( G ∗ ) that ω ( G ∗ ) ≥ W in 24 cases . The status of the seven remaining instances is yet unknown . Also , l a ( G ) < l a ( G ∗ ) for 11 out of these 31 instances while l a ( G ) > l a ( G ∗ ) for 6 of them ( and l a ( G ) = l a ( G ∗ ) for the 14 remaining instances ) . Furthermore , let | V ( G ) | − | V ( G ∗ ) | | V ( G ) | be the reduction ratio between the number of vertices in graphs G and G ∗ . The mean reduction ratio for the 72 instances is 20 % , among which 18 Penalty - Imp . Penalty - dfmax MIN evaporation evaporation Problem n n ∗ W l a ( G ) l a ( G ∗ ) l b ( G ) l b ( G ∗ ) l c ( G ) l c ( G ∗ ) l d ( G ) l d ( G ∗ ) brock200 1 200 198 21 21 21 14 16 20 20 20 21 brock200 2 200 197 12 12 12 7 8 10 11 11 12 brock200 3 200 199 15 15 15 10 11 14 13 14 14 brock200 4 200 195 17 17 17 11 13 16 16 17 17 brock400 1 400 399 27 27 + 27 + 19 19 23 23 25 24 brock400 2 400 399 29 29 + 29 + 20 18 23 24 29 25 brock400 3 400 399 31 31 + 31 + 20 17 24 25 31 31 brock800 3 800 799 25 21 + 21 + 15 15 19 20 22 22 c - fat200 - 1 200 90 12 12 12 12 12 12 12 12 12 c - fat200 - 2 200 24 24 24 24 24 24 24 24 24 24 c - fat200 - 5 200 116 58 58 58 58 58 58 58 58 58 c - fat500 - 1 500 140 14 14 14 14 14 14 14 14 14 c - fat500 - 10 500 252 126 124 + 126 126 126 126 126 126 126 c - fat500 - 2 500 260 26 26 26 26 26 26 26 26 26 c - fat500 - 5 500 128 64 64 64 64 64 64 64 64 64 c1000 9 1000 997 68 53 + 52 + 51 51 64 64 67 67 c2000 5 2000 1999 16 16 + 16 + 10 10 15 15 16 16 c250 9 250 242 44 41 + 42 + 35 36 44 44 44 44 c4000 5 4000 3998 18 17 + 17 + 12 12 16 17 18 17 c500 9 500 498 57 47 + 47 + 42 47 56 54 57 57 dsjc1000 5 1000 998 15 15 15 10 10 14 14 15 15 dsjc500 5 500 498 13 13 13 10 10 12 12 13 13 gen200 p0 9 44 200 197 44 44 + 44 + 32 32 44 44 44 44 gen200 p0 9 55 200 196 55 55 55 36 37 55 55 55 55 gen400 p0 9 55 400 388 55 43 + 44 + 42 44 51 51 53 52 gen400 p0 9 65 400 398 65 43 + 43 + 40 40 65 52 65 65 gen400 p0 9 75 400 398 75 45 + 45 + 45 47 75 75 75 75 hamming10 - 4 1024 1023 40 32 + 34 + 29 27 40 40 40 40 hamming8 - 4 256 114 16 16 16 16 11 16 16 16 16 keller5 776 770 27 24 + 25 + 15 15 26 27 27 27 keller6 3361 3338 59 42 + 45 + 32 36 39 43 59 59 Table 6 : Lower bounds l x ( G ) and l x ( G ∗ ) 36 instances have a reduction ratio of more than 5 % . If we focus on these 36 instances , we ﬁnd 35 instances with ω ( G ∗ ) ≥ W and one ( p hat1500 - 1 ) with ω ( G ∗ ) < W . In general , it seems preferable to perform a heuristic method on G ∗ rather than on G . When MIN ( l b ) is used , there are 25 instances with better results on G ∗ and only 14 instances with better results on G ( for the other instances , we obtain the same results on G and G ∗ ) . Similarly , the penalty - evaporation method ( l c ) is better when applied to G ∗ in 14 cases , and better when applied to G for 7 instances . For the last method , the situation is reversed , since l d ( G ∗ ) > l d ( G ) in only two cases , while l d ( G ∗ ) < l d ( G ) for 7 instances . For one of these 7 instances , we know that ω ( G ∗ ) < ω ( G ) , while for four other instances , we do not know whether G ∗ contains a maximum clique of G or not . 19 Penalty - Imp . Penalty - dfmax MIN evaporation evaporation Problem n n ∗ W l a ( G ) l a ( G ∗ ) l b ( G ) l b ( G ∗ ) l c ( G ) l c ( G ∗ ) l d ( G ) l d ( G ∗ ) latin square 10 . col 900 88 90 90 + 81 + 90 90 90 90 90 90 le450 15a . col 450 335 15 15 15 5 6 15 15 15 15 le450 15b . col 450 341 15 15 15 8 8 15 15 15 15 le450 15c . col 450 430 15 15 15 7 7 15 15 15 15 le450 15d . col 450 434 15 15 15 5 5 15 15 15 15 le450 25a . col 450 217 25 25 25 11 9 25 25 25 25 le450 25b . col 450 237 25 25 25 13 12 25 25 25 25 le450 25c . col 450 376 25 25 25 7 8 25 25 25 25 le450 25d . col 450 373 25 25 25 8 9 25 25 25 25 le450 5a . col 450 392 5 5 5 4 5 5 5 5 5 le450 5b . col 450 388 5 5 5 4 3 5 5 5 5 le450 5c . col 450 449 5 5 5 3 3 5 5 5 5 p hat1000 - 1 1000 665 10 10 10 7 9 10 10 10 10 p hat1000 - 2 1000 470 46 43 + 41 + 38 40 46 46 46 46 p hat1000 - 3 1000 853 68 49 + 48 + 57 57 67 68 68 68 p hat1500 - 1 1500 752 12 12 11 8 7 12 11 12 11 p hat1500 - 2 1500 690 65 46 + 48 + 54 59 65 65 65 65 p hat1500 - 3 1500 1263 94 53 + 54 + 75 81 94 94 94 94 p hat300 - 1 300 245 8 8 8 7 7 8 8 8 8 p hat300 - 2 300 169 25 25 25 23 20 25 25 25 25 p hat300 - 3 300 279 36 36 36 31 31 36 36 36 36 p hat500 - 1 500 372 9 9 9 6 8 9 9 9 9 p hat500 - 2 500 257 36 36 36 29 33 36 36 36 36 p hat500 - 3 500 448 50 44 + 48 + 42 42 49 50 50 50 p hat700 - 1 700 487 11 11 11 7 7 11 11 11 11 p hat700 - 2 700 324 44 44 44 38 42 44 44 44 44 p hat700 - 3 700 621 62 50 + 51 + 55 53 62 62 62 62 san1000 1000 970 15 10 + 10 + 8 8 8 8 15 10 san200 0 7 1 200 30 30 30 30 16 30 17 30 30 30 san200 0 7 2 200 189 18 18 + 18 + 12 12 13 13 18 18 san200 0 9 1 200 70 70 48 + 70 45 70 45 70 70 70 san200 0 9 3 200 198 44 44 + 36 + 31 30 36 43 44 43 san400 0 5 1 400 13 13 13 13 7 13 8 13 13 13 san400 0 7 1 400 390 40 22 + 20 + 21 20 21 20 22 22 san400 0 7 2 400 398 30 17 + 17 + 15 15 18 18 30 30 san400 0 7 3 400 376 22 17 + 22 + 12 12 17 17 22 22 san400 0 9 1 400 393 100 49 + 50 + 41 39 54 100 100 100 sanr200 0 7 200 197 18 18 18 14 14 18 18 18 18 sanr200 0 9 200 198 42 40 + 40 + 35 36 42 42 42 42 sanr400 0 5 400 395 13 13 13 10 9 13 12 13 13 sanr400 0 7 400 397 21 21 21 16 16 21 20 21 21 Table 7 : Lower bounds l x ( G ) and l x ( G ∗ ) 5 Conclusion In this paper , we have presented a sequential elimination algorithm to compute an upper bound on the clique number of a graph . At each iteration , this algorithm removes one vertex and updates a tentative upper bound by considering the closed neighborhoods of the remaining vertices . Given any method to compute an upper bound on the clique number of a graph , we have shown , under mild assumptions , that the sequential elimi - nation algorithm is guaranteed to improve upon that upper bound . Our computational 20 results on DIMACS instances show signiﬁcant improvements of about 60 % . We have also shown how to use the output of the sequential elimination algorithm to improve the computation of lower bounds . It would be interesting to apply the sequential elimination algorithm to other upper bound functions to see if similar trends can be observed . The development of other heuristic methods based on the sequential elimination algorithm is another promising avenue for future research . References [ 1 ] M . Aouchiche . Comparaison automatis´ee d’invariants en th´eorie des graphes . PhD thesis , ´Ecole polytechnique de Montr´eal , 2006 . [ 2 ] D . Applegate and D . Johnson . Dfmax source code in C . A World Wide Web page . ftp : / / dimacs . rutgers . edu / pub / challenge / graph / solvers / . [ 3 ] I . M . Bomze , M . Budinich , P . M . Pardalos , and M . Pelillo . The maximum clique problem . In D . Z . Du and P . M . Pardalos , editors , Handbook of Combinatorial Optimization , volume 4 , pages 1 – 74 . Kluwer Academic Publishers , 1999 . [ 4 ] D . Br´elaz . New methods to color the vertices of a graph . Communications of the ACM , 22 ( 4 ) : 251 – 256 , 1979 . [ 5 ] P . Galinier and A . Hertz . A survey of local search methods for graph coloring . Computers and Operations Research , 33 ( 9 ) : 2547 – 2562 , 2006 . [ 6 ] M . R . Garey and D . S . Johnson . Computers and Intractability : A Guide to the Theory of NP - Completeness . W . H . Freeman , 1979 . [ 7 ] J . Harant , Z . Ryjacek , and I . Schiermeyer . Forbidden subgraphs and MIN - algorithm for independence number . Discrete Mathematics , 256 ( 1 - 2 ) : 193 – 201 , 2002 . [ 8 ] A . Hertz and D . de Werra . Using tabu search for graph coloring . Computing , 39 : 345 – 351 , 1987 . 21 [ 9 ] D . S . Johnson and M . A . Trick , editors . Cliques , Coloring , and Satisﬁability – Second DIMACS Implementation challenge , volume 26 of DIMACS – Series in Discrete Mathematics and Theoretical Computer Science . American Mathematical Society , 11 – 13 October 1993 . [ 10 ] D . E . Knuth . The sandwich theorem . Electronic Journal of Combinatorics , 1 : 48 , 1994 . [ 11 ] L´aszl´o Lov´asz . On the Shannon capacity of a graph . IEEE Transactions on Infor - mation Theory , 25 ( 1 ) : 1 – 7 , 1979 . [ 12 ] P . M . Pardalos and J . Xue . The maximum clique problem . Journal of Global Opti - mization , 4 ( 3 ) : 301 – 328 , 1994 . [ 13 ] P . St - Louis , B . Gendron , and J . A . Ferland . A penalty - evaporation heuristic in a de - composition method for the maximum clique problem . Working paper , D´epartement d’informatique et de recherche op´erationnelle , Universit´e de Montr´eal , Canada . [ 14 ] G . Szekeres and H . S . Wilf . An inequality for the chromatic number of graphs . Journal of Combinatorial Theory , 4 : 1 – 3 , 1968 . 22