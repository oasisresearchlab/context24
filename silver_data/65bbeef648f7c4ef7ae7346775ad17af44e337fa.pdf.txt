Jointly published by AkadØmiai Kiad(cid:243) , Budapest Scientometrics , and Springer , Dordrecht Vol . 63 , No . 2 ( 2005 ) 373(cid:150)401 Received November 24 , 2004 Address for correspondence : M ICHEL Z ITT Lereco , INRA , Nantes , France E - mail : zitt @ nantes . inra . fr 0138(cid:150)9130 / US $ 20 . 00 Copyright ' 2005 AkadØmiai Kiad(cid:243) , Budapest All rights reserved Relativity of citation performance and excellence measures : From cross - field to cross - scale effects of field - normalisation M ICHEL Z ITTa , b S UZY R AMANANA - R AHARY , b E LISE B ASSECOULARDa a Lereco , INRA , Nantes ( France ) b Observatoire des Sciences et des Techniques ( OST ) , Paris ( France ) As citation practices strongly depend on fields , field normalisation is recognised as necessary for fair comparison of figures in bibliometrics and evaluation studies . However fields may be defined at various levels , from small research areas to broad academic disciplines , and thus normalisation values are expected to vary . The aim of this project was to test the stability of citation ratings of articles as the level of observation (cid:150) hence the basis of normalisation (cid:150) changes . A conventional classification of science based on ISI subject categories and their aggregates at various scales was used , namely at five levels : all science , large academic discipline , sub - discipline , speciality and journal . Among various normalisation methods , we selected a simple ranking method ( quantiles ) , based on the citation score of the article in each particular aggregate ( journal , speciality , etc . ) it belonged to at each level . The study was conducted on articles in the full SCI range , for publication year 1998 with a four - year citation window . Stability is measured in three ways : overall comparison of article rankings ; individual trajectory of articles ; survival of the top - cited class across levels . Overall rank correlations on the observed empirical structure are benchmarked against two fictitious sets that keep the same embedded structure of articles but reassign citation scores either in a totally ordered or in a totally random distribution . These sets act respectively as a (cid:145)worst case(cid:146) and (cid:145)best case(cid:146) for the stability of citation ratings . The results show that : ( a ) the average citation rankings of articles substantially change with the level of observation ( b ) observation at the journal level is very particular , and the results differ greatly in all test circumstances from all the other levels of observation ( c ) the lack of cross - scale stability is confirmed when looking at the distribution of individual trajectories of articles across the levels ; ( d ) when considering the top - cited fractions , a standard measure of excellence , it is found that the contents of the (cid:145)top - cited(cid:146) set is completely dependent on the level of observation . The instability of impact measures should not be interpreted in terms of lack of robustness but rather as the co - existence of various perspectives each having their own form of legitimacy . A follow - up study will focus on the micro levels of observation and will be based on a structure built around bibliometric groupings rather than conventional groupings based on ISI subject categories . Introduction Citations and impacts have been recognised for decades as a feature of central importance in science studies . They have received even more attention recently with the M . Z ITT et al . : Relativity of citation performance 374 Scientometrics 63 ( 2005 ) pervasive practices of institutional assessment , benchmarking , and (cid:145)excellence(cid:146) measurement . Interpretations of citation analyses are subject to many caveats which have been studied by both sociologists and bibliometricians from a variety of schools . A major issue is the discrepancy of citation behaviour across fields ( P INSKY & N ARIN , 1976 ; M URUGESAN & M ORAVCSIK , 1978 ) . In the early eighties various proposals for field - normalisation of impact figures were suggested , in both the USA and Europe , making comparisons possible between say , articles in mathematics ( a generally low - impact field ) and in fundamental biology ( a generally high impact field ) . Some milestones in bibliometric research were reviewed by S CHUBERT & B RAUN ( 1996 ) . There is little doubt about the need of normalisation , but the question arises of the particular level that should be used . A narrow research area ? A too small reference set can be statistically fragile and unstable over time . A large academic discipline ? It may be too heterogeneous , hence inefficient for normalisation . Thus , various pros and cons of narrow versus large reference sets can be discussed ( see the conclusion ) . To a certain extent , this corresponds to different perspectives having their own form of legitimacy . If we want to address the problem in general , we must consider a wide range of extensions of the reference set used for normalisation . In other words , we have to examine the sensitivity of normalised impact measures for particular articles as the scale of observation / normalisation changes . To this end , we need two pieces of information , first the citation score of individual articles ( available in SCI series ) , and also a complete ( i . e . multi - level ) and realistic classification of scientific articles , which will provide , at various levels of aggregation , the reference set for normalisation or relative ranking . There is no (cid:145)objective(cid:146) way to uncover the structure of science , which may reflect institutional habits , mental representations or self - organisation phenomena . Among the possible ways of offering manageable classifications , there are three classical approaches . Firstly , the projection of institutional settings , for example traditional academic disciplines definition ; secondly , the information retrieval categories in databases often based on experts(cid:146) advice ; thirdly , the clusters uncovered by bibliometric analyses of scientific networks ( lexical and citation networks ) , with many sub - options , e . g . for citation networks : citation transactions , co - citations , bibliographic coupling . These broad families of methods are likely to provide different views of the structure of science . In the present study we rely on the ISI retrieval categories and we will discuss the issues from the macro - perspective alone . Macro - analysis is defined here as starting from the journal level and to build the further levels as collections of journals , whereas we define micro - analysis by the use of clusters built from the document level , regardless of journals . The best - known example of macro - classification is ISI(cid:146)s (cid:145)subject category(cid:146) list . Subject categories are far from perfect , based on rather unclear delineation methods , but since they are widely used and their journal lists easily M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 375 available , they are often used as proxies for specialised research areas . We will use these ISI categories as the next level of aggregation , the first being the journal . Then we will gather these specialities into (cid:145)sub - disciplines(cid:146) and finally sub - disciplines into disciplines . Including the all - science level , we have five levels of aggregation that will be used as normalisation referents . Certain limitations of this macro perspective , based on ISI categories and their further aggregations into our own schemes , are apparent . The hierarchical structure is meant to be realistic , but it cannot escape some arbitrary choices . We will come back to this subject in the conclusion . We have chosen to study the stability by relative rankings ( quantiles ) , instead of cardinal normalised impacts , at all levels of aggregation . In addition , we focus on a particular class , the (cid:145)highly - cited(cid:146) articles . Among the many approaches to measure excellence , measures relying on highly - cited papers can be the most tempting , this in spite of the many difficulties of interpretation raised by both sociologists and bibliometricians . (cid:145)Excellence(cid:146) is currently in fashion , with the concept of (cid:145)Networks of Excellence(cid:146) pioneered in Canada in the late eighties ( F ISHER et al . , 2001 ) and being implemented , for example , in the 6th Framework program of the European Union . The skewness of citation distributions is expected to give robustness to corresponding measures of excellence , this notion however being open to challenge when we consider changes in the reference set used for observation . In essence , an outstanding paper in a micro - community may get only a modest score when assessed within a larger field if the rest of this field has more generous referencing practices . At what extent cross - field differences , combined to an embedded classification scheme , create cross - scale differences that matter for performance evaluation ? Data and methods Macro - structure The present (cid:145)macro(cid:146) approach is based on the following levels of observation : journal ; specialities ( ISI subject categories ) ; sub - disciplines ; disciplines (cid:150) the latter two are specific aggregates , by OST , of ISI subject categories . However , we have used a modified form of this structure , in order to obtain strictly embedded levels i . e . without overlaps . (cid:1) This strictly hierarchical structure is not of course the best model of the organisation of science , where disciplinary overlaps are a common feature , but rather a (cid:1) To begin with we forced journals into a single speciality ( subject category ) using a random algorithm trying to avoid extreme losses in categories , but the (cid:145)specialities(cid:146) in the present exercise do have fewer journals than the corresponding ISI subject categories . Then we modified the contour of OST sub - disciplines to a collection of specialities . In this strictly embedded scheme , a journal belongs to a single speciality , a speciality to a single sub - discipline , etc . The grouping of category codes ( specialities ) into the large academic disciplines we refer to is found in the annex of the biannual OST report , see for example B ARR(cid:201) & E STERLE ( 2002 ) . M . Z ITT et al . : Relativity of citation performance 376 Scientometrics 63 ( 2005 ) convenient simplification for the present study . Overlapping classes result in several normalised impact measures for each multi - assigned journal , which would obscure the proposed stylised analysis . The five levels for this macro - study are defined as follows : L1 : all science , L2 : large - discipline ( 9 groups including multidisciplinary ) , L3 : sub - disciplines ( 31 groups ) , L4 : speciality ( 155 groups ) , L5 : journal ( 3702 groups reduced to 3529 after filtering based on document type ) . The table is given in the Annexes In the following , the words (cid:145)field(cid:146) and (cid:145)domain(cid:146) are , here , general terms used as equivalents , whatever the scale . Groups at a particular level are termed as above : (cid:150) e . g . the term (cid:145)speciality(cid:146) ( level 4 ) corresponds , more or less , to the ISI (cid:147)subject category(cid:148) used in several Thomson - ISI products ( SCI , JCR , WoS ) , with the afore - mentioned difference in relation to journals assignment : here we have assigned all journals to a single speciality ; (cid:150) terms such as (cid:147)discipline(cid:148) may be misleading . For example , (cid:147)civil engineering(cid:148) may be held as a (cid:147)discipline(cid:148) by scientists in this area . As it is a (cid:147)subject category(cid:148) in ISI classification , we consider it as a speciality , level L4 . The fact that ISI sometimes calls (cid:147)discipline(cid:148) the subject category may be confusing . For this reason , we do not use herein the term discipline alone , but only (cid:147)large - discipline(cid:148) to designate broad academic fields such as physics , fundamental biology , earth & space sciences , etc . The structure of the classification we have used is shown in Annex 1 ; (cid:150) it may be the case that a particular field survives through several levels of aggregation . This is due to the choices adopted for OST classification . One example is (cid:147)mathematics(cid:148) , which , with the same journal set , is both a sub - discipline and a large - discipline ( L3 and L2 ) . But it splits at the L4 level . Another example is the field (cid:147)multidisciplinary(cid:148) which is a subject category defined by ISI , a quite heterogeneous grouping . Our classification keeps it as such , at the sub - discipline and the large - discipline level , there being no particular reason to join this group with any other . Other variants of ISI - based classifications are found in literature , and the particular scheme we are using can certainly be questioned on a number of grounds . The classification we use , and this is true for the comparable variants , does not claim to be an accurate representation of the structure of science . It is , rather , a limited but (cid:147)realistic(cid:148) tool suitable for macro - analysis purposes . It is unlikely that using any other sensible (cid:147)macro - classification(cid:148) would profoundly alter the conclusions . The empirical set ( observed SCI ) and two fictitious benchmarks Empirical SCI data . This research is based on primary data from ISI . Since the main aim is methodological , standard SCI coverage has been chosen . The publication year 1998 was selected , to give a sufficient delay for citations ( i . e . a 4 - year window ) . As far as the type of document is concerned , we wished to address a homogeneous population , M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 377 avoiding for example the inclusion of (cid:145)review articles(cid:146) . We therefore considered only the type (cid:145)article(cid:146) ( whether or not it came from proceedings or other sources ) . The empirical set makes use of real data and of a realistic structure of science . In addition to this observed set , we used two fictitious sets which represent extreme models of citation distribution in order to benchmark the (cid:145)observed(cid:146) set against a (cid:145)worst case(cid:146) and (cid:145)best case(cid:146) scenario , from the point of view of the cross - scale stability of indicators . To build these two sets , we have kept the same embedded structures L1 - L5 without changing the size of classes ( journals , specialities , etc . ) at each level . But instead of their own real citations , articles were assigned new citation figures generated by a redistribution of original figures over the whole set , using two contrasting rules : 1st benchmark : (cid:145)ordered fields model (cid:146) . This set was obtained using a redistribution of real scores between articles , by juxtaposing the real field structure and the list of ranked citation scores . As a result the first large - discipline in the list ( conventional ) gathers all the top - ranked articles , the second one the next highly cited articles , etc . ; similarly , the 1st sub - discipline in the 1st large - discipline gathers the most cited articles in the large - discipline , and so on . The level of citation is forced to be completely dependent on the domain , at all levels of aggregation . In this model , the respective proximities of two articles in terms of topic and of citation score are strongly dependent . The structure of science , reflected in the classification , dictates the citation behaviour . The expected result of this model is that normalised indicators , for a given article , will exhibit a very poor stability when the scale changes . For example , if the average citation of the domain is used as a normalisation factor , this factor will be different at the five levels considered ( journal ; speciality ; sub - discipline ; large - discipline ; all ) . The model has no sampling rationale whatever the level . It represents the (cid:145)worst case(cid:146) for the stability of citation indicators as the scale of observation changes . An interesting aspect of the ordered - field model is the supply of lower bounds for inter - level correlation values ( see below ) . 2nd benchmark : (cid:145)random model (cid:146) . For the second model the embedded structure ( L1 - L5 ) is also retained but with a random redistribution of the real citations scores amongst the articles : each article randomly receives the score of another one ( we limited ourselves to one draw ) . In this model the respective proximities of two articles in terms of topic ( as described by the classification scheme ) and of citation score are independent . The structure of science , operationalised by the classification , does not influence the citation scores . No field - dependence of citations is expected and each group in a classification , whatever the level ( journal ; speciality , etc . ) , will behave as a random sample of the overall distribution , reflecting the dispersion of citation scores of all science . Hence a sensible normalisation factor , say the average citation score of the domain , would tend to be stable through all the levels , as well as throughout the fields at any given level . We will illustrate below that the random model implemented confirms this sampling M . Z ITT et al . : Relativity of citation performance 378 Scientometrics 63 ( 2005 ) rationale , though , theoretically , alteration of sampling features could occur in such strongly concentrated distributions ( H AITUN , 1982 ) . We refer to this model as the (cid:145)random model(cid:146) , expected to provide the (cid:145)best case(cid:146) for the stability of normalised citation indicators as the scale changes . The contents of the three tables , SCI , ordered fields and random model are too large to be displayed . A worked example , based on a ( fictitious ) miniature set of five small journals and two specialities , may be found in Annex 2 . The particular position of the (cid:145)observed(cid:146) set , between the extremes , i . e . the (cid:145)best case(cid:146) and (cid:145)worst case(cid:146) configurations , gives an idea of the citation structure of (cid:145)real science(cid:146) associated with the particular classification in use . Other benchmark models might be built with different properties . For example , a model with a strict hierarchy at the L5 level ( with journals strictly associated with a prestige level ) but a random mix of journals at the L4 level will tend to yield a zero correlation between L4 and L5 , but a correlation close to one between all pairs of levels from L4 to L1 . More generally , if at a given level fields are a random mix of sub - fields at the next lower level , then all fields at higher aggregation levels will maintain this sampling rationale . At the opposite end of the spectrum , the (cid:145)ordered fields(cid:146) model above has no sampling rationale whatever the level . More sophisticated models could be used to try to emulate the properties of the observed SCI dataset . In Mandelbrot(cid:146)s wake , power - law or quasi power - laws encountered in bibliometrics have been interpreted in terms of self - similarity and put down to self - organisation mechanisms in science ( for example K ATZ , 1999 ; V AN R AAN , 2000 ) . Normalised citations : a rank approach There are several ways to define field - normalised impacts : regular standardisation of variables ; ratio to the field - average , which is commonly used ; ratio to the field - average with log - transformation ; and non - parametric positioning on ranks . Cardinal measures are more appropriate for some types of analysis , for example based on variance , after proper transformation to deal with the skewness of distributions . Distribution - free approaches may also be useful in addressing the problem in a general way . In this work we have privileged this (cid:145)ranking(cid:146) approach , which also readily applies to (cid:145)excellence(cid:146) measures . The rationale for rank comparisons is closer to the standardised - variables approach ( the dispersion within each group is neutralised in both cases ) than to normalisation using ratios to a central value ( which keeps information on the dispersion of individual groups ) . The principle is to rank all world articles , using quantiles on the criterion of citation score . A quasi - normalisation is obtained by using a local ranking at the level chosen : by discipline , by sub - discipline , etc . This method is very useful for positioning an actor by its (cid:145)activity index(cid:146) profile in successive quantiles of citations . M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 379 Discontinuous : quantiles defined at the discipline level Continuous : quantiles defined at the speciality level Class 1 _ 5 : first class , 5 % of articles Figure 1 . Actor (cid:145)XXX(cid:146) : Profile using Activity Index in visibility classes In a given class , for example the first one defined as the top - cited 5 % , noted 1 _ 5 , the activity index is the ratio of the percentage of the actors(cid:146) articles falling in this class , to the percentage of the world articles in the class . Real values used in the denominator may be different from the nominal values ( 5 % , 5 % , 10 % , etc . ) , especially for the last quantiles , because of ties . Figure 1 gives an illustration for a particular actor XXX ( real case ) , with two profiles corresponding to discipline - level and speciality - level (cid:145)normalisations(cid:146) . Abscissas correspond to classes of visibility , based on variable quantiles : 5 % top - cited ( excellence class ) , next 5 % , next 10 % , next 20 % , next 20 % , last 40 % . Ordinates represent the activity index : for example the index would be 1 . 5 in the excellence class if 7 . 5 % of the actors(cid:146) publications fall into this class . Descending profiles correspond to a sound distribution of citations , the actor being more present in highly cited fractions . The figure shows that for this particular actor , changing the level of observation / normalisation alters the profile , see for example the activity index in the top - 5 % (cid:145)excellence class(cid:146) . In this study we do not focus on actors(cid:146) comparison but on global differences on rankings over all SCI . We address the cross - scale stability using three entries , the overall correlation of rankings of all articles between the aggregation levels ; the individual trajectory of articles throughout the levels ; and the survival of the (cid:145)excellence(cid:146) top - cited sets throughout the levels . M . Z ITT et al . : Relativity of citation performance 380 Scientometrics 63 ( 2005 ) Overall comparison of article rankings . At each level of observation , L1 ( all science ) through L5 ( journal ) , (cid:1) articles are ordered by the citations they receive in the field they belong to , which puts them in particular quantiles ( see footnote for technical issues (cid:1)(cid:1) ) . L1 corresponds to the absence of field - normalisation : articles just receive their original ranking in all science ( with for example a low expected performance of mathematics as a whole ) . In contrast , at the L4 level for example , the first percentiles of the overall ranking will be made of the most highly - ranked articles in each speciality . This corresponds to a strong field - normalisation . A step further , the first percentiles of the L5 overall ranking will contain the most highly ranked articles in each journal . Clearly , the percentile position of an article may change with the scale . For example a mathematical article may receive a mediocre score at the journal level L5 , a good score at the speciality level L4 ( if the journal has a good impact ) , and again a mediocre score at the L1 level , where mathematics are not favoured . However , there are several built - in limitations to the discrepancies between levels . In the embedded structure L1 - L5 , the order relationship between two articles A and B belonging to the same field , at a given level , holds at all higher levels of aggregation . For example if article A is more cited than article B belonging to the same journal , this inequality is also true at the speciality level , the sub - discipline level , and all superior levels . This constraint mechanically bounds the discrepancies between rankings at different levels . Another mechanic factor that limits these discrepancies is due to the particular classification scheme adopted . As mentioned earlier the (cid:145)multidisciplinary(cid:146) field persists over three levels ( large - discipline , sub - discipline , speciality ) and (cid:145)mathematics(cid:146) over two levels ( large - discipline , sub - discipline ) . An advantage of the (cid:145)ordered - fields(cid:146) model is to give a measure of the lower bounds of correlation between levels due to these built - in factors . Another factor increases somewhat artificially the correlation between rankings at different levels , that is the nature of citation distributions , which creates a huge number of ties in low score classes ( particularly zero or one citation . ) . This somewhat artificially increases the correlation between rankings at different levels . In order to reduce this effect , we used truncated sets ( without the zero citation articles ; without the less cited half of all articles (cid:1)(cid:1)(cid:1) ) together with the original set with all articles . (cid:1) L6 ( document level ) is degenerated , clusters are reduced to individual documents . (cid:1)(cid:1) The different frequencies by field / level obliges us to use quantiles rather than citation scores . Let us take the example of a 100 cells grid ( percentiles ) . Thus article i belongs to percentile x i in its journal , to percentile y i in its speciality , and so on . The skewed nature of the distribution of citations creates multiple ties for lower scores , e . g . zero or one citation . Ranking procedures offer several options for ties i . e . low , average , high , or random ties . For the global analysis we used the (cid:145)high ties(cid:146) option which gives the least favourable rank . Thus all zero citations articles belong to the same last class with the lowest rank ( e . g . 100 for centiles ) . As a result the size of low percentile classes may be irregular , which is true for all tie options except (cid:145)random ties(cid:146) . The (cid:147)random ties(cid:148) option is recommended for comparisons with the two extreme models . (cid:1)(cid:1)(cid:1) Truncation has been carried out at the speciality level . Because of ties , only 45 % of the articles were kept , representing almost 9 / 10 of the total citations . M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 381 The global agreement between rankings of all articles between all ( pairs of ) levels was assessed by Kendall(cid:146)s rank correlation , based on the difference of concordances and discordances of ranks for each pair of items , of direct interest here . We tested several quantiles grids ( 20 half - deciles , 100 percentiles , 500 and 1000 quantiles ) , and the results tend to converge as the grids become finer and finer , the difference between grids (cid:145)500(cid:146) and (cid:145)1000(cid:146) no longer affects the last digit in the subsequent tables . (cid:1) Results ( in the form of 5 by 5 tables ) are therefore reported using grid (cid:145)1000(cid:146) . For the reason stated above ( persistence of order relations in couples when the aggregation level increases ) it may be useful to judge the difference to independence by considering the lower boundary values given by the tables (cid:145)ordered fields model(cid:146) as a reference , instead of the zero correlation . Individual trajectory of articles . Thereafter , a study of individual article(cid:146)s trajectories , between L1 through L5 , is sketched out . One simple measure of the total trajectory length is R j = 1 . . 4 [ | x i ( j + 1 ) - x ij | ] . This index measures the degree of change in scores as the level of aggregation changes within the embedded structure adopted . Another interesting feature is the range of variation Max j = 1 . . 4 ( x ij ) (cid:150) Min j = 1 . . 4 ( x ij ) . Distributions of the trajectories(cid:146) lengths and ranges give an idea of the stability of scores throughout the levels . Excellence measures using top - cited articles . Among other indicators the contents of the (cid:145)top end(cid:146) of bibliometric distributions ( and especially citations ) is a typical way in which (cid:145)excellence(cid:146) is measured . An important question is whether such a measure can resist changes of scale . We chose three operational definitions for the excellence class , ranging from a (cid:145)looser(cid:146) to a (cid:145)tighter(cid:146) definition : (cid:150) the 1st half - decile of the impact distribution , i . e . using grid : (cid:145)20(cid:146) ; ca . 25 , 000 top - cited articles for all SCI (cid:150) the 1st percentile , grid : (cid:145)100(cid:146) ; ca . 5000 top - cited articles (cid:150) the first 0 . 2 % ( grid : (cid:145)500(cid:146) ; ca . 1000 top - cited articles ) For each level of aggregation L1 - L5 , and with each given threshold , the top - cited set was built . By construction , at any level , the number of (cid:145)excellent(cid:146) items from a particular field is proportional to the total size of this field (cid:150) with respect to the fluctuations due to ties . For ranking , the (cid:145)low ties(cid:146) option , giving the most favourable rank , was selected to pick up at least one article in each journal . Obviously not all grids can be applied to the whole range of levels , in order to respect a minimum size of selected sets . The grids (cid:145)100(cid:146) and (cid:145)500(cid:146) ( in particular ) are meaningless at the journal level L5 , which contains ca . 3500 journals ; the grid (cid:145)20(cid:146) is already questionable at this level ; so is the grid (cid:145)500(cid:146) at the speciality level . (cid:1) The choice of a unique grid applicable to all levels is a trade - off . If the grid is (cid:145)coarse - grain(cid:146) ( say percentiles ) , a large number of ties is created at the higher levels of aggregation , and the rank comparisons between levels tend to give higher rank correlation than the fine - grain grids . If a fine - grain ( say 10 , 000 ) is chosen , many gaps are created at the lower level ( s ) of aggregation . However statistical packages can handle this problem . M . Z ITT et al . : Relativity of citation performance 382 Scientometrics 63 ( 2005 ) The question then is (cid:147)do the contents of the top - cited class (cid:150) in terms of articles (cid:150) change when the level of aggregation / observation changes(cid:148) ? We addressed this question by studying : (cid:150) the degree of overlap of (cid:145)top - cited sets(cid:146) between each pair of levels ; (cid:150) the degree of global overlap between top - cited sets at all levels , giving the persistence of a top - cited class ; (cid:150) the set of articles considered top - cited at ( at least ) one level . Are citation scores stable across - scale ? Impacts , a core topic in bibliometrics , have received a great deal of attention in the literature . The (cid:145)state - of - the - art(cid:146) concerning impact factors was discussed in particular by G L˜NZEL & M OED ( 2002 ) . Recent debates about impact factor measures have been commented upon by M OED ( 2002 ) and the implementation of relative citation rate analyses using a normalisation at the journal level were carried out at the ISSRU group ( S CHUBERT & B RAUN , 1986 ) . The literature is full of applications of normalisation at various levels of aggregation , including micro - levels . For example , normalisation at the level of small clusters of journals was used by B ASSECOULARD & Z ITT ( 1999 ) to select local cores of journals ; normalisation at the level of small groups of papers by K OSTOFF in his studies of team or researcher performance ( 2002 , see also V INKLER , 2002 ) . The perennial question of field - normalisation was further reviewed by S CHUBERT & B RAUN ( 1996 ) . Also , general views related to relative indicators have been developed by for example G L˜NZEL , 1988 and E GGHE & R OUSSEAU , 2003 . Most producers of indicators have for decades offered relative measures ( i . e . relative impact measures : citation share over publication share ) or ranking measures which make comparisons between fields possible at a given disaggregation level . The properties of various normalisation techniques have to be explained when a measure at a given level is intended to reflect structural discrepancies at lower levels . In reaction to the common practice among decision - makers , using straightforward (cid:145)ISI impact factors(cid:146) , the flow of articles recommending various forms of field - level disaggregation and / or normalisation is constant ( see for example amongst others S EN , 1992 ; M ARSHAKOVA - S HAIKEVICH , 1996 ; C APSKI , 1997 ; R AMIREZ et al . , 2000 ; S OLARI & M AGRI , 2000 ) . As mentioned above , we wish to address here a cross - scale perspective adding further to this cross - sectional perspective . The general landscape The differences in average impact between ISI categories are well - known . For the data and the particular delineation of specialities used here , using four years citation windows , the general picture on observed SCI is as follows : M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 383 Table 1 . Average impacts ( 4 - years window ) (cid:150) examples of field discrepancies across three levels L2 ( 9 large disciplines ) L3 ( 31 sub - disciplines ) L4 ( 155 specialities ) Fields with high values max value ( underlined ) multidisciplinaryfundamental biology , medical research multidisciplinarybio / cellchem immunologyoncology , astronomy multidisciplinaryembryologymol . biology immunologybiochemistry Examples of fields with median values earth & space physicschemistry general physics healthchemistry ( narrow ) pharmacyapplied physics parasitologylimnologydermatologymicroscopysurgery Fields with low values min value ( underlined ) applied biology engineering , mathematics food science materialscomputer / info mech / fluid eng . mathematics geotech . mine engin . mater . / analysis civil engin . photography Across - field ratio : max / min 11 11 30 Figure 2 . Distribution of mean impact by field ( empirical SCI set ) triangles : fields = disciplines ( L2 ) , squares : fields = sub - discipline ( L3 ) , circles : fields = speciality ( L4 ) , stars : fields = journals ( L5 ) M . Z ITT et al . : Relativity of citation performance 384 Scientometrics 63 ( 2005 ) The across - field ratio is mechanically equal for L2 and L3 because the conventional classification adopted maintains the categories (cid:145)multidisciplinary(cid:146) ( highest impact ) and (cid:145)mathematics(cid:146) ( lowest impact ) , unchanged , at L2 and L3 levels . The increase of the ratio max / min for L4 is due to the poor citation performance of a small speciality . Figure 2 shows the distribution ( arithmetic mean , weighted ) of fields(cid:146) mean impact at the L2 through L5 levels . Analysis of the geometric mean and first quartile distribution ( not shown ) lead to similar results . The reduction of variance with aggregation is lower than expected , showing that discrepancies in citation behaviour are maintained through a large range of scale . The picture would be completely different in the (cid:145)random model(cid:146) . Stability of rankings in scale changes As explained in the methodological section , we evaluated the level of discrepancy between citation rankings of articles for each combination of levels , for the three cases : the observed set ( empirical SCI data ) ; the random model ; and the (cid:145)ordered fields(cid:146) model . If the structure of science embodied in the classification large - discipline / sub - discipline / speciality / journal were based on random mixes ( random model ) , a quasi - maximum correlation would be expected for all pairs of levels . As mentioned above , this would be the (cid:145)best case(cid:146) for the cross - scale stability of citation indicator , the score of articles would be practically unchanged whatever the level of observation . In contrast , the worst case corresponds to a structure of science based on a strictly (cid:145)ordered fields(cid:146) model , with very low correlation indices expected . Tables 2a - e show the Kendall rank correlation between ratings at different levels . Table 2a . Global rank correlation between levels (cid:150) observed SCI (cid:150) grid 1000 (cid:150) ties option : high Kendall tau grid 1000 L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 1 . 00 0 . 81 0 . 76 0 . 72 0 . 51 L2 0 . 87 1 . 00 0 . 86 0 . 80 0 . 54 L3 0 . 84 0 . 91 1 . 00 0 . 86 0 . 56 L4 0 . 82 0 . 87 0 . 91 1 . 00 0 . 58 L5 0 . 66 0 . 68 0 . 69 0 . 71 1 . 00 Above diagonal : articles with zero citation excluded Below diagonal : all articles M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 385 Table 2b . Global rank correlation between levels (cid:150) observed SCI (cid:150) grid 1000 (cid:150) ties option : random Kendall tau grid 1000 L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 1 . 00 0 . 77 0 . 71 0 . 67 0 . 44 L2 0 . 83 1 . 00 0 . 85 0 . 78 0 . 49 L3 0 . 79 0 . 89 1 . 00 0 . 85 0 . 52 L4 0 . 76 0 . 83 0 . 88 1 . 00 0 . 55 L5 0 . 55 0 . 59 0 . 61 0 . 63 1 . 00 Above diagonal : articles with zero citation excluded Below diagonal : all articles Table 2c . Global rank correlation (cid:150) random model (cid:150) grid 1000 (cid:150) ties option : random Kendall tau grid 1000 L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 1 . 00 1 . 00 0 . 99 0 . 99 0 . 94 L2 1 . 00 1 . 00 1 . 00 0 . 99 0 . 94 L3 0 . 99 1 . 00 1 . 00 0 . 99 0 . 94 L4 0 . 99 0 . 99 0 . 99 1 . 00 0 . 94 L5 0 . 94 0 . 94 0 . 94 0 . 94 1 . 00 Above diagonal : articles with zero citation excluded Below diagonal : all articles Table 2d . Global rank correlation between levels (cid:150) (cid:145)ordered fields(cid:146) model (cid:150) grid 1000 (cid:150) ties option : random Kendall tau grid 1000 L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 1 . 00 0 . 18 0 . 04 0 . 01 0 . 00 L2 0 . 17 1 . 00 0 . 22 0 . 08 0 . 00 L3 0 . 04 0 . 23 1 . 00 0 . 27 0 . 02 L4 0 . 01 0 . 09 0 . 27 1 . 00 0 . 06 L5 0 . 00 0 . 01 0 . 02 0 . 06 1 . 00 Above diagonal : articles with zero citation excluded Below diagonal : all articles Table 2e . Global rank correlation between levels (cid:150) observed SCI ( truncated ) (cid:150) grid 1000 (cid:150) ties option : random Kendall tau grid 1000 L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 1 . 00 0 . 71 0 . 64 0 . 57 0 . 50 L2 1 . 00 0 . 80 0 . 69 0 . 59 L3 1 . 00 0 . 79 0 . 65 L4 1 . 00 0 . 74 L5 1 . 00 Data for truncated SCI : only the 50 % most cited articles ( selection at the speciality level ) are kept . Tables 2a , 2b , 2e show results in relation to the (cid:145)real(cid:146) ( observed ) SCI . whereas tables 2c and 2d refer to the two (cid:145)benchmark(cid:146) sets . Rank correlation tends to decrease , as expected , with the distance between levels . For example , in table 2a depicting the observed SCI , on the row L1 , the coefficients decrease from column L2 through column L5 . The correlations between adjacent levels M . Z ITT et al . : Relativity of citation performance 386 Scientometrics 63 ( 2005 ) remain fairly high ( > 0 . 80 , Table 2a above diagonal ) , but are far from expressing a sampling situation as described in the random model Table 2c . The striking contrast with the (cid:145)ordered fields(cid:146) model ( 2d ) with its absolute hierarchy and its very low correlations is less surprising . Over four levels ( all science vs . speciality ) , the correlation drops to 0 . 72 . The journal level is a particular case . Compared with all others , this level shows a strong discrepancy , with correlation coefficients of only 0 . 6 with the next level L4 ( Table 2a , figures without zero citation items ) . This is only partly due to the inter - level distance , since on average the speciality has a size > 20 times a journal , roughly the same factor as between L2 and L4 , but correlation L2 - L4 is much higher than L4 - L5 . The singular nature of the journal level supports the idea of a twofold competition : for accessing the best journals on the one hand ; and for gaining visibility within each journal on the other hand . The corresponding classical indicators are respectively the Expected Impact ( or actor(cid:146)s impact factor ) and the Relative Citation Ratio ( RCR , S CHUBERT & B RAUN , 1986 ) . The global impact can be decomposed as the product of Expected Impact and RCR . A two - step model of between - journal and within - journal competition has been proposed by V AN R AAN ( 2001 ) . The singular nature of the journal level suggests that the real model of science is a mixed one . The passage L5 - L4 is consistent with a mixing process of journals strongly unequal ( L5 ) , but only to a certain extent . As a result , the aggregation brought by the speciality level reduces the variety , but not all the variety . If specialities were really based on a random sampling of journals , we would have a mixed scheme , with a very low L5 - L4 correlation coefficient , and all the subsequent coefficients ( all pairs of levels among L1 - L4 ) close to one . In such a situation , all citation scores could be considered as stable for all aggregation levels beyond L5 . This is not the case , and levels from L4 through L2 , in the classification adopted , always retain some inter - field variety , and as a result , a cross - scale instability of citation rankings . The correlation indices are sensitive to the removal of uncited or little cited articles . Correlation for complete sets may be considered spurious because of the abundance of ties for low scores . Light truncation ( discarding zero - citation articles ) and strong truncation ( only keeping the half more cited , Table 2e ) make clearer the instability of citation rankings across scales . In Table 2e , we watch the effect for the large discipline level normalisation , with a correlation coefficient of rankings L1 and L2 scarcely above 0 . 7 . We will consider further , in the next section , the effects of a drastic truncation which retains only the top of the distribution . Individual trajectory length Low Kendall coefficients indicate a global disarray between scores of two particular levels . A complementary view is provided by looking at trajectories of individual M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 387 articles from L1 through L5 levels , using indices defined in earlier . If the trajectories are short , it is an indication that the structure of science adopted does not affect individual article benchmarking . In this case the organisation would be close to the random model . Long trajectories suggest that the choice of the aggregation level in the structure of science heavily affects the citation score and subsequent evaluations . This would be the case for the (cid:145)ordered fields(cid:146) model for example . The observed SCI data , on the 1000 - grid , yield an average total trajectory of ca . 300 positions in the four intervals L1 through L5 , i . e . about 75 positions ( 0 . 75 decile ) at one level change . The distribution of the trajectory length for the observed SCI set is shown in Figure 3 . The standard deviation of the total trajectory is about 165 positions , and the maximum reaches 1125 , i . e . 280 positions ( almost 3 deciles ) for one level change . The long tail indicates the presence of strong deviations ( log - normal shape ) . Figure 3 . Trajectory lengths distribution ( empirical SCI set (cid:150) grid = 1000 ) M . Z ITT et al . : Relativity of citation performance 388 Scientometrics 63 ( 2005 ) Top - cited articles There are many ways to approach (cid:145)excellence(cid:146) by bibliometric measures , for example by considering the tails of bibliometric distributions ( production , collaboration , citation , etc . ) , the presence in particular categories ( funding and scientific committees ) , the position in various networks ( strategic themes , collaborations , etc . ) . Highly - cited articles are among the most commonly used indicators ( see for example G ARFIELD , 1986 on the very top articles ) . Indicator producers generally trust this type of measure but at the same time highlight the technical caveats and the necessity for corroborative results from several points of view ( T IJSSEN et al . , 2002 ) . Studies by sociologists and bibliometricians on citation analyses have brought evidence that citations are a marker of communication and visibility , but the danger of over - interpreting them as a marker of quality is a threat to accurate research evaluation ( see amongst many others S EGLEN , 1997 ; M C R OBERTS & M C R OBERTS , 1989 ; and for the opposing argument , see for example V INKLER , 2004 ) . This is particularly true for measures of excellence . We do not wish to address here the issue of fundamental limits of citations for measuring excellence , but the simple technical stability of top - citedness indicators as the scale of normalisation changes . The rationale is the same as in the previous sections , with a simple change in focus to the top - end of the distribution : we considered three selections , the very top class ( 0 . 2 % ) designated as E1 , the first percentile ( 1 % ) as E2 , and the first half - decile ( 5 % ) as E3 . Tables 3a - c show the overlaps between pairs of levels . For example , the first figure in the box L1 - L2 ( Table 3a ) indicates that for the very top class , the overlap between this class defined at the L1 level ( all science ) and at the L2 level is 52 % . Table 3a . First class = 0 . 2 % of publications (cid:150) overlap ( % ) (cid:150) observed SCI (cid:150) ties option : low Overlap ( % ) for E1 ( first 0 . 2 % ) L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 52 . 0 38 . 6 33 . 1 ns L2 51 . 6 64 . 5 50 . 9 ns L3 38 . 0 63 . 9 69 . 5 ns L4 30 . 7 47 . 5 65 . 5 ns L5 ns ns ns ns Above diagonal : as a fraction of the top - cited class at higher level Below diagonal : as a fraction of the top - cited class at lower level ( the two fractions usually differ because of ties ) Italics : small average size of units M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 389 Table 3b . First class = 1 % of publications (cid:150) overlap ( % ) (cid:150) observed SCI (cid:150) ties option : low Overlap ( % ) for E2 ( first percentile ) L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 60 . 7 48 . 7 42 . 2 ns L2 60 . 2 71 . 8 60 . 8 ns L3 47 . 6 70 . 8 71 . 7 ns L4 40 . 7 59 . 2 70 . 7 ns L5 ns Ns ns ns Above diagonal : as a fraction of the top - cited class at higher level Below diagonal : as a fraction of the top - cited class at lower level ( the two fractions usually differ because of ties ) Italics : small average size of units Table 3c . First class = 5 % of publications (cid:150) overlap ( % ) (cid:150) observed SCI (cid:150) ties option : low Overlap ( % ) for E3 ( first half - decile ) L1 ( all science ) L2 ( large disc . ) L3 ( sub - disc . ) L4 ( speciality ) L5 ( journal ) L1 70 . 4 64 . 3 58 . 1 39 . 4 L2 70 . 1 80 . 6 72 . 7 45 . 6 L3 63 . 2 79 . 7 80 . 2 49 . 1 L4 56 . 9 71 . 5 79 . 8 54 . 1 L5 31 . 8 36 . 9 40 . 2 44 . 6 Above diagonal : as a fraction of the top - cited class at higher level Below diagonal : as a fraction of the top - cited class at lower level ( the two fractions usually differ because of ties ) Italics : small average size of units The tables above show that the overlaps between excellence classes defined at different levels are only moderate , and tend to decrease as the threshold of excellence goes up . For example , for the 1 % excellence level , the overlap between the all - science excellence class and sub - discipline or speciality - excellence class is less than 50 % . Between two candidate levels for practical normalisation , L3 and L4 ( L5 having a clearly different meaning ) , the overlap is only of two thirds . The benchmark models , not shown , behave as expected : overlaps close to 100 % for the random model , and very weak for the (cid:145)ordered fields(cid:146) model . Let us now consider the across - level stability in a wide range of levels : L1 through L4 , leaving aside the journal level , and L1 through L5 including the journal level only when it is not meaningless . The question is (cid:147)which fraction of articles is top - cited whatever the level ? (cid:148) i . e . constantly retrieved in the top - cited class ( Table 4a ) . M . Z ITT et al . : Relativity of citation performance 390 Scientometrics 63 ( 2005 ) Table 4a . Constantly top - cited articles (cid:150) observed SCI (cid:150) ties option : low Level of (cid:145)excellence(cid:146) Frequency % of total publications bold : ( % of nominal size of top - cited class ) Grid level Percentage of total publications Nominal size of top - cited class ( thousands ) L1thr . L5 L1thr . L4 L1thr . L5 L1thr . L4 E1 : 500 0 . 2 % 1 . 1 ns 0 . 3 ns 0 . 06 % ( 27 % ) E2 : 100 1 % 5 . 6 ns 2 . 0 ns 0 . 36 % ( 36 % ) E3 : 20 5 % 27 . 8 8 . 6 14 . 7 1 . 55 % ( 31 % ) 2 . 64 % ( 53 % ) total 556 . 8 556 . 8 556 . 8 556 . 8 100 . 00 100 . 00 Table 4a shows that the fraction of top - cited papers remaining top - cited is low , except for E3 in the window L1 - L4 where it reaches 50 % . For example , if we use the first percentile as defining top - citations , the total overlap between the top - classes defined at four levels L1 - L4 covers only one third ( 36 % ) of a percentile . Generally speaking , only a minority of top - cited articles resist the scale change . The overlap becomes much lower , as expected , when the journal level is included . From another perspective , the information about (cid:147)articles being top - cited at least at one of the five levels(cid:148) is given in table 4b . Table 4b . Articles top - cited at least at one level (cid:150) observed SCI (cid:150) ties option : low Level of (cid:145)excellence(cid:146) Frequency % of total publications bold : ( % of nominal size of top - cited class ) Grid level Percentage of publicationspub Nominal size of exc . class ( thousands ) L1thr . L5 L1thr . L4 L1thr . L5 L1thr . L4 E1 : 500 0 . 2 % 1 . 1 Ns 2 . 4 ns 0 . 43 % ( 215 % ) E2 : 100 1 % 5 . 6 Ns 10 . 6 ns 1 . 91 % ( 191 % ) E3 : 20 5 % 27 . 8 62 . 9 45 . 9 11 . 3 % ( 226 % ) 8 . 25 % ( 165 % ) total 556 . 8 556 . 8 556 . 8 556 . 8 100 . 00 100 . 00 The excellence class is roughly doubled with respect to the nominal threshold , except again for E3 / L1 - L4 . For example if we define the top - cited class as the first percentile ( row (cid:145)E2(cid:146) ) we find about two percentiles of all scientific publications that can be considered as excellent somewhere . The benchmark models , not shown , exhibit the expected results : the persistence of the top - cited classes is very low for the (cid:145)ordered fields(cid:146) model , and close to 100 % for the random model . M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 391 These empirical findings confirm that the contents of (cid:145)top - cited classes(cid:146) are strikingly dependent on the level of aggregation / normalisation . Secondly , the contents of the top - class are all the more unstable as the selection of the (cid:145)elite(cid:146) is stringent . This effect may be linked to fact that in large top - cited sets , a long trajectory ( Figure 3 ) is needed for the fraction of most - cited items to escape the set when the level of aggregation changes . The low probability of these long trajectories , compared to medium ones , could enhance the stability of large sets compared to very highly cited ones . Discussion (cid:150) conclusion Main results It is widely recognised that the diversity of citation practices in scientific fields justifies some form of field - normalisation . The field - normalisation here was operationalized by a local quantile score for each article in its field . But scientific publications , for example the SCI set , can be aggregated at various levels , e . g . from a (cid:145)macro(cid:146) perspective : journals , specialities , sub - disciplines , disciplines , and all science . Depending on the level , the quantile score of an article is subject to change . It would be substantially the same for cardinal measures , for example citations normalised by a central field value . As a result , field - normalised indicators are not only , trivially , dependent on the delineation of fields , but also , for a given multi - level classification , dependent on the hierarchical level of observation in a particular classification . An article may exhibit very different citation scores or rankings when compared within a narrow speciality or a large academic discipline . More generally , evaluation based on citation scores is likely to be wholly dependent on the level of aggregation used . This is not a purely theoretical debate . In universities or research institutes , especially if they cover a wide scope of fields , the question unavoidably arises of the breakdown level . We have studied , empirically , the stability of citation scores using one year of SCI data and a conventional classification scheme , realistic from the point of view of macro - level indicators of science . We have considered five levels of observation / normalisation : all science ( e . g . original rankings ) ; large academic discipline ; sub - discipline ; speciality ; and journal . Certain limitations of the methodology should be borne in mind : (cid:150) The science classification we have used may be called into question , including the composition of ISI subject categories . The strict embedding of the structures we have adopted for the sake of simplicity ( one article has a single trajectory ) may also exaggerate some irregularities that would be smoothed by multiple assignment , especially at the journal level . M . Z ITT et al . : Relativity of citation performance 392 Scientometrics 63 ( 2005 ) (cid:150) A cardinal approach instead of rankings , using variance analysis at each level with an appropriate transformation of variables , might also be a helpful complement . (cid:150) As far as excellence is concerned , the analysis was carried out on articles . For the benchmarking of authors or institutions , aggregates may be more robust . However , these issues would be unlikely to alter the main findings : 1 . We investigated the citation scores , in terms of relative ranking , at various levels of observation , in a realistic field - classification scheme . The variation of citation scores depends on the particular distribution of articles citations vis - (cid:224) - vis the classification scheme . We observed a large degree of discrepancy of citation rankings among levels of observation . 2 . The journal level is a very particular case , and differs greatly , in all cases , from all other levels . This phenomenon is similar to discrepancies observed by scholars , using cardinal measures , between (cid:145)relative citation ratio ( RCR ) (cid:146) at the journal level and overall impact measures . Furthermore , compared to the more extreme benchmark models , (cid:145)real science(cid:146) depicted here by an actual citation distribution among articles , appears as a mixed model , with a large but partial mixing process taking place when aggregating journals into specialities . Further aggregation keeps conveying discrepancies in terms of citation behaviour and , as a result , instability of citation indicators . 3 . The distribution of individual trajectories of articles(cid:146) rankings over all the levels has a long tail , indicating that for particular articles the discrepancies between ratings at different levels are severe . A similar observation could be anticipated from the average values of impact at each node of the tree corresponding to the particular classification used . 4 . Turning to the top - cited fractions , a classic measure of excellence , it becomes clear that a large proportion of the top - cited set does not survive the change of scale . Moreover , for sensible levels of definition of the top class , the narrower the definition of excellence , the greater the instability . The fact that citation indicators are not stable from a cross - scale perspective is a serious worry for bibliometric benchmarking . What can appear technically as a (cid:145)lack of robustness(cid:146) raises deeper questions about the legitimacy of particular scales of observation . A few questions are particularly appealing for future research . The need for a micro - level approach We used a macro - classification , a realistic but perhaps limited approach . A purely theme - based (cid:147)micro - approach(cid:148) , i . e . based on grouping of individual papers rather than journals , would perhaps be more suitable to address these theoretical issues of scientific M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 393 structure . This method would bypass the (cid:145)journal(cid:146) step which conveys a mixed logic of thematic delineation and prestige level . In the second stage of this study , devoted to the micro - approach , we intend to define successive levels using bibliometric groupings ( research fronts , bibliographic coupling clusters , etc . ) rather than the conventional breakdowns based on ISI subject categories . Because of computational constraints however , the investigation will perforce be limited to a particular field . Cited - side or citing - side normalisation ? In this paper we have addressed normalisation in a typically classical way , namely from the viewpoint of the cited side . This is perfectly adequate as long as the cited field and the citing field coincide . But knowledge transactions , and from Mertonian perspective their citation counterpart , take place between fields as well as within fields , whatever the level of analysis , and multi - disciplinarity is a key dimension of the evolution of research systems . In such cases , one should be aware of the fact that discrepancies in behaviour , and in particular in referencing practices , originate from the citing side . Together with other aspects ( such as the regimes of growth ) , the length of the reference list , rather than the size of the field ( on the latter point see G ARFIELD , 1998 ) is responsible for the citation biases we would wish to neutralize . The question arises of a normalisation at the source rather than at the reception of citations , either by some fractional count of emitted citations , used for example by Z ITT et al . ( 1994 ) in a co - citation context ( S MALL ( 1985 ) , credits Thomson and Dean as the originators of this fractional option ) or by a field - normalisation on the citing side . Strong normalisation vs . no normalisation and the case of mutlidisciplinary articles There are a number of arguments for the (cid:147)smallest set(cid:148) strategy . The rationale is : the smaller the set , the more relevant the comparison . At the macro - level , the choice of the level of ISI subject categories , though purely arbitrary ( and possibly with questionable delineation ) , is often made because it is simply the smallest basis widely available . Micro - approaches can provide still smaller clusters of articles . K OSTOFF ( 2002 ) investigated normalisation at this level . The use of ISI research fronts or other micro - analysis clusters could also be a possible approach . The radical statement about the differentiation process of research by W ASMER ( 2001 ) , who notes with Fitoussi that , in the extreme , (cid:147) any researcher is in a monopoly situation and can by definition not be evaluated (cid:148) , illustrates the potential limit case . But there also arguments against over - normalisation . One is purely technical , sets which are too small jeopardize statistical stability . The other argument is more fundamental and relates to trans - disciplinarity . Over - normalisation can unduly level down all specialities or themes in science , and under - rates the role of articles in leading M . Z ITT et al . : Relativity of citation performance 394 Scientometrics 63 ( 2005 ) or central topics . Examples of potentially leading articles are documents with a multidisciplinary scope and / or published in multidisciplinary journals . At the macro - level , the (cid:145)multidisciplinary(cid:146) category of SCI , where Nature , Science and PNAS are found , has a very high citation average . If a crude category - level normalisation is applied , using for example its average citation as the normalisation factor , the visibility of many strong articles will be under - estimated . The same will be true for a micro - approach grouping multidisciplinary articles with similar profiles in the same cluster . The normalization on this reference will tend to under - rate their significance , while a (cid:145)quick and dirty(cid:146) normalisation using their main disciplinary assignment , or some all - science mix , would produce better results in this particular case . Again citing - side normalisation may be helpful . Not one best level A variety of points of view need to be accepted . This was already the implicit message of the promoters of RCR , coupling two levels of analysis , the relative citation ratio ( local view ) and the expected impact combined into the regular impact ( global view ) . K OSTOFF ( 2002 ) in another context talks about the combination of (cid:147)job right(cid:148) ( local view ) and (cid:147)right job(cid:148) in a global performance . It remains the case that the choice of the best level for delineating the topic or the job is largely arbitrary since scientific networks exhibit to a large extent a self - similar structure . Not much can be expected from the analysis of local stability across levels . The persistence of an article in the top - cited class is an example . The rationale of such multi - level ratings is weak , many of the scale - resistant articles simply have the good fortune to belong to specialities which are , perhaps only as the result of citation habits , the most visible . In quasi - continuous classification schemes used in (cid:147)micro - bibliometrics(cid:148) , local maxima of stability can also be looked for as the level of observation changes , but again the choice of a single level is questionable . The absence of (cid:145)one best level(cid:146) of observation has a particular consequence for excellence measures . In a relativist view , if all levels are equal in terms of legitimacy , each scientist can (cid:145)choose his / her level of excellence(cid:146) by picking the aggregate where his / her articles will score the highest in a sensible classification scheme . Without going to such an extreme , exclusively thinking in terms of (cid:145)vertical bibliometrics(cid:146) and not paying attention to variety and emergence may be a counter - productive approach . At the very least , vertical bibliometrics should cope with cross - scale instability and arbitrary choices of levels of observation , and offer shifting viewpoints with different zoom settings . This suggests a particular prudence in interpretation of citation indicators , including (cid:145)excellence(cid:146) studies based on top - cited fractions . M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 395 * The authors would like to thank Ronald Kostoff for comments on a first version of this text , and anonymous referees for helpful suggestions . References B ARR(cid:201) , R . , E STERLE , L . ( 2002 ) , Science & Technologie . Indicateurs 2002 . Rapport de l(cid:146)Observatoire des Sciences et des Techniques , Economica , Paris . B ASSECOULARD , E . , Z ITT , M . ( 1999 ) , Indicators in a research institute : A multi - level classification of scientific journals , Scientometrics , 44 ( 3 ) : 323(cid:150)345 . C ZAPSKI , G . ( 1997 ) , The use of deciles of the citation impact to evaluate different fields of research in Israel , Scientometrics , 40 ( 3 ) : 437(cid:150)443 . E GGHE , L . , R OUSSEAU , R . ( 2002 ) , A general frame - work for relative impact indicators , Canadian Journal of Information and Library Science (cid:150) Revue Canadienne des Sciences de l(cid:146)Information et de Bibliotheconomie , 27 ( 1 ) : 29(cid:150)48 . F ISHER , D . , A TKINSON - G ROSJEAN , J . , H OUSE , D . ( 2001 ) , Changes in academy / industry / state relations in Canada : The creation and development of the networks of centres of excellence , Minerva , 39 ( 3 ) : 299(cid:150)325 . G ARFIELD , E . ( 1986 ) , Do Nobel prizes winners write citation classics ? Current Contents , ( 23 ) : 182 . G L ˜ NZEL , W . , M OED , H . F . ( 2002 ) , Journal impact measures in bibliometric research , Scientometrics , 53 ( 2 ) : 171(cid:150)193 . H AITUN , S . D . ( 1982 ) , Stationary scientometric distributions . Part ii . Non - gaussian nature of scientific activities , Scientometrics , 4 ( 2 ) : 89(cid:150)104 . K ATZ , J . S . ( 1999 ) . The self - similar science system , Research Policy , 28 ( 5 ) : 501(cid:150)517 . K OSTOFF , R . N . ( 2002 ) , Citation analysis of research performer quality , Scientometrics , 53 ( 1 ) : 49(cid:150)71 . M ARSHAKOVA - S HAIKEVICH , I . ( 1996 ) , The standard impact factor as an evaluation tool of science fields and scientific journals , Scientometrics , 35 ( 2 ) : 283(cid:150)290 . M C R OBERTS , M . H . , M C R OBERTS , B . R . ( 1989 ) , Problems of citation analysis : A critical review , Journal of the American Society for Information Science , 40 ( 5 ) : 342(cid:150)349 . M OED , H . F . ( 2002 ) , The impact - factor debate : the ISI(cid:146)s uses and limits , Nature , 415 ( 14 Sep ) : 731(cid:150)732 . M URUGESAN , P . , M ORAVCSIK , M . J . ( 1978 ) , Variation of the nature of citation measures with journal and scientific specialties , Journal of the American Society for Information Science , 29 : 141(cid:150)155 . N ARIN , F . ( 1976 ) , Evaluative bibliometrics : The Use of Publication and Citation Analysis in the Evaluation of Scientific Activity , National Science Foundation , Contract NSF C - 627 , P INSKI , G . , N ARIN , F . ( 1976 ) , Citation influence for journal aggregates of scientific publications : theory , with application to the literature of physics , Information processing and management , 12 : 297(cid:150)312 . R AMIREZ , A . M . , G ARCIA , E . O . , D EL R IO , J . A . ( 2000 ) , Renormalized impact factor , Scientometrics , 47 ( 1 ) : 3(cid:150)9 . S CHUBERT , A . , B RAUN , T . ( 1986 ) , Relative indicators and relational charts for comparative assessment of publication output and citation impact , Scientometrics , 9 ( 5 - 6 ) : 281(cid:150)291 . S CHUBERT , A . , B RAUN , T . ( 1996 ) , Cross - field normalization of scientometric indicators , Scientometrics , 36 : 311 - 324 . S CHUBERT , A . , G L ˜ NZEL , W . , B RAUN , T . ( 1988 ) , Against absolute methods : relative scientometric indicators and relational charts as evaluation tools , In : A . F . J . V AN R AAN ( Ed . ) , H andbook of Quantitative Studies of Science and Technology , Elsevier , Amsterdam , pp . 137(cid:150)169 . S EGLEN , P . O . ( 1997 ) , Citations and journal impact factors : questionable indicators of research quality , Allergy , 52 : 1050(cid:150)1056 . M . Z ITT et al . : Relativity of citation performance 396 Scientometrics 63 ( 2005 ) S EN , B . K . ( 1992 ) , Documentation Note Normalized Impact Factor , Journal of Documentation , 48 ( 3 ) : 318(cid:150)325 . S IEGEL , S . ( 1956 ) , Nonparametric Statistics for the Behavioral Sciences , McGraw - Hill , New - York ( USA ) . S MALL , H . , S WEENEY , E . ( 1985 ) , Clustering the Science Citation Index using co - citations , I - A comparison of methods , Scientometrics , 7 ( 3 - 6 ) : 391(cid:150)409 . S OLARI , A . , M AGRI , M . H . ( 2000 ) , A new approach to the SCI Journal Citation Reports , a system for evaluating scientific journals , Scientometrics , 47 ( 3 ) : 605(cid:150)625 . T IJSSEN , R . J . W . , V ISSER , M . S . , VAN L EEUWEN , T . N . ( 2002 ) , Benchmarking international scientific excellence : Are highly cited research papers an appropriate frame of reference ? Scientometrics , 54 ( 3 ) : 381(cid:150)397 . VAN R AAN , A . F . J . ( 2000 ) , On growth , ageing , and fractal differentiation of science , Scientometrics , 47 ( 2 ) : 347(cid:150)362 . VAN R AAN , A . F . J . ( 2001 ) , Competition amongst scientists for publication status : Toward a model of scientific publication and citation distributions , Scientometrics , 51 ( 1 ) : 347(cid:150)357 . V INKLER , P . ( 2002 ) , Subfield problems in applying the Garfield ( Impact ) Factors in practice , Scientometrics , 53 ( 2 ) : 267(cid:150)279 . V INKLER , P . ( 2004 ) , Characterization of the impact of sets of scientific papers : The Garfield ( Impact ) Factor , Journal of the American Society for Information Science and Technology , 55 ( 5 ) : 431(cid:150)435 . W ASMER , E . ( 2001 ) Some political economy of excellence , Workshop (cid:147) In Search of Scientific Excellence : Research Performance by Discipline(cid:148) , EU , STI - ERA , Nov 13 . Z ITT , M . , B ASSECOULARD , E . ( 1994 ) , Development of a method for detection and trend analysis of research fronts built by lexical or cocitation analysis , Scientometrics , 30 ( 1 ) : 333(cid:150)351 . Z ITT , M . , R AMANANA - R AHARY , S . , B ASSECOULARD , E . ( 2003 ) , Correcting glasses help fair comparisons in international science landscape : Country indicators as a function of ISI database delineation , Scientometrics , 56 ( 2 ) : 259(cid:150)282 . M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 397 Annex 1 The table represents an extract of the classification used , for two large disciplines . As mentioned , (cid:145)specialities(cid:146) are based on ISI (cid:145)subject categories(cid:146) but for the need of this particular exercise journals are assigned to a single one , which can make a large difference in their contents . Sub - disciplines as sets of specialities are adapted from OST sub - disciplines , again without multi - assignment . Large academic disciplines are those used at OST . Disc Discipline Sub - discipline Sub - discipline Speciality Engineering , biomedical Medical informatics Medical laboratory technology Materials science , biomaterials BING Biomedical Engineering Microscopy Biochemical research methods Biochemistry & molecular biology Biophysics Cell biology BIOG Biochemistry / Molecular & Cellular Biology & Genetics Developmental biology Anatomy & morphology Genetics & heredity Nutrition & dietetics Physiology DIVF Misc . Fund . Biol . Reproductive biology Biotechnology & applied microbiology Microbiology Parasitology MIIN Microbiology / Virology / Infections / Bioprocesses Virology Behavioral sciences Neurosciences 01 FUNDAMENTALBIOLOGY NEUR Neurosciences / Psychology Psychology M . Z ITT et al . : Relativity of citation performance 398 Scientometrics 63 ( 2005 ) Disc Discipline Sub - discipline Sub - discipline Speciality OncologyHematology CANC Oncology / Hematology Medicine , research & experimentalChemistry , medicinal Medicine , legal CHME Medical Chemistry / Pharmacy Pharmacology & pharmacy Andrology ENDO Endocrinology Endocrinology & metabolism Medicine , general & internal Pathology GMED General Medicine / Miscellaneous Radiology , nuclear medicine & medical imaging Allergy IMMU Immunology ImmunologyAnesthesiology Cardiac & cardiovascular systemsEmergency medicine GastroenterologyRespiratory system Sport sciences SurgeryTransplantationUrology & nephrology INTE Gastroenterology / Cardiology / Pneumology / Surgery Peripherical vascular disease Dentistry , oral surgery & medicineDermatology & veneral diseases Infectious diseases OphtalmologyOrthopaedicsOtorhinolaryngologyRehabilitationRheumatologyTropical medicine MSPE Other Medical Specialties Veterinary sciences Substance abuse Health care sciences & services Geriatrics & gerontology Public , environmental & occupational health Clinical neurology Obstetrics & gynecology PediatricsPsychiatry 02 MEDICALRESEARCH SANT Public Health / Epidemiology / Life Cycle / Toxicology Toxicology M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 399 Annex 2 Construction of the sets (cid:150) numerical example This table illustrates the construction of the three sets ( observed , ordered fields , random ) . The example here is purely fictitious , over - simplified and reduced to three levels of aggregation : journals ( 5 journals ) , specialities ( 2 ) , sub - discipline ( 1 ) . The example is based on a plausible distribution of citations . The three sets share the classification / structure including the size of journals and the scores of citations , but the original citation figure in the (cid:145)observed set(cid:146) for one article is attributed to other articles : randomly for the (cid:145)random set(cid:146) , hierarchically along the arbitrary list of journals and further aggregates , in the (cid:145)ordered fields set(cid:146) . For example the score 19 of the article # A6 in the original article goes to the article # A2 in the ordered set and # D7 in the random set . Relative rankings are based here on rank percentages with a random processing of ties (cid:150) as recalled in the text , the results are sensitive to ranking options , since citation - type distributions yield a huge number of ties in the low frequency area . In the last table , correlation is the usual correlation , analogous to Spearman since applied to rank percentages . Correlations amongst the three levels show , as expected , the intermediary situation of the (cid:145)observed set(cid:146) between the random model ( very high coefficients ) and the hierarchical model ( much lower ) . We can visually watch the instability of an (cid:145)excellence(cid:146) subset ( boldface ) , here arbitrarily fixed at the first decile , again intermediary between the built - in instability in the ordered set model , and the stability observed in the random model . M . Z ITT et al . : Relativity of citation performance 400 Scientometrics 63 ( 2005 ) Construction of the three sets (cid:150) fictitious example CLASSIFICATION OBSERVED SCI benchmark : ORDERED FIELDS benchmark : RANDOM SET S U B D I S C I P L SP E C I A L I T Y J OU R NA L A R T I C LE c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l X 1 A A1 3 6 . 9 6 . 3 4 . 6 31 10 . 0 10 . 0 10 . 0 0 1 . 9 2 . 1 1 . 9 X 1 A A2 1 4 . 1 2 . 6 1 . 0 19 9 . 8 9 . 5 9 . 1 4 7 . 8 6 . 8 7 . 3 X 1 A A3 31 10 . 0 10 . 0 10 . 0 14 9 . 6 8 . 9 8 . 2 10 9 . 3 9 . 5 10 . 0 X 1 A A4 10 9 . 3 8 . 4 7 . 3 12 9 . 4 8 . 4 7 . 3 1 5 . 0 4 . 7 4 . 6 X 1 A A5 2 6 . 7 5 . 8 3 . 7 10 9 . 3 7 . 9 6 . 4 0 2 . 3 2 . 6 2 . 8 X 1 A A6 19 9 . 8 9 . 5 9 . 1 8 9 . 1 7 . 3 5 . 5 2 5 . 6 5 . 2 5 . 5 X 1 A A7 5 8 . 3 7 . 9 6 . 4 7 8 . 9 6 . 8 4 . 6 5 8 . 2 7 . 3 8 . 2 X 1 A A8 2 6 . 5 5 . 2 2 . 8 6 8 . 7 6 . 3 3 . 7 0 1 . 5 1 . 5 1 . 0 X 1 A A9 4 7 . 8 7 . 3 5 . 5 6 8 . 5 5 . 8 2 . 8 8 9 . 1 8 . 9 9 . 1 X 1 A A10 12 9 . 4 8 . 9 8 . 2 5 8 . 3 5 . 2 1 . 9 2 6 . 1 5 . 8 6 . 4 X 1 A A11 2 6 . 3 4 . 7 1 . 9 5 8 . 2 4 . 7 1 . 0 0 2 . 8 3 . 1 3 . 7 X 1 B B1 1 3 . 9 2 . 1 4 . 0 4 8 . 0 4 . 2 10 . 0 0 1 . 4 1 . 0 1 . 0 X 1 B B2 1 3 . 8 1 . 5 2 . 5 4 7 . 8 3 . 6 8 . 5 1 3 . 0 3 . 6 2 . 5 X 1 B B3 2 6 . 1 4 . 2 8 . 5 4 7 . 6 3 . 1 7 . 0 12 9 . 4 10 . 0 10 . 0 X 1 B B4 2 6 . 0 3 . 6 7 . 0 3 7 . 4 2 . 6 5 . 5 1 3 . 8 4 . 2 4 . 0 X 1 B B5 4 7 . 6 6 . 8 10 . 0 3 7 . 2 2 . 1 4 . 0 7 8 . 9 8 . 4 8 . 5 X 1 B B6 1 3 . 6 1 . 0 1 . 0 3 7 . 1 1 . 5 2 . 5 3 6 . 9 6 . 3 5 . 5 X 1 B B7 2 5 . 8 3 . 1 5 . 5 3 6 . 9 1 . 0 1 . 0 6 8 . 7 7 . 9 7 . 0 X 2 C C1 8 9 . 1 9 . 7 9 . 2 2 6 . 7 10 . 0 10 . 0 0 1 . 0 1 . 0 1 . 0 X 2 C C2 1 3 . 4 4 . 8 2 . 6 2 6 . 5 9 . 7 9 . 2 4 8 . 0 8 . 5 8 . 4 X 2 C C3 2 5 . 6 7 . 1 5 . 1 2 6 . 3 9 . 4 8 . 4 31 10 . 0 10 . 0 10 . 0 X 2 C C4 2 5 . 4 6 . 8 4 . 3 2 6 . 1 9 . 1 7 . 5 1 4 . 7 4 . 8 5 . 9 X 2 C C5 6 8 . 7 9 . 1 8 . 4 2 6 . 0 8 . 8 6 . 7 2 6 . 3 6 . 5 6 . 7 X 2 C C6 14 9 . 6 10 . 0 10 . 0 2 5 . 8 8 . 5 5 . 9 1 4 . 3 4 . 2 4 . 3 X 2 C C7 1 3 . 2 4 . 5 1 . 8 2 5 . 6 8 . 3 5 . 1 1 3 . 6 3 . 3 3 . 4 X 2 C C8 3 7 . 4 8 . 0 7 . 5 2 5 . 4 8 . 0 4 . 3 0 1 . 2 1 . 3 1 . 8 X 2 C C9 3 7 . 2 7 . 7 6 . 7 1 5 . 2 7 . 7 3 . 4 2 6 . 7 7 . 1 7 . 5 X 2 C C10 1 3 . 0 4 . 2 1 . 0 1 5 . 0 7 . 4 2 . 6 1 4 . 5 4 . 5 5 . 1 X 2 C C11 3 7 . 1 7 . 4 5 . 9 1 4 . 9 7 . 1 1 . 8 0 2 . 1 1 . 9 2 . 6 X 2 C C12 1 5 . 2 6 . 5 3 . 4 1 4 . 7 6 . 8 1 . 0 5 8 . 3 8 . 8 9 . 2 M . Z ITT et al . : Relativity of citation performance Scientometrics 63 ( 2005 ) 401 CLASSIFICATION OBSERVED SCI benchmark : ORDERED FIELDS benchmark : RANDOM SET S U B D I S C I P L SP E C I A L I T Y J OU R NA L A R T I C LE c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l c it a ti on s r k i n s ubd i s c r k i n s p ec i a lit y r k i n j ou r n a l X 2 D D1 0 2 . 8 3 . 9 7 . 3 1 4 . 5 6 . 5 10 . 0 1 5 . 2 5 . 3 2 . 8 X 2 D D2 0 2 . 6 3 . 6 6 . 4 1 4 . 3 6 . 2 9 . 1 2 5 . 4 5 . 6 3 . 7 X 2 D D3 0 2 . 5 3 . 3 5 . 5 1 4 . 1 5 . 9 8 . 2 14 9 . 6 9 . 4 9 . 1 X 2 D D4 0 2 . 3 3 . 0 4 . 6 1 3 . 9 5 . 6 7 . 3 2 6 . 5 6 . 8 6 . 4 X 2 D D5 1 5 . 0 6 . 2 9 . 1 1 3 . 8 5 . 3 6 . 4 3 7 . 2 7 . 7 7 . 3 X 2 D D6 5 8 . 2 8 . 5 10 . 0 1 3 . 6 5 . 1 5 . 5 2 6 . 0 6 . 2 5 . 5 X 2 D D7 0 2 . 1 2 . 7 3 . 7 1 3 . 4 4 . 8 4 . 6 19 9 . 8 9 . 7 10 . 0 X 2 D D8 0 1 . 9 2 . 4 2 . 8 1 3 . 2 4 . 5 3 . 7 0 2 . 6 2 . 4 1 . 0 X 2 D D9 0 1 . 7 2 . 2 1 . 9 1 3 . 0 4 . 2 2 . 8 2 5 . 8 5 . 9 4 . 6 X 2 D D10 1 4 . 9 5 . 9 8 . 2 0 2 . 8 3 . 9 1 . 9 6 8 . 5 9 . 1 8 . 2 X 2 D D11 0 1 . 5 1 . 9 1 . 0 0 2 . 6 3 . 6 1 . 0 1 4 . 1 3 . 9 1 . 9 X 2 E E1 1 4 . 7 5 . 6 6 . 6 0 2 . 5 3 . 3 10 . 0 3 7 . 1 7 . 4 7 . 8 X 2 E E2 0 1 . 4 1 . 6 3 . 3 0 2 . 3 3 . 0 8 . 9 1 3 . 4 3 . 0 4 . 4 X 2 E E3 4 8 . 0 8 . 3 7 . 8 0 2 . 1 2 . 7 7 . 8 1 4 . 7 4 . 8 6 . 6 X 2 E E4 1 4 . 5 5 . 3 5 . 5 0 1 . 9 2 . 4 6 . 6 3 7 . 4 8 . 0 8 . 9 X 2 E E5 7 8 . 9 9 . 4 10 . 0 0 1 . 7 2 . 2 5 . 5 1 3 . 9 3 . 6 5 . 5 X 2 E E6 0 1 . 2 1 . 3 2 . 1 0 1 . 5 1 . 9 4 . 4 0 1 . 7 1 . 6 1 . 0 X 2 E E7 0 1 . 0 1 . 0 1 . 0 0 1 . 4 1 . 6 3 . 3 0 2 . 5 2 . 2 2 . 1 X 2 E E8 6 8 . 5 8 . 8 8 . 9 0 1 . 2 1 . 3 2 . 1 4 7 . 6 8 . 3 10 . 0 X 2 E E9 1 4 . 3 5 . 1 4 . 4 0 1 . 0 1 . 0 1 . 0 1 3 . 2 2 . 7 3 . 3 Correlations of rankings among levels option for ties : corr spec jnal corr spec jnal corr spec jnal random sdisc 0 . 91 0 . 74 sdisc 0 . 54 0 . 20 sdisc 0 . 99 0 . 94 spec 0 . 77 spec 0 . 40 spec 0 . 95