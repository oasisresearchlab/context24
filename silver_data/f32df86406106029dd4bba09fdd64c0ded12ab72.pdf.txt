Semantic Annotation of Papers : Interface & Enrichment Tool ( SAPIENT ) Maria Liakata † , Claire Q †† , Larisa N . Soldatova ††† Department of Computer Science University of Wales , Aberystwyth SY23 3DB UK † mal @ aber . ac . uk , †† ceq08 @ aber . ac . uk , ††† lss @ aber . ac . uk Abstract In this paper we introduce a web application ( SAPIENT ) for sentence based annotation of full papers with semantic information . SAPI - ENT enables experts to annotate scientiﬁc pa - pers sentence by sentence and also to link re - lated sentences together , thus forming spans of interesting regions , which can facilitate text mining applications . As part of the system , we developed an XML - aware sentence split - ter ( SSSplit ) which preserves XML markup and identiﬁes sentences through the addition of in - line markup . SAPIENT has been used in a systematic study for the annotation of scientiﬁc papers with concepts representing the Core Information about Scientiﬁc Papers ( CISP ) to create a corpus of 225 annotated pa - pers . 1 Introduction Given the rapid growth in the quantity of scientiﬁc literature , particularly in the Biosciences , there is an increasing need to work with full papers rather than abstracts , both to identify their key contribu - tions and to provide some automated assistance to researchers ( Karamanis et al . , 2008 ; Medlock and Briscoe , 2007 ) . Initiatives like OTMI 1 , which aim to make full papers available to researchers for text mining purposes is further evidence that relying solely on abstracts presents important limitations for such tasks . A recent study on whether information retrieval from full text is more effective than search - ing abstracts alone ( Lin Jimmy , 2009 ) showed that 1 http : / / opentextmining . org / wiki / Main Page the former is indeed the case . Their experimental re - sults suggested that span - level analysis is a promis - ing strategy for taking advantage of the full papers , where spans are deﬁned as paragraphs of text as - sessed by humans and deemed to be relevant to one of 36 pre - deﬁned topics . Therefore , when working with full papers , it is important to be able to iden - tify and annotate spans of text . In previous research , sentence based annotation has been used to identify text regions with scientiﬁc content of interest to the user ( Wilbur et al . , 2006 ; Shatkay et al . , 2008 ) or zones of different rhetorical status ( AZ ) ( Teufel and Moens , 2002 ) . Sentences are the structural units of paragraphs and can be more ﬂexible than paragraphs for text mining purposes other than information re - trieval . Current general purpose systems for linguistic an - notation such as Callisto 2 allow the creation of a simple annotation schema that is a tag set augmented with simple ( e . g . string ) attributes for each tag . Knowtator ( Ogren , 2006 ) is a plug - in of the knowl - edge representation tool Prot´eg´e 3 , which works as a general purpose text annotation tool and has the advantage that it can work with complex ontology - derived schemas . However , these systems are not particularly suited to sentence by sentence annota - tion of full papers , as one would need to highlight entire sentences manually . Also these systems work mainly with plain text , so they do not necessarily interpret the structural information already available in the paper , which can be crucial to annotation deci - sions for the type of high level annotation mentioned 2 http : / / callisto . mitre . org / manual / use . html 3 http : / / protege . stanford . edu / above . The OSCAR3 ( Corbett et al . , 2007 ) tool for the recognition and annotation of chemical named entities fully displays underlying paper information in XML but is not suited to sentence by sentence an - notation . To address the above issues , we present a sys - tem ( SAPIENT ) for sentence by sentence annota - tion of scientiﬁc papers which supports ontology - motivated concepts representing the core informa - tion about scientiﬁc papers ( CISP ) ( Soldatova and Liakata , 2007 ) . An important aspect of the system is that although annotation is sentence based , the sys - tem caters for identiﬁers , which link together sen - tences pertaining to the same concept . This way spans of interest or key regions are formed . SAPI - ENT also incorporates OSCAR3 capability for the automatic recognition of chemical named entities and runs within a browser , which makes it platform independent . SAPIENT takes as input full scien - tiﬁc papers in XML , splits them into individual sen - tences , displays them and allows the user to anno - tate each sentence with one of 11 CISP concepts as well as link the sentence to other sentences refer - ring to the same instance of the concept selected . The system is especially suitable for so called multi - dimensional annotation ( Shatkay et al . , 2008 ) or ontology - motivated annotation , where a label origi - nates from a class with properties . SAPIENT is cur - rently being employed by 16 Chemistry experts to develop a corpus of scientiﬁc papers ( ART Corpus ) annotated with Core Information about Scientiﬁc Papers ( CISP ) covering topics in Physical Chemistry and Biochemistry . 2 SAPIENT System Description We chose to implement SAPIENT as a web appli - cation , so as to make it platform independent and easier to incorporate as part of an online workﬂow . We have used state of the art web technologies to develop SAPIENT , namely Java , Javascript ( with Asynchronous JavaScript and XML ( AJAX ) func - tionality ) , XSLT , CSS and XML . The system has a client - server architecture ( see Figure 1 ) , with pa - pers being uploaded and stored on the server but functionality for annotation contained in Javascript , which runs client - side in the browser . This is in - spired by but in contrast with OSCAR3 ( Corbett et al . , 2007 ) , which also allows manual annota - tion alongside the automated annotation of chemical named entities , but where each minor edit is saved to the server , writing to a ﬁle . We chose to make more of the functionality client - side in order to re - duce the number of server requests , which could be - come problematic if the system became widely dis - tributed . SAPIENT Architecture User Input User Input Browser Browser XML Http request response Click on paper Paper in . xml Page for paper upload & links to uploaded papers Paper displayed in dynamic html Javascript based annotation with CISP Processing with . xsl Click on Save ServerServer Annotations saved In mode2 . xml Paper saved as source . xml 1 ) Paper is split into sentences with SSSplit 2 ) Paper saved as mode2 . xml OSCAR annotations Figure 1 : Architecture of the SAPIENT System SAPIENT has been designed to take as input full papers in XML , conforming to the SciXML schema ( Rupp et al . , 2006 ) ( see Section 3 ) . To view or annotate a paper , a user must ﬁrst up - load it . The index page of SAPIENT shows a list of papers already uploaded ( available as links ) and an interface for uploading more papers ( See Figure 2 ) . Once the user selects a link to a paper , the pa - per is split into sentences using the XML - aware sen - tence splitter SSSplit which we have developed ( See section 4 ) and is included in the server - side Java . The resultant XML ﬁle is stored alongside the origi - nal upload . Sentence splitting involves detecting the boundaries of sentences and , in this context , mark - ing the latter by inline < s > < / s > tags added to the original XML . The < s > < / s > tags contain an id at - tribute enumerating the sentence . After sentence splitting , the new XML ﬁle containing sentence boundaries marked by < s id = # NUM > < / s > tags is parsed by XSLT into HTML , so that it displays in the browser . In the HTML interface dynamically generated in this way , Javascript annotation drop - downs are available for Figure 2 : Index page of the SAPIENT System each sentence . The user can perform annotations by selecting items from the drop - downs and all the corresponding annotation information is stored in Javascript until a request to save is made by the user . The Javascript drop - downs allow annotation at two levels ( Figure 3 ) , enabling a sentence to have a semantic label ( type ) with properties ( subtypes ) and an identiﬁer ( conceptID ) . In the current implementation of SAPIENT , The type drop - down value corresponds to the selection of one out of 11 general scientiﬁc concepts ( Li - akata and Soldatova , 2008 ) , namely ( ‘Background’ , ‘Conclusion’ , ‘Experiment’ , ‘Goal of the Investi - gation’ , ‘Hypothesis’ , ‘Method’ , ‘Model’ , ‘Motiva - tion’ , ‘Object of the Investigation’ , ‘Observation’ , ‘Result’ ) . These labels originate from a set of meta - data ( The Core Information about Scientiﬁc Concepts ( CISP ) ( Soldatova and Liakata , 2007 ) which were constructed using an ontology method - ology , based on an ontology of experiments EXPO ( Soldatova and King , 2006 ) . Because these labels map to ontology classes , they can also have prop - erties . For example , ‘Method’ has the property ‘New’ / ‘Old’ , ‘Advantage’ / ‘Disadvantage’ . These properties are dependent on the type selected and are expressed in terms of the subtype drop - down . The third drop - down , concept ID allows a user to provide a concept identiﬁer . The latter is an entity formed by the name of a concept and a number ( e . g . “Res2” ) . Concept identiﬁers uniquely identify an in - stance of a concept ( e . g . the second Result ) , but not a sentence . That is , concept identiﬁers designate and link together instances of the same semantic con - cept , spread across different sentences , which can be in different parts of the paper . For example , the second result ( “Res2” ) can be referred to by 1 sen - tence in the abstract , 5 sentences in the Discussion and 2 sentences in the Conclusion sections . The distinction between sentence identiﬁers and concept identiﬁers is an important characteristic of the system . It means that the system does not neces - sarily assume a ‘1 - 1’ correspondence between a sen - tence and a concept , but rather that concepts can be represented by spans of often disjoint text . There - fore , SAPIENT indirectly allows the annotation of discourse segments beyond the sentence level and also keeps track of co - referring sentences . 2 . 1 SAPIENT Usability Even though SAPIENT has been primarily designed to work with CISP concepts , it can be used to an - notate papers according to any sentence based anno - tation scheme . Changes required can be easily per - formed by modifying the XSL sheet which dynami - cally generates HTML from XML and organises the structure of drop - down menus . Automated noun - phrase based annotation from existing ontologies is available to SAPIENT users through OSCAR3 ( Corbett et al . , 2007 ) , since SAPIENT incorporates OSCAR3 functionality for chemical named entity recognition . The latter is implemented as a link which when selected calls the OSCAR3 workﬂow ( integrated in the system ) to automatically recognise chemical named entities ( NEs ) ( See Figure 5 ) . When all annotations ( both sentence based and chemical NEs ) are saved to the server , a new ver - sion of the XML ﬁle is produced , which contains in - line annotation for sentences as well as extra in - line annotation for the semantic concepts and NEs embedded within < s > < / s > tags . These annotation tags are compliant with the SciXML schema ( Rupp et al . , 2006 ) and in the case of sentence - based anno - tations are of the form : < annotationART atype = ‘‘GSC’’ type = # TYPE conceptID = # CONCEPTID novelty = ‘‘Yes / No’’ advantage = ‘‘Yes / No’’ < / annotationART > ( See Figure 4 ) . The attribute type , stands for the CISP concept selected for the sentence in question . The conceptID attribute is an enumerator of the par - ticular concept , which the sentence refers to . For example , two different sentences will have differ - ent sentence ids but if they refer to the same con - cept ( e . g . the same “Conclusion” ) , they will be assigned the same concept ID ( e . g . “Con3” ) . The attributes novelty and advantage , are properties of the concepts assigned to a sentence and depend on the concept selection . They take boolean val - ues or the dummy value “None” if the properties are not deﬁned for a particular concept . For ex - ample , these attributes are relevant when the con - cept selected is a ‘Method’ , in which case the method can be “New / Old” and / or have an “Advan - tage / Disadvantage” . The novelty and advantage at - tributes co - exist in the annotation ( as can be seen in Figure 4 ) but they are not set by the system at the same time . For instance , if a sentence refers to a new method , it will be given the type ‘Method’ and the subtype “New” ; this sets the novelty attribute in the underlying XML to “Yes” and leaves the advantage attribute set to the default “None” . The sentence will also be given a conceptID , e . g . “Met1” . If another sentence refers to an advantage of this method , then the new sentence will be assigned the type ‘Method’ , the subtype “Advantage” ( which sets the underlying advantage attribute to “Yes” ) and the same concep - tID “Met1” . The novelty attribute value is then in - herited from the novelty attribute value of the ﬁrst coreferring sentence , which in this case is “New” . 3 Input : Paper in XML SAPIENT currently accepts as input papers in XML , especially ones compliant with the SciXML schema ( Rupp et al . , 2006 ) . SciXML is ideally suited for this purpose as it was developed for representing the logical structure of scientiﬁc research papers . Tags used in the schema serve the purpose of paper iden - tiﬁcation ( e . g . < TITLE > , < AUTHOR > ) , deﬁning sections of the paper ( e . g . < DIV > , < HEADER > ) , text sections with speciﬁc function and formatting ( e . g . < ABSTRACT > , < EQUATION > ) , paragraph tags < P > , references , tables , ﬁgures and footnotes , lists , bibliography . SAPIENT operates only on the < TITLE > , < ABSTRACT > , < BODY > and < P > tags , leaving out any list elements following the body , such as acknowledgements , ﬁgures or refer - ences at the end of the paper . This is because we make the assumption that only the abstract and the body contain sentences with semantic content of any importance to the research carried out in the paper . This would have been different if SAPIENT anno - tated ﬁgures as well , but such provision is not cur - rently made . Tags such as < REF > , citations in the text , are included within the sentence boundaries . Even though SAPIENT was developed with the SciXML schema in mind , it will work with any well formed XML document that has < PAPER > as the root node and which also contains an < ABSTRACT > and < BODY > node . Therefore , it is relatively easy to adapt SAPIENT to other XML schemas . 4 SSSplit : Sapient Sentence Splitting 4 . 1 Sentence Matching The reason for developing our own sentence split - ter was that sentence splitters widely available could not handle XML properly . The XML markup con - tains useful information about the document struc - ture and formatting in the form of inline tags , which is important for determining the logical struc - ture of the paper . The latter is worth preserv - ing for our purposes , since it can inﬂuence the annotation of individual sentences . XML markup ( e . g . < ABSTRACT > , < REF > , < EQUATION > ) needs to be combined carefully with tags designat - ing sentence boundaries ( < s > < / s > ) , so that the resulting document is in well formed XML . Cur - rent sentence splitters ignore XML markup , which means that any document formatting / information would have to be removed in order to use them . RASP ( Briscoe et al . , 2006 ) , the sentence splitter used in the Sciborg project 4 at the University of Cambridge , can deal with XML but has to be com - piled for different operating systems , which would result in compromising the platform independence of SAPIENT . A recent MPhil thesis ( Owusu , 2008 ) has also developed an XML - aware sentence splitter but the code is in Microsoft C # . Net and therefore not platform independent . We have written the XML - aware sentence split - ter SSSplit in the platform - independent Java lan - guage ( version 1 . 6 ) , based on and extending open source Perl code 5 for handling plain text . In or - 4 http : / / www . cl . cam . ac . uk / research / nl / sciborg / www / 5 http : / / search . cpan . org / tgrose / HTML - Summary - 0 . 017 / Figure 3 : Example of SAPIENT annotation through selection from drop - down menu . Figure 4 : Behind the scenes : Example XML fragment of a paper annotated using SAPIENT . Figure 5 : Incorporation of OSCAR3 annotations in SAPIENT , after selecting the link “Auto Annotate” der to make our sentence splitter XML aware , we translated the Perl regular expression rules into Java and modifed them to make them compatible with the SciXML ( Rupp et al . , 2006 ) schema . We then fur - ther improved the rules , by training on a set of 14 papers in SciXML . This involved displaying the pa - pers , checking whether the XML was well formed and making corrections accordingly . We would ob - serve cases of oversplit and undersplit sentences and amend the rules while keeping them as general as possible . The rules in SSSplit were evaluated by comparing the system output against a gold standard of 41 papers , where sentence boundaries had been provided by human experts ( See section 4 . 2 ) . The sentence splitter is integrated within the SAPIENT system but is also available as a separate package ( “SSSplit” ) . This should enable any future work to easily incorporate or extend it . It is currently trained for splitting papers in SciXML , but can be easily ported to any other kind of XML , as discussed in section 3 . 4 . 2 SSSplit Evaluation SAPIENT and SSSplit have been have been em - ployed by more than 20 different users to success - fully display 270 full papers . For a more accurate evaluation of the quality of the sentences produced by SSSplit , we used a Perl script which compared the sentence boundaries ( start and end ) generated by SSSplit , to sentence tags in a set of 41 papers ( SciXML ﬁles ) annotated manually by human ex - perts . If both the start and end of a sentence matched up in the generated and manual versions , we consid - ered this a true positive result . In the case where a sentence did not match in the two versions , we ﬁrst searched for a matching end in our generated set of sentences and then in the hand annotated version . If the ‘true’ end of the sentence ( as deﬁned by the man - ual annotation ) was found in later sentences in the SSSplit version , this meant that the system had split a sentence too early , or “oversplit” . This we consid - ered to be a false positive , since we had detected a sentence boundary where in reality there was none . This would result in the following sentence being matched at the end only , which also counts as a false positive . In the case where the end of the SSSplit sentence was found in a later sentence , within the set of ‘true’ sentences , it meant that our sentence RASP Owusu SSSplit Precision 0 . 994 0 . 996 0 . 964 Recall 0 . 983 0 . 990 0 . 994 F - measure 0 . 988 0 . 992 0 . 978 Table 1 : Comparison of sentence splitters in RASP , Owusu and SSSplit . spanned too wide , or that the system had “under - split” . These cases we considered to be false nega - tives , as we had failed to detect a sentence boundary where there was one . Our training consisted of 14 papers in the ﬁelds of physical chemistry and biochemistry . A different set of 41 papers distinct from the training set but from the same thematic domain was used as a test set . Out of these 41 papers , 36 feature as a test set ( with n - fold validation ) also for the sentence splitters RASP ( Briscoe et al . , 2006 ) and the XML - aware sentence splitter developed by ( Owusu , 2008 ) . The results for all three systems , obtained as medians of Precision , Recall and F - measure for the 36 papers are shown in Table 1 . Precision is the proportion of true positives over all end and start tags returned , giving a measure of the number of boundaries identiﬁed correctly . Re - call is the proportion of true positives over all the relevant start and end tags in the hand - annotated pa - pers , giving a measure of the number of boundaries actually found . F - Measure combines Precision and Recall to give a more balanced view on the system performance . In comparison with RASP and the XML - Aware splitter of ( Owusu , 2008 ) , SSSplit performed well , though it did not outperform these systems . Their highest result for precision was 0 . 996 ( vs 0 . 964 for SSSplit ) and for recall 0 . 990 ( vs 0 . 994 for SSSplit ) . We can explain their higher results somewhat by their use of n - fold cross - validation on 36 out of the same 41 papers that we used , which can allow in - formation from the test set to leak into the training data . We did not perform n - fold cross - validation , as this would have involved going through each of the papers and removing any potential inﬂuence on our regular expression rules of the sentences included within , which is a non - trivial process . Our test data was completely unseen , which meant that our eval - Training Testing ( 1979 sentences ) ( 5002 sentences ) Precision 0 . 961 0 . 964 Recall 0 . 995 0 . 994 F - measure 0 . 96875 0 . 978 Table 2 : Comparison of SSSplit on the training and test - ing papers . The training set consisted of 14 papers ( 1979 sentences ) and the testing set of 41 papers ( 5002 sen - tences ) . uation is stricter , avoiding any inﬂuence from the training data . In addition to the comparison between SSSplit and the other two XML - aware sentence splitters , we also performed a comparison between our training and testing sets , depicted in Table 2 . As can be seen in Table 2 , recall was only slightly better on the training set than the test set , but preci - sion was worse on the training set , presumably be - cause of lack of attention being paid to the oversplit - ting in a particular paper ( “b103844n” ) . This shows that we have not overﬁtted to the training set in de - veloping our splitter . Our recall is particularly high , indicating that our splitter makes very few false neg - ative errors . We can attribute many of the false pos - itive errors to our somewhat small set of abbrevi - ations considered , resulting in oversplit sentences . We would like to incorporate a more sophisticated approach to abbreviations in the future . 5 Performing CISP Annotations Within the context of the ART project ( Soldatova et al . , 2007 ) , SAPIENT has been used by 16 Chem - istry experts to annotate 265 papers from RSC Pub - lishing journals , covering topics in Physical Chem - istry and Biochemistry . Experts have been anno - tating the papers sentence by sentence , assigning each sentence one of 11 core scientiﬁc concepts and linking together sentences across a paper which re - fer to the same instance of a concept . The aim is to create a corpus of annotated papers ( ART - corpus ) with regions of scientiﬁc interest identiﬁed by CISP concepts ( “Result” , “Conclusion” , “Obser - vation” , “Method” and so on ) . A preliminary evaluation of the experts’ agree - ment on the ART Corpus , based on a sample of 41 papers , annotated by the 16 experts in non - overlapping groups of 3 , shows signiﬁcant agree - ment between annotators , given the difﬁculty of the task ( an average kappa co - efﬁcient of 0 . 55 per group ) . The details of this work are beyond the scope of the current paper , but the preliminary re - sults underline the usability of both the CISP meta - data and SAPIENT . In the future , we plan to further evaluate the ART Corpus by incorporating existing machine learning algorithms into SAPIENT and au - tomating the generation of CISP meta - data . This would make SAPIENT a very useful tool and would indeed add a lot more value to the meta - data , since training and paying annotators is a costly process and manually annotating papers is incredibly time consuming . 6 Conclusion and Future Work We have presented SAPIENT , a web - based tool for the annotation of full papers , sentence by sentence , with semantic information . We have also discussed how these annotations result in the indirect deﬁni - tion of regions of interest within the paper . The sys - tem has been already tested in a systematic study and has been employed for the creation of a corpus of papers annotated with CISP concepts ( ART Cor - pus ) . In the future we plan to extend SAPIENT so that the system can itself suggest annotation labels to users . We also plan to target the needs of partic - ular users such as authors of papers , reviewers and editors . SAPIENT , SSSplit and their documenta - tion are both available for download from http : / / www . aber . ac . uk / compsci / Research / bio / art / sapient / . Acknowledgments We would like to thank Peter Corbett , Amanda Clare , Jem Rowland and Andrew Sparkes for reading and commenting on earlier versions of this paper . We would also like to thank the anonymous reviewers for their useful com - ments . This work was part of the ART Project ( http : / / www . aber . ac . uk / compsci / Research / bio / art / ) , funded by the U . K . Higher Education Joint Information Services Committee ( JISC ) . References E . Briscoe , J . Carroll and R . Watson 2006 . The Sec - ond Release of the RASP System . Proceedings of the COLING / ACL 2006 Interactive Presentation Sessions , Sydney , Australia . P . Corbett , P . Batchelor and S . Teufel . 2007 . Annotation of Chemical Named Entities . Proc . BioNLP . Nikiforos Karamanis , Ruth Seal , Ian Lewin , Peter Mc - Quilton , Andreas Vlachos , Caroline Gasperin , Rachel Drysdale and Ted Briscoe . 2008 . Natural Language Processing in aid of FlyBase curators . BMC Bioinfor - matics , 9 : 193 . Maria Liakata and Larisa N . Soldatova . 2008 . Guide - lines for the annotation of General Scientiﬁc Concepts JISC Project Report , http : / / ie - repository . jisc . ac . uk / . Jimmy Lin 2009 . Is Searching Full Text More Effec - tive Than Searching Abstracts ? BMC Bioinformatics , 10 : 46 . Ben Medlock and Ted Briscoe . 2007 . Weakly supervised learning for hedge classiﬁcation in scientiﬁc literature . 45th Annual Meeting of the Association for Compu - tational Linguistics , 23 - 30 Jun 2007 , Prague , Czech Republic . P . Ogren . 2006 . Knowtator : a Prot´eg´e plug - in for an - notated corpus construction . Proceedings of the 2006 Conference of the North American Chapter of the As - sociation For Computational Linguistics on Human Language Technology : Companion Volume : Demon - strations , New York Press , New York , June 04 - 09 , 2006 . Lawrence Owusu . 2008 . XML - Aware Sentence Splitter . MPhil thesis , Cambridge , UK . CJ Rupp , Ann Copestake , Simone Teufel and Ben Wal - dron . 2006 . Flexible Interfaces in the Application of Language Technology to an eScience Corpus . Pro - ceedings of the UK e - Science Programme All Hands Meeting 2006 ( AHM2006 ) , Nottingham , UK Hagit Shatkay , Fengxia Pan , Andrey Rzhetsky and W . John Wilbur . 2008 . Multi - dimensional classiﬁcation of biomedical text : Toward automated , practical pro - vision of high - utility text to diverse users . Bioinfor - matics , 24 ( 18 ) : 2086 – 2093 . Larisa N . Soldatova and Maria Liakata . 2007 . An ontol - ogy methodology and CISP - the proposed Core Infor - mation about Scientiﬁc Papers . JISC Project Report , http : / / ie - repository . jisc . ac . uk / 137 / . L . Soldatova , C . Batchelor , M . Liakata , H . Fielding , S . Lewis and R . King 2007 . ART : An ontology based tool for the translation of papers into Semantic Web format . Proceedings of the SIG / ISMB07 ontology workshop . , p . 33 – 36 . Larisa N . Soldatova and Ross D . King . 2006 . An On - tology of Scientiﬁc Experiments . Journal of the Royal Society Interface , 3 : 795 – 803 . S . Teufel and M . Moens . 2002 . Summarizing Scientiﬁc Articles – Experiments with Relevance and Rhetorical Status . Computational Linguistics , 28 ( 4 ) . ( preprint ) W . Wilbur , A . Rzhetsky and H . Shatkay . 2006 . New Di - rections in Biomedical Text Annotations : Deiﬁnitions , Guidelines and Corpus Construction . BMC Bioinfor - matics , 7 : 356 .