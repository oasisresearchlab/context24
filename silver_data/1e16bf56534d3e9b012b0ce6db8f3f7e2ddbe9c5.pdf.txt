ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support Napol Rachatasumrit Carnegie Mellon University napol @ cmu . com Gonzalo Ramos Microsoft Research goramos @ microsoft . com Jina Suh Microsoft Research jinsuh @ microsoft . com Rachel Ng Microsoft Research rachel . ng @ microsoft . com Christopher Meek Microsoft Research meek @ microsoft . com ABSTRACT Online research is a frequent and important activity people perform on the Internet , yet current support for this task is basic , fragmented and not well integrated into web browser experiences . Guided by sensemaking theory , we present ForSense , a browser extension for accelerating people’s online research experience . The two primary sources of novelty of ForSense are the integration of multiple stages of online research and providing machine assistance to the user by leveraging recent advances in neural - driven machine reading . We use ForSense as a design probe to explore ( 1 ) the benefits of inte - grating multiple stages of online research , ( 2 ) the opportunities to accelerate online research using current advances in machine read - ing , and ( 3 ) the opportunities to support online research tasks under the presence of imprecise machine suggestions . In our study , we observe people performing online research tasks , and see that they benefit from ForSense’s integration and machine support for online research . From our study , we derive and share key recommenda - tions for designing and supporting imprecise machine assistance for research tasks . CCS CONCEPTS • Human - centeredcomputing → Interactivesystemsandtools ; Empirical studies in interaction design ; • Information sys - tems → Web searching and information discovery . KEYWORDS human - AI collaboration , sensemaking ACM Reference Format : Napol Rachatasumrit , Gonzalo Ramos , Jina Suh , Rachel Ng , and Christopher Meek . 2021 . ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support . In 26th International Conference on Intelligent User Interfaces ( IUI ’21 ) , April 14 – 17 , 2021 , College Station , TX , USA . ACM , New York , NY , USA , 11 pages . https : / / doi . org / 10 . 1145 / 3397481 . 3450649 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA © 2021 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - 8017 - 1 / 21 / 04 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3397481 . 3450649 1 INTRODUCTION The world - wide - web has become an indispensable tool for con - ducting research [ 32 ] . The Internet is essential for many people during times of emergency to access information and fulfill their needs in social , professional , and educational settings [ 31 ] . Some information needs are best described as finding the answer to a well - defined question ( i . e . , question - answering ) . For such infor - mation needs , the current browser experience driven by search engines provides strong support , often enabling information seek - ers to quickly satisfy their information needs . Our focus , however , is on information needs best described as exploratory research tasks and where successful research outcomes are typically the result of seeking , collecting , analyzing , and synthesizing information found in diverse online locations or documents . Incontrasttoquestion - answeringinformationneeds , exploratory research is a complex task . During this type of research , people engage in activities such as collecting and organizing information clippings , both of which can demand substantial amounts of time and cognitive efforts . For instance , Kellar et al . [ 15 ] distilled five categories describing the different information seeking tasks people do with their web browsers . Of these , they found that information gathering was the task that demanded more time , browser windows , pages visited , searches , and usage of a browser’s functions . There are several tools that assist people in information gather - ing , such as bookmarks built into most browsers or browser exten - sions that support collection and organization . However , browser’s bookmarks typically do not provide insight into why the informa - tion on a web page was relevant to the information need . Further - more , information organizing activities are less supported natively in the browser ; the collecting - organizing experience often involv - ing fragmented notes or clippings across external applications or extensions such as Pocket [ 27 ] , Pinterest [ 25 ] , or Notion [ 23 ] . In addition to supporting some form of folksonomies [ 24 ] , these appli - cations and services provide machine - learning ( ML ) enhancements in the form of article recommendations or keyword suggestions which are often separated from the original research material or the web browser . Our goal is to improve the efficiency of the web browser - based online research experience . We see opportunities to accelerate on - line research tasks by framing them as an integrated sensemaking experience . Our work draws inspiration from work on sensemaking . Sensemaking describes the process of , given a knowledge building task , iteratively creating , and refining a representation system for information , and the subsequent process of encoding information 608 IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Rachatasumrit N . , Ramos G . , Suh J . , Ng R . and Meek C . into that system . Seminal work by [ 26 , 33 ] describes this process and its costs ( cognitive and external ) . During this process , people are engaged into two interconnected loops or activities : foraging and sensemaking . In fact , the name of our system , ForSense , is a portmanteau of these words . While foraging , people collect infor - mation , look at diverse sets of examples or evidence , and start to develop theories about how to organize information as their knowl - edge about a topic evolves . While sensemaking , people explicitly form an information representation system , test it , and refine it using the information collected during the foraging stage . Sensemaking theory provides an elegant framework that high - lights opportunities and requirements for integrating foraging and sensemaking as activities a person should easily alternate in - between when doing research . We argue that such integration leads to less fragmented experiences with less distractions arising from context or application switching [ 13 ] . Applying a sensemaking lens brings attention to tasks that have the potential for machine sup - port . In particular , some of these tasks are things current machine - learned functions can do quite well over large sets of documents ; e . g . , searching for relations , read and extract information , suggest structures or groupings . We also see opportunities to accelerate online research tasks by providing task support enabled by recent advances in deep neu - ral transformer models applied to natural language understanding ( NLU ) of semantically coherent text clippings . These models enable systems to perform remarkable tasks such as named entity detec - tion , question answering , next word or sentence prediction , and text summarization . A fundamental property of these models is their ability to produce embeddings of text phrases or sentences . These embeddings can be seen as encoding some form of meaning and provide numerical representations that allow a machine to suggest the semantic proximity of two embeddings to a person , who can then take advantage of that information . This ability to process and understand information can be used to support and complement people engaged in online research activities . In particular , these models have a higher chance of understanding a part of a web page as a cohesive concept than the totality of a web page . This observation makes these ML models very relevant when focusing on parts or clippings of a web document as units of information . Motivated by these observations , opportunities , and “the lack of support for sensemaking in existing systems” [ 40 ] , we present ForSense , a browser extension for accelerating people’s online re - search experience . ForSense ’s key features consist of integrating multiple sensemaking activities , and leveraging recent advances in transformer models for NLU to support and complement users during their activities . We use ForSense as a design probe to explore ( 1 ) the benefits of integrating multiple stages of online research on the same tool , ( 2 ) the opportunities to accelerate online research using current advances in machine reading , and ( 3 ) the opportunities to support - ing online research tasks under the presence of imprecise machine suggestions . In our study , we observe people perform online re - search tasks and see how our integrated sensemaking design brings benefits like keeping people in a state of flow that facilitates the research task . We also see that machine support based on modern transformer models are beneficial to the experience by supporting users at different points during their research . Our design probe not only helped us provide answers to the above three issues , it also enabled us to identify key recommendations for designing and sup - porting imperfect machine assistance for the design of human - AI collaborative experiences for online research . 2 RELATED WORK 2 . 1 Designing for machine support Prior work in mixed - initiative systems [ 12 ] underscores design principles to enhance a user’s experience by “an elegant coupling of automated services with direct manipulation” . [ 2 ] proposes design guidelines for human - AI interaction in AI - infused applications , with an emphasis on thinking critically about the properties of AI or ML as a design component early in a system’s inception process . We draw inspirations from these guidelines to inform our prototype design , specifically principles such as minimizing the cost of poor guesses , considering uncertainty about a user’s goals , supporting efficient correction and conveying the consequences of user actions . As applications where the interaction or collaboration between people and some form of AI / ML system become more sophisticated and ubiquitous , researchers try to assess their efficacy in getting tasks done . [ 14 ] looked at this issue with the added dimension of perceived effectiveness in the context of an AI - assisted sorting task . They observed that while the system helped people being more efficient , people’s perceptions of efficacy were inverted . This work reveals the challenges of how interacting with a system in - tended to enhance an experience can affect someone’s perception of one’s abilities . We consider these ideas in our work and try to minimize undesired influence from a machine research support by by maximizing user control and supporting research flow . 2 . 2 Sensemaking Tools Sensemaking tools should support users to be in the flow across stages and help them move fluidly between foraging and sensemak - ing activities [ 4 ] . However , most of the tools do not assist users throughout the full process . SenseMaker [ 3 ] focuses on foraging across heterogenous sources , while providing some organization capabilities . WebCutter [ 20 ] allows users to visualize network of related web documents to facilitate their selection . IdeaMache [ 18 ] expands the notion of slideware onto a free - form canvas to foster sensemaking . Tools mentioned above typically use a web page or a document as the smallest unit of information . It has been shown , however , that users regularly think and work with smaller units , or parts of a document [ 21 , 34 ] . There are other tools designed to support more granular information units . Hunter Gatherer [ 35 ] deals with clippings from web pages , [ 9 ] lets users collect parts of a web page , and Kittur’s Clipper [ 16 ] supports saving web page’s parts along with their summary . Nonetheless , these tools do not fully support the foraging sensemaking processes . Tools that only partially support the process can lead to di - vided attention as users switch between them [ 38 ] . On the other hand , tools that integrate searching , collecting , and organizing documents have been shown to benefit from supporting the full foraging - sensemaking process [ 11 , 40 ] . SenseMap [ 22 ] supports the full spectrum of sensemaking activities through letting users 609 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA implicitly build a history map of their web navigation history , cap - ture clips from the pages they see , and build a relationships map for further understanding of a topic . Our work builds on the idea of supporting the foraging - sensemaking process in its entirety . In addition , we leverage parts of web pages as our unit of information and introduce intelligent machine support in each of the steps in the process . 2 . 3 Reading and collecting information on the Web Related to the support of research tasks is the practice of active reading [ 1 ] . During active reading , a reader is engaged in critical thinking and actively marks , highlights and takes notes . The XLibris is one of the early systems that integrates this practice in electronic form and introduce notions of different types of computer support for its users [ 28 ] . Our work is inspired by XLibris ideas and fea - tures about highlighting documents while reading and using these markings to provide research support , and project them into a web browser and the Internet . Later work [ 21 ] looked into understanding the role of clipping information people encounter and its implications for the design of interactions with electronic documents . They found clippings to an important role as reference materials , reminders or sharing materi - als , and they also found challenges in organization and revisitation of clips . Our work leverages clips as an important information unit that people are familiar and work with . We combine these obser - vations with the notion that clips also provide coherent semantic units that machines can understand and build support from . Several products in the market target helping users with col - lecting and organizing web content . Pocket [ 27 ] focuses on the collection of articles , videos and stories from web sources that help users tee up the sequence of content that they want to go through . Services such as Pinterest [ 25 ] suggest related clippings from other sources as an attempt for cross - pollination , yet affinity and connections between existing clippings are not highlighted . In Evernote’s browser extension [ 10 ] , past clippings related to a current search are surfaced to remind users of prior clippings that might be associated or related to the search activity . Nonetheless , these suggestions are encouraged as a complementary revisiting of old clippings , rather than encouraging users to actively synthesize research at hand . Prominence is placed still on the foraging process of research , rather than sensemaking . 3 THE FORSENSE SYSTEM 3 . 1 Sensemaking Framing We apply sensemaking theory [ 26 , 33 ] as a design framework not only to organize tasks and actions that people perform during online research activities but also to identify opportunities for a machine to support them . At a high level , sensemaking process involves alternating between foraging and sensemaking loops to form an information representation structure . Each loop can be further characterized by actions that support online research . Figure 1 illustrates how foraging and sensemaking actions can be organized for online research tasks . During the foraging loop , people interact with data sources ( e . g . , web pages ) to search for information ( Figure 1 - A ) . After reading and comprehending the information ( Figure 1 - B ) , people curate a set of relevant and promising information by clipping and extracting information from web pages ( Figure 1 - C ) . This collecting activity fits the common practice of active reading [ 1 , 28 ] and forms the basis of the foraging loop . As people clip information , they form a collection called a shoebox . As people engage in foraging tasks , they also form theories about how the collected information can be organized or structured . This is the start of a process Pirolli and Card [ 26 ] call schematization , described as the nexus between foraging and sensemaking loops . During the sensemaking loop , people form a schema from col - lected information . Schemas can be seen as an articulation and representation of the knowledge and understanding gained during the larger sensemaking process that informs the overall online re - search . Inspired by [ 17 ] , we further break down the sensemaking loop into defining and modifying a schema or groups of clipped information ( Figure 1 - D ) and evolving a schema or group semantics ( Figure 1 - E ) as people test the schema’s fit for the clipped informa - tion ( Figure 1 - F ) . Each one of the human actions performed during this sense - making process provides an opportunity for machines to provide research support . This could either be directly related to the current action at hand , or could accelerate the overall research goals by facilitating foraging or sensemaking tasks in parallel . For example , when people are collecting clips of information from a web page , the machine could suggest other relevant parts the web page to be clipped , thus assisting with the current foraging action . On the other hand , a machine can also suggest how the clip supports ex - isting schema or which group the clip belongs to , thus assisting with a sensemaking action in parallel . Machine supports in Figure 1 demonstrate such potential opportunities for machines to aug - ment each foraging and sensemaking action . Although this list of opportunities are not exhaustive , they provide inspirations for our system design . 3 . 2 Design Principles With sensemaking theory as a design framework , we identified tasks and design opportunities for machine support for online re - search activities . In addition to supporting these human actions , we wanted to account for the iterative and evolutionary nature of online research , support the frequent alternation and overlap between foraging and sensemaking loops , and incorporate machine support without hampering the main research task . Therefore , we summarize our design goals into the following principles to guide our design : DP1 - Use small units of analysis . As people collect information they naturally underline , mark or clip part of a larger document [ 21 ] . We argue that not only there is value in leveraging this practice , but also that having smaller information chunks leads to more seman - tically coherent units that facilitates schematization and machine support . DP2 - Leverage machine’s capabilities . We aim to explore oppor - tunities for leveraging modern machine - reading capabilities for the system to support online research activities as illustrated in Figure 1 . These machine capabilities include seeing relationships among 610 IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Rachatasumrit N . , Ramos G . , Suh J . , Ng R . and Meek C . Figure 1 : Human actions and machine support for foraging and sensemaking loops in online search activities . Machines can support foraging and sensemaking actions throughout the entire process to speed up alternating between foraging and sense - making actions . Solid lines for machine support indicate that these capabilities are implemented in the current ForSense pro - totype . pieces of clips people have collected as well as revealing connec - tions among unseen clips , at large scales and at speeds beyond human capabilities . DP3 - Support integrated sensemaking activities . Existing support for online research is fragmented ; i . e . , people often have to switch between different applications or move across separate foraging and sensemaking activities . We aimed at eliminating the cognitive burden from these fragmented experiences by directly integrating support tools into where the research is performed and by making it easy to switch between foraging and sensemaking actions . DP4 - Minimize the cost of incorrect machine support . Powerful and enabling at best , system support fueled by machine learning can be at times unhelpful or incorrect . We strive to augment human capabilities , while giving people the agency to disregard or easily recover from unwanted machine suggestions . 3 . 3 System Overview Guided by sensemaking theory and ourdesign principles , we crafted ForSense , a chromium browser extension prototype to support and improve people’s online research experience . At a high level , ForS - ense supports human actions as well as machine support capabilities outlined in Figure 1 . ForSense consists of three main components : The browser extension ( Section 3 . 3 . 1 ) , an NLP service providing paragraph encoding capabilities ( Section 3 . 3 . 2 ) , and a data and syn - chronization service that stores clips and updates different web browser elements about changes made by a user ( Section 3 . 3 . 3 ) . 3 . 3 . 1 Browser Extension . We implemented our prototype as a chromium extension to directly integrate the experience into the tool people use to find and research information for their task . ForSense supports in place foraging activities through a clips sidebar ( Figure 2 - A ) by letting people highlight interesting or meaningful parts of the web pages under review . We call these collected highlights clips . The extension also allows for people to easily switch into sensemaking activities through a sensemaking canvas ( Figure 3 ) by letting them organize collected clips into groups that can provide an overview of what they are researching . As people collect and organize relevant infor - mation they find by navigating web pages , they can make progress towards fulfill a variety of research tasks . Clips Sidebar and Clipping . ForSense injects a clips sidebar ( Figure 2 - A ) , an area that keeps a record of clips people collect during their web browsing research and fulfills the role of the shoebox from the sensemaking theory . People collect clips by highlighting a part of a web page that is currently in view and hitting the Save Clip button at the clips sidebar ( Figure 2 - B ) . Once collected , a truncated view of the of the clip appears as a card in the sidebar , while its highlight remains in the page ( Figure 2 - E ) . Because it is sometime desirable to collect a whole page , the sidebar allows to collect a whole page if no selection is currently being made . Clicking on clips reveals the clip detail view which contains the full captured content . The clip detail view also provides the opportunity to add custom comments to the clip , to qualify the reason why a clip was captured , for example , and to assign a clip into existing groups if the user has created groups of clips . The Sensemaking Canvas . People can inspect and organize the clips they have collected in a view we call sensemaking canvas or canvas for short , which is designed to directly support the sensemaking loop ( Figure 3 ) . The canvas is opened as a browser tab when people click its button in the sidebar ( Figure 2 - F ) . The main canvas area allows people to organize the clips they have collected into groups and spatially arrange them to make sense of a larger picture or a set of topics ( Figure 3 - A ) . To the left of the main canvas area is the collection pane which contains the clips a user has collected and has not yet put onto the canvas ( Figure 3 - B ) . This collection pane also has a filter that lets users find clips with highlights or notes containing a search term . A user can move a clip onto the canvas by dragging it from the collection pane onto any location that makes sense to them . Users can then create groups that represent a topic or a category for a set of clips on the canvas by selecting one or more of them 611 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Figure 2 : ForSense foraging experience . ( A ) Clip sidebar injected into the web page , ( B ) Save clip / page button , ( C ) a clipped item cards ( D ) the card has grey color if ungrouped , otherwise has the group’s color , ( E ) clipped item highlighted in the web page , ( F ) Sensemaking canvas button , ( G ) Machine suggested clip , ( H ) Interacting on a suggested clip . hitting the create group button that appears near them ( Figure 3 - C ) . Once created , users can click on a group’s area to reveal a details pane that lets them edits its name or write comments . Each group has a unique color associated with it . Clips belonging to a group will display the group’s color to indicate their membership . If a clip on the canvas does not have a color , it means that it does not belong to a group . The canvas lets users evolve their knowledge representation over time by dragging clips in and out of groups . In this way , large groups can split into other groups , or smaller groups merged . Machine Support . As we illustrated in Figure 1 , machines can pro - vide both foraging and sensemaking support . Our prototype uses the clips in a group to compute a group embedding , which is used to make suggestions for related clips or groups . As such , ForSense will make better suggestions if the clips in a group represent a coherent theme or topic . After ForSense learns about the ideas , concepts or themes that are important to the current online research task , it will start sug - gesting parts of the web pages that might be of interest during the foraging loop . These suggestions are highlighted as decorations on the web page that the user is currently viewing . In addition , the clips are colored according to the group that the machine thinks the clip belongs to , hence allowing for direct integration of schema - tization activity within this foraging loop . The users can collect these suggestions as clips , mark as irrelevant , or ignore ( Figure 2 - G ) . If the suggested group is incorrect , the user can correct the clip’s group membership in the clip detail view . Similar to group suggestions during the foraging loop , ForS - ense also suggests what group a clip likely belongs to within the sensemaking canvas . Each clip from the collection pane has an autogroup button that , when hovered over , highlights the group that ForSense suggests as the most likely destination ( Figure 3 - E , F ) . This preview helps users consider if they want to accept the sys - tem’s suggestion . If a user agrees with that suggestion , they can click the button and have the prototype move the clip onto the suggested group area . ForSense provides a counterpart to the auto - group functionality . Hovering on the attract button on a clip or a group highlights ungrouped clips on the canvas likely to be related . Clicking on this button brings these clips close to the attracting clip or group . To allow easy recovery from undesired machine suggestions , we provide an undo button to recover previous states . 3 . 3 . 2 NLP Services . Modern transformer ML models such as BERT [ 8 ] can be used as a way to encode text input into a representation made up of an array of numbers , called embedding . These embeddings have the remarkable property that two semantically close pieces of text will also be close in the embedding space according to a distance metric ( e . g . the cosine distance between two vectors ) . ForSense takes advantage of this machine capability and applies it to the clips that users collect while researching online . ForSense computes an embedding of every clip users collect . Similarly , when users visit a 612 IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Rachatasumrit N . , Ramos G . , Suh J . , Ng R . and Meek C . Figure 3 : ForSense’s sensenmaking canvas . ( A ) Main canvas area where people can spatially position clips into groups , ( B ) Collection pane that contains collected clips and filter / search functionality . ( C ) New group button , ( D ) Example of a group and clips within them , ( E ) Auto group button in the collection pane , and the group it is suggesting with a emphasized border ( F ) . web page , ForSense computes a list of embeddings from its parts ( text content within the < p > or < li > tags ) . Page clips and parts are likely to be semantically more coherent than a whole page , which makes their embeddings to be more faithful representations of their original content . When users create or update a group , its embedding is calculated as an average of its clip’s embeddings . Our system uses these embeddings in several ways . Given a set of groups , the system can suggest which clips are within a specified semantic distance to the groups . Given a clip , the system can suggest which groups are closer than a specific semantic distance to it . Finally , given a group , ForSense can suggest which clips are within a specified semantic distance to the group . These suggestions are based on a general distance threshold that we determined through pilot studies to favor recall over precision . The embeddings computation was separated from the browser due to its computational cost . We implemented a RESTful service that is accessible to the browser extension . This service computes BERT embeddings using bert - as - a - service [ 39 ] from different types of input such as text paragraphs or a web page’s URL . We used the pre - trained uncased _ L - 12 _ H - 768 _ A - 12 BERT model which provided useful suggestions through pilot studies . 3 . 3 . 3 Data and Synchronization Services . Between the browser extension and the NLP services , we have data and synchronization service layer , a RESTful service that pro - vides data storage and Create / Read / Update / Delete ( CRUD ) capa - bilities to the extension . This service also interfaces with the NLP services to obtain the embeddings , which it uses to provide the machine suggestions enumerated in Section 3 . 3 . 2 to the system . The browser extension’s UI is kept synchronized and consistent across different browser tabs through websockets . 4 USER STUDY We built ForSense as a design probe [ 5 ] to engage potential users of the system in our design process and to collect information that can help us understand how the integrated support for foraging - sensemaking experiences and the use of ML - based machine support can enhance online research tasks . We use the probe in combination with a task - based , semi - structured interviews in order to observe realistic use of the system in an online research task and to elicit feedback from participants about our current design and potential new directions for the system . Thus , in our user study , we aim to answer the following seminal research questions in the context of our online research task : RQ1 . How do people and their actions benefit from the machine’s support as they perform the online research task ? RQ2 . How useful is the integration of foraging and sensemaking activities into the system and the flexible alternation between them in helping people accelerate their research task ? RQ3 . What are effective strategies for handling imprecise sup - port by the machine ? 4 . 1 Participants We recruited 10 ( 6 Female , 4 Male ) participants from a large tech - nology company , which aligns with local standards for sample size for design probe studies in HCI [ 7 ] . These participants hold diverse 613 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA backgrounds and roles raging from Designers , Program Managers , Scientist , Design Producers and Software Engineers . All partici - pants have performed online research tasks on the Internet using a web browser . Seven participants were between 25 - 34 years of age , 1 was between 18 - 24 years of age , and 2 were between 35 - 44 years of age . Four participants had a bachelor’s degree , and six held Master’s degree or higher . Participants were compensated with a $ 25 gift card . 4 . 2 Procedure We conducted the study remotely using a video conferencing plat - form . The study consisted of three stages : introduction , practice , and task . During the introduction , participants watched an approx - imately 5 - minute long video that presented the main features of ForSense : selecting and clipping text parts of a web page , organizing these clips in the sensemaking canvas , and using the system’s high - lights and suggestion features . After the introduction , participants connected to a remote machine that had the ForSense extension installed 1 . Participants shared their screen as they practiced with the system’s features for about 10 minutes , and the researcher an - swered questions about the system . After the practice stage and a brief explanation of the task ( described in the next section ) , partici - pants began the online research task for 30 - 40 minutes and were encouraged to think aloud . Once participants completed their re - search task , they filled a system usability scale ( SUS ) survey [ 6 ] . The study concluded with a 10 - minute semi - structured interview about their experience : what aspects of the experience they liked , which ones had room for improvement , and what other types of machine support they would welcome . 4 . 3 Online Research Task Participants were asked to conduct online research in order to pre - pare an outline for an introductory presentation about a topic . They could choose a research topic that they were not familiar with but were interested in learning about . Although we provided a list of re - search topics to choose from , participants were free to come up with their own topic . Example topics include Designing a board game , What is Kombucha and how to make it , and Becoming a birdwatcher . Participants had 30 minutes to complete their online research , with up to an additional 10 minutes to commit their presentation outline . We gave people the choice to produce this outline as a bulleted list ( using a standard text editor ) or in the system’s sensemaking canvas . Figure 4 shows an example outcome of the study . 5 RESULTS All participants successfully completed their research task and pro - duced outlines for their chosen topics . In the following sections , we summarize and discuss our observations and insights that address our research questions . 5 . 1 Machine support accelerated human online research actions ( RQ1 ) Participants thought that machine support helped their foraging and sensemaking activities . Participants who took advantage of the 1 To reduce setup time and avoid installation issues , we provided a remote machine with the appropriate set up that participants could use for the study . autogroup or attract features praised them as shortcuts to accelerate sensemaking : “ ( P07 ) For me I think it’s exciting because it’s going to surface relationships within data . Maybe relationships that I hadn’t thought of when I created that rough outline to go and research” . . Participants also liked the system suggesting parts of web pages as potential content to clip : “ ( P08 ) [ I just like ] the idea to , like , clipping and cataloging things” . We also observed that machine suggestions accelerated the re - search task . First , clip suggestions allowed participants to quickly focus on relevant parts of a page . Second , they helped participants attend to parts of a page they would have otherwise missed because they were quickly scanning a page or focusing only on noticeable images or fonts : “ ( P05 ) Did you see how I naturally scroll right over it , but I noticed the pink line , and like . . . wait woah , let’s go back up there” . Third , machine suggestions gave people a starting point for a mixed - initiative interaction [ 12 ] , an opinion they could editorial - ize , undo , or correct . Regardless of the quality of the suggestions , they provided visual landmarks for efficient active reading process , increased a reader’s awareness of topics , themes , and concepts of interest in the page , and accelerated clipping . We observed other patterns of use that could be further inves - tigated . Clip suggestions were more visible for those people that frequently alternated between foraging and sensemaking activities than those that performed these activities in batches or chunks be - cause the participants’ schematization of clips into groups gave the machine structural information to provide updated suggestions . On the other hand , the system implementation did not provide sugges - tions without existing groups , illustrating a well - known cold - start problem in learning systems . We could have used existing clips to suggest other clips but this was a design choice that should be revisited . Some participants missed suggestions that could have enhanced their clipping and grouping actions early on . Others expressed that they would have liked to see the system propose potential groups given a set of clips , even as an imperfect starting point to refine : “ ( P05 ) If there was a way to maybe suggest . . . at the very beginning when you just started your search and you were just starting to save things . , It could auto suggest categories” . Although the autogroup feature was well understood , some peo - ple were confused about the attract feature : “ ( P11 ) The only concepts that was a little weird to me was attract” . In addition to making the feature more intuitive , participants suggested a way to control the strength of the attraction and modulate how many or semantically distant clips it affects . Such interaction could potentially be used to improve control and understanding of the system . 5 . 2 Seamless integration between foraging and sensemaking promoted research flow ( RQ2 ) Participants expressed how they liked having the ability to collect clips ( i . e . , foraging ) and organize them ( i . e . , sensemaking ) all within the same browser : “ ( P06 ) I mean the more the more stuff we can do in the browser the better , and not having to switch between a million apps . ” . We observed how the sensemaking canvas provided participants with a way to externalize their current mental model about a topic ( create groups ) , test it ( assign clips to groups ) , refine it ( create new group or sub - groups ) and quickly switch back to 614 IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Rachatasumrit N . , Ramos G . , Suh J . , Ng R . and Meek C . Figure 4 : Screenshot of a participant’s sensemaking canvas at the end of the study . The participant used the sensemaking canvas to define seven grops to help them in their research about how to create a board game : Theme , Pitch , Rules , Market , Asia - Pacific Market , Distribution Channels , and Prototype . collecting more information from the same browser session by simply opening a new tab and starting a new search . We found that participants had differing strategies for navigat - ing between foraging and sensemaking loops . Some participants alternated fluidly between foraging and sensemaking tasks early on . Others stayed in a foraging activity for a while ( at least 15 min - utes ) before switching to a sensemaking activity . After that switch , these participants behaved like the first group . Many participants that had created groups in the canvas expressed how they liked the ability to assign clips to groups without having to switch to the canvas view . In general , we observed that being able to switch between foraging and sensemaking activities in the browser kept participants in a state of research flow ; participants who were able to blur the boundaries between collecting and organizing were more efficient at their tasks . Our study revealed opportunities for further task integration and to help people “brain dump” at any point during research . Participants thought out loud the groups they wanted to create before or during the foraging stage . Most participants expressed the need to create empty groups , before any clips about it were collected : “ ( P04 ) I’m going to create a group . . . oh , . . . I was hoping that I could just [ do that ] ” . 5 . 3 Machine suggestions were accepted as part of the process , and needed to be correctable ( RQ3 ) Occasionally during the study , the system provided imprecise or unhelpful suggestions to the participants . We observed that partici - pants formed a mental model about how the system works and how they can affect it [ 30 ] . For example , some participants took these unhelpful suggestions as signals for human intervention , that they needed to collect more clips for a group , or that a group was not well defined . After human intervention , participants previewed group suggestions to evaluate if the system started to understand what theme or concept was important for each group . Some participants rationalized machine suggestions : even when they saw a decision they did not agree with , they forgave the system because the sys - tem did not have the full picture : “ ( P11 ) I feel like maybe I trained it poorly and it would not highlight good things , but I’m still super interested in that highlighting feature . ” Other participants wanted to correct an incorrect suggestion by teaching the system what it did wrong or what to look for in clips , highlighting a “teaching” moment that future systems could design for [ 29 ] . Participants thought that the ability to revert an unhelpful ma - chine suggestion was especially useful during the attract action , where many clips could be brought into a group . However , because attract operation could moved several clips with a mix of help - ful and unhelpful suggestions , participants wanted finer control 615 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA beyond previews and undo actions to regulate the system’s recom - mendations and to verify their understanding of the quality of the suggestion . We observed that there were human costs associated with un - helpful suggestions : “ ( P05 ) if a computer is telling me it should go here [ the group that she doesn’t expect ] , I would reread it and I would be like maybe I’m misinterpreting it . ” However , others pointed out the ease of handling errors with a generous tolerance for incorrect suggestions : “ ( P04 ) For machine learning , honestly , I would hope for at least a 50 % like success rate at least since it’s not like super criti - cal and I can easily change it . 50 to 70 % would be good . ” Therefore , understanding and embracing a system’s limitations can be key in establishing how a person and a machine’s capabilities complement one another . 5 . 4 Usability and System Limitations The average and median SUS scores were 72 . 3 and 73 . 8 respectively . Figure 5 illustrates the distribution of the participants’ answers . Participants that scored the system below these values pointed to prototype limitations in grouping functionality and sporadic bugs that required reloading the current web page . Participants suggested additional features to improve the usability of the system . For example , participants wanted the ability to clip images or videos from web pages or to automatically layout clips within a group . Others suggested the ability to define multiple research session to decompose their tasks . Finally , some participants wanted to directly export or connect their sensemaking work into other systems so that it could be used as a basis for a presentation deck or to share findings with other people . 6 DESIGN RECOMMENDATIONS Using ForSense as a design probe , we learned that machine sup - port can accelerate human online research efforts and that fluid interaction between foraging and sensemaking promoted research flow . We also found that people formed mental models about the system and wanted to correct unhelpful or incorrect suggestions . Based on our findings from the user study , we identified several key design considerations for incorporating machine support in human - AI collaborative online research systems : Imprecise machine support can be useful . During our study , we consistently observed that participants not only tolerated , but also valued imprecise support . Suggestions provided opportunities to question their perspectives , and exploring the diversity of informa - tion , which is crucial during research tasks . These suggestions also provided an insight about the system’s model of the world ; people used that information to form theories on what the system needs to improve . Therefore , it is important to design a system that allows people to form appropriate mental models about the system , for example , through visualizing and inspecting the factors that affect the system’s decision or suggestion . Think about complementing before collaborating . While there is a collective aspiration for systems that display general intelligence , most intelligent systems nowadays only provide specialized behav - iors for specific tasks ( e . g . , classification , detection , prediction ) or subject domains . Over the course of our study , we found it use - ful not to think about human - AI collaboration , which can elicit imagery of aligning goals from two entities , but rather to think about complementing human and AI capabilities . This perspective relaxes what one needs to expect from a system and think about how a person’s capabilities can be augmented , not replaced by ML technologies . In a human - AI complementary framework , machine support begins where human agency ends - and vice - versa . Figure 1 illustrates how we used sensemaking theory to identify how to complement people’s actions throughout an online research task . Identify and design for teaching moments . In our study , partic - ipants understood that defining groups was a means to tell ForS - ense about what concepts were important to them . In our system , the only way to express these concepts was to collect clips . Even though groups and clips were sufficient for the underlying natural language understanding model to be helpful in online research tasks , participants expressed additional ways to teach the system such as a desire to mark a suggested clip as a negative example for a group . Therefore , it is important to identify and design for these teaching moments that give people agency about telling the system what is important , what is not , and why . We hypothesize that a system that receives this information should be better at support - ing a person with their research activities . Teaching opportunities can also originate from the system . ForSense’s users could have benefited from system nudges , similar to those in [ 37 ] , that could have helped them take actions that move their data collection or organization tasks forward . ( short ) Clips are useful units of information . In our study , we saw that participants were comfortable with collecting and ma - nipulating snippets from web pages ( i . e . , clips ) . Furthermore , our participants readily use these clips to express concepts and building blocks for higher - level semantic structures . The clips were typically more semantically coherent than the web pages containing them . Therefore , using these clips as units of information may lead to easier human manipulation and understanding as well as better machine comprehension and suggestion . 7 FUTURE DIRECTIONS During our study , we identified promising directions for future research and studies : Accelerating the selection of search results . Participants in our study unanimously used web search to look for content to read and , if relevant , later collect it . We believe that decorating a list of search results with their potential relevance to groups or topics of the research task may help accelerate selecting worthwhile results . Improving complementary support by increasing a person’s vo - cabulary to express concepts . We believe it is important to increase the ways in which people can express knowledge to a system . In addition to providing positive clips to define a group , it should be straightforward to provide negative clips to refine it . The distance calculation to this group may favor clips close to the positive set of examples , while penalizing clips closer to the negative set . Enhancing research flow by incorporating foraging into sense - making . In the same way that participants performed grouping 616 IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA Rachatasumrit N . , Ramos G . , Suh J . , Ng R . and Meek C . Figure 5 : Distribution of answers for SUS questions from the study’s participants . Each horizontal bar accounts for 10 re - sponses . activities in the foraging stage , there is an opportunity to collect clips during the schematization stage . As illustrated in Figure 1 , future versions of ForSense can provide suggested clips found from sources such as the browser’s history , currently opened tabs , active web search results , well - known news or document sources , etc . Leveraging embeddings beyond text for collecting more diverse relevant information . Although ForSense only leveraged text - based embeddings , current ML advances can produce representations or embeddings for other types of media such as images [ 19 , 41 ] or videos [ 36 ] . Furthermore , images can be translated into textual descriptions which can be used to calculate semantic distances with clipped text paragraphs . Future versions of ForSense can lever - age these additional embeddings to provide semantic similarities between different types of media . Being able to suggest relations between different types of media can accelerate not only people’s ability to schematize , but also to collect relevant information for their research . 8 CONCLUSION In this work , we use sensemaking theory to ground the design of ForSense , a web browser extension for accelerating people’s online research experience . ForSense integrates foraging and sensemaking activities into the web browser experience and leverages recent ad - vances in neural - driven machine reading to provide complementary support while a person collects and groups relevant information . We use ForSense as a design probe during a user study where peo - ple performed a real research task . We observed that the system’s integrated foraging - sensemaking approach and machine - driven support promoted people’s research flow , while complementing and enhancing people’s capacity to collect and group information . We were happy to find that people engaged in research tasks are tolerant to imprecise system suggestions and that these imprecise suggestions can still be useful . Lastly , our work underscored that complementary human - AI is a useful way to think about the inter - action between people and AI in system , in situations where the AI is specialized or imprecise . REFERENCES [ 1 ] MJ Adler and C Van Doren . 2014 . How to read a book : The classic guide to intelligent reading ( Touchstone ed . ) . [ 2 ] Saleema Amershi , Dan Weld , Mihaela Vorvoreanu , Adam Fourney , Besmira Nushi , Penny Collisson , Jina Suh , Shamsi Iqbal , Paul N . Bennett , Kori Inkpen , Jaime Teevan , Ruth Kikin - Gil , and Eric Horvitz . 2019 . Guidelines for Human - AI Interaction . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . [ 3 ] Michelle Q Wang Baldonado and Terry Winograd . 1997 . SenseMaker : an information - exploration interface supporting the contextual evolution of a user’s interests . In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems . 11 – 18 . [ 4 ] Benjamin B Bederson . 2004 . Interfaces for staying in the flow . Ubiquity 5 , 27 ( 2004 ) , 1 . [ 5 ] Kirsten Boehner , Janet Vertesi , Phoebe Sengers , and Paul Dourish . 2007 . How HCI interprets the probes . In Proceedings of the SIGCHI conference on Human factors in computing systems . 1077 – 1086 . [ 6 ] John Brooke . 2013 . SUS : A Retrospective . J . Usability Studies 8 , 2 ( Feb . 2013 ) , 29 – 40 . [ 7 ] Kelly Caine . 2016 . Local Standards for Sample Size at CHI . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems ( San Jose , California , USA ) ( CHI ’16 ) . Association for Computing Machinery , New York , NY , USA , 981 – 992 . [ 8 ] Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . BERT : Pre - training of Deep Bidirectional Transformers for Language Understanding . In Proceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics : Human Language Technologies , Volume 1 ( Long and ShortPapers ) . AssociationforComputationalLinguistics , Minneapolis , Minnesota , 4171 – 4186 . [ 9 ] MiraDontcheva , StevenMDrucker , GeraldineWade , DavidSalesin , andMichaelF Cohen . 2006 . Collecting and organizing web content . In Personal Information Management - Special Interest Group for Information Retrieval Workshop . 44 – 47 . [ 10 ] Evernote . 2020 . Evernote is the home for everything you need to remember , and everything you want to achieve . https : / / evernote . com / Accessed October 2020 . [ 11 ] Marti A Hearst and Duane Degler . 2013 . Sewing the seams of sensemaking : A practical interface for tagging and organizing saved search results . In Proceedings of the symposium on human - computer interaction and information retrieval . 1 – 10 . [ 12 ] Eric Horvitz . 1999 . Principles of Mixed - Initiative User Interfaces . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Pittsburgh , Pennsylvania , USA ) ( CHI ’99 ) . Association for Computing Machinery , New York , 617 ForSense : Accelerating Online Research Through Sensemaking Integration and Machine Research Support IUI ’21 , April 14 – 17 , 2021 , College Station , TX , USA NY , USA , 159 – 166 . [ 13 ] Shamsi T . Iqbal and Eric Horvitz . 2007 . Disruption and recovery of computing tasks : fieldstudy , analysis , anddirections . In ProceedingsoftheSIGCHIConference on Human Factors in Computing Systems . 677 – 686 . [ 14 ] Rune Møberg Jacobsen , Lukas Bjørn Leer Bysted , Patrick Skov Johansen , Eleft - herios Papachristos , and Mikael B . Skov . 2020 . Perceived and Measured Task Effectiveness in Human - AI Collaboration . In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems ( Honolulu , HI , USA ) ( CHI EA ’20 ) . Association for Computing Machinery , New York , NY , USA , 1 – 9 . [ 15 ] Melanie Kellar , Carolyn Watters , and Michael Shepherd . 2007 . A field study characterizing Web - based information - seeking tasks . Journal of the American Society for information science and technology 58 , 7 ( 2007 ) , 999 – 1018 . [ 16 ] Aniket Kittur , Andrew M Peters , Abdigani Diriye , and Michael Bove . 2014 . Stand - ing on the schemas of giants : socially augmented information foraging . In Pro - ceedings of the 17th ACM conference on Computer supported cooperative work & social computing . 999 – 1010 . [ 17 ] Gary Klein , Jennifer K . Phillips , Erica L . Rall , and Deborah A . Peluso . 2007 . A data - frame theory of sensemaking . Lawrence Erlbaum Associates Publishers , Mahwah , NJ , US , 113 – 155 . [ 18 ] Rhema Linder , Nic Lupfer , Andruid Kerne , Andrew M Webb , Cameron Hill , Yin Qu , Kade Keith , Matthew Carrasco , and Elizabeth Kellogg . 2015 . Beyond slideware : How a free - form presentation medium stimulates free - form thinking in the classroom . In Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition . 285 – 294 . [ 19 ] Jiasen Lu , Dhruv Batra , Devi Parikh , and Stefan Lee . 2019 . ViLBERT : Pretraining Task - Agnostic Visiolinguistic Representations for Vision - and - Language Tasks . arXiv : 1908 . 02265 [ cs . CV ] [ 20 ] Yoelle S Maarek , Michal Jacovi , Menachem Shtalhaim , Sigalit Ur , Dror Zernik , and Israel Z Ben - Shaul . 1997 . WebCutter : a system for dynamic and tailorable site mapping . Computer networks and ISDN systems 29 , 8 - 13 ( 1997 ) , 1269 – 1279 . [ 21 ] Catherine C . Marshall and Sara Bly . 2005 . Saving and Using Encountered In - formation : Implications for Electronic Periodicals . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Portland , Oregon , USA ) ( CHI ’05 ) . Association for Computing Machinery , New York , NY , USA , 111 – 120 . [ 22 ] P . H . Nguyen , K . Xu , A . Bardill , B . Salman , K . Herd , and B . L . W . Wong . 2016 . SenseMap : Supporting browser - based online sensemaking through analytic provenance . In 2016 IEEE Conference on Visual Analytics Science and Technol - ogy ( VAST ) . 91 – 100 . [ 23 ] Notion . 2020 . Notion : All in one workplace . https : / / www . notion . so / Accessed October 2020 . [ 24 ] I . Peters and P . Becker . 2009 . Folksonomies : Indexing and Retrieval in Web 2 . 0 . De Gruyter / Saur . [ 25 ] Pinterest . 2020 . Pinterest : Welcome to visual discovery . https : / / www . pinterest . com / Accessed October 2020 . [ 26 ] Peter Pirolli and Stuart Card . 2005 . The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis . In Proceedings of international conference on intelligence analysis , Vol . 5 . McLean , VA , USA , 2 – 4 . [ 27 ] Pocket . 2020 . Pocket . https : / / app . getpocket . com / Accessed October 2020 . [ 28 ] Morgan N . Price , Bill N . Schilit , and Gene Golovchinsky . 1998 . XLibris : The Active Reading Machine . In CHI 98 Conference Summary on Human Factors in Computing Systems ( Los Angeles , California , USA ) ( CHI ’98 ) . Association for Computing Machinery , New York , NY , USA , 22 – 23 . [ 29 ] Gonzalo Ramos , Christopher Meek , Patrice Simard , Jina Suh , and Soroush Gho - rashi . 2020 . Interactivemachineteaching : ahuman - centeredapproachtobuilding machine - learned models . Human – Computer Interaction 35 , 5 - 6 ( 2020 ) , 413 – 451 . [ 30 ] Gonzalo Ramos , Felicia Ng , Nicole Sultanum , Chris Meek , Jina Suh , and Soroush Ghorashi . 2019 . Do Machine Teachers Dream of Algorithms ? Workshop on Human - Centric Machine Learning at the 33rd Conference on Neural Information Processing Systems . ( December 2019 ) . [ 31 ] PewResearch . 2020 . 53 % ofAmericansSaytheInternetHasBeenEssentialDuring the COVID - 19 Outbreak . https : / / tinyurl . com / y7lvxmkr Accessed October 2020 . [ 32 ] Pew Research . 2020 . Most Americans rely on their own research to make big decisions , and that often means online searches . https : / / tinyurl . com / yaay6vbr Accessed September 2020 . [ 33 ] Daniel M . Russell , Mark J . Stefik , Peter Pirolli , and Stuart K . Card . 1993 . The Cost Structure of Sensemaking . In Proceedings of the INTERACT ’93 and CHI ’93 Con - ference on Human Factors in Computing Systems ( Amsterdam , The Netherlands ) ( CHI ’93 ) . Association for Computing Machinery , New York , NY , USA , 269 – 276 . [ 34 ] MC Schraefel and Yuxiang Zhu . 2001 . Interaction design for web - based , within - page collection making and management . In Proceedings of the 12th ACM confer - ence on Hypertext and Hypermedia . 125 – 125 . [ 35 ] Monica C Schraefel , Yuxiang Zhu , David Modjeska , Daniel Wigdor , and Sheng - dong Zhao . 2002 . Hunter gatherer : interaction support for the creation and management of within - web - page collections . In Proceedings of the 11th interna - tional conference on World Wide Web . 172 – 181 . [ 36 ] Chen Sun , Austin Myers , Carl Vondrick , Kevin Murphy , and Cordelia Schmid . 2019 . VideoBERT : A Joint Model for Video and Language Representation Learn - ing . arXiv : 1904 . 01766 [ cs . CV ] [ 37 ] Emily Wall , Soroush Ghorashi , and Gonzalo Ramos . 2019 . Using Expert Patterns in Assisted Interactive Machine Learning : A Study in Machine Teaching . In Human - Computer Interaction - INTERACT 2019 - 17th IFIP TC 13 International Conference , Paphos , Cyprus , September 2 - 6 , 2019 , Proceedings , Part III . 578 – 599 . [ 38 ] Christopher D Wickens , Justin G Hollands , Simon Banbury , and Raja Parasura - man . 2015 . Engineering psychology and human performance . Psychology Press . [ 39 ] Han Xiao . 2018 . bert - as - service . https : / / github . com / hanxiao / bert - as - service . [ 40 ] Xiaolong Zhang , Yan Qu , C . Lee Giles , and Piyou Song . 2008 . CiteSense : Support - ing Sensemaking of Research Literature . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( Florence , Italy ) ( CHI ’08 ) . Association for Computing Machinery , New York , NY , USA , 677 – 680 . [ 41 ] Luowei Zhou , Hamid Palangi , Lei Zhang , Houdong Hu , Jason J . Corso , and Jianfeng Gao . 2019 . Unified Vision - Language Pre - Training for Image Captioning and VQA . arXiv : 1909 . 11059 [ cs . CV ] 618