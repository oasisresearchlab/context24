a r X i v : 2006 . 01287v1 [ c s . I R ] 1 J un 2020 Outlier Resilient Collaborative Web Service QoS Prediction Fanghua Ye University College London fanghua . ye . 19 @ ucl . ac . uk Zhiwei Lin Sun Yat - sen University linzhw25 @ mail2 . sysu . edu . cn Chuan Chen Sun Yat - sen University chenchuan @ mail . sysu . edu . cn Zibin Zheng Sun Yat - sen University zhzibin @ mail . sysu . edu . cn Hong Huang Huazhong University of Science and Technology honghuang @ hust . edu . cn Emine Yilmaz University College London emine . yilmaz @ ucl . ac . uk ABSTRACT Nowadays , more and more Web services are provided by diﬀer - ent enterprises and organizations . The proliferation of Web ser - vices makes it diﬃcult for users to select the most appropriate Web services among numerous functionally identical or similar service candidates . Quality - of - Service ( QoS ) is widely employed for describing the non - functional characteristics of Web services , and it has become the key diﬀerentiator for service selection . How - ever , userscannot invoke allWeb services toobtainthe correspond - ing QoS values due to high time cost and huge resource overhead . Thus , it is essential to predict unknown QoS values . Although vari - ous QoS prediction methods have been proposed , few of them have taken outliers into consideration , which may dramatically degrade the prediction performance . To overcome this limitation , we pro - pose a robust collaborative QoS prediction method in this paper . Our method utilizes Cauchy loss to measure the discrepancy be - tween the observed QoS values and the predicted ones . Owing to the robustness of Cauchy loss , our method is resilient to outliers . We further extend our method to provide time - aware QoS predic - tion results by taking the temporal information into consideration . Finally , we conduct extensive experiments on both static and dy - namic datasets . The results demonstrate that our method is able to achieve better performance than state - of - the - art baseline methods . KEYWORDS Web service , QoS prediction , outlier resilience , collaborative ﬁlter - ing , Cauchy loss 1 INTRODUCTION Web service is a standard technology for providing interoperabil - ity between disparate software applications and plays the key role in service - oriented computing [ 3 ] . Over the past few years , a large number of Web services have been published as indicated by the Web service repository – ProgrammableWeb 1 . The proliferation of Web services brings great beneﬁts in building versatile service - oriented applications and systems . It is apparent that the quality of service - oriented applications and systems relies heavily on the quality of their component Web services . Thus , investigating the quality of Web services is an im - portant task to ensure the reliability of the ultimate applications 1 https : / / www . programmableweb . com / and the entire systems . The quality of Web services can be charac - terized by their functional and non - functional attributes . Quality - of - Service ( QoS ) represents the non - functional aspect of Web ser - vices , such as response time , throughput rate and failure probabil - ity [ 38 , 47 ] . Since there are many functionally equivalent or simi - lar services oﬀered on the Web , investigating non - functional QoS properties becomes the major concern for service selection [ 13 , 62 ] . However , the QoS value observed by users depends heavily on the Web service invocation context . Hence , the quality of the same Web service experienced by diﬀerent users may be relatively dif - ferent [ 43 ] . For this reason , it is important to acquire personalized QoS values for diﬀerent users . Considering that users cannot in - voke all Web services to obtain personalized QoS values on their own due tohigh time cost and huge resource overhead [ 47 , 61 ] , pre - dicting missing QoS values based on existing observations plays an essential role in obtaining approximate personalized QoS values . For QoS prediction , collaborative ﬁltering is one of the most widely adopted methods [ 47 ] . Existing collaborative ﬁltering meth - ods can be grouped into memory - based methods and model - based methods . The memory - based methodsaim at utilizingsimilar users ( or similar Web services ) for a target user ( or a target Web service ) to predict unknown QoS values [ 10 , 72 ] . Although memory - based methods are straightforward and easy to implement , they usually suﬀer from the data sparsity problem [ 61 , 66 ] . The model - based methods aim at building global prediction models based on exist - ing QoS observations to predict unknown QoS values [ 61 ] . Among model - based methods , matrix factorization ( MF ) has gained the most attention and popularity and it is able to deal with the issue of data sparsity [ 26 ] . In addition , MF - based methods usually have greater capability than memory - based methods in capturing the similarity between users and the similarity between Web services , which therefore results in better QoS prediction performance . However , most existing MF - based QoS prediction methods di - rectly utilize L 2 - norm to measure the diﬀerence between the ob - served QoS values and the predicted ones [ 32 , 44 , 48 , 50 , 53 , 57 , 66 ] . It is well - known that L 2 - norm is sensitive to outliers [ 8 , 35 , 58 , 63 , 64 , 69 ] . That is , the objective function value may be dominated by outliers during the L 2 - norm minimization process , which will lead to severe approximation deviation between the observed normal values and the predicted ones . As a result , without taking outliers into consideration , existing MF - based methods may not achieve satisfactory performance . In recent years , there are some explo - rations on enhancing the robustness of MF - based QoS prediction methods by replacing L 2 - norm with L 1 - norm [ 70 ] . Although L 1 - norm is more robust to outliers [ 14 , 23 , 36 , 64 ] , L 1 - norm - based objective function is much harder to optimize and the solution is also unstable [ 35 , 56 ] . Moreover , L 1 - norm is still sensitive to outliers especially when outliers take signiﬁcantly diﬀerent val - ues from the normal ones [ 11 , 55 ] . There are also some methods seeking to identify outliers explicitly by means of clustering algo - rithms [ 18 , 49 , 71 ] , which usually treat all the elements in the small - est cluster as outliers [ 19 , 47 ] . However , it is diﬃcult to choose a proper number of clusters , thus either some outliers may not be eliminated successfully or some normal values may be selected as outliers falsely . To deal with the aforementioned issues , in this paper we pro - pose a novel robust QoS prediction method under the matrix fac - torization framework . Our method chooses to measure the discrep - ancy between the observed QoS values and the predicted ones by Cauchy loss [ 2 , 28 ] instead of the L 1 - norm loss or L 2 - norm loss . It has been shown that Cauchy loss is much more robust to out - liers than the L 1 - norm loss and L 2 - norm loss [ 28 , 55 ] . Theoreti - cally , Cauchy loss allows nearly half of the observations to be out of the normal range before it gives incorrect results [ 37 ] . Appar - ently , for a given QoS dataset , it is almost impossible that nearly half of the observations are outliers . Thus , Cauchy loss is suﬃcient for outlier modeling and has the potential to provide better predic - tion results . Note also that our method does not identify outliers explicitly , which reduces the risk of misclassiﬁcation and makes our method more general and more robust . In other words , our method is resilient to outliers . Considering that the QoS value of a Web service observed by a speciﬁc user may change over time , it is essential to provide time - aware personalized QoS prediction results . To achieve this goal , we further extend our method under the tensor factorization framework by taking the temporal infor - mation into consideration . In summary , the main contributions of this paper include : • First , we proposea robustWebservice QoSprediction method with outlier resilience . Our method measures the discrep - ancy between the observed QoS values and the predicted ones by Cauchy loss , which is robust to outliers . • Second , we extend our method to provide time - aware QoS prediction results under the tensor factorization framework by taking the temporal information into consideration . • Third , we conduct extensive experiments on both static and dynamic datasets toevaluate theperformance ofourmethod . The results demonstrate that our method can achieve better performance than state - of - the - art baseline methods . The remainder of this paper is organized as follows . Section 2 shows the unavoidability of outliers in QoS observations . Section 3 provides an overview on howmatrixfactorizationcan be employed for QoS prediction . Section 4 presents the detailed description of our method and its extension for time - aware QoS prediction . Sec - tion 5 reports the experimental results . Section 6 gives a brief re - view of the related work . This paper is ﬁnally concluded in Sec - tion 7 . 2 UNAVOIDABILITY OF QOS OUTLIERS Most existing QoS prediction methods assume that the QoS obser - vations are reliable and rational . However , this assumption may not hold in the real world . This is because the observed QoS data 0 20 40 60 80 100 Web Services 0 2 4 6 8 10 12 14 R e s p o n s e T i m e ( s ) User 1 User 2 User 3 ( a ) Response Time 0 20 40 60 80 100 Web Services 0 100 200 300 400 T h r o u g h p u t ( k bp s ) User 1 User 2 User 3 ( b ) Throughput 0 20 40 60 80 100 Users 0 2 4 6 8 10 R e s p o n s e T i m e ( s ) Web Service 1 Web Service 2 Web Service 3 ( c ) Response Time 0 20 40 60 80 100 Users 0 25 50 75 100 125 150 175 T h r o u g h p u t ( k bp s ) Web Service 1 Web Service 2 Web Service 3 ( d ) Throughput Figure 1 : The distribution of response time and throughput . can be aﬀected by many factors . For example , there may be some malicious users submitting wrong QoS values deliberately . The ser - vice providers may also pretend to be service users and thus exag - gerate the performance of their own Web services and depreciate the performance of their competitors’ Web services . In addition , the QoS values observed by users are largely dependent on the invocation environment such as network latency and server over - load , which may lead some of the QoS values to deviate far from the normal range . In consideration of these complicatedfactors , we argue that it is highly possible that some of the QoS observations are outliers . However , we are in lack of an oracle showing in advance which QoS observations are outliers . Here , we treat the rare extreme val - ues which signiﬁcantly diﬀer from the remaining ones as outliers by following the deﬁnition in [ 24 ] . To be more intuitive , in Figure 1 ( a ) and Figure 1 ( b ) , we show the distribution of both response time and throughput of 100 Web services invoked by 3 randomly se - lectedusers froma publiclyavailable dataset – WS - DREAM _ dataset1 2 . As can be seen , although a user tends to have diﬀerent usage expe - riences on diﬀerent Web services , most QoS values of these Web services observed by the three users fall into a normal range . For example , the response time mainly falls in the interval of [ 0 , 2 ] . However , there are also some observations deviating far from the normal range . As shown in Figure 1 ( a ) , the response time expe - rienced by user 2 even reaches up to 14 seconds , which is far be - yond the normal range . Needless to say , such kind of observations should be treated as outliers . We further demonstrate the distri - bution of response time and throughput of 3 Web services experi - enced by 100 diﬀerent users in Figure 1 ( c ) and Figure 1 ( d ) . It can be observed that although the usage experiences of a Web service can vary widely among diﬀerent users , the QoS values of the same Web service observed by the majority of users tend to fall into a normal range . Whereas , there are also some observations taking 2 https : / / github . com / wsdream / wsdream - dataset / tree / master / dataset1 2 values far beyond the normal range . These phenomena verify the rationality of treating extreme values as outliers and also reveal the unavoidability of outliers in QoS observations . 3 PRELIMINARIES Suppose that we are provided with a set of m users and a set of n Web services , then the QoS values between all users and Web ser - vices can be represented by a matrix X ∈ R m × n whose entry X ij denotes the QoS value of Web service j observed by user i . Obvi - ously , it is both time - consuming and resource - consuming for each user to invoke all Web services to get the personalized QoS val - ues . As a consequence , we typically have only partial observations between users and Web services , which means that lots of entries in X are null . The goal of QoS prediction is to predict these null entries by exploiting the information contained in existing obser - vations . 3 . 1 Problem Deﬁnition Let Ω denote the set of existing QoS observations , that is , Ω = { ( i , j , X ij ) | the QoS value X ij between user i and Web service j has been observed } . ( 1 ) Then the problem of QoS prediction is deﬁned as follows . Problem Statement : Given a set of QoS observations Ω , QoS prediction aims at predicting unknown QoS values by utilizing the information contained in Ω . 3 . 2 Matrix Factorization for QoS Prediction Matrixfactorizationis arguablythe mostpopularmodel - basedQoS prediction method at present [ 61 ] . Generally speaking , matrix fac - torization tries to factorize a given matrix into the product of sev - eral low - rank factor matrices . In the context of QoS prediction , the basic framework of MF - based methods is to factorize matrix X into two low - rank factor matrices U ∈ R m × l and S ∈ R n × l , i . e . , X ≈ US T . Here , each row of U represents the latent feature of a user , and each row of S represents the latent feature of a Web service . The dimensionality of latent features is controlled by pa - rameter l ( l ≪ min ( m , n ) ) . It is apparent that US T should be as close to X as possible , which means that in MF - based methods , the QoS values are determined by users’ latent features and Web ser - vices’ latent features simultaneously . More speciﬁcally , the rows of U and S imply the contribution to the corresponding QoS val - ues from user side and Web service side respectively [ 19 ] . In order to make US T approximate X well , there is no doubt that similar users and similar Web services should have similar latent features . Compared with memory - based QoS prediction methods that need to calculate similar users and similar Web services directly ( e . g . , calculating similarity according to Pearson correlation coeﬃcient ( PCC ) [ 65 , 72 ] ) , MF - based methods are able to capture the similar - ity automatically , which lends more ﬂexibility and generability to themselves . Based on the discussions above , we can derive the following gen - eral objective function for MF - based QoS prediction methods : min U , S L ( X , US T ) + λ L reд , ( 2 ) where L measures the degree of approximation between US T and X , L reд denotes the regularization term to avoid over - ﬁtting , and λ represents the regularization coeﬃcient . The most widely adopted loss function in matrix factorization is the least square loss ( i . e . , L 2 - norm loss ) , which is also the most commonly used loss function in MF - based QoS prediction methods [ 32 , 57 , 61 , 66 , 70 ] . In this setting , the speciﬁcobjective function can be clearly given as follows : min U , S 1 2 k I ⊙ ( X − US T ) k 22 + λ L reд , ( 3 ) where k · k 2 denotes the L 2 - norm which is calculated as the square root of the sum of squares of all entries , ⊙ denotes the Hadamard product ( i . e . , entry - wise product ) , and I ∈ R m × n denotes the indi - cator matrix whose entry I ij indicates whether the QoS value of Web service j has been observed by user i or not . If user i has the record of Web service j , I ij is set to 1 ; otherwise , it is set to 0 . The objective function based on L 2 - norm as in Eq . ( 3 ) is smooth and can be optimized by the gradient descent method [ 16 ] . How - ever , the L 2 - norm is sensitive to outliers ( i . e . , rare extreme values ) [ 63 ] . When the given observations contain outliers , the residuals between these outliers’ corresponding entries in X and their ap - proximation entries in US T become huge due to the square opera - tion . Therefore , when minimizing the objective function in Eq . ( 3 ) , more priorities are given to these outliers , which unfortunately causes severe approximation deviation of the normal QoS values . As a result , the QoS prediction performance may degrade dramat - ically . To make the model more robust to outliers , a common stategy is to replace L 2 - norm with L 1 - norm [ 14 , 23 , 51 , 70 ] . Based on L 1 - norm , the objective function is formularized as below : min U , S k I ⊙ ( X − US T ) k 1 + λ L reд , ( 4 ) where k · k 1 denotes the L 1 - norm which is calculated as the sum of the absolute values of all entries . Although L 1 - norm is to some ex - tent more robust to outliers than L 2 - norm , the objective function based on L 1 - norm as in Eq . ( 4 ) is a non - smooth function and it is much harder to optimize . What’s more , although the large resid - uals due to outliers are not squared in L 1 - norm , they may still be quite large relative to the normal ones and thus one would expect that they would inﬂuence the objective function as well [ 11 ] . 4 OUR METHOD As stated in the previous section , both L 1 - norm and L 2 - norm are sensitive to outliers . In order to make the MF - based methods more robusttooutliers , we proposeanovel QoSprediction methodwhich utilizes Cauchy loss [ 2 ] as the measurement of the discrepancy be - tween the observed QoS values and the predicted ones . It has been shown that Cauchy loss is resistant to outliers [ 17 , 37 , 55 ] . Thus our method is expected to be robust to outliers . 4 . 1 M - estimator Before presenting the details of our method , we ﬁrst introduce the concept of M - estimator . In robust statistics , M - estimators are a broad class of estimators , which represent the minima of particu - lar loss functions [ 21 ] . Let r i denote the residual of the i - th datum , 3 i . e . , the diﬀerence between the i - th observation and its approxi - mation . Then M - estimators try to optimize the following objective function : min Õ i д ( r i ) , ( 5 ) where function д gives the contribution of each residual to the ob - jective function . A reasonable function д should satisfy the follow - ing four properties [ 15 ] : • д ( x ) ≥ 0 , ∀ x ; • д ( x ) = д ( − x ) , ∀ x ; • д ( 0 ) = 0 ; • д ( x ) is non - decreasing in | x | , i . e . , д ( x 1 ) ≤ д ( x 2 ) , ∀ | x 1 | < | x 2 | . The inﬂuence function of д is deﬁned as its ﬁrst - order derivative : д ′ ( x ) = d д ( x ) d x . ( 6 ) The inﬂuence function д ′ measures the inﬂuence of each datum on the value of the parameter estimate . For a robust M - estimator , it would be inferred that the inﬂuence of any single datum is in - suﬃcient to yield any signiﬁcant oﬀset [ 55 ] . Ideally , a robust M - estimator should have a bounded inﬂuence function . Both L 2 - norm loss and L 1 - norm loss satisfy the four properties required by M - estimators . For the L 2 estimator with д ( x ) = 12 x 2 , the inﬂuence function is д ′ ( x ) = x , which means that the inﬂuence of a datum on the parameter estimate grows linearly as the error increases . This conﬁrms the non - robusteness of L 2 estimator to outliers . Although the L 1 estimator with д ( x ) = | x | can reduce the inﬂuence of large errors due to its bounded inﬂuence function , it will still be aﬀected by outliers since its inﬂuence function has no cut oﬀ point [ 28 , 55 ] ( | д ′ ( x ) | = 1 even when x → ±∞ ) . Besides , L 1 estimator is not stable because д ( x ) = | x | is not strictly convex in x . It follows that the inﬂuence function of a robust M - estimator should not only be bounded but also be insensitive to the increase of errors ( | д ′ ( x ) | → 0 when x → ±∞ ) . Cauchy estimator has been shown to possess such precious characteristics . The д function of Cauchy estimator ( i . e . , Cauchy loss ) is shown as follows : д ( x ) = ln (cid:18) 1 + x 2 γ 2 (cid:19) , ( 7 ) where γ is a constant . The inﬂuence function is then calculated as д ′ ( x ) = 2 x γ 2 + x 2 , ( 8 ) which takes value in the range of [ − 1 γ , 1 γ ] . Moreover , д ′ ( x ) tends to zero when x goes to inﬁnity . This indicates that the inﬂuence function ofCauchy estimatoris insensitive tothe increase oferrors . Therefore , Cauchy estimator is robust to outliers . A comparison of diﬀerent M - estimators is illustrated in Figure 2 . 4 . 2 Model Formulation In view of the robustness of Cauchy estimator , we choose Cauchy loss to construct the objective function of our method . Based on Cauchy loss , the objective function is derived as min U , S L = 1 2 m Õ i = 1 n Õ j = 1 I ij ln 1 + ( X ij − U i S Tj ) 2 γ 2 ! + λ u 2 k U k 22 + λ s 2 k S k 22 , ( 9 ) −4 −2 0 2 4 x 0 2 4 6 8 10 g 1 ( x ) = 0 . 5 x 2 g 2 ( x ) = | x | g 3 ( x ) = ln ( 1 + x 2 ) g 4 ( x ) = ln ( 1 + ( 5 x ) 2 ) g 5 ( x ) = ln ( 1 + ( 0 . 5 x ) 2 ) ( a ) The Loss Function −4 −2 0 2 4 x −4 −2 0 2 4 g ′ 1 ( x ) g ′ 2 ( x ) g ′ 3 ( x ) g ′ 4 ( x ) g ′ 5 ( x ) ( b ) The Inﬂuence Function Figure 2 : Comparison of diﬀerent M - estimators . where U i and S j denote the i - th row of U and the j - th row of S respectively , λ u and λ s represent the regularization coeﬃcients . The objective function in Eq . ( 9 ) can be eﬃciently optimized by the gradient descent method [ 16 ] . Speciﬁcally , we choose to opti - mize U and S row by row . Then , we have the following update rules : U i ← U i − η u ∂ L ∂ U i , ( 10 ) S j ← S j − η s ∂ L ∂ S j , ( 11 ) where η u and η s denote the learning rates for U and S , and ∂ L ∂ U i = λ u U i − n Õ j = 1 I ij X ij − U i S Tj γ 2 + ( X ij − U i S Tj ) 2 S j , ( 12 ) ∂ L ∂ S j = λ s S j − m Õ i = 1 I ij X ij − U i S Tj γ 2 + ( X ij − U i S Tj ) 2 U i . ( 13 ) The overall optimization procedure of our method is presented in Algorithm 1 , whose time complexity is shown in Theorem 1 . Theorem 1 . Let r denote the number of iterations for Algorithm 1 to achieve convergence and let ρ denote the number of available en - tries in X , then the time complexity of Algorithm 1 is O ( rρl ) . Proof . The main time cost of Algorithm 1 lies in the updates of U and S . In each iteration , updating U takes O ( ml + ρl ) time and updating S takes O ( nl + ρl ) time . Since both m and n are less than ρ , the time complexity of updating U and S can both be simpliﬁed as O ( ρl ) . Thus , the overall time complexity is of order O ( rρl ) . (cid:3) 4 . 3 Extension for Time - aware QoS Prediction As pointed out in [ 62 ] , the QoS performance of Web services is highly related to the invocation time because the service status ( e . g . , number of users ) and the network environment ( e . g . , network speed ) may change over time . Thus , it is essential to provide time - aware personalized QoS information to help users make service se - lection at runtime [ 68 ] . In this part , we aim to extend our method in order to make it suitable for time - aware personalized QoS pre - diction . To achieve the goal , we choose to extend our method under the tensor factorization framework . A tensor is a multidimensional or 4 Algorithm 1 Algorithm for Static QoS Prediction Input : X ∈ R m × n , l , γ , λ u , λ s , η u , η s ; Output : U ∈ R m × l , S ∈ R n × l ; 1 : Randomly initialize U and S ; 2 : repeat 3 : for i = 1 to m do 4 : Update U i according to Eq . ( 10 ) ; 5 : for j = 1 to n do 6 : Update S j according to Eq . ( 11 ) ; 7 : until Convergence 8 : return U , S ; N - way array [ 25 ] . An N - way tensor is denotedas X ∈ R I 1 × I 2 ×···× I N , which has N indices ( i 1 , i 2 , · · · , i N ) and its entries are denoted by X i 1 i 2 ··· i N . In this sense , a tensor can be treated as a generalized matrix and a matrix can also be treated as a two - way tensor . For time - aware QoS prediction , we need to take the temporal in - formation of QoS values into consideration . According to the def - inition of tensors , it is clear that we can model QoS observations with temporal information as a three - way tensor X ∈ R m × n × t whose each entry X ijk represents the QoS value of Web service j observed by user i at time k . Here , t denotes the total number of time intervals . Accordingly , we can use an indicator tensor I ∈ R m × n × t to show whether the QoS values have been observed or not . If user i has the record of Web service j at time k , I ijk is set to 1 ; otherwise , its value is set to 0 . To predict the unknown QoS val - ues in X , similar to MF - based methods , we ﬁrst factorize X to learn the latent features of users , Web services and contexts respectively , and then leverage the interaction among them to predict QoS val - ues . Speciﬁcally , we adopt the canonical polyadic ( CP ) decomposi - tion method [ 39 ] to factorize X into three low - rank factor matrices U ∈ R m × l , S ∈ R n × l and T ∈ R t × l . Then , X is approximated in the following way : X ≈ ˆ X = l Õ ℓ = 1 U ( ℓ ) ◦ S ( ℓ ) ◦ T ( ℓ ) , ( 14 ) where U ( ℓ ) ∈ R m , S ( ℓ ) ∈ R n and T ( ℓ ) ∈ R t denote the ℓ - th col - umn of U , S and T respectively , and ◦ represents the vector outer product . In this way , each entry X ijk is approximated by X ijk ≈ ˆ X ijk = l Õ ℓ = 1 U i ℓ S j ℓ T k ℓ . ( 15 ) In the literature , there are some approaches [ 34 , 60 , 62 ] resort - ing to tensor factorization for time - aware QoS prediction as well . However , none of these approaches have taken outliers into con - sideration . Besides , these approaches usually enforce nonnegative constraints on the factor matrices to promote the model’s inter - pretability . Following the same strategy , we also add nonnegative constraints toallthe factormatrices U , S and T . Then togetherwith the Cauchy loss , we derive the objective function for time - aware Algorithm 2 Algorithm for Time - aware QoS Prediction Input : X ∈ R m × n × t , l , γ , λ u , λ s , λ t ; Output : U ∈ R m × l , S ∈ R n × l , T ∈ R t × l ; 1 : Randomly initialize U ≥ 0 , S ≥ 0 and T ≥ 0 ; 2 : repeat 3 : for i = 1 to m do 4 : Update U i according to Eq . ( 17 ) ; 5 : for j = 1 to n do 6 : Update S j according to Eq . ( 18 ) ; 7 : for k = 1 to t do 8 : Update T k according to Eq . ( 19 ) ; 9 : until Convergence 10 : return U , S , T ; QoS prediction as below : min U , S , T L ′ = 1 2 m Õ i = 1 n Õ j = 1 t Õ k = 1 I ijk ln 1 + ( X ijk − ˆ X ijk ) 2 γ 2 ! + λ u 2 k U k 22 + λ s 2 k S k 22 + λ t 2 k T k 22 , s . t . U ≥ 0 , S ≥ 0 , T ≥ 0 , ( 16 ) where λ t denotes the regularization coeﬃcient for matrix T . Due to the nonnegative constraints , we cannot adopt the gradi - ent descent method to optimize the objective function in Eq . ( 16 ) any more . Alternatively , we use the multiplicative updating ( MU ) algorithm [ 27 ] tosolve Eq . ( 16 ) . To be more speciﬁc , MU alternately updates U , S and T with the other two being ﬁxed in each iteration . Although the objective function in Eq . ( 16 ) is nonconvex over U , S and T simultaneously , it is a convex function in each variable when the other two are ﬁxed . Thus we can derive a closed - form update rule for each variable under the Karush - Kuhn - Tucker ( KKT ) con - ditions [ 5 ] . The detailed update rules are listed as follows : U i ← U i ⊙ Í nj = 1 Í tk = 1 I ijk ∆ ijk X ijk ( S j ⊙ T k ) Í nj = 1 Í tk = 1 I ijk ∆ ijk ˆ X ijk ( S j ⊙ T k ) + λ u U i , ( 17 ) S j ← S j ⊙ Í mi = 1 Í tk = 1 I ijk ∆ ijk X ijk ( U i ⊙ T k ) Í mi = 1 Í tk = 1 I ijk ∆ ijk ˆ X ijk ( U i ⊙ T k ) + λ s S j , ( 18 ) T k ← T k ⊙ Í mi = 1 Í nj = 1 I ijk ∆ ijk X ijk ( U i ⊙ S j ) Í mi = 1 Í nj = 1 I ijk ∆ ijk ˆ X ijk ( U i ⊙ S j ) + λ t T k . ( 19 ) In the above Equations , ∆ ijk is deﬁned as ∆ ijk = 1 γ 2 + ( X ijk − ˆ X ijk ) 2 . Algorithm 2 summarizes the overall optimization procedure of our time - aware QoS prediction method . Since Algorithm 2 updates U , S and T alternately and each update decreases the objective function value monotonically , it is guaranteed to converge to a lo - cal minimal solution . The time complexity of Algorithm 2 is shown in Theorem 2 . Theorem2 . Let r ′ denotethenumberof iterationsfor Algorithm2 to achieve convergence and let ρ ′ denote the number of available en - tries in X , then the time complexity of Algorithm 2 is O ( r ′ ρ ′ l ) . Proof . The proof is similar to that of Theorem 1 . In each itera - tion , it takes O ( ρ ′ l ) time to update U , S and T . Therefore , the total time complexity of Algorithm 2 is of order O ( r ′ ρ ′ l ) . (cid:3) 5 Table 1 : Statistics of QoS Data Type QoS Attributes # User # Service # Time Range Mean Static Response Time ( s ) 339 5825 - 0 - 20 0 . 9086 Throughput ( kbps ) 339 5825 - 0 - 1000 47 . 5617 Dynamic Response Time ( s ) 142 4500 64 0 - 20 3 . 1773 Throughput ( kbps ) 142 4500 64 0 - 6727 11 . 3449 It is worthmentioning thatin bothAlgorithm 1and Algorithm2 , we do not detect outliers explicitly , thus our method will not suf - fer from the problem of misclassiﬁcation , which indicates that our method is more resilient and more robust to outliers . 5 EXPERIMENTS In this section , we conduct a set of experiments on both static QoS prediction and time - aware QoS prediction to evaluate the ef - ﬁciency and eﬀectiveness of our method by comparing it with sev - eral state - of - the - art QoS prediction methods . We implement our method and all baseline methods in Python 3 . 7 . And all the experi - ments are conducted on a server with two 2 . 4GHz Intel Xeon CPUs and 128GB main memory running Ubuntu 14 . 04 . 5 ( 64 - bit ) . 5 . 1 Datasets We conductallexperiments ona publiclyavailable datasetcollection – WS - DREAM 3 , which was collected from real - world Web services . WS - DREAM contains both static and dynamic QoS datasets . The static dataset describes real - world QoS measurements , including bothresponse time and throughputvalues , obtainedfrom 339users on 5825 Web services . The dynamic dataset describes real - world QoS measurements from 142 users on 4500 Web services over 64 consecutive time slices ( at 15 - minute interval ) . The dynamic dataset also includes records of both response time and throughput values . The statistics of the datasets are presented in Table 1 . 5 . 2 Evaluation Metrics The most commonly used evaluation metrics for QoS prediction include mean absolute error ( MAE ) [ 67 ] and root mean square er - ror ( RMSE ) [ 67 ] . Let Π denote the set of QoS values to be predicted ( i . e . , Π is the testing set ) and let N = | Π | , then MAE is calculated as MAE = Í q ∈ Π | q − ˆ q | N , ( 20 ) and RMSE is calculated as RMSE = s Í q ∈ Π ( q − ˆ q ) 2 N , ( 21 ) where ˆ q denotes the predicted value for the observation q . For both MAE and RMSE , smaller values indicate better performance . However , according to the deﬁnition of MAE and RMSE , we can see thatbothMAEandRMSEare sensitive tooutliers , which means that if Π contains outliers , then MAE and RMSE cannot truely re - ﬂect the QoS prediction performance . For example , suppose that q ∗ ∈ Π is an outlier , then in order to get small MAE value and RMSE value , the predicted ˆ q ∗ should be close to q ∗ rather than the normal QoS value . As thus , smaller MAE or RMSE value may not 3 https : / / github . com / wsdream / wsdream - dataset 0 100 200 300 Users 0 . 0 0 . 5 1 . 0 1 . 5 2 . 0 2 . 5 3 . 0 3 . 5 4 . 0 R e s p o n s e T i m e ( s ) Normal Outlier ( a ) Response Time 0 100 200 300 Users 0 5 10 15 20 25 30 35 40 T h r o u g h p u t ( k bp s ) Normal Outlier ( b ) Throughput Figure 3 : Exemplary outlier detection results by i Forest . really indicate better performance . To overcome this limitation , we eliminate outliers from Π when calculating MAE and RMSE . Note that we do not have groundtruth labels for outliers . Therefore , we need to detect outliers from scratch . To achieve this goal , we em - ploy the i Forest ( short for isolation forest ) method [ 30 , 31 ] for out - lier detection . i Forest detects outliers purely based on the concept of isolation without employing any distance or density measure , which makes i Forest quite eﬃcient and robust . i Forest will calcu - late an outlier score for each datum . The score takes value in the range of [ 0 , 1 ] and larger value indicates more possibility to be out - liers . Based on the outlier score , we can set the number of outliers ﬂexibly . To intuitively show the eﬀectiveness of i Forest , we report the outlier detection results of a randomly selected Web service from the static dataset in Figure 3 , where the outlier ratio is set to 0 . 05 . As can be seen , i Forest demonstrates good performance in outlier detection . It can detect both overinﬂated and underinﬂated outliers . 5 . 3 Baseline Methods For ease of presentation , we name our method for static QoS pre - diction as CMF and our method for time - aware QoS prediction as CTF hereafter . For static QoS prediction , we compare CMF with the following ﬁve methods : • MF 2 : MF 2 denotes the basic MF - basedQoSprediction method [ 66 ] and it measures the discrepancy between the observed QoS values and the predicted ones by L 2 - norm . • MF 1 : MF 1 is also an MF - based QoS prediction method [ 70 ] . However , it utilizes the L 1 - norm loss to construct the objec - tive function . MF 1 is expected to be more robust to outliers . Note that we implement MF 1 a little diﬀerently from the original one proposed in [ 70 ] . In our implementation , we ignore the privacy and location information . • CAP : CAP is a credibility - aware QoS prediction method [ 47 ] . It ﬁrst employs two - phase k - means clustering algo - rithmtoidentify untrustworthyusers ( i . e . , outliers ) , and then predicts unknown QoS values based on the clustering infor - mation contributed by trustworthy users . • TAP : TAP is a trust - aware QoS prediction method [ 45 ] . It aims to provide reliable QoS prediction results via calculat - ing the reputation of users by a beta reputation system and it identiﬁes outliers based on k - means clustering as well . 6 Table 2 : Performance Comparison with Diﬀerent Training Ratios on Static Dataset ( Best Results in Bold Numbers ) QoS Attributes Methods MAE RMSE 10 % 20 % 30 % 70 % 80 % 90 % 10 % 20 % 30 % 70 % 80 % 90 % Response Time MF 2 0 . 5334 0 . 4103 0 . 3534 0 . 3044 0 . 2921 0 . 2848 0 . 8407 0 . 6978 0 . 6195 0 . 5742 0 . 5565 0 . 5438 MF 1 0 . 4041 0 . 4037 0 . 4036 0 . 2815 0 . 2786 0 . 2798 0 . 6120 0 . 6106 0 . 6103 0 . 5590 0 . 5544 0 . 5505 CAP 0 . 3603 0 . 3521 0 . 3312 0 . 2282 0 . 2112 0 . 1881 0 . 6439 0 . 6640 0 . 6789 0 . 5815 0 . 5987 0 . 5821 TAP 0 . 3385 0 . 2843 0 . 2449 0 . 2477 0 . 2812 0 . 3189 0 . 5512 0 . 4985 0 . 4589 0 . 4687 0 . 5155 0 . 5665 DALF 0 . 3955 0 . 3439 0 . 3081 0 . 2496 0 . 2492 0 . 2397 0 . 7466 0 . 6779 0 . 5974 0 . 5471 0 . 5403 0 . 5388 CMF 0 . 1762 0 . 1524 0 . 1408 0 . 1153 0 . 1102 0 . 1085 0 . 3705 0 . 3599 0 . 3504 0 . 3106 0 . 2877 0 . 2699 Throughput MF 2 13 . 9730 12 . 3750 10 . 7753 7 . 8371 7 . 8255 7 . 8071 28 . 9608 26 . 8906 24 . 6608 19 . 6406 19 . 2831 18 . 6451 MF 1 16 . 5509 13 . 1105 10 . 7200 7 . 5736 7 . 3263 7 . 1115 33 . 8889 27 . 9648 23 . 6611 18 . 1316 17 . 9458 17 . 3698 CAP 16 . 4269 16 . 3125 16 . 1946 9 . 7147 8 . 6984 7 . 8516 32 . 9558 32 . 9334 32 . 9540 23 . 7955 22 . 2425 21 . 3711 TAP 22 . 1419 19 . 8273 17 . 8388 14 . 5786 14 . 8380 15 . 4028 43 . 4987 40 . 9533 38 . 8371 33 . 3052 32 . 4076 32 . 0935 DALF 13 . 1968 11 . 9619 10 . 6882 7 . 8156 7 . 7902 7 . 7771 27 . 8531 26 . 0299 24 . 4506 19 . 3523 18 . 9886 18 . 2965 CMF 8 . 4573 7 . 2501 6 . 4300 5 . 1865 5 . 1241 5 . 0078 24 . 9137 20 . 8927 18 . 8985 17 . 2916 17 . 1433 16 . 9388 • DALF : DALF is a data - aware latent factor model for QoS prediction [ 49 ] . It utilizes the density peaks based clustering algorithm [ 41 ] to detect unreliable QoS data directly . For time - aware QoS prediction , we compare our CTF with the following ﬁve methods : • NNCP : NNCP is a tensor - based time - aware QoS prediction method [ 60 ] . It is based on CP decomposition and it imposes nonnegative constraints on all the factor matrices . • BNLFT : BNLFT is a biased nonnegative tensor factorization model [ 34 ] . It incorporates linear biases into the model for describing QoS ﬂuctuations and it adds nonnegative con - straints to the factor matrices as well . • WLRTF : WLRTF is an MLE ( maximum likelihood estima - tion ) based tensor factorization method [ 9 ] . It models the noise of each datum as a mixture of Gaussian ( MoG ) . • PLMF : PLMF is an LSTM ( long short - term memory ) [ 20 ] based QoS prediction method [ 54 ] . PLMF can capture the dynamic latent representations of users and Web services . • TASR : TASR is a time - aware QoS prediction method [ 12 ] . It integrates similarity - enhanced collaborative ﬁltering model and the ARIMA model ( a time series analysis model ) [ 4 ] . Although MF 1 , CAP , TAP and DALF are able to deal with out - liers to some extent for static QoS prediction , to our best knowl - edge , our method CTF is the ﬁrst to take outliers into consideration for time - aware QoS prediction . It is also worth emphasizing that our method and all baseline methods ( except for CAP , TAP and DALF ) will not detect outliers explicitly when learning the predic - tion model . The reason for detecting outliers during the testing phase is to make MAE and RMSE able to truely reﬂect the QoS prediction performance . For all methods , outliers will be removed when calculating MAE and RMSE . In addition , in the experiments , we run each method 10 times and report the average results for fair comparison . 5 . 4 Experiments for Static QoS Prediction We ﬁrst conduct experiments for static QoS prediction . 5 . 4 . 1 Parameter Settings . In theexperiments , forallbaseline meth - ods , we tune the corresponding parameters following the guidance of the original papers . As for our method CMF , on the response time dataset , the parameters are set as l = 30 , γ = 1 , λ u = λ s = 1 , and η u = η s = 0 . 003 . On the throughput dataset , the parameters are set as l = 30 , γ = 20 , λ u = λ s = 0 . 01 , and η u = η s = 0 . 025 . For MF 2 , MF 1 and DALF , the feature dimensionality is also set to 30 . 5 . 4 . 2 Experimental Results . We ﬁrst report the results by varying the training ratios in the range of { 0 . 1 , 0 . 2 , 0 . 3 , 0 . 7 , 0 . 8 , 0 . 9 } . This is to simulate various prediction scenarios with diﬀerent data spar - sity . For example , when the training ratio is set to 0 . 1 , then 10 % of the dataset will be used as training data and the rest will be used as testing data . As aforementioned , during the testing phase , outliers should be eliminated explicitly . Here we set the outlier ratio to 0 . 1 , which means 10 % of the testing data that have large outlier scores will be removed when calculating MAE and RMSE . The detailed comparison results are presented in Table 2 . As can be seen , our method CMF consistently shows better performance than all base - line methods . Moreover , the MAE and RMSE values obtained by our method are much smaller than those of baseline methods , es - pecially on the response time dataset . For instance , CMF achieves more than 30 % performance promotion on response time over both MAE and RMSE . From Table 2 , we can also see that MF 1 , MF 2 , DALF and CMF tend to obtain smaller MAE and RMSE values as the training ratio increases . This is desired because larger train - ing ratio indicates that more QoS observations ( i . e . , more informa - tion ) will be used to train the prediction model . However , CAP and TAP do not show this pattern , especially on the response time dataset . We can also observe that although CAP , TAP and DALF ex - plicitly take outliers into consideration during the training phase , their performance is not satisfactory . The reason may be the mis - classiﬁcation of outliers . Since our method does not detect outliers directly during the training phase , it will not suﬀer from the mis - classiﬁcation issue . The resilience of our method to outliers makes it more robust . We then report the results by varying the outlier ratios in the range of { 0 . 02 , 0 . 04 , 0 . 06 , 0 . 08 , 0 . 1 , 0 . 2 } . In this experiment , thetrain - ing ratio is ﬁxed at 0 . 5 . The results are shown in Table 3 . From Ta - ble 3 , we can see that our method still shows the best performance under diﬀerent outlier ratios . It can also be observed that the MAE and RMSE values of all methods become smaller as the outlier ra - tio increases . This is reasonable because the larger the outlier ratio is , the more testing data with large outlier scores will be removed . 7 Table 3 : Performance Comparison with Diﬀerent Outlier Ratios on Static Dataset ( Best Results in Bold Numbers ) QoS Attributes Methods MAE RMSE 2 % 4 % 6 % 8 % 10 % 20 % 2 % 4 % 6 % 8 % 10 % 20 % Response Time MF 2 0 . 4080 0 . 3732 0 . 3533 0 . 3445 0 . 3306 0 . 3072 0 . 8040 0 . 7210 0 . 6711 0 . 6508 0 . 6021 0 . 5810 MF 1 0 . 3761 0 . 3390 0 . 3185 0 . 2972 0 . 2702 0 . 2525 0 . 7935 0 . 6903 0 . 6398 0 . 5918 0 . 5575 0 . 3744 CAP 0 . 4163 0 . 3657 0 . 3311 0 . 2997 0 . 2739 0 . 2413 0 . 9789 0 . 8375 0 . 7616 0 . 6817 0 . 6191 0 . 5258 TAP 0 . 4562 0 . 3788 0 . 3268 0 . 2703 0 . 2183 0 . 1649 1 . 1536 0 . 9393 0 . 8148 0 . 6475 0 . 4294 0 . 2478 DALF 0 . 3622 0 . 3217 0 . 3071 0 . 2890 0 . 2781 0 . 2480 0 . 7695 0 . 6728 0 . 6346 0 . 5975 0 . 5701 0 . 5132 CMF 0 . 2134 0 . 1758 0 . 1545 0 . 1384 0 . 1253 0 . 1019 0 . 6582 0 . 5001 0 . 4452 0 . 3811 0 . 3195 0 . 2347 Throughput MF 2 11 . 8832 10 . 7024 9 . 6776 9 . 0889 8 . 6373 8 . 1358 32 . 9795 28 . 5992 25 . 3608 22 . 9710 21 . 1042 18 . 5597 MF 1 12 . 3647 10 . 7403 9 . 8674 9 . 2223 8 . 7708 8 . 1667 32 . 9672 27 . 7982 24 . 4438 22 . 1691 20 . 2018 17 . 4015 CAP 18 . 2991 16 . 8273 15 . 5975 13 . 8889 13 . 6477 12 . 6762 45 . 9353 39 . 6390 35 . 5944 31 . 4784 29 . 2029 25 . 2830 TAP 22 . 0584 18 . 8479 16 . 9577 15 . 9026 15 . 1283 14 . 2151 58 . 5192 47 . 7490 41 . 6689 38 . 5700 35 . 2813 31 . 2779 DALF 11 . 8763 10 . 5724 9 . 1783 8 . 9276 8 . 6037 8 . 0449 32 . 8586 28 . 5797 24 . 8752 22 . 7428 20 . 9789 18 . 3713 CMF 8 . 3266 7 . 2138 6 . 5143 6 . 0463 5 . 5718 5 . 0177 30 . 5885 26 . 0933 22 . 9529 20 . 7105 17 . 8538 14 . 7925 10 20 30 40 50 60 70 80 Dimensionality 0 . 10 0 . 15 0 . 20 0 . 25 M A E Response Time o = 0 . 02 o = 0 . 1 ( a ) MAE 10 20 30 40 50 60 70 80 Dimensionality 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 R M S E Response Time o = 0 . 02 o = 0 . 1 ( b ) RMSE 10 20 30 40 50 60 70 80 Dimensionality 5 6 7 8 9 M A E Throughput o = 0 . 02 o = 0 . 1 ( c ) MAE 10 20 30 40 50 60 70 80 Dimensionality 15 20 25 30 35 R M S E Throughput o = 0 . 02 o = 0 . 1 ( d ) RMSE Figure 4 : Impact of dimensionality l on CMF ( with outlier ratio set to 0 . 02 and 0 . 1 ) . 0 . 1 0 . 5 1 5 10 20 50 Values of gamma 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 M A E Response Time o = 0 . 02 o = 0 . 1 ( a ) MAE 0 . 1 0 . 5 1 5 10 20 50 Values of gamma 0 . 3 0 . 6 0 . 9 1 . 2 1 . 5 R M S E Response Time o = 0 . 02 o = 0 . 1 ( b ) RMSE 0 . 1 0 . 5 1 5 10 20 50 Values of gamma 5 10 15 20 M A E Throughput o = 0 . 02 o = 0 . 1 ( c ) MAE 0 . 1 0 . 5 1 5 10 20 50 Values of gamma 10 20 30 40 50 60 70 R M S E Throughput o = 0 . 02 o = 0 . 1 ( d ) RMSE Figure 5 : Impact of parameter γ on CMF ( with outlier ratio set to 0 . 02 and 0 . 1 ) . Thus , the eﬀects of outliers on the calculation of MAE and RMSE will be reduced accordingly . From Table 3 , we can further obtain that with the increasing of outlier ratios , the performance promo - tion of CMF relative to MF 2 increases from 48 % to 67 % over MAE and from 18 % to 60 % over RMSE on the response time dataset . On the throughput dataset , the performance promotion also increases from 30 % to 38 % over MAE and from 7 % to 20 % over RMSE . The increase of performance promotion veriﬁes the necessity of remov - ing outliers during the testing phase . It also veriﬁes again the ro - bustness of our proposed method . 5 . 4 . 3 Impact of Dimensionality . The parameter dimensionality l controls the dimension of latent features in the factor matrices . To study the impact of l , we vary its value from 10 to 80 with a step size of 10 . In this experiment , the training ratio is ﬁxed at 0 . 5 and the outlier ratio ( denoted as o ) is set to 0 . 02 and 0 . 1 . The results are illustrated in Figure 4 . As we can see , both MAE and RMSE take smaller values when dimensionality l grows . This is because when l takes larger values , more features of users and Web services will be captured , thus resulting in more accurate prediction results . We also observe on the throughput dataset that the performance tends to be stable when l ≥ 40 , which indicates that l = 40 is suﬃcient for the factor matrices to well approximate the original matrix . 8 0 . 10 . 20 . 30 . 40 . 50 . 60 . 70 . 80 . 9 Training Ratio 0 . 10 0 . 15 0 . 20 0 . 25 0 . 30 M A E Response Time o = 0 . 02 o = 0 . 1 ( a ) MAE 0 . 10 . 20 . 30 . 40 . 50 . 60 . 70 . 80 . 9 Training Ratio 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 R M S E Response Time o = 0 . 02 o = 0 . 1 ( b ) RMSE 0 . 10 . 20 . 30 . 40 . 50 . 60 . 70 . 80 . 9 Training Ratio 6 8 10 12 14 M A E Throughput o = 0 . 02 o = 0 . 1 ( c ) MAE 0 . 10 . 20 . 30 . 40 . 50 . 60 . 70 . 80 . 9 Training Ratio 20 30 40 50 R M S E Throughput o = 0 . 02 o = 0 . 1 ( d ) RMSE Figure 6 : Impact of data sparsity on CMF ( with outlier ratio set to 0 . 02 and 0 . 1 ) . 5 . 4 . 4 Impact of Parameter γ . Recall that γ denotes the constant in the Cauchy loss . Here we study its impact on the performance of ourmethodbyvarying itsvalue in therange of { 0 . 1 , 0 . 5 , 1 , 5 , 10 , 20 , 50 } . In this experiment , the training ratio is ﬁxed at 0 . 5 and the outlier ratio o is set to 0 . 02 and 0 . 1 as well . The results are illustrated in Figure 5 . As can be seen , our method is sensitive to γ . This is due to that γ implicitly determines which data will be treated as outliers during the training phase . Thus we need to choose a proper γ to achieve the best performance . As shown in Figure 5 , γ should take value around 1 on the response time dataset and around 20 on the throughput dataset to obtain accurate prediction results . 5 . 4 . 5 Impact of Data Sparsity . To evaluate the performance of our method comprehensively , it is also necessary to investigate the im - pact of the sparsity of training data . To this end , we vary the train - ing ratio from 0 . 1 to 0 . 9 with a step size of 0 . 1 . Apparently , diﬀerent training ratio implies diﬀerent data sparsity . In this experiment , we also set the outlier ratio o to0 . 02 and 0 . 1 . The results are reportedin Figure 6 . From Figure 6 , we see that as the training ratio increases ( i . e . , the sparsity of data decreases ) , more accurate results are ob - tained . 5 . 5 Experiments for Time - aware QoS Prediction We now conduct experiments for time - aware QoS prediction . 5 . 5 . 1 Parameter Settings . In the experiments , we tune the param - eters of all baseline methods following the guidance of the origi - nal papers . As for our method CTF , on the response time dataset , the parameters are set as l = 15 and λ u = λ s = λ t = 0 . 1 . γ is set to 10 when calculating MAE and 35 when calculating RMSE . On the throughput dataset , the parameters are set as l = 15 and λ u = λ s = λ t = 100 . γ is ﬁxed at 5 for both MAE and RMSE . As for NNCP , BNLFT , WLRTF and PLMF , the feature dimensionality is also set to 15 . 5 . 5 . 2 Experimental Results . We ﬁrst report the results by varying the training ratios in the range of { 0 . 1 , 0 . 2 , 0 . 3 , 0 . 7 , 0 . 8 , 0 . 9 } and ﬁxing the outlier ratio at 0 . 1 . The results are presented in Table 4 . From Table 4 , we can see that our method consistently shows bet - ter performance than all baseline methods on both datasets . The results verify the robustness of our method in the time - aware ex - tension . M F 2 M F 1 C A P T A P D A L F C M F 0 500 1000 1500 2000 T i m e ( S e c o n d s ) ( a ) Static N N C P B N L F T W L R T F P L M F T A S R C T F 0 2000 4000 6000 8000 T i m e ( S e c o n d s ) ( b ) Dynamic Figure 7 : Runtime comparison on the response time dataset . We then report the results by varying the outlier ratios in the range of { 0 . 02 , 0 . 04 , 0 . 06 , 0 . 08 , 0 . 1 , 0 . 2 } and ﬁxing the training ra - tio at 0 . 5 . The results are shown in Table 5 , from which we observe that our method achieves better performance under diﬀerent out - lier ratios , which is similar to the results on the static dataset . 5 . 6 Eﬃciency Analysis In this section , we investigate the runtime eﬃciency of our method . In this experiment , we ﬁx the training ratio at 0 . 5 and the outlier ratio at 0 . 1 . The runtime of diﬀerent methods on the response time datasetis reportedin Figure 7 . On the static dataset , we can observe that CMF is very eﬃcient . Its runtime is comparable to that of MF 2 and MF 1 . It also runs much faster than CAP , TAP and DALF . On the dynamic dataset , although CTF runs slower than PLMF and TASR , it is faster than BNLFT and WLRTF , and it is comparable to NNCP . 6 RELATED WORK 6 . 1 Collaborative QoS Prediction Most existing QoS prediction methods fall into collaborative ﬁlter - ing methods [ 47 ] , which can be further divided into two categories : memory - based methods [ 6 , 7 , 22 , 42 , 67 ] and model - based meth - ods [ 40 , 44 , 51 , 53 , 59 ] . Memory - based methods predict unknown QoS values by employing the neighbourhood information of simi - lar users and similar Web services [ 65 ] , which further leads to user - based methods [ 6 ] , service - based methods [ 42 ] and hybrid meth - ods [ 7 , 22 , 67 ] that systematically combine the user - based methods and service - based methods . It is well known that memory - based methods usually suﬀer from the data sparsity problem [ 61 , 66 ] due to limited number of Web services a single user will invoke . Model - based methods are able to deal with the problem of data 9 Table 4 : Performance Comparison with Diﬀerent Training Ratios on Dynamic Dataset ( Best Results in Bold Numbers ) QoS Attributes Methods MAE RMSE 10 % 20 % 30 % 70 % 80 % 90 % 10 % 20 % 30 % 70 % 80 % 90 % Response Time NNCP 1 . 0796 1 . 0536 1 . 0550 1 . 0424 1 . 0406 1 . 0392 2 . 6401 2 . 5797 2 . 5809 2 . 5574 2 . 5668 2 . 5616 BNLFT 1 . 0828 1 . 0575 1 . 0467 1 . 0368 1 . 0556 1 . 0403 2 . 6181 2 . 5809 2 . 5682 2 . 5559 2 . 5731 2 . 5582 WLRTF 1 . 0560 1 . 0437 1 . 0288 1 . 0299 1 . 0218 1 . 0274 2 . 6009 2 . 5706 2 . 5642 2 . 5566 2 . 5571 2 . 5491 PLMF 2 . 6133 2 . 5932 2 . 4054 2 . 2097 2 . 1266 2 . 0247 4 . 5582 4 . 3536 4 . 3294 4 . 1843 3 . 9818 3 . 8542 TASR 2 . 8188 2 . 7120 2 . 5591 2 . 1184 2 . 0066 1 . 8854 6 . 3872 6 . 1807 5 . 9552 5 . 0212 4 . 8000 4 . 5447 CTF 0 . 9215 0 . 8981 0 . 8890 0 . 8860 0 . 8766 0 . 8750 2 . 5865 2 . 5579 2 . 5548 2 . 5529 2 . 5517 2 . 5401 Throughput NNCP 1 . 5079 1 . 4342 1 . 4287 1 . 3761 1 . 3708 1 . 3761 4 . 9207 4 . 7019 4 . 6404 4 . 5080 4 . 4484 4 . 4968 BNLFT 1 . 4241 1 . 3935 1 . 3791 1 . 3856 1 . 3695 1 . 3613 4 . 6031 4 . 4685 4 . 4537 4 . 4128 4 . 3595 4 . 3493 WLRTF 2 . 9576 2 . 9568 2 . 9564 2 . 9561 2 . 9562 2 . 9537 4 . 9161 4 . 9160 4 . 9165 4 . 9153 4 . 9159 4 . 9095 PLMF 2 . 4712 2 . 2602 2 . 4459 2 . 3328 2 . 4655 2 . 2329 3 . 6705 3 . 8363 3 . 8455 3 . 8209 3 . 7541 3 . 5119 TASR 4 . 3265 3 . 6419 3 . 4736 2 . 8803 2 . 8258 2 . 7417 5 . 9152 5 . 1844 5 . 0034 4 . 3744 4 . 3142 4 . 2709 CTF 1 . 3567 1 . 1945 1 . 1225 0 . 9907 0 . 9889 0 . 9782 3 . 0436 2 . 9225 2 . 8576 2 . 7732 2 . 6978 2 . 6178 Table 5 : Performance Comparison with Diﬀerent Outlier Ratios on Dynamic Dataset ( Best Results in Bold Numbers ) QoS Attributes Methods MAE RMSE 2 % 4 % 6 % 8 % 10 % 20 % 2 % 4 % 6 % 8 % 10 % 20 % Response Time NNCP 1 . 1846 1 . 1451 1 . 1069 1 . 0692 1 . 0521 1 . 0204 2 . 6740 2 . 6393 2 . 6023 2 . 5826 2 . 5805 2 . 5799 BNLFT 1 . 1647 1 . 1253 1 . 0871 1 . 0654 1 . 0475 0 . 9936 2 . 6499 2 . 6149 2 . 5771 2 . 5687 2 . 5659 2 . 5646 WLRTF 1 . 1436 1 . 1036 1 . 0562 1 . 0435 1 . 0261 0 . 9758 2 . 6438 2 . 6079 2 . 5696 2 . 5609 2 . 5584 2 . 5581 PLMF 2 . 6379 2 . 6011 2 . 5798 2 . 4241 2 . 3315 2 . 3162 5 . 2828 5 . 0571 4 . 7704 4 . 5917 4 . 2765 4 . 0729 TASR 2 . 5125 2 . 4326 2 . 3589 2 . 3363 2 . 3292 2 . 3019 5 . 4851 5 . 4510 5 . 4229 5 . 4018 5 . 3942 5 . 3877 CTF 1 . 0292 0 . 9813 0 . 9357 0 . 9105 0 . 8879 0 . 8448 2 . 6369 2 . 6015 2 . 5627 2 . 5564 2 . 5541 2 . 5503 Throughput NNCP 2 . 4853 2 . 0339 1 . 7508 1 . 5419 1 . 3926 1 . 0231 9 . 8925 7 . 6471 6 . 2757 5 . 2096 4 . 5026 2 . 8916 BNLFT 2 . 4335 1 . 9909 1 . 7163 1 . 5137 1 . 3693 1 . 0117 9 . 7267 7 . 4979 6 . 1664 5 . 1236 4 . 4319 2 . 8376 WLRTF 6 . 4309 4 . 8846 3 . 9224 3 . 3382 2 . 9562 2 . 0911 17 . 9461 11 . 6611 7 . 9882 5 . 9178 4 . 9156 3 . 1509 PLMF 5 . 3105 4 . 1556 3 . 0467 2 . 9632 2 . 3924 2 . 1807 13 . 7985 8 . 7995 6 . 6349 4 . 9651 3 . 8347 3 . 7906 TASR 5 . 7661 4 . 5595 3 . 8264 3 . 3965 3 . 1322 2 . 6317 14 . 8241 9 . 7143 6 . 8450 5 . 2958 4 . 6089 3 . 5886 CTF 2 . 2624 1 . 6385 1 . 3421 1 . 1437 1 . 0193 0 . 7323 9 . 5370 6 . 0759 4 . 3650 3 . 2415 2 . 7989 1 . 8020 sparsity , thus they have gained the most popularity [ 61 ] . Model - based methods usually train a predeﬁned prediction model based on existing QoS observations and then predict missing QoS val - ues . For example , Wu et al . [ 52 ] propose to train a factorization machine model for QoS prediction . Luo et al . [ 33 ] introduce fuzzy neural networks and adaptive dynamic programming to predict QoS values . Matrix factorization is also a model - based technique and it has obtained the most attention [ 32 , 44 , 53 , 61 , 66 ] . MF - based methods factorize the user - service matrix into two low - rank factor matrices with one factor matrix capturing the latent representa - tions of users and another revealing the latent representations of Web services . Therefore , MF - based methods are able to automati - cally model the contributions to a speciﬁc QoS value from user side and service side simultaneously , which usuallyresults in betterpre - diction performance . In addition , MF - based methods possess high ﬂexibility of incorporating side information such as location [ 19 ] , contexts [ 50 , 51 ] and privacy [ 29 ] . MF - based methods can also be easily generalized for time - aware QoS prediction under the tensor factorization framework [ 34 , 46 , 60 , 62 ] . There are also a few other kinds of time - aware QoS prediction methods like time series model based methods [ 1 , 12 ] and neural networks based methods [ 54 ] . 6 . 2 Reliable QoS Prediction Although there are various QoS prediction methods , few of them have taken outliers into consideration . However , as analyzed in Section 2 , some QoS observations indeed should be treated as out - liers . Thus , the performance of existing methods may not be reli - able . Forexample , mostexisting MF - based QoS prediction methods directly utilize L 2 - norm to measure the discrepancy between the observed QoS values and the predicted ones [ 32 , 44 , 50 , 53 , 57 , 66 ] . It is widely accepted that L 2 - norm is not robust tooutliers [ 8 , 35 , 58 , 63 , 64 , 69 ] . As a consequence , the performance of MF - based meth - ods may be severely inﬂuenced when QoS observations contain outliers . In order to obtain reliable QoS prediction results , it is necessary to take outliers into consideration . One popular method to reduce the eﬀects of outliers is replacing L 2 - norm with L 1 - norm because L 1 - norm is more robust to outliers [ 14 , 23 , 36 , 64 ] . For example , an L 1 - norm low - rank MF - based QoS prediction method is introduced in [ 70 ] . However , L 1 - norm - based objective function is non - smooth and thus much harder to optimize [ 35 , 56 ] . Besides , L 1 - norm is still sensitive to outliers especially when outliers are far beyond the normal range of QoS values [ 11 , 55 ] . Another line of reliable QoS prediction is detecting outliers ex - plicitly based on clustering algorithms . In [ 47 ] , Wu et al . propose 10 a credibility - aware QoS prediction method , which employs two - phase k - means clustering algorithmtoidentify untrustworthyusers ( i . e . , outliers ) . Su et al . [ 45 ] propose a trust - aware QoS prediction method , which provides reliable QoS prediction results via calcu - lating the reputation of users by a beta reputation system and iden - tiﬁes outliers based on k - means clustering as well . In [ 49 ] , a data - aware latent factor model is introduced , which utilizes the density peaks based clustering algorithm [ 41 ] to detect unreliable QoS val - ues . However , it is diﬃcult to choose a proper number of clusters , thus either some outliers may not be eliminated successfully or some normal values may beselected as outliersfalsely . Our method does not detect outliers explicitly , therefore it will not suﬀer from the misclassiﬁcation issue . 7 CONCLUSION In this paper , we have proposed a novel robust QoS prediction method , which utilizes Cauchy loss to measure the discrepancy between the observed QoS values and the predicted ones . Owing to the robustness of Cauchy loss , our method is resilient to out - liers . That is , there is no need to detect outliers explicitly . There - fore , our method will not suﬀer from the problem of misclassiﬁ - cation . Considering that the QoS performance may change over time , we have further extended our method to make it suitable for time - aware QoS prediction . To evaluate the eﬃciency and eﬀec - tiveness of our method , we have conducted extensive experiments on both static and dynamic datasets . Experimental results have demonstratedthatourmethodcan achieve betterperformance than existing methods . REFERENCES [ 1 ] Ayman Amin , Lars Grunske , and Alan Colman . 2012 . An automated approach to forecasting QoS attributes based on linear and non - linear time series model - ing . In Proceedings of the 27th IEEE / ACMInternational Conference on Automated Software Engineering ( ASE ) . ACM , 130 – 139 . [ 2 ] JonathanTBarron . 2019 . Ageneralandadaptiverobustlossfunction . In Proceed - ings of the IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) . 4331 – 4339 . [ 3 ] Athman Bouguettaya , Munindar Singh , Michael Huhns , Quan Z Sheng , Hai Dong , Qi Yu , Azadeh Ghari Neiat , Sajib Mistry , Boualem Benatallah , Brahim Medjahed , et al . 2017 . A service computing manifesto : the next 10 years . Com - mun . ACM 60 , 4 ( 2017 ) , 64 – 72 . [ 4 ] George EP Box and David A Pierce . 1970 . Distribution of residual autocorrela - tions in autoregressive - integrated moving average time series models . J . Amer . Statist . Assoc . 65 , 332 ( 1970 ) , 1509 – 1526 . [ 5 ] Stephen BoydandLievenVandenberghe . 2004 . Convexoptimization . Cambridge University Press . [ 6 ] John S Breese , David Heckerman , and Carl Kadie . 1998 . Empirical analysis of predictive algorithms for collaborativeﬁltering . In Proceedings of the Fourteenth ConferenceonUncertaintyinArtiﬁcialIntelligence ( UAI ) . MorganKaufmannPub - lishers Inc . , 43 – 52 . [ 7 ] Jie Cao , Zhiang Wu , Youquan Wang , and Yi Zhuang . 2013 . Hybrid collaborative ﬁltering algorithm for bidirectional Web service recommendation . Knowledge and Information Systems 36 , 3 ( 2013 ) , 607 – 627 . [ 8 ] XiangyongCao , YangChen , QianZhao , DeyuMeng , YaoWang , DongWang , and Zongben Xu . 2015 . Low - rank matrix factorization under general mixture noise distributions . In Proceedings of the IEEE International Conference on Computer Vision ( ICCV ) . 1493 – 1501 . [ 9 ] Xi’ai Chen , Zhi Han , Yao Wang , Qian Zhao , Deyu Meng , and Yandong Tang . 2016 . Robust tensor factorization with unknown noise . In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 5213 – 5221 . [ 10 ] Zhen Chen , Limin Shen , Feng Li , Dianlong You , and Jean Pepe Buanga Mapetu . 2020 . Web service QoS prediction : when collaborative ﬁltering meets data ﬂuc - tuating in big - range . World Wide Web ( 2020 ) , 1 – 26 . [ 11 ] Chris Ding and Bo Jiang . 2017 . L1 - norm error function robustness and outlier regularization . arXiv preprint arXiv : 1705 . 09954 ( 2017 ) . [ 12 ] Shuai Ding , Yeqing Li , Desheng Wu , Youtao Zhang , and Shanlin Yang . 2018 . Time - aware cloud service recommendation using similarity - enhanced collabo - rativeﬁlteringandARIMAmodel . DecisionSupportSystems 107 ( 2018 ) , 103 – 115 . [ 13 ] Joyce El Haddad , Maude Manouvrier , and Marta Rukoz . 2010 . TQoS : Transac - tional and QoS - aware selection algorithm for automatic Web service composi - tion . IEEE Transactions on Services Computing 1 ( 2010 ) , 73 – 85 . [ 14 ] Anders Eriksson and Anton Van Den Hengel . 2010 . Eﬃcient computation of robust low - rank matrix approximations in the presence of missing data using the L 1 norm . In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition ( CVPR ) . IEEE , 771 – 778 . [ 15 ] John Fox . 2002 . An R and S - Plus companion to applied regression . Sage . [ 16 ] Rainer Gemulla , Erik Nijkamp , Peter J Haas , and Yannis Sismanis . 2011 . Large - scale matrix factorization with distributed stochastic gradient descent . In Pro - ceedings ofthe 17thACMSIGKDDInternational Conference onKnowledge Discov - ery and Data Mining ( SIGKDD ) . ACM , 69 – 77 . [ 17 ] NaiyangGuan , TongliangLiu , YangmuziZhang , DachengTao , andLarrySDavis . 2017 . Truncated Cauchy non - negative matrix factorization . IEEE Transactions on Pattern Analysis and Machine Intelligence 41 , 1 ( 2017 ) , 246 – 259 . [ 18 ] FitriyahHasny , SamuelMensah , DeliangYi , ChuneLi , andRichongZhang . 2016 . Predicting the quality of Web servicesbased on userstability . In 2016IEEEInter - national Conference on Services Computing ( SCC ) . IEEE , 860 – 863 . [ 19 ] Pinjia He , Jieming Zhu , Zibin Zheng , Jianlong Xu , and Michael R Lyu . 2014 . Location - based hierarchical matrix factorization for Web service recommenda - tion . In 2014 IEEE International Conference on Web Services ( ICWS ) . IEEE , 297 – 304 . [ 20 ] Sepp Hochreiter and JürgenSchmidhuber . 1997 . Long short - termmemory . Neu - ral Computation 9 , 8 ( 1997 ) , 1735 – 1780 . [ 21 ] Peter J Huber . 2011 . Robust statistics . Springer . [ 22 ] YechunJiang , JianxunLiu , Mingdong Tang , andXiaoqingLiu . 2011 . Aneﬀective Web servicerecommendation method basedon personalized collaborativeﬁlter - ing . In 2011IEEEInternationalConferenceonWebServices ( ICWS ) . IEEE , 211 – 218 . [ 23 ] Qifa Ke and Takeo Kanade . 2005 . Robust L / sub 1 / norm factorization in the pres - ence of outliers and missing data by alternative convex programming . In 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition ( CVPR ) , Vol . 1 . IEEE , 739 – 746 . [ 24 ] Minjung Kim , Byungkook Oh , Jooik Jung , and Kyong - Ho Lee . 2016 . Outlier - robust Web service selection based on a probabilistic QoS model . International Journal of Web and Grid Services 12 , 2 ( 2016 ) , 162 – 181 . [ 25 ] Tamara G Kolda and Brett W Bader . 2009 . Tensor decompositions and applica - tions . SIAM Rev . 51 , 3 ( 2009 ) , 455 – 500 . [ 26 ] Yehuda Koren , Robert Bell , and Chris Volinsky . 2009 . Matrix factorization tech - niques for recommender systems . Computer 8 ( 2009 ) , 30 – 37 . [ 27 ] Daniel D Lee and H Sebastian Seung . 2001 . Algorithms for non - negative matrix factorization . In Advances in Neural Information Processing Systems ( NIPS ) . 556 – 562 . [ 28 ] Xuelong Li , QuanmaoLu , Yongsheng Dong , andDachengTao . 2018 . Robustsub - space clustering by Cauchyloss function . IEEETransactionson Neural Networks and Learning Systems 30 , 7 ( 2018 ) , 2067 – 2078 . [ 29 ] An Liu , Xindi Shen , Zhixu Li , Guanfeng Liu , JiajieXu , LeiZhao , Kai Zheng , and Shuo Shang . 2018 . Diﬀerential private collaborative Web services QoS predic - tion . World Wide Web ( 2018 ) , 1 – 24 . [ 30 ] Fei Tony Liu , Kai Ming Ting , and Zhi - Hua Zhou . 2008 . Isolation forest . In 2008 Eighth IEEE International Conference on Data Mining ( ICDM ) . IEEE , 413 – 422 . [ 31 ] Fei Tony Liu , Kai Ming Ting , and Zhi - Hua Zhou . 2012 . Isolation - based anomaly detection . ACM Transactions on Knowledge Discovery from Data ( TKDD ) 6 , 1 ( 2012 ) , 3 . [ 32 ] Wei Lo , Jianwei Yin , Ying Li , and Zhaohui Wu . 2015 . Eﬃcient Web service QoS prediction using local neighborhood matrix factorization . Engineering Applica - tions of Artiﬁcial Intelligence 38 ( 2015 ) , 14 – 23 . [ 33 ] XiongLuo , YixuanLv , RuixingLi , andYiChen . 2015 . WebserviceQoSprediction basedonadaptivedynamicprogrammingusingfuzzyneuralnetworksforcloudservices . IEEE Access 3 ( 2015 ) , 2260 – 2269 . [ 34 ] Xin Luo , HaoWu , HuaqiangYuan , andMengChuZhou . 2019 . Temporalpattern - aware QoS prediction via biased non - negative latent factorization of tensors . IEEE Transactions on Cybernetics ( 2019 ) , 1 – 12 . [ 35 ] Deyu Meng and Fernando De La Torre . 2013 . Robust matrix factorization with unknown noise . In Proceedings of the IEEEInternational Conference on Computer Vision ( ICCV ) . 1337 – 1344 . [ 36 ] Deyu Meng , Zongben Xu , Lei Zhang , and Ji Zhao . 2013 . A cyclic weighted median method for l1 low - rank matrix factorization with missing entries . In Twenty - Seventh AAAI Conference on Artiﬁcial Intelligence ( AAAI ) . 704 – 710 . [ 37 ] Ivan Mizera and Christine H Müller . 2002 . Breakdown points of Cauchy regression - scaleestimators . Statistics & Probability Letters 57 , 1 ( 2002 ) , 79 – 89 . [ 38 ] Michael P Papazoglou , Paolo Traverso , Schahram Dustdar , and Frank Leymann . 2007 . Service - orientedcomputing : Stateoftheartandresearchchallenges . Com - puter 40 , 11 ( 2007 ) , 38 – 45 . [ 39 ] Stephan Rabanser , Oleksandr Shchur , and Stephan Günnemann . 2017 . Introduc - tion to tensor decompositions and their applications in machine learning . arXiv 11 preprint arXiv : 1711 . 10781 ( 2017 ) . [ 40 ] SarathkumarRangarajan . 2018 . Qos - based Web service discovery and selection using machine learning . arXiv preprint arXiv : 1807 . 01439 ( 2018 ) . [ 41 ] Alex Rodriguez and Alessandro Laio . 2014 . Clusteringby fast searchand ﬁnd of density peaks . Science 344 , 6191 ( 2014 ) , 1492 – 1496 . [ 42 ] Badrul Munir Sarwar , George Karypis , Joseph A Konstan , John Riedl , et al . 2001 . Item - based collaborativeﬁltering recommendation algorithms . WWW 1 ( 2001 ) , 285 – 295 . [ 43 ] LingshuangShao , Jing Zhang , Yong Wei , Junfeng Zhao , Bing Xie , and Hong Mei . 2007 . Personalized QoS prediction for Web services via collaborative ﬁltering . In IEEE International Conference on Web Services ( ICWS ) . IEEE , 439 – 446 . [ 44 ] Kai Su , Liangli Ma , Bin Xiao , and Huaiqiang Zhang . 2016 . Web service QoS predictionbyneighborinformationcombinednon - negativematrixfactorization . Journal of Intelligent & Fuzzy Systems 30 , 6 ( 2016 ) , 3593 – 3604 . [ 45 ] Kai Su , Bin Xiao , Baoping Liu , Huaiqiang Zhang , and Zongsheng Zhang . 2017 . TAP : A personalized trust - aware QoS prediction approach for Web service rec - ommendation . Knowledge - Based Systems 115 ( 2017 ) , 55 – 65 . [ 46 ] Qingxian Wang , Minzhi Chen , Mingsheng Shang , and Xin Luo . 2019 . A momentum - incorporated latent factorization of tensors model for temporal - aware QoS missing data prediction . Neurocomputing 344 ( 2019 ) , 299 – 307 . [ 47 ] Chen Wu , Weiwei Qiu , Zibin Zheng , Xinyu Wang , and Xiaohu Yang . 2015 . QoS prediction of Webservicesbasedon two - phasek - meansclustering . In 2015IEEE International Conference on Web Services ( ICWS ) . IEEE , 161 – 168 . [ 48 ] Di Wu , Qiang He , Xin Luo , Mingsheng Shang , Yi He , and Guoyin Wang . 2019 . APosterior - neighborhood - regularizedLatent FactorModel forHighly Accurate Web Service QoS Prediction . IEEE Transactionson Services Computing ( 2019 ) . [ 49 ] DiWu , XinLuo , MingshengShang , YiHe , GuoyinWang , andXindong Wu . 2019 . A data - awarelatent factormodel forWeb serviceQoSprediction . In Paciﬁc - Asia Conference on Knowledge Discovery and Data Mining ( PAKDD ) . Springer , 384 – 399 . [ 50 ] Hao Wu , Kun Yue , Bo Li , Binbin Zhang , and Ching - Hsien Hsu . 2018 . Collabora - tive QoS prediction with context - sensitive matrix factorization . Future Genera - tion Computer Systems 82 ( 2018 ) , 669 – 678 . [ 51 ] Hao Wu , Zhengxin Zhang , Jiacheng Luo , Kun Yue , and Ching - Hsien Hsu . 2018 . Multiple attributes QoS prediction via deep neural model with contexts . IEEE Transactions on Services Computing ( 2018 ) . [ 52 ] Yaoming Wu , Fenfang Xie , Liang Chen , Chuan Chen , and Zibin Zheng . 2017 . An embedding based factorization machine approach for Web service QoS prediction . In International Conference on Service - Oriented Computing ( ICSOC ) . Springer , 272 – 286 . [ 53 ] Qi Xie , Shenglin Zhao , Zibin Zheng , Jieming Zhu , and Michael R Lyu . 2016 . Asymmetriccorrelation regularizedmatrixfactorizationforWeb servicerecom - mendation . In 2016 IEEE International Conference on Web Services ( ICWS ) . IEEE , 204 – 211 . [ 54 ] Ruibin Xiong , Jian Wang , Zhongqiao Li , Bing Li , and Patrick CK Hung . 2018 . PersonalizedLSTMbasedmatrixfactorizationforonline QoSprediction . In 2018 IEEE International Conference on Web Services ( ICWS ) . IEEE , 34 – 41 . [ 55 ] Chang Xu , Dacheng Tao , and Chao Xu . 2015 . Multi - view intact space learn - ing . IEEETransactionson Pattern Analysis and Machine Intelligence 37 , 12 ( 2015 ) , 2531 – 2544 . [ 56 ] Huan Xu , Constantine Caramanis , and Shie Mannor . 2012 . Sparse algorithms are not stable : A no - free - lunch theorem . IEEE Transactions on Pattern Analysis and Machine Intelligence 34 , 1 ( 2012 ) , 187 – 193 . [ 57 ] Jianlong Xu , Zibin Zheng , and Michael R Lyu . 2016 . Web service personalized quality of service prediction via reputation - based matrix factorization . IEEE Transactions on Reliability 65 , 1 ( 2016 ) , 28 – 37 . [ 58 ] Shuang Xu , Chunxia Zhang , and Jiangshe Zhang . 2020 . Adaptive Quantile Low - Rank Matrix Factorization . Pattern Recognition ( 2020 ) , 107310 . [ 59 ] Yatao Yang , Zibin Zheng , Xiangdong Niu , Mingdong Tang , Yutong Lu , and Xi - angkeLiao . 2018 . Alocation - based factorizationmachinemodel forWebservice QoS prediction . IEEE Transactions on Services Computing ( 2018 ) . [ 60 ] Wancai Zhang , Hailong Sun , Xudong Liu , and Xiaohui Guo . 2014 . Temporal QoS - aware Web service recommendation via non - negative tensor factorization . In Proceedings of the 23rd International Conference on World Wide Web ( WWW ) . ACM , 585 – 596 . [ 61 ] Yiwen Zhang , Kaibin Wang , Qiang He , Feifei Chen , Shuiguang Deng , Zibin Zheng , and Yun Yang . 2019 . Covering - basedWeb service quality prediction via neighborhood - aware matrix factorization . IEEE Transactions on Services Com - puting ( 2019 ) . [ 62 ] Yilei Zhang , Zibin Zheng , and Michael R Lyu . 2011 . WSPred : A time - awareper - sonalized QoS prediction framework for Web services . In 2011 IEEE 22nd Inter - national Symposium on Software Reliability Engineering ( ISSRE ) . IEEE , 210 – 219 . [ 63 ] QianZhao , DeyuMeng , ZongbenXu , WangmengZuo , and YanYan . 2015 . L _ { 1 } - normlow - rankmatrixfactorizationbyvariationalBayesianmethod . IEEETrans - actions on Neural Networks and Learning Systems 26 , 4 ( 2015 ) , 825 – 839 . [ 64 ] Yinqiang Zheng , Guangcan Liu , Shigeki Sugimoto , Shuicheng Yan , and Masatoshi Okutomi . 2012 . Practical low - rank matrix approximation under ro - bust l 1 - norm . In 2012 IEEE Conference on Computer Vision and Pattern Recogni - tion ( CVPR ) . IEEE , 1410 – 1417 . [ 65 ] Zibin Zheng and Michael R Lyu . 2010 . Collaborative reliability prediction of service - oriented systems . In 2010 ACM / IEEE 32nd International Conference on Software Engineering ( ICSE ) , Vol . 1 . IEEE , 35 – 44 . [ 66 ] ZibinZheng andMichaelRLyu . 2013 . PersonalizedreliabilitypredictionofWeb services . ACM Transactions on Software Engineering and Methodology ( TOSEM ) 22 , 2 ( 2013 ) , 12 . [ 67 ] Zibin Zheng , Hao Ma , Michael R Lyu , and Irwin King . 2011 . Qos - aware Web servicerecommendation bycollaborativeﬁltering . IEEETransactionsonServices Computing 4 , 2 ( 2011 ) , 140 – 152 . [ 68 ] Jieming Zhu , Pinjia He , Zibin Zheng , and Michael R Lyu . 2017 . Online QoS predictionforruntimeserviceadaptationviaadaptivematrixfactorization . IEEE Transactions on Parallel and Distributed Systems 28 , 10 ( 2017 ) , 2911 – 2924 . [ 69 ] Rui Zhu , Di Niu , and Zongpeng Li . 2017 . Robust Web service recommendation via quantile matrix factorization . In IEEE 2017 International Conference on Com - puter Communications ( INFOCOM ) . IEEE , 1 – 9 . [ 70 ] Xiaoke Zhu , Xiao - Yuan Jing , Di Wu , Zhenyu He , Jicheng Cao , Dong Yue , and Lina Wang . 2018 . Similarity - maintaining privacy preservation and location - aware low - rank matrix factorization for QoS prediction based Web service rec - ommendation . IEEE Transactions on Services Computing ( 2018 ) . [ 71 ] Zhiliang Zhu , Haitao Yuan , Jie Song , Jing Bi , and Guoqi Liu . 2010 . WS - SCAN : A eﬀective approach for Web services clustering . In 2010 International Conference on Computer Application and System Modeling ( ICCASM ) , Vol . 5 . IEEE , 618 – 622 . [ 72 ] Guobing Zou , Ming Jiang , Sen Niu , Hao Wu , Shengye Pang , and Yanglan Gan . 2018 . QoS - aware Web service recommendation with reinforced collaborative ﬁltering . In International Conference on Service - Oriented Computing ( ICSOC ) . Springer , 430 – 445 . 12