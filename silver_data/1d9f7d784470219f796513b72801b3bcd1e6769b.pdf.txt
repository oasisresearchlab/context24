Meeting in the notebook : a notebook - based environment for micro - submissions in data science collaborations MICAH J . SMITH , Massachusetts Institute of Technology , USA JÜRGEN CITO , TU Wien , Austria and Massachusetts Institute of Technology , USA KALYAN VEERAMACHANENI , Massachusetts Institute of Technology , USA Developers in data science and other domains frequently use computational notebooks to create exploratory analyses and prototype models . However , they often struggle to incorporate existing software engineering tooling into these notebook - based workflows , leading to fragile development processes . We introduce Assemblé , a new development environment for collaborative data science projects , in which promising code fragments of data science pipelines can be contributed as pull requests to an upstream repository entirely from within JupyterLab , abstracting away low - level version control tool usage . We describe the design and implementation of Assemblé and report on a user study of 23 data scientists . CCS Concepts : • Human - centered computing → Interactive systems and tools ; Collaborative and social computing systems and tools ; • Software and its engineering ; Additional Key Words and Phrases : collaborative data science , computational notebooks , notebook extensions 1 INTRODUCTION Software engineering is a mature discipline with robust processes for team - based development , including version control tools , build tools , documentation generators , unit test frameworks , linters and formatters , and code review interfaces . Taken together , these tools address or prevent a wide class of issues in collaborative software development and make the resulting processes much more robust . Although diverse types of practitioners write code , there has traditionally been a divide between the processes used by software engineers and those used by other developers , such as data scientists . Data scientists in particular often do exploratory data analysis and prototyping within a computational notebook , such as Jupyter Notebook or its successor , JupyterLab [ 13 ] . These “notebook - based” developers then productionize completed analyses , either by themselves or together with specialized teammates . The exploratory code may be refactored , made more efficient and modular , or rewritten in a different framework or to target a different runtime . This two - stage development process presents challenges for developers that are not as fluent in using development tools , and makes the resulting software vulnerable to quality issues . In response , researchers have proposed a variety of improvements to the data science development process . One recent idea is Ballet , a software framework that supports collaborative data science development by composing a data science pipeline from a collection of modular patches that can be written in parallel [ 22 ] . Within the larger practice of data science , Ballet focuses on predictive machine learning ( ML ) , and more specifically , feature engineering , a key subprocess in which raw variables are transformed into useful features suitable for learning . Thus developers might split up work to write individual feature definitions in short code snippets , while the Ballet framework is responsible for structuring contributions , validating them in the context of the prediction task , and composing them into an executable feature engineering pipeline . Typically , a developer contributing to a Ballet project ( or other kinds of data science projects ) does exploratory work in a notebook before finally identifying a worthwhile patch to contribute . By this time , their notebook may be “messy” [ 11 ] and the process to extract the relevant patch and translate it into a well - structured contribution to a shared 1 a r X i v : 2103 . 15787v1 [ c s . H C ] 29 M a r 2021 Micah J . Smith , Jürgen Cito , and Kalyan Veeramachaneni Submit from ballet import b X _ raw , y _ raw = b . api . load _ data ( ) [ 1 ] from ballet import Feature input = ' FHINS3C ' transformer = None feature = Feature ( input , transformer ) b . validate _ feature _ api ( feature ) INFO - Building features and target . . . INFO - Building features and target . . . DONE INFO - Feature is NOT valid ; here is some advice for resolving the feature API issues . INFO - NoMissingValuesCheck : When transforming sample data , the feature produces NaN values . If you reasonably expect these missing values , make sure you clean missing values as an additional step in your transformer list . For example : NullFiller ( replacement = replacement ) False [ 1 ] [ 8 ] [ 8 ] [ 24 ] [ 24 ] 1 2 + from ballet import Feature + from ballet . eng import NullFiller + input = ' FHINS3C ' + t r ansformer = NullFiller ( replacement = 1 . 0 ) + feature = Feature ( input , transformer ) src / predict _ x / features / contrib / user _ bob / feature . py src / predict _ x / features / contrib / user _ bob / _ _ init _ _ . py Empty ﬁle . Propose new feature # 37 Open bob wants to merge 1 commit into alice / ballet - predict - x from bob / ballet - predict - x : submit - feature Fig . 1 . A overview of the Assemblé development environment . Assemblé’s frontend ( left ) extends JupyterLab to add a Submit button and a GitHub authentication button to the Notebook toolbar ( top right ) . Users first authenticate Assemblé with GitHub using a supported OAuth flow . Then , after developing a patch within a larger , messy notebook , users select the code cell containing their desired patch using existing Notebook interactions ( 1 ) and press Assemblé’s Submit button ( 2 ) to cause it to be automatically formulated as a pull request by the backend . ( 2 ) . The backend performs initial static analysis and validation of the intended submission and then creates a well - structured PR containing the patch ( right ) . Taken together , the components of Assemblé support the patch contribution task for notebook - based developers . repository becomes a challenge . Developers usually need to rely on a completely separate set of tools for this process , jettisoning the notebook for command line or GUI tools targeting team - based version control . This patch contribution task is challenging even for developers experienced with open - source practices [ 10 ] , and is only more acute for data science developers who are less familiar with open - source development workflows . To address this challenge , we propose a novel development environment , Assemblé . 1 , 2 Assemblé solves the patch contribution task to data science collaborations that use Ballet 3 by providing a higher - level interface for contributing code snippets within a larger notebook to an upstream repository — meeting data science developers where they are most comfortable . Rather than asking developers to productionize their exploratory notebooks , Assemblé enables data scientists to both develop and contribute back their code without leaving the notebook . A code fragment selected by a developer can be automatically formulated as a pull request ( PR ) to an upstream GitHub repository using an interface situated within the notebook environment itself , automating and abstracting away usage of low - level tools for testing and team - based development . It integrates tightly with Binder , 4 a community service for cloud - hosted notebooks , so that developers can get started with no setup required . In this paper , we describe the ideation , design , and implementation of a development environment that supports notebook - based collaborative data science . We then report on a user study of 23 developers using Assemblé in a data science collaboration case study . Finally , we discuss future directions for interfaces and workflows to support collaborative data science development . 1 https : / / github . com / ballet / ballet - assemble 2 Assemblé is a ballet move that involves lifting off the floor on one leg and landing on two . 3 Assemblé targets contributions to Ballet projects because of the structure that these projects impose on code contributions , but can be extended to support other settings as well . 4 https : / / mybinder . org / 2 A notebook - based environment for micro - submissions in data science collaborations 2 BACKGROUND AND RELATED WORK 2 . 1 Collaborative data science Researchers have observed that large collaborations in data science are rare compared to traditional software develop - ment , even as the field continues to grow and mature [ 5 ] . In data science development , one approach to collaboration is to coordinate around a shared work product , such as a data science pipeline [ 6 ] . However the scale of previous collaborations has not approached what is regularly observed in open - source software development . Ballet is a framework that builds on approaches to facilitating collaboration between data scientists by carefully structuring a data science pipeline as a composition of smaller modules that can be developed separately [ 22 ] . The creation of these small components can be done in parallel by different contributors who then introduce a patch to the upstream project defining this new component . For example , as data science is an expansive and rapidly growing field , Ballet focuses on predictive machine learning and an important subprocess called feature engineering , in which developers write code to transform raw variables into useful features suitable for learning algorithms . In such a feature engineering project , a feature engineering pipeline is composed of features ; this pipeline is grown incrementally by patches / pull requests to the repository that contain feature definitions . Thus developers might split up work to write individual feature definitions in short code snippets , in much the same way that they would split up work in fixing bugs or implementing new functionality in a traditional software project . The framework imposes a structure on the repository ( i . e . feature definitions are written in individual Python source files at a specific path ) and is then able to collect many feature definitions into a single feature engineering pipeline . It is also responsible for validating contributions using a custom suite of statistical and software tests . Other data scientists can freely install and use this collaboratively written feature engineering pipeline on their data that follows the same schema . Ballet leaves open the subsequent question of supporting data science developers in the process of creating feature definitions . One naïve workflow that is available to software development experts is to use their usual low - level command line tools to manually structure their patches and make pull requests to the shared project repository [ 9 ] . However , this workflow is challenging and discouraging for many data science developers . Assemblé fills this gap by allowing notebook - based developers to transparently contribute their work from within a notebook environment to a shared repository without exposing any low - level tools . 2 . 2 Exploratory data analysis Similar to other data analysis tasks , creating a new feature definition is an iterative process in which data scientists explore patterns in the raw data , hypothesize about possible relationships , and evaluate potential transformations . Data scientists frequently use computational notebooks like Jupyter for exploratory analyses [ 13 , 15 ] . However , functionality that is popular for exploratory work , such as interleaving code input and rich outputs and executing code cells in arbitrary orders , can can lead to analyses that are difficult to share , understand , reproduce , or productionize [ 4 , 14 , 24 ] . One response to this situation is to try to make the tools used in team - based software engineering more common in data science settings [ 1 , 26 , 27 ] , such as those for version control , testing , and building . These tools may be used more easily if they are embedded within the primary development environment , so both JupyterLab and other IDEs offer support for applying git operations , either natively or in extensions [ 18 , 21 ] . However , the challenge of using git remains , albeit with a different visual interface . In contrast to these tools , while Assemblé is backed by git , it operates at a higher level of abstraction and its users never interact with git directly . 3 Micah J . Smith , Jürgen Cito , and Kalyan Veeramachaneni Researchers and practitioners have also built new tools that extend the functionality of existing tools to additional formats and settings . These include version control and provenance of notebooks and datasets , as well as other artifacts such as figures and learned model parameters ; test frameworks for notebooks ; and language extensions to support notebooks as libraries within a larger application [ 8 , 17 ] . Another approach is to attempt to improve the notebook experience itself with these issues in mind . For example , Head et al . [ 11 ] introduce code - gathering tools in a JupyterLab extension . With these tools , a notebook user can select certain content from a messy notebook , such as a variable assignment or displayed figure , and identify the set of code cells needed to produce that value along with the order in which they were executed . These can then be exported to a “clean” notebook . Other notebook extensions allow notebook users to track past analysis choices [ 12 ] or join with other developers for synchronous editing [ 25 ] . 2 . 3 Learning data science A separate line of related work inverts this problem and asks about challenges for non - ML experts learning ML . In the case of software developers , it is a lack of mathematical and theoretical background that causes hurdles [ 3 ] , rather than difficulties using software development processes as in our case . For other non - experts , common pitfalls include challenges in formulating learning problems and over - reliance on headline performance metrics [ 27 ] . 3 DESIGN To investigate development workflow issues in Ballet , we first conducted a formative study with eight data scientists recruited from a laboratory mailing list at a large research university . We asked them to write and submit feature definitions for a collaborative project based around predicting the incidence rates of dengue fever in two different regions . Although participants created feature definitions successfully , we observed that they struggled to contribute them to the shared repository using the pull request model , with only two creating a pull request at all . In interviews , participants acknowledged that a lack of familiarity and experience with the pull request - based model of open source development was an obstacle to contributing the code that they had written , especially in the context of team - based development [ 10 ] . In this study , and in other experiments with Ballet , we observed that data scientists predominately used notebooks to develop feature definitions before turning to entirely different environments and tools to extract the smallest relevant patch and create a pull request . We thus identified the patch contribution task as an important interface problem to address in order to improve collaborative data science . Once working code has been written , we may be able to automate the entire process of code contribution according to the requirements of the specific project the user is working on . With this in mind , we elicited the following design criteria to support patch contribution in a collaborative data science environment . D1 Make code easy to contribute . Once a patch has been identified , it should be easy to immediately contribute it without a separate process to productionize it . D2 Hide low - level tools . Unfamiliarity and difficulty with low - level tooling and processes , such as git and the pull request model , tend to interrupt data scientists’ ability to collaborate on a shared repository . Any solution to submitting patches should not include manual use of these tools . D3 Minimize setup and installation friction . Finally , the solution should fit seamlessly within users’ existing develop - ment workflows , and should be easy to setup and install . 4 A notebook - based environment for micro - submissions in data science collaborations Post cell contents to / assemble / submit Assemblé frontend Assemblé backend 1 GitHub Select code cell and press “Submit” button 2 3 Run static analysis of code for errors Detect and load Ballet project Fork upstream repo and clone to / tmp Commit changes to conﬁgured path Push to feature branch Propose pull request with default description 4 5 6 7 8 9 Render link to resulting PR Assemblé backend github - oauth - gateway GitHub Assemblé frontend Start OAuth ﬂow R e d i r ec t t o O A u t h l og i n p a g e w i t h s ec r e t s t a t e Send access token and secret Prompt for token Request user credentials Generate secret Store secret - token pair Poll for token associated with secret 1 3 2 5 4 2 6 1 Fig . 2 . The Assemblé environment includes both Jupyter frontend and server extensions . Completed code snippets are submitted directly to an upstream GitHub repository as pull requests ( left ) . Users authenticate with GitHub using an accompanying OAuth proxy server ( right ) . Based on these criteria , we propose a design that extends the notebook interface to support submission of individual code cells as pull requests . By focusing on individual code cells , we allow developers to easily isolate relevant code to submit . Once a user has selected a code cell using existing Notebook interactions , pressing a simple , one - click “Submit” button added to the Notebook Toolbar panel spurs the creation and submission of a patch according to the configuration of the underlying project . By abstracting away the low - level details of this process , we lose the ability to identify some code quality issues that would otherwise be identified by the tooling . To address this , we run an initial server - side validation using static analysis before forwarding on the patch , in order to immediately surface relevant problems to users within the notebook context . If submission is successful , the contributor can view their new PR in a matter of seconds . Assemblé is tightly integrated with Binder such that it can be launched from every Ballet project via a README badge . Installation of the extension is handled automatically and the project settings are automatically detected so that developers can get right to work . An in - notebook , OAuth - based authentication flow also allows developers to easily authenticate with GitHub without difficult configuration . In summary , we design Assemblé to provide the following functionality : • isolate relevant code snippets from a messy notebook • transparently provide access to take actions on GitHub • automatically formulate an isolated snippet as a PR to an upstream data science project without exposing any git details 4 IMPLEMENTATION Assemblé is implemented in three components : a JupyterLab frontend extension , a JupyterLab server extension , and an OAuth proxy server . These are shown in Figure 2 . 5 Micah J . Smith , Jürgen Cito , and Kalyan Veeramachaneni 4 . 1 JupyterLab extension The frontend extension is implemented in TypeScript on JupyterLab 2 . It adds two buttons to the Notebook Panel toolbar . The GitHub button allows the user to initiate an authentication flow with GitHub ( Section 4 . 2 ) . The Submit button identifies the currently selected code cell from the active notebook and extracts the source . It then posts the contents to the server to be submitted ( D1 ) . If the submission is successful , it displays a link to the GitHub pull request view . Otherwise , it shows a relevant error message – usually a Python traceback due to syntax errors in the user’s code . The server extension is implemented in Python on Tornado 6 . It adds routes to the Jupyter Server under the / assemble prefix . These include / assemble / submit to receive the code to be submitted , and three routes under / assemble / auth to handle the authentication flow with GitHub . Upon extension initialization , it detects a Ballet project by ascending the file system , via the current working directory looking for the ballet . yml file and loading the project using the ballet library according to that configuration . When the server extension receives the code to be submitted , it first runs a static analysis using Python’s ast module to ensure that it does not have syntax errors or undefined symbols , and automatically cleans / reformats the code to the target project’s preferred style . It then prepares to submit it as a pull request . The upstream repository is determined from the project’s settings and is forked , if needed , via the pygithub interface to the GitHub API with the user’s OAuth token , and cloned to a temporary directory . Using the Ballet client library , Assemblé can create an empty file at the correct path in the directory structure that will contain the proposed contribution , and writes to and commits this file . Depending on whether the user has contributed in the past , Assemblé may then also need to create additional files / folders to preserve the Python package structure ( i . e . _ _ init _ _ . py files ) . It then pushes to a new branch on the fork , and creates a pull request with a default description . Finally , it returns the pull request view link . This replaces what is usually 5 - 7 manual git operations with a robust and automated process ( D2 ) . 4 . 2 GitHub authentication The final piece of the puzzle is authentication with GitHub , such that the server can act on GitHub as the user to create a new pull request . Most extensions that provide similar functionality ( i . e . take some actions with an external service on behalf of a user that require authentication ) ask the user to acquire a personal access token from the external service and provide it as a configuration variable , and in some cases register a web application using a developer console [ 19 , 20 ] . For our purposes , this is not acceptable , due to the high cost of setup for non - expert software developers ( D2 , D3 ) . Instead , we would like to use OAuth [ 16 ] to allow the user to enter their username and password for the service , and exchange them for a token that the server can use . However , this cannot be accomplished directly using the OAuth protocol because OAuth applications on GitHub ( or elsewhere ) must register a static callback URL . Instead , Assemblé might be running at any address , because with its Binder integration , the URLs assigned to Binder sessions are dynamic and on different domains . 5 To address this , we create github - oauth - gateway , a lightweight proxy server for GitHub OAuth . 6 We create a reference deployment on Heroku and register it as an OAuth application with GitHub . Before the user can submit their code , they click the GitHub icon in the toolbar ( Figure 1 ) . This launches the OAuth flow . First the server creates a secret “state” at random . Then it redirects the user to the GitHub OAuth login page . The user is prompted to enter their username and password , and if the sign - in is successful , GitHub responds to the gateway with 5 For example , launching the same repository in a Binder can result in first a hub . gke . mybinder . org URL and then an notebooks . gesis . org URL , depending on the BinderHub deployment selected by the MyBinder load balancer . 6 https : / / github . com / ballet / github - oauth - gateway 6 A notebook - based environment for micro - submissions in data science collaborations the token and the state created previously . The server polls the gateway for a token associated with its unique state , and receives the token in response when it is available . 5 EVALUATION We report our analysis of a user study in which 23 participants used Assemblé to develop and submit feature definitions to a shared repository as part of a collaborative project . We aim to assess the ability of users to successfully create pull requests for code snippets within a messy notebook and to identify key themes from participants’ experiences . 5 . 1 Procedures The predict - census - income project 7 is a collaborative effort to predict personal income from responses to the U . S . Census American Community Survey ( ACS ) . As part of a larger effort to understand collaborative data science practices [ 22 ] , we recruited developers to use the Ballet framework to develop and share feature definitions that would be predictive of personal income . In recruiting participants , we wanted to ensure that all participant backgrounds were represented : beginner / intermediate / expert developers in data science , software , and survey data analysis ( the problem domain ) . Participants were entered into a drawing for several nominal prizes but were not otherwise compensated . In total , 27 developers were recruited after sampling personal contacts with a variety of backgrounds , posting to relevant mailing lists and message boards , and then using snowball sampling to reach more participants with similar backgrounds . Of these , 23 participants used Assemblé ( v0 . 7 . 2 ) to develop their code and submit it to the shared repository . Participants first completed a short questionnaire in which they self - reported their background in data science and open - source software development and their preferred development environments for data science tasks . Participants were also asked to consent to telemetry data collection . If they did , we instrumented Assemblé to collect detailed usage data on their development sessions , their use of the Submit button functionality , and their use of the Ballet client library . After completing their feature development , participants were also asked to take a short survey about their use of Assemblé , its features , and their overall experience with the project , and were invited to share free - response feedback . We linked survey responses and telemetry data , and then removed all identifying information . Two researchers also qualitatively analyzed participants’ free - response feedback using open and axial coding [ 2 ] . 5 . 2 Results Only five participants reported a preference for performing data science activities and Python development in notebook environments before the study , with 10 instead preferring IDEs and four preferring text editors . Seven participants had never contributed to open - source projects at all , while the remainder reported contributing approximately yearly ( eight ) , monthly ( four ) , or weekly ( four ) . Fifteen participants opted into telemetry data collection , generating an average of 33 telemetry events each . A summary of participant background is shown in Figure 3 . 5 . 3 Quantitative Result Our main finding is that even with their diverse backgrounds and initial preferences , all participants in the study successfully used Assemblé to create one or more pull requests to the upstream project repository . According to telemetry data , the modal user pressed the Submit button just once . Since the user study task was to submit a single feature , this suggests that users were immediately successful at creating a pull request for their desired contribution . We also find 7 https : / / github . com / HDI - Project / ballet - predict - census - income 7 Micah J . Smith , Jürgen Cito , and Kalyan Veeramachaneni that participants were able to do this fairly quickly – half were able to create a pull request using Assemblé in three minutes or less ( Figure 3b ) . In 16 cases out of 45 submit events captured in the telemetry data ( belonging to five unique users ) , Assemblé’s static analysis identified syntax errors in the intended submissions , each of which would have led to a pull request that would have failed Ballet’s automated test suite . In all of these cases , users were able to quickly resolve these errors and submit again . 5 . 4 Qualitative Results From a qualitative perspective , we identified two major themes from free text responses in our post - participation survey . Keep It Simple While Introducing Better Affordances . Users overwhelmingly noted the simplicity with which they were able to submit their features , with one participant noting “The process of integrating the new feature was very smooth " and another saying “ [ Submitting a feature ] was extremely and springily easy ! Most rewarding part " . However , some participants noted that while the submission process was seamless , affordances could be better highlighted , e . g . : “Maybe highlight a bit more that you need to select the feature cell before hitting submit - I got confused after I missed this part " . Indeed , in the few cases where participants were not able to submit their feature on their first attempt , we see in our telemetry data that they either selected the wrong cell or introduced a syntax error . Tensions between Abstraction and Submission Transparency . Submission transparency was another theme that emerged in our analysis . While we achieved our goal of hiding the lower - level procedures required in the pull request model , some participants were curious about the underlying process . Some wanted to know how their feature was evaluated , both in server - side validation and in continuous integration after pull request creation : “It was not clear whether my feature was actually good , especially compared to other features . " Others expressed a lack of understanding of what was going on " under the hood : " “I didn’t fully understand how Assemblé was working on the backend to actually develop the feature with relatively straightforward commands , but it seemed to work pretty well . " This feedback highlights the tension between abstraction and transparency . While users clearly appreciated the simplicity facilitated by the submission mechanism , they missed the traceability and feedback a more classical pull request model would have provided . We see this as an opportunity to introduce optionally available traces detailing the steps of the underlying process , partly as a way of onboarding non - experts into the open - source development workflow . 6 DISCUSSION AND CONCLUSION For developers to select the code to submit , we rely upon simple existing interactions provided by Jupyter ( i . e . select one cell , select multiple cells ) . However , as some developers requested better affordances , other interactions could be incorporated . For example , code gathering tools [ 11 ] could provide the means to more easily select the code to be submitted , while staying within the notebook environment . One reason ( of many ) that powerful developer tools exist for team - based version control is to avoid and / or resolve merge conflicts when contributions are often scattered across multiple files . By tightly coupling with Ballet projects , we take advantage of the structure those projects impose on contributions : they are in single Python modules at well - defined locations in the directory structure . By relaxing this assumption , or by defining such structures for other settings , Assemblé could be used more generally to contribute patches to central locations . For example , the ML Bazaar framework [ 23 ] organizes data science pipelines into a graph of “ML primitives , ” each of which requires experts to create and validate the primitive ( a JSON annotation of some underlying implementation ) in a notebook . Assemblé could be used to extract the completed primitive and submit it to the project’s curated catalog of community primitives . 8 A notebook - based environment for micro - submissions in data science collaborations Data Science Software Development Domain expertise 0 3 6 9 12 15 c o un t Beginner Intermediate Expert ( a ) Background of 23 developers using Assemblé in a study involving predicting personal income . 0 2 4 6 8 10 12 Minutes spent - Submitting Features 0 1 2 3 4 5 C o un t ( b ) Distribution of total minutes spent submitting features to upstream repository . Fig . 3 . User study results . As another example , an educator running an introductory programming class could invite students to submit their implementations of a basic algorithm to a joint hosting repository , such that they could share in the code review process and learn from the implementations of others . Similarly , a Python language extension for sharing simple functions [ 7 ] could use the functionality of the development environment to share functions , rather than requiring the manual addition of function decorators . In this paper , we presented the design and implementation of the Assemblé development environment . We showed how this environment vastly improves the efficiency and experience of developers collaborating on a data science pipeline using the Ballet framework , and how the use of JupyterLab extensions allows developers to share code without leaving the notebook . ACKNOWLEDGMENT We’d like to thank the participants of the ballet - predict - census - income study . This work is supported in part by NSF Award 1761812 . REFERENCES [ 1 ] Saleema Amershi , Andrew Begel , Christian Bird , Robert DeLine , Harald Gall , Ece Kamar , Nachiappan Nagappan , Besmira Nushi , and Thomas Zimmermann . 2019 . Software Engineering for Machine Learning : A Case Study . In 2019 IEEE / ACM 41st International Conference on Software Engineering : Software Engineering in Practice ( ICSE - SEIP ) . IEEE , Montreal , QC , Canada , 291 – 300 . https : / / doi . org / 10 . 1109 / ICSE - SEIP . 2019 . 00042 [ 2 ] Andreas Böhm . 2004 . Theoretical Coding : Text Analysis in . A companion to qualitative research 1 ( 2004 ) . [ 3 ] Carrie J . Cai and Philip J . Guo . 2019 . Software Developers Learning Machine Learning : Motivations , Hurdles , and Desires . In 2019 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . IEEE , Memphis , TN , USA , 25 – 34 . https : / / doi . org / 10 . 1109 / VLHCC . 2019 . 8818751 [ 4 ] Souti Chattopadhyay , Ishita Prasad , Austin Z . Henley , Anita Sarma , and Titus Barik . 2020 . What’s Wrong with Computational Notebooks ? Pain Points , Needs , and Design Opportunities . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . ACM , Honolulu HI USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3313831 . 3376729 [ 5 ] Joohee Choi and Yla Tausczik . 2017 . Characteristics of Collaboration in the Emerging Practice of Open Data Analysis . ACM Press , 835 – 846 . https : / / doi . org / 10 . 1145 / 2998181 . 2998265 [ 6 ] Kevin Crowston , Jeff S . Saltz , Amira Rezgui , Yatish Hegde , and Sangseok You . 2019 . Socio - Technical Affordances for Stigmergic Coordination Implemented in MIDST , a Tool for Data - Science Teams . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( Nov . 2019 ) , 1 – 25 . 9 Micah J . Smith , Jürgen Cito , and Kalyan Veeramachaneni https : / / doi . org / 10 . 1145 / 3359219 [ 7 ] Ethan Fast and Michael S . Bernstein . 2016 . Meta : Enabling Programming Languages to Learn from the Crowd . In Proceedings of the 29th Annual Symposium on User Interface Software and Technology - UIST ’16 . ACM Press , 259 – 270 . https : / / doi . org / 10 . 1145 / 2984511 . 2984532 [ 8 ] Julien Gori , Han L . Han , and Michel Beaudouin - Lafon . 2020 . FileWeaver : Flexible File Management with Automatic Dependency Tracking . In Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology . ACM , Virtual Event USA , 22 – 34 . https : / / doi . org / 10 . 1145 / 3379337 . 3415830 [ 9 ] GeorgiosGousios , MartinPinzger , andArievanDeursen . 2014 . AnExploratoryStudyofthePull - BasedSoftwareDevelopmentModel . In Proceedingsof the36thInternationalConferenceonSoftwareEngineering - ICSE2014 . ACMPress , Hyderabad , India , 345 – 355 . https : / / doi . org / 10 . 1145 / 2568225 . 2568260 [ 10 ] Georgios Gousios , Andy Zaidman , Margaret - Anne Storey , and Arie Van Deursen . 2015 . Work practices and challenges in pull - based development : the integrator’s perspective . In 2015 IEEE / ACM 37th IEEE International Conference on Software Engineering , Vol . 1 . IEEE , 358 – 368 . [ 11 ] Andrew Head , Fred Hohman , Titus Barik , Steven M . Drucker , and Robert DeLine . 2019 . Managing Messes in Computational Notebooks . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . ACM , New York , NY , USA , Article 270 , 12 pages . [ 12 ] Mary Beth Kery , Bonnie E . John , Patrick O’Flaherty , Amber Horvath , and Brad A . Myers . 2019 . Towards Effective Foraging by Data Scientists to Find Past Analysis Choices . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . ACM , Glasgow Scotland Uk , 1 – 13 . https : / / doi . org / 10 . 1145 / 3290605 . 3300322 [ 13 ] Mary Beth Kery and Brad A . Myers . 2017 . Exploring exploratory programming . In 2017 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . 25 – 29 . https : / / doi . org / 10 . 1109 / VLHCC . 2017 . 8103446 [ 14 ] Mary Beth Kery , Marissa Radensky , Mahima Arya , Bonnie E . John , and Brad A . Myers . 2018 . The Story in the Notebook : Exploratory Data Science Using a Literate Programming Tool . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems ( CHI ’18 ) . Association for Computing Machinery , New York , NY , USA , 1 – 11 . https : / / doi . org / 10 . 1145 / 3173574 . 3173748 [ 15 ] Michael Muller , Ingrid Lange , Dakuo Wang , David Piorkowski , Jason Tsay , Q . Vera Liao , Casey Dugan , and Thomas Erickson . 2019 . How Data Science Workers Work with Data : Discovery , Capture , Curation , Design , Creation . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 15 . https : / / doi . org / 10 . 1145 / 3290605 . 3300356 [ 16 ] OAuth Working Group . 2012 . The OAuth 2 . 0 Authorization Framework . RFC 6749 . RFC Editor . https : / / www . rfc - editor . org / rfc / rfc6749 [ 17 ] Dean Pleban . 2020 . Announcing Data Science Pull Requests . https : / / dagshub . com / blog / data - science - pull - requests / . [ 18 ] Project Jupyter Contributors . [ n . d . ] . JupyterLab Git . https : / / github . com / jupyterlab / jupyterlab - git . Accessed on 2021 - 03 - 24 ( commit 267c149 ) . [ 19 ] Project Jupyter Contributors . [ n . d . ] . JupyterLab GitHub . https : / / github . com / jupyterlab / jupyterlab - github . Accessed on 2021 - 01 - 10 ( commit 065aa44 ) . [ 20 ] Project Jupyter Contributors . [ n . d . ] . jupyterlab - google - drive . https : / / github . com / jupyterlab / jupyterlab - google - drive . Accessed on 2021 - 01 - 10 ( commit ab727c4 ) . [ 21 ] Amit Rathi . [ n . d . ] . JupyterLab GitPlus . https : / / github . com / ReviewNB / jupyterlab - gitplus . Accessed on 2021 - 03 - 24 ( commit c6cfa76 ) . [ 22 ] Micah J . Smith , Jürgen Cito , Kelvin Lu , and Kalyan Veeramachaneni . 2020 . Enabling Collaborative Data Science Development with the Ballet Framework . arXiv : 2012 . 07816 [ cs ] ( December 2020 ) . arXiv : 2012 . 07816 [ cs ] [ 23 ] Micah J . Smith , Carles Sala , James Max Kanter , and Kalyan Veeramachaneni . 2020 . The Machine Learning Bazaar : Harnessing the ML Ecosystem for Effective System Development . In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data ( SIGMOD ’20 ) . Association for Computing Machinery , Portland , OR , USA , 785 – 800 . https : / / doi . org / 10 . 1145 / 3318464 . 3386146 [ 24 ] Krishna Subramanian , Nur Hamdan , and Jan Borchers . 2020 . Casual Notebooks and Rigid Scripts : Understanding Data Science Programming . In 2020 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . 1 – 5 . https : / / doi . org / 10 . 1109 / VL / HCC50065 . 2020 . 9127207 [ 25 ] April Yi Wang , Anant Mittal , Christopher Brooks , and Steve Oney . 2019 . How Data Scientists Use Computational Notebooks for Real - Time Collaboration . Proceedings of the ACM on Human - Computer Interaction 3 , CSCW ( Nov . 2019 ) , 1 – 30 . https : / / doi . org / 10 . 1145 / 3359141 [ 26 ] G . Wilson . 2006 . Software Carpentry : Getting Scientists to Write Better Code by Making Them More Productive . Computing in Science & Engineering 8 , 6 ( Nov . 2006 ) , 66 – 69 . https : / / doi . org / 10 . 1109 / MCSE . 2006 . 122 [ 27 ] Qian Yang , Jina Suh , Nan - Chen Chen , and Gonzalo Ramos . 2018 . Grounding Interactive Machine Learning Tool Design in How Non - Experts Actually Build Models . Proceedings of the 2018 on Designing Interactive Systems Conference 2018 - DIS ’18 ( 2018 ) , 573 – 584 . https : / / doi . org / 10 . 1145 / 3196709 . 3196729 10