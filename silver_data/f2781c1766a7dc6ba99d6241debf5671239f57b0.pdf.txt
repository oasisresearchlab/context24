Embodied Companion Technologies for Autistic Children Katharina Spiel , Julia Makhaeva , Christopher Frauenberger Vienna Technical University Vienna , Austria [ katharina . spiel ] [ julia . makhaeva ] [ christopher . frauenberger ] @ tuwien . ac . at ABSTRACT With few exceptions , technology for autistic children tends to be focused on the regulation of perceived deﬁcits . With OutsideTheBox we focus on the strengths of the children as design partners and created in our ﬁrst year four technological objects together with them . They all have common that they are embedded in the children’s lives and share some degree of embodied interaction . We present a case study along with four objects , two of them with wearable components , two of them focused at sharing experiences in an embodied mode . This opens up the argument not only for more design actu - ally led by autistic children , but also for companion technolo - gies that embody situatedness . Such technologies are then not driven by an outsider’s perspective of what an autistic child needs , but rather are intrinsically valuable to them as a user . Author Keywords Embodiment ; Case Studies ; Prototypes ; Autism ; Children ; Co - Design ACM Classiﬁcation Keywords H . 5 . m . Information Interfaces and Presentation ( e . g . HCI ) : Miscellaneous INTRODUCTION A majority of technologies for autistic children 1 is not only ﬁxated at functional performance , but also set in static con - texts with video , virtual reality , desktop or web applications ( cf . [ 15 ] or [ 1 ] ) . While the number of applications for tablets and smartphones constantly rises , research into tan - gible , sensor - based or wearable technologies such as by [ 24 ] or [ 8 ] is rare . Furthermore , autistic children are systemati - cally not included in the design process ; however , exceptions can be found in [ 9 ] or [ 14 ] . 1 Several self - advocated statements refer to the use of person - ﬁrst language as not reﬂecting their own feeling about themselves ( see , e . g . , [ 20 ] ) . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , topostonserversortoredistributetolists , requirespriorspeciﬁcpermission and / or a fee . Request permissions from Permissions @ acm . org . TEI ’16 , February 14 - 17 , 2016 , Eindhoven , Netherlands Copyright is held by the owner / author ( s ) . Publication rights licensed to ACM . ACM 978 - 1 - 4503 - 3582 - 9 / 16 / 02 $ 15 . 00 DOI : http : / / dx . doi . org / 10 . 1145 / 2839462 . 2839495 Our project , OutsideTheBox , aims to show the viability of both , including autistic children in the design process and cre - ating smart objects with them . Calls for inclusion of disabled user groups such as the one by Mankoff et al . [ 17 ] motivate us to implement a series of case studies using different Co - Design methodologies . Over the span of three years , we work with four to six children each year . In doing so , we create a large set of case studies showing the childrens design engage - ment . The objects are unique to every child which leads to a comparatively large corpus of novel objects . We keep the design brief deliberately open with only two requirements : the technology should afford positive experi - ences in a meaningful way to the child and the child should be supported in sharing those experiences with their social environment . Furthermore , we expect the ﬁnal objects to be radically different from existing technologies . While these restrictions do not necessitate tangible objects or embodied interaction , they make such technologies more likely ; all ob - jects built in the ﬁrst year afford embodied interaction . We present the case studies and focus on their modes of interac - tion as well as their technological setup . SUBJECT MATTER This work touches on several ﬁelds and while we will not cover all of them , we give a short introduction to the diagnosis of autism and what technologies are offered to this user group in terms of potentially embodied interaction . Autism There is no single set of symptoms that leads to a diagno - sis of autism . However , the core traits associated with autism are an impairment of reciprocal socio - communicative interac - tion often combined with repetitive interests and behaviours . These have been reported to correlate with a heightened sen - sitivity to sensory input – often self - regulating reaction to that input ( cf . [ 16 ] ) . Sensory overload can also lead to melt - downs . The ways in which the symptoms manifest themselves cover a broad spectrum . It is not without reason that a common proverb says ”If you have seen one autistic individual , you have seen one autistic individual” . Diagnoses are given across a spectrum that is in its entirety called autism . The root cause for the condition has not been determined at this point . It is estimated that about one person out of 160 can be seen as being on this spectrum [ 26 ] . Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 245 The spectrum unfolds into diagnoses such as High - Functioning Autism ( HFA ) , Low - Functioning Autism ( LFA ) , Atypical Autism or Pervasive Developmental Disorder ’Other’ , describing the degree of ability to function within a predominantly non - autistic society . During the last few decades there has been a surge in diagnoses , resulting in an increase of awareness among parents , professionals and re - searchers [ 3 ] . Recent criticism by De Jaegher [ 4 ] points out that an autis - tic experience is inherently embodied and that previous the - ories explaining the condition , such as Theory of Mind [ 2 ] , Weak Central Coherence [ 12 ] or Executive Function [ 19 ] are too focused on perceived deﬁcits and only provide piecemeal explanations for the condition . According to De Jaegher , sense - making in autism follows different modes of perceiv - ing and rhythm . They propose that intervention that aims to improve interaction between autistic and non - autistic individ - uals , also described as participatory sense - making , considers both modes of experience equally . Autism and Embodied Technology There have been several recent efforts to create technologies using embodied interaction for autistic individuals in general and children in particular . We only present a small selection as examples in which embodied interaction plays a role in technologies for autistic children . Some attempts make technology , which has not been de - signed with this particular user group in mind , suitable for the context of autistic users ( cf . [ 13 ] ) . One example is the Self - Cam project [ 21 ] , which has been initially developed as a system that analyses facial expressions in order to assign emotional state matching a person’s mood . Due to privacy issues the system was changed to only monitor the wearer’s face . With this change , it has been suggested that autistic individuals could use the device to self - monitor their facial expressions . Another example that does not require much information on how children experience that technology is the way the smart toys by Westeyn et al . [ 25 ] are used to monitor the devel - opmental progress of children . Sensor data is acquired about the way children interact with the toys given to them and can be mapped with developmental markers . It should be noted , however , that the direct user group ( the monitors ) do not in - teract with the system in an embodied fashion . A different version of the former two approaches has been used by Farr et al . [ 8 ] , who investigated the suitability of Topobos for autistic children . They found out , that playing with Topobos elicited more social behaviour of autistic chil - dren than playing with simple LEGO bricks . A similar effect has been additionally shown for the Reactable [ 24 ] . MEDIATE is a project which purely aims at creating an en - vironment that supports exploratory fun for autistic children [ 18 ] . With the help of large walls , users can explore the space with full - body engagement . This is also one of the rare projects that is dedicated to the user experience of autistic children . Almost none of the presented projects created the technology together with their user groups . Rather , developers relied on third hand accounts about autism or relied on information by proxy such as caretakers , parents or autistic individuals with high communication skills . Hence , technologies have been developed for autistic users rather than with them . With Out - sideTheBox we show which technologies emerge from direct involvement of the autistic children themselves . CASE STUDIES The four objects we present all afford some type of embod - iment where the technology has a participative status in the lives of its users [ 6 ] . First , we give a brief overview of the process that made these objects come into existence followed by a deeper look into the systematic components as well as the interaction principles inherent in each of the objects indi - vidually . Genesis of Objects During the ﬁrst year of OutsideTheBox , we worked with a total of four autistic children , to whom we refer as B , R , J , and H throughout this article . Over the span of a year we co - designed a unique object with each child ( see also Table 1 ) . ID age diagnosis design method object name B 8 Autism FW BSmart R 6 HFA FW ThinkM J 6 HFA CI Adaja H 8 Atypical CI ProDraw Table 1 . Research Partners in the ﬁrst year of OutsideTheBox together with diagnosis , age , design method used and name of ﬁnished object ; ID - Identiﬁer , FW - Future Workshops , CI - Co - Operative Inquiry , HFA - High - Functioning Autism We met each child every two weeks for a design session re - sulting in a range of eight to 15 sessions per child during the school year in Austria ( September throughout June ) . In be - tween , the researchers prepared the subsequent sessions by working through the feedback and the experience of previ - ous meetings . The ﬁrst meeting was conducted as an initial meeting where we got to know the children and established relationships between the child and the research team . This was followed by sessions where we conducted Contextual In - quiry ( cf . [ 22 ] ) , in which we investigated the life world of each child by handing them a media capturing device ( e . g . , camera , audio recorder ) and reﬂecting together on their data . The actual design work was conducted using the main de - sign method , we established as suitable for each child . With Future Workshops ( cf . [ 23 ] ) we used the future as a narra - tive space in which we explored ideas for new technologies without being tied to what is technically feasible now . Us - ing Co - Operative Inquiry ( cf . [ 7 ] ) on the other hand allowed us to explore areas of interest together and designing artifacts based on our conjoined design - research activities . Following the interests and needs of each individual child as established during the Contextual Inquiry we adapted the methods for co - designing . In one case , for example , we com - bined the approach of Future Workshops with narrative meth - ods used in Fictional Inquiry ( cf . [ 5 ] ) to provide a stronger Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 246 Figure 1 . BSmart - The Smart Companion for Telling Stories and Investigating Upcoming Movies narrative structured environment to better support B’s imagi - nation . By using these established methods for Participatory Design , we open up space to converse with autistic children about needs they have that are not delineated by the perceived deﬁcits emerging from their diagnosis . As with those per - ceived deﬁcits , the strengths and interest of each autistic child differ as well . During the sessions the children and the research team devel - oped the concepts for the unique designs of each smart ob - ject iteratively . Initial design sketches were critiqued by the children in different forms ( see for a discussion of the creativ - ity involved in interpreting feedback from autistic children in [ 10 ] ) . We recently deployed working prototypes to the chil - dren and are gathering feedback on several levels to assess the user experience the children have with their technologies . It is vital to emphasise that the objects have been created together with the children , since embodied interaction then plays a role not only in using the technology but also in cre - ating it . Through activities like crafting , tinkering , testing and making , the relationship between child and technology is embodied from the start and includes the research team as well . Via close cooperation with the child , the created ob - jects are integrated deeply in the child’s physical world . For example , by interacting notionally with initial paper proto - types , the children were inspired by the material to further specify the look and feel as well as the interactive potential of their smart object . Through this approach following Co - operative Inquiry , the children were less inﬂuenced by exist - ing technologies that surround them in their everyday lives . With Future Workshops , we followed the opposite approach : electronic components like LittleBits 2 acted as a trigger for novel ideas at the very beginning of prototyping phase . By interacting with sensors children thought about potentials for physical interaction and combined their ideas for smart ob - jects with the possibilities discovered . The objects as we can now present them are , hence , not only inherently covering aspects of embodied interaction , but have also been created in an embodied process by the user group themselves . 2 http : / / littlebits . cc CS 1 : BSmart In the form of a kaleidoscope , BSmart is a smart companion that not only informs about upcoming movies , but can also support its user by giving prompts while telling someone a story ( see also Figure 1 ) . It functions as a facilitator between the child and their environment in certain situations , making these more controllable and , hence , predictable for the child them self . This follows the particular interest B has in movies , cinema and story telling . System Description BSmart is implemented in Python on a Raspberry Pi 2 and displays its visual content using an Aiptek Mobile Cinema Q20 projector . Both of them are visibly located on the inside , so that B could investigate the different components and ex - plain others how their object works . Next to using an on / off switch , a user can switch between the video mode displaying up to three movie trailers , one after the other , or the story mode , which shows up to ten pictures of agents or back - grounds that inspire the user to tell / continue a story using them . Another button advances the pictures / movies . When the limit of movies or pictures is reached , BSmart enforces a pause in order to avoid narrow focus on single activities – as per B’s suggestion ( ! ) . They wanted their object to be able to do several things which are unrelated to each other . Accordingly , the story mode and the movie mode function independent from each other . We plan to enhance the system by implementing a website where the user and people of their choice can edit the avail - able content easily . Affording Embodied Interaction Between People While BSmart works in many ways via a standard interaction mechanism : buttons , its required contextual setting makes it facilitate embodied interaction between the storyteller or main user and their audience . It is very much not a tool to be used alone but rather requires a partner to explore content and potential content together . This is why , if charged , BSmart is portable and can be shown to others and moved around . In observation of B’s interaction with the object , we could see that they showed Reactive Embodiment in that they physically reacted to what happened with the object which on the other hand inﬂuenced how the object presented its content . For ex - ample , they were investigating , how the story changes when Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 247 Figure 2 . ThinkM - Embodied Reﬂection of Situations where the own Body fails pointing the projector on different surfaces , reacted gleefully to how things changed , moved BSmart in their hands , creat - ing a new picture by accidentally moving it to a new surface , which again made them explore more or react again . Much of the quality of interaction with the technology for B seems to rely on embodied context that is created around and through it . Hence , BSmart affords the facilitation of these embodied interaction between the main user and their audi - ence . CS 2 : ThinkM ThinkM is a wearable companion that helps a user to reﬂect on social situations after the fact , in which they did not have enough time for in - situ reﬂection ( see also Figure 2 ) . As well as its function as a stylish enhancement , it also gives a user back the control they lost in certain situations . R found it im - portant to help themselves to better understand situations in which they lost control over their own reactions in order to decrease the amount of social problems they encounter . R is very interested in science and scientiﬁc methods , so it was im - portant to them to have a structured way in which to analyse such situations . System Description There are two parts to ThinkM , a headband and a base station . On the headband , two Arduino Mini Pro control a pulse sen - sor and a JPEG camera . The camera is located at the height of a users eyes and records an image every ten seconds . Simul - taneously , the pulse rate of the user is recorded as additional information in terms of arousal for later reﬂection . The pulse sensor is located on the inside of the headband and connected with a roller switch . This way , it starts recording pulse data as soon as the headband is worn . The heart rate data together with the pictures the camera created are transmitted to the base station via a Bluetooth module . The base station consists of a Raspberry Pi 2 , a 7” display and also a Bluetooth module in order to receive the data recorded by the headband . As well as managing the data transfer the base station loops starting with the most novel pictures through all available pictures while displaying the heart beat data recorded when the picture was made . However , just like the human brain 3 , the base station forgets pictures over time . 3 This is the metaphor that the child themselves used . This has been implemented in that there is a half time for pic - ture folders . This means , after a week , half of the pictures in a folder are deleted , after another week , only a quarter of the pictures remain and so on . With such a procedure we could address the privacy issues that occurred during discus - sions with R , not only about their own privacy but also that of others , they might incidentally record . Hence , the data never leaves the system . Due to the combination of a static device with a wearable component the machine works in two phases : the recording phase and the reﬂection phase . During the recording phase , interaction becomes embodied and ambient . As soon as the user wears the headband , it automatically starts taking pic - tures and recording their heartbeat data . During the reﬂection phase , however , direct and intended interaction is important , so in order to support more reﬂection on a single picture , the user can pause the picture loop whenever they want . A potential improvement of ThinkM could include an algo - rithm where the real time pulse data inﬂuences the frequency at which pictures are taken . This way , the emotional impor - tance of a situation as measured by the heart rate of a user is reﬂected not only in the heartbeat data displayed next to the pictures on the base station , but also in the number of pictures dedicated to a certain moment in a situation . Embodied Reﬂection R explained to us , that they would like to create ThinkM as a machine , that remembers everything they do . Especially in situations that others perceive as violent meltdown , R ex - pressed the wish to be able to reﬂect on these afterwards , be - cause they cannot remember what happened after the fact . They would like to be able to assess , what lead to such a situ - ation and be able to read signs ahead of time . Hence , ThinkM becomes relevant in situations where immediate embodied re - ﬂection is not an option . It was crucial for R to have the heart rate data readily avail - able next to the pictures the headband records as an additional mode of assessment . Together with the heart rate data the pic - ture becomes more meaningful to them , because the numeric value lets them analyse a situation in a science mode they like and enjoy . Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 248 Figure 3 . Adaja - The Ambient Companion for Exploring Sounds of Self and Others CS 3 : Adaja Adaja is an ambient companion for a user who is interested in exploring sounds they create themselves and that are around them ( see also Figure 3 ) . It also can assert or remind a user about the noise level currently present around Adaja , by telling them that a certain noise threshold has been crossed . J constantly surprised us with their changing interests , so it was necessary to create an object with them that would react adaptively to context and could both be manipulated as well as create new things on its own . System Description The whole setup for Adaja consists of an Arduino Mini Pro in combination of a microphone and a 1 . 5” OLED - screen . It is arranged into a wearable ambient device that constantly updates its screen according to the intensity of noise it records via the microphone . Future work on Adaja could include more interesting visual feedback that reacts inverted to the loudness of the input . That way , the visual feedback could aid the emotional regulation of a user . Ambient Companion There are three different use case scenarios for Adaja . First , it can be used as a passively acting ambient companion , that just gives constant visual feedback of the noise level sur - rounding it and , by extension , its user . The user can choose to look at it and investigate further or decide not to do that . However , the display is ambient in that it pushes itself into the foreground occasionally because of its location on the wearer’s chest . Second , Adaja can be actively used as a sound lens through which to discover a user’s environment . Different visuali - sations of different sounds can be investigated and experi - mented with . It is , hence , important that the visualisation of the acoustics stays ﬂexible and can change to create new vi - sual patterns with different sounds . Third , Adaja can also be used socially . It affords showing the screens to others and makes it possible for the wearer to not only investigate themselves , but together with others or show them something they ﬁnd interesting either by showing what is ( still ) available on the screen or going to the place in their environment where it happened . They can also make sounds individually or together to see how the visual patterns change . In all three use case scenarios , full control over Adaja is given to the wearer . They can decide when they interact with it at all and when they let others interact with it . In classroom situ - ations , we could observe how this led peers to ask a wearer to share their experiences with Adaja , which opened up new op - tions for spaces of negotiation . The visualisation itself is de - pendent to surrounding noises . All the while it privileges the wearer’s voice . Having a clear hierarchical structure where the control is always given to the wearer ( and is therefor em - bodied ) . For J , this establishes security during the interaction . CS 4 : ProDraw With ProDraw a user cannot only create drawings , but also animate them with their own body as the extension of an input device ( see also Figure 4 ) . H is an avid drawer and has issues getting acknowledged for their skills by their peers . ProDraw offers H a way to put focus on their talents rather than their perceived deﬁcits . System Description ProDraw lets H draw on a touch surface and animate pre - viously drawn pictures . It is implemented in Python on a Raspberry 2 using an 8” touch enabled display as a drawing and interaction surface , that also comes with a touch - enabled pen . Furthermore , there is a DBPOWER 2 . 4 LCD TFT dis - play projector for displaying pictures to a larger audience and a Wii Remote Controller for controlling the speed of an ani - mation . A user is in one of two modes during a certain point of in - teraction . In the drawing mode , pictures can be drawn and saved . They will be automatically grouped for later anima - tion . In the animation mode , a folder is chosen and the ani - mation loops through the pictures in that folder to create the animation – quite like a ﬂip book works . The speed of the animation is determined by the sensor data received from the Wii Remote Controller . The faster the controller is shaken , the faster the animation plays . Potential projection of what happens on the touch surface is independent from the mode . Embodied Control While the drawing mode of ProDraw does follow fairly paradigmatic standards of interaction with a touch surface , Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 249 Figure 4 . ProDraw - Showing Self - Created Animations with Embodied Control the animation mode forces a user to take a step back and in - teract with the technology using their own body . This also makes clear , that the drawing experience is more private than the animation experience , which is more addressed towards a larger space including a potential surrounding audience . While it is technically possible to always project what hap - pens on the touch surface or to just turn the projector off dur - ing animation , having the animation react to the input of the Wii and how fast it is shaken , makes the user step back from the technology and open themselves up to a public . This gives them full embodied control over their sharing experience . It opens up new spaces for interaction between the user and a potential audience that would not be possible by a static or non - embodied mode of interaction . DISCUSSION Within these case studies we saw different forms of embodi - ment playing a key role . In CS 1 we saw that the embodiment afforded can go beyond the interaction between a single user and a technological artifact , but rather spark embodied inter - action between that user and the audience with whom they want to engage . With CS 2 we could show that embodiment can also be separated temporally , in order to reﬂect the abil - ities of a user . A completely contrary approach can be ob - served in CS 3 where ambient embodiment is very much tied to the user , but also unobtrusively offers possibilities of inter - action . CS 4 , on the other hand , presents a case where em - bodiment takes the visual focus away from the physical body of a user while , at the same time , incorporating that body into the projection process . All of these technologies are the result of an inherently em - bodied design process and would probably not be as embed - ded in the lives of their users , if the children not participated in the creation of the technologies . By closely examining the artifacts , it becomes apparent that the live worlds of the children with whom we worked , while each different , are all inﬂuenced by a desire for embodied interaction with others through modes which they can control and shape . We also noted another shared property of all technologies : they all work with visual feedback either by screens and / or in - built projectors . For our future case studies we aim to crit - ically review our own technology related biases and explore more option for feedback together with the children . One might also say that they are tied to currently available tech - nology , however , that is only the case for their ﬁnal form . More about the ideation and design processes with the four children can be found in [ 11 ] . The technologies created within the ﬁrst year of OutsideThe - Box show how Co - Design processes with autistic children yield concrete results that could not have been created by non - autistic researchers alone . Next to this we expect some technologies to have more of a long term signiﬁcance – also for other users – than others . While we were not aiming to develop technologies that might support emotional learning , ThinkM provides a setup that might be well used in a more structured approach to teach emotion recognition and reﬂec - tion on social settings to children – autistic or not . Future Work These four case studies only show a trend of what technology autistic children are interested in creating and using for them - selves . As well as collecting more examples by providing fur - ther case studies , OutsideTheBox will also test the viability of different design methods and how they not only impact the design but also the interaction paradigms of the technologies that emerge from them . Additionally , we are currently devel - oping an evaluation strategy for assessing the experiences the children have with their technologies . It might furthermore be interesting to take the presented tech - nologies and look into the use cases other autistic or non - autistic children might have with them . We are aware that the objects created during the ﬁrst year of OutsideTheBox are very tied to the user that has co - created them . It can be , however , that some paradigms are interesting for other user groups as well . We have founded these more general ques - tions with the ﬁndings of our research . CONCLUSION In its ﬁrst year OutsideTheBox was able to show that the objects our autistic children created conjointly with us are deeply embodied along aspects of interaction . We experi - mented with two design processes and adapted them where needed . Technologies , that are inspired by the everyday lives of their users , increase a feeling of ownership . Through their genesis they also provide an empowering opportunity for the children as co - creators of their own technologies . Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 250 Said technology provides a structure and makes the physical environment more predictable and controllable by providing a lens through which to perceive it , either directly ( like with the visualisation of sounds in Adaja ) or indirectly ( like the temporal shift of reﬂection provided by ThinkM ) . We propose to call the class of objects we created embodied companion technologies . They are part of their users’ lives in a meaningful way , that makes sense to them and aid them in their sense making about the world not only as autonomous subjects , but also in situations of participatory sense - making ( as deﬁned in [ 4 ] ) . In fact , all of these technologies give their users a way to let others participate in their own sense - making in a form that was not available to their peers and environment before . The technologies extend the children’s process of sense - making by letting others participate in it and consequently shape this process in return by giving the children a way to integrate others’ perspectives . Our technologies make sense in their users’ lives . ACKNOWLEDGMENTS This work has been funded by the Austrian Science Fund [ P26281 - N23 ] . We also thank Geraldine Fitzpatrick and Eva Hornecker as well as the anonymous reviewers for their helpful feedback on earlier versions of this paper . Furthermore , our gratitude goes to Kearsley Schieder - Wethy and Cynthia Kop for proof reading several iterations of drafts . Finally , we are very grateful for having met the children and thank them – as well as the schools , parents and mentors – for granting us the opportunity that we could work with them . REFERENCES 1 . Nuria Aresti - Bartolome and Begonya Garcia - Zapirain . 2014 . Technologies as Support Tools for Persons with Autistic Spectrum Disorder : A Systematic Review . International Journal of Environmental Research and Public Health 11 ( Aug . 2014 ) , 7767 – 7802 . DOI : http : / / dx . doi . org / 10 . 3390 / ijerph110807767 2 . Simon Baron - Cohen , Alan M Leslie , and Uta Frith . 1985 . Does the autistic child have a theory of mind ? Cognition 21 , 1 ( 1985 ) , 37 – 46 . 3 . Simon Baron - Cohen , Fiona J Scott , Carrie Allison , Joanna Williams , Patrick Bolton , Fiona E Matthews , and Carol Brayne . 2009 . Prevalence of Autism - Spectrum Conditions : UK School - Based Population Study . The British Journal of Psychiatry 194 , 6 ( 2009 ) , 500 – 509 . 4 . Hanne De Jaegher . 2013 . Embodiment and sense - making in autism . Frontiers in Integrative Neuroscience 7 ( 2013 ) , 15 . DOI : http : / / dx . doi . org / 10 . 3389 / fnint . 2013 . 00015 5 . Christian Dindler and Ole Sejer Iversen . 2007 . Fictional Inquiry - design collaboration in a shared narrative space . CoDesign 3 , 4 ( Dec . 2007 ) , 213 – 234 . DOI : http : / / dx . doi . org / doi : 10 . 1080 / 15710880701500187 6 . Paul Dourish . 2001 . Where the Action is : The Foundations of Embodied Interaction . MIT Press , Cambridge , MA , USA . 7 . Allison Druin . 1999 . Cooperative Inquiry : Developing New Technologies for Children with Children . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’99 ) . ACM , New York , NY , USA , 592 – 599 . DOI : http : / / dx . doi . org / 10 . 1145 / 302979 . 303166 8 . William Farr , Nicola Yuill , and Hayes Rafﬂe . 2010 . Social beneﬁts of a tangible user interface for children with Autistic Spectrum Conditions . Autism 14 , 3 ( 2010 ) , 237 – 252 . DOI : http : / / dx . doi . org / 10 . 1177 / 1362361310363280 9 . Christopher Frauenberger , Judith Good , Alyssa Alcorn , and Helen Pain . 2012a . Supporting the Design Contributions of Children with Autism Spectrum Conditions . In Proceedings of the 11th International Conference on Interaction Design and Children ( IDC ’12 ) . ACM , New York , NY , USA , 134 – 143 . DOI : http : / / dx . doi . org / 10 . 1145 / 2307096 . 2307112 10 . Christopher Frauenberger , Judith Good , Wendy Keay - Bright , and Helen Pain . 2012b . Interpreting Input from Children : A Designerly Approach . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’12 ) . ACM , New York , NY , USA , 2377 – 2386 . DOI : http : / / dx . doi . org / 10 . 1145 / 2207676 . 2208399 11 . Christopher Frauenberger , Julia Makhaeva , and Katharina Spiel . Under Review . Designing Smart Objects with Autistic Children – Four Design Expos ` es . ( Under Review ) . 12 . Uta Frith . 1989 . Autism : Explaining the enigma . ( 1989 ) . 13 . Rana el Kaliouby , Rosalind Picard , and Simon Baron - Cohen . 2006 . Affective Computing and Autism . Annals of the New York Academy of Sciences 1093 , 1 ( Dec . 2006 ) , 228 – 248 . DOI : http : / / dx . doi . org / 10 . 1196 / annals . 1382 . 016 14 . Wendy E . Keay - Bright . 2007 . The Reactive Colours Project : Demonstrating Participatory and Collaborative Design Methods for the Creation of Software for Autistic Children . Digital Creativity 1 , 2 ( June 2007 ) , 7 – 16 . http : / / ijg . cgpublisher . com / product / pub . 154 / prod . 17 15 . Julie A . Kientz , Matthew S . Goodwin , Gillian R . Hayes , and Gregory D . Abowd . 2013 . Interactive Technologies for Autism . Synthesis Lectures on Assistive , Rehabilitative , and Health - Preserving Technologies 2 , 2 ( 2013 ) , 1 – 177 . DOI : http : / / dx . doi . org / 10 . 2200 / S00533ED1V01Y201309ARH004 16 . Anne V . Kirby , Virginia A . Dickie , and Grace T . Baranek . 2015 . Sensory experiences of children with autism spectrum disorder : In their own words . Autism 19 , 3 ( April 2015 ) , 316 – 326 . DOI : http : / / dx . doi . org / 10 . 1177 / 1362361314520756 Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 251 17 . Jennifer Mankoff , Gillian R . Hayes , and Devva Kasnitz . 2010 . Disability studies as a source of critical inquiry for the ﬁeld of assistive technology . In Proceedings of the 12th international ACM SIGACCESS conference on Computers and accessibility ( ASSETS ’10 ) . ACM , Orlando , Florida , USA , 3 – 10 . DOI : http : / / dx . doi . org / 10 . 1145 / 1878803 . 1878807 18 . N . Pares , P . Masri , G . van Wolferen , and C . Creed . 2005 . Achieving dialogue with children with severe autism in an adaptive multisensory interaction : the ”MEDIATE” project . IEEE Transactions on Visualization and Computer Graphics 11 , 6 ( Nov . 2005 ) , 734 – 743 . DOI : http : / / dx . doi . org / 10 . 1109 / TVCG . 2005 . 88 19 . James Ed Russell . 1997 . Autism as an executive disorder . Oxford University Press . 20 . Jim Sinclair . 2013 . Why I dislike person ﬁrst Language . Autonomy , the Critical Journal of Interdisciplinary Autism Studies 1 , 2 ( Oct . 2013 ) . http : / / www . larry - arnold . net / Autonomy / index . php / autonomy / article / view / OP1 21 . Alea Teeters , Rana El Kaliouby , and Rosalind Picard . 2006 . Self - Cam : Feedback from What Would Be Your Social Partner . In ACM SIGGRAPH 2006 Research Posters ( SIGGRAPH ’06 ) . ACM , New York , NY , USA . DOI : http : / / dx . doi . org / 10 . 1145 / 1179622 . 1179782 22 . Fenne van Doorn , Pieter Jan Stappers , and Mathieu Gielen . 2013 . Design research by proxy : using children as researchers to gain contextual knowledge about user experience . . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems . ACM , 2883 – 2892 . http : / / dl . acm . org / citation . cfm ? id = 2481399 23 . Giasemi Vavoula and Mike Sharples . 2007 . Future technology workshop : A collaborative method for the design of new learning technologies and activities . International Journal of Computer - Supported Collaborative Learning 2 , 4 ( 2007 ) , 393 – 419 . DOI : http : / / dx . doi . org / 10 . 1007 / s11412 - 007 - 9026 - 0 24 . Lilia Villafuerte , Milena Markova , and Sergi Jorda . 2012 . Acquisition of social abilities through musical tangible user interface : children with autism spectrum condition and the reactable . In CHI’12 Extended Abstracts on Human Factors in Computing Systems . ACM , 745 – 760 . http : / / dl . acm . org / citation . cfm ? id = 2212847 25 . Tracy L . Westeyn , Gregory D . Abowd , Thad E . Starner , Jeremy M . Johnson , Peter W . Presti , and Kimberly A . Weaver . 2012 . Monitoring childrens developmental progress using augmented toys and activity recognition . Personal and Ubiquitous Computing 16 , 2 ( Feb . 2012 ) , 169 – 191 . DOI : http : / / dx . doi . org / 10 . 1007 / s00779 - 011 - 0386 - 0 26 . World Health Organization WHO . 2013 . Autism Spectrum Disorders & Other Developmental Disorders – From Raising Awareness to Building Capacity . ( December 2013 ) . Not For Kids Only TEI 2016 , February 14 - 17 , 2016 , Eindhoven , the Netherlands 252