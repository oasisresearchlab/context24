Entity Graphs for Exploring Online Discourse Nicholas Botzer 1 and Tim Weninger 1 , * 1 University of Notre Dame , Notre Dame , IN * Corresponding author : tweninger @ nd . edu April 10 , 2023 Abstract Vast amounts of human communication occurs online . These digi - tal traces of natural human communication along with recent advances in natural language processing technology provide for computational analysis of these discussions . In the study of social networks the typical perspective is to view users as nodes and concepts as ﬂowing through and among the user - nodes within the social network . In the present work we take the opposite perspective : we extract and organize mas - sive amounts of group discussion into a concept space we call an entity graph where concepts and entities are static and human communicators move about the concept space via their conversations . Framed by this perspective we performed several experiments and comparative analy - sis on large volumes of online discourse from Reddit . In quantitative experiments , we found that discourse was diﬃcult to predict , especially as the conversation carried on . We also developed an interactive tool to visually inspect conversation trails over the entity graph ; although they were diﬃcult to predict , we found that conversations , in general , tended to diverge to a vast swath of topics initially , but then tended to converge to simple and popular concepts as the conversation pro - gressed . An application of the spreading activation function from the ﬁeld of cognitive psychology also provided compelling visual narratives from the data . 1 Introduction In any conversation , members continuously track the topics and concepts that are being discussed . The colloquialism “train - of - thought” is often used 1 a r X i v : 2304 . 03351v1 [ c s . S I ] 6 A p r 2023 to describe the path that a discussion takes , where a conversation may “de - rail , ” or “come - full - circle , ” etc . An interesting untapped perspective of these ideas exists within the realm of the Web and Social Media , where a train - of - thought could be analogous to a trail over a graph of concepts . With this perspective , an individual’s ideas as expressed through language can be mapped to explicit entities or concepts , and , therefore , a single argument or train - of - thought can be treated as a path over the graph of concepts . Within a group discussion , the entities , concepts , arguments , and stories can be ex - pressed as a set of distinct paths over a shared concept space , what we call an entity graph . Scholars have long studied discourse and the ﬂow of narrative in group conversations , especially in relation to debates around social media [ 32 ] and intelligence [ 29 ] . The study of language and discourse is rooted in psychology [ 7 ] and consciousness [ 6 ] . Indeed , the linguist Wallace Chafe considered “ . . . conversation as a way separate minds are connected into networks of other minds . ” [ 7 ] Looking at online conversations from this angle , a natural hypothesis arises : If we think of group discussion as a graph of interconnected ideas , then can we learn patterns that are descriptive and predictive of the discussion ? Fortunately , recent developments in natural language processing , graph mining , and the analysis of discourse now permit the algorithmic modelling of human discussion in interesting ways by piecing them together . This is a broad goal , but in the present work we provide a ﬁrst step towards graph mining over human discourse . Another outcome of the digital age is that much of human discourse has shifted to online social systems . Interpersonal communication is now observable at a massive scale . Digital traces of emails , chat rooms , Twitter or other threaded conversations that approximate in person communication are commonly available . A newer form of digital group discussion can be seen in the dynamics of Internet fora where individuals ( usually strangers ) discuss and debate a myriad of issues . Technology that can parse and extract information from these conver - sations currently exists and operates with reasonable accuracy . From this large body of work , the study of entity linking has emerged as a way to ground conversational statements to well - deﬁned entities , such as those that constitute knowledge bases and knowledge graphs [ 41 ] . Wikiﬁcation , i . e . , where entities in prose are linked to Wikipedia - entries as if it was written for Wikipedia , is one example of entity linking [ 9 ] . The Information Car - tography project is another example that uses these NLP - tools to create visualizations that help users understand how related news stories are con - 2 Figure 1 : Illustration of an entity graph created from threaded conversa - tions from r / politics ( blue - edges ) and r / conservative ( red - edges ) . The x - axis represents the ( threaded ) depth at which each entity was mentioned within conversations , extracted from Reddit , rooted at Joe Biden . The y - axis rep - resents the semantic space of each entity , i . e . , similar entities are closer than dissimilar entities on the y - axis . Edge colors denote whether the transition from one entity set to another occurs more often from one groups conver - sations than another . Node colors represent equivalent entity sets along the x - axis . In this visualization we observe a pattern of aﬀective polariza - tion as comments coming from / r / Conservative are more likely to drive the conversation towards topics related to the opposing political party . nected in a simple , yet meaningful manner [ 40 , 39 , 25 ] . But because entity linking techniques have been typically trained from Wikipedia or long - form Web - text , they have a diﬃcult time accurately processing conversational narratives , especially from social media [ 13 ] . Fortunately , recent progress in Social - NLP has made considerable strides in recent years [ 35 ] providing the ability to extract grounded information from informal , threaded online discourse [ 27 ] . Taking this perspective , the present work studies and explores the ﬂow of entities in online discourse through the lens of entity graphs . We focus our attention on discussion threads from Reddit , but these techniques should generalize to online discussions on similar platforms so long as the entity linking system can accurately link the text to the correct entities . The threaded conversations provide a clear indication of the reply - pattern , which allows us to chart and visualize conversation - paths over entities . To be clear , this perspective is the opposite of the conventional social networks approach , where information and ideas traverse over user - nodes ; on the contrary , we consider discourse to be humans traversing over a graph 3 of entities . The conventional approach to social networks is important for areas such as inﬂuence maximization [ 26 ] and the spread of behaviors [ 5 ] . Instead , the goal of our alternative perspective is to discover this network of minds and uncover patterns of how they think over topics . This alter - native perspective is motivated by the large number of inﬂuence campaigns [ 37 ] , information operations [ 44 ] , and the eﬀectiveness of disinformation [ 18 ] . These campaigns often operate by seeding conversations in order to exploit conversation patterns and incite a particular group . Another motivation for our proposed methodology is humans attraction towards homophily and the large number of echo chambers that have been created online [ 10 , 17 ] . Prior works [ 17 ] looking at echo chambers in political discourse rely on this notion of the ideas spreading between user - nodes . Other works looking at morality [ 4 ] also follow this notion of how moral text spreads throughout a user network . We stress here that our entity graph will allow for a ﬂipped perspective of having users move across the graph of entities in various types of conversations . This position allows for a diﬀerent form of analysis into how diﬀerent groups or communities think as a whole . Our way of thinking is illustrated in Fig . 1 , which shows a subset of path traversals , which we describe in detail later , from thousands of conversations in / r / politics and / r / conservative that start from the entity Joe Biden . As a brief preview , we ﬁnd that conversations starting with Joe Biden tend to lead towards United States in conversations from the / r / conservative subred - dit ( indicated by a red edge ) , but commonly lead towards mentions of the Republican Party in conversations from / r / politics ( indicated by blue - purple edge ) . From there the conversations move onward to various other entities and topics that are cropped from Fig 1 to maintain clarity . In the present work , we describe how to create entity graphs and use them to answer questions about the nature of online , threaded discourse . Speciﬁcally , we ask three research questions : RQ1 How predictable is online discourse ? Can we accurately determine where a conversation will lead ? RQ2 What do entity graphs of Reddit look like ? In general , does online discourse tend to splinter , narrow , or coalesce ? Do conversations tend to deviate or stay on topic ? RQ3 Can cognitive - psychological theories on spreading activation be ap - plied to further illuminate and compare online discourse ? We ﬁnd that entity graphs provide a detailed yet holistic illustration of online discourse in aggregate that allow us to address our proposed research 4 questions . Conversations have an enormous , visually random , empirical pos - sibility space , but attention tends to coalesce towards a handful of common topics as the depth increases . Prediction is diﬃcult , and gets more diﬃ - cult the longer a conversation goes on . Finally , we show that entity graphs present a particularly compelling tool by which to perform comparative anal - ysis . For example , we ﬁnd , especially in recent years , that conservatives and liberals both tend to focus their conversations on the out - group – a notion known as aﬀective polarization [ 22 ] . We also ﬁnd that users also tend to stick to the enforced topics of a subreddit as shown by how r / news tends towards entities from the United States and r / worldnews tends towards non - US topics . 2 Methodology 2 . 1 Online Discourse Dataset Of all the possible choices from which to collect online discourse , we ﬁnd that Reddit provides exactly the kind of data that can be used for this task . It is freely and abundantly available [ 1 ] , and it has a large number of users and a variety of topics . Reddit has become a central source of data for many diﬀerent works [ 30 ] . For example , recent studies on the linguistic analysis of Schizophrenia [ 48 ] , hate speech [ 8 ] , misogyny [ 15 ] , and detecting depression related posts [ 42 ] all make substantial use of Reddit data . The threading system that is built into Reddit comment - pages is impor - tant for our analysis . Each comment thread begins with a high level topic ( the post title ) , that is often viewed as the start of a conversation around a speciﬁc topic . Users often respond to the post with their own comments . These can be viewed as direct responses to the initial post , and then each of these comments can have replies . This threading system generates a large tree structure where the root is the post title . Of course , such a threading system is only one possible realization of digital discussion , but this system provides the ability to understand how conversations move as users respond to each other in turn . Twitter , Facebook , and Youtube also have discussion sections , but it is very diﬃcult to untangle who is replying to whom in these ( mostly ) unthreaded systems . Reddit contains a large variety of subreddits , which are small commu - nities focused on a speciﬁc topic . We limit our analysis to only a small number of them , but for each selection we obtain their complete comment history from January 2017 to June 2021 . In total we selected ﬁve subreddits : / r / news , / r / worldnews , / r / Conservative , / r / Coronavirus and / r / politics . 5 Germany challenges Russia over alleged cyberattacks ( a ) Comment Thread ( b ) Entity Tree Entity Extractionand Linking Russia About time somebody had the balls to stand up to Russia It ' s sad people think that this is Russia . No one knows who it is . No one . Trump was right when he said it could be a 500 pound person in a basement with no affiliation . And then what happens ? Sure Russia is messing around with other countries , but I doubt much will come from this . Well hopefully Germany can get the rest of Europe on board . Germany Europe Germany Russia Russia Russia Donald _ Trump Figure 2 : ( Left ) Example comment thread with the post title as the root , two immediate child comments , one of which has two additional child comments . Entity mentions are highlighted in yellow . ( Right ) The resulting entity tree where each comment is replaced by their entity set . Note the case where the mention - text Trump in the comment thread is represented by the standardized entity - label Donald Trump in the entity tree . We selected these subreddits because they are large and attract a lot of discussion related to current events , albeit with their own perspectives and guidelines . These subreddits also contain a large number of entities , which we plan to extract and analyze . Like most social sites , Reddit post - engagement follows the 90 - 9 - 1 rule of Internet engagement . Simply put , most users don’t post or comment , and most posts receive almost no attention [ 30 ] . Because of this we limit our data to include only those threads that are in the top 20 % in terms of number of comments per post . Doing so ensures that we mostly collect larger discussions threads that have an established back and forth . We also ignore posts from the well - known bot accounts , ( e . g . , AutoMod , LocationBot ) to ensure we get actual user posts in the conversation . 2 . 2 Entity Linking We use entity linking tools to extract the entities from each post title and comment in the dataset ( c . f . [ 41 ] ) . Entity linking tools seek to determine parts of free form text that represent an entity ( a mention ) and then map 6 Table 1 : Reddit discourse dataset . Top 20 % of posts in terms of number of comments from ﬁve subreddits between January 2017 to June 2021 . # Posts # Comments Total Entities Unique Entities / r / news 7 , 299 106 , 428 240 , 009 10 , 573 / r / worldnews 16 , 056 263 , 227 692 , 735 12 , 840 / r / politics 15 , 596 326 , 958 756 , 576 11 , 908 / r / Conservative 3 , 093 41 , 439 100 , 756 4 , 308 / r / Coronavirus 18 , 469 252 , 303 509 , 632 10 , 246 that mention to the appropriate entity - listing in a knowledge base ( disam - biguation ) , such as Wikipedia . Existing models and algorithms rely heavily on character matching between the mention - text and the entity label , but more - recent models have employed deep representation learning to make this task more robust [ 38 ] . An example of entity linking on a comment thread is illustrated in Fig . 2 . Each comment thread T contains a post R which serves as the root of the tree c r ∈ T and comments c x ∈ T , where subscript r and x serve to index the post title and a speciﬁc comment . Each comment can reply to the root c → r or to another comment c x → c y thereby determining a comment’s depth (cid:96) ∈ [ 0 , . . . , L ] . Comments and post titles may or may not contain one or more entities S ( c ) . These entity sets are likewise threaded , such that S ( c x ) → S ( c y ) means that the entities in c x were responded to with the entities in c y , i . e . , c x is the parent of c y . With this formalism , the entity linking task transforms a comment threads into an entity tree as seen in Fig . 2 . Speciﬁcally , we utilize the End - to - End ( E2E ) neural model created by Kolitaskas et . al . [ 27 ] to perform entity linking on our selected subreddits . Previous work has shown that entity linking on Reddit can be quite chal - lenging due to the wide variety of mentions used [ 3 ] . The E2E model we use has been shown to have a high level of precision on Reddit but lacks a high recall [ 3 ] . We ﬁnd using this model appropriate as we want to ensure that the entities we ﬁnd are correct and reliable , but acknowledge that it may miss a portion of the less well - known entities , as well as missing any new entities that arise from entity drift . The choice of this entity linker also inﬂuenced our decision to analyze the selected subreddits as the perfor - mance is better in these selected subreddits . We also experimented with the popular REL entity linker [ 43 ] . Although it did retrieve many more entities from the comments , we found a large number of the entities to be incorrect . Using the E2E model we extract entities from each post title and com - 7 1 Depth : 1 Depth : 2 2 3 3 Europe Europe Germany Russia Germany Russia Germany Russia Russia Germany Russia Germany Russia Russia Germany Russia Russia Russia Europe Germany Russia Russia Germany Russia Donald _ Trump Russia Donald _ Trump Donald _ Trump ( b ) Entity Tree ( c ) Conversation Paths Russia Germany Europe Germany Russia Russia Russia Donald _ Trump Path Expansion Figure 3 : Paths extracted from the entity tree in Fig . 2 ( b ) represented by directed edges over entity sets . ment individually and construct the entity tree as illustrated in Fig 2 . Table 1 shows a breakdown of the post , comment , and entity statistics for each subreddit considered in the present work . 2 . 3 Entity Graph Given an entity tree , our next task is to construct a model that can be used to make predictions about the shape and future of the conversation , but also can be used as a visual , exploratory tool . Although entity trees may provide a good picture for a single conversation , we want to investigate patterns in a broader manner . To do this we consider conversations coming from a large number of entity trees in aggregate . This model takes the form of a weighted directed graph G = ( V , E , w ) where each vertex v ∈ V is a tuple of an entity set S ( c ) and it’s associated depth (cid:96) in the comment tree v = ( S ( c ) , (cid:96) ) . Each directed edge in the graph e ∈ E connects two vertices e = ( v 1 , v 2 ) such that the depth , (cid:96) of v 1 must be one less than the depth of v 2 . Each edge in the graph e ∈ E also contains a weight w : E → R that represents the frequency of the transition from one entity set to another . This directed graph captures not only the speciﬁc concepts and ideas mentioned within the discourse , but also the conversational ﬂow over those concepts . Continuing the example from above , Fig . 3 shows three individual paths P representing the entity tree from Fig . 2 ( b ) . Each entity set moves from one depth to the next , representing the progression of the discussion . During the construction of the entity paths , we remove comments that do not have any replies . Short paths , those with a length less than three , do 8 not oﬀer much information in terms of how the conversation will progress , because the conversation empirically did not progress . It may be useful to analyze why some topics resulted in no follow - on correspondence , but we leave this as a matter for future work . Because we wish to explore online discourse in aggregate , this is the point where we aggregate across many comment threads T ∈ T where T repre - sents an entire subreddit or an intentional mixture of subreddits depending on the task . We extract all of the conversation paths from our comment threads T to now have a group of conversation paths P . To generate our graph we iterate over our group of paths P and aggregated them together to construct our entity graph . For every instance of an entity set transition in a conversation path we increment the weight w of it’s respective edge in our entity graph . One key aspect of this is that we count this transition only once per each comment thread T . This ensures that entity transitions do not get over counted , by virtue of the thread being larger and containing more conversation paths overall . One of the limitations of the current graph structure is that the graph does not capture conversation similarities if some of the entities overlap between two diﬀerent vertices . For instance , another entity tree may result in having an entity set S ( c r ) that contains a subset of the entities in a given vertex . This new entity set may have a similar conversational ﬂow but will not be captured in our current entity graph because the model does not allow for any entity overlap . To help alleviate this issue we borrow from the notion of a hypergraph and perform a star - expansion on our graph G [ 47 ] . A hypergraph is deﬁned as H = ( X , E ) where X is the set of vertices and E is a set of non - empty sub - sets of X called hyperedges . The star expansion process turns a hypergraph into a simple , bipartite graph . It works by generating a new vertex in the graph for each hyperedge present in the hypergraph and then connects each vertex to each new hyperedge - vertex . This generates a new graph G ( V , E ) from H by introducing a new vertex and edge for each hyperedge such that V = E ∪ P . While our model is a graph we can treat each entity set S ( c ) as a hy - peredge in our case to perform this star expansion . This will give us new vertices to represent each individual entity and allow us to capture transi - tions from one entity set to another if they share a subset of entities . An example of the resulting graph after performing a star - expansion can be seen in Fig . 4 . This helps to provide valid transition paths that would otherwise not exist without the star expansion . When the star expansion operation is performed the edge weights between the new individual entity vertices 9 1 Depth : 1 Depth : 2 2 3 3 Europe Europe Germany Russia Germany Russia Germany Russia Russia Germany Russia Germany Russia Russia Germany Russia Russia Russia Europe Germany Russia Russia Germany Russia Donald _ Trump Russia Donald _ Trump Donald _ Trump ( b ) Entity Tree ( c ) Conversation Paths Russia Germany Europe Germany Russia Russia Russia Donald _ Trump Path Expansion Figure 4 : Entity graph constructed from a star - expansion of the entity tree in Fig 2 ( b ) and the conversation paths in Fig . 3 ( c ) This model represents the entities , their frequent combinations , and the paths frequently used in their invocation . and their respective entity sets is set to the number of times that entity set occurred at a given depth l . Although the star expansion process will generate a much larger graph due to the large number of vertices , it proves to be useful for prediction and aligning entity set vertices in a visual space . This graph - model therefore represents the entities , their frequent com - binations , and the paths frequently used in their invocation over a set of threaded conversations . 3 Conversation Prediction Having generated these entity graphs we turn our attention to the three research questions . RQ1 ﬁrst asks if these entity graphs can be used to predict where a conversation may lead . Clearly this is a diﬃcult task , but recent advances in deep learning and language models have led to major improvements and interest in conversational AI [ 34 ] , which has further lead to the development of a number of models that utilize entities and knowledge graphs [ 45 ] from various sources including Reddit [ 46 ] . The main motivation of these tools is to use the topological structure of the knowledge graphs ( entities and their relationships ) to improve a conversational agents’ ability to more - naturally select the next entity in the conversation . The typical methodology in related machine learning papers seeks to predict the next entity in some conversation [ 31 ] . In these cases , a dataset of paths through a knowledge graph is constructed from actual human conversations as well as one or more AI models . Then a human annotator picks the entity that 10 2 4 6 8 0 . 6 0 . 8 1 Conversation Depth ( (cid:96) ) P e r ce n t a g e o f V a li d E n t i t i e s / r / news / r / worldnews / r / politics / r / coronavirus / r / conservative Figure 5 : Percent of the predictions made on the testing set that , on average , exist in the training set for 5 - folds . Higher is better . they feel is most natural [ 31 , 23 ] . Our methodology varies from these as we are not focused on making a machine learning model to accurately predict these entities precisely . Our goal is to demonstrate more broad patterns of people conversing over and through the topics . To this end , we do not evaluate with a standard ma - chine learning paradigm aiming to optimize for metrics such as accuracy , precision , recall , etc . To demonstrate that our entity graph captures broad patterns that can be further explored we perform two tasks : ( 1 ) the general - ization task and ( 2 ) a similarity prediction task . Each task uses 5 - fold cross validation where we split the entity graph into 80 / 20 splits for H train and H test respectively . We perform this cross validation in a disjoint manner with the Reddit threads that we have extracted . This creates 5 diﬀerent entity graphs , one for each split , and validates the model’s generalization to unseen Reddit threads . Although this disjoint split ensures the threads are separate , we do not consider the temporal aspect of these threads . The ﬁrst task : generalization , gets at the heart of our broader question on the predictability of conversation paths . In this task we simply calculate the number of entity sets , at each level in H test that also appear in the same level in H train of our entity graph . Formally , we measure generalization as 1 − (cid:107) S (cid:96) ∈H test \ S (cid:96) ∈H train (cid:107) (cid:107) S (cid:96) ∈H test (cid:107) for each (cid:96) . In simple terms , generalization tells us , given an unseen conversation comment , if the model can make a prediction from the given comment by matching at least one entity in our entity graph model . This task there - fore validates how well the model captures general conversation patterns by 11 matching at the entity level . Results of this analysis are shown in Fig . 5 where color and shape combinations indicate the subreddit and (cid:96) is repre - sented along the x - axis . Error bars represent the 95 % conﬁdence interval of the mean across the 5 folds . We ﬁnd that the entity graph captures much more of the information early in conversations . As the depth increases to three and beyond , we note a sharp drop in the overlap between the test and training sets . The widening conﬁdence interval also indicates that the amount of information varies based on the test set . From these results , we conclude that analyzing the ﬂow of an unseen conversation early - on is reasonable , but ﬁndings from deeper in the conversation may be diﬃcult because key entities may be missing from the entity graph . The second task : similarity prediction looks to measure the similarity between a predicted entity set and the actual entity set . This methodology uses the entity embeddings from the E2E entity linking model to represent the entities in the vector space . For each root in H test we ﬁnd its matching root in the H train ; if a match does not exist , we discard and start again . Then we make the Markovian assumption and perform probabilistic pre - diction for each path in the training set via P r ( S (cid:96) + 1 ( c y ) | S (cid:96) ( c x ) ) , i . e . , the empirical probability of a conversation moving to S (cid:96) + 1 ( c y ) given the conver - sation is currently at S (cid:96) ( c x ) in H train . The probability for each transition is based on the edge weights that we captured during the graph construction step . As determined in the previous experiment , entity sets are increasingly unlikely to match exactly as the depth increases ; so rather than a 0 / 1 loss , we measure the word movers distance ( WMD ) between the predicted entities and the actual entities [ 28 ] . Results for this comparison are shown in Fig . 6 for three of the larger subreddits . We again ﬁnd that as the depth of the conversation increases the distance between our predicted tree and the ground truth entities rises . These results indicate that as a conversation continues , the variety of topics discussed tends to increase . Therefore , predictions are likely to not align well very to those of the true conversation . This is most clearly seen in the / r / politics plot in Fig . 6 , where we note a sharp increase in the later parts of the conversation . If the variety of topics was consistent , then we would expect the WMD to stay relatively ﬂat throughout the conversation depth . 4 Conversation Traversals Next , we investigate RQ2 through a visualization of the entity graph . Recall that the entity graph contains entity sets over the depths of the conversation . 12 0 2 4 6 8 0 2 4 6 Conversation Depth ( (cid:96) ) W M D / r / news 0 2 4 6 8 Conversation Depth ( (cid:96) ) / r / worldnews 0 2 4 6 8 Conversation Depth ( (cid:96) ) / r / politics Figure 6 : Box plot of Word Movers Distance ( WMD ) as a function of the conversation depth (cid:96) . Lower is better . Box plots represent WMD - error of entity representations predicted by the narrative hypergraph over all entities , over all depth , over ﬁve folds . Speciﬁcally , we seek to understand what conversations on Reddit look like . Do they splinter , narrow , or behave in some other way ? We call the set of visual paths conversation traversals because they indicate how users traverse the entity graph . We generate these visual conversation traversals using a slightly modiﬁed force directed layout [ 16 ] . Graph layout algorithms operate like graph em - bedding algorithms LINE , node2vec , etc , but rather than embedding graphs into a high dimension space , visual graph layout tools embed nodes and edges into a 2D space . In our setting we do make some restrictions to the algorithm in order to force topics to coalesce into a visually meaningful and standardized space . Speciﬁcally , we ﬁx the position of each vertex in our graph on the x - axis according to (cid:96) . As in Fig . 4 , individual entity vertices always occur to the left of entity set vertices , making the visualization il - lustrate how conversations ﬂow from the start to ﬁnish in a left to right fashion . This restriction forces the embedding algorithm to adjust the position only on the y - coordinate , and this is necessary to allow the individual entity to entity set edges from the star - expansion to pull entity set vertices close together if and only if they share many common entities . Loosely connected or disconnected entities will therefore not be pulled together . As a result , the y - axis tends to cluster entities and entity - sets together in a semantically meaningful way . Embedding algorithms are typically parameterized with a learning rate parameter that determines how much change can happen to the learned 13 representation at each iteration . Because we want entities to be consistent horizontally , we modify the learning rate function to increasingly dampen embedding updates over 100 iterations per depth . For example , given a entity graph of depth L = 10 , we would expect 1 , 000 iterations total . We initially allow all entities and entity sets to update according to the default learning rate , but as the iterations increase to 100 the learning rate of the entities and entity sets at (cid:96) = 1 will slowly dampen and eventually lock into place at iteration 100 . When these entities and entity sets lock we also lock those same entities and entity sets at all other depths . This ensures that each of these entities and entity sets will be drawn as a horizontal line at the given y position . Then , from iterations 100 - 200 , the learning rate of the entities and entity sets at (cid:96) = 2 will slowly dampen and eventually lock into place at iteration 200 . Meanwhile the entities and entity sets at deep levels will continue to be reﬁned . In this way , the semantically meaningful y - coordinates tend to propagate from left to right as the node embedding algorithm iterates . One complication is that the sheer number of entities and the conver - sation paths over the entities is too large to be meaningful to an observer . So we do not draw the entity - nodes generated by the star - expansion and instead opt to rewire entities sets based on the possible paths through the individual entity nodes . We also tune the edge opacity based on the edge weights . We draw the resulting graph with D3 to provide an interactive visual - ization [ 2 ] . Conversation traversals of the entity graph generated from / r / news is illustrated in Fig . 7 . This illustration is cropped to remove the four deepest vertical axes ( on the right ) and is also cropped to show the middle half of the illustration . A zoomed in version highlights some interesting entity sets present in the / r / news conversation . Recall that the entity sets are consis - tent horizontally so that both red circles on the left and the right of the inset plot both indicate the entity set with Donald Trump ; likewise the blue circles on the left and the right of the insert both represent Barack Obama . Edges moving visually left to right indicate topical paths found in online dis - course . In the / r / news subreddit , which tracks only US news , Donald Trump and Barack Obama are frequent visits , but so too are national entities like United States ( not highlighted ) , Iraq , and others . It is diﬃcult to see from this illustration , but the expanded interactive visualization shows a common coalescing pattern where large sets of entities and unique combinations of ideas typically coalesce into more simple singleton entities like Barack Obama or United States . 14 Figure 7 : Entity graph showing the visual conversation traversals from / r / news . This illustration shows the paths of conversations over entity sets . The x - axis represents the depth of the conversation ; entity sets are clustered into a semantically meaningful space along the y - axis . Inset graph highlights ﬁve example entity sets and their connecting conversation paths . Node col - ors represent equivalent entity sets . In this example we highlight how entity sets are placed in meaningful semantic positions in relation to one another . 4 . 1 Spreading Activation Next , we adapt the illustration of conversation traversals to begin to answer RQ3 . Speciﬁcally , we are interested in how the diﬀerences in starting points , at the roots of the comment tree , have any impact on the eventual shape of the conversation . For example , given a conversation starting with Don - ald Trump how will the conversation take shape for liberals and how might that conversation be diﬀerent among conservatives ? This kind of analysis provides endless possibilities in the analysis of how diﬀerent groups of people think and articulate ideas a given topic . To help answer this question , we employ tools from the study of spreading activation [ 11 ] . Spreading activation is a concept from cognitive psychology that has been used to model how ideas spread and propagate in the brain from an initial source . A popular use for spreading activation has been on semantic networks to ﬁnd the relatedness between diﬀerent concepts . Formally , spreading activation works by specifying two parameters : ( 1 ) a ﬁring threshold F ∈ [ 0 , . . . , 1 ] and ( 2 ) a decay factor D ∈ [ 0 , . . . , 1 ] . The vertex / entity set selected by a user will be given an initial activation A i of 1 . This is then propagated to each connected vertex as A i × w j × D 15 Figure 8 : Entity graph example of spreading activation on / r / news when Barack Obama is selected as the starting entity . The x - axis represents the ( threaded ) depth at which each entity was mentioned within conversations rooted at Barack Obama . The y - axis represents the semantic space of each entity , i . e . , similar entities are closer than dissimilar entities on the y - axis . Node colors represent equivalent entity sets . In this example , we observe that conversations starting from Barack Obama tend to center around the United States , political ﬁgures such as Donald Tump , and discussion around whether his religion is Islam . 16 where w j is the weight of each edge connection to the corresponding vertex . Each vertex will then acquire its own activation value A i based on the total amount of signal received from all incoming edges . If a vertex has acquired enough activation to exceed the ﬁring threshold F , it too will ﬁre further propagating forward through the graph . In the common setting , vertices are only allowed to ﬁre once and the spreading will end once there is no more vertices to activate . In our work we use spreading activation as a method for a user to select a starting topic / entity set within the illustration of conversation traversals . The spreading activation function will then propagate the activation of en - tities along the conversation paths to highlight those that are mostly likely to activate from a given starting point . Because we permit the entity graph to be constructed ( and labeled ) from multiple subreddits , we can also use the spreading activation function to compare and contrast how users from diﬀerent subreddits activate in response to a topic . After spreading activation has been calculated , our interactive visualiza - tion tool removes all vertices and links that are not part of the activated portion of the graph . All of the vertices involved in spreading activation will have their size scaled based on how much activation they received . An example of this is cropped and illustrated in Fig . 8 , which shows how spread - ing activation occurs when the entity set Barack Obama is activated within / r / news . Here we see that conversations starting with ( only ) Barack Obama tend to move towards discussions about the United States . We also note that the Islam entity is semantically far away from Barack Obama and Don - ald Trump as indicated its placement on the y - axis . The results from using spreading activation allow for a much more granular investigation of conver - sational ﬂow . These granular levels of conversational ﬂow demonstrate that an individual can search for patterns related to inﬂuence campaigns , echo chambers and other social media maladies across a number of topics . 5 Comparative Analysis The visual conversation traversals appears to be helpful for investigating trends within a group . But , our ﬁnal goal is to use these to compare and contrast how diﬀerent groups move through the conversation space . Our ﬁrst attempt at this was to use and overlay separate plots and attempt to compare the trends . This would be challenging though because it would fail to capture the magnitude in any diﬀerences between the groups for vari - ous entity set transitions . Our second attempt , instead , modiﬁed the entity 17 graph creation process to take in data from two diﬀerent subreddits . By us - ing both communities we can capture how often an entity transition occurs in each subreddit and use color gradients to indicate the relative strength of each transition probability based on the edge weight we ﬁnd in each sub - reddit . This visually shows if correlations occur between subreddits . In the present work , we examined three diﬀerent scenarios among the subreddits in our dataset . Scenario 1 : liberals and conservatives Determining how motivated groups communicate about and respond to various topics is of enormous importance in modern communication studies . For example , communica - tion specialists and political scientists are interested in understanding how users respond to coordinated inﬂuence campaigns that ﬂood social media channels with the same message [ 33 ] . Repetition is key for the idea to stick , and we would expect then that these forms of messaging would begin to ap - pear in the entity graphs and possibly visually indicated in the conversation traversals . Although a full analysis of this diﬃcult topic is not within the purvue of the current work , we do perform a comparative analysis of / r / Conservative and / r / politics as proxies for comparing conservative and liberal groups , re - spectively . We pay particular attention to determining the particular topics and entities that each group tends to go towards later ( deeper ) in the con - versation . Such a comparative analysis may be key to understanding how coordinated inﬂuence campaigns orient the conversation of certain groups or de - rail them . The comparative illustration using spreading activation was used at the beginning of the paper in Fig . 1 and is not re - illustrated in this section . The illustration yields some interesting ﬁndings . While one might expect / r / Conservative to discuss members or individuals related to the republican party , we instead ﬁnd that conversations tend to migrate toward mentions of liberal politicians ( e . g . , Joe Biden ) indicated by red lines in Fig . 1 . The reverse holds true as well : mentions of Joe Biden leads towards mentions of the Republican Party by the liberal group , as indicated by the blue line connecting the two . A brief inspection of the underlying comments reveals that users in each subreddit tend to talk in a negative manner towards the other party’s politicians . This is a clear example of aﬀective polarization [ 22 ] being captured by our visualization tool . Aﬀective polarization is where individuals organize around principles of dislike and distrust towards the out - group ( the other political party ) even moreso than trust in their in - 18 group . Another ﬁnding we observe is the more pronounced usage of the United States by conservatives than liberals . This observation could be explained by the ﬁnding that conservatives show a much larger degree of overt patriotism than liberal individuals [ 20 ] , which has more recently lead to a renewed interest in populism and nationalism [ 12 ] . Scenario 2 : US news and Worldnews In our second scenario , we compare the conversations from / r / news ( red ) and / r / worldnews ( blue ) , which are geared towards US - only news and non - US news respectively . The comparison between these subreddits reveals unsurprising ﬁndings . A much larger portion of the entity sets come from / r / worldnews as they discuss a much broader range of topics . Many of the entity transitions that are dominated by / r / worldnews come from discussions of other countries , events , and people outside of the United States . The aspects that are shown to come primarily from / r / news are topics surrounding the United States , China , and major political ﬁgures from the United States . An example of this can be seen in Fig . 9 which illustrates spreading activation starting from White House . Here , the dominating red lines , which reﬂects transitions from within conversations on / r / news , converge to United States , even after topics like Russia or Islam are discussed . An interesting side note is that many of the unlabeled entities entering the conversation via blue lines ( / r / worldnews ) in (cid:96) = 5 and (cid:96) = 6 represent other countries such as Canada , Japan , Mexico , and Germany . The ﬁndings from this comparative analysis do not show any extremely interesting results but , it does show that the entity graph is able to capture what one would see as the assumed patterns to ﬁnd from comparing these two subreddits of interest . Scenario 3 : COVID and Vaccines Our ﬁnal analysis focuses on com - paring a single subreddit , / r / Coronavirus , but during two diﬀerent time periods . There is a large amount of work that has been done analyzing Covid online looking at partisanship [ 36 ] , user reaction to misinformation [ 24 ] , and diﬀerences in geographic concerns [ 19 ] . The ﬁrst segment ( high - lighted in red ) comes from the period of January through June in 2020 , which was during the emergence of the novel Coronavirus . Although the / r / Coronavirus subreddit had existed for many years prior , it became ex - tremely active during this time . The second segment was from the following year January - June 2021 . This time period corresponded to the develop - ment , approval and early adoption of vaccines . 19 Figure 9 : Illustration of an entity graph created from threaded conversations from / r / news ( red - edges ) and r / worldnews ( blue - edges ) . The x - axis repre - sents the ( threaded ) depth at which each entity set was mentioned within conversations rooted at White House . The y - axis represents the semantic space of each entity , i . e . , similar entities are closer than dissimilar entity sets on the y - axis . Nodes colors represent equivalent entity sets . Conversa - tions in / r / news tends to coalesce to United States , while conversations in / r / worldnews tend to scatter into various other countries ( unlabeled black nodes connected by thin blue lines ) Our analysis of this visualization yielded some interesting ﬁndings re - lated to the coronavirus pandemic that we illustrate in Fig . 10 . If we begin spreading activation from the perspective of United States we ﬁnd that most of the discussion leads to China and Italy in 2020 , which appears reasonable because of China and Italy’s early struggles with virus outbreaks . In com - parison , the 2021 data appeared more likely to mention Sweden , India , and Germany , which had severe outbreaks during those months . Our ﬁndings from spreading activation allow us to capture the shifting changes in coun - tries of interest from 2020 to 2021 as the pandemic progressed . 6 Discussion In the current work we presented a new perspective by which to view and think about online discourse . Rather than taking the traditional social net - works view where information ﬂows over the human participants , our view is to consider human conversations as stepping over a graph of concepts and entities . We call these discourse maps entity graphs and we show that they present a fundamentally diﬀerent view of online human communication . 20 Figure 10 : Comparison between the ﬁrst 6 months of / r / Coronavirus from 2020 to 2021 . Illustration of an entity graph created from threaded con - versations from / r / Coronavirus in Jan – June of 2020 ( red - edges ) and from Jan – June of 2021 ( blue - edges ) . The x - axis represents the ( threaded ) depth at which each entity set was mentioned within conversations rooted at United States . The y - axis represents the semantic space of each entity set , i . e . , similar entity sets are closer than dissimilar entity sets on the y - axis . Node colors represent equivalent entity sets . Conversations tended to focus on Chin a and Italy early in the pandemic , but turn towards a broader topic space later in the pandemic . Taking this perspective we set out to answer three research questions about ( 1 ) discourse prediction , ( 2 ) illustration , and ( 3 ) behavior comparisons between groups . We found that discourse remains diﬃcult to predict , and this prediction gets harder the deeper into the conversation we attempt predictions . We demonstrate that the visual conversation traversals provide a view of group discourse , and we ﬁnd that online discourse tends to coalesce into narrow , simple topics as the conversation deepens – although those topics could be wildly diﬀerent from starting topic . Finally , we show that the spreading activation function is able to focus the visualization to provide a comparative analysis of competing group dynamics . 21 6 . 1 Limitations While the work in its current state is helpful for better understanding con - versations , it is not without its limitations . Foremost , in the present work we only considered conversations on Reddit . Another limitation is that the entity linking method we chose is geared towards high - precision at the cost of low - recall . This means that we can be conﬁdent that the entities extracted in the conversations are mostly correct , but we have missed some portion of entities . The recall limitation does inhibit the total number of entities we were able to collect ; a better system would provide for better insights in our downstream analysis . This issue can also be highlighted with the long tail distribution of entities and the challenges this poses to current methods [ 21 ] . An entity linking model that focuses on recall may still result in useful graphs as prior works have found that many of the entities are considered “close enough” even when they are not a perfect match to ground truth data [ 14 ] . Using a diﬀerent entity linking model could lead to diﬀerent patterns extracted from our method . For a model that optimizes for higher recall it could create a much larger entity graph , though it would likely contain a fair amount of noise due to the precision - recall trade oﬀ . Another limitation inherent to the present work is the consideration of conversations as threaded trees . This is an imperfect representation of natu - ral , in - person conversation , and still diﬀerent from unthreaded conversations like those found on Twitter and Facebook , which may require a vastly diﬀer - ent entity graph construction method . Finally , the interactive visualization tool is limited in its ability to process enormous amounts of conversation data because of its reliance on JavaScript libraries and interactive browser rendering . 6 . 2 Future Work These limitations leave open avenues for further exploration in future work . Our immediate goals are to use the entity graphs to better understand how narratives are crafted and shaped across communities . Improvements in the entity linking process and addition of concept vertices , pronoun anaphora resolution , threaded information extraction and other advances in SocialNLP will serve to improve the technology substantially . We also plan to ingest other threaded conversational domains such as Hackernews , 4chan , and even anonymized email data . Extensions of this work could also include capturing more information between entity transitions such as the sentiment overlayed on a given entity or group of entities . This extra in - 22 formation could allow us to create entity graphs that not only show the transition but also how various groups speak and feel about those speciﬁc entities . 7 Acknowledgements The authors would like to thank Yifan Ding and Justus Hibshman for their feedback on the paper . This work is supported in part by the Defense Advanced Research Projects Agency ( DARPA ) and Army Research Oﬃce ( ARO ) under Contract No . W911NF - 21 - C - 0002 . References [ 1 ] Baumgartner , J . , Zannettou , S . , Keegan , B . , Squire , M . , and Blackburn , J . The pushshift reddit dataset . Proceedings of the international AAAI conference on web and social media , 2020 . [ 2 ] Bostock , M . , Ogievetsky , V . , and Heer , J . D 3 data - driven doc - uments . IEEE transactions on visualization and computer graphics 17 , 12 ( 2011 ) , 2301 – 2309 . [ 3 ] Botzer , N . , Ding , Y . , and Weninger , T . Reddit entity linking dataset . Information Processing & Management 58 , 3 ( 2021 ) , 102479 . [ 4 ] Brady , W . J . , Crockett , M . J . , and Van Bavel , J . J . The mad model of moral contagion : The role of motivation , attention , and design in the spread of moralized content online . Perspectives on Psychological Science 15 , 4 ( 2020 ) , 978 – 1010 . [ 5 ] Centola , D . The spread of behavior in an online social network experiment . science 329 , 5996 ( 2010 ) , 1194 – 1197 . [ 6 ] Chafe , W . Discourse , consciousness , and time : The ﬂow and dis - placement of conscious experience in speaking and writing . University of Chicago Press , 1994 . [ 7 ] Chafe , W . Language and the ﬂow of thought . The new psychology of language ( 2017 ) , 93 – 111 . [ 8 ] Chandrasekharan , E . , Pavalanathan , U . , Srinivasan , A . , Glynn , A . , Eisenstein , J . , and Gilbert , E . You can’t stay here : 23 The eﬃcacy of reddit’s 2015 ban examined through hate speech . Pro - ceedings of the ACM on Human - Computer Interaction 1 , CSCW ( 2017 ) , 1 – 22 . [ 9 ] Cheng , X . , and Roth , D . Relational inference for wikiﬁcation . Em - pirical Methods in Natural Language Processing , 2013 . [ 10 ] Cinelli , M . , De Francisci Morales , G . , Galeazzi , A . , Quat - trociocchi , W . , and Starnini , M . The echo chamber eﬀect on social media . Proceedings of the National Academy of Sciences 118 , 9 ( 2021 ) , e2023301118 . [ 11 ] Collins , A . M . , and Loftus , E . F . A spreading - activation theory of semantic processing . Psychological review 82 , 6 ( 1975 ) , 407 . [ 12 ] De Cleen , B . Populism and nationalism . The Oxford handbook of populism 1 ( 2017 ) , 342 – 262 . [ 13 ] Derczynski , L . , Maynard , D . , Rizzo , G . , Van Erp , M . , Gor - rell , G . , Troncy , R . , Petrak , J . , and Bontcheva , K . Analysis of named entity recognition and linking for tweets . Information Pro - cessing & Management 51 , 2 ( 2015 ) , 32 – 49 . [ 14 ] Ding , Y . , Botzer , N . , and Weninger , T . Posthoc veriﬁcation and the fallibility of the ground truth . arXiv preprint arXiv : 2106 . 07353 ( 2021 ) . [ 15 ] Farrell , T . , Fernandez , M . , Novotny , J . , and Alani , H . Ex - ploring misogyny across the manosphere in reddit . Proceedings of the 10th ACM Conference on Web Science , 2019 . [ 16 ] Fruchterman , T . M . , and Reingold , E . M . Graph drawing by force - directed placement . Software : Practice and experience 21 , 11 ( 1991 ) , 1129 – 1164 . [ 17 ] Garimella , K . , De Francisci Morales , G . , Gionis , A . , and Mathioudakis , M . Political discourse on social media : Echo cham - bers , gatekeepers , and the price of bipartisanship , 2018 . [ 18 ] Glenski , M . , Ayton , E . , Mendoza , J . , and Volkova , S . Multilin - gual multimodal digital deception detection and disinformation spread across social platforms . arXiv preprint arXiv : 1909 . 05838 ( 2019 ) . 24 [ 19 ] Guntuku , S . C . , Buttenheim , A . M . , Sherman , G . , and Mer - chant , R . M . Twitter discourse reveals geographical and temporal variation in concerns about covid - 19 vaccines in the united states . Vac - cine 39 , 30 ( 2021 ) , 4034 – 4038 . [ 20 ] Huddy , L . , and Khatib , N . American patriotism , national identity , and political involvement . American journal of political science 51 , 1 ( 2007 ) , 63 – 77 . [ 21 ] Ilievski , F . , Vossen , P . , and Schlobach , S . Systematic study of long tail phenomena in entity linking . Proceedings of the 27th Interna - tional Conference on Computational Linguistics , 2018 . [ 22 ] Iyengar , S . , Lelkes , Y . , Levendusky , M . , Malhotra , N . , and Westwood , S . J . The origins and consequences of aﬀective polariza - tion in the united states . Annual Review of Political Science 22 ( 2019 ) , 129 – 146 . [ 23 ] Jung , J . , Son , B . , and Lyu , S . Attnio : Knowledge graph explo - ration with in - and - out attention ﬂow for knowledge - grounded dialogue . Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ( EMNLP ) , 2020 . [ 24 ] Kalantari , N . , Liao , D . , and Motti , V . G . Characterizing the online discourse in twitter : Users’ reaction to misinformation around covid - 19 in twitter , 2021 . [ 25 ] Keith Norambuena , B . F . , and Mitra , T . Narrative maps : An algorithmic approach to represent and extract information narratives . Proceedings of the ACM on Human - Computer Interaction 4 , CSCW3 ( 2021 ) , 1 – 33 . [ 26 ] Kempe , D . , Kleinberg , J . , and Tardos , ´ E . Maximizing the spread of inﬂuence through a social network . Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining , 2003 . [ 27 ] Kolitsas , N . , Ganea , O . - E . , and Hofmann , T . End - to - end neural entity linking . arXiv preprint arXiv : 1808 . 07699 ( 2018 ) . [ 28 ] Kusner , M . , Sun , Y . , Kolkin , N . , and Weinberger , K . From word embeddings to document distances . International conference on machine learning , 2015 . 25 [ 29 ] Mateas , M . , and Sengers , P . Narrative intelligence . J . Benjamins Pub . , 2003 . [ 30 ] Medvedev , A . N . , Lambiotte , R . , and Delvenne , J . - C . The anatomy of reddit : An overview of academic research . Dynamics on and of Complex Networks , 2017 . [ 31 ] Moon , S . , Shah , P . , Kumar , A . , and Subba , R . Opendialkg : Explainable conversational reasoning with attention - based walks over knowledge graphs . Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics , 2019 . [ 32 ] Page , R . The narrative dimensions of social media storytelling . The handbook of narrative analysis ( 2015 ) , 329 – 347 . [ 33 ] Paul , C . , and Matthews , M . The russian “ﬁrehose of falsehood” propaganda model . Rand Corporation 2 , 7 ( 2016 ) , 1 – 10 . [ 34 ] Ram , A . , Prasad , R . , Khatri , C . , Venkatesh , A . , Gabriel , R . , Liu , Q . , Nunn , J . , Hedayatnia , B . , Cheng , M . , Nagar , A . , et al . Conversational ai : The science behind the alexa prize . arXiv preprint arXiv : 1801 . 03604 ( 2018 ) . [ 35 ] Ran , C . , Shen , W . , and Wang , J . An attention factor graph model for tweet entity linking . Proceedings of the 2018 World Wide Web Conference , 2018 . [ 36 ] Rao , A . , Morstatter , F . , Hu , M . , Chen , E . , Burghardt , K . , Ferrara , E . , Lerman , K . , et al . Political partisanship and anti - science attitudes in online discussions about covid - 19 : Twitter content analysis . Journal of medical Internet research 23 , 6 ( 2021 ) , e26692 . [ 37 ] Schia , N . N . , and Gjesvik , L . Hacking democracy : managing inﬂu - ence campaigns and disinformation in the digital age . Journal of Cyber Policy 5 , 3 ( 2020 ) , 413 – 428 . [ 38 ] Sevgili , O . , Shelmanov , A . , Arkhipov , M . , Panchenko , A . , and Biemann , C . Neural entity linking : A survey of models based on deep learning . arXiv preprint arXiv : 2006 . 00575 ( 2020 ) . [ 39 ] Shahaf , D . , and Guestrin , C . Connecting the dots between news articles . Proceedings of the 16th ACM SIGKDD international confer - ence on Knowledge discovery and data mining , 2010 . 26 [ 40 ] Shahaf , D . , Yang , J . , Suen , C . , Jacobs , J . , Wang , H . , and Leskovec , J . Information cartography : creating zoomable , large - scale maps of information . Proceedings of the 19th ACM SIGKDD interna - tional conference on Knowledge discovery and data mining , 2013 . [ 41 ] Shen , W . , Wang , J . , and Han , J . Entity linking with a knowl - edge base : Issues , techniques , and solutions . IEEE Transactions on Knowledge and Data Engineering 27 , 2 ( 2014 ) , 443 – 460 . [ 42 ] Tadesse , M . M . , Lin , H . , Xu , B . , and Yang , L . Detection of depression - related posts in reddit social media forum . IEEE Access 7 ( 2019 ) , 44883 – 44893 . [ 43 ] van Hulst , J . M . , Hasibi , F . , Dercksen , K . , Balog , K . , and de Vries , A . P . Rel : An entity linker standing on the shoulders of giants , 2020 . [ 44 ] Weedon , J . , Nuland , W . , and Stamos , A . Information opera - tions and facebook . Retrieved from Facebook : https : / / fbnewsroomus . ﬁles . wordpress . com / 2017 / 04 / facebook - and - information - operations - v1 . pdf ( 2017 ) . [ 45 ] Yu , W . , Zhu , C . , Li , Z . , Hu , Z . , Wang , Q . , Ji , H . , and Jiang , M . A survey of knowledge - enhanced text generation . arXiv preprint arXiv : 2010 . 04389 ( 2020 ) . [ 46 ] Zhang , H . , Liu , Z . , Xiong , C . , and Liu , Z . Grounded conversa - tion generation as guided traverses in commonsense knowledge graphs . arXiv preprint arXiv : 1911 . 02707 ( 2019 ) . [ 47 ] Zien , J . Y . , Schlag , M . D . , and Chan , P . K . Multilevel spectral hypergraph partitioning with arbitrary vertex sizes . IEEE Transac - tions on computer - aided design of integrated circuits and systems 18 , 9 ( 1999 ) , 1389 – 1399 . [ 48 ] Zomick , J . , Levitan , S . I . , and Serper , M . Linguistic analysis of schizophrenia in reddit posts . Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology , 2019 . 27