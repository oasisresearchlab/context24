Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Leilani Battle leibatt @ cs . washington . edu University of Washington Seattle , Washington , USA Alvitta Ottley alvitta @ wustl . edu Washington University St . Louis , Missouri , USA ABSTRACT Researchers have devised many theoretical models for specifying users’ objectives , tasks , and insights as they interact with a visualiza - tion system . These representations are essential for understanding the insight discovery process , such as when inferring user interac - tion patterns that lead to insight or assessing the rigor of reported insights . However , many theoretical models can be notoriously difficult to translate into code , limiting their applicability across multiple studies . This paper calls attention to the consistent struc - tures that recur across the visualization literature and describes how they connect multiple theoretical representations of insight . We present a toolkit called Pyxis that makes it easy to specify insights , tasks , and objectives using these consistent structures , enabling a wider audience of researchers and developers to adopt the corre - sponding models . Furthermore , our evaluation scenarios show that Pyxis enables a broader and deeper understanding of the structure and properties of insight compared to theoretical representations alone . CCS CONCEPTS • Computer systems organization → Embedded systems ; Re - dundancy ; Robotics ; • Networks → Network reliability . KEYWORDS datasets , neural networks , gaze detection , text tagging ACM Reference Format : Leilani Battle and Alvitta Ottley . 2022 . Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks . In Proceedings of Make sure to enter the correct conference title from your rights confirmation emai ( Conference acronym ’XX ) . ACM , New York , NY , USA , 15 pages . https : / / doi . org / XXXXXXX . XXXXXXX 1 INTRODUCTION Ben Shneiderman famously said , “the purpose of visualization is insight , not pictures , ” underscoring a long - held conviction in the visualization community that the goal of the visualization tool is to enhance the user’s understanding of the underlying data [ 29 ] . To this end , numerous scholars have aimed to understand the insight Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM mustbehonored . Abstractingwithcreditispermitted . Tocopyotherwise , orrepublish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY © 2022 Association for Computing Machinery . ACM ISBN 978 - 1 - 4503 - XXXX - X / 18 / 06 . . . $ 15 . 00 https : / / doi . org / XXXXXXX . XXXXXXX discovery process , to design visualization tools to maximize insight , and to develop insight - based evaluation methodologies . This body of work in insight discovery has helped researchers derive meaning from their empirical observations ; for example , to infer a user’s objective through recurring patterns in her logged interactions [ 6 , 41 ] , or to understand which of the user’s utterances correspond to high - quality insights [ 44 , 74 ] . An emergent theme from this body of work is that insights , ob - jectives , and tasks , are inextricably linked . For example , the types of insights gained during a task are likely influenced by the user’s cur - rent objective , such as confirming an established hypothesis versus searching for interesting patterns in the data [ 7 ] . Similarly , when a user pivots to a new task , i . e . , changes their analysis objective , their recent insights likely influenced that pivot . The literature also seems to suggest that generalizable theory models should capture not only the various facets of user tasks ( insights and objectives ) but also their interconnected nature . For example , Andrienko and An - drienko model these connections by defining visualization tasks in two parts [ 4 ] : the target information sought during the task and the constraints the target has to fulfill . Brehmer and Munzner expand on this principle through a multi - level typology that connects why the user performs a task , how they execute the related methods , and what the task’s inputs and outputs are [ 10 ] . By connecting the inputs that guide the task ( objectives ) with the outputs produced from the task ( insights ) , theoretical task models provide a holistic structure that enables researchers to analyze how tasks evolve and induce particular insights over time . However , these complex relationships can be challenging to operationalize , leading to ad hoc solutions that fail to generalize to tasks observed in research and practice . For example , recent work has shown how existing task models are difficult to incorpo - rate into visualization tools due to the intensive effort involved in translating them into code [ 19 , 24 ] . Even when they are eventually programmed , it seems these models fail to generalize to logs from just a few tools [ 19 ] . Based on these findings , we argue that visu - alization researchers lack toolkits for expressing the connections between objectives , insights and tasks , which could ease the pro - cess of making sense of users’ analytic behavior . Similar to how D3 [ 9 ] and Vega - Lite [ 57 ] reduce barriers to creating visualizations , toolkits can make the expressive power of visualization task models accessible to a wider audience of researchers as well as a broader range of empirical applications . In this paper , we introduce a toolkit called Pyxis for more pre - cise specification of users’ insights , objectives , and analysis tasks as well as the relationships between them . Pyxis supports a diverse range of empirical applications , from recreating theorized tasks a r X i v : 2206 . 04767v2 [ c s . H C ] 5 O c t 2022 Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . in the literature to evaluating existing theoretical models to ana - lyzing logged user interactions and insights . To build Pyxis , we synthesize existing task theory literature into a precise definition of task that can be implemented through code . Rather than defining a task as a sequence of interactions , we instead define a task by the user’s objective in performing it and the insights extracted through completing it . Assuming a retrospective analysis , where we have detailed knowledge of the user’s objectives , actions , and insights ( i . e . , through rich user study data ) , we can measure the scope of the corresponding tasks programmatically using inferences and data transformations encoded using Pyxis . To demonstrate the utility of Pyxis , we apply it to a wide range of example tasks , insights , and analysis sessions from the literature . Not only was Pyxis ex - pressive in all cases , but the resulting structures contribute new understanding and nuance to established theories regarding the scope , complexity , and discovery of insights . To summarize , this paper makes the following contributions : • We present a review of the relevant literature on visualization task theory , which we synthesize into concrete design goals for developing task model toolkits to better support empirical applications . • We introduce Pyxis , a toolkit for specifying connections between insights , objectives , and tasks . We define the key theoretical components behind Pyxis and share examples of the Pyxis syntax . • We apply Pyxis to three different empirical applications to demonstrate its versatility . All of the code is publicly avail - able and shared through our supplemental materials 1 , in - cluding a collection of interactive tutorials on Observable . 2 BACKGROUND The insight discovery process is often studied in terms of the various tasks analysts perform in pursuit of insight . In this section , we review key concepts from existing visualization task theory that we build upon in Pyxis . We use these concepts to guide our formal definition of tasks , objectives and insights as well as the Pyxis language design . 2 . 1 Insight Existing research places a strong emphasis on insight discovery during visual analysis and exploration tasks [ 11 , 24 , 44 ] . For ex - ample , researchers often test visual analysis tools by the quan - tity , accuracy , and quality of insights users generate while using them [ 7 , 38 , 45 , 55 , 74 ] . Thus , insights appear to play a critical role in visual analysis tasks , where the formulation of insights ( or lack thereof ) may suggest the end of a task . Here , we summarize existing definitions and characteristics of insight , and highlight recurring overlaps and themes that we leverage to build Pyxis . 2 . 1 . 1 Categories of Insight . The prior work details several high - level categories of insights . For example , Chang et al . [ 11 ] distin - guish between a “knowledge - building insight , ” or information that directly extends a user’s existing knowledge structures , and “spon - taneous insight , ” or a “eureka” moment that reorganizes or connects loosely related knowledge structures . This distinction is similar to 1 https : / / osf . io / t9e63 / ? view _ only = 9857ef52c3334739b0001dd6d7cf324c “directed” versus “unexpected” insights as proposed by Saraiya et al . [ 55 ] . Chang et al . [ 11 ] argue that knowledge - building insight is typically the focus of visualization and visual analytics work [ 11 ] , though some argue the opposite [ 50 , 51 , 61 ] . We focus on analyzing knowledge - building insights in this paper , however Pyxis could be extended to represent spontaneous insights as well . Alternatively , Smuc et al . [ 64 ] and Liu and Heer [ 38 ] observe that users may also gain insights into how to improve the visual analysis tool they are interacting with , and distinguish between data insights and tool insights . Further , Pousman et al . argue that traditional visual analytics systems focus on “analytic insight , ” and suggest that tools designed for casual information visualization scenarios support other kinds of insight , in particular “awareness insight , ” “social insight , ” and “reflective insight” [ 51 ] . Saraiya et al . define four different categories of insights [ 54 , 55 ] : “overview , ” “pat - terns , ” “groups , ” and “details . ” Finally , Liu and Heer propose seven insight categories for analyzing exploratory visual analysis out - comes [ 38 ] : “observation , ” “generalization , ” “hypothesis , ” “question , ” “recall , ” “interface , ” and “simulation , ” where we find that the simu - lation category was not proposed in prior insight studies . These categories act as a supserset of sorts , and overlap significantly with categories proposed in the literature , such as those by Saraiya et al . [ 54 – 56 ] and North [ 45 ] , Smuc et al . [ 64 ] , Gomez et al . [ 20 ] and Guo et al . [ 24 ] , and Yi et al [ 71 ] . Note that these categories are not mutually exclusive , and have been found to co - occur [ 64 ] . Rather than defining fixed insight classes , we instead introduce a formal definition for data relationships , which can capture differ - ing levels of dataset coverage ( overview ) , statistical patterns and clusters ( patterns ) , user - defined groupings of data tuples ( groups ) , and detailed information for individual tuples of interest ( details ) such as outliers [ 45 ] . 2 . 1 . 2 The Varying Definitions of Insight . The literature present inconsistent definitions for what constitutes an insight . We use these existing definitions to mine the literature for concrete ex - amples of insights , which we recreate using Pyxis to demonstrate its applicability to a wide range of data analysis and exploration scenarios . For example , insights are utterances . In the context of a user study , Saraiya et al . define insight as “an individual observa - tion about the data by the participant , a unit of discovery , ” [ 54 , 55 ] which can include “any data observation that the user mentions” during in - person lab studies [ 38 , 55 , 73 , 74 ] , as well as self - reported insight diaries collected through field studies [ 56 ] and competition submissions [ 50 ] . Gomez et al . observe that users may only report a subset of their insights that are relevant to the study at hand [ 20 ] . Zgraggen et al . posit that insights may not only be explicitly defined through direct user reporting but also implicitly defined through observation , such as when the user is observed performing an anal - ysis but does not officially report the outcome of this analysis to experimenters [ 74 ] . The prior work also suggests that insights are knowledge links . In particular , Chang et al . argue that in visual analytics “in - sight is considered to be more or less units of knowledge” [ 11 ] . Oth - ers refine this idea further by defining insights as links that connect analysis findings , such as visualizations and statistical results [ 65 ] , with user knowledge [ 2 , 3 , 21 – 23 , 26 , 44 , 52 , 53 , 55 , 56 , 62 – 64 , 71 ] , such as knowledge synthesized from the current session or earlier Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY sessions [ 11 , 21 – 23 , 26 , 56 , 62 – 64 ] , or a priori knowledge the user brings to the exploration process [ 3 , 22 , 23 , 26 , 51 , 53 , 56 , 62 , 64 , 71 ] . These links can be implicit , such as when observed through qualita - tive insight studies [ 55 , 56 , 64 ] , or explicit , such as when users apply annotation interactions [ 21 , 22 ] or link interactions [ 17 , 21 , 22 , 26 , 62 , 63 ] to connect system visualization state with concepts recorded in their own digitized notes . Furthermore , insights can be hierar - chical in nature , and build on one another over time , increasing the complexity of subsequent insights [ 21 , 23 , 39 , 44 , 51 , 55 , 56 , 62 , 64 ] . Moreover , Pike et al . argue for more formal semantics for captur - ing user insights , which can enable visual analysis systems to more effectively process , reason about and even extract new insights [ 47 ] . Smuc et al . argue that insights can be more effectively analyzed through a direct analysis of how users’ reported insights build on one another , and propose relational insight organizers ( or RIOs ) to organize and visualize the resulting insight graph [ 64 ] . RIOs share similarities with the structures proposed by Gotz et al . [ 22 ] , where user knowledge is also captured as a graph , with high level con - cepts and instantiations of these concepts stored as nodes within the graph , and links between concepts and analysis findings stored as edges in the graph . Similar graph - based structures have also been suggested by Shrinivasan and van Wijk [ 63 ] , Mathisen et al . [ 39 ] , and He et al . [ 26 ] . Several works categorize insights in terms of how they support user hypotheses , claims , and reflections , pointing to a third def - inition – insights are data facts . Choe and Lee propose eight insight classes , where five classes are statistical in nature ( “trend , ” “correlation , ” “data summary , ” “distribution , ” and “outlier” ) , two are adapted from existing taxonomies ( “detail” [ 55 , 56 ] and “self - reflection” [ 51 ] ) , and the final “comparison” class reinforces the established link between analysis findings and user knowledge that defines insights . Zgraggen et al . propose five insight classes , all of which are statistical in nature [ 74 ] : “shape , ” “mean , ” “vari - ance , ” “correlation” and “ranking” . We observe that the statistical insight classes proposed by Choe and Lee [ 12 ] and Zgraggen et al . [ 74 ] all fall under the “patterns” category originally proposed by Saraiya et al . [ 55 , 56 ] . Visualization recommendation systems such as Voyager [ 68 ] , ForeSight [ 16 ] , DataSite [ 14 ] , SeeDB [ 66 ] , and Voder [ 65 ] extract statistical patterns , relationships , and anomalies to strengthen the user’s understanding of the data , and hopefully guide the user toward new insights . Chen et al . formalize the re - lationship between statistical analysis findings , or data facts , and insight through their Fact Management Framework [ 70 ] , which provides a theoretical base from which to derive formal a definition of insight . Finally , the prior work suggests that insights are hypotheses and / or evidence . For example , to evaluate how study participants perform during open - ended exploration tasks , Gomez et al . label each observed insight from their study as a “claim , ” i . e . , “a general hypothesis , question , or remark about the data model that is po - tentially synthesized from multiple observations , ” or as “evidence , ” such as an observation comprised of “specific references to data points” that support the claim [ 20 ] . Guo et al . augment the claim - evidence structure proposed by Gomez et al . to encompass “facts , ” “generalizations , ” and “hypotheses” [ 24 ] , where facts are units of truth extracted about specific entities observed in the data , general - izations are inferred relationships between observed entities , and hypotheses are claims that can be supported by facts and gener - alizations . Sacha et al . argue that users leverage analysis findings primarily as evidence to support , refute , or generate new hypothe - ses [ 53 ] : “Analysts try to find evidence that supports or contradicts hypotheses in order to gain knowledge from data . ” At face value , these definitions of insight may appear distinct . However , a close look at the varying perspectives points to an overarching theme – an insight is a unit of knowledge . How one captures ( e . g . , through utterances ) or represents ( e . g . , as data facts or evidence ) specific instances of insights would depend on the instrumentation and observations available to the researcher . Our work unites these perspectives . Rather than focusing on how we capture the user’s knowledge , we present a formal as well as programmatic representation that captures the knowledge source and links . 2 . 2 Objective The existing literature emphasizes the importance of objectives or goals in visual analysis tasks [ 7 , 37 , 52 ] . In a survey of the literature on exploratory visual analysis , Battle and Heer observe that goals are a pervasive topic [ 7 ] . Lam et al . make a similar observation in their survey of the design study literature [ 37 ] . Furthermore , in their review of existing definitions of visual analysis tasks , Rind et al . argue that the concept of objective should be emphasized over the concept of task in visualization research [ 52 ] . For these reasons , we incorporate objectives as a key component in Pyxis . In this sub - section , we review existing definitions and characteristics of objectives , and highlight overlaps that we can exploit in Pyxis . The notion that objectives are questions is prominent in the literature . For example , North [ 44 ] suggests that analysis questions seem to drive user data analysis and exploration sessions . The insight - based evaluation protocol proposed by Saraiya et al [ 55 ] embraces this idea and involves first asking participants to list the analysis questions they might ask about a given data . O’brien et al . adopted the insight - based evaluation method for this study and asked participants to record initial questions that they may want to investigate about a particular genomics dataset prior to explo - ration [ 46 ] . O’brien et al . suggest that these questions represent “expected insights” that can later be compared with users’ actual insights after exploration . Finally , more recent work by He et al . adopted a similar strategy , where they asked study participants to “input tasks , ” which shared a similar structure to open - ended ques - tions , e . g . , “to explore effective drugs for * * tumor” [ 26 ] , which could be reframed as “what drugs are considered effective for * * tumor ? ” . He et al . also observe that users may switch tasks mid - exploration , denoted by inputting a new task description . In their model , Sacha et al . [ 53 ] focus on hypotheses rather than initial questions , pointing to another potential definition , objec - tives are hypotheses . They argue that “the visual analytics pro - cess is guided by hypotheses” [ 53 ] . Shrinivasan et al . too observe that hypotheses tend to drive subsequent analysis actions [ 62 ] . Fur - ther work by Rind et al . extend the knowledge generation model proposed by Sacha et al . to explicitly include the concept of a user analysis objective , which clarifies the relationship between users’ hy - potheses and insights [ 52 ] . However , Green et al . observe significant potential but also significant risk in users’ hypothesis generation Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . Figure 1 : A task is typically demarcated by the objective driv - ing it and insights discovered while completing it . processes as “it can be fraught with human cognitive bias” [ 23 ] . To mitigate potential confirmation bias , Zgraggen et al . take this idea further by framing exploratory visual analysis as multiple hypothe - sis testing , and evaluate each insight reported by study participants as separate hypotheses to be tested against the data [ 74 ] . Whether objectives are questions or hypotheses is not always clear - cut . For example , in their studies of exploratory visual analysis behavior , Liu and Heer [ 38 ] and Gomez et al . [ 20 ] observe analysts using both analysis questions and hypotheses as exploration ob - jectives . Our conceptualization builds directly on the definition of objective proposed by Rind et al [ 52 ] . We reinforce the connection between objectives , hypotheses , and questions established in the literature by linking these concepts : hypotheses or analysis ques - tions are often used to structure the user’s objective . Further , we specify the connection between objectives ( expected insights from a dataset ) and insights ( actual observations made from this dataset ) , which together define analytic tasks . 2 . 3 Task Tobuildaneffectiveandmeaningfulvisualizationsystem , researchers and developers are encouraged to consider the context under which the visualization system will be used [ 43 ] . A key component of this characterization process is identifying the analysis tasks that users seek to perform [ 40 , 59 ] . Many theoretical models have been devel - oped to streamline the process of identifying relevant and meaning - ful visual analysis tasks to drive system design [ 52 ] . These models often take the form of task taxonomies and typologies [ 19 ] , where specific tasks observed in the field or in lab studies are generalized into an abstract set of task classes , such as “Find Anomalies” [ 2 ] , “Search / Comparison” [ 33 ] or “characterizing data distributions and relationships” [ 7 ] . These models also take the form of frameworks , where the scope and structure of observed tasks , and relationships between these tasks , are abstracted into general - purpose hierar - chies . Examples include the framework of tasks , sub - tasks , actions , and events proposed by Gotz and Zhou [ 21 ] , and the goals to tasks framework proposed by Lam et al . [ 37 ] . We integrate ideas from ex - isting task models with principles from domain - specific languages for data science ( e . g . , [ 15 , 30 , 31 , 67 ] ) to build Pyxis . Prominent in the literature is the notion that the completion of tasks are often denoted by the insights that were ( or were not ) de - rived . For example , when an analyst discovers insights that answer their current question or support / refute their current hypothesis , then they will likely end the current task and move on to a new one [ 20 , 24 , 49 ] . Furthermore , if the analyst discovers insights that favor the pursuit of a new and unexpected task , then the analyst is also likely to end the current task and pivot to the new one [ 55 ] . This scenario also comes into play when an analyst fails to uncover any insights relevant to the current task , and switches to a more promising alternative [ 5 , 74 ] . We also observe in the literature that an analyst’s objectives in pursuing certain visual analysis tasks are often defined in relation to the kinds of insights they expect to uncover . This observation stems from the idea that a user’s data analysis strategy is not random ; it is likely informed by an initial goal or “hunch” [ 7 , 37 , 74 ] , even if only vaguely at first [ 7 ] . For example , Bertin defines tasks according to the structure of the underlying data and the information the user seeks to learn from this data [ 8 ] . Adrienko and Adrienko extend Bertin’s ideas to define tasks as declarative functions over data relations comprised of targets , i . e . , data attributes of interest , and constraints , i . e . , query predicates over these attributes [ 4 ] . We note that Adrienko and Adrienko and Bertin’s proposals overlap signif - icantly with established definitions of task in database research , notably relational calculus , a core component of the relational model that also defines tasks ( or queries ) as declarative functions over data relations [ 13 ] . However , existing declarative definitions of task are limited to expressing the intent behind the task ( what users aim to find ) and fail to capture the outcomes of the task ( what users actually find ) , which is of particular interest in insight discovery work . A new toolkit could fill this gap . In summary , the literature seems to suggest that visual analysis tasks are demarcated in the beginning by the objective driving the task and at the end by the insights uncovered from the task ; this relationship is shown in Figure 1 . This loose specification of the beginning and end of tasks from the literature points to a potential declarative approach to specifying visual analysis tasks , which we explore further in this paper . This specification is distinct from most definitions of visual analysis tasks found in the literature , which tend to focus on imperative definitions of tasks , such as by defining tasks in terms of the specific visualisations created or sequence of interactions performed using a particular visualization tool [ 4 , 7 , 52 , 69 ] . Unlike imperative task definitions , which may become brittle due to idiosyncrasies in visualization tool design , a declarative definition of task could generalize well across both visualization tools and empirical applications [ 4 ] . 3 DESIGN GOALS FOR PYXIS This paper aims to provide an executable implementation of ex - isting task models that can capture observed nuances between current definitions of insight and expresses the connections be - tween objectives , insights , and tasks . Based on our review of the visualization task theory literature , we highlight three recurring principles that connect insights , objectives , and tasks . For each principle , we present corresponding design goals for developing generalizable toolkits for task and insight modeling . These design goals inform the structure of our toolkit , Pyxis . Principle 1 : Insights Represent Linked Units of Knowledge . We observe in the literature that insights establish links between the user’s data manipulations , data observations and their knowledge of related phenomena , and new insights often link back to old ones as analysts’ understanding of the data evolves ( subsubsection 2 . 1 . 2 ) . Furthermore , analysts’ data interpretations often involve mining facts or relationships from the data , which researchers categorize in various ways ( subsubsection 2 . 1 . 1 ) . We observe that it may prove Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY difficult to capture these complex relationships within a single , monolithic definition of insight . Instead , toolkits may be better served by considering the constituent parts of insight and their relationships . To this end , we establish the following design goal : Design Goal 1 : Rather than specifying insights di - rectly , enable specification of the lower - level com - ponents of insight ( data manipulations , data relation - ships , and domain knowledge ) and their relationships . Principle 2 : Objectives Often Look Like Insights . Insights can lead to new questions and hypotheses , suggesting that insights can themselves become objectives that drive future analysis tasks ( sub - subsection 2 . 1 . 2 ) . This insight - objective connection is exemplified by how insights build on each other over time . Some even suggest that objectives are insights ( e . g . , [ 24 ] ) , blurring the line between insights and objectives even more . We observe that objectives are , in a sense , an expectation of insight . Rather than defining objectives independently from insights , these ideas suggest that objectives could be defined as a function or derivative of insights . For example , objectives could be defined as constraints on the space of possible insights an analyst may uncover from a given dataset . Based on these ideas , we propose our second design goal : Design Goal 2 : Use the same low - level components to define objectives and insights . Furthermore , con - sider defining objectives as constraints on or functions of insights . Principle 3 : Tasks Follow a Consistent Structure . We observe that objectives and insights often demarcate tasks and the literature consistently describes the structure of analysis tasks : they tend to begin with an objective driving the task and end with discovering insights that either meet the objective or hint at an alternative ( subsection 2 . 3 ) . For these reasons , we suggest that task model toolkits enable specification of this recurring task structure , leading to our third design goal : Design Goal 3 : Allow users to specify tasks declara - tively by linking objectives with insights . Together , these three design goals inform the structure and se - mantics behind Pyxis presented in the following section . 4 A PROGRAMMATIC DEFINITION OF VISUALIZATION INSIGHTS We present Pyxis , a specification language for defining visual analy - sis domain knowledge , analytic knowledge , insights , objectives , and tasks that is consistent with the academic literature . Our insight definition is inspired by the work of Gotz et al . , which defines an insight as a link connecting multiple knowledge bases used by an analyst [ 22 ] . Gotz et al . classify these knowledge bases into one of two groups : analytic knowledge , i . e . , information derived from manipulating and visualizing data , and domain knowledge , i . e . , out - side information that provides meaning and context to this data . Pyxis allows researchers to specify an insight using domain knowl - edge and analytic knowledge as the low - level building blocks or knowledge nodes . 4 . 1 Insights : Linking Domain Knowledge and Analytic Knowledge A grouping of domain knowledge and analytic knowledge nodes represents an insight . Thus , insights are a higher level representa - tion of knowledge within Pyxis , specified as follows : 𝑖𝑛𝑠𝑖𝑔ℎ𝑡 : = { 𝑛𝑎𝑚𝑒 , ∗∗ 𝑑𝑒𝑠𝑐𝑟𝑖𝑝𝑡𝑖𝑜𝑛 , [ 𝑑𝑜𝑚𝑎𝑖𝑛𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 1 , 𝑑𝑜𝑚𝑎𝑖𝑛𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 2 , . . . ] , [ 𝑎𝑛𝑎𝑙𝑦𝑡𝑖𝑐𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 1 , 𝑎𝑛𝑎𝑙𝑦𝑡𝑖𝑐𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 2 , . . . ] , [ 𝑠𝑜𝑢𝑟𝑐𝑒𝐼𝑛𝑠𝑖𝑔ℎ𝑡 1 , 𝑠𝑜𝑢𝑟𝑐𝑒𝐼𝑛𝑠𝑖𝑔ℎ𝑡 2 , . . . ] , [ 𝑡𝑎𝑟𝑔𝑒𝑡𝐼𝑛𝑠𝑖𝑔ℎ𝑡 1 , 𝑡𝑎𝑟𝑔𝑒𝑡𝐼𝑛𝑠𝑖𝑔ℎ𝑡 2 , . . . ] } The name and description are strings that describe the spe - cific insight recorded by the researcher or analyst . To support complex insights , more than one node can be specified in the domainKnowledge and analyticKnowledge properties . Further - more , insights can be hierarchical as new insights connect to or summarize existing ones [ 22 , 49 , 64 ] . In Pyxis , we can link any previous insights as a sourceInsight that informed the current insight and new insights as a targetInsight that were informed by the current insight . ∗∗ denotes optional arguments . This formulation enables us to track the growth of an analyst’s domain knowledge and analytic knowledge in tandem , as well as meaningful intersections between the two , i . e . , insights . With a precise specification of insights , we can unambiguously record which analysis findings ( or the lack thereof ) led to the completion of a given analysis task . However , insights can also be null results , which we can easily record by connecting the relevant null results from our analytic knowledge nodes . 4 . 2 Knowledge Nodes Domain knowledge and analytic knowledge are the low - level build - ing blocks of Pyxis . One unit of domain or analytic knowledge is represented as a knowledge node within a larger knowledge graph : 𝑘𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒𝑁𝑜𝑑𝑒 : = { 𝑛𝑎𝑚𝑒 , ∗∗ 𝑑𝑒𝑠𝑐𝑟𝑖𝑝𝑡𝑖𝑜𝑛 , [ 𝑠𝑜𝑢𝑟𝑐𝑒𝑁𝑜𝑑𝑒 1 , 𝑠𝑜𝑢𝑟𝑐𝑒𝑁𝑜𝑑𝑒 2 , . . . ] , [ 𝑡𝑎𝑟𝑔𝑒𝑡𝑁𝑜𝑑𝑒 1 , 𝑡𝑎𝑟𝑔𝑒𝑡𝑁𝑜𝑑𝑒 2 , . . . ] } where name is a string identifier and description provides an brief , optional explanation . Finally , we can link related knowledge nodes that appeared previously in the analysis and ones that mate - rialize in the future . 4 . 2 . 1 Defining Domain Knowledge . Consistent with Gotz et al . [ 22 ] we define domain knowledge nodes using two data structures en - coding concepts and instances . Specifically , we track concepts that analysts reason about while they analyze a dataset , the different types of concepts that arise , and specific instances of these concepts that stand out . Thus , the domain knowledge specification extends the knowledge node class : 𝑑𝑜𝑚𝑎𝑖𝑛𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒𝑁𝑜𝑑𝑒 : = { 𝑠𝑢𝑝𝑒𝑟 , 𝑖𝑛𝑠𝑡𝑎𝑛𝑐𝑒 } We define instance as follows : 𝑖𝑛𝑠𝑡𝑎𝑛𝑐𝑒 : = { 𝑛𝑎𝑚𝑒 , 𝑐𝑜𝑛𝑐𝑒𝑝𝑡 , 𝑑𝑎𝑡𝑎 } Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . An instance specifies a representative case of a concept and the supporting data . In Pyxis , domain knowledge concepts are similar to custom type definitions representing a belief or hypoth - esis that the analyst wants to express , such as the concepts of an “organization” , “conspiracy” , or “protest” . 4 . 2 . 2 Defining Analytic Knowledge . Analystsobtainanalyticknowl - edge through interactions and manipulation of visualization and data . We can deduce from the prior work on the insight discov - ery process ( see subsubsection 2 . 1 . 2 ) that analytic knowledge typ - ically takes the form of statistical characteristics derived from a dataset , such as correlations , distributions , sequences , or anom - alies [ 12 , 55 , 70 , 71 , 73 ] . We refer to these statistical characteristics as data relationships in Pyxis . However , analysts often have to pre - process their data prior to inferring relationships , such as filtering , aggregating , sorting , etc . , which we refer to as data transformations . Both data relationships and data transformations are considered forms of analytic knowledge in Pyxis . Thus , we extend the knowl - edge node class and specify analytic knowledge as follows : 𝑎𝑛𝑎𝑙𝑦𝑡𝑖𝑐𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒𝑁𝑜𝑑𝑒 : = { 𝑠𝑢𝑝𝑒𝑟 , 𝑑𝑎𝑡𝑎𝑇𝑟𝑎𝑛𝑠𝑓𝑜𝑟𝑚𝑎𝑡𝑖𝑜𝑛 , 𝑑𝑎𝑡𝑎𝑅𝑒𝑙𝑎𝑡𝑖𝑜𝑛𝑠ℎ𝑖𝑝 } Data Transformations . Similar to the approach of Adrienko and Adrienko [ 4 ] , we specify dataTransformations as queries over data relations . However , rather than re - defining these established functions , weintegrateexistingdatatransformationlibraries . Specif - ically , our codebase imports the Vega transforms library 2 and Ar - quero library [ 27 ] directly within Pyxis , so any transform that can be specified in Vega or Arquero can also be specified in Pyxis . Note that these libraries are themselves implementations of the relational model from database research , specifically , relational algebra [ 13 ] . Relational algebra can be thought of as an alternative to relational calculus ( see subsection 2 . 3 ) . Data Relationships . Pyxis supports multiple models for capturing multivariate dataRelationships , such as KNN ( K nearest neigh - bors ) , linear regression , and naive Bayes models , as well as uni - variate relationships ( e . g . , via kernel density estimation ) and other statistical relationships such as outliers ( e . g . , via isolation forests ) . In this way , specified analytic knowledge can be tested directly for statistical rigor by testing the accuracy of the underlying data relationships , supporting prior calls for more precise evaluation of user insights [ 74 ] . 4 . 3 Defining Objectives as Partially Specified Insights Analysis tasks tend to begin with objectives and end with insights , where insights are well - defined but objectives are often described only vaguely , if at all . This uncertainty can make objectives difficult to specify in a consistent way , demonstrated by the variability in how objectives are defined in the literature ( see subsection 2 . 2 ) . However , we leverage two key principles that remain consistent across prior work ( see section 3 ) . First , visual analysis objectives are described more as goals to be attained rather than actions to be performed , suggesting a declarative specification of objectives is 2 https : / / vega . github . io / vega / docs / transforms / possible . Second , objectives appear to be informed at least in part by the type of insights the user seeks to uncover , such as evidence for or against a given hypothesis or answers to a specific analysis question . This suggests that objectives could be specified in relation to expected insights . Therefore , Pyxis utilizes the insight definition to also specify objectives as follows : 𝑜𝑏𝑗𝑒𝑐𝑡𝑖𝑣𝑒 : = { 𝑛𝑎𝑚𝑒 , ∗∗ 𝑑𝑒𝑠𝑐𝑟𝑖𝑝𝑡𝑖𝑜𝑛 , [ 𝑑𝑜𝑚𝑎𝑖𝑛𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 1 , 𝑑𝑜𝑚𝑎𝑖𝑛𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 2 , . . . ] , [ 𝑎𝑛𝑎𝑙𝑦𝑡𝑖𝑐𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 1 , 𝑎𝑛𝑎𝑙𝑦𝑡𝑖𝑐𝐾𝑛𝑜𝑤𝑙𝑒𝑑𝑔𝑒 2 , . . . ] , [ 𝑠𝑜𝑢𝑟𝑐𝑒 1 , 𝑠𝑜𝑢𝑟𝑐𝑒 2 , . . . ] , [ 𝑡𝑎𝑟𝑔𝑒𝑡 1 , 𝑡𝑎𝑟𝑔𝑒𝑡 2 , . . . ] } The intuition behind our definition of objectives is that they are structured much like insights . Thus , objectives can also be repre - sented as links between domain knowledge and analytic knowl - edge nodes . For example , objectives often take the form of analysts evaluating an existing “hunch” they have about a certain phenome - non [ 18 , 22 , 74 ] , such as a potential conspiracy or crime . Similar to insights and other knowledge - based structures in Pyxis , objectives can also be hierarchical in nature . Thus , they can also connect to or summarize existing objectives , such as when analysts break goals down into smaller sub - tasks ( e . g . , [ 7 , 52 ] ) . However , the key difference lies in how objectives are often underspecified compared to insights . In Pyxis , we handle the un - certainty associated with objectives using the concept of wildcards . Specifically , we can represent an objective using an insight ob - ject in Pyxis , and insert a placeholder value ( i . e . , a wildcard ) for properties that are not currently specified ; for example , to denote missing analytic knowledge in a specified objective , we can replace [ analyticKnowledge _ 1 , analyticKnowledge _ 2 , . . . ] withawild - card . By extension , a fully - specified objective is by definition an insight . Ouradoption ofwildcardsis inspiredby thenotion of partial specifications in visualization recommendation research [ 42 , 68 , 72 ] . 4 . 4 Defining Task as Objective - Insight Pairs We define a task as a pairing of the objective driving the task and the set of insights discovered while completing the task : 𝑡𝑎𝑠𝑘 : = { 𝑛𝑎𝑚𝑒 , 𝑜𝑏𝑗𝑒𝑐𝑡𝑖𝑣𝑒 , [ 𝑖𝑛𝑠𝑖𝑔ℎ𝑡 1 , 𝑖𝑛𝑠𝑖𝑔ℎ𝑡 2 , . . . ] , [ 𝑠𝑜𝑢𝑟𝑐𝑒𝑇𝑎𝑠𝑘 1 , 𝑠𝑜𝑢𝑟𝑐𝑒𝑇𝑎𝑠𝑘 2 , . . . ] , [ 𝑡𝑎𝑟𝑔𝑒𝑡𝑇𝑎𝑠𝑘 1 , 𝑡𝑎𝑟𝑔𝑒𝑡𝑇𝑎𝑠𝑘 2 , . . . ] } Tasks can also be hierarchical and may comprise several smaller sub - tasks [ 7 , 37 ] . For this reason , we also structure tasks as node objects that can have sources and targets , similar to the other key components of Pyxis . We use the sourceTask to link a parent task to a particular task object . Similarly , we use targetTask to add a target task , i . e . , a sub - task . 5 ILLUSTRATIVE EXAMPLE Throughout this section , we demonstrate how to use Pyxis by recreating a data analysis scenario from Mathisen et al . [ 39 ] , which follows a fictional analyst , John , as he investigates crime peaks in Baltimore from 2012 through 2015 . John’s analysis uncovers the Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY first crime peak on April 27 , 2015 which coincides with protests sparked by the funeral of Freddie Gray , a young black man who was killed by the Baltimore police . An overview is provided in Figure 2 , where each node represents a particular Pyxis object that we create throughout the example , and the edges between nodes represent relationships between objects . 5 . 1 Domain Knowledge Example Pyxis enables us to formalize John’s domain knowledge as abstract concepts , e . g . , the “protests” and specific instances of these concepts , e . g . , the “Baltimore protests . ” We define the concepts “Crime” and “Protest” ( lines 1 - 8 ) . Then , we define an instance of the “Protest” concept based on the Baltimore Protests in 2015 ( lines 9 - 22 ) . Finally , we define a unit of domain knowledge as a new domain knowledge node ( lines 23 - 26 ) . Each node is associated with a specific instance , and each instance is associated with a core concept and ( optional ) relevant concepts . 1 const crime = new Concept ( 2 name : " Crime " , / / name 3 [ ] / / parentConcepts 4 ) ; 5 const protest = new Concept ( 6 " Protest " , / / name 7 [ ] / / parentConcepts 8 ) ; 9 const baltimoreProtests = new Instance ( 10 " WikipediaArticle - 2015BaltimoreProtests " , / / name 11 protest , / / coreConcept 12 { / / metadata 13 attributes : [ { 14 name : " link " , 15 attributeType : AttributeType . nominal 16 } ] , 17 values : { 18 " link " : " https : / / en . wikipedia . org / wiki / " + 19 " 2015 _ Baltimore _ protests " 20 } 21 } 22 ) ; 23 const protestsNode = new DomainKnowledgeNode ( 24 " 2015BaltimoreProtests " , / / name 25 baltimoreProtests / / instance 26 ) ; Researchers can link instances together by programming edges between their corresponding nodes which represent different con - ceptual relationships , such as one node “causing” another node , suggesting a directed relationship between the two nodes , or one node being “related to” another node , suggesting a general link but no causal direction . To link a source ( i . e . , parent ) node , we call the addSource function on the protestsNode object ; similarly , we call addTarget to add a target ( i . e . , child ) domain knowledge node . Related nodes can be linked using the addRelated function . 5 . 2 Analytic Knowledge Example To develop analytic knowledge , analysts infer relationships from a given dataset [ 22 , 49 , 65 , 70 ] , such as by visualizing potential trends or testing correlations through computational models , e . g . , calculating a linear regression . To prepare the data for visualization or modeling , analysts apply data transformations [ 27 , 58 , 70 ] , such as deriving new data attributes for further analysis , aggregating the data to calculate summary statistics , or filtering the data to remove irrelevant records . We demonstrate the application of these ideas through our continuing example . To start , we demonstrate how to create data transformations by using Arquero to calculate total reported crimes per day and identify peak crime days . 1 / / Arquero Data Transformation 2 const aggTransform = { 3 sources : [ baltimoreCrime ] , 4 transforms : [ 5 / / group by day 6 { op : " groupby " , args : [ " CrimeDate " ] } , 7 / / count crimes per day 8 { op : " rollup " , args : [ { count : op . count ( ) } ] } , 9 / / sort days by count 10 { op : " orderby " , args : [ desc ( " count " ) ] } , 11 / / return top 3 days with highest counts 12 { op : " filter " , args : [ ( ) = > op . rank ( ) < = 2 ] } 13 ] 14 } ; 15 const getAggTransformResults = 16 ( ) = > executeDataTransformation ( aggTransform ) ; First , we specify the input datasets , in this case the Baltimore crime dataset ( line 3 ) . Then , we list the transforms to execute : group the reported crimes by date ( line 6 ) , count total records per day ( line 8 ) , sort the dates by count ( line 10 ) , and filter for only the top three dates with the highest counts ( line 12 ) . Finally , we can execute the transformationsonthedatausingthe executeDataTransformation method on line 16 . 1 const crimePeaks = new AnalyticKnowledgeNode ( 2 " peakCrimes " , / / node name 3 Date . now ( ) , / / timestamp 4 aggTransform , / / data transformation 5 null , / / data relationship 6 getAggTransformResults , / / results 7 " top 3 days of reported crimes " / / [ optional ] description ↩ → 8 ) ; Then , we can record how John processed the data to identify peaks in a new analytic knowledge node . First , we give this unit of analytic knowledge a name ( line 2 ) and when he learned this knowledge ( line 3 ) . Then , we connect any relevant data transforma - tions and / or relationships ( lines 4 - 5 ) . In this case , John’s findings relate only to the aggTransform object . Optionally , we can add notes about what John learned as a final parameter ( line 7 ) . Sim - ilar to domain knowledge nodes , we can link to other analytic knowledge nodes using addSource , addTarget , and addRelated . All node objects in Pyxis share this linking property . Pyxis can also record data relationships in analytic knowledge nodes . Consider the following extension of the Baltimore exam - ple : suppose John is interested in determining whether location is Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . protest Concept baltimoreProtests Instance protestsNode Domain Knowledge crimePeaks Analytic Knowledge aggTransform Data Transformation johnsInsight Insight protestsObjective Objective protestsTask Task Figure 2 : An overview of how the major components of Pyxis connect to form insights , objectives and tasks , demonstrated by the illustrative example in section 5 recreating an analysis scenario where John , a ( fictitious ) analyst , investigates a crime peak in Baltimore that coincides with protests in the area [ 39 ] . The grey nodes represent the specified Pyxis objects from this example . Each node is labeled with its corresponding theoretical component from section 4 , shown in italics . The directed edges represent input relationships . For example , the protest object is an input to the baltimoreProtests object . indicative of crime type , for example , whether different crimes hap - pen indoors versus outdoors , or in an apartment versus a business . We can specify a new model to predict this relationship as follows : 1 const dt = new DecisionTreeClassificationRelationshipModel ( ↩ → 2 " predictCrimeType " , / / name 3 [ / / input attributes to predict with 4 { 5 name : " Inside / Outside " , 6 attributeType : AttributeType . nominal 7 } , 8 { 9 name : " Premise " , 10 attributeType : AttributeType . nominal 11 } 12 ] , 13 / / output attribute to be predicted 14 { 15 name : " Description " , 16 attributeType : AttributeType . nominal 17 } 18 ) ; 19 dt . train ( baltimoreCrimes . records ) ; 20 const prediction = dt . predict ( baltimoreCrimes . records [ 0 ] ) ; ↩ → Here , we specify a decision tree classifier to predict the rela - tionship ( line 1 ) . The input attributes used to train the model are “Inside / Outside” and “Premise” ( lines 3 - 12 ) . The output attribute being predicted is “Description” ( lines 14 - 17 ) , which describes the type of crime reported . Pyxis enables one to not only specify data relationships but also compute them directly on the input data . For example , Line 19 shows how we can train the specified decision tree model on the Baltimore crimes dataset using Pyxis , and Line 20 shows how this model can be used to predict the crime type of specific records . In this way , specified analytic knowledge can be evaluated for statistical rigor by testing the accuracy of the un - derlying data relationships , supporting prior calls for more precise evaluation of user insights [ 74 ] . Note that Pyxis supports multiple models for capturing multi - variate relationships , such as K nearest neighbors , linear regression , and naive Bayes models , as well as univariate relationships ( e . g . , via kernel density estimation ) and other statistical relationships such as outliers ( e . g . , via isolation forests ) . 5 . 3 Insight Example The last step in specifying insights is to link domain knowledge with relevant analytic knowledge . Continuing our example , we specify an insight connecting John’s domain knowledge about the Baltimore protests ( line 3 ) and analytic knowledge regarding peak crime dates in Baltimore ( line 4 ) : 1 const johnsInsight = new InsightNode ( 2 " johnsInsight " , / / name 3 [ protestsNode ] , / / domain knowledge 4 [ crimePeaks ] , / / analytic knowledge 5 " Peak Crime = Freddy Grey ' s Funeral " / / [ optional ] description ↩ → 6 ) ; Similar to the domain and analytic knowledge nodes , insight objects are also nodes , and thus support the linking of source , target , and related insights . 5 . 4 Objective Example We demonstrate the use of a wildcard below , denoted with “ * ” . In this case , we have a complete specification for domain knowledge ( line 3 ) but not for analytic knowledge ( line 4 ) . This suggests that John wants to explore a range of analyses that may potentially connect data with his existing domain knowledge , which we can frame as an analysis question : How did the date of Freddy Gray’s funeral ( April 27 , 2015 ) impact crime in Baltimore ? Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY 1 const protestsObjective = new InsightNode ( 2 " protestsObjective " , / / name 3 [ protestsNode ] , / / domain knowledge 4 " * " , / / analytic knowledge 5 " How did Freddy Gray ' s funeral impact Baltimore crime ? " / / [ optional ] description ↩ → 6 ) ; Now , suppose we stepped backward into John’s analysis timeline where he had initially uncovered the crime peak on April 27 , 2015 , but before he learned about Freddy Gray’s funeral . We can reframe the corresponding objective as the following question : What hap - pened on April 27 , 2015 that may have led to more crime ? In this example , we specify analytic knowledge ( line 4 ) and the wildcard appears for domain knowledge ( line 3 ) : 1 const aprilCrimeObjective = new InsightNode ( 2 " aprilCrimeObjective " , / / name 3 " * " , / / domainKnowledge 4 [ crimePeaks ] , / / analyticKnowledge 5 " What happened on April 27 , 2015 that may have led to more crime ? " / / [ optional ] description ↩ → 6 ) ; Note that we can also include wildcards within nested proper - ties , for example within a data relationship or data transform ( see supplemental materials for more details ) . 5 . 5 Task Example Using our Baltimore crimes example , we can specify John’s analysis task as shown below . In this case , John has an objective to explore potential relationships between protests and incidence of crime , represented by the protestsObjective object in line 3 . In pursuing this objective , he arrives at an insight , represented by the array containing the protestsInsight object in line 4 . 1 const protestsTask = new SimpleTaskNode ( 2 " protestsTask " , / / name 3 protestsObjective , / / objective 4 [ protestsInsight ] , / / insights 5 ) ; 6 DEMONSTRATIVE EVALUATION SCENARIOS Two distinguishing features of Pyxis are : ( 1 ) it collates existing visualization task theory into a coherent set of interconnected data structures and ( 2 ) it enables researchers to quantitatively analyze observed insights by declaratively specifying instances of and re - lationships between these data structures . In particular , we can use Pyxis to replicate existing examples of insights , objectives and tasks , and quantify the complexity and scope of these examples . We present three usage scenarios representing a diverse range of theoretical and empirical examples developed by Amar et al . [ 2 ] ( subsection 6 . 1 ) , North [ 44 ] ( subsection 6 . 2 ) , and Battle and Heer [ 7 ] ( subsection 6 . 3 ) . By recreating these analyses with Pyxis , we enable the community to revisit existing work from a new perspective , revealing unexplored ideas and opportunities for future research . We share the code for each usage scenario in our supplemental materials . 6 . 1 Usage Scenario 1 : Recreating Low - Level Components of Analytic Activity By enabling precise specification of insight , researchers who use Pyxis to represent insights , objectives , and tasks can quickly un - derstand how their specifications connect with prior work . We demonstrate these benefits through a usage scenario that explores an example task proposed by Amar et al . [ 2 ] . Our goal is to provide deeper insight into the task structure revealed by Pyxis . Amar et al . pose a broad , exploration - focused objective : “un - derstanding trends in [ movie ] popularity over time” . Then , they suggest two analysis sub - tasks in pursuit of this objective : ( 1 ) iden - tify movies that have won Academy Awards in the last ten years and ( 2 ) test for a correlation between movie length and popular - ity among award winners . To recreate this exploration task , we capture the results of the proposed analysis activity using a new in - sight object and show how to specify the proposed objective using wildcards . 1a ) First , We Define the Task . . . Figure 3 demonstrates a partially - specified task with unknown insights . 1b ) . . . And the Objective as a Partially - Specified Insight . . . . Given the original objective is quite broad , our objective in Figure 3 includes a domain knowledge node but replaces the analytic knowledge nodes with a wildcard in our specification . This specification suggests that the analyst is initially interested in film length , but the analysis approach is not yet known . We populate the filmLengthNode variable in the next step . 1c ) . . . And We Specify Domain Knowledge . Our objective depends on domain knowledge representing the analyst’s understand - ing of factors that may affect film quality . For example , Fig - ure 3 demonstrates how we can specify a new quality con - cept and record relevant articles as instances of the quality concept , such as articles discussing the effect of film length on movie popularity . Then , we record these instances in a new domain knowledge node ( filmLengthNode ) . 2 ) Then , We Record Analytic Knowledge representing our un - derstanding of how the data supports our concepts . For sub - task one , the example in Figure 3 joins a well - known movies dataset [ 68 ] with an Oscars dataset 3 to get detailed informa - tion for award - winning movies in our target time period . For sub - task two , we can specify a data relationship to test cor - relations between movie length and popularity ( e . g . , linear regression , decision tree regression , etc . ) . Our supplemen - tary material provides fully implemented examples for both sub - tasks . 3 ) Finally , We Link our Domain Knowledge Node and Analytic Knowledge Node by passing them as inputs to a new insight object named moviesInsight . Then , we can revisit our task definition , replacing the wildcard in Figure 3 ( 1a ) with the moviesInsight object to complete our task specification . 3 https : / / datahub . io / rufuspollock / oscars - nominees - and - winners # data Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . const moviesObjective = new InsightNode ( “moviesObjective” , / / objective name [ filmLengthNode ] , / / domain knowledge [ “ * ” ] , / / analytic knowledge / / [ optional ] description “Trends in movie popularity over time” ) ; 1234567 1a ) First , We Define the Task… 1b ) … the Objective as a Partially - Specified Insight… 1c ) … and Specify Domain Knowledge . 2 ) Second , We Record Analytic Knowledge . 3 ) Third , We Link Domain and Analytic Knowledge to Specify an Insight . const moviesTask = new SimpleTaskNode ( “moviesTask” , / / task name moviesObjective , / / objective [ “ * ” ] / / insights ) ; 12345 const filmDetailsNode = new AnalyticKnowledgeNode ( “filmDetails” , / / name Date . now ( ) , / / timestamp joinTransformation , / / data transformation null , / / data relationship / / [ optional ] description “Join oscar winners with movie details” ) ; filmDetailsNode . addSource ( oscarWinnersNode ) ; 123456789 const filmQuality = new Concept ( “FilmQuality” , / / name [ ] / / parentConcepts ) ; const biArticle = new Instance ( “BusinessInsiderArticle” , filmQuality , / / coreConcept [ ] , / / relevantConcepts { / / [ optional ] metadata attributes : [ { name : “link” , attributeType : AttributeType . nominal } ] , values : { link : “https : / / www . businessinsider . com / ” + “are - movies - getting - longer - 2016 - 6” } } ) ; const filmLengthNode = new DomainKnowledgeNode ( “filmLengthNode” , / / name biArticle / / instance ) ; 12345678910111213141516171819202122232425 const moviesInsight = new InsightNode ( “moviesInsight” , / / insight name filmLengthNode , / / domain knowledge / / analytic knowledge [ oscarWinnersNode , filmDetailsNode ] , / / [ optional ] description “Film length increases for all movies . ” ) ; 12345678 Figure 3 : A demonstrative scenario recreating Amar et al . ’s movie data exploration task [ 3 ] . First , we ( 1a ) specify the task with a wildcard to denote known domain knowledge but unknown analytic knowledge . This task involves an analysis objective ( 1b ) to explore relationships between film length and quality . We ( 1c ) record relevant domain knowledge in the form of online articles discussing film length . As we analyze the data in pursuit of the objective , we can ( 2 ) record our findings as analytic knowledge , and finally ( 3 ) link our domain and analytic knowledge to form an insight object , which we can use to complete our original task specification in ( 1a ) . Benefits of Pyxis . Some may consider the original objective posed by Amar et al . to be under - specified . For example , it is unclear whether studying movie length is the full objective ( as suggested by the insights proposed by Amar et al . ) or only part of a broader objective ( as suggested by the description of the objective ) . Under - specified objectives are generally considered difficult to analyze , however under - specified objectives are also common and even nec - essary in certain scenarios such as data exploration [ 1 , 7 ] . Pyxis provides just enough structure to preserve the flexibility of the an - alyst’s intent while also making the corresponding objectives more actionable for visualization systems . For example , now an objective can be specified in terms of permuting data inputs ( e . g . , different attributes ) , data outputs ( e . g . , different regression models or trans - formation operations ) , and the relationships between them , which provides a well - defined space of actions for generating automated recommendations . An objective can also be specified in relation to informative online articles , which could be mined for topics and keywords using NLP techniques , which in turn could guide the gen - eration of recommendations for relevant datasets to analyze . In this way , Pyxis transforms under - specified objectives into a strength rather than a weakness , and provides useful data structures for studying complex analysis scenarios like data exploration . 6 . 2 Usage Scenario 2 : Representing Analytic Knowledge of Varied Complexity To the best of our knowledge , Pyxis is the first task model toolkit that supports programmatic measurement of the depth and breadth of specified insights . We demonstrate this capability by exploring a range of insights posed by North [ 44 ] . North describes three forms of insights over monthly rents : calculating the maximum and minimum value , estimating a normal distribution , and capturing the shape of the data using a histogram . We use the 50th percentile rent estimates provided by the U . S . Department of Housing and Urban Development as our input dataset 4 . A ) Record “Simple” Insights . The simplest insight suggested by North computes minimum and maximum rent values . We can calculate them in our code using an aggregate data trans - formation . B ) Record “More Complex” Insights . North’s example of a “more complex” insight is to estimate a normal distribution over the rent data . We can specify a normal distribution data relationship in our code using Vega’s native support for statistical distributions 5 . C ) Record “Even More Complex” Insights . The most complex in - sight that North describes is estimating the shape of the rent distribution using a histogram . This estimate translates to a series of data transforms to bin the data and then aggregate it using the bin ranges , which we can calculate using Vega or Arquero . Benefits of Pyxis . In reflecting on this example as a whole , we see that North is defining insights at a relatively low level , even though these insights vary in complexity . Technically , the described data transformations and relationships are not considered full insights within our formalism , and instead are sub - units of analytic knowl - edge ( see subsubsection 4 . 2 . 2 ) . In this way , we also see how North’s definition of insight differs from the definition proposed by Gotz et al . [ 22 ] , which defines insights at a higher level of abstraction ( connecting analytic knowledge with domain knowledge ) . Further - more , we see how these two definitions still connect to broaden our overall understanding of insight . Specifically , both definitions include critical building blocks of insight , but North’s definition 4 https : / / www . huduser . gov / portal / datasets / 50per . html 5 https : / / github . com / vega / vega - statistics / Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY const skyNode = new AnalyticKnowledgeNode ( “skyKnowledge” , / / name Date . now ( ) , / / timestamp skyTransformation , / / transformation null , / / data relationship / / [ optional ] description “Incidents increase over time . ” ) ; 12345678 A ) First , We Analyze the Incidence of Strikes Using the precip Attribute const precipTransformation = { sources : [ birdstrikes ] , transforms : [ { op : “filter” , args : [ d = > d . precip ! = = null & & op . lower ( d . precip ) ! = = “none” ] } , { op : “derive” , args : [ { year : d = > op . year ( d [ “incident _ date” ] ) , precip : d = > op . lower ( d . precip ) } ] } , { op : “groupby” , args : [ “year” , ”precip” ] } , { op : “rollup” , args : [ { frequency : op . count ( ) } ] } , { op : “orderby” , args : [ “year” ] } ] } ; 1234567891011121314151617181920212223242526272829 B ) Second , We Analyze the sky attribute and Compare . const precipNode = new AnalyticKnowledgeNode ( “precipKnowledge” , / / name Date . now ( ) , / / timestamp precipTransformation , / / transformation null , / / data relationship / / [ optional ] description “Incidents do not increase with time . ” ) ; 12345678 ( a ) Specified data transformations ( left ) and analytic knowledge nodes ( right ) . Only lines6 - 7and13needtochangetoanalyzethe precip or sky attribute , showninyellow . 1 , 990 2 , 000 2 , 010 year 0 100 200 300 f r e qu e n cy fog fog , rain fog , rain , snow fog , snow rain rain , snow snow precip Total Strikes Per Year , Grouped By Precipitation ( b ) Analyzing the precip attribute . Participants likely posited that strikes do not increase with time . 1 , 990 2 , 000 2 , 010 year 0 1 , 000 2 , 000 3 , 000 f r e qu e n cy no cloud overcast some cloud some clouds sky Total Strikes Per Year , Grouped By Sky Conditions ( c ) Analyzing the sky attribute . Participants likely posited that strikes do increase with time . Figure 4 : Recreating results from a prior study where participants explored wildlife - aircraft strikes under various weather conditions , precip and sky [ 7 ] . Holding data transformations constant ( a ) , we posit that participants that focused on the precip attribute ( b ) likely drew different conclusions from those who focused on the sky attribute ( c ) , showing how attribute selection can influence insight discovery . describes a component of the broader definition of insight proposed by Gotz et al [ 22 ] . However , as hinted at by North , we can quantify the overall complexity of an insight by measuring the depth and breadth of its corresponding analytic knowledge nodes . Using Pyxis , we can hy - pothesize a new measure for knowledge node depth by computing the longest path from this node to the earliest node that it builds upon , which aligns with existing definitions of exploration depth posed in the literature [ 7 ] . In this case study , we see that all three examples are self - contained , i . e . , they are not connected to any other knowledge nodes . As a result , they all would have a depth of one . We can also conceive a new measure of knowledge node breadth as the percentage of data values ( rows × columns ) involved as inputs and outputs to the corresponding data transformations and / or relationships . Here , all three examples take the same data attribute ( rent ) and the same number of rows as input . Where they vary is in the size of the output of each corresponding data trans - formation / relationship , which shows that North may be defining the complexity of analytic knowledge primarily in terms of output size . 6 . 3 Usage Scenario 3 : Analyzing Participants’ Insights Although insight - based user studies have been critical to under - standing how people form insights , participants’ insights are gen - erally self - reported , requiring a means of validating insight quality . Traditionally this has been done by hand [ 24 , 38 , 44 , 55 , 56 ] . How - ever , recent work explores ways to partially automate the validation process [ 7 , 26 , 74 ] . Pyxis provides a convenient structure for validating participants’ insights and could facilitate further automation . We demonstrate this benefit by recreating insights reported by Battle and Heer from their study of how analysts explore data in Tableau [ 7 ] . We focus on task “T3” for the wildlife strikes dataset 6 , which asks : “What relationships ( if any ) do you observe involving weather conditions and strike frequency , or counts over time ? ” The task also specifies three attributes to consider : precip , sky , and incident _ date . We recreate two contradictory answers observed by Battle and Heer : ( A ) strikes are not correlated with time ( reported by 13 participants ) and ( B ) bad weather leads to more strikes over time ( reported by 3 participants ) . We use Pyxis to shed light on the discrepancy among participants , summarized in Figure 4 . A ) Analyze the precip Attribute . To recreate the first answer , we analyze the incidence of wildlife strikes using the precip at - tribute , shown in Figure 4a . Specifically , we apply a series of data transformations ( using Arquero ) to remove null precip entriesonlines4 - 7 , extracttheyearfromeach incident _ date on line 11 , and count the total incidents observed per year , grouped by precip conditions ( e . g . , “fog , ” “rain , ” etc . ) on lines 15 - 26 . Overall , we see that incidents do not appear to increase with time , with the exception of “rain” conditions , shown in Figure 4b . We can record these findings in a new analytic knowledge node named precipNode in Figure 4a . B ) Analyze the sky Attribute . To recreate the second answer , we repeat this analysis , but replace the precip attribute with the sky attribute . To do this , we replace precip with sky on lines 6 and 12 in our code , denoted in yellow in Figure 4a . In this case , we see a steady increase in incidents per year 6 https : / / wildlife . faa . gov / search Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . for all observed weather conditions , shown in Figure 4c . We can record these findings in a new analytic knowledge node named skyNode in Figure 4a . Benefits of Pyxis . We see that even if participants performed the exact same data transformations , they could still derive drastically different answers based on which attributes were analyzed . These results seem to suggest that even if participants’ analyzed both attributes while completing T3 , their final task answers were likely influenced by which attribute they favored , precip or sky . Since Battle and Heer focused primarily on interaction sequences in their analysis [ 7 ] ( i . e . , imperative definitions of task ) , they may have over - looked potential structural similarities in participants’ answers . By using a consistent structure to represent analytic knowledge , we see how the data could directly influence the direction of participants’ conclusions in this analysis task , regardless of which interaction sequences were performed . 7 DISCUSSION Pyxis aims to integrate multiple definitions and theories in visual - ization into a holistic framework . A powerful takeaway from our research is that although existing definitions differ in how they label the major components of insights , they largely agree on what these major components are and how they relate to one another . In other words , existing definitions are structurally consistent but seman - tically inconsistent . In Pyxis insights link analytical and domain knowledge , objectives are partially specified insights , and tasks are pairings between objective and insights . By formally defining these components and their relationships , our framework reinforces exist - ing structural consistencies and reduces semantic inconsistencies , enabling visualization researchers to re - examine these definitions on a more leveled playing field . In this section , we discuss benefits of and limitations to our approach , and opportunities to extend this work from theoretical , empirical , and systems design perspectives . 7 . 1 Imperative Versus Declarative Definitions of Task Pyxis’ task definition is markedly different from many of the ex - isting ones in the visualization community . In particular , existing models ( e . g . , taxonomies , typologies , or frameworks ) tend to fo - cus on task abstraction – translating specific instances of observed tasks into more universal , general - purpose structures [ 19 ] . This abstraction generally flows from low - level system details to high - level , system - agnostic concepts , such as translating findings from a specific interaction log into abstract concepts in an academic paper . Few provide support for the instantiation of tasks that is often help - ful for evaluating visual analytics systems . Our synthesized model offers a precise , systematic approach to applying high - level theo - ries of tasks to low - level analytics activities , which we implement within Pyxis . Although Pyxis results in a declarative definition of user tasks , it could potentially be used to capture imperative definitions of task as well , i . e . , the sequence of activities a particular user performed dur - ing a task . For example , interactions often map to specific low - level data transformations , such as changing an encoding to aggregate the data , or filtering the data via dynamic queries [ 10 , 28 ] . Using Pyxis , researchers could record these interactions as a chain of ana - lytic nodes , each containing an individual data transformation . Rele - vant utterances could be recorded using the description property of the corresponding nodes . Furthermore , analytic nodes can easily be extended to include new properties , for example a Vega - Lite specification representing how each interaction was rendered [ 58 ] . 7 . 2 Using wildcards for Partial Specification In our objective specification , the adoption of wildcards enables further flexibility , which was inspired by partial specifications in visualization recommendation research [ 42 , 67 , 68 , 72 ] . For example , the Voyager 2 system allows users to specify wildcards in place of individual encoding choices , which the system uses to generate recommendations [ 68 ] ; for example , if a user wants to “examine potential associations among quantitative fields , ” they can specify two quantitative attributes wildcards and encoding wildcards to visualize all pairs of quantitative attributes . This partial specifica - tion approach is of particular interest because the visualization design space is generally modeled as a graph , where individual visualizations map to specific nodes within this graph [ 72 ] . A com - plete specification within the visualization design space leads to a single visualization design and thus a single node within the cor - responding graph , whereas a partial specification leads to multiple visualization designs and potentially multiple target nodes . In other words , wildcards provide a way to control which properties of the design space will be permuted , allowing a visualization recommen - dation system to limit the range of nodes to be explored within the underlying design space graph . Much like how individual visualization designs are modeled as nodes within a larger design space , we model individual units of knowledge as nodes within one or multiple knowledge bases . However , in our case , the full graph is not known a priori . We observed this in Scenario 1 of subsection 6 . 1 in which the initial moviesTask and moviesObjectives were both partially - specified . That being said , our goal is to enable specification of individual tasks and objectives , and not necessarily to enumerate and rank the space of all the possibilities ( i . e . , the goal of visualization recommendation systems [ 72 ] ) . However , we can still use wildcards to our advantage when defining individual objectives and tasks . Moreover , wildcards highlight a vital principle of Pyxis : a partially - specified insight is an objective . 7 . 3 Inferring and Responding to User Goals We designed Pyxis primarily as an evaluation tool , limiting its im - mediate applicability to systems design . For example , although it is theoretically possible to incorporate Pyxis directly into visualiza - tion systems , as shown by the iterative description in Scenario 1 of subsection 6 . 1 , future work is needed to make said application a reality . In particular , instantiations of Pyxis assume that tasks and objective details are known . Thus , implementation would require capturing annotations or inferring such information in real - time , both of which involve overcoming human - related or technical chal - lenges . Still , Pyxis opens up new opportunities to design automated support features ( e . g . , visualization recommendation engines [ 72 ] ) Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY by leveraging existing techniques in artificial intelligence . For ex - ample , we represent analytic knowledge as graphs in this paper , where insights represent one or more nodes within these graphs . We also represent objectives as partially specified insight objects , which in turn represent a subset of possible goal nodes within these graphs . Using this framing , researchers could potentially formu - late visual analysis tasks in the future as graph search problems , which could be solved using existing search algorithms ( e . g . , A * [ 25 ] ) and path planning algorithms ( e . g . , probabilistic roadmaps [ 34 ] ) . Since our proposed objective specifications constrain the space of possible goal nodes , researchers could also tackle this problem using constraint - based search techniques ( e . g . , answer set program - ming [ 42 ] ) . Furthermore , Pyxis assumes that the user’s goals are always de - fined in terms of what the analyst knows and doesn’t know about the data or their domain . In reality , an analyst may have many reasons for analyzing a dataset , such as to present their findings to others [ 36 , 39 , 48 , 60 ] , or even just pure enjoyment [ 10 , 51 ] . An exciting opportunity for future work would be to extend Pyxis to in - corporate alternative motivations . As an example , one could model factors such as surprise or enjoyment as cost functions over the edges of an analytic knowledge graph . In other words , the analyst may search for a goal node that not only satisfies the specified objective but also maximizes surprise or enjoyment along the way . In another example , research in communication and narrative may require modeling not only the user’s knowledge but also the knowledge of the target audience [ 32 , 35 ] . How should domain and analytic knowledge be specified for target audiences ? How should relation - ships or discrepancies between presenter and audience knowledge be modeled ? With a manipulable graph representation for analysis tasks , objectives , and insights , researchers can make theoretical inferences that complement existing work . 8 CONCLUSION In a review of the literature , we find that researchers seem to agree on the structure of visual analysis insights , i . e . , their major building blocks , but not the semantics of insights , i . e . , terminology . However , the literature also seems to converge on the idea that objectives tend to be goals defined in relation to expected insights , hinting at a declarative approach to defining visual analysis tasks based on relationships between these core building blocks ( objectives , insights , user knowledge ) . Leveraging these ideas , we propose a unified model of insight discovery that tracks the objectives driving the user’s analysis , the insights the user gains along the way , and the analysis task that unites them . We implemented this model as a publicly available toolkit called Pyxis and demonstrate the versatility of Pyxis by recreating insights , objectives , and tasks from four different research papers . Through these case studies , we observe how different definitions of insight , objective and task interact with one another , we show how the expressiveness of Pyxis enhances these definitions , and and we highlight potential blind spots in existing work revealed by our work , which present interesting opportunities for future research . REFERENCES [ 1 ] Sara Alspaugh , Nava Zokaei , Andrea Liu , Cindy Jin , and Marti A . Hearst . 2019 . FutzingandMoseying : InterviewswithProfessionalDataAnalystsonExploration Practices . IEEE Transactions on Visualization and Computer Graphics 25 , 1 ( 2019 ) , 22 – 31 . https : / / doi . org / 10 . 1109 / TVCG . 2018 . 2865040 [ 2 ] R . Amar , J . Eagan , and J . Stasko . 2005 . Low - level components of analytic activity in information visualization . In IEEE Symposium on Information Visualization , 2005 . INFOVIS 2005 . 111 – 117 . https : / / doi . org / 10 . 1109 / INFVIS . 2005 . 1532136 ISSN : 1522 - 404X . [ 3 ] R . A . Amar and J . T . Stasko . 2005 . Knowledge precepts for design and evaluation of information visualizations . IEEE Transactions on Visualization and Computer Graphics 11 , 4 ( July 2005 ) , 432 – 442 . https : / / doi . org / 10 . 1109 / TVCG . 2005 . 63 Con - ference Name : IEEE Transactions on Visualization and Computer Graphics . [ 4 ] Natalia Andrienko and Gennady Andrienko . 2006 . Exploratory analysis of spatial and temporal data : a systematic approach . Springer Science & Business Media . [ 5 ] Calvin S . Bao , Siyao Li , Sarah G Flores , Michael Correll , and Leilani Battle . 2022 . Recommendations for Visualization Recommendations : Exploring Preferences andPrioritiesinPublicHealth . In Proceedingsofthe2022CHIConferenceonHuman Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 411 , 17 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3501891 [ 6 ] Leilani Battle , Remco Chang , and Michael Stonebraker . 2016 . Dynamic Prefetch - ing of Data Tiles for Interactive Visualization . In Proceedings of the 2016 Interna - tional Conference on Management of Data ( SIGMOD ’16 ) . ACM , New York , NY , USA , 1363 – 1375 . https : / / doi . org / 10 . 1145 / 2882903 . 2882919 [ 7 ] Leilani Battle and Jeffrey Heer . 2019 . Characterizing Exploratory Visual Analysis : ALiteratureReviewandEvaluationofAnalyticProvenanceinTableau . Computer Graphics Forum 38 , 3 ( 2019 ) , 145 – 159 . https : / / doi . org / 10 . 1111 / cgf . 13678 _ eprint : https : / / onlinelibrary . wiley . com / doi / pdf / 10 . 1111 / cgf . 13678 . [ 8 ] Jacques Bertin . 1983 . Semiology of graphics . University of Wisconsin press . [ 9 ] Michael Bostock , Vadim Ogievetsky , and Jeffrey Heer . 2011 . D3 Data - Driven Documents . IEEE Transactions on Visualization and Computer Graphics 17 , 12 ( 2011 ) , 2301 – 2309 . https : / / doi . org / 10 . 1109 / TVCG . 2011 . 185 [ 10 ] Matthew Brehmer and Tamara Munzner . 2013 . A Multi - Level Typology of Ab - stract Visualization Tasks . IEEE Transactions on Visualization and Computer Graphics 19 , 12 ( Dec . 2013 ) , 2376 – 2385 . https : / / doi . org / 10 . 1109 / TVCG . 2013 . 124 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 11 ] R . Chang , C . Ziemkiewicz , T . M . Green , and W . Ribarsky . 2009 . Defining Insight for Visual Analytics . IEEE Computer Graphicsand Applications 29 , 2 ( March 2009 ) , 14 – 17 . https : / / doi . org / 10 . 1109 / MCG . 2009 . 22 Conference Name : IEEE Computer Graphics and Applications . [ 12 ] E . K . Choe , B . Lee , and m c schraefel . 2015 . Characterizing Visualization Insights from Quantified Selfers’ Personal Data Presentations . IEEE Computer Graphics and Applications 35 , 4 ( July 2015 ) , 28 – 37 . https : / / doi . org / 10 . 1109 / MCG . 2015 . 51 Conference Name : IEEE Computer Graphics and Applications . [ 13 ] E . F . Codd . 1970 . A Relational Model of Data for Large Shared Data Banks . Commun . ACM 13 , 6 ( jun 1970 ) , 377 – 387 . https : / / doi . org / 10 . 1145 / 362384 . 362685 [ 14 ] Zhe Cui , Sriram Karthik Badam , M Adil Yalçin , and Niklas Elmqvist . 2019 . Dat - aSite : Proactive visual data exploration with computation of insight - based rec - ommendations . Information Visualization 18 , 2 ( April 2019 ) , 251 – 267 . https : / / doi . org / 10 . 1177 / 1473871618806555 Publisher : SAGE Publications . [ 15 ] Robert A DeLine . 2021 . Glinda : Supporting Data Science with Live Programming , GUIs and a Domain - Specific Language . In Proceedings of the 2021 CHI Conference onHumanFactorsinComputingSystems ( Yokohama , Japan ) ( CHI’21 ) . Association for Computing Machinery , New York , NY , USA , Article 309 , 11 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445267 [ 16 ] Demiralp , Çağatay and Haas , Peter J . and Parthasarathy , Srinivasan and Pedapati , Tejaswini . 2017 . Foresight : recommendingvisualinsights . ProceedingsoftheVLDB Endowment 10 , 12 ( Aug . 2017 ) , 1937 – 1940 . https : / / doi . org / 10 . 14778 / 3137765 . 3137813 [ 17 ] W . Dou , D . H . Jeong , F . Stukes , W . Ribarsky , H . R . Lipford , and R . Chang . 2009 . Recovering Reasoning Processes from User Interactions . IEEE Computer Graphics and Applications 29 , 3 ( May 2009 ) , 52 – 61 . https : / / doi . org / 10 . 1109 / MCG . 2009 . 49 Conference Name : IEEE Computer Graphics and Applications . [ 18 ] Wenwen Dou , Caroline Ziemkiewicz , Lane Harrison , Dong Hyun Jeong , William Ribarsky , Xiaoyu Wang , and Remco Chang . 2012 . Toward a deeper understand - ing of the relationship between interaction constraints and visual isomorphs . Information Visualization 11 , 3 ( July 2012 ) , 222 – 236 . https : / / doi . org / 10 . 1177 / 1473871611433712 Publisher : SAGE Publications . [ 19 ] Sneha Gathani , Shayan Monadjemi , Alvitta Ottley , and Leilani Battle . 2022 . A Grammar - Based Approach for Applying Visualization Taxonomies to Interaction Logs . In Computer Graphics Forum , Vol . 41 . Wiley Online Library , 489 – 500 . https : / / doi . org / 10 . 1111 / cgf . 14557 [ 20 ] S . R . Gomez , H . Guo , C . Ziemkiewicz , and D . H . Laidlaw . 2014 . An insight - and task - based methodology for evaluating spatiotemporal visual analytics . In 2014 IEEE Conference on Visual Analytics Science and Technology ( VAST ) . 63 – 72 . https : / / doi . org / 10 . 1109 / VAST . 2014 . 7042482 [ 21 ] David Gotz and Michelle X . Zhou . 2009 . Characterizing Users’ Visual Analytic Activity for Insight Provenance . Information Visualization 8 , 1 ( Jan . 2009 ) , 42 – 55 . https : / / doi . org / 10 . 1057 / ivs . 2008 . 31 Publisher : SAGE Publications . Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY Trovato and Tobin , et al . [ 22 ] D . Gotz , M . X . Zhou , and V . Aggarwal . 2006 . Interactive Visual Synthesis of Analytic Knowledge . In 2006 IEEE Symposium On Visual Analytics Science And Technology . 51 – 58 . https : / / doi . org / 10 . 1109 / VAST . 2006 . 261430 [ 23 ] T . M . Green , W . Ribarsky , and B . Fisher . 2008 . Visual analytics for complex concepts using a human cognition model . In 2008 IEEE Symposium on Visual Analytics Science and Technology . 91 – 98 . https : / / doi . org / 10 . 1109 / VAST . 2008 . 4677361 [ 24 ] H . Guo , S . R . Gomez , C . Ziemkiewicz , and D . H . Laidlaw . 2016 . A Case Study Using Visualization Interaction Logs and Insight Metrics to Understand How Analysts Arrive at Insights . IEEE Transactions on Visualization and Computer Graphics 22 , 1 ( Jan . 2016 ) , 51 – 60 . https : / / doi . org / 10 . 1109 / TVCG . 2015 . 2467613 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 25 ] Peter E . Hart , Nils J . Nilsson , and Bertram Raphael . 1968 . A Formal Basis for the Heuristic Determination of Minimum Cost Paths . IEEE Transactions on Systems Science and Cybernetics 4 , 2 ( 1968 ) , 100 – 107 . https : / / doi . org / 10 . 1109 / TSSC . 1968 . 300136 [ 26 ] Chen He , Luana Micallef , Liye He , Gopal Peddinti , Tero Aittokallio , and Giulio Jacucci . 2020 . Characterizing the Quality of Insight by Interactions : A Case Study . IEEE Transactions on Visualization and Computer Graphics ( 2020 ) , 1 – 1 . https : / / doi . org / 10 . 1109 / TVCG . 2020 . 2977634 ConferenceName : IEEETransactions on Visualization and Computer Graphics . [ 27 ] Jeffrey Heer . 2021 . Arquero | arquero . https : / / uwdata . github . io / arquero / [ 28 ] Jeffrey Heer and Ben Shneiderman . 2012 . Interactive Dynamics for Visual Analy - sis : A taxonomy of tools that support the fluent and flexible use of visualizations . Queue 10 , 2 ( Feb . 2012 ) , 30 – 55 . https : / / doi . org / 10 . 1145 / 2133416 . 2146416 [ 29 ] Jessica Hullman . 2019 . The purpose of visualization is insight , not pic - tures : An interview with Ben Shneiderman . ACM Interactions ( 2019 ) . https : / / interactions . acm . org / blog / view / the - purpose - of - visualization - is - insight - not - pictures - an - interview - with - ben [ 30 ] Eunice Jun , Maureen Daum , Jared Roesch , Sarah Chasins , Emery Berger , Rene Just , and Katharina Reinecke . 2019 . Tea : A High - Level Language and Runtime System for Automating Statistical Analysis . In Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology ( New Orleans , LA , USA ) ( UIST ’19 ) . Association for Computing Machinery , New York , NY , USA , 591 – 603 . https : / / doi . org / 10 . 1145 / 3332165 . 3347940 [ 31 ] Eunice Jun , Audrey Seo , Jeffrey Heer , and René Just . 2022 . Tisane : Authoring Statistical Models via Formal Reasoning from Conceptual and Data Relationships . In Proceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , Article 490 , 16 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3501888 [ 32 ] AlexKale , YifanWu , andJessicaHullman . 2022 . CausalSupport : ModelingCausal Inferences with Visualizations . IEEE Transactions on Visualization and Computer Graphics 28 , 1 ( 2022 ) , 1150 – 1160 . https : / / doi . org / 10 . 1109 / TVCG . 2021 . 3114824 [ 33 ] Y . Kang and J . Stasko . 2012 . Examining the Use of a Visual Analytics System for Sensemaking Tasks : Case Studies with Domain Experts . IEEE Transac - tions on Visualization and Computer Graphics 18 , 12 ( Dec . 2012 ) , 2869 – 2878 . https : / / doi . org / 10 . 1109 / TVCG . 2012 . 224 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 34 ] L . E . Kavraki , P . Svestka , J . - C . Latombe , and M . H . Overmars . 1996 . Probabilistic roadmaps for path planning in high - dimensional configuration spaces . IEEE Transactions on Robotics and Automation 12 , 4 ( 1996 ) , 566 – 580 . https : / / doi . org / 10 . 1109 / 70 . 508439 [ 35 ] Yea - Seul Kim , Katharina Reinecke , and Jessica Hullman . 2017 . Explaining the Gap : Visualizing One’s Predictions Improves Recall and Comprehension of Data . In Proceedingsofthe2017CHIConferenceonHumanFactorsinComputingSystems ( Denver , Colorado , USA ) ( CHI ’17 ) . Association for Computing Machinery , New York , NY , USA , 1375 – 1386 . https : / / doi . org / 10 . 1145 / 3025453 . 3025592 [ 36 ] Robert Kosara and Jock Mackinlay . 2013 . Storytelling : The Next Step for Visual - ization . Computer 46 , 5 ( 2013 ) , 44 – 50 . https : / / doi . org / 10 . 1109 / MC . 2013 . 36 [ 37 ] Heidi Lam , Melanie Tory , and Tamara Munzner . 2018 . Bridging from Goals to TaskswithDesignStudyAnalysisReports . IEEETransactionsonVisualizationand ComputerGraphics 24 , 1 ( Jan . 2018 ) , 435 – 445 . https : / / doi . org / 10 . 1109 / TVCG . 2017 . 2744319 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 38 ] Z . Liu and J . Heer . 2014 . The Effects of Interactive Latency on Exploratory Visual Analysis . IEEE Transactions on Visualization and Computer Graphics 20 , 12 ( Dec . 2014 ) , 2122 – 2131 . https : / / doi . org / 10 . 1109 / TVCG . 2014 . 2346452 ConferenceName : IEEE Transactions on Visualization and Computer Graphics . [ 39 ] A . Mathisen , T . Horak , C . N . Klokmose , K . Grønbæk , and N . Elmqvist . 2019 . Insid - eInsights : Integrating Data - Driven Reporting in Collaborative Visual Analytics . ComputerGraphicsForum 38 , 3 ( 2019 ) , 649 – 661 . https : / / doi . org / 10 . 1111 / cgf . 13717 _ eprint : https : / / onlinelibrary . wiley . com / doi / pdf / 10 . 1111 / cgf . 13717 . [ 40 ] S . McKenna , D . Mazur , J . Agutter , andM . Meyer . 2014 . DesignActivityFramework forVisualizationDesign . IEEETransactionsonVisualizationandComputerGraph - ics 20 , 12 ( Dec . 2014 ) , 2191 – 2200 . https : / / doi . org / 10 . 1109 / TVCG . 2014 . 2346331 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 41 ] S . Monadjemi , R . Garnett , and A . Ottley . 2020 . Competing Models : Inferring Exploration Patterns and Information Relevance via Bayesian Model Selection . IEEE Transactions on Visualization and Computer Graphics ( 2020 ) , 1 – 1 . https : / / doi . org / 10 . 1109 / TVCG . 2020 . 3030430 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 42 ] Dominik Moritz , Chenglong Wang , Greg L . Nelson , Halden Lin , Adam M . Smith , Bill Howe , and Jeffrey Heer . 2019 . Formalizing Visualization Design Knowledge as Constraints : Actionable and Extensible Models in Draco . IEEE Transactions on Visualization and Computer Graphics 25 , 1 ( 2019 ) , 438 – 448 . https : / / doi . org / 10 . 1109 / TVCG . 2018 . 2865240 [ 43 ] T . Munzner . 2009 . A Nested Model for Visualization Design and Validation . IEEE Transactions on Visualization and Computer Graphics 15 , 6 ( Nov . 2009 ) , 921 – 928 . https : / / doi . org / 10 . 1109 / TVCG . 2009 . 111 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 44 ] C . North . 2006 . Toward measuring visualization insight . IEEE Computer Graphics and Applications 26 , 3 ( May 2006 ) , 6 – 9 . https : / / doi . org / 10 . 1109 / MCG . 2006 . 70 Conference Name : IEEE Computer Graphics and Applications . [ 45 ] Chris North , Purvi Saraiya , and Karen Duca . 2011 . A comparison of benchmark taskandinsightevaluationmethodsforinformationvisualization . InformationVi - sualization 10 , 3 ( July 2011 ) , 162 – 181 . https : / / doi . org / 10 . 1177 / 1473871611415989 [ 46 ] T . O’Brien , A . Ritz , B . Raphael , and D . Laidlaw . 2010 . Gremlin : An Interac - tive Visualization Model for Analyzing Genomic Rearrangements . IEEE Trans - actions on Visualization and Computer Graphics 16 , 6 ( Nov . 2010 ) , 918 – 926 . https : / / doi . org / 10 . 1109 / TVCG . 2010 . 163 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 47 ] William A . Pike , John Stasko , Remco Chang , and Theresa A . O’Connell . 2009 . The Science of Interaction . Information Visualization 8 , 4 ( Jan . 2009 ) , 263 – 274 . https : / / doi . org / 10 . 1057 / ivs . 2009 . 22 Publisher : SAGE Publications . [ 48 ] Peter Pirolli . 2007 . Cognitive models of human - information interaction . In Handbook of applied cognition , 2nd ed . John Wiley & Sons , Inc . , Hoboken , NJ , US , 443 – 470 . https : / / doi . org / 10 . 1002 / 9780470713181 . ch17 [ 49 ] Peter Pirolli and Stuart Card . 2005 . The sensemaking process and leverage points for analyst technology as identified through cognitive task analysis . In Proceedings of International Conference on Intelligence Analysis , Vol . 5 . [ 50 ] C . Plaisant , J . - D . Fekete , and G . Grinstein . 2008 . Promoting Insight - Based Evaluation of Visualizations : From Contest to Benchmark Repository . IEEE Transactions on Visualization and Computer Graphics 14 , 1 ( Jan . 2008 ) , 120 – 134 . https : / / doi . org / 10 . 1109 / TVCG . 2007 . 70412 [ 51 ] Z . Pousman , J . Stasko , and M . Mateas . 2007 . Casual Information Visualization : Depictions of Data in Everyday Life . IEEE Transactions on Visualization and Computer Graphics 13 , 6 ( Nov . 2007 ) , 1145 – 1152 . https : / / doi . org / 10 . 1109 / TVCG . 2007 . 70541 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 52 ] Alexander Rind , Wolfgang Aigner , Markus Wagner , Silvia Miksch , and Tim Lammarsch . 2016 . Task Cube : A three - dimensional conceptual space of user tasks in visualization design and evaluation . Information Visualization 15 , 4 ( Oct . 2016 ) , 288 – 300 . https : / / doi . org / 10 . 1177 / 1473871615621602 Publisher : SAGE Publications . [ 53 ] D . Sacha , A . Stoffel , F . Stoffel , B . C . Kwon , G . Ellis , and D . A . Keim . 2014 . Knowl - edge Generation Model for Visual Analytics . IEEE Transactions on Visualization and Computer Graphics 20 , 12 ( Dec . 2014 ) , 1604 – 1613 . https : / / doi . org / 10 . 1109 / TVCG . 2014 . 2346481 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 54 ] P . Saraiya , C . North , andK . Duca . 2004 . AnEvaluationofMicroarrayVisualization Tools for Biological Insight . In IEEE Symposium on Information Visualization . 1 – 8 . https : / / doi . org / 10 . 1109 / INFVIS . 2004 . 5 ISSN : 1522 - 404X . [ 55 ] P . Saraiya , C . North , and K . Duca . 2005 . An Insight - Based Methodology for Evaluating Bioinformatics Visualizations . IEEE Transactions on Visualization and Computer Graphics 11 , 4 ( July 2005 ) , 443 – 456 . https : / / doi . org / 10 . 1109 / TVCG . 2005 . 53 [ 56 ] P . Saraiya , C . North , VyLam , andK . A . Duca . 2006 . AnInsight - BasedLongitudinal Study of Visual Analytics . IEEE Transactions on Visualization and Computer Graphics 12 , 6 ( Nov . 2006 ) , 1511 – 1522 . https : / / doi . org / 10 . 1109 / TVCG . 2006 . 85 [ 57 ] Arvind Satyanarayan , Dominik Moritz , Kanit Wongsuphasawat , and Jeffrey Heer . 2017 . Vega - Lite : A Grammar of Interactive Graphics . IEEE Transactions on Visualization and Computer Graphics 23 , 1 ( 2017 ) , 341 – 350 . https : / / doi . org / 10 . 1109 / TVCG . 2016 . 2599030 [ 58 ] Arvind Satyanarayan , Dominik Moritz , Kanit Wongsuphasawat , and Jeffrey Heer . 2017 . Vega - Lite : A Grammar of Interactive Graphics . IEEE Transactions on Visualization and Computer Graphics 23 , 1 ( 2017 ) , 341 – 350 . https : / / doi . org / 10 . 1109 / TVCG . 2016 . 2599030 [ 59 ] M . Sedlmair , M . Meyer , and T . Munzner . 2012 . Design Study Methodology : Reflections from the Trenches and the Stacks . IEEE Transactions on Visualization and Computer Graphics 18 , 12 ( Dec . 2012 ) , 2431 – 2440 . https : / / doi . org / 10 . 1109 / TVCG . 2012 . 213 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 60 ] Edward Segel and Jeffrey Heer . 2010 . Narrative Visualization : Telling Stories with Data . IEEE Transactions on Visualization and Computer Graphics 16 , 6 ( 2010 ) , 1139 – 1148 . https : / / doi . org / 10 . 1109 / TVCG . 2010 . 179 Pyxis : A Programmatic Definition of Visualization Insights , Objectives , and Tasks Conference acronym ’XX , June 03 – 05 , 2018 , Woodstock , NY [ 61 ] Ben Shneiderman . 2002 . Inventing Discovery Tools : Combining Information VisualizationwithDataMining . InformationVisualization 1 , 1 ( March2002 ) , 5 – 12 . https : / / doi . org / 10 . 1057 / palgrave . ivs . 9500006 Publisher : SAGE Publications . [ 62 ] Y . B . Shrinivasan , D . Gotzy , andJ . Lu . 2009 . Connectingthedotsinvisualanalysis . In 2009 IEEE Symposium on Visual Analytics Science and Technology . 123 – 130 . https : / / doi . org / 10 . 1109 / VAST . 2009 . 5333023 [ 63 ] YedendraBabuShrinivasanandJarkeJ . vanWijk . 2008 . Supportingtheanalytical reasoning process in information visualization . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI ’08 ) . Association for Computing Machinery , New York , NY , USA , 1237 – 1246 . https : / / doi . org / 10 . 1145 / 1357054 . 1357247 [ 64 ] M . Smuc , E . Mayr , T . Lammarsch , W . Aigner , S . Miksch , and J . Gärtner . 2009 . To Score or Not to Score ? Tripling Insights for Participatory Design . IEEE Computer Graphics and Applications 29 , 3 ( May 2009 ) , 29 – 38 . https : / / doi . org / 10 . 1109 / MCG . 2009 . 53 Conference Name : IEEE Computer Graphics and Applications . [ 65 ] A . Srinivasan , S . M . Drucker , A . Endert , and J . Stasko . 2019 . Augmenting Visual - izations with Interactive Data Facts to Facilitate Interpretation and Communica - tion . IEEE Transactions on Visualization and Computer Graphics 25 , 1 ( Jan . 2019 ) , 672 – 681 . https : / / doi . org / 10 . 1109 / TVCG . 2018 . 2865145 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 66 ] Manasi Vartak , Sajjadur Rahman , Samuel Madden , Aditya Parameswaran , and Neoklis Polyzotis . 2015 . SeeDB : Efficient Data - Driven Visualization Recom - mendations to Support Visual Analytics . Proceedings of the VLDB Endowment International Conference on Very Large Data Bases 8 , 13 ( Sept . 2015 ) , 2182 – 2193 . https : / / www . ncbi . nlm . nih . gov / pmc / articles / PMC4714568 / [ 67 ] Kanit Wongsuphasawat , Dominik Moritz , Anushka Anand , Jock Mackinlay , Bill Howe , and Jeffrey Heer . 2016 . Towards a General - Purpose Query Language for Visualization Recommendation . In Proceedings of the Workshop on Human - In - the - Loop Data Analytics ( San Francisco , California ) ( HILDA ’16 ) . Association for Computing Machinery , New York , NY , USA , Article 4 , 6 pages . https : / / doi . org / 10 . 1145 / 2939502 . 2939506 [ 68 ] Kanit Wongsuphasawat , Zening Qu , Dominik Moritz , Riley Chang , Felix Ouk , Anushka Anand , Jock Mackinlay , Bill Howe , and Jeffrey Heer . 2017 . Voyager 2 : Augmenting Visual Analysis with Partial View Specifications . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems ( CHI ’17 ) . Association for Computing Machinery , New York , NY , USA , 2648 – 2659 . https : / / doi . org / 10 . 1145 / 3025453 . 3025768 [ 69 ] Jing Nathan Yan , Ziwei Gu , and Jeffrey M Rzeszotarski . 2021 . Tessera : Discretiz - ing Data Analysis Workflows on a Task Level . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 20 , 15 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445728 [ 70 ] Yang Chen , Jing Yang , and W . Ribarsky . 2009 . Toward effective insight manage - ment in visual analytics systems . In 2009 IEEE Pacific Visualization Symposium . 49 – 56 . https : / / doi . org / 10 . 1109 / PACIFICVIS . 2009 . 4906837 ISSN : 2165 - 8773 . [ 71 ] Ji Soo Yi , Youn - ah Kang , John T . Stasko , and Julie A . Jacko . 2008 . Understanding and characterizing insights : how do people gain insights using information visualization ? . In Proceedings of the 2008 conference on BEyond time and errors novel evaLuation methods for Information Visualization - BELIV ’08 . ACM Press , Florence , Italy , 1 . https : / / doi . org / 10 . 1145 / 1377966 . 1377971 [ 72 ] Zehua Zeng , Phoebe Moh , Fan Du , Jane Hoffswell , Tak Yeon Lee , Sana Malik , Eunyee Koh , and Leilani Battle . 2022 . An Evaluation - Focused Framework for Visualization Recommendation Algorithms . IEEE Transactions on Visualization and Computer Graphics 28 , 1 ( 2022 ) , 346 – 356 . https : / / doi . org / 10 . 1109 / TVCG . 2021 . 3114814 [ 73 ] E . Zgraggen , A . Galakatos , A . Crotty , J . Fekete , and T . Kraska . 2017 . How Progressive Visualizations Affect Exploratory Analysis . IEEE Transactions on Visualization and Computer Graphics 23 , 8 ( Aug . 2017 ) , 1977 – 1987 . https : / / doi . org / 10 . 1109 / TVCG . 2016 . 2607714 Conference Name : IEEE Transactions on Visualization and Computer Graphics . [ 74 ] Emanuel Zgraggen , Zheguang Zhao , Robert Zeleznik , and Tim Kraska . 2018 . Investigating the Effect of the Multiple Comparisons Problem in Visual Analysis . In Proceedingsofthe2018CHIConferenceonHumanFactorsinComputingSystems ( CHI ’18 ) . Association for Computing Machinery , New York , NY , USA , 1 – 12 . https : / / doi . org / 10 . 1145 / 3173574 . 3174053