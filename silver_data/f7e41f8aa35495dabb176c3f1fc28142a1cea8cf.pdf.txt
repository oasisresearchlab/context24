‘Treat me as your friend , not a number in your database’ : Co - designing with Children to Cope with Datafication Online Ge Wang ge . wang @ cs . ox . ac . uk Department of Computer Science . University of Oxford Oxford , UK Max Van Kleek max . van . kleek @ cs . ox . ac . uk Department of Computer Science . University of Oxford Oxford , UK Jun Zhao jun . zhao @ cs . ox . ac . uk Department of Computer Science . University of Oxford Oxford , UK Nigel Shadbolt nigel . shadbolt @ cs . ox . ac . uk Department of Computer Science . University of Oxford Oxford , UK ABSTRACT Datafcation refers to the practices through which children’s online actions are pervasively recorded , tracked , aggregated , analysed , and exploited by online services in ways including behavioural engineering and monetisation . Previous research has shown that not only do children care signifcantly about various aspects of datafcation , but they demand a chance to take action . Through 10 co - design sessions with 53 children , we examined how children in the UK want to be supported to cope with the datafcation prac - tices . Our fndings provide insights for creating age - appropriate support for children’s algorithmic literacy development , highlight - ing and unpacking the importance of no one - size - ftting - all designs to support children’s coping with datafcation . We contribute a frst understanding of how children aged 7 – 14 would like to be supported with datafcation and what future data - driven digital experiences should be like for them , who demand a shift of the current data ecosystem towards a more humane - by - design and autonomy - supportive future . CCS CONCEPTS • Human - centered computing → Empirical studies in HCI ; • Security and privacy → Social aspects of security and privacy . KEYWORDS Datafcation , Data Inference , Online Platforms , Children , Co - design ACM Reference Format : Ge Wang , Jun Zhao , Max Van Kleek , and Nigel Shadbolt . 2023 . ‘Treat me as your friend , not a number in your database’ : Co - designing with Children to Cope with Datafcation Online . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems ( CHI ’23 ) , April 23 – 28 , 2023 , Hamburg , Germany . ACM , New York , NY , USA , 21 pages . https : / / doi . org / 10 . 1145 / 3544548 . 3580933 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specifc permission and / or a fee . Request permissions from permissions @ acm . org . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany © 2023 Copyright held by the owner / author ( s ) . Publication rights licensed to ACM . ACM ISBN 978 - 1 - 4503 - 9421 - 5 / 23 / 04 . . . $ 15 . 00 https : / / doi . org / 10 . 1145 / 3544548 . 3580933 1 INTRODUCTION Today , children are spending more time online than ever before [ 63 , 81 ] . Children’s data and actions are being pervasively recorded , tracked , aggregated , analysed , and exploited by online services , which can be used to manipulate their online behaviour , engage - ment , or content consumption [ 68 , 72 , 118 ] , this contributes to the so - called datafed childhood [ 68 ] . On one hand , individual children and communities can beneft from big data , as data - driven apps , systems and platforms are starting to play a variety of roles in the digital ecosystems of children , enabling them to learn and have fun online [ 110 ] . On the other hand , data collection and analysis on a massive scale responds frst and foremost to a business logic , labelled by Zubof as ‘surveillance capitalism’ — “a new form of information capitalism [ which ] aims to predict and modify human behavior as a means to produce revenue and market control” [ 117 ] . At the core of this datafcation is online services’ ability to make data inference on children , that is to analyse their data , supported by al - gorithms , with the aim to evaluate certain personal aspects relating to a natural person [ 68 ] , in particular , to predict aspects concerning that natural person’s performance at work , economic situation , health , personal preferences , interests , reliability , behaviour , loca - tion or movements [ 5 ] . Such datafcation is practically impossible to avoid or undo through deletion [ 63 ] . Furthermore , such activities take place mostly invisibly behind the scenes of apps and services and are less well understood or discussed as risks than other kinds of more easily characterised harms , such as the collection or pro - fling of particular kinds of sensitive data . Given that most adults have little understanding of how their own data are being collected , processed , and used to shape their digital environments [ 25 ] , it is not particularly surprising that children too lack a robust under - standing or adequate mental models of how their data are processed or used [ 58 , 116 ] . On the other hand , a recent study on children’s perceptions of the datafcation practices online showed that while there are still key knowledge gaps in children’s understanding of datafcation practices , most children already possess rudimentary conceptual understandings of some aspects of datafcation , notably those that they care most signifcantly about , and have a signif - icant interest and willingness to take action to shape it to their desires [ 109 ] . This paper aims to extend existing understandings and examine how children would like to be supported in order to take action on the datafcation practices . More specifcally , we aim to explore two research questions : CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . • RQ1 : How do children currently perceive datafcation and en - vision themselves to be supported ? • RQ2 : What kind of designs are desired and needed by children to help them navigate datafcation ? To this end , we chose to use the YouTube platform as an example datafcation platform [ 69 , 76 ] for our study , due to its popular - ity among children throughout the world [ 9 ] . We used a series of co - design activities with children , including fctional inquiry [ 51 ] to help us explore children’s perception of datafcation and their requirements for support , and feature redesign , drawing on the fram - ing from critical algorithmic literacy [ 30 , 53 ] , to help us explore the design mechanisms required and desired by children . We report our results based on 10 co - design sessions with 53 children , aged 7 – 14 , from UK schools undertaken between May and June 2022 . Our fndings identifed diferent types of envisioned support and design mechanisms desired by children of diverse age groups . This paper provides crucial insights for creating age - appropriate support for children’s algorithmic literacy development , highlighted and unpacked the importance of no one - size - ftting - all designs when supporting children’s coping with datafcation . While previous re - search [ 14 , 21 , 64 , 86 , 101 , 116 ] has looked at how children perceive data and their privacy online , our work extends this landscape by specifcally looking at how children perceive issues around dataf - cation – a phenomena that goes beyond basic data collection and related privacy issues , but refers to the entire pipeline in today’s datafed society in which children’s data are not only being col - lected , shared , but more importantly , algorithmically processed , analysed and exploited in ways that online services were able to make inference on them relating to personal aspects , leading to behavioural engineering and monetisation . We contribute a frst understanding of how children aged 7 – 14 would like to be sup - ported with datafcation and what future data - driven digital expe - riences should be like for them , who demand a shift of the current data ecosystem towards a more humane - by - design and autonomy - supportive future . 2 BACKGROUND 2 . 1 Datafcation on Online Platforms To establish the scope of our investigation , we frst aim to defne what we mean by datafcation online , which refers to the process that children’s actions are pervasively recorded , tracked , aggre - gated , analysed , and exploited by online services in multiple ways that include behavioural engineering , and monetisation [ 68 , 72 , 118 ] . At the core of this datafcation is online services’ ability to make data inference on children , that is to analyse their data , supported by al - gorithms , with the aim to evaluate certain personal aspects relating to a natural person [ 64 ] , in particular , to predict aspects concerning that natural person’s performance at work , economic situation , health , personal preferences , interests , reliability , behaviour , loca - tion or movements [ 6 ] . By making inferences about individual’s lives , datafcation has been proved useful in terms of providing users with the services they want , therefore improving their online experience [ 15 , 56 ] ; but on the other hand , datafcation has also been seen as a violation of privacy [ 25 ] , and even as a potential threat to human autonomy [ 107 ] brought by increasingly sophisticated dataveillance techniques [ 93 ] . Meanwhile , datafcation practices are becoming increasingly common in the online world today , and in fact , can be found on almost any online platform [ 26 , 54 , 89 ] . Existing research [ 89 ] found that big online platforms including Google and Yahoo have been us - ing users’ demographic data , data on interests and attitudes to make inferences about individuals or groups , which includes predictions about their future actions and inactions , general characteristics and specifc preferences . Facebook has been found to make infer - ences on its users to form an ‘interested reading’ of their digital trace data [ 91 ] , so as to create interest classifcations that produce sales for advertisers and maintain user engagement on the news feed [ 104 ] . Research on Instagram also showed that there have been profling practices on its users , to nudge them towards certain content such as idealised images which could have negative im - pacts on the body satisfaction of young girls [ 84 ] . Similarly , there has been evidence on YouTube conducting inference on users to maximise their engagement on the platform , which could be partic - ularly problematic for the minors [ 84 ] . While various regulations have attempted to protect children from such practices , such as GDPR [ 28 ] for restricting profling on children , and COPPA [ 1 ] for protecting online collection of personal information of children under 13 years of age , resulting in most social media platforms set - ting an 13 / 14 minimum age requirement for users to have accounts . In recent years , many has argued that this age limit has become more of an excuse for the social media platforms to continue to ignore the vast amount of under - aged children on their platform ( whether using visitor mode , their parents’ or siblings’ accounts , or simply lying about their ages ) [ 80 , 83 ] . There has been clear evidence that children under 13s are still on , and even have heavy usage on social media platforms [ 80 , 103 ] . A recent report on 2 , 002 US children showed that 45 % of kids under 13 are on Facebook , and 40 % already use Instagram [ 103 ] . While YouTube had a ‘YouTube Kids’ version that was claimed to be for under 13s , most children are still on the main platform and it remains to be the most popular video - sharing - platform among 8 - 12 year - olds , according to 2021 Ofcom report on UK children , with more than 85 % of preschoolers found to commonly used YouTube to watch content [ 80 ] . 2 . 2 Children’s Perception of Datafcation Online There has been growing concern expressed relating to the dataf - cation of children , especially as children may lack the awareness , knowledge , or mental faculties to be able to understand or be aware of such practices . Most previous research on children and data was around how children perceive their data privacy online , and mostly oriented around their understanding on how their personal infor - mation is collected online . While this does not equal to datafcation , as the latter refers to practices beyond data collection , and extends to online services’ ability to process the collected data and make algorithmic data inference on users for behavioural engineering and monetisation ; however , these existing research on children’s perception of online privacy provided us with a useful starting point as discusses in the following . A study with children aged 6 - 10 showed that while they could identify and articulate certain privacy risks well , such as information oversharing or revealing real identities online , they had less awareness of other risks , such ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany as online tracking or personalised promotions [ 116 ] . Similarly , a re - port on 169 UK children aged 11 – 16 showed that children primarily conceptualised data in relation to interpersonal contexts , but had misapprehensions about how personal data was collected , inferred and used by organisations and public institutions , such as their schools , or private / commercial businesses [ 101 ] . These fndings were compatible with fndings from a study in 2017 [ 86 ] , in which teenagers aged 14 to 18 were found to have more concerns over interpersonal contexts , but often failed to understand or perceive potential threats to their privacy from ways frst and third parties might make use of their data , and how personal data could be used in predictive ways to shape their future experiences and behav - iors . In addition to children’s limited ability to recognise beyond interpersonal privacy risks , children have been found to particu - larly struggle to draw personal connections to ‘data traces’ they left online [ 14 ] . Children showed limited knowledge about data fows and cross - platform data sharing , and as a result struggled to to view data fows as a dynamic process and imagine the wide impact on their personal privacy [ 21 ] . This was also identifed by another study with children of diferent age groups , which found that children struggled to grasp the relation between privacy and data , and they would only focus on data they know they give , much more than data that is taken or inferred [ 64 ] . While children would likely have difculties in fully understand - ing the complexities of datafcation or its means , some more recent research has shown that children could be well - equipped and ca - pable of grasping essential concepts related to datafcation , for example , how their personal data ( such as activity history ) could be processed and used to sell products to the users ( such as them - selves ) . Studies have shown that if children were given sufcient scafolding and nudges from parents and educators , their under - standing could grow with experience [ 64 ] . A recent study ofered a clearer picture on how children under 13 perceive and under - stand the datafcation phenomena online [ 109 ] , suggesting that they could already articulate the datafcation practices quite well , demonstrating their rudimentary conceptual understanding ( online datafcation practices would “make guesses on them” ) , although not necessarily comprehending the full picture ( such as how data could be transmitted across platforms and the subsequent cross - platform profling ) . The study also identifed signifcant willingness from children to take action to shape the online datafcation practices on - line , especially in terms of having greater transparency and means of control on these practices . Inspired by these previous research , this paper aims to extend existing understandings and examine how children would like to be supported in order to take action on the datafcation practices . 2 . 3 Datafcation and Stages of Cognitive and Social Development Children’s ability to recognise and understand datafcation prac - tices may be infuenced and limited by their particular stages of development , like many other kinds of cognition . For children aged 3 to 5 , for instance , most online activities are still parent - guided , for instance , using apps and watching videos on parents’ phones [ 81 ] . For children aged 6 to 9 , they start to learn about the complexity of social relationships , and can start to feel various social pressures , such as the need to conform or desire to ft in with various social groups [ 80 ] . Children in this age group are also more involved in online activities , and enjoy playing games with their friends [ 46 ] . Such social interactions makes them more aware of interpersonal privacy risks , such as how their personal information being shared with their peers , parents , and others online [ 64 ] ; but less of other privacy risks such as how frst and third parties might make use of their data to shape their future experiences [ 64 , 116 ] . At ages 10 to 15 , many children start to become more active on social media [ 81 ] . At this stage , children’s became more aware of how vloggers may be paid to endorse products or services [ 82 ] , as well as online platforms may be monetising their data online [ 81 ] . Related to this recognition of how children of diferent stages of development are afected by datafcation practices , there have been a variety of developments looking into how to support children developing their ‘digital literacy’ [ 29 , 44 , 52 ] as well as AI liter - acy [ 35 , 37 , 65 ] . However , such frameworks were often oriented around data privacy or online safety , with the algorithmic process - ing of data by online systems scarcely mentioned . On the other hand , ‘critical algorithmic literacy’ ( CAL ) [ 30 , 53 ] puts particular emphasis on understanding the implications of data processing , by directing children’s attention towards data and the algorithmic processes applied to them . The goal of CAL is not merely assisting the development of knowledge about algorithms but also an ability to engage in critique of algorithmic systems refexively . The CAL framing proposed that computational thinking should include three key frames : the cognitive , the situated , and the critical thinking [ 53 ] . Cognitive thinking focuses on the understanding of key computa - tional concepts , practices , and perspectives and the associated skill building and competencies ; situated thinking encourages learning to take place in contexts that the learner cares about so that they include their personal expression and social engagement in their pathway of learning ; and fnally critical computational thinking recognizes that computing is not an unequivocal social good , and emphasises the importance of supporting the questioning of larger structures and processes behind the computational phenomenon . While there is no consensus on the best framework to use for sup - porting children’s digital literacy development , and we do not claim the CAL framing to be the best approach for scafolding children’s knowledge about datafcation , in this paper , we introduced ele - ments of the CAL framing into our co - design activities , as a way to invoke children’s discussions and identify the more nuanced and in - depth design needs of children . 2 . 4 Co - designing with Children Co - designing with users has been an increasingly popular design method over the past few decades [ 100 ] . Having roots in both US - driven user - centred design approach [ 41 ] ( i . e . “user as subject” ) and the Scandinavian participatory design approach [ 79 ] ( i . e . “user as partner” ) , co - design can comprise diverse approaches , ranging from research - oriented ones ( e . g . , applied ethnography ) [ 99 ] , to design - oriented ones ( e . g . , using generative tools ) [ 27 ] ; and ranging from approaches in which researchers and designers move toward users ( e . g . , usability testing ) [ 62 ] , to approaches in which users move toward researchers and designers ( e . g . , participatory design ) [ 100 ] . The term co - design is defned by Sanders and Stappers [ 92 ] as “the CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . act of applying the collective creativity of designers and people not previously trained in design who work together across the whole span of a design process” , and by Kleinsmann and Valkenburg [ 57 ] as “actors from diferent disciplines share their knowledge about both the design process and the design content in order to create shared understanding” – emphasising co - design as processes of creative cooperation and developing shared understanding . In the last decade , the Child - Computer Interaction community has been actively adopting co - design methods , and increasingly value the direct involvement of children in the design process [ 38 , 61 , 112 ] . Druin developed a widely adopted model for involving children in the design process – children can take on various roles , including users , testers , informants , and full design partners [ 40 ] . The frst two roles focus primarily on obtaining feedback or input from chil - dren at the end of the design cycle ; the latter two focus on idea elaboration , where children as co - design partners are positioned as equal design partners with adult co - design partners , and are expected to be equal stakeholders in the design of new technolo - gies and have an equal opportunity to contribute to the design process [ 40 ] . In our work , we conducted co - design sessions with children , during which children are considered to be equal stakeholders [ 40 ] . This was a critical design decision so that we can not only boost the chance of developing viable and usable designs for children [ 98 ] but also support the empowerment of children in shaping the di - rection of innovating technologies and concepts [ 71 ] . We specif - cally focused on working with children as co - design partners using the method of Cooperative Inquiry ( CI ) [ 39 , 40 ] . First proposed by Druin [ 39 ] , CI emphasises the close partnerships with children , during which children are considered designer partners who hold expertise in being a child [ 49 ] . The method has been widely adopted in various previous studies , and proved to be efective especially in terms of investigating the existing conceptualisation of children on digital phenomenon / artefacts , and eliciting the design needs of children . Previous scenarios include designing with children for intelligent interfaces [ 113 ] , social robots [ 16 , 36 ] , online safety ap - plications [ 59 , 70 ] , remote technology use during pandemic [ 18 , 74 ] as well as AI literacy framework for families [ 38 ] . Meanwhile , re - searchers have used a range of techniques to communicate and co - design with children . Walsh et al . [ 108 ] created a framework to help researchers select , create , and modify design techniques based on the context of design . For instance , techniques such as Fictional Inquiry [ 34 , 51 ] , Big Papers [ 48 , 108 ] , and Bags - of - Stuf [ 49 , 114 ] are more typically used at the early stages of the design process for eliciting children’s perception of a topic ; and techniques such as Comicboarding [ 51 , 77 ] and Stickies [ 114 , 115 ] are more generally used in later stages for evaluation . 3 METHODS Given our focus on investigating how children want to manage datafcation practices online , we chose the YouTube platform to be used as an example , and conducted a series of co - design activities with children , including fctional inquiry and feature redesign , to elicit their requirements . We selected YouTube as the exemplar datafcation platform because it contains a variety of data process - ing practices , and is familiar by most children [ 46 , 82 ] . 3 . 1 Study Design To encourage children’s involvement and their voices in the co - design process , we planned each co - design session to be composed of 3 activities : 1 ) . Pre - design activity , 2 ) . Co - design activity # 1 : Fictional Inquiry , and 3 ) . Co - design activity # 2 : “Big Paper” Fea - ture Redesign . The fctional inquiry session was designed to be more open - ended and to collect children’s perceptions and how they envision to cope with the datafcation practices ; while the feature redesign session was more scafolded by drawing on the CAL framing ( see Section 2 . 3 ) , in order to allow us to identify the actual support / design mechanisms needed by children to manage datafcation . Each session was designed to last about 1 . 5 hour , con - sisting of 5 – 6 children and 2 adult researchers as co - design partners . The co - design groups were then broken into two design teams for Co - design activity # 1 ( Fictional Inquiry ) and # 2 ( “Big Paper” Fea - ture Redesign ) , with each design team containing 2 – 3 children and one adult design partner . In each design activity , the adult design researchers acted as partners by designing with children and facili - tating discussions . After each design activity , the two design teams came back together for discussion . Throughout the study , adult partners co - designed with children and facilitated discussion in a way that avoids infuencing the direction of the design and carried out conversations by encouraging children to clarify their design intents , rather that trying to guide the direction of discussion . Pre - design Activity . The warm - up session included a game of “throwing a ball” [ 78 ] and invited everyone in the room to share their favourite YouTube video with others . This session was designed as a break - the - ice session to help the children to relax and get familiar with each other and the researchers . Then children were asked about two questions : How do you think your video recommendations are generated ? How do you think your personalised advertisements are generated ? We followed up children’s responses by asking them to explain any terms they mentioned , such as “cookies” , “trackers” , or “profle” . We have not intended to introduce this activity for learning purposes . The adult researchers did not try to provide children with a “right” answer , or provide guidance to elicit responses to those questions in any way . Instead , children were encouraged to express their own perceptions and opinions about datafcation and related issues without being judged as right or wrong . These questions were designed to give us an initial insight about children’s understanding of the datafcation practices online . Particularly , we invited children to talk about their perceptions of datafcation practices taking place , and their understanding of data inferences and profling . Co - design Activity # 1 : Fictional Inquiry . In co - design activity 1 , we conducted a fctional inquiry session . Fictional inquiry is a participatory design technique that entails creating an immersive fctional storyline and prompting participants to brainstorm within the context of this imagined reality [ 51 ] . By creating a fctional context for individuals to develop ideas , this method attempts to reduce the constraints of reality and free participants to be more generative . Prior work has showed this technique to be efective with children as young as 5 for eliciting their requirements [ 33 , 51 ] . In our work , fctional inquiry was used for facilitating children to think about their experiences with datafcation practices , as well as how they may want these experiences to be diferent / better . For this , we created an original story titled “Noah and Lola : and a ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Figure 1 : Fictional storyline used in co - design activity # 1 for children to read through and complete as a group . close encounter of the third kind” ( Figure 1 ) . The story describes Noah and Lola , who are brother and sister , meeting the YouTube elf ( representing the YouTube platform ) one day and having to decide what to do with the elf . In the story , the datafcation practices were described to children through conversations between the three main characters , and the story was left open - ended . During the design , we made a careful choice of our character ( use of “elf” instead of characters that were typically perceived more negatively such as “monsters” or “witches” [ 17 , 50 ] ) to avoid introducing any negative afections to the practice of datafcation and tried to remain as neutral as possible by explaining both the good side and down side of datafcation in the story . At the start of this session , all children and adult design partners were invited to role - play when they read aloud the story as a group : each design partner took the part of a character from the story , and read out its lines . We noticed that this helped children to become more engaged and pay more attention to the story . After fnishing reading the story , the adult design partners encouraged the group to discuss on “ What happened in the story ? ” This helped the adult design partners to confrm what children understood about the story , and facilitate discussions to clarify the story if needed . The group was then split into two design teams ( each with 2 – 3 children and one adult ) to draw their suggestions about what Noah and Lola should do with the YouTube elf . After working on this task for 30 minutes , the design teams came together and each team presented their stories in front of the whole group , while an adult design partner took notes . The adult design partners then synthesized story ideas across the group and facilitated group discussions based on these ideas . During the design process , design partners were explicitly reminded not to focus on how well they can draw , but what goes into their story . We have not intended to design or introduce the fctional storyline for education or learning purposes due to the relatively short duration of the study ; instead , this activity mainly aimed to invoke children’s discussions about datafcation and their envisioning on how to cope with these practices . Co - design Activity # 2 : “Big Paper” Feature Redesign . In the co - design activity 2 , we drew on the aforementioned CAL fram - ing ( see Section 2 . 3 ) and presented children participants with a collection of design mockups ( see Figure 2 ) in order to identify how children may perceive these designs that are built upon dif - ferent levels of computational thinking , and thus provide diferent levels of transparency and degree of controls . Children were pre - sented with mockups of changes to two key mechanisms on the YouTube platform—video recommendations on the homepage , and personalised advertisements that show up at the beginning of a video . These two mechanisms were chosen as they were consid - ered to be the most representative for the datafcation practices on YouTube . For each of the two mechanisms , we created 3 mockups for transparency , and 3 mockups for control , varied with the 3 de - sign thinkings from CAL . As was discussed in Section 2 . 3 , the CAL framing proposed that supporting the development of computa - tional thinking should include three key frames : the cognitive , the situated , and the critical thinking : • The cognitive - thinking version of transparency mockups ( the left card in Fig 2 ) provides the basic information , such as category of data being collected and used to generate video recommendations / personalised ads , without going into the details and the implications ; and the control mockups were designed to ofer a basic control on these diferent categories of data . ( e . g . , We choose this ads for you based on : the time of day or your general location , your age and gender , your interaction with similar ads , and our estimation of your interests . ) • The situated - thinking version of transparency ( the middle card in Fig 2 ) and control not only display the data being collected and used for video recommendations / personalised ads , but also provide a contextualised explanation and con - trol option according to children’s personal experience on YouTube and multiple other online platforms . For example , in addition to the YouTube videos children watched , the de - sign mockup also shows children the websites they visited and the products they purchased on third - party platforms . ( e . g . , We choose this ads [ Worms Rumble - Launch Trailer | PS5 , PS4 ] for you because : you searched for " Worms Rumble " 8 times last week on Google , you purchased a PS4 console this week on Amazon . . . [ other online activities ] . ) CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . • Finally , in the critical - thinking version of transparency ( the right card in Fig 2 ) and control , we tried to reveal the bigger picture behind video recommendation and personalised ads , explaining the process of profling and oferring controls on this profling process . ( e . g . , We collect all your activities across all websites you visited into a profle , that means all your digital footprints on the Internet . Your profle is as follows : Love gaming , particularly into Worms Rumble ( information from YouTube and Steams ) . . . [ other interests assumptions ] . ) The 12 mockups and the detailed explanations on the exact features can be found in Figure 4 and 5 in Appendix . Again , in each session , 5 - 6 children and 2 adult researchers par - ticipated as co - design partners . The adult partner frst presented the group with the CAL - inspired mockups on a big screen . Each child partner spent fve minutes reviewing the CAL - inspired mockups , which were showcased on the screen in a random order . Each child partner was then invited to go through what they like and don’t like about each of the mockups in front of the group . The co - design group was then broken into two design teams ( each with 2 - 3 chil - dren and one adult ) , to think about how they would like to redesign the given mockups . Each team received a packet of printouts of the mockups , pens and pencils , scissors , markers , and tape . We used the “Big Paper” paper - prototyping technique [ 48 ] , where design part - ners directly iterate upon previous designs by cutting out , drawing upon , and marking up printouts with their suggestions , additions , and changes [ 49 ] . After working on this task for 40 minutes , the design teams came together and each team presented their ideas in front of the whole group while an adult design partner took notes . The adult design partners then synthesised design ideas across the group and clarifed and elaborated these ideas through discussions with the children . In our study , the CAL - inspired mockups were used for facilitating children’s discussion and brainstorming on their needs when dealing with datafcation practices ; and whether such needs would have any age - appropriate implications . We do not claim that CAL is the best approach for scafolding children’s knowledge about datafcation ; however , we introduced elements of it into our mockup designs as a way to invoke discussion and the more nuanced needs of children . 3 . 2 Participants Participants were recruited from local schools , and a public fo - rum for recruiting family participants . Recruitment started in May 2022 after obtaining institutional research ethics approval , and we conducted 10 co - design sessions ( with an average group size of 5 ) with 53 children between May and June 2022 , contributing to - wards a total of 19 co - design teams made up of children and adult design partners . We made a careful selection on the age range of the children participants , setting it as from 7 to 14 . We chose to work with this age group for several reasons : previous research has shown that from 7 onward , children started to become more heavily involved in online activities especially social media [ 81 ] , and gradually transitioned away from mainly parent - guided online activities [ 80 ] . Meanwhile , as was explained in Section 2 . 1 , children under 13 are active users on many social media platforms despite of the age restrictions claimed by these platforms [ 83 , 90 ] . There is also clear evidence that , not only children below this age thresh - old are heavy adopters of online social media , but they already demonstrate some rudimentary conceptual understanding of on - line datafcation ( see Section 2 . 1 ) . This age group is also consistent with previous work on CI [ 19 , 48 , 73 , 87 , 106 ] , demonstrating their competency in participating co - design activities [ 64 , 109 ] . Among the 53 participant children , 25 were between 7 to 11 1 , another 28 were among the age range of 12 to 14 2 , with an average age of 11 ( range = 7 – 14 , s . d . = 2 . 05 ) . Apart from the age of participant children , we also made a careful selection ensuring the diversity of the demographic background of our participants . Children were recruited from fve local schools : two private schools 3 , one grammar school 4 , and two state schools 5 . For the participants recruited from public forums , we also noted down the type of schools they attend , participants’ demographic information including their ethnicity , YouTube usage behaviours , and some basic information on their schools’ and family education on topics related to datafcation ( see Table 1 – 3 in Appendix for summary and details on individual participant ) . While participants were recruited from schools and public fo - rums , the co - design sessions were not conducted in a school setting to mitigate the potential infuence brought by the typical power structure in a school setting in which adults such as teachers exer - cise authority over children [ 106 ] . Instead , children signed up to our study were invited to our lab . This also allowed us to carefully organise children into groups , so as to ensure that single - session participants were of diverse ages , genders , ethnicity groups , types of schools attended , and related experiences on datafation . Mean - while , we tried to maintain an equal partnership between children and adults throughout all session . For example , sessions often begin with a snack and casual conversation ; participants wear informal clothing ; and children do not need to raise their hands to speak nor refer to adults by their titles or last name . Extra attention was paid to children who were younger , or knew less about the subject , or simply being shy . 3 . 3 Data Analysis After completing the ten design sessions , the frst and second au - thors transcribed all the video recordings . There was a total of 927 minutes of video data ( not including snack time at the beginning of each session ) , which resulted in a total of 1853 utterances used for analysis . Out of the 1853 utterances , 1396 were made by children ( 75 . 3 % ) , the rest were made by adult design partners ( researchers ) . We analysed the data using a grounded , thematic approach [ 22 ] to develop codes and themes related to each of the three parts of the study . Photographs of children’s drawing were also consulted to complement our analysis . The thematic coding process started by dividing the transcrip - tions into two equal - sized sets . The frst two authors independently analysed the frst set of transcriptions to derive an initial set of 1 Primary school age in the UK . 2 Secondary school age in the UK . 3 Private schools ( also known as ‘independent schools’ ) in the UK : charge fees to attend instead of being funded by the government . 4 Grammar schools in the UK : government - funded schools that are allowed to select their pupils by means of an examination taken . 5 State schools in the UK : government - funded schools that provide education free of charge . ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Figure 2 : Transparency mockups redesigning the personalised ads mechanism on YouTube ( EXPLAIN ! cards ) . We created three versions of the mockups drawing on the CAL framing : cognitive , situated , critical . Each mockup was evaluated and later redesigned by the participants in the co - design activity . For more details on all 12 mockups , please see Figure 4 and 5 in Appendix . codes ( for each of the three parts of the study ) . They then met to consolidate and reconciled codes into three common codebooks for each part of the study , with Cohen’s kappas of 0 . 79 , 0 . 78 , and 0 . 78 . More specifcally , results from part 1 of the study ( Pre - design Activity ) contained children’s understanding of the datafcation practices online . During the coding process , we tried to calibrate how children understand the YouTube’s data processing practices , and this led towards a codebook on children’s understanding of the datafcation practices . Results from part 2 of the study ( Co - design Activity # 1 : Fictional Inquiry ) contained children’s brainstorming on their designed story endings for the fctional storyline . Our anal - ysis identifed how children currently perceive datafcation and their envisioning on how datafcation should be dealt with . This led towards to a codebook on children’s conceptual model on how the current datafcation could be dealt with , what went wrong and what could be done better . With respect to the data collected from part 3 of the study ( Co - design Activity # 2 : Feature Redesign ) . We frst categorised children’s rankings and comments around the three sets of CAL - inspired mockups ( cognitive , situated and critical ) for both transparency and control ( EXPLAIN ! cards and CONTROL ! cards ) . For children’s proposed redesigns of the mockups , we clus - tered their proposed design mechanisms . This gave us a codebook on the specifc design mechanisms / support children want to have for knowing about and controlling the datafcation practices . 4 RESULTS We present our results by frst outlining children’s overall under - standing of the datafcation practices online . We then present chil - dren’s perceptions of datafcation and their envisioning on how to cope with datafcation . Finally , we present our analysis on chil - dren’s preferences of the CAL - inspired features , followed by an in - depth analysis regarding children’s desired design mechanisms for coping with datafcation , with specifc examples from our design sessions ( e . g . , [ DSx ] ) . We present individual children’s quotes with their participant id and age . For information on our participants’ demographic information , please see Table 1 – 3 in Appendix . 4 . 1 Children’s General Understanding on Datafcation Online In general , we noticed that children’s understanding of datafcation aligns with their age group , and can be broadly categorised into three phases ( 7 - 9Yr , 9 + to 11Yr , 11 + Yr ) . This categorisation is also found to be aligned with UK ICO’s Guidance on Age and develop - mental Stages [ 4 ] . In the UK , age 11 is also an important transition year for children to enter secondary schools . Here we report their understanding of datafcation clustered into three major themes : data collection , data sharing , and data inference . Starting with children between 7 - 9Yr , children in this age group largely demonstrated an awareness of the data collection practices on YouTube , especially how their recommended content could be generated based on their activities on YouTube ( e . g . , videos watched , CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . Age Group Dataﬁcation as Data Collection Dataﬁcation as Data Sharing Dataﬁcation as Data Inference 7 to 9Yr 9 + to 11Yr 11 + Yr Data on my interactions with YouTube ( videos watched , terms searched , likes and comments ) is collected to generate videos for me These data are not owned by me , and they are not my personal information Collected data will be stored by YouTube , may be shared across departments within YouTube Data won ' t be shared ( traded ) across platforms Some basic conceptual knowledge on collected data could be used to do things , but can ' t articulate more Not aware that data could be used to infer personal aspects of them Not only what I do on YouTube , but things I do on other platforms would be collected to generate recommendations Not sure data on which platforms would be collected ( tend to think within Google ) Collected data will be shared across platforms Data will only be shared across platforms that are related ( e . g . , under the same company , visited through the same browser ) Data is processed through algorithm / some kind of automatic process , through which guesses about me ( e . g . , what I might like ) could be inferred Find it hard to understand how " guesses about me " could mean for other aspects in their life apart from " giving me better videos " Data collection is enabled through Cookies There are terms and conditions on data collection in user agreement Trackers are used to track my activities across platforms Can ' t really describe how exactly is data collection enabled ( apart from knowing the term Cookies ) Can ' t really describe how exactly is data sharing enabled ( apart from knowing the term Trackers ) , only vague ideas on data might be traded , but don ' t know how Data inference is making proﬁles about people Can ' t describe how exactly is inference conducted Think they have rights , but don ' t know how to implement those in a dataﬁed society Figure 3 : Summary of children’s understanding of datafcation , organised into three themes . terms searched , location information ) . Meanwhile , most of them only considered location information as personal information and think the platforms own this data ; instead , they do not think their online activities data such as videos watched and terms searched are personal information , and many ( 7 / 11 ) regarded these data as “ owned by YouTube , not by me” ( P5 , age 7 ) . Meanwhile , children in this age group generally did not have much idea on the data sharing of their data , especially how it could be shared across platforms . None of them thought data would be shared , or traded by YouTube to another platform / company , as “Why would they do that , I thought they [ YouTube , TikTok ] are enemies . ” ( P11 , age 7 ) . As a result , they tend to think data would only fow within “diferent departments of YouTube” ( P12 , age 8 ) . In terms of data inference , most children in this group were not aware that once their data is collected , it could be used to infer more sensitive things about them . This point was also refected in the later on co - design sessions , in which many of them demonstrated confusion on how profles about users could be set up . Children between 9 + to 11Yr all demonstrated an awareness of the data collection practices on YouTube , and how their recom - mended content could be generated based on not only what they do on YouTube , but also their activities across multiple platforms “If you visit a cofee website , YouTube will give you ads on cofee . ” ( P19 , age 10 ) . While some children ( 8 / 13 ) were able to discuss how data could be transmitted across platforms , they demonstrated diferent understandings in terms of how such across - platform data sharing is enabled . Many of them ( 10 / 13 ) thought data sharing was only performed between YouTube and websites that they visited through Google Chrome , as “YouTube and Google is the same company . ” ( P40 , age 11 ) . As a result , they generally thought they won’t be tracked as long as they don’t sign in to a Google account , or just use other browsers such as Safari and Firefox . In terms of data inference , most children ( 9 / 13 ) in this group had some awareness or had heard about this topic , describing data inference as “make guesses about me” ( P46 , age 10 ) . Some of them also mentioned the concept of algorithms , such as how their recommendations is “automated by algorithms” ( P29 , age 11 ) or “some kind of machine” ( P24 , age 10 ) . Meanwhile , they were less certain about the specifc things that could be inferred about them . For instance , while they described data inference as “categorise people and infuence the content they get” ( P17 , age 11 ) , they generally believed such inference was only for better videos per se , and found it hard to connect to other aspects in their life . For children aged 11Yr onward , they tend to have more under - standing on topics around datafcation . Unlike the younger age groups who sometimes have some understanding on a certain topic but cannot describe fully , many children in this age group can ac - curately name specifc terms in datafcation , such as data collection is enabled through cookies , and cross - platform data sharing could be achieved through trackers . Meanwhile , some directly used the term profling when referring to data inference . Children in this age group were more aware of the monetisation process behind scenes . For example , in conversations during design activities , many ( 19 / 28 ) mentioned that the companies are trying to make money – “They collect our data because they want to sell it . ” ( P43 , age 14 ) ; “They all have some kind of partnership , for trading users’ profles . ” ( P45 , age 14 ) . On the other hand though , children were less certain when talked about how the datafcation practices actually work “I guess it’s [ enabled through ] some kind of algorithm , but honestly don’t know anything about it . ” ( P32 , age 13 ) . Furthermore , some of them ( 13 / 28 ) demonstrated confusion in terms of why platforms nowadays would try to infer / learn things about people , and were generally unsure about what rights do they ( or can they ) have in a datafed society . 4 . 2 Children’s Envisioning on How to Cope with Datafcation In the part 2 of the study , children were guided to draw their own endings to the fctional storyline provided to them , making sugges - tions to the fctional siblings regarding what they should do with ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany the YouTube elf . This activity encouraged children to think about how they would perceive and cope with datafcation . Although the drawings from the children provided some valuable indications of their requirements , we found the discussions and think - aloud during the process presented additional and richer insights . 4 . 2 . 1 Demand for more respect from platforms . One of the most refected points from our children participants was how they gener - ally felt that they could be more respected by the platforms , through more interactive communications and dialogue . As such , children proposed three possible directions : Increased Transparency . Many children expressed that more trans - parency about how platforms function and what they do with their data would be critical for them . Particularly , they often referred to the lack of transparency in the current terms and conditions provided by the websites , as a direct example of how their trusts of platforms are afected : “Literally anything could be in the terms and conditions , if you’re willing to sell your soul or something , but nobody would pay attention . ” ( P35 , age 11 ) . Some children also brought up the more design - level lack of transparency , such as how they identifed the “sneaky” ( P17 , age 11 ) design patterns could hinder their autonomy online , and nudge them towards unwise decisions : “If you click no ( to the cookies ) they say the app won’t function , like a bunch of negative things . ” ( P16 , age 10 ) . Many children argued that they think it is important for platforms to make more child - specifc considerations . Some children mentioned how they would want a child - friendly version of the terms and conditions , which can “actually help me know what’s going on” ( P41 , age 12 ) ; while children suggested that they would like to be especially reminded of the “important matters” , such as “profling and selling of info - that’s what most people actually care about” ( P39 , age 9 ) . Increased Control . Children also brought up how they think plat - forms could be more respectful by providing users with more power of control : “Yes being able to see things is nice , but what’s important is that we would actually be able to do something about it . ” ( P27 , age 14 ) Starting with data collection , children talked about how they would like to control the “types of data being tracked online” ( P18 , age 9 ) as well as the “types of data being traded online” ( P20 , age 11 ) . Some children also mentioned how they want platforms to min - imise the datafcation practices : “limit the data they harvest to only what’s needed” ( P36 , age 8 ) , and “delete our profle after an amount of time” ( P24 , age 10 ) . Furthermore , many children talked about how they want to be able to control their profles . In particular , some children brought up the idea of having “privacy - preserving profling” options , and they brainstormed on ways such as anonymising or randomising all profles so that “platforms won’t know as much about my life” ( P28 , age 11 ) . Meanwhile , children also mentioned how they want to be supported when making decisions , and how they expect the platforms to guide them throughout this process : “That’s something the elf should be helping us with — making good decisions” ( P15 , age 13 ) . Increased Sympathy . Related to develop communication and in - teractions with platforms , a strong theme is that children want to build a relationship with the platforms . Many children , especially the younger ones , described how they want to have “actual bonding with the elves” ( P11 , age 7 ) , and building “friendship with the plat - form” ( P23 , age 9 ) . In particular , they used words such as “thinking for me” ( P22 , age 14 ) , “be considerate” ( P46 , age 10 ) . A group of children [ DS5 ] envisioned a scenario in which they can tell their secret ( which is their data and profles ) to the elf , and the elf would help to protect that secret — “the elf wouldn’t tell anyone” ( P27 , age 14 ) . This idea echoed with the story from another group of children [ DS3 ] , in which they described a concept of a “value - sensitive elf” — instead of just being an algorithm which is programmed to do its job , the children want the elves to be actually taking caring of them and protecting them online : “The elf can actually tell that , oh this information might be too sensitive or embarrassing for this child , so I won’t hurt them . ” ( P7 , age 12 ) . 4 . 2 . 2 Demand for unbiased digital experiences . How datafcation may infuence their experience online was extensively discussed by the children during the fctional inquiry session , ranging from bias and discrimination , to targeted promotions , and to flter bubbles . To start with , some children discussed how they think the current datafcation practices could create bias and discrimination due to them trying to “group people online” ( P19 , age 10 ) , and how bias could arise due to “gender steoreotypes” ( P33 , age 14 ) or “how rich they think you are” ( P17 , age 11 ) . In terms of how to cope with this , children argued that it is the platforms’ responsibility to avoid bias and discrimination and they proposed a “scrutinising algorithm” that platforms could develop to assess whether bias and discrimi - nation exist , and that algorithms used for profling should not be based on sensitive categories : “when they are profling on people , they should know there are things people don’t want you to profle . ” ( P36 , age 8 ) . Meanwhile , children argued that advertisers shouldn’t be marketing on people based on sensitive categories from the beginning : “It’s 2022 , and you’re still targeting boys v . s . girls , you will get cancelled . ” ( P41 , age 12 ) ; “Ban advertisers from using some parameters for their ads , so now they can’t ask YouTube to target certain groups . ” ( P18 , age 9 ) Apart from bias and discrimination , some children also argued about how datafcation could lead to echo chambers online : “The profle would restrict the things you see , pushing you to whichever group they think you’re in . ” ( P9 , age 11 ) ; “so people don’t have a full view” ( P33 , age 14 ) Children brainstormed on new mechanisms to increase their content diversity , a group of children [ DS6 ] introduced an “explorer mode” in which users would be given more freedom to see what’s outside their world — “Like I’m a boy living in the UK and speaks English . I would want to see what a girl , say living in India would see . ” ( P29 , age 11 ) . Many children also mentioned how they want to more directly see whether they are in an echo chamber — how their content were limited by the profling of them , for example , “we recommend this to you because you are tagged with this” ( P12 , age 8 ) . 4 . 2 . 3 Demand for fundamental changes made to the datafied soci - ety . An interesting theme emerged from children’s discussion is that , many of them believed that datafcation is becoming a social issue , and they talked about how stakeholders - platforms , users , regulators should take an active role in the increasingly datafed society . Such belief has been even transformed into some kind of data activism — “fundamental changes need to be made” ( P42 , age 13 ) . Increased Public Awareness . Many children talked about how the datafcation phenomena and associated consequences should be made aware by the public . They felt currently such practices were CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . largely unknown by the general public , and they talked about how “social movement” ( P5 , age 7 ) and “campaigns on social media” ( P4 , age 8 ) should be brought in thus to “spread the world” . A group of children [ DS2 ] even brainstormed on organising public protest on the datafcation phenomena and its related issues : “Noah and Lola would make a website , and ask people to join their protest . ” ( P6 , age 12 ) . Apart from relying on the public eforts , some children also talked about how they want new regulations to be made for protecting them against these datafcation practices online , such as “an upgraded version of GDPR” ( P42 , age 13 ) . New Business Models for the Datafed Society . A large proportion of the children demonstrated a strong awareness that data is online platforms’ main source of money . In fact , many of them have already accepted it as a norm that companies would be making money based on their data , in exchange of the services they ofer : “It’s all about data selling , and it’s very difcult to shut down something that is their core business . ” ( P8 , age 14 ) On the other hand , some children envisioned there should be some kind of revolution on this data - centred business model . Children in our study generated several versions of “new business models” . For example , a ‘Weight Loss Scheme” [ DS6 ] : “The Internet could go on a diet , like eating less but healthier - taking less but more efective data . And whoever signed up to it would be promoted more . ” ( P30 , age 12 ) Another group of children [ DS8 ] generated a similar idea to this — a “Fair Trade Union” . Companies joining would be checked on the fair use of users’ data , and thus get promoted more . A group of children [ DS10 ] envisioned a “Data Pass Scheme” . The idea was that users would pay companies for them to stop taking their data ( through purchasing “data blocks” ) . On the other hand , some children began to question why platforms have the rights to make money from their data in the frst place : “We should be the ones getting paid as it’s our data . ” ( P41 , age 12 ) and described such data - centred business model as “the ultimate scam” ( P42 , age 13 ) . Finally , some children [ DS5 ] talked about some initial ideas towards a data - decentralised structure - future platforms would only be passing requests from their local device : “Every phone or laptop will have a creature living inside . But it only does things locally , like providing you service based on what’s in your phone , but not giving your information away to YouTube or TikTok . ” ( P25 , age 11 ) and platforms would “only be parsing whatever is requested by these creatures . ” ( P24 , age 10 ) . 4 . 3 Children’s Desired Designs Mechanism for Coping with Datafcation In the part 3 of the study , children were asked to comment and redesign the provided CAL - inspired mockups . We observed three themes about how children would like to be supported when coping with the datafcation practices on YouTube . First , children demon - strated age - related design needs for them to make more informed choices . Second , children envisioned more humane designs that treat them in more respectful ways . Finally , children desired for more autonomy - supportive designs for more active engagement . Im - portantly , these proposed design mechanisms aligned closely with the themes emerged from their envisioning on how to cope with datafcation during the fctional inquiry , demonstrating children’s desire of transforming their conceptualisation to concrete design practices . 4 . 3 . 1 Age - Related Needs for More Informed Choices . Although the fctional inquiry sessions indicated some diferences of responses from diferent age groups , our feature redesign activities led to more specifc age - related observations . Children often showed dif - ferent preferences and expressed diferent needs for how they want to be supported , often depending on how familiar they are with datafcation concepts , which was typically related to their age . Starting with children who had possibly less datafcation knowl - edge ( typically between 7 – 9Yr ) , almost all of them ( 10 / 11 ) preferred the cognitive - thinking designs the most , which present children with the basic information about what data was being collected and how . They found these designs “easy to understand and confgure” ( P36 , age 8 ) . Meanwhile , they largely disliked the situated - thinking designs , which listed their activities and showed how their recom - mendations were made based on these activities ; and they reported feeling “being judged” ( P49 , age 9 ) and “unsafe” ( P11 , age 7 ) . They also disliked the critical - thinking designs , considering the designs mentioning profling as “random” ( P4 , age 8 ) and “feels unreal” ( P5 , age 7 ) . Interestingly , even though these children were previ - ously able to describe some basic datafcation concepts such as how platforms take and make use of users’ data ; they seemed to have dif - fculty in relating such abstract concepts to their own datafcation scenarios , thus showed understanding barriers and felt intimidated when actually being showed what datafcation can learn about them . Children also exhibited desire for more straightforward and more direct support for coping with datafcation . For example , P11 ( age 7 ) suggested removing the “complex sentences” , explaining : “I feel like ‘we build your profle’ is a bit too deep” , and just using words like “We could guess what you like . ” Children also wanted simpler control confgurations and they especially liked the idea of having a “one button for all” ( P12 , age 8 ) , proposing designs that can “stop profling in just one click . ” ( P5 , age 7 ) . Meanwhile , they preferred more direct and obvious support when making decisions . For example , they wanted for designs that “just tell me what to do” , giving them direct instructions on “if clicking on this button is good or bad” ( P36 , age 8 ) , or direct parental help “Mom will tell me what to do . ” ( P10 , age 8 ) . We found that children ( usually between 9 + to 11Yr ) in our study started to demonstrate a diferent set of preferences , going through a transition phase . They showed more positive perceptions towards the situated - thinking designs for them being “more related to me” ( P46 , age 10 ) , while some disliked the cognitive - thinking designs , for them being “too vague” ( P16 , age 10 ) in the explanation , and being “too broad and general” ( P20 , age 11 ) for exercising controls . These children were able to connect abstract datafcation concepts to me , and care more about how me would be afected by the datafcation practices . Such a contrast to the younger participants was also refected in their design proposals , which included signifcantly more designs on managing things about me . For example , P16 ( age 10 ) envisioned for designs to tell them more specifcally how profles were formed around me : “How they made that guess . Maybe like put up a search history , saying that I have searched this on this day so they think I’m a child or a boy or something . ” Children also showed greater interest in controlling things about me , such as “removing these guesses about me on my profle” ( P25 , age 11 ) and “choosing which websites can receive my profle” ( P52 , age 10 ) . In general , children want to be able to decide what goes onto their profle , how ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany it’s generated and could be used . In terms of how they want to be supported , it is interesting to see that , unlike younger children who preferred direct help , children from this age group wanted for support that help them make their own choices : “Tell me the consequences of my choices , but let me decide . ” ( P35 , age 11 ) , and they expected parental involvement in more communicative ways instead of just telling them what to do : P17 ( age 11 ) explaining “We added a button here to invite parents to do these settings with us . ” Finally , from around 11Yr onward , children in our study largely found the cognitive - thinking insufcient and preferred the situ - ated and critical - thinking support . Meanwhile , they demonstrated greater interest in the critical - thinking designs . Apart from things about me , children from this age group started to also become in - terested in things about people other than me , and more broadly around the datafcation phenomena and its implications . This is also refected in their designs , such that they started to want de - signs that explain “the full picture of datafcation” ( P38 , age 14 ) to them , including topics ranging from algorithms used in the dataf - cation practices — “the kind of formula , weights of factors used in the algorithm” ( P34 , age 13 ) , to what are the “data partnership be - tween the websites I visit the most” ( P31 , age 12 ) . Children from this group not only care about what is being done by the datafcation practices , but also why the datafcation practices were performed and how it would have greater impact . They expect designs to be delivered in ways with both facts and reasoning behind the facts . When comparing to younger children , children in this age group demonstrated interest beyond things about me , and extend such interest to “people around me” and the greater society . For exam - ple , P45 ( age 14 ) talked about wanting to learn “how my data , my friends data , my parents data , and everyone’s data is combined and merged by them [ platforms ] and how it [ datafcation ] would have efect on every single one of us . ” . P31 ( age 12 ) also described : “Why they [ platforms ] are doing all these , how it beneft them and how it may have impact on us as users , and maybe even how it would impact the society . ” 4 . 3 . 2 Demand for More Autonomy - Supportive Designs . Children in our study envisioned several key designs to assist them to have greater autonomy , i . e . , to take more active roles when coping with datafcation practices , where the children felt like they should be the ones to initiate the action . To start with , some children proposed that it is important for them to receive alerts and notifcations in a more visible way so that they could take an active action . For example , P11 ( age 7 ) described the design of “a huge question mark that you can click on , at every place they brought up this profling thing . To me , that’s more important than other things” . Furthermore , many children expressed that it is crucial to have more simplifed designs that encourage active actions , instead of having to navigate complicated user interfaces . As a step in this direction , P18 ( age 9 ) sketched a home screen that present users with all the settings they can confgure on one page , instead of “hiding all settings under sixteen layers of pages” . Some more active designs include the ones that enable children to inspect on things to ask for clarifcations and modifcations [ DS6 ] , as in P28’s ( age 11 ) sketch with their teammate : “We designed for this e - highlighter function , so that you can highlight the bit where you fnd confusing or don’t like . Like them guessing that you like fast food , the website would then go back and review that assumption they made about you . ” Some still more active designs were when the ( typically older ) child expressed a desire to control and personalise how data profling is computed about them : instead being treated as passive recipients that can only confgure things once all the datafcation is done , children proposed ways to actively engage in the whole datafcation process . Such mechanisms included designs that support them to “choose which pages I visited can be used to generate my profle” ( P38 , age 14 ) [ DS7 ] ; “deciding the models used to build my profle , like I can assign a value on how much this thing I did online matters , or if that’s just a random thing I did . ” ( P51 , age 10 ) [ DS4 ] . Similarly , instead of just being told how their profles might be shared with other platforms , a group of children [ DS6 ] designed for mechanisms that they can create a list of platforms themselves , deciding on who can have their profle or not . 4 . 3 . 3 Call for More Humane Designs . Another theme that emerged from children’s design activities was their desire to have positive experience and willingness to build a positive relationship with the platforms . Children expressed their expectations to be treated more equally and more humanely by the platforms : “If the platforms were humane , which I think they are , which I hope they are . They would know they are dealing with actual people , we are not just statistics in their database or whatever . ” ( P52 , age 10 ) . To start with , children described how they want to have “more positive experience” ( P12 , age 8 ) on the digital platforms , such as through the use of smiley icons and more friendly tones [ DS2 ] : “We changed this sentence to ‘Will you allow us to recommend you videos based on your profle ? ’ . Because with that , it feels like a nice lady trying to talk to you , unlike a machine just trying to generate info about you . ” ( P6 , age 12 ) . Some children also talked about the use of “more humane way” ( P43 , age 14 ) of delivering the designs : “Don’t just show me the numbers , it feels really cold . ” ( P50 , age 13 ) . Children expressed great emotions and angers when they felt they are not “being treated as a human” : “ I’m being dehumanised . The way they deliver these things [ e . g . , data policy ] . . . give me information , but don’t care about my reactions at all . ” ( P51 , age 14 ) ; “It feels like all that matters to them is ‘me’ as my data , like not ‘me’ as a human - being . ” ( P2 , age 13 ) . One interesting observation we had on children’s redesigns is their tendency to per - sonify a platform , almost in an unconscious way . A direct example of this is how often some kind of bot - personifed version of the platform would show up in diferent children’s designs ( e . g . , [ DS3 ] , [ DS4 ] , [ DS9 ] ) . Children talked about how they want to be able to have “actual conversations” with it , because “That’s what human do , they talk with each other , not just showing each other with numbers and statistics . ” ( P12 , age 8 ) Other children [ DS4 ] also designed for mechanisms that can “take care of me , know what I want” ( P18 , age 9 ) — designs that can tell what’s personal or secretive to a child and help children to hide these information from the datafcation practices , or even mechanisms that can “protect me when I need it” - P39 ( age 9 ) redesigned for a mechanisms in which platforms are now able to identify if one’s profle contains “sensitive information” and whether such information would cause harmful efect on them . When performing these redesigns , themes including “friendship” and “relationship” were frequently brought up ( e . g . , [ DS2 ] , [ DS5 ] , [ DS10 ] ) : “Treat me as your friend , not just a number in your database” ( P6 , age 12 ) . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . 5 DISCUSSION 5 . 1 Implications for Children’s Digital Literacy Development Children are often regarded as less capable or competent than adults for coping with the complexities of online life , including aspects of privacy , safety , and datafcation [ 63 ] . However , through a multi - step co - design workshop , we found that not only do children care signif - icantly about various aspects of datafcation , but they demonstrate some rudimentary conceptual understandings of it , and a strong willingness to transform their conceptualisation to concrete design practices . Children in our study demonstrate understandings of various levels while with diferences across age groups , confrming the urgency in extending children’s critical algorithmic literacy . We observed three key knowledge gaps in children : lack of recognition of their own data rights , data being transmitted across platforms and companies , and the real - world implications of inference being made about them . Our results reinforced existing fndings that chil - dren do not always comprehend datafcation to a full extent [ 109 ] , and shed a new light on how children’s understanding difers in age , which requires age - appropriate support for children’s algorithmic literacy development . The three gaps of knowledge demonstrated by children in dif - ferent age groups are largely aligned with the three forms of com - putational thinking in CAL ( Section 2 . 3 ) , namely from cognitive thinking ( i . e . understanding of basic computational concepts ) , to situated thinking ( i . e . situate the abstract computational concepts in context children know and care about ) , and fnally to critical thinking ( i . e supporting the questioning of larger structures and processes behind the computational phenomenon ) . The CAL frame - work provides a useful framework for us to make sense of the diferent datafcation perceptions exhibited by children of younger v . s . older age , and identify future directions to support children’s digital literacy development . For the youngest children ( 7 to 9Yr ) , our results indicate a need for the design community to focus on informing children of basic computational concepts ( e . g , what is data , what is data transmission , what is data processing ) ; such concepts do not necessarily need to be in great depth and go be - yond laying down a foundation for children to comprehend more complicated context . This will complement existing focus on using accessible medium ( such as cartoons or video material ) for younger children [ 8 ] . Meanwhile , our fndings also resonates the emphasis in CAL that children’s computational thinking should go beyond cog - nitive thinking , and situated thinking will complement children’s understanding of the social aspects of algorithmic systems . This is particularly relevant for the 9 + to 11Yr age group , while such content could appear daunting for some younger aged children . Platforms like Track This [ 13 ] , which allows children to choose a fctional persona ( as an infuencer or flthy rich ) to explore the impact of datafcation , or Interland [ 12 ] , which creates a virtual context for users to explore a diverse range of digital footprints and their implications , provide good situated thinking scenarios . Other fndings , especially from 11 + Yr children , demonstrated the importance of introducing critical thinking in algorithmic literacy . This ability of situating datafcation in a broader digital society is rarely discussed in existing research of algorithmic literacy [ 65 , 85 ] and can be challenging to facilitate . There is an increased number of tools and technologies supporting children’s algorithmic liter - acy development ( such as the UNESCO Algorithm & Data Literacy Project [ 10 ] ) . However , these initiatives rarely provide opportu - nities for children to play with ‘real’ data that is meaningful for them or allow them to carry out algorithmic investigations , and we encourage future designers to focus on these two specifc as - pects , as both of are crucial for pushing children to “conceptualise , create , and disseminate digital projects that break silences , expose important truths , and challenge unjust system” [ 53 ] . 5 . 2 Implications for Future Age - Appropriate Designs for Children Through our co - design activities , we identifed a strong need for providing age - appropriate support for children of diferent ages . Our results showed that the depth of children’s understanding of datafcation varied signifcantly between age groups . We found that children in the younger age group preferred simpler designs ( cognitive - thinking inspired ones ) that ofered them more simplifed information , helping them to grasp the basic ideas on datafcation and its implications . Whereas almost all children in the older age groups preferred designs that are more situated to their actual digi - tal experiences and to provoke their critical - thinking , and showed great willingness towards having more information “related to me” as well as learning about the more in - depth problems behind the datafcation phenomena . Our fndings provide critical inputs re - garding design implications for future age - appropriate designs that support children coping with datafcation . We therefore propose that there is no one - fts - all design solution when it comes to design - ing for children . How shall future designers address the various needs in children from diferent age groups , and how shall they unpack this no one - fts - all design then ? Rethink what ‘transparency’ means for children of diferent age groups . To start with , we have observed that , in contrast to how some of the child - specifc technologies have been carefully consid - ered according to children’s age and developmental needs [ 3 , 31 , 42 ] , today’s digital platforms have given much less consideration regard - ing how children should be informed of the ubiquitous datafcation behaviours online . This poses a strong need for future designers to rethink what ‘transparency’ means for children of diferent age groups . . Our co - design activities have particularly focused on ex - ploring the type of data transparency that children would care for and be able to make sense of ( as shown by examples in Section 3 . 1 ) . The general assumption is that children have less awareness about the datafcation practice and data - based exploitation in their digital worlds [ 101 , 116 ] . Our research has shed new lights on this presumption . Children may have less ability to develop the nu - anced mental models exhibited in the previous research with adults , however , our observations of how diferent age groups perceived datafcation diferently provide important indicators for future de - sign developments : keeping languages simple is rudimentary for supporting younger children ( 7 - 9Yr ) , who also are more likely to need more parental involvement and support ; whereas connect - ing datafcation with a child’s individual interests or context may provide a more convincing perspectives for designing algorith - mic transparency for older children ( 9Yr + ) . For 11Yr + children , we recommend designers to consider scafolding children for more ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany in - depth thinking including what are their roles and rights in a datafed society . Future design investigations must be cautious of the age - specifc needs from children and a child - centred design approach is crucial to the process . Reposition children as active participants than passive con - sumers online . A key insight from our fndings is children’s strong desire on self - autonomy over their own digital experience and signifcant willingness to confgure the datafcation practices on them , as shown in our discussions in Section 4 . 3 . This indicates a strong need to reposition children as ‘active’ participants than passive consumers in the process of designing empowerment tools for them . Designers should consider options to facilitate children to actively engage in the various datafcation practices ( e . g . , how a specifc video has been chosen for them , how data about them is shared and used ) ; instead of treating them as passive recipients of content . This support should also be considered according to age - specifc needs of children . For younger children ( 7 - 9Yr ) , designers should consider allowing children to conduct direct control , providing protection for children against the datafcaiton practices not wanted ( e . g . , a button to turn of all data inference ) , and avoid hiding such option under layers of menus . We also suggest designers to ofer children direct guidance on what would happen is a certain choice is made and send out alerts and notifcations in a more visible way . For the slightly older children ( 9 + to 11Yr ) , many children expressed their desire for real - time support as they make choices online , which could be better supported with mechanisms such as just - in - time visualisations of how choices could efect their online experience ( e . g . , a visualisation on the changes in recommendations ) . Older children ( 11Yr + ) demonstrated a strong need for more fne - grained control , as they seek ways to actively shape their own datafcaiton experience . These children also demonstrated tendency to seek help from their peers instead of parents , and thus setting up mechanisms for peer support or for informing children of their data rights may be more meaningful . Demonstrate care and respect . Another interesting theme ob - served from our fndings is children’s great willingness in building a “positive relationship” / “friendship” with the online platforms , and their desire in being treated in more humane ways - they want to be treated as a human , not “a random number in the database” . Such an expectation echoes with the recent line of work in UX literature around designing for dignity / humane by design , which promotes designing systems so that users experience dignity throughout the system , and its core holding is that designers must view users not just as a means to making capital , but treat them with respect and dignity themselves [ 2 , 11 ] . Children expected themselves to be respected and taken care of by the platforms . For the younger children ( 7 - 9Yr ) , they require “positive elements” to reinforce this reassurance , such as through smiley icons and nicer tones . An in - teresting fnding is that the children consistently conceptualise ways for platforms to have conversations with them , and respond in a human - like manner ( e . g . , human characterstics ) . Prior stud - ies have showed that personifed voice assistants with traits such as diferent accents and personalities could be more favoured by young children [ 47 ] . Mechanisms such as using basic conversa - tional elements to present information or respond to choices made ( e . g . , “You did a great job ! ” ) could be an efective direction to ex - plore for younger children . However , such approaches must ensure children’s innocence is protected but not exploited and guided by careful , ethical considerations ( further discussions in Section 5 . 3 ) . Older children ( 9 + above ) are keen to receive explanations that show them how things have been done in their best interests , and demand themselves not to be treated as numbers . Future designs should consider providing more than factual details , and comple - ment such with contextualised explanations on how and why things are done . Designers should also consider allowing children to re - spond to information given and decision made for them ( e . g . , “I don’t agree with this” button ) , and accommodate their requests in an equal and respectful way . 5 . 3 Towards Future Data - driven Digital Experiences for Children Our observations of children’s current experience and perceptions of datafcation prompted the need for rethinking what future data - driven digital experiences should be like for children . One interest - ing observation was children did not only want to be meaningfully informed about their data , but they wanted the informant to be humanoid in some way . Such fndings echo with previous research , that children interact with virtual agents diferently than adults , and they tend to have social exchanges ( e . g . , “bye ! Google ! ” ) [ 24 ] and emotional interactions ( e . g . , “I love you , Alexa ! ” ) [ 47 ] with systems , and could refer to virtual agents with person pronouns more often than those adult users [ 88 ] . Children want to be treated with respect and they demand to be treated as equal human - being . It is perhaps therefore not surprising that when coming up with solutions and design alternatives , children tend to believe that their wish will be fulflled if the data - driven platforms were human . While such ideologies provide new design opportunities for chil - dren’s experience online — personifed voice assistants with traits such as diferent accents and personalities were found to be more favoured by children [ 47 ] , the innocence and willingness to estab - lish friendships with platforms exhibited by children also called for the need on greater safeguarding measures and more cautious designs — it should be protected , not exploited . While humanis - ing these platforms seemed wonderful at frst glance , there is an implication that trust can be misused to further monetisation prior - ities , while exploiting people ( children ) who are most vulnerable . Existing research within the children - robot interaction community suggest that children can develop trust and afection on humanoid robots [ 23 , 67 , 102 , 105 ] . While these studies found that children could fnd it easier to approach a humanoid with their problems than approach an actual human [ 94 , 96 ] . It was also suggest that children could more likely to share secrets or problems which they would normally not share [ 20 , 111 ] . It was found that when too much personifcation is embedded , children could feel deceived when humanoid pass on the information being told [ 97 , 111 ] . In the meantime , to autonomously detect which information was told in secrecy ( as was suggested by some of our children participants ) , sophisticated speech recognition would be required , and existing approaches are yet to work reliably with children [ 55 ] . We therefore call for attention to the designers community to carefully consider their design choices – What happens when we give data personal - ity ? What happens when data is not just used to inform children , but children develop trust with data that can be breached ? While CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . there has yet to be complete answers to these questions , we urge fu - ture designs to not simply focus on exploiting children’s willingness in building positive relationship through simple personifcation de - signs ( e . g . , using human - like voices or calling out names ) , but build systems and platforms in ways that genuinely care about children , treating them with respect and providing them with the care and support that they need . Children’s expectation in respect and care directly relates to - wards children’s desire for greater data autonomy online . In our study , both children’s proposed solutions to perceived problems in the fctional inquiry sessions and their designs in the feature redesign sessions confrmed and echoed with previous fndings on children’s desire for more legibility and control [ 109 ] . Children’s expressed a need for means to learn more about and to efectively control their data online marks a strong call for greater data au - tonomy from children . As pointed out by many children in our study , the current datafed society demands a fundamental shift of the current data ecosystem ( “a revolution is needed” P32 , age 13 ) . They believe that the key contributing factor to the current ubiquitous datafcation in their lives , as well as our society , is the centralised data monopoly and concentration of power by a number of platforms ( “1 % companies controlling 98 % data” P53 , age 14 ) . A strong theme of data activism emerged from children’s discussion , and these “young data activists” are demanding actions to be taken . Data activism here refers to the recent movement in which citizens are becoming increasingly engaged in the range of socio - technical practices that interrogate the fundamental paradigm shift brought about by datafcation [ 75 ] . While the notion of data activism is not entirely new and dates back to discussion around the democratic agency of things [ 60 , 66 ] and directly relates to this new wave of de - centralised paradigms for data sharing and ownership , which seeks to expand individual data subjects’ ability to control access to their data [ 7 ] , our work is the frst to identify such data activism in chil - dren , possibly even stronger than adults . . Previous research have attempted to address children’s autonomy online mainly through supporting them with improved behavioural autonomy [ 32 , 43 , 45 ] , such as dealing with excessive nudging or data - based behaviour manipulations , within the existing data ecosystem , which undoubt - edly is important . However , our work suggests that such support is probably not sufcient when children demand for more funda - mental changes to be taken and more fundamental autonomy to be re - gained . This provides crucial inputs to the current research re - garding supporting children’s digital autonomy , and we encourage future research make further explorations regarding how to design for mechanisms that help children regain their data rights , and how children would want a future , more humane and autonomy - supportive data ecosystem to look like . 6 LIMITATIONS AND FUTURE WORK There are several important limitations of this work , including self - reporting data in the pre - design activity , the study length and the use of a fctional storyline . We have attempted to mitigate these limitations through several ways . We correlated children’s self - reported perception and experiences with their responses in the design activities , to identify any potential misconceptions or gaps of knowledge , which led to our key fnding regarding the importance of age - appropriate designs . To avoid overburdening our partici - pants , our study sessions were designed to last no longer than 1 . 5 hours , which may afect children’s ability to recall knowledge . Researchers were briefed to pay particular attention to quieter chil - dren and encourage their inputs , and group activities are regarded as more efective to prompt knowledge sharing and recall . Children were reminded there are no “right way” of redesigning features they want , and we endeavoured to ask questions in a language appropriate for the participant’s age and development . Finally , we acknowledge that our introduction of YouTube “elf” in the story - line may relate to our fndings about children’s tendency towards personifying online platforms . However , we believe such potential nudge may not afect our fndings much , as children’s tendency to - wards personifying non - living objects dates well back to their early stage development such as how they personify puppets / toys [ 95 ] , and thus is not uniquely triggered by our study setting . Further - more , our fnding was more nuanced and showed children’s desire to be treated as equal human - beings , which is a demand for more autonomy and humane - design , than simply viewing the platforms in a personifed way . Future work aims to explore how we may integrate the identifed design implications to existing features on the online platforms , and develop ways to support children’s tendency towards data autonomy . We intend to develop prototypes following the identifed design implications , exploring fexible scafolding for children’s diverse needs and their efects on children . Meanwhile , we aim to explore more ways for supporting the data activism in children as well as supporting their data literacy development . 7 CONCLUSION As children are growing up in an age of datafcation , children’s data are now being routinely used to profle , analyse and make predic - tions of them . Their actions online are not only recorded , tracked , aggregated , but also analysed and monetised . Such practices are hard to understand even by adult users , let alone children . This paper is the frst to contribute an understanding of how children aged 7 – 14 would like to be supported when coping with dataf - cation practices . Through 10 co - design sessions with 53 children , we identifed children’s envisioning and demand from platforms for coping with datafcation , followed by their desired concrete design practices , including age - related needs for more informed choices , call for more humane designs , and autonomy - supportive designs for more active engagement . Our fndings provide cru - cial insights for creating age - appropriate support for children’s algorithmic literacy development , highlighting and unpacking the importance of no one - size - ftting - all designs to support children’s coping with datafcation . We contribute a frst understanding of how children aged 7 – 14 would like to be supported with datafca - tion and what future data - driven digital experiences should be like for them , who demand a shift of the current data ecosystem towards a more humane - by - design and autonomy - supportive future . We hope that our fndings will support future designing for children in accommodating their diverse needs , and lay down the foundation for a more ethical data governance structure for children in the future . ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany REFERENCES [ 1 ] 1998 . Children’s Online Privacy Protection Rule ( " COPPA " ) . https : / / www . ftc . gov / enforcement / rules / rulemaking - regulatory - reform - proceedings / childrens - online - privacy - protection - rule [ 2 ] 2020 . 7 Heuristics For Humane Design . https : / / designlab . com / blog / heuristics - humane - design - designing - for - dignity / [ 3 ] 2020 . Age appropriate design : a code of practice for online ser - vices . https : / / ico . org . uk / for - organisations / guide - to - data - protection / ico - codes - of - practice / age - appropriate - design - a - code - of - practice - for - online - services [ 4 ] 2020 . Annex B : Age and developmental stages . https : / / ico . org . uk / for - organisations / guide - to - data - protection / ico - codes - of - practice / age - appropriate - design - a - code - of - practice - for - online - services / annex - b - age - and - developmental - stages / [ 5 ] 2020 . What is automated individual decision - making and profling ? https : / / ico . org . uk / for - organisations / guide - to - data - protection / guide - tothe - general - data - protection - regulation - gdpr / automated - decision - makingand - profling / what - is - automated - individual - decision - making - and - profling / [ 6 ] 2020 . What is automated individual decision - making and profling ? https : / / ico . org . uk / for - organisations / guide - to - data - protection / guide - to - the - general - data - protection - regulation - gdpr / automated - decision - making - and - profling / what - is - automated - individual - decision - making - and - profling / [ 7 ] 2021 . Ethical Web And Data Architectures . https : / / www . oxfordmartin . ox . ac . uk / ethical - web - and - data - architectures / [ 8 ] 2021 . ICO Age - appropriate mindsets tool . https : / / ico . org . uk / media / for - organisations / documents / 4017954 / age - appropriate - mindsets - pdf . pdf [ 9 ] 2021 . Playful by Design : Free play in a digital world . https : / / digitalfuturescommission . org . uk / wpcontent / uploads / 2021 / 11 / A - Vision - of - Free - Play - in - a - Digital - World . pdf [ 10 ] 2022 . The Algorithmic and Data Literacy Project . https : / / algorithmliteracy . org / [ 11 ] 2022 . Humane by Design . https : / / humanebydesign . com / [ 12 ] 2022 . InterLand . https : / / beinternetawesome . withgoogle . com / en _ us / interland [ 13 ] 2022 . Track This . https : / / trackthis . link / [ 14 ] Amelia Acker and Leanne Bowler . 2017 . What is your Data Silhouette ? Raising teen awareness of their data traces in social media . In Proceedings of the 8th International Conference on Social Media & Society . 1 – 5 . [ 15 ] Divyakant Agrawal , Philip Bernstein , Elisa Bertino , Susan Davidson , Umeshwas Dayal , Michael Franklin , Johannes Gehrke , Laura Haas , Alon Halevy , Jiawei Han , et al . 2011 . Challenges and opportunities with Big Data 2011 - 1 . ( 2011 ) . [ 16 ] Lindsey Arnold , Kung Jin Lee , and Jason C Yip . 2016 . Co - designing with children : An approach to social robot design . ACM Human - Robot Interaction ( HRI ) ( 2016 ) . [ 17 ] Alejandra Arrúa , Leticia Vidal , Lucía Antúnez , Leandro Machín , Joseline Martínez , María Rosa Curutchet , Ana Giménez , and Gastón Ares . 2017 . In - fuence of label design on children’s perception of 2 snack foods . Journal of Nutrition Education and Behavior 49 , 3 ( 2017 ) , 211 – 217 . [ 18 ] Thomas Beelen , Ella Velner , Roeland Ordelman , Khiet P Truong , Vanessa Evers , and Theo Huibers . 2022 . Designing Conversational Robots with Children during the Pandemic . arXiv preprint arXiv : 2205 . 11300 ( 2022 ) . [ 19 ] Mathilde M Bekker , Panos Markopoulos , and M Kersten - Tsikalkina . 2002 . Inter - action design and children : proceedings of the International Workshop " Interaction design and children " , August 28 - 29 , 2002 , Eindhoven , The Netherlands . Shaker - Verlag . [ 20 ] Cindy L Bethel , Matthew R Stevenson , and Brian Scassellati . 2011 . Secret - sharing : Interactions between a child , robot , and adult . In 2011 IEEE International Conference on systems , man , and cybernetics . IEEE , 2489 – 2494 . [ 21 ] Leanne Bowler , Amelia Acker , Wei Jeng , and Yu Chi . 2017 . “It lives all around us” : Aspects of data literacy in teen’s lives . Proceedings of the association for information science and technology 54 , 1 ( 2017 ) , 27 – 35 . [ 22 ] Virginia Braun and Victoria Clarke . 2006 . Using thematic analysis in psychology . Qualitative research in psychology 3 , 2 ( 2006 ) , 77 – 101 . [ 23 ] Kimberly A Brink and Henry M Wellman . 2020 . Robot teachers for children ? Young children trust robots depending on their perceived accuracy and agency . Developmental Psychology 56 , 7 ( 2020 ) , 1268 . [ 24 ] AJ Brush , Paul Johns , Kori Inkpen , and Brian Meyers . 2011 . Speech @ home : an exploratory study . In CHI’11 Extended Abstracts on Human Factors in Computing Systems . 617 – 632 . [ 25 ] Moritz Büchi , Eduard Fosch - Villaronga , Christoph Lutz , Aurelia Tamò - Larrieux , and Shruthi Velidi . 2021 . Making sense of algorithmic profling : user perceptions on Facebook . Information , Communication & Society ( 2021 ) , 1 – 17 . [ 26 ] Moritz Büchi , Eduard Fosch - Villaronga , Christoph Lutz , Aurelia Tamò - Larrieux , Shruthi Velidi , and Salome Viljoen . 2020 . The chilling efects of algorithmic profling : Mapping the issues . Computer law & security review 36 ( 2020 ) , 105367 . [ 27 ] Ingrid Burkett . 2012 . An introduction to co - design . Sydney : Knode ( 2012 ) , 12 . [ 28 ] European Commision . 2021 . General Data Protection Regulation ( GDPR ) . https : / / gdpr - info . eu / [ 29 ] European Commission . 2016 . The European Digital Competence Framework for Citizens . [ 30 ] Sayamindu Dasgupta and Benjamin Mako Hill . 2020 . Designing for Critical Algorithmic Literacies . arXiv preprint arXiv : 2008 . 01719 ( 2020 ) . [ 31 ] Lindsay Daugherty , Rafq Dossani , Erin - Elizabeth Johnson , and Cameron Wright . 2014 . Moving beyond Screen Time : Redefning Developmentally Appropriate Technology Use in Early Childhood Education . Policy Brief . RAND Corporation ( 2014 ) . [ 32 ] Maria del Mar Pàmies , Gerard Ryan , and Mireia Valverde . 2016 . How interven - tion can empower children as consumers in dealing with advertising . Interna - tional Journal of Consumer Studies 40 , 5 ( 2016 ) , 601 – 609 . [ 33 ] Christian Dindler , Eva Eriksson , Ole Sejer Iversen , Andreas Lykke - Olesen , and Martin Ludvigsen . 2005 . Mission from Mars : a method for exploring user re - quirements for children in a narrative space . In Proceedings of the 2005 conference on Interaction design and children . 40 – 47 . [ 34 ] Christian Dindler and Ole Sejer Iversen . 2007 . Fictional inquiry—design collab - oration in a shared narrative space . CoDesign 3 , 4 ( 2007 ) , 213 – 234 . [ 35 ] Stefania Druga , Sarah T Vu , Eesh Likhith , and Tammy Qiu . 2019 . Inclusive AI literacy for kids around the world . In Proceedings of FabLearn 2019 . 104 – 111 . [ 36 ] Stefania Druga , Sarah T . Vu , Eesh Likhith , and Tammy Qiu . 2019 . Inclusive AI Literacy for Kids around the World . In Proceedings of FabLearn 2019 ( New York , NY , USA ) ( FL2019 ) . Association for Computing Machinery , New York , NY , USA , 104 – 111 . https : / / doi . org / 10 . 1145 / 3311890 . 3311904 [ 37 ] Stefania Druga , Randi Williams , Hae Won Park , and Cynthia Breazeal . 2018 . How smart are the smart toys ? Children and parents’ agent interaction and intelligence attribution . In Proceedings of the 17th ACM Conference on Interaction Design and Children . 231 – 240 . [ 38 ] Stefania Druga , Jason Yip , Michael Preston , and Devin Dillon . 2021 . The 4As : Ask , Adapt , Author , Analyze - AI Literacy Framework for Families . In Algorithmic Rights and Protections for Children . PubPub . [ 39 ] Allison Druin . 1999 . Cooperative inquiry : developing new technologies for children with children . In Proceedings of the SIGCHI conference on Human Factors in Computing Systems . 592 – 599 . [ 40 ] Allison Druin . 2002 . The role of children in the design of new technology . Behaviour and information technology 21 , 1 ( 2002 ) , 1 – 25 . [ 41 ] Kenneth D Eason . 1995 . User - centred design : for users or by users ? Ergonomics 38 , 8 ( 1995 ) , 1667 – 1673 . [ 42 ] Colleen Finegan and Nancy Jo Austin . 2002 . Developmentally appropriate technology for young children . Information Technology in Childhood Education Annual 2002 , 1 ( 2002 ) , 87 – 102 . [ 43 ] Dan Fitton and Janet C Read . 2019 . Creating a framework to support the critical consideration of dark design aspects in free - to - play apps . In Proceedings of the 18th ACM International Conference on Interaction Design and Children . 407 – 418 . [ 44 ] UK Council for Internet Safety . 2020 . Education for a Connected World - 2020 Edition . https : / / assets . publishing . service . gov . uk / government / uploads / system / uploads / attachment _ data / fle / 896323 / UKCIS _ Education _ for _ a _ Connected _ World _ . pdf [ 45 ] Sarah Forberger , Lucia Reisch , Teresa Kampfmann , and Hajo Zeeb . 2019 . Nudg - ing to move : a scoping review of the use of choice architecture interventions to promote physical activity in the general population . International Journal of Behavioral Nutrition and Physical Activity 16 , 1 ( 2019 ) , 1 – 14 . [ 46 ] 5 Rights Foundation . 2021 . Playful by Design : Free play in a digital world . https : / / digitalfuturescommission . org . uk / wp - content / uploads / 2021 / 11 / A - Vision - of - Free - Play - in - a - Digital - World . pdf [ 47 ] Radhika Garg and Subhasree Sengupta . 2020 . He Is Just Like Me : A Study of the Long - Term Use of Smart Speakers by Parents and Children . Proc . ACM Interact . Mob . Wearable Ubiquitous Technol . 4 , 1 , Article 11 ( mar 2020 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3381002 [ 48 ] Mona Leigh Guha , Allison Druin , Gene Chipman , Jerry Alan Fails , Sante Simms , and Allison Farber . 2004 . Mixing ideas : a new technique for working with young children as design partners . In Proceedings of the 2004 conference on Interaction design and children : building a community . 35 – 42 . [ 49 ] Mona Leigh Guha , Allison Druin , and Jerry Alan Fails . 2013 . Cooperative Inquiry revisited : Refections of the past and guidelines for the future of intergenera - tional co - design . International Journal of Child - Computer Interaction 1 , 1 ( 2013 ) , 14 – 23 . https : / / doi . org / 10 . 1016 / j . ijcci . 2012 . 08 . 003 [ 50 ] Valerie Hémar - Nicolas , Hanum Putri Hapsari , Stephanie Angka , and Annemarie Olsen . 2021 . How cartoon characters and claims infuence children’s attitude towards a snack vegetable – An explorative cross - cultural comparison between Indonesia and Denmark . Food Quality and Preference 87 ( 2021 ) , 104031 . [ 51 ] Alexis Hiniker , Kiley Sobel , and Bongshin Lee . 2017 . Co - designing with preschoolers using fctional inquiry and comicboarding . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems . 5767 – 5772 . [ 52 ] DQ Institute . 2021 . Digital Intellegence Framework . https : / / www . dqinstitute . org / global - standards / [ 53 ] Yasmin Kafai , Chris Proctor , and Debora Lui . 2020 . From theory bias to theory dialogue : embracing cognitive , situated , and critical framings of computational thinking in K - 12 CS education . ACM Inroads 11 , 1 ( 2020 ) , 44 – 53 . CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . [ 54 ] Gabriella Kazai , Iskander Yusof , and Daoud Clarke . 2016 . Personalised news and blog recommendations based on user location , Facebook and Twitter user pro - fling . In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval . 1129 – 1132 . [ 55 ] James Kennedy , Séverin Lemaignan , Caroline Montassier , Pauline Lavalade , Bahar Irfan , Fotios Papadopoulos , Emmanuel Senft , and Tony Belpaeme . 2017 . Child speech recognition in human - robot interaction : evaluations and recom - mendations . In Proceedings of the 2017 ACM / IEEE International Conference on Human - Robot Interaction . 82 – 90 . [ 56 ] Nawsher Khan , Ibrar Yaqoob , Ibrahim Abaker Targio Hashem , Zakira Inayat , Waleed Kamaleldin Mahmoud Ali , Muhammad Alam , Muhammad Shiraz , and Abdullah Gani . 2014 . Big data : survey , technologies , opportunities , and chal - lenges . The scientifc world journal 2014 ( 2014 ) . [ 57 ] Maaike Kleinsmann and Rianne Valkenburg . 2008 . Barriers and enablers for creating shared understanding in co - design projects . Design studies 29 , 4 ( 2008 ) , 369 – 386 . [ 58 ] Priya Kumar , Shalmali Milind Naik , Utkarsha Ramesh Devkar , Marshini Chetty , Tamara L Clegg , and Jessica Vitak . 2017 . ’No Telling Passcodes Out Because They’re Private’ Understanding Children’s Mental Models of Privacy and Secu - rity Online . Proceedings of the ACM on Human - Computer Interaction 1 , CSCW ( 2017 ) , 1 – 21 . [ 59 ] Priya Kumar , Jessica Vitak , Marshini Chetty , Tamara L Clegg , Jonathan Yang , Brenna McNally , and Elizabeth Bonsignore . 2018 . Co - designing online privacy - related games and stories with children . In Proceedings of the 17th ACM confer - ence on interaction design and children . 67 – 79 . [ 60 ] Bruno Latour et al . 2004 . Politics of nature : How to bring the sciences into democ - racy . Harvard University Press . [ 61 ] Kung Jin Lee , Wendy Roldan , Tian Qi Zhu , Harkiran Kaur Saluja , Sungmin Na , Britnie Chin , Yilin Zeng , Jin Ha Lee , and Jason Yip . 2021 . The show must go on : A conceptual model of conducting synchronous participatory design with children online . In Proceedings of the 2021 CHI conference on human factors in computing systems . 1 – 16 . [ 62 ] James R Lewis . 2006 . Usability testing . Handbook of human factors and er - gonomics 12 ( 2006 ) , e30 . [ 63 ] Sonia Livingstone . 2018 . Children : a special case for privacy ? Intermedia 46 , 2 ( 2018 ) , 18 – 23 . [ 64 ] Sonia Livingstone , Mariya Stoilova , and Rishita Nandagiri . 2019 . Children’s data and privacy online . Technology 58 , 2 ( 2019 ) , 157 – 65 . [ 65 ] Duri Long and Brian Magerko . 2020 . What is AI literacy ? Competencies and design considerations . In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems . 1 – 16 . [ 66 ] Noortje Suzanne Marres et al . 2005 . No issue , no public : Democratic defcits after the displacement of politics . Amsterdam . [ 67 ] Dorothea U Martin , Madeline I MacIntyre , Conrad Perry , Georgia Clift , Sonja Pedell , and Jordy Kaufman . 2020 . Young children’s indiscriminate helping behavior toward a humanoid robot . Frontiers in psychology 11 ( 2020 ) , 239 . [ 68 ] Giovanna Mascheroni . 2020 . Datafed childhoods : Contextualising datafcation in everyday life . Current Sociology 68 , 6 ( 2020 ) , 798 – 813 . [ 69 ] Ariadna Matamoros - Fernández . 2017 . Platformed racism : The mediation and circulation of an Australian race - based controversy on Twitter , Facebook and YouTube . Information , Communication & Society 20 , 6 ( 2017 ) , 930 – 946 . [ 70 ] Brenna McNally , Priya Kumar , Chelsea Hordatt , Matthew Louis Mauriello , Shal - mali Naik , Leyla Norooz , Alazandra Shorter , Evan Golub , and Allison Druin . 2018 . Co - designing mobile online safety applications with children . In Pro - ceedings of the 2018 CHI Conference on Human Factors in Computing Systems . 1 – 9 . [ 71 ] Brenna McNally , Matthew Louis Mauriello , Mona Leigh Guha , and Allison Druin . 2017 . Gains from participatory design team membership as perceived by child alumni and their parents . In Proceedings of the 2017 CHI conference on human factors in computing systems . 5730 – 5741 . [ 72 ] Ulises A Mejias and Nick Couldry . 2019 . Datafcation . Internet Policy Review 8 , 4 ( 2019 ) . [ 73 ] Amanda Meincke Melo and M Cecília C Baranauskas . 2003 . Design with children : a Semiotic approach . In Proceedings of the Latin American conference on Human - computer interaction . 69 – 78 . [ 74 ] Rebecca Michelson , Akeiylah DeWitt , Ria Nagar , Alexis Hiniker , Jason Yip , Sean A Munson , and Julie A Kientz . 2021 . Parenting in a Pandemic : Juggling Multiple Roles and Managing Technology Use in Family Life During COVID - 19 in the United States . Proceedings of the ACM on Human - Computer Interaction 5 , CSCW2 ( 2021 ) , 1 – 39 . [ 75 ] Stefania Milan and Lonneke Van der Velden . 2016 . The alternative epistemolo - gies of data activism . Digital Culture & Society 2 , 2 ( 2016 ) , 57 – 74 . [ 76 ] Lilian Mitrou , Miltiadis Kandias , Vasilis Stavrou , and Dimitris Gritzalis . 2014 . Social media profling : A Panopticon or Omniopticon tool ? . In Proc . of the 6th Conference of the Surveillance Studies Network . Barcelona , Spain , 1 – 15 . [ 77 ] Neema Moraveji , Jason Li , Jiarong Ding , Patrick O’Kelley , and Suze Woolf . 2007 . Comicboarding : using comics as proxies for participatory design with children . In Proceedings of the SIGCHI conference on Human factors in computing systems . 1371 – 1374 . [ 78 ] Myfanwy Morgan , Sara Gibbs , Krista Maxwell , and Nicky Britten . 2002 . Hear - ing children’s voices : methodological issues in conducting focus groups with children aged 7 - 11 years . Qualitative research 2 , 1 ( 2002 ) , 5 – 20 . [ 79 ] Michael J Muller and Sarah Kuhn . 1993 . Participatory design . Commun . ACM 36 , 6 ( 1993 ) , 24 – 28 . [ 80 ] Ofcom . 2021 . Children and parents : media use and attitudes report 2020 / 21 . https : / / www . ofcom . org . uk / _ _ data / assets / pdf _ fle / 0025 / 217825 / children - and - parents - media - use - and - attitudes - report - 2020 - 21 . pdf [ 81 ] Ofcom . 2022 . Children and parents : media use and attitudes report 2022 . https : / / www . ofcom . org . uk / _ _ data / assets / pdf _ fle / 0025 / 217825 / children - and - parents - media - use - and - attitudes - report - 2022 . pdf [ 82 ] Ofcom . org . [ n . d . ] . children and parents : media use and attitudes report 2019 . https : / / www . ofcom . org . uk / _ _ data / assets / pdf _ fle / 0023 / 190616 / children - media - use - attitudes - 2019 - report . pdf [ 83 ] Gwenn Schurgin O’Keefe , Kathleen Clarke - Pearson , Council on Communica - tions , and Media . 2011 . The impact of social media on children , adolescents , and families . Pediatrics 127 , 4 ( 2011 ) , 800 – 804 . [ 84 ] Joint Committee on the Draft Online Safety Bill . 2021 . Draft Online Safety Bill . https : / / committees . parliament . uk / publications / 8206 / documents / 84092 / default / [ 85 ] Luci Pangrazio and Lourdes Cardozo - Gaibisso . 2021 . “Your Data Can Go to Anyone” : The Challenges of Developing Critical Data Literacies in Children . In Critical digital literacies : Boundary - crossing practices . Brill , 35 – 51 . [ 86 ] Luci Pangrazio and Neil Selwyn . 2017 . ’My Data , My Bad . . . ’ Young People’s Personal Data Understandings and ( Counter ) Practices . In Proceedings of the 8th International Conference on Social Media & Society . 1 – 5 . [ 87 ] M Platt . 1999 . Children as our technology design partners . A . Druin ( 1999 ) . [ 88 ] Amanda Purington , Jessie G Taft , Shruti Sannon , Natalya N Bazarova , and Samuel Hardman Taylor . 2017 . " Alexa is my new BFF " Social Roles , User Satisfaction , and Personifcation of the Amazon Echo . In Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems . 2853 – 2859 . [ 89 ] Ashwini Rao , Florian Schaub , and Norman Sadeh . 2015 . What do they know about me ? Contents and concerns of online behavioral profles . arXiv preprint arXiv : 1506 . 01675 ( 2015 ) . [ 90 ] Deborah Richards , Patrina HY Caldwell , and Henry Go . 2015 . Impact of social media on the health of children and young people . Journal of paediatrics and child health 51 , 12 ( 2015 ) , 1152 – 1157 . [ 91 ] Bernhard Rieder . 2017 . Scrutinizing an algorithmic technique : The Bayes classi - fer as interested reading of reality . Information , Communication & Society 20 , 1 ( 2017 ) , 100 – 117 . [ 92 ] Elizabeth B - N Sanders and Pieter Jan Stappers . 2008 . Co - creation and the new landscapes of design . Co - design 4 , 1 ( 2008 ) , 5 – 18 . [ 93 ] Marijn Sax . 2016 . Big data : Finders keepers , losers weepers ? Ethics and Infor - mation Technology 18 , 1 ( 2016 ) , 25 – 31 . [ 94 ] Sofa Serholt , Wolmet Barendregt , Asimina Vasalou , Patrícia Alves - Oliveira , Aidan Jones , Sofa Petisca , and Ana Paiva . 2017 . The case of classroom robots : teachers’ deliberations on the ethical tensions . Ai & Society 32 , 4 ( 2017 ) , 613 – 631 . [ 95 ] Rachel L Severson and Shailee R Woodard . 2018 . Imagining others’ minds : The positive relation between children’s role play and anthropomorphism . Frontiers in psychology 9 ( 2018 ) , 2140 . [ 96 ] Amanda JC Sharkey . 2016 . Should we welcome robot teachers ? Ethics and Information Technology 18 , 4 ( 2016 ) , 283 – 297 . [ 97 ] Matthijs Smakman , Paul Vogt , and Elly A Konijn . 2021 . Moral considerations on social robots in education : A multi - stakeholder perspective . Computers & Education 174 ( 2021 ) , 104317 . [ 98 ] Clay Spinuzzi . 2005 . The methodology of participatory design . Technical communication 52 , 2 ( 2005 ) , 163 – 174 . [ 99 ] Pieter Jan Stappers , Paul Hekkert , David Keyson , et al . 2007 . Design for inter - action : consolidating the user - centred focus in industrial design engineering . In DS 43 : Proceedings of E & PDE 2007 , the 9th International Conference on Engi - neering and Product Design Education , University of Northumbria , Newcastle , UK , 13 . - 14 . 09 . 2007 . 69 – 74 . [ 100 ] Marc Steen . 2013 . Co - design as a process of joint inquiry and imagination . Design Issues 29 , 2 ( 2013 ) , 16 – 28 . [ 101 ] Mariya Stoilova , Sonia Livingstone , and Rishita Nandagiri . 2020 . Digital by default : Children’s capacity to understand and manage online data and privacy . Media and Communication ( 2020 ) . [ 102 ] Rebecca Stower , Natalia Calvo - Barajas , Ginevra Castellano , and Arvid Kappas . 2021 . A meta - analysis on children’s trust in social robots . International Journal of Social Robotics 13 , 8 ( 2021 ) , 1979 – 2001 . [ 103 ] THORN . 2021 . Responding to Online Threats : Minors’ Perspectives on Dis - closing , Reporting , and Blocking . https : / / info . thorn . org / hubfs / Research / Responding % 20to % 20Online % 20Threats _ 2021 - Full - Report . pdf [ 104 ] Kjerstin Thorson , Kelley Cotter , Mel Medeiros , and Chankyung Pak . 2021 . Al - gorithmic inference , political interest , and exposure to news and politics on Facebook . Information , Communication & Society 24 , 2 ( 2021 ) , 183 – 200 . ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany [ 105 ] Simone Van Der Hof , Eva Lievens , Ingrida Milkaite , Valerie Verdoodt , Thijs Hannema , and Ton Liefaard . 2020 . The child’s right to protection against economic exploitation in the digital world . The International Journal of Children’s Rights 28 , 4 ( 2020 ) , 833 – 859 . [ 106 ] Maarten Van Mechelen . 2016 . Designing technologies for and with children : The - oretical refections and a practical inquiry towards a co - design toolkit . ( 2016 ) . [ 107 ] Sandra Wachter . 2020 . Afnity Profling and Discrimination by Association in Online Behavioral Advertising . Berkeley Tech . LJ 35 ( 2020 ) , 367 . [ 108 ] Greg Walsh , Elizabeth Foss , Jason Yip , and Allison Druin . 2013 . FACIT PD : a framework for analysis and creation of intergenerational techniques for par - ticipatory design . In proceedings of the SIGCHI Conference on Human Factors in Computing Systems . 2893 – 2902 . [ 109 ] Ge Wang , Jun Zhao , Max Van Kleek , and Nigel Shadbolt . 2022 . ‘Don’t make assumptions about me ! ’ : Understanding Children’s Perception of Datafcation Online . Proc . ACM Hum . - Comput . Interact . 6 , CSCW2 , Article 419 ( nov 2022 ) , 24 pages . https : / / doi . org / 10 . 1145 / 3555144 [ 110 ] Ge Wang , Jun Zhao , Max Van Kleek , and Nigel Shadbolt . 2022 . Informing Age - Appropriate AI : Examining Principles and Practices of AI for Children . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems ( New Orleans , LA , USA ) ( CHI ’22 ) . Association for Computing Machinery , New York , NY , USA , 1 – 29 . https : / / doi . org / 10 . 1145 / 3491102 . 3502057 [ 111 ] J Kory Westlund , Cynthia Breazeal , and A Story . 2015 . Deception , secrets , children , and robots : What’s acceptable . In Workshop on The Emerging Policy and Ethics of Human - Robot Interaction , held in conjunction with the 10th ACM / IEEE International Conference on Human - Robot Interaction . [ 112 ] Julia Woodward , Zari McFadden , Nicole Shiver , Amir Ben - Hayon , Jason C Yip , and Lisa Anthony . 2018 . Using co - design to examine how children conceptualize intelligent interfaces . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . 1 – 14 . [ 113 ] Julia Woodward , Zari McFadden , Nicole Shiver , Amir Ben - hayon , Jason C . Yip , and Lisa Anthony . 2018 . Using Co - Design to Examine How Children Conceptualize Intelligent Interfaces . In Proceedings of the 2018 CHI Confer - ence on Human Factors in Computing Systems ( Montreal QC , Canada ) ( CHI ’18 ) . Association for Computing Machinery , New York , NY , USA , 1 – 14 . https : / / doi . org / 10 . 1145 / 3173574 . 3174149 [ 114 ] Jason Yip , Tamara Clegg , Elizabeth Bonsignore , Helene Gelderblom , Emily Rhodes , and Allison Druin . 2013 . Brownies or bags - of - stuf ? Domain expertise in cooperative inquiry with children . In Proceedings of the 12th International Conference on Interaction Design and Children . 201 – 210 . [ 115 ] Jason C Yip , Elizabeth Foss , Elizabeth Bonsignore , Mona Leigh Guha , Leyla Norooz , Emily Rhodes , Brenna McNally , Panagis Papadatos , Evan Golub , and Allison Druin . 2013 . Children initiating and leading cooperative inquiry sessions . In Proceedings of the 12th International Conference on Interaction Design and Children . 293 – 296 . [ 116 ] Jun Zhao , Ge Wang , Carys Dally , Petr Slovak , Julian Edbrooke - Childs , Max Van Kleek , and Nigel Shadbolt . 2019 . ‘I Make up a Silly Name’ : Understanding Children’s Perception of Privacy Risks Online . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems ( Glasgow , Scotland Uk ) ( CHI ’19 ) . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3290605 . 3300336 [ 117 ] Shoshana Zubof . 2015 . Big other : surveillance capitalism and the prospects of an information civilization . Journal of information technology 30 , 1 ( 2015 ) , 75 – 89 . [ 118 ] Shoshana Zubof . 2019 . The age of surveillance capitalism : The fght for a human future at the new frontier of power : Barack Obama’s books of 2019 . Profle books . A APPENDIX CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . Table 1 : Summary of participants’ demographic information Figure 4 : This table describes our redesigns of the 12 mechanisms on YouTube . We created 6 mockups for each mechanism , split between transparency and control , and with diferent design thinkings inspired by the CAL framing : cognitive , situated , and critical . See Figure 5 for graphical representations . ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Table 2 : Individual participant’s demographics ( co - design session 1 – 5 ) CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Ge Wang et al . Table 3 : Individual participant’s demographics ( co - design session 6 – 10 ) ‘Treat me as your friend , not a number in your database’ CHI ’23 , April 23 – 28 , 2023 , Hamburg , Germany Figure 5 : 12 Mockups of Changes to Mechanisms in the YouTube Platform