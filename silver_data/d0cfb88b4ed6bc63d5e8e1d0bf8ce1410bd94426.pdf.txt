1 Prototyping Dynamics : Sharing Multiple Designs Improves Exploration , Group Rapport , and Results Steven P . Dow , Julie Fortuna , Dan Schwartz , Beth Altringer , Daniel L . Schwartz , Scott R . Klemmer Stanford HCI Group [ spdow , srk ] @ stanford . edu ABSTRACT Prototypes ground group communication and facilitate decision making . However , overly investing in a single prototype can lead to fixation and impede the collaborative process . Does sharing multiple prototypes improve collabo - rative design ? In a study , participants prototyped advertis - ing designs alone and then discussed the campaign with a partner . In the Share Multiple condition , participants de - signed and shared three ads . In the Share Best condition , participants designed three ads and selected one to share . In the Share One condition , participants designed and shared one ad . Each condition was allotted the same time for de - sign . In all conditions , partners critiqued each other’s ads , then individually created a final ad . Share Multiple ads significantly outperformed other ads . Participants who designed and shared multiple prototypes integrated more of their partner’s ideas into their own subsequent designs , explored a more divergent set of ideas , and provided more productive critiques of their partner’s designs . Understand - ing how and why prototyping practices differentially affect results can have a broad impact on design research and education . Author Keywords Prototyping , group dynamics , iteration , feedback , compari - son , divergence , exploration , critique , conceptual blending , design communication , group rapport ACM Classification Keywords H . 1 . m . [ Information Systems ] : Models and Principles General Terms Experimentation , Design INTRODUCTION Many designers live by the principle , “never go to a client meeting without a prototype” [ 52 ] . Prototypes help people summarize their ideas , demonstrate progress and expertise , surface implicit design vocabulary , and ground group communication and decision making [ 13 , 44 , 45 ] . Sharing prototypes may also carry risks . First , the presence of a concrete prototype may ( for better and for worse ) focus the discussion on refining that idea rather than thinking more broadly [ 14 , 31 ] . Second , those presenting designs often believe their status to be on the line [ 13 ] . This risk encour - ages overinvesting time , labor , psychological energy , and social momentum into a single concept [ 12 , 18 ] . In this single - prototype strategy , individuals may seek validation for their ideas and disregard or fear the critique and feed - back necessary for exploration and revision [ 39 ] . Without exploration , people often interpret the frame of the design problem too narrowly [ 32 ] . Compounding this , collabora - tive work is often susceptible to groupthink , where mem - bers reinforce each other’s belief in the current direction at the expense of other options [ 30 ] . An alternate strategy is for designers to share multiple rough prototypes during critiques instead of just one . This “parallel” strategy can help individuals more effectively understand underlying design principles , enumerate more diverse solutions , and react less negatively to feedback [ 18 ] . Distributing one’s psychological investment across multiple prototypes can reduce fixation and sunk - cost rea - soning [ 6 , 31 ] . Individuals may be more candid and critical of their own and others’ ideas [ 53 ] , resulting in more fluid and effective collaboration . However , creating multiple alternatives leaves less time to polish each one and may be perceived as wasting effort [ 45 ] . Focusing on fewer endeavors can help people focus , contemplate , relax , and be more productive [ 29 , 36 ] . In - creasing options can cause analysis paralysis — a “paradox” of choice [ 46 ] — and may jeopardize a group’s ability to achieve consensus [ 9 ] . What are the impacts of preparing and sharing multiple designs ? This paper investigates the hypothesis that sharing multiple prototypes increases design performance , im - proves group interaction , and leads to more effective idea sharing . In a between - subjects experiment , 84 participants working in pairs designed Web banner advertisements for a non - profit organization . The study comprised three steps . First , participants prototyped designs individually . Second , they worked with a partner to critique each other’s ideas . Third , each individual created a final ad . Participants an - swered survey questions at several points and open - ended questions at the end . Pairs were randomly assigned to one of three conditions : creating and sharing multiple ads ; cre - ating multiple ads and sharing the best ; and creating and sharing one ad . Comparing these three conditions separates the effects of producing multiple designs and sharing mul - tiple designs . The study found that ads in the Share Multiple condition generated more clicks per impression than the other condi - tions ( see Figure 1 ) . Independent ( and blind - to - condition ) judges rated ads from the Share Multiple condition signifi - unpublished tech report , 09 . 24 . 2010 2 cantly higher than the Share One and Share Best condi - tions . Judges also rated Share Multiple ads as significantly more divergent . Participants in the Share Multiple condition shared significantly more ideas and moved more towards consensus than pairs who shared only one design . Group members in the Share Multiple condition reported a greater increase in rapport over the course of the experiment , while rapport in the Share One and Share Best conditions dropped . Moreover , Share Multiple participants exchanged turns speaking significantly more often . Participants who scored high on a pretest of design principles created higher - rated ads . In short , sharing multiple designs improves outcome , explo - ration , sharing , and group rapport . This result has signifi - cant implications for how designers and educators structure creative group work . Exposure to examples enhances individual exploration Exposing people to examples increases the likelihood they will integrate similar features into their own designs [ 42 ] , even when they are asked to create vastly different ideas [ 22 ] . Furthermore , people’s borrowing increases with the number of examples people see [ 37 ] . Smith et al . hypothe - sized that people often take the path of least resistance , and that this conformity constrains creativity [ 42 ] . However , using Smith et al . ’s task , Marsh et al . found that partici - pants who saw many examples created equally novel work [ 37 ] . In other words , participants borrowed from examples when they lacked a better idea , but viewing examples did not “push out” or inhibit people’s novel ideas . Furthermore , when viewed from a quality perspective rather than a nov - elty perspective , people perform better when examples are readily available [ 11 , 34 ] . In all of this prior work , the ex - amples were presented anonymously . Collaborative work is importantly different in this regard because the examples are produced by a known and co - present peer . This paper hypothesizes that producing multiple prototypes and being exposed to multiple examples produced by other group members leads individuals to create a more divergent set of prototypes . Hypothesis 1 : Creating and viewing multiple proto - types leads to more individual design exploration . This study measured individual design exploration by hav - ing independent raters judge the diversity / similarity of each participant’s prototypes . Sharing multiple prototypes improves collaboration Designers often work collaboratively to generate , critique , and revise ideas , and to build consensus [ 25 , 44 , 55 ] . Under controlled conditions , individuals working separately often collectively produce a greater volume of ideas than group brainstorming [ 17 , 51 ] . Group members may block each other from sharing ideas [ 48 ] , get frustrated with bad apples in the group [ 21 ] , and deferentially follow others’ ideas [ 30 ] . However , measuring only the sheer volume of ideas is misleading : group brainstorming supports organizational memory of design solutions , recognizes skill variety among team members , and builds shared ownership of ideas— crucial for selecting and refining concepts [ 50 ] . To some extent , the debate over whether to design individually or collectively presents a false choice ; creative work typically involves both [ 10 , 49 ] . Sharing ideas with a group can be an anxiety - laden experi - ence , and this anxiety can negatively affect performance [ 16 , 43 ] . Individuals who know they will be judged by ex - perts produce less novel ideas [ 17 ] . Many critique providers are aware that public feedback can be emotionally fraught ; consequently they take care to temper criticism [ 53 ] and supplement critique with praise [ 28 ] . Anxiety may increase when people believe their worth as a person is part of what’s being assessed [ 16 , 33 ] . For this reason , many educa - tors and parents use language that critiques the work and the behavior , rather than the person [ 19 , 43 ] . Creating multiple designs may help both critique providers and creators separate egos from artifacts . When asked for feedback , people provide more substantive critique when presented with multiple design alternatives [ 53 ] . People react less negatively to critique when they create multiple alternatives in parallel , rather than serially [ 18 ] . This prior work studied individual behavior ; this paper analyzes the social effects . This paper hypothesizes that sharing multiple designs— rather than one—improves group rapport and increases the rate at which people exchange ideas . Hypothesis 2 : Sharing multiple prototypes leads to more productive dialogue and better group rapport . This study measured peer interaction by counting speech turns by each partner [ 40 , 41 ] . Also , five questions posed before and after the group discussion assessed individual views of their group’s rapport . Sharing multiple ideas facilitates conceptual blending When collaborating , groups often merge properties of dif - ferent concepts [ 20 ] . Sometimes , these blends directly in - herit properties [ 26 ] , other times blends spawn new emer - gent features [ 22 , 47 ] . Blending can be highly structured , as in morphological design [ 57 ] , but is more commonly ad Figure 1 Online ad performance ( clicks per million impressions ) : Share Multiple ads outperformed the other conditions . 3 hoc . When concepts are dissimilar blending them yields a more ambiguous artifact [ 56 ] . In design , conceptual ambiguity can provide a generative resource [ 23 , 35 ] . Sharing multiple designs may help col - laborators blend ideas . The process of comparing and con - trasting alternatives helps people create higher - level struc - tures [ 24 ] ; these structures also help collaborators under - stand and communicate the rationale behind design deci - sions [ 38 ] . This paper hypothesizes that sharing multiple prototypes facilitates conceptual blending and that collaborators will use more surface - level and thematic features from their partner’s work . Hypothesis 3 : Sharing multiple prototypes leads to more effective conceptual blending . This study measures conceptual blending by counting fea - tures that migrate from one partner’s preliminary designs to the other’s final design . Independent raters also judged the similarity of partner’s designs before and after the pair shared their work . Finally , this paper hypothesizes that sharing multiple de - signs leads to better performance due to a confluence of three factors : individuals explore more divergent ideas ; groups have stronger dialogue and rapport ; and the final design exhibit more effective conceptual blending . Hypothesis 4 : Sharing multiple prototypes produces better design results . This study measures design quality by gathering click - through performance metrics on advertisement designs and by recruiting professionals , clients , and other independent judges to rate ads . METHOD A between - subjects study manipulated prototyping prac - tices prior to a group critique . Web advertising was chosen as the design task because it fulfills the following criteria : ◊ Quality can be measured objectively and subjectively ; ◊ Participants need minimal artistic or engineering ability to either create or critique ads ; ◊ Individuals can complete tasks within a single lab session ; ◊ Solutions demonstrate creative diversity and a range of performance quality . Study Design Participants all created Web ads for the same client , FaceAIDS . org . The study allocated equal time for individ - ual design and group discussions across three conditions . In the Share Multiple condition , participants created three prototype advertisements and shared all three during the group discussion . In the Share Best condition , participants created three prototype ads and chose one to share during the group discussion . In the Share One condition , partici - pants spent the entire individual design time on a single ad to share during the group discussion . Participants We recruited 84 participants through papers fliers , online advertisements , and email lists . Two individuals arrived concurrently to form study pairs . Each pair was assigned to one of three conditions using a stratified randomization approach ; the study balanced for gender ( 41 females ) and graphic design knowledge across pairs and conditions . Ten true - or - false questions assessed graphic design knowledge ( see Appendix A ) ; participants were deemed experienced if they correctly answered eight or more ( 36 did ) . Participants who scored below eight were deemed novices . Participants’ average age was 26 . 5 ; three - fourths were students . Procedure The experiment comprised the following steps : consent form , icebreaker , tool training , practice ad , design brief , individual prototyping , discussion , final design , group in - terview , and final debriefing . Questionnaires collected demographic and self - report assessments . The icebreaker , group discussion , and group interview were co - located and video - recorded . All other procedures took place in separate rooms at individual workstations with no video recording . For 120 minutes of participation , subjects received $ 20 USD cash . Icebreaker activities Partners collaborated on three icebreaker activities for three minutes each . They built a tower with toy blocks , played the game Operation , and generated a list of animal names beginning with ‘M’ ( e . g . , monkey ) . Graphic design tool training At separate workstations , partners viewed a five - minute video about the Web - based graphic design tool [ 1 ] . Then , using the tool , participants replicated a graphic unrelated to the main task . All participants replicated the graphic in less than ten minutes . None had used the tool before . Selecting a novel tool avoids confounds from participant’s tool - specific expertise . Design brief A five - minute video described participants’ main design activity : to create an ad for FaceAIDS , a non - profit organization dedicated to global health equity and social justice [ 2 ] . In the video , the organization’s executive director outlined four goals : reach out to students interested in starting local chapters of FaceAIDS , increase traffic to the FaceAIDS Web site , impress three judges from the FaceAIDS organization , and create ads with effective graphic design . A paper version of the design brief was available for the group discussion ( see Appendix A ) . Individual Design Period All participants had 30 minutes for individual design . In the Share Multiple and Share Best conditions , participants started a fresh design every 10 minutes . At the end of this period , Share Best participants were prompted to select one design to be critiqued by the study partner . After the design period , a study proctor printed ads for the group discussion . 4 Group discussion Participants sat together and viewed a print out of their partner’s design ( s ) . The study proctor set a timer for five minutes and then instructed the pair : “Examine your peer’s design concept ( s ) and then provide a critique . What advice would you provide ? Please speak aloud . ” After this , the proctor set another five - minute timer and instructed : “Now spend another 5 minutes discussing what you think is the most effective way to satisfy the design brief . ” After that , participants were instructed to return to their individual workstations to create a final ad design . Final design period Participants individually created another advertisement and were instructed that this final ad would be rated by judges and hosted in a live ad campaign . Group interview The study concluded with an open - ended group interview . A study proctor used an interview guide and followed up with related questions . These questions provided guidance for the final interview ; the exact order and phrasing varied . ◊ Describe how you arrived at your final design . ◊ Explain the difference between your two final ads . ◊ How much did the group discussion affect what you did in your final ad design ? ◊ How did your peer’s critique affect your ad design ? ◊ To what extent were you able to reach agreement on the final design concept ? Dependent Measures Performance After the experiment , the final graphic ads were hosted on Google AdWords [ 3 ] for a 12 - day campaign . Design per - formance was determined through two objective measures : ◊ Click - through rates ( CTR ) : number of clicks divided by the number of impressions , and ◊ Google Analytics [ 4 ] on the target client Website : total time spent and number of pages visited from each ad . Ads were also independently judged by 30 individuals : three clients from FaceAIDS , six ad professionals , and twenty - one people recruited from Mechanical Turk , an online crowdsourcing system for paying workers for short tasks [ 5 ] . This collection of raters provided important—and different—audience perspectives . Each judge read the FaceAIDS design brief and viewed ads in random order . For each ad , they estimated ( on a 7 - point scale ) each ad’s performance in an online campaign ( see Figure 2 ) . Individual design exploration Exploring a diverse set of ideas can help people examine the space of designs and their relative merits [ 13 ] . To obtain a measure of idea diversity , ten independent raters assessed pair - wise similarity of all combinations of individual par - ticipant’s ads ( see Figure 3 ) . Raters recruited from Amazon Mechanical Turk assessed similarity on a scale from 1 to 7 ( not similar to very similar ) . Change in group rapport At two points—after the icebreakers and after the discus - sion—five questions asked individuals to assess their group rapport . The change between these two points measures the discussion’s impact on group rapport . Four questions origi - nate from the Subjective Value Inventory ( SVI ) , an assess - ment of viewpoints on negotiation [ 15 ] . The relationship questions from the SVI provide a systematic measure of a group rapport ; they assess partners’ feelings about the rela - tionship in terms of overall impressions , satisfaction , trust , and foundations for future interaction . The fifth question derives from the Inclusion of Self in Others Scale ( see Figure 4 ) , a measure of someone’s sense of connectedness with another [ 7 ] . The questions asked : ◊ What kind of overall impression did your peer make on you ? ◊ How satisfied are you with your relationship with your peer as a result of the interaction ? ◊ Did the interaction make you trust your peer ? ◊ Did the interaction build a foundation for future interac - tions with your peer ? ◊ Please check the picture below which best describes your relationship with your peer : Conversational turn taking In the group discussion , partners exchanged ideas . A coder recorded the start time and duration of each group mem - ber’s utterances . This provided the overall number of speech turns by each partner , the total amount of speaking , Figure 4 Inclusion of Self in Others Scale : Illustration reprinted from Aron et al . [ 7 ] Figure 2 Quality rating : Judges rated ( on a 1 - 7 scale ) how well each ad will perform in an online campaign . Figure 3 Similarity rating : Judges viewed a pair of ads and rated their similarity on a seven - point scale . This pair’s average rating was 5 . 7 . ( The overall average was 3 . 6 . ) 5 the ratio of time spent by the more conversationally - dominant partner ( high and low talkers ) , and the frequency of turns per minute of interaction . Design feature sharing For each final ad , we counted cross - pollinated features in five categories : word phrases , background color , images , layout , and styles ( i . e . , fonts , rotations , etc . ) . Cross - pollination was a binary value for each category . A cate - gory received a mark if a participant’s final ad exhibited a feature that was present in their partner’s shared provisional ad , but not in their own provisional ad ( s ) ( see Figure 5 ) . Group consensus As an aggregate measure of group consensus , independent raters assessed pair - wise similarity between partner ads . The similarity assessment contrasted ads created before and after the discussion . Ten raters recruited from Mechanical Turk assessed similarity on a scale from 1 to 7 ( not similar to very similar ) ( see Figure 3 ) . If the designs are more simi - lar after the discussion , it suggests that partners converge around similar concepts . RESULTS Participants created a wide variety of ad designs , demon - strating a range of quality . The highest - rated ads tended to be original , visually appealing , and cleverly touched on themes relevant to FaceAIDS ( see Figure 6 , left ) . The high - est rated ads did not always garner the highest click - through rates ( see Figure 6 , right ) ; they used images that reflected the client’s brand , but exhibit poorer graphic design . FaceAIDS reviewed the ads before they appeared online . The client found four of the ads to have inappropriate nega - tive imagery , and requested they not be shown . Three of these were from Share Best ; one was from Share Multiple . In total , the ad campaign generated 239 clicks on 274 , 539 impressions ( ad appearances ) . The total advertising costs were $ 362 USD ( an average of $ 1 . 51 per click ) . Participants in the Share Multiple condition produced higher - quality designs ( better click - through rates and higher subjective ratings ) and created more diverse designs . Pairs of participants in the Share Multiple condition reported a greater increase in rapport , exchanged more verbal informa - tion , and shared more ideas . Moreover , ads by more experi - enced participants received higher rating than novices ; the prototypes created by experienced participants were less diverse than novices . Sharing multiple led to higher quality designs Ad campaign results A chi - squared analysis examined ad campaign performance for all 12 days . Share Multiple ads had 98 , 867 impressions with 106 clicks , Share Best ads had 77 , 558 impressions with 57 clicks , and Share One ads had 98 , 038 impressions with 76 clicks ( Figure 1 summarizes the average clicks per million impressions ) . Share Multiple ads had a significantly higher click - through rate ( χ 2 = 4 . 72 , p < 0 . 05 ) . An analysis of variances was performed with condition ( Share Multiple , Share Best , and Share One ) and graphic design score ( experienced or novice ) as factors and total time spent and pages visited as dependent variables . Be - tween conditions , there were no differences for total time spent ( F ( 5 , 202 ) = 0 . 808 , p > 0 . 05 ) or number of pages visited from each ad ( F ( 5 , 202 ) = 0 . 461 , p > 0 . 05 ) . Graphic design experience did not effect campaign results Ads created by participants who scored high on the graphic design exam garnered 110 clicks on 128 , 783 impressions ; novice ads had 129 clicks on 145 , 756 impressions . This was not a significant difference ( χ 2 = 0 . 08 , p > 0 . 05 ) . Experi - enced participants benefited more from the manipulation than novices did ( see Table 1 ) . Experienced participants in the Share Multiple condition outperformed experienced participants in the Share Best ( χ 2 = 3 . 95 , p < 0 . 05 ) and Share One conditions ( χ 2 = 8 . 33 , p < 0 . 05 ) . There were no ad per - formance differences between conditions for novices . Figure 5 Design feature sharing : The two partner ads above have three commonalities : images , phrasing , and background color Figure 6 Top five highest - rated ads ( left ) ; ads with top five click - through rates ( right ) 6 An ANOVA showed that experience did not significantly affect total time spent ( F ( 5 , 202 ) = 0 . 091 , p > 0 . 05 ) or number of pages visited from each ad ( F ( 5 , 202 ) = 0 . 076 , p > 0 . 05 ) . Quality ratings Thirty raters judged all final ads ; their average rating was 3 . 74 on a 7 - point scale . An analysis of variances was per - formed with condition ( Share Multiple , Share Best , and Share One ) and graphic design score ( experienced or nov - ice ) as factors and performance rating as the dependent variable . The Share Multiple condition ( µ = 3 . 89 , SD = 1 . 82 ) outperformed the other conditions ( F ( 2 , 2519 ) = 5 . 075 , p < 0 . 05 ) . The difference between the Share Best ( µ = 3 . 63 , SD = 1 . 78 ) and Share One ( µ = 3 . 71 , SD = 1 . 71 ) conditions was not significant ( t ( 1678 ) = 0 . 983 , p > 0 . 05 ) . Professionals , clients , and turkers ( workers on Amazon Mechanical Turk ) all rated Share Multiple ads higher than the other conditions ( see Table 2 ) . Clients ( µ = 3 . 77 , SD = 1 . 73 ) and turkers ( µ = 3 . 99 , SD = 1 . 74 ) ratings were higher on average than those by ad professionals ( µ = 2 . 85 , SD = 1 . 60 ) ( F ( 2 , 2519 ) = 86 . 961 , p < 0 . 05 ) . This differential between advertising professionals and other stakeholders is consistent with prior work [ 18 ] . Graphic design experience led to better ratings Participants who scored highly on the graphic design exam ( µ = 4 . 10 , SD = 1 . 709 ) significantly outperformed those who scored poorly ( µ = 3 . 48 , SD = 1 . 773 ) , ( F ( 1 , 2519 ) = 74 . 613 , p < 0 . 05 ) . The ANOVA shows that novices benefited more from the manipulation than experienced participants did ( F ( 2 , 2519 ) = 3 . 536 , p < 0 . 05 ) ( see Table 3 ) . This differential gain is the opposite from the click - through rate , where experienced participants benefited more from sharing mul - tiple designs . Sharing multiple led to more individual exploration Raters from Amazon Mechanical Turk deemed Share Mul - tiple ads to be most divergent . An analysis of variances was performed with condition ( Share Multiple , Share Best , and Share One ) and graphic design score ( experienced or nov - ice ) as factors and pair - wise similarity rating as the depend - ent variable . Share Best ( µ = 3 . 99 , SD = 1 . 96 ) and Share One ( µ = 5 . 45 , SD = 1 . 86 ) ads were deemed significantly more similar than Share Multiple ads ( µ = 3 . 85 , SD = 1 . 93 ) ( F ( 2 , 3640 ) = 82 . 07 , p < 0 . 05 ) . T - tests confirmed that Share Multiple ads were more diverse than Share Best ads ( t ( 3358 ) = 2 . 077 , p < 0 . 05 ) , and Share Best ads were more diverse than Share One ads ( t ( 1958 ) = 11 . 66 , p < 0 . 05 ) . Experienced participants created ads that were deemed significantly more similar ( µ = 4 . 20 , SD = 1 . 96 ) than those who scored poorly ( µ = 3 . 91 , SD = 1 . 99 ) ( F ( 1 , 3640 ) = 7 . 692 , p < 0 . 05 ) . There was no interaction effect between condition and prior experience . Group rapport rose for partners who shared multiple Group rapport increased in the Share Multiple condition ( µ = 0 . 89 , SD 3 . 06 ) compared to the other conditions ( F ( 2 , 83 ) = 4 . 147 , p < 0 . 05 ) . It was the only condition where participants rated rapport after the discussion higher than before ( see Table 4 ) . Overall , group rapport dropped from an average of 24 . 5 to 23 . 5 ( t ( 83 ) = 2 . 050 , p < 0 . 05 ) . Pair - wise t - tests confirmed significant differences between the Share Multiple condition and the Share Best ( t ( 54 ) = 2 . 816 , p < 0 . 05 ) and Share One conditions ( t ( 54 ) = 2 . 539 , p < 0 . 05 ) . Share Multiple partners took more conversational turns An video analysis of speech duration during the group discussion showed that participants in the Share Multiple condition had significantly more frequent verbal exchanges ( a higher number of speaker turns per minute of speaking time ) than other conditions ( F ( 2 , 39 ) = 3 . 506 , p < 0 . 05 ) . Share Multiple pairs averaged 12 . 1 ( SD = 4 . 99 ) turns per minute , compared to 9 . 1 ( SD = 2 . 62 ) and 8 . 6 ( SD = 2 . 86 ) turns per minute , for Share Best and Share One , respectively . There were no significant between - condition differences for total number of speaker turns ( F ( 2 , 39 ) = 0 . 695 , p > 0 . 05 ) , total speaking time ( F ( 2 , 39 ) = 1 . 057 , p < 0 . 05 ) , or the ratio of high and low talkers ( F ( 2 , 39 ) = 0 . 092 , p < 0 . 05 ) . Share Multiple pairs borrowed more features In total , Share Multiple partners borrowed 32 features , Share Best 18 , and Share One 19 ( see Table 5 ) . ( The theo - retical maximum for each condition is 140 : 28 participants , 5 categories . ) Participants in the Share Multiple condition borrowed significantly more features overall ( χ 2 = 4 . 05 , p < 0 . 05 ) . Experienced Novice Share Multiple 1125 . 3 ( 818 . 0 ) 991 . 7 ( 482 . 2 ) Share Best 704 . 3 ( 422 . 2 ) 758 . 9 ( 888 . 5 ) Share One 540 . 3 ( 500 . 0 ) 905 . 5 ( 371 . 7 ) Table 1 Online performance in clicks per million impressions for condition and experience ( std dev in parentheses ) . Experienced participants created better ads and were more affected by condition . Clients Ad pros Turkers Share Multiple 4 . 06 ( 1 . 70 ) 2 . 95 ( 1 . 63 ) 4 . 14 ( 1 . 80 ) Share Best 3 . 45 ( 1 . 77 ) 2 . 76 ( 1 . 63 ) 3 . 90 ( 1 . 74 ) Share One 3 . 79 ( 1 . 69 ) 2 . 85 ( 1 . 55 ) 3 . 94 ( 1 . 68 ) Table 2 Average ratings ( std dev in parentheses ) . All rater types ( clients , ad pros , and turkers ) rated Share Multiple ads higher . Experienced Novice Share Multiple 4 . 11 ( 1 . 71 ) 3 . 68 ( 1 . 90 ) Share Best 4 . 19 ( 1 . 71 ) 3 . 31 ( 1 . 74 ) Share One 4 . 01 ( 1 . 71 ) 3 . 48 ( 1 . 67 ) Table 3 Average ratings by condition and experience ( std dev in parentheses ) . Experienced created higher - rated ads ; novices were more affected by condition . Before design critique After design critique Group rapport shift Share Multiple µ = 24 . 6 ( 4 . 35 ) µ = 25 . 5 ( 4 . 66 ) + 0 . 89 Share Best µ = 24 . 0 ( 5 . 24 ) µ = 22 . 3 ( 4 . 79 ) - 1 . 75 Share One µ = 24 . 9 ( 5 . 18 ) µ = 22 . 8 ( 5 . 86 ) - 2 . 11 Table 4 Individual views of group rapport rose in the Share Multiple condition ; it dropped in other conditions ( std dev in parentheses ) 11 7 Share Multiple pairs reached a better consensus Independent judges rated the partner ad similarity before and after the discussion . The similarity change provides a measure of shared perspective . Overall , final ads were more similar ( µ = 3 . 40 , SD = 1 . 91 ) than initial ads ( µ = 2 . 68 , SD = 1 . 64 ) ( t ( 3078 ) = 8 . 107 , p < 0 . 05 ) . Similarity increased more for the Share Multiple condition ( 0 . 91 ) than the Share Best ( 0 . 55 ) or Share One conditions ( 0 . 52 ) ( see Table 6 ) . DISCUSSION The results supported all hypotheses . Sharing multiple designs led to several kinds of better outcomes . Simply creating multiple prototypes was not sufficient . Both the Share Best and Share Multiple participants created several alternative designs . The benefits were only realized if par - ticipants shared multiple designs . It’s important to remem - ber that participants worked on the same task for the same amount of time . The only variable was how many proto - types they created and shared . Why did this simple act affect performance ? This section outlines several reasons for the differential outcomes , illustrating these with inter - view excerpts . Does producing and sharing multiple designs impact how people individually explore the conceptual landscape ? The Share Multiple and Share Best conditions explored signifi - cantly more broadly than the Share One condition . As this study and prior work found [ 18 ] , rapidly producing alterna - tives—as opposed to refining one idea—results in more variance . Creative work often benefits from broadly explor - ing possibilities before choosing a direction to refine [ 13 ] . Options must first be on the table to be consciously chosen . By forcing individuals to embody more ideas , both the Share Multiple and the Share Best strategies support diver - gent individual exploration . Share Multiple goes further by exposing more perspectives . As one Share Multiple partici - pant described seeing her partner’s designs : “they were completely different from mine and I was like holy hell , that’s pretty good . I didn’t think about that . ” Another par - ticipant claimed that “getting a different perspec - tive…helped and also seeing different ideas - not flaws in mine , but different ideas in his that I’d like to borrow . ” Discussing multiple designs encouraged the construction of conceptual structures to compare and contrast within and across participants . The study found that experienced participants created less diverse designs than novices ; their ads were also rated higher . As Schön describes , expert designers can rapidly construct entailments , mentally simulating design “moves” and their consequences [ 44 ] . Experienced designers ignore or disregard the obviously bad options . This foresight al - lows experts to sample a narrower , yet more promising part of the conceptual landscape . Does sharing multiple prototypes improve design collabo - ration ? Across all conditions , participants reported an over - all decline in group rapport from before to after the discus - sion . This is not surprising given the sensitive nature of critique . As one Share Best participant admitted , “she didn ' t make me feel terrible about what I produced . . . even though I . . . I , … she didn ' t make me feel like a total failure . ” Having only selected her “best” prototype , this individual’s sense of risk may have disrupted group interaction . The notion of taking personally a partner’s critique appears obviated to some extent when participants distribute effort across mul - tiple designs . Reports of group rapport actually increased when participants shared multiple designs . Similarly , stud - ies of group design show that when teams generate lots of ideas , people feel more shared ownership and stronger team cohesiveness [ 25 , 50 ] . Pairs in the Share Multiple condition had significantly more frequent verbal exchanges than the other conditions . As one Share Multiple participants said , “being able to see the other person ' s designs and actually bounce ideas back and forth… that helped clarify what was good design and what wasn ' t . " More frequent exchanges enabled participants to delve into design tradeoffs and the context for advertising , as one participant said , “it got me thinking about who would click on an ad and why someone would click on an ad . ” Such statements illustrate some partners’ willingness to discuss more fundamental changes to their solutions . Does sharing multiple prototypes increase conceptual blending ? Compared to conditions where participants shared only one ad design , participants in the Share Multi - ple condition integrated more features and modified their designs to be more like their partner’s . Participants often talked about the process of merging designs . One Share Multiple participant said , “we agreed we like elements of mine and I really like some elements of one of his and we just kind of did a mash - up and combined them . ” In contrast , a Share Best participant said , “we thought about some ideas , but we didn ' t really get to a consensus of what we were going to design . ” Likewise , a Share One participant said , “I didn ' t really get a lot of things to change on mine , so I just stuck with what I had . ” This notion of “sticking” with an idea did not surface in the Share Multiple condition . Share Multiple Share Best Share One Word phrases 15 9 6 Background color 3 0 2 Images 10 6 7 Layout 3 2 3 Surface patterns 1 1 1 Total 32 18 19 Table 5 Participants in the Share Multiple condition borrowed more features from their partners than other conditions Before design critique After design critique Similarity shift Share Multiple 2 . 59 ( 1 . 55 ) 3 . 50 ( 1 . 91 ) 0 . 91 Share Best 2 . 75 ( 1 . 71 ) 3 . 30 ( 1 . 97 ) 0 . 55 Share One 2 . 87 ( 1 . 81 ) 3 . 39 ( 1 . 85 ) 0 . 52 Table 6 Pairs designs in the Share Multiple condition increased in similarity more than other conditions ( st . dev . in parentheses ) 8 Direct comparison can help people understand underlying principles [ 24 ] . Since Share Multiple participants viewed several of their partners’ designs , they could utilize com - parison processes to see deeper patterns . One participant in the Share Multiple condition saw beyond surface - level similarities , and said “ ( our ) ads look different , but I feel like in general it ' s the same message that ' s getting across . ” This pair claimed to be connecting their ideas on a more thematic level . Forming a stronger understanding of their partner’s design rationale may be one reason participants came closer to consensus and produced better results . Reflections on Method The advertising paradigm described in this paper helps provide experimenters leverage when studying creative work . It offers strong quantitative benchmarks through its Web analytics , captures the views of many stakeholders , and provides measures of several different types of out - comes . While using an advertising platform to measure analytics has clear benefits in terms of ecological validity , the goals of an ad platform can sometimes be in conflict with scientific goals . For others interested in this approach , we share three challenges . First , many advertisers show ads differentially . If an ad ( or cohort of ads ) performs well , it is shown more . If initial performance is poor , it is shown less . Experimenters must take care to insure that all ads are shown sufficiently , and that interactions between impressions and click - through rate are minimized . There’s a reason that some people make a living managing online ad campaigns . Second , at first blush , it can appear that advertising pipe - lines have an unlimited capacity for showing ads , and con - sequently scale effortlessly . This is not the case . ( Except , perhaps , for Justin Bieber . ) Even with a major client and the world’s largest advertising network , eighty ads pushes the limits of how many alternate ads can be simultaneously shown . Showing more ads would prevent each one from receiving enough impressions for statistical analysis . Even in the age of the Web , experimenters must be judicious . Third , with many measures , which one is “right” ? Raters assess aesthetic quality ; clicks assess bottom line . ( At least in the short term . ) In our study , online click performance did not correlate with overall rating ( R 2 = 0 . 018 , F ( 1 , 79 ) = 2 . 445 , p > 0 . 05 , b = 0 . 174 ) . Some unattractive ads receive many clicks ; the Web has a preponderance of such exam - ples . Do clicks or positive reviews by different stakeholders define the success of an advertisement ? As in brainstorm - ing , design has several objective functions [ 50 ] . CONCLUSIONS AND FUTURE WORK This paper found that when people produce and share mul - tiple alternatives at group discussions , they explore more diverse ideas , integrate more of their partner’s features , engage in more productive design conversations , and ulti - mately , create higher - quality work . Many designers already practice this approach . This research seeks to develop a theoretical understanding of creative work to help practitio - ners and students solve design problems more effectively . These results suggest that many more practitioners and teachers might beneficially adopt a “share multiple” strat - egy . More broadly , this work raises several important ques - tions . First , ( how ) do these results generalize to different types of groups ? In this study , participants were independently re - cruited , with no prior collaboration , and had comparable authority . In most professional work , collaboration is longi - tudinal , and power relationships and social dynamics are more complex . Second , how might groups be alternatively structured ? For example , what if dyads performed complementary tasks rather than equivalent ones ? Such work could explore strategies for cross - functional teams . One example of a cross - functional strategy is jigsaw learning , where different students are responsible for complementary parts of a topic [ 8 ] . Jigsaw learning has been found to increase learning outcomes , especially in heterogeneous classrooms . Third , recent research on “the crowd within” suggests that at least some of the benefits of aggregating many people’s work can be accomplished by providing individuals with a structured approach to considering alternatives [ 54 ] . This study witnessed several benefits of group discussion ; can some of these be achieved through structured reflection ? Fourth , this study’s three conditions were : create one and share one , create three and share one , create three and share three . This leaves an unexplored cell : create one design and share three designs . How might designers share multiple ideas without creating them ? One strategy would be to have designers supplement their own creations with previously created examples . An alternative would be for software to ( semi - ) automatically synthesize design alternatives [ 27 , 34 ] . Fifth , the benefits of rapidly creating and sharing multiple alternatives are myriad . How might software tools help designers work explore more broadly ? Initial results are promising [ 27 , 34 ] ; more exciting work remains . REFERENCES 1 . Web graphic editing tool . http : / / www . flashimageeditor . com . 2 . FaceAIDS Organization . http : / / faceaids . org . 3 . Google Ad Words . https : / / adwords . google . com . 4 . Google Analytics . http : / / www . google . com / analytics . 5 . Amazon Mechanical Turk . https : / / www . mturk . com / mturk . 6 . Arkes , H . R . and Blumer , C . The psychology of sunk cost . Organizational Behavior and Human Decision Processes 35 , 1 ( 1985 ) , 124 - 140 . 7 . Aron , A . , Aron , E . N . , and Smollan , D . Inclusion of Other in the Self Scale and the Structure of Interpersonal Close - ness . Journal of Personality and Social Psychology 63 , 4 ( 1992 ) , 596 - 612 . 8 . Aronson , E . , Bridgeman , D . , and Geffner , R . Interde - pendent Interactions and Prosocial Behavior . Journal of Research and Development in Education 12 , 1 ( 1978 ) , 9 16 - 27 . 9 . Ball , L . J . and Ormerod , T . C . Structured and opportunistic processing in design : a critical discussion . International Journal Human - Computer Studies 43 , 1 ( 1995 ) , 131 - 151 . 10 . Bao , P . , Gerber , E . , Gergle , D . , and Hoffman , D . Momen - tum : getting and staying on topic during a brainstorm . Proc of conf on Human factors in computing systems , ACM ( 2010 ) , 1233 - 1236 . 11 . Brandt , J . , Dontcheva , M . , Weskamp , M . , and Klemmer , S . R . Example - centric programming : integrating web search into the development environment . Proc of conf on Human factors in computing systems , ACM ( 2010 ) , 513 - 522 . 12 . Brereton , M . , Cannon , M . , Mabogunje , A . , and Leifer , L . Collaboration in Design Teams : How Social Interaction Shapes the Product . In Analyzing Design Activity . Wiley , 1996 . 13 . Buxton , B . Sketching User Experiences : Getting the Design Right and the Right Design . Morgan Kaufmann , 2007 . 14 . Cross , N . Expertise in design : an overview . Design Stud - ies 25 , 5 ( 2004 ) , 427 - 441 . 15 . Curhan , J . R . , Elfenbein , H . A . , and Xu , H . What Do Peo - ple Value When They Negotiate ? Mapping the Domain of Subjective Value in Negotiation . Journal of Personality and Social Psychology 91 , 3 ( 2006 ) , 493 - 512 . 16 . Dannels , D . P . and Martin , K . N . Critiquing Critiques : A Genre Analysis of Feedback Across Novice to Expert De - sign Studios . Journal of Business and Technical Commu - nication 22 , 2 ( 2008 ) , 135 - 159 . 17 . Diehl , M . and Stroebe , W . Productivity Loss In Brain - storming Groups : Toward the Solution of a Riddle . Jour - nal of Personality and Social Psychology 53 , 3 ( 1987 ) , 497 - 509 . 18 . Dow , S . , Glassco , A . , Kass , J . , Schwarz , M . , Schwartz , D . L . , and Klemmer , S . R . Parallel Prototyping Leads to Better Design Results , More Divergence , and Increased Self - Efficacy . Transactions on Computer - Human Interac - tion 4 , ( 2010 ) . 19 . Dweck , C . Mindset : The New Psychology of Success . Ballantine Books , 2007 . 20 . Fauconnier , G . and Turner , M . The Way We Think : Con - ceptual Blending and the Mind ' s Hidden Complexities . Basic Books , 2003 . 21 . Felps , W . , Mitchell , T . , and Byington , E . How , When , and Why Bad Apples Spoil the Barrel : Negative Group Members and Dysfunctional Groups . Research in Orga - nizational Behavior 27 , ( 2006 ) , 175 - 222 . 22 . Finke , R . A . , Ward , T . B . , and Smith , S . M . Creative Cog - nition : Theory , Research , and Applications . The MIT Press , 1996 . 23 . Gaver , W . W . , Beaver , J . , and Benford , S . Ambiguity as a resource for design . Proceedings of the SIGCHI confer - ence on Human factors in computing systems , ACM ( 2003 ) , 233 - 240 . 24 . Gentner , D . , Loewenstein , J . , and Thompson , L . Learning and transfer : A general role for analogical encoding . Journal of Educational Psychology 95 , ( 2003 ) , 408 , 393 . 25 . Gerber , E . Prototyping Practice in Context : The Psycho - logical Experience in a High Tech Firm . Journal of De - sign Studies , ( 2010 ) . 26 . Hampton , J . A . Inheritance of attributes in natural concept conjunctions . Memory & Cognition 15 , 1 ( 1987 ) , 55 - 71 . 27 . Hartmann , B . , Yu , L . , Allison , A . , Yang , Y . , and Klemmer , S . R . Design as exploration : creating interface alternatives through parallel authoring and runtime tun - ing . Proc of the conf on User interface software and tech - nology , ACM ( 2008 ) , 91 - 100 . 28 . Hyland , F . and Hyland , K . Sugaring the pill : Praise and criticism in written feedback . Journal of Second Lan - guage Writing 10 , 3 ( 2001 ) , 185 - 212 . 29 . Iyengar , S . S . and Lepper , M . R . When choice is demoti - vating : can one desire too much of a good thing ? Journal of Personality and Social Psychology 79 , 6 ( 2000 ) , 995 - 1006 . 30 . Janis , I . L . Groupthink : Psychological Studies of Policy Decisions and Fiascoes . Wadsworth Publishing , 1982 . 31 . Jansson , D . and Smith , S . Design Fixation . Design Stud - ies 12 , 1 ( 1991 ) , 3 - 11 . 32 . Kershaw , T . C . and Ohlsson , S . Multiple causes of diffi - culty in insight : the case of the nine - dot problem . Journal of Experimental Psychology . Learning , Memory , and Cognition 30 , 1 ( 2004 ) , 3 - 13 . 33 . Kosara , R . Visualization Criticism - The Missing Link Between Information Visualization and Art . Proc of the Conf on Information Visualization , IEEE Computer Soci - ety ( 2007 ) , 631 - 636 . 34 . Lee , B . , Srivastava , S . , Kumar , R . , Brafman , R . , and Klemmer , S . R . Designing with interactive example gal - leries . Proc of the conf on Human factors in computing systems , ACM ( 2010 ) , 2257 - 2266 . 35 . Leifer , L . Dancing with Ambiguity : design thinking in theory and practice . 2010 . 36 . Mark , G . , Gonzalez , V . M . , and Harris , J . No task left behind ? : examining the nature of fragmented work . Proc of the conf on Human factors in computing systems , ( 2005 ) , 321 - 330 . 37 . Marsh , R . L . , Landau , J . D . , and Hicks , J . L . How examples may ( and may not ) constrain creativity . Memory & Cog - nition 24 , 5 ( 1996 ) , 669 - 680 . 38 . Moran , T . P . and Carroll , J . M . Design Rationale : Con - cepts , Techniques , and Use . CRC Press , 1996 . 39 . Nickerson , R . S . Confirmation Bias : A Ubiquitous Phe - nomenon in Many Guises . Review of General Psychology 2 , ( 1998 ) , 175 - - 220 . 40 . Pentland , A . Learning Communities — Understanding Information Flow in Human Networks . BT Technology Journal 22 , 4 ( 2004 ) , 62 - 70 . 41 . Ranganath , R . , Jurafsky , D . , and McFarland , D . It ' s not 10 you , it ' s me : detecting flirting and its misperception in speed - dates . Proc of Conf on Empirical Methods in Natu - ral Language Processing , Association for Computational Linguistics ( 2009 ) , 334 - 342 . 42 . S . Smith , T . B . Ward , and J . S . Schumacher . Constraining effects of examples in a creative generation task . Memory & Cognition 21 , ( 1993 ) , 837 - 845 . 43 . Schon , D . A . Educating the Reflective Practitioner : To - ward a New Design for Teaching and Learning in the Professions . Jossey - Bass , 1990 . 44 . Schon , D . A . The Reflective Practitioner : How Profes - sionals Think in Action . Ashgate Publishing , 1995 . 45 . Schrage , M . Serious Play : How the World ' s Best Compa - nies Simulate to Innovate . Harvard Business School Press , 1999 . 46 . Schwartz , B . The Paradox of Choice : Why More Is Less . Ecco , 2004 . 47 . Schwartz , D . L . The Emergence of Abstract Representa - tions in Dyad Problem Solving . Journal of the Learning Sciences 4 , 3 ( 1995 ) , 321 . 48 . Stroebe , W . and Diehl , M . Why Groups are less Effective than their Members : On Productivity Losses in Idea - generating Groups . European Review of Social Psychol - ogy 5 , ( 1994 ) , 271 . 49 . Sutton , R . Eight Tips for Better Brainstorming . Busi - nessWeek : Innovation , 2006 . 50 . Sutton , R . and Hargadon , A . Brainstorming groups in context : effectiveness in a product design firm . Adminis - trative Science Quarterly , ( 1996 ) . 51 . Taylor , D . , Berry , P . , and Block , C . Does Group Partici - pation When Using Brainstorming Facilitate or Inhibit Creative Thinking ? Administrative Science Quarterly 3 , 1 ( 1958 ) , 23 - 47 . 52 . Thomke , S . and Nimgade , A . IDEO Product Develop - ment . Harvard Business School Case , ( 2000 ) . 53 . Tohidi , M . , Buxton , W . , Baecker , R . , and Sellen , A . Get - ting the right design and the design right . Proceedings of the SIGCHI conference on Human Factors in computing systems , ACM ( 2006 ) , 1243 - 1252 . 54 . Vul , E . and Pashler , H . Measuring the crowd within : probabilistic representations within individuals . PSY - CHOLOGICAL SCIENCE , ( 2008 ) , 645 - - 647 . 55 . Warr , A . and O ' Neill , E . Understanding design as a social creative process . Proc of the conf on Creativity & Cogni - tion , ACM ( 2005 ) , 118 - 127 . 56 . Wisniewski , E . and Gentner , D . On the combinatorial semantics of noun pairs : { Minor } and major adjustments to meaning . In Understanding word and sentence . Am - sterdam : North Holland , 1991 , 241 - 284 . 57 . Zwicky , F . Discovery , Invention , Research Through the Morphological Approach . MACMILLAN , 1969 . APPENDIX A : Graphic Design Assessment APPENDIX B : Advertising Design Brief Assignment You have been hired to design a graphic advertisement for FACEAIDS . org . You will learn to use a new graphic design tool , design provisional ads , and create a final ad to be posted through the Google ad network . Goals Keep in mind the following goals as you create your ads : a ) Increase traffic to the FaceAIDS website : http : / / www . faceaids . org / b ) Reach out to the target audience : students interested in im - proving global healthcare equality and making a difference in the AIDS epidemic in Africa . c ) Impress the clients from FaceAIDS , who will rate your ads . The client wants an ad that fits their overall aesthetic and theme ( see below ) . d ) Create ads with effective graphic design . Ad professionals will rate your ads . What is FaceAIDS ? FaceAIDS is a nonprofit organization dedicated to mobilizing and inspiring students to fight AIDS in Africa . FaceAIDS aims to build a broad - based movement of students seeking to increase global health equality . The organization raises awareness and funds , with the goal of increasing global health equality starting with the AIDS epidemic in Africa . Theme and Aesthetic for the FaceAids Ad FaceAIDS would like an advertisement that embodies the theme and general aesthetic of the organization . In particular , they are looking to encourage high school and college students interested in getting involved in service or social justice work to start FaceAIDS chapters on their campuses , as a leadership development opportu - nity and a way to join a vibrant , impactful community of like - minded , driven peers . In general they are looking for an ad that is tasteful , creative , professional , visually appealing , and conveys a clear message about the organization . Rules / Requirements -­‐ You may download and use graphics , images , text etc . as you see fit . -­‐ You may not use another company’s logo , copyrighted im - ages , profanity , obscenity or nudity . Unacceptable ads will be rejected by the research team . -­‐ Do not include the magazine’s URL on the ad . Clicking the ad will direct the user to the site . Instructions : For each of the statements below , indicate ( True or False ) whether or not the statement is a rule of graphic design . 1 Mix serif and sans serif fonts in order to give variety to the ad . F 2 To help balance the ad , leave slightly more space at the top relative to the bottom of the ad . F 3 Create a visual separation between the text and the background . T 4 Angle the text in order to contrast different parts of the ad . F 5 Keep all elements in the ad aligned to one side . F 6 Create multiple visual focal points in order to attract attention to the ad as a whole . F 7 Use borders or white around text and images to help frame the content . T 8 You may use repetition to create a consistent and bal - anced look . T 9 You may break alignment to draw the viewer’s attention to important elements in the ad . T 10 Draw the viewer’s attention to important elements by contrasting scale . T