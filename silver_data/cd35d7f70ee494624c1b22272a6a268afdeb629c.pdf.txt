Designing for Collaborative Sensemaking : Using Expert & Non - Expert Crowds Nitesh Goyal Information Science , Cornell University ngoyal @ cs . cornell . edu Abstract Crime solving is a domain where solution discovery is often serendipitous . Unstructured mechanisms , like Reddit , for crime solving through crowds have failed so far . Mecha - nisms , collaborations , workflows , and micro - tasks necessary for successful crime solving might also vary across different crimes . Cognitively , while experts might have deeper do - main knowledge , they might also fall prey to biased analy - sis . Non - experts , while lacking formal training , might in - stead offer non - conventional perspectives requiring direc - tion . The analytical process is itself an iterative process of foraging and sensemaking . Users would explore to broaden solution space and narrow down to a solution iteratively un - til identifying the global maxima instead of local maxima . In this proposal , my research aims to design systems for en - abling complex sensemaking tasks that require collaboration between remotely located non - expert crowds with expert crowds to compensate for their cognitive challenges and lack of training . This would require better understanding of the structure , workflow , and micro - tasks necessary for suc - cessful collaborations . This proposal builds upon previous work on collaborative sensemaking between remote partners in lab experiments and endeavors to scale it across multiple team members , with varying expertise levels . Keywords sensemaking , collaborative sensemaking , ex - pert crowdsourcing Motivation While sensemaking has been studied in the past , designing interfaces for relatively complex sensemaking where ex - perts and non - experts may collaborate remains a challenge . Further , if we could leverage human cognition for collabo - rative sensemaking , crowds may help us better solve un - structured problems where traditional computational tech - niques have failed . In particular , researching how to design for experts and non - experts in the crime - solving domain , where solutions are often found through serendipity instead of rules , might offer us insights into how to best utilize crowd expertise , and leverage it to solve otherwise hard problems . Background and Related Work Crowdsourcing for somewhat complex tasks has been pur - sued in the past . Collaborative document editing in Soy lent ( Bernstein et al . 2010 ) , creating taxonomy of colors in Cascade ( Chilton et al . 2013 ) , suggesting a travel itinerary under constraints using Mobi ( Zhang et al , 2012 ) , and min - ing sentiments by crowds for text analytics in Opin - ionBlocks ( Hu et al , 2013 ) are some recent forays where crowdsourcing has shown to be performant and / or effi - cient . However , more open - ended domains like crime solv - ing , requiring serendipitous discovery of clues and crimi - nals , have yet to be crowd - sourced successfully . As number of workers and associated workflows grow in complexity , crowdsourcing can be challenging ( Bern - stein 2010 ) . Crowdsourcing for complex workflows has been pursued also . For example , CrowdForge explains how map - reduce framework popularized by Google may be used to partition bigger complex tasks into smaller tasks dynamically by workers ( Kittur et al , . 2005 ) . Further , Malone et al â€˜s aggregation dimension suggests that crowd - workers can either work alone independently or depend upon each other to work together ( Malone et al , 2005 ) ] . TurKit can further help decide what to present to each worker such that the flow of results of tasks between de - pendent workers can be controlled ( Little et al 2010 ) . As such crowd - workflows become complex , researchers must identify the level of crowd - supervision needed for optimal output . Turkomatic was designed based on price - divide - loop such that real time visualization of the work - flow - design is evident because unsupervised crowds failed to produce proper workflows resulting in a less than opti - mal output ( Kulkarni et al 2012 ) . On the other hand , super - vised crowds in a conversational - agent , Chorus ( Lasecki et al . 2013 ) , made users believe that a single user exist behind Chorus . Instead , Chorus employs multiple crowd workers who collectively create response possibilities , such that Crowd workers can learn and remember collectively . Alternatively , Kulkarni shows a computational method of identifying Experts in a crowd who subsequently utilize non - Experts to perform the tasks , in Wish ( Kulkarni , et al 2014 ) . Other researchers have pursued task - routing based on expertise level ( Bragg et al . 2014 ) . To summarize , while relatively complex tasks and workflows using crowds have been attempted , we have yet been unable to design a sys - tem that may structure non - experts ( lesser trained crowds ) and experts ( trained workers ) together in an interface to solve complex challenges like crime solving . Proposed Research The core aim of this research is to pursue a user centered design approach to designing a web - interface and an un - derlying system that may enable collaborations between experts and non - experts , and within non - experts . I hypoth - esize that such an interface for solving carefully broken down micro - tasks would help leverage distributed human cognition to solve complex tasks like crimes . To pursue this research , at least the following two important research questions need to be pursued : Research Questions First , understanding how to break up the task and data ( materials ) is important to imitate a realistic crime - solving scenario . This a wide landscape , where in one direction , one may consider sharing the entire dataset with the crowds and then enable the crowds to deduce the parti - tion mechanism for the dataset and create associated work - flows . However , this requires expertise . On the other hand , an expert might already partition the dataset into smaller datasets that are visible uniquely to each crowd worker . However , this prevents crowds from directly finding global maxima , since the broader overview is not visible to the workers . Perhaps , the solution is somewhere in between the two extremes and this knowledge will help find answer to the next question . Second , identifying the workflow for user collabora - tions to enable the best solution discovery is important to overcome biased knowledge generation . Should the users perform solo work initially , and then collaborate on the fruits of solo labor ? Or vice versa ? Or , a combination hitherto . It is unclear how to enable collaboration for a fuller attention spread across all the possible solutions ? Does this process remain static , or should the system com - putationally identify opportune moments to suggest collab - orations based on the user performance ? It is yet unclear , the role of algorithmic aids , and collaboration with crowds to best promote unbiased solution discovery . Further , online collaborations between crowd members require op - erational stability in case of drop - offs , or inactivity . Planned Methodology I plan to integrate my findings based on a mixed - methods study . First , I will understand how trained - non - experts ( trained students , through video and usage - log analysis ) solve complex problems singularly and collabora - tively . Consequently , I will extract important features that result in success and failure in problem solving . Based on these features , I propose to create a web - interface for col - laborative problem solving . Finally , I will design a study to validate whether the identified features ( reflected as exper - tise ) lead to success or failure with non - expert crowds , and a mix of expert + non - expert crowds ? So , based on the iterative nature of design process , my proposed solution would involve multiple iterations and steps before I design the final interface : Step 1 . Understand role of currently used features for solo sensemaking . Step 2 . Explore effects of information - sharing collabora - tive sensemaking . Step 3 . Extract features to identify micro - tasks , and work - flows for success . Step 4 . Design web - interface for experts and non - experts to collaborate . Step 5 . Design a set of user - studies to measure user - experience , and performance achieved by non - experts with the web - interface at solving crimes . Progress so far I have completed three iterations of system building of SAVANT tool to support solo ( Goyal et al . 2012 ) and col - laborative sensemaking ( Goyal et al . 2013 ) ( Goyal et al . 2014 ) ( Goyal et al . 2016 ) to better understand role of dif - ferent design features : In Iteration 1 ( Step 1 ) , I tested the utility of system - generated visualization of data links and a notepad for col - lecting annotations , and found system - generated visualiza - tions to be significantly important in solving crimes ( Goyal et al . 2012 ) . In Iteration 2 ( Step 2 ) , I explored value of implicitly sharing insights by self - created visualizations of annota - tions , without explicitly pushed / requested information by collaborators . When implicit sharing of notes and self - created visualization of these notes was available , users identified more clues ( Goyal et al . 2013 ) ( Goyal et al . 2014 ) . In Iteration 3 ( Step 2 ) , I explored value of visualizing real - time sensemaking translucence to reduce biased analy - sis using NLP on implicitly shared notes , and explicit chat channel . With sensemaking translucence , users improved task - performance from previous work ( Goyal et al . 2013 ) ( Goyal et al . 2014 ) by identifying the serial killer significantly more ( Goyal et al . 2016 ) . In Step 3 I finished conducting a qualitative video - analysis , and usage - log analysis of the actions performed by successful and unsuccessful pairs in Step 2 . Based on video - analysis , 3 design goals seem promising for success : externalizing insights ; shoe - boxing visually ; and iterating over previously collected information . For Step 3 , I am also identifying user - actions , based on interface - log analysis , when pursued multiple times by users would lead to successful resolution of the task . Next Steps Based on preliminary findings , I am designing the web - interface ( SAVANT ) for non - experts and experts with rec - ommended steps associated with success . Based on these findings , Iâ€™d be better equipped with knowledge of micro - tasks that would enable success in task - resolution . So , Iâ€™d propose using the lessons learnt to design the next SA - VANT version where users using the full SAVANT suite might be able to collaborate and auto - direct micro - tasks to crowds that would support / challenge their own insights and help resolve the crime - solving task . However , what remains to be pursued , is thematically segregated as follows : 1 . Identify the best workflows and aggregation mechanisms that support collaboration between expert and non - expert crowd workers to identify the serial killer . 2 . Identify system - generated micro - tasks vs . manual - ly generated micro - tasks and associated cost vs . benefit ratio . 3 . Understand how to generalize the findings from this work . Challenges The following challenges need to be overcome for the suc - cess of this work . So , feedback in the following directions and potential experiment designs would be useful : 1 . Identifying optimal data / task set - up that balances utility of the task with resemblance to the real - world situations : I am hoping that deliberation on how to better characterize the task for crowd would be beneficial . 2 . Identifying an aggregation mechanism that ena - bles individual crowd workers to not just identify a killer , but the serial killer across multiple crime cases : Aggregated results may be reiterated through the crowds . 3 . Identifying workflows that enable collaboration between experts and non - experts for optimal knowledge generation and dissemination : Proce - dural and temporal collaboration effects need to be studied . 4 . Identifying the balance between computer and human computation : Understanding , when and how to aid the crowds will help improve task per - formance , and perhaps user satisfaction . References Bernstein , M . S . ( 2010 , October ) . Crowd - powered interfaces . In Adjunct proceedings of UIST 2010 ( pp . 347 - 350 ) . ACM ( 2010 ) . Bernstein , M . S . , Little , G . , Miller , R . C . , et al . Soylent : a word processor with a crowd inside . Proceedings of UIST 2010 , ACM ( 2010 ) , 313 â€“ 322 . Bragg , J . , et al . " Parallel Task Routing for Crowdsourcing . " Se - cond AAAI Conference on Human Computation and Crowdsourcing . 2014 . Chilton , L . B . , Little , G . , Edge , D . , Weld , D . S . , & Landay , J . A . ( 2013 , April ) . Cascade : crowdsourcing taxonomy creation . In Proceedings of the CHI 2013 ( pp . 1999 - 2008 ) . ACM . Goyal , N . , Leshed , G . , & Fussell , S . R . ( 2013 ) . Effects of Visual - ization and Note - Taking on Sensemaking and Analysis . In Pro - ceedings of the CHI 2013 , ACM . Goyal , N . , Leshed , G . , Cosley , D . , & Fussell , S . R . ( 2014 ) . Ef - fects of Implicit Sharing in Collaborative Sensemaking . In Pro - ceedings of the CHI 2014 , ACM . Goyal , N . , Leshed , G . , & Fussell , S . R . ( 2013 ) . Leveraging part - ner ' s insights for distributed collaborative sensemaking . CSCW Companion 2013 . ACM . Goyal , N . , & Fussell , S . R . ( 2016 ) . Effects of Sensemaking Translucence on Distributed Collaborative Analysis . Accepted . In Proceedings of the CSCW 2016 . ACM . Hu , Mengdie , et al . " OpinionBlocks : a crowd - powered , self - improving interactive visual analytic system for understanding opinion text . " Human - Computer Interaction â€“ INTERACT 2013 . Springer Berlin Heidelberg , 2013 . 116 - 134 . Kittur , A . , Smus , B . , Khamkar , S . , & Kraut , R . E . Crowd - Forge : Crowdsourcing Complex Work . Proceedings of UIST 2011 , ACM ( 2011 ) , 43 . 52 Kulkarni , A . , Can , M . , and Hartmann , B . . " Collaboratively crowdsourcing workflows with turkomatic . " Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work . ACM , 2012 . Kulkarni , A , et al . " Wish : Amplifying Creative Ability with Ex - pert Crowds . " Second AAAI Conference on Human Computation and Crowdsourcing . 2014 . Lasecki , W . S . , Wesley , R . , Nichols , J . , Kulkarni , A . , Allen , J . F . , & Bigham , J . P . ( 2013 , October ) . Chorus : a crowd - powered con - versational assistant . In Proceedings of the UIST 2013 ( pp . 151 - 162 ) . ACM . Little , G . , Chilton , L . B . , Goldman , M . , and Miller , R . C . TurKit : human computation algorithms on mechanical turk . Proceedings of UIST 2010 , ACM ( 2010 ) , 57 â€“ 66 . Malone , T . , Laubacher , R . , & Dellarocas , C . ( 2009 ) . Harnessing crowds : Mapping the genome of collective intelligence . Zhang , H . , Law , E . , Miller , R . , Gajos , K . , Parkes , D . , & Horvitz , E . ( 2012 , May ) . Human computation tasks with global con - straints . In Proceedings of the CHI 2012 ( pp . 217 - 226 ) . ACM . Appendix I want to participate in the Doctoral consortium at this point be - cause after multiple controlled studies in lab where careful modi - fications have yielded directions on how to improve collaborative sensemaking between pairs , I would like to scale my work to larger worker pool . To this end , I have identified important re - search questions that would help scaling my prior research to wider user population and support generalization of my work . I am hoping to get feedback on how to pursue these questions be - cause I have already proposed this work . I am in the midst of creating a lightweight front - end of crowd workerâ€™s web interface as an extension of prior work with SAVANT . The back - end and logic design of this system will be generated , over remaining Fall 2015 and early Spring 2016 , based on the feedback received at HCOMP 2015 . Feedback will also help design subsequent exper - iments to be run in late Spring 2016 . I am hoping to write the results as my dissertation over Summer 2016 with an expected defense date in mid September 2016 .