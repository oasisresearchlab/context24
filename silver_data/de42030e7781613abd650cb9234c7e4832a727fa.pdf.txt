Journal of Structural Biology 157 ( 2007 ) 47 – 55 www . elsevier . com / locate / yjsbi 1047 - 8477 / $ - see front matter © 2006 Elsevier Inc . All rights reserved . doi : 10 . 1016 / j . jsb . 2006 . 07 . 003 SPARX , a new environment for Cryo - EM image processing Michael Hohn a , Grant Tang b , Grant Goodyear c , P . R . Baldwin c , Zhong Huang c , Pawel A . Penczek c , Chao Yang e , Robert M . Glaeser d , Paul D . Adams a , Steven J . Ludtke b , ¤ a Lawrence Berkeley National Laboratory , Physical Bioscience Division , Berkeley , CA 94720 , USA b National Center for Macromolecular Imaging , Verna and Marrs McLean Department of Biochemistry and Molecular Biology , Baylor College of Medicine , Houston , TX 77030 , USA c The University of Texas , Houston Medical Center , Department of Biochemistry and Molecular Biology , Houston , TX 77030 , USA d The University of California , Department of Molecular and Cell Biology , Physical Biosciences Division , Lawrence Berkeley National Laboratory , Berkeley , CA 94720 , USA e Lawrence Berkeley National Laboratory , Computational Research Division , Berkeley , CA 94720 , USA Received 9 May 2006 ; received in revised form 1 July 2006 ; accepted 7 July 2006 Available online 16 July 2006 Abstract SPARX ( single particle analysis for resolution extension ) is a new image processing environment with a particular emphasis on transmission electron microscopy ( TEM ) structure determination . It includes a graphical user interface that provides a complete graphi - cal programming environment with a novel data / process - X ow infrastructure , an extensive library of Python scripts that perform speci W c TEM - related computational tasks , and a core library of fundamental C + + image processing functions . In addition , SPARX relies on the EMAN2 library and cctbx , the open - source computational crystallography library from PHENIX . The design of the system is such that future inclusion of other image processing libraries is a straightforward task . The SPARX infrastructure intelligently handles retention of intermediate values , even those inside programming structures such as loops and function calls . SPARX and all dependencies are free for academic use and available with complete source . © 2006 Elsevier Inc . All rights reserved . Keywords : CryoEM ; TEM ; Single particle analysis ; 3 - D reconstruction ; Image processing 1 . Introduction Numerous excellent software packages are available for the TEM community , including SPIDER ( Frank et al . , 1996 ) , IMAGIC ( van Heel et al . , 1996 ) , BSOFT ( Heymann , 2001 ) , FREALIGN ( Grigorie V , 1998 ) , EM ( Hegerl , 1996 ) , IMIRS ( Liang et al . , 2002 ) , SUPRIM ( Schroeter and Bre - taudiere , 1996 ) , IMOD ( Kremer et al . , 1996 ) , PHOELIX ( Carragher et al . , 1996 ) , PFT ( Baker and Cheng , 1996 ) , the MRC reconstruction tools ( Crowther et al . , 1996 ) and Xmipp ( Sorzano et al . , 2004 ) . Each of these packages has its own strengths and weaknesses , and although the general thrust of the methodologies is the same , each has its own set of particularly well developed methods used to achieve a W nal reconstruction . However , because of varying W le for - mats , di V erent conventions for Euler angles and the param - eterization of the contrast transfer function ( CTF ) of the instrument , parameters of the image formation process , etc . , moving between packages in order to take advantage of their respective strengths can be an exceedingly di Y cult and time consuming process . Over the last two decades , single particle reconstruction has gone from a technique that initially was capable of achieving structures in the 20 – 30Å range to a versatile mainstream tool frequently producing structures at subna - nometer resolution , and in a few pioneering projects , approaching 4 – 5Å resolution . One of the requirements to achieve high resolution is to limit the electron dose * Corresponding author . E - mail address : sludtke @ bcm . edu ( S . J . Ludtke ) . 48 M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 delivered to the specimen in order to minimize the impact of radiation damage . Reduction of the dose causes a corre - sponding decrease in the signal - to - noise ratio in the image . Therefore , the techniques required to achieve high resolu - tion structures must become ever more sophisticated in order to cope with very noisy data and at the same time to deliver highly accurate alignment parameters . Numerous computational methods are used in a single particle reconstruction , and for each there are various choices of competing algorithms . For example , it is possible to compute a 3 - D reconstruction from projection data using algebraic real - space methods often implemented as iterative algorithms , such as ART ( Gordon et al . , 1970 ) or SIRT ( Lakshminarayanan and Lent , 1979 ) , W ltered back - projection methods , or direct Fourier inversion methods implemented in Fourier space ( for detailed review see ( Vainshtein and Penczek , 2006 ) ) . For 2 - D alignment of noisy particles to low - noise projections , there are exhaus - tive search algorithms , iterative algorithms which separate the rotational alignment from the translational alignment , methods based on moments of the two images , and many others . Beyond this , there are choices between di V erent methodologies for the overall reconstruction process , some of which use so - called ‘inverse’ methods , and avoid the reconstruction step entirely , as discussed below . In no case can a single algorithm be selected and make a claim to be ‘the best’ algorithm for all situations . Di V erent algorithms react di V erently to variations in overall signal - to - noise ratio , shape of the object and CTF parameters . To discover the optimal methods for a particular reconstruction , it is often necessary to try many possible variants of the avail - able algorithms . Incorporation of all or most possibilities into a single environment would dramatically ease this pro - cess of determining what works best in a particular experi - ment , and , in fact , may lead to a better understanding of why speci W c algorithms perform better in speci W c situa - tions . An additional di Y culty arising in virtually all of the aforementioned software is the di Y culty in organizing datasets which often consist of tens if not hundreds of thou - sands of particles drawn from tens to thousands of micro - graphs or CCD frames . Frequently , obtaining a W nal reconstruction involves gradually paring the data down to include only the highest quality micrographs , and / or only the highest quality particles from each micrograph . This process is a substantial data organization task , generally handled manually through careful organization of tiered directories containing hundreds of W les each . This rapidly becomes untenable as reconstructions grow from a few thousand particles from tens of images to hundreds of thousands of particles from thousands of images . Develop - ment of an automatic data tracking system integrated with the reconstruction software has become an important task in the further development of single particle processing . The goal in creating SPARX is to provide a uniform environment for end - users , in which to combine elements of di V erent structure determination strategies , and develop their own approaches , without being forced to acquaint themselves with all available software suites . High - level strategies can be easily modi W ed using a graphical program - ming approach , which does not require detailed knowledge of algorithms made available by the designers of the system . Issues such as W le format conversion and Euler angle con - ventions are dealt with as automatically and transparently as possible . SPARX o V ers a core of robust image processing capabilities and an easy to use programming environment . X - ray crystallography and cryo - EM single particle reconstruction are powerful techniques for macromolecular structure determination at intermediate to high resolutions . One of the goals of SPARX is to provide an integrated computational environment for both methods . This is of increasing importance as they are now often used concur - rently . Crystallographic reconstructions of components of a macromolecular assembly can be readily combined with lower resolution structures of intact complexes solved by cryo - EM . In the future , as cryo - EM methods move to higher resolution it will be possible to take advantage of existing crystallographic tools for electron density interpre - tation . Conversely , crystallographic methods can bene W t from the use of cryo - EM envelopes for phasing . 2 . SPARX design In recent years , a wide range of scienti W c disciplines have adopted the Python scripting language ( http : / / www . python . org ) in conjunction with low - level C + + code to address the need for X exibility without sacri W cing perfor - mance . As discussed in Section 3 , as an easy to learn object - oriented scripting language , Python permits very rapid development and debugging of new routines . Thus , SPARX makes use of C + + for compute - intensive code , while Python is used to implement complex higher level image processing tasks . The link between C + + and Python is generated using the Boost Python Library ( Abrahams and Grosse - Kunstleve , 2003 ) . This same approach has been used successfully in the PHENIX software suite for auto - mated crystallographic structure determination ( Adams et al . , 2002 , 2004 ) . The overall design of SPARX is diagrammed in Fig . 1 . Users can interact with SPARX in three di V erent ways : ( i ) through a graphical programming interface , which requires no formal programming background , ( ii ) through use of pre - written scripts from a command shell , ( iii ) through a text - based customized Python interpreter . The SPARX C + + core library integrates three components : a set of algorithms written speci W cally by SPARX developers , the core image processing library from the EMAN2 package ( see the companion piece in this issue ) and cctbx ( Grosse - Kunstleve et al . , 2002 ) from the PHENIX project , provid - ing tools for manipulating crystallographic data and molec - ular models . Expanding SPARX by adding simple links to other image processing packages is a simple process . To demonstrate this , a partial wrapper for SPIDER ( Frank et al . , 1996 ) is provided , making use of the W le format and M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 49 mathematical convention conversions in SPARX . This wrapper gives access to many SPIDER algorithms from any SPARX interface . In the future , additional wrappers may be written by the SPARX developers or outside users for other image processing suites as the need arises . 2 . 1 . EMAN2 library The EMAN2 library provides the basic image processing functionality in SPARX , such as transparent read / write support for over 20 di V erent image W le formats , and several hundred image processing algorithms ranging from simple W ltration to sophisticated 3 - D reconstruction routines . The shared SPARX / EMAN2 library design makes use of an easy to use modular extensible class structure . All of these extensible classes support calling functions by name and passing of arbitrary parameters . Full introspection is avail - able , meaning applications can get a list of available func - tions from the library when the GUI is executed . This permits the GUI to immediately become aware of any newly added algorithms , their parameters , and full docu - mentation . As a simple example of the library interface , to apply a low - pass Gaussian W lter to an image , one would simply call : new _ img D img . process ( “filter . lowpass . gauss” , { “sigma” : 0 . 2 } ) , where img is the input image that will be W ltered , new _ img is the output image , W lter . lowpass . gauss speci W es the W lter , which is a member of the process class , sigma is the name of the input parameter , i . e . , the standard deviation in Fourier space of the W lter Gaussian function , and 0 . 2 is the sigma value given in absolute frequency units , in which 0 . 5 is the Nyquist frequency . The ‘process ( ) ’ and ‘process _ inplace ( ) ’ functions provide access to a wide range of image processing algorithms , each accessed by name . Other algorithm categories also exist , and use a similar structure , such as ‘cmp ( ) ’ for comparing two image objects using a named similarity metric with optional parameters , or ‘align ( ) ’ for performing 2 - D or 3 - D registration of one image to a reference image . Documentation for each of the algorithms can be obtained interactively , for example , ‘dump _ processors ( ) ’ , through the on - line manual ( http : / / www . macro - em . org / sparxwiki ) or for programs making use of the library , through a set of introspection function calls . More details on this modular extensible class structure can be found in the companion manuscript on EMAN2 in this issue . 2 . 2 . The computational crystallography toolbox ( cctbx ) The cctbx is an open - source C + + library for crystallog - raphy and other scienti W c calculations ( Grosse - Kunstleve et al . , 2002 ) . It provides a wealth of fundamental algorithms drawn from the PHENIX package ( Adams et al . , 2002 , 2004 ) , and is the source of the necessary crystallographic tools for SPARX . Consistent with the design goals of SPARX , it provides high - level interfaces to the underlying C + + algorithms via the Python scripting language . Indeed , the cctbx has been designed with an open and X exible archi - tecture to promote extendibility and easy incorporation into other software environments . As with the other cores , the package is organized as a set of C + + classes with Python bindings . The cctbx project currently consists of the following modules , many of which are already available in SPARX : libtbx : A build system common to all other modules ( based on the open - source Scons software construction tool ) and some associated general Python utilities for build - ing and testing libraries and applications . The libtbx also includes PHIL , the Python - based Hierarchical Interchange Language ( Grosse - Kunstleve et al . , 2005 ) for user - friendly processing of input parameters . boost _ adaptbx : A very small adaptor toolbox with plat - form - independent instructions for building the Boost . Python library ( Abrahams and Grosse - Kunstleve , 2003 ) , a crucial tool for the e Y cient integration of Python and C + + . scitbx : Libraries for general scienti W c computing ( i . e . , not speci W c to crystallographic applications ) : a family of high - level C + + array types , matrix / vector manipulations , special functions , a fast Fourier transform library , and a C + + port of the popular L - BFGS quasi - Newton minimizer , all including Python bindings . cctbx : Libraries for general crystallographic applica - tions , useful for both small - molecule and macro - molecular crystallography . The libraries in the cctbx module cover everything from algorithms for the handling of unit cells to high - level building blocks for re W nement algorithms and maximum - likelihood molecular replacement . mmtbx : Libraries speci W c to macromolecular crystallog - raphy : absolute and relative scaling of protein and nucleic acid datasets , high - level PDB interpretation , automatic bulk - solvent correction , Cartesian molecular dynamics , Fig . 1 . Diagram of the overall design of SPARX . SPARX is built on top of several other toolkits including EMAN2 and cctbx from the PHENIX project through bindings to the Python programming language . External software suites not available as libraries ( such as SPIDER ) can be inte - grated through Python wrapper scripts . GUI Scripting Interface Python Python Modules Sparx , EMAN2 , cctbx Libraries ( C + + ) Sparx , EMAN2 , cctbx External programs SPIDER L3 50 M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 non - crystallographic symmetry restraints , and maximum - likelihood re W nement targets . iotbx : Input / output utilities to support the cctbx and mmtbx modules : automatic recognition and processing of all common re X ection W le formats , low - level PDB interpre - tation . 2 . 3 . SPARX core The core algorithms provided by the EMAN2 core and cctbx are augmented by a large set of algorithms re X ecting the unique expertise of the contributors to the SPARX pro - ject . These include , for example , addition of highly accurate methods based on non - uniform Fourier transform , also known as gridding ( Penczek et al . , 2004 ) and a comprehen - sive set of 3 - D reconstruction algorithms ( for details see ( Vainshtein and Penczek , 2006 ) ) . In addition , an implemen - tation of a uni W ed approach to the 3 - D structure and pro - jection orientation re W nement using quasi - Newton algorithm ( Yang et al . , 2005 ) is being developed . In this method , the 3 - D map and projection directions are updated simultaneously resulting in a rapid convergence rate , i . e . , high resolution structures can be obtained faster than using standard 3 - D projection alignment methods . These varied contributions will continue to expand as SPARX develop - ment continues . 3 . Interactive SPARX ( Python ) interpreter Over recent years , the Python scripting language has become increasingly popular in the scienti W c programming community , mainly because it dramatically shortens the turnaround time between concept and application . Com - plex ideas can be realized in a relatively easy to learn , but powerful scripting language opening many possibilities to non - specialists . Therefore , Python constitutes an ideal plat - form on which to base a modern scienti W c software pack - age . As methodologies of EM structure determination are under continuous development , coding in Python makes it possible to rapidly implement , test and integrate new algo - rithms and strategies , making them immediately available to the EM community . Python has been successfully used in numerous scienti W c visualization packages , for example , Vision ( Sanner et al . , 2002 ) , Chimera ( Pettersen et al . , 2004 ) and Pymol ( DeLano Scienti W c , http : / / www . pymol . org ) . The typical design pat - tern is the creation of a library in C + + or Fortran , contain - ing compute - intensive operations . This library is then bound to the Python language in which all of the higher level logic of the W nal program is implemented . Python has native support for lists , dictionaries ( hashes ) , sets and a variety of other data types , as well as string processing capabilities rivaling those of Perl . It also has an extensive set of standard libraries on all supported platforms , includ - ing a wide range of network protocols and mathematical operations . In many ways it represents a superior cross - platform development language to Java . Its object - oriented capabilities make it an ideal companion language to C + + based libraries . The SPARX interpreter is an enhanced Python shell , and provides access to three distinct types of callable func - tions : Level 1 : Direct access to the C + + core image processing routines from Python . Calling syntax is almost identi - cal between Python and C + + . This includes opera - tions such as image i / o , basic image processing , Fourier transforms , W lters , and so on . Level 2 : Python scripts built using Level 1 functions , writ - ten as a shell command . For example , performing a 3 - D reconstruction from a set of projection images could be implemented in a command - line program called ‘reconstruct . py’ . This program could then be used directly from the system shell , or imported into the interactive interpreter and then called directly as a Python function . Level 3 : Higher level Python scripts consisting of Level 2 or level 1 functions . These scripts can be written by hand or be constructed using the graphical programming tool described below . Once tested and built through the graphical programming interface , such algorithms may also be called from the interactive interpreter . Now , consider the simple example of an interactive SPARX session in Fig . 2 . This script will ( 1 ) create an image object , ( 2 ) read ‘img001 . spi’ from disk , ( 3 ) display basic image information using a user - de W ned utility func - tion , ( 4 ) display the image in an window on the screen with a control panel permitting adjustment of brightness , con - trast , ƒ , and ( 5 ) invert the contrast of the image data . Note step 5 will also produce an immediate screen update in the displayed image . Any operation applied in - place to img will be immediately re X ected in the image display window . In writing level 2 Python scripts , the concept is similar , but the style has to be slightly more expansive . Fig . 3 has an example of a command - line program that reads a stack of images , W lters each image with a low - pass Gaussian W lter , and writes the W ltered images to a new stack W le . The ‘sigma’ parameter speci W es the full width of the low - pass Fourier W lter expressed in units where Nyquist frequency is Fig . 2 . A sample of an interactive text - based session in SPARX . This sim - ple example , reads a W le from disk , displays various image properties , ren - ders the image in a new window , then inverts the contrast in the image . M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 51 0 . 5 . The de W nition of any of the named parameters , like ‘sigma’ are part of the built - in documentation system avail - able both in the manual and via introspection . Note that the actual script functionality is embodied in the ‘ W lt ( ) ’ function , and the remaining code simply deals with parsing command - line options . If this program were in a W le called ‘ W lter . py’ , one could simply execute : filter . py input . spi output . hdf - - sigma D 0 . 5 from the command - line . Alternatively , one could achieve identical results from Python / SPARX with : from filter import filt filt ( “input . spi” , “output . hdf” , 0 . 5 ) The script could also be used from within the SPARX GUI and take advantage of all of the features this interface provides . 4 . The SPARX interface 4 . 1 . The design The main motivation for the development of the SPARX GUI is to provide an interface with the ease - of use of a graphical programming environment as well as a range of capabilities usually found only in language - based sys - tems . First , the environment provides full retention of all intermediate values in a user - controllable way . Second , it supports parallelism and disconnected operation , meaning the user interface can be exited and restarted while a com - putational job is being executed . Third , it supports loops and conditionals with automatic dependency checking . A few of these features have long been available in tools such as AVS ( www . avs . com ) and Iris Explorer ( www . nag . co . uk / welcome _ iec . asp ) , allowing non - program - mers to write simple programs graphically without having to learn the syntax of an actual programming language . These tools represent speci W c tasks as boxes . A network is formed by interconnecting boxes representing data X ow between di V erent tasks . For example , one box might repre - sent reading an image from a W le , and a second box might represent displaying an image on the screen . The two boxes are connected to form a network that reads a W le from disk and displays it on the screen . In general , when the network is executed , data interdependencies are checked , and all of the individual boxes perform their respective tasks . How - ever , certain constructs needed in tasks like single particle reconstruction , such as data - dependent ( dynamic ) loops , are di Y cult to implement in such strict data - X ow systems . In order to address speci W c needs for EM data process - ing , a new language called L3 was designed for SPARX . L3 is a full programming language ( manuscript in preparation ) with numerous features , but brie X y , L3 embeds Python , providing Python syntax and allowing direct access to all of Python’s functions , including the SPARX library . The design of L3 adds certain capabilities such as retention of computed values and variables , the ability to resume an interrupted computation , the ability to execute only the portion of a program where dependencies have changed , and other re W nements necessary to build the GUI . The low - est level tasks in the GUI , such as W ltering an input image , are simple calls to the functions in the underlying SPARX Fig . 3 . An example of a level 2 SPARX program . This program can be used directly from GUI , from the command prompt , or imported into Python as a callable function . This simple example will read a set of images from a W le , low - pass W lter them , then write the results to a new W le , which may be in any supported W le format . 52 M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 library . More complex tasks can then be constructed graph - ically by combining existing low - level tasks , naturally form - ing a hierarchy of tasks . Further , there is no distinction between user - de W ned tasks and tasks distributed with SPARX , so users can build their own custom task collec - tions . All tasks have dual graphical and textual representa - tion , regardless of how they were created . Thus , sharing assembled tasks with others can be as simple as e - mailing the textual representation . All of the image processing capabilities in the SPARX core are provided as visual tasks , so the end - user will rarely need to directly write L3 code . The programming environment provides full retention of all intermediate values , in a user - controllable way . Every datum computed during execution is archived in a local data - base structure . In e V ect , a full history of the script execution is available for later investigation . For example , if a script representing an iterative reconstruction process is created and then executed for W ve iterations , the intermediate results produced during each iteration will be available . Since stor - age of all intermediate W les in a large reconstruction would be prohibitive , the user can specify intermediates for which only the most recent value should be available . This mechanism also provides persistent sessions . That is , if the user builds a ( visual ) script for iterative reconstruction , executes four itera - tions , then exits , he or she can return later and reload the same script . Everything will be in the same state as when he or she last exited , including the full history of intermediate values for each of the four iterations . To support parallelism and disconnected operation , the graphical interface is separated from execution . The user starts the GUI , builds a script visually , speci W es which tasks can be executed in parallel , then executes the script . The actual execution is then handled by an independent process , which executes the script on the appropriate parallel resources , such as nodes of a computational cluster . The GUI then interactively displays the progress of the running script . Even if the GUI were terminated , the task would continue executing and the user could later restart the GUI and monitor the task’s progress or access intermediate results . To support long - term projects in which scripts evolve over time , tasks are executed only when data or parameters they depend on change . For example , if a long - running script containing ten iterations were interrupted during the sixth iteration , ordinarily , the entire script would have to be re - executed . Using L3 , execution resumes after the last suc - cessful command , with all previously computed results pre - served . If some parameters were changed before restarting the job , only intermediate values relying on the changed parameters would be recalculated . 4 . 2 . The GUI A screenshot of the current GUI is shown in Fig . 4 . The main window consists of two panes . On the left is the library of available tasks . On the right is the canvas in Fig . 4 . A snapshot of the current SPARX GUI . The interface in the current version is still somewhat minimalistic , but it is undergoing continual improve - ments . The frame on the left contains available tasks and programming constructs that may be copied and used to form scripts . The frame on the right is used to construct scripts using the library tasks from the left . Shown in the right of this snapshot is the sample problem described in the text : the initial script to compute projections and backprojections ( on the left ) , the hierarchy of computed data ( on the upper right ) , and a second script constructed using data ( delta theta and the cross - correlation coe Y cient ) accumulated by the initial script . M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 53 which the user constructs their program ( s ) from the tasks in the library . The canvas holds multiple scripts ; each script is constructed vertically and is hierarchical . For example , a loop is represented by a box . The tasks that are executed multiple times as part of the loop are boxes inside the loop box . Each task has associated parameters / values . Analo - gous to the way a directory structure is browsed , parame - ters and contained elements can be displayed or hidden from view . Note that the library portion of the display can also be expanded . The user can build a small collection of tasks to perform a speci W c function , name it and move it back into the library for later use in other scripts . Because tasks can be nested , whole programs can be contained in single task , and added to the library in the same way . We demonstrate the workings of the GUI by following the simple example session shown in Fig . 4 . Inside the loop , projections of a 3 - D model are generated and then used to reconstruct a model . Begin by considering the left - most ‘Program’ box in the canvas on the right . This exam - ple begins with a 3 - D model , generates a set of projections with a speci W c angular step , reconstructs the model from the projections , then compares the reconstructed model with the original . The loop in this example executes this overall process multiple times for di V erent angular steps Fig . 5 . The plot produced when the script in the lower right of Fig . 2 was executed . The current version lacks axis labels and other re W nements , which will be added in future releases . 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 10 15 20 25 30 35 40 45 Fig . 6 . The text corresponding to the upper left visual program in Fig . 2 . This script can be executed independently of the GUI while maintaining continu - ous data and execution tracking . 54 M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 ( deltheta ) . One could use such a simple script in order to examine the possible artifacts introduced by projection / reconstruction algorithms , and to establish a reasonable choice for angular sampling when performing a single particle reconstruction . Once the script has been executed , the results are exam - ined through the same interface—the script itself . For example , in order to inspect the reconstructed 3 - D objects for each possible angular step , one simply goes to the ‘back - project’ box , selects the output image , and chooses ‘display’ from its menu . This will then display the list of images pro - duced by all loop iterations . The full results are shown par - tially expanded in the ‘anonymous’ box in the upper right of Fig . 4 . Instead of just displaying a value , the value can itself be used as part of a new script . This introduces a convenient way of examining one’s data . Continuing the example , by selecting the cross _ corr box and choosing ‘insert values’ , a list of values is put on the canvas . Then , select - ing the deltheta box and again choosing ‘insert values’ , a second list of values is put on the canvas . Now , a ‘program’ task and a ‘plot’ task ( not visible in the W gure ) are added to the canvas , and a plot script is assembled ( Fig . 4 , lower right ) . This derived script is then executed to produce the plot in Fig . 5 . As mentioned above , a program constructed in the GUI is equivalent to an L3 script , which is what is actually exe - cuted . In Fig . 6 , the textual script corresponding to the main visual script in Fig . 4 is shown . These scripts , whether typed by hand or produced by the GUI , can be executed as stand - alone programs outside the SPARX GUI , and still maintain history tracking capabilities , because even in the GUI , they are executed by the underlying L3 interpreter , not by the GUI itself . 4 . 3 . Integration with other software The SPARX GUI is basically a user - friendly wrapper for Python . To bring other ( non - graphical ) software into the SPARX environment and gain its bene W ts only requires writing a custom Python wrapper . The core library already supports multiple W le formats and several data structuring conventions used by other packages , so conversion to / from an internal SPARX format by the wrapper is greatly sim - pli W ed . This approach provides seamless integration of a variety of tools . As concrete example , a Python - SPIDER connection called pyspi is included with SPARX . This experimental module makes » 40 SPIDER commands available in Python and the SPARX GUI . This capability will be gradually expanded as SPARX matures to allow direct mixing of algorithms between EMAN2 , SPIDER , FREALIGN and possibly other TEM software packages . The process of integrating standalone programs into the GUI is usually straightforward . One of the great bene W ts of development within SPARX is the ability to take advantage of an existing package by incor - porating it into a structure determination project . 5 . Conclusions SPARX will be an attractive environment for those users who wish X exibility in their image processing , but do not wish to learn a full programming language or to those with some programming skills who wish to integrate algorithms from multiple packages . It combines the ease of graphical programming as used in packages such as IRIS Explorer or AVS with process - X ow features such as loops , historical data tracking and inspection , and parallelization capabili - ties . SPARX is not designed to supplant existing software , such as SPIDER and EMAN , but to unify access to such existing tools in a common environment , including novel algorithms developed in SPARX itself . The core infrastructure of SPARX is largely complete and tested , and a usable prototype of the GUI has been completed . The W rst beta version of the complete package which will incorporate SPARX , the EMAN2 core , cctbx and all dependencies is expected in late - 2006 . Full docu - mentation , details and contact information is available from the SPARX web site at http : / / blake . bcm . tmc . edu / SPARX . Both EMAN2 and the cctbx are also indepen - dently available at http : / / blake . bcm . tmc . edu / EMAN2 and http : / / cctbx . sourceforge . net , respectively . Acknowledgments This research has been supported by NIH Grant P01GM064692 and by the US Department of Energy under Contract No . DE - AC02 - 05CH11231 . Support for the core EMAN2 libraries is provided by R01GM080139 and P41RR02250 . References Abrahams , D . , Grosse - Kunstleve , R . W . , 2003 . Building hybrid systems with Boost Python . CC Plus Plus Users Journal 21 , 29 – 36 . Adams , P . D . , Grosse - Kunstleve , R . W . , Hung , L . W . , Ioerger , T . R . , McCoy , A . J . , Moriarty , N . W . , Read , R . J . , Sacchettini , J . C . , Sauter , N . K . , Terwil - liger , T . C . , 2002 . PHENIX : building new software for automated crys - tallographic structure determination . Acta . Cryst . D 58 , 1948 – 1954 . Adams , P . D . , Gopal , K . , Grosse - Kunstleve , R . W . , Hung , L . W . , Ioerger , T . R . , McCoy , A . J . , Moriarty , N . W . , Pai , R . K . , Read , R . J . , Romo , T . D . , 2004 . Recent developments in the PHENIX software for automated crystallo - graphic structure determination . J . Synchrotron . Radiat . 11 , 53 – 55 . Baker , T . S . , Cheng , R . H . , 1996 . A model - based approach for determining orientations of biological macromolecules imaged by cryoelectron microscopy . J . Struct . Biol . 116 , 120 – 130 . Carragher , B . , Whittaker , M . , Milligan , R . A . , 1996 . Helical processing using PHOELIX . J . Struct . Biol . 116 , 107 – 112 . Crowther , R . A . , Henderson , R . , Smith , J . M . , 1996 . MRC image processing programs . J . Struct . Biol . 116 , 9 – 16 . Frank , J . , Radermacher , M . , Penczek , P . , Zhu , J . , Li , Y . , Ladjadj , M . , Leith , A . , 1996 . SPIDER and WEB : processing and visualization of images in 3D electron microscopy and related W elds . J . Struct . Biol . 116 , 190 – 199 . Gordon , R . , Bender , R . , Herman , G . T . , 1970 . Algebraic reconstruction techniques ( ART ) for three - dimensional electron microscopy and X - ray photography . J . Theor . Biol . 29 , 471 – 481 . Grigorie V , N . , 1998 . Three - dimensional structure of bovine NADH : ubi - quinone oxidoreductase ( complex I ) at 22 Å in ice . J . Mol . Biol . 277 , 1033 – 1046 . M . Hohn et al . / Journal of Structural Biology 157 ( 2007 ) 47 – 55 55 Grosse - Kunstleve , R . W . , Sauter , N . K . , Moriarty , N . W . , Adams , P . D . , 2002 . The computational crystallography toolbox : crystallographic algo - rithms in a reusable software framework . J . Appl . Cryst . 35 , 126 – 136 . Grosse - Kunstleve , R . W . , Afonine , P . V . , Sauter , N . K . , Adams , P . D . 2005 . cctbx news : Phil and friends . Newsletter of the Commission on Crystallographic Computing , International Union of Crystal - lography , 5 . Hegerl , R . , 1996 . The EM program package : a platform for image processing in biological electron microscopy . J . Struct . Biol . 116 , 30 – 34 . Heymann , J . B . , 2001 . Bsoft : image and molecular processing in electron microscopy . J . Struct . Biol . 133 , 156 – 169 . Kremer , J . R . , Mastronarde , D . N . , McIntosh , J . R . , 1996 . Computer visuali - zation of three - dimensional image data using IMOD . J . Struct . Biol . 116 , 71 – 76 . Lakshminarayanan , A . V . , Lent , A . , 1979 . Methods of least squares and SIRT in reconstruction . J . Theor . Biol . 76 , 267 – 295 . Liang , Y . , Ke , E . Y . , Zhou , Z . H . , 2002 . IMIRS : a high - resolution 3D recon - struction package integrated with a relational image database . J . Struct . Biol . 137 , 292 – 304 . Penczek , P . A . , Renka , R . , Schomberg , H . , 2004 . Gridding - based direct Fourier inversion of the three - dimensional ray transform . J . Opt . Soc . Am . A 21 , 499 – 509 . Pettersen , E . F . , Goddard , T . D . , Huang , C . C . , Couch , G . S . , Greenblatt , D . M . , Meng , E . C . , Ferrin , T . E . , 2004 . UCSF Chimera—a visualiza - tion system for exploratory research and analysis . J . Comput . Chem . 25 , 1605 – 1612 . Sanner , M . F . , Sto Z er , D . , Olson , A . J . 2002 . ViPEr , a visual Programming Environment for Python , Paper presented at : Proceedings of the 10th International Python conference . Schroeter , J . P . , Bretaudiere , J . P . , 1996 . SUPRIM : easily modi W ed image processing software . J . Struct . Biol . 116 , 131 – 137 . Sorzano , C . O . , Marabini , R . , Velazquez - Muriel , J . , Bilbao - Castro , J . R . , Scheres , S . H . , Carazo , J . M . , Pascual - Montano , A . , 2004 . XMIPP : a new generation of an open - source image processing package for electron microscopy . J . Struct . Biol . 148 , 194 – 204 . Vainshtein , B . K . , Penczek , P . A . , 2006 . Three - dimensional reconstruction . In : Shmueli , U . ( Ed . ) , International Tables for Crystallography . Klu - wer , Dordrecht . van Heel , M . , Harauz , G . , Orlova , E . V . , Schmidt , R . , Schatz , M . , 1996 . A new generation of the IMAGIC image processing system . J . Struct . Biol . 116 , 17 – 24 . Yang , C . , Ng , E . G . , Penczek , P . A . , 2005 . Uni W ed 3 - D structure and projec - tion orientation re W nement using quasi - Newton algorithm . J . Struct . Biol . 149 , 53 – 64 .