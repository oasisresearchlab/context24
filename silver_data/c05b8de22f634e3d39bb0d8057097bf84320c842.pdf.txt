111 Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting YILIN YE , RONG HUANG , KANG ZHANG , and WEI ZENG âˆ— , The Hong Kong University of Science and Technology ( Guangzhou ) , China and The Hong Kong University of Science and Technology , China The recent advances of AI technology , particularly in AI - Generated Content ( AIGC ) , have enabled everyone to easily generate beautiful paintings with simple text description . With the stunning quality of AI paintings , it is widely questioned whether there still exists difference between human and AI paintings and whether human artists will be replaced by AI . To answer these questions , we develop a computational framework combining neural latent space and aesthetics features with visual analytics to investigate the difference between human and AI paintings . First , with categorical comparison of human and AI painting collections , we find that AI artworks show distributional difference from human artworks in both latent space and some aesthetic features like strokes and sharpness , while in other aesthetic features like color and composition there is less difference . Second , with individual artist analysis of Picasso , we show human artistsâ€™ strength in evolving new styles compared to AI . Our findings provide concrete evidence for the existing discrepancies between human and AI paintings and further suggest improvements of AI art with more consideration of aesthetics and human artistsâ€™ involvement . CCS Concepts : â€¢ Computing methodologies â†’ Artificial intelligence ; â€¢ Applied computing â†’ Arts and humanity ; â€¢ Human - centered computing â†’ Visualization . ACM Reference Format : Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng . 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting . J . ACM 37 , 4 , Article 111 ( August 2018 ) , 22 pages . https : / / doi . org / XXXXXXX . XXXXXXX 1 INTRODUCTION Artistic creativity has long been considered the exclusive talent of human beings . Even in the age of artificial intelligence ( AI ) when deep learning has shown superior performance in various tasks [ 42 ] , many technologists and artists believe that art would be the safe sanctuary of human work . Recent development of AI has , however , challenged the idea that machines can only surpass humans in well - defined perceptive tasks . Specifically , the latest AI - generated content ( AIGC ) models like OpenAIâ€™s DALL Â· E 2 model [ 57 ] and text - to - image diffusion models [ 59 ] can generate impressive paintings with only text prompts provided by laymen without any training in fine art . Using the AI technology , tools and platforms like Stable Diffusion and Midjourney enable painting creation with custom contents and styles . âˆ— Wei Zeng is the corresponding author Authorsâ€™ address : Yilin Ye , yyebd @ connect . ust . hk ; Rong Huang , rhuang421 @ connect . hkust - gz . edu . cn ; Kang Zhang , kzhangcma @ ust . hk ; Wei Zeng , weizeng @ ust . hk , The Hong Kong University of Science and Technology ( Guangzhou ) , Guangzhou , Guangdong , China and The Hong Kong University of Science and Technology , Hong Kong SAR , China . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from permissions @ acm . org . Â© 2018 Association for Computing Machinery . 0004 - 5411 / 2018 / 8 - ART111 $ 15 . 00 https : / / doi . org / XXXXXXX . XXXXXXX J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . a r X i v : 2304 . 07999v1 [ c s . H C ] 17 A p r 2023 111 : 2 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng These new developments have sparked a concerning question few people have seriously consid - ered before : can AI be considered as creative as human artists ? This question has become more realistic as an AI generated painting even confound the eyes of experts and won the first prize in a fine art competition , which is traditionally reserved for human artists . This event provides evidence that AI paintings and human paintings are almost indistinguishable to human eyes if we only look at some of the best quality samples . With nearly zero - cost high quality painting generation , many artists worry about losing their jobs , whilst AI enthusiasts envision a near future that anyone can easily produce masterful paintings without commissioning artists . Such opinion makes people wonder whether artists , or more specifically fine art painters as a group , will be replaced by AI . Surrounding this question , there is also huge controversy among artists and general public . Most of the arguments remain qualitative with personal creative experience and subjective evaluation . For example , many believe that AI models are especially good at colors and atmosphere ; some artists have even started to learn from AI generated color palette . On the other hand , many artists insist that AI art is an advanced version of plagiarism which combines the elements in training data in less recognizable ways . Some artists also criticize the insufficient or unbalanced depiction of details in AI arts . For such skepticism , AI art enthusiasts argue that it is merely a matter of more fine - grained training data . However , neither side can provide convincing evidence with concrete quantitative analysis . To provide scientific perspectives on such a challenging question , just comparing a few samples of human and AI paintings is not enough . Instead , one needs to perform a larger - scale comparison of collections between human and AI paintings for insightful and convincing findings . Specifically , there are two aspects of the question . â€¢ First , what differences can be observed between collections of AI and human paintings ? â€¢ Second , compared to individual human artists , does AI have superior creativity , especially in terms of the ability to develop new styles ? To answer these questions , we develop a data - driven scientific framework that takes the advan - tages of neural latent embeddings and computational aesthetics , to reveal and quantify the distinction between human and AI paintings . On one hand , AI researchers rely on neural latent embeddings by deep learning networks to analyze human paintings [ 8 , 61 ] and to generate paintings [ 23 , 24 ] . The embeddings can capture rich visual and semantic features in paintings but suffers from poor interpretability . The evaluation techniques used by AI researchers , such as FrÃ©chet inception dis - tance [ 29 ] and inception score [ 60 ] , are only focused on statistical difference between the results and the training data in latent space . This makes it hard to comprehensively capture the differences as an open - world painting generator independent of the training data . On the other hand , compu - tational aesthetics [ 19 , 38 , 43 ] leverage explicit aesthetics - aware statistics to capture and analyze painting features . These approaches have better interpretability but suffer from the limited scope and potential human bias in hand - crafted features [ 43 ] . As illustrated in Figure 1 , the proposed framework supports various pronged analyses , including latent embedding clustering , distribution discrepancy measurement , aesthetic feature comparison , and evolutionary analysis . The spatio - temporal illustration helps one to gain a comprehensive understanding of the difference between AI and human paintings . We further build an interactive visualization interface to assist exploratory analysis of human and AI painting collections . We apply the framework in two experiments and derive interesting findings , as follows : â€¢ Categorical comparison of human and AI paintings : There are subtle differences between hu - man and AI paintings , which can be captured by latent embedding clustering and distribution discrepancy measurement . AI paintings are more similar to digital human paintings than traditional human paintings . Amongst the various aesthetic features , strokes offer the most J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 3 distinctive difference , sharpness and complexity are the next , and color and composition show marginal differences , between AI and human paintings . â€¢ Human artistsâ€™ ability to evolve compared to AI : We generate AI imitations of a best - known human artist , Pablo Picasso and compare AI - generated Picasso paintings with Picassoâ€™s original works . Evolutionary analysis reveals drastic style changes from early years of realism , to styles of Blue and then Rose periods , and finally to Picassoâ€™s iconic Cubism . In contrast , AI paintings fail to demonstrate any meaningful style change . Overall , human artists can change styles over time , whilst AI paintings are unable to evolve in styles . On the basis of these findings , we deduce the limitations of current AI art process and results . Next , we discuss perspectives for both artists and AI developers , including the positive and neg - ative implications on artists , and how AI developers can improve AI models with more artistic consideration . Particularly , we stress how collaboration can be established between the two fields to promote shared prosperity of the future of AI art . Our code and dataset have been released at https : / / github . com / yilinye / AI _ and _ human _ paintings . 2 RELATED WORK 2 . 1 AI - generated Visual Art Various deep neural networks ( DNN ) have been developed for generation and modification of realistic and artistic images based on different inputs . Neural style transfer is the first important milestone that enables automatic transformation of styles with image input [ 23 ] . This is achieved through combination of content and style features extracted by the intermediate layers of con - volutional neural networks . Subsequently , several powerful generation frameworks leveraging the potential of DNN latent space have been introduced . One important framework is Generative adversarial network ( GAN ) [ 24 ] . This framework consists of one generator neural network and one discriminator neural network which jointly learn the distribution of image features . GAN has been widely adopted to derive a series of unconditional and conditional generation models , such as WGAN [ 26 ] , CycleGAN [ 77 ] and StyleGAN [ 36 ] . Another important framework is Variational Auto - enconder ( VAE ) [ 39 ] . This framework trains generation model with an auto - regressive process where a decoder neural network generate images based on the latent space embedding produced by an encoder . Concurrently , diffusion - based framework has been proposed , such as DDPM [ 30 ] and Latent Diffusion [ 59 ] . These models formulate the generation process as denoising artificially blurred images . The diffusion - based models prove to be more effective , especially in text - guided generation [ 57 ] . Recently , few - shot finetuning technique ( LORA ) [ 33 ] and basic structure control ( ControlNet ) [ 76 ] are introduced to facilitate more customized generation . Even though the models have achieved significant progress and great impact on art community , the evaluation has been limited . Particularly , AI researchers focus on quantitative evaluation directly comparing the generated results with the training data using latent space statistics like FID [ 29 ] and Inception Score [ 60 ] without consideration of aesthetics . A few qualitative studies [ 32 , 57 ] have been conducted but only provide subjective evaluation score on general attributes without concrete aesthetic features . In our work , we provide more comprehensive comparison of human paintings and paintings generated by the latest text - guided diffusion models on both collection and instance levels , with consideration of aesthetic features . 2 . 2 Computational Aesthetics Many researchers have explored the possibility of quantitatively measuring aesthetic features of artworks , providing more objective statistics for artistic evaluation of images . Some of the studies adopt generic features in image processing to predict aesthetic values , such as SIFT , Fisher J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 4 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng Vector and Bag - of - words [ 14 , 48 , 66 ] . Other studies focus on more interpretable feature descriptors explicitly designed to measure certain aesthetic aspects , such as color , composition , strokes , and image quality . For example , the aesthetic color features include descriptors of global and local hue , saturation and brightness features [ 43 ] , as well as harmonic color templates [ 12 , 54 ] . Composition is difficult to measure , with some preliminary attempt based on image segmentation [ 43 ] . Regarding stroke features , special filters can be applied to detect pixels of lines and edges , which is then summarized in distribution metric designed by researchers [ 38 , 43 ] . Other works try to measure image quality features like sharpness [ 2 ] and complexity [ 45 ] . Although a rich variety of computational aesthetic metrics have been developed , these methods require prior human knowledge and hand - crafted feature extraction rules , which cannot fully cover the rich implicit features of the artworks . Recently , some researchers attempt to combine these metrics with deep neural networks [ 34 ] . But these studies are limited to predicting subjective ratings of human paintings . Moreover , the specialized networks used for rating prediction cannot reveal further implicit information about the artworks . In our study , we combine implicit features extracted by multi - modal self - supervised DNN embeddings with computational aesthetic features for more general multi - faceted evaluation . 2 . 3 Exploratory Analysis of Image Collection To facilitate exploratory analysis of image collections , many researchers have developed visual - ization techniques and systems . The common visualization techniques include scatterplot [ 53 ] , tree [ 44 ] and graph [ 25 ] , treemaps [ 4 ] , and self - organizing map [ 65 ] . Most previous works calculate the visual layout based on low - level hand - crafted features . Other works rely on extra metadata of images such as time and author [ 16 , 74 ] . These methods intuitively reveal the global distribution patterns on certain aspects . However , other explicit and implicit features are omitted . Semantic gap also exists between the low - level feature layout and human perception [ 41 ] , which include not just low - level features but also high - level semantic information . Recently , some researchers start to leverage latent space features extracted by neural networks . For example , Semantic Image Explorer [ 72 ] exploit image embedding and word embedding models to incorporate semantic information into image collection visualization . Latent Space Cartogra - phy [ 46 ] allows exploration of image collections along user - defined semantic axis in latent space . VISAtlas [ 73 ] leverages image embedding combined with contextual visualization to facilitate overview comparison of different image collections . However , the purely DNN - driven methods suffer from poor interpretability because of the complex and implicit nature of latent space fea - tures . Thus , in our work we complement the implicit features with explicit aesthetic features in coordinated multiple view visualization . 3 METHODS As illustrated in Figure 1 , for human and AI painting collections , we first represent their features by combining neural latent embeddings with computational aesthetics metrics ( Section 3 . 1 ) . The rich feature representations allow us to capture explicit and implicit aesthetic characteristics of the paintings . Subsequently , we combine the expressive features with the power of visualization to perform four - pronged analyses consisting of latent embedding clustering , distribution discrepancy measurement , aesthetic feature comparison , and evolutionary analysis ( Section 3 . 2 ) . We also provide an interactive exploration system to assist the analysis . 3 . 1 Features Neural latent space . In order to explore and compare the creative space of human and AI paintings , we leverage a shared latent space produced by the state - of - the - art multi - modal CLIP embedding J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 5 Dataset Analysis & Visualization Features Human paintings AI paintings Latent Embeddings Latent Embedding Clustering Aesthetic Feature Comparison Distribution Discrepancy Measurement Evolutionary Analysis Aesthetic Features Focus Hue TextInput ImageInput Text Encoder . . . . . . . . . . . . . . . ImageEncoder Composition Edge Color T 1 T 2 T 3 T N I 1 I 1 T 1 I 2 T 1 I 3 T 1 I N T 1 I 1 T 2 I 2 T 2 I 3 T 2 I N T 2 I 1 T 3 I 2 T 3 I 3 T 3 I N T 3 I 1 T N I 2 T N I 3 T N I N T N I 2 I 3 I N . . . . . . . . . . . . . . . . . . . . . . . . . . . Fig . 1 . The framework of our method . ( a ) Collections of human and AI paintings . ( b ) Combining latent embeddings with computational aesthetics features including color , edge , and composition metrics to extract features of paintings . ( c ) Four - pronged analyses based on the extracted features , including latent embedding clustering , distribution discrepancy measurement , aesthetic feature comparison , and evolutionary analysis . model [ 56 ] . Specifically , the CLIP model is a contrastive language - image pretrained model which maps texts and images data to a high dimensional latent space ( in our work , the dimension of the space is set to be 512 ) . As illustrated in [ 56 ] , the latent space embedding model is pretrained on an enormous dataset of over 400 million image - text pairs crawled from publicly available resources online . To achieve better integration of visual features and higher level semantic features , the model adopts a two - step transformation in training and in subsequent feature extraction shown in Equations ( 1 ) - ( 4 ) . In training , the first step is to separately extract visual ( ğ¼ ğ‘“ ) and textual ( ğ‘‡ ğ‘“ ) features from image - text pairs ( ğ¼ , ğ‘‡ ) with an image encoder and a text encoder . The text encoder is a Transformer Neural Network [ 68 ] , while the image encoder is a Vision Transformer Neural Network [ 17 ] . The outputs of the first step are two high dimensional vectors ( ğ¼ ğ‘“ , ğ‘‡ ğ‘“ ) corresponding to visual features and semantic features respectively . In the second step , two linear transformation ( ğ‘Š ğ‘– , ğ‘Š ğ‘¡ ) are added to map the image visual feature vectors and text semantics vectors to a common high dimensional space . The training relies on alignment of the visual features and semantic features in the common space through a contrastive learning approach with multi - class n - pair loss objective [ 62 ] . Subsequently , the pretrained model can be applied to new images to extract latent space representations which contain rich features with both visual and semantic information . ğ¼ ğ‘“ = ğ‘–ğ‘šğ‘ğ‘”ğ‘’ _ ğ‘’ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ ( ğ¼ ) , ğ‘‡ ğ‘“ = ğ‘¡ğ‘’ğ‘¥ğ‘¡ _ ğ‘’ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ ( ğ‘‡ ) , ( 1 ) ğ¼ ğ‘’ = ğ‘Š ğ‘– Â· ğ¼ ğ‘“ âˆ¥ ğ‘Š ğ‘– Â· ğ¼ ğ‘“ âˆ¥ 2 , ğ‘‡ ğ‘’ = ğ‘Š ğ‘¡ Â· ğ‘‡ ğ‘“ âˆ¥ ğ‘Š ğ‘¡ Â· ğ‘‡ ğ‘“ âˆ¥ 2 . ( 2 ) Computational aesthetics . In order to gain more interpretable insights into the similarity and difference between human and AI paintings , we design a number of computational aesthetic features based on previous studies [ 19 , 34 , 38 , 43 ] and our own knowledge . The features include four aspects of aesthetics , as follows . ( 1 ) Color : We consider various color features including brightness , hue and saturation follow - ing [ 43 ] . We adopt the HSL ( hue - H , saturation - S , lightness - L ) color space to represent colors and calculate color features . Specifically , for brightness we compute the mean brightness ğµ ğ‘šğ‘’ğ‘ğ‘› and brightness contrast features ğµ ğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ = ğ¿ ğ‘šğ‘ğ‘¥ âˆ’ ğ¿ ğ‘šğ‘–ğ‘› . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 6 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng For hue we compute the mean hue , hue contrast , major hue , major hue ratio , and hue histogram . Particularly , the hue contrast are computed as ğ» ğ‘ğ‘œğ‘›ğ‘¡ğ‘Ÿğ‘ğ‘ ğ‘¡ = ğ‘šğ‘ğ‘¥ ( âˆ¥ ğ» ( ğ¼ ğ‘¥ , ğ‘¦ ) âˆ’ ğ» ( ğ¼ ğ‘¥ â€² , ğ‘¦ â€² ) âˆ¥ ) , ( 3 ) where âˆ¥ Â· âˆ¥ denotes the arc - length distance on the hue wheel . For the hue histogram , we discretize the hue wheel into 60 bins and count the number of pixels in each bin . Based on this hue histogram , we also compute the major hue and major hue ratio . For saturation we calculate the mean saturation as ğ‘† ğ‘šğ‘’ğ‘ğ‘› = 1 ğ‘‹ğ‘Œ âˆ‘ï¸ ğ‘¥ âˆ‘ï¸ ğ‘¦ ğ‘† ( ğ¼ ğ‘¥ , ğ‘¦ ) . ( 4 ) In addition , as in [ 43 ] , for the focus region which is located in the center of the canvas with one - third the height and width of the whole image , we calculate the mean brightness , hue as well as saturation . ( 2 ) Image quality : Features on image quality include sharpness and entropy . The sharpness is calculated by first modeling the current image as the Gaussian blurring result of a hypothetical image ğ¼ ğ‘  with the best sharpness quality and then inverting the Gaussian blurring model ( ğº ğœ ) with Fast Fourier Transform ( FFT ) [ 43 ] . ğ¼ ğ‘ = ğº ğœ âˆ— ğ¼ ğ‘  , ğ¹ = ğ¹ğ¹ğ‘‡ ( ğ¼ ğ‘ ) , ( 5 ) ğ¶ = { ( ğ‘¢ , ğ‘£ ) | | ğ¹ ( ğ‘¢ , ğ‘£ ) | > ğœƒ } , ğ‘†â„ğ‘ğ‘Ÿğ‘ğ‘›ğ‘’ğ‘ ğ‘  = âˆ¥ ğ¶ âˆ¥ âˆ¥ ğ¼ ğ‘ âˆ¥ , ( 6 ) The entropy features are calculated as spatial entropy ğ¸ ğ‘  , which is a no - reference indicator of image quality [ 45 ] . ğ¸ ğ‘  = âˆ’ âˆ‘ï¸ ğ‘¥ , ğ‘¦ ğ‘“ ( ğ‘¥ , ğ‘¦ ) ğ‘™ğ‘œğ‘” 2 ğ‘“ ( ğ‘¥ , ğ‘¦ ) , ( 7 ) where ğ‘“ ( ğ‘¥ , ğ‘¦ ) denotes the relative frequency at position ( ğ‘¥ , ğ‘¦ ) . ( 3 ) Edge : The edge features are indicators of stroke distribution . First , edges are extracted by combining Gaussian filter ğº ğœ ( ğœ is set to 1 ) to remove noise with Laplacian filter to detect edges . The Gaussian filter can be written as the following matrix . Thus , the edge detection results ğ¼ ğ‘’ is the output of the composed transformation of Gaussian filter ğº ğœ with Laplacian filter applied to image ğ¼ . ğ¼ ğ‘’ = ğ¿ğ‘ğ‘ğ‘™ğ‘ğ‘ğ‘–ğ‘ğ‘› âˆ— ğº ğœ ( ğ¼ ) , ( 8 ) Then , based on the detection results , three features are computed , including the bounding box area and edge area of 81 % of total edge energy , along with the mean edge energy ratio , which means ratio of pixels higher than mean edge energy . The 81 % threshold is set according to previous study [ 43 ] . The bounding box area âˆ¥ ğµ âˆ¥ and the edge area âˆ¥ ğ‘… ğ‘’ âˆ¥ are respectively the smallest rectangle area and the smallest irregular shape area enclosing most edge energy ( a threshold of 81 % ) . 1 (cid:205) | ğ¼ ğ‘’ ( ğ‘¥ , ğ‘¦ ) | âˆ‘ï¸ ( ğ‘¥ , ğ‘¦ ) âˆˆ ğ´ | ğ¼ ğ‘’ ( ğ‘¥ , ğ‘¦ ) | = 0 . 81 ( 9 ) where ğ´ = ğµ or ğ´ = ğ‘… ğ‘’ . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 7 The mean edge energy ratio is the ratio of pixels with above average edge energy . ğ¸ ğ‘šğ‘’ğ‘ğ‘› âˆ’ ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ = âˆ¥ ğ¸ ğ‘š âˆ¥ ğ‘‹ğ‘Œ ( 10 ) where ğ¸ ğ‘š = { ( ğ‘¥ , ğ‘¦ ) | | ğ¼ ğ‘’ ( ğ‘¥ , ğ‘¦ ) | > | ğ¼ ğ‘’ | } . ( 4 ) Composition : Following [ 43 ] , the composition features are obtained by first segmenting the image into major regions and calculate spatial distribution features of the top 3 largest regions , including positions of the mass center for the region , and the spatial variance which measures how wide the region spreads and skewness which measures the asymmetry of the region . For the segmentation step , we adopt K - means clustering method to group similar pixels into regions and set the maximum number of regions to be 8 . After the segmentation , we compute the x and y coordinates of mass center as well as the variance and skewness features for the top 3 regions , as follows . ğ‘‹ ğ‘– = 1 âˆ¥ ğ‘… ğ‘– âˆ¥ âˆ‘ï¸ ( ğ‘¥ , ğ‘¦ ) âˆˆ ğ‘… ğ‘– ğ‘¦ , ğ‘Œ ğ‘– = 1 âˆ¥ ğ‘… ğ‘– âˆ¥ âˆ‘ï¸ ( ğ‘¥ , ğ‘¦ ) âˆˆ ğ‘… ğ‘– ğ‘¦ , ( 11 ) ğ‘‰ğ‘ğ‘Ÿ ğ‘– = âˆ‘ï¸ ( ğ‘¥ , ğ‘¦ ) âˆˆ ğ‘… ğ‘– ( ğ‘¥ âˆ’ ğ‘‹ ğ‘– ) 2 + ( ğ‘¦ âˆ’ ğ‘Œ ğ‘– ) 2 âˆ¥ ğ‘… ğ‘– âˆ¥ , ğ‘†ğ‘˜ğ‘’ğ‘¤ ğ‘– = âˆ‘ï¸ ( ğ‘¥ , ğ‘¦ ) âˆˆ ğ‘… ğ‘– ( ğ‘¥ âˆ’ ğ‘‹ ğ‘– ) 3 + ( ğ‘¦ âˆ’ ğ‘Œ ğ‘– ) 3 âˆ¥ ğ‘… ğ‘– âˆ¥ , ( 12 ) where ğ‘… ğ‘– denotes the ğ‘– ğ‘¡â„ region and âˆ¥ ğ‘… ğ‘– âˆ¥ denotes the area of the region . 3 . 2 Analysis and Visualization Analysis . We conduct comparative analysis of different distributions of human and AI paintings in both the neural latent space and aesthetic distributions , calculate the importance of each feature for cluster separation , and perform evolutionary analysis of individual human artist compared to AI . ( 1 ) Latent embedding clustering : We adopt the cosine distance as the distance metric for the em - bedding vectors . This metric is not sensitive to the variance of magnitude in high dimensional sparse vectors , easy to interpret , and frequently used for information retrieval [ 15 , 51 ] . To facilitate more visual understanding of the distribution and reveal the clustering patterns , we also employ dimension reduction techniques such as t - SNE [ 67 ] , MDS [ 13 ] and PCA [ 71 ] to project the high dimensional embedding vectors onto a human readable 2 - D plane . ( 2 ) Distribution discrepancy measurement : Subsequently , based on our distance metric , we further compute maximum mean discrepancy [ 20 ] , for pairwise dataset discrepancy measurement . In the following equation , ğ‘š , ğ‘š â€² are independent samples from the first distribution ; ğ‘› , ğ‘› â€² are independent samples from the second distribution ; ğ‘˜ ( Â· , Â· ) is a positive definite kernel ( in our work we use Gaussian Kernel ) ; ğ¸ denotes expectation . The maximum mean discrepancy ğ· satisfies ğ· 2 = ğ¸ [ ğ‘˜ ( ğ‘š , ğ‘š â€² ) + ğ‘˜ ( ğ‘› , ğ‘› â€² ) âˆ’ 2 ğ‘˜ ( ğ‘š , ğ‘› ) ] ( 13 ) where ğ‘˜ ( ğ‘š , ğ‘› ) = ğ‘’ âˆ’âˆ¥ ğ‘š âˆ’ ğ‘› âˆ¥ 2 2 ğœ 2 . ( 3 ) Aesthetic feature comparison : Similar to the latent space distribution , we first study their distribution on dataset level . For each feature , we compute its mean and variance in each dataset . We also compute and show histograms of feature distribution , using contrastive histograms [ 21 ] to allow for direct visual comparison of the feature distribution on two datasets or clusters . Next , to identify salient features distinguishing human and AI paintings , we adopt a tree - based feature selection method with a Random Forest classifier . Specifically , we compute the feature importance based on mean decrease in impurity [ 37 ] . The impurity J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 8 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng a b c Fig . 2 . Our visual exploration system . ( a ) Latent embedding overview shows the distribution of images in different human and AI painting collections . ( b ) Aesthetic features view shows the collection level distribution of aesthetic features . ( c ) Instance Detail view shows the feature statistics of selected individual painting . is a measure of how well a node in decision tree can classify the data , which is defined as the class impurity , namely the probability of getting two samples of different classes under the node . Then feature importance is measured by the decrease of mean impurity in the tree after adding nodes corresponding to a feature . ğ¼ğ‘šğ‘ğ‘¢ğ‘Ÿğ‘–ğ‘¡ğ‘¦ = 1 âˆ’ ğ‘ âˆ‘ï¸ ğ‘˜ = 1 ğ‘ 2 ğ‘˜ , ( 14 ) where ğ‘ ğ‘˜ denotes the probability for the ğ‘˜ ğ‘¡â„ class . ( 4 ) Evolutionary analysis : Finally , in order to provide a relatively fair comparison between AI and individual human artist , we focus on the aspect of evolution . We first collect an individual human artistâ€™s works and arrange them in chronological order . Then , we use AI ( Stable Diffusion ) to imitate each painting by inputting the same descriptive title and the style of the artist . Next , we extract the features of both the artistâ€™s works and AIâ€™s works as described in 3 . 1 . Finally , we calculate and visualize the temporal evolutionary patterns of human artistâ€™s evolution relative to AI in both latent space and aesthetic feature space . Visualization . We further build an interactive visualization system ( Figure 2 ) for the exploration of human and AI paintings . The system mainly consists of three parts : 1 ) Embedding Overview showing the latent space distribution ; 2 ) Aesthetic Features View comparing the aesthetic feature distribution of human and AI painting collections ; 3 ) Instance Detail View displaying specific feature statistics of individual painting . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 9 ( 1 ) Embedding Overview : As shown in Figure 2 ( a ) , this view allows users to observe the latent space distribution based on the projection of latent space embedding illustrated in Section 3 . 2 . The painting data are visualized in a scatterplot with color encoding the collections . The default projection method is t - SNE , which better preserves the high dimensional cluster structure . To assist further exploration of local neighborhood detail , we introduce several interactions . Users can perform lasso filtering to focus on a region of data points . In addition , zooming and panning interactions enable users to easily navigate the projection space . Finally , visual query allows users to mouse over specific data point and inspect image detail in the Instance Detail View . ( 2 ) Aesthetic Features View : In this view ( Figure 2 ( b ) ) , users can intuitively explore the results of aesthetic feature comparison in contrastive histograms as explained in Section 3 . 2 . Users can select specific aspects of aesthetic features including color , edge , quality and composition . They can also select which collections of human and AI paintings to compare . Furthermore , this view is coordinated with the Embedding Overview through interactions , where the feature histograms will respond to the lasso filtering in the overview and show the distribution in the subset . ( 3 ) Instance Detail View : This view displays the aesthetic statistics of specific data instance ( Figure 2 ( c ) ) . Apart from showing the image of the painting and the feature values , we also design a circular color histogram to intuitively show the color palette used in the painting . Specifically , we combine histogram with the hue ring by turning the bars into trapesoids pointing towards the center of the ring and color the bars with the corresponding hues . 4 RESULTS 4 . 1 Datasets We collect human and AI painting datasets for comparitive analysis from a wide range of sources . Most of the human painting datasets come from open - source collections provided by previous studies on computational aesthetics and generative art , including : â€¢ WikiArt Emotion ( WikiEmo ) [ 52 ] contains more than 4 , 100 pieces of paintings from four western styles ( Renaissance Art , Post - Renaissance Art , Modern Art , and Contemporary Art ) , which are annotated with emotions evoked in the observer for emotion analysis . â€¢ SemArt [ 22 ] contains paintings collected from the Web Gallery of Art ( https : / / wga . hu / ) , a website archiving European fine art between the 8th and the 19th century . To facilitate semantic analysis of paintings , the dataset is annotated with several attributes such as title , author and school along with a short artistic comment for each painting . â€¢ Deviant dataset is constructed by the authors through crawling the online Deviant Art gallery https : / / deviantart . com / that contain modern artworks posted since 2000 . There are few openly available datasets of artworks generated by AI , so we construct our AI painting datasets with two different approaches . â€¢ The first approach is crawling the artworks created by users on several popular AI art plat - forms featuring the latest text to image AI art technology . The platforms include Midjourney ( https : / / midjourney . com / ) , Stability AI ( https : / / stability . ai / ) , NightCafe ( https : / / nightcafe . studio / ) , and ArtBreeder ( https : / / artbreeder . com / ) . â€¢ The second approach is feeding the prompt data shared by AI painting users into specific models such as stable diffusion [ 59 ] and vary the generation results by tweaking random seed and step parameters of the models . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 10 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng ( a ) ( b ) ( c ) A I P a i n t i n g s H u m a n P a i n t i n g s AI Paintings Human Paintings AI Paintings Human Paintings SemArt 1 . 2 1 . 0 0 . 8 0 . 6 0 . 4 0 . 2 Maximum Mean Discrepancy WikiEmo Deviant Midjourney Stable NightCafe SemArt W i k i E m o Deviant Midjourney Stable NightCafe All Human Paintings vs . AI Paintings Modern Human Paintings vs . AI Paintings T e s t A cc u r a c y 100 % 90 % 80 % 70 % 60 % 50 % 40 % 30 % 20 % 10 % SVMRFNN 0 % Fig . 3 . Comparison of human and AI paintings via neural latent embeddings . ( a ) The latent space overview shows a clear cluster separation between human and AI paintings . ( b ) Maximum mean discrepancies of distributional differences among the datasets . The modern digital painting collection of Deviant shows much closer to AI paintings than other collections of traditional human paintings . ( c ) Classification accuracy of support vector machine ( SVM ) , random forest ( RF ) and neural network ( NN ) on all human vs . AI paintings , and modern human vs . AI paintings . 4 . 2 Categorical Comparison of Human and AI Paintings Does there exist any difference between human and AI paintings ? If so , what are the differences ? Observations on isolated cases alone cannot provide convincing insights . Instead , we shed light on this question by comparing numerous AI paintings created by popular AI art platforms with human paintings from a global distribution perspective . Neural Latent Embeddings Aspect : As shown in Figure 3 , we first represent painting images in neural latent space , which is a high dimensional vector space storing the implicit data embeddings extracted by neural networks . Figure 3 ( a ) shows the embeddings projected onto a 2 - D plane with t - SNE dimension reduction [ 67 ] . One may observe a clear separation between collections of AI paintings in cool colors and human paintings in warm colors . It is also apparent that Deviant paintings a modern digital painting dataset , are relatively closer to AI paintings compared to other collections of more traditional human paintings . To quantitatively verify these differences , we calculate the distributional difference in the latent space between these datasets . Using maximum mean discrepancy ( MMD ) metric , which is a statistic indicating the distance between a pair of distributions , we compute the dissimilarity between each pair of datasets . Figure 3 ( b ) shows the results of pairwise MMD between the datasets , which are consistent with the overview as in J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 11 M e a n e n t r o p y S h a r p n e ss BB X a r e a E dg e a r e a M e a n e dg e e n e g y r a t i o S k e w n e ss 3 V a r i a n c e 3 S k e w n e ss 2 V a r i a n c e 2 V a r i a n c e 1 M e a n y 3 M e a n x 3 M e a n y 2 M e a n x 2 M e a n y 1 M a j o r hu e r a t i o M a j o r hu e H u e c o n t r a s t M e a n s a t u r a t i o n M e a n hu e F o c u s s a t u r a t i o n F o c u s b r i g h t n e ss B r i g h t n e ss c o n t r a s t M e a n b r i g h t n e ss F o c u s hu e M e a n x 1 S k e w n e ss 1 0 . 00 Quality Edge Composition Color 0 . 05 0 . 10 0 . 15 0 . 20 ( a ) Edge Area : 0 . 36 Sharpness : 0 . 89 Edge Area : 0 . 41 Sharpness : 0 . 24 Edge Area : 0 . 43 Sharpness : 0 . 68 ( c ) ( b ) 0 . 250 . 200 . 150 . 100 . 050 . 00 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 Edge area Focus hue 0 . 15 0 . 10 0 . 05 0 . 00 0 50 100 150 AI Human AI Human Midjourney Deviant SemArt Fig . 4 . Comparison of human and AI paintings via aesthetic feature analysis . ( a ) Feature importance of various aesthetic features for classifying AI and human paintings . ( b ) Classification features like edge area and hue of a focus region both show divergent distributions in human and AI paintings . ( c ) Examples of classic ( SemArt ) and modern ( Deviant ) human painted portraits and AI generated ( Midjourney ) portraits , showing differences in features of edge area , sharpness , and hue histogram . Figure 3 ( a ) . In particular , it is evident that Deviant is much closer to AI paintings than other human painting collections . The superiority of neural latent embeddings in revealing the potential discrepancy between human and AI paintings is further demonstrated in Figure 3 ( c ) . Here , we construct three models for classification human and AI paintings , two based on computational aesthetic features , including support vector machine ( SVM ) [ 9 ] and random forest ( RF ) [ 31 ] , and another neural network ( NN ) classification model [ 56 ] based on latent space embeddings . Comparing AI paintings with all human paintings , the classification accuracy of the three models are over 80 % , in which the NN model has the highest accuracy of 95 . 03 % . When only comparing AI paintings with modern digital paintings by humans ( i . e . , Deviant dataset ) , the SVM and RF models based on aesthetic features have noticeable drop in accuracy , while the NN model is much less affected with a high accuracy of 93 . 94 % . The results provide further evidence that modern human digital paintings are closer to AI paintings . This is probably because modern digitized artworks constitute the major source of training data for AI art models , as the models learn from large amounts of open source digital arts [ 57 , 59 ] . Computational Aesthetics Aspect . To further understand the difference , we leverage computational aesthetic features , including those in color , edge and texture , composition , and image quality [ 43 ] , extracted from paintings . We train a RF classifier to separate human and AI paintings based on the features . Using the classifier , we compute feature importance measured on the mean decrease in impurity , which is a measurement of classification certainty of nodes corresponding to specific features in decision trees [ 37 ] . The results of feature importance are presented in Figure 4 ( a ) . Notably , edge features representing lines , strokes and corners in paintings , show highest importance . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 12 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng 0 . 95 0 . 90 0 . 85 0 . 80 0 . 75 S i m il a r i t y t o A I P i c a ss o Year 0 . 70 0 . 65 0 . 60 1890 1902 1910 1917 1925 1934 1941 1949 1958 1967 ( b ) Evolutionary Analysis 1 2 3 4 5 9 6 7 8 1 2 5 4 7 8 0 . 52159 . 4 3 . 28 6 0 . 39242 . 3 3 . 23 9 Edge Area Early BlueRose Cubism Neoclassicism Brightness Contrast Mean Entropy 3 10 0 . 25229 . 5 3 . 11 0 . 35204 . 0 3 . 48 10 4 7 9 8 5 6 2 1 3 AI Picasso Picasso ( a ) Latent Space Comparison AI Picasso Picasso 10 Fig . 5 . Individual artist analysis focusing on Pablo Picasso . ( a ) Latent space overview of real Picassoâ€™s and AI - generated Picasso paintings . ( b ) Temporal illustration of latent space similarity between real Picassoâ€™s and AI - generated Picasso artworks . Real Picassoâ€™s artworks demonstrate a clear trend of style development which is consistent with different periods in the artistâ€™s career , whilst AI - generated Picasso artworks only show small random changes without meaningful style variations . Specifically , edge area and mean energy ratio that characterize the distribution of lines and strokes in paintings dominate the feature importance . Figure 4 ( b - top ) reveals that edge areas in human paintings as a whole are higher than those in AI paintings , indicating human paintings tend to distribute edge energy across a larger proportion of the canvas . This is consistent with human painting process , as lines and strokes are manually drawn by human artists as testimony to the tangible process of human creation . Image quality features , including sharpness and mean entropy , are also important for separating human and AI paintings . This is because AI paintings typically show local defects despite achieving impressive quality in the entire painting . Figure 4 ( c ) shows three example portraits depicting an old man from traditional ( SemArt ) and modern ( Deviant ) human paintings , and AI paintings ( Midjourney ) . The feature statistics show that edge areas of both the traditional and modern old man portraits are slightly higher than that of the AI generated ones . Closer inspection of the edge detection results as in the black - and - white insets reveals more obvious traces of manual strokes in both the foreground and background in human paintings . Moreover , the AI - generated old man portrait displays higher sharpness than the human ones . This is because AI model is good at generating sharp hyper - realistic paintings much like real photos and 3D - rendered images due to the large proportion of realistic images in the training set . Furthermore , we find that human and AI paintings are less distinguishable in composition features and color features . But among the color features , we find interesting patterns in the distribution of focus hue . As illustrated in Figure 4 ( b - bottom ) , focus hues in human paintings tend to be more accumulated in warmer colors , whilst those in AI paintings are richer in color palette with better use of complementary colors . The hue histograms in Figure 4 ( c ) confirms the finding , where human paintings have more focused usage of reds , whilst AI painting are more spread . This reflects that even though AI art has approached human artistsâ€™ use of color palettes , AI paintings still exhibit different statistics from human paintings . 4 . 3 Human Artistsâ€™ Ability to Evolve Compared to AI The difference between human and AI art not only includes latent embedding distributions and aesthetic features of the artworks in general . Human artists are also influenced by many factors , such as political events , technological innovations and personal experience [ 27 , 47 ] in evolving their styles . However , to what extent AI is capable of developing styles like human artists is still J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 13 unknown . In this section , we demonstrate results of a retrospective study which looks back at the development of a famous human artist , Pablo Picasso , in comparison to the same artist in the eyes of AI . This culminates in an attempt to show evidence of human artistsâ€™ irreplaceable capability of evolving new styles . Picasso in AI vs real Picasso . We first zoom in on the famous Post - Impressionism artist Pablo Picasso who invented the unique style of Cubism . To compare the artist with AI art , we collect more than 1 , 000 authentic artworks of the artist with meta - data , including title and time of each work . Then , we use the same title and time information together with the name of the artist to construct prompts to generate AI artworks . Subsequently , we measure the difference between the real Picassoâ€™s and AI - generated artworks by measuring the distance in latent space . Figure 5 ( a ) presents the comparison of real Picassoâ€™s and AI - generated Picasso paintings in the latent space . Generally , real Picasso paintings and AI Picasso paintings form separable clusters that are separable . Nevertheless , some real Picasso paintings are closer to AI , such as artworks 8 and 9 , which are Picassoâ€™s late styles . To discover more detailed patterns of the difference , we further analyze the evolution of Picassoâ€™s style over time , by organizing real Picassoâ€™s works in years , and generating AI paintings using the corresponding prompts with the same artist name , artwork title , and year information for one representative work in each year . The blue line in Figure 5 ( b ) shows the latent space similarity of real Picassoâ€™s artworks , while the orange line shows the variance of AIâ€™s Picasso artworks , both to the centroid of AI - generated Picasso artworks . The comparison clearly shows a trend in the real Picassoâ€™s development of his unique styles during his long creative career . Particularly , Picasso in the eyes of AI is closer to the later Cubism works of Picasso , where he shows his full - fledged artistic persona . In contrast , the AI synthetic works of Picasso given the same topic and time information only shows a random fluctuating pattern close to the best - known Cubism style . A closer look at the trend for the real Picassoâ€™s artworks reveals the artistâ€™s style evolution and confirms the art history : â€¢ Early Period : At the beginning of Picassoâ€™s career , starting from 1890 to around 1894 , one can see a noticeable drop in similarity . Interestingly , this coincides with the earliest period when he learned to paint and his earliest work in 1890 is even closer to his final style than those after four years of training . As the artist puts it , â€œIt took me four years to paint like Raphael , but a lifetime to paint like a child . â€ This drop represents a shift from the beginner towards the accomplished skills in Realism [ 11 ] . One representative work of this period is The First Communion , 1896 ( Figure 5 ( b - 1 ) ) . Created at the age of 14 , this work shows great mastery of academic realism which is distinct from the better known styles of Picasso . â€¢ Blue Period : A more interesting finding is that the first turning point and upward trend almost exactly match the formation of his first unique style , the Blue Period , partially influenced by the suicide of his friend Casagemas . During this period , Picasso first traveled to Paris where he met many artist friends but lived under extremely poor conditions [ 11 ] . He gradually developed a sombre style in his Blue Period , exemplified by the work La Vie ( Life ) , 1903 ( Figure 5 ( b - 2 ) ) [ 70 ] . â€¢ Rose Period : A short span of fluctuation that follows the Blue Period exactly corresponds to the Rose Period [ 70 ] , which features more optimistic tones and warmer colors as he met Fernande Olivier and became famous among collectors [ 50 , 64 ] . One of the representative artworks in this period is Au Lapin Agile ( At the Lapin Agile ) , 1905 ( Figure 5 ( b - 3 ) ) . â€¢ Cubism Period : The works of Blue and Rose Periods mark the deviation from the early Realism and the influence of Symbolism which leads to the development of Picassoâ€™s signature style : Cubism . This development is almost perfectly represented by the upward trend in the line chart between mid - 1890s and 1910 . A transition from the Rose Period to the Cubism Period J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 14 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng Data Model Images Collect Control ( a ) Current AI art process ( b ) Photography process Select Real World Camera Photos Explore Control Select Fig . 6 . The comparison of current AI art process and Photography process . ( a ) In AI art , humans only play a peripheral role in creation process . Specifically , users are limited by the insufficient data and the uninterpretable AI model which allows for little artistsâ€™ involvement in aesthetic details . These limitations in the process lead to the limitations in generated results , including the lack of stimulus and personality , the lack of semantics , and the lack of order and layers . ( b ) In photography , despite the use of cameras , humans still play a central role . The professional photographers can explore more possibilities in the real world and have more intuitive aesthetic control in the process . can be seen from artworks of Les Demoiselles dâ€™Avignon ( The Young Ladies of Avignon ) , 1907 ( Figure 5 ( b - 4 ) ) to Girl with a Mandolin , 1910 ( Figure 5 ( b - 5 ) ) . However , Picasso did not settle for a fixed style in the remaining years of his career . â€¢ Neoclassicism Period : Another profoundly intriguing finding is that a significant drop in the line chart near the end of the first world war ( 1917 ) matches Picassoâ€™s Neoclassicism Period when he echoed other artistsâ€™ desire to return to order after the devastating war [ 7 ] . A typical work in this period is Acrobat , 1922 ( Figure 5 ( b - 6 ) ) . â€¢ World War II and Post - war Period : Subsequently , around the time of the Second World War , influenced by the Surrealists who praised him as a pioneer of Surrealism in art , Picasso revived his interest in Cubism [ 58 ] . A famous work in this period is Guernica , 1937 ( Figure 5 ( b - 7 ) ) . The following years of his career is generally getting closer to the Picasso in AI . A noticeable shift is that his artworks of Cubism became more colourful [ 55 ] , which is a typical feature of AI generated Picasso artworks . An example of the late years of Picasso is Woman Sitting in Armchair , 1962 ( Figure 5 ( b - 8 ) ) . In comparison , AI - generated Picasso paintings are all in one similar style , with small random fluctuations . For example , Figure 5 ( b - 9 ) is AI - generated portrait of an acrobat , which is clearly Picassoâ€™s signature Cubism , but AI can hardly generate Picassoâ€™s other styles like Neoclassicism . Figure 5 ( b - 10 ) is AI - generated painting of Guernica , which looks typical of the Cubism style and similar to the real Picassoâ€™s Guernica . However , there still exist finer aesthetic differences as shown in Figure 5 and discussed below . The aesthetic features of real Picassoâ€™s works compared to AI Picassoâ€™s works also reveal inter - esting patterns . For example , consistent with our findings in Section 4 . 2 , given the same content ( Figure 5 ( b - 6 ) , ( b - 9 ) are portraits of an acrobat , and Figure 5 ( b - 7 ) , ( b - 10 ) are depiction of Guernica ) , AI - generated Picasso paintings has smaller values in edge area feature compared to real Picassoâ€™s works . Again , the difference indicates a clearer trace of human artistsâ€™ manual rendering of paint - ings stroke by stroke . Interestingly , in real Picassoâ€™s works ( e . g . Figure 5 ( b - 6 ) , ( b - 7 ) ) , there is a noticeable trend of decreasing edge area as he developed more abstract Cubism style which is closer to AI generated Picasso paintings . This is consistent with the latent space evolutionary pattern and testify to the more simplistic usage of strokes in Cubism to stress the outline of shapes . In addition , Picassoâ€™s works also show a tendency of increasing brightness contrast , which is also a characteristic of AI - generated Picasso paintings . The higher brightness contrast indicate bolder J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 15 attempt to emphasize the sense of space with lighting effects . Furthermore , in the mean entropy feature , we find that the real Picassoâ€™s works tend to have higher value , which reflects the higher complexity of the human artistsâ€™ works compared to AI - generated ones . Notably , even in later period of Picassoâ€™s career when he mostly focused on more abstract Cubism with simpler strokes , he did not decrease the overall visual complexity of the paintings , which shows the artistâ€™s superior control of details compared to AI . Overall , the aesthetic features of real Picassoâ€™s works show significant changes consistent with the artistâ€™s development shown in Figure 5 , while the features of AI - generated works only change randomly within a small range . 5 DISCUSSION This section presents a summary of current AI artâ€™s limitations based on the revealed results ( Section 5 . 1 ) . On the basis , we further discuss artistsâ€™ perspectives on AI art and how AI developers can improve AI models ( Section 5 . 2 ) with more consideration of aesthetics and artistsâ€™ concerns . 5 . 1 Limitations of AI Art When AI art has raised panic among many human artists , some artists and critics are happy to embrace this new technology . They often compare AI art to other innovations in the history of human art , such as photography , film and digital art tools like Adobe Photoshop [ 28 ] . Artists who fear or even boycott AI art are compared to old - fashioned artists who could only mimic reality before camera was invented . However , there are significant limitations in the process of current AI art which makes the comparison with photography invalid . Figure 6 shows a comparison of the current AI art process and photography process . In current AI art , at the beginning , huge amount of human artwork data is required for the AI to learn . Unfortunately , due to the sheer volume of data required to train AI , it is difficult for any individual user to control the quality of data and address the insufficiency problem , which can severely limit the exploration space of AI art . In comparison , in photography , artists can observe not just existing artworks , but also the real world with infinite possibilities to be explored . Next , in the central part of the current AI art process , humans control the model by entering text prompts and tuning model parameters . But such control is highly limited because of the uninterpretable black - box AI model and the insufficient involvement of human artists in creating the aesthetics . In contrast , despite using a camera , photographers are fully aware and in control of what aesthetic features they can create intentionally , such as the subtle manipulation of lighting , focus and perspective [ 3 ] . AI art only allows users to have full control in the final selection of generated images , but this makes them more of curators than artists as they can do little about the deficiencies in the results caused by the limitations in the process . In detail , the current AI art process is limited in the following aspects . â€¢ Insufficient data : A fundamental issue of the current AI art is insufficient data . As AI learns how to create artworks from the human art data fed into the model , the generation results heavily depend on the data . However , the data used in the current AI art is insufficient in two important aspects . First , the data is limited to only digital images of art . For traditional art - works , there is always an original physical version which need to be scanned for digitization . The scanning process causes significant loss of information about the unique features of the artworks . In addition , different scanning devices and conditions also cause diverging results . The AI art model learning from such data inevitably fail to capture the full aesthetic values of traditional artworks . This observation can be supported by our results in Figure 3 , where we show AI learns modern digital paintings better than traditional paintings . Second , the data J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 16 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng suffer from bias or insufficient coverage , which means it contains more samples from some categories than others . This can cause the AI art model to unfairly favor particular styles , genres or other categories , eventually limiting the possibilities of creation . For example , our results in Section 4 . 3 show that AI art model focus too much on the Cubism style while ignoring Picassoâ€™s other styles in his early career . Furthermore , the bias can also perpetuate existing discrimination in human art , such as unfair representation of females or minorities . â€¢ Uninterpretable AI models . Human artists have a logical and transparent creative process which links concepts and ideas to the aesthetic features of artworks . In contrast , AI art relies on black - box neural network approximating a probability distribution with uninterpretable parameters which are difficult to associate with aesthetic values . For example , as shown in Section 4 . 3 , the AI - generated Picasso paintings only show some random variations without meaningful patterns . In fact , the control parameters of the AI art models such as random seed and step of diffusion do not have any understandable artistic meaning . Therefore , given only the text prompts describing the high - level content , it is a mystery how the model execute the idea and produce the final visual form of art . â€¢ Insufficient artistsâ€™ involvement . The current AI art is focused on providing simple end - to - end generation for laymen users with little knowledge and training in art . But there is little consideration of how to involve human artists in this new creation pipeline . The biased distribution shown in Figure 3 is partly due to the usersâ€™ lack of knowledge about the bigger picture of diverse styles in art history , which limits most of their creation to the popular modern digital art styles . The deficiencies in some aesthetic features ( Figure 4 ) can also be attributed to this phenomenon . The insufficient involvement of human artists can prohibit the acceptance of AI art in art community , limit the usability of AI art tools in professional art making , and impede the development of AI art . Because of the limitations in the process of current AI art , there are significant limitations in the results as follows . â€¢ Lack of stimulus and personality . The AI - generated artworks lack stimulus and personality , which are nuanced but important aesthetic aspects besides the technical competence of AI art [ 35 ] . This can in turn lead to lower evaluation of AI artworks compared to human - created ones [ 32 ] . For example , emotions are an important stimulus which influences or even inspires human artistsâ€™ creation process [ 6 ] . However , AI art does not have any emotions in the generation process because its objective is to output images with similar visual effects to previous human artworks based on superficial description of content . Thus , AI art is ignorant of the emotions and motivations behind the artworks . The observation can be supported by our results ( Figure 5 ) , which show how Picassoâ€™s styles are influenced by different events in his life , primarily his love life , while the current AI technology has no way to understand or learn the emotional effects in human artistsâ€™ works . In addition , Picassoâ€™s personality as a pacifist is also a driving factor behind the work Guernica , which is a masterpiece that AI can only partially imitate , as shown in our results . This results in a disconnection between the creative inspiration and the visual appearance of art , which is detrimental for the creation of meaningful artworks from human experience . â€¢ Lack of semantics . As AI art adopts a statistical learning framework , it does not recognize objects or understand their relationships in a scene . According to Gestalt theory which has been applied to analysis of visual art [ 1 , 5 ] , instead of simple accretion of isolated visual elements , art requires creative vision which put together different elements logically and organically into a whole ; and the appearance of any single object depends on its place and function in an overall structural pattern . Human artworks contain expression of aesthetics J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 17 from deliberate control of such structural relations by artist through clear reasoning and understanding of semantics . In comparison , AI art has no way to prioritize the objects and emphasize one over another , let alone dealing with other subtle semantic relations . Consequently , AI art model cannot distinguish Realism and Abstraction styles . In particular , as shown in our results ( Figure 5 ) the styles of Neoclassicism ( more realistic style ) and Cubism ( more abstract style ) are not well distinguished . Thus , the generation results are highly uncertain with few satisfactory outcomes when contents are sophisticated . â€¢ Lack of meaningful order and layers . Human artists have coherent order of creation ( e . g . in strokes ) [ 69 ] and logical separation of different layers like foreground and background , which is not adequately addressed in current AI art models . Our results also show evidence for this , particularly in the gap in stroke features ( Figure 4 ) . This discrepancy can lead to deficiencies of AI art in fine - grained details which are hardly noticeable by common users but obvious to professional artists . For example , the spatial and temporal distribution of strokes and white space [ 19 ] are often deliberately created by artists to achieve better aesthetic experience such as rhythm in paintings . But AI art still cannot capture such elaborate aesthetic features . 5 . 2 Perspectives In this section , we further discuss the perspectives of artists and AI developers respectively , shedding light on the implications on art community and the directions for improving AI art . Perspectives for Artist . AI art is a new technology for the art community with incredible potential . However , our results and the discussion of AI artâ€™s limitations indicate that a completely optimistic perspective is not without flaws , providing justification for some artistsâ€™ concerns on AI art . â€¢ Positive . On one hand , AI art can bring some benefits to artists and art lovers , including inspiration , reduced workload and increased accessibility of art creation . First , artists can get inspirations from the diverse images generated by AI because of its randomness which can provide new perspectives and help artists break away from their familiar genre , style and techniques . Some artists even comment that they can find interesting combination of styles they have not seen before . Second , artists can reduce artistsâ€™ workload especially in some tedious and redundant part of creation . For example , for some artists who mainly focus on color instead of strokes to express their aesthetics , they can expect that a more sophisticated AI can separate the tasks and finish the sketching and tracing but leave the coloring to them . Third , AI can increase the accessibility of art creation as it allows art lovers without much professional training in art to bring their creative ideas to life . For example , writers with little painting skill can use AI art to produce beautiful visual illustrations of the scenes in their stories to create more engaging visual novels . â€¢ Negative . On the other hand , AI art also have detrimental impact on artists . The first problem is the incomplete artistic process in AI art . The users of AI art like to claim that they have provided artistic ingenuity through the prompts describing the content , and the selection process after the generation of paintings . However , from artistsâ€™ perspective , the incomplete artistic process as shown in Figure 6 is particularly concerning . This is because in photography and traditional visual art , an important common step in the central part of artistic process is the artist deliberately creating association between the high level content description and the aesthetic features of the artworks . For more evidence , we can refer to several studies in the field of neuroaesthetics on human art creation process , including archival and real - life case studies [ 49 , 63 , 75 ] . Particularly , in a real - life study comparing artist and nonartist brain activity in artistic process using fMRI [ 63 ] , the artist showed higher activation in the right - middle frontal area of the brain , an area responsible for more complex associations , J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 18 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng manipulation of visual forms , and planning of the fine motor responses of the hands . Such association is further enhanced by the interactive prototyping process of sketching in human artistsâ€™ workflow [ 18 , 47 ] . Sketching provides visual cues â€œon the flyâ€ for the association of structural and functional issues associated with the artifact being developed , which does not exists in AI art either . Even the specially designed sketch to image AI technology [ 10 ] consider sketches as only inputs to machine learning models and lack understanding of the artistâ€™s evolution of sketch in art making process . Such visual association and prototyping are erased by the AI art process , which deprives users of the chance to truly create their original works expressing their own aesthetics . This can even cause the loss of artistic talent if increasing number of people adopt the incomplete AI art process . The second problem is the devaluation of artists and their works . As AI art can easily generate large number of superficially beautiful artworks in seconds , professional artistsâ€™ hard work may be devalued by AI users who have hardly spend any effort in art practice . To make matter worse , many artistsâ€™ works are fed into AI models to make similar - looking cheap replicates without their permission . Such abuse of AI art even causes some artists to worry about their livelihood . Novice artists may also be intimidated by the grim prospect and want to give up their career . â€¢ Use AI art with caution . AI art provides a kind of mechanical generator which can finish most of the workload on behalf of users like a free tool instead of a human artist who charges for commission . All the users need to do is contributing to a small part of artistic effort , namely specifying the content and high - level features by prompt engineering . This can drastically speed up the ideation and prototyping process for content designers . But artists should be aware of the disadvantages before they rush to jump on the bandwagon . With so many limitations and concerns as we discussed , artists should not become too dependent on AI art unless better solutions are developed . Perspectives for AI Developers . At the same time , for AI developers , it is important to take into consideration the limitations and artistsâ€™ concerns to improve AI art . â€¢ Model : Aesthetics - aware detail improvement . Our results have shown that AI art can still improve or get closer to human art by refining aesthetic details like strokes . Other aesthetic details that are less quantifiable include the anatomy of figures in portraits , most notably the structure of hands , which is a well - known weakness of AI art . Generally , to improve these details , there are two approaches . The first is to build additional specialized training data to fine - tune the model . For example , some AI developers are trying to improve hand details by collecting specialized training data for hands . The second is to introduce some inductive constraints into the model such as changing model architecture or designing additional loss functions to optimize performances on specific features . For example , to improve similarity to human works on edge features , edge detection transformation such as Laplacian filter or Hough transform can be incorporated into the model . â€¢ Data : Solutions to the data issues . In terms of the data , two major issues of concern need to be addressed : transparency and bias . The transparency issue is concerning for artists as many of them are worried that their works are fed into AI model to train the model without permission and credits . This may discourage human artists from creating and sharing their works for fear of being plagiarized by AI users who exploit their works to produce thousands of similar artworks . Therefore , AI art should be more transparent about the specific data it is trained on to give due credit to the original art creators . Regarding the issue of bias in training data , AI researchers can alleviate the problem by applying debiasing methods used in other multi - modal AI tasks . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 19 â€¢ Involvement : Better integration of human artists and AI technology . Most importantly , to promote shared prosperity of the future of AI art , more involvement of artists in the process is essential . First , artists need to be more involved in data collection and preparation . As some studies have shown , ordinary people without art training have relatively simple perception and preference of artworks which tend to put high value on mediocre works and lack understanding of artistic originality [ 40 ] . Therefore , AI developers need to enlist more human artistsâ€™ help . For example , as we mentioned above , they need to give enough credits to artists and encourage them to willingly provide their artworks and their evaluation to better tackle insufficiency problem and improve the artistic value of data . Second , developers should introduce more intuitive control parameters and evaluation metrics which are relevant to aesthetics and understandable to human artists . This can help alleviate the uninterpretable model problem shown in Figure 6 . Finally , it is important to develop more steerable AI models which allows artists to have more fine - grained control of aesthetics in all stages of the artistic process , including sketching , tracing , coloring and shadowing . This allows human artists to easily modify the structure and other visual features if they are dissatisfied . For example , in calligraphy and line art , even a single curve or line drawn by human artists have variation of thickness and strength along the trajectory which expresses human emotions and motivations . In coloring process , some human artists would intentionally add small amount of complementary colors in large area of dominant colors to give special flavors to the works . Human control of such fine - grained features should not be erased by AI . For instance , when incorporating sketch control , we can introduce additional loss functions to keep the consistency of stroke width and strength variation features deliberately created by human artists to provide them consistent control throughout the creative process . 6 CONCLUSION In this study , we propose a novel framework to perform large - scale comparative analysis of human and AI paintings by combining the power of both neural latent space and computational aesthetics with visualization . Using this framework , we compare human and AI paintings on large scale collection level and individual artist level . We discover distributional difference between human and AI painting collections in both latent space and aesthetic features . Furthermore , we provide some quantitative evidence supporting human artistâ€™s superior ability to evolve compared with AI . We finally discuss the implications of these findings on the development of AI art , particularly in terms of how AI can better cooperate with human artists in the future . REFERENCES [ 1 ] Rudolf Arnheim . 1969 . Art and visual perception : A psychology of the creative eye . University of California Press . [ 2 ] TunÃ§ Ozan AydÄ±n , Aljoscha Smolic , and Markus Gross . 2014 . Automated aesthetic analysis of photographic images . IEEE Transactions on Visualization and Computer Graphics 21 , 1 ( 2014 ) , 31 â€“ 42 . [ 3 ] Bruce Barnbaum . 2017 . The art of photography : a personal approach to artistic expression . Rocky Nook , Inc . [ 4 ] Benjamin B Bederson . 2001 . PhotoMesa : a zoomable image browser using quantum treemaps and bubblemaps . In Proceedings of the ACM Symposium on User Interface Software and Technology . 71 â€“ 80 . [ 5 ] Roy R Behrens . 1998 . Art , design and gestalt theory . Leonardo 31 , 4 ( 1998 ) , 299 â€“ 303 . [ 6 ] Marion Botella , Vlad Glaveanu , Franck Zenasni , Martin Storme , Nils Myszkowski , Marion Wolff , and Todd Lubart . 2013 . How artists create : Creative process and multivariate factors . Learning and Individual Differences 26 ( 2013 ) , 161 â€“ 170 . [ 7 ] Benjamin HD Buchloh . 1981 . Figures of authority , ciphers of regression : notes on the return of representation in European painting . October ( 1981 ) , 39 â€“ 68 . [ 8 ] Eva Cetinic , Tomislav Lipic , and Sonja Grgic . 2020 . Learning the principles of art history with convolutional neural networks . Pattern Recognition Letters 129 ( 2020 ) , 56 â€“ 62 . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 20 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng [ 9 ] Chih - Chung Chang and Chih - Jen Lin . 2011 . LIBSVM : a library for support vector machines . ACM Transactions on Intelligent Systems and Technology 2 , 3 ( 2011 ) , 1 â€“ 27 . [ 10 ] Wengling Chen and James Hays . 2018 . SketchyGAN : Towards Diverse and Realistic Sketch to Image Synthesis . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 9416 â€“ 9425 . [ 11 ] Juan Eduardo Cirlot . 1972 . Picasso : birth of a genius . Praeger . [ 12 ] Daniel Cohen - Or , Olga Sorkine , Ran Gal , Tommer Leyvand , and Ying - Qing Xu . 2006 . Color harmonization . In Proceedings of ACM SIGGRAPH . 624 â€“ 630 . [ 13 ] Michael AA Cox and Trevor F Cox . 2008 . Multidimensional scaling . In Handbook of Data Visualization . 315 â€“ 347 . [ 14 ] Gabriella Csurka , Christopher Dance , Lixin Fan , Jutta Willamowski , and CÃ©dric Bray . 2004 . Visual categorization with bags of keypoints . In Proceedings of the European Conference on Computer Vision Workshops . [ 15 ] Inderjit S Dhillon and Dharmendra S Modha . 2001 . Concept decompositions for large sparse text data using clustering . Machine Learning 42 , 1 ( 2001 ) , 143 â€“ 175 . [ 16 ] Ao Dong , Wei Zeng , Xi Chen , and Zhanglin Cheng . 2019 . VIStory : Interactive storyboard for exploring visual informa - tion in scientific publications . In Proceedings of the International Symposium on Visual Information Communication and Interaction . 1 â€“ 8 . [ 17 ] AlexeyDosovitskiy , LucasBeyer , AlexanderKolesnikov , DirkWeissenborn , XiaohuaZhai , ThomasUnterthiner , Mostafa Dehghani , Matthias Minderer , Georg Heigold , Sylvain Gelly , et al . 2021 . An image is worth 16x16 words : Transformers for image recognition at scale . In Proceedings of International Conference on Learning Representations . [ 18 ] Claudia Eckert and Martin Stacey . 2003 . Adaptation of sources of inspiration in knitwear design . Creativity Research Journal 15 , 4 ( 2003 ) , 355 â€“ 384 . [ 19 ] ZhenBao Fan , Kang Zhang , and XianJun Sam Zheng . 2019 . Evaluation and analysis of white space in Wu Guanzhongâ€™s Chinese paintings . Leonardo 52 , 2 ( 2019 ) , 111 â€“ 116 . [ 20 ] Robert Fortet and Edith Mourier . 1953 . Convergence de la rÃ©partition empirique vers la rÃ©partition thÃ©orique . In Annales Scientifiques de lâ€™Ã‰cole Normale SupÃ©rieure , Vol . 70 . 267 â€“ 285 . [ 21 ] Takanori Fujiwara , Oh - Hyun Kwon , and Kwan - Liu Ma . 2019 . Supporting analysis of dimensionality reduction results with contrastive learning . IEEE Transactions on Visualization and Computer Graphics 26 , 1 ( 2019 ) , 45 â€“ 55 . [ 22 ] Noa Garcia and George Vogiatzis . 2018 . How to read paintings : semantic art understanding with multi - modal retrieval . In Proceedings of the European Conference on Computer Vision Workshops . [ 23 ] Leon A Gatys , Alexander S Ecker , and Matthias Bethge . 2016 . Image style transfer using convolutional neural networks . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 2414 â€“ 2423 . [ 24 ] Ian Goodfellow , Jean Pouget - Abadie , Mehdi Mirza , Bing Xu , David Warde - Farley , Sherjil Ozair , Aaron Courville , and Yoshua Bengio . 2020 . Generative adversarial networks . Commun . ACM 63 , 11 ( 2020 ) , 139 â€“ 144 . [ 25 ] Yi Gu , Chaoli Wang , Jun Ma , Robert J Nemiroff , and David L Kao . 2015 . iGraph : a graph - based technique for visual analytics of image and text collections . In Proceedings of the Conference on Visualization and Data Analysis . 53 â€“ 67 . [ 26 ] IshaanGulrajani , FarukAhmed , MartinArjovsky , VincentDumoulin , andAaronCCourville . 2017 . Improvedtrainingof Wasserstein GANs . In Proceedings of the International Conference on Neural Information Processing Systems . 5769 â€“ 5779 . [ 27 ] Richard B Gunderman and C Matthew Hawkins . 2008 . The self - portraits of Frida Kahlo . Radiology 247 , 2 ( 2008 ) , 303 â€“ 306 . [ 28 ] Aaron Hertzmann . 2018 . Can computers create art ? Arts 7 , 2 ( 2018 ) , 18 : 1 â€“ 25 . [ 29 ] Martin Heusel , Hubert Ramsauer , Thomas Unterthiner , Bernhard Nessler , and Sepp Hochreiter . 2017 . GANs trained by a two time - scale update rule converge to a local Nash equilibrium . In Proceedings of the International Conference on Neural Information Processing Systems . 6629 â€“ 6640 . [ 30 ] Jonathan Ho , Ajay Jain , and Pieter Abbeel . 2020 . Denoising diffusion probabilistic models . Proceedings of the International Conference on Neural Information Processing Systems 33 ( 2020 ) , 6840 â€“ 6851 . [ 31 ] Tin Kam Ho . 1998 . The random subspace method for constructing decision forests . IEEE Transactions on Pattern Analysis and Machine Intelligence 20 , 8 ( 1998 ) , 832 â€“ 844 . [ 32 ] Joo - Wha Hong and Nathaniel Ming Curran . 2019 . Artificial intelligence , artists , and art : attitudes toward artwork produced by humans vs . artificial intelligence . ACM Transactions on Multimedia Computing , Communications , and Applications 15 , 2s ( 2019 ) , 1 â€“ 16 . [ 33 ] Edward J Hu , Yelong Shen , Phillip Wallis , Zeyuan Allen - Zhu , Yuanzhi Li , Shean Wang , Lu Wang , and Weizhu Chen . 2021 . LoRA : Low - rank adaptation of large language models . arXiv preprint arXiv : 2106 . 09685 ( 2021 ) . [ 34 ] Kiyohito Iigaya , Sanghyun Yi , Iman A Wahle , Koranis Tanwisuth , and John P Oâ€™Doherty . 2021 . Aesthetic preference for art can be predicted from a mixture of low - and high - level visual features . Nature Human Behaviour 5 , 6 ( 2021 ) , 743 â€“ 755 . [ 35 ] Thomas Jacobsen . 2006 . Bridging the arts and sciences : A framework for the psychology of aesthetics . Leonardo 39 , 2 ( 2006 ) , 155 â€“ 162 . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . Everyone Can Be Picasso ? A Computational Framework into the Myth of Human versus AI Painting 111 : 21 [ 36 ] Tero Karras , Samuli Laine , and Timo Aila . 2019 . A style - based generator architecture for generative adversarial networks . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition . 4401 â€“ 4410 . [ 37 ] Jalil Kazemitabar , Arash Amini , Adam Bloniarz , and Ameet S Talwalkar . 2017 . Variable importance using decision trees . In Proceedings of the International Conference on Neural Information Processing Systems . 425 â€“ 434 . [ 38 ] Yan Ke , Xiaoou Tang , and Feng Jing . 2006 . The design of high - level features for photo quality assessment . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 419 â€“ 426 . [ 39 ] Diederik P Kingma and Max Welling . 2013 . Auto - encoding variational bayes . arXiv preprint arXiv : 1312 . 6114 ( 2013 ) . [ 40 ] Aaron Kozbelt . 2006 . Dynamic evaluation of Matisseâ€™s 1935 large reclining nude . Empirical Studies of the Arts 24 , 2 ( 2006 ) , 119 â€“ 137 . [ 41 ] Afshan Latif , Aqsa Rasheed , Umer Sajid , Jameel Ahmed , Nouman Ali , Naeem Iqbal Ratyal , Bushra Zafar , Saadat Hanif Dar , MuhammadSajid , andTehminaKhalil . 2019 . Content - basedimageretrievalandfeatureextraction : acomprehensive review . Mathematical Problems in Engineering 2019 ( 2019 ) . [ 42 ] Yann LeCun , Yoshua Bengio , and Geoffrey Hinton . 2015 . Deep learning . Nature 521 , 7553 ( 2015 ) , 436 â€“ 444 . [ 43 ] Congcong Li and Tsuhan Chen . 2009 . Aesthetic visual quality assessment of paintings . IEEE Journal of Selected Topics in Signal Processing 3 , 2 ( 2009 ) , 236 â€“ 252 . [ 44 ] Yuan Liang , Xiting Wang , Song - Hai Zhang , Shi - Min Hu , and Shixia Liu . 2017 . PhotoRecomposer : Interactive photo recomposition by cropping . IEEE Transactions on Visualization and Computer Graphics 24 , 10 ( 2017 ) , 2728 â€“ 2742 . [ 45 ] Lixiong Liu , Bao Liu , Hua Huang , and Alan Conrad Bovik . 2014 . No - reference image quality assessment based on spatial and spectral entropies . Signal Processing : Image Communication 29 , 8 ( 2014 ) , 856 â€“ 863 . [ 46 ] Yang Liu , Eunice Jun , Qisheng Li , and Jeffrey Heer . 2019 . Latent space cartography : Visual analysis of vector space embeddings . In Computer Graphics Forum , Vol . 38 . 67 â€“ 78 . [ 47 ] Paul J Locher . 2010 . How does a visual artist create an artwork . The Cambridge Handbook of Creativity ( 2010 ) , 131 â€“ 144 . [ 48 ] Luca Marchesotti , Florent Perronnin , Diane Larlus , and Gabriela Csurka . 2011 . Assessing the aesthetic quality of photographs using generic image descriptors . In Proceedings of the IEEE / CVF International Conference on Computer Vision . 1784 â€“ 1791 . [ 49 ] Joshua Chang Mell , Sara M Howard , and Bruce L Miller . 2003 . Art and the brain : the influence of frontotemporal dementia on an accomplished artist . Neurology 60 , 10 ( 2003 ) , 1707 â€“ 1710 . [ 50 ] James R Mellow . 2003 . Charmed circle : Gertrude Stein and company . Macmillan . [ 51 ] Tomas Mikolov , Ilya Sutskever , Kai Chen , Greg S Corrado , and Jeff Dean . 2013 . Distributed representations of words and phrases and their compositionality . In Proceedings of the International Conference on Neural Information Processing Systems . 3111 â€“ 3119 . [ 52 ] Saif Mohammad and Svetlana Kiritchenko . 2018 . WikiArt Emotions : An annotated dataset of emotions evoked by art . In Proceedings of the International Conference on Language Resources and Evaluation . 1225 â€“ 1238 . [ 53 ] Giang P Nguyen and Marcel Worring . 2008 . Interactive access to large image collections using similarity - based visualization . Journal of Visual Languages and Computing 19 , 2 ( 2008 ) , 203 â€“ 224 . [ 54 ] Masashi Nishiyama , Takahiro Okabe , Imari Sato , and Yoichi Sato . 2011 . Aesthetic quality classification of photographs based on color harmony . In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 33 â€“ 40 . [ 55 ] Patrick Oâ€™Brian . 1994 . Picasso : A biography . WW Norton & Company . [ 56 ] Alec Radford , Jong Wook Kim , Chris Hallacy , Aditya Ramesh , Gabriel Goh , Sandhini Agarwal , Girish Sastry , Amanda Askell , Pamela Mishkin , Jack Clark , et al . 2021 . Learning transferable visual models from natural language supervision . In Proceedings of the International Conference on Machine Learning . 8748 â€“ 8763 . [ 57 ] Aditya Ramesh , Prafulla Dhariwal , Alex Nichol , Casey Chu , and Mark Chen . 2022 . Hierarchical text - conditional image generation with clip latents . arXiv preprint arXiv : 2204 . 06125 ( 2022 ) . [ 58 ] John Richardson . 2021 . A Life of Picasso IV : The Minotaur Years : 1933 - 1943 . Knopf Publishing Group . [ 59 ] Robin Rombach , Andreas Blattmann , Dominik Lorenz , Patrick Esser , and BjÃ¶rn Ommer . 2022 . High - resolution image synthesis with latent diffusion models . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition . 10684 â€“ 10695 . [ 60 ] TimSalimans , IanGoodfellow , WojciechZaremba , VickiCheung , AlecRadford , andXiChen . 2016 . Improvedtechniques for training GANs . In Proceedings of the International Conference on Neural Information Processing Systems . 2234 â€“ 2242 . [ 61 ] Xi Shen , Alexei A Efros , and Mathieu Aubry . 2019 . Discovering visual patterns in art collections with spatially - consistent feature learning . In Proceedings of the IEEE / CVF Conference on Computer Vision and Pattern Recognition . 9278 â€“ 9287 . [ 62 ] Kihyuk Sohn . 2016 . Improved deep metric learning with multi - class n - pair loss objective . In Proceedings of the International Conference on Neural Information Processing Systems . 1857 â€“ 1865 . [ 63 ] Robert L Solso . 2001 . Brain activities in a skilled versus a novice artist : An fMRI study . Leonardo 34 , 1 ( 2001 ) , 31 â€“ 34 . [ 64 ] Arianna Stassinopoulos and Arianna Stassinopoulos Huffington . 1988 . Picasso : Creator and destroyer . Simon & Schuster . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 . 111 : 22 Yilin Ye , Rong Huang , Kang Zhang , and Wei Zeng [ 65 ] Grant Strong and Minglun Gong . 2011 . Similarity - based image organization and browsing using multi - resolution self - organizing map . Image and Vision Computing 29 , 11 ( 2011 ) , 774 â€“ 786 . [ 66 ] Hsiao - Hang Su , Tse - Wei Chen , Chieh - Chi Kao , Winston H Hsu , and Shao - Yi Chien . 2012 . Preference - aware view recommendation system for scenic photos based on bag - of - aesthetics - preserving features . IEEE Transactions on Multimedia 14 , 3 ( 2012 ) , 833 â€“ 843 . [ 67 ] Laurens Van der Maaten and Geoffrey Hinton . 2008 . Visualizing data using t - SNE . Journal of Machine Learning Research 9 , 11 ( 2008 ) . [ 68 ] Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Åukasz Kaiser , and Illia Polosukhin . 2017 . Attention is all you need . In Proceedings of the International Conference on Neural Information Processing Systems . 6000 â€“ 6010 . [ 69 ] Zeyu Wang , Sherry Qiu , Nicole Feng , Holly Rushmeier , Leonard McMillan , and Julie Dorsey . 2021 . Tracing versus freehand for evaluating computer - generated drawings . ACM Transactions on Graphics 40 , 4 ( 2021 ) , 1 â€“ 12 . [ 70 ] Richard J Wattenmaker and Albert Coombs Barnes . 1993 . Great French paintings from the Barnes Foundation : impres - sionist , post - impressionist , and early modern . Alfred a Knopf Incorporated . [ 71 ] Svante Wold , Kim Esbensen , and Paul Geladi . 1987 . Principal component analysis . Chemometrics and Intelligent Laboratory Systems 2 , 1 - 3 ( 1987 ) , 37 â€“ 52 . [ 72 ] Xiao Xie , Xiwen Cai , Junpei Zhou , Nan Cao , and Yingcai Wu . 2018 . A semantic - based method for visualizing large image collections . IEEE Transactions on Visualization and Computer Graphics 25 , 7 ( 2018 ) , 2362 â€“ 2377 . [ 73 ] Yilin Ye , Rong Huang , and Wei Zeng . 2022 . VISAtlas : An Image - based Exploration and Query System for Large Visualization Collections via Neural Image Embedding . IEEE Transactions on Visualization and Computer Graphics ( 2022 ) , 1 â€“ 15 . [ 74 ] Ka - Ping Yee , Kirsten Swearingen , Kevin Li , and Marti Hearst . 2003 . Faceted metadata for image search and browsing . In Proceedings of the ACM CHI Conference on Human Factors in Computing Systems . 401 â€“ 408 . [ 75 ] Sawako Yokochi and Takeshi Okada . 2005 . Creative cognitive process of art making : A field study of a traditional Chinese ink painter . Creativity Research Journal 17 , 2 - 3 ( 2005 ) , 241 â€“ 255 . [ 76 ] Lvmin Zhang and Maneesh Agrawala . 2023 . Adding conditional control to text - to - image diffusion models . arXiv preprint arXiv : 2302 . 05543 ( 2023 ) . [ 77 ] Jun - Yan Zhu , Taesung Park , Phillip Isola , and Alexei A Efros . 2017 . Unpaired image - to - image translation using cycle - consistent adversarial networks . In Proceedings of the IEEE / CVF International Conference on Computer Vision . 2223 â€“ 2232 . J . ACM , Vol . 37 , No . 4 , Article 111 . Publication date : August 2018 .