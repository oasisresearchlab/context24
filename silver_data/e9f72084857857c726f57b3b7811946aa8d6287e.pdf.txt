AfriKI : Machine - in - the - Loop Afrikaans Poetry Generation Imke van Heerden Dept . of Comparative Literature College of Social Sciences and Humanities Koc¸ University , Istanbul , Turkey ivanheerden @ ku . edu . tr Anil Bas Dept . of Computer Engineering Faculty of Technology Marmara University , Istanbul , Turkey anil . bas @ marmara . edu . tr Abstract This paper proposes a generative language model called AfriKI . Our approach is based on an LSTM architecture trained on a small cor - pus of contemporary ﬁction . With the aim of promoting human creativity , we use the model as an authoring tool to explore machine - in - the - loop Afrikaans poetry generation . To our knowledge , this is the ﬁrst study to attempt cre - ative text generation in Afrikaans . 1 Introduction Afrikaans 1 is a language spoken largely in South Africa , Namibia , Botswana and Zimbabwe . Masakhane ( ∀ et al . , 2020a , b ) draws important at - tention to the current disproportion of NLP research and resources with respect to African languages . In fact , in the entire ACL Anthology , 2 of the thir - teen studies that mention “Afrikaans” in their titles , only four ( Sanby et al . , 2016 ; Augustinus et al . , 2016 ; Dirix et al . , 2017 ; Ralethe , 2020 ) appeared in the last ﬁve years . By no means do we ignore studies with inclusive ( Eiselen and Puttkammer , 2014 ) and multilingual approaches ( Ziering and Van der Plas , 2016 ) or those published via other platforms ( Van Zaanen and Van Huyssteen , 2003 ) . This is simply an indication that NLP research in Afrikaans is limited , especially in comparison to resource - rich languages , i . e . the so - called “winners” in the taxonomy of Joshi et al . ( 2020 ) . In this paper , we present a generative lan - guage model called AfriKI , an abbreviation for “Afrikaanse Kunsmatige Intelligensie” ( Afrikaans 1 The Constitution of the Republic of South Africa recog - nises Afrikaans as one of eleven ofﬁcial languages , alongside Sepedi , Sesotho , Setswana , siSwati , Tshivenda , Xitsonga , En - glish , isiNdebele , isiXhosa and isiZulu ( Assembly , 1996 ) . In South Africa , there are approximately 6 . 9 million ﬁrst - language speakers of Afrikaans , according to the most recent census ( Lehohla , 2012 ) . 2 https : / / www . aclweb . org / anthology / Artiﬁcial Intelligence ) . We use this model as an authoring tool to explore machine - in - the - loop poetry generation in Afrikaans . Machine - in - the - loop frameworks promote human creativity through computational assistance , as opposed to human - in - the - loop pipelines , which aim to strengthen ma - chine learning models ( Clark et al . , 2018 ) . We treat poetry generation as a hybrid system , an ex - perimental approach that enables the generation of high - quality poetic text with very limited data . To our knowledge , this is the ﬁrst study in creative text generation as well as an initial step towards automatic poetry generation in Afrikaans . Whereas NLG in its quest for full automation may frown upon human involvement , our human - centred framework does the opposite . According to Lubart ( 2005 ) , one criticism of artiﬁcial intelligence pro - grams that claim to be creative is exactly that a human plays a role at some point , which reduces the autonomy of the ma - chine . From the HCI perspective [ . . . ] these “failed” AI creativity programs are examples of successful human – computer interactions to facilitate creativity . This study demonstrates that human - machine collaboration could enhance human creativity . We agree with Shneiderman ( 2002 ) that support tools “make more people more creative more often” . 2 Related Work Several computational models focus on automatic poetry generation . First approaches follow rule - based , template - based systems ( Gerv´as , 2001 ; D´ıaz - Agudo et al . , 2002 ) . Levy ( 2001 ) and Ma - nurung et al . ( 2012 ) apply genetic algorithms while Jiang and Zhou ( 2008 ) and He et al . ( 2012 ) use sta - tistical machine translation , with Yan et al . ( 2013 ) utilising text summarisation to generate poetry . a r X i v : 2103 . 16190v1 [ c s . C L ] 30 M a r 2021 Oliveira ( 2009 ) provides a clear overview of early systems and presents a comparable method ( 2012 ) . Starting with Zhang and Lapata ( 2014 ) , we have seen great advancements in poetry generation using neural networks . Wang et al . ( 2016a ) extend this using the attention mechanism ( Bahdanau et al . , 2015 ) . There are many attempts to improve the quality of learning - based generated poetry , by us - ing planning models ( Wang et al . , 2016b ) , ﬁnite - state machinery ( Ghazvininejad et al . , 2016 ) , re - inforcement learning ( Yi et al . , 2018 ) as well as variational autoencoders ( Yang et al . , 2018 ) . Conventional recurrent neural networks ( RNN ) are not suitable for learning long range depen - dencies ( Wang et al . , 2016a ) due to the vanish - ing gradient problem ( Bengio et al . , 1994 ) . Long short - term memory ( LSTM ) networks ( Hochreiter and Schmidhuber , 1997 ) address this issue and are widely used for language modeling ( Sunder - meyer et al . , 2012 ) . Tikhonov and Yamshchikov ( 2018 ) propose word - based LSTM to generate po - etry . Potash et al . ( 2015 ) adopt a similar technique to produce rap lyrics . Zugarini et al . ( 2019 ) apply syllable - based LSTM to generate tercets . Finally , composed of various LSTM models , Deep - speare ( Lau et al . , 2018 ) generates Shakespearean sonnets . The remarkable quality and results of these stud - ies are indisputable . However , they all concentrate on data - rich languages such as English , Chinese , Italian and Russian . For example , the character lan - guage model of Hopkins and Kiela ( 2017 ) uses a poetry corpus consisting of 7 . 56 million words and 34 . 34 million characters . Likewise , a recent study by Liu et al . ( 2020 ) trained on over 200 thousand poems and 3 million ancient Chinese prose texts . We trained an LSTM network for poetic text gen - eration as well . However , our approach differs in signiﬁcant ways . First , whereas these studies gen - erate verse in a fully automatic manner , we empha - sise human creativity , introducing a strong compu - tational component to the creative writing process . Second , the aforementioned studies either trained on comprehensive poetry datasets or model poetic qualities . To illustrate the latter , the recent work of Van de Cruys ( 2020 ) focuses on speciﬁcally non - poetic text in English and French , however , is able to model the rhyme constraint using phonetic rep - resentation of words from Wiktionary . Since there is no publicly available large - scale poetry dataset in Afrikaans , we follow an alternative approach , constructing our model as a text generator that pro - Figure 1 : Frequently occurring words in Die Biblioteek aan die Einde van die Wˆereld . Stop words were re - moved . Note that Ian and Thuli are the protagonists . duces individual sentences and phrases instead of stanzas of verse . In other words , the model outputs a set of lines , which we arrange vertically into short poems without modiﬁcation . 3 Model In this section , we explain the dataset , model archi - tecture as well as the co - creative poetry generation process . Corpus : AfriKI trained on a lengthy ( 208 , 616 - word ) literary novel titled Die Biblioteek aan die Einde van die Wˆereld ( The Library at the End of the World ) ( Van Heerden , 2019 ) by the South African novelist Etienne van Heerden . In 2020 , the book was awarded the University of Johannesburg Prize for Literature ( Pienaar , 2020 ) . This work of new journalism combines ﬁctional techniques with documentary language , and is particularly suitable given its use of rich imagery , ﬁgurative language as well as different Afrikaans varieties like Kaaps ( or Cape Afrikaans ) and Standard Afrikaans . Figure 1 shows a word cloud of its most commonly used words . Model Architecture : Experimenting with sev - eral architectures , including LSTM , Multi - Layer LSTM and Bi - LSTM , we obtain best results with the following two - layer LSTM architecture . We use a vanilla LSTM structure ( Hochreiter and Schmidhuber , 1997 ) and , to avoid repetitiveness , omit to describe the network diagram and equa - tions , similar to Sundermeyer et al . ( 2012 ) . We start with 100 - dimensional word embeddings with a vocabulary size of 23 , 317 words , where weights are randomly initialised from a normal distribu - tion with zero mean and standard deviation 0 . 01 . Next , we stack two LSTM layers with 50 units in each layer followed by dropout layers with the Original ( Afrikaans ) Translation ( English ) Die konstabel se skiereiland The constable’s peninsula Afrika drink Africa drinks onheil in die water . disaster in the water . Die landskap kantel sy rug The landscape tilts its back in sigbewaking en vlam . in surveillance and ﬂame . Ons oopgesnyde sake Our cut - open affairs brandtrappe vir die ander state . ﬁre escapes for other states . Hierdie grond word intimidasie . This soil becomes intimidation . Gedigte , daar by die brul van ’n brander Poetry , there near the roar of a wave Hier is die o¨e katvoet vir Here the eyes are cautious of die spoelrotse onder uitdrukkings the sea rocks under expressions die golwe van gister wat the waves of yesterday that getol en woes en water whirled and wild and water saam met die son skuim in hul woorde froth with the sun in their words die ingedagte see the introspective sea lig die geure en praat lifts the scents and utters ’n asemhaal a breath Kaapstad Cape Town Vandag is ons nie net die stad nie Today we are not just the city maar but die vertaler van die son the translator of the sun Vanaand se gordyne Tonight’s curtains glinster by skuifvensters glitter at sliding windows in die stadsliggies in the city lights Die uur van die winde The hour of the winds sorg dat dit rondom klink takes care it sounds around Sy wil die glasvensters deurkosyn She wants to doorframe the glass windows eens iets te beskerm to protect something Tafelberg Table Mountain maak ’n vraag waarbinne ons creates a question in which we ’n duisend name are given genoem word a thousand names Table 1 : Example results of machine - in - the - loop poetry generation . rate of 0 . 2 . This is followed by a fully connected layer and a softmax layer . We use the Adam opti - miser ( Kingma and Ba , 2015 ) with a learning rate = 0 . 001 , batch size = 16 , and train for 300 epochs . Although tweaking the parameters did change the model performance , it was not signiﬁcant . Machine - in - the - Loop : Human - machine collab - oration for the enhancement of creative writing has been examined under automated assistance ( Roem - mele and Gordon , 2015 , 2018 ) , co - authorship ( Tucker , 2019 ) , co - creativity ( Manjavacas et al . , 2017 ; Kantosalo and Riihiaho , 2019 ; Calderwood et al . , 2020 ) , interactive storytelling ( Swanson and Gordon , 2012 ; Brahman et al . , 2020 ) and machine - in - the - loop ( Clark et al . , 2018 ; Akoury et al . , 2020 ) . Applying Clark et al . ( 2018 ) ’s terminology , we employ an iterative interaction structure that fol - lows a push method of initiation with low intrusive - ness . To clarify , our process consists of a single loop with two stages . First , the model generates a sizable set of unique individual lines ( hundreds ) . Although memory networks may repeat parts of the training data ( Ghazvininejad et al . , 2016 ) , the gen - erated phrases are highly distinct from the dataset , with hardly any repetition of word order . Second , the ﬁrst author responds by choosing phrases at will . To create the ﬁnal artefact , the author ar - ranges the selected lines vertically . Generated text is used strictly without modiﬁcation ( except for some capitalisation and punctuation ) . The result of our collaborative writing system is short , com - pelling works of poetry that draw inspiration from the literary movements Imagism ( Hughes , 1972 ) and Surrealism ( Balakian , 1986 ) . 4 Results Table 1 presents three examples of poems produced by means of the co - creative process . Here , we discuss quality from a literary perspective . Trained on prose , the text is generated as free verse ( i . e . free from the restrictions of rhythm and rhyme ) which we associate with contemporary po - etry . In the lines , various poetic devices can be iden - tiﬁed , such as alliteration ( e . g . “ g olwe van g ister” ) and assonance ( e . g . “m aa k ’n vr aa g w aa rbinne” ) . The generated lines abound with ﬁgurative lan - guage as well . As an instance of an extended metaphor , the ﬁrst stanza of the second poem sug - gests sensitivity to the country’s turbulent history . Personiﬁcation is particularly prevalent , lending a visceral quality to the text : Africa drinks , the landscape tilts its back , the sea breathes , and Ta - ble Mountain poses a question . The imagery is vivid , portraying sight ( Tonight’s curtains / glit - ter at sliding windows / in the city lights ) , smell ( the introspective sea / lifts the scents and utters / a breath ) and sound ( roar of a wave ) . The lan - guage can be described as minimalist , evocative and abstract , and therefore open to interpretation , resembling Imagist and Surrealist poetry . Afrikaans has a rich poetic tradition ( Brink and Opperman , 2000 ) , and we believe that creative text generation has the potential to enrich poetic lan - guage . Alongside Afrikaans varieties , the corpus contains some English as well , which inﬂuenced the generated text in interesting ways . As one ex - ample , it is grammatically incorrect in Standard Afrikaans to use “sun” as both noun and verb , e . g . “to sun in the garden” . The model , however , adopted this and other patterns from the English , generating novel phrases ( that do not sound angli - cised ) such as “sonlig son die promenade” – sun - light suns the promenade . 5 Conclusion In this study , we present Afrikaans poetry gener - ation in a machine - in - the - loop setting . Each and every line of poetry is automatically generated by the proposed LSTM network . In order to clearly identify the machine’s contribution to the process , the human writer’s interaction is limited to the se - lection and vertical arrangement of the lines – with - out any modiﬁcation . We believe this is the ﬁrst creative text generation study in the Afrikaans lan - guage . More broadly , the work encourages human - centred design in low - resource languages . Creative industries would beneﬁt from co - creative tools and methods ( Hsu et al . , 2019 ) , perhaps more than fully automatic approaches . 6 Future Work There are many ways in which this work can be extended . First , similar to Yi et al . ( 2017 ) , we could follow line - to - line poem generation , where the network takes the previous line as prompt and generates a new line which , in turn , is the prompt for the next entry . We could also experiment with different architectures , such as Transformer ( Vaswani et al . , 2017 ) , as well as training schemes . For example , we could borrow AfriBERT ( Ralethe , 2020 ) , the recent BERT ( Devlin et al . , 2019 ) adaptation for Afrikaans , to apply transfer learning . Second , as demonstrated in Van de Cruys ( 2020 ) , poetry generation is also possible by training on prosaic ( non - poetic ) text and modeling poetic con - straints ( e . g . rhyme ) . This way , we could expand to fully automatic poetry generation . Naturally , this would require an extensive literature corpus . Third , regarding the unconventional use of some nouns as verbs in Afrikaans , future research could explore how prevalent this type of novel , cross - language variation is . To improve textual quality , we could incorporate Afrikaans datasets such as the NCHLT Annotated Text Corpora ( Eiselen and Puttkammer , 2014 ; Puttkammer et al . , 2014 ) as well as the Afrikaans treebank ( Augustinus et al . , 2016 ) , which are available via SADiLaR ( Roux , 2016 ) in addition to others . Finally , a promising direction to pursue would be the involvement of poets and writers to investigate whether this approach could inform and improve their creative writing practices . Acknowledgments This paper has been produced beneﬁting from the 2232 International Fellowship for Outstanding Researchers Program of T ¨UB˙ITAK ( Project No : 118C285 ) . However , the entire responsibility of the paper belongs to the owner of the paper . The ﬁnancial support received from T ¨UB˙ITAK does not mean that the content of the publication is approved in a scientiﬁc sense by T ¨UB˙ITAK . We would like to thank Etienne van Heerden for providing his manuscript to be used in this study . References Nader Akoury , Shufan Wang , Josh Whiting , Stephen Hood , Nanyun Peng , and Mohit Iyyer . 2020 . STO - RIUM : A dataset and platform for human - in - the - loop story generation . In Proc EMNLP , pages 6470 – 6484 . Constitutional Assembly . 1996 . Constitution of the Re - public of South Africa . Cape Town , 230 ( 38 ) : 1241 – 1331 . Liesbeth Augustinus , Peter Dirix , Daniel Van Niek - erk , Ineke Schuurman , Vincent Vandeghinste , Frank Van Eynde , and Gerhard Van Huyssteen . 2016 . Afri - Booms : An online treebank for Afrikaans . In Proc LREC , pages 677 – 682 . Dzmitry Bahdanau , Kyung Hyun Cho , and Yoshua Bengio . 2015 . Neural machine translation by jointly learning to align and translate . In Proc ICLR . Anna Balakian . 1986 . Surrealism : The Road to the Absolute . University of Chicago Press . Yoshua Bengio , Patrice Simard , and Paolo Frasconi . 1994 . Learning long - term dependencies with gradi - ent descent is difﬁcult . IEEE transactions on neural networks , 5 ( 2 ) : 157 – 166 . Faeze Brahman , Alexandru Petrusca , and Snigdha Chaturvedi . 2020 . Cue me in : Content - inducing approaches to interactive story generation . In Proc AACL - IJCNLP , pages 588 – 597 . Andr´e Philippus Brink and Diederik Johannes Opper - man . 2000 . Groot verseboek 2000 . Tafelberg . Alex Calderwood , Vivian Qiu , Katy Ilonka Gero , and Lydia B Chilton . 2020 . How novelists use genera - tive language models : An exploratory user study . In Proc ACM IUI Workshop . Elizabeth Clark , Anne Spencer Ross , Chenhao Tan , Yangfeng Ji , and Noah A Smith . 2018 . Creative writ - ing with a machine in the loop : Case studies on slo - gans and stories . In Proc ACM IUI , pages 329 – 340 . Tim Van de Cruys . 2020 . Automatic poetry generation from prosaic text . In Proc ACL , pages 2471 – 2480 . Jacob Devlin , Ming - Wei Chang , Kenton Lee , and Kristina Toutanova . 2019 . BERT : Pre - training of deep bidirectional transformers for language under - standing . In Proc NAACL , pages 4171 – 4186 . Bel´en D´ıaz - Agudo , Pablo Gerv´as , and Pedro A Gonz´alez - Calero . 2002 . Poetry generation in COL - IBRI . In Proc ECCBR , pages 73 – 87 . Peter Dirix , Liesbeth Augustinus , Daniel Van Niekerk , and Frank Van Eynde . 2017 . Universal dependen - cies for Afrikaans . In Proc NoDaLiDa , pages 38 – 47 . Roald Eiselen and Martin Puttkammer . 2014 . Develop - ing text resources for ten South African languages . In Proc LREC , pages 3698 – 3703 . ∀ , Wilhelmina Nekoto , Vukosi Marivate , Tshi - nondiwa Matsila , Timi Fasubaa , Taiwo Fagbo - hungbe , Solomon Oluwole Akinola , Shamsud - deen Muhammad , Salomon Kabongo Kabenamualu , Salomey Osei , Freshia Sackey , Rubungo Andre Niyongabo , Ricky Macharm , Perez Ogayo , Ore - vaoghene Ahia , Musie Meressa Berhe , Mofetoluwa Adeyemi , Masabata Mokgesi - Selinga , Lawrence Okegbemi , Laura Martinus , Kolawole Tajudeen , Kevin Degila , Kelechi Ogueji , Kathleen Siminyu , Julia Kreutzer , Jason Webster , Jamiil Toure Ali , Jade Abbott , Iroro Orife , Ignatius Ezeani , Idris Abdulka - dir Dangana , Herman Kamper , Hady Elsahar , Good - ness Duru , Ghollah Kioko , Murhabazi Espoir , Elan van Biljon , Daniel Whitenack , Christopher Onyefu - luchi , Chris Chinenye Emezue , Bonaventure F . P . Dossou , Blessing Sibanda , Blessing Bassey , Ay - odele Olabiyi , Arshath Ramkilowan , Alp ¨Oktem , Adewale Akinfaderin , and Abdallah Bashir . 2020a . Participatory research for low - resourced machine translation : A case study in African languages . In Proc EMNLP , pages 2144 – 2160 . ∀ , Iroro Orife , Julia Kreutzer , Blessing Sibanda , Daniel Whitenack , Kathleen Siminyu , Laura Martinus , Jamiil Toure Ali , Jade Abbott , Vukosi Marivate , Sa - lomon Kabongo , Musie Meressa , Espoir Murhabazi , Orevaoghene Ahia , Elan van Biljon , Arshath Ramk - ilowan , Adewale Akinfaderin , Alp ¨Oktem , Wole Akin , Ghollah Kioko , Kevin Degila , Herman Kam - per , Bonaventure Dossou , Chris Emezue , Kelechi Ogueji , and Abdallah Bashir . 2020b . Masakhane – machine translation for Africa . In Proc ICLR Work - shop . Pablo Gerv´as . 2001 . An expert system for the composi - tion of formal Spanish poetry . In Proc SGES , pages 19 – 32 . Marjan Ghazvininejad , Xing Shi , Yejin Choi , and Kevin Knight . 2016 . Generating topical poetry . In Proc EMNLP , pages 1183 – 1191 . Jing He , Ming Zhou , and Long Jiang . 2012 . Generat - ing Chinese classical poems with statistical machine translation models . In Proc AAAI , volume 26 . Sepp Hochreiter and J¨urgen Schmidhuber . 1997 . Long short - term memory . Neural computation , 9 ( 8 ) : 1735 – 1780 . Jack Hopkins and Douwe Kiela . 2017 . Automatically generating rhythmic verse with neural networks . In Proc ACL , pages 168 – 178 . Ting - Yao Hsu , Yen - Chia Hsu , and Ting - Hao Huang . 2019 . On how users edit computer - generated visual stories . In Proc ACM CHI , pages 1 – 6 . Glenn Hughes . 1972 . Imagism & the Imagists : A Study in Modern Poetry . Biblo & Tannen Publishers . Long Jiang and Ming Zhou . 2008 . Generating Chinese couplets using a statistical MT approach . In Proc COLING , pages 377 – 384 . Pratik Joshi , Sebastin Santy , Amar Budhiraja , Kalika Bali , and Monojit Choudhury . 2020 . The state and fate of linguistic diversity and inclusion in the NLP world . In Proc ACL , pages 6282 – 6293 . Anna Kantosalo and Sirpa Riihiaho . 2019 . Experi - ence evaluations for human – computer co - creative processes – planning and conducting an evaluation in practice . Connection Science , 31 ( 1 ) : 60 – 81 . Diederik P Kingma and Jimmy Ba . 2015 . Adam : A method for stochastic optimization . In ICLR . Jey Han Lau , Trevor Cohn , Timothy Baldwin , Julian Brooke , and Adam Hammond . 2018 . Deep - speare : A joint neural model of poetic language , meter and rhyme . In Proc ACL , pages 1948 – 1958 . Pali Lehohla . 2012 . Census in brief 2011 . Statistics South Africa . Robert P Levy . 2001 . A computational model of poetic creativity with neural network as measure of adap - tive ﬁtness . In Proc ICCBR Workshop . Yusen Liu , Dayiheng Liu , and Jiancheng Lv . 2020 . Deep poetry : A Chinese classical poetry generation system . In Proc AAAI , volume 34 ( 09 ) , pages 13626 – 13627 . Todd Lubart . 2005 . How can computers be partners in the creative process : classiﬁcation and commen - tary on the special issue . International Journal of Human - Computer Studies , 63 ( 4 - 5 ) : 365 – 369 . Enrique Manjavacas , Folgert Karsdorp , Ben Burten - shaw , and Mike Kestemont . 2017 . Synthetic litera - ture : Writing science ﬁction in a co - creative process . In Proc CCNLG , pages 29 – 37 . Ruli Manurung , Graeme Ritchie , and Henry Thompson . 2012 . Using genetic algorithms to create meaning - ful poetic text . Journal of Experimental & Theoreti - cal Artiﬁcial Intelligence , 24 ( 1 ) : 43 – 64 . Hugo Oliveira . 2009 . Automatic generation of poetry : an overview . Universidade de Coimbra . Hugo Gonc¸alo Oliveira . 2012 . PoeTryMe : a versatile platform for poetry generation . Computational Cre - ativity , Concept Invention , and General Intelligence , 1 : 21 . Hans Pienaar . 2020 . Prize - winning novel on # FeesMustFall is a campus of ideas . Business Day . https : / / www . businesslive . co . za / bd / life / books / 2020 - 04 - 09 - book - review - prize - winning - novel - on - feesmustfall - is - a - campus - of - ideas / . Peter Potash , Alexey Romanov , and Anna Rumshisky . 2015 . Ghostwriter : Using an LSTM for automatic rap lyric generation . In Proc EMNLP , pages 1919 – 1924 . Martin Puttkammer , Martin Schlemmer , and Ruan Bekker . 2014 . NCHLT Afrikaans Annotated Text Corpora . South African Centre for Digital Language Resource . https : / / hdl . handle . net / 20 . 500 . 12185 / 296 . Sello Ralethe . 2020 . Adaptation of deep bidirectional transformers for Afrikaans language . In Proc LREC , pages 2475 – 2478 . Melissa Roemmele and Andrew Gordon . 2018 . Lin - guistic features of helpfulness in automated support for creative writing . In Proc ICIDS , pages 14 – 19 . Melissa Roemmele and Andrew S Gordon . 2015 . Cre - ative help : A story writing assistant . In Proc ICIDS , pages 81 – 92 . Justus Roux . 2016 . South African National Centre for Digital Language Resources . In Proc LREC , pages 2467 – 2470 . Lauren Sanby , Ion Todd , and Maria C Keet . 2016 . Comparing the template - based approach to GF : the case of Afrikaans . In Proc WebNLG , pages 50 – 53 . Ben Shneiderman . 2002 . Creativity support tools . Communications of the ACM , 45 ( 10 ) : 116 – 120 . Martin Sundermeyer , Ralf Schl¨uter , and Hermann Ney . 2012 . LSTM neural networks for language model - ing . In Proc INTERSPEECH . Reid Swanson and Andrew S Gordon . 2012 . Say any - thing : Using textual case - based reasoning to enable open - domain interactive storytelling . ACM Transac - tions on Interactive Intelligent Systems , 2 ( 3 ) : 1 – 35 . Aleksey Tikhonov and Ivan Yamshchikov . 2018 . Sounds Wilde : Phonetically extended embeddings for author - stylized poetry generation . In Proc SIG - MORPHON , pages 117 – 124 . Aaron Tucker . 2019 . Machine co - authorship ( s ) via translative creative writing . Journal of Creative Writing Studies , 4 ( 1 ) : 7 . Etienne Van Heerden . 2019 . Die Biblioteek aan die Einde van die Wˆereld . NB - Uitgewers . Menno Van Zaanen and Gerhard Van Huyssteen . 2003 . Improving a spelling checker for Afrikaans . In Proc CLIN , pages 143 – 156 . Ashish Vaswani , Noam Shazeer , Niki Parmar , Jakob Uszkoreit , Llion Jones , Aidan N Gomez , Łukasz Kaiser , and Illia Polosukhin . 2017 . Attention is all you need . In Proc NIPS , pages 6000 – 6010 . Qixin Wang , Tianyi Luo , Dong Wang , and Chao Xing . 2016a . Chinese song iambics generation with neural attention - based model . In Proc IJCAI , pages 2943 – 2949 . Zhe Wang , Wei He , Hua Wu , Haiyang Wu , Wei Li , Haifeng Wang , and Enhong Chen . 2016b . Chinese poetry generation with planning based neural net - work . In Proc COLING , pages 1051 – 1060 . Rui Yan , Han Jiang , Mirella Lapata , Shou - De Lin , Xue - qiang Lv , and Xiaoming Li . 2013 . I , poet : auto - matic Chinese poetry composition through a genera - tive summarization framework under constrained op - timization . In Proc IJCAI . Xiaopeng Yang , Xiaowen Lin , Shunda Suo , and Ming Li . 2018 . Generating thematic Chinese poetry using conditional variational autoencoders with hybrid de - coders . In Proc IJCAI , pages 4539 – 4545 . Xiaoyuan Yi , Ruoyu Li , and Maosong Sun . 2017 . Gen - erating Chinese classical poems with RNN encoder - decoder . In Proc NLP - NABD , pages 211 – 223 . Xiaoyuan Yi , Maosong Sun , Ruoyu Li , and Wenhao Li . 2018 . Automatic poetry generation with mutual re - inforcement learning . In Proc EMNLP , pages 3143 – 3153 . Xingxing Zhang and Mirella Lapata . 2014 . Chinese poetry generation with recurrent neural networks . In Proc EMNLP , pages 670 – 680 . Patrick Ziering and Lonneke Van der Plas . 2016 . To - wards unsupervised and language - independent com - pound splitting using inﬂectional morphological transformations . In Proc NAACL , pages 644 – 653 . Andrea Zugarini , Stefano Melacci , and Marco Maggini . 2019 . Neural poetry : Learning to generate poems using syllables . In Proc ICANN , pages 313 – 325 .