A Novel Hierarchical Discourse Model for Scientific Article and It’s Efficient Top - K Resampling - based Text Classification Approach Abstract — Scientific articles contain rich knowledge that can significantly assists scientific research , but it is difficult to precisely extract knowledge information due to the complexity of the discourse structure of scientific articles . To provide more accurate scientific research knowledge for researchers in a specific academic domain , it is necessary to study the discourse structure of domain scientific articles and to propose an automatic annotation approach to automatically annotate discourse information from articles . Unfortunately , few works have studied the discourse structure of domain scientific articles and the corresponding automatic discourse annotation . To fill this gap , we take scientific articles of the wastewater - based epidemiology domain as a case to study how to automatically and efficiently annotate discourse information . This paper has three contributions . Firstly , we propose a hierarchical discourse model with two layers to cover all potential discourses in various domain scientific articles . Specifically , the first layer defines four core discourse concepts to describe the main process of a scientific research which can be applied in all scientific articles in various domains . The second layer defines fine - granular domain - specific structure , which can accurately describe the entire research contents of a specific domain . Secondly , based on the proposed model , we build a corpus dataset of 100 annotated scientific articles in the wastewater - based epidemiology domain . Thirdly , based on the model and dataset , we propose a simple yet efficient Top - K resampling - based approach to train a more effective classifier for automatic annotation . Extensive experiments verify the effectiveness and efficiency of our proposed hierarchical discourse model and the Top - K resampling - based classification approach . Keywords — discourse , scientific articles , text classification , automatic annotation I . I NTRODUCTION Scientific articles record main process of scientific research for a specific problem in a specific academic domain , which is of great significance to researchers to acquire knowledge , write field reviews , select research topics , and design experiments . Unfortunately , most of the existing information retrieval systems of scientific articles , such as Google Scholar , Web of Science , can only provide retrieval by input meta - data , such as author , journal , and keywords . Although meta - data can provide some information on the publication time , citation , and author cooperation of articles , it is still a challenge to answer the questions about the detailed research content recorded in the articles , for example , what is the research problems of an article . Moreover , these retrieval systems usually return a web page , or a complete document , but it is very time - consuming for domain scientists to read the full text of the document . In order to alleviate the above problems and better assist scientific research , it is necessary to analyze the textual content of scientific articles , i . e . , the discourse . In general , a discourse is a kind of linguistic unit , which consists of a series of consecutive segments or sentences . The segments are cohesion in form and coherence in semantics . In the humanities and social sciences , discourse defines statements about what can be said about a topic . In this sense , the textual content of a scientific article is a discourse . As scientific research has certain commonalities , the writing of scientific papers follows a certain pattern , and the discourse structure of scientific articles can be defined . There have been several efforts that construct discourse models of scientific articles and annotate discourse with the help of human experts or use artificial intelligence approaches to automatically annotate discourse . For example , Argumentative Zoning ( AZ ) [ 1 ] - [ 3 ] is proposed to automatically generate abstract and conduct citation analysis . In addition to defining concepts to describe the content of articles , it pays special attention to the knowledge attribution of discourse segments . Core Information about Scientific Papers ( CISP ) [ 4 ] , [ 5 ] aims to generate abstract and better store and retrieve information , so it designs 12 important concepts of scientific research . SciAnnotDoc [ 6 ] , [ 7 ] decomposes the article discourse into 5 categories which contains Findings , Hypothesis , Methodology , Related Work , and Definition . However , all these works have some shortcomings . ( 1 ) First of all , defining too many discourse concepts prone to conceptual confusion , which may reduce the annotation efficiency or accuracy of experts . Therefore , these models are difficult to be widely applied in various research domains . ( 2 ) Moreover , none of these works Min Gao , Student Member , IEEE , Chun - Hua Chen ( Corresponding Author ) , Member , IEEE , Zhi - Han Gao , Wei - Long Chen , Yuan Ren , Sam Kwong , Fellow , IEEE , and Zhi - Hui Zhan , Senior Member , IEEE ( Corresponding Author ) M . Gao and Z . - H . Zhan are with the School of Computer Science and Engineering , South China University of Technology , 510006 Guangzhou , P . R . China and are also with the Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information , 510006 Guangzhou , P . R . China . Email : zhanapollo @ 163 . com . C . - H . Chen and W . - L . Chen are with the School of Software Engineering , South China University of Technology , 510006 Guangzhou , P . R . China . Email : chunhuachen @ scut . edu . cn . Z . - H . Gao and Y . Ren are with the School of Environment and Energy , South China University of Technology , 510006 Guangzhou , P . R . China . S . Kwong is with the Department of Computer Science , City University of Hong Kong , Hong Kong . This work was supported in part by the National Key Research and Development Program of China under Grant 2019YFB2102102 , in part by the National Natural Science Foundations of China ( NSFC ) under Grant 62176094 and Grant 61873097 , in part by the Key - Area Research and Development of Guangdong Province under Grant 2020B010166002 , and in part by the Guangdong Natural Science Foundation Research Team under Grants 2018B030312003 . 2022 IEEE International Conference on Systems , Man , and Cybernetics ( SMC ) 978 - 1 - 6654 - 5258 - 8 / 22 / $ 31 . 00 ©2022 IEEE 774 2022 I EEE I n t e r n a ti on a l C on f e r e n ce on S y s t e m s , M a n , a nd C yb e r n e ti c s ( S M C ) | 978 - 1 - 6654 - 5258 - 8 / 22 / $ 31 . 00 © 2022 I EEE | DO I : 10 . 1109 / S M C 53654 . 2022 . 9945306 distinguish the vast differences among different domain nor design a finer structure oriented to the specific academic domain . More refined models for specific domains are more valuable . Therefore , we propose a novel hierarchical discourse model of scientific articles that contains two layers . In the first layer , we construct a general discourse model . Different from most of the existing efforts such as CISP [ 4 ] , [ 5 ] , this general discourse model only contains four core concepts that can describe the main research process of scientific research . In the second layer , we further construct the discourse model of scientific articles in a specific domain , which is a further refinement and expansion of the first layer . The advantage of this hierarchical structure mainly include that ( 1 ) it only cares about the most valuable research knowledge recorded in the scientific articles , that is , the research problems , methods , results , and conclusions , therefore , it can be easily applied to various scientific domains ; ( 2 ) it allows domain experts to refine the core concepts of the first layer into the second layer according to the characteristics of domain research , and build domain - specific discourse models , which will not cause conceptual confusion ; ( 3 ) domain - specific discourse models can better meet the actual needs of domain experts , and have higher application value . In our study , we use the articles of the domain of wastewater - based epidemiology ( WBE ) as a case . We have two goals . The first goal is to construct the discourse model of scientific articles for specific scientific domains ( e . g . , in the domain of WBE ) and build the corresponding corpus dataset by annotating scientific articles with the help of domain experts . That is , every sentence of each scientific article is marked with a label by the domain experts of WBE . All these labeled sentences are in different categories and are used to train a multi - label text classifier . Therefore , the second goal is to utilize deep learning approach to train an efficient multi - label text classifier , which can automatically annotate scientific articles . That is , input a scientific article , the trained classifier annotates every sentence of the scientific article into proper categories ( i . e . , with proper labels ) and output the results . In our early primary study for the second goal , we found that many existing multi - label text classification approaches have poor classification performance on this problem with the limited manual annotated data . This is mainly due to that the original labeled data are very imbalanced . Specifically , the number of positive samples of some categories is large , while the number of positive samples in some categories is very small , only a or several dozens . In order to deal with the problem of imbalanced data and better apply deep learning approaches to solve multi - label text classification problem , we propose a simple but effective Top - K resampling - based approach that uses the prediction results of a trained classifier to guide the data quality assessment , and designs a higher - quality resampling approach for data augmentation based on the data quality . Our innovations and contributions are summarized as follow . ( 1 ) We propose a novel hierarchical discourse model for scientific articles . In the first layer , we define general discourse model that contains four core discourse concepts and can be easily applied to all scientific domains ; In the second layer , we use the scientific articles of WBE as a research case and construct the discourse model of WBE . ( 2 ) To the best of our knowledge , our work is the first to study the discourse structure of scientific articles in WBE domain . With the help of domain experts in WBE , we obtain a dataset of 100 annotated WBE articles . ( 3 ) In order to automatically annotate scientific articles , we use Bert to train a multi - label text classifier and propose a simple yet efficient Top - K resampling - based approach to alleviate the impact of data imbalance on classification performance . Experiments show that after using the Top - K resampling approach , the prediction performance is significantly improved . The remainder of this paper is organized as follows . Section II reviews some related work . Section III describes our proposed hierarchical discourse model in detail . Section IV describes the Top - K resampling - based approach . Section V gives the experimental results and analysis . Section VI concludes our work . II . B ACKGROUND A . The Discourse Model of Scientific Articles Existing work has proposed some discourse models of scientific articles [ 1 ] - [ 8 ] . For example , Argumentative Zoning ( AZ ) [ 1 ] - [ 3 ] is proposed to automatically generate abstract and conduct citation analysis . In addition to defining concepts about the research content , AZ pays special attention to the knowledge attribution of discourse segments . They are applied to the scientific articles in the domain of computational linguistics and biochemistry . Core Information about Scientific Papers ( CISP ) [ 4 ] proposes a series of important concepts of scientific research to describe the content of scientific articles . After experts testing and actual annotation analysis , 12 core concepts are retained , such as Goal , Object , Background , Result , and so on . The work extensively investigates the opinions of researchers and identifies the five most popular categories including Goal , Method , Object , Result , and Conclusion . Based on CISP , Core scientific concepts ( CoreSC ) [ 5 ] further select 11 core concepts . What’s more , CoreSC designs a concept attribute layer that contains New , Old , Advantage , and Disadvantage to enrich the expression ability of the model . In 2015 , SciAnnotDoc [ 6 ] , [ 7 ] is proposed and it contains concepts including Findings , Hypothesis , Methodology , Related Work , and Definition . In the effort of the literature [ 8 ] , the author defines 6 important discourse concepts including Background , Objective , Methods , Results , and Conclusions . B . Text Classification Approaches Text classification aims to automatically assign labels for a certain sentence or document [ 9 ] . It is an important research area in the Natural Language Process ( NLP ) [ [ 10 ] . There has been a large amount of research to apply text classification into various range such as sentiment analysis [ 11 ] , question answering [ 12 ] , and news classification [ 13 ] . The earliest approaches of text classification are some rule - based approaches , but they rely too much on the knowledge of experts . Subsequently , a series of machine learning approaches emerged , such as SVM [ 14 ] , decision tree , etc . However , the performance of classifiers is limited by complex and accurate feature processing . With the development of 775 deep learning , approaches based on CNN [ 15 ] - [ 18 ] and RNN [ 19 ] , [ 20 ] have been proposed , which effectively improve the performance of text classification . In recent years , Google has proposed Bidirectional encoder representations from transformers ( Bert ) [ 21 ] . Bert learns both masked words prediction and next sentence prediction tasks , capturing word - level features and sentence - level features of text and it uses a bidirectionally trained Transformer and attention mechanism to better understand context . When dealing with specific NLP tasks , loading the pre - trained Bert model and fine - tune for a specific task yields satisfactory results [ 22 ] . Bert series approaches such as Roberts [ 23 ] , Albert [ 24 ] , etc . , have been widely used in various tasks of NLP . C . WBE Research Wastewater - based epidemiology ( WBE ) is an emerging domain of environmental science in recent years . It takes wastewater as the research object . By detecting and analyzing the concentration of target substances in wastewater , such as human - use substances , drugs , chemicals , etc . , WBE can estimate the use and consumption of substances by combining wastewater treatment plant population information , flow , and other information [ 25 ] . III . A N OVEL H IERARCHICAL D ISCOURSE M ODEL FOR S CIENTIFIC A RTICLE Our proposed discourse model for scientific articles has two layers , the first layer is a general discourse model applicable to scientific articles in all domains , and the second layer is a domain - specific discourse model . This paper takes sewage epidemiology as a case study . Next , we will introduce the two layers in turn . A . First Layer : Four Core Discourse Concepts At the first level of the discourse model , different from the existing discourse models of scientific articles , we hope to build a simple and general discourse structure . It has the following characteristics : ( 1 ) It contains only a small number of discourse concepts , which are easily understood by researchers in various domains . The advantage is that when manual annotation is implemented , there is no ambiguity in understanding . ( 2 ) It contains concepts that can fully describe the most important contents recorded in the scientific articles and the knowledge that is of most interest to researchers . The advantage is that it can better meet the needs of researchers and is more valuable . We analyzed and discussed the four most concerned core discourse concepts in the content of a research scientific article , including Problem , Method , Result , and Conclusion . These four concepts are determined by questionnaire survey and sufficient demonstration by experts . We find that the existing discourse models of scientific articles , although they have subtle differences in details and definitions , they basically define these four discourse concepts . Although there is also some other information recorded in an article , such as background and related works , we do not take them into account because they are not the authors’ own research outputs . These four concepts can be applied to all scientific articles to describe the content of a research work . The meaning of each concept is explained as follows : Problem concept is used to identify the discourse sentences that describe a specific problem that scientific research is trying to solve . Problems in each domain vary widely . In some research domain , the research problem can be briefly summarized , such as text classification problem in the domain of NLP . While in some other domain , such as WBE , an investigative science , research time and location are also important elements of the research problems because they contribute to distinguish one study from another . Therefore , the problem of WBE articles is usually a combination of a series of descriptive sentences . Method concept is used to identify discourse sentences that describe specific research methods used in the author ' s research process . The method can be a model , an algorithm , a research process , a mathematical method , etc . Result concept is used to identify discourse sentences that describe specific experimental and analytical results obtained in a study . Conclusion concept is used to identify discourse sentences that summarize the research conclusions and these sentences usually appear in the conclusion section . B . Second Layer : Discourse Model of WBE We further construct the second layer , namely the discourse model of WBE . In the second layer of the model , some core concepts are decomposed into collections of more specific concepts according to the characteristics of the research in WBE , which can express the complete domain knowledge . We will elaborate the discourse model of WBE scientific articles in details . ( 1 ) Problem in WBE WBE detects and analyzes the concentration of biological indicators in sewage . The results can be used to estimate the consumption of a substance in a certain place at a certain time to a certain extent . Therefore , the research time , research location , research content and application range are very important to describe a scientific research work . After expert discussion and analytical verification of the articles , these M e t h o d i n W BE d o m a i n Investigation Sampling Preprocess Analysis Population Flow Stability Excretion Uncertainty Data Process It includes sentences that describe literature surveys , WWTP characteristics surveys , population surveys , chemical properties of substances , human metabolism , etc . It includes sentences that describe the sampling method . It includes sentences that describe some preprocess operations on sewage samples , such as filter , drying , centrifugation , enrichment , etc . It includes sentences that describe the methods used to analyze and measure the content of the target substance , such as chromatography , mass spectrometry , etc . It includes sentences that describe the method of estimating the population size of the research area . It includes sentences that describe the method of estimating the flow of the WWTPs . It includes sentences describing research methods for the stability of the target substance in circulation . It includes sentences that describe the method of analyzing the excretion rate of the target substance in the human body . It includes sentences that describe the analysis of uncertainty to the target substance . It includes sentences that describe a range of mathematical and statistical methods of processing data used in the research process . Fig . 1 . 10 categories of methods in the research of WBE . 776 four concepts can describe the problem of scientific research in the domain of WBE . Research Time indicates the time of the study . It should be noted that research time is different from the publication time of the paper . Research Location indicates the sewage sampling location , which is usually a city , a community , a region , etc . ; Research Content is the core of the research problem that describes the main content of a research . Finally , we summarize the five categories of research content in WBE , including concentration measurement , consumption estimation , population estimation , stability analysis and excretion rate research . Application Range indicates the specific biological indicators in the sewage detected in this study , such as a metabolite and a drug [ 25 ] . ( 2 ) Method in WBE In a complete research process of WBE , a total of 10 categories of methods are involved , namely , Investigation , Sampling , Preprocess , Analysis , Population , Flow , Stability , Excretion , Uncertainty , and Data Process . Therefore , we further refine the method and divide it into 10 categories . The meanings of each category are explained in the Fig . 1 . The advantage is that domain experts can easily distinguish specific method categories based on domain knowledge . ( 3 ) Conclusion in WBE For research conclusions , research in this area we focus on sentences that reflect the reliability of the research . Therefore , we divided our research findings into two categories : Positive and Negative . Positive conclusions tend to refer to positive summative sentences that indicate that the research is reliable , relevant , or consistent compared with official real data , while Negative conclusion tends to refer to negative summative sentences that indicate that the research is unreliable , irrelevant , or inconsistent compared with official real data . C . Complete Discourse Model of WBE After the above analysis , our proposed complete discourse model is shown Fig . 2 . As can be seen , the discourse model of scientific articles of WBE is hierarchical , fine - grained , domain - specific scientific articles . Fully validated by domain experts , the model can fully express the important knowledge of WBE articles . IV . T OP - K R ESAMPLING - BASED T EXT C LASSIFICATION A PPROACH Full text annotation of large - scale scientific articles is very time - consuming and labor - intensive . Therefore , we use deep learning approaches to train an effective text classifier , which can automatically assign appropriate labels for sentences . Since a sentence may contain multiple semantics and will be assigned different multiple labels , our problem is essentially a multi - label text classification problem , that can also be viewed as multiple binary classification problems . The dataset obtained by performing annotation using the discourse model of WBE scientific articles contains 25 categories . However , the data is extremely imbalanced . Fig . 3 shows the number of sentences of each category of 30 WBE articles . It can be observed that the number of sentences varies greatly among 25 categories and there are only very few sentences contains in some categories . This is likely to result in poor performance of deep learning approaches . There are two reasons for such data imbalance : ( 1 ) Our proposed discourse model is hierarchical and inclusive . The four categories defined in the first layer have a higher layer and they are divided into more specific categories in a specific academic domain . For example , Method contains 10 WBE research methods . Therefore , the number of sentences of the four core categories of the first layer of the discourse model must be more . ( 2 ) The characteristics of the writing of a scientific article determine that the imbalance is wide - spread . In a research scientific article , the descriptive sentences about the research problems and conclusions are usually general and fewer , and most of the sentences are about the research methods and results . This imbalance of data leads to poor performance of deep learning text classification approaches . Therefore , it is necessary to study an effective approach to enable deep learning text classification approaches to achieve satisfactory classification results in our annotated data . In this section , we propose a new data augmentation approach named Top - K resampling , which can effectively improve the quality of the data , alleviate the impact of imbalance at the data level , and improve the classification prediction ability of the deep learning model . T h e D i s c o u r s e M o d e l o f W BE S c i e n t i f i c A r t i c l e s P r o b l e m M e t h o d R e s u l t C o n c l u s i o n R e s e a rc h T i m e R e s e a rc h L o c a t i o n R e s e a rc h C o n t e n t A pp li c a t i o n R a n g e I n v e s t i ga t i o n S a m p li n g P re p r o ce ss A n a l y s i s P o pu l a t i o n F l o w S t a b ili t y E x cre t i o n P o s i t i v e N e ga t i v e U n cer t a i n t y D a t a P r o ce ss M e a s u re m e n t C o n s u m p t i o n P o pu l a t i o n E s t i m a t i o n S t a b ili t y A n a l y s i s E x cre t i o n S t ud y F ou r c o r e c on ce p t s o f t h e f i r s t l a y e r . T h e c on ce p t s o f t h e W B E ( t h e s ec ond l a y e r ) . T h e f i v e i m po r t a n t r e s ea r c h c on t e n t s o f W B E . Fig . 2 . Complete discourse model of the scientific article of WBE . 1903 148 510 1037 347 620 5 65 16 1536 746 132 109 109 127 29 17 56 44 58 105 990 85 84 1 P r o b l e m R e s e a rc h T i m e R e s e a rc h L o c a t i o n R e s e a rc h C o n t e n t M e a s u re m e n t C o n s u m p t i o n P o pu l a t i o n E s t i m a t i o n S t a t i b ili t y A n a l y s i s E x cre t i o n S t ud y A pp li c a t i o n R a n g e M e t h o d I n v e s t i ga t i o n S a m p li n g P re p r o ce ss A n a l y s i s P o pu l a t i o n F l o w E x cre t i o n S t a b ili t y U n cer t a i n i t y D a t a P r o ce ss R e s u l t C o n c l u s i o n P o s i t i v e N e ga t i v e 0 200 400 600 800 1000 1200 1400 1600 1800 2000 A nno t a ti on s t a ti s ti c s o f 30 a r ti c l e s Fig . 3 . Annotation statistics of 30 articles . Classifier Pre - assessment OriginalData Quality Ranking Top - K Resampling Augmented Data ClassifierRe - assessment Predict Fig . 4 . The complete process of Top - K resampling - based test classification approach . 777 The process of Top - K resampling - based text classification approach first relies on a pre - assessment result of the classification , and based on the pre - assessment results , the quality ranking of all sentences in the original data can be obtained . Then , Top - K resampling is performed based on the quality ranking to obtain an augmented data set . Finally , we use the augmented data to retrain the classifier to reassess performance . The complete process is shown in the Fig . 4 . Next , we will introduce the details of Top - K resampling . A . Pre - Assessment Assuming that there are m sentences in the dataset and n possible categories for each sentence ( n = 25 ) , we can construct an actual matrix A m n   , where A ij = 1 indicates the i - th sentence is a positive sample belonging to category j , A ij = 0 indicates the i - th sentence is a negative sample belonging to category j . Although the predictive results of training a deep learning classifier using original data is unsatisfactory , the results can still provide some meaningful information . Therefore , we first train a classifier using Bert and evaluate its performance on the original training dataset . This evaluation result will be used for subsequent quality ranking . B . Quality Ranking After pre - assessment , a predicted matrix P m n   can be obtained . We show the A and P of 5 categories of 4 sentences in Fig . 5 to explain quality ranking . If the actual classification is the same as the predicted classification ( yellow position in Fig . 5 ) , this is called a true prediction , which includes true positive prediction ( TP ) and true negative ( TN ) . If the actual classification and the predicted classification are different ( orange position in Fig . 5 ) , this is called a false prediction , which includes false prediction ( FP ) and false negative ( FN ) . According to the prediction results , we can calculate the number of correct predictions for each sentence cnt = TN + TP . If the i - th row and the j - th column of the A and P matrices are yellow , we can have two aspects of information . On the one hand , this directly shows that the classifier can well discriminate whether the i - th sentence belongs to the j - th category ; on the other hand , it also shows that the i - th sentence has more obvious and useful features that can help the classifier to better learn and distinguish sample categories . Therefore , if a sentence is correctly classified in multiple categories , it means that this sentence contributes a lot to the classifier to distinguish all categories . When assessing the quality of a sentence , we hope that the sentence with high quality will contribute to true prediction . Therefore , we calculate the cnt = TP + TF of all sentences , and sort all sentences in descending order of cnt to obtain a quality ranking Q = { r 1 , r 2 , … , r m } , where r i is the index of the sentence with rank i . The higher the rank of a sentence , the higher the quality of the sentence . C . Top - K Resampling To alleviate data imbalance and improve the prediction performance of the categories with few training samples , we propose the Top - K resampling as shown in Algorithm 1 . First , we set MAX , which limits the sampling upper bound K of positive samples in those categories with extremely imbalanced positive and negative samples . Assuming that the number of positive samples of all categories is denoted as a set T = { t 1 , t 2 , … , t n } , when t i < MAX , we sample K = MAX - t i , sentences of i - th category . The significance of MAX is that it can limit the amount of augmented data . Sampling too much data will not only increase the training time of the classification model , but also increase the risk of overfitting . We sample the Top - K samples belonging to category j from Q in order of quality from high to low . We need to pay attention to two cases as shown in line 5 - 14 : ( 1 ) when K < = t i , it is enough to sample Top - K data ; ( 2 ) when K > t i , the amount of existing data is not enough to sample K samples , then , we repeat this Top - K resampling process . After Top - K resampling , we will obtain the augmented data { S’ , A’ } , where S’ is the augmented sentences and the A’ is actual labels matrix of S’ . V . E XPERIMENTS A . Dataset We use the keyword “sewage epidemiology” to search for scientific articles of WBE from web of science . With the help of domain experts , we obtain annotated corpus of 100 articles . We divide it into 3 groups , the first group contains 30 articles data , the second group contains 60 articles , and the third 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 0 c1 c2 c3 c4 c5 Actual label matrix : A s1 s2 s4 s3 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 1 c1 c2 c3 c4 c5 Predicted label matrix : P s1 s2 s4 s3 Step1 : calculate cnt = TP + TN for each sentence : { s1 : 3 , s2 : 2 , s3 : 5 , s4 : 1 } Step2 : obtain the quality ranking based on cnt : s3 > s1 > s2 > s4 Fig . 5 . The process of calculating the quality ranking Q of sentences . Yellow denotes a true prediction , which includes true positive prediction ( TP ) and true negative ( TN ) , while orange denotes a false predication , which includes false prediction ( FP ) and false negative ( FN ) . Algorithm 1 : The process of Top - K resampling Input : { S , A } – the original data with m sentences and n categories ; m – the number of sentences in original data ; n – the number of categories ; Q – the quality ranking of original data ; MAX – the minimum number of samples for each category ; Output : { S’ , A’ } - the augmented data using Top - K resampling ; m ’ - the number of augmented data ; Begin 1 : Statistic T = { t 1 , t 2 , … , t n } ; / / calculate number of positive samples 2 : m ’ = m ; 2 : For i = 1 to n Do : / / iterate through each category 3 : K = MAX - t i ; / / calculate resampling size 4 : While K > 0 Do : 5 : If K < = t i Do : / / case ( 1 ) 6 : Resample the top K data belonging to the i - th category ; 7 : m ’ = m ’ + K ; 8 : Break ; / / break the while loop 9 : End If 10 : If K > t i Do : / / case ( 2 ) 11 : Resample all data belonging to the i - th category ; 12 : m ’ = m ’ + K ; 13 : K = K - t i ; 14 : End If 15 : End While 16 : End For End 778 group had 100 articles . This helps us to study the performance of text classification under different amounts of data . The basic statistical results of the 3 groups of data are reported in TABLE I . B . Settings We use Bert for pre - assessment . Due to the limitations of computational resources and the size of training data , we use pre - trained model bert - base - uncased . In the stage of fine - tuning , we directly feed the sentence features obtained by Bert to a full connection layer , which is one of the most common ways of fine - tuning . We use Accuracy , Precision , Recall , and F1 to evaluate the overall prediction performance of the classifier . We experiment two loss functions , binary cross entropy ( BCE ) loss function and Focal loss function [ 26 ] , where BCE is a commonly used loss function and Focal is a loss function specially designed for imbalanced data . We set Max = 200 and batch size bs = 32 . All the experiments use 10 epochs for training . The hyperparameter settings of the Bert classification approach on the three datasets are reported in TABLE II . The optimal value of learning rate and batch size are obtained by grid searching on the validation set . C . Purpose After using Top - K resampling , we can obtain an augmented data . The purpose of our experiments is to answer the following questions : ( 1 ) Does Top - K resampling - based approach work effectively ? ( 2 ) How does the hyperparameter Max affect the results ? ( 3 ) How does our proposed approach perform in terms of training time and performance ? ( 4 ) Can Top - K resampling - based approach be effectively applied to other classification approaches ? The answer and analyze to these four questions are provided in the following Section V - D to Section V - G , respectively . D . The Effectiveness of Top - K Resampling - Based Approach To answer the first question , we use Bert model to train original data , randomly resampled augmented data , and Top - K resampling augmented data to predict their performance on the test dataset . Moreover , we use BCE loss function and Focal loss function to calculate loss , respectively . The results of experiments with different data augmentation and different loss functions in three groups are reported in TABLE III . We have the following observations : ( 1 ) By comparing the performance of the classifier trained with the original data and the classifier trained with the augmented data ( Random , Top - K ) , we can observe that the latter performs significantly better . If we analyze the changes of evaluation indicators of each category , we can find that the improvement is mainly because the prediction performance of the classifier for categories with extremely few positive samples is significantly improved . As the performance of classifier is limited by the quality of the data , under the same experimental setup , a multi - label text classifier can better predict those categories where the positive and negative samples are relatively balanced , but it is difficult to correctly predict those categories with extremely imbalanced positive and negative samples . The number of positive and negative samples of some categories in the original data is too different , resulting in poor overall performance of the multi - label classifier . Resampling alleviates the negative impact of this imbalance to a certain extent . ( 2 ) To further illustrate the benefits of Top - K resampling , we use a random resampling approach . The amount of augmented data obtained by this random resampling is the same as that of Top - K resampling , because we set Max = 200 . The only difference is that random resampling does not take into account the quality of the sentences . By comparing the results of Top - K resampling augmentation and Random resampling augmentation , we can observe that Top - K resampling performs better . Specifically , classifiers using Top - K resampling have the largest number of indicators ranked first and second . ( 3 ) In group A , the performance of the classifier using Focal loss function is not as good as the classifier using BCE loss function , but in both groups B and C , the classifier using Focal loss performs better . This is because , as the amount of data increases , the imbalance of data of some categories is increasing , and the positive and negative samples are more difficult to distinguish . Under this situation , Focal loss can improve the classification performance by increasing the weight of the difficult samples in the loss function . E . Effects on Max To answer the second question , we study the performance change when the hyperparameter Max varies in the range of { 150 , 175 , 200 , 225 , 250 } . The experimental results are shown in Fig . 6 . When Max = 200 , the effect is the best . We found that a better Max value can be estimated by observing the indicators of each category and the number of positive samples of the category during pre - assessment . During our research , we found that the Precision and Recall indicators are very poor for those categories with the number of positive samples < 200 . Therefore , we roughly estimate Max = 200 . After the parameter sensitivity experimental analysis , it is found that this rough estimation is effective . TABLE I . T HE B ASIC S TATISTICS OF D ATASETS Group Articles Sentences Train Validation Test A 30 2558 2046 255 257 B 60 8867 7094 886 887 C 100 12922 10337 1292 1293 TABLE II . T HE S ETTINGS OF H YPERPARAMETERS IN T HREE G ROUPS Group Max learning rate bs Epochs A 200 0 . 0001 32 10 B 200 2e - 5 32 10 C 200 2e - 5 32 10 150 175 200 225 250 0 . 700 0 . 725 0 . 750 0 . 775 0 . 800 0 . 825 0 . 850 0 . 875 0 . 900 0 . 925 0 . 950 0 . 975 1 . 000 T h e va l u e o f i nd i c a t o r s Max Accuracy Precision Recall F1 Fig . 6 . The sensitivity of parameter Max . 779 F . Analysis of Training Time and Performance The largest characteristic of our approach is that the training data is increased , so compared with the original data , the training time of the model will increase . However , since hyperparameter Max is not large , the amount of data does not increase much . For example , in Group C . the data only increases from 10336 to 11204 , so this training time is acceptable . Fig . 7 reports the performance of the model trained by the original data and Top - K resampling enhanced data in Group C with the increase of epoch . When epoch = 3 , the values of the three indicators using Top - K resampling all exceed the original data . This further illustrates the advantages of our approach . G . The Effectiveness of Top - K Resampling on Other Classification Approaches To answer the last question , we use multiple deep learning text classification models to train classifiers by using original data , augmented data using random resampling , and augmented data using Top - K resampling to further verify the effectiveness of Top - K resampling on different classification approaches . We select Roberta and Bert - CNN to implement experiments . Roberta model , like Bert , uses a fully connected layer for text classification , and Bert - CNN model feeds the output vectors of the last four transformer layers of the Bert into convolutional neural network [ 27 ] for classification . It should be noted that here we do not need to use new model to pre - assess to obtain new augmented data , but directly use the augmented data obtained in Section V - D . We report the performance in Fig . 8 . It can be observed that the prediction performance of the classifier trained with the dataset obtained by Top - K resampling is always the best , and the performance is significantly better than the classifier trained on the original data . This experimental result is consistent with previous experiments . This shows that our augmented data obtained by Top - K resampling is effective on multiple models . Moreover , when changing the classification model , we do not need to implement pre - assessment process to obtain new augmented data , because the result of once pre - assessment can improve the prediction performance of multiple classification approaches . This shows that the quality of the data has indeed improved . Fig . 8 . The performance of the classifier trained with three types of data ( origin data , augmented data using random resampling augmented data using Top - K resampling ) . We use 3 models ( Bert , Roberta , and Bert - CNN ) to verify the applicability of the Top - K resampling - based approach . VI . C ONCLUSION This paper makes a new attempt on the discourse model of scientific articles . Different from the previous scientific article discourse model , this paper proposes a hierarchical discourse model including two layers . The first layer simplifies and unifies the general structure of scientific articles . The second layer considers the research process in a specific domain and builds a more detailed and hierarchical discourse model . The hierarchical discourse model has higher 0 1 2 3 4 5 6 7 8 9 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 1 . 1 T h e va l u e o f i nd i c a t o r s e p o c h O r i g i n : P r ec i s i on O r i g i n : R eca ll O r i g i n : F 1 T op - K : P r ec i s i on T op - K : R eca ll T op - K : F 1 Fig . 7 . The performance of the classifier with and without Top - K resampling as the epoch increases . TABLE III . T HE A CCURACY , P RECISION , R ECALL , AND F1 R ESULTS WITH D IFFERENT D ATA P RE - PROCESS A PPROACHES OF B ERT IN T HREE G ROUPS Group Data Loss Accuracy Precision Recall F1 Best / second - best A Origin BCE 0 . 949 0 . 536 0 . 481 0 . 493 0 / 0 Focal 0 . 940 0 . 528 0 . 340 0 . 372 Random BCE 0 . 951 0 . 588 0 . 602 0 . 586 2 / 1 Focal 0 . 947 0 . 610 0 . 534 0 . 563 Top - K BCE 0 . 951 0 . 668 0 . 564 0 . 591 3 / 2 Focal 0 . 948 0 . 591 0 . 580 0 . 568 B Origin BCE 0 . 973 0 . 707 0 . 612 0 . 633 0 / 1 Focal 0 . 976 0 . 810 0 . 694 0 . 729 Random BCE 0 . 975 0 . 835 0 . 823 0 . 822 1 / 2 Focal 0 . 976 0 . 884 0 . 803 0 . 835 Top - K BCE 0 . 976 0 . 844 0 . 837 0 . 833 3 / 3 Focal 0 . 977 0 . 866 0 . 836 0 . 846 C Origin BCE 0 . 968 0 . 735 0 . 649 0 . 669 0 / 0 Focal 0 . 969 0 . 778 0 . 658 0 . 706 Random BCE 0 . 992 0 . 956 0 . 938 0 . 946 2 / 3 Focal 0 . 993 0 . 969 0 . 941 0 . 953 Top - K BCE 0 . 992 0 . 969 0 . 939 0 . 952 3 / 3 Focal 0 . 992 0 . 965 0 . 943 0 . 954 a . Bold indicates the best result in a group , and underlined indicates the second - best result in a group . Best / second - best indicates the number of indicators ranked first and second . 0 . 803 0 . 639 0 . 702 0 . 959 0 . 89 0 . 921 0 . 975 0 . 927 0 . 949 0 . 81 0 . 675 0 . 722 0 . 98 0 . 91 0 . 941 0 . 976 0 . 917 0 . 943 0 . 747 0 . 64 0 . 686 0 . 963 0 . 871 0 . 911 0 . 969 0 . 885 0 . 923 P rec i s i o n R ec a ll F 1 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 1 . 1 O r i g i n R a ndo m T op - K O r i g i n R a ndo m T op - K O r i g i n R a ndo m T op - K T h e va l u e o f i nd i c a t o r s ( b ) . R o b er t a P rec i s i o n R ec a ll F 1 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 1 . 1 T h e va l u e o f i nd i c a t o r s ( a ) . B er t P rec i s i o n R ec a ll F 1 0 . 0 0 . 1 0 . 2 0 . 3 0 . 4 0 . 5 0 . 6 0 . 7 0 . 8 0 . 9 1 . 0 1 . 1 T h e va l u e o f i nd i c a t o r s ( c ) . B er t - CNN 780 value and can assist scientific research more effectively and accurately . Our work first uses the scientific articles of WBE as a case , and annotates a certain amount of data with the help of domain experts . Moreover , we explore an effective Top - K resampling - based approach to train a high - performance classifier for automatically annotating scientific articles . Our research process can be applied to scientific articles in other domains . In the future work , we will construct discourse models of scientific articles in other domains . Then , we will further extract fine - grained semantic knowledge based on the annotated corpus , and construct a knowledge graph of domain scientific article , to realize the reasoning task of domain scientific research . R EFERENCES [ 1 ] S . Teufel , J . Carletta , and M . Moens , “An annotation scheme for discourse - level argumentation in research articles , ” in Proceedings of the Ninth Conference of the European Chapter of the Association for Computational Linguistics , 1999 , pp : 110 - 117 . [ 2 ] S . Teufel and M , Moens , “Summarizing scientific articles : Experiments with relevance and rhetorical status , ” Computational linguistics , vol . 28 , no . 4 , pp . 409 - 445 , 2002 . [ 3 ] S . Teufel A . Siddharthan , and C . Batchelor , “Towards domain - independent argumentative zoning : Evidence from chemistry and computational linguistics , ” in Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing , 2009 , pp . 1493 - 1502 . [ 4 ] N . Larisa , Soldatova , and M . Liakata , “An ontology methodology and CISP - the proposed Core Information about Scientific Papers , ” JISC Project Report , 2007 , http : / / ie - repository . jisc . ac . uk / 137 / . [ 5 ] M . Liakata , et . al . , “A th ree - way perspective on scientific discourse annotation for knowledge extraction , ” in Proceedings of the Workshop on Detecting Structure in Scholarly Discourse , 2012 , pp . 37 - 46 . [ 6 ] H . Ribaupierre and G . Falquet , “An automated annotation process for the SciDocA nnot scientific document model , ” in Proceedings of the 5th international workshop on semantic digital archives . Osaka : International Workshop on Semantic Digital Archives , 2015 , pp . 30 - 41 . [ 7 ] H . Ribaupierre and G . Falquet , “Extracting discourse elements and annotating scientific documents using the SciAnnotDoc model : A use case in gender documents , ” International Journal on Digital Libraries , vol . 19 , no . 2 - 3 , pp . 271 - 286 , 2018 . [ 8 ] G . Yu , Z . Zhang , H . Liu , and L . Ding , “Masked sentence model based on bert for mov e recognition in medical scientific abstracts , ” Journal of Data and Information Science , vol . 4 , no . 4 , pp . 42 - 55 , 2019 . [ 9 ] S . Minaee , N . Kalchbrenner , E . Cambria , N . Nikzad , M . Chenaghlu , and J . Gao . “Deep learning - - based text classification : A comprehensive review , ” ACM Computing Surveys ( CSUR ) , vol . 54 , no . 3 , pp . 1 - 40 , 2021 . [ 10 ] Y . Kang , Z . Cai , C . - W . Tan , Q . Huang , and H . Liu , “Natural language processing ( NLP ) in management research : A literature review , ” Journal of Management Analytics , vol . 7 , no . 2 , pp . 139 - 172 , 2020 . [ 11 ] A . Yadav and D . - K . Vishwakarma , “Sentiment analysis using deep learning architectures : A review , ” . Artificial Intelligence Review , vol . 53 , no . 6 , pp . 4335 - 4385 , 2020 . [ 12 ] T . Kwiatkowski , et . al . , “Natural questions : A benchmark for question answering research , ” Transactions of the Association for Computational Linguistics , 2019 , pp . 453 - 466 . [ 13 ] L . Bozarth and C . Budak , “Toward a better performance evaluation framework for fake news classification , ” in Proceedings of the International AAAI Conference on Web and Social Media , 2020 , pp . 60 - 71 . [ 14 ] S . Huang , et . al . , “Applications of support vector machine ( SVM ) learning in cancer genomics , ” Cancer Genomics & Proteomics , vol . 15 , no . 1 , pp . 41 - 51 , 2018 . [ 15 ] Y . LeCun , L . Bottou , Y . Bengio , and P . Haffner , “Gradient - based learning applied to document recognition , ” in Proceedings of the IEEE , vol . 86 , no . 11 , pp . 2278 – 2324 , 1998 . [ 16 ] N . Kalchbrenner , E . Grefenstette , and P . Blunsom , “A convolution al neural network for modelling sentences , ” in Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , 2014 . [ 17 ] Y . Kim , “Convolutional neural networks for sentence classification , ” in Proceedings of the Conference on Empirical Methods Natural Language Processing ( EMNLP ) , 2014 , pp . 1746 - 1751 . [ 18 ] J . Liu , W . - C . Chang , Y . Wu , and Y . Yang , “Deep learning for extreme multi - label text classification , ” in Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval , 2017 , pp . 115 - 124 . [ 19 ] X . Zhu , P . Sobihani , and H . Guo , “Long short - term memory over recursive structures , ” in International Conference on Machine Learning , 2015 , pp . 1604 – 1612 . [ 20 ] P . Zhou , Z . Qi , S . Zheng , J . Xu , H . Bao , and B . Xu , “Text classification improved by integrating bidirectional lstm with two - dimensional max pooling , ” arXiv preprint arXiv : 1611 . 06639 , 2016 . [ 21 ] J . Devlin , M . - W . Chang , K . Lee , and K . Toutanova , “BERT : pre - training of deep bidirectional transformers for language understanding , ” in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , 2019 , pp . 4171 – 4186 . [ 22 ] C . Sun , X . Qiu , Y . Xu , and X . Huang , “How to fine - tune bert for text cla ssification ? , ” China National Conference on Chinese Computational Linguistics , 2019 : pp . 194 - 206 . [ 23 ] Y . Liu , et . al . , “Roberta : A robustly optimized bert pretraining approach , ” . arXiv preprint arXiv : 1907 . 11692 , 2019 . [ 24 ] Z . Lan , M . Chen , S . Goodman , K . Gimpel , P . Sharma , and R . Soricut , “Albert : A lite bert for self - supervised learning of language representations , ” arXiv preprint arXiv : 1909 . 11942 , 2019 . [ 25 ] P . - M . Choi , et . al . , “Wastewater - based epidemiology biomarkers : Past , present and future , ” TrAC Trends in Analytical Chemistry , vol . 105 , pp . 453 - 469 , 2018 . [ 26 ] T . - Y . Lin , P . Goyal , R . Girshick , K . He , and P . Dollár , “Focal loss for dense object detection , ” in Proceedings of the IEEE International Conference on Computer Vision , 2017 , pp . 2980 - 2988 . [ 27 ] A . Safaya , M . Abdull atif , and , D . Yuret , “Kuisail at semeval - 2020 task 12 : Bert - cnn for offensive speech identification in social media , ” in Proceedings of the Fourteenth Workshop on Semantic Evaluation , 2020 , pp . 2054 - 2059 . 781