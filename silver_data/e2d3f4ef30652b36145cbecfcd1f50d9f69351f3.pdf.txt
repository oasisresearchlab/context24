Automating String Processing in Spreadsheets Using Input - Output Examples Sumit Gulwani Microsoft Research , Redmond , WA , USA sumitg @ microsoft . com Abstract We describe the design of a string programming / expression lan - guage that supports restricted forms of regular expressions , condi - tionals and loops . The language is expressive enough to represent a wide variety of string manipulation tasks that end - users struggle with . We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input - output examples . The synthesis algorithm is very efﬁcient taking a fraction of a second for various benchmark examples . The synthesis algo - rithm is interactive and has several desirable features : it can rank multiple solutions and has fast convergence , it can detect noise in the user input , and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations . The algorithm has been implemented as an interactive add - in for Microsoft Excel spreadsheet system . The prototype tool has met the golden test - it has synthesized part of itself , and has been used to solve problems beyond author’s imagination . Categories and Subject Descriptors D . 1 . 2 [ Programming Tech - niques ] : Automatic Programming ; I . 2 . 2 [ Artiﬁcial Intelligence ] : Program Synthesis General Terms Algorithms , Human Factors Keywords Program Synthesis , User Intent , Programming by Ex - ample ( PBE ) , Version Space Algebra , Spreadsheet Programming , String Manipulation 1 . Introduction More than 500 million people worldwide use spreadsheets . These business end - users have myriad diverse backgrounds and include commodity traders , graphic designers , chemists , human resource managers , ﬁnance pros , marketing managers , underwriters , com - pliance ofﬁcers , and even mailroom clerks – they are not profes - sional programmers , but they need to create small , often one - off , applications to support business functions [ 5 ] . Unfortunately , the state of art in spreadsheet programming is far from satisfactory . Spreadsheet systems come with tons of fea - tures , but end - users struggle to ﬁnd the correct feature or succes - sion of commands to use from a maze of features to accomplish Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full citation on the ﬁrst page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . PoPL’11 , January 26 – 28 , 2011 , Austin , Texas , USA . Copyright c ⃝ 2011 ACM 978 - 1 - 4503 - 0490 - 0 / 11 / 01 . . . $ 10 . 00 their task [ 9 ] . More signiﬁcantly , programming is still required to perform tedious and repetitive tasks such as transforming entities like names / phone - numbers / dates from one format to another , data cleansing , extracting data from several text ﬁles or web pages into a single document , etc . Spreadsheet systems like Microsoft Excel allow users to write macros using a rich inbuilt library of string and numerical functions , or to write arbitrary scripts using a variety of programming languages like Visual Basic , or . Net . Since end - users are not proﬁcient in programming , they ﬁnd it too difﬁcult to write desired macros or scripts . We have performed an extensive case study of spreadsheet help forums and identiﬁed that string processing is one of the most common class of programming problems that end - users struggle with . This is not surprising given that languages like Perl , Awk , Python came into existence to support string / text processing , and that new languages like Java / C # provide a rich support for string processing . During our study of help forums , we also carefully studied how these users were describing the speciﬁcation of the desired program to the experts on the other side of the help forums . It turns out that the most common form of speciﬁcation was input - output examples . Since input - output examples may lead to under - speciﬁcation , the interaction between the user and the expert often involved a few rounds of communication ( over multiple days ) . We describe a program synthesis system that is capable of syn - thesizing a wide range of string processing programs in spread - sheets from input - output examples . The synthesizer aims to replace the role of the forum expert , which not only removes a human from the loop , but also enables users to solve their problems in a few seconds as opposed to a few days . Our synthesis system , which is deployment ready , has the following important usability proper - ties . ∙ Fully Automated : We do not require non - sophisticated end - users to provide annotations / hints of any form . ∙ Real Time : Our system takes less than 0 . 1 second on average per interactive round . ∙ Easy Interaction : Programming by examples is an interactive process where examples are added in each round to make the speciﬁcation more precise . Our system helps identify the inputs for which the user should provide examples . ∙ Fast Convergence : Our system typically takes 1 - 4 rounds of iteration for convergence in practice . ∙ Noise Handling : If the user makes a small mistake in mostly correct speciﬁcation , our system can still compute the likely solution and report the likely mistake . This paper makes the following contributions . 1 . We describe a string programming / expression language that is expressive enough to represent a wide variety of string manipu - lation tasks found during an extensive study of Excel online help forums , while at the same time also being restrictive enough to enable efﬁcient program search over that space ( Section 3 ) . 2 . We describe an algorithm with several novel concepts that can efﬁciently synthesize a set of programs in our language that are consistent with a given set of input - output examples ( Section 4 ) . 3 . We describe extensions to the above algorithm that enable sev - eral usability properties ( Section 5 ) . 4 . We discuss our experience with a ready - to - be - deployed proto - type tool ( Section 6 ) . 2 . Problem Deﬁnition We start out by describing a representative case - study , picked up from an online Excel help forum , that illustrates a typical interac - tion between a user and an expert on help forums . We then use it to motivate the key technical problem that we address in this paper . E XAMPLE 1 . The user intends to extract the following bold sub - strings from the respective strings : 1 . John DOE 3 Data [ TS ] 865 - 000 - 0000 - - 453442 - 00 06 - 23 - 2009 2 . A FF MARILYN 30’S 865 - 000 - 0030 4535871 - 00 07 - 07 - 2009 3 . A GEDA - MARY 100MG 865 - 001 - 0020 - - 5941 - 00 06 - 23 - 2009 The user initially provides a few examples to the expert that are similar to the ﬁrst example above . The expert provides a program 𝑃 1 that uses the logic of extracting 12 characters after the ﬁrst occurrence of “ ] ” . The user runs program 𝑃 1 on other inputs in her spreadsheet and observes that it does not perform the desired extraction for the second example above and then presents that to the expert . The expert then provides a program 𝑃 2 that uses the logic of ﬁnding the ﬁrst occurrence of “ - ” and extracting 3 characters on left of it and 8 characters on right of it . The user runs program 𝑃 2 on her spreadsheet and observes that it does not perform the desired extraction for the third example above and then presents that to the expert . The expert then provides a program 𝑃 3 that uses the logic of ﬁnding the ﬁrst occurrence of a pattern of the form “ ? ? ? - ? ? ? ? - ? ? ? ” , where ? is supposed to match any character . The user runs program 𝑃 3 on her spreadsheet and is satisﬁed with the produced results , and the thread is closed . One might wonder why did the expert not suggest a program 𝑃 4 which is similar to 𝑃 3 , but ? is supposed to match any digit as op - posed to any character . Or why did the expert not suggest a program 𝑃 5 which is similar to 𝑃 3 , but the ﬁrst three occurrences of ? are forced to match only 865 . Even though programs 𝑃 3 , 𝑃 4 and 𝑃 5 are semantically different , these programs may not yield different outputs on the inputs the user has in her spreadsheet . Hence these programs are observationally equivalent over the format of the in - puts present in the spreadsheet . We draw the following conclusions from this representative case study . First , the user is communicating her intent using input - output examples . Second , the user cannot be expected to provide representative inputs in the ﬁrst round . Hence , an example based synthesis system must be interactive . However , in order to remain usable , the system should allow the user to interact easily and converge quickly ( i . e . , in a few rounds ) to the desired intent [ 10 ] . In this paper , we describe such a program synthesis system . We present an algorithm for synthesizing string manipulation programs that are consistent with input - output examples . We also describe how the algorithm can be extended to enable easy interaction and fast convergence . 3 . Expression Language for String Manipulation We have identiﬁed a string expression language that is expressive enough to describe various string manipulation tasks succinctly , while at the same time concise enough to be amenable for efﬁcient learning . There is a tradeoff between the expressiveness of a search space , and the complexity of ﬁnding simple consistent hypotheses within that space [ 6 , 18 ] . In general , the more expressive a search space , the harder the task of ﬁnding consistent hypotheses within that search space . However , it is also worth - mentioning that the expressiveness - complexity tradeoff is not as simple as it seems , as an expressive language can sometimes make a simple theory ﬁt the data , whereas restricting the expressiveness of the language means that any consistent theory must be very complex . Our string expres - sion language seems to enjoy the right tradeoff . We present a core version of this language ; extensions that enable easy adaptation of the underlying algorithm are mentioned later in Section 4 . 7 . 1 . The syntax and semantics of the string expressions 𝑃 is for - mally described in Figure 1 and Figure 2 respectively . We use the notation 𝜖 to denote an empty string and ⊥ to denote an undeﬁned value . If any of the arguments to any constructor is ⊥ , then it re - turns ⊥ . The notation 𝑠 [ 𝑡 1 : 𝑡 2 ] denotes the substring of 𝑠 starting at location 𝑡 1 and ending at location 𝑡 2 . The string expressions 𝑃 map an input state 𝜎 , which holds values for 𝑚 string variables 𝑣 1 , ⋅⋅ , 𝑣 𝑚 ( denoting the multiple input columns in a spreadsheet ) , to a single output string 𝑠 . 𝑃 : ( String × . . . × String ) → String The above formalism can also be used for string processing tasks that require generating a tuple of 𝑛 strings as an output by simply solving 𝑛 independent problems . A trace expression refers to the Concatenate ( f 1 , ⋅⋅ , f 𝑛 ) con - structor , which denotes the string obtained by concatenating the strings represented by f 1 , f 2 , ⋅⋅ , f 𝑛 in that order . An atomic expres - sion refers to ConstStr ( denoting a constant string ) , SubStr or Loop constructors , which are explained below . 3 . 1 Substrings The SubStr ( 𝑣 𝑖 , p 1 , p 2 ) constructor makes use of two position ex - pressions p 1 and p 2 , each of which evaluates to an index within the string 𝑣 𝑖 . SubStr ( 𝑣 𝑖 , p 1 , p 2 ) denotes the substring of string 𝑣 𝑖 that starts at index speciﬁed by p 1 and ends at index speciﬁed by p 2 - 1 . If either of p 1 or p 2 refer to an index that is outside the range of string 𝑣 𝑖 , then the SubStr constructor returns ⊥ . The position expression CPos ( 𝑘 ) refers to the 𝑘 𝑡ℎ index in a given string from the left side ( or right side ) , if the integer constant 𝑘 is non - negative ( or negative ) . Pos ( r 1 , r 2 , c ) is another position constructor , where r 1 and r 2 are some regular expressions and integer expression c evaluates to a non - zero integer . The Pos constructor evaluates to an index 𝑡 in a given string 𝑠 such that r 1 matches some sufﬁx of 𝑠 [ 0 : 𝑡 - 1 ] and r 2 matches some preﬁx of 𝑠 [ 𝑡 : ℓ - 1 ] , where ℓ = Length ( 𝑠 ) . Furthermore , 𝑡 is the c 𝑡ℎ such match starting from the left side ( or the right side ) if c is positive ( or negative ) . If not enough matches exist , then ⊥ is returned . We use notation SubStr2 ( 𝑣 𝑖 , r , c ) to denote the c 𝑡ℎ occurrence of regular expression r in 𝑣 𝑖 , i . e . , SubStr ( 𝑣 𝑖 , Pos ( 𝜖 , r , c ) , Pos ( r , 𝜖 , c ) ) . We often denote SubStr2 ( 𝑣 𝑖 , CPos ( 0 ) , CPos ( - 1 ) ) by simply 𝑣 𝑖 . Tokens and Regular Expressions A token is either some special token or is constructed from some character class 𝐶 in two ways : 𝐶 + denotes a token that matches a sequence of one or more charac - ters from 𝐶 . ¬ 𝐶 + denotes a token that matches a sequence of one or more characters that do not belong to 𝐶 . We use the following collection of character classes 𝐶 : Numeric Digits ( 0 - 9 ) , Alphabets ( a - zA - Z ) , Lowercase alphabets ( a - z ) , Uppercase alphabets ( A - Z ) , Accented alphabets , Alphanumeric characters , Whitespace charac - ters , All characters . We use the following SpecialTokens . ∙ StartTok : Matches the beginning of a string . ∙ EndTok : Matches the end of a string . String expr 𝑃 : = Switch ( ( b 1 , e 1 ) , ⋅⋅ , ( b 𝑛 , e 𝑛 ) ) Bool b : = d 1 ∨ ⋅ ⋅ ∨ d 𝑛 Conjunct d : = 𝜋 1 ∧ ⋅ ⋅ ∧ 𝜋 𝑛 Predicate 𝜋 : = Match ( 𝑣 𝑖 , r , 𝑘 ) ∣ ¬ Match ( 𝑣 𝑖 , r , 𝑘 ) Trace expr e : = Concatenate ( f 1 , ⋅⋅ , f 𝑛 ) Atomic expr f : = SubStr ( 𝑣 𝑖 , p 1 , p 2 ) ∣ ConstStr ( 𝑠 ) ∣ Loop ( 𝜆𝑤 : e ) Position p : = CPos ( 𝑘 ) ∣ Pos ( r 1 , r 2 , c ) Integer expr c : = 𝑘 ∣ 𝑘 1 𝑤 + 𝑘 2 Regular Expression r : = TokenSeq ( T 1 , ⋅⋅ , T 𝑚 ) Token T : = 𝐶 + ∣ [ ¬ 𝐶 ] + ∣ SpecialToken Figure 1 . Syntax of String Expressions 𝑃 . 𝑣 𝑖 refers to a free string variable , while 𝑤 refers to a bound integer variable . 𝑘 denotes an integer constant and 𝑠 denotes a string constant . ∙ A token for each special character , such as hyphen , dot , semi - colon , colon , comma , backslash , forwardslash , left / right paren - thesis / bracket etc . For better readability , we reference tokens by representative names . For example , AlphTok refers to a sequence of alphabetic charac - ters , NumTok refers to a sequence of numeric digits , NonDigitTok refers to a sequence of characters that are not numeric digits , HyphenTok matches with the hyphen character . Addition of more tokens may make the language more power - ful . ( These tokens may be added either by the user or can be mined by searching for frequently occurring substrings in a given spread - sheet . ) However , to stay true to our goal of avoiding any user anno - tations , we aim to keep the language expressive without having to depend on addition of problem - speciﬁc tokens . A regular expression r = TokenSeq ( T 1 , ⋅⋅ , T 𝑛 ) is a sequence of tokens T 1 , ⋅⋅ , T 𝑛 . We often refer to singleton token sequences TokenSeq ( T 1 ) simply as T 1 . We use the notation 𝜖 to denote an empty sequence of tokens . 𝜖 matches an empty string . It is worth discussing our restricted choice of regular expres - sions . First , we allow for only a restricted form of the Kleene star operator . The Kleene star is restricted to one or more occurrences as opposed to zero or more occurrences ( and that too at the innermost level ) . Second , we do not allow for the disjunction operator . These restrictions ( together with the token partitioning optimization de - scribed in Section 4 . 2 ) enable us to efﬁciently enumerate regular expressions that match certain parts of a string . If we allowed ar - bitrary Kleene star and disjunction , we would lose this ability . Use of conditionals at the outer level allow us to recover some of the expressiveness lost due to restricted form of regular expressions . The following two examples illustrate the expressive power of our substring constructor . E XAMPLE 2 . The goal in this problem , taken from an Excel online help forum , is to extract the quantity of the purchase . Observe that characterizing the substring that is being extracted is non - trivial , in fact , not even possible using the character - class tokens that our language provides . However , characterizing the ( left ) position before the substring and the ( right ) position after the substring is relatively easy and also expressible in our language . [ [ Switch ( ( b 1 , e 1 ) , ⋅⋅ , ( b 𝑛 , e 𝑛 ) ) ] ] 𝜎 = if ( [ [ b 1 ] ] 𝜎 ) then [ [ e 1 ] ] 𝜎 . . . else if ( [ [ b 𝑛 ] ] 𝜎 ) then [ [ e 𝑛 ] ] 𝜎 else ⊥ [ [ d 1 ∨ . . . ∨ d 𝑛 ] ] 𝜎 = [ [ d 1 ] ] 𝜎 ∨ . . . ∨ [ [ d 𝑛 ] ] 𝜎 [ [ 𝜋 1 ∧ . . . ∧ 𝜋 𝑛 ] ] 𝜎 = [ [ 𝜋 1 ] ] 𝜎 ∧ . . . ∧ [ [ 𝜋 𝑛 ] ] 𝜎 [ [ Match ( 𝑣 𝑖 , r , 𝑘 ) ] ] 𝜎 = Match ( 𝜎 ( 𝑣 𝑖 ) , r , 𝑘 ) [ [ Concatenate ( f 1 , ⋅⋅ , f 𝑛 ) ] ] 𝜎 = Concatenate ( [ [ f 1 ] ] 𝜎 , ⋅⋅ , [ [ f 𝑛 ] ] 𝜎 ) [ [ Loop ( 𝜆𝑤 : e ) ] ] 𝜎 = LoopR ( 𝜆𝑤 : e , 1 , 𝜎 ) LoopR ( 𝜆𝑤 : e , 𝑘 , 𝜎 ) = let 𝑡 : = [ [ e [ 𝑘 / 𝑤 ] ] ] 𝜎 in if ( 𝑡 = ⊥ ) then 𝜖 else Concatenate ( 𝑡 , LoopR ( 𝜆𝑤 : e , 𝑘 + 1 , 𝜎 ) ) [ [ SubStr ( 𝑣 𝑖 , p 1 , p 2 ) ] ] 𝜎 = 𝑠 [ [ [ p 1 ] ] 𝑠 : [ [ p 2 ] ] 𝑠 ] , where 𝑠 = 𝜎 ( 𝑣 𝑖 ) . [ [ ConstStr ( 𝑠 ) ] ] 𝜎 = 𝑠 [ [ CPos ( 𝑘 ) ] ] 𝑠 = { 𝑘 if 𝑘 ≥ 0 Length ( 𝑠 ) + 𝑘 otherwise [ [ Pos ( r 1 , r 2 , c ) ] ] 𝑠 = 𝑡 such that ∃ 𝑡 1 , 𝑡 2 s . t . 0 ≤ 𝑡 1 < 𝑡 ≤ 𝑡 2 , 𝑠 [ 𝑡 1 : 𝑡 - 1 ] matches r 1 , 𝑠 [ 𝑡 : 𝑡 2 ] matches r 2 , and 𝑡 is the c 𝑡ℎ such position ( in increasing / decreasing order if c is positive / negative . Figure 2 . Semantics of String Expressions 𝑃 . Input 𝑣 1 Output BTR KRNL WK CORN 15Z 15Z CAMP DRY DBL NDL 3 . 6 OZ 3 . 6 OZ CHORE BOY HD SC SPNG 1 PK 1 PK FRENCH WORCESTERSHIRE 5 Z 5 Z O F TOMATO PASTE 6 OZ 6 OZ The following string program identiﬁes the left position to be the one before the occurrence of the ﬁrst number , while the right posi - tion to be the one at the end of the string . String Program ( in our language ) : SubStr ( 𝑣 1 , Pos ( 𝜖 , NumTok , 1 ) , CPos ( − 1 ) ) E XAMPLE 3 ( Directory Name Extraction ) . Consider the follow - ing example taken from an excel online help forum . Input 𝑣 1 Output Company ∖ Code ∖ index . html Company ∖ Code ∖ Company ∖ Docs ∖ Spec ∖ specs . doc Company ∖ Docs ∖ Spec ∖ String Program : SubStr ( 𝑣 1 , CPos ( 0 ) , Pos ( SlashTok , 𝜖 , − 1 ) ) 3 . 2 Loops The string expression Loop ( 𝜆𝑤 : e ) refers to concatenation of e 1 , e 2 , . . . , e 𝑛 , where e 𝑖 is obtained from e by replacing all occur - rences of 𝑤 by 𝑖 . 𝑛 is the smallest integer such that evaluation of e 𝑛 + 1 yields ⊥ . It is also possible to deﬁne more interesting termi - nation conditions ( based on position expression , or predicates ) , but we leave out details for lack of space . E XAMPLE 4 ( Generate Abbreviation ) . The goal here is to extract out all uppercase letters . This problem is taken from [ 21 ] and is presented as an example of Advanced Text Formulas . Input 𝑣 1 Output International Business Machines IBM Principles Of Programming Languages POPL International Conference on Software Engineering ICSE String Program : Loop ( 𝜆𝑤 : Concatenate ( SubStr2 ( 𝑣 1 , UpperTok , 𝑤 ) ) ) . E XAMPLE 5 ( Split Odds ) . The goal in this problem , taken from an Excel help forum , is to place each odd in a separate cell , while ignoring any extraneous numbers or parenthesis . We reduce the problem of generating multiple unbounded number of output strings to that of generating one output string where the multiple strings are separated by a unique symbol , say # . Input 𝑣 1 Output ( 6 / 7 ) ( 4 / 5 ) ( 14 / 1 ) 6 / 7 # 4 / 5 # 14 / 1 # 49 ( 28 / 11 ) ( 14 / 1 ) 28 / 11 # 14 / 1 # ( ) ( 28 / 11 ) ( 14 / 1 ) 28 / 11 # 14 / 1 # String Program : Loop ( 𝜆𝑤 : Concatenate ( SubStr ( 𝑣 1 , p 1 , p 2 ) , ConstStr ( “ # ” ) ) ) where p 1 ≡ Pos ( LeftParenTok , TokenSeq ( NumTok , SlashTok ) , 𝑤 ) ) and p 2 ≡ Pos ( TokenSeq ( SlashTok , NumTok ) , RightParenTok , 𝑤 ) . E XAMPLE 6 ( Remove excess spaces ) . The goal in this problem , provided by the product team and also present in [ 21 ] , is to re - move all leading and trailing spaces and replace internal strings of multiple spaces by a single space . Notice how the loop expression prints out all but last sequence of non - whitespace characters ( to not print any trailing whitespace in the output ) . Input 𝑣 1 Output Oege de Moor Oege de Moor Kathleen Fisher AT & T Labs Kathleen Fisher AT & T Labs String Program : Concatenate ( Loop ( 𝜆𝑤 : Concatenate ( SubStr ( 𝑣 1 , p 1 , p 2 ) ) , ConstStr ( “ ” ) ) , SubStr2 ( 𝑣 1 , NonSpaceTok , − 1 ) ) where p 1 ≡ Pos ( 𝜖 , NonSpaceTok , 𝑤 ) , and p 2 ≡ Pos ( NonSpaceTok , TokenSeq ( SpaceTok , NonSpaceTok ) , 𝑤 ) . 3 . 3 Conditionals The top - level string expression 𝑃 is a Switch constructor whose arguments are pairs of ( disjoint ) boolean expressions b and trace expressions e . The value of 𝑃 in a given input state 𝜎 is the value of the trace expression that corresponds to the boolean expression sat - isﬁed by 𝜎 . Boolean expressions b are represented in DNF form and are boolean combinations of predicates of the form Match ( 𝑣 𝑖 , r , 𝑘 ) , where r is some regular expression and 𝑘 is some integer constant . Match ( 𝑣 𝑖 , r , 𝑘 ) evaluates to true iff 𝑣 𝑖 contains at least 𝑘 matches of regular expression r . We often denote Match ( 𝑣 𝑖 , r ) by simply Match ( 𝑣 𝑖 , r , 1 ) . Conditionals play a very important role in our string processing language . They allow us to appropriately interpret / process data that is in multiple formats . This is precisely the place where most existing ( data cleansing ) tools that allow string processing through tons of automated pre - canned features fail since they assume that the input is in a ﬁxed structured format . Conditionals also allow us to express transformations that are beyond the expressive power of the underlying conditional - free part of our language . E XAMPLE 7 ( Conditional Concatenation ) . The goal here is to concatenate the ﬁrst and the second strings 𝑣 1 and 𝑣 2 in the in - put tuple as 𝑣 1 ( 𝑣 2 ) , only if both 𝑣 1 and 𝑣 2 are non - empty strings . Otherwise , the output should be empty string . This example is taken from an Excel online help forum . Input 𝑣 1 Input 𝑣 2 Output Alex Asst . Alex ( Asst . ) Jim Manager Jim ( Manager ) Ryan 𝜖 𝜖 𝜖 Asst . 𝜖 String Program : Switch ( ( b 1 , e 1 ) , ( b 2 , 𝜖 ) ) , where b 1 ≡ Match ( 𝑣 1 , CharTok ) ∧ Match ( 𝑣 2 , CharTok ) , e 1 ≡ Concatenate ( 𝑣 1 , ConstStr ( “ ( ” ) , 𝑣 2 , ConstStr ( “ ) ” ) ) , b 2 ≡ ¬ Match ( 𝑣 1 , CharTok ) ∨ ¬ Match ( 𝑣 2 , CharTok ) . E XAMPLE 8 ( Mixed Date Parsing ) . The goal here is to parse dates in multiple formats into day , month , and year . This example is taken from an internal mailing list . We show below the program for day extraction ( Month and year extraction are solved similarly . ) Input 𝑣 1 Output 01 / 21 / 2001 01 22 . 02 . 2002 02 2003 - 23 - 03 03 String Program : Switch ( ( b 1 , e 1 ) , ( b 2 , e 2 ) , ( b 3 , e 3 ) ) , where b 1 ≡ Match ( 𝑣 1 , SlashTok ) , b 2 ≡ Match ( 𝑣 1 , DotTok ) , b 3 ≡ Match ( 𝑣 1 , HyphenTok ) , e 1 ≡ SubStr ( 𝑣 1 , Pos ( StartTok , 𝜖 , 1 ) , Pos ( 𝜖 , SlashTok , 1 ) ) e 2 ≡ SubStr ( 𝑣 1 , Pos ( DotTok , 𝜖 , 1 ) , Pos ( 𝜖 , DotTok , 2 ) ) e 3 ≡ SubStr ( 𝑣 1 , Pos ( HyphenTok , 𝜖 , 2 ) , Pos ( EndTok , 𝜖 , 1 ) ) E XAMPLE 9 ( Name Parsing ) . The goal in this problem , provided by the product team , is to parse names that occur in multiple formats and transform them into a uniform format . Input 𝑣 1 Output Dr . Eran Yahav Yahav , E . Prof . Kathleen S . Fisher Fisher , K . Bill Gates , Sr . Gates , B . George Ciprian Necula Necula , G . Ken McMillan , II McMillan , K . String Program for extracting initial of the ﬁrst name : The logic used is that of extracting the initial of the ﬁrst word not followed by a dot : SubStr ( 𝑣 1 , p 1 , p 2 ) , where p 1 ≡ Pos ( 𝜖 , TokenSeq ( AlphTok , NonDotTok ) , 1 ) , and p 2 ≡ Pos ( 𝜖 , TokenSeq ( LowerTok , NonDotTok ) , 1 ) . String Program for extracting last name : The logic used is that of extracting the word followed by a comma , or the last word ( if no comma exists ) : Switch ( ( b 1 , e 1 ) , ( b 2 , e 2 ) ) , where b 1 ≡ Match ( 𝑣 1 , CommaTok ) , b 2 ≡ ¬ Match ( 𝑣 1 , CommaTok ) , e 1 ≡ SubStr2 ( 𝑣 1 , p 1 , p 2 ) , e 2 ≡ SubStr2 ( 𝑣 1 , AlphTok , − 1 ) , p 1 ≡ Pos ( 𝜖 , TokenSeq ( AlphTok , CommaTok ) , 1 ) and p 2 ≡ Pos ( AlphTok , CommaTok , 1 ) The above two programs can be concatenated together ( after dis - tributing conditionals at the top - level ) along with some constant strings to yield the desired program . E XAMPLE 10 ( Phone Numbers ) . The goal here is to parse phone numbers that occur in multiple formats and transform them into a uniform format , adding a default area code of “425” if the area code is missing . This example was provided by the product team . Input 𝑣 1 Output 323 - 708 - 7700 323 - 708 - 7700 ( 425 ) - 706 - 7709 425 - 706 - 7709 510 . 220 . 5586 510 - 220 - 5586 235 7654 425 - 235 - 7654 745 - 8139 425 - 745 - 8139 String Program : Switch ( ( b 1 , e 1 ) , ( b 2 , e 2 ) ) , where ˜ 𝑃 : = Switch ( ( b 1 , ˜ e 1 ) , ⋅⋅ , ( b 𝑛 , ˜ e 𝑛 ) ) ˜ e : = Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , ˜ 𝜉 , 𝑊 ) , where 𝑊 : ˜ 𝜉 → 2 ˜ f ˜ f : = Loop ( 𝜆𝑤 : ˜ e ) ∣ SubStr ( 𝑣 𝑖 , { ˜ p 𝑗 } 𝑗 , { ˜ p 𝑘 } 𝑘 ) ( 1 ) ∣ ConstStr ( 𝑠 ) ˜ p : = CPos ( 𝑘 ) ∣ Pos ( ˜ r 1 , ˜ r 2 , ˜ c ) ˜ r : = TokenSeq ( ˜ T 1 , ⋅⋅ , ˜ T 𝑛 ) [ [ Switch ( ( b 1 , ˜ e 1 ) , ⋅⋅ , ( b 𝑛 , ˜ e 𝑛 ) ) ] ] = { Switch ( ( b 1 , e 1 ) , ⋅⋅ , ( b 𝑛 , e 𝑛 ) ) ∣ e 𝑖 ∈ [ [ ˜ e 𝑖 ] ] } [ [ Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , 𝑊 ) ] ] = { Concatenate ( f 1 , ⋅⋅ , f 𝑛 ) ∣ f 𝑖 ∈ [ [ 𝑊 ( 𝜉 𝑖 ) ] ] , 𝜉 1 , ⋅⋅ , 𝜉 𝑛 ∈ ˜ 𝜉 form a path between 𝜂 𝑠 and 𝜂 𝑡 } [ [ { ˜ f 𝑖 } 𝑖 ] ] = { f ∣ f ∈ [ [ ˜ f 𝑖 ] ] } [ [ Loop ( 𝜆𝑤 : ˜ e ) ] ] = { Loop ( 𝜆𝑤 : e ) ∣ e ∈ [ [ ˜ e ] ] } [ [ SubStr ( 𝑣 𝑖 , { ˜ p 𝑗 } 𝑗 , { ˜ p ′ 𝑘 } 𝑘 ) ] ] = { SubStr ( 𝑣 𝑖 , p 1 , p 2 ) ∣ p 1 ∈ [ [ ˜ p 𝑗 ] ] , p 2 ∈ [ [ ˜ p ′ 𝑘 ] ] } [ [ ConstStr ( 𝑠 ) ] ] = { ConstStr ( 𝑠 ) } [ [ CPos ( 𝑘 ) ] ] = { CPos ( 𝑘 ) } [ [ Pos ( ˜ r 1 , ˜ r 2 , ˜ c ) ] ] = { Pos ( r 1 , r 2 , c ) ∣ r 1 ∈ ˜ r 1 , r 2 ∈ ˜ r 2 , c ∈ ˜ c } [ [ TokenSeq ( ˜ T 1 , ⋅⋅ , ˜ T 𝑛 ) ] ] = { TokenSeq ( T 1 , ⋅⋅ , T 𝑛 ) ∣ T 1 ∈ ˜ T 1 , ⋅⋅ , T 𝑛 ∈ ˜ T 𝑛 } Figure 3 . Syntax and semantics of a language / data - structure for succinctly describing huge sets of string expressions . Intersect ( Dag ( ˜ 𝜂 1 , 𝜂 𝑠 1 , 𝜂 𝑡 1 , ˜ 𝜉 1 , 𝑊 1 ) , Dag ( ˜ 𝜂 2 , 𝜂 𝑠 2 , 𝜂 𝑡 2 , ˜ 𝜉 2 , 𝑊 2 ) ) = Dag ( ˜ 𝜂 1 × ˜ 𝜂 2 , ( 𝜂 𝑠 1 , 𝜂 𝑠 2 ) , ( 𝜂 𝑡 1 , 𝜂 𝑡 2 ) , ˜ 𝜉 12 , 𝑊 12 ) , where ˜ 𝜉 12 = { ⟨ ( 𝜂 1 , 𝜂 2 ) , ( 𝜂 ′ 1 , 𝜂 ′ 2 ) ⟩ ∣ ⟨ 𝜂 1 , 𝜂 ′ 1 ⟩ ∈ ˜ 𝜉 1 , ⟨ 𝜂 2 , 𝜂 ′ 2 ⟩ ∈ ˜ 𝜉 2 } , and 𝑊 12 ( ⟨ ( 𝜂 1 , 𝜂 2 ) , ( 𝜂 ′ 1 , 𝜂 ′ 2 ) ⟩ ) = { Intersect ( ˜ f , ˜ f ′ ) ∣ ˜ f ∈ 𝑊 1 ( ⟨ 𝜂 1 , 𝜂 ′ 1 ⟩ ) , ˜ f ′ ∈ 𝑊 2 ( ⟨ 𝜂 2 , 𝜂 ′ 2 ⟩ ) } Intersect ( SubStr ( 𝑣 𝑖 , { ˜ p 𝑗 } 𝑗 , { ˜ p 𝑘 } 𝑘 ) , SubStr ( 𝑣 ′ 𝑖 , { ˜ p ′ ℓ } ℓ , { ˜ p 𝑚 } 𝑚 ) ) = { IntersectPos ( ˜ p 𝑘 , ˜ p 𝑚 ) } 𝑘 , 𝑚 ) Intersect ( ConstStr ( 𝑠 1 ) , ConstStr ( 𝑠 2 ) ) = ConstStr ( 𝑠 1 ) if 𝑠 1 = 𝑠 2 Intersect ( Loop ( 𝜆𝑤 : ˜ e 1 ) , Loop ( 𝜆𝑤 : ˜ e 2 ) ) = Loop ( 𝜆𝑤 : Intersect ( ˜ e 1 , ˜ e 2 ) ) IntersectPos ( CPos ( 𝑘 1 ) , CPos ( 𝑘 2 ) ) = CPos ( 𝑘 1 ) if 𝑘 1 = 𝑘 2 ( 2 ) IntersectPos ( Pos ( ˜ r 1 , ˜ r 2 , ˜ c ) , Pos ( ˜ r ′ 1 , ˜ r ′ 2 , ˜ c ′ ) ) = Pos ( IntersectRegex ( ˜ r 1 , ˜ r ′ 1 ) , IntersectRegex ( ˜ r 2 , ˜ r ′ 2 ) , ˜ c ∩ ˜ c ′ ) IntersectRegex ( TokenSeq ( ˜ T 1 , ⋅⋅ , ˜ T 𝑛 ) , TokenSeq ( ˜ T ′ 1 , ⋅⋅ , ˜ T ′ 𝑚 ) ) = TokenSeq ( ˜ T 1 ∩ ˜ T ′ , ⋅⋅ , ˜ T 𝑛 ∩ ˜ T ′ 𝑚 ) if 𝑛 = 𝑚 Figure 4 . The Intersect function . The Intersect function returns ∅ in all other cases not covered above . b 1 ≡ Match ( 𝑣 1 , NumTok , 3 ) , b 2 ≡ ¬ Match ( 𝑣 1 , NumTok , 3 ) , e 1 ≡ Concatenate ( SubStr2 ( 𝑣 1 , NumTok , 1 ) , ConstStr ( “ - ” ) , SubStr2 ( 𝑣 1 , NumTok , 2 ) , ConstStr ( “ - ” ) , SubStr2 ( 𝑣 1 , NumTok , 3 ) ) e 2 ≡ Concatenate ( ConstStr ( “425 - ” ) , SubStr2 ( 𝑣 1 , NumTok , 1 ) , ConstStr ( “ - ” ) , SubStr2 ( 𝑣 1 , NumTok , 2 ) ) 4 . Algorithm In this section , we describe an algorithm for learning a string ex - pression ( in the language presented in Section 3 ) that is consis - tent with the provided input - output examples . In fact , the algorithm ends up learning a set of string expressions all of which are con - sistent with the provided input - output examples . This enables the algorithm to have several desirable properties discussed later . The top - level structure of the algorithm is described in proce - dure GenerateStringProgram in Fig 7 , which we explain below . Step 1 : The algorithm ﬁrst computes ( in the loop at Line 2 ) , for each input - output pair ( 𝜎 , 𝑠 ) , a set of all trace expressions that map input 𝜎 to output 𝑠 . We refer to this set as a trace set . This is done using the procedure GenerateStr ( explained in Section 4 . 3 ) . The set of such expressions can be huge ; a key enabling technology is the data - structure ( described in Section 4 . 1 ) for succinctly repre - senting and manipulating such a huge set of expressions . Step 2 : If the target program does not contain any conditionals ( i . e . , it is expressible as a trace expression , then the algorithm can simply intersect the trace sets of all input - output examples . How - ever , since this is not a valid assumption , the algorithm ﬁrst parti - tions the examples so that inputs in the same partition are handled by the same conditional in the top - level Switch construct ( and then intersect the trace sets for inputs in the same partition ) . Partitioning is performed ( in Line 4 ) using the procedure GeneratePartition ( explained in Section 4 . 5 . 1 ) . Inputs in the same partition have the property that intersection of their trace sets is non - empty . The al - gorithm uses a greedy heuristic to minimize the number of such partitions by starting with singleton partitions and then iteratively merging those partitions that have the highest compatibility score ( a notion deﬁned in Sec 4 . 5 . 1 ) . Step 3 : The algorithm then constructs ( in the loop at Line 7 ) a boolean classiﬁcation scheme as a function of the inputs that will place them in the appropriate partition . This is done using the pro - cedure GenerateBoolClassifier ( explained in Section 4 . 5 . 2 ) . This boolean classiﬁcation forms the top - level switch construct for the string program returned by the algorithm at Line 9 . Steps 2 and 3 are explained in detail in Sec 4 . 5 . The GenerateStr procedure used in Step 1 is explained in Sec 4 . 3 . It makes use of two key procedures GenerateSubstring and GenerateLoop , which are discussed in Sections 4 . 2 and 4 . 4 respectively . We start out by brieﬂy describing the key data - structure ( used by these procedures ) and the operations that it supports . 4 . 1 Data - structure for Manipulating Sets of Expressions Figure 3 describes our data - structure / language for succinctly rep - resenting huge sets of string expressions of various kinds and also presents its formal semantics . ˜ 𝑃 , ˜ e , ˜ f , ˜ p , and ˜ r denote respectively a set of string programs , a set of trace expressions , a set of atomic expressions , a set of position expressions , and a set of regular expressions . They are represented using the data - structure shown in Fig 3 . ˜ T and ˜ c represent a set Size ( Switch ( ( b 1 , ˜ e 1 ) , ⋅⋅ , ( b 𝑛 , ˜ e 𝑛 ) ) ) = Size ( ˜ e 1 ) × ⋅ ⋅ × Size ( ˜ e 𝑛 ) Size ( Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , 𝑊 ) ) = size ( 𝜂 𝑡 ) where size ( 𝜂 ) = ∑ 𝜂 ′ ( size ( 𝜂 ′ ) × ∑ ˜ f ∈ 𝑊 ( ⟨ 𝜂 ′ , 𝜂 ⟩ ) Size ( ˜ f ) ) and size ( 𝜂 𝑠 ) = 1 Size ( SubStr ( 𝑣 𝑖 , { ˜ p 𝑗 } 𝑗 , { ˜ p ′ 𝑘 } 𝑘 ) ) = ( ∑ 𝑗 Size ( ˜ p 𝑗 ) ) × ( ∑ 𝑘 Size ( ˜ p ′ 𝑘 ) ) Size ( Loop ( 𝜆𝑤 : ˜ e ) ) = Size ( ˜ e ) Size ( ConstStr ( 𝑠 ) ) = 1 Size ( CPos ( 𝑘 ) ) = 1 Size ( Pos ( ˜ r 1 , ˜ r 2 , ˜ c ) ) = Size ( ˜ r 1 ) × Size ( ˜ r 2 ) × Size ( ˜ c ) Size ( TokenSeq ( ˜ T 1 , ⋅⋅ , ˜ T 𝑛 ) ) = Size ( ˜ T 1 ) × ⋅ ⋅ × Size ( ˜ T 𝑛 ) Figure 5 . The Size function . The equations here also illustrate the huge representation savings that our data - structures provide compared to explicit representation . of tokens and a set of integer expressions , and are represented explicitly . The Concatenate constructor used in our string language is generalized to the Dag constructor Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , ˜ 𝜉 , 𝑊 ) , where ˜ 𝜂 is a set of nodes containing two distinctly marked source and tar - get nodes 𝜂 𝑠 and 𝜂 𝑡 , ˜ 𝜉 is a set of edges over nodes in ˜ 𝜂 that in - duces a DAG , and 𝑊 maps each 𝜉 ∈ ˜ 𝜉 to a set of atomic expres - sions . The set of all Concatenate expressions represented by a Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , ˜ 𝜉 , 𝑊 ) constructor include those whose ordered ar - guments belong to the corresponding edge on any path from 𝜂 𝑠 to 𝜂 𝑡 . The Switch , Loop , SubStr , Pos , and TokenSeq constructors have all been overloaded to accept a set of values of the correspond - ing type for its arguments with the expected semantics . The data - structure supports the following two interesting oper - ations , both of which are required for the partitioning procedure . Intersection Operation Given two sets of expressions of the same kind , construct a set of expressions that are common to the two given sets . The intersection function is described in Fig 4 . The most interesting part is the intersection of two DAGs , which is similar to intersection of two regular automatas . The challenge , compared to regular automata case , is to intersect the labels on the edges - in case of automata , the labels are simply a set of characters , while in our case , the labels are sets of string expressions . We intersect sets of string expressions using the intersection operation supported by the data - structure used for representing those sets of string expressions . Size Operation Given a set of expressions of some kind , estimate the size of the set . The size function is described in Figure 5 . Observe the succinctness beneﬁts provided by the factorization used by each set construct . 4 . 2 Learning Substring Extraction Logics In this section , we describe how to learn the set of all SubStr ex - pressions in our language that can be used to extract a given sub - string from a given string . ( This is an important component of the procedure GenerateStr . ) The number of such expressions may be huge , in which case , explicit representation and computation of all these expressions would be infeasible with respect to both time and space . For example , following is a small sample of various logics for extracting “706” from the string “425 - 706 - 7709” ( call it 𝑣 1 ) . ∙ Second number : SubStr2 ( 𝑣 1 , NumTok , 2 ) . ∙ Second last alphanumeric token : SubStr2 ( 𝑣 1 , AlphNumTok , − 2 ) . ∙ Substring between the ﬁrst hyphen and the last hyphen : SubStr ( 𝑣 1 , Pos ( HyphenTok , 𝜖 , 1 ) , Pos ( 𝜖 , HyphenTok , − 1 ) ) . ∙ First number that occurs between hyphen on both ends . SubStr ( 𝑣 1 , Pos ( HyphenTok , TokenSeq ( NumTok , HyphenTok ) , 1 ) , Pos ( TokenSeq ( HyphenTok , NumTok ) , HyphenTok , 1 ) ) . ∙ First number that is preceded by a number - hyphen sequence . SubStr ( 𝑣 1 , Pos ( TokenSeq ( NumTok , HyphenTok ) , NumTok , 1 ) , Pos ( TokenSeq ( NumTok , HyphenTok , NumTok ) , 𝜖 , 1 ) ) . The GenerateSubstring procedure performs this task effec - tively , and is built around the following two key observations . Decomposition into independent sub - problems The substring - extraction problem can be decomposed into two independent position - identiﬁcation problems , each of which can be solved inde - pendently . Note the two independent calls to GeneratePosition procedure at Lines 3 and 4 in GenerateSubstring procedure in Figure 7 . The solutions to the substring - extraction problem can also be maintained succinctly by independently representing the solutions to the two position - identiﬁcation problems . Note the rep - resentation of the SubStr constructor in Eq . 1 in Figure 3 . Partitioning of Tokens into Indistinguishable Sets A given string does not often distinguish between several sets of tokens . Hence , for any position - identiﬁcation problem , the choice of reg - ular expressions for a given string can be restricted to using only one token from each set of indistinguishable tokens . We deﬁne this more formally below . D EFINITION 1 ( Indistinguishability ) . We say that a token T 1 is indistinguishable from token T 2 with respect to a string 𝑠 if the set of matches of token T 1 in 𝑠 is same as the set of matches of token T 2 in string 𝑠 . Note that indistinguishability is an equivalence relation . D EFINITION 2 ( Indistinguishability Partition ) . Given a string 𝑠 and a set of tokens , let IParts 𝑠 denote the partition of tokens into indistinguishable sets , and let Reps 𝑠 denote some set of representa - tive tokens , one from each partition . We use the notation IParts 𝑠 ( T ) to denote the set in which token T lies . We use this observation to restrict the choice of tokens used in constructing regular expressions to come from the set Reps 𝑠 at Lines 2 and 3 in procedure GeneratePosition . This signiﬁcantly reduces the number of regular expressions that get considered at Lines 2 and 3 without affecting the completeness of the algorithm . 4 . 3 Learning Traces In this section , we discuss how to learn the set of all trace expres - sions ( i . e . , Concatenate constructors ) that can be used to gener - ate a given output string from a given input state . The number of such expressions may be huge . For example , consider the prob - lem of transforming phone numbers in Example 10 . Consider the second input - output example , where the input state consists of one string “ ( 425 ) - 706 - 7709” and the output string is “425 - 706 - 7709” . Figure 6 shows a small sampling of different ways of generating parts of the output string from the input string using SubStr and ConstStr constructors . ( Each substring extraction task itself can be performed in a huge number of ways as explained in Sec 4 . 2 ) . Following are three of the trace expressions represented in the ﬁg - ure , of which the second one ( also shown in bold in the ﬁgure ) , would lead to the correct answer . 1 . Extract the substring “425” . Extract the substring “ - 706 - 7709” . 4 2 5 – 7 0 6 – 7 7 0 9 ( 4 2 5 ) – 7 0 6 – 7 7 0 9 Constant Constant Constant Constant Input Output Figure 6 . Small sampling of different ways of generating parts of an output string from the input string . 2 . Extract the substring “425” . Print constant “ - ” . Extract the sub - string “706” . Print constant “ - ” . Extract the substring “7709” . 3 . Extract the substring “425” . Extract the substring “ - 706” . Print constant “ - ” . Extract the substring “7709” . GenerateStr procedure performs this task effectively ( by us - ing the DAG data - structure introduced earlier to succinctly repre - sent all trace expressions ) . It uses the following crucial observa - tions . Independence of ( unknown ) sub - problems First , observe that the logic for generating some substring of an output string is com - pletely decoupled from the logic for generating another disjoint substring of the output string . Hence , the problem of generating the output string can be decoupled into independent sub - problems of generating different parts of the output string . In particular , assume that we have an oracle ( as in a PBD system like [ 11 ] ) that provides us with the decomposition of a given out - put string into 𝑛 disjoint adjacent substrings , where each disjoint substring gets generated by a different argument of the enclosing concatenate operator . Given such a decomposition , we can decom - pose the problem of identifying the trace expression for generating the output string , into 𝑛 independent sub - problems of generating each of the disjoint adjacent substrings using at atomic expression constructor . These problems can not only be solved independently , but their solutions can also be stored independently to succinctly represent an exponential number of solutions in linear space . How - ever , unfortunately , we do not apriori know the appropriate decom - position of the output string into various parts for which we can independently seek a solution . The naive strategy of enumerating all possible decompositions would not scale since the number of decompositions is exponential in the size of the output string . Number of possible sub - problems is quadratic Second , observe that the total number of different substrings / parts of a string is quadratic ( and not exponential ) in the size of the output string . This leads to a succinct representation of all possible decompositions of a string using a DAG representation , and hence allows us to de - compose the problem of generating the output string ( using a trace expression ) into a quadratic number of independent sub - problems of generating different substrings of the output string ( using some atomic expression ) . With the above two observations , we are now ready to explain the effective functioning of the procedure GenerateStr . The pro - cedure GenerateStr generates a Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , ˜ 𝜉 , 𝑊 ) constructor that represents the set of all trace expressions that can generate a given output string from a given input state . The key idea is to construct a node corresponding to each position within the out - put string and create an edge from a node corresponding to any position to a node corresponding to any later position . Observe that each edge here corresponds to some substring of the output . Each such edge is annotated with the set of all atomic expressions that can generate the corresponding substring ( Lines 5 and 6 in procedure GenerateStr ) . The set of all such SubStr and Loop expressions is generated by Procedures GenerateSubstring and GenerateLoop respectively . The following theorem holds . T HEOREM 1 . Procedure GenerateStr ( 𝜎 , 𝑠 ) computes the set of all trace expressions e with the following properties : A1 . ( Soundness ) e generates the output string 𝑠 from the input state 𝜎 , i . e . , [ [ e ] ] 𝜎 = 𝑠 . A2 . ( Completeness Restriction ) Any loop that occurs in e is non - nested and executes at least twice on 𝜎 . P ROOF : The procedure GenerateSubstring ( 𝜎 , 𝑠 ) generates the set of all SubStr expressions that can generate 𝑠 from 𝜎 . The procedure GenerateLoop ( 𝜎 , 𝑠 , 𝑊 ) extends the map - ping 𝑊 ( 𝑘 1 , 𝑘 4 ) with all Loop expressions that can generate 𝑠 [ 𝑘 1 , 𝑘 4 ] from 𝜎 and furthermore satisfy the restrictions in A2 . Hence , the theorem follows . 4 . 4 Learning Loops In this section , we discuss how to infer the set of all Loop construc - tors that can be used to generate some unknown part of a given output string 𝑠 from a given input state 𝜎 . In the process , we would also identify the unknown part of the output string that the Loop constructor can generate . Procedure GenerateLoop performs this task effectively , and involves the following steps : 1 . Guess three positions within the output string 𝑘 1 , 𝑘 2 , and 𝑘 3 . 2 . Unify the set of trace expressions that can generate 𝑠 [ 𝑘 1 : 𝑘 2 ] with the set of trace expressions that can generate 𝑠 [ 𝑘 2 : 𝑘 3 ] to obtain a new set of string expressions , say ˜ e that uses the loop iterator 𝑤 . The uniﬁcation algorithm is explained below . 3 . Obtain the set of substrings obtained by running the string ex - pressions ˜ e on input 𝜎 . If this set contains a singleton string that matches 𝑠 [ 𝑘 1 : 𝑘 3 ] for some 𝑘 3 , then we conclude that 𝑠 [ 𝑘 1 : 𝑘 3 ] can be generated by Loop ( 𝜆𝑤 : ˜ e ) . Otherwise ignore . The uniﬁcation algorithm is same as the intersection algorithm except with the following replacement to Eq . 2 in Figure 4 . IntersectPos ( 𝑘 1 , 𝑘 2 ) = ( 𝑘 2 − 𝑘 1 ) 𝑤 + 𝑘 1 if 𝑘 1 ∕ = 𝑘 2 The key idea above is to guess a set of loop bodies by unifying the sets of trace expressions associated with the substrings 𝑠 [ 𝑘 1 : 𝑘 2 ] and 𝑠 [ 𝑘 2 : 𝑘 3 ] , and then test the validity of the conjectured set of loops . For performance reasons , we do not recursively invoke GenerateLoop ( in the call that it makes to GenerateStr ) . This allows us to discover all single loops . Nested loops may be discov - ered by controlling the recursion depth . 4 . 5 Learning Conditionals In this section , we discuss how to generate the top - level Switch constructor , after having learned , for each input - output example , the set of all trace expressions that can generate the output string from the input state . There are two important components that enable learning of appropriate conditionals : partitioning of input - output examples into disjoint partitions , and learning classiﬁers based on inputs for those partitions . The classiﬁers provide the conditionals , while the intersection of the trace sets associated with various inputs in a partition yields the computational branch for the corresponding conditional . 4 . 5 . 1 Learning Partitions In this section , we discuss how to appropriately classify the input - output examples into different partitions - the idea being that exam - GenerateStringProgram ( 𝑆 : Set of ( 𝜎 , 𝑠 ) pairs ) 1 𝑇 : = ∅ ; 2 foreach ( 𝜎 , 𝑠 ) ∈ 𝑆 3 𝑇 : = 𝑇 ∪ ( { 𝜎 } , GenerateStr ( 𝜎 , 𝑠 ) ) ; 4 𝑇 : = GeneratePartition ( 𝑇 ) ; 5 ˜ 𝜎 ′ : = { 𝜎 ∣ ( 𝜎 , 𝑠 ) ∈ 𝑆 } ; 6 foreach ( ˜ 𝜎 , ˜ e ) ∈ 𝑇 : 7 let 𝐵 [ ˜ 𝜎 ] : = GenerateBoolClassifier ( ˜ 𝜎 , ˜ 𝜎 ′ - ˜ 𝜎 ) 8 Let ( ˜ 𝜎 1 , ˜ e 1 ) , . . . , ( ˜ 𝜎 𝑘 , ˜ e 𝑘 ) be the 𝑘 elements in 𝑇 in increasing order of Size ( ˜ e ) . 9 return Switch ( ( 𝐵 [ ˜ 𝜎 1 ] , ˜ e 1 ) , . . . , ( 𝐵 [ ˜ 𝜎 𝑘 ] , ˜ e 𝑘 ) ) ; GeneratePartition ( 𝑆 : Set of ( 𝜎 , 𝑠 ) pairs ) 1 while exists ( ˜ 𝜎 , ˜ e ) , ( ˜ 𝜎 ′ , ˜ e ′ ) ∈ 𝑇 s . t . Comp ( ˜ e , ˜ e ′ ) 2 Let ( ˜ 𝜎 1 , ˜ e 1 ) , ( ˜ 𝜎 2 , ˜ e 2 ) ∈ 𝑇 be s . t . CS ( ˜ e 1 , ˜ e 2 ) is largest . 3 𝑇 : = 𝑇 − { ( ˜ 𝜎 1 , ˜ e 1 ) , ( ˜ 𝜎 2 , ˜ e 2 ) } ∪ { ( ˜ 𝜎 1 ∪ ˜ 𝜎 2 , Intersect ( ˜ e 1 , ˜ e 2 ) ) } ; 4 return 𝑇 ; GenerateBoolClassifier ( ˜ 𝜎 1 , ˜ 𝜎 2 : Set of inputs ) 1 ˜ 𝜎 ′ 1 : = ˜ 𝜎 1 ; b : = false ; 2 while ( ˜ 𝜎 ′ 1 ∕ = ∅ ) 3 Old ˜ 𝜎 ′ 1 : = ˜ 𝜎 ′ 1 ; 4 ˜ 𝜎 ′ 2 : = ˜ 𝜎 2 ; ˜ 𝜎 ′′ 1 : = ˜ 𝜎 ′ 1 ; d : = true ; 5 while ( ˜ 𝜎 ′ 2 ∕ = ∅ ) 6 Old ˜ 𝜎 ′ 2 : = ˜ 𝜎 ′ 2 ; 7 Preds : = { Match ( 𝑣 𝑖 , r , 𝑐 ) , ¬ Match ( 𝑣 𝑖 , r , 𝑐 ) ∣ [ [ Match ( 𝑣 𝑖 , r , 𝑐 ) ] ] 𝜎 , 𝜎 ∈ ˜ 𝜎 1 ∪ ˜ 𝜎 2 } ; 8 Let 𝜋 ∈ Preds be s . t . CSP ( 𝜋 , ˜ 𝜎 ′′ 1 , ˜ 𝜎 ′ 2 ) is largest . 9 d : = d ∧ 𝜋 ; 10 ˜ 𝜎 ′′ 1 : = ˜ 𝜎 ′′ 1 − { 𝜎 1 ∣ 𝜎 1 ∈ ˜ 𝜎 ′′ 1 , ¬ [ [ 𝜋 ] ] 𝜎 1 } ; 11 ˜ 𝜎 ′ 2 : = ˜ 𝜎 ′ 2 − { 𝜎 2 ∣ 𝜎 2 ∈ ˜ 𝜎 ′ 2 , ¬ [ [ 𝜋 ] ] 𝜎 2 } ; 12 if ( Old ˜ 𝜎 ′ 2 = ˜ 𝜎 ′ 2 ) then FAIL . 13 ˜ 𝜎 ′ 1 : = ˜ 𝜎 ′ 1 − ˜ 𝜎 ′′ 1 ; b : = b ∨ d ; 14 if ( Old ˜ 𝜎 ′ 1 = ˜ 𝜎 ′ 1 ) then FAIL . 15 return b ; GenerateStr ( 𝜎 : Input state , 𝑠 : Output string ) 1 ˜ 𝜂 : = { 0 , . . . , Length ( 𝑠 ) } ; 2 𝜂 𝑠 : = { 0 } ; 3 𝜂 𝑡 : = { Length ( 𝑠 ) } ; 4 ˜ 𝜉 : = { ⟨ 𝑖 , 𝑗 ⟩ ∣ 0 ≤ 𝑖 < 𝑗 ≤ Length ( 𝑠 ) } ; 5 Let 𝑊 be the mapping that maps edge ⟨ 𝑖 , 𝑗 ⟩ ∈ ˜ 𝜉 to the set { ConstStr ( 𝑠 [ 𝑖 : 𝑗 − 1 ] ) } ∪ GenerateSubstring ( 𝜎 , 𝑠 [ 𝑖 : 𝑗 − 1 ] ) ; 6 𝑊 ′ : = GenerateLoop ( 𝜎 , 𝑠 , 𝑊 ) ; 7 return Dag ( ˜ 𝜂 , 𝜂 𝑠 , 𝜂 𝑡 , ˜ 𝜉 , 𝑊 ′ ) ; GenerateLoop ( 𝜎 : Input state , 𝑠 : Output string , 𝑊 ) 1 𝑊 ′ : = 𝑊 ; 2 foreach 0 ≤ 𝑘 1 , 𝑘 2 , 𝑘 3 < Length ( 𝑠 ) : 3 ˜ e 1 : = GenerateStr ( 𝜎 , 𝑠 [ 𝑘 1 : 𝑘 2 ] ) ; ˜ e 2 : = GenerateStr ( 𝜎 , 𝑠 [ 𝑘 2 : 𝑘 3 ] ) ; 4 ˜ e : = Unify ( ˜ e 1 , ˜ e 2 ) ; 5 if ( [ [ Loop ( 𝜆𝑤 : ˜ e ) ] ] 𝜎 = { 𝑠 [ 𝑘 1 : 𝑘 4 ] } ) for some 𝑘 4 6 𝑊 ′ ( ⟨ 𝑘 1 , 𝑘 4 ⟩ ) : = 𝑊 ′ ( ⟨ 𝑘 1 , 𝑘 4 ⟩ ) ∪ { Loop ( 𝜆𝑤 : ˜ e ) } ; 7 return 𝑊 ′ ; GenerateSubstring ( 𝜎 : Input state , 𝑠 : String ) 1 result : = ∅ ; 2 foreach ( 𝑖 , 𝑘 ) s . t . 𝑠 is substring of 𝜎 ( 𝑣 𝑖 ) at position 𝑘 3 𝑌 1 : = GeneratePosition ( 𝜎 ( 𝑣 𝑖 ) , 𝑘 ) ; 4 𝑌 2 : = GeneratePosition ( 𝜎 ( 𝑣 𝑖 ) , 𝑘 + Length ( 𝑠 ) ) ; 5 result : = result ∪ { SubStr ( 𝑣 𝑖 , 𝑌 1 , 𝑌 2 ) } ; 6 return result ; GeneratePosition ( 𝑠 : String , 𝑘 : int ) 1 result : = { CPos ( 𝑘 ) , CPos ( - ( Length ( 𝑠 ) - 𝑘 ) } ; 2 foreach r 1 = TokenSeq ( T 1 , ⋅⋅ , T 𝑛 ) matching 𝑠 [ 𝑘 1 : 𝑘 - 1 ] for some 𝑘 1 : 3 foreach r 2 = TokenSeq ( T ′ 1 , ⋅⋅ , T ′ 𝑚 ) matching 𝑠 [ 𝑘 : 𝑘 2 ] for some 𝑘 2 : 4 r 12 : = TokenSeq ( T 1 , ⋅⋅ , T 𝑛 , T ′ 1 , ⋅⋅ , T ′ 𝑚 ) ; 5 Let 𝑐 be s . t . 𝑠 [ 𝑘 1 : 𝑘 2 ] is the 𝑐 𝑡ℎ match for r 12 in 𝑠 . 6 Let 𝑐 ′ be the total number of matches for r 12 in 𝑠 . 7 ˜ r 1 : = generateRegex ( r 1 , 𝑠 ) ; 8 ˜ r 2 : = generateRegex ( r 2 , 𝑠 ) ; 9 result : = result ∪ { Pos ( ˜ r 1 , ˜ r 2 , { 𝑐 , - ( 𝑐 ′ - 𝑐 + 1 ) } ) } ; 10 return result ; generateRegex ( r : Regular Expression , 𝑠 : String ) let r be of the form TokenSeq ( T 1 , ⋅⋅ , T 𝑛 ) . return TokenSeq ( IParts 𝑠 ( T 1 ) , ⋅⋅ , IParts 𝑠 ( T 𝑛 ) ) ; Figure 7 . Algorithm for learning string programs that are consistent with a given set 𝑆 of input - output examples . ples that end up in the same partition are those that require similar computational processing . We attempt to achieve this by requiring the partitioning to satisfy the following two properties . ∙ Utility : For each partition , there is at least one trace expression e that is consistent with all examples in that partition . ∙ Minimality : Number of partitions should be as small as possible . Observe that the utility requirement can be satisﬁed trivially on its own by placing each example in its own partition , but then it would not lead to any generalization , which in turn would not lead to any convergence . The minimality requirement can be satisﬁed trivially on its own by placing all examples in the same partition , but it may lead to failure because there might not be any trace expression that can express the transformation for all the examples . It is the combination of these two requirements that leads to faster successful convergence . It would be computationally expensive to try out all possible partitioning choices and select the one that contains smallest num - ber of partitions . We present a partitioning algorithm ( based on greedy algorithmic design pattern ) that is not only efﬁcient , but in practice , yields the smallest number of partitions . The algorithm for learning partitions is described in procedure GeneratePartition in Figure 7 . We start with singleton parti - tions that contain one input each , along with associated trace sets . We then merge two partitions only if their associated trace sets have at least one trace expression in common . ( This criterion leads to sat - isfaction of the utility requirement ) . We refer to such trace sets as being compatible with each other . D EFINITION 3 ( Compatible ) . We say that trace sets ˜ e 1 and ˜ e 2 are compatible with each other , denoted Comp ( ˜ e 1 , ˜ e 2 ) , if Comp ( ˜ e 1 , ˜ e 2 ) 𝑑𝑒𝑓 = Intersect ( ˜ e 1 , ˜ e 2 ) ∕ = ∅ Often there are multiple choices of pairs of partitions that can be merged with each other . We select a pair that has the highest compatibility score . The compatibility score is designed to facilitate partitioning decisions that , at least in practice , lead to the smallest number of partitions . The compatibility score has two components CS 1 and CS 2 . CS 1 measures agreement of two partitions with respect to the compatibility of their trace sets and their intersection with all other trace sets . In particular , if two trace sets ˜ e 1 and ˜ e 2 are both com - patible with ˜ e 3 , and so is Intersect ( ˜ e 1 , ˜ e 2 ) , then we bump up the compatibility score of ˜ e 1 and ˜ e 2 . Also , if two trace sets ˜ e 1 and ˜ e 2 are both not compatible with ˜ e 3 , then we bump up the compatibil - ity score of ˜ e 1 and ˜ e 2 . Note that in either of above - mentioned two cases , the potential of ˜ e 1 or ˜ e 2 to merge with ˜ e 3 is unchanged as a result of the intersection of ˜ e 1 and ˜ e 2 . The idea is to select those partitions for merging that keep alive merging potential with other partitions in a later step , resulting in a smaller number of overall partitions . CS 2 is used to produce a ﬁner score in case there are ties on the CS 1 score . It gives preference to those pairs of trace sets whose relative size after intersection is largest . The idea is that a larger trace set is more likely to merge with other trace sets in a later step , resulting in a smaller number of overall partitions . D EFINITION 4 ( Compatibility score ) . Let ˜ e 1 and ˜ e 2 be two com - patible trace sets drawn from a set 𝑇 = { ˜ e 𝜎 ( 1 ) , . . . , ˜ e 𝜎 ( 𝑛 ) } of trace sets . We deﬁne the compatibility score of ˜ e 1 and ˜ e 2 with respect to 𝑇 , denoted by CS ( ˜ e 1 , ˜ e 2 , 𝑇 ) as : CS ( ˜ e 1 , ˜ e 2 , 𝑇 ) 𝑑𝑒𝑓 = ( CS 1 ( ˜ e 1 , ˜ e 2 , 𝑇 ) , CS 2 ( ˜ e 1 , ˜ e 2 ) ) where CS 1 and CS 2 are deﬁned as follows : CS 1 ( ˜ e 1 , ˜ e 2 , 𝑇 ) 𝑑𝑒𝑓 = ∑ ˜ e 𝑘 ∈ 𝑇 , 𝑘 ∕ = 1 , 𝑘 ∕ = 2 𝑧 ( ˜ e 1 , ˜ e 2 , ˜ e 𝑘 ) 𝑧 ( ˜ e 1 , ˜ e 2 , ˜ e 𝑘 ) ≡ ⎧⎨ ⎩ 1 if ( Comp ( ˜ e 1 , ˜ e 𝑘 ) = Comp ( ˜ e 2 , ˜ e 𝑘 ) = Comp ( Intersect ( ˜ e 1 , ˜ e 2 ) , ˜ e 𝑘 ) ) 0 otherwise CS 2 ( ˜ e 1 , ˜ e 2 ) 𝑑𝑒𝑓 = Size ( Intersect ( ˜ e 1 , ˜ e 2 ) ) Max { Size ( ˜ e 1 ) , Size ( ˜ e 2 ) } Comparison on compatibility scores ( x , y ) , which are pairs of numbers , is deﬁned using lexicographic ordering , i . e . , ( 𝑥 1 , 𝑦 1 ) > ( 𝑥 2 , 𝑦 2 ) 𝑑𝑒𝑓 = ( 𝑥 1 > 𝑥 2 ) ∨ ( 𝑥 1 = 𝑥 2 ∧ 𝑦 1 > 𝑦 2 ) We repeat the merging process one by one until no more parti - tions can be merged . 4 . 5 . 2 Learning Classiﬁers for Partitions In this section , we discuss how to generate classiﬁers for the vari - ous partitions generated using the algorithm GeneratePartition described above . A classiﬁer for a partition is a boolean condition ( over the set of predicates in our language ) that returns true for all inputs in the partition and returns false for all inputs not in that partition . We attempt to learn not just any classiﬁer , but a simple ( small - sized ) one . Given a set of predicates , one simple approach can be to enu - merate boolean formulas of increasingly large sizes and check if it can act as a classiﬁer for some partition . However , this approach would be computationally expensive . We present a classiﬁer learn - ing algorithm ( based on greedy algorithmic design pattern ) that is not only efﬁcient , but in practice , yields smallest classiﬁers . The algorithm for learning classiﬁers is described in procedure GenerateBoolClassifier in Figure 7 . We learn a boolean clas - siﬁer in DNF form . The loop in line 2 learns a new conjunct d in each iteration with the property that none of the inputs in ˜ 𝜎 2 satisfy d , but several inputs in ˜ 𝜎 ′ 1 do . ˜ 𝜎 ′ 1 is that monotonically decreasing subset of inputs from ˜ 𝜎 1 that are not yet covered by the disjunctive boolean formula b learned so far . The loop in line 2 is repeated until ˜ 𝜎 ′ 1 becomes empty ( or it does not change ) . The loop in line 5 identiﬁes a new predicate 𝜋 in each iteration with the property that several inputs in ˜ 𝜎 ′′ 1 satisfy 𝜋 , but several inputs in ˜ 𝜎 ′ 2 do not satisfy 𝜋 , and then adds it to the conjunct d . ˜ 𝜎 ′′ 1 and ˜ 𝜎 ′ 2 are both those monotonically decreasing subsets of ˜ 𝜎 ′ 1 and ˜ 𝜎 2 respectively that satisfy the conjunct d built so far . ˜ 𝜎 2 is used to decide whether or not the loop in line 5 needs to be iterated any further , while ˜ 𝜎 ′′ 1 is used to update ˜ 𝜎 ′ 1 , which is required for the loop in line 2 . Hence , the following theorem holds . T HEOREM 2 . If GenerateBoolClassifier ( ˜ 𝜎 1 , ˜ 𝜎 2 ) does not fail and returns a boolean condition b , then all inputs in ˜ 𝜎 1 satisfy b and none of the inputs in ˜ 𝜎 2 satisfy b . To ensure learning of small boolean formulas , we ensure that the predicate 𝜋 that is chosen at Line 8 is such that ∙ several inputs in ˜ 𝜎 ′ 2 do not satisfy 𝜋 . This keeps ˜ 𝜎 ′ 2 smaller , which helps to terminate the inner loop at Line 5 faster , which leads to conjuncts d containing small number of predicates . ∙ several inputs in ˜ 𝜎 ′′ 1 satisfy 𝜋 . This keeps ˜ 𝜎 ′′ 1 larger , which helps to keep ˜ 𝜎 ′ 1 smaller , which in turn helps to terminate the outer loop in Line 2 faster , which leads to fewer number of conjuncts . To enable a selection that satisﬁes above - mentioned criterion , we choose a predicate with highest classiﬁcation score ( as deﬁned below ) with respect to the sets ˜ 𝜎 ′′ 1 and ˜ 𝜎 ′ 2 . D EFINITION 5 ( Classiﬁcation Score of a Predicate ) . Given two sets of inputs ˜ 𝜎 1 and ˜ 𝜎 2 , and a unary predicate 𝜋 over inputs , we deﬁne the classiﬁcation score of 𝜋 , denoted by CSP ( 𝜋 , ˜ 𝜎 1 , ˜ 𝜎 2 ) , as : CSP ( 𝜋 , ˜ 𝜎 1 , ˜ 𝜎 2 ) 𝑑𝑒𝑓 = Size ( { 𝜎 1 ∣ 𝜎 1 ∈ ˜ 𝜎 1 , [ [ 𝜋 ] ] 𝜎 1 } ) × Size ( { 𝜎 2 ∣ 𝜎 2 ∈ ˜ 𝜎 2 , ¬ [ [ 𝜋 ] ] 𝜎 2 } ) 4 . 6 Correctness If procedure GenerateBoolClassifier does not fail , the synthe - sis algorithm succeeds . In that case , the following theorem holds . T HEOREM 3 ( Soundness ) . The set ˜ 𝑃 of string expressions re - turned by GenerateStringProgram ( { ( 𝜎 𝑖 , 𝑠 𝑖 ) } 𝑖 ) are all consis - tent with each input - output pair ( 𝜎 𝑖 , 𝑠 𝑖 ) , i . e . , ∀ 𝑃 ∈ ˜ 𝑃 ∀ 𝑖 : ( [ [ 𝑃 ] ] 𝜎 𝑖 ) = 𝑠 𝑖 The proof of theorem 3 follows from similar soundness properties of the involved procedures , of which the most interesting one has been stated in Theorem 2 . C ONJECTURE 1 ( Completeness ) . If there exists a string expres - sion in our language that is consistent with the given set of input - output pairs , the algorithm produces one . The above conjecture is true at the level of traces , i . e . , if there ex - ists a consistent trace expression ( satisfying the restriction A2 in Theorem 1 ) , then the algorithm generates it . However , the above conjecture may not be true in general . In practice though , we have observed our partitioning and classiﬁcation procedures to always work , and it appears that there are some interesting theoretical properties of these procedures that might pave the way for proving the above conjecture under some general conditionals . This inves - tigation is left for future work . 4 . 7 Discussion 4 . 7 . 1 Adaptability to Language Extensions The algorithm can be easily adapted to deal with the following lan - guage extensions . The choice of tokens / predicates can be enriched arbitrarily as long as they can be efﬁciently enumerated . The choice of regular expressions is inextensible for reasons mentioned earlier . The substring construct can be extended further to allow for a con - stant index offset into the current choice of substrings . The loop construct can be enriched to allow for termination conditions based on position logic or conjunctions of predicates . It may be possible to nest conditionals inside loops . The key algorithmic idea would be to recursively perform partitioning and classiﬁcation , as is done at the top - level , instead of a simple uniﬁ - cation . However , performance may be a concern . 4 . 7 . 2 General Principles Here , we summarize some key general principles of our learn - ing algorithm . The algorithm ﬁrst learn traces and then infer loops / conditionals . This is unlike recent work on more - general program synthesis techniques ( e . g . , [ 19 ] ) that attempt to learn ev - erything at the same time , often leading to unscalablility . For learning conditionals , the algorithm uses a greedy strat - egy based on scoring functions to ﬁrst infer partitioning and then boolean classiﬁcation . The standard way to learn conditionals in recent program synthesis work is to phrase this as a combinatorial search problem ( using SAT / SMT solvers ) , which leads to solutions that may not scale in real - time settings like ours . For learning traces , the algorithm uses DAG based data - structures that can represent and manipulate ( intersection , evaluation , size / rank computation ) huge sets of programs . This approach would work in general for any term algebra . The DAG based data - structure can be likened to BDDs , which can succinctly represent and manipulate ( conjunction , disjunction , negation ) huge sets of program states , and are popular in the veriﬁcation community . 5 . Usability Extensions 5 . 1 Active Interaction Model ( for easier interaction ) A simple interaction model can be to ask the user to investigate the results of a synthesized program on other inputs in the spread - sheet and to report any discrepancy . However , this may be cum - bersome in case of large spread - sheets . To enable easier interac - tion , we exploit the fact that our synthesis algorithm returns a set of programs ˜ 𝑃 . The synthesis system can run ˜ 𝑃 on every input 𝜎 in the spreadsheet to generate a set of corresponding outputs ˜ 𝑠 , i . e . , ˜ 𝑠 = { [ [ 𝑃 ] ] 𝜎 ∣ 𝑃 ∈ ˜ 𝑃 } . The set ˜ 𝑠 can be computed directly without explicitly enumerating all programs in ˜ 𝑃 . ( This requires exploit - ing the structural decomposition of the underlying data - structures as is done in Intersect and Size methods - we leave out details for lack of space . ) The synthesis system can then highlight any in - put ( for user inspection ) whose corresponding output set contains at least two strings . We refer to this as the active interaction model . It is interesting to compare the above idea with the idea of distinguishing inputs that was introduced recently in the context of synthesis of bit - vector algorithms [ 8 ] . An application of that idea in our context would mean picking any two ( semantically different ) programs from ˜ 𝑃 and then synthesizing an input on which the two programs yield different outputs . Such an approach would not be effective in our setting since , as is illustrated by the case - study in Example 1 , convergence does not require to narrow the choice of consistent programs down to a semantically unique program in the language . It is sufﬁcient to narrow the choice down to that set of consistent programs that are equivalent with respect to the ﬁnite number of inputs in the spreadsheet . 5 . 2 Noise Handling The algorithm declares failure when it fails to learn a boolean clas - siﬁcation scheme . In that case , it can attempt to identify any noise ( inadvertent error in one input - output example ) as follows . The al - gorithm classiﬁes an input - output example as a potentially - noisy if the input belongs to a singleton partition , but the boolean classiﬁca - tion scheme fails to generate a boolean classiﬁer for that singleton partition . For each potentially - noisy example , the algorithm ignores the corresponding partition , and re - learns the boolean classiﬁcation scheme for other partitions . If it succeeds , it classiﬁes the example as noisy and presents that to the user for validation , and can even suggest a ﬁx by running the learned program on the input corre - sponding to the noisy example . E XAMPLE 11 . Consider the following set of examples provided to our tool in one of the scenarios , in which the user failed to spell Kimberly correctly in the output column . Input 𝑣 1 Input 𝑣 2 Output Otis Daniels Otis , D . Kimberly Jones Kimberley , J . Mary Leslie Mary , L . The GeneratePartition algorithm groups the ﬁrst and third ex - ample in one partition , while the second example belongs to a singleton partition . The GenerateBoolClassifier algorithm fails to generate a boolean classiﬁcation scheme that distin - guishes the two partitions . Ignoring the singleton partition enables GenerateBoolClassifier algorithm to succeed trivially ( since there is only one partition ) . The algorithm declares the second example to be noisy and asks the user to investigate if she really meant “Kimberly , J . ” ( which it generates by running the learned program on the noisy input ) . 5 . 3 Ranking of Multiple Solutions ( for faster convergence ) Selecting an expressive language for inductive program synthesis systems raises an interesting dilemma . While it makes users who want to program sophisticated tasks happy , it may adversely impact users who want to program simple tasks but now may require to provide more bits for disambiguation of their intent ( which manifests in the need to provide more examples and more rounds of interaction ) . The Occam’s razor principle , which states that the simplest explanation is usually the correct one , comes to our rescue here . We deﬁne a comparison scheme between different string expressions by deﬁning a partial order between them . Some of these choices are subjective , but have been observed to work well . ( There is also a fascinating prospect of personalizing this partial order based on the user intent observed during last few scenarios ) . A Concatenate constructor is simpler than another one if it contains smaller number of arguments or its arguments are pair - wise simpler . Similarly for TokenSeq constructor . StartTok and EndTok are simpler than all other tokens ( suggesting that extrac - tion logics based on the start / end of strings are more common ) . A token corresponding to a character class is simpler than the one cor - responding to a smaller character class . ( We favor generality here . ) CPos expressions are simpler than Pos expressions ( giving prefer - ence to extraction logics based on constant offsets ) . A SubStr con - structor is simpler than both ConstStr constructor ( it is less likely for constant parts of an output string to also occur in the input ) and Concatenate constructor ( if there is a long substring match be - tween input and output , it is more likely that the corresponding part of the output was produced by a single substring extraction logic ) . Procedures generateRegex , GenerateLoop , GenerateStr , GeneratePosition , and GenerateSubstring , which generate a set of solutions , can take this ordering into account to produce an ordered set of solutions . 6 . Prototype Tool We have built the program synthesis system described in this pa - per as an add - in , called QuickCode , for Microsoft Excel 2010 . Mi - crosoft Excel is the most popularly used spreadsheet system in the world and is widely regarded to be the swiss army knife of all busi - nesses . The program synthesis system has two components : ( a ) the algorithm described in Section 4 , which has been implemented in C # ( it is less than 5000 lines of code ) , and ( b ) the usability extensions described in Section 5 , which are supported using a simple , but cool , graphical user interface described below . 6 . 1 User Interface The user ﬁrst selects a rectangular region of spreadsheet containing both input and output columns . We treat the mostly populated columns as input columns , and less populated columns as output columns . However , we also provide the ﬂexibility for the user to select multiple column ranges and identify explicitly which columns are inputs and which columns are outputs ( since it may be the case that most cells in an input column have null entries , while our default treatment would be to regard it as an output column ) . We treat the rows that contain entries for an output column as input - output examples for the program to be learned for that column . The user then presses the QuickCode button . The system then populates the spreadsheet as follows . It invokes the synthesis algo - rithm ( procedure GenerateStringProgram ) for each of the out - put column . For each output cell 𝛼 𝑟 , 𝑐 ( in row 𝑟 and output column 𝑐 ) , the system runs the generated set of programs for output column 𝑐 on the input state speciﬁed in row 𝑟 to generate an ordered set ˜ 𝑠 of possible outputs . The system populates the cell 𝛼 𝑟 , 𝑐 as follows : ∙ If ˜ 𝑠 contains one string ( the most common case ) , the system populates the cell with that string . ∙ If ˜ 𝑠 contains multiple strings , the system populates the cell with the ﬁrst string ( top ranked solution ) , but highlights it to point out to the user that there are multiple computational interpretations of the few examples provided by the user , and that the user may want to investigate the output of the highlighted cell . ∙ If ˜ 𝑠 is empty , the system populates the cell with ? ? to draw the attention that the user should provide the output for that cell . The user may then ( repeatedly ) ﬁx contents of any cell by right - clicking on it , wherein a dialog box opens up that allows the user to choose from other strings in the corresponding sequence ˜ 𝑠 , or to provide a new output altogether . After any such ﬁx , the above learning process is automatically repeated with the extended set of input - output examples , and the contents of spreadsheet are automatically updated to reﬂect the new learned results . 6 . 2 Evaluation Metrics Our synthesis system can be evaluated against several metrics stated below . Algorithmic Performance : This is a measure of the effectiveness of the data - structures used by the algorithm . The algorithm was timed to take less than 0 . 1 seconds on average for a varied bench - mark suite of more than 100 problem instances drawn from online help forums or obtained from Excel product team as representative examples . ( The examples described in this paper form a representa - tive part of this benchmark suite . ) Each problem instance contained up to 10 input - output pairs ( more than what the user would want to provide in any scenario ) and each string in any pair contained up to 100 characters ( more than what is typical of spreadsheet cells ) . Experiments were performed on a machine with Intel Core - 2 - Duo 2 . 8 GHz CPU , and 4 GB RAM . Number of Interactive Rounds : This is a measure of the general - ization power of the conditional learning part of the algorithm and the ranking scheme . We observed that the tool typically requires just one round of interaction , when the user is smart enough to give an example for each input format ( which typically range from 1 to 3 ) to start with . It is heartening to note that this was indeed the case for most scenarios in our benchmarks , even though our algorithm can function robustly without this assumption . The maximum num - ber of interactive rounds required in any scenario was 4 ( with 2 to 3 being a more typical number ) . The maximum number of examples required in any scenario over all possible interactions was 10 . Success Ratio : We have not come across any problem instance that can be expressed in our language , but our algorithm fails to converge to the correct solution . This is a measure of the validity of the completeness hypothesis discussed in Section 4 . 6 . However , we have found several problem instances that cannot be expressed in our language . Most of these instances are related to semantic entity reasoning ( such as transforming dates into day of the week ) . For syntactic string manipulation tasks , we have been more than pleasantly surprised at the expressiveness of our lan - guage . Few testing moments came in the middle of some internal demos to large audiences , where we were asked to try out modiﬁed scenarios on the spot ( on real spreadsheet data ) . The tool success - fully learned the desired transformations in all those cases . Following are a few examples of scenarios where QuickCode was used by fellow colleagues to perform tasks beyond the imagi - nation of the author . E XAMPLE 12 ( Synthesis of part of a future extension of itself ) . The synthesis system is currently being extended with semantic knowledge of common entities that would allow the system to per - form transformations that are beyond the realm of syntactic com - putations . One of the dictionaries that was recently added to the system was mapping from a country’s international dialing code to the name of that country . Rishabh Singh performed this task , which he originally thought would take around an hour ( in absence of any scripting ) , in less than a minute using the QuickCode add - in ( after copying and pasting the data from Wikipedia into an Excel spreadsheet ) . Input 𝑣 1 Input 𝑣 2 Output Albania 355 case 355 : return “Albania” ; Algeria 213 case 213 : return “Algeria” ; String Program : Concatenate ( ConstStr ( “ 𝑐𝑎𝑠𝑒 ” ) , 𝑣 2 , ConstStr ( “ : 𝑟𝑒𝑡𝑢𝑟𝑛 “ ” ) , 𝑣 1 , ConstStr ( “ ” ; ” ) ) The above examples were sufﬁcient for QuickCode to populate the spreadsheet with the desired output for more than 200 rows , each containing data for a different country . The resultant code - fragment in the output column was copied and pasted in Visual Studio Development Environment as part of a switch statement , and it compiled ! E XAMPLE 13 ( Filtering Task ) . Ben Zorn wanted to estimate the total number of page - hits to links in the pictures directory from weekly statistics consisting of pairs of links and page - hits . He tried to use the QuickCode add - in by giving examples where the output column was a copy of the input page - hit column only if the input link column contained “pictures” in the path . Input 𝑣 1 Input 𝑣 2 Output / um / people / sumitg / pictures / lake - tahoe / index . html 192 192 / um / people / sumitg / index . html 104 0 / um / people / sumitg / pubs / speed . html 16 0 / um / people / sumitg / pubs / popl10 synthesis . pdf 13 0 / um / people / sumitg / pictures / verona / index . html 7 7 / um / people / sumitg / pictures / kerela / target21 . html 3 3 Quite surprisingly for the author , the QuickCode add - in worked successfully ( without use of its hidden capability of being able to add new tokens - addition of “pictures” token would have done the trick ) . Closer investigation of the generated program revealed an - other trick for solving the same problem : all ( and only ) “pictures” links had 6 occurrences of the backslash token - a pattern that could not have been easy for the user to discover . String Program : Switch ( ( b 1 , 𝑣 2 ) , ( b 2 , ConstStr ( 0 ) ) ) , where b 1 ≡ Match ( 𝑣 1 , SlashTok , 6 ) , and b 2 ≡ ¬ Match ( 𝑣 1 , SlashTok , 6 ) . E XAMPLE 14 ( Arithmetic Task ) . The synthesis engine currently does not support any arithmetic reasoning . Hence , we thought that a few examples found on Excel help forums , asking for computing the sum of all numbers in a string , had to wait . However , Bill Harris showed us a cute trick that almost did it . Input 𝑣 1 Output Alpha 10 Beta 20 Charlie 30 Delta 10 + 20 + 30 POPL 9 CAV 7 PLDI 6 ESOP 4 9 + 7 + 6 + 4 String Program : Concatenate ( Loop ( 𝜆𝑤 : Concatenate ( SubStr ( 𝑣 1 , p 1 , p 2 ) , ConstStr ( “ + ” ) ) ) , SubStr2 ( 𝑣 1 , NumTok , − 1 ) ) where p 1 ≡ Pos ( 𝜖 , NumTok , 𝑤 ) and p 2 ≡ Pos ( NumTok , TokenSeq ( NonDigitTok , NumTok ) , 𝑤 ) . It is interesting to note above how the loop constructor gets used to print all , but last , numbers , each followed by a plus sign ( The position expression p 2 ensures that there better be another number following the number to be extracted ) . The last integer is then concatenated separately . ( The desired sum can now be obtained by formatting the output column as a number inside Excel . ) 7 . Related Work Work on learning concepts such as deterministic ﬁnite state au - tomata [ 1 ] , or regular transducers [ 20 ] from examples is not appli - cable in our setting because it requires making many more queries to the user , and most string processing tasks described in this paper are more expressive than what can be expressed by these concepts . The most closely related work is that of automating text - editing using demonstrations or examples . These text - editor techniques may be lifted to the spreadsheet setting , but they would not work well because ( a ) the real spreadsheet scenarios are more challeng - ing than what these techniques can handle , ( b ) the PBD interface , inherent to most of these techniques , requires users to provide much more information that is way beyond the usability bar in spread - sheets . We explain these issues below . Text - editing using Demonstrations SMARTedit [ 11 ] is a Pro - gramming by Demonstration ( PBD ) system for learning text - editing commands , where the primitive program statements in - clude moving the cursor to a new position and inserting / deleting text . However , there are two signiﬁcant differences : ( a ) The lan - guage of programs considered is not as expressive as required in the spreadsheet setting . In particular , it does not provide support for conditionals , which are very important for data cleansing tasks in spreadsheets . Hence , it cannot be applied for the processing re - quired in Examples 7 , 8 , 9 , 10 , 13 . Also , its cursor movement logic is restricted to positions either before or after the 𝑘 𝑡ℎ occurrence of a single token , while scanning from left side . In contrast , our position extraction logic is much more powerful - it allows to iden - tify positions based on 𝑘 𝑡ℎ occurrence of sequences of tokens both before and after the desired position , while scanning from left or right side . As a result , the SMARTedit system cannot be applied for processing required in Examples 1 , 3 , 5 , and 14 . ( b ) More sig - niﬁcantly , as for any PBD system , the user is required to provide a complete demonstration or trace , where the demonstration consists of a sequence of the editor state after each primitive action , really spelling out how to do the transformation , but on a given exam - ple . The user is also required to segment each iteration of an inner loop . Further , PBD based systems also have the drawback of being sensitive to the order in which the user chooses to perform actions . Our system is based on Programming by Example ( as opposed to Demonstration ) - it requires the user to only provide the ﬁnal state ( as opposed to also providing the intermediate states ) . This ren - ders our system much more usable [ 10 ] , however , at the expense of making the learning problem much more difﬁcult , for which we do present an effective algorithm . TELS [ 22 ] is another PBD system that records high - level ac - tions similar to the actions used in SMARTedit , and implements a set of heuristics / expert rules for generalizing the arguments of each of the actions . However , TELS’s dependence on heuristic rules to describe the possible generalizations makes it difﬁcult to under - stand the hypothesis space clearly , as well as to imagine applying it to the different domain of spreadsheet applications . Simultaneous editing [ 15 ] is another PBD - like system that al - lows the user to deﬁne a set of regions to edit , and then allows the user to make edits in one , while the system makes equivalent edit - ing in all other records . The inference used in simultaneous editing is much less powerful since it does not support conditional or loopy edits ( every editing action is applied uniformly to every record ) . Text - editing using Examples Nix described a text - editing system that synthesizes gap programs based on examples [ 17 ] . A gap program is a collection of ( pattern , replacement ) pairs , where each pattern is composed of constants and variables that bind to the text in between the constants , and a replacement can be a constant string or a variable from the input pattern . Gap programs are not expressive enough to represent the solution of most of the string processing benchmark examples described in this paper . Data Processing for Programmers The PADS project has en - abled simpliﬁcation of ad hoc data processing tasks for program - mers by contributing along several dimensions : development of do - main speciﬁc languages for describing text structure or data for - mat [ 2 , 3 ] , learning algorithms for automatically inferring such for - mats [ 4 ] , and a markup language to allow users to add simple anno - tations to enable more effective learning of text structure [ 23 ] . The learned format can then be used by programmers for documenta - tion or implementation of custom data analysis tools . In contrast , the focus of this paper is to enable end - users ( non - programmers ) to perform small , often one - off , repetitive tasks on their spread - sheet data . Asking end - users to provide annotations for learning ( relatively simple ) text structure , and then develop custom tools to format / process the inferred structure is way above the expertise and usability bar for these users . Hence , we are interested in automating the entire end - to - end process , which includes not only learning the text structure from the inputs , but also learning the desired trans - formation from the outputs . Algorithmic Techniques [ 6 ] provides a good survey of various program synthesis techniques : exhaustive search , logical reason - ing , probabilistic inference , and version - space algebras . Exhaus - tive search based techniques would not scale for our problem set - ting since the underlying state space ( even for programs of small bounded size ) is huge . Logical reasoning techniques ( such as those used in learning straight - line bit - vector programs from input - output examples [ 8 ] , or loopy programs from logical speciﬁcations [ 19 ] ) are not suited for various reasons : they are not as scalable ( several minutes are acceptable for discovering a new bit - vector algorithm , but not for an interactive spreadsheet session ) ; they cannot deal with noise in the user input ; they cannot easily compute all solu - tions ( required for providing various computational interpretations to the user for an ambiguous input ) . The GenerateStr part of the synthesis algorithm presented in this paper is closest to the version - space algebra approach that in - volves maintaining a set of all hypotheses ( drawn from a hypothesis space ) that are consistent with a sequence of observed examples . Mitchell originally used this idea for reﬁnement - based learning of boolean functions [ 16 ] , while Lau et . al . extended the concept to learning more complex functions in a PBD setting [ 13 ] . Our syn - thesis algorithm shows how the concepts of version - space algebra can be lifted to the PBE ( Programming by Example ) setting , for a fairly expressive string expression language involving conditionals and loops . The idea of using DAGs as the version space for concate - nate constructor is inspired by the use of a similar data - structure in a very different context of solving an important open problem re - lated to global value numbering [ 7 ] . The novel concepts introduced in this paper are quite general - we feel that they might be used to create PBE versions of other version - space algebra based PBD sys - tems ( e . g . , those that learn shell scripts [ 12 ] or imperative Python programs [ 14 ] ) . 8 . Conclusion General purpose computational devices , such as cell - phones , com - puters , are becoming accessible to people at large at an impres - sive rate . In the future , robots will become house - hold entities . But , unfortunately , programming general purpose platforms has never been easy , because we are still mostly stuck with the model of pro - viding step - by - step , detailed , and syntactically correct instructions on how to accomplish a certain task , instead of simply describing what the task is . Program synthesis has the revolutionary potential to change this landscape , when targeted for the right set of people , for the right set of problems , and using the right interaction model . In this paper , we have identiﬁed a killer application , that of automating string processing in spreadsheets , which hundreds of millions of end - users struggle with on a regular basis ( as is evident from online help forums and talking to product groups ) . We have developed an efﬁcient algorithm to help automate a variety of string processing tasks from input - output examples ( which we found to be the most natural intent expression mechanism on help forums ) . We have paid special attention to usability issues and crossed the line from developing an academic - only technology to one that is ready to be deployed . Acknowledgments Thanks to Ben Zorn who had such a belief in the promise of this technology that he helped ﬁnd connections in product teams even before a prototype could be built . Thanks to the Excel product team who kept engaging with us despite their initial skepticism whether such a “magical” technology can ever be possible . Thanks to Piali Choudhury for building a cool UI for the tool . Thanks to Bill Harris and Rishabh Singh for adding new features and taking the technology to another level , details of which are beyond the scope of this paper . Thanks to Ras Bodik , Venkie , and David Walker for useful discussions . Finally to my Excel - literate parents and spouse for the best ( tear - rendering ) compliment after playing with the tool : “For the ﬁrst time , we understand what your research is about” . References [ 1 ] D . Angluin . Learning regular sets from queries and counterexamples . Inf . Comput . , 75 ( 2 ) : 87 – 106 , 1987 . [ 2 ] K . Fisher and R . Gruber . PADS : a domain - speciﬁc language for processing ad hoc data . In PLDI , pages 295 – 304 , 2005 . [ 3 ] K . Fisher , Y . Mandelbaum , and D . Walker . The next 700 data descrip - tion languages . In POPL , pages 2 – 15 , 2006 . [ 4 ] K . Fisher , D . Walker , K . Q . Zhu , and P . White . From dirt to shovels : fully automatic tool generation from ad hoc data . In POPL , 2008 . [ 5 ] M . Gualtieri . Deputize end - user developers to deliver business agility and reduce costs . In Forrester Report for Application Development and Program Management Professionals , April 2009 . [ 6 ] S . Gulwani . Dimensions in program synthesis . In PPDP . ACM , 2010 . [ 7 ] S . Gulwani and G . C . Necula . A polynomial - time algorithm for global value numbering . In SAS , pages 212 – 227 , 2004 . [ 8 ] S . Jha , S . Gulwani , S . Seshia , and A . Tiwari . Oracle - guided component - based program synthesis . In ICSE , 2010 . [ 9 ] A . J . Ko , B . A . Myers , and H . H . Aung . Six learning barriers in end - user programming systems . In VL / HCC , pages 199 – 206 , 2004 . [ 10 ] T . Lau . Why PBD systems fail : Lessons learned for usable AI . In CHI 2008 Workshop on Usable AI , Florence , Italy , 2008 . [ 11 ] T . Lau , S . Wolfman , P . Domingos , and D . Weld . Programming by demonstration using version space algebra . Machine Learning , 53 ( 1 - 2 ) , 2003 . [ 12 ] T . Lau , L . Bergman , V . Castelli , and D . Oblinger . Programming shell scripts by demonstration . In Workshop on SCLAS , AAAI , 2004 . [ 13 ] T . A . Lau , P . Domingos , and D . S . Weld . Version space algebra and its application to programming by demonstration . In ICML , 2000 . [ 14 ] T . A . Lau , P . Domingos , and D . S . Weld . Learning programs from traces using version space algebra . In K - CAP , pages 36 – 43 , 2003 . [ 15 ] R . C . Miller and B . A . Myers . Interactive simultaneous editing of multiple text regions . In USENIX Annual Technical Conference , 2001 . [ 16 ] T . M . Mitchell . Generalization as search . Artif . Intell . , 18 ( 2 ) , 1982 . [ 17 ] R . P . Nix . Editing by example . TOPLAS , 7 ( 4 ) : 600 – 621 , 1985 . [ 18 ] S . Russell and P . Norvig . Artiﬁcial Intelligence : A Modern Approach ( 2nd Edition ) . Prentice Hall , 2 edition , December 2002 . [ 19 ] S . Srivastava , S . Gulwani , and J . Foster . From program veriﬁcation to program synthesis . In POPL , 2010 . [ 20 ] J . M . Vilar . Query learning of subsequential transducers . In Proceed - ings of the 3rd International Colloquium on Grammatical Inference , 1996 . [ 21 ] J . Walkenbach . Excel 2010 Formulas . John Wiley and Sons , 2010 . [ 22 ] I . H . Witten and D . Mo . TELS : learning text editing tasks from examples . In Watch what I do : programming by demonstration , pages 293 – 307 . MIT Press , Cambridge , MA , USA , 1993 . [ 23 ] Q . Xi and D . Walker . A context - free markup language for semi - structured text . In PLDI , pages 221 – 232 , 2010 .