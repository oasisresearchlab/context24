Measuring the influence of social abilities on acceptance of an interface robot and a screen agent by elderly users Marcel Heerink Hogeschool van Amsterdam Instituut voor Information Engineering Almere , Netherlands m . heerink @ hva . nl Ben Kröse University of Amsterdam Intelligent Systems Laboratory Amsterdam , Netherlands kröse @ science . uva . nl Bob Wielinga , Vanessa Evers University of Amsterdam Human Computer Studies Laboratory Amsterdam , Netherlands wielinga , evers { @ science . uva . nl } ABSTRACT Personal robots and screen agents can be equipped with social abilities to facilitate interaction . This paper describes our research on the influence of these abilities on elderly user’s acceptance of such a system . Experiments were set up in eldercare institutions where a robotic and screen agent with simulated conversational capabilities were used in a Wizard of Oz experiment . Both agents were used with two conditions : a more socially communicative ( the agent made use of a larger set of social abilities in interaction ) and a less socially communicative interface . Results show that participants who were confronted with the more socially communicative version of the robotic agent felt more comfortable and were more expressive in communicating with it . This suggests that the more socially communicative condition would be more likely to be accepted as a conversational partner . This effect was less strong however , with the screen agent , suggesting that embodiment plays a role in this . Furthermore , results did show a correlation between social abilities as perceived by participants and some aspects of technology acceptance for both systems , but this did not relate to the more and less socially communicative conditions . Evaluating the experiments and specifically the use of our acceptance model we suggest that this particular context of robotic and screen agents for elderly users requires the development of a more appropriate acceptance model which not only features technology acceptance , but also conversational acceptance . Categories and Subject Descriptors H . 5 . 2 . [ Information Interfaces And Presentation ] : User Interfaces - Evaluation / methodology . General Terms Measurement , Human Factors , Standardization , Theory Keywords User interfaces , Geriatrics , Technology acceptance model , Robot acceptance 1 . INTRODUCTION he expected growth of the elderly population and labor shortage in healthcare have inspired a number of researchers to explore the applicability of intelligent systems in general and robots and screen agents in particular to enable elderly people to live more independently [ 1 - 3 ] The functionalities are generally related to supporting independent living by supporting mobility , basic activities like eating , bathing , toileting , getting dressed , providing household maintenance , monitoring and maintaining safety [ 1 - 4 ] Some studies also focus on the companionship a robot might provide , or on the environment where they can be used and on the factors that influences user acceptance [ 3 , 5 , 6 ] , [ 7 ] . Still , if robots are to be used in the ( near ) future by elderly users , they have to be accepted by them and although a large category of elders may be open to facilitating technologies , technology acceptance remains a delicate matter that demands the use of sophisticated models [ 1 , 8 - 10 ] . This may be so for both robotic and screen agents : since research on the use of screen agents , reports that responses to physical and virtual embodied agent systems is similar [ 11 ] to robotic agents it seems apparent that the influences on acceptance are similar . Both are in fact systems that people often tend to engage to as if it were personalities as they appear to do with mediated systems in general [ 12 ] . A particular influence we are interested in is that of ( perceived ) social intelligence . Recent studies on interaction with robots and screen agents stress the importance of social intelligence even more so in a health - and eldercare environment [ 13 - 17 ] . This implies that a more social intelligent agent will be more effective in its communication - it can be expected to be easier and more pleasant to interact with and therefore would be indeed accepted more easily . However , many of these studies , especially those on social intelligence in human - agent interaction concerning elderly people , is based on either theoretical considerations or qualitative findings from a small set of users [ 1 , 3 , 7 , 18 ] . In this paper , we present two experiments in eldercare institutions to gather quantitative data investigating the influence of perceived social intelligence on the acceptance of a robotic and screen agent by elderly users . The experiments were carried out with an interface robot ( robotic agent ) called iCat and a screen agent called Annie , both used in a more and less socially communicative condition . In the following section we will report related work . Subsequently we will discuss the main concept of social intelligence , explain how it was simulated for the used interfaces and present how acceptance was measured . This is T © The Author 2009 . Published by the British Computer Society 430 HCI 2009 – People and Computers XXIII – Celebrating people and technology followed by a description of the set up of the experiments . After this , we will present the results , a discussion of the findings and conclusions . 2 . RELATED WORK Research involving tests of robots or agents with elderly users has been carried out with a seal shaped robot named Paro . In earlier studies [ refs ] , it was positioned in a group of elders where they could interact with it , mainly by caressing and talking to it [ 5 , 19 ] . The aim of this study was to observe the use of a robot in a setting described as ‘robot assisted activity’ and to prove that elders felt more positive after a few sessions . This was done by measuring the moods of the participants , both with a face scale form and the Profile of Mood States ( POMS ) questionnaire . More recently , research with Paro focuses on collecting physical data on elders that have been exposed to the robot to measure its effect on their wellbeing [ 20 ] . Other experiments that took place in an eldercare institution concerned a robot named Pearl [ 21 , 22 ] . The robot was used in open - ended interactions , delivering candies and used to guide elders through the building to the location of a physiotherapy department . The experiments with Paro and Pearl both registered a high level of positive excitement on the side of elders , suggesting that a robot would be accepted . In case of Paro it would merely be beneficial as a pet ( a study by Libin and Cohen - Mansfield [ 23 ] shows that a robotic pet is preferred over a plush toy cat ) and in case of Pearl it would be used as an actual assistant . However , these studies were not addressing the issue of robot acceptance by collecting quantitative data . Related research in which acceptance did play a significant role is described by De Ruyter et al . [ 24 ] . It concerned a robotic interface ( the iCat made by Philips ) , which was tested in a Wizard of Oz experiment where the robot was controlled remotely by an experimenter . This experiment was done in a laboratory setting , with adult , but not elderly participants . The participants were asked to program a DVD - recorder and to participate in an online auction , by using the iCat interface . They were exposed to an introvert and an extravert version of the iCat interface to see whether this difference in interaction would lead to different scores in degree of acceptance . To measure acceptance , the UTAUT questionnaire ( Unified Theory of Acceptance and the Use of Technology , [ 25 ] ) was used . UTAUT is a model that incorporates several influences on acceptance of technology , usually in the workplace . It covers the following constructs : performance expectancy , effort expectancy , attitude toward using technology , self - efficacy , anxiety and behavioral intention to use . The aim of the study was to find out to what extent participants would use the iCat at home after having experienced it . To see whether participants would perceive the extravert iCat to be more socially intelligent , a social behavior questionnaire ( SBQ ) was developed and used . The results showed that the extravert iCat was indeed perceived to be more socially intelligent and that this version also was more likely to be accepted by the user . The same robot was used in an experiment by Looije et al . [ 26 ] where it featured as a personal assistant for people with diabetes . Results showed that participants appreciated a more intelligent agent and a greater chance of usage for a more social robot . Research concerning experiments with screen agents for elders is reported by Bickmore and Picard [ 27 ] . The study focuses on the acceptance of a relational agent ( a screen agent that simulates to have a personal interest in the user ) appearing on a computer screen and functioning as a health advisor for older adults . Findings ( scores on questions related to affection , trust and acceptance ) indicate that the agent was accepted by the participants as a conversational partner on health and health behavior and rated high on issues like trust and friendliness . It was also found to be successful as a health advisor . Other research with the same agent [ 28 ] is focused on the ability to function in long term relationships in which social abilities also appear essential . It is linked to the notion of social presence [ 29 , 30 ] that people feel in interaction with systems and although it is not measured in the experiments presented in this paper , it can play a role in interpreting the responses of people when social abilities are perceived . Research comparing robots and agents generally shows that people respond to them in a similar way [ 11 , 31 , 32 ] . However , there might be differences in trust and it might be that the embodiment of a robot is more appealing and therefore people will invest more effort in communicating with it [ refs ] . It seems that research on robot and agent acceptance can be subdivided into two areas : acceptance of the robot in terms of usefulness and ease of use ( functional acceptance ) [ 1 , 21 , 22 ] , [ 24 ] , [ 25 ] and acceptance of the robot as a conversational partner with which a human or pet like relationship is possible ( social acceptance ) [ 5 , 7 , 19 , 27 ] . The experiments with Paro were more focused on social acceptance while the experiments with Pearl and iCat focused more on the acceptance of the robot regarding its functionalities . 3 . AGENTS AND SOCIAL ABILITIES 3 . 1 Defining social intelligence and social abilities In research concerning social aspects of autonomous interactive systems there are several definitions of the concept of social intelligence [ 16 ] . For the purpose of this study , our view of social intelligence and sociability will fit the description given for socially communicative robots within the classification by Breazeal [ 13 ] ( extended by Fong et al . [ 33 ] ) : robots providing a ‘natural’ interface by employing human - like social cues and communication modalities , that do not have to be based on deep models of social cognition . These social cues are in this study social abilities , embodied in the behavior of the robotic or screen agent . 3 . 2 Listing relevant abilities Since we are interested in the influence of social abilities in a robotic interface on its acceptance , it is important to look at ways to measure both acceptance and social abilities . A widely used tool to evaluate social abilities for humans is Gresham & Elliott ' s Social Abilities Rating System ( SSRS ) [ 34 ] . This tool usually is applied in social research , mostly on scholars and students , often related to disabilities . Nevertheless , the five basic features ( Cooperation , Empathy , Assertion , Self - Control and Responsibility ) match the aspects found in Human - Robot Interaction literature on social ( or sociable ) robots and agents [ 13 , 16 ] . Similar constructs also appear to be relevant abilities in related studies [ 24 , 35 , 36 ] . In comparable studies [ 24 , 31 ] , [ 32 ] we also found Trust and Competence to be relevant concepts in human - agent interaction , so we added those to our list . 431 M . Heerink et al . HCI 2009 – People and Computers XXIII – Celebrating people and technology This leads to the following social abilities to be relevant in human - agent interaction : ( 1 ) cooperate , ( 2 ) express empathy , ( 3 ) show assertivity , ( 4 ) exhibit self control , ( 5 ) show responsibility , ( 6 ) gain trust and ( 7 ) show competence In a recent study by Lee et al . [ 37 ] a similar attempt to list social abilities departs from Sternberg et al . ’s prototypes of socially competent behavior , based on lay people’s observations [ 38 ] . Although this is a very different list , the process to translate it into specific acts that can be mapped onto and agent’s body ( in case of Lee et al . the subject is an android ) it faces the same problems which is addressed as the criterion of ‘embodifiability’ . Only limited acts can represent a specific ability and some abilities can not be represented because of the limitations of the specific agent or the context . In section V we will describe our attempt to face this issue and explain how we embodied the above mentioned abilities . 3 . 3 Embodiment of social abilities Lee et al . [ 37 ] present a list of 27 behavioral codes with operational definitions that pass their criterion of ‘embodifiability’ . Although it is based on a different listing on perceived social behavior and is directed towards the specific category of androids , it covers the possibilities of embodiment of the above listed social abilities . With the specific agents ( not mobile , limited possibilities of body movement ) and the context of our experiments ( just a short time to get acquainted and a very limited set of tasks to perform ) we found only the following five behavioral features to be applicable ( the numbers refer to the above listed abilities ) : - listening attentively , for example by looking at the participant and nodding ( 1 , 2 ) , - being nice and pleasant to interact with , for example by smiling ( 1 , 2 , 7 ) , - remembering little personal details about people , for example by using their names ( 6 , 7 ) , - being expressive , for example by using facial expressions ( 2 , 3 ) , - admitting mistakes ( 5 , 6 ) . Most items are more or less represented - only the feature ‘exhibit self control’ ( 4 ) is not represented at all . In section V we will demonstrate how the behavior was actually implemented . 4 . USER ACCEPTANCE OF AGENTS IN ELDERCARE Research on how and why individuals adopt new information technologies has lead to several approaches with different focuses . In an attempt to construct a unifying model that incorporates the most widely used approaches , Venkatesh et al . [ 25 ] included the theoretical models that employ intention and / or usage as the key dependent variable . The result of this process is the UTAUT ( Unified Theory of Acceptance and Use of Technology ) model which has also been used in previous research in acceptance of robots [ 24 , 26 ] . The UTAUT model incorporates several influences on acceptance of technology , usually in the workplace . It covers the following constructs : performance expectancy , effort expectancy , attitude toward using technology , self - efficacy , anxiety and behavioral intention to use . As mentioned above in section II , when dealing with acceptance of robots , it is important to not only address acceptance in terms of the usefulness and ease of use of a system but also relational or social acceptance . This means that a user accepts the robot as a conversational partner , finds the robot’s social skills credible , sees the robot as an autonomous social being and is more likely to exhibit natural verbal and non - verbal conversational behavior as well as feeling comfortable in interacting with the robot . This means that a user will demonstrate more conversational engagement by being more expressive [ 39 ] and thus we can use behavioral clues as an indication of conversational acceptance [ 40 ] . 5 . EXPERIMENTS 5 . 1 Hypotheses The aim of this study is to evaluate the effect of social abilities in a robotic and screen agent on its acceptance by elders . In this specific experiment , acceptance was measured both as functional acceptance by using a technology acceptance model and conversational acceptance by using relevant questions and observations . The social abilities were implemented using the behavioral features as listed previously ( III ) . The hypotheses for this experiment were : ( 1 ) The implementation of social abilities has a measurable influence on the acceptance of an agent by elders in an eldercare environment . ( 2 ) An agent in which more social abilities are implemented will be perceived to be more social by its users . ( 3 ) The influence of social abilities on acceptance will be similar for a robotic and screen interface . 5 . 2 Experimental methods All experiments were carried out at eldercare institutions in Lelystad and Almere , the Netherlands . The experiments with the robotic agent took place in November and December 2005 , those with the screen agent in may 2006 5 . 2 . 1 Subjects Participants for each agent 42 elderly inhabitants of the institutions , living more or less independently , or needing daily care and who volunteered for the study . In the final analyses , we only used data produced by the second experiment . From these final data some participants were not included because of disturbances during the observation session and severe hearing problems . We asked the nursing staff to pre - selected participants whose mental condition was such that a questionnaire could be coped with . Otherwise there was no selection on mental or physical health features . 5 . 2 . 2 Procedure A specific interaction context was created where the iCat could be used in a Wizard of Oz fashion , which guaranteed a similar pattern for all sessions . The participants were first exposed to the iCat in groups ( 8 participants per group ) . After a short introduction by one of the researchers the robot told them what its possibilities were : an interface to domestic applications , monitoring , companionship , information providing , agenda - keeping and memorizing medication times and dates . They were told that for today’s experiment , the robot was only programmed to perform three tasks : setting an alarm , give directions to the nearest supermarket and giving the weather forecast for tomorrow . The experimenter subsequently demonstrated how to have a conversation with the robot in which it performed these tasks . 432 Measuring the influence of social abilities on acceptance of an interface robot and a screen agent by elderly users HCI 2009 – People and Computers XXIII – Celebrating people and technology After this group session , the participants were invited one by one to have a conversation with the robot , while the other group members were waiting in a different section of the room . The conversation was standardized as much as possible and we asked the participants to have the robot perform the three simple tasks . While being engaged in conversation , the participants’ behavior was observed by a researcher and recorded by camera . The group session and the individual session were both about 5 minutes , so the maximum time spent with the robot was 10 minutes for each participant . 5 . 2 . 3 Instruments The questions concerning acceptance were adapted from the UTAUT questionnaire . The adaptations were necessary for three reasons . First , some elders that piloted the questionnaire had difficulty indicating the level to which they agreed with statements and responded far better to questions than to statements . Also , because some of the participants had trouble reading , it turned out to be much easier for most of them if they were asked the questions by an interviewer , who could clarify the question if necessary . Furthermore , since UTAUT is developed for using technology at work , the questions needed to be adapted to a domestic user environment . This meant that questions that could not be adapted were omitted . We also added five questions concerning trust and perceived social abilities . The answers to the UTAUT questions were given on a five point scale ( 1 is ‘absolutely not’ , 2 is ‘not’ , etcetera ) . The final questionnaire contained 27 questions of which 19 were related to UTAUT constructs , each construct represented by two , three or four questions . Apart from the UTAUT constructs we added five questions concerning trust and social abilities ( SA ) ( also to be answered on a five point scale ) , two questions on experience with computers ( CE ) ( to be answered with yes or no ) and one question concerning the extent to which people felt ( un ) comfortable when talking to a robot ( CA ) ( to be answered with ‘yes’ , ‘no’ or ‘a bit’ ) . This means that there were three constructs added for this special context : ‘social abilities’ , ‘conversational acceptance’ and ‘computer experience’ . The issue of conversational acceptance was only represented by one question in the questionnaire , but also measured extensively by our observation model . Table 1 lists the questions . The sessions were recorded by video and were analyzed afterwards . During analysis verbal and non - verbal forms of conversational expressiveness were counted for each participant such as greeting ( with or without words ) nodding or shaking the head , smiling , looking surprised or irritated ( frowning ) , and moving towards or away from the robot . This list of items considering conversational expressiveness was generated by listing classical feedback gestures ( see [ 35 ] , [ 39 ] , [ 40 ] , [ 41 ] and [ 42 ] ) without categorizing them to specific communicative functions . We added the behavior of verbal greeting to it , because we considered this also a sign of relational feedback . 5 . 3 Agents 5 . 3 . 1 The robotic agent The robotic agent we used in our experiment is the iCat ( “interactive cat” ) , developed by Philips , also used in the experiments by De Ruyter et al . [ 24 ] and Looije et al [ 26 ] . The iCat is a research platform for studying social robotic user - interfaces . It is a 38 cm tall immobile robot with movable lips , eyes , eyelids and eyebrows to display different facial expressions to simulate emotional behavior . There is a camera installed in the iCat’s nose which can be used for different computer vision capabilities , such as recognizing objects and faces . The iCat’s base contains two microphones to record the sounds it hears and a loudspeaker is built in for sound and speech output . We used the iCat with a female voice . Table 1 . The questionnaire as used in the experiments Code Question CE 1 ) Have you ever used a computer ? CE 2 ) Do you still sometimes use a computer ? CA 3 ) Did you feel uncomfortable talking to a system ? PE 4 ) Do you think the system would be useful to you ? PE 5 ) Do you think the system would help you do things ? EE 6 ) As you have noticed , you control iCat by speech . Do you think you can easily communicate with it that way ? EE 7 ) Do you think you can quickly learn how to control iCat ? EE 8 ) Do you think iCat is easy to use ? SI 9 ) Do you think many people would be pleased if you would have an iCat ? SI 10 ) Are these people who’s opinion you value ? SI 11 ) Are these people who are important to you ? SI 12 ) Do you think the staff would be pleased if you would have an iCat ? SA 13 ) Did you find iCat a pleasant conversational partner ? SA 14 ) Would you consider iCat to be social ? SA 15 ) Would you trust iCat if it gave you advice ? SA 16 ) Would you follow iCat’s advice ? SA 17 ) Do you feel understood by iCat ? AT 18 ) Do you think it is a good idea to use iCat ? AT 19 ) Would you like to use iCat ? SE 20 ) Do you think you could work with iCat without any help ? SE 21 ) Do you think you could work with iCat if you could call someone for help ? SE 22 ) Do you think you could work with iCat if you had a good manual ? ANX 23 ) Do you feel at ease with iCat ? ANX 24 ) If you were to use iCat , would you be afraid to make mistakes or break something ? ITU 25 ) If you could have iCat , would you want it immediately ? ITU 26 ) If you could have iCat , would you want it in a few months ? ITU 27 ) If you could have iCat , would you want it in a few years ? UTAUT : Other : PE EE SI AT SE ANX ITU CE CA SA performance expectancy effort expectancy social influence attitude toward using technology self - efficacy anxiety intention to use computer experience conversational acceptance social abilities Items are translated – the list used in the experiments is in Dutch . 433 M . Heerink et al . HCI 2009 – People and Computers XXIII – Celebrating people and technology Fig . 1 The iCat 5 . 3 . 2 The screen agent The screen agent was developed for our tests by students of the Instituut voor Information Engineering in Almere , Netherlands . It features a female character being able to move the same facial parts as the iCat . It was used on a 17 inch lcd screen in combination with a webcam ( attached to the screen ) , a microphone and two speakers . Fig . 2 Screen agent Annie 5 . 3 . 3 Embodiment of social abilities in both agents For both agents the difference between the more social and less social condition was realized with the following behavioral features : • The agent in the more social condition would gaze straight at the conversation partner , the agent in the less social condition would look past the participant . • The agent would make a mistake by saying good morning when it would be afternoon or the other way round . When this would be made clear , the agent in the more social condition would admit this mistake , the agent in the less social condition would not . • The agent in the more social condition would smile when appropriate and express cheerfulness in its movements , the agent in the other condition did not do this . • The agent in the more social condition remembered the participant’s name and use it – the agent in the less social condition would not . • The agent in the more social condition would support the conversation partner by nodding and blinking , the agent in the less social condition would not do this . • The agent in the more social condition would be better in turn taking by waiting until the conversation partner finished speaking , the agent in the less social condition was less polite . 6 . RESULTS The first step in our analysis is to compare the effect of the two conditions on the acceptance of both agents . Then we will study correlations between constructs . Our focus in this is to find out whether a higher perception of social abilities correlates with a higher score on other constructs . Finally we present the results of a factor analysis on the combined scores , which enables us to evaluate the relation between questions and constructs . 6 . 1 Comparing the two conditions 6 . 1 . 1 Questionnaire Before analyzing the scores for the more and less socially communicative conditions , we calculated Cronbach’s Alpha for the UTAUT constructs to check internal consistency . Although some researchers consider an alpha higher than 0 . 62 high enough , generally in psychology , an alpha of 0 . 7 and higher is considered acceptable , [ 43 ] . The constructs were formed by joining and mediating the scores for the questions that represented it . An exception to this was the SI construct : it represented by four questions , but two ( questions 10 and 11 ) are dependent questions so only the first and last one were incorporated in the scores . As table 2 shows , the scores on the constructs for Social Influence and Anxiety were too low for both agents , implying that we should not take these constructs into account because of low internal consistency . To analyze the differences on the scores for the constructs , we used paired T - test . As is shown in Table 2 , in fact none of the UTAUT - constructs showed a significant difference for the two conditions for neither of the agents . Also the scores on the five non - UTAUT questions related to social abilities ( SA ) did not show any significant differences for the two conditions . Nevertheless , there is a pattern of higher score on constructs for the more social condition . Table 2 . Cronbach’s alpha and t - scores on two conditions Robot Screen agent Construct Alpha t Sig . ( 2t ) Alpha t Sig . ( 2t ) PE , 7649 - 0 , 1327 0 , 8953 , 8921 0 . 838 0 . 408 EE , 8610 0 , 3622 0 , 7195 , 6376 0 . 973 0 . 338 SI , 2997 * , 5060 * AT , 8889 0 , 4961 0 , 6230 , 7575 0 . 677 0 . 503 SE , 8942 0 , 4567 0 , 6509 , 6500 0 . 429 0 . 670 ANX , 4303 * , 1153 * ITU , 8954 0 , 4036 0 , 6891 , 8483 1 . 108 0 . 276 SA , 7466 1 , 477 0 , 149 , 7656 1 , 605 0 , 118 all constr . , 9346 , 9120 all items , 9084 , 9299 * Internal consistency for construct too low . 434 Measuring the influence of social abilities on acceptance of an interface robot and a screen agent by elderly users HCI 2009 – People and Computers XXIII – Celebrating people and technology As Table 3 shows , a significant difference was found between the two conditions of the robotic agent on the question ‘Did you feel uncomfortable talking to a robot’ ( question 3 in Table 1 , related to ‘conversational acceptance’ ) which could be answered with ‘yes’ , ‘a little’ or ‘no’ ( so this is a question with answers on a 3 - point scale ) . All ( 17 ) participants who experienced the more social condition reported to feel comfortable ( or ‘not uncomfortable’ ) about it , while 47 % of the ( 19 ) participants that encountered the less social condition reported to feel a little or very uncomfortable . However , Table 3 also shows that this difference did not occur in the results for the screen agent . Table 3 . T score question on Conversational Acceptance Condition Robot Screen agent N Mean t Sig . ( 2t ) N Mean t Sig . ( 2t ) more social 17 1 , 00 - 3 , 75 0 , 0015 18 1 , 28 - 0 , 263 0 , 794 less social 19 1 , 53 18 1 , 33 Table 4 . Two conditions for the combined scores Construct Cronbach’s Alpha t Sig . ( 2 - tailed ) CA ( q3 ) 2 , 223 0 , 029 PE , 8357 0 , 540 0 , 591 EE , 7737 0 , 900 0 , 371 SI , 4825 * AT , 8269 0 , 807 0 , 423 SE , 6450 * ANX , 2248 * ITU , 8746 1 , 026 0 , 308 SA , 7145 2 , 046 0 , 045 All constr . , 8824 1 , 280 0 , 205 Listed are UTAUT constructs , plus the question on feeling uncomfortable talking to the robotic agent ( CA ) and the non - UTAUT construct of Social Abilities ( SA ) Table 5 . Two - way ANOVA for all constructs source variable F sig . system ca , 003 , 955 pe , 461 , 499 ee , 075 , 785 sa , 015 , 903 at , 246 , 622 se 2 , 185 , 144 itu , 413 , 523 condition ca 7 , 834 * , 007 pe 3 , 125 , 082 ee 1 , 081 , 302 sa 4 , 033 * , 049 at , 845 , 361 se , 521 , 473 itu 1 , 440 , 235 After looking at these results for the robotic and screen agent , we combined the scores for both agents , calculated Cronbach’s Alpha and performed a t - test on the results ( see Table 4 ) . The non - UTAUT construct of Social Abilities shows a significant difference between the conditions , indicating the more social condition would be indeed recognized as such . A two - way ANOVA on the combined scores ( Table 5 ) confirms our findings , with significant scores for Conversational Acceptance and Social Abilities where the conditions are compared ( no interaction effects between robot and condition were found ) . 6 . 1 . 2 Behavior observation The different types of expressive behavior by participants during their interaction with the agent were counted and analyzed to measure conversational expressiveness , indicating conversational acceptance . Tables 6 and 7 show that , although none of these differences for individual behaviors are to be seen as significant ( which is not surprising considering the small amounts ) , there are remarkable differences and there is a certain pattern of more expressiveness . Table 6 . Conversational expressiveness for the robot Behavior more social ( N = 17 ) less social ( N = 19 ) t Sig . ( 2 - tailed ) Nodding head 66 54 0 , 3946 0 , 6958 Shaking head 16 15 - 0 , 1261 0 , 9005 non - verbal greeting 2 0 1 , 4552 0 , 1628 ' don ' t know ' gesture 3 0 1 , 0000 0 , 3306 move away 0 4 - 1 , 7253 0 , 1037 approach robot 17 7 1 , 6170 0 , 1152 Smile 42 30 1 , 1380 0 , 2631 Laugh 26 9 1 , 8477 0 , 0775 Surprise 2 0 1 , 4552 0 , 1628 Frown 1 2 - 0 , 5045 0 , 6189 Verbal greeting 36 21 1 , 9004 0 , 0672 Table 7 . Conversational expressiveness for the screen agent Behavior more social ( N = 17 ) less social ( N = 19 ) t Sig . ( 2 - tailed ) Nodding head 83 50 2 , 526 0 , 016 Shaking head 9 10 0 , 015 0 , 988 non - verbal greeting 3 2 0 , 603 0 , 551 ' don ' t know ' gesture 2 10 - 1 , 576 0 , 124 move away 5 6 - 0 , 137 0 , 892 approach robot 6 17 - 2 , 251 0 , 031 Smile 47 32 1 , 915 0 , 064 Laugh 16 17 0 , 157 0 , 876 Surprise 1 4 - 1 , 309 0 , 199 Frown 11 11 0 , 293 0 , 771 Verbal greeting 23 21 0 , 822 0 , 417 If we look at the total number of times a type of behavior ( positive / negative ) occurred for the different conditions ( Table 8 ) , there is a significant difference both in total expressions and in the total amount of expressions that can be categorized as positive expressions ( all behaviors except shaking head , move away and frown ) . 435 M . Heerink et al . HCI 2009 – People and Computers XXIII – Celebrating people and technology Table 8 . T sores on categorized behavioral observations Agent Robotic agent Screen agent Combined t Sig . t Sig . t Sig . Positive 2 , 450 0 , 020 2 , 017 0 , 052 2 , 902 0 , 005 Negative - 0 , 986 0 , 333 0 , 457 0 , 650 - 0 , 471 0 , 639 All items 2 , 063 0 , 047 2 , 024 0 , 051 2 , 607 0 , 011 6 . 2 Correlations To see how the scores on constructs interrelated we performed a correlation analysis , using the scores on UTAUT constructs , the construct of Social Abilities ( SA ) and the question on feeling uncomfortable talking to a robot . Table 9 . Pearson correlation between perceived social abilities and constructs for the robot Construct Correlation Sig . ( 2 - tailed ) Feeling uncomfortable - 0 , 337 0 , 045 performance expectancy 0 , 210 0 , 219 effort expectancy 0 , 580 0 , 000 social influence 0 , 332 0 , 048 Attitude toward using technology 0 , 473 0 , 004 self - efficacy 0 , 264 0 , 120 Anxiety - 0 , 453 0 , 006 intention to use 0 , 201 0 , 241 As Table 9 shows , the score on the ( non - UTAUT ) construct of social abilities did show correlations with some of the UTAUT constructs and with the question on feeling uncomfortable talking to the robotic agent . The scores for the screen agent show a correlation of Social Abilities with every item ( Table 10 ) . Table 10 . Pearson correlation between perceived social abilities and constructs for the screen agent Construct Correlation Sig . ( 2 - tailed ) feeling uncomfortable 0 , 517 0 , 001 performance expectancy 0 , 584 0 , 000 effort expectancy 0 , 625 0 , 000 social influence 0 , 536 0 , 001 Attitude toward using technology 0 , 744 0 , 000 self - efficacy 0 , 522 0 , 001 Anxiety 0 , 751 0 , 000 intention to use 0 , 729 0 , 000 6 . 3 Comparing the two agents Comparing the results of the robotic agent to those of the screen agent using t - tests , we found no significant differences between the scores for the constructs ( neither for the more social , nor for the less social condition ) . For the individual questions we also did not find any significant differences except for question 24 . On the question if they would be afraid to make mistakes or break something the score for the robotic agent was much higher for both conditions ( see Table 11 – note that this concerns a reversed score : more negative response scores higher ) . Table 11 . T score question on being afraid to make mistakes or break something comparing both agents Agent N Mean t Sig . ( 2 - tailed ) Robotic 36 4 . 06 - 3 , 108 0 , 003 Screen 36 4 , 83 6 . 4 Combining the scores of both agents To detect relationships among the questions beyond the existing constructs and to be able to explore alternative constructs by detecting hidden factors which underlie the questions , we performed a factor analysis . We used the combined scores of the agents and omitted questions 10 and 11 from the results , because these were dependent questions in the SI - construct . The questions on the Intention to Use were also not involved , because of their unique interrelation ( they ask the same question , just the time is varied ) and can thus form a construct that other constructs are to relate to . After a principal component analysis ( see Table 12 ) we were able to distinguish five factors on which the responses to the questions loaded . We regrouped the questions according to these factors , thus forming new constructs ( Table 13 ) . The first construct we called Performance and Attitude ( PA ) . It measures how respondents ‘see themselves’ both practically and socially in the light of the new technology . It features the questions 4 , 5 , 12 , 18 and 19 . We kept the questions 25 , 26 and 27 apart from this , because these Intention to Use questions were to remain an independent key construct that other constructs were to relate to . Table 12 . Rotated component matrix for the combined scores Question / Construct Component 1 2 3 4 5 3 CA , 645 4 PE , 782 5 PE , 781 6 EE , 498 7 EE , 782 8 EE , 629 9 SI , 667 12 SI , 704 13 SA , 629 14 SA , 720 15 SA , 846 16 SA , 851 17 SA , 759 18 AT , 726 19 AT , 581 20 SE , 770 21 SE , 750 22 SE , 798 23 ANX , 534 24 ANX , 481 Extraction Method : Principal Component Analysis . Rotation Method : Varimax with Kaiser Normalization . For questions loading on more components the highest score is listed . 436 Measuring the influence of social abilities on acceptance of an interface robot and a screen agent by elderly users HCI 2009 – People and Computers XXIII – Celebrating people and technology The second construct we called Effort , Ease and Anxiety ( EEA ) . It measures how easily people think they can adapt , learning how to work with the technology and overcoming eventual anxieties . It features questions 7 , 8 , 20 , 21 , 22 and 24 . The third construct we called Trust ( TR ) . It features questions 15 and 16 on how well they trust the system when it advises them . The fourth construct is called Sociability and Understanding ( SU ) . It measures how how sociable they rate the system and includes how well they feel understood . It features questions 6 , 14 and 17 . The fifth construct we called Enjoyment ( ENJ ) . It incorporates questions 3 , 9 , 13 and 22 and measures how pleased people feel and how pleased they think others will feel with the new technology . The last construct would still be Intention to Use . As stated earlier , this remains a construct for other questions and constructs to relate to . Applying Cronbach’s Alpha to the newly formed constructs ( Table 14 ) shows that overall they appear more consistent than the UTAUT constructs , although there is one weaker construct . The t - scores are generally higher , but still not leading to significant differences . 7 . DISCUSSION It is a remarkable development that our senior citizens might become the pioneers of a new era in which the company of robots becomes as usual as the use of cars . They might be among the first to get emotionally close to screen agents and robots . Our results on conversational acceptance suggest that this closeness will be slightly more probable for robots than for screen agents – it might be embodiment does have a say in this . Table 13 . Newly formed constructs Construct Questions Performance and Attitude ( PA ) Do you think the system would be useful to you ? Do you think the system would help you do things ? Do you think the staff would be pleased if you would have this system ? Do you think it is a good idea to use the system ? Would you like to use the system ? Effort , Ease and Anxiety ( EEA ) Do you think you can quickly learn how to control the system ? Do you think the system is easy to use ? Do you think you could work with the system without any help ? Do you think you could work with the system if you could call someone for help ? Do you think you could work with the system if you had a good manual ? If you were to use the system , would you be afraid to make mistakes or break something ? Trust ( TR ) Would you trust the system if it gave you advice ? Would you follow the system’s advice ? Sociability ( SO ) As you have noticed , you control the system by speech . Do you think you can easily communicate with it that way ? Would you consider the system to be social ? Do you feel understood by the system ? Enjoyment ( ENJ ) Did you feel uncomfortable talking to a system ? Do you think many people would be pleased if you would have this system ? Did you find the system a pleasant conversational partner ? Do you feel at ease with the system ? Table 14 . Two conditions for the combined scores - Cronbach’s alpha and t - scores for the alternative constructs Construct Cronbach’s Alpha t Sig . ( 2 - tailed ) PA , 8607 0 , 793 0 , 431 EEA , 8477 0 , 355 0 , 724 SO , 6186 * TR , 8860 1 , 892 0 , 063 ENJ , 7029 1 , 929 0 , 058 ITU , 8746 1 , 026 0 , 308 all constructs , 8406 1 , 539 0 , 129 * Internal consistency for construct too low . We are certain that while developing autonomous interactive systems like robots and screen agents for elderly users it is crucial to work on the implementation of social abilities in order to optimize interaction and acceptance . Our study did show a significant influence of these social abilities , in conversational acceptance and correlations , but remarkably not in scores of UTAUT constructs as was done in other studies that used ( an adapted version of ) UTAUT as an acceptance model [ 24 ] , [ 26 ] . This can be attributed to the relative shortness of the time that our participants were interacting and the simplicity of their tasks . This suggests that it may be necessary to collect data on longer - term interaction in which the experience of working with an agent goes beyond the first impression : results might in our case have been troubled somewhat by the ‘overwhelmingness’ of it . Also the simplicity of the tasks might be something to take a closer look at . It enabled us to set up a very strict scenario , allowing few surprises , but it also gave participants less of an impression of what an agent could do for them . Besides such differences concerning the experiment itself , there was a difference in the instruments used . The other experimenters modified UTAUT less then we did and used statements instead of a questionnaire , which could have influenced the outcome . Nevertheless our experiments did show the relevance of looking beyond technology acceptance when dealing with autonomous interactive systems and incorporate social acceptance . Besides , it demonstrated how a behavior analyses can complement a questionnaire based model . This is especially the case when dealing with elderly participants , because many of them are difficult to interview , either because of difficulty remembering what happened moments ago or because of difficulty focusing on anything longer than few minutes . To our experience , a questionnaire with 27 items is about the maximum . The behavior analysis also lead to what might be one of the most surprising results of our experiment : participants were more expressive when interacting with a more expressive robot or screen agent ( though the affect for the screen agent appeared less strong ) . This type of chameleon effect [ 44 ] has also been registered other research where it could be related to social acceptance [ 45 ] . The need to look for influences beyond technology acceptance is also illustrated by our factor analysis . We demonstrated how a re - arrangement of questions possibly results in more solid model , although this has of course to be confirmed by further research , involving not only tests that predict acceptance , but also data concerning acceptance in real use situations . 437 M . Heerink et al . HCI 2009 – People and Computers XXIII – Celebrating people and technology 8 . CONCLUSIONS The results show a significant correlation of social abilities with factors that influence acceptance , but the influence of social abilities has only been partly confirmed by the present research . We could however confirm that systems in which social abilities were incorporated were recognized as being more sociable . Regarding the differences between the robot and screen agent , we conclude there are some differences that have to be accounted for . The effect of participants being more expressive when interacting with a more expressive agent appears to be stronger for the robot than for the screen agent . Besides , when dealing with the robot , participants were more afraid to do something wrong or break something , which might in some cases increase anxiety . Concerning the acceptance model used , our experiments show that when dealing with robots and screen agents , a model that does not only focus on technology acceptance but also on conversational acceptance can be a more appropriate instrument . 9 . ACKNOWLEDGMENT This work was supported in part by the Hogeschool van Amsterdam and in part by the European Commission Division FP6 - IST Future and Emerging Technologies under Contract FP6 - 002020 ( Cogniron ) . 10 . REFERENCES [ 1 ] Forlizzi , J . , DiSalvo , C . , and Gemperle , F . “Assistive Robotics and an Ecology of Elderly Living Independently in Their Homes . ” Journal of HCI Special Issue on Human - Robot Interaction , V19 N1 / 2 , January , 2004 . [ 2 ] Pollack , M . “Intelligent Technology for an Aging Population : The Use of AI to Assist Elderly with Cognitive Impairment . ” AI Magazine , Summer ( 2005 ) [ 3 ] Taggart , W . , Turkle , S . , and Kidd , C . , “An interactive robot in a nursing home : Preliminary remarks . ” In “Towards Social Mechanisms of Android Science” , Cognitive Science Society , Stresa , Italy , July 2005 . [ 4 ] Mynatt , E . D . , Essa , I . , and Rogers , W . , “Increasing the opportunities for aging in place . ” Proceedings of the CUU 2000 Conference on Universal Usability New York : ACM . 65 - 71 . 2000 [ 5 ] Wada , K . , Shibata , T . , Saito , T . and Tanie , K . , “Effects of Robot Assisted Activity to Elderly People who Stay at a Health Service Facility for the Aged . ” Proceedings of the 2003 IEEE / RSJ Intl . Conference on Intelligent Robots and Systems , Las Vegas , Nevada , October 2003 . [ 6 ] Forlizzi , J . “Robotic products to assist the aging population . ” Interactions , volume 12 Issue 2 , 2005 [ 7 ] Graf , B . , Hans , M . , and Schraft , R . D . “Care - O - bot II - development of a next generation robotic home assistant . ” Autonomous robots 16 . 2 , 2004 . [ 8 ] Giuliani , M . ; Scopelliti , M . ; and Fornara , F . 2005 . Coping strategies and technology in later life . In Proceedings of AISB 2005 - Symposium “Robot Companions : Hard Problems and Open Challenges in Robot - Human Interaction” , Hatfield , UK . [ 9 ] Wilson , E . V . , and Lankton , N . K . . ( 2004 ) . Modeling Patients ' Acceptance of Provider Delivered E - Health . Journal of the American Medical Informatics Association 11 : 4 . 241 - 248 . [ 10 ] Zajicek M . , Arnold A . , ( 1999 ) , The ‘Technology Push ' and The User Tailored Information Environment , 5th European Research Consortium for Informatics and Mathematics , Workshop on ‘User interfaces for all’ , Dagstuhl , Germany [ 11 ] Bartneck , C . , Reichenbach , J . , Breemen , A . J . N . van , “In your face , robot ! The influence of a character ' s embodiment on how users perceive its emotional expressions , Design and Emotion . ” Proceedings of the Design and Emotion 2004 Conference Ankara , Turkey : 2004 . [ 12 ] Reeves , B . and Nash , C . " The Media Equation : How People Treat Computers , Televisions , and New Media as Real People and Places . " New York : Cambridge University Press , 1996 . [ 13 ] Breazeal , C . , “Towards sociable robots” , Robotics and Autonomous Systems 42 . 3 - 4 : 167 - 175 , 2003 [ 14 ] Breazeal , C . , “Socially intelligent robots” , Interactions , Volume 12 Issue 2 : 19 – 22 , 2005 [ 15 ] Dautenhahn , K . , Ogden , B . , and Quick , T . , “From embodied to socially embedded agents—implications for interaction aware robots” , Cognitive Systems Research ( 3 ) , 2002 [ 16 ] Dautenhahn , K . “Roles and functions of robots in human society : implications from research in autism therapy . ” Robotica , Volume 21 Issue 4 august 2003 [ 17 ] Duffy , B . R . “Anthropomorphism and The Social Robot . ” Robotics and Autonomous Systems , march ( 2003 ) : 170 - 190 . [ 18 ] Libin , A . “Therapeutic robocat for nursing home residents with dementia : Preliminary inquiry . ” American Journal of Alzheimer ' s Disease and Other Dementias , Vol . 19 - 2 , 2004 . [ 19 ] Shibata , T , Wada , K . , and Tanie , K . , “Statistical Analysis and Comparison of Questionnaire Results of Subjective Evaluations of Seal Robot in Japan and U . K . ” Proceedings of the 2003 IEEE International Conference on Robotics & Automation 2003 . [ 20 ] Wada , K . and Shibata , T . , “Robot Therapy in a Care House - Results of Case Studies” , Proceedings RO - MAN , Hertfordshire , September 2006 [ 21 ] Montemerlo , M . , Pineau , J . , Roy , N . , Thrun , S . , and Verma , V . , “Experiences with a Mobile Robotic Guide for the Elderly . ” Proceedings of the AAAI National Conference on Artificial Intelligence , 2002 . [ 22 ] Pineau , J . , Montemerlo , M . , Pollack , M . , Roy , N . and Thrun , S . “Towards robotic assistants in nursing homes : Challenges and results . ” Robotics and Autonomous Systems 42 ( 2003 ) : 271 - 281 . 2003 [ 23 ] Libin , A . , Cohen - Mansfield , J . " Therapeutic robocat for nursing home residents with dementia : preliminary inquiry . " American Journal of Alzheimer’s Disease and Other Dementias 19 . 2 ( 2004 ) : [ 24 ] De Ruyter , B . , Saini , P . , Markopoulos . , P . and Van Breemen , A . J . N . “Assessing the Effects of Building Social Intelligence in a Robotic Interface for the Home . ” Interacting with Computers , Volume 17 , Issue 5 , 1 September 2005 , 522 - 541 . 2005 438 Measuring the influence of social abilities on acceptance of an interface robot and a screen agent by elderly users HCI 2009 – People and Computers XXIII – Celebrating people and technology [ 25 ] Venkatesh , V , . Morris , M . G . , Davis , G . B . , and Davis , F . D . “User Acceptance of Information Technology : Towards a Unified View . ” MIS Quaterly , 27 ( 3 ) , 425 - 478 , 2003 [ 26 ] Looije , R . , F . Cnossen , M . A . Neerincx , “Incorporating Guidelines for Health Assistance into a Socially Intelligent Robot” , Proceedings RO - MAN , Hertfordshire , September 2006 [ 27 ] Bickmore , T . , and Picard R . W . , “Towards Caring Machines” , Proceedings of CHI , Vienna , April 2004 . [ 28 ] Bickmore , T . , and Picard R . W . , " Establishing and Maintaining Long - Term Human - Computer Relationships” , ACM Transactions on Computer - Human Interaction , Vol . 12 , No . 2 , June 2005 . [ 29 ] Lombard , M . and Ditton , T . B . At the heart of it all : The concept of presence . Journal of Computer - Mediated - Communication , 3 ( 2 ) , 1997 [ 30 ] Lee , Kwan Min , Clifford Nass . " Digital sociability : Designing social presence of social actors in human computer interaction . " Proceedings of the SIGCHI conference on Human factors in computing systems 2003 . [ 31 ] Shinozawa , K . , Reeves , B . , Wise , K . , Lim , S . , Maldonado , H . , and Naya , F . , “Robots as New Media : A Cross - Cultural Examination of Social and Cognitive Responses to Robotic and On - Screen Agent . ” Proceedings of Annual Conference of Internation Communication Association 2003 , pp . 998 - 1002 , 2003 . [ 32 ] Shinozawa , K , Naya , F . , Yamato , J . and Kogure , K . , “Differences in Effect of Robot and Screen Agent Recommendations on Human Decision - Making , ” IJHCS Vol 62 / 2 , pp 267 - 279 , 2005 . [ 33 ] Fong , T . , Nourbakhsh , I . , Dautenhahn , K . “A survey of socially interactive robots . ” Robotics and Autonomous Systems 42 , 2003 . [ 34 ] Gresham , F . M . , and Elliot , S . N . , “Social abilities rating system . ” Manua . Circle Pines : American Guidance Service , 1990 [ 35 ] Heylen , D . , Nijholt , A . , & Reidsma , D . , “Determining what people feel and think when interacting with humans and machines : notes on corpus collection and annotation . ” Proceedings 1st California Conference on Recent Advances in Engineering Mechanics , 2006 . [ 36 ] Gockley , R . , R . Simmons and J . Forlizzi , “Modeling Affect in Socially Interactive Robots” , Proceedings RO - MAN , Hertfordshire , September 2006 [ 37 ] Lee , B . , G . D . Hope , and N . J . Witts , “Could next generation androids get emotionally close ? ‘Relational closeness’ from human dyadic interactions” , Proceedings RO - MAN , Hertfordshire , September 2006 [ 38 ] Sternberg , R . J . , Conway , B . E . , Ketron , J . L . , & Bernstein , M . ( 1981 ) . “People ' s conceptions of intelligence . ” Journal of Personality and Social Psychology , 41 , 37 - 55 . [ 39 ] Sidner , C . L . ; Lee , C . , “Engagement During Dialogues with Robots . ” AAAI Spring Symposia , March 2005 . [ 40 ] Axelrod , L . and Hone , K . , “Identifying Affectemes : Transcribing Conversational Behaviour” , Proceedings of the Symposium on Conversational Informatics for Supporting Social Intelligence and Interaction , 2005 . [ 41 ] Cerrato , L . A . “Comparison between Feedback Strategies in Human - to - Human and Human - Machine Communication . ” Proceedings of ICSLP 2002 Denver , Colorado USA : 2002 . [ 42 ] Scherer , K . R . “Toward a dynamic theory of emotion : The component process model of affective states . ” Geneva Studies in Emotion and Communication , 1987 . [ 43 ] Decoster , J . & Claypool , H . M . , “A Meta - Analysis of Priming Effects on Impression Formation Supporting a General Model of Informational Biases . ” Personality and social psychology review , 8 ( 1 ) , 2004 . [ 44 ] Chartrand T . L . , Bargh J . A . “The chameleon effect : the perception - behavior link and social interaction . ” Journal of Personality and Social Psycholology , Jun ; 76 ( 6 ) , 1999 . [ 45 ] Kahn , P . H . , Jr . , N . G . Freier , B . Friedman , R . L . Severson , and E . Feldman , “Social and moral relationships with robotic others ? ” in Proceedings of the 13th International Workshop on Robot and Human Interactive Communication , Kurashiki , Okayama , Japan , 2004 439 M . Heerink et al . HCI 2009 – People and Computers XXIII – Celebrating people and technology