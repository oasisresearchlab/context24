TeleVIP : On - site Person Removal and Context Distillation Platform for Dedicated Telepresence Experience Mingyeol Kim mingyeol . kim @ postech . ac . kr POSTECH Pohang , Gyeongbuk , South Korea Inseok Hwang i . hwang @ postech . ac . kr POSTECH Pohang , Gyeongbuk , South Korea ABSTRACT For the application of telepresence robots , the on - site person usu - ally has been regarded as a main element in remote interaction . However , in the context of a remote tour , the visual presence of an on - site person unexpectedly interrupting a robot’s view may worsen the remote visitor’s viewing experience . Moreover , the pres - ence of a telepresence robot with its camera on may arise the privacy concerns of an on - site person . In this sense , we developed TeleVIP , a platform that provides telepresence applications with easy - to - use APIs to remove the figures of on - site people and selectively dis - till the useful information from the presence or context of on - site people , according to the application’s demand . We implemented a working prototype of TeleVIP and performed pilot experiments in terms of both quantitative metrics and qualitative results , indicating the preliminary usability and feasibility of TeleVIP . CCS CONCEPTS • Human - centered computing → Mixed / augmented reality . KEYWORDS Telepresence Robot ; Platform ; Human Removal ; Inpainting ; Context Distillation ACM Reference Format : Mingyeol Kim and Inseok Hwang . 2023 . TeleVIP : On - site Person Removal and Context Distillation Platform for Dedicated Telepresence Experience . In Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing & the 2023 ACM International Sympo - sium on Wearable Computing ( UbiComp / ISWC ’23 Adjunct ) , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico . ACM , New York , NY , USA , 5 pages . https : / / doi . org / 10 . 1145 / 3594739 . 3610704 1 INTRODUCTION Telepresence robots have been widely researched in a variety of applications and contexts where interaction with a remote space occurs . Among those contexts , remote communications mediated by a telepresence robot have been researched for various types of social environments [ 6 , 12 , 14 , 19 ] . In the context of remote communication , a person who locally exists in a remote space has been regarded as a main element for a remote participant to deal with . Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . UbiComp / ISWC ’23 Adjunct , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico © 2023 Copyright held by the owner / author ( s ) . ACM ISBN 979 - 8 - 4007 - 0200 - 6 / 23 / 10 . https : / / doi . org / 10 . 1145 / 3594739 . 3610704 In other scenarios , however , the presence of an on - site person could act as a main hindrance rather than a main interactive el - ement . A telepresence - mediated remote tour in a distant exhibit could be such a scenario . For the remote tour experience of visit - ing places like a distant art museum , the presence or movement of on - site people may unexpectedly or continuously interrupt the robot’s view , annoying the telepresence user’s viewing experiences . Although dealing with such on - site people would be common in real - world situations , there is an obvious social asymmetry between an on - site person and a remote visitor due to the limited mobility and expressiveness of the telepresence robot [ 2 ] , making the remote visitor feel more pressured than an on - site person . Conversely , the on - site person may feel privacy concerns about the presence of the telepresence robot roaming around with its cameras on ; it is little intuitively known to the on - site person about the identity or context of the remote user behind the telepresence robot . In this sense , we develop TeleVIP , a telepresence platform that supports the features of selective removal or alterations of the on - site people on the remote user’s perception . The design rationale of TeleVIP is that it could be deemed more beneficial to remove the figures of the on - site person from the view of the remote visitor , in favor of both parties’ viewing experiences . TeleVIP accepts appli - cations’ requests which could be either simple removal of on - site people and / or an event subscription upon the on - site people’s spe - cific contexts ( e . g . , bodily gestures ) to be met . Primarily , we apply the concept of diminishing perception on humans to the domain of telepresence by designing and implementing a remote tour system where on - site people are visually removed from the remote visitor’s view . Furthermore , while removing the perceptual presence of on - site people , TeleVIP distills the useful information from the on - site people and renders it in alternative , less - annoying , and privacy - preserving forms . For example , a degree of localized crowdedness in an exhibition or even a high behavioral similarity therein may indicate a location of a potential attraction [ 9 – 11 , 15 , 17 , 18 ] . Simply removing the whole presence of on - site people would result in such indications being lost . For the remainder of this paper , we outline the conceptual and technical background . Then we introduce the overall architecture of TeleVIP and articulate the major components , followed by the report of the preliminary results from our pilot experiments , including basic performance metrics and qualitative examples . 2 RELATED WORK Telepresence robots capable of networked video chat and self - mobility have been studied for their effectiveness in various social contexts such as hybrid work environments [ 19 ] , classrooms [ 6 ] , 123 UbiComp / ISWC ’23 Adjunct , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico Kim et al . Double 3 + 360 Cam . 360 Image FrontalView Semantic Segmentation HumanMask TELEA Inpainting InpaintedView Streaming to Client Pos . If visited grid Dir . Fetch Cached 360 Image Cached360 Image Cubemap CurrentView Request to Server False True CloudServer Request from Platform 360 Image Cubemap n - th Plane Local Storage of Platform Semantic Segmentation Deep Learning based Inpainting HumanMask InpaintedPlanes Inpainted360 Image for each cubemap plane ClientDevice Figure 1 : Architecture of TeleVIP PlatformAPI Human Removal API # 1 API # 2 Application APP # 1 APP # 2 APP # 3 Subscribe to Human Removal ProcessedCamera Stream Camera Stream Pos . + Dir . TelepresenceRobot API Camera Stream Position + Direction Hardware 360 Camera IMU Compass Request CloudServer Figure 2 : The Flow of Using APIs provided by the TeleVIP and work - separated families [ 12 ] . Such telepresence robots are es - pecially beneficial for remotely participating in a live social event since the user can freely roam around while visually interacting with the remote place in real - time [ 23 ] . The approach of purposefully removing or concealing the visual appearance of real - world scenes and objects has been researched in the domain of Diminished Reality ( DR ) [ 3 ] . Through DR , users perceive a visually simplified or even vacant version of the real environment . Several applications based on the concept of DR have been proposed . The target objects to be removed differ accord - ing to the purpose of each application . Humans have been also considered a target for the purpose of privacy protection for the on - site people [ 7 ] , removing possible occlusions to the scene that the telepresence user tries to see [ 16 ] , or better understanding the human - irrelevant scene properties [ 13 ] . Moreover , a set of technolo - gies including real - time inpainting to make the implementation of such DR applications feasible have been researched [ 22 ] . 3 DESIGN AND IMPLEMENTATION 3 . 1 TeleVIP TeleVIP sits between the basic telepresence functions ( e . g . , loco - motion , vision , sensing ) and multiple telepresence applications , providing key APIs to ease the development and execution of telep - resence applications demanding removal or alternative representa - tion of on - site people’s presence and context . Figure 1 depicts the architecture of TeleVIP . The key APIs of TeleVIP include human detection , human re - moval ( with an option to inpaint ) , and event subscription APIs . Invoking one of these APIs registers a respective persistent service which keeps running until de - registered by the original caller ap - plication . For example , once the application invokes the human removal APIs with the inpainting option turned on , the camera stream from now on is directed to the real - time human segmen - tation unit followed by the real - time inpainting unit , where the output stream is delivered to the application . The event subscription APIs allow the application to express various contextual conditions that it is interested in . Currently , TeleVIP supports the people density event and bodily gesture event , which detect a localized group of people above the application - specified spatial density [ 20 , 21 ] and one of the pre - defined body poses and gestures ( e . g . , pointing with an arm ) [ 24 , 27 ] , respectively . We designed TeleVIP to operate in both on - and off - device modes so that it selectively offloads computationally heavy tasks to a high - end cloud server . Below , we explain the systematic operation of our human removal API and outline other APIs . 3 . 2 Human Removal API In the human removal API , TeleVIP retrieves raw camera frames , and removes the figures of on - site people that appear on the frames . If a 360° camera is being used , TeleVIP refers to the user’s cur - rent viewport data to determine the rectangular portion to remove 124 TeleVIP UbiComp / ISWC ’23 Adjunct , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico Imageplane 𝐻 ( m ) 𝐿 ! ( px ) 𝐿 " ( px ) 𝑙 " ( px ) 𝑙 ! ( px ) Center of the bottom Bounding Box ( Object Detection ) 𝜃 ! 𝐷 ( m ) 𝑊 ( m ) Imageplane 𝜃 " 𝐷 ( m ) T op V i e w 𝑓 ( m ) 𝑓 ( m ) S i d e V i e w C a m e r a V i e w Figure 3 : Calculation of On - site Person’s Location based on Object Detection on - site person appearances therein . Two main techniques are em - ployed to remove on - site person appearances from the camera view : semantic segmentation and image inpainting . Human masks are extracted from the semantic segmentation , and the masked re - gions are filled through the image inpainting technique . To regulate the overall computational workload for these processings , TeleVIP caches each inpainted frame along with the robot’s self - odometry information on its local storage , for possible reuse upon the robot re - visiting this scene within a time limit of cache - staleness thresh - old . TeleVIP divides the space into equally sized square grids for cache management . Considering the trade - offs between latency and the quality of the inpainted results , TeleVIP employs multiple segmentation and inpainting libraries each specializing in on - or off - robot execution . Upon the robot entering a new region that has never been cached or was cached too past beyond the staleness limit , low - latency mod - els are preferred for immediate delivery to the remote user . For this purpose , TeleVIP has locally executable light - weight semantic segmentation ( Tensorflow BodyPix library ) and inpainting ( TELEA algorithm [ 25 ] ) , respectively . Otherwise , once - visited scenes are re - ferred to the off - device cloud server to refine the inpainting quality by applying a heavier image inpainting model [ 26 ] . 3 . 3 Crowdedness Detection API The presence or certain context of on - site people may convey use - ful information to the telepresence application even though those people’s visual appearances are removed . Currently , TeleVIP sup - ports distilling the degree of localized crowdedness and certain predefined bodily gestures from the on - site people . Below , we detail the crowdedness detection as an example . To de - termine localized crowdedness , TeleVIP needs to detect a group of people and their spatial density , which requires the distance infor - mation of each person detected in the scene . Upon using a camera with a depth sensor available , this could be trivially done . Upon using a 360° camera which does not support all - around depth infor - mation , the spatial location of each person can be still estimated under two assumptions : the robot is exploring on a flat ground , and the object detection model is accurate enough that the bottom side of the bounding box estimated is well aligned with a foot of the corresponding person . Let’s assume that a person is located at an arbitrary location ( 𝐷 ( 𝑚 ) , 𝑊 ( 𝑚 ) ) with respect to the 360° camera of a focal length 𝑓 ( 𝑚 ) , where the camera is installed at the telepresence robot’s height 𝐻 ( 𝑚 ) ( Figure 3 ) . Through this formulation , we can develop two proportional expressions : 𝐷 : 𝐻 = 𝐷 − 𝑓 : 𝐻 − 𝑙 ℎ × 2 𝑓 tan 𝜃 𝑣 𝐿 ℎ 𝐷 : 𝑊 = 𝑓 : 𝑙 𝑤 × 2 𝑓 tan 𝜃 𝑢 𝐿 𝑤 Then , we can derive the location of the person , i . e . , 𝐷 and 𝑊 , like below : 𝐷 = 𝐻𝐿 ℎ 2 𝑙 ℎ tan 𝜃 𝑣 𝑊 = 𝐻𝐿 ℎ 𝑙 𝑤 tan 𝜃 𝑢 𝐿 𝑤 𝑙 ℎ tan 𝜃 𝑣 Once the location of every on - site person has been calculated , we determine the spatial density of a localized group of people . If a group density remains above the application - specified value for more than 3 seconds ( an empirically chosen time window ) , TeleVIP notifies the application that a crowdedness event has happened , along with the on - site location information . The application may in - dicate this event to the telepresence user’s interface , e . g . , rendering a graphical icon associated with the detected on - site location . 4 RESULT Based on the design described in Section 3 , we implemented a working prototype of TeleVIP , and performed pilot experiments to evaluate the quantitative metric and qualitative results . The prototype was built in a local environment on Double 3 [ 1 ] , which is a telepresence robot commercially being on sale . We first evaluated the results of human removal in terms of la - tency metric . In Double 3 , the latency on semantic segmentation and image inpainting has been quantitatively evaluated . We run 125 UbiComp / ISWC ’23 Adjunct , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico Kim et al . Original image Human mask TELEA ( Double 3 ) HiFill ( Server ) Figure 4 : Qualitative Comparison on Inpainting Results be - tween the Local Environment of Double 3 and the Cloud Server MobileNet [ 8 ] provided by BodyPix library for semantic segmenta - tion , and run TELEA algorithm [ 25 ] for image inpainting . In actual implementation , the result of the semantic segmentation model has been dilated by 3 × 3 kernel to deal with inaccurate parts of a mask , which has been also included in a latency metric for seman - tic segmentation . We run the models on 6 images , frontal views captured by Ricoh Theta V . As a result , each semantic segmentation and image inpainting showed an average latency of 35 . 3 ms and 39 . 1 ms respectively , which indicates that the responsiveness of human removal operations can be guaranteed . We also evaluated the latency of inpainting method run on the high - end cloud server . We use HiFill [ 26 ] model for the server - side image inpainting , and run inference on a single GPU , NVIDIA RTX 6000 Ada . Although we didn’t use HiFill [ 26 ] model on Double 3 , we also checked the latency of running the same model on an embedded GPU of Double 3 , Jetson TX2 , to confirm whether it is rational to off - load the work on the server . As a result , the server showed a much shorter latency ( 91 . 0 ms ) than the local environment of Double 3 ( 837 ms ) , which indicates that offloading the work to the high - end server is a rational choice . Lastly , we qualitatively compared the results of human removal as illustrated in Figure 4 , and the server - side results showed a significantly better inpainting quality than the results from Double 3 as we expected in the design of TeleVIP . 5 DISCUSSION AND CONCLUSION In this paper , we developed a telepresence platform named TeleVIP which selectively provides a processed camera stream where all figures of on - site people are removed and useful information is distilled from a camera stream to applications according to their re - quests . In addition , we implemented a working prototype of TeleVIP on the local environment of Double 3 with APIs of human removal and a degree of localized crowdedness , and presented quantitative and qualitative results on the processing of TeleVIP . We expect that TeleVIP can be functionally more generalized for remote tour applications by adding more distillable features in a set of APIs , and further be a cornerstone for a remote tour system to apply the concept of diminishing perceptions on humans . To effectively sup - port a semi - interactive scenario , TeleVIP would be extended with additional APIs to assess the interaction probability for each person ( through a rule - based , history - based , or a proactive probing [ 4 ] ) , so that the human removal API could be invoked selectively by the application or direct user input [ 5 ] . ACKNOWLEDGMENTS This research was supported by the National Research Foundation of Korea ( NRF ) grant funded by the Korea government ( MSIT ) ( No . 2021R1A2C200386612 ) . This research was also partly supported by the Alchemist Project NTIS1415187366 ( 20025752 ) funded by the Ministry of Trade , Industry & Energy ( MOTIE , Korea ) , and by the KOCCA grant funded by the Ministry of Culture , Sports and Tourism in 2022 ( Project Number : R2021040136 , Contribution Rate : 20 % ) . REFERENCES [ 1 ] 2023 . Double Robotics . Retrieved Jun . 2 , 2023 from https : / / www . doublerobotics . com [ 2 ] AndrianaBoudouraki , JoelEFischer , StuartReeves , andSeanRintel . 2021 . " Ican’t get round " Recruiting Assistance in Mobile Robotic Telepresence . Proceedings of the ACM on Human - Computer Interaction 4 , CSCW3 ( 2021 ) , 1 – 21 . [ 3 ] Yi Fei Cheng , Hang Yin , Yukang Yan , Jan Gugenheimer , and David Lindlbauer . 2022 . Towards understanding diminished reality . In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems . 1 – 16 . [ 4 ] Sungjae Cho , Yoonsu Kim , Jaewoong Jang , and Inseok Hwang . 2023 . AI - to - HumanActuation : BoostingUnmodifiedAI’sRobustnessbyProactivelyInducing Favorable Human Sensing Conditions . Proceedings of the ACM on Interactive , Mobile , Wearable and Ubiquitous Technologies 7 , 1 ( 2023 ) , 1 – 32 . [ 5 ] Sungjae Cho , Jungeun Lee , and Inseok Hwang . 2022 . TouchVR : A Modality for InstantVRExperience . In AdjunctProceedingsofthe35thAnnualACMSymposium on User Interface Software and Technology . 1 – 3 . [ 6 ] Naomi T Fitter , Nisha Raghunath , Elizabeth Cha , Christopher A Sanchez , Leila Takayama , and Maja J Matarić . 2020 . Are we there yet ? Comparing remote learning technologies in the university classroom . IEEE Robotics and Automation Letters 5 , 2 ( 2020 ) , 2706 – 2713 . [ 7 ] Kunihiro Hasegawa and Hideo Saito . 2015 . Diminished reality for hiding a pedestrian using hand - held camera . In 2015 IEEE International Symposium on Mixed and Augmented Reality Workshops . IEEE , 47 – 52 . [ 8 ] Andrew G Howard , Menglong Zhu , Bo Chen , Dmitry Kalenichenko , Weijun Wang , Tobias Weyand , Marco Andreetto , and Hartwig Adam . 2017 . Mobilenets : Efficient convolutional neural networks for mobile vision applications . arXiv preprint arXiv : 1704 . 04861 ( 2017 ) . [ 9 ] Inseok Hwang , Qi Han , and Archan Misra . 2005 . MASTAQ : a middleware archi - tecture for sensor applications with statistical quality constraints . In Third IEEE International Conference on Pervasive Computing and Communications Workshops . IEEE , 390 – 395 . [ 10 ] Inseok Hwang , Hyukjae Jang , Taiwoo Park , Aram Choi , Youngki Lee , Chanyou Hwang , YangguiChoi , LamaNachman , andJunehwaSong . 2012 . Leveragingchil - dren’s behavioral distribution and singularities in new interactive environments : Study in kindergarten field trips . In Pervasive Computing : 10th International Con - ference , Pervasive 2012 , Newcastle , UK , June 18 - 22 , 2012 . Proceedings 10 . Springer , 39 – 56 . [ 11 ] Hyukjae Jang , Sungwon Peter Choe , Inseok Hwang , Chanyou Hwang , Lama Nachman , and Junehwa Song . 2012 . RubberBand : augmenting teacher’s aware - ness of spatially isolated children on kindergarten field trips . In Proceedings of the 2012 ACM conference on ubiquitous computing . 236 – 239 . [ 12 ] BumsooKang , InseokHwang , JinhoLee , SeungchulLee , TaegyeongLee , Youngjae Chang , and Min Kyung Lee . 2018 . My being to your place , your being to my place : Co - present robotic avatars create illusion of living together . In Proceedings of the 16th Annual International Conference on Mobile Systems , Applications , and Services . 54 – 67 . 126 TeleVIP UbiComp / ISWC ’23 Adjunct , October 08 – 12 , 2023 , Cancun , Quintana Roo , Mexico [ 13 ] Bumsoo Kang , Seungwoo Kang , and Inseok Hwang . 2021 . Momentmeld : Ai - augmented mobile photographic memento towards mutually stimulatory inter - generational interaction . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems . 1 – 16 . [ 14 ] Bumsoo Kang , Seungwoo Kang , and Inseok Hwang . 2023 . AI - driven Family Interaction Over Melded Space and Time . IEEE Pervasive Computing 22 , 1 ( 2023 ) , 85 – 94 . [ 15 ] Byoungjip Kim , SangJeong Lee , Youngki Lee , Inseok Hwang , Yunseok Rhee , and Junehwa Song . 2011 . Mobiiscape : Middleware support for scalable mobility pattern monitoring of moving objects in a large - scale city . Journal of Systems and Software 84 , 11 ( 2011 ) , 1852 – 1870 . [ 16 ] Taehyung Kim and Gerard J Kim . 2022 . Real - time and on - line removal of moving human figures in hand - held mobile augmented reality . The Visual Computer ( 2022 ) , 1 – 12 . [ 17 ] Wonjung Kim , Seungchul Lee , Youngjae Chang , Taegyeong Lee , Inseok Hwang , and Junehwa Song . 2021 . Hivemind : social control - and - use of IoT towards democratization of public spaces . In Proceedings of the 19th Annual International Conference on Mobile Systems , Applications , and Services . 467 – 482 . [ 18 ] Haechan Lee , Miri Moon , Taiwoo Park , Inseok Hwang , Uichin Lee , and Junehwa Song . 2013 . Dungeons & swimmers : designing an interactive exergame for swimming . In Proceedings of the 2013 ACM conference on Pervasive and Ubiquitous Computing adjunct publication . 287 – 290 . [ 19 ] Min Kyung Lee and Leila Takayama . 2011 . " Now , i have a body " uses and social norms for mobile remote presence in the workplace . In Proceedings of the SIGCHI conference on human factors in computing systems . 33 – 42 . [ 20 ] Youngki Lee , Younghyun Ju , Chulhong Min , Seungwoo Kang , Inseok Hwang , and Junehwa Song . 2012 . Comon : Cooperative ambience monitoring platform with continuity and benefit awareness . In Proceedings of the 10th international conference on Mobile systems , applications , and services . 43 – 56 . [ 21 ] Youngki Lee , Seungwoo Kang , Chulhong Min , Younghyun Ju , Inseok Hwang , and Junehwa Song . 2015 . CoMon + : A cooperative context monitoring system for multi - device personal sensing environments . IEEE Transactions on Mobile Computing 15 , 8 ( 2015 ) , 1908 – 1924 . [ 22 ] Shohei Mori , Sei Ikeda , and Hideo Saito . 2017 . A survey of diminished reality : Techniques for visually concealing , eliminating , and seeing through real objects . IPSJ Transactions on Computer Vision and Applications 9 , 1 ( 2017 ) , 1 – 14 . [ 23 ] Yeonju Oh , Ramviyas Parasuraman , Tim McGraw , and Byung - Cheol Min . 2018 . 360 vr based robot teleoperation interface for virtual tour . In Proceedings of the 1st International Workshop on Virtual , Augmented , and Mixed Reality for HRI ( VAM - HRI ) . [ 24 ] Taiwoo Park , Jinwon Lee , Inseok Hwang , Chungkuk Yoo , Lama Nachman , and Junehwa Song . 2011 . E - gesture : a collaborative architecture for energy - efficient gesture recognition with hand - worn sensor and mobile devices . In Proceedings of the 9th ACM Conference on Embedded Networked Sensor Systems . 260 – 273 . [ 25 ] AlexandruTelea . 2004 . Animageinpaintingtechniquebasedonthefastmarching method . Journal of graphics tools 9 , 1 ( 2004 ) , 23 – 34 . [ 26 ] ZiliYi , QiangTang , ShekoofehAzizi , DaesikJang , andZhanXu . 2020 . Contextual residual aggregation for ultra high - resolution image inpainting . In Proceedings of the IEEE / CVF conference on computer vision and pattern recognition . 7508 – 7517 . [ 27 ] Chungkuk Yoo , Inseok Hwang , Eric Rozner , Yu Gu , and Robert F Dickerson . 2016 . Symmetrisense : Enabling near - surface interactivity on glossy surfaces using a single commodity smartphone . In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems . 5126 – 5137 . 127