Ubiquitous Computing MICHAEL BERNSTEIN CS 376 Reminders  First critiques were due this morning  Idea Generation ( Round One ) due Friday  Idea Generation ( Round Two ) , with a team , due next Friday  Next week :  Social computing  Design and creation 2 3 Flickr : GARNET Ubiquitous ? Ubiquitous ? 4 Flickr : GARNET Ubicomp Vision  ‘A new way of thinking about computers in the world , one that takes into account the natural human environment’ where computers will ‘vanish into the background’ , weaving ‘themselves into the fabric of ever yday life until they are indistinguishable from it . ’ 5 Mar k Weiser ( late 80s / ear ly 90s ) , quotes compiled by Daniel Fallman Beyond Weiser  Ubiquitous computing is a set of visions for distributing computation into the environment .  These visions require interactive systems to become reactive , context - aware , ambient , and embedded in ever yday activities . 6 PAPERS CHI 97 * 22 - 27 March 1997 Tangible Bits : Towards Seamless Interfaces between People , Bits and Atoms Hiroshi Ishii and Brygg Ullmer MIT Media Laboratory Tangible Media Group 20 Ames Street , Cambridge , MA 02139 - 4307 USA { ishii , ullmer } @ media . mit . edu A B S T R A C T This paper presents our vision of Human Computer Interaction ( HCI ) : " Tangible Bits . " Tangible Bits allows users to " grasp & manipulate " bits in the center of users’ attention by coupling the bits with everyday physical objects and architectural surfaces . Tangible Bits also enables users to be aware of background bits at the periphery of human perception using ambient display media such as light , sound , airflow , and water movement in an augmented space . The goal of Tangible Bits is to bridge the gaps between both cyberspace and the physical environment , as well as the foreground and background of human activities . This paper describes three key concepts of Tangible Bits : interactive surfaces ; the coupling of bits with graspable physical objects ; and ambient media for background awareness . We illustrate these concepts with three prototype systems – the metaDESK , transBOARD and ambientROOM – to identify underlying research issues . K e y w o r d s tangible user interface , ambient media , graspable user interface , augmented reality , ubiquitous computing , center and periphery , foreground and background INTRODUCTION : FROM THE MUSEUM Long before the invention of personal computers , our ancestors developed a variety of specialized physical artifacts to measure the passage of time , to predict the movement of planets , to draw geometric shapes , and to compute [ 10 ] . We can find these beautiful artifacts made of oak and brass in museums such as the Collection of Historic Scientific Instruments at Harvard University ( Fig . 1 ) . We were inspired by the aesthetics and rich affordances of these historical scientific instruments , most of which have disappeared from schools , laboratories , and design studios and have been replaced with the most general of appliances : personal computers . Through grasping and manipulating these instruments , users of the past must have developed rich languages and cultures which valued haptic interaction with real physical objects . Alas , much of this richness has been lost to the rapid flood of digital technologies . We began our investigation of " looking to the future of HCI " at this museum by looking for what we have lost with the advent of personal computers . Our intention was to rejoin the richness of the physical world in HCI . BITS & ATOMS We live between two realms : our physical environment and cyberspace . Despite our dual citizenship , the absence of seamless couplings between these parallel existences leaves a great divide between the worlds of bits and atoms . At the present , we are torn between these parallel but disjoint spaces . We are now almost constantly " wired " so that we can be here ( physical space ) and there ( cyberspace ) simultaneously [ 14 ] . Streams of bits leak out of cyberspace through a myriad of rectangular screens into the physical world as photon beams . However , the interactions between people and cyberspace are now largely confined to traditional GUI ( Graphical User Interface ) - based boxes sitting on desktops or laptops . The interactions with these GUIs are separated from the ordinary physical environment within which we live and interact . Although we have developed various skills and work practices for processing information through haptic interactions with physical objects ( e . g . , scribbling messages on Post - It™ notes and spatially manipulating them on a wall ) as well as peripheral senses ( e . g . , being aware of a change in weather through ambient light ) , most of these practices are neglected in current HCI design because of the lack of diversity of input / output media , and too much bias towards graphical output at the expense of input from the real world [ 3 ] . Outline of This Paper To look towards the future of HCI , this paper will present our vision of Tangible Bits and introduce design projects including the metaDESK , transBOARD and ambientROOM systems to illustrate our key concepts . This paper is not intended to propose a solution to any one single problem . Rather , we will propose a new view of interface and raise a set of new research questions to go beyond GUI . FROM DESKTOP TO PHYSICAL ENVIRONMENT In 1981 , the Xerox Star workstation set the stage for the first generation of GUI [ 16 ] , establishing a " desktop metaphor " which simulates a desktop on a bit - mapped Figure 1 Sketches made at Collection of Historical Scientific Instruments at Harvard University Permission to make digital / hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage , the copyright notice , the title of the publication and its date appear , and notice is given that copyright is b y permission of th ACM , Inc . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires specific permission and / or a fee . CHI ‘97 , Atlanta GA USA Copyright 1997 ACM 0 - 89791 - 802 - 9 / 97 / 03 . . $ 3 . 50 Tangible Computing  Directly - manipulable physical interfaces to data and computation  ‘Pure’ form of ubicomp in that there is no computer to be seen 7 Urp : a luminous - tangible wor kbench for urban planning and design . Under kofﬂer , Ishii . CHI ’99 . Urp : a luminous - tangible wor kbench for urban planning and design . Under kofﬂer , Ishii . CHI ’99 . Ishii , Mazalek , Lee . Bottles as a minimal interface to access digital information . CHI EA ’01 . Ryokai , Mar ti , Ishii . I / O Br ush : Drawing with Ever yday Objects as Ink . CHI ’04 . Transforming data into physical form  What Weiser calls one of the ﬁrst calm technologies : Live Wire , a wire on a stepper motor , monitoring ethernet trafﬁc [ Jeremijenko ’95 ] 12 Themes of ubicomp research  Activity sensing and monitoring  Context - aware computing  Input techniques 13 Activity Recognition from User - Annotated Acceleration Data Ling Bao and Stephen S . Intille Massachusetts Institute of Technology 1 Cambridge Center , 4FL Cambridge , MA 02142 USA intille @ mit . edu Abstract . In this work , algorithms are developed and evaluated to de - tect physical activities from data acquired using ﬁve small biaxial ac - celerometers worn simultaneously on di ﬀ erent parts of the body . Ac - celeration data was collected from 20 sub jects without researcher su - pervision or observation . Sub jects were asked to perform a sequence of everyday tasks but not told speciﬁcally where or how to do them . Mean , energy , frequency - domain entropy , and correlation of acceleration data was calculated and several classiﬁers using these features were tested . De - cision tree classiﬁers showed the best performance recognizing everyday activities with an overall accuracy rate of 84 % . The results show that although some activities are recognized well with sub ject - independent training data , others appear to require sub ject - speciﬁc training data . The results suggest that multiple accelerometers aid in recognition because conjunctions in acceleration feature values can e ﬀ ectively discriminate many activities . With just two biaxial accelerometers – thigh and wrist – the recognition performance dropped only slightly . This is the ﬁrst work to investigate performance of recognition algorithms with multiple , wire - free accelerometers on 20 activities using datasets annotated by the sub jects themselves . 1 Intro duction One of the key di ﬃ culties in creating useful and robust ubiquitous , context - aware computer applications is developing the algorithms that can detect context from noisy and often ambiguous sensor data . One facet of the user’s context is his phys - ical activity . Although prior work discusses physical activity recognition using acceleration ( e . g . [ 17 , 5 , 23 ] ) or a fusion of acceleration and other data modalities ( e . g . [ 18 ] ) , it is unclear how most prior systems will perform under real - world conditions . Most of these works compute recognition results with data collected from sub jects under artiﬁcially constrained laboratory settings . Some also evalu - ate recognition performance on data collected in natural , out - of - lab settings but only use limited data sets collected from one individual ( e . g . [ 22 ] ) . A number of works use naturalistic data but do not quantify recognition accuracy . Lastly , research using naturalistic data collected from multiple sub jects has focused on A . Ferscha and F . Mattern ( Eds . ) : PERVASIVE 2004 , LNCS 3001 , pp . 1 – 17 , 2004 . c ⃝ Springer - Verlag Berlin Heidelberg 2004 Activity recognition  Sense the user’s physical state by using minimally invasive sensors  For example , wearing ﬁve 2d accelerometers and predicting tasks like walking , watching TV , reading , eating . . . 14 Activity recognition  Detecting the user’s state is powerful , but often involves invasive sensors .  So , monitor the environment rather than the user : energy use , water use , activities of an aging population 15 Patel et al . At the Flick of a Switch : Detecting and Classifying Unique Electrical Events on the Residential Power Line . Ubicomp ’07 . Environmental Sensors  Monitor secondar y signals in the environment : biosensors ! 17 Nurturing Natural Sensors Stacey Kuznetsov , William Odom , James Pierce , Eric Paulos Human - Computer Interaction Institute Carnegie Mellon University Pittsburgh , PA , USA { stace , wodom , jjpierce , paulos } @ cs . cmu . edu ABSTRACT Sensing has played a significant role in the evolution of ubiquitous computing systems , enabling many of today’s compelling interactive and ubiquitous experiences . In this paper , we argue for expanding the current landscape of sensing to include living organisms such as plants and animals , along with traditional tools and digital devices . We present a field study of ten individuals who routinely work with living organisms such as plants , fish , reptiles and bees , and rely on these organisms as well as analog instruments and digital sensors to infer environmental conditions and inform future actions . Our findings offer a new perspective on everyday biomarkers , and we use the lens of organic and non - digital sensing to reflect on current sensing paradigms in ubiquitous computing . We conclude with three opportunity areas to help frame future work in ubiquitous sensing : ( 1 ) incorporating traditional technologies and living systems into ubiquitous sensing applications , ( 2 ) developing information technologies that teach new ways of ‘seeing’ , and ( 3 ) supporting richer forms of metadata to unite stakeholders through their actions , interests and concerns . Author Keywords Phenology , biomarkers , sensors INTRODUCTION Over the past few decades , UbiComp and HCI communities have explored a range of sensing systems to support our interactions with local environments , as well as the people , technologies and artifacts inhabiting them . While a sensor can be broadly defined as any device that responds to a physical stimulus , the majority of prior and ongoing research in UbiComp has understandably focused on electronic instantiations of sensing devices . In this paper , we present the practices of gardeners , beekeepers , zoologists and other ‘experts’ in the domain of organic and non - digital sensing to reflect on the question , when is an electronic sensor appropriate or necessary in a given context ? Visionary research has often turned to groups outside ‘mainstream’ user populations to productively inform new areas of inquiry within the UbiComp community [ e . g . , 39 ] . Similarly , we explore the values and practices of individuals who use everyday biomarkers - common biological organisms that express information about an ecosystem or its many parts . We present a field study of 10 participants who routinely work with living organisms such as plants , fish , reptiles or bees . While many people make inferences about the environment ( e . g . , a cloudy sky suggests the possibility of rain ) , we expect our sample of participants to be more attuned to environmental processes as their work explicitly engages with living systems . Specifically , we focus on participants’ use of digital devices , traditional tools and living organisms to infer environmental conditions and inform actions related to local ecosystems . In doing so , we reflect on current sensing paradigms in ubiquitous computing through the lens of organic and non - electronic sensing . Our findings offer new insights into everyday biomarkers and serve to expand UbiComp visions of sensing to include more traditional instruments as well as the living organisms themselves . We conclude with three opportunity areas to help critically frame future work in ubiquitous sensing : ( 1 ) leveraging non - digital sensors , ( 2 ) designing technologies that teach new ways of ‘seeing’ , and ( 3 ) enriching practices of data collection and sharing . WHAT IS A SENSOR ? In what follows , we present several categories of electronic sensing technologies that emerged from our review of the UbiComp and HCI literature . Although these categories are by no means exhaustive or exclusive , they help contextualize the diverse range of sensors currently studied by these communities . Figure 1 . Everyday biomarkers : reptile posture suggesting a disturbance to the environment ( top left ) ; scale larvae signifying a pest problem ( top right ) ; bee behavior reflecting local weather and bloom cycles ( bottom left ) ; fish appearance indicating water quality and parasite levels ( bottom right ) . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . UbiComp ‘11 , Sep 17 – Sep 21 , 2011 , Beijing , China . Copyright 2011 ACM 978 - 1 - 60558 - 843 - 8 / 10 / 09 . . . $ 10 . 00 . Hodges , et al . SenseCam : A retrospective memor y aid . Ubicomp ’06 . Context - aware computing  Collect information about the user’s environment , and use it to customize their computing experience  Some types of context : location , social surroundings , activity level  But beware overuse of the term ‘context’ ! 19 Towards a Better Understanding of Context and Context - Awareness Anind K . Dey and Gregory D . Abowd Graphics , Visualization and Usability Center and College of Computing , Georgia Institute of Technology , Atlanta , GA , USA 30332 - 0280 { anind , abowd } @ cc . gatech . edu Abstract . The use of context is important in interactive applications . It is par - ticularly important for applications where the user’s context is changing rap - idly , such as in both handheld and ubiquitous computing . In order to better un - derstand how we can use context and facilitate the building of context - aware applications , we need to more fully understand what constitutes a context - aware application and what context is . Towards this goal , we have surveyed existing work in context - aware computing . In this paper , we provide an over - view of the results of this survey and , in particular , definitions and categories of context and context - aware . We conclude with recommendations for how this better understanding of context inform a framework for the development of context - aware applications . 1 Introduction Humans are quite successful at conveying ideas to each other and reacting appropri - ately . This is due to many factors : the richness of the language they share , the com - mon understanding of how the world works , and an implicit understanding of every - day situations . When humans talk with humans , they are able to use implicit situ - ational information , or context , to increase the conversational bandwidth . Unfortu - nately , this ability to convey ideas does not transfer well to humans interacting with computers . In traditional interactive computing , users have an impoverished mecha - nism for providing input to computers . Consequently , computers are not currently enabled to take full advantage of the context of the human - computer dialogue . By improving the computer’s access to context , we increase the richness of communica - tion in human - computer interaction and make it possible to produce more useful computational services . In order to use context effectively , we must understand both what context is and how it can be used . An understanding of context will enable application designers to choose what context to use in their applications . An understanding of how context can be used will help application designers determine what context - aware behaviors to support in their applications . Context - aware computing  Detection of context is typically the hardest problem  Some successes :  Localization using wiﬁ access points [ LaMarca et al . , Per vasive ’05 ]  Social networks using mobile phones [ Eagle and Pentland , Per s . Ubiq . Comp . ’06 ]  Google Now 20 Wearable Computing Steve Mann , MIT Media Lab 21 Wearable Computing  Lilypad Arduino [ Buechley et al . , CHI ’08 ]  And of course , Google Glass 22 Input and interaction  Effective control of ubiquitous computing systems without the traditional input channels  Gesture , on - body , on - wall , on - ﬂoor : on any surface available 23 Harrison , Morris , Tan . Skinput : Appropriating the Body as an Input Surface . CHI ’10 . Harrison , Benko , Wilson . Omnitouch : Wearable Multitouch Interaction Ever ywhere . UIST ’11 . 26 Yao et al . . PneUI : pneumatically actuated soft composite materials for shape changing interfaces . UIST ’13 . Follmer , Leithinger , Olwal , Hogge , Ishii . inFORM : Dynamic Physical Affordances and Constraints through Shape and Object Actuation . UIST ’13 . What’s difﬁcult about ubiquitous computing research ?  Noisy inputs  Sensor fusion  Context is only a proxy for human intent [ Dey , in Kr umm 2009 ]  Lack of standardization in interface patterns  Privacy 28 What are open opportunities in ubiquitous computing research ?  The hardware is increasingly easy to ﬁnd and to program 29 Arduino Uno What are open opportunities in ubiquitous computing research ?  New I / O opportunities are coming out ever y year — from industr y and from HCI researchers 30 Next ubicomp topics  Per vasive  Infrastructure - mediated sensing and the humantenna  Interaction  Muscle - computer interfaces and Skinput  Global Citizenship  Avaaj Otalo : cell phone - based information networks  Design tools  Midas : fabricating custom capacitive touch sensors to prototype interactive objects  Intelligent User Interfaces  Predicting human interruptability with sensors 31