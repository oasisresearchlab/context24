SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION 70 acm Inroads 2015 June • Vol . 6 • No . 2 SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION cybersecurityeducation of analysis and visualization tools . Even with the use of such tools only expert users can usually make sense of the output produced by the tools . Further , scoring is inconsistent across competitions and it’s not clear which team is winning and how scores are calculated ; sometimes even by the competitors themselves . One of the techniques that LUCID employs to engage the au - dience is sensemaking . Broadly defined as finding meaning in a situation [ 25 ] , the term sensemaking is used in a variety of fields , including network security [ 2 , 8 , 15 , 22 , 29 ] , education and learning sciences [ 23 ] , and data analytics [ 22 ] . In human computer interac - tion ( HCI ) , sensemaking refers to the cognitive act of understand - ing information [ 7 , 25 ] . Since sensemaking is an essential part of learning , we suggest that the tool will ultimately serve to enhance learning and understanding in network security principles and practice . LUCID aims to capture computer and network activities for all the competing teams and present them to the spectator in a user - friendly manner using state - of - the - art broadcasting , visu - alization of computer and network attack and defense , anima - tion and commentary . Although visualization has been utilized at some large - scale cyber defense competitions , such as the Mid - Atlantic Collegiate Cyber Defense Competition ( MACCDC ) [ 21 ] , DEF CON [ 6 ] , and Maryland Cyber Challenge and Con - ference ( MDC3 ) [ 19 ] , it is still used only in a limited way . Fur - ther , it does not engage the spectator in a meaningful way , and In a cyber defense competition , teams of students are charged with managing and defending an enterprise network against secu - rity attacks from a team of experienced hackers . In the case of the Collegiate Cyber Defense Competition ( CCDC ) , the stated pur - pose of these exercises is education , with a goal of helping students better defend computer systems and networks against attacks [ 12 ] . However , the number of student participants engaged in these competitions has been relatively small , especially among underrep - resented minorities and women [ 25 ] . One of the reasons for this lack of representation to date may be attributed to the fact that the competitions are mainly beneficial and of interest to participants , such as student teams , cybersecurity experts , and administrators and judges of the games . For a spectator of a competition , the ex - citement and educational value do not necessarily transfer . Our hypothesis is that spectators’ excitement and learning outcomes are associated with the audience ability to extract , visualize and comprehend the details of the game as they unfold . The proposed visualization system , LUCID , aims to help spec - tators at a cyber defense competition—especially novice specta - tors—make sense of the ongoing activities of a competition . Unlike other competitions such as chess , where you can see which moves players make , or a basketball game where you can see where the ball is and easily understand the scoring , the activities in a cyber de - fense competition take place on a network and on computers . The strategic moves in the competition cannot be seen without the use LUCID : A VISUALIZATION AND BROADCAST SYSTEM FOR CYBER DEFENSE COMPETITIONS Claude Turner , Jie Yan , Dwight Richards , Pamela O’Brien , Jide Odubiyi , Quincy Brown I n this article , we discuss LUCID , a visualization and broadcast system targeted to improving a spectator’s ability to understand and make sense of cyber defense competitions . The system aims to engage the spectator by presenting information pertinent to understanding the real - time events of the competition as they unfold . It accomplishes this through a combination of techniques , including real - time network security visualization , live video and audio monitoring , animation , computer graphics , user profiling , and commentary . We examine , specifically , how the LUCID system enables the audience to make sense of ongoing activities in a cyber defense competition . 2015 June • Vol . 6 • No . 2 acm Inroads 71 SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION A CCDC is typically composed of four primary teams that are designated using color associations . These include the Blue , Green , Red , and White teams described here . ■ Blue Teams : These are typically the competitors . Each Blue Team is composed of between four and eight students who are tasked with running their own pseudo - corporate network . ■ Green Team : This team of local professionals and graduate students play the role of users of the services provided by the Blue Teams . Each Blue Team provides the Green Team with the credentials necessary to access the services available on their respective networks . ■ Red Team : The Red Team consists of local professionals , professors , and advanced graduate students who are tasked with attacking the Blue Teams’ networks . These individuals are able to use almost any means necessary to compromise the Blue Teams’ systems . ■ White Team : The White Team facilitates the role of administra - tors for the competition as a whole . Members of the White Team provide assistance to all teams and also function as intermediaries between the Red Team and other teams if necessary . OUR COMPETITION To examine its performance , the LUCID visualization system will be employed in a one - day , small - scale competition . There are a va - riety of models for one - day , small - scale cyber defense competitions and we will adopt a model discussed by O’Leary [ 24 ] that has been used to prepare students for external competitions , such as the Na - tional Collegiate Cyber Defense Competition ( NCCDC ) . In this model , each of 4 - 8 student teams ( Blue teams ) , consist - ing of 6 - 8 virtual machines , is provided with a pre - built network . The networks are identically ( mis ) configured , with variations only in IP addresses and names ( host names and domain names ) . Each network consists of a mixture of Windows and Linux systems with a multitude of different services that typically include a Windows domain , Domain Name Service ( DNS ) and one or more Web ap - plications . This model lends itself well to a one - day competition because the students do not need to build their own network , and offensive and defensive techniques commence fairly quickly as explained by O’Leary [ 24 ] . The machines are deliberately misconfigured to make them easy for the student teams to exploit . The goal of the student teams is to both defend their networks as well as to exploit those of the opposing team . Because the machines are iden - tically ( mis ) configured , students have the opportunity to play offense while playing defense . it is rarely used in small - scale cybersecurity competitions like in - house university events . By improving the spectator experience , we believe that more students will be attracted to CCDC and ultimately to cyber secu - rity related fields . The system will also be beneficial to competition participants , especially to student teams who could use the tool for network security visualization . CYBER DEFENSE COMPETITIONS An excellent summary of cyber defense competitions is given by Hoffman et al . [ 12 ] who write that the main aim of such competi - tions is “to provide a venue for practical education in the imple - mentation of all strategies , tools , techniques , and best practices employed to protect the confidentiality , integrity , authenticity , and availability of designated information and information services . ” The authors further recognize that cyber security exercises “fulfill the same role as capstone projects in traditional engineering pro - grams . ” That is , they enable students to synthesize and integrate knowledge acquired through course work and other learning expe - riences into a project usually conducted in a workplace . Jacobson and Evans [ 14 ] inform us that competitions also increase aware - ness and understanding of security exploits , tools , and countermea - sures in the rapidly changing network security environment . Collegiate Cyber Defense Competitions ( CCDCs ) have ex - perienced modest growth since a group of educators , students , government , and industry representatives gathered in San Anto - nio , Texas , to discuss the feasibility and desirability of establishing regular cybersecurity exercises with a uniform structure for post - secondary level students [ 23 ] . However , there continues to be sig - nificant under - representation of women , non - Asian minorities and students from minority - serving institutions who participate in the CCDCs [ 28 ] . There are several regional CCDCs and a national CCDC . Ev - ery year , the winners from each of the regional CCDCs engage in a national competition where a final winner is chosen . CCDC has already been shown to offer a valid testing environment for net - work security visualization [ 18 ] . Prior to and during these competitions , smaller practice com - petitions among teams within an institution or among a few in - stitutions usually ensue . These types of competitions have been correctly labeled “Small - Scaled Cybersecurity competitions . ” [ 24 ] Having been previously discussed by various authors [ 3 , 11 , 20 , 24 ] , however , they do not represent a new phenomenon . It is within this latter environment of small - scale cybersecurity competitions that we will employ and test LUCID . Research on the video game spectators has revealed that , through computer graphics and animation , spectators gain educational content from viewing the game play , and also become as emotionally engaged through the vicarious play as the participants in the competition . 72 acm Inroads 2015 June • Vol . 6 • No . 2 LUCID : A Visualization and Broadcast System for Cyber Defense Competitions SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION cybersecurityeducation terface , commentary , audience composition , and replays , are crucial for understanding and participation [ 4 ] . Spectators of esports ( elec - tronic sports or competitive gaming ) who are cognizant of these design considerations , have increased their popularity , with some tournaments attracting over 4 . 7 million viewers worldwide [ 10 ] . During an esporting event , computer animation / graphics is paired , often in multiple streams , with audio commentary and interviews with the participating teams . This is the model that will be utilized for the production of small - scale , cyber defense competitions . We believe this will go a long way to helping the spectators make sense of what is transpiring during a cyber defense competition . LUCID SYSTEM DESIGN , DESCRIPTION , FUNCTIONS , AND METHODS The proposed LUCID visualization system is illustrated in Figure 1 . The system is comprised of the following seven basic subsystems . ■ Computer and Network Data Capture , Analysis , and Storage Subsys - tem ( CNDCASS ) —captures , stores and analyzes data from blue and red teams’ networks and computers . It then outputs important events gleaned from the analysis . ■ Computer and Network Visualization Subsystem ( CNVS ) —receives the output from the CNDCASS and uses visualization techniques to obtain an output of the events suitable for an audience . ■ Animated Commentator Subsystem ( ACS ) —takes inputs from the CNVS and the Pre - Recorded Video , Images and Audio input and generates relevant animated commentary to supplement and enhance the visual representation generated by the CNVS . ■ Human Commentators —alternate with the ACS to add relevant commentary to the information obtained from the CNVS . ■ Flypack Subsystem —with the aid of a human expert , selects es - sential scenes ( events obtained from the CNVS and the video and audio feed ) to be broadcast . In addition , it explains these events by alternating between human and animated commentary . It is composed of the following two subsystems . Camera and Audio Selection Subsystem ( CASS ) —obtains audio and video feed from the competition environment . We will depart from O’Leary and use a formal and consistent scoring approach—instead of making the scoring low - - key and in - formal—and we will pay particular attention to engaging the spec - tator through visualization and commentary . LUCID SYSTEM OVERVIEW The LUCID visualization system targets a broad audience that in - cludes technical users as well as novice spectators . The tool borrows from a variety of methodologies , including the use of animation and graphics . Drawing from research regarding gaming and the game - user - spectator relationship , the interface aims to provide a visual representation of the activities of each of the participating teams . A simulated “playing field” populated with team avatars offers visual reinforcement of the audio commentary . Cognitive theory , in conjunction with narrative comprehension of video gam - ing spectators , divides the viewing experience into a “bottom - up” and “top - down” perspective . A “bottom - up” approach deals with basic data such as color , sound and screen orientation . “Bottom - up” design is used to allow viewers to process information quickly [ 17 ] . “Top - down” processes require spectators to process more complex information in order to acquire knowledge and make judgments . “Top - down” perspectives are created through the audio commen - tary / narrative and more sophisticated animation [ 17 ] . Research on the video game spectators has revealed that , through computer graphics and animation , spectators gain educational con - tent from viewing the game play , and also become as emotionally engaged through the vicarious play as the participants in the com - petition [ 4 , 13 , 17 ] . Animation , in partnership with the commentary , can be varied to compensate for the knowledge level of the spec - tators . Spectator design considerations , which include graphic in - Computer / Network Data Pre - Recorded Video , Images and Audio Mike ( s ) Camera ( s ) FLYPACK Camera and Audio SelectionSubsystem Computer and Network Data Capture , Analysis and Storage Subsystem Computer and Network Visualization Internet Animated Commentator Subsystem Web Server Display Subsystem BroadcastSubsystem Figure 1 : Logical View of the LUCID Visualization System 2015 June • Vol . 6 • No . 2 acm Inroads 73 SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION How the Visualization of Computer and Network Attack and Defense Enable Sensemaking In addition to table and slideshow elements described in the previous section , the LUCID system accomplishes computer and network at - tack and defense visualization through a multi - level grid system . The current rendition of the system consists of three levels : Summary View ( Level 1 ) , Status view ( Level 2 ) , and Attack View ( Level 3 ) . As illustrated in Figure 4 , Level 1 ( Summary View ) presents a large - scale view of all the teams involved in the competition . It shows nodes for each team , the name of the operating system run - ning on each node , and the name / IP address of each node . Each team occupies a unique column on the grid , and every row of that column that is occupied represents a different node in the team’s network . The columns representing the blue teams are organized in descending order ( left to right ) according to score . Nodes for each blue team are colored blue . However , each node has a heading section with a unique color and bears the team logo or abbrevia - tion . There is one node per cell in each column and each cell is split into two sub - cells . The sub - cell on the left gives us the status of the particular node in terms of its services . It displays a glowing red if there is at least one critical service that is down . The number Broadcast Subsystem —selects the parts of the information ob - tained from the CNVS and CASS to be broadcast , and decides how and when to broadcast them . It also combines the selected portions with human and animated commentary . ■ Webserver Subsystem —takes input from the Flypack system and streams it live via a Web site . ■ Display Subsystem —consists of a large on - site , split - screen monitor that displays the information being broadcast on the web site via the Webserver Subsystem . A general outline of the proposed partitioning for the monitor screen and the kinds of information that would be presented in each partition is illustrated in Figure 2 . The upper left - side par - tition is reserved for commentary by one or more commentators or an animated commentator . The upper right - side partition gives live video and audio feed from the competition arena , which would include the competitors themselves , the red team , and other key players in the competition arena . The lower half of the screen is reserved for a scoreboard and for live and recent activities taking place on team networks and computers . A mockup of a snap - shot of the system interface is depicted in Figure 3 . It uses a combination of graphics , tables and a slideshow to portray both a large - scale ( “big picture” ) and a detail view of the on - going events of the competition . Located at the center of the page , the slideshow depicts real - time events of the competition , including the state of team networks and attacks against teams . In this particular example , the slideshow shows a blue team under attack by a red team . Tables providing a summary perspective of the competition are located to the right and left - hand side of the slide show . More detail tables are provided at the bottom of the Hosts and Network Visualization and Scoring ( HNVS ) partition . On the top left of HNVS partition is the scoreboard that provides the score for each team . The two tables directly beneath it are the Attack Targets and Attack Types tables . The Attack Targets table provides the num - ber of current attacks against each of the teams . The Attack Types show the number and types of attacks on each team . Figure 2 : System Interface Hosts and Network visualization and Scoring Live Commentator , Animated Commentator , Discussions Live Feed Figure 3 : Interface Mockup Figure 4 : Level 1—Summary View 74 acm Inroads 2015 June • Vol . 6 • No . 2 LUCID : A Visualization and Broadcast System for Cyber Defense Competitions SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION cybersecurityeducation attacks , but also ensures that the audience understands the basic rules of the competition and how each team is progressing based on these rules . By depicting the teams as “enemies , ” the commentator creates important audience involvement [ 14 ] . This “enemy” narra - tive can be reinforced by computer graphics , where each team will have an easily recognizable identity , to highlight the most impor - tant information for the spectators . In addition , the commentary can provide important foreshadowing for what teams may do as the competition progresses and also allows for viewer engagement [ 12 ] . During real - time webcasts , the commentators again work with “experts” to explain what is happening live . Much like in sporting events , the commentators serve to control the flow of discussion ( perhaps through interviewing experts in voice - over ) regarding the competitions and provide “color” commentary that keeps the audi - ence informed and involved . By utilizing remote control cameras located in each room where teams are working , commentators are able to have constant visual access to what is occurring , without interrupting the competition . How Animated Commentary Enables Sensemaking The animated and scalable virtual agent that is being developed as part of LUCID will serve as a virtual commentator in small - scale cyber security competitions , but is flexible enough to be employed in the CCDC environment . The animated virtual commentator is able to express life - like behavior , much like a sensitive and effective human commentator . To accomplish this , we investigate the facial expressions and hand gestures of a real human commentator , and endow an animated virtual commentator with these behaviors . The animated virtual commentator enhances the cyber defense compe - tition experience in several important ways . It provides a remark - able communication instrument—the human face—to the human computer interface . During speech production , faces are informa - tive linguistically . When producing speech , the lips , tongue and jaw provide visual cues that complement auditory cues . The Animated Virtual Commentator is designed to interact with spectators , and provides several types of feedback including causal , congratulatory , deleterious , assistive , background , and motivational responses . A vital and growing multidisciplinary community of scientists is devoting significant efforts to develop and evaluate animated agents that act as virtual humans in various application scenarios . Overviews of the scope of enquiry and the theoretical , cognitive and computational models underlying current research aimed at developing believable animated agents , capable of natural face - to - face conversations with people , are discussed in a variety of works [ 1 , 5 , 9 , 16 ] . To date , researchers have generated powerful concep - tual frameworks , architectures , and systems for representing and of critical services down may also be shown . Clicking this sub - cell moves the system to the Level 2 grid for the respective team . Level 2 shows critical services / applications running on team nodes . All the critical services and their status ( up or down ) for a particular node are displayed in a unique column . On Level 1 , the sub - cell on the right side tells whether the node is under attack and the number of active attacks . Clicking it takes the system to Level 3 . Level 3 presents the attacks for all teams in tabular form or - dered chronologically , with the most recent attack in row 1 . The table is endowed with automatic scrolling , and it enables filtering so that the attacks can be viewed on a per team basis . The fields of the table are the time of the attack , the type of attack if known , the IP address of the attacker , and the IP address of the target . The field values are hyperlinked , and clicking any of the four entries , provides further details of the particular attack . Visualization and commentary aids in clarifying these details . Level 3 uses a myriad of visualization techniques to illustrate attacks , including in - house techniques , footage from red team monitors , and output from secu - rity tools , such as Armitage , Metasploit and Zenmap . How Commentary , Cameras , and Audio Enables Sensemaking LUCID captures network activities and video information for each team . The video information is captured by a camera crew , as well as stationary cameras attached to workstations , laptops , and other devices throughout the competition site . Periodic updates , based on the information obtained from the CNVS and captured video , are provided by one or more commentators ( or animated commen - tator ) through a split screen monitor . Best practices to enhance the viewing experience are employed , such as ensuring that windows on the split - screen monitor are ap - propriately labeled and occasional text scrolling with brief explana - tions . We strive for a similar viewing experience for remote specta - tors , but network resource availability ( bandwidth , etc . ) may require a more dynamic presentation for screens at remote locations . In this case , audio commentary guides and keeps remote spectators focused on the major action events . The broadcast system is be - ing designed to be fully duplex . That is , it is designed to broadcast events from its current location to users on - site and remotely , and users can communicate with the commentator . Hence , the system facilitates two - way communications , such as interviews and Q & A . Commentary aims to enhance the animated depictions of the LUCID aims to engage the spectator by presenting information pertinent to understanding the real - time events of a competition and accomplishes this through the combination of various techniques . 2015 June • Vol . 6 • No . 2 acm Inroads 75 SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION one of these groups upon registration . Thereafter , once a user logs onto the system remotely through a mobile device or computer , he / she will be presented with a menu of choices tailored to their level of expertise that will help them to make sense of the competition . Thus , while we envision a large split - screen monitor to offer pe - riodic updates about the competition and discuss matters that ap - peal to a wide audience , remote viewing will offer more user - focus information competition and on - site related activities . Activities may include panel discussions , workshops , and hands - on activities . During downtimes , the large split - screen monitor could also be utilized to present more user - focus information . CONCLUSION This article has discussed a visualization and broadcast system , LU - CID , targeted to improving spectators’ ability to understand and make sense of cyber defense competitions . LUCID aims to engage the spectator by presenting information pertinent to understand - ing the real - time events of a competition and accomplishes this through the combination of various techniques . These techniques include user profiling , real - time network security visualization , live video and audio monitoring , animation , computer graphics and commentary . This article examined , specifically , how the visualiza - tion system enables the audience to make sense of ongoing activi - ties in a cybersecurity competition . We anticipate that the system will ultimately improve the educational value and excitement for the spectator and broaden interest in the field of cybersecurity . Ir Acknowledgments This material is based upon work supported by the National Science Foundation under Grant DUE 1303424 . Any opinions , findings , and conclusions or recommendations expressed in this material are those of the author ( s ) and do not necessarily reflect the views of the National Science Foundation . References [ 1 ] Bellegarda , J . “A Data - Driven Affective Analysis Framework Toward Naturally Expressive Speech Synthesis , ” IEEE Transactions on Audio Speech and Language Processing , 19 , 5 ( 2011 ) : 1113 . [ 2 ] Carvalho , M . , et al . “Command and Control Requirements for Moving - Target Defense , ” Intell . Syst . IEEE , 27 , 3 ( 2012 ) : 79 – 85 . [ 3 ] Caltagirone , S . , et al . “Design and Implementation of a Multi - Use Attack - Defend Computer Security Lab , ” in Proceedings of the 39th Annual Hawaii International Conference on System Sciences ( HICSS’06 ) , 2006 : 220c . [ 4 ] Cheung , G . and J . Huang , “Starcraft from the stands : understanding the game spectator , ” in Proceedings of the 2011 annual conference on Human factors in computing systems : 763 – 772 . [ 5 ] Cole , R . et . al . “Perceptive animated interfaces : First steps toward a new paradigm for human - computer interaction , ” Proc . of IEEE : Special Issue on Human Computer Multi - Modal Interfaces , 91 , 9 ( 2003 ) : 1391 – 1405 . [ 6 ] DEF CON ; https : / / www . defcon . org / index . html . Accessed 2015 January 19 . [ 7 ] Fisher , K . , S . Counts , and A . Kittur , “Distributed sensemaking , ” in Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems - CHI ’12 ( 2012 ) : 247 . [ 8 ] Goodall , J . and M . Sowul , “VIAssist : Visual analytics for cyber defense , ” in Technologies for Homeland Security , 2009 . HST ’09 . IEEE Conference on , ( 2009 ) : 143 – 150 . [ 9 ] Gratch , J . and S . Marsella , “Tears and Fears : Modeling emotions and emotional behaviors in synthetic agents , ” in Proceedings of the 5th International Conference on Agents on Autonomous Agents , ( New York : ACM , 2001 ) : 278 - 285 . [ 10 ] Groen , A . “How video games are becoming the next great North American spectator sport , ” arstechnica Sept . 28 , 2012 ; http : / / arstechnica . com / gaming / 2012 / 09 / how - video - games - are - becoming - next - great - north - america - spectator - sport / . Accessed 2015 March 13 . [ 11 ] Hill , J . et al . “Using an isolated network laboratory to teach advanced networks and security , ” ACM SIGCSE Bull . , 33 , 1 ( March 2001 ) : 36 – 40 . [ 12 ] Hoffman , L . and D . Ragsdale , “Exploring a National Cyber Security Exercise for Colleges and Universities , ” The George Washington University Cyber Security and Policy Research Institute and the United States Military Academy Information Technology and Operations Center . Washington , D . C . , August 24 , 2004 . http : / / www . maccdc . org / wp - content / uploads / 2010 / 02 / CDE _ Report . pdf . Accessed 2015 March 13 . controlling behaviors and facial expressions of animated agents to make them believable , personable and emotional . These behaviors and expressions range from facial emotions , to gestures , gaze and emotions conveyed in speech . Figure 5 shows diverse facial expressions of an animated virtual commentator that we have developed to engage spectators in the CCDC environment . In the research , the datasets collected are the audio and video sequences that effectively conduct communications and interactions between the professional human commentator and spectators . By recording and observing the interactional behaviors of different professional human commentators working with different groups of spectators in a set of cyber defense competitions , we iden - tify specific coordinated verbal and nonverbal signals and cues ex - changed during each competition , including verbal behaviors , head nods , direction of eye gaze ( including eye contact ) , facial expressions , posture shifts and hand and arm gestures . Once these have been cod - ified , and analyzed to determine their temporal organization and contexts of occurrence , we con - duct a series of experiments to better understand the behaviors of the real human commentator and develop models to improve communication and interaction of the animated commentator . User Modeling to Support Sensemaking To better engage spectators , we need to determine who we view as the users of the LUCID visualization system . By users here we mean the viewers or the spectators of the competition ( i . e . , the au - dience ) . A user may be an individual , a collection of individuals at independent sites , or a collection of many individuals at a common site . To serve the users effectively , the system collects information on user profiles to address their preferences . The system maintains profiles of current users / viewers ( inter - ests , expertise , preferences ) , and creates and maintains profiles for new users when discovered through other sources . LUCID’s user modeling approach will consider the overall user profile , beyond attributes for the current session , as important data for effective interaction with the user . User interaction is minimal since the pri - mary focus is information sharing . The more that is known about a user , the better a system can anticipate and meet his / her needs . In - formation about the user is collected with a brief questionnaire and used for newly registered users . To expedite profile construction , the system will be able to process completed user questionnaires online prior to the CCDC event . Concerns about privacy and security of personal information may prevent users from allowing extra - domain information to be monitored . Our approach will alleviate these concerns by providing full transparency to personal profiles ( i . e . , users may view and mod - ify profile contents ) and permitting users to treat each individual interest object as fully “private , ” “restricted” ( shared with selected group ) or “public . ” LUCID partitions users into three major groups : novice , inter - mediate and expert . Based on their profiles , users are placed into Figure 5 : Diverse Facial Expressions 76 acm Inroads 2015 June • Vol . 6 • No . 2 LUCID : A Visualization and Broadcast System for Cyber Defense Competitions SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION SPECIAL SECTION cybersecurityeducation [ 28 ] Shumba , R . et al . “Cybersecurity , women and minorities : findings and recommendations from a preliminary investigation . ” In Proceedings of the ITiCSE working group reports conference on Innovation and technology in computer science education - working group reports ( ITiCSE - WGR ‘13 ) . ( New York : ACM , 2013 ) : 1 - 14 . [ 29 ] Zhuo , W . , and Y . Nadjin , “MalwareVis , ” in Proceedings of the Ninth International Symposium on Visualization for Cyber Security - VizSec ’12 , ( 2012 ) : 41 – 47 . CLAUDE TURNER Department of Computer Science , Norfolk State University , Norfolk , Virginia , USA cturner @ nsu . edu JIE YAN Department of Computer Science , Bowie State University , Maryland , USA jyan @ bowiestate . edu DWIGHT RICHARDS Department of Engineering Science and Physics College of Staten Island of the City University of New York , Staten Island , New York , USA dwight . richards @ csi . cuny . edu PAMELA O’BRIEN Department of Communications , Bowie State University , Bowie , Maryland , USA pobrien @ bowiestate . edu JIDE ODUBIYI Segma Technologies , Inc , Silver Spring , Maryland , USA jodubiyi @ segma . com QUINCY BROWN Department of Computer Science , Bowie State University , Bowie , Maryland , USA qbrown @ bowiestate . edu DOI : 10 . 1145 / 2746408 © 2015 ACM 2153 - 2184 / 15 / 06 $ 15 . 00 [ 13 ] Huizinga , J . Homo Ludens . Beacon Press , 1971 . [ 14 ] Jacobson , D . and N . Evans , “Cyber Defense Competition , ” in 2006 ASEE Annual Conference & Exposition : Excellence in Education . [ 15 ] Jajodia , S . et al . “Cauldron mission - centric cyber situational awareness with defense in depth , ” in Military Communications Conference , 2011 - MILCOM 2011 ( 2011 ) : 1339 – 1344 . [ 16 ] Johnson , W . and J . Pickel , “Animated Pedagogical Agents : Face - to - Face Interaction in interactive Leaning Environments . ” International Journal of Artificial Intelligence in Deducation , 11 ( 2000 ) : 47 - 78 . [ 17 ] Kemper , T . “Instant Re - Players - From Sports Fans to Video Game Players : A Cognitive History , ” MIT Commun . Forum , 2012 ; http : / / web . mit . edu / comm - forum / papers / kemper . html . Accessed 2015 March 13 . [ 18 ] Luse , A . , B . Mennecke , J . Triplett , N . Karstens , and D . Jacobson , “A Design Methodology and Implementation for Corporate Network Security Visualization : A Modular - Based Approach , ” AIS Trans . Human - Computer Interact . , 3 , 2 ( 2011 ) : 104 – 132 . [ 19 ] Maryland Cyber Challenge and Conference ( MDC3 ) ; https : / / www . fbcinc . com / e / cybermdconference / challenge . aspx . Accessed 2015 January 19 . [ 20 ] Micco , M . and Rossman , H . “Building a cyberwar lab : lessons learned , ” ACM SIGCSE Bull . , 34 , 1 ( March 2002 ) : 23 . [ 21 ] Mid - Atlantic Collegiate Cyber Defense Competition ; http : / / maccdc . org / . Accessed 2015 January 19 . [ 22 ] Natarajan , S . , and X . Huang , “An interactive visualization framework for next generation networks , ” in Proceedings of the ACM CoNEXT Student Workshop on - CoNEXT ’10 Student Workshop , ( 2010 ) : 1 . [ 23 ] “National Collegiate Cyber Defense Competition ; ” http : / / www . nationalccdc . org / . Accessed 2015 March 13 . [ 24 ] O’Leary , M . “Small - Scale Cyber Defense Competitions , ” in The 16th Annual Colloquium for Information Systems Security Education ( CISSE ) , 2012 ; http : / / pages . towson . edu / moleary / docs / Presentations / 2012 % 20CISSE . pdf . Accessed 2015 March 13 . [ 25 ] Paul , S . A . and M . R . Morris , “CoSense , ” in Proceedings of the 27th international conference on Human factors in computing systems - CHI 09 ( 2009 ) : 1771 . [ 26 ] Petre , M . “MOOCs schmoocs , ” ACM Inroads , 4 , 4 ( 2013 December ) : 22 – 23 . [ 27 ] Schafer , J . et al . “The IWAR range : a laboratory for undergraduate information assurance education , ” J . Comput . Sci . Coll . , 16 , 4 ( April 2001 ) : 223 – 232 . ACM Transactions on Interactive Intelligent Systems ACM Transactions on Interactive Intelligent Systems ( TIIS ) . This quarterly journal publishes papers on research encompassing the design , realization , or evaluation of interactive systems incorporating some form of machine intelligence . World - Renowned Journals from ACM ACM publishes over 50 magazines and journals that cover an array of established as well as emerging areas of the computing field . IT professionals worldwide depend on ACM ' s publications to keep them abreast of the latest technological developments and industry news in a timely , comprehensive manner of the highest quality and integrity . For a complete listing of ACM ' s leading magazines & journals , including our renowned Transaction Series , please visit the ACM publications homepage : www . acm . org / pubs . PLEASE CONTACT ACM MEMBER SERVICES TO PLACE AN ORDER Phone : 1 . 800 . 342 . 6626 ( U . S . and Canada ) + 1 . 212 . 626 . 0500 ( Global ) Fax : + 1 . 212 . 944 . 1318 ( Hours : 8 : 30am – 4 : 30pm , Eastern Time ) Email : acmhelp @ acm . org Mail : ACM Member Services General Post Office PO Box 30777 New York , NY 10087 - 0777 USA ACM Transactions on Computation Theory ( ToCT ) . This quarterly peer - reviewed journal has an emphasis on computational complexity , foun - dations of cryptography and other computation - based topics in theo - retical computer science . ACM Transactions on Computation Theory www . acm . org / pubs