TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 1364 - 6613 / 02 / $ – see front matter © 2002 Elsevier Science Ltd . All rights reserved . PII : S1364 - 6613 ( 02 ) 01882 - X 200 OpinionOpinion Analogy - making , whether human or computational , is typically conceived of as involving a ‘mapping’ between two domains , called the source ( or ‘base’ ) and the target . Hall [ 1 ] lists four abstract processes that are widely considered to be necessary for analogical reasoning : ( 1 ) recognition of a source , given a target description ; ( 2 ) elaboration and evaluation of the mapping between the two ; ( 3 ) transfer of information from the source to the target ; ( 4 ) consolidation ( i . e . learning ) of the outcome . Chalmers , French and Hofstadter suggested that this basic framework should also include dynamic representation - building mechanisms and parallel sub - process interaction [ 2 ] . The following ( true ) example anecdotally illustrates not only these processes , but also the ubiquity of analogical processing , even in completely ordinary situations . In 1973 I was , for the first time ever , in a European bathroom [ target ] . This obviously brought to mind [ recognition ] an American bathroom [ source ] because [ elaboration and evaluation ] the European bathroom sink clearly mapped to an American bathroom sink , the European bathtub approximately mapped to an American bathtub ( although having a significantly different shape ) , the European towel - rack to an American towel - rack , the European mirror to an American mirror , and so on . However , one object in the European bathroom puzzled me . It was made of porcelain , had a drain , and could be rinsed out with water from two faucets . I concluded [ transfer ] that this object must be a European toilet and acted on my conclusion… ( I only later discovered what a ‘bidet’was and realized that European toilets are frequently not in the bathroom . ) Classes of computational models of analogy - making Although there are many ways of classifying analogy - making programs , I have chosen to classify them into three broad groups based on their underlying architectures . ( For another classification scheme , see , for example , Ref . [ 3 ] ) . These are : (cid:127) ‘symbolic’models , so called because they are largely part of the symbolic paradigm in AI , in which symbols , logic , planning , search , and means – ends analysis , play a predominant role . ( See Ref . [ 1 ] for an extensive review of these early models . ) (cid:127) ‘connectionist’models that adopt , broadly speaking , the framework of the connectionist networks , including nodes , weights , spreading activation , and so on . (cid:127) hybrid models that lie somewhere in between connectionist and symbolic models . Symbolic models The distinction of being the first computer model of analogy - making probably goes to Reitman’s Argus [ 4 ] . The program solved proportional analogies that , by today’s standards , seem trivial . For example , the program was given : bear : pig : : chair : ? and had to pick an answer from one of four choices : foot , table , coffee , strawberry . Although the program was simple in the extreme , its architecture nevertheless included many far - sighted principles , including the use of a conceptual network , interactions between the concept network and the problem to be solved , the realization of the necessity of automatic representation - building for the source and target , and so on . The best known model from the 1960s was Evans’ ANALOGY [ 5 ] . Like Argus , this program was designed to do proportional analogies of the form A : B : : C : ? taken from standardized high - school IQ tests ( see Box 1 ) . All of the objects in the analogies were simple geometric figures . One important feature of ANALOGY was that its input was a low - level description of each figure and , based on this , the program built a high - level description of the figure . All of the problems solved by ANALOGY are from the same domain , that is , both source and target consist of geometric figures . Also about that time , JCM attempted to put the computational modeling of analogy - making into a more cognitively plausible , real - world framework [ 6 ] . It did this by incorporating incipient notions of learning , working memory ( WM ) and a long - term memory ( LTM ) , in which were stored representations of a set of primitive objects , importance - ranked relations between them , events and causal mappings . A number of models from this early period drew heavily on formal logic . For example , ZORBA - 1 was an automated theorem prover that solved ( target ) problems by finding an analogous ( source ) problem , taking its proof and applying it to the target problem [ 7 ] . Munyer ( PhD thesis , University College of Santa Cruz , 1981 ) and Greiner [ 8 ] also developed The computational modeling of analogy - making Robert M . French Our ability to see a particular object or situation in one context as being ‘the same as’ another object or situation in another context is the essence of analogy - making . It encompasses our ability to explain new concepts in terms of already - familiar ones , to emphasize particular aspects of situations , to generalize , to characterize , to explain or describe new phenomena , to serve as a basis for how to act in unfamiliar surroundings , and to understand many types of humor . Within this framework , the importance of analogy - making in modeling cognition becomes clear . Robert M . French Quantitative Psychology and Cognitive Science , Dept of Psychology ( B33 ) , B - 4000 Liege , Belgium . e - mail : rfrench @ ulg . ac . be URL : http : / / www . ulg . ac . be / cogsci / rfrench . html TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 201 Opinion analogy - making systems based on formal logic . Munyer’s system , in particular , combined planning , problem - solving and deductive logic and implemented a process of gradual ‘convergence’to a correct mapping via an interaction between top - down ( logic ) and bottom - up , competitive processes . The first attempt to apply production systems to computational analogy - making was McDermott’s ANA [ 9 ] a program that did problem - solving in a micro - world . This program had an LTM knowledge base ( stored as production rules ) and a working memory . ANA progressively built the appropriate productions needed to solve the target task , analogous to a source task stored in LTM that it already knows how to do . It learned by saving the new productions in LTM . Carbonell applied means – ends analysis to analogical retrieval [ 10 ] . One key difference with previous work was that his transformational - analogy method used weak search methods and sub - goaling to find ‘solution paths’to a solution to a particular target problem . The program had a stored set of second - order representations of solution paths for previously solved problems . Means – ends analysis was then used to discover the source problem that best corresponded to the target problem . This transformational - analogy method was later extended to a more powerful derivational - analogy method [ 11 , 12 ] , which operated on automatically derived representations and included a peripheral knowledge base to improve the evaluation of various parts of the solution path . Simpson’s MEDIATOR was the earliest application of case - based reasoning ( CBR ) to analogy - making [ 13 ] . Prodigy / Analogy combined CBR and Carbonell’s derivational approach to analogy - making [ 14 ] . This architecture was explicitly designed to be scaled up to larger domains and several empirical results have shown that , as the number of stored episodes increased , the integrated learning system was able to keep search requirements under control . In the late 1970s , Winston developed the notion of ‘transfer frames’ [ 15 ] . Two objects ( one source , one target ) were presented to the program as being similes . Mappings were then made by the program between the source and target based on the most salient properties of the source , the prototypicality of the information in the target , and the instructional context provided by a tutor . After checking for inconsistencies with respect to these criteria , properties were transferred from the source to the target . This work was extended to a model of analogical reasoning in which , in order to respond to a particular query , a rule was extracted from the source situation based on attributional and relational information in the source situation [ 16 , 17 ] . This rule , based on consistent relational structure , was used to answer the target query . Winston’s work anticipated , in some sense , Gentner’s Structure Mapping Theory ( SMT ) [ 18 ] ( and see Box 2 ) . SMT is unquestionably the most influential work to date on the modeling of analogy - making and has been applied in a wide range of contexts , from child development to folk physics . SMT explicitly shifts the emphasis in analogy - making to the structural similarity between the source and target domains . Two major principles underlie SMT : ( 1 ) the relation - matching principle : good analogies are determined by mappings of relations and not attributes ( originally only identical predicates were mapped ) . ( 2 ) the systematicity principle : mappings of ‘coherent systems’of relations are preferred over mappings of individual relations . Opinion ANALOGY , one of the earliest analogy - making programs [ a ] attempts to ‘construct a rule which transforms figure A into figure B , and figure C into exactly one of the five answer figures’ ( see Fig . I ) . The representation module first analyzes the input ( written as a low - level description , rather than being the actual figures ) and describes figure A , for example , as [ ( inside P2 P3 ) ( above P1 P3 ) ( above P1 P2 ) ] . Similar representations are made for figures B and C and for the five test figures . Based on these representations , the program matches the most similar descriptions in order to discover the correct analogy . Notice that the program has no semantic knowledge about the figures it manipulates . For example , it does not know that squares and rectangles are generally closer in people’s minds than , say , squares and letters . Reference a Evans , T . ( 1968 ) Aprogram for the solution of a class of geometric analogy intelligence test questions . In Semantic Information Processing , pp . 271 – 353 , MIT Press Box 1 . Constructing rules A B C Z Z 1 2 3 4 5 Z Z TRENDS in Cognitive Sciences Z Fig . I . ( see text for details ) TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 202 Opinion This structural approach was intended to produce a domain - independent mapping process . The Structure Mapping Engine ( SME ) was the computational implementation of SMT [ 19 ] . More recent versions of SME have explored the use of pragmatics , as well as re - representation techniques that allow related , but not identical , predicates to match [ 20 ] . MAC / FAC , a two - stage analogical retrieval engine , was later developed as a front - end to SME [ 21 , 22 ] . The first stage of its retrieval process consists of a sweep through LTM , retrieving many potential source episodes based on a superficial search ; the second stage is a detailed , best - match process designed to select the best matches to the target . Only then does the structure - mapping phase begin . MAGI , another SME - based model , detects regularity within a given situation or scene by seeking maximally consistent mappings among its parts [ 23 ] . Depending on the nature of the mappings found , elements of the scene can be categorized as being repetitions , or symmetrical . This structural notion of regularity applies to conceptual , as well as perceptual , materials . IAM incrementally maps portions of a base domain to the source , thereby gradually building up a single interpretation based on selected portions of the domain rather than on many alternative interpretations [ 24 , 25 ] . If the mapping produced is not optimal then this mapping will be abandoned and another constructed . The completely serial nature of IAM processing , however , has produced doubts about its ability to scale up [ 26 ] . I - SME is an incremental version of SME based , in part , on the IAM architecture [ 26 ] . The most significant difference with the latter program is that , instead of the strictly serial approach adopted by IAM , I - SME mixes serial and parallel processing . In recent work , another SME - based program , SEQL , has been applied to infant categorization [ 27 ] . The authors suggest that categories are represented via structured descriptions and formed by a process of progressive abstraction , through successive comparison with incoming exemplars . Burstein’s CARL extends the ideas of Gentner in a multi - stage analogy - making program that constructs analogies based on several others presented by a teacher in a somewhat context - dependent manner [ 28 ] . Kedar - Cabelli’s model of purpose - driven analogy attempts to derive relevant structural and functional features automatically in order to make mappings [ 29 ] . Recently , a ‘path - mapping’model [ 30 ] of how humans integrate analogical mapping and problem - solving has been developed based on ACT - R [ 31 ] . ACT - R has also been used in the context of analogy - making to attempt to develop a unified theory of metaphor Opinion SME , the Structure Mapping Engine [ a ] , a computational implementation of the Structure Mapping Theory [ b ] , has been the most influential computational model of analogy - making to date . It receives predicate - calculus representations of the base and source and searches both representations to determine where there are structural similarities between them . It builds a mapping between the two situations based on these structures and their overall coherence . Discovering two matching systematic structures ( Fig . I , heavy lines ) in the source ( Solar system ) and in the target ( Rutherford atom ) allows the program to transfer structure found in the source to the target ( in this case , to conclude that the cause of the electron revolving around the nucleus is the charge ) . It is hard to know what conclusions SME might have drawn if the representation of the Rutherford atom had also included the fact that , in addition to electrical forces , there are gravitational forces between the nucleus and the electron ( for a discussion of this point , see Ref . [ c ] ) . References a Falkenhainer , B . , Forbus , K . D . and Gentner , D . ( 1989 ) The structure - mapping engine . Artif . Intell . 41 , 1 – 63 b Gentner , D . ( 1983 ) Structure - mapping : a theoretical framework for analogy . Cogn . Sci . 7 , 155 – 170 c French , R . ( 1995 ) The Subtlety of Sameness : ATheory and Computer Model of Analogy - Making , MIT Press Box 2 . Structure mapping Cause Gravity Mass ( Sun ) Mass ( planet ) Attracts ( Sun , planet ) AND Greater Mass ( Sun ) Mass ( planet ) Cause Revolve ( Sun , planet ) Greater Temperature ( Sun ) Temperature ( planet ) Rutherford atom Cause Solar system Opposite - sign Charge ( nucleus ) Charge ( electron ) Attracts ( nucleus , electron ) Greater Mass ( nucleus ) Mass ( electron ) Revolve ( nucleus , electron ) AND Cause TRENDS in Cognitive Sciences Fig . I . ( see text for details ) TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 203 Opinion understanding , semantic illusions and text memory [ 32 ] and to model invention by analogy [ 33 ] . A final pair of symbolic models , BORIS [ 34 ] and MORRIS [ 35 ] , deserve mention . These programs attempt to understand narrative through the use of abstract ‘thematic abstraction units’ , which closely resemble Schank’s ‘Thematic Organization Points’ ( TOPS ) [ 36 ] implemented in a dynamically organized memory . Analogies in these models are recognized largely through structural relations , rather than with simple attribute information . Connectionist models Symbolic systems are generally well equipped to model relational structures involving situations represented as objects and relations between objects . For this reason , these models held the high ground for many years in the computational modeling of analogy - making . However , connectionist models have taken their place alongside symbolic models of analogy - making , largely owing to recent advances in their representation techniques . Most importantly , distributed connectionist representations provide a natural internal measure of similarity , thereby allowing the system to handle with relative ease the problem of similar , but not identical , relations , a problem that has proved difficult for symbolic models . ACME was the first attempt to develop an architecture in which analogy - making was an emergent result of constrained , parallel activation of states of in a neural network - like structure [ 37 ] . In this model , structural similarity , semantic similarity , and pragmatic importance determine a set of constraints to be simultaneously satisfied . The model is supplied with representations of the target and source and proceeds to build a localist constraint - satisfaction network in which hypothesis nodes correspond to all possible hypotheses pairing the elements of the source with those of the target . Excitatory and inhibitory links between these nodes implement the constraints . In this way , contradictory hypothesis nodes compete with one another and ( usually ) do not become simultaneously active , whereas consistent nodes tend to mutually support each other . The relaxation of the network provides a parallel evaluation of all possible mappings and finds the best one , represented by the set of most active hypothesis nodes . ARCS is a model of retrieval that is coupled with ACME in which mapping is dominated by structural similarity and retrieval is dominated by semantic similarity [ 38 ] . One of the most ambitious connectionist models of analogy - making is LISA [ 39 ] . Whereas ACME required all objects in the source to be pairwise connected to all elements in the target , LISA relies on more plausible mechanisms , such as partially distributed representations of concepts , selective activation and dynamic binding as the means of associating the relevant structures . Only node structures that oscillate in synchrony are bound together [ 40 , 41 ] . Crucially , the synchronous binding mechanism means that both WM and LTM can interact during both retrieval and mapping . Even though , for the moment , LISA cannot make inferences , it does successfully integrate the process of retrieval of a base and the mapping of the base and target . STAR - 1 , designed to solve proportional analogies , was the first distributed connectionist model of analogy - making [ 42 ] and is based on the tensor product connectionist models developed by Smolensky [ 43 ] . STAR - 2 is a recent and more complex version of STAR - 1 , developed in an attempt to achieve a better understanding of the development of analogy - making capabilities in children [ 44 ] . DRAMA [ 45 ] is a recent connectionist model of analogy - making that implements holographic reduced representations [ 46 ] , a type of convolution - correlation memory [ 47 ] . This program , using fully distributed representations of concepts , attempts to integrate the semantics and structure of the base and target during the mapping process . Jani and Levine [ 48 ] have developed a neural - network approach to analogy - making based on Adaptive Resonance Theory [ 49 ] . This system has a concept - association mechanism based on synaptic triads , and explicitly appeals to neurobiological plausibility . Analogator is a connectionist model that learns to make analogies by seeing numerous analogies ( Blank , PhD thesis , Indiana University , 1996 ) . Hybrid models Hybrid models share features of both connectionist and symbolic models . ( The term ‘connectionist’ here is meant to be broadly construed , encompassing architectures that rely on connectionist - like mechanisms , such as spreading activation among node structures , excitation and inhibition between nodes , and so forth . ) The first two models discussed here rely on agent - based approaches to analogy - making . COPYCAT ( [ 50 ] ; see Box 3 ) , TABLETOP [ 51 ] , LETTER - SPIRIT [ 52 ] , and METACAT [ 53 ] form a family of models whose basic architectural principles were described by Hofstadter [ 54 , 55 ] . Three of the most important features of these models of analogy - making are : ( 1 ) their ability to build up their own representations of the source and target as well as the mapping between them via an agent - driven interaction between top - down ( LTM ) and bottom - up ( WM ) processing ; ( 2 ) their Opinion ‘ . . . connectionist models have taken their place alongside symbolic models of analogy - making . . . ’ TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 204 Opinion use of ( simulated ) parallelism ; and ( 3 ) their stochastic nature . These models abandon traditional sequential processing and allow representation - building and mapping to run in parallel and continually to influence each other . In this way , partial mappings can have an impact on further representation - building ( and vice - versa ) , thus allowing the gradual construction of context - sensitive representations . AMBR [ 56 ] , an analogical problem - solver , is based on the principles of the DUAL model [ 57 ] , a general , context - sensitive cognitive architecture consisting of many micro - agents each of which represents a small piece of knowledge . Each micro - agent has a symbolic part that encodes the declarative and / or procedural knowledge it is representing , and a connectionist part that computes the agent’s activation level , which represents the relevance of this knowledge to the current context . The AMBR model , and its later extension , AMBR - 2 [ 58 ] , implement the interactive parallel processes of recollection , mapping and transfer that emerge from the collective behavior of the agents . The result is an analogy , but also a re - representation of the old episode which might turn out to be illusory memory . Other hybrid models that combine symbolic and connectionist mechanisms use spreading activation mechanisms , node structures implementing knowledge bases , and other mechanisms , and include ASTRA [ 59 ] and ABR - C onposit [ 60 ] . ASTRA implements ‘continuous analogical reasoning’ , which recognizes the importance of integrating the various stages of analogy - making rather than treating them independently . ABR - C onposit is an implementation of Analogy - Based Reasoning that implements WM – WM matching , creates and modifies WM representations , and manipulates complex data structures in an explicit attempt to bridge the symbolic – connectionist gap . Conclusion I have presented a brief , and necessarily incomplete , survey of computational models of analogy - making over the past 35 years . These models are divided into three broad classes : those whose architectures are based largely on the principles of the symbolic tradition of artificial intelligence , those that draw on connectionist principles , and , finally , hybrid models that depend on a combination of these and other principles . Even though the field has come a long way since Walter Reitman’s and Thomas Evans’first analogy - making programs of the mid - 1960s , great challenges still lie ahead . These include : ( 1 ) the development of context - sensitive ways for analogy programs to settle on the appropriate representations of the base and target situations ; ( 2 ) the development of a better understanding of the long - term memory retrieval mechanisms that allow ‘analogous’ situations to be activated in working memory ; ( 3 ) the systematic exploration of experimenter - independent representation - building and learning mechanisms ; and ( 4 ) the incorporation of these mechanisms into analogy - making programs – and all of this , with a keen eye , as always , to the all - important issue of scaling - up . The lessons of almost 40 years of research in the computational modeling of analogy - making have , more than anything else , shown us just how hard the problem is . Analogy - making is so intimately and so deeply part of human cognition that it is probably safe to say that any program capable of doing analogy - making in a manner truly comparable to human beings would stand a very good chance of passing the Turing Test . Opinion COPYCAT [ a , b ] solves letter - string analogies of the form : ABC : ABD : : KJI : ? and gives probabilistically possible answers , such as LJK , KJJ , KJD ( see Fig . I ) . The architecture of COPYCAT involves a working memory , a semantic network ( simulating LTM ) defining the concepts used in the system and their relationships , a procedural memory storing small , nondeterministic computational agents ( ‘codelets’ ) that build , examine and , possibly , destroy the structures in the working memory and continually interact with the semantic network . The system gradually settles towards a set of consistent set of structures that will determine the mapping between the base and the target . References a Hofstadter , D . R . ( 1984 ) The COPYCAT Project : An Experiment in Nondeterminism and Creative Analogies , MIT AI Memo No . 755 b Mitchell , M . ( 1993 ) Analogy - Making as Perception : AComputer Model , MIT Press Box 3 . Using non - deterministic agents a b c k j i a b d l j i Replace letter - category of rightmost letter by successor whole → whole group → group succgrp → succgrp right → left succ → succ letcat → letcat let → let rmost → lmost mid → mid let → let lmost → rmost Replace letter - category of leftmost letter by successor TRENDS in Cognitive Sciences Fig . I . ( see text for details ) Acknowledgements This work was funded in part by grant no . HPRN - CT - 1999 - 00065 from the European Commission . Special thanks to Dedre Gentner for her valuable feedback on an earlier draft of this paper . ‘ . . . almost 40 years of research in the ( . . . ) modeling of analogy - making have ( . . . ) shown us just how hard the problem is . ’ TRENDSin Cognitive Sciences Vol . 6 No . 5 May 2002 http : / / tics . trends . com 205 Opinion References 1 Hall , R . ( 1989 ) Computational approaches to analogical reasoning : a comparative analysis . Artif . Intell . 39 , 39 – 120 2 Chalmers , D . J . , French , R . M . and Hofstadter , D . R . ( 1992 ) High - level perception , representation , and analogy : a critique of artificial intelligence methodology . J . Exp . Theor . Artif . Intell . 4 , 185 – 211 3 Spanoudakis , G . and Constantopoulos , P . ( 1996 ) Elaborating analogies from conceptual models . In International Journal of Intelligent Systems ( Vol . 11 , No . 11 ) ( Yager R . , ed . ) , pp . 917 – 974 , John Wiley & Sons 4 Reitman , W . R . ( 1965 ) Cognition and Thought : An Information Processing Approach . John Wiley & Sons 5 Evans , T . ( 1968 ) Aprogram for the solution of a class of geometric analogy intelligence test questions . In Semantic Information Processing , pp . 271 – 353 , MIT Press 6 Becker , J . D . ( 1969 ) The modeling of simple analogic and inductive processes in a semantic memory system . Proc . Int . Joint Conf . Artif . Intell . ( IJCAI - 69 ) , pp . 655 – 668 , Morgan Kaufmann 7 Kling , R . ( 1971 ) Aparadigm for reasoning by analogy . Artif . Intell . 2 , 147 – 178 8 Greiner , R . ( 1988 ) Learning and understanding by analogies . Artif . Intell . 35 , 81 – 125 9 McDermott , J . ( 1979 ) Learning to use analogies . In Proc . Int . Joint Conf . Artif . Intell . ( IJCAI - 79 ) , pp . 568 – 576 , Morgan Kaufmann 10 Carbonell , J . G . ( 1983 ) Learning by analogy : formulating and generalizing plans from past experience . In Machine Learning : An Artificial Intelligence Approach ( Vol . I ) , pp . 137 – 162 , Morgan Kaufmann 11 Carbonell , J . G . ( 1986 ) Derivational analogy : a theory of reconstructive problem solving and expertise acquisition . In Machine Learning : An Artificial Intelligence Approach ( Vol . 2 ) , pp . 371 – 392 , Morgan Kaufmann 12 Veloso , M . and Carbonell , J . ( 1990 ) Integrating analogy into a general problem - solving architecture . In Intelligent Systems ( Zemankova , M . and Ras , Z . , eds ) , pp . 29 – 51 , EllisHorwood , Chichester 13 Simpson , R . L . ( 1985 ) Acomputer model of case - based reasoning in problem solving : an investigation in the domain of dispute mediation . Technical Report GIT - ICS - 85 / 18 , School of Information and Computer Science , Georgia Institute of Technology , Atlanta 14 Veloso , M . M . and Carbonell , J . G . ( 1993 ) Derivational analogy in PRODIGY : automating case acquisition , storage , and utilization . Machine Learn . 10 , 249 – 278 15 Winston , P . H . ( 1978 ) Learning by creating and justifying transfer frames . Artif . Intell . 10 , 147 – 172 16 Winston , P . H . ( 1980 ) Learning and reasoning by analogy . Commun . ACM 23 , 689 – 703 17 Winston , P . H . ( 1982 ) Learning new principles from precedents and exercises . Artif . Intell . 19 , 321 – 350 18 Gentner , D . ( 1983 ) Structure - mapping : a theoretical framework for analogy . Cogn . Sci . 7 , 155 – 170 19 Falkenhainer , B . , Forbus , K . D . and Gentner , D . ( 1989 ) The structure - mapping engine . Artif . Intell . 41 , 1 – 63 20 Falkenhainer , B . ( 1990 ) Analogical interpretation in context . In Proc . 12th Annu . Conf . Cogn . Sci . Soc . , pp . 69 – 76 , Lawrence Erlbaum 21 Gentner , D . and Forbus , K . D . ( 1991 ) MAC / FAC : amodel of similarity - based access and mapping . In Proc . 13th Annu . Conf . Cogn . Sci . Soc . , pp . 504 – 509 , Lawrence Erlbaum 22 Forbus , K . D . , Gentner , D . and Law , K . ( 1995 ) MAC / FAC : a model of similarity - based retrieval . Cogn . Sci . 19 , 141 – 205 23 Ferguson , R . W . ( 1994 ) MAGI : analogy - based encoding using symmetry and regularity . In Proc . 16th Annu . Conf . Cogn . Sci . Soc . , pp . 283 – 288 , Lawrence Erlbaum 24 Keane , M . and Brayshaw , M . ( 1988 ) The incremental analogical machine : a computational model of analogy . In European Working Session on Learning ( Sleeman , D . , ed . ) , pp . 53 – 62 , Pitman 25 Keane , M . , Ledgeway , T . and Duff , S . ( 1994 ) Constraints on analogical mapping : a comparison of three models . Cogn . Sci . 18 , 387 – 438 26 Forbus , K . D . , Ferguson , R . and Gentner , D . ( 1994 ) Incremental structure - mapping . In Proc . 16th Annu . Conf . Cogn . Sci . Soc . , pp . 313 – 318 , Lawrence Erlbaum 27 Kuehne , S . E . et al . ( 2000 ) SEQL : category learning as progressive abstraction using structure mapping . In Proc . 22nd Annu . Conf . Cogn . Sci . Soc . , Lawrence Erlbaum 28 Burstein , M . ( 1986 ) Concept formation by incremental analogical reasoning and debugging . In Machine Learning : An Artificial Intelligence Approach ( Vol . 2 ) ( Michalski , R . et al . , eds ) , pp . 351 – 370 , Morgan Kaufman 29 Kedar - Cabelli , S . ( 1985 ) Purpose - directed analogy . In Proc . 7th Annu . Conf . Cogn . Sci . Soc . , pp . 150 – 159 , Lawrence Erlbaum 30 Salvucci , D . and Anderson , J . ( 2001 ) Integrating analogical mapping and general problem - solving : the path - mapping theory . Cogn . Sci . 25 , 67 – 110 31 Anderson , J . R . ( 1993 ) Rules of the Mind , Lawrence Erlbaum 32 Budiu , R . and Anderson , J . R . ( 2000 ) Integration of background knowledge in sentence processing : aunified theory of metaphor understanding , semantic illusions and text memory . In Proc . 3rd Int . Conf . Cogn . Modeling , pp . 50 – 57 , University of Groningen , Netherlands 33 Murdock , J . W . et al . ( 1998 ) Modeling invention by analogy in ACT - R . In Proc . 20th Annu . Conf . Cogn . Sci . Soc . , pp . 740 – 745 , Lawrence Erlbaum 34 Lehnert , W . et al . ( 1983 ) BORIS : an experiment in in - depth understanding of narratives . Artif . Intell . 20 , 15 – 62 35 Dyer , M . ( 1983 ) Understanding stories through morals and remindings . In Proc . Int . Joint Conf . Artif . Intell . ( IJCAI - 83 ) , pp . 75 – 77 , MorganKaufmann 36 Schank , R . ( 1982 ) Dynamic Memory : ATheory of Reminding and Learning in Computers and People , Cambridge University Press 37 Holyoak , K . J . and Thagard , P . ( 1989 ) Analogical mapping by constraint satisfaction . Cogn . Sci . 13 , 295 – 355 38 Thagard , P . et al . ( 1990 ) Analog retrieval by constraint satisfaction . Artif . Intell . 46 , 259 – 310 39 Hummel , J . E . and Holyoak , K . J . ( 1997 ) Distributed representations of structure : a theory of analogical access and mapping . Psychol . Rev . 104 , 427 – 466 40 Shastri , L . and Ajjanagadde , V . ( 1993 ) From simple associations to systematic reasoning : a connectionist representation of rules , variables and dynamic bindings using temporal synchrony . Behav . Brain Sci . 16 , 417 – 494 41 Sougné , J . ( 1996 ) Aconnectionist model of reflective reasoning using temporal properties of node firing . In Proc . 18th Annu . Conf . Cogn . Sci . Soc . , pp . 666 – 671 , Lawrence Erlbaum 42 Halford , G . et al . ( 1994 ) Connectionist implications for processing capacity limitations in analogies . In Advances in Connectionist and Neural Computation Theory , Analogical Connections ( Vol . 2 ) ( Holyoak , K . and Barnden , J . , eds ) , pp . 363 – 415 , Ablex Publishing 43 Smolensky , P . ( 1990 ) Tensor product variable binding and the representation of symbolic structures in connectionist systems . Artif . Intell . 46 , 159 – 216 44 Wilson , W . et al . ( 2001 ) The STAR - 2 model for mapping hierarchically structured analogs . In The Analogical Mind . ( Gentner , D . et al . , eds ) , pp . 125 – 159 , MIT Press 45 Eliasmith , C . and Thagard , P . ( 2001 ) Integrating structure and meaning : a distributed model of analogical mapping . Cogn . Sci . 25 , 245 – 286 46 Plate , T . ( 1995 ) Holographic reduced representations . IEEE Trans . Neural Netw . 6 , 623 – 641 47 Metcalfe - Eich , J . ( 1985 ) Levels of processing , encoding specificity , elaboration and CHARM . Psychol . Rev . 92 , 1 – 38 48 Jani , N . and Levine , D . ( 2000 ) Aneural network theory of proportional analogy - making . Neural Netw . 13 , 149 – 183 49 Carpenter , G . and Grossberg , S . ( 1986 ) . Adaptive resonance theory : stable self - organization of neural recognition codes in response to arbitrary list of input patterns . In Proc . 8th Annu . Conf . Cogn . Sci . Soc . , pp . 45 – 62 , Lawrence Erlbaum 50 Mitchell , M . ( 1993 ) Analogy - Making as Perception : AComputer Model , MIT Press 51 French , R . ( 1995 ) The Subtlety of Sameness : ATheory and Computer Model of Analogy - Making , MIT Press 52 Hofstadter , D . and McGraw , G . ( 1995 ) Letter spirit : esthetic perception and creative play in the rich microcosm of the roman alphabet . In Fluid Concepts and Creative Analogies : Computer Models of the Fundamental Mechanisms of Thought , pp . 407 – 488 , Basic Books 53 Marshall , J . and Hofstadter , D . ( 1997 ) The METACAT project : a self - watching model of analogy making – cognitive studies . Bull . Jap . Cogn . Sci . Soc . ( Special issue on similarity and analogical reasoning ) 4 , 57 – 71 54 Hofstadter , D . R . ( 1984 ) The COPYCAT Project : An Experiment in Nondeterminism and Creative Analogies . MIT AI Memo No . 755 55 Hofstadter , D . and the Fluid Analogies Research Group ( 1995 ) Fluid Concepts and Creative Analogies : Computer Models of the Fundamental Mechanisms of Thought , Basic Books 56 Kokinov , B . ( 1988 ) Associative memory - based reasoning : how to represent and retrieve cases . In Artificial Intelligence III : Methodology , Systems , and Applications ( O’Shea , T . and Sgurev , V . , eds ) , pp . 51 – 58 , Elsevier 57 Kokinov , B . ( 1994 ) The context - sensitive cognitive architecture DUAL . In Proc . 16th Annu . Conf . Cogn . Sci . Soc . , pp . 502 – 507 , Lawrence Erlbaum 58 Kokinov , B . and Petrov , A . ( 2000 ) Dynamic extension of episode representation in analogy - making in AMBR . In Proc . 22nd Annu . Conf . Cogn . Sci . Soc . , pp . 274 – 279 , Lawrence Erlbaum 59 Eskeridge , T . ( 1994 ) Ahybrid model of continuous analogical reasoning . In Advances in Connectionist and Neural Computation Theory : Analogical Connection s ( Vol . 2 ) ( Holyoak , K . and Barnden , J . , eds ) , pp . 207 – 246 , Ablex Publishing 60 Barnden , J . A . ( 1994 ) On the connectionist implementation of analogy and working memory matching . In Advances in Connectionist and Neural Computation Theory : Analogy , Metaphor , and Reminding ( Vol . 3 ) ( Barnden , J . E . and Holyoak , K . J . , eds ) , pp . 327 – 374 , Ablex Publishing Opinion