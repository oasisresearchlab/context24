Long YH , Chen YC , Chen XP et al . Test - driven feature extraction of web components . JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY 37 ( 2 ) : 389 { 404 Mar . 2022 . DOI 10 . 1007 / s11390 - 022 - 0673 - 4 Test - Driven Feature Extraction of Web Components Yong - Hao Long 1 ; 2 ( 9 [ (cid:211) ) , Yan - Cheng Chen 1 ( (cid:157) (cid:4) ¥ ) , Xiang - Ping Chen 3 ( (cid:157) (cid:137) – ) , Member , CCF Xiao - Hong Shi 4 ( (cid:156) ¡ ø ) , and Fan Zhou 1 ; (cid:3) ( – (cid:133) ) 1 School of Computer Science and Engineering , National Engineering Research Center of Digital Life Sun Yat - sen University , Guangzhou 510006 , China 2 School of Design , The Hong Kong Polytechnic University , Hong Kong , China 3 Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion , The School of Communication and Design , Sun Yat - sen University , Guangzhou 510006 , China 4 School of Information Technology and Engineering , Guangzhou College of Commerce , Guangzhou 511363 , China E - mail : f longyh3 , chenych28 g @ mail2 . sysu . edu . cn ; chenxp8 @ mail . sysu . edu . cn ; shixh @ gcc . edu . cn E - mail : isszf @ mail . sysu . edu . cn Received May 31 , 2020 ; accepted February 18 , 2022 . Abstract With the growing requirements of web applications , web components are developed to package the implemen - tation of commonly - used features for reuse . In some cases , the developer may want to reuse some features which cannot be customized by the component’s APIs . He / she has to extract the implementation by hand . It is labor - intensive and error - prone . Considering the widely - used test cases which can be useful to specify the software features , a test - driven approach is proposed to extract the implementation of the desired features in web components . The satisfaction of the user’s require - ments is transformed into the passing rate of user - speci(cid:12)ed test cases . In this way , the quality of the extraction result can be evaluated automatically . Meanwhile , a record / replay - based GUI test generation method is proposed to ensure that the extraction result has the correct GUI appearance . To extract the feature implementation , a hierarchical genetic algorithm is proposed to (cid:12)nd the code snippet that can pass all the tests and has the approximate smallest size . We compare our method with two existing feature extraction methods . The result shows that our method can extract the correct implementation with the minimum size . A human - subject study is conducted to show the e(cid:11)ectiveness and weaknesses of our method in helping users extract the features . Keywords feature extraction , genetic algorithm , graphical user interface , software reuse 1 Introduction The web application is one of the fastest - growing and most widespread application domains today , per - forming a crucial role in daily life . Numerous features are developed to meet the massive user requirements . It makes the development e(cid:14)ciency more and more im - portant . Among the updated features , some of the simi - lar functionalities have already existed in a variety of web applications , and facilitating their reuse o(cid:11)ers sig - ni(cid:12)cant bene(cid:12)ts [ 1 ] . Web components are proposed to package the imple - mentation of commonly - used features to facilitate web development . Fig . 1 shows an example of using a muti - selection component . The user needs to provide some contents to be displayed ( lines 1 { 5 ) , initialize the com - ponent object ( lines 7 { 10 ) , and customize the compo - nent by using the given con(cid:12)gurations ( for instance , multiple = " multiple " in line 1 and closeOnSelect : false in line 9 ) . The component will handle the user’s inputs and generate a multi - selection widget with pre - de(cid:12)ned appearances and interactions . A problem arises when the user wants to utilize a Regular Paper This work was supported by the Key - Area Research and Development Program of Guangdong Province under Grant No . 2020B010165001 , the National Natural Science Foundation of China under Grant No . 61976061 , Guangdong Basic and Applied Basic Research Foundation under Grant No . 2020A1515010973 . (cid:3) Corresponding Author © Institute of Computing Technology , Chinese Academy of Sciences 2022 390 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 1 . < select class = " basic - multiple " multiple = " multiple " > 2 . < optgroup label = " A / H Time Zone " > 3 . < option value = " AK " > Alaska < / option > 4 . < option value = " HI " > Hawaii < / option > 5 . < / optgroup > 6 . . . . < script > 7 . $ ( document ) . ready ( function ( ) { 8 . $ ( ' . basic - multiple ' ) . select2 ( { 9 . closeOnSelect : false / / API 10 . } ) ; } ) ; . . . 11 . < / script > 1 . Defaults . prototype . apply = function ( options ) { 2 . . . . 3 . if ( options . closeOnSelect ) { 4 . options . dropdownAdapter = Utils . Decorate ( 5 . options . dropdownAdapter , 6 . CloseOnSelect 7 . ) ; 8 . } . . . } / / Specified by pre - defined API 9 . . . . 10 . this . $ results . on ( ' mouseenter ' , 11 . ' . select2 - results _ _ option [ aria - selected ] ' , 12 . . . . 13 . self . getHighlightedResults ( ) 14 . . removeClass ( ' option - - highlighted ' ) ; 15 . . . . 16 . } ; / / Specified by test cases 17 . . . . 18 . MultipleSelection . prototype . render = function ( ) { 19 . $ selection . addClass ( ' select2 - selection - - multiple ' ) ; 20 . $ selection . html ( 21 . ' < ul class = " select2 - selection _ _ rendered " > < / ul > ' 22 . ) ; 23 . return $ selection ; 24 . } ; / / Specified by usage scenario ( a ) ( b ) ( c ) ( d ) Fig . 1 . A select box component in ( a ) implemented by select2 1 ○ . The desired features are mixed with some default events in ( b ) and cannot be customized by the component’s APIs in ( c ) but can be speci(cid:12)ed by the component’s test cases combined with the usage scenario as shown in ( d ) . set of features that cannot be customized by con(cid:12)gura - tions in the component . For instance , the user wants to extract the selecting feature ( to update the input area when clicking the \ Hawaii " item as shown in the \ Us - age Scenario " ) in the component shown in Figs . 1 ( a ) and 1 ( b ) . These events are default events that are bound to the items when the component is initialized . No APIs are provided by the component to specify the events . In this case , the user has to manually forage and extract the desired features from thousands of lines of code [ 2 ] . Extracting the code that corresponds to the feature is complex since the feature may be related to the HTML elements , JS codes , CSS de(cid:12)nitions , etc . The dynamic interplay between di(cid:11)erent entities makes the extract - ing process labor - intensive and error - prone [ 3 ] . The lack of (cid:13)exible reusing supports makes developers turn to reinvent the features [ 4 ] . The feature extraction aims to (cid:12)nd a code snippet that implements the required functionalities in a soft - ware system [ 5 ] . In the domain of web applications , a typical strategy is using the usage scenario to record the user’s actions on the component ( as shown in Fig . 1 ) . Some methods based on software analysis like code instrumentation [ 6 , 7 ] or software slicing [ 8 , 9 ] were used to (cid:12)nd the relevant statements to the usage scenario as the extraction result . Using the usage scenario to specify the features is intuitive and straightforward . However , it may su(cid:11)er from quality problems . First , the improper scenario will lead to an unsatis(cid:12)ed extraction result . Second , some features are not appearance - relevant and easy to be overlooked in the scenario such as memory mana - gement and exception handlers . Considering the test cases , which are widely used in web implementation , especially in the open - source components , can be use - ful to specify the software features . In this paper , we propose a novel method to auto - matically extract a code snippet and related resources in a web component that implements the user - speci(cid:12)c functionalities . Considering test cases may not cover all the software features in some cases , a GUI test case generation algorithm based on the record / replay strat - egy is proposed to ensure the elements of interest in the extraction result have the same appearances as those in the original component . An extraction result is thought to contain the required features if it can pass the test cases . As fewer lines of code mean less cost users spend - ing on learning the core concepts of components [ 10 ] , a 1 ○ The select2 component . https : / / select2 . org / , July 2021 . Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 391 hierarchical genetic algorithm that considers the code structure is proposed to get the approximate minimum size of the extraction result . Several qualitative and quantitative experiments were conducted to show the e(cid:11)ectiveness and correctness of our method . The con - tributions in this paper include the followings . (cid:15) An automated GUI test case generating method is proposed based on the record / replay strategy . (cid:15) A hierarchical genetic algorithm is proposed to ex - tract an implementation that satis(cid:12)es the requirements and achieves the approximate minimum lines of code . (cid:15) Experimental comparison of our method and existing feature extraction methods shows that our method can correctly extract all the components’ fea - tures and generate the minimum lines of code . 2 Related Work Our method aims to extract desired features from a web component . The related studies include feature lo - cating , JavaScript analysis , and web application reuse . 2 . 1 Feature Extraction The feature extraction aims to (cid:12)nd a code snippet that implements the required functionalities in a soft - ware system [ 11 ] . Several studies [ 6 , 9 , 12 ] were conducted based on code instrumentation , program slicing , etc . An intuitive way of feature extraction is recording the executed statements in the scenario as the imple - mentation of the features [ 6 ] . Studies like Unravel [ 7 ] and Scry [ 12 ] show the executed statements in each action in the scenario to help users focus on the code mutating the DOM states . The feature implementation is a sub - set of the executed statements , and a part of the irrel - evant statements is included in the extraction result . Several feature extraction methods [ 8 , 9 ] are based on program slicing . These methods record the vis - ited DOM elements and the trigger events in the us - age scenario as the slicing start point . Then they apply backward and forward slicing to (cid:12)nd the statements in the dependency graph . The feature implementation is thought to be contained in the slicing result . The ex - traction result might also contain some irrelevant state - ments which have dependencies on the user scenario but make no contributions to the features , for example , the redundant assignments . When the developer uses a scenario to specify the features , some features may hardly be presented in the scenario such as memory management or exception handlers . Barr et al . [ 13 ] used the test cases to specify the features . The code which could pass all the user - speci(cid:12)ed test cases was thought to contain the feature . Then , a genetic algorithm was developed to (cid:12)nd the feature implementation . In our work , we also specify the features by user - speci(cid:12)ed tests , but we focus on ex - tracting the features in the web components which are cross - language , highly dynamic , and weak - typed . 2 . 2 JavaScript Analysis The JavaScript code performs a crucial role in web applications . It is dynamic , weakly - typed , and prototype - based , which makes the JS code hard to be understood and maintained [ 8 ] . Considerable studies [ 14 { 30 ] have been proposed to analyze the JS pro - gram in recent decades . Some static analysis methods were proposed to an - alyze the JS program without actually running it . The static JS program analysis usually parses the source code by an abstract interpreter like TAJS [ 14 ] , JSAI [ 15 ] , and (cid:21) JS [ 16 ] . Combined with the speci(cid:12)ed rules or mathematical constraints , the analyser is adopted in pointer analysis [ 17 , 18 ] , type inference [ 14 , 19 ] , data (cid:13)ow analysis [ 20 , 21 ] , call graph analysis [ 22 , 23 ] , etc . The static analysis is e(cid:11)ective , but it faces seri - ous limitations in JavaScript because it cannot pre - cisely reason about many dynamic language features . Dynamic analysis was proposed to avoid the challenge of statically approximating behavior [ 24 ] . Considerable studies based on dynamic analysis have been proposed in recent decades , in particular , studies like record / re - play debugging [ 25 , 26 ] , feature locating [ 27 , 28 ] , and dy - namic program slicing [ 29 , 30 ] have close relations to our work . Our work has some relations to JavaScript analysis . We propose an automated GUI test case generating method based on the record / replay techniques . In the code extraction , we parse the source code to (cid:12)nd the code structure and ensure the extraction process does not break the code structures . 2 . 3 Web Application Reuse Developing a satisfying web application requires the developers to have rich knowledge of user experiences , interface design , and programming on multi - languages . Instead of developing from scratch , developers often seek inspiration from examples to reduce the developing cost [ 31 ] . Some studies [ 32 , 33 ] were proposed to provide pre - de(cid:12)ned templates to simplify the development . Users 392 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 can choose one template and replace the generic in - formation in the template with their contents . The Bricolage [ 34 ] was proposed to enlarge the scale of tem - plates . According to a mapping between the elements in source and reference web pages , the contents in the source elements can be (cid:12)lled into the reference web page , and thus every existing web page can be reused as a template . These studies [ 32 { 34 ] center on providing a static web page for inspiration , while the interactions have to be manually implemented by the users . In some cases , the users want to reuse part of the features in an example , instead of reusing the whole web page [ 35 ] . Several studies were proposed to handle this issue . For example , the web component library [ 36 ] allows developers to choose and reuse a component of interest from the library . Similarly , some studies [ 37 { 40 ] were proposed to extract and reuse components from existing web pages . The markup languages CTS [ 37 ] and Mavo [ 38 ] ask end - users to manipulate their HTML (cid:12)les to build a mapping between the original HTML el - ements and the example elements , in order to insert the example components’ features into their applications . The component encapsulates the commonly - used functionalities into a class or package , and users can easily reuse the feature by inserting the component into their software . However , the component may contain some features that the user does not want to use , and removing some of the useless features may require the user’s knowledge on the implementation of the compo - nent . Hence , in this work , we propose a method that helps users reuse the features from the components in (cid:12)ner granularity . 3 Test - Driven Feature Extraction In this section , we (cid:12)rst formulate the feature extrac - tion problem , in which we transfer the requirements of features to passing a set of test cases related to the features . Then we introduce an automated GUI test generating method to guarantee the desired elements in the extraction result have the same appearance as those in the original component . We (cid:12)nally introduce a hierarchical genetic algorithm to extract a code snip - pet that both passes the given test cases and contains statements as few as possible . 3 . 1 Problem Formulation Feature . The feature refers to a speci(cid:12)c function - ality , de(cid:12)ned by requirements , and accessible to deve - lopers and users [ 41 ] . The feature in this context does not include non - functional requirements such as perfor - mance or reusability 2 ○ . It is implemented by a subset of code and resources of the whole application [ 9 ] . In this paper , we focus on extracting the JS code that implements the speci(cid:12)ed features on the client side . The web component is de(cid:12)ned as ( C ; R ) which has two parts : the JS code C and related resources R . The resources include HTML , CSS (cid:12)les , and external re - sources like background images or videos . Features on canvas are not included in the method . A component ( C ; R ) contains the speci(cid:12)ed features F if it satis(cid:12)es : P ( T ; ( C ; R ) ) = j T j ; where T represents the set of test cases for F , and j T j is the number of test cases . P ( T ; ( C ; R ) ) means the number of test cases in T that ( C ; R ) can pass . In this way , the user can specify the features by a set of test cases . It has two advantages : 1 ) the test cases are easy to read since most of them contain descriptions , and 2 ) we can automatically evaluate the degree of the result’s satisfaction to the user’s requirements by checking the passing rate of test cases . In this paper , we focus on extracting the JS code which contributes to the features . The related resources are determined by code instrumentation : any resources that the extraction result requires are kept as the re - lated resources . As a result , we simplify the compo - nent’s test passing rate as P ( T ; C ) . Irrelevant Statements . For a code snippet C which contains the desired features , there may be some state - ments that make no contributions to the required fea - ture . A statement s in C is regarded as irrelevant if deleting it does not a(cid:11)ect the passing rate of test cases : P ( T ; C (cid:0) s ) = P ( T ; C ) : Feature Extraction . Feature extraction refers to ex - tracting a code snippet and related resources in a web component that implements the user - speci(cid:12)c function - alities . The extraction result could run independently and exclude irrelevant statements as many as possible . Formally , we de(cid:12)ne the feature extraction as a searching problem : given the source code C of the web component and a set of user - speci(cid:12)ed test cases T , the feature extraction is (cid:12)nding a code snippet C ? in C , which can pass all of the given test cases and has the minimum LOC : LOC ( C ? ) = min f LOC ( C 0 ) j C 0 2 C ; P ( T ; C 0 ) = j T jg ; 2 ○ Software , and S . E . S . Committee . IEEE Standard for Software and System Test Documentation . IEEE . 2008 . Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 393 where LOC ( C 0 ) refers to the lines of code in C 0 . We take Fig . 2 to illustrate the process . Supposing the required features are speci(cid:12)ed by the four tests , the colored rectangles represent the feature implementation speci(cid:12)ed by the tests . The extraction result must pass all of the tests and contains the irrelevant statements as few as possible . To achieve this goal , we look through the original code and (cid:12)nd the irrelevant statements hi - erarchically . At the outmost block , only a function de(cid:12) - nition exists and it is crucial to keep it to pass the tests . Then we look into the function de(cid:12)nition block . The handled statements are the single statements in lines 2 { 6 , 19 and 20 , and a compound statement for block ranging from line 7 to line 18 . Removing the state - ments in lines 3 { 5 will not a(cid:11)ect the passing rate and they are thought to be irrelevant . The other statements are crucial to the test passing rate . More speci(cid:12)cally , the statement in line 2 contributes to passing test # 182 , and removing other statements will make the result fail to pass tests # 184 and # 185 . After that , we look into the for block and (cid:12)nd the statements in lines 10 and 11 are also irrelevant . Therefore , the feature extraction result will exclude the statements in lines 3 { 5 , 10 and 11 . 3 . 2 Augmenting Test Cases GUI testing is tedious and complex . Most visual features are tested manually . A few of the features are checked by test scripts [ 42 ] . Our observation on the components’ test cases also supports the point of view : most of the test assertions are checking the status of a function of object in the JS code , instead of the DOM element . To (cid:12)ll this gap , a GUI testing method is pro - posed to ensure the desired elements in the component will be correctly displayed in the extraction result . The record / replay [ 26 ] method is used to generate a GUI test case automatically . The elements manipu - lated in the usage scenario are considered as the ele - ments of interest . Users can also point out other ele - ments as the desired elements . If the pointed element is not a leaf , we will ask users to specify the desired leaves in the subtree whose root is this element to (cid:12)lter the uninterest elements . For a usage scenario that consists of n actions on the original component , our method (cid:12)rst records the initial appearances of the desired elements when no action happens . Then , the method records the appearances of the desired elements ( named frame ) in the compo - nent when each of the actions happens . Hence we get n + 1 frames for the original component . After that , the method generates a test case that triggers the n actions and asserts the frames in the extraction result should be the same as the frames in the original component . The consistency of the elements’ appearances is checked by comparing the visual - related attributes in the source code rather than using the image - based methods in GUI testing [ 43 ] for two reasons . The (cid:12)rst is our method will remove some elements in the original component , which may change the extraction result’s appearances . The second is the image - based methods often consider the number of the same pixels between two snapshots . The color distortion of the snapshots may a(cid:11)ect the result . Four visual aspects that determine the component’s appearance are considered in our method : 1 ) the posi - tions of elements in the HTML (cid:12)le ; 2 ) the required re - sources such as the background image ; 3 ) the contents of the elements ; 4 ) the inline , internal , and external styles of the elements . The path from the root < HTML > element to ( b ) ( a ) Fig . 2 . Combining di(cid:11)erent test cases in ( a ) can specify di(cid:11)erent feature implementations in ( b ) . 394 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 the target element is recorded as the element’s posi - tion . The position is used as the element’s identi(cid:12)er . The element’s resources and contents can be found in HTML source code . The styles are determined by the matching of selectors ( including the pseudo - classes , e . g . , a : hover ) in CSS and HTML (cid:12)les . All of the visual properties are recorded as the JSON - format text . The generated test case triggers the actions in sequence . Once an action is triggered , the desired elements’ appearances in the extraction result are recorded . And an assertion is generated to check if the result’s appearance text is the same as the text ex - tracted from the original component . 3 . 3 Hierarchical Genetic Algorithm Feature extraction is a process of removing irrele - vant statements . It is a combination problem since the statements may cooperate to implement a feature . As a result , removing the statements one by one could not achieve the goal . For example , the two cases in line 3 and line 5 in Fig . 3 should be removed together to pass the test case . But removing one of them could not pass the given test cases . Fig . 3 . Statements in line 3 and line 5 are unwanted , and only removing one of them will fail to pass the tests . Finding the best solution ( i . e . , satisfying the re - quirements with the minimum lines of codes ) to this combination problem is an NPC problem . We propose a hierarchical genetic algorithm ( HGA for short ) to (cid:12)nd an approximate result that satis(cid:12)es the user’s require - ments and contains as few statements as possible . We assume that the required feature is made up of state - ments that are distributed in some block statements like the functions or objects . As a result , our method starts from the statements in the outmost code blocks , and recursively (cid:12)nds irrelevant statements layer by layer as shown in Algorithm 1 . The feature extraction method is based on the hier - archical genetic algorithm , which detects and removes the irrelevant statements hierarchically . Because re - moving inner statements may cause the statements in the outer layer to be irrelevant , HGA has to rerun the extraction result . As Algorithm 1 shows , after each running of HGA , we compare the result with the input code to see if the result has LOC decreasing and HGA’s running times do not exceed the maximum number R . If so , we will run HGA on the result to (cid:12)nd more irrel - evant statements . Algorithm 1 . Hierarchical Genetic Algorithm Input : the original JS code C , a set of test cases T that specify the desired features in C Output : a result code snippet CS which passes all of T and contains the statements as few as possible 1 : function HGA ( C ; count ) 2 : CS C ; 3 : l 0 ; 4 : while l 6 the max layer of statements in C do ; 5 : S l the statements of C in layer l ; 6 : res l GA ( C ; S l ; T ) ; B Remove the statements in S l that make no contributions to passing the tests in T 7 : if fitness ( res l ) > 1 then 8 : CS res l ; 9 : end if 10 : + + l ; 11 : end while 12 : if LOC ( CS ) < LOC ( C ) and count 6 R then 13 : CS 6 HGA ( CS ; count + 1 ) 14 : end if 15 : return CS 16 : end function Removing the statements could be regarded as pruning nodes in an abstract syntax tree ( AST ) . Once a statement is deleted , the corresponding nodes in the AST should be removed . Any subtrees whose roots are in the removed nodes should also be deleted . That is , if a compound statement is removed , the inner state - ments should also be removed . We give each statement a number to indicate its layer in the hierarchical struc - tures of statements in the AST . The statements in layer 0 are de(cid:12)ned as the children of the root in the AST . The sta - tement’s layer will be increased with the depth of the AST node . In each layer , a genetic algorithm ( GA ) is used to (cid:12)nd a code snippet with the highest (cid:12)tness as denoted by res l in Algorithm 1 . If the (cid:12)tness of res l is higher than 1 , which means some statements are removed and the result passes all of the test cases without errors , the result will be the candidate code and handled in the next layer . Otherwise , the original code will be the candidate in the next layer . To perform the GA on each layer , we need to encode the source code to a chromosome , de(cid:12)ne the gene , and specify the crossover , mutation , and selection strate - gies . Moreover , the individual’s (cid:12)tness should be de - (cid:12)ned and an appropriate initial population needs to be Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 395 constructed to (cid:12)nd an approximate best result quickly . For a code snippet with n lines of code , the algo - rithm generates an array of n integers to be the chro - mosome of the code . The element in the chromosome is a gene which represents the choosing of the code . For instance , if the i - th gene in chromosome is 1 , the state - ment in line i will be kept ; otherwise , the statement will be removed if the corresponding gene is 0 . The crossover in GA is Uniform Crossover , and the mutation is Flip Mutation . The selection strategy in GA is selecting the top 10 % individuals into the next generation (cid:12)rst , and we use champion selection for the others . The individuals are ranked by (cid:12)tness . In the GA process of software transplantation [ 13 ] , the passing rate of test cases is considered to evaluate the (cid:12)tness of an individual , while the compiler would remove the individuals failing to compile . In our case , JavaScript is an interpreted programming language and has no \ compile error " . But during the loading phase , \ Script Error " or \ Reference Error " may appear . Any individual with such errors will have zero (cid:12)tness . Mean - while , if both the two individuals can pass all of the test cases with no errors , we prefer the one with less lines of code . The assumption is based on the learning barriers of unfamiliar codes [ 10 ] . From the user’s perspective , the extraction result is a demo for using the desired features . Less code means lower learning barrier and less super(cid:13)uous details that distract from learning core concepts . The calculation of (cid:12)tness is de(cid:12)ned as ( 1 ) , where fitness ( i ) is the (cid:12)tness of individual i which contains j chromosome j lines of code . P ( T ; i ) stands for the num - ber of tests in T that i can pass , and LOC ( i ) represents the lines of code in i . ERR i indicates if the i - th individ - ual has any \ Script Error " or \ Reference Error " , and it is assigned to 1 if so . fitness ( i ) = 8 > > > > > > > > > < > > > > > > > > > : 0 ; if ERR i = 1 ; P ( T ; i ) j T j ; if P ( T ; i ) j T j < 1 and ERR i = 0 ; 2 (cid:0) LOC ( i ) j chromosome j ; if P ( T ; i ) j T j = 1 and ERR i = 0 : ( 1 ) The individual is run on the browser to calculate the (cid:12)tness . It will cost about 1 second per individual , which means the time cost will be unacceptable if the search space ( i . e . , the population of GA ) is too large . As a result , we generate a set of individuals that have high (cid:12)tness as the initial population in each layer as shown in Algorithm 2 . To ensure that we will get at least one result that can pass all of the tests and has no errors , we put the original code in the current layer into the initial population ( IP ) as shown in line 3 . Algorithm 2 . Initial Population Generation Input : the handled JS statements S l in the current layer l , the size n of population , the chosen test cases T Output : the initial population IP 1 : function IPG ENERATOR ( C ; S l ; T ) 2 : IP ; ; 3 : IP . push ( C ) 4 : greedyRes G ET G REEDY R ES ( C ; S l ; T ) ; 5 : IP . push ( greedyRes ) ; 6 : for s i 2 S l do 7 : IP . push ( S l (cid:0) s i ) ; 8 : end for 9 : if j IP j > n then 10 : IP top - n individuals in IP sorted by fitness ; 11 : else 12 : randomIP R ANDOM C HOOSING ( S l ; n (cid:0) j IP j ) 13 : IP . push ( randomIP ) 14 : end if 15 : return IP 16 : end function 17 : function G ET G REEDY R ES ( C ; S l ; T ) 18 : C 0 C ; 19 : for s i 2 S l do 20 : if P ( T ; C 0 (cid:0) s i ) = P ( T ; C ) then 21 : C 0 C 0 (cid:0) s i 22 : C 0 G ET G REEDY R ES ( C 0 ; S l ; T ) 23 : end if 24 : end for 25 : return C 0 26 : end function Then , we use the greedy strategy ( line 4 ) to (cid:12)nd a result by removing the statements individually as the second member of IP . More speci(cid:12)cally , for each state - ment in the current layer , it will be removed if the re - moving does not a(cid:11)ect the result’s passing rate ; oth - erwise , it will be kept . Once a statement is removed , the algorithm will repeat checking the irrelevant state - ments in the result until no statements can be removed ( as shown in lines 20 { 22 ) . To enlarge the population of IP , we remove the statements in the current layer in sequence and add the results to IP as shown in lines 5 { 7 . If the popu - lation is beyond the threshold of IP ( supposed to be n ) , we will sort the individuals by (cid:12)tness , and choose top n individuals to be the (cid:12)nal result as shown in line 396 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 9 and line 10 . Otherwise , we will randomly select a set of statements in C as individuals to (cid:12)ll up IP as shown in lines 11 { 13 . The number of generation and the size of population per generation are related to the handled statements ( denoted as j gene j ) in the current layer . We set two upper bounds to limit the searching space . The two properties are de(cid:12)ned as : j generation j = max ( 5 (cid:2) j gene j ; 100 ) ; j population j = max ( 10 (cid:2) j gene j ; 200 ) : 3 . 4 Running Example We take the code snippet in Fig . 2 to illustrate the HGA process . As Fig . 4 ( a ) shows , we (cid:12)rst transform the code to a chromosome , where each gene is a binary number that represents the choosing of statements . In the (cid:12)rst layer , only one statement ( i . e . , the function declaration of update ) exists . We do bit (cid:13)ip mutation on the (cid:12)rst gene in individual i 1 (cid:0) 1 , and get a new indi - vidual i 1 (cid:0) 2 . Note that the (cid:12)rst gene in i 1 (cid:0) 1 corresponds to the function de(cid:12)nition in line 1 in Fig . 2 , and the last gene is the end of the de(cid:12)nition statement . To keep the code structure , both genes are changed to 0 , and the inner statements are set to be 0 consequently . The (cid:12)tness of i 1 (cid:0) 2 is zero since none of the chosen tests can be passed . In the second layer , suppose we get three individuals i 2 (cid:0) 1 , i 2 (cid:0) 2 and i 2 (cid:0) 3 , in one generation . The (cid:12)tness of i 2 (cid:0) 1 is 0 . 25 since it can only pass test # 183 . While in the second generation , the uniform crossover happens on i 2 (cid:0) 1 and i 2 (cid:0) 2 . We get i 2 (cid:0) 4 and i 2 (cid:0) 5 . Similarly , the (cid:12)tness of i 2 (cid:0) 4 is 0 . 25 since it can only pass test # 183 . Meanwhile , one gene ( in orange ) in i 2 (cid:0) 3 is mutated ( bit (cid:13)ip ) and we get a new individual i 2 (cid:0) 6 . Suppose the upper bound of the population is 4 , when picking the individuals to the next generation , i 2 (cid:0) 6 is picked since its (cid:12)tness is in the top 10 % . And the other three individuals will be selected from the left (cid:12)ve individuals by champion selection . 4 Implementation We run all the tests on Ubuntu 18 . 04 with 3 . 0 GHz Intel Core i5 and 8 GB Memory . The test tool and the browser are on the SSD for the I / O speed purposes . We run the tests on headless Chrome and the GPU - disabled mode . We develop the GA algorithm based on DEAP 3 ○ , and the probability of crossover is 0 . 5 and that of mu - tation is 0 . 1 . In our implementation , we set the upper bound of HGA’s running times to be 3 . In some cases , the component contains more than one JS (cid:12)le . A feature implementation may involve sub - routine invocations . In respect of HGA , we use one chromosome to represent the statements in all of the JS (cid:12)les . We build a gene - statement mapping to ease the modi(cid:12)cations of the statements in JS (cid:12)les : once a gene is changed , we (cid:12)nd the location of the correspond - ing statement in the mapping and change the statement in the corresponding (cid:12)le . 5 Evaluation In this section , we investigate the correctness and e(cid:11)ectiveness of our method . We address two research questions . RQ 1 . Compared with existing studies , what are the strength and weakness of our method ? RQ 2 . To what extent can our method facilitate the user in feature extraction ? Bit Flip 1 1 1 . . . 1 1 0 0 1 0 0 0 1 1 0 . . . 0 1 1 1 1 0 0 1 1 1 1 . . . 1 1 1 1 1 0 1 0 Bit Flip UniformCrossover 1 1 0 0 1 1 1 . . . 0 1 1 1 1 1 0 0 . . . 0 0 0 0 0 1 1 1 0 . . . 0 1 1 1 0 0 1 1 1 . . . 1 1 1 1 0 0 0 1 1 . . . 1 1 1 1 fitness ( i 1 - 1 ) / 1 fitness ( i 2 - 1 ) / 0 . 25 fitness ( i 2 - 2 ) / 1 + 1 / 21 fitness ( i 2 - 3 ) / 1 + 2 / 21 fitness ( i 2 - 5 ) / 1 + 2 / 21 fitness ( i 2 - 6 ) / 1 + 3 / 21 fitness ( i 2 - 4 ) / 0 . 25 fitness ( i 1 - 2 ) / 0 1 1 1 0 0 ( b ) ( a ) 0 Fig . 4 . Running example of the code in Fig . 2 . ( a ) Individuals in layer 1 . ( b ) Individuals in layer 2 . 3 ○ DEAP evolutionary computation framework . https : / / github . com / DEAP / deap , July 2021 . Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 397 5 . 1 RQ1 : Method Comparison Two existing feature extraction methods were com - pared with our method : FireCrystal [ 6 ] and Firecrow [ 9 ] . FireCrystal is based on code instrumentation , and Fire - crow is based on program slicing . 5 . 1 . 1 Study Design We conducted the feature extraction on two data - sets . One dataset ( denoted as dataset - 1 ) is proposed in Firecrow [ 9 ] , which includes nine web pages and 13 required features . One feature was not included in our evaluation since it was not found in the author’s dataset 4 ○ and the given URL was not accessible . Hence we actually used eight di(cid:11)erent web pages and 12 re - quired features . The features in this dataset were spe - ci(cid:12)ed by usage scenarios which were described as Sele - nium test script . The features in dataset - 1 are GUI - related and we built another dataset ( denoted as dataset - 2 ) containing 10 web components with 10 sets of features speci(cid:12)ed by usage scenarios and test cases . The web components were collected from Github . As shown in Table 1 , # TA and # TC represent the number of test assertions and test cases respectively . All the components have more than 100 stars and have relatively complete test cases using QUnit 5 ○ . The required features could not be di - rectly extracted by con(cid:12)gurations . The test cases were chosen by two participants , and we accepted the test case for a feature if it was chosen by both of the par - ticipants ; otherwise , we would ask another participant to decide the test cases . We did not have FireCrystal’s source code . Instead , we implemented it by recording the executed state - ments in the usage scenario and the test cases . Firecrow was a Firefox plugin , thereby we conducted the experi - ments on Firefox ( v28 . 0 . 0 . 5186 ) . The extracted result was thought to be correct if the usage scenario could be reproduced on the result cor - rectly , and it could pass the given tests with no errors . If two results were correct , we preferred the result with fewer statements . The goal of our method was to extract the imple - mentation of features in the component . As a result , we did not extract the library codes like jQuery 6 ○ or requireJS 7 ○ although they contributed to the feature . 5 . 1 . 2 Results Table 2 and Table 3 describe the extraction re - sults in the two datasets respectively . In dataset - 2 , we failed to use Firecrow to do the extraction in any of the components . The main reason was that Firecrow did not support handling the JS (cid:12)les written with EC - MAScript6 . Table 1 . Web Components Used in Dataset - 2 ID URL Feature Requirement # TA # TC C1 uxsolutions / bootstrap - datepicker Get the \ highlight day of the week " feature from the calendar 5 1 C2 mugi(cid:13)y / jquery - simple - datetimepicker Extract the \ date " from \ datetimepicker " 29 9 C3 Mottie / Keyboard Simple arithmetic operations ( + , (cid:0) , (cid:2) , (cid:4) , = ) and numbers 13 1 C4 OwlCarousel2 / OwlCarousel2 Extract the \ swipe " function which can browse the image by dragging or clicking the buttons 17 8 C5 Prinzhorn / skrollr Get the \ rotate texts " , \ horizonal or vertical text mov - ing " when the scrollbar moves 64 6 C6 smalot / bootstrap - datetimepicker Change the \ dateTimePicker " to a simple date picker , without changing the format of the date 239 53 C7 igorescobar / jQuery - Mask - Plugin Get the telephone number formatting function 60 10 C8 select2 / select2 Select a set of elements ; when selecting the same ele - ment or clicking the fork icon of the element , the ele - ment should be removed 10 5 C9 jquery - backstretch / jquery - backstretch Clicking di(cid:11)erent buttons , change the background to the corresponding image 8 3 C10 jquery - validation / jquery - validation Get the E - mail and password formatting function 9 1 Note : All of the URLs start with \ https : / / github . com / " . # : number of . 4 ○ Firecrow . https : / / github . com / jomaras / Firecrow , July 2021 . 5 ○ QNnit JavaScript testing framework . https : / / qunitjs . com / , July 2021 . 6 ○ The jQuery JavaScript library . https : / / jquery . com / , July 2021 . 7 ○ RequireJS . https : / / requirejs . org / , July 2021 . 398 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 Table 2 . Feature Extraction Results on Dataset - 1 ID LOC ori LOC FireCrystal LOC FireCrow LOC ours F1 1642 476 239 35 F2 1642 474 207 13 F3 1642 592 345 207 F4 1174 229 139 19 F5 1174 228 139 17 F6 260 71 38 26 F7 594 160 130 13 F8 53 47 47 46 F9 10 10 10 10 F10 16 16 16 16 F11 301 161 125 101 F12 518 224 202 158 Table 3 . Feature Extraction Results on Dataset - 2 ID LOC ori FireCrystal Ours LOC Correct LOC Correct C1 1757 980 Y 258 Y C2 2143 1679 Y 578 Y C3 4267 2557 N 802 Y C4 2976 2318 Y 1368 Y C5 1088 736 Y 600 Y C6 1772 1257 Y 610 Y C7 473 364 Y 161 Y C8 5301 3375 Y 1304 Y C9 1276 688 Y 273 Y C10 1404 833 Y 371 Y All of the tasks in the (cid:12)rst dataset were successfully ful(cid:12)lled by the three methods . In dataset - 2 , one Fire - Crystal’s result ( C3 ) included some irrelevant buttons and got the wrong result . In general , FireCrystal got the biggest size of results , FireCrow the medium , and our method the minimum . The reason for FireCrystal having the biggest size of results is that the code instrumentation would in - volve statements that were executed in the scenario but made no contributions to the features [ 6 ] . As shown in Fig . 5 , in C3 , the features were speci(cid:12)ed by a test case including 13 assertions checking the calculation of plus , minus , multiplication , and division for the inte - gers and (cid:13)oats . Hence an acceptable result should only contain the basic arithmetic operators and the digits . The developer gave every button a property to de(cid:12)ne the functionality and these de(cid:12)nitions were located in the constructor function . The de(cid:12)nitions were executed and thus some irrelevant buttons were kept with the buttons of interest in FireCrystal’s result . ( b ) ( a ) Fig . 5 . FireCrystal’s result in ( a ) includes some unwanted but - tons which are not in the red closure and is di(cid:11)erent to ( b ) the correct appearance . In Firecrow , the method (cid:12)rst built a dependency graph of the source code . Then the method did dy - namic slicing starting from the triggered events and the user - speci(cid:12)ed DOM elements . All the dependent state - ments were treated as the feature implementation , and thus the executed irrelevant statements were removed . The dynamic slicing was heuristic . It would keep the statements that manifest the features directly or indirectly . From our observation of Firecrow’s res - ults , statements that had dependencies on the speci(cid:12)ed DOM elements were kept as the feature implements . And consequently , some irrelevant statements were in - volved . For instance , in F4 and F5 , some event listeners of the speci(cid:12)ed DOM elements were kept in Firecrow , while the handlers were removed ( as shown in lines 18 , 21 { 25 , Fig . 6 ) . These events were not triggered in the us - age scenario , thereby they were feature - irrelevant . But in the view of program slicing , these events belonged to the DOM object’s properties and thus had depen - dencies on the DOM element . As a consequence , these events were kept . Another majority part of irrelevant statements kept in Firecrow were the maps , since the method did not handle arrays ( as shown in lines 3 { 12 , in Fig . 6 ) . But in the jQuery code , many parameters in the callbacks were written in a key - value way , and that is another reason why our method reduced irrelevant statements signi(cid:12)cantly . Compared with the above methods , our method achieved the minimum size of feature implementation . However , some of the removed statements should be kept to enhance the robustness of the program . For instance , our method removed the variable declara - tions without assignments . The result could also run correctly , but the related variables became global and would be harmful to the program’s robustness . Brie(cid:13)y speaking , all of the methods supported ex - tracting features speci(cid:12)ed by usage scenarios or test cases ( Firecrow also supports extracting the features speci(cid:12)ed by the tests as described in [ 9 ] ) . Our method Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 399 ArraysEvent Handlers Fig . 6 . Some redundant statements kept in Firecrow : the arrays and event handlers . generated the smallest size of results in all of the tasks . 5 . 2 RQ2 : Human - Subject Study In this study , we checked if our method could help the participants extract the features . We investigated the e(cid:11)orts that the participants spent on using our method and extracting the feature implementation by hand . We transformed the usage scenario to be a GUI test case with a series of assertions . The GUI test case was appended to the chosen test cases as the require - ments of features . Moreover , the diversity of the test cases chosen by participants was checked to see if they had a signi(cid:12)cant di(cid:11)erence . Our results were compared with the manually extracted results to see the advan - tages and drawbacks of our method . 5 . 2 . 1 Study Design We invited (cid:12)ve participants to the experiments . They had some experience with programming but were relatively new to JavaScript programming . The sub - jects were three sets of features in three web compo - nents listed in Table 1 . Each set of features contains both visual and appearance - irrelevant features . On the one hand , we asked the participants to choose the feature - relevant tests from the test cases pro - vided by the implementation of the corresponding web component . On the other hand , the participants were asked to use our GUI generating method to interact with the feature - relevant elements to generate a GUI test script . We recorded the time that participants spent on choosing the test cases and interacting with the com - ponents ( the two processes were denoted as \ feature speci(cid:12)cation " ) . The time cost represented the labor cost of using our method in the feature extraction . For comparison , we asked the participants to manually ex - tract the implementation of the features and recorded the extraction time . A retrospective interview was con - ducted after the participants (cid:12)nished the extraction . We compared the time of feature speci(cid:12)cation with the time of manual feature extraction to see if our method can help reduce the human e(cid:11)orts . Then we evaluated the consistency of the test cases chosen by dif - ferent participants . Moreover , we compared the man - ually extracting result with our result and asked the participants to explain why they kept or deleted the statements . 5 . 2 . 2 Results Fig . 7 shows the comparison of time cost on fea - ture speci(cid:12)cation and extracting the implementation by hand . We can see the time cost spent on feature 400 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 speci(cid:12)cation is much less than that spent on manual extraction . Participants reported that in C5 and C6 , they could not get the correct entry point of the fea - ture by Firefox Developer tools . Instead , they started foraging from the constructors and guessed the entry point by reading the API documentation and the deve - lopers’ comments . When the participants found out the core functions related to the features , they strug - gled to (cid:12)nd all of the dependencies that supported the executing of the core functions . In contrast , the partic - ipants told that choosing the feature - related test cases was much easier since the test cases provide detailed de - scriptions and the number of test cases was smaller than the number of statements . And interacting with the feature - relevant elements was also simple to the partic - ipants because the feature descriptions were clear and straightforward . 160 140 120 100 80 60 40 20 0 T i m e ( m i n ) Web Component ID Feature Specification Code Extraction C2 C5 C6 Fig . 7 . Time cost of feature speci(cid:12)cation and manually feature extraction by (cid:12)ve participants . We calculated the consistency of the test cases cho - sen by di(cid:11)erent participants to check if the chosen test cases were varied by di(cid:11)erent participants . Table 4 shows that in C2 and C5 , most of the tests are the same in (cid:12)ve participants’ results . That means the par - ticipants have a similar understanding of the test cases . The main reason was that the test cases in these compo - nents had explicit descriptions and were well structured in modules , as one participant said : \ It is easy to know what this test is working for . I clearly know what I want . " Table 4 . Number of Consistency Test Assertions Chosen by Participants Component # Inconsistency / # Ours P01 P02 P03 P04 P05 C2 0 / 25 0 / 25 0 / 25 2 / 25 1 / 25 C5 0 / 64 (cid:0) 1 / 64 0 / 64 0 / 64 0 / 64 C6 (cid:0) 2 / 239 + 44 / 239 + 31 / 239 + 12 / 239 + 15 / 239 Note : The positive number means the participant chose more test assertions than ours . And the negative number means the participant missed some test assertions . \ # Ours " represents the number of assertions chosen by our method . In C6 , there were some test assertions that the par - ticipants chose but were not included in our tests . We found that most of these assertions were described as testing the format of the date like \ tomorrow " , \ next year " , \ last month " . But in fact , the subject of these test cases was a JS function \ val ( ) " . The test oracles checked if the outputs of this function were as expected in various inputs as shown in Fig . 8 . The participants were misled by the test description , and they wrongly chose these test cases since they did not check the im - plementations of these tests . An essential question is whether the addition - al / missing test cases will make the extraction result di(cid:11)erent . The answer is yes . The extracting result will be in(cid:13)uenced by the type of additional / missing test cases . If an additional test case is chosen by users , an extra feature will be included in our result . If a test case is missing , a feature may or may not be lost in the extrac - tion result . If the chosen tests and the usage scenario do not cover the missing feature , the extraction result will lose the feature . Otherwise , the extracting result will be the same as expected . The missing test case needs to be selected by hand . Luckily , the foraging cost is not big . ( b ) ( a ) Fig . 8 . Test cases in C6 wrongly chosen by participants . ( a ) # 15 was described to test the format of the setting of the day \ Tomorrow " , but in fact , the test assertion was checking if the function input . val ( ’ + 1d’ ) in ( b ) could correctly run . Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 401 We compared the manual extraction results of the (cid:12)ve participants with our results as shown in Table 5 . Our results contained fewer statements than any of the participants’ results . We found that the participants mostly deleted the coarse - grained code snippets , for in - stance , the class or function de(cid:12)nitions , the if state - ments , or the try - catch blocks , while they seldom re - moved the single statements . All of them said they could delete more statements in their results . But they gave up as most of the rest had complex dependencies , and removing the irrelevant statements costs much ef - fort . One participant said in the interview : \ Locat - ing the implementation ( of the core function ) is over - whelming . I think it is enough to delete the irrelevant functions . And I have to admit that there are more statements that could be removed . But it will cost me much more time ( to (cid:12)nish the task ) , because (cid:12)nding the dependencies of variables is very complex and boring . " Table 5 . LOC Comparison Between Manual Results and Our Results Component Participant’s ID Our Result P01 P02 P03 P04 P05 C2 896 1140 876 912 843 578 C5 869 982 757 891 756 600 C6 1053 1366 1136 964 1169 610 Our results were compared with manual results to see the divergent decisions on the statements . The removed code snippets were classi(cid:12)ed into three cat - egories by their sizes : small block ( 1 { 5 consecutively deleted statements ) , medium block ( 6 { 10 consecutively deleted statements ) , and large block ( 10 + consecutively deleted statements ) . We counted the number of blocks and LOC for each kind of blocks . There were 1 001 small blocks ( total LOC = 2 077 ) , 158 medium blocks ( total LOC = 1 144 ) and 157 large blocks ( total LOC = 2 448 ) . In respect of LOC , the small blocks oc - cupied 36 . 63 % of the deleted statements ( delLOC = 2 : 05 ) , 20 . 19 % of the deleted statements were in medium blocks ( delLOC = 7 : 25 ) , and 43 . 18 % were in large blocks ( delLOC = 15 : 59 ) ; while in respect of the num - ber of blocks , 76 . 24 % of the deleted code snippets were small blocks , 11 . 92 % were medium blocks , and 11 . 84 % were large blocks . We looked through the deleted statements and found some typical statements that were missed by the participants . Most statements in small blocks were variable declarations , branches , function calls , etc . The medium and large blocks were mostly function def - initions and class de(cid:12)nitions . Our method removed considerable small code blocks , meaning that the par - ticipants forgot to remove a lot of scattered small code snippets . We also found some statements that could be re - tained as the participants did but were removed from our results . The typical statements are the variable dec - larations without initializations and the functions for enhancing the compatibility on di(cid:11)erent browsers . In our results , the variable declaration without the initial - ization was deleted and made the variable global if no error happened . This would in(cid:13)uence the program un - derstanding and software maintenance . In the further , heuristic rules to enhance code quality will be added to solve this problem , which will be discussed in Section 6 . The code of adaptation was removed since we only used Firefox and these statements were not executed in the test cases . The latter case happened in the other exist - ing methods since these features were not speci(cid:12)ed in the scenario or the test cases . Keeping these statements in the extraction result can enhance the robustness of the component . But checking the completeness of the feature speci(cid:12)cation is beyond the scope of this paper . In conclusion , our method can extract the imple - mentation of certain features . Users can save signi(cid:12)cant time with our method . To enhance the implementation quality , users could manually look through the extrac - tion result and decide the statements which should be deleted . 6 Limitations and Discussion In this section , we discuss the limitations in our method , including the (cid:13)aky test problem , the quality of test cases , and possible irrelevant code in the extraction result . We generate a GUI test case to compare the de - sired elements’ appearance - related properties . In some cases , the properties may be dynamically generated by the components and may not be consistent in di(cid:11)erent runs of tests . The generated test case may be (cid:13)aky . For instance , a test assertion checks the value of \ current - Date " to be \ 1st Jan . " , resulting in that the extracting result can pass the test only on 1st Jan . . Our HGA method only considers the hierarchical structure of the code , and it works in most cases . How - ever , the code structure is more complex . For instance , there may be some irrelevant statements distributed in di(cid:11)erent layers and had dependencies on each other . In this case , our method will be ine(cid:11)ective since it only considers removing statements in the same layer . These 402 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 cases rarely happened in our experiments and are re - mained to be solved in our future work . If the case cannot cover all the feature implemen - tation , some features such as the exception handlers or adaptation functions may be removed . Enlarging the test cases is vital but beyond the scope of this paper . Currently , we generate a result that highlighted the re - moved statements and asked the user to reserve or re - move them . Moreover , some irrelevant parameters may also exist in our result even though they are not active since the handlers are removed . Removing these irrel - evant parameters can help users better understand the implementation of features . But the process is complex since the parameters have much more complex depen - dencies than statements . 7 Conclusions In this paper , a novel code extraction method was proposed to extract the implementation of features spe - ci(cid:12)ed by the test cases . The feature requirements were transformed to be a set of test cases which cover both the visual and logical functionalities . The results of quantitative and qualitative experiments showed that the proposed method could correctly extract the imple - mentation utilizing the test cases provided by users and generated from user scenarios . Compared with directly extracting features from the source code , specifying the features by test cases could signi(cid:12)cantly save the hu - man e(cid:11)orts . The proposed method could facilitate the software reuse of web applications . In the GUI test case generation , we only generated a test case that checks the visual appearance of the result but ignores the appearance - unrelated features such as the memory cost . If these features are not covered by the test cases or usage scenario , they cannot be chosen in our method . We will provide more information on the user’s interaction with the component in the future work , and this may help the user (cid:12)nd more features of interest . It is also important to seek to insert the extracted result into users’ software automatically . That will help the users reuse the components in a (cid:13)exible and easy way . In this case , the extraction result has to adapt to the environment . We prepare to seek inspiration from studies on software transplantation [ 13 ] to achieve the goal . References [ 1 ] Krueger C W . Software reuse . ACM Computing Surveys , 1992 , 24 ( 2 ) : 131 - 183 . DOI : 10 . 1145 / 130844 . 130856 . [ 2 ] Chattopadhyay S , Nelson N , Gonzalez Y R , Leon A A , Pandita R , Sarma A . Latent patterns in activities : A (cid:12)eld study of how developers manage context . In Proc . the 41st IEEE / ACM Int . Conference on Software Engineering , May 2019 , pp . 373 - 383 . DOI : 10 . 1109 / ICSE . 2019 . 00051 . [ 3 ] Gascon - Samson J , Jung K , Goyal S , Rezaiean - Asel A , Pattabiraman K . ThingsMigrate : Platform - independent migration of stateful JavaScript IoT applications . In Proc . the 32nd European Conference on Object - Orie - nted Programming , July 2018 , Article No . 18 . DOI : 10 . 4230 / LIPIcs . ECOOP . 2018 . 18 . [ 4 ] Xu B , An L , Thung F , Khomh F , Lo D . Why reinvent - ing the wheels ? An empirical study on library reuse and re - implementation . Empirical Software Engineering , 2020 , 25 ( 1 ) : 755 - 789 . DOI : 10 . 1007 / s10664 - 019 - 09771 - 0 . [ 5 ] Kr(cid:127)uger J , Mukelabai M , Gu W , Shen H , Hebig R , Berger T . Where is my feature and what is it about ? A case study on recovering feature facets . Journal of Systems and Software , 2019 , 152 : 239 - 253 . DOI : 10 . 1016 / j . jss . 2019 . 01 . 057 . [ 6 ] Oney S , Myers B . FireCrystal : Understanding inte - ractive behaviors in dynamic web pages . In Proc . the 2019 IEEE Symp . Visual Languages and Human - Centric Computing , Sept . 2009 , pp . 105 - 108 . DOI : 10 . 1109 / VL - HCC . 2009 . 5295287 . [ 7 ] Hibschman J , Zhang H . Unravel : Rapid web application reverse engineering via interaction recording , source trac - ing , and library detection . In Proc . the 28th Annual ACM Symp . User Interface Software & Technology , Nov . 2015 , pp . 270 - 279 . DOI : 10 . 1145 / 2807442 . 2807468 . [ 8 ] Alimadadi S , Sequeira S , Mesbah A , Pattabiraman K . Un - derstanding JavaScript event - based interactions . In Proc . the 36th Int . Conference on Software Engineering , May 2014 , pp . 367 - 377 . DOI : 10 . 1145 / 2568225 . 2568268 . [ 9 ] Maras J , Stula M , Carlson J , Crnkovic I . Identifying code of individual features in client - side web applications . IEEE Trans . Software Engineering , 2013 , 39 ( 12 ) : 1680 - 1697 . DOI : 10 . 1109 / TSE . 2013 . 38 . [ 10 ] Sha(cid:11)er D W , Resnick M . \ Thick " authenticity : New me - dia and authentic learning . Journal of Interactive Learning Research , 1999 , 10 ( 2 ) : 195 - 216 . [ 11 ] Razzaq A , Le Gear A , Exton C , Buckley J . An empiri - cal assessment of baseline feature location techniques . Em - pirical Software Engineering , 2020 , 25 ( 1 ) : 266 - 321 . DOI : 10 . 1007 / s10664 - 019 - 09734 - 5 . [ 12 ] Burg B , Ko A J , Ernst M D . Explaining visual changes in web interfaces . In Proc . the 28th Annual ACM Symp . User Interface Software & Technology , Nov . 2015 , pp . 259 - 268 . DOI : 10 . 1145 / 2807442 . 2807473 . [ 13 ] Barr E T , Harman M , Jia Y , Marginean A , Petke J . Au - tomated software transplantation . In Proc . the 2015 Int . Symp . Software Testing and Analysis , July 2015 , pp . 257 - 269 . DOI : 10 . 1145 / 2771783 . 2771796 . [ 14 ] Jensen S H , M(cid:28)ller A , Thiemann P . Type analysis for JavaScript . In Proc . the 16th Int . Symp . Static Analysis , August 2009 , pp . 238 - 255 . DOI : 10 . 1007 / 978 - 3 - 642 - 03237 - 0 17 . [ 15 ] Kashyap V , Dewey K , Kuefner E A et al . JSAI : A static analysis platform for JavaScript . In Proc . the 22nd ACM SIGSOFT Int . Symp . Foundations of Software Engineer - ing , Nov . 2014 , pp . 121 - 132 . DOI : 10 . 1145 / 2635868 . 2635904 . Yong - Hao Long et al . : Test - Driven Feature Extraction of Web Components 403 [ 16 ] Guha A , Saftoiu C , Krishnamurthi S . The essence of JavaScript . In Proc . the 24th European Conference on Object - Oriented Programming , June 2010 , pp . 126 - 150 . DOI : 10 . 1007 / 978 - 3 - 642 - 14107 - 2 7 . [ 17 ] Madsen M , Livshits B , Fanning M . Practical static analysis of JavaScript applications in the presence of frameworks and libraries . In Proc . the 9th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on Foundations of Software Engineering , Au - gust 2013 , pp . 499 - 509 . DOI : 10 . 1145 / 2491411 . 2491417 . [ 18 ] Guarnieri S , Pistoia M , Tripp O , Dolby J , Teilhet S , Berg R . Saving the world wide web from vulnerable JavaScript . In Proc . the 2011 Int . Symp . Software Testing and Analysis , July 2011 , pp . 177 - 187 . DOI : 10 . 1145 / 2001420 . 2001442 . [ 19 ] Malik R S , Patra J , Pradel M . NL2Type : Inferring JavaScript function types from natural language infor - mation . In Proc . the 41st IEEE / ACM Int . Conference on Software Engineering , May 2019 , pp . 304 - 315 . DOI : 10 . 1109 / ICSE . 2019 . 00045 [ 20 ] Jensen S H , Madsen M , M(cid:28)ller A . Modeling the HTML DOM and browser API in static analysis of JavaScript web applications . In Proc . the 19th ACM SIGSOFT Symp . and the 13th European Conference on Founda - tions of Software Engineering , Sept . 2011 , pp . 59 - 69 . DOI : 10 . 1145 / 2025113 . 2025125 . [ 21 ] Kristensen E K , M(cid:28)ller A . Reasonably - most - general clients for JavaScript library analysis . In Proc . the 41st Int . Confe - rence on Software Engineering , May 2019 , pp . 83 - 93 . DOI : 10 . 1109 / ICSE . 2019 . 00026 . [ 22 ] Madsen M , Tip F , Lhot(cid:19)ak O . Static analysis of event - driven Node . js JavaScript applications . ACM SIGPLAN Notices , 2015 , 50 ( 10 ) : 505 - 519 . DOI : 10 . 1145 / 2858965 . 2814272 . [ 23 ] Park C , Ryu S . Scalable and precise static ana - lysis of JavaScript applications via loop - sensitivity . In Proc . the 29th European Conference on Object - Oriented Programming , July 2015 , pp . 735 - 756 . DOI : 10 . 4230 / LIPIcs . ECOOP . 2015 . 735 . [ 24 ] Andreasen E , Gong L , M(cid:28)ller A et al . A survey of dy - namic analysis and test generation for JavaScript . ACM Computing Surveys , 2017 , 50 ( 5 ) : Article No . 66 . DOI : 10 . 1145 / 3106739 . [ 25 ] Sen K , Kalasapur S , Brutch T , Gibbs S . Jalangi : A se - lective record - replay and dynamic analysis framework for JavaScript . In Proc . the 9th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering , August 2013 , pp . 488 - 498 . DOI : 10 . 1145 / 2491411 . 2491447 . [ 26 ] Burg B , Bailey R , Ko A J , Ernst M D . Interactive record / re - play for web application debugging . In Proc . the 26th ACM Symp . User Interface Software and Technology , Oct . 2013 , pp . 473 - 484 . DOI : 10 . 1145 / 2501988 . 2502050 . [ 27 ] Mahajan S , Halfond W G . Finding HTML presen - tation failures using image comparison techniques . In Proc . the 29th ACM / IEEE Int . Conference on Auto - mated Software Engineering , Sept . 2014 , pp . 91 - 96 . DOI : 10 . 1145 / 2642937 . 2642966 . [ 28 ] Ocariza F S , Pattabiraman K , Mesbah A . Detecting in - consistencies in JavaScript MVC applications . In Proc . the 37th Int . Conference on Software Engineering , May 2015 , pp . 325 - 335 . DOI : 10 . 1109 / ICSE . 2015 . 52 . [ 29 ] Wang J , Dou W , Gao C , Wei J . JSTrace : Fast reproducing web application errors . Journal of Systems and Software , 2018 , 137 : 448 - 462 . DOI : 10 . 1016 / j . jss . 2017 . 06 . 038 . [ 30 ] Li P , Wohlstadter E . Script InSight : Using models to ex - plore JavaScript code from the browser view . In Proc . the 9th Int . Conference on Web Engineering , June 2009 , pp . 260 - 274 . DOI : 10 . 1007 / 978 - 3 - 642 - 02818 - 2 21 . [ 31 ] Dow S P , Glassco A , Kass J , Schwarz M , Schwartz D L , Klemmer S R . Parallel prototyping leads to better design results , more divergence , and increased self - e(cid:14)cacy . ACM Trans . Computer - Human Interaction , 2010 , 17 ( 4 ) : Article No . 18 . DOI : 10 . 1145 / 1879831 . 1879836 . [ 32 ] Gibson D , Punera K , Tomkins A . The volume and evolu - tion of web page templates . In Proc . the 14th Int . Confe - rence on World Wide Web , May 2005 , pp . 830 - 839 . DOI : 10 . 1145 / 1062745 . 1062763 . [ 33 ] Lee B , Srivastava S , Kumar R , Brafman R , Klem - mer S R . Designing with interactive example galleries . In Proc . the SIGCHI Conference on Human Factors in Computing Systems , Apr . 2010 , pp . 2257 - 2266 . DOI : 10 . 1145 / 1753326 . 1753667 . [ 34 ] Kumar R , Talton J O , Ahmad S , Klemmer S R . Bricolage : Example - based retargeting for web design . In Proc . the SIGCHI Conference on Human Factors in Computing Systems , May 2011 , pp . 2197 - 2206 . DOI : 10 . 1145 / 1978942 . 1979262 . [ 35 ] Swearngin A , Dontcheva M , Li W , Brandt J , Dixon M , Ko A J . Rewire : Interface design assistance from exam - ples . In Proc . the 2018 CHI Conference on Human Factors in Computing Systems , Apr . 2018 , Article No . 504 . DOI : 10 . 1145 / 3173574 . 3174078 . [ 36 ] Wang Z , Cheng B , Jin Y , Feng Y , Chen J . EasyApp : A widget - based cross - platform mobile development environ - ment for end - users . In Proc . the 23rd Annual Int . Confe - rence on Mobile Computing and Networking , Oct . 2017 , pp . 591 - 593 . DOI : 10 . 1145 / 3117811 . 3131242 . [ 37 ] Benson E O , Karger D R . Cascading tree sheets and recombinant HTML : Better encapsulation and retarget - ing of web content . In Proc . the 22nd Int . Confe - rence on World Wide Web , May 2013 , pp . 107 - 118 . DOI : 10 . 1145 / 2488388 . 2488399 . [ 38 ] Verou L , Zhang A X , Karger D R . Mavo : Creat - ing interactive data - driven web applications by author - ing HTML . In Proc . the 29th Annual Symp . User Inter - face Software and Technology , Oct . 2016 , pp . 483 - 496 . DOI : 10 . 1145 / 2984511 . 2984551 . [ 39 ] Liu X , Huang G , Zhao Q , Mei H , Brain B M . iMashup : A mashup - based framework for service composition . Sci - ence China Information Sciences , 2014 , 57 ( 1 ) : 1 - 20 . DOI : 10 . 1007 / s11432 - 013 - 4782 - 0 . [ 40 ] Huang G , Liu X , Ma Y , Lu X , Zhang Y , Xiong Y . Pro - gramming situational mobile web applications with cloud - mobile convergence : An Internetware - oriented approach . IEEE Trans . Services Computing , 2016 , 12 ( 1 ) : 6 - 19 . DOI : 10 . 1109 / TSC . 2016 . 2587260 . [ 41 ] Eisenbarth T , Koschke R , Simon D . Locating features in source code . IEEE Trans . Software Engineering , 2003 , 29 ( 3 ) : 210 - 224 . DOI : 10 . 1109 / TSE . 2003 . 1183929 . 404 J . Comput . Sci . & Technol . , Mar . 2022 , Vol . 37 , No . 2 [ 42 ] Mahajan S , Alameer A , McMinn P , Halfond W G . Auto - mated repair of layout cross browser issues using search - based techniques . In Proc . the 26th ACM SIGSOFT Int . Symp . Software Testing and Analysis , July 2017 , pp . 249 - 260 . DOI : 10 . 1145 / 3092703 . 3092726 . [ 43 ] Chang T H , Yeh T , Miller R C . GUI testing using com - puter vision . In Proc . the 28th International Conference on Human Factors in Computing Systems , Apr . 2010 , pp . 1535 - 1544 . DOI : 10 . 1145 / 1753326 . 1753555 . Yong - Hao Long is currently a post - doc fellow in The Hong Kong Polytech - nic University , Hong Kong . He received his Ph . D . degree in computer science at Sun Yat - sen University , Guangzhou , in 2021 . His research interests include soft - ware reuse and GUI testing . Yan - Cheng Chen received his M . S . degree in software engineering from Sun Yat - sen University , Guangzhou , in 2020 . His research interests include software testing and veri(cid:12)cation . Xiang - Ping Chen is currently an associate professor in the Sun Yat - sen University , Guangzhou . She received her Ph . D . degree in software engi - neering from the Peking University , Beijing , in 2010 . Her research interests include software engineering and mining software repositories . Xiao - Hong Shi is currently a lec - turer in Guangzhou College of Com - merce , Guangzhou . She received her Ph . D . degree in mathematics from Guangzhou University , Guangzhou , in 2021 . Her research interests include software engineering and multimedia processing . Fan Zhou is currently a professor in Sun Yat - sen University , Guangzhou . He received his Ph . D . degree in com - puter science from Sun Yat - sen Uni - versity , Guangzhou , in 2007 . His re - search interests include computer graph - ics , computer aided design and image processing .