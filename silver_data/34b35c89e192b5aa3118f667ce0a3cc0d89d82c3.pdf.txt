Prompt Middleware : Mapping Prompts for Large Language Models to UI Affordances Stephen MacNeil Temple University Philadelphia , PA , USA stephen . macneil @ temple . edu Andrew Tran Temple University Philadelphia , PA , USA andrew . tran10 @ temple . edu Joanne Kim Temple University Philadelphia , PA , USA joanne . kim @ temple . edu Ziheng Huang University of California—San Diego La Jolla , CA , USA z8huang @ ucsd . edu Seth Bernstein Temple University Philadelphia , PA , USA seth . bernstein @ temple . edu Dan Mogil Temple University Philadelphia , PA , USA daniel . mogil @ temple . edu Figure 1 : Three methods to connect user interface components to large language models . 1 ) static prompts are predefined prompts that can be selected directly from the UI , 2 ) template - based prompts generate prompts based on selected options in the UI , 3 ) free - form prompts provide a direct way of interacting with prompts . KEYWORDS large language models , prompt middleware , prompt programming 1 ABSTRACT To help users do complex work , researchers have developed tech - niques to integrate AI and human intelligence into user interfaces ( UIs ) . With the recent introduction of large language models ( LLMs ) , which can generate text in response to a natural language prompt , there are new opportunities to consider how to integrate LLMs into UIs . We present Prompt Middleware , a framework for generating prompts for LLMs based on UI affordances . These include prompts that are predefined by experts ( static prompts ) , generated from templates with fill - in options in the UI ( template - based prompts ) , or created from scratch ( free - form prompts ) . We demonstrate this framework with FeedbackBuffet , a writing assistant that automati - cally generates feedback based on a user’s text input . Inspired by Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for third - party components of this work must be honored . For all other uses , contact the owner / author ( s ) . UIST 2022 , Oct 20 – Nov 2 , 2022 , Bend , Oregon © 2022 Copyright held by the owner / author ( s ) . ACM ISBN 978 - 1 - 4503 - XXXX - X / 18 / 06 . prior research showing how templates can help non - experts per - form more like experts , FeedbackBuffet leverages template - based prompt middleware to enable feedback seekers to specify the types of feedback they want to receive as options in a UI . These options are composed using a template to form a feedback request prompt to GPT - 3 . We conclude with a discussion about how Prompt Mid - dleware can help developers integrate LLMs into UIs . 2 INTRODUCTION Previous research has demonstrated ways that intelligence can be integrated into UI [ 2 , 4 , 13 , 15 , 19 ] . In ‘Wizard of Oz’ systems , an expert manually controls UI features to simulate an intelligent user interface [ 4 , 19 ] . Similarly , crowdsourcing systems , such as Soylent [ 2 ] , integrate crowdworkers to power UIs through crowd workflows [ 13 , 15 ] . Finally , specialized machine learning models have also been trained for a specific task and then embedded into systems and interfaces [ 23 ] . Across these systems , rules , heuristics , workflows , and specialized models guide the ways that interface affordances can be enhanced with intelligence . Recent advances in natural language processing have resulted in large language models ( LLMs ) , such as GPT - 3 [ 3 ] , which have the ability to understand natural language prompts and generate relevant text responses . These models are already being used to facilitate creative work [ 5 , 6 , 9 , 20 , 27 ] . However , it is not yet clear a r X i v : 2307 . 01142v1 [ c s . H C ] 3 J u l 2023 UIST 2022 , Oct 20 – Nov 2 , 2022 , Bend , Oregon MacNeil et al . how to best integrate LLMs into existing UI . In this paper , we explore three methods for integrating LLMs into UI using prompts that are predefined by experts ( static prompts ) , generated from templates with fill - in options in the UI ( template - based prompts ) , or created from scratch ( free - form prompts ) . These three techniques for integrating LLMs into UIs , which we call Prompt Middleware , provide varying amounts of control and guidance to users over the underlying prompt generation process . We demonstrate the concept of Prompt Middleware by developing FeedbackBuffet , a writing assistant that generates feedback for users by guiding them through a menu of feedback options allowing them to determine the type of feedback they would like to receive . FeedbackBuffet implements the ‘template prompt’ middleware to package these feedback options into a prompt for GPT - 3 . 3 PROMPT MIDDLEWARE : CONNECTING UI AFFORDANCES TO LLMS Crafting high - quality prompts is challenging [ 11 , 22 ] . To help peo - ple create high - quality prompts , PromptMaker guides users to cre - ate their own prompts with templates and procedural guidance [ 11 ] . Another approach called AI Chaining simplifies a complex prompt - ing process by splitting a request into smaller requests which are individually prompted and then stitched back together [ 24 ] . This approach was shown to improve performance and transparency . Where previous work has focused on making prompt engineer - ing easier , these approaches have not yet addressed two crucial aspects : 1 ) techniques to scaffold domain expertise into the prompting process , and 2 ) directly integrating LLMs into user interfaces . We propose Prompt Middleware as a framework for achieving these two goal by mapping options in the UI to generate prompts for an LLM . Prompt Middleware acts as a middle layer between the LLM and the UI , while also embedding domain expertise into the prompt - ing process . The UI abstracts away the complexity of the prompts and separates concerns between a user completing their tasks and the prompts that might guide LLMs to help them in those tasks . Summarized in Figure 1 , the following sections introduce three Prompt Middleware types : static , template - based , and free - form . 3 . 1 Static prompts leverage best practices Prompt engineering and few - shot learning are common techniques to improve the quality of responses from LLMs [ 22 ] . We propose the concept of static prompts as a method for making these best practices available to users in a UI . A static prompt is a predefined prompt generated by experts through prompt engineering to achieve high - quality responses from an LLM . As shown in Figure 1 , static prompts can be hidden behind a button in a UI to send a predefined prompt to an LLM on behalf of the user . This allows users to tap into best practices with minimal effort but at the cost of giving up control of prompt generation . 3 . 2 Template - based prompts provide flexibility Previous researchers have shown how expertise and best prac - tices can be directly embedded into templates to guide crowdwork - ers [ 12 ] , non - experts [ 10 , 17 , 18 , 28 ] , and even experts [ 8 ] to do better work . For example , Motif , a video storytelling application , leverages storytelling patterns to guide users’ story creation [ 12 ] . Inspired by how templates can guide people , we explore how expert templates might similarly guide LLMs . We propose template - based prompts as a method for generating prompts by filling in a pre - made template with options from a user interface . The template and user interface can integrate expertise and best practices while giving users more control through options in the UI . 3 . 3 Free - form prompts provide full control Previous research shows that developing free - form prompts can be challenging [ 11 ] . However , experts can generate high - quality prompts through the process of prompt engineering . Providing users with full control of the prompting process may be desired in some cases . Free - form prompts provide full access to users as they design their prompt from scratch . 4 CASE STUDY The case study methodology is a technique for illustrating an idea through the use of examples [ 26 ] . To engage more deeply with the concept of Prompt Middleware , we developed the FeedbackBuffet prototype which implements the template - based prompting design pattern . This case study illustrates what template - based prompting might look like when implemented in a user interface . 4 . 1 FeedbackBuffet System FeedbackBuffet is a writing assistant that allows users to request automated feedback for any writing sample , such as an essay , email , or statement of purpose , based on UI options . As shown in Fig - ure 2 , UI options offer users relevant feedback options which are combined using a template to form a prompt for GPT - 3 . The tem - plate integrates best practices of feedback design and cues the feed - back seeker to consider qualities of good feedback . FeedbackBuffet implements the template - based prompt middleware to integrate intelligence into the interface . 4 . 1 . 1 System Implementation . The system is implemented as a ReactJS web app . The prompts are generated through template literals ( i . e . : string interpolation ) where each selected option from the UI is injected into the template to form a string that is sent as a prompt to OpenAI via API calls using zero - shot learning . 4 . 1 . 2 Integrate Best Practices in Feedback Design . There are prin - ciples and best practices for feedback design , such as asking a clarifying question and then making a statement [ 16 ] , sandwiching criticism between two positive comments [ 7 ] , and making feedback actionable [ 14 ] . The feedback template used by FeedbackBuffet is based on a feedback framework that includes valence , level of abstraction , and feedback type [ 1 ] , summarized in Figure 2 . We present examples of the feedback generated by GPT - 3 using our template in Figure 3 . 4 . 2 Use Case : Requesting Design Feedback To illustrate how FeedbackBuffet operates , we present the following use case about Sasha , a CS student who is taking career prepara - tory course to work on his statement of purpose . Sasha completes a first draft of his statement and he receives feedback from his instructor that critiques the structure—Sasha did not start with a strong motivation . He focused too much on the graduate program Prompt Middleware UIST 2022 , Oct 20 – Nov 2 , 2022 , Bend , Oregon Figure 2 : FeedbackBuffet enables users to insert writing samples ( 1 ) and select from a set of predefined options for the type of feedback they want to receive ( 2 ) . Using a template , these options are combined to form a prompt ( 3 ) which is sent to GPT - 3 using OpenAI’s public API ( 4 ) . GPT - 3 then generates feedback , which is displayed in a text box for the user to review ( 5 ) . before motivating the reader . After adding motivation based on his journey into computers , he uses FeedbackBuffet to get more feedback before his next class . He pastes his statement into the in - put area and selects options to request feedback about the content of this draft . These options along with his draft are packaged as a prompt and then sent to GPT - 3 . He receives the feedback shown in Figure 2 . Based on this feedback , Sasha edits his statement to add more specific details about how he learned to code by forming an informal group with his friends . He continues to iterate on his statement of purpose , periodically referring back to FeedbackBuffet , and he is excited to show his progress to his instructor . 5 DISCUSSION In this paper , we build on existing research [ 2 , 10 , 17 , 18 , 21 ] for integrating expertise and intelligence into UIs . We introduce the Prompt Middleware Framework to guide the process of integrating LLMs into a UI . We demonstrate this vision with FeedbackBuffet , a intelligent writing assistant that automatically generates feedback based on text input . Given that previous attempts at integrating intelligence may require effort to acquire intelligence sources or be costly , FeedbackBuffet offers a lightweight method for integrating intelligence and best practices into a UI . FeedbackBuffet’s UI acts as a facade around the LLM , abstracting away the complexity of interacting with LLMs . While FeedbackBuffet currently focuses on template - based prompts , we could include static prompts as well . For example , with a button titled ‘Pros and Cons’ , which would send the prompt shown in Figure 1 to an LLM . Researchers have identified several challenges individuals face when interacting with general purpose AI , such as a lack of aware - ness about the AI’s capabilities which can lead them to request overly complicated on non - existent tasks from the AI agent [ 25 ] . Researchers are still developing an understanding of the capabil - ities of LLMs , but in this paper we show it is possible to convey known possibilities afforded by LLMs through a UI . Through static prompts , users can use prompts that have been engineered by ex - perts to be effective . Through template - based prompts , they can choose from a list of menu options to generate prompts that have been previously tested by experts . This ability to communicate the capabilities afforded by LLMs has the potential to make them more accessible for non - experts . As future work , we plan to evaluate three systems , including FeedbackBuffet , that embody these three types of prompt middle - ware to understand how best to integrate LLMs into existing UI . Through this evaluation , we also hope to develop a better under - standing of how much control is desired when interacting with LLMs through UI . While complete control in the form of free - form prompts might be desired in some contexts , it likely depends . For example , a feedback system based on static prompts , which provide less control , may simplify the feedback request process . 6 CONCLUSION In this paper , we present FeedbackBuffet , a writing assistant that generates feedback on writing samples using GPT - 3 . The user can choose from a set of feedback options that are combined using a template to form a prompt for GPT - 3 . This system demonstrates UIST 2022 , Oct 20 – Nov 2 , 2022 , Bend , Oregon MacNeil et al . how templates can serve as middleware to map affordances in a user interface to prompt a large language model . This work serves as an initial step toward developing a prompt middleware that can bridge the gap between users and large language models . REFERENCES [ 1 ] Ibis Alvarez , Anna Espasa , and Teresa Guasch . 2012 . The value of feedback in improving collaborative writing assignments in an online learning environment . Studies in Higher Education 37 , 4 ( 2012 ) , 387 – 400 . [ 2 ] Michael S Bernstein , Greg Little , Robert C Miller , Björn Hartmann , Mark S Ackerman , David R Karger , David Crowell , and Katrina Panovich . 2010 . Soylent : a word processor with a crowd inside . In Proceedings of the 23nd annual ACM symposium on User interface software and technology . 313 – 322 . [ 3 ] Tom Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared D Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , et al . 2020 . Language models are few - shot learners . Advances in Neural Information Processing Systems 33 ( 2020 ) , 1877 – 1901 . [ 4 ] Nils Dahlbäck , Arne Jönsson , and Lars Ahrenberg . 1993 . Wizard of Oz stud - ies—why and how . Knowledge - based systems 6 , 4 ( 1993 ) , 258 – 266 . [ 5 ] Giulia Di Fede , Davide Rocchesso , Steven P . Dow , and Salvatore Andolina . 2022 . The Idea Machine : LLM - Based Expansion , Rewriting , Combination , and Sugges - tion of Ideas . In Proceedings of the 14th Conference on Creativity and Cognition ( Venice , Italy ) ( C & C ’22 ) . Association for Computing Machinery , New York , NY , USA , 623 – 627 . https : / / doi . org / 10 . 1145 / 3527927 . 3535197 [ 6 ] Zijian Ding , Arvind Srinivasan , Stephen Macneil , and Joel Chan . 2023 . Fluid Transformers and Creative Analogies : Exploring Large Language Models’ Ca - pacity for Augmenting Cross - Domain Analogical Creativity . In Proceedings of the 15th Conference on Creativity and Cognition ( Virtual Event , USA ) ( C & C ’23 ) . Association for Computing Machinery , New York , NY , USA , 489 – 505 . https : / / doi . org / 10 . 1145 / 3591196 . 3593516 [ 7 ] Dennis M Docheff . 1990 . The feedback sandwich . Journal of Physical Education , Recreation & Dance 61 , 9 ( 1990 ) , 17 – 18 . [ 8 ] Atul Gawande . 2009 . The Checklist Manifesto : How to Get Things Right . Metropol - itan Books . [ 9 ] Ziheng Huang , Kexin Quan , Joel Chan , and Stephen MacNeil . 2023 . CausalMap - per : Challenging Designers to Think in Systems with Causal Maps and Large LanguageModel . In Proceedingsofthe15thConferenceonCreativityandCognition ( VirtualEvent , USA ) ( C & C’23 ) . AssociationforComputingMachinery , NewYork , NY , USA , 325 – 329 . https : / / doi . org / 10 . 1145 / 3591196 . 3596818 [ 10 ] Julie S Hui , Darren Gergle , and Elizabeth M Gerber . 2018 . Introassist : A tool to support writing introductory help requests . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems . 1 – 13 . [ 11 ] Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie J Cai . 2022 . PromptMaker : Prompt - based Prototyping with Large Language Models . In CHI Conference on Human Factors in Computing Systems Extended Abstracts . 1 – 8 . [ 12 ] JoyKim , MiraDontcheva , WilmotLi , MichaelS . Bernstein , andDanielaSteinsapir . 2015 . Motif : SupportingNoviceCreativitythroughExpertPatterns . In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems ( Seoul , Republic of Korea ) ( CHI ’15 ) . Association for Computing Machinery , New York , NY , USA , 1211 – 1220 . https : / / doi . org / 10 . 1145 / 2702123 . 2702507 [ 13 ] Aniket Kittur , Susheel Khamkar , Paul André , and Robert Kraut . 2012 . Crowd - Weaver : visually managing complex crowd work . In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work . 1033 – 1036 . [ 14 ] Markus Krause , Tom Garncarz , JiaoJiao Song , Elizabeth M . Gerber , Brian P . Bailey , and Steven P . Dow . 2017 . Critique Style Guide : Improving Crowdsourced Design Feedback with a Natural Language Model . In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems ( Denver , Colorado , USA ) ( CHI ’17 ) . Association for Computing Machinery , New York , NY , USA , 4627 – 4639 . https : / / doi . org / 10 . 1145 / 3025453 . 3025883 [ 15 ] Anand Kulkarni , Matthew Can , and Björn Hartmann . 2012 . Collaboratively crowdsourcing workflows with turkomatic . In Proceedings of the acm 2012 con - ference on computer supported cooperative work . 1003 – 1012 . [ 16 ] Fritz Lekschas , Spyridon Ampanavos , Pao Siangliulue , Hanspeter Pfister , and Krzysztof Z . Gajos . 2021 . Ask Me or Tell Me ? Enhancing the Effectiveness of Crowdsourced Design Feedback . In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 564 , 12 pages . https : / / doi . org / 10 . 1145 / 3411764 . 3445507 [ 17 ] Stephen MacNeil , Zijian Ding , Kexin Quan , Thomas j Parashos , Yajie Sun , and Steven P . Dow . 2021 . Framing Creative Work : Helping Novices Frame Better Problems through Interactive Scaffolding . In Creativity and Cognition ( Virtual Event , Italy ) ( C & C ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 30 , 10 pages . https : / / doi . org / 10 . 1145 / 3450741 . 3465261 [ 18 ] Stephen MacNeil , Ziheng Huang , Kenneth Chen , Zijian Ding , Alexander Yu , Kendall Nakai , and Steven P . Dow . 2023 . Combining Freeform Curation with Structured Templates . In Creativity and Cognition ( Gathertown ) ( C & C ’19 ) . ACM , New York , NY , USA , 11 pages . https : / / doi . org / 10 . 1145 / 3591196 . 3593337 [ 19 ] David Maulsby , Saul Greenberg , and Richard Mander . 1993 . Prototyping an Intelligent Agent through Wizard of Oz . In Proceedings of the INTERACT ’93 and CHI ’93 Conference on Human Factors in Computing Systems ( Amsterdam , The Netherlands ) ( CHI ’93 ) . Association for Computing Machinery , New York , NY , USA , 277 – 284 . https : / / doi . org / 10 . 1145 / 169059 . 169215 [ 20 ] Piotr Mirowski , Kory W Mathewson , Jaylen Pittman , and Richard Evans . 2023 . Co - Writing Screenplays and Theatre Scripts with Language Models : Evaluation by Industry Professionals . In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems . 1 – 34 . [ 21 ] VineetPandey , JustineDebelius , EmbrietteRHyde , TomaszKosciolek , RobKnight , and Scott Klemmer . 2018 . Docent : transforming personal intuitions to scientific hypotheses through content learning and process training . In Proceedings of the Fifth Annual ACM Conference on Learning at Scale . 1 – 10 . [ 22 ] Laria Reynolds and Kyle McDonell . 2021 . Prompt Programming for Large Lan - guage Models : Beyond the Few - Shot Paradigm . In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems ( Yokohama , Japan ) ( CHI EA ’21 ) . Association for Computing Machinery , New York , NY , USA , Article 314 , 7 pages . https : / / doi . org / 10 . 1145 / 3411763 . 3451760 [ 23 ] Sarah Theres Völkel , Christina Schneegass , Malin Eiband , and Daniel Buschek . 2020 . What is " Intelligent " in Intelligent User Interfaces ? A Meta - Analysis of 25 Years of IUI . In Proceedings of the 25th International Conference on Intelligent User Interfaces ( Cagliari , Italy ) ( IUI ’20 ) . Association for Computing Machinery , New York , NY , USA , 477 – 487 . https : / / doi . org / 10 . 1145 / 3377325 . 3377500 [ 24 ] TongshuangWu , MichaelTerry , andCarrieJunCai . 2022 . AIChains : Transparent and Controllable Human - AI Interaction by Chaining Large Language Model Prompts . In Proceedingsofthe2022CHIConferenceonHumanFactorsinComputing Systems ( NewOrleans , LA , USA ) ( CHI’22 ) . AssociationforComputingMachinery , New York , NY , USA , Article 385 , 22 pages . https : / / doi . org / 10 . 1145 / 3491102 . 3517582 [ 25 ] Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020 . Re - Examining Whether , Why , and How Human - AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York , NY , USA , 1 – 13 . https : / / doi . org / 10 . 1145 / 3313831 . 3376301 [ 26 ] Robert K Yin et al . 2018 . Case study research and applications : Design and methods . Los Angeles , UK : Sage ( 2018 ) . [ 27 ] Ann Yuan , Andy Coenen , Emily Reif , and Daphne Ippolito . 2022 . Wordcraft : story writing with large language models . In 27th International Conference on Intelligent User Interfaces . 841 – 852 . [ 28 ] AlvinYuan , KurtLuther , MarkusKrause , SophieIsabelVennix , StevenPDow , and BjornHartmann . 2016 . AlmostanExpert : TheEffectsofRubricsandExpertiseon PerceivedValueofCrowdsourcedDesignCritiques . In Proceedingsofthe19thACM Conference on Computer - Supported Cooperative Work & Social Computing ( San Francisco , California , USA ) ( CSCW ’16 ) . Association for Computing Machinery , New York , NY , USA , 1005 – 1017 . https : / / doi . org / 10 . 1145 / 2818048 . 2819953 Prompt Middleware UIST 2022 , Oct 20 – Nov 2 , 2022 , Bend , Oregon Figure 3 : Examples of feedback that GPT - 3 can provide by combining different options within our feedback template . These results can be compared across two example contexts—an email and a short statement of purpose .