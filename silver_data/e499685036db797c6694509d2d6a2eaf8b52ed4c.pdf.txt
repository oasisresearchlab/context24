The Social Cost of Cheap Pseudonyms Eric J . Friedman ∗ Department of Economics , Rutgers University New Brunswick , NJ 08903 . Paul Resnick University of Michigan School of Information 314 West Hall Ann Arbor , MI 48109 - 1092 August 17 , 2000 Abstract We consider the problems of societal norms for cooperation and reputation when it is possible to obtain “cheap pseudonyms” , something which is becoming quite common in a wide variety of interactions on the Internet . This introduces opportunities to mis - behave without paying reputational consequences . A large degree of cooperation can still emerge , through a convention in which newcomers “pay their dues” by accepting poor treatment from players who have established positive reputations . One might hope for an open society where newcomers are treated well , but there is an inherent social cost in making the spread of reputations optional . We prove that no equilib - rium can sustain signiﬁcantly more cooperation than the dues - paying equilibrium in a repeated random matching game with a large number of players in which players have ﬁnite lives and the ability to change their identities , and there is a small but nonvanishing probability of mistakes . Although one could remove the ineﬃciency of mistreating newcomers by disallowing anonymity , this is not practical or desirable in a wide variety of transactions . We discuss the use of entry fees , which permits newcomers to be trusted but excludes some players with low payoﬀs , thus introducing a diﬀerent ineﬃciency . We also discuss the use of free but unreplaceable pseudonyms , and describe a mechanism which implements them using standard encryption techniques , which could be practically implemented in electronic transactions . ∗ This was supported in part by the National Science Foundation under grant IIS - 9977999 . The authors would like to thank Roger Klein , Jeﬀ MacKie - Mason , Rich Mclean , Hiroki Tsurumi , and workshop partic - ipants at Berkeley , Harvard , Michigan , Rutgers and Stonybrook for helpful conversations and comments . Email : friedman @ econ . rutgers . edu and presnick @ umich . edu . 1 1 Introduction One of the fundamental questions of social theory is the conditions which facilitate coop - eration . Repetition and reputation are two of the most useful features . Repetition causes people to cooperate in the present in order to avoid negative consequences in future interac - tions with the same people . Reputations spread information about people’s behavior , so that expectations of future interactions can inﬂuence behavior even if the future interactions may be with diﬀerent people than those in the present . The ways in which reputations spread can aﬀect their ability to inﬂuence behavior , and it is especially interesting to consider situations where people exercise some control over the spread of their own reputations , a situation that is common on the Internet . The Internet has spawned numerous social and business environments that allow frequent and meaningful interactions among people who are relative strangers . This leads to many problems and properties that do not usually arise in other social settings . However , the pliability of the Internet as a social structure also allows for a large degree of “engineering” which is also more diﬃcult in standard social settings , allowing for the solution of many of these problems , and providing a fertile ground for the application of many tools from economics and game theory . 1 The key aspect of reputation on the Internet that does not typically arise in non - electronic settings is the ability to easily change one’s identity ; whereas in real life this is a complex process ( often involving national governments and cosmetic surgery ) on the Internet an iden - tity change may require just a few keystrokes . 2 Thus , a person has a choice of interacting 1 For example , recent applications include the economics of information ( Varian , 1997 ) , economic aspects of evaluations ( Avery , Resnick and Zeckhauser , 1999 ) , aspects of competition ( Bakos and Brynjolfsson , 1998 ) , cost sharing ( Moulin and Shenker ( 1992 ) , Herzog , Shenker and Estrin , ( 1997 ) ) and various properties of learning ( Friedman and Shenker , 1998 ) . 2 Many games , auction sites , and interactive forums allow users to choose a pseudonym when they register . Even services that identify users based on their email addresses do not prevent identity changes , since users can easily acquire new email addresses through free services like Hotmail . Beyond name changes , the Internet enables completely anonymous interactions . For example , anonymizing intermediaries such as remailers and proxy servers can exchange messages between parties without revealing either one’s identity to the other ( Goldschlag , Reed , and Syverson 1999 , Rubin and Reiter 1999 ) . There are even techniques using cryptography that allow for electronic payments where the buyer’s identity is untraceable ( Schneier , 1996 , p . 139 - 147 ) . 2 anonymously ( by changing identiﬁers constantly ) or maintaining a persistent identity . This case is intermediate between persistent identities and totally anonymous interactions . In eﬀect , the option of anonymity turns the transfer of reputation information into a strate - gic variable , controlled by each player , in contrast to previous work ( Kandori ( 1992 ) , and Milgrom , North and Weingast ( 1990 ) ) where reputation transfer is limited but not under players’ control . 3 With name changes , people can easily shed negative reputations . 4 For example , some health support forums have been shaken by people who pretend to have severe illnesses and other problems . Once found out such people often reappear on the same or a diﬀerent forum with a new identity and repeat the process . For example , Alice Grady ( 1998 ) reported on a woman who claimed that she had an eating disorder and an abusive boyfriend to gain sympathy in an eating - disorder chat group on the Internet . Eventually found out , she continued her tales in other support groups . Chased out of the eating - disorder chat room , the woman turned up in others , including one for sexual - abuse survivors . She was found out and banished from that one , too , then joined another group . When last heard from , she was dying of AIDS . Easy name changes make it natural to distrust newcomers , since they may really be people who have just changed identiﬁers . But such distrust imposes other costs . Grady ( 1998 ) reports : In another scam that dragged on for months last year , a girl [ Kim ] who said she was 15 communicated on line with parents of premature infants . The 400 or so members in the virtual support group had babies who were or had been critically ill and had spent months in the hospital . . . . 3 Tadelis ( 1999 ) considers an interesting model where reputation transfer is a strategic variable but where performance is not . In that model , names may be traded from higher skill to lower skill players , decreasing but not eliminating the signaling value of reputations . By contrast , we are interested in situations where reputations serve not as signals of underlying skill but as motivators for good performance . 4 On the Internet , nobody knows that yesterday you were a dog , and therefore should be in the doghouse today . 3 Regardless of what drove Kim , her behavior had a chilling eﬀect on a group that had been trusting and closely knit . Some parents expressed feelings of betrayal , and many stopped posting messages . People in the group agreed to provide information so a coordinator could verify that they really were parents of preemies . Some newcomers were put oﬀ by the atmosphere of suspicion . Even with easy name changes , there can still be a fair amount of cooperation , however , as people will want to develop positive reputations . For example , the on - line auction service eBay ( www . ebay . com ) maintains a “Feedback Forum” for buyers and sellers to make com - ments about each other , after a trade is completed . 5 As analyzed by Peter Kollock ( 1998 ) , people go out of their way to accumulate positive comments and , once they have accumu - lated them , to avoid negative comments . 6 Two empirical studies , by David Lucking - Reiley et al ( 2000 ) and by Patrick Bajari and Ali Hortacsu ( 2000 ) suggest that , at least for some product categories , negative comments reduce selling prices , though the studies do not show a clear eﬀect of positive comments on prices . Newcomers can overcome initial distrust by accepting bad treatment for a while , a form of dues paying that is suﬃcient to discourage participants from changing identiﬁers . But suspicion of newcomers is socially ineﬃcient , especially in free - ﬂowing environments with lots of newcomers : it would be more eﬃcient to trust newcomers until they proved untrust - worthy , if that did not provide incentives for participants to misbehave and then change identiﬁers . The distrust can be eliminated entirely through a subtle punishment strategy , where newcomers are distrusted only if a veteran player in the previous period did some - thing wrong . That strategy is quite brittle , however , in the face of either a few malicious participants 7 or occasional mistakes ( trembles ) , such as typing the wrong key by accident . 5 Recognizing the importance of persistent reputations , eBay oﬀers an easy name - changing facility , but a person’s feedback comments follow such name changes . This attempt to limit reputation shedding may be futile , however , since a person can easily acquire a new email address and then re - register with no trace of the earlier comments . 6 One participant reported that after an accidental snafu , he received a check from the seller for more than the purchase price of the item he had bought , along with a request not to enter a negative comment . [ David Richardson , personal communication , January 1998 . ] 7 If it were possible to collapse an entire social order with a single malicious act , then it is hard to imagine 4 In fact , with either malicious players or occasional trembles , we prove that there is no way to achieve substantially more cooperation in equilibrium than that achieved by distrusting all newcomers . Thus , the distrust of newcomers is an inherent social cost of easy identity changes . 8 Unfortunately , the obvious solution of disallowing anonymity is problematic for a variety of reasons , from questions of civil liberties to the practical eﬀects on information exchange . On - line support forums for diseases such as AIDS could not function without some guarantees of anonymity , in order to avoid negative consequences from people they know in real life ﬁnd - ing out about their condition . On a lighter side , many users of gaming network sites such as chess ( chess . onenet . net ) , backgammon ( www . netgammon . com ) , bridge ( www . okbridge . com ) , go ( igs . nuri . net ) or quake ( www . idsoftware . com ) prefer anonymity , while role playing games depend fundamentally on the disassociation between real identities and roles played . De - spite the disassociation with real identities , information about the past behavior of players is important in choosing partners who play at a similar skill level , have a compatible sense of sportsmanship , and have fast network connections . Thus , we must encourage players to maintain a persistent identiﬁer within each social arena without relying on the veriﬁcation and revelation of true identities . that some player would not topple the system for ‘fun . ’ Consider such common entities on the Internet as viruses and worms . 8 This is somewhat analogous to the trust - building that must accompany the beginning of long - term re - lationships . Ghosh and Ray ( 1996 ) , Kranton ( 1996 ) and Watson ( 1999 ) analyze models where individuals form cooperative pairwise relationships that either party can break oﬀ at any time . At the end of a relation - ship , both individuals are randomly matched with someone else , and no information about past behavior is available to the new partner . In order to maintain cooperation in the long - term relationships , there must be a cost to starting over , and the equilibria they ﬁnd all begin with some type of sunk cost , such as a slow - start where partners play for low stakes initially and gradually trust more over time . Breaking oﬀ a match in these models is analogous to changing a pseudonym in our context , which in equilibrium must incur a cost for the individual , to encourage players to maintain good behavior using their current pseudonyms . In our model , when two newcomers meet their play is analogous to these slow - start strategies . However , unlike these models of long - term relationships , starting over is not a symmetric act in our analysis ; a veteran player can maintain a positive reputation with her current pseudonym even if an interaction partner acts badly and starts over with a new pseudonym . This enables us to consider what happens when newcomers interact with veterans , and we ﬁnd equilibria where veterans extract dues directly from newcomers rather than equilibria where newcomers dissipate value in their interactions with each other . This behavior is analogous to an asymmetric version of the giving of gifts that are costly to the giver but not valuable to the receiver , which can also be used to maintain long term relationships ( see , e . g . , Carmicheal and Macleod , 1996 ) . 5 An obvious candidate is the use of entry fees ( associated with each personal identiﬁer ) . One commonly used procedure is a time consuming registration process ; while such a pro - cedure may encourage cooperation , it is clearly wasteful . Using monetary registration fees entails no such loss of eﬃciency , as they are pure transfers , but in a heterogeneous environ - ment may prevent players from using the system , which is clearly ineﬃcient as these systems are essentially public goods with zero or eﬀectively negative marginal cost ( due to network externalities ) . The conventional wisdom is that there is an inherent tradeoﬀ between anonymity and accountability . For example , several articles in a special issue of The Information Society emphasize that there are real beneﬁts to anonymity , despite the costs that come from reduced accountability ( Kling et al 1999 , Marx 1999 , Nissenbaum 1999 ) . The beneﬁts stem from separating behavior in one realm from possible repercussions in another , and can accrue to whistle - blowers , politial dissidents , people with stigmatized diseases , and people who merely want to keep their purchasing behavior private from potential gossips . The consensus of a AAAS sponsored conference , as reported by Teich et al ( 1999 ) , was that the tradeoﬀs should sometimes be resolved in favor of anonymity and thus that regulatory regimes should strive to preserve the possibility of anonymity . We show , however , that it is not always necessary to choose : there is an intermediate form of anonymity that maintains the privacy beneﬁts but reduces the social costs from loss of accountability . We propose a system of anonymous certiﬁcates in which , for each diﬀerent social arena , a person is given a single identiﬁer that is unrelated to the person’s true identity ; however , the certiﬁcate provider guarantees that each person will only be granted a single certiﬁcate ( in each arena ) . We call these once - in - a - lifteime identiﬁers . A player using a once - in - a - lifetime identiﬁer eﬀectively commits to having his reputation spread through the arena . Given the option , players would choose to make such commitments and thus achieve the same level of cooperation that would be achieved playing under their true identiﬁers . If , for example , a collection of support groups deﬁned itself as a single arena , then a malicious intruder could disrupt only one group ; exclusion from that group could lead to exclusion from the 6 others . We show that such certiﬁcates can be constructed with a large degree of security using standard encryption techniques . The paper is organized as follows . In the next section we present the basic model . Sec - tion 3 considers the eﬀects of a fraction (cid:143) of malicious players who thrive on sowing discord among the other players and the related scenario where each player trembles with proba - bility (cid:143) . Section 4 discusses monetary entry fees . Finally , section 5 presents the certiﬁcate mechanism for once - in - a - lifetime identiﬁers . 2 The Basic Model We consider an inﬁnite , synchronously repeated game with periods t ∈ T = { 0 , 1 , . . . } . In each period , there are M active players . At the end of each period αM exit ( e . g . , their interests change and they no longer visit the web site or participate in that newsgroup ) and the same number of new players enter . ( Assume that α ∈ ( 0 , 1 ) and αM is an integer . ) Players are labeled by i ∈ Z + , where players 1 . . M enter at t = 0 . In each period , current players are matched at random ( uniformly ) to play a prisoner’s dilemma 9 with payoﬀs : C D C 1 , 1 − 1 , 2 D 2 , − 1 0 , 0 At the beginning of each period , active players may have the choice of continuing to play under their current identiﬁers or getting new ones . ( When obtaining a new identiﬁer is possible , it is costless ; we discuss entry fees in Section 4 . ) When players are paired , each is told only the identiﬁer currently being used by the other . Thus , a player who acquires a new identiﬁer is indistinguishable ( to all the other players ) from a new entrant to the system . We assume that the system keeps a public history of which identiﬁers were paired in 9 While some of the real - world interactions we discuss , such as health support forums , are not pure prisoner’s dilemmas , they do contain opportunities for either selﬁsh behavior that hurts others or for more cooperative , mutually beneﬁcal behavior . The prisoner’s dilemma is a useful model because it places the incentives for choosing between these behaviors in stark relief . 7 previous periods and the actions taken by the players controlling those identiﬁers . 10 Thus , when two players meet , each can see the opponent’s complete history , which includes not only the actions played by the opponent , but also those by the opponent’s opponents , ad inﬁnitum . To model this simply , we assume that in period t the entire history of play , h ts ∈ H ts , is common knowledge , where h ts is the pairing of identiﬁers and the actions taken in time periods prior to t . 11 Each player also knows her own personal history of name changes , h ti ∈ H ti , where h ti is the history of identiﬁers used by player i in periods prior to t . We will also assume that there is an exogenous signal q , which is uniformly distributed on [ 0 , 1 ] . This signal is revealed at the beginning of period t before players choose their actions . 12 Player i ’s strategy in period t is a mapping s t i : H t s × H t i × H t E → ∆ ( { C , D } ) , where H tE is the history of exogenous signals up to and including q t . Let S be the set of all such ( mixed behavioral ) strategies . A player’s payoﬀ for a strategy s i is given by the total ( undiscounted ) expected payoﬀ . For example , if player i enters in period b ( i ) then her payoﬀ from strategy vector s , which includes her own strategy and strategies for each of the other players , is given by u i ( s ) = (cid:80) b ( i ) + l ( i ) t = b ( i ) u ti where u ti is her payoﬀ in period t and l ( i ) is the “age” of player i when she exits the system . 13 Note that the expected lifetime of a player is 1 / α so we deﬁne the normalized ( per - period ) 10 In our scenario , it is not possible to have explicit norms of behavior that are centrally enforced . It may be fairly easy , however , to publish the history , and leave the enforcement up to the actual players . In practice , this history is captured either by monitoring play , such as on the Internet Go Server ( igs . nuri . net ) , or by gathering explicit feedback from participants about each other , as on the Internet Auction site eBay ( www . ebay . com ) . Wherever possible , explicit and centrally enforceable rules of behavior should be applied , and then one can interpret our analysis as modeling the part of the interaction for which such rules are not centrally enforceable . 11 This assumption is made to simplify notation ; the equilibrium strategies that we are interested in will use far less information . Also , this assumption allows us to disentangle the eﬀects caused by name changes from those generated by imperfect transfer of information about the history of play . The question of the reliability of player reported information is quite complex and beyond the scope of this paper . For example , eBay founder Pierre Omidyar exhorted users to give negative feedback when it was warranted ( Omidyar , 1998 ) , apparently because users hesitated to give negative feedback in fear that it would be reciprocated . 12 Once we introduce trembles ( Section 3 ) there will be no need for exogenous signals , as players would be able to correlate on the history of trembles . Nonetheless , we will maintain the exogenous signals to simplify the presentation . 13 In our model , players do not know in advance when they will exit . Endogenous exit creates problems of defection prior to exit . Tadelis ( 2000 ) analyzes a model in which the possibility of privately selling one’s name upon exit maintains incentives for cooperation prior to exit . 8 payoﬀ to be αE [ u i ( s ) ] . 14 We will consider only sequential equilibria , for which we use the standard deﬁnition ( e . g . , Fudenberg and Tirole ( 1991 ) ) . Our benchmark for the amount of cooperation will be the average among all the players of the expected per - period payoﬀ , V ( s ) = lim inf N →∞ (cid:80) Ni = 0 αE [ u i ( s ) ] N Thus , if every player cooperates in every period then V = 1 while if every player defects in every period then V = 0 . 2 . 1 Fixed identiﬁers If players are unable to change their identiﬁers ( eg . , if they must reveal their real - world names ) , the public history makes total cooperation a sustainable equilibrium . For example , suppose every player adopts the following localized punishment strategy ( LPS ) . LPS calls for a player to play C against a newcomer or against a veteran who complied with LPS in the previous period , and D against a veteran who deviated in the previous period . For α ≤ 1 / 2 , V ( LP S ) = 1 when identiﬁers are ﬁxed . 2 . 2 Free identiﬁer changes If players can change their identiﬁers freely , LPS is no longer an equilibrium , because a player can defect , then acquire a new identiﬁer and be treated as a newcomer , against whom other players cooperate . Another strategy , however , does lead to total cooperation in equilibrium . That strategy , the “public grim trigger strategy” ( PGTS – a generalized punishment strategy ) , has every player defect if there has ever been a defection in an earlier period , and otherwise cooperate . As long as α ≤ 1 / 2 , cooperation is the best strategy while everyone else is cooperating and defection is the best strategy if a defection triggers everyone else to start defecting . Thus , PGTS is a sequential equilibrium . For α ≤ 1 / 2 , V ( P GT S ) = 1 . 14 Note also that 1 − α plays a role analogous to a discount factor , although this model does not include an explicit discount factor . 9 Intuitively , however PGTS seems fragile and unrealistic . We now introduce a new element into the model that highlights the fragility of PGTS . 3 Malicious Players and Trembles Suppose there are a few malicious players who like to see others suﬀer and thus will choose actions that cause a general increase in the level of defection . Malicious players make up a small but non - zero fraction of the population , (cid:143) . Alternatively , consider the problem of occasional mistakes by well - meaning players . These may occur from errors of judgment , unstable network connections ( a player who is faring badly in a backgammon game may quit the game because of a lost network connection , which could appear to the opponent as poor sportsmanship ) or simply because a person mistakenly hits the wrong key on a keyboard . Let (cid:143) be the probability that when a player attempts to choose an action , that she trembles and plays the other action . In the presence of trembles , a strategy deﬁnes the deliberate choices that players make , conditioned on the observed actions of others . Trembles are randomly determined after their deliberate choices , so that a player who deliberately chooses D will actually play C with probability (cid:143) , and vice - versa . 15 In our model , we need some exogenous variability in the number of new identiﬁers each period , to eliminate unrealistic strategies that trigger based on the number of new identiﬁers . The variability could come from variation in the number of players leaving the game . Instead , we assume that at the end of each period each player ‘loses’ his identiﬁer by accident with probability (cid:143) and must start again as an entrant with a new identiﬁer . There is no reason why the probability of losing one’s identiﬁer should be equal to that of trembling ; we simply assume this to reduce notation . The eﬀects of malicious players are similar to those for trembles , since each introduces a few defections that are not chosen by normal players . In the remainder of this paper we focus 15 Note that when there are ﬁnite trembles , this game is essentially a repeated game with imperfect public information ( Green and Porter 1984 , Abreu , Pearce , and Stachetti , 1990 ) , i . e . , players cannot always tell whether defections were deliberate or caused by trembles . 10 on the model with trembles . The analysis for the game with malicious players is analogous . 16 We will be interested in the social welfare for ﬁxed (cid:143) and large populations . Let V ∗ ( (cid:143) , M ) be the supremum of V ( s ) over all sequential equilibria , with population M in each period and the probability of a tremble (cid:143) and probability of a lost identiﬁer (cid:143) . Deﬁne the “stable value” of the game to be SV = lim (cid:143) → 0 lim M →∞ V ∗ ( (cid:143) , M ) . Thus , the stable value is the maximal expected per - period social welfare when the population is large in relation to the error rate . 17 To simplify presentation and analysis , we will rely on order notation . Thus , the statement g ( (cid:143) ) = O ( f ( (cid:143) ) ) implies that there exists some c > 0 such that for (cid:143) suﬃciently small , | g ( (cid:143) ) | ≤ cf ( (cid:143) ) . Similarly , for M , where we are interested in large values , g ( M ) = O ( f ( M ) ) implies that there exists some c > 0 such that for M suﬃciently large , | g ( M ) | ≤ cf ( M ) . 3 . 1 Fixed Identiﬁers First , consider the case in which players can not change their identiﬁers . The LPS strategy , where players defect against players who deviated in the previous period , is an equilibrium , with no deliberate defection . Proposition 1 For all α < . 3 , M > 1 and (cid:143) < . 1 , LPS is an equilibrium with V ( s ) = 1 − O ( (cid:143) ) . More precisely , V ( s ) ≥ 1 − 2 (cid:143) . 16 That a small probability of trembles or malicious players can have important eﬀects is well known . For example , the evolutionary behavior of the prisoner’s dilemma is very diﬀerent with trembles than without ( Nowak and Sigmund , 1993 ) while the eﬀect of a few “atypical players” can have dramatic eﬀects on the set of equilibria ( Kreps et . al . , 1982 ) . 17 Note that the stable value diﬀers from some analyses of games with trembles in which the order of the limits is reversed . For example , with the order reversed , Ellison’s ( 1994 ) analysis shows that the prisoner’s dilemma with anonymous random matching attains lim M →∞ lim (cid:143) → 0 V ( (cid:143) , M ) = 1 using randomized versions of contagion strategies , while Friedman ( 1997 ) has shown that the stable value for that game is 0 . The SV order of limits is more appropriate for our analysis , where we expect a large enough population so that at least one error per period is expected . The reversed order would eﬀectively take a limit where the number of errors , M(cid:143) , approaches 0 . 11 Thus , we get the standard result of full cooperation ( except for trembles ) analogous to that for a prisoner’s dilemma of iterated play with the same partner . Corollary 1 For the game with persistent identities SV = 1 . 3 . 2 Free Identiﬁer Changes When players can freely change identiﬁers , malicious players or trembles ruin the PGTS equilibrium . A single tremble or malicious player causes mass defection in future periods . For any (cid:143) > 0 , PGTS has an expected average per - period payoﬀ of 0 ; V ( P GT S ) = 0 . As discussed by Ellison ( 1994 ) , PGTS can be replaced by a “public forgiving trigger strategy” ( PFTS ) that works for ( very ) small (cid:143) > 0 . In PFTS a player cooperates until the ﬁrst time someone defects . Then she chooses D for a ﬁnite number of periods ( the punishment phase ) after which she goes back to cooperating . For ﬁxed (cid:143) , however , as M gets large , there will be a tremble in almost every period and this will not be an equilibrium . 18 The point of the punishment phase is to deter non - malicious players from defecting . An alternative way to do that is through a “paying your dues” strategy ( PYD ) , which makes it much less attractive to have a new identiﬁer than one that has a history of cooperative action . Essentially , it rewards positive reputations rather than punishing negative reputa - tions . Under PYD , when an entrant meets a compliant veteran ( non - entrant ) the entrant chooses C and the veteran chooses D . Thus , ‘dues’ are transferred from the entrant to the veteran , although at a cost to overall eﬃciency . The dues act as an endogenous entry fee , discouraging a veteran from deviating since he must then change his name , behave as an entrant and pay more dues . While our prisoner’s dilemma model suggests that dues be paid in the form of “defection” against cooperative newcomers in a simultaneous game , in practice newcomers’ dues may take several forms . In fraternity initiation , newcomers perform work or accept humiliation . At eBay , new buyers may have to accept shipping delays ( for example , a seller may wait for 18 Even if trembles are very rare , an environment where PFTS operates may attract a malicious player , since such a player can create a large disruption . Thus in ( the perhaps more realistic ) case when the number of malicious players is endogenous our discussion is also valid . 12 a newcomer’s check to clear before sending goods , but send goods immediately to veteran buyers ) and new sellers may have to accept lower prices for their goods . 19 Kollock ( 1998 ) reports that newcomers accept more transaction risks in the on - line environment for trading playing cards for the game Magic . After people who have never met each other agree to exchange cards ( or sell cards for money ) , the person without an established reputation has to send his card ﬁrst ; the veteran should reciprocate after receiving the newcomer’s card , but the newcomer accepts the risk that this might not happen . Formally , the PYD strategies are as follows . Identiﬁers are divided into two types , en - trants ( those that have no history of previous actions ) , and veterans . Identiﬁers are said to be “in compliance” if all their past actions conform to the PYD strategy ( entrants are triv - ially in compliance ) . Note that an identiﬁer can remain in compliance even after defecting , so long as the defection was called for in the PYD strategy . A player always cooperates if both she and her opponent are the same type and “in compliance” . If a compliant veteran meets an entrant then the entrant chooses C and , if q < ˆ q ( α , (cid:143) , M ) , the veteran chooses D ( otherwise C ) where ˆ q ( α , (cid:143) , M ) = 1 − 1 / M ( 1 − α ) ( 2 − α − 2 / M − (cid:143) + (cid:143) / M + (cid:143) α ) ( 1 − 2 (cid:143) ) ( Note that to improve eﬃciency we only require dues to be paid part of the time . This is the reason for introducing the exogenous signal q . ) If either player is not in compliance , then both players choose D . Finally , the strategy calls for a player whose identiﬁer is not in compliance to take on a new identiﬁer and begin again as an entrant . The function ˆ q ( α , (cid:143) , M ) is precisely the minimal punishment probability to prevent a player from deliberately deviating and then returning as an entrant in the following period . In the absence of trembles , for M going to inﬁnity , this equilibrium has expected payoﬀ per player of 1 α − 1 2 − α . Some of a player’s ﬁrst - period dues may be recovered in later periods if the player is allowed to defect against a newcomer , but there is a net loss of between . 5 and 1 19 In a somewhat diﬀerent scenario , Carl Shapiro ( 1983 ) suggests below - cost pricing as a way of investing in a reputation and Benjamin Klein and Keith Leﬄer ( 1981 ) suggest that newcomers could make other ﬁrm - speciﬁc capital investments such as purchasing advertising . 13 utils per player . As the following proposition shows , for small (cid:143) , PYD is still an equilibrium with approximately the same payoﬀs . Proposition 2 For α < . 3 , (cid:143) < . 1 and M > 11 , and ˆ q ( α , (cid:143) , M ) ≤ 1 , PYD is an equilibrium of the game with impersistent identities , where V ( s ) = 1 − α 2 − α − O ( (cid:143) ) − O ( 1 / M ) . From this we get a lower bound for the stable value , resulting from the dues paid by newcomers ( essentially , the α 2 − α term ) . As epsilon go to zero in computing the stable value limit , the losses by veterans who tremble goes to 0 . ( Note that the condition ˆ q ( α , (cid:143) , M ) ≤ 1 is automatically satisﬁed when α < . 24 or (cid:143) < . 05 . ) Corollary 2 For the game with impersistent identities SV ≥ 1 − α 2 − α . Note that for small (cid:143) , the PYD equilibrium implies an average loss in ( unnormalized ) payoﬀs to each player of ( 2 − α ) − 1 , which is approximately 1 / 2 for α close to zero . Although compliant veterans never deliberately deviate from the PYD equilibrium , the equilibrium includes defections . There is dues paying by newcomers and by veterans who trembled in the previous period , leading to some ineﬃciency . It is logical that trembling players be punished , else other players will misbehave and claim to have trembled . It seems wasteful , however , to punish the true newcomers , who have done nothing wrong . If , somehow , the trembling players were usually punished but the true newcomers usually were not , such an outcome would have value V ( s ) = 1 − O ( (cid:143) ) and a stable value of 1 even though previous period deviants cannot be distinguished from this period’s true newcomers . It is , in fact , possible , to do somewhat better than the PYD equilibrium . For example , consider a variant that omits the dues for newcomers in any period following one where there are no deviations . This strategy yields an equilibrium , but for ﬁxed (cid:143) , as M gets large there will almost always be at least one deviation , so the improvement over PYD is only O ( e − (cid:143)M ) . More generally , there may be ways to condition the payoﬀs for newcomers in the next period on the collective behavior of veterans in the previous period ( more dues next period if more deviation this period ) . This increases the fraction of the total dues paid by tremblers 14 ( as opposed to true newcomers ) . Our next proposition , however , shows that no equilibrium yields signiﬁcantly higher payoﬀs than PYD . Thus , while there can be improvements over the PYD equilibrium , the improvements are slight and the bound for the stable value given in Corollary 2 is tight . The key ideas in the proof are : 1 ) Although an equilibrium can have unusual behavior for special periods or special players , on average , veterans must receive expected payoﬀs that are suﬃciently larger than the en - trants’ payoﬀs to prevent someone from defecting and then returning in the following period as a new entrant . ( See lemma 2 in the proof ) . 2 ) The “most eﬃcient” ( i . e . , with the fewest defections ) way to create a diﬀerential between the value of being a veteran rather than an entrant is by having a veteran defect against an entrant , since this “transfers” utility from the entrants to the veterans . ( See lemma 5 in the proof ) . Proposition 3 Fix α < . 3 . There exists some β > 0 such that for any v > 1 − α 2 − α there exists an (cid:143) such that for all (cid:143) < (cid:143) and M > β / (cid:143) there is no equilibrium , s ∗ , of the game with impersistent identities with V ( s ∗ ) ≥ v . Thus , the stable value is precisely what was obtained from the PYD equilibrium . Corollary 3 For the game with impersistent identities SV = 1 − α 2 − α . This shows that there is no fully eﬃcient “stable” equilibrium when identities are not persistent and PYD has the highest payoﬀs ( to within O ( (cid:143) ) + O ( 1 / M ) ) of any equilibrium strategy . One further implication of the two ideas behind the proof is that any equilibrium with approximately as much cooperation as PYD must have almost all its defections be by veterans against entrants . Thus , although the PYD equilbrium is not unique , all other equilibria that achieve near maximum eﬃciency must operate in the same spirit that PYD does , with veterans defecting against entrants . In particular , slow - start schemes where new - comers initially play low stakes games until they build reputations would be less eﬃcient than schemes that transfer utility from newcomers to veterans . 15 4 Payments for Identiﬁers The simplest method to attain full eﬃciency in the game with impersistent identities and either malicious players or trembles is to make dues paying explicit , such as with the im - position of an entry fee . 20 It is easy to see that if such a fee is chosen appropriately then players will have a suﬃcient incentive not to defect from the equilibrium and begin again with a new identiﬁer , as they would then incur a new entry fee . Suppose that the entry fees collected in period t + 1 are distributed evenly among all the players who participated in period t . Since such a fee is purely a transfer it does not impact eﬃciency . If each player uses , in expectation , the same number of identiﬁers , then each player will , in expectation , collect back exactly the amount of her entry fee . Players who change identiﬁers deliberately would increase the amount that other players collect in distributions . Thus , if an equilibrium strategy calls for a player not to change identiﬁers deliberately , the entry fee would not impact that player’s willingness to participate . While attractive , this scheme suﬀers from two problems . First , the redistribution pay - ments may introduce incentives for players to stay in the game beyond the time when their natural interest or life circumstances change . Thus , redistribution of entry fees would invali - date our modeling of the exit process as exogenous . Even without this problem , this solution does not work if players’ expected lifetimes are heterogeneous . For example , some players may know that they have a short attention span and thus don’t expect to be in the system long enough to recoup their entry fee . These problems can be eliminated if entry fees are not redistributed to the players ( per - haps they are given to charity , or kept as proﬁt by an entity running the environment ) . If , however , player payoﬀs are heterogeneous , such fees will introduce ineﬃciency : some players will choose not to participate . To make this argument explicitly , consider a variation of the game with impersistent 20 An alternative is to require posting of a bond for each new identiﬁer , to be forfeited if some central authority determines that the player has deviated from acceptable behavior . The advantage of straight entry fees over bonds is that no central authority is needed , which is important on the internet where there is often strong distrust of such authorities . 16 identities in which players’ varying wealth causes them to value money diﬀerently , as modeled by a parameter λ ∈ ( 0 , 1 ] . The expected payoﬀ for a player with intensity λ is V ( s ) α − λF , where F is the entry fee . Our point is easily made when α = . 1 , and players’ intensities are i . i . d . with λ = 1 ( the poor players ) with probability p and λ = 0 . 01 ( the wealthy players ) with probability 1 − p . It is clear that in this case , the entry fee must be suﬃciently large to prevent the wealthy players from deviating , but this will deter the other players from entering , thereby leading to eﬃciency losses . More generally , the optimal entry fee will often exclude some players yet still be insuﬃcient to deter the wealthiest players from defecting . A similar problem occurs if players have heterogeneous payoﬀs in the game rather than heterogeneous value for money ; in that case , the optimal dues for a PYD equilibrium would also exclude some players from the game yet be insuﬃcient to deter some others from defecting regularly . The problem of large ﬁxed costs deterring some entrants is well known in the economics literature , but standard solutions such as price discrimination or two - part tariﬀs are not applicable here . 5 Identiﬁer Commitments We now describe an implementable system which achieves full eﬃciency even in the presence of heterogeneous payoﬀs , by allowing players to credibly commit not to change identiﬁers , still without revealing their true identities . As a starting point , suppose that there were an intermediary , trusted by all players . 21 The intermediary assigns identiﬁers to players when they request them , but promises never to reveal which players received which identiﬁers . Suppose that the intermediary also oﬀers a special class of identiﬁers , which we call once - in - a - lifetime identiﬁers but for each social arena will issue at most one such identiﬁer to each player . A player with a once - in - a - lifetime identiﬁer is not prevented from returning with a regular identiﬁer , although regular identiﬁers may be viewed with suspicion by other players . Any equilibrium strategy vector for the game where identiﬁers are ﬁxed can be extended 21 Other forms of intermediary have already emerged to reduce risk in ecommerce . For example , auction sites oﬀer insurance and links to escrow services , but insurance introduces ineﬃciency from moral hazard and escrow services introduce signiﬁcant transaction costs . 17 to a strategy vector for the game where players have the option of using once - in - a - lifetime identiﬁers . Players choose D against regular identiﬁers and follow the original strategy against once - in - a - lifetime identiﬁers . Since regular identiﬁers are treated so poorly , use of a once - in - a - lifetime identiﬁer eﬀectively signals a commitment to keep using that identiﬁer rather than returning anonymously . Conversely , a player who does not use a once - in - a - lifetime identiﬁer ( i . e . , does not make an identiﬁer commitment ) signals that she is not trustworthy . In equilibrium , no one uses regular identiﬁers . In particular , LPS ( defect against anyone who deviated in the previous period ) extends to an equilibrium with nearly complete cooperation ( only trembles are punished ) . Note also that even if players diﬀer in the intensity of their payoﬀs , this remains an equilibrium with full participation and full cooperation , unlike entry fees , which might exclude some players from participating . Thus we note that in this game the stable value is 1 . In this scenario , the players have to trust the intermediary not to reveal their true iden - tities , even though the intermediary knows the mapping between players and identiﬁers . We can reduce the trust requirement somewhat through a cryptographic technique known as blind signatures ( Schneier , p . 112 - 114 ) . 22 The protocol , though it would actually be imple - mented using encrypted electronic communications , is easiest to describe with an analogy to carbon paper and envelopes . Player A signs the outside of an envelope with her true signature . A then types up a letter specifying a new once - in - a - lifetime identiﬁer for herself and puts it in the envelope together with a piece of carbon paper . She sends the envelope to the intermediary , who checks A’s signature on the envelope without opening it . After checking that A has not previously requested a once - in - a - lifetime identiﬁer , the intermediary signs the outside of the envelope ; because of the carbon paper , the signature bleeds through onto the letter . The intermediary sends the unopened envelope back to A , who removes the 22 One of the strengths of the Internet is the ease with which complicated encryption and veriﬁcation mechanisms can be implemented . For example , Eudora Lite , a standard email program , is distributed free with Pretty Good Privacy , an encryption program which provides a large degree of security against eavesdroppers . It is easy to use even for the novice as the program does most of the work . Thus , it is possible for ordinary people to use sophisticated encryption programs , something that is quite diﬃcult for non - electronic transactions . 18 letter , now signed by the intermediary , and presents it to other players in the game as proof of her once - in - a - lifetime identiﬁer . The intermediary never learns what identiﬁer A is using , since it was sealed in the en - velope , although the intermediary knows that A acquired some once - in - a - lifetime identiﬁer . This protocol is still subject to a timing attack , however : the intermediary can watch to see what new once - in - a - lifetime identiﬁer is used in the game , and associate it with the last player who requested one . If players wish to avoid this , they need to acquire their identiﬁers and hold onto them for a random length of time before they use them . The envelope and carbon paper protocol described above can be implemented quite practically if identiﬁers correspond to private - public encryption key pairs . Encryption keys are just long strings of bits ; the private portion of the key pair is known only to the key’s owner , while the public key is available to everyone . A private key is used to “sign” a string of bits by computing a function of the bits and the private key . The function works such that anyone with the corresponding public key can verify that the private key was used to make the signature , but no one can forge a signature by computing the function’s output without knowing the private key . 23 Each player is assumed to start with a private key associated with her true identity . 24 To establish a once - in - a - lifetime identiﬁer for some arena , player A ﬁrst constructs a brand new key pair ( a new pseudonym ) . A sends the public half of the new pair to the intermediary , but blinds it by multiplying by a randomly chosen number ( the equivalent of sealing it in an envelope with carbon paper ) . The player uses the private key for her true identity to sign the request , so that the intermediary can verify that it came from A ( only someone knowing A’s private key could have generated the signature ) . If the intermediary has never previously certiﬁed a pseudonym for A , the intermediary uses its own private key to sign the new blinded 23 Private - public encryption and signature handling software is already built into the major Web browsers and is routinely used for establishing private communication ( URLs that begin https : / / usually cause this feature to be invoked ) and for assessing the safety of downloaded code . 24 There are some practical diﬃculties to be surmounted in setting up an infrastructure for establishing key pairs for individuals and publicizing the public portion . A few companies , most notably Verisign , have established a foothold in this business , and there is also speculation that governments may provide such services . 19 public key that A provided . A receives the blinded signed key and is able to remove the blinding factor ( the equivalent of opening the envelope ) , leaving a certiﬁcate , signed by the intermediary , that attests that the new public key is valid as a once - in - a - lifetime identiﬁer . The intermediary knows that A has acquired a once - in - a - lifetime identiﬁer , but does not know which one . Subsequently , player A can participate in the game without revealing her true identity . She presents the certiﬁcate and signs communications with the pseudonym’s private key ( not the private key associated with her true identity ) . Other players can verify that the certiﬁ - cate is authentic , using the intermediary’s public key to verify the intermediary’s signature . They can verify that the communications are signed by whoever owns the once - in - a - lifetime identiﬁer , using the identiﬁer’s public key . But no one , not even the intermediary , can tell that the identiﬁer belongs to A . Note that while this procedure involves sending long strings of bits , the transmission re - quirements are extremely modest compared to even a simple web page . The computational burden of generating and verifying digital signatures is not trivial but comparable crypto - graphic operations are performed routinely by both clients and servers on the Internet today . The burden on people is also minimal , as little as a single keystroke or mouseclick to tell the computer to send the once - in - a - lifetime identiﬁer . There can be diﬀerent intermediaries for diﬀerent social arenas , or a single intermediary can handle several arenas simultaneously , enforcing a restriction of one once - in - a - lifetime identiﬁer per arena . For game servers or support groups , this process will prevent players returning over and over again with new pseudonyms , while protecting their true identities . There is still a danger that a person can acquire several once - in - a - lifetime identiﬁers for a single arena , if she uses several people’s true identiﬁers to acquire the certiﬁcates . If a robust cryptography infrastructure develops , however , most people will be very reluctant to allow another to use their true identiﬁers . In any case , the need to use a true identiﬁer to acquire a once - in - a - lifetime identiﬁer will impose almost no cost on individuals who wish to acquire just one , but will impose a signiﬁcant cost on those who try to acquire several . 20 How should the intermediary for an arena be selected ? One possibility would be for the oﬃcial intermediary to be allocated according to some public auction . Once chosen , the intermediary will be a monopolist ( we cannot have competition unless the competitors share information about which players have already been issued committed identiﬁers ) . The initial auction , however , can compete away ( most of ) the monopolists’ rents , at least for those services that can be speciﬁed by contract . Thus , for example , the winner of the auction may have to agree to provide identiﬁers for a ﬁxed fee , and within a speciﬁed turnaround time , or else lose its franchise . The intermediary may also be required to submit to regular audits , to make sure that it issues only one once - in - a - lifetime identiﬁer per player . 25 Note that there is still a tradeoﬀ between anonymity and accountability in the choice of how broad a set of activities to deﬁne as a single arena . Should the arena in which a person commits to a single identiﬁer consist of eBay’s Beanie Baby auctions , all eBay auctions , or all auctions at any on - line service ? A broader arena increases accountability , both because there will be more historical data available to assess any individual’s reputation , and because a bad reputation follows an individual to more places . However , the broader the arena , the more opportunities there are for correlating behavior between activities that an individual would like to keep separate . For example , a partici - pant in an alcoholics anonymous support group may not want comments there linked with comments he makes in other arenas and a seller of sex toys may not want to use the same pseudonym for sales of children’s toys . In the most extreme case , there would be just one arena for all of the the Internet and hence just one Internet identiﬁer per person . We would expect more narrowly deﬁned arenas , however , in those sensitive areas where people care more about anonymity . 25 Auctioning monopoly rights can be problematic , especially when there is uncertainty about demand or cost of provision , lock - in to one provider over time , or diﬃculty in monitoring , as noted by Williamson ( 1976 ) . However , the marginal costs of providing 1L pseudonyms are suﬃciently small and the service is so clearcut ( and easily contracted on ) that auctioning monopoly rights might be expected to work reasonably well in practice . 21 6 Concluding Remarks Even in the physical world , name changes have always been possible as a way to erase one’s reputation . The Internet highlights the issue , by making name changes almost cost - free . This creates a situation where positive reputations are valuable , but negative reputations do not stick . It is natural to ask how much cooperation can be sustained relying only on positive reputations . The answer is , “quite a lot” , but not complete cooperation . A natural convention is to distrust or even mistreat strangers until they establish positive reputations . Suspicion of strangers is costly to society . It is especially costly on the Internet , since the great potential of the medium is to allow people to expand their horizons , to sample a variety of interest groups and to trade with people they have never met . It would be nice to create environments where strangers were trusted until proven otherwise . Unfortunately , obvious strategy vectors involving cooperation with strangers are not stable , and we proved that no strategy vector can do substantially better than punishing all newcomers . Thus , there is an inherent social cost to free name changes . We can mitigate this cost by charging for name changes , but this also requires charging for names in the ﬁrst place . That may exclude poor people or those who are just exploring and not yet sure whether the payoﬀs from participation would justify the entry fee . A better solution is to give people the option of committing not to change identiﬁers . We described cryptographic mechanisms that enable credible commitment to a single pseudonym within some arena , without revealing one’s true identity . We expect both techniques for limiting name changes , entry fees and pseudonym commitments , to blossom in Internet arenas . A Proofs of Propositions A . 1 Proposition 1 For all α < . 3 , M > 1 and (cid:143) < . 1 , LPS is an equilibrium with V ( s ) = 1 − O ( (cid:143) ) . More precisely , V ( s ) ≥ 1 − 2 (cid:143) . The proof of Proposition 1 is similar to standard equilibrium proofs with some compli - 22 cations due to the existence of ﬁnite tremble probabilities . First , consider a single deviation from the asserted equilibrium . The only possibly prof - itable deviation is to try to defect when LPS calls for cooperation . When the defection is carried out , the gain is 1 as compared to cooperation ( for either action by the opponent ) but the player’s opponent will try to defect in the next period . This increases by 1 − 2 (cid:143) ( due to trembles ) the probability of the opponent actually defecting in the next period , which would impose a penalty of 2 ( for either action by the player ) . Thus , a decision to deviate will be proﬁtable only if 1 > 2 ( 1 − α ) ( 1 − 2 (cid:143) ) . But for the given parameters , this is never true : 2 ( 1 − α ) ( 1 − 2 (cid:143) ) > 2 ( 1 − . 3 ) ( 1 − . 2 ) = 1 . 12 > 1 . Thus , LPS is an equilibrium . Next , we compute the per - period average payoﬀ for each player . In any period , some players may have deviated ( unintentionally ) from LPS . When 2 non - deviators meet , they ( attempt to ) cooperate and each has an expected payoﬀ of ( 1 − (cid:143) ) 2 ( 1 ) + (cid:143) ( 1 − (cid:143) ) ( 2 ) + (cid:143) ( 1 − (cid:143) ) ( − 1 ) + (cid:143) 2 ( 0 ) = 1 − (cid:143) . When 2 deviators meet they ( attempt to ) defect the expected payoﬀ is ( 1 − (cid:143) ) 2 ( 0 ) + (cid:143) ( 1 − (cid:143) ) ( − 1 ) + (cid:143) ( 1 − (cid:143) ) ( 2 ) + (cid:143) 2 ( 1 ) = (cid:143) . Similarly , a deviator meeting a non - deviator gets − 1 + 3 (cid:143) and the opposite yields 2 − 3 (cid:143) . If there were k deviations in the previous period , the average payoﬀ per player in the current period will be : ( k / M ) 2 (cid:143) + ( 1 − k / M ) ( k / M ) ( − 1 + 3 (cid:143) ) + ( 1 − k / M ) ( k / M ) ( 2 − 3 (cid:143) ) + ( 1 − k / M ) 2 ( 1 − (cid:143) ) . Using the fact that E [ k / M ] = (cid:143) in equilibrium , this is 1 − 2 (cid:143) + 2 (cid:143) 2 , which is larger than 1 − 2 (cid:143) . A . 2 Proposition 2 For α < . 3 , (cid:143) < . 1 and M > 11 , and ˆ q ( α , (cid:143) , M ) ≤ 1 , PYD is an equilibrium of the game with impersistent identities , where V ( s ) = 1 − α 2 − α − O ( (cid:143) ) − O ( 1 / M ) . As in the previous proof , the gain for defecting when the equilibrium strategy calls for cooperating is 1 , while the loss arises because the expected payoﬀ in the next period is reduced , since the player must return as an entrant . This loss only occurs when q t + 1 ≤ ˆ q . If the player is matched with a veteran , then the loss is due to the veteran choosing defect 23 ( which leads to a loss of 2 utils when it happens ) with probability 1 − (cid:143) instead of probability (cid:143) . If the player is matched with an entrant then the loss is due to the player not defecting ( which loses 1 util when it happens ) with probability 1 − (cid:143) instead of (cid:143) . The probability of being matched with an entrant in the next period is the same whether the player deviates or not , and can be calculated from the expected number of trembles this period and the expected number of true newcomers in the next period , p e = ( Mα + ( M ( 1 − α ) − 1 ) (cid:143) ) / ( M − 1 ) . The expected loss , then , from a defection when the strategy calls for cooperation , is ( 1 − α ) ( 1 − 2 (cid:143) ) ˆ q ( p e + 2 ( 1 − p e ) ) . Thus , players will not try to deviate , which increases the probability of actually deviating , if 1 ≤ ( 1 − α ) ( 1 − 2 (cid:143) ) ˆ q ( p e + 2 ( 1 − p e ) ) , which is satisﬁed with equality for the value of ˆ q in the proposition . To compute the expected payoﬀ for this equilibrium , we note that by stationarity and anonymity of PYD we need only compute the average payoﬀ for a period . To do this we note that the total payoﬀ in a period is M − ˆ M where ˆ M is the number of defections in that period , since every defection costs 1 util in total payoﬀs . Thus V = 1 − p D where p D is the probability that a randomly chosen player will defect . The only type of player who attempts to defect in equilibrium is a veteran who is matched with an entrant in a period in which q t ≤ ˆ q . Let p be the probability that a veteran is matched with an entrant . Then p D = ( 1 − (cid:143) ) ˆ qp + (cid:143) ( 1 − p ) ) . Since in any period there are ( on average ) Mα + M ( 1 − α ) (cid:143) entrants , p = α ( 1 − α ) + O ( (cid:143) + 1 / M ) . Since ˆ q = ( ( 1 − α ) ( 2 − α ) ) − 1 + O ( (cid:143) + 1 / M ) this implies that p D = α 2 − α + O ( (cid:143) + 1 / M ) and thus V = 1 − p D = 1 − α 2 − α − O ( (cid:143) + 1 / M ) proving the proposition . (cid:50) A . 3 Proposition 3 Fix α < . 3 . There exists some β > 0 such that for any v > 1 − α 2 − α there exists an (cid:143) such that for all (cid:143) < (cid:143) and M > β / (cid:143) there is no equilibrium , s ∗ , of the game with impersistent 24 identities with V ( s ∗ ) ≥ v . We will show that no strategy vector with average expected payoﬀs greater than 1 / α − 1 / ( 2 − α ) can provide suﬃcient incentives to prevent entrants from defecting . An equilib - rium can include unusual behavior in selected periods or by selected players . We establish , however , a minimal diﬀerence , on average , between the payoﬀs of newcomers and veterans . If this minimum is not met , then there will be at least one player ( at least one newcomer , in fact ) who in some period would deviate from the strategy . This is suﬃcient to infer a minimal number of defections in any equilibrium strategy . First note that for any equilibrium , there is a payoﬀ equivalent equilibrium in which no player ever intentionally gets a new identity . Let s be a set of strategies . Deﬁne s (cid:48) to be the set of strategies which are identical with s except for the following . 1 ) If s tells a player to intentionally get a new identity , then s (cid:48) has the player maintain her current identity . 2 ) In s (cid:48) when playing against a player who would have gotten a new identity in s treat them as if they were an entrant in the most recent period when they should have gotten a new identity . Clearly , such a change will not aﬀect any player’s payoﬀs or incentives and thus s (cid:48) is still an equilibrium and is payoﬀ equivalent ( along every sample path ) to s . Thus , if there is an equilibrium strategy with payoﬀs greater than our bound , there is also one that involves no deliberate name changes ( except after name trembles ) . Without loss of generality , we assume for the remainder of the proof that strategies involve no deliberate name changes . Deﬁne V i to be the expected per - period payoﬀ to player i conditional on the history of play before she enters , ( note that we are suppressing the explicit notation for histories , for ease of presentation ) . Note that V i will be the same for all new identiﬁers in the period that i begins . Thus we will abuse the notation slightly by writing V t for the expected per - period payoﬀ to any newcomer in period t , or V b ( i ) for the expected per - period payoﬀ to any newcomer in i ’s ﬁrst period . Deﬁne W i as the expected per - period payoﬀ for player i starting in the second period of participation ( b ( i ) + 1 ) , conditional on the fact that the player actually conformed to the strategy in the previous period , conditional on not exiting after the ﬁrst period , and conditional on all information available at the time of their action choice 25 in the period in which they enter . Deﬁne V (cid:48) i as the expected per - period payoﬀ to player i starting in the second period of participation , conditional on player i actually deviating and not exiting . First we note that V b ( i ) + 1 is a good approximation for V (cid:48) i for ‘most’ players . Lemma 1 For all ψ , φ > 0 there exists some β > 0 such that for all M > β / (cid:143) the following holds : Given any t > 0 let Z be the set of entrants in period t − 1 ; then the set Z (cid:48) = { i ∈ Z | V (cid:48) i − V t > ψ } satisﬁes | Z (cid:48) | < φ | Z | . 26 We will refer to Z (cid:48) as the “trigger” players , the ones whose deviations trigger big changes in the payoﬀs in the next period . The proof is by contradiction . Suppose there exists ψ , φ > 0 such that for any β > 0 there is a strategy vector s , with M > β / (cid:143) , such that | Z (cid:48) | ≥ φ | Z | . Let x ∈ { 0 , 1 } Z where x i = 0 if player i ∈ Z deviates in period t − 1 and 0 otherwise . Let V ( x ) be the expected value of V t under s if x is the actual pattern of deviations by entrants in period t − 1 . Let Σ be the set of all permutations of Z which respect Z (cid:48) , i . e . , σ ∈ Σ is a mapping Z → Z such that σ ( Z (cid:48) ) = Z (cid:48) . With a slight abuse of notation let σ ( x ) be the permutation of the vector x by σ , e . g . , σ ( x ) σ ( i ) = x i . Now consider a new function ˆ V ( · ) which is deﬁned as follows , ˆ V ( x ) = (cid:80) σ ∈ Σ V ( σ ( x ) ) / | Σ | . Deﬁne ˆ V (cid:48) i = E [ ˆ V in period t | i deviates in period t - 1 ] and ˆ V t = E [ ˆ V in period t ] . Note that since deviations by all trigger players are equally likely that ˆ V t = V t . Moreover , if i ∈ Z \ Z (cid:48) , ˆ V (cid:48) i is the average among non - trigger players of V (cid:48) i ( again , because in equilibrium deviations by all trigger players are equally likely ) , but V (cid:48) i − V t ≤ ψ for all such players , so that ˆ V (cid:48) i − V t ≤ ψ for such players . Similarly , if i ∈ Z (cid:48) , ˆ V (cid:48) i − V t > ψ . Thus , ˆ V has the same set of trigger players as V but ˆ V ( x ) depends only on the number of deviations by each type of entrant ( trigger and non - trigger ) and not on which particular players deviate . We will now show that when there are enough trigger players , each can have only a limited impact on the distribution of the number of deviations , and hence on ˆ V , which contradicts the deﬁnition of being a trigger player . Deﬁne ˆ V k = E [ ˆ V | k deviations by trigger players ] . 26 This result closely parallels the main lemma in Fudenberg , Levine and Pesendorfer ( 1998 ) , in a diﬀerent setting . 26 Thus , V t = E [ ˆ V k ] while for a trigger player i ∈ Z (cid:48) , V (cid:48) i = E [ ˆ V k | i actually deviates ] . Let m = | Z (cid:48) | , the number of trigger players . Then the probability of k deviations by trigger players is given by the formula for a binomial distribution , P mk = m ! k ! ( m − k ) ! (cid:143) k ( 1 − (cid:143) ) m − k , while for k ≥ 1 the probability , contingent on i deviating , is P m − 1 k − 1 . This implies that ˆ V (cid:48) i − ˆ V t = − ˆ V 0 P m 0 + m (cid:88) k = 1 ˆ V k [ P m − 1 k − 1 − P mk ] . Since ˆ V k ∈ [ − 1 , 2 ] we see that 1 2 | ˆ V (cid:48) i − ˆ V t | ≤ P m 0 + m (cid:88) k = 1 | P m − 1 k − 1 − P mk | . The sum on the r . h . s . of this equation is equal to (cid:98) m(cid:143) (cid:99) (cid:88) k = 1 P mk − P m − 1 k − 1 + m (cid:88) k = (cid:98) m(cid:143) (cid:99) + 1 P m − 1 k − 1 − P mk and thus the r . h . s . of that equation is equal to the sum of | P r [ k ≤ (cid:98) m(cid:143) (cid:99) ] − | P r [ k ≤ (cid:98) m(cid:143) (cid:99) | i deviates ] and P r [ k > (cid:98) m(cid:143) (cid:99) ] − P r [ k > (cid:98) m(cid:143) (cid:99) | i deviates ] | assuming that m(cid:143) is not an integer ; but both of these terms are small since m(cid:143) is the mode of both distributions , and all the probabilities converge to 1 / 2 + O ( ( m(cid:143) ) − 1 / 2 ) by the central limit theorem ( Hoeﬀding , 1994 ) . Thus , it is easy to show that the r . h . s . of that equation is O ( ( m(cid:143) ) − 1 / 2 ) for ﬁxed α and is O ( ( M(cid:143) ) − 1 / 2 ) for ﬁxed φ , since , by assumption , m > φM . Thus for M(cid:143) suﬃcienty large this implies that ˆ V (cid:48) i − ˆ V t ≤ ψ providing the required contradiction . Intuitively , the assumption of a constant fraction of trigger players means that , as M gets large , there are a large number of trigger players . But when there are large number of them , and the payoﬀs are controlled only by the quantity who deviate ( and not which ones ) , one player’s deliberate decision to deviate can have only a minor impact on the total payoﬀs . But that contradicts what it means to be trigger player . (cid:133) Now , consider an entrant i who in equilibrium chooses C in her ﬁrst period of play . The immediate beneﬁt from a deviation is 1 while the future cost of returning the next period as an entrant is W i − V i α (cid:48) with probability ( 1 − α ) . Thus , to maintain equilibrium , we must have ( 1 − α ) α ( W i − V (cid:48) i ) > 1 . 27 For an entrant i who in equilibrium chooses D in her ﬁrst period of play , there is no immediate beneﬁt from a deviation . However , if W i − V (cid:48) i < 0 she will choose to get a new name in the following period . Thus , to maintain an equilibrium with no deliberate name changes , we must have W i − V (cid:48) i > 0 . Fix α , T > 0 and deﬁne V ( T ) to be the expected value of V i averaged over all players entering before period T , i . e . , all i such that b ( i ) < T . Note that since the same number of entrants are expected in each period , V ( T ) is also the average of V t over all t < T . Similarly let W ( T ) be the expected average over W i for all i such that b ( i ) < T . For r , s ∈ { e , v } let p rs be the empirical probability in periods 1 through T that player of type r defects against a player of type s , while p r is the empirical probability that type r defects and p is the empirical probability of any player defect . Note that since players never deliberately change names , to O ( (cid:143) + 1 / M ) , p r = αp re + ( 1 − α ) p rv and p = αp e + ( 1 − α ) p v . Lemma 2 If s is an equilibrium then ( 1 − α ) ( W − V ) / α ≥ ( 1 − p e ) − O ( ψ + φ + 1 / T + (cid:143) + 1 / M ) . Proof : On all sample paths ( 1 − α ) α ( W i − V (cid:48) i ) ≥ 1 for players who choose C in their ﬁrst period in the system and ( 1 − α ) α ( W i − V (cid:48) i ) ≥ 0 for those who choose D . Note that ( 1 − p e ) of the entrants are of the ﬁrst type and p e are of the second type . By lemma 1 , only a fraction φ are trigger players , and their payoﬀs are bounded , and of the remaining players , their V (cid:48) i values are within ψ of V b ( i ) + 1 . Finally , note that V is within a constant of the average of the V b ( i ) + 1 ( a few V 0 values are replaced by V T values ) . Taking the expectation and combining these proves the result . (cid:133) Now we will show that this can not occur for any equilibrium with payoﬀs larger than PYD . First we compute V and W . Lemma 3 V = 1 − p + O ( 1 / T + 1 / M + (cid:143) ) . Proof : This can be computed directly , but it is most easily seen by noting that every defection removes one util from the total payoﬀ to the players . (cid:133) Lemma 4 W = 1 + α ( p ve − 2 p ev ) − ( 1 − α ) p vv + O ( 1 / T + 1 / M + (cid:143) ) . 28 Proof : This follows since a defection by a veteran against another veteran costs the set of veterans 1 util , a defection of a veteran against an entrant gains 1 util , and a defection of an entrant against a veteran loses 2 utils . (cid:133) We now show that if V is large , there are not enough defections overall to keep W − V suﬃciently large . Lemma 5 If V ≥ 1 − α / ( 2 − α ) + δ then ( 1 − α ) α ( W − V ) ≤ ( 1 − p e − ( 1 − α ) α δ ) + O ( 1 / M + 1 / T + (cid:143) ) , for any δ > 0 . Proof : Let Y = ( 1 − α ) α ( W − V ) − ( 1 − p e − ( 1 − α ) α δ ) . Applying the formulas for W and V yield Y = ( 1 − α ) α [ α ( p ve − 2 p ev ) − ( 1 − α ) p vv + δ + p ] − ( 1 − p e ) + O ( 1 / M + 1 / T + (cid:143) ) . Thus , we need to show that Y max = { max Y | V ≥ 1 − α / ( 2 − α ) + δ } ≤ 0 . Since V ≥ 1 − p , Y max ≤ { max Y | p ≤ α / ( 2 − α ) − δ } ≤ { max Y + [ α / ( 2 − α ) − δ − p ] ( 1 − α ) α | p ≤ α / ( 2 − α ) − δ } . Ignoring the term O ( 1 / M + 1 / T + (cid:143) ) , we get Y max ≤ { max ( 1 − α ) α [ α ( p ve − 2 p ev ) − ( 1 − α ) p vv + δ + α / ( 2 − α ) − δ ] − ( 1 − p e ) | p ≤ α / ( 2 − α ) − δ } . It is easy to see that both p ev and p vv will be 0 at the maximum , so Y max ≤ { max ( 1 − α ) p ve − 1 / ( 2 − α ) + αp ee | α 2 p ee + α ( 1 − α ) p ve ≤ α / ( 2 − α ) − δ } . The constraint implies that Y max ≤ − 1 / ( 2 − α ) + 1 / ( 2 − α ) − δ / α = − δ / α . This is strictly negative and thus remains negative when the order terms , O ( 1 / M + 1 / T + (cid:143) ) , are included . (cid:133) Proof of Proposition : By the assumption on V and Lemma 5 we know that ( 1 − α ) α ( W − V ) ≤ ( 1 − p e − ( 1 − α ) α δ ) + O ( 1 / M + 1 / T + (cid:143) ) , but for any δ > 0 , this contradicts Lemma 2 when φ , ψ , and 1 / T are suﬃciently small . By Lemma 1 , choosing β suﬃciently large and letting T go to inﬁnity makes those values arbitrarily small and thus yields a contradiction . (cid:50) References [ 1 ] D . Abreu , D . Pearce , and E . Stachetti . Toward a theory of discounted repeated games with imperfect monitoring . Journal of Economic Theory , 58 : 1041 – 1064 , 1990 . [ 2 ] C . Avery , P . Resnick , and R . Zeckhauser . The market for evaluations . American Eco - nomic Review ) , 89 ( 3 ) , 1999 . 29 [ 3 ] P . Bajari and A . Hortacsu . Winner’s curse , reserve prices and endogenous entry : Em - pirical insights from ebay auctions . Mimeo , 2000 . [ 4 ] Y . Bakos and E . Brynjolfsson . Bundling information goods : Pricing , proﬁts and eﬃ - ciency . MIT Sloan School working paper , 1998 . [ 5 ] L . Carmichael and W . B . Macleod . Gift giving and the evolution of cooperation . Inter - national Economic Review , 38 ( 3 ) : 485 – 509 , 1996 . [ 6 ] G . Ellison . Cooperation in the prisoner’s dilemma with anonymous random matching . Review of Economic Studies , 61 : 567 – 588 , 1994 . [ 7 ] E . J . Friedman . On social norms in noisy environments . mimeo , 1999 . [ 8 ] E . J . Friedman and S . Shenker . Learning and implementation in the Internet . mimeo , available from econ . rutgers . edu / home / friedman / , 1998 . [ 9 ] D . Fudenberg , D . Levine , and W . Pesendorfer . When are nonanonymous players negli - gible ? Journal of Economic Theory , 79 ( 1 ) : 46 – 71 , 1998 . [ 10 ] D . Fudenberg and J . Tirole . Game Theory . MIT Press , Cambridge , Massachusetts , 1991 . [ 11 ] P . Ghosh and D . Ray . Cooperation in community interactions without information ﬂows . Review of Economic Studies , 63 : 491 – 519 , 1996 . [ 12 ] D . Goldschlag , M . Reed , and P . Syverson . Onion routing for anonymous and private internet connections . Communications of the ACM , 42 ( 2 ) : 39 – 41 , 1999 . [ 13 ] D . Grady . Faking pain and suﬀering on the Internet . The New York Times , 1998 . April 23 . [ 14 ] E . Green and R . Porter . Noncooperative collusion under imperfect price information . Econometrica , 52 : 87 – 100 , 1984 . 30 [ 15 ] S . Herzog , S . Shenker , and D . Estrin . Sharing the cost of multicast trees : an axiomatic analysis . Transactions on Networks , 5 ( 6 ) : 847 – 860 , 1997 . [ 16 ] W . Hoeﬀding . Probability inequalities for sums of bounded random variables . In N . Fisher and P . Sen , editors , The Collected Works of Wassily Hoeﬀding . Springer - Verlag , 1994 . [ 17 ] M . Kandori . Social norms and community enforcement . Review of Economic Studies , 59 : 63 – 80 , 1992 . [ 18 ] B . Klein and K . Leﬄer . The role of market forces in assuring contractual performance . The Journal of Political Economy , 89 ( 4 ) : 615 – 641 , 1981 . [ 19 ] R . Kling , Y . Lee , A . Teich , and M . Frankel . Assessing anonymous communication on the internet : Policy deliberations . The Information Society , 15 ( 2 ) , 1999 . [ 20 ] P . Kollock . The production of trust in online markets . To appear in : Advances in Group Processes ( Vol . 16 ) , eds E . J . Lawler , M . Macy , S . Thyne , and H . A . Walker . Greenwich , CT : JAI Press . 1999 , 1998 . [ 21 ] R . Kranton . The formation of cooperative relationships . Journal of Law , Economics and Organization , 12 ( 1 ) : 214 – 233 , 1996 . [ 22 ] D . Kreps , P . Milgrom , J . Roberts , and R . Wilson . Rational cooperation in the ﬁnitely repeated prisoner’s dilemma . Econometrica , 27 : 245 – 252 , 1982 . [ 23 ] D . Lucking - Reiley , D . Bryan , N . Prasad , and D . Reeves . Pennies from ebay : the deter - minants of price in online auctions . Mimeo , 2000 . [ 24 ] G . Marx . What’s in a name ? some reﬂections on the sociology of anonymity . The Information Society , 15 ( 2 ) , 1999 . [ 25 ] P . Milgrom , D . North , and B . Weingast . The role of institutions in the revival of trade : the law merchant , private judges , and the champaign fairs . Economics and Politics , 2 : 1 – 23 , 1990 . 31 [ 26 ] H . Moulin and S . Shenker . Serial cost sharing . Econometrica , 60 : 1009 – 1037 , 1992 . [ 27 ] H . Nissenbaum . The meaning of anonymity in an information age . The Information Society , 15 ( 2 ) , 1999 . [ 28 ] M . Nowak and K . Sigmund . A strategy of win - stay , lose - shift that outperforms tit - for - tat in the prisoner’s dilemma game . Nature , 364 ( 64 ) : 56 , 1993 . [ 29 ] P . Omidyar . Regarding the feedback forum , letter from founder Pierre Omidyar to the ebay community . http : / / pages . ebay . com / aw / letter - 060998 - feedback . html , 1998 . [ 30 ] M . Reiter and A . Rubin . Anonymous web transactions with crowds . Communications of the ACM , 42 ( 2 ) : 32 – 38 , 1999 . [ 31 ] B . Schneier . Applied Cryptography . John Wiley & Sons , Inc . , New York , 2nd edition , 1996 . [ 32 ] C . Shapiro . Premiums for high quality products as returns to reputations . Quarterly Journal of Economics , 98 ( 4 ) : 1 – 30 , 1983 . [ 33 ] S . Tadelis . What’s in a name ? Reputation as a tradeable asset . American Economic Review , 89 ( 3 ) , 1999 . [ 34 ] S . Tadelis . The market for reputations as an incentive mechanism . Mimeo , 2000 . [ 35 ] A . Teich , M . Frankel , R . Kling , and Y . Lee . Anonymous communication policies for the internet : Results and recommendations of the AAAS . The Information Society , 15 ( 2 ) , 1999 . [ 36 ] H . Varian . Buying , sharing and renting information goods . mimeo , 1994 . [ 37 ] J . Watson . Starting small and renegotiation . Journal of Economic Theory , 85 ( 1 ) , 1999 . [ 38 ] O . Williamson . Franchise bidding for natural monopolies - in general and with respect to CATV . The Bell Journal of Economics , 7 ( 1 ) : 73 – 104 , 1976 . 32