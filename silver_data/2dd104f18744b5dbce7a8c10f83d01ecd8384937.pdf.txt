R E S PLIT : Improving the Structure of Jupyter Notebooks by Re - Splitting Their Cells Sergey Titov JetBrains Research Saint Petersburg , Russia sergey . titov @ jetbrains . com Yaroslav Golubev JetBrains Research Saint Petersburg , Russia yaroslav . golubev @ jetbrains . com Timofey Bryksin JetBrains Research HSE University Saint Petersburg , Russia timofey . bryksin @ jetbrains . com Abstract —Jupyter notebooks represent a unique format for programming — a combination of code and Markdown with rich formatting , separated into individual cells . We propose to perceive a Jupyter Notebook cell as a simpliﬁed and raw version of a programming function . Similar to functions , Jupyter cells should strive to contain singular , self - contained actions . At the same time , research shows that real - world notebooks fail to do so and suffer from the lack of proper structure . To combat this , we propose R E S PLIT , an algorithm for an automatic re - splitting of cells in Jupyter notebooks . The algorithm analyzes deﬁnition - usage chains in the notebook and consists of two parts — merging and splitting the cells . We ran the algorithm on a large corpus of notebooks to evaluate its performance and its overall effect on notebooks , and evaluated it by human experts : we showed them several notebooks in their original and the re - split form . In 29 . 5 % of cases , the re - split notebook was selected as the preferred way of perceiving the code . We analyze what inﬂuenced this decision and describe several individual cases in detail . I . I NTRODUCTION In the 1980 - s , Knuth described the idea of literate program - ming as integrating the code and the natural language [ 1 ] . Modern computational notebooks enable this idea by consist - ing of intertwined cells with either code or rich formatted text , which allows the resulting interactive documents to have a nar - rative [ 2 ] . This aspect made computational notebooks popular in such areas as data science [ 3 ] and education [ 4 ] , where code is just as important as its commentary . However , there is another side to their features — computational notebooks con - tain a lot of code duplicates [ 5 ] , lack proper environments [ 6 ] , and have a very low rate of reproducibility [ 7 ] . Overall , for a medium that strives to be more comprehensive than pure code , notebooks frequently fail to live up to this goal [ 8 ] , [ 9 ] . Currently , there exist several approaches to improve the comprehensibility of notebooks [ 10 ] . One of the main ideas in this ﬁeld is to automate the annotation of code in a notebook — from simply tagging notebook cells [ 11 ] up to fully generating the annotation text [ 12 ] . Another possible approach is to introduce the history of code changes in cells or rearrange cells in order to make the notebook reproducible [ 13 ] . In this work , we focus on one of the basic parts of a notebook — its cells . The presence of logically separated code snippets that can be easily executed is one of the most crucial features of notebooks . Our hypothesis is that an ideal cell could be viewed as an equivalent of a singular action ( or even as a proto - function ) , but because of the very non - restrictive environment and the nature of the software development process , these singular actions become entangled , which results in incomprehensible , non - singular cells . In order to solve this problem , we propose an approach that is similar to the Extract refactoring [ 14 ] for code improvement . We present R E S PLIT , a two - step algorithm that suggests a new re - splitting of the existing cells based on a number of heuristics . On the ﬁrst step , the algorithm suggests merging some of the cells together , and on the second step , it suggests extracting certain code fragments from the original cells into new ones . We expect the new splitting of cells to better represent the singularity of their actions , which would improve the structure and the coherence of a notebook . To test R E S PLIT , we carried out two evaluations . Firstly , we ran the approach on a large corpus of notebooks to evaluate its performance and its effect on the characteristics of the dataset . In the second evaluation , we compare the original and the re - split notebooks from the standpoint of their perception by human experts . We asked the participants to read a small sample of notebooks and then asked several questions about the content of cells in both versions . As a result , we discovered that users prefer the re - split version of a notebook in 29 . 5 % of cases . The current shortcomings are merging cells that generate different output and signiﬁcant changes of the formatting structure . Without these problems , the ratio of selecting the re - split notebook signiﬁcantly rises , which indicates that R E S PLIT has potential to automatically improve the structure of notebooks in the future . The source code of R E S PLIT and supplementary materials are available : https : / / github . com / JetBrains - Research / ReSplit . II . B ACKGROUND A . Previous Work on Jupyter Notebooks Several approaches exist that aim to improve the compre - hensibility of Jupyter notebooks in various ways . Workﬂow - related approaches are targeted at introducing some structure or discipline to the process of writing a notebook . This can simply mean providing some advice on how to write a notebook [ 15 ] or introducing fully - ﬂedged toolkits for docu - menting the whole process of creating a notebook [ 16 ] , [ 17 ] . A more automated approach is to generate annotations for notebooks . Wang et al . [ 12 ] generated annotations for cells a r X i v : 2112 . 14825v1 [ c s . S E ] 29 D ec 2021 with a machine learning algorithm combined with simple ad - ditions from a ﬁxed set of documented functions . The approach proved to be efﬁcient — the experts scored the automatically annotated notebooks as more readable and informative . However , the comprehensibility of notebooks also suffers from the innate messiness of the notebook structure — individ - ual cells could be clear , but their order could be problematic . Several works focused on the structure of the notebooks . Most works are dedicated to implementing some kind of a version control system [ 18 ] . Also , Head et al . [ 8 ] proposed an algorithm that allows users to choose the resulting cells , and then ﬁlters out all redundant code that is not related to the selected cells . While this approach works very well , we wanted to take one step further and try to restructure the notebook automatically , without the user’s input . B . Notebook Re - Splitting In this work , we focus on re - splitting the notebook into cells . We believe that reorganizing code in the notebook should help with its compressibility . In the already discussed work of Head et al . [ 8 ] , during the user study , the authors showed that organizing code in cells is a useful feature for notebook cleaning . Also , Dong et al . [ 19 ] demonstrated that one of the common refactorings for notebooks is splitting certain cells ( or parts of the cells ) into separate scripts . We hypothesize that Jupyter notebook cells could be per - ceived as proto - functions . What we mean is that when the programmers create cells , they are using the same principles as when they create functions : the code in a function must do one dedicated thing , must be reusable , and should be independent from other code . However , because of the looser nature of the medium , these requirements are often applied less strictly . This leads us to the idea that we could improve code quality in the notebooks by re - splitting cells into a more functional style : clearer actions , more reusable and independent code . Additionally , such an approach can work incrementally — the users do not need to ﬁnish a notebook or ﬁnalize the results to start restructuring it . III . A PPROACH R E S PLIT consists of two steps — merging and splitting the cells of the given notebook . Both of these steps operate using the deﬁnition - usage ( DEF - USE ) chain analysis [ 20 ] . This approach could be seen as a simpliﬁed version of data ﬂow graph analysis — we are analysing all connections between object deﬁnitions and their usages . We extract all the chains of such deﬁnitions and usages for notebooks , and perform cell transformations based on a set of heuristics . In this section , we explain these heuristics and transformations , you can ﬁnd detailed and illustrative examples in the project’s repository . A . Creating Code Dependency Representation In order to obtain DEF - USE chains , we use the Python package called beniget , 1 which allows to extract DEF - USE chains for a given snippet . As a result , for each deﬁned object , 1 Beniget : https : / / github . com / serge - sans - paille / beniget the package returns a sequence of nodes in the Abstract Syntax Tree ( AST ) where the object was used . This technique is very fast and allows us to process large corpora of notebooks . An example of a simple DEF - USE chain is presented in Figure 1 . import pandas pd as df = pd . DataFrame ( { : [ , ] , : [ , ] } ) ’a’ ’b’ 1 2 3 4 const = 5 print ( ) f’Constant is ’ { const } Fig . 1 . An example of a simple DEF - USE chain between several statements . B . Merging Cells The main goal of merging the cells is to unite several statements into a single action . In terms of cells , we want to ﬁnd consequent , related cells , and merge them into one . In order to do this , we introduce two assumptions about the cells , based on which we perform the merging . One thing we want to avoid during the merging process is turning big chunks of code into even bigger ones , so we introduce the requirement of the maximum size of the cell that we include in the merging . While there is no recommendation on what the optimal size of a cell should be , we decided to set it as 10 lines of code . This is slightly more than the suggested comfortable number of elements for human perception [ 21 ] and less than the maximum recommendations in different programming style guides , like in the rule of 30 [ 22 ] , where functions should take up less than 30 lines of code . The second assumption has to do with different types of cells . In order to merge the cells , we build DEF - USE chains for the entire notebook . After we have extracted all the chains , we calculate the following two features for each cell : • Intra - cell links : the number of chain links between statements inside the cell ( chains that are contained within the cell ) . • Inter - cell links : the number of chain links to statements in other cells ( chains that lead to other cells ) . We hypothesise that cells in notebooks could be divided into two types : mostly intra - linked and mostly inter - linked . The intra - linked cells are usually operation - heavy . For example , such a cell can be a cell where the developer constructs features for a dataset and frequently uses temporary variables for intermediate results . At the same time , the inter - linked cells mostly operate with global objects that are used throughout the notebook — like importing library functions or creating model objects that will later be used for prediction . Based on this assumption , we can use the ratio between intra - cell links and inter - cell links in the merging process . One problem that we want to solve with merging is the over - splitting of code : when developers use a separate cell for each individual statement . For example , this can happen when the user writes some complex piece of code line by line and uses separate cells for each line , or when they add imports one by one . We hypothesize that such cases could be deﬁned in terms of intra - and inter - linked cells : consecutive cells of the same type are a part of one bigger action and we want to merge them . One way of doing it is to set the restriction on the permitted change of the ratio . In our algorithm , we calculate the inter - cell link ratio as follows : r inter ( c ) = N inter cell links N all links For each pair of cells that are candidates for merging , we compare the ratios before and after potential transformations and , in order to avoid merging different types of cells , we prohibit merges that cause a change in the cell ratio greater than a certain threshold . The resulting algorithm for merging the cells works as follows . We traverse the notebook , extract DEF - USE chains , and calculate r inter for each cell . Then , for each pair of consecutive cells , we check for the following requirements : each cell is less than 5 lines and the potential change in the link ratio after merging is less than 0 . 1 . If both these criteria are met , we merge these cells . C . Splitting Cells The goal of splitting cells is similar to that of the Extract Method refactoring — ﬁnd discrete actions inside the cell and extract them into separate cells . To do so , we ﬁrst need to detect these discrete actions . We do this with the following algorithm . The ﬁrst step is , once again , to extract all chains for each cell in the notebook . As a result , we can represent each cell as a set of Python statements linked by certain usage connections , e . g . , if our code consists of three statements : 1 a = 2 + 2 2 b = a / 2 3 c = 16 * 2 then we can say that object a is deﬁned in the ﬁrst statement and is used in the second one , while the third statement is not connected to any of the ﬁrst two . Having such a representation of cells , our algorithm seeks sequentially linked statements : if we are able to ﬁnd a series of statements connected with DEF - USE chains with no other code between these statements , we mark the start and the end of the series as a potential place for splitting the cell . The second step of the splitting part of the algorithm is building new cells . We start from the bottom of the original cell and collect statements into a new cell until we reach the potential place of splitting . If the number of already collected statements has exceeded the predeﬁned threshold of a minimum of 3 lines to split , we perform the transformation , and if the number of statements is smaller , then we continue collecting the statements until the next potential split . We chose to start from the bottom because we noticed that a considerable amount of cells have output statements at the end that could not be directly chained with previous statements . By starting with them , we are guaranteed to incorporate them in a bigger cell and not leave them to hang . IV . E VALUATION To test R E S PLIT , we perform two different evaluations . Firstly , we run the algorithm on a large corpus of code to test its performance and demonstrate how the algorithm affects the amount and length of cells in a large sample of notebooks . Secondly , we perform a human study to evaluate whether re - splitting the cells made the notebooks more comprehensible . A . Dataset For our purposes , we took a dataset of 1 , 159 , 166 Jupyter notebooks from the work of Pimentel et al . [ 7 ] . Due to the complexity of our algorithm , we decided to reduce the size of the data . To do so , we decided to only keep the notebooks related to Data Science , since they allow us to retain the diversity of the data ( prototypes , homeworks , reports , etc . ) . We ﬁltered the data by leaving only notebooks that contain at least one use of one of the following Python libraries — sklearn , pytorch , tensorﬂow , spacy , and nltk . We chose these libraries because they either provide crucial functions for most of the Data Science tasks or a full pipeline for some of them . This left us with 290 , 381 notebooks . Additionally , based on the work of Koenzen et al . [ 5 ] , we decided to ﬁlter out code clones in the dataset . To detect clones , we used SourcererCC [ 23 ] . We tokenized all the code cells in each notebook , and searched for clones using the similarity threshold of 80 % . As a result , we found and excluded 55 , 843 notebook duplicates , and the ﬁnal dataset contained 234 , 538 notebooks . B . Algorithm’s Validation We start the analysis of the suggested algorithm by verifying one of our assumptions about the data that we made in Section III - B : we suggested that there are two types of cells — mostly inter - linked and mostly intra - linked . Figure 2 shows the inter - cell link ratio for all the cells in our dataset eligible for merging . We can see two noticeable spikes near 1 and 0 that demonstrate the hypothesized effect . 0 . 0 0 . 2 0 . 4 0 . 6 0 . 8 1 . 0 0 1 0 2 0 3 0 4 0 P e r c e n t o f c e l l s I n t e r - c e l l l i n k r a t i o Fig . 2 . The distribution of inter - cell link ratio for all the cells in our dataset . Now , let us take a look at the effect of applying R E S PLIT on the characteristics of cells in the notebook . The mean number of cells in a notebook and the mean length of a cell in the dataset are shown in Table I . The algorithm worked as ex - pected — merging caused an increase in the mean cell length and a decrease in the number of cells , while splitting caused the opposite effect . Both transformations applied together did not drastically change both characteristics , which shows that the merging and splitting processes are balancing each other out , thus not causing any drastic overhauls of the notebooks that could be uncomfortable for the user . Transformations Mean cell length Mean number of cells None ( original dataset ) 8 . 76 36 . 67 Only merge 11 . 32 28 . 95 Only split 7 . 91 39 . 89 Both merge and split 9 . 47 34 . 52 TABLE I T HE INFLUENCE OF THE APPROACH ON THE CHARACTERISTICS OF THE DATASET . C . Human Evaluation Another hypothesis of ours was that re - splitting cells would help with the comprehension of notebooks . To check this hy - pothesis , we performed a human evaluation of our algorithm : we re - split a small sample of the dataset and asked potential users to choose which split they found to be more appropriate . Firstly , we showed the participants the entire code of the notebook in the form of a script ( i . e . , a regular Python ﬁle ) . This step was necessary for reducing the cognitive load bias of the ﬁrst - time code viewing . Additionally , we asked “How well do you understand the script ? ” to control the quality of answers . All evaluations with low scores on this question were excluded from the results . After the participants had acknowledged the code , we showed them two notebooks — the original and the re - split . After the participants went through both notebooks , we asked them to choose which form of the code representation was the most appropriate — the script , the ﬁrst notebook , or the second one . Finally , we asked them if they wanted to split the notebook in an entirely different way . We employed a blind procedure for this experiment . We randomly sampled ﬁve pairs of notebooks ( re - split and orig - inal ) from our dataset . We used two criteria for sampling : ( 1 ) the number of cells in a notebook should be between 5 and 15 in order to avoid edge cases of extremely short or long notebooks , and ( 2 ) the number of cells should change after re - splitting . We randomized the order of notebooks in each pair , the information about the true source of the notebooks was not accessible to the authors of the paper until the ﬁnal analysis of the data . We conducted this research using a Google Form and a remotely hosted Jupyter server for viewing demonstration . In total , 23 developers participated in our study . The mean experience in software engineering for our participants was 4 . 76 years ( SD = 2 . 84 ) . 43 % of them use notebooks less than one time in a week , 39 % — two or three times a week , and 17 % use them every day . Participants needed to choose between notebooks in 5 tasks , resulting in 115 choices in our sample . We discarded 3 answers due to low scores of understanding the given script . As a result , we got 70 cases ( 62 . 5 % ) where the participants chose the original notebooks , and 33 cases ( 29 . 5 % ) when they chose a re - split variant . Also , the participants preferred the script to notebooks 9 times ( 8 % ) . Statistical analysis showed that the participants’ choice is not independent of the task ( Pearson χ 2 , p < 0 . 05 ) , so let us take a closer look at the notebooks and the preference ratio for each of them . The details of the participants’ choices are presented in Table II . Task No . Original Re - split Script 1 15 ( 68 . 2 % ) 6 ( 27 . 3 % ) 1 ( 4 . 5 % ) 2 15 ( 68 . 2 % ) 6 ( 27 . 3 % ) 1 ( 4 . 5 % ) 3 9 ( 39 . 1 % ) 8 ( 34 . 8 % ) 6 ( 26 . 1 % ) 4 11 ( 50 % ) 11 ( 50 % ) 0 ( 0 % ) 5 20 ( 87 % ) 2 ( 8 . 7 % ) 1 ( 4 . 3 % ) TABLE II T HE NUMBER OF CHOICES BETWEEN THE ORIGINAL , THE RE - SPLIT , AND THE SCRIPT VIEWS OF THE NOTEBOOKS FOR EACH TASK . 1 ) Task 1 : The original representation was chosen in 68 . 2 % of cases . The reason might be that in this notebook , our algorithm only merged cells , and it merged a lot of statements that have output , like df . head ( ) or plt . show ( ) . 2 ) Task 2 : Similar to the previous task , the original rep - resentation was chosen in 68 . 2 % of cases . However , in this notebook , our algorithm only split cells . We suppose that in this case , R E S PLIT changed the original logical structure that was conveyed with the chucks of code separated by new lines , and made it less comprehensible . 3 ) Task 3 : This very short notebook received 26 . 1 % of the votes for the form of the script . Once again , our algorithm merged cells with output functions . However , in the form of a script , these statements would not have any effect either way , and still some participants wanted to read the code that way . 4 ) Task 4 : This is our most successful notebook — the re - split version was chosen in half of the cases . Here , our idea of merging worked successfully — we merged the ﬁrst three cells , in which the author introduced objects that were used later . Catching such cases was one of our main goals . 5 ) Task 5 : Our least successful notebook — the re - split version was chosen only in 8 . 7 % of cases . The low score could be caused by the merge action : according to our idea , we merged two mostly intra - linked cells — one with creating the dataset object , and another one with the model object . While our algorithm did this correctly , from the data science perspective , these are two separate actions . Based on the results of the evaluation , we can conclude that our algorithm shows potential and works as expected in some cases , but needs to be improved with the following features : • We need to analyse statements that produce an output — they frequently dictate the structure of the notebook and must be accounted for . • We need to be more careful with the original formatting or even use it as an additional heuristic . Speciﬁcally , some users like to format the code into chunks by using newlines — and this can happen within a single cell . • We need to pick candidates for transformation better . Currently , we do it based solely on the size of the cell and do not try to score the content of the cell . V . C ONCLUSION The task of re - splitting notebooks is an important practical task — with reported low levels of reproducibility [ 7 ] , it is crucial to develop tools that could increase the comprehensi - bility of the medium . We suppose that a notebook is a distinct code entity that lies between the ﬁrst sketch solution for the problem and a production - ready one . It requires its own style guide , because such things as multiple outputs or cell size are not regulated in the existing ones . Pimentel et al . [ 24 ] already proposed a simple linter for Jupyter notebooks , and we believe that the logic of splitting cells could be a good part for such linter . Also , as we stated in Section II , we propose to perceive notebook cells as proto - functions . We believe that studying cell splits could shed some light on how people think when solving programming problems . Fan et al . [ 25 ] showed that people use spaces between chunks of code for navigation in the codebase . We suggest that cell division plays the same role , but it is less controlled by style guides , so it could provide more insight into the underlying logical structure of the code . In this paper , we presented R E S PLIT , an algorithm for re - splitting Jupyter notebooks without any input from the user . Our evaluation showed that in 29 . 5 % of cases , people preferred the restructured notebooks . Although this is not a prevailing result , we can say that our heuristic caught some of the desirable structure of notebook . We provided the detailed case studies of speciﬁc tasks in our survey and came up with a list of improvements that can make the approach even better . Apart from these improvements , our main target is imple - menting R E S PLIT as a plugin for Jupyter notebooks . One of the main advantages of our work is that our algorithm can work during the process of developing a notebook — deploying it as an interactive tool for data scientists is the ﬁrst priority for us , since this will allow us to gather a lot of crucial feedback . We are considering developing the plugin for the IntelliJ Platform , 2 since this will allow us to use more complex representation of code and give access to such tools as the complete data and control ﬂow graphs , which can improve both parts of R E S PLIT : merging and splitting . A complete data ﬂow graph will help us to acquire more precise information about the way the notebook cells are linked , and the control ﬂow graph would improve the splitting of cells into more logical and more efﬁcient chunks . Lastly , R E S PLIT uses a lot of hyper - parameters — the minimum and maximum length for cells , the minimum chain length for split , etc . An important part of the future work for us is to experiment with the hyper - parameters and ﬁnd the most suitable ones . The source code of R E S PLIT and supplementary materials are available : https : / / github . com / JetBrains - Research / ReSplit . R EFERENCES [ 1 ] D . E . Knuth , “Literate programming , ” The computer journal , vol . 27 , no . 2 , pp . 97 – 111 , 1984 . [ 2 ] A . Rule , A . Tabard , and J . D . Hollan , “Exploration and explanation in computational notebooks , ” in Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , 2018 , pp . 1 – 12 . [ 3 ] J . M . Perkel , “Why Jupyter is data scientists’ computational notebook of choice , ” Nature , vol . 563 , no . 7732 , pp . 145 – 147 , 2018 . [ 4 ] J . W . Johnson and K . H . Jin , “Jupyter notebooks in education , ” Journal of Computing Sciences in Colleges , vol . 35 , no . 8 , pp . 268 – 269 , 2020 . 2 The IntelliJ Platform SDK Documentation : https : / / plugins . jetbrains . com / docs / intellij / welcome . html [ 5 ] A . P . Koenzen , N . A . Ernst , and M . - A . D . Storey , “Code duplication and reuse in Jupyter notebooks , ” in 2020 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . IEEE , 2020 , pp . 1 – 9 . [ 6 ] J . Wang , L . Li , and A . Zeller , “Restoring execution environments of Jupyter notebooks , ” in 2021 IEEE / ACM 43rd International Conference on Software Engineering ( ICSE ) . IEEE , 2021 , pp . 1622 – 1633 . [ 7 ] J . F . Pimentel , L . Murta , V . Braganholo , and J . Freire , “A large - scale study about quality and reproducibility of Jupyter notebooks , ” in 2019 IEEE / ACM 16th International Conference on Mining Software Repositories ( MSR ) . IEEE , 2019 , pp . 507 – 517 . [ 8 ] A . Head , F . Hohman , T . Barik , S . M . Drucker , and R . DeLine , “Man - aging messes in computational notebooks , ” in Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems , 2019 , pp . 1 – 12 . [ 9 ] S . Chattopadhyay , I . Prasad , A . Z . Henley , A . Sarma , and T . Barik , “What’s wrong with computational notebooks ? Pain points , needs , and design opportunities , ” in Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems , 2020 , pp . 1 – 12 . [ 10 ] D . Kang , T . Ho , N . Marquardt , B . Mutlu , and A . Bianchi , “ToonNote : Improving communication in computational notebooks using interactive data comics , ” in Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems , 2021 , pp . 1 – 14 . [ 11 ] G . Zhang , M . A . Merrill , Y . Liu , J . Heer , and T . Althoff , “Coral : Code representation learning with weakly - supervised transformers for analyzing data analysis , ” arXiv preprint arXiv : 2008 . 12828 , 2020 . [ 12 ] A . Y . Wang , D . Wang , J . Drozdal , M . Muller , S . Park , J . D . Weisz , X . Liu , L . Wu , and C . Dugan , “Themisto : Towards automated doc - umentation generation in computational notebooks , ” arXiv preprint arXiv : 2102 . 12592 , 2021 . [ 13 ] M . B . Kery and B . A . Myers , “Interactions for untangling messy history in a computational notebook , ” in 2018 IEEE Symposium on Visual Languages and Human - Centric Computing ( VL / HCC ) . IEEE , 2018 , pp . 147 – 155 . [ 14 ] N . Tsantalis and A . Chatzigeorgiou , “Identiﬁcation of Extract method refactoring opportunities for the decomposition of methods , ” Journal of Systems and Software , vol . 84 , no . 10 , pp . 1757 – 1782 , 2011 . [ 15 ] A . Rule , A . Birmingham , C . Zuniga , I . Altintas , S . - C . Huang , R . Knight , N . Moshiri , M . H . Nguyen , S . B . Rosenthal , F . P´erez et al . , “Ten simple rules for writing and sharing computational analyses in Jupyter notebooks , ” 2019 . [ 16 ] J . F . Pimentel , S . Dey , T . McPhillips , K . Belhajjame , D . Koop , L . Murta , V . Braganholo , and B . Lud¨ascher , “Yin & Yang : demonstrating comple - mentary provenance from noWorkﬂow & YesWorkﬂow , ” in International Provenance and Annotation Workshop . Springer , 2016 , pp . 161 – 165 . [ 17 ] S . Samuel and B . K¨onig - Ries , “ProvBook : Provenance - based semantic enrichment of interactive notebooks for reproducibility , ” in International Semantic Web Conference ( P & D / Industry / BlueSky ) , 2018 . [ 18 ] M . Brachmann and W . Spoth , “Your notebook is not crumby enough , replace it , ” in Conference on Innovative Data Systems Research ( CIDR ) , 2020 . [ 19 ] H . Dong , S . Zhou , J . L . Guo , and C . K¨astner , “Splitting , renaming , re - moving : A study of common cleaning activities in Jupyter notebooks , ” in 9th International Workshop on Realizing Artiﬁcial Intelligence Synergies in Software Engineering , 2021 . [ 20 ] K . Kennedy , “Use - deﬁnition chains with applications , ” Computer Lan - guages , vol . 3 , no . 3 , pp . 163 – 179 , 1978 . [ 21 ] G . A . Miller , “The magical number seven , plus or minus two : Some limits on our capacity for processing information . ” Psychological review , vol . 63 , no . 2 , p . 81 , 1956 . [ 22 ] M . Lippert and S . Roock , Refactoring in large software projects : performing complex restructurings successfully . John Wiley & Sons , 2006 . [ 23 ] H . Sajnani , V . Saini , J . Svajlenko , C . K . Roy , and C . V . Lopes , “SourcererCC : Scaling code clone detection to big - code , ” in Proceedings of the 38th International Conference on Software Engineering , 2016 , pp . 1157 – 1168 . [ 24 ] J . F . Pimentel , L . Murta , V . Braganholo , and J . Freire , “Understanding and improving the quality and reproducibility of Jupyter notebooks , ” Empirical Software Engineering , vol . 26 , no . 4 , pp . 1 – 55 , 2021 . [ 25 ] Q . Fan , The effects of beacons , comments , and tasks on program com - prehension process in software maintenance . University of Maryland , Baltimore County , 2010 .