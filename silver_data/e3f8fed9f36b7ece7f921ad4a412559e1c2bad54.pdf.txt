a r X i v : 2105 . 04620v1 [ c s . A I ] 10 M a y 2021 A Description Logic for Analogical Reasoning Steven Schockaert , Yazm´ın Ib´a˜nez - Garc´ıa , V´ıctor Guti´errez - Basulto Cardiff University , UK { schockaerts1 , ibanezgarciay , gutierrezbasultov } @ cardiff . ac . uk Abstract Ontologies formalise how the concepts from a given domain are interrelated . Despite their clear potential as a backbone for explainable AI , existing ontologies tend to be highly incomplete , which acts as a signiﬁcant barrier to their more widespread adoption . To mitigate this issue , we present a mech - anism to infer plausible missing knowledge , which relies on reasoning by analogy . To the best of our knowledge , this is the ﬁrst paper that studies ana - logical reasoning within the setting of description logic ontologies . After showing that the standard formalisation of analogical proportion has impor - tant limitations in this setting , we introduce an al - ternative semantics based on bijective mappings be - tween sets of features . We then analyse the proper - ties of analogies under the proposed semantics , and show among others how it enables two plausible inference patterns : rule translation and rule extrap - olation . 1 Introduction The last decade has witnessed an increasing interest in methods for automated knowledge base completion . While most work has focused on predicting plausible missing facts in knowledge graphs [ Bordes et al . , 2013 ; Yang et al . , 2015 ; Trouillon et al . , 2017 ; Balazevic et al . , 2019 ] , some authors have also looked at the problem of predicting plau - sible missing rules in ontologies [ Beltagy et al . , 2013 ; Bouraoui and Schockaert , 2019 ] . The underlying principle of these latter approaches is to rely on external knowledge about the similarity structure of concepts , typically in the form of a vector space embedding of concept names . The main idea is that knowledge about concepts can often be ex - tended to concepts with a similar representation in the given vector space . The same principle also lies at the basis of rule - based frameworks with a soft uniﬁcation mechanism [ Medina et al . , 2004 ; Rockt¨aschel and Riedel , 2017 ] . How - ever , these similarity based reasoning methods can clearly only provide us with knowledge that is similar to what is al - ready in the knowledge base . Humans , on the other hand , can also infer plausible knowledge in more creative ways , where a particularly prominent role is played by the idea of rea - soning by analogy . This phenomenon has been extensively studied in cognitive science and philosophy [ Gentner , 1983 ; Hofstadter et al . , 1995 ; Holyoak and Thagard , 1997 ] , but to the best of our knowledge , the use of analogical reasoning for completing ontologies has not yet been considered 1 Within Artiﬁcial Intelligence , the formalisation of ana - logical reasoning typically builds on analogical propor - tions , i . e . statements of the form “ A is to B what C is to D ” [ Bayoudh et al . , 2007 ; Prade and Richard , 2014 ; Barbot et al . , 2019 ] . A key result in this area has been the development of analogical classiﬁers , which are based on the principle that whenever the features of four examples are in an analogical proportion , then their class labels should be in an analogical proportion as well [ Bayoudh et al . , 2007 ; Hug et al . , 2016 ] . The same principle can be applied to in - fer plausible concept inclusions , i . e . concept inclusions which are not entailed from a given TBox , but which are likely to hold given additional background knowledge that we have about analogical relationships between different concepts . The resulting inference pattern , which we call rule extrap - olation , is illustrated in the next example . Example 1 ( Rule extrapolation ) . Suppose we have an ontol - ogy with the following concept inclusions : Young ⊓ Cat ⊑ Cute ( 1 ) Adult ⊓ WildCat ⊑ Dangerous ( 2 ) Young ⊓ Dog ⊑ Cute ( 3 ) Suppose we are furthermore given that “ Cat is to WildCat what Dog is to Wolf ” . Trivially , we also have that “ Young is to Adult what Young is to Adult ” and “ Cute is to Dangerous what Cute is to Dangerous ” Using rule extrapolation , we can then infer the following : Adult ⊓ Wolf ⊑ Dangerous ( 4 ) Analogies can also be used to infer plausible knowledge by allowing us to transfer knowledge from one domain to an - other . This is illustrated in the following example . 1 We note that the term “analogical reasoning” has been used in the literature to refer to a form of similarity - based ontology com - pletion [ d’Amato et al . , 2006 ] . In contrast , we reserve this term for methods that require drawing parallels between different domains . Example 2 ( Rule translation ) . Suppose we are given the fol - lowing knowledge : Program ⊑ ∃ speciﬁes . Software ( 5 ) and the fact that “ Program is to Plan what Software is to Building” . Then we can plausibly infer : Plan ⊑ ∃ speciﬁes . Building ( 6 ) Ontologies often use the same “templates” to encode knowl - edge from different domains ( e . g . knowledge about different professions ) . The strategy from Example 2 then allows us to complete the ontology by introducing additional domains . Using analogies for identifying plausible missing knowl - edge is appealing , because they can be learned from text quite effectively . For instance , Turney [ 2006 ] proposed a method for identifying similarities between pairs of words ( i . e . ana - logical proportions ) using matrix factorization and ternary co - occurrence statistics , which approximated the performance of an average US college applicant . Moreover , the GPT - 3 lan - guage model is able to identify analogical word pairs with even higher accuracy [ Brown et al . , 2020 ] . To a more lim - ited extent , some types of analogical relationships can also be obtained from word embeddings [ Mikolov et al . , 2013 ] . The main aim of this paper is to propose a semantics for modelling analogies within the setting of description logics , which introduces a number of unique challenges ( see Section 3 ) . We focus in particular on an extension of EL ⊥ . We start from the semantics proposed by Ib´a˜nez - Garc´ıa et al . [ 2020 ] , which extends the EL semantics by assigning to each individ - ual a set of features . Their aim was to support another form of plausible inference , called interpolation ( see Section 2 ) . We show that having access to these features in the semantics also allows us to formalise analogies . 2 Background We start by introducing the Description Logic ( DL ) EL ⊲⊳ ⊥ , which is a straightforward extension of the logic EL ⊲⊳ that was proposed in [ Ib´a˜nez - Garc´ıa et al . , 2020 ] to formalise rule interpolation 2 . Our approach to analogical reasoning in this paper will build on EL ⊲⊳ ⊥ . Rule interpolation is another in - ference pattern for obtaining plausible missing concept inclu - sions in a DL ontology . Interpolation is based on the notion of betweenness , where a concept B is said to be between con - cepts A and C if B has all the natural properties that A and C have in common . In such a case , knowledge that holds for both A and C seems likely to hold for B as well . This inference pattern is illustrated in the next example . Example 3 ( Rule interpolation ) . Suppose we have the follow - ing concept inclusions : Cat ⊑ X Wolf ⊑ X ( 7 ) As long as X is a “natural concept” , it seems plausible that the following concept inclusion also holds : Dog ⊑ X 2 We include ⊥ because disjointness will play an important role in this paper . This is because all the common ( natural ) properties of Cat and Wolf are also satisﬁed by Dog . In such a case , we say that the concept Dog is between the concepts Cat and Wolf . The notion of naturalness plays an important role in most philosophical accounts of induction . Intuitively speaking , a natural concept or property is one that admits inductive in - ferences . The semantics from [ Ib´a˜nez - Garc´ıa et al . , 2020 ] is based on the common view that natural concepts are those which can be characterised as a set of features ( i . e . a conjunc - tion of elementary properties ) [ Tversky , 1977 ] . Syntax . The logic EL ⊲⊳ ⊥ extends the standard DL EL ⊥ with in - between concepts of the form C ⊲⊳ D , describing the set of objects that are between the concepts C and D . Further , EL ⊲⊳ ⊥ includes an inﬁnite set of natural concept names . More precisely , consider countably inﬁnite but disjoint sets of con - cept names N C and role names N R , where N C contains a dis - tinguished inﬁnite set of natural concept names N NatC . The syntax of EL ⊲⊳ ⊥ concepts C , D is deﬁned by the following grammar , where A ∈ N C , A ′ ∈ N NatC and r ∈ N R : C , D : = ⊤ | ⊥ | A | C ⊓ D | ∃ r . C | N N , N ′ : = A ′ | N ⊓ N ′ | N ⊲⊳ N ′ Concepts of the form N , N ′ are called natural concepts . An EL ⊲⊳ ⊥ TBox is a ﬁnite set of concept inclusions C ⊑ D , where C , D are EL ⊲⊳ ⊥ concepts . Semantics . The semantics of EL ⊲⊳ ⊥ is given in terms of feature - enriched interpretations , which extend standard ﬁrst - order interpretations by also specifying a mapping π from individuals to sets of features . Formally , a feature - enriched interpretation is a tuple I = ( I , F , π ) in which I = ( ∆ I , · I ) is a classical DL interpretation , F is a ﬁnite set of features , and π : ∆ I → 2 F , such that the following hold : 1 . For each d ∈ ∆ I it holds that π ( d ) ⊂ F ; 2 . for each F ⊂ F there exists some individual d ∈ ∆ I such that π ( d ) = F . For an EL ⊲⊳ ⊥ concept C , C I is deﬁned as a pair h C I , ϕ ( C ) i where C I ⊆ ∆ I and ϕ ( C ) is the set of all features associated with a concept C , deﬁned as : ϕ ( C ) = \ { π ( d ) | d ∈ C I } Intuitively , the set of features ϕ ( C ) describes the concept C at a ﬁner - grained level that what may be possible in the lan - guage . This makes it possible to capture knowledge about what different concepts have in common , which is needed in EL ⊲⊳ ⊥ to model the semantics of in - between concepts . For a standard EL ⊥ concept C , C I is deﬁned as usual [ Baader et al . , 2017 ] . For in - between concepts , · I is deﬁned as follows . ( N ⊲⊳ N ′ ) I = { d ∈ ∆ I | ϕ ( N ) ∩ ϕ ( N ′ ) ⊆ π ( d ) } . Intuitively , ( N ⊲⊳ N ′ ) I contains all elements from the domain that have all the features that are common to both N and N ′ . A feature - enriched interpretation I = ( I , F , π ) satisﬁes a concept inclusion C ⊑ D if C I ⊆ D I . I is a model of an EL ⊲⊳ TBox T if it satisﬁes all CIs in T and for every natural concept N in T , it holds that N I = { d ∈ ∆ I | ϕ ( N ) ⊆ π ( d ) } ( 8 ) i . e . N is fully speciﬁed by its features . It is easy to verify that ( 8 ) is satisﬁed for a complex natural concept , as soon as it is satisﬁed for its constituent natural concept names . A concept C is satisﬁable w . r . t . a TBox T , if there is a model I of T such that C I 6 = h∅ , Fi . The purpose of introducing features in the semantics of EL ⊲⊳ ⊥ is to make explicit what different concepts have in common , and to use this as the basis for enabling a par - ticular kind of inductive inference ( i . e . interpolation ) . For instance , in the case of Example 3 , if the concept inclu - sions in ( 7 ) are complemented with Dog ⊑ Cat ⊲⊳ Wolf , it can be veriﬁed that Dog ⊑ X can indeed be inferred ( assuming all concept names are natural ) . In applications , knowledge about in - between concepts would typically be in - duced from a vector space embedding . See , for instance , [ Bouraoui and Schockaert , 2019 ] for a practical application of rule interpolation based on pre - trained word embeddings . In this paper , we will build on the feature - enriched semantics to encode correspondences between analogous domains . 3 Analogical Concepts Analogical proportions are a central notion in the formali - sation of analogical reasoning , going back to Aristotle ( see [ Barbot et al . , 2019 ] for a historical perspective ) . While they can be deﬁned more generally , here we will focus on ana - logical proportions between sets . In particular , the sets S 1 , S 2 , S 3 , S 4 are said to be in an analogical proportion , de - noted as S 1 : S 2 : : S 3 : S 4 if S 1 and S 2 differ in the same way that S 3 and S 4 differ . Formally , S 1 : S 2 : : S 3 : S 4 is satisﬁed if : S 1 \ S 2 = S 3 \ S 4 S 2 \ S 1 = S 4 \ S 3 ( 9 ) Some key properties of analogical proportions are as follows : Reﬂexivity A : B : : A : B Symmetry ( A : B : : C : D ) ⇔ ( C : D : : A : B ) Exchange of means ( A : B : : C : D ) ⇔ ( A : C : : B : D ) S - transitivity ( A : B : : C : D ) ∧ ( A : B : : E : F ) ⇒ ( C : D : : E : F ) C - transitivity ( A : C : : D : B ) ∧ ( A : E : : F : B ) ⇒ ( C : E : : F : D ) 3 . 1 Analogical Proportions between DL Concepts In this paper , we are concerned with analogies between de - scription logic concepts . We can deﬁne analogical propor - tions between EL ⊲⊳ ⊥ concepts A , B , C , D as A I : B I : : C I : D I or as ϕ ( A ) : ϕ ( B ) : : ϕ ( C ) : ϕ ( D ) . In general these two expres - sions are not equivalent , and there are advantages in requiring that both of them are satisﬁed at the same time , which has been studied in detail in [ Barbot et al . , 2019 ] within the set - ting of Formal Concept Analysis . However , if A , B , C , D are natural , then A I : B I : : C I : D I and ϕ ( A ) : ϕ ( B ) : : ϕ ( C ) : ϕ ( D ) are equivalent . Moreover , for natural concepts , the semantic constraint ϕ ( A ) : ϕ ( B ) : : ϕ ( C ) : ϕ ( D ) can be modelled syntac - tically in EL ⊲⊳ ⊥ . Indeed it holds that ϕ ( A ) : ϕ ( B ) : : ϕ ( C ) : ϕ ( D ) is satisﬁed iff the following conditions are satisﬁed 3 : ϕ ( A ) ∩ ϕ ( D ) = ϕ ( B ) ∩ ϕ ( C ) ( 10 ) 3 This follows immediately from the characterisation of Boolean analogical proportions in terms of conjunction and disjunction ; see [ Prade and Richard , 2013 ] for details . ϕ ( A ) ∪ ϕ ( D ) = ϕ ( B ) ∪ ϕ ( C ) ( 11 ) The analogical proportion ϕ ( A ) : ϕ ( B ) : : ϕ ( C ) : ϕ ( D ) is thus satisﬁed if the following concept inclusions are satisﬁed : A ⊓ D ⊑ B ⊓ C B ⊓ C ⊑ A ⊓ D A ⊲⊳ D ⊑ B ⊲⊳ C B ⊲⊳ C ⊑ A ⊲⊳ D In the following , we will write A : B : : C : D as an abbreviation for these four concept inclusions . The fact that we can model A : B : : C : D within EL ⊲⊳ ⊥ is an advantage , but as we will see below , modelling analogies between DL concepts in this way has a number of important limitations . 3 . 2 Desiderata for Modelling Analogies in DLs Our motivation for studying analogies is to enable plausible inferences . A clear requirement is thus that we want some form of the rule extrapolation and rule translation inference patterns , as illustrated in Examples 1 and 2 , to be satisﬁed . Another important requirement comes from the fact that we usually only have access to information about analogical re - lationships between concept names ( e . g . obtained from a lan - guage model ) . However , the aforementioned inference pat - tern may rely on analogical relationships between complex concepts . To enable non - trivial inferences in practice , it is thus important that analogies between concept names can be lifted to analogies between complex concepts . Let us now consider the suitability of analogical propor - tions , in light of these desiderata . First , rule translation is satisﬁed for analogical proportions . Proposition 1 . Let I = ( I , F , π ) be a feature - enriched inter - pretation , and let A 1 , A 2 , B 1 , B 2 be natural concepts in I . If ϕ ( A 1 ) : ϕ ( A 2 ) : : ϕ ( B 1 ) : ϕ ( B 2 ) holds and I satisﬁes A 1 ⊑ B 1 , then I also satisﬁes A 2 ⊑ B 2 . However , rule extrapolation is not valid for analogical propor - tions . Furthermore , analogical proportions between concept names cannot be lifted to complex concepts . For instance , from A 1 : B 1 : : C 1 : D 1 and A 2 : B 2 : : C 2 : D 2 , in general we can - not infer ( A 1 ⊓ A 2 ) : ( B 1 ⊓ B 2 ) : : ( C 1 ⊓ C 2 ) : ( D 1 ⊓ D 2 ) . Coun - terexamples are provided in the appendix . 4 The Logic EL ana ⊥ Given the limitations of analogical proportions that were highlighted in Section 3 . 2 , we propose an alternative ap - proach for modelling analogies between description logic concepts . This approach is based on the common view that analogies are mappings from one domain into another , which lies among others at the basis of the seminal Structure Map - ping framework [ Gentner , 1983 ] . In particular , we propose the logic EL ana ⊥ , which extends EL ⊲⊳ ⊥ with two novel ele - ments : analogy assertions and intra - domain roles . Analogy assertions are similar to analogical proportions , in that they encode a relationship of the form “ A is to B what C is to D ” , but their semantics is deﬁned in terms of mappings between different domains , where domains will be identiﬁed with sets of features . Intuitively , intra - domain roles are roles which preserve the structure of analogous domains . 4 . 1 Syntax Let N C , N NatC and N R be deﬁned as before . We assume that N R contains an inﬁnite set N Int R of distinguished intra - domain role names . The syntax of EL ana ⊥ concepts C , D is deﬁned by the following grammar , where A ∈ N C , A ′ ∈ N NatC , r ∈ N R and r ′ ∈ N Int R : C , D : = ⊤ | ⊥ | A | C ⊓ D | ∃ r . C | N N , N ′ : = A ′ | N ⊓ N ′ | N ⊲⊳ N ′ | ∃ r ′ . N EL ana ⊥ concepts extend EL ⊲⊳ ⊥ concepts by allowing existential restrictions over intra - domain roles as natural concepts . An EL ana ⊥ TBox is a ﬁnite set containing two types of assertions : ( i ) EL ana ⊥ concept inclusions , and ( ii ) analogy assertions of the form C 1 ⊲D 1 : : C 2 ⊲D 2 , where C 1 , C 2 , D 1 , D 2 are natural EL ana ⊥ concepts . 4 . 2 Semantics Analogies intuitively involve transferring knowledge from one domain to another domain 4 , e . g . from software engineer - ing to architecture in the case of Example 2 . In our frame - work , these domains will be associated with subsets of F . In particular , we will require that interpretations specify a parti - tion [ F 1 , . . . , F k ] of F , deﬁning the different domains of inter - est . Some of the partition classes will furthermore be viewed as being analogous , in the sense that there is some kind of structure - preserving mapping between them . Another extension of the feature - enriched semantics is aimed at improving how disjointess can be modelled . In the semantics from [ Ib´a˜nez - Garc´ıa et al . , 2020 ] , no individ - ual d ∈ ∆ I is allowed to have all the features from F , but all proper subsets F ⊂ F are witnessed in the sense that there is some d such that π ( d ) = F . This limits how disjoint con - cepts can be modelled . For instance , B cannot be satisﬁed w . r . t . { B ⊑ A ⊲⊳ C , A ⊓ B ⊑ ⊥ , A ⊓ C ⊑ ⊥ , B ⊓ C ⊑ ⊥ } using a feature - enriched interpretation . Disjointness will play an important role in our semantics , as concepts from different domains will be required to be disjoint ( see below ) . For this reason , we extend the feature - enriched semantics with sets of forbidden feature combinations . In particular , interpretations will specify a set X ∈ 2 F such that for X ∈ X , it holds that no individual can have all the features from X . For the ease of presentation , we write C for the set of all consistent sets of features , i . e . F ∈ C iff F 6⊇ X for all X ∈ X . We also write C i for the restriction of C to subsets of F i . Deﬁnition 1 . Let [ F 1 , . . . , F k ] be a partition of a non - empty ﬁnite set F . We call I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) a do - main constrained interpretation if I = ( ∆ I , . I ) is a clas - sical DL interpretation , X ⊆ 2 F , F ∈ X , π : ∆ I → 2 F , ∼ is an equivalence relation over { 1 , . . . , k } and S = { σ ( s , t ) | ( s , t ) ∈∼ } , with each σ s , t a bijection from F s to F t , and we have : 1 . for every d ∈ ∆ I and X ∈ X it holds that X 6⊆ π ( d ) ; 2 . if X ∈ C then π ( d ) = X for some d ∈ ∆ I ; 4 In this paper , we use the term domain to refer to a particular thematic area . This should not be confused with the set ∆ I , which is often referred to as the domain of the interpretation I . 3 . we have σ − 1 ( s , t ) = σ ( t , s ) and σ ( t , u ) ◦ σ ( s , t ) = σ ( s , u ) for any ( s , t ) , ( t , u ) ∈∼ ; 4 . for F ∈ C i and ( i , j ) ∈∼ , we have { σ ( i , j ) ( f ) | f ∈ F } ∈ C ; 5 . if f ∈ F i and g ∈ F j then { f , g } ∈ X , for all ( i , j ) ∈∼ with i 6 = j . Intuitively , each of the sets F i corresponds to a different do - main . If ( s , t ) ∈∼ , it means that there is an analogy be - tween the source domain F s and the target domain F t . In that case , there is a one - to - one mapping σ ( s , t ) between the features from F s and those from F t . The ﬁrst two condi - tions from Deﬁnition 1 capture the fact that a set of features X ⊆ F is witnessed by some individual iff it is consistent , i . e . X ∈ C . The third condition ensures that the mappings σ ( i , j ) can be composed and reversed . The fourth condition encodes that the mapping σ ( i , j ) maps consistent feature combinations to consistent feature combinations . This is a natural require - ment , given the intuition that analogous domains should have the same structure . The last condition captures the require - ment that individuals cannot have features from two analo - gous domains . While analogies are normally indeed deﬁned between distinct domains , the reader may wonder at this point whether this restriction is necessary . We will come back to this question in Section 4 . 4 . Domain Translations Before presenting the semantics of analogy assertions , we ﬁrst study how the bijections σ ( i , j ) can be combined to deﬁne mappings between the sets of features ϕ ( C ) , ϕ ( D ) associated with two concepts . First , we deﬁne a domain assignment mapping δ , which maps each concept C to the set of domains on which it depends : δ ( C ) = { i | F i ∩ ϕ ( C ) 6 = ∅ } Next , we extend the mappings σ ( i , j ) to mappings between sets of domains . Let U = { ( s 1 , t 1 ) , . . . , ( s l , t l ) } , with s 1 , . . . , s l all distinct and t 1 , . . . , t l all distinct . The mapping σ U is deﬁned as follows : σ U ( f ) = (cid:26) σ ( s i , t i ) ( f ) if f ∈ F s i f otherwise We call σ U a domain translation , and write src ( U ) for the set { s 1 , . . . , s l } of source domains and tgt ( U ) for the set { t 1 , . . . , t l } of target domains . The source domains need to be distinct to ensure that the domain translation is uniquely deﬁned . Target domains are required to be distinct to allow domain translations to be reversible . For the ease of presenta - tion , we will write σ U ( F ) to denote the set { σ U ( f ) | f ∈ F } . For a pair of concepts C and D , we write µ ( C , D ) for the set of domain translations σ U such that : ϕ ( D ) = σ U ( ϕ ( C ) ) ( 12 ) src ( U ) ⊆ δ ( C ) ( 13 ) tgt ( U ) ∩ ( δ ( C ) \ src ( U ) ) = ∅ ( 14 ) The ﬁrst condition states that the domain translations in µ ( C , D ) essentially “translate” the concept C to the concept D . The second condition ensures that µ ( C , D ) contains min - imal domain translations only , in the sense that U should not contain any redundant pairs . The third condition is needed to ensure that domain translations are reversible . To see why this is needed , let ϕ ( C ) = { f 1 , g 2 } , ϕ ( D ) = { g 1 , g 2 } , F 1 = { f 1 , f 2 } , F 2 = { g 1 , g 2 } , σ ( 1 , 2 ) ( f i ) = g i . Then ϕ ( D ) = σ ( 1 , 2 ) ( ϕ ( C ) ) , but there is no domain translation σ U s . t . ϕ ( C ) = σ U ( ϕ ( D ) ) . As the following result shows , im - posing ( 14 ) is enough to ensure reversibility . Proposition 2 . Let U be a domain translation , and let U ` = { ( t , s ) | ( s , t ) ∈ U } . It holds that σ − 1 U = σ U ` . As the next result shows , the composition of two domain translations is also a valid domain translation . In particular , if there is some domain translation σ U that maps C to D and some domain translation σ V that maps D to E , then σ U and σ V can be composed to deﬁne a domain translation from C to E . Moreover , in such a case , any domain translation from C to E can be deﬁned as such a composition . Proposition 3 . If µ ( C , D ) 6 = ∅ and µ ( D , E ) 6 = ∅ we have : µ ( C , E ) = { σ U ⊕ V | σ U ∈ µ ( C , D ) , σ V ∈ µ ( D , E ) } where U ⊕ V = { ( i , k ) | ( i , j ) ∈ U , ( j , k ) ∈ V , i 6 = k } ∪ { ( i , j ) | ( i , j ) ∈ U , j / ∈ src ( V ) } ∪ { ( j , k ) | ( j , k ) ∈ V , j / ∈ tgt ( U ) } Semantics of Intra - Domain Roles We will need to put additional constraints on the interpretation of a role r to be able to infer ( ∃ r . A ) ⊲ ( ∃ r . B ) : : ( ∃ r . C ) ⊲ ( ∃ r . D ) or A⊲B : : ( ∃ r . C ) ⊲ ( ∃ r . D ) from A⊲B : : C⊲D . To allow such lift - ing of analogy assertions , we will associate with each intra - domain role r a mapping κ r between sets of features , which satisﬁes a number of conditions . In particular , we introduce the following notion of intra - domain relation . Deﬁnition 2 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a do - main constrained interpretation and let r ∈ N R . We say that r is interpreted as an intra - domain relation if for every concept C , we have ( ∃ r . C ) I = { d ∈ ∆ I | π ( d ) ⊇ κ r ( ϕ ( C ) } , for a mapping κ r satisfying : 1 . κ r ( F ) = κ r ( F ∩ F 1 ) ∪ . . . ∪ κ r ( F ∩ F k ) , for all F ∈ C ; 2 . κ r ( F ) ⊆ F i , for all i ∈ { 1 , . . . , k } and F ∈ C i ; 3 . κ r ( σ { ( i , j ) } ( F ) ) = σ { ( i , j ) } ( κ r ( F ) ) , for all ( i , j ) ∈∼ and F ∈ C i ; 4 . κ r ( F ) 6 = ∅ , for all i ∈ { 1 , . . . , k } and F ∈ C i \ { ∅ } . The ﬁrst two conditions in Deﬁnition 2 state that the features in κ r ( F ) are determined per domain . The third condition cap - tures the intuition that analogous domains should have the same structure . The last condition essentially encodes that whenever C depends on some domain i then ∃ r . C should also depend on domain i , i . e . if ϕ ( C ) contains at least one feature from F i then the same should be true for κ r ( ϕ ( C ) ) . Note that if r is interpreted as an intra - domain relation and C is a natural concept , then ∃ r . C is a natural concept , whose fea - tures are determined by the features in ϕ ( C ) . We then have ϕ ( ∃ r . C ) = κ r ( ϕ ( C ) ) . The semantics of EL ana ⊥ concepts can now be deﬁned sim - ilarly to Section 2 , but we additionally require that every r ∈ N Int R is interpreted as an intra - domain relation . Semantics of TBoxes We now deﬁne the semantics of EL ana ⊥ TBoxes . We start with that of analogy assertions . We say that a domain constrained interpretation I satisﬁes the analogy assertion C 1 ⊲C 2 : : D 1 ⊲D 2 if : µ ( C 1 , C 2 ) ∩ µ ( D 1 , D 2 ) 6 = ∅ ( 15 ) Clearly , C 1 ⊲C 2 : : D 1 ⊲D 2 is equivalent to D 1 ⊲D 2 : : C 1 ⊲C 2 . One may wonder whether ( 15 ) is sufﬁcient , i . e . whether we should not require µ ( C 1 , C 2 ) = µ ( D 1 , D 2 ) . However , as the following result shows , for non - empty concepts , µ ( C 1 , C 2 ) and µ ( D 1 , D 2 ) can have at most one element . Proposition 4 . Let I = ( I , F , X , π , ∼ , S ) be a domain - constrained interpretation . If C I 6 = ∅ , D I 6 = ∅ and µ ( C , D ) 6 = ∅ , then | µ ( C , D ) | = 1 . We deﬁne the semantics of EL ana ⊥ TBoxes similarly to Sec - tion 2 , but now including analogy assertions . A domain con - strained interpretation I is a model of an EL ana ⊥ TBox T if I satisﬁes all CIs and analogy assertions in T ; every natural concept N ∈ T is fully speciﬁed by its features ; and every intra - domain role is interpreted as an intra - domain relation . For a TBox T and CI or analogy assertion φ we write T | = φ to denote that every model of T satisﬁes φ . If T is a singleton of the form { ψ } , we also write this as ψ | = φ . 4 . 3 Properties of Analogy Assertions Basic Properties Before returning to the desiderata from Section 3 . 2 , we brieﬂy look at the properties of analogical proportions that were listed in Section 3 . First , reﬂexivity is trivially satisﬁed . The symmetry property also holds for anal - ogy assertions , thanks to the reversibility of domain transla - tions . Proposition 5 . We have C 1 ⊲C 2 : : D 1 ⊲D 2 | = C 2 ⊲C 1 : : D 2 ⊲D 1 . Exchange of means is not satisﬁed . This can easily be seen from the fact that whenever C 1 ⊲C 2 : : D 1 ⊲D 2 is satisﬁed , we have | ϕ ( C 1 ) | = | ϕ ( C 2 ) | and | ϕ ( D 1 ) | = | ϕ ( D 2 ) | but not necessarily | ϕ ( C 1 ) | = | ϕ ( D 1 ) | . As a result of this , there are two variants of S - transitivity that can be considered . As the next proposition shows , both of these variants are satisﬁed . Proposition 6 . It holds that : { C 1 ⊲C 2 : : D 1 ⊲D 2 , D 1 ⊲D 2 : : E 1 ⊲E 2 } | = C 1 ⊲C 2 : : E 1 ⊲E 2 ( 16 ) { C 1 ⊲C 2 : : D 1 ⊲D 2 , C 2 ⊲C 3 : : D 2 ⊲D 3 } | = C 1 ⊲C 3 : : D 1 ⊲D 3 ( 17 ) We also have that C - transitivity is satisﬁed . Proposition 7 . It holds that : { C 1 ⊲D 1 : : D 2 ⊲C 2 , C 1 ⊲E 1 : : E 2 ⊲C 2 } | = D 1 ⊲E 1 : : E 2 ⊲D 2 Lifting analogy assertions As the next two results show , analogy assertions can indeed be lifted to ( non - empty ) con - junctions and existentially quantiﬁed concepts . Proposition 8 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a domain - constrained interpretation satisfying ( C i ⊓ D i ) I 6 = ∅ for i ∈ { 1 . . 4 } , C 1 ⊲C 2 : : C 3 ⊲C 4 and D 1 ⊲D 2 : : D 3 ⊲D 4 . Then I also satisﬁes ( C 1 ⊓ D 1 ) ⊲ ( C 2 ⊓ D 2 ) : : ( C 3 ⊓ D 3 ) ⊲ ( C 4 ⊓ D 4 ) . Proposition 9 . Let r be an intra - domain role . It holds that : C⊲D : : E⊲F | = ( ∃ r . C ) ⊲ ( ∃ r . D ) : : ( ∃ r . E ) ⊲ ( ∃ r . F ) ( 18 ) C⊲D : : E⊲F | = C⊲D : : ( ∃ r . E ) ⊲ ( ∃ r . F ) ( 19 ) Analogy Based Inference Patterns We now return to the two considered analogy based inference patterns : rule trans - lation and rule extrapolation . First , similar as for analogical proportions , we ﬁnd that rule translation is supported . Proposition 10 . Let I be a domain constrained interpreta - tion . If I satisﬁes { C 1 ⊲D 1 : : C 2 ⊲D 2 , C 1 ⊑ C 2 } then I also satisﬁes D 1 ⊑ D 2 . Example 4 . Suppose Program ⊲ Plan : : Software ⊲ Building holds and assume that speciﬁes is an intra - domain role . Us - ing Proposition 9 we can then infer : Program ⊲ Plan : : ( ∃ speciﬁes . Software ) ⊲ ( ∃ speciﬁes . Building ) If we are additionally given that the concept inclusion ( 5 ) is satisﬁed , we can infer ( 6 ) using Proposition 10 . A version of rule extrapolation is also supported . Proposition 11 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a domain constrained interpretation . Suppose that C I 1 6 = ∅ and that I satisﬁes the following TBox : T = { C 1 ⊲C 2 : : C 3 ⊲C 4 , D 1 ⊲D 2 : : D 3 ⊲D 4 , D 1 ⊲D 3 : : D 2 ⊲D 4 , C 1 ⊑ D 1 , C 2 ⊑ D 2 , C 3 ⊑ D 3 } Then I also satisﬁes the assertion C 4 ⊑ D 4 . Example 5 . Suppose the concept inclusions ( 1 ) – ( 3 ) are sat - isﬁed , as well as the following analogy assertions 5 : Young ⊲ Adult : : Young ⊲ Adult Cat ⊲ WildCat : : Dog ⊲ Wolf Cute ⊲ Dangerous : : Cute ⊲ Dangerous Cute ⊲ Cute : : Dangerous ⊲ Dangerous Assuming the intersections involved are all non - empty , us - ing Proposition 8 we can infer ( Young ⊓ Cat ) ⊲ ( Adult ⊓ WildCat ) : : ( Young ⊓ Dog ) ⊲ ( Adult ⊓ Wolf ) . Finally , using Proposition 11 we can infer that ( 4 ) holds . Note that both D 1 ⊲D 2 : : D 3 ⊲D 4 and D 1 ⊲D 3 : : D 2 ⊲D 4 are re - quired for the above proposition to hold ( see the appendix for a counterexample that shows this ) . For analogical pro - portions , adding both conditions makes no difference , as D 1 : D 2 : : D 3 : D 4 and D 1 : D 3 : : D 2 : D 4 are equivalent . 4 . 4 Alternative Semantics As shown in Section 4 . 3 , the proposed semantics for anal - ogy assertions satisﬁes the main desiderata from Section 3 . 2 . We may wonder , however , whether all aspects of the seman - tics are necessary for this to hold . We return in particu - lar to Condition 5 from Deﬁnition 1 , which is perhaps the most restrictive condition . In particular , let us deﬁne the no - tion of weak domain constrained interpretation as a tuple ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) that satisﬁes all conditions from Deﬁnition 1 , apart from Condition 5 . One immediate con - sequence of dropping Condition 5 is that Proposition 4 is no longer valid . As a result , in addition to analogy assertions of the form A 1 ⊲A 2 : : B 1 ⊲B 2 , with the semantics deﬁned in ( 15 ) , we can now also consider strong analogy assertions , denoted 5 Note that Cute ⊲ Cute : : Dangerous ⊲ Dangerous is trivially sat - isﬁed , since σ ∅ ∈ µ ( Cute , Cute ) ∩ µ ( Dangerous , Dangerous ) . as A 1 ◮ A 2 : : B 1 ◮ B 2 , which are satisﬁed if ( 15 ) is satisﬁed and moreover : µ ( A 1 , A 2 ) = µ ( B 1 , B 2 ) Under this weak semantics , C - transitivity ( i . e . Proposition 7 ) is no longer satisﬁed , neither for the standard analogy as - sertions nor for strong analogy assertions ( see the appendix for counterexamples ) . Regarding S - transitivity , the variant in ( 17 ) remains valid and is furthermore also valid for strong analogy assertions . However , the variant in ( 16 ) is no longer valid for standard analogy assertions , although it is satisﬁed for strong analogy assertions . In contrast , Proposition 9 re - mains valid for standard analogy assertions , but it is not sat - isﬁed for strong analogy assertions . Proposition 8 is neither satisﬁed for standard analogy assertions nor for strong anal - ogy assertions . Finally , in terms of inference patterns , Propo - sition 10 remains valid , but Proposition 11 does not , neither for standard nor strong analogy assertions . 5 Conclusions We have proposed a framework for analogy assertions of the form “ A is to B what C is to D ” that is suitable for analog - ical reasoning in description logics . The underlying assump - tion is that analogy assertions between concept names can be learned from text , and that we can then lift these to obtain analogy assertions between complex DL concepts . We have shown how the resulting semantics allows us to infer concept inclusions using two analogy based inference patterns . This complements other types of plausible inference patterns , such as interpolation and similarity based reasoning . There are two important lines for immediate future work . First , we plan to study the computational complexity of rea - soning in EL ana ⊥ . Results from [ Ib´a˜nez - Garc´ıa et al . , 2020 ] provide a CO NP lower bound for concept subsumption w . r . t . EL ana ⊥ TBoxes . For the upper bound , one key issue would be to relate the number of domains and features of concepts oc - curring in analogy assertions , as well of those of existential restrictions over intra - domain roles of such concepts . One would also need to establish a bound on the number of fea - tures and domains . From the practical side we need mech - anisms to deal with the noisy nature of the available knowl - edge about betweenness and analogy assertions ( which typi - cally would be learned from data ) and the inconsistencies that may introduce . To this end , we plan to study probabilistic or non - monotonic extensions of our framework . A Proofs Proof of Proposition 1 First note that A 2 ⊑ B 2 is equivalent to ϕ ( B 2 ) ⊆ ϕ ( A 2 ) , since A 2 and B 2 are natural concepts . Let f ∈ ϕ ( B 2 ) . We thus need to show that f ∈ ϕ ( A 2 ) . If f / ∈ ϕ ( B 1 ) then we must have f ∈ ϕ ( A 2 ) \ ϕ ( A 1 ) , since A 1 : A 2 : : B 1 : B 2 is sat - isﬁed . If f ∈ ϕ ( B 1 ) , then we must have f ∈ ϕ ( A 1 ) since A 1 ⊑ B 1 is satisﬁed . Since f / ∈ ϕ ( B 1 ) \ ϕ ( B 2 ) we must have f / ∈ ϕ ( A 1 ) \ ϕ ( A 2 ) , which means f ∈ ϕ ( A 2 ) . Proof of Proposition 2 Let us write U = { ( s 1 , t 1 ) , . . . , ( s k , t k ) } . We show for each g ∈ F that σ U ` ( σ U ( g ) ) = g . If g ∈ F s i , for some i ∈ { 1 , . . . , k } , then by the deﬁnition of domain translation , we have σ U ` ( σ U ( g ) ) = σ ( t i , s i ) ( σ ( s i , t i ) ( g ) ) = g . If g / ∈ F s 1 ∪ . . . ∪ F s k , then σ U ( g ) = g . In that case , we also have g / ∈ F t 1 ∪ . . . ∪ F t k , since g ∈ F j for some j ∈ δ ( A 1 ) \ src ( U ) and we know from ( 14 ) that tgt ( U ) ∩ ( δ ( A 1 ) \ src ( U ) ) = ∅ . From g / ∈ F t 1 ∪ . . . ∪F t k we ﬁnd σ X ` ( g ) = g and in particular σ U ` ( σ U ( g ) ) = σ U ` ( g ) = g . Proof of Proposition 3 We show this proposition in two steps . Lemma 1 . We have µ ( A , C ) ⊇ { σ U ⊕ V | σ U ∈ µ ( A , B ) , σ V ∈ µ ( B , C ) } Proof . Let σ U ∈ µ ( A , B ) and σ V ∈ µ ( B , C ) . We need to show that σ U ⊕ V satisﬁes conditions , ( 12 ) , ( 13 ) and ( 14 ) w . r . t . the concept pair ( A , C ) . First consider ( 13 ) . Let i ∈ src ( U ⊕ V ) . If i ∈ src ( U ) then we have i ∈ δ ( A ) since σ U ∈ µ ( A , B ) . The only other possibility is that i ∈ src ( V ) and i / ∈ tgt ( U ) . Since σ V ∈ µ ( B , C ) , we have that i ∈ src ( V ) implies i ∈ δ ( B ) . Since σ U ∈ µ ( A , B ) and i / ∈ tgt ( U ) , this furthermore implies i ∈ δ ( A ) . In all cases we thus have that ( 13 ) is satisﬁed . Next we show that ( 14 ) is satisﬁed , i . e . that tgt ( U ⊕ V ) ∩ ( δ ( A ) \ src ( U ⊕ V ) ) = ∅ . Suppose k ∈ tgt ( U ⊕ V ) ; we show that k / ∈ δ ( A ) \ src ( U ⊕ V ) . We consider two cases : • Suppose k / ∈ δ ( A ) \ src ( U ) . Suppose k ∈ δ ( A ) \ src ( U ⊕ V ) were to hold . This is only possible if k ∈ src ( U ) \ src ( U ⊕ V ) . By deﬁnition of ⊕ , this is only possible if ( k , j ) ∈ U and ( j , k ) ∈ V for some j . From k ∈ tgt ( U ⊕ V ) we then ﬁnd that ( i , k ) ∈ U for some i and k / ∈ src ( V ) . However , this implies that k ∈ tgt ( V ) ∩ ( δ ( B ) \ src ( V ) ) , which is a contradiction since σ V ∈ µ ( B , C ) . We thus have k / ∈ δ ( A ) \ src ( U ⊕ V ) . • Suppose k ∈ δ ( A ) \ src ( U ) . Then k ∈ δ ( B ) . However , since σ Y ∈ µ ( B , C ) , we know that k / ∈ δ ( B ) \ src ( V ) , hence we ﬁnd k ∈ src ( V ) . In other words , V contains some pair of the form ( k , l ) . Furthermore , from tgt ( U ) ∩ ( δ ( A ) \ src ( U ) ) = ∅ , we know that k / ∈ tgt ( U ) . By construction of U ⊕ V we ﬁnd ( k , l ) ∈ U ⊕ V and thus k ∈ src ( U ⊕ V ) , and in particular k / ∈ δ ( A ) \ src ( U ⊕ V ) . Finally , we show that ( 12 ) is satisﬁed , i . e . that ϕ ( C ) = { σ U ⊕ V ( f ) | f ∈ ϕ ( A ) } . Let f ∈ ϕ ( A ) . • Suppose ( i , j ) ∈ U , ( j , k ) ∈ V and i 6 = k . Since σ U ∈ µ ( A , B ) and σ V ∈ µ ( B , C ) , we know that σ ( i , j ) ( f ) ∈ ϕ ( B ) and σ ( j , k ) ( σ ( i , j ) ( f ) ) ∈ ϕ ( C ) . Since σ ( j , k ) ◦ σ ( i , j ) = σ ( i , k ) we ﬁnd σ ( i , k ) ( f ) ∈ ϕ ( C ) , and in particular σ U ⊕ V ( f ) ∈ ϕ ( C ) . • Suppose ( i , j ) ∈ X and j / ∈ src ( V ) . We then have σ ( i , j ) ( f ) ∈ ϕ ( B ) as well as σ ( i , j ) ( f ) ∈ ϕ ( C ) , and in particular σ U ⊕ V ( f ) ∈ ϕ ( C ) . • Suppose ( j , k ) ∈ Y and j / ∈ tgt ( U ) . This implies that j / ∈ src ( U ) . We thus have f ∈ ϕ ( B ) , σ ( j , k ) ( f ) ∈ ϕ ( C ) and in particular σ U ⊕ V ( f ) ∈ ϕ ( C ) . This already shows that ϕ ( C ) ⊇ { σ U ⊕ V ( f ) | f ∈ ϕ ( A ) } . Conversely , suppose f ∈ ϕ ( C ) . Then we know there must be some g ∈ ϕ ( B ) such that σ V ( g ) = f and some h ∈ ϕ ( A ) such that σ U ( h ) = g . Suppose h ∈ F i , g ∈ F j and f ∈ F k . • If h 6 = g and g 6 = f , it must be the case that ( i , j ) ∈ U and ( j , k ) ∈ V . If i 6 = k we have ( i , k ) ∈ U ⊕ V and thus σ U ⊕ V ( h ) = f . If i = k , we have i / ∈ src ( U ⊕ V ) and thus again σ U ⊕ V ( h ) = f . • If h 6 = g and g = f , we have j = k , j / ∈ src ( V ) and thus ( i , j ) ∈ U ⊕ V , meaning σ U ⊕ V ( h ) = σ U ( h ) = g = f . • If h = g and g 6 = f , we have i = j , j / ∈ tgt ( U ) and thus ( j , k ) ∈ U ⊕ V , meaning σ U ⊕ V ( h ) = σ U ⊕ V ( g ) = σ V ( g ) = f . This shows ϕ ( C ) ⊆ { σ U ⊕ V ( f ) | f ∈ ϕ ( A ) } ❏ To complete the proof of Proposition 3 , we now also show the following result Lemma 2 . If µ ( A , B ) 6 = ∅ and µ ( B , C ) 6 = ∅ then it holds that : µ ( A , C ) ⊆ { σ U ⊕ V | σ U ∈ µ ( A , B ) , σ V ∈ µ ( B , C ) } Proof . Let σ Z ∈ µ ( A , C ) . We show that there are mappings σ U ∗ ∈ µ ( A , B ) and σ V ∗ ∈ µ ( B , C ) such that Z = U ∗ ⊕ V ∗ . Let σ U and σ V be arbitrary elements from µ ( A , B ) and µ ( B , C ) respectively . If Z = U ⊕ V then we can simply choose U ∗ = U and V ∗ = V . Now suppose there is some feature f ∈ F i such that σ U ⊕ V ( f ) 6 = σ Z ( f ) . Let us write g = σ U ⊕ V ( f ) and g ′ = σ Z ( f ) . Furthermore , let f ′ and f ′′ be the features from ϕ ( A ) such that σ U ⊕ V ( f ′ ) = g ′ and σ Z ( f ′′ ) = f . Let us write i , i ′ , i ′′ for the domains of f , f ′ , f ′′ and j , j ′ for the domains of g , g ′ respectively . Note that we then have ϕ ( A ) ∩ F i = { σ − 1 U ⊕ V ( x ) | x ∈ ϕ ( C ) ∩ F j } = { σ − 1 Z ( x ) | x ∈ ϕ ( C ) ∩ F j ′ } from which we ﬁnd ϕ ( C ) ∩ F j ′ = { σ Z ( σ − 1 U ⊕ V ( x ) ) | x ∈ ϕ ( C ) ∩ F j } ϕ ( C ) ∩ F j = { σ U ⊕ V ( σ − 1 Z ( x ) ) | x ∈ ϕ ( C ) ∩ F j ′ } and in particular thus also : ϕ ( C ) ∩ F j ′ = { σ ( j , j ′ ) ( x ) | x ∈ ϕ ( C ) ∩ F j } ( 20 ) ϕ ( C ) ∩ F j = { σ ( j ′ , j ) ( x ) | x ∈ ϕ ( C ) ∩ F j ′ } ( 21 ) We show that we can always ﬁnd U ′ and V ′ such that σ U ′ ∈ µ ( A , B ) , σ V ′ ∈ µ ( B , C ) , σ U ′ ⊕ V ′ ( f ) = σ Z ( f ) , and such that for each feature f ′ for which we had σ U ⊕ V ( f ′ ) = σ Z ( f ′ ) , we have σ U ′ ⊕ V ′ ( f ′ ) = σ Z ( f ′ ) . Thus , given that the set of features F is ﬁnite , by repeating the same pro - cess , we will end up with mappings σ U ∗ and σ V ∗ such that σ U ∗ ⊕ V ∗ = σ Z . • Suppose U contains a pair of the form ( i , l ) and V con - tains pair of the form ( l , j ) . – Suppose V also contains a pair of the form ( l ′ , j ′ ) . Let U ′ = U and V ′ = ( V \ { ( l , j ) , ( l ′ , j ′ ) } ) ∪ { ( l , j ′ ) , ( l ′ , j ) } . From ( 20 ) – ( 21 ) , together with the transitivity properties of the mappings σ ( i , j ) ( i . e . Condition 3 from Deﬁnition 1 ) , it follows that ϕ ( C ) ∩ F j ′ = { σ ( l , j ′ ) ( x ) | x ∈ ϕ ( B ) ∩ F l } ϕ ( C ) ∩ F j = { σ ( l , j ) ( x ) | x ∈ ϕ ( B ) ∩ F l ′ } It follows that σ V ′ ∈ µ ( B , C ) while U ′ and V ′ satisfy the required conditions . – Suppose V does not contain any pair of the form ( l ′ , j ′ ) but U contains a pair of the form ( l ′ , j ′ ) , then we deﬁne U ′ = ( U \ { ( l ′ , j ′ ) } ) ∪ { ( l ′ , j ) } and V ′ = ( V \ { ( l , j ) } ) ∪ { ( l , j ′ ) } . Similarly as in the previous case , we ﬁnd that U ′ and V ′ satisfy the requirements . – If U does not contain any pair of the form ( l ′ , j ′ ) either , then it must be the case that σ U ⊕ V ( f ′ ) = f ′ and i ′ = j ′ . In this case , we can choose U ′ = U and V ′ = ( V \ { ( l , j ) } ) ∪ { ( l , j ′ ) , ( i ′ , j ) } . • Suppose U contains a pair of the form ( i , j ) . – If V contains a pair of the form ( l ′ , j ′ ) , then we can choose U ′ = ( U \ { ( i , j ) } ) ∪ { ( i , j ′ ) } and V ′ = ( V \ { ( l ′ , j ′ ) } ) ∪ { ( l ′ , j ) } . – If V does not contain a pair of the form ( l ′ , j ′ ) , but U contains such a pair then we can choose U ′ = ( U \ { ( i , j ) , ( l ′ , j ′ ) } ) ∪ { ( i , j ′ ) , ( l ′ , j ) } and V ′ = V . – If U does not contain a pair of the form ( l ′ , j ′ ) either , then i ′ = j ′ and we can choose U ′ = ( U \ { ( i , j ) } ) ∪ { ( i , j ′ ) } and V ′ = V ∪ { ( i ′ , j ) } . • Suppose V contains a pair of the form ( i , j ) . – Suppose V also contains a pair of the form ( l ′ , j ′ ) . Then we can choose U ′ = U and V ′ = ( V \ { ( i , j ) , ( l ′ , j ′ ) } ) ∪ { ( i , j ′ ) , ( l ′ , j ) } . – Suppose V does not contain a pair of the form ( l ′ , j ′ ) but U contains such a pair . Then we can choose U ′ = ( U \ { ( l ′ , j ′ ) } ) ∪ { ( l ′ , j ) } and V ′ = ( V \ { ( i , j ) } ) ∪ { ( i , j ′ ) } . – Suppose U does not contain a pair of the form ( l ′ , j ′ ) either . Then i ′ = l ′ and we can choose U ′ = U and V ′ = ( V \ { ( i , j ) } ) ∪ { ( i , j ′ ) , ( i ′ , j ) } . We thus ﬁnd that suitable sets U ′ and V ′ can be found in all cases . ❏ Proof of Proposition 4 We ﬁrst show the following lemmas . Lemma 3 . Let I = ( I , [ F 1 , . . . F k ] , X , π , ∼ , S ) be a domain - constrained interpretation . If i , j ∈ δ ( A ) such that ( i , j ) ∈∼ and i 6 = j , it holds that A I = ∅ . Proof . This follows immediately from Conditions 1 and 5 of Deﬁnition 1 . ❏ Lemma 4 . Let I = ( I , [ F 1 , . . . F k ] , X , π , ∼ , S ) be a domain - constrained interpretation . If µ ( A , B ) 6 = ∅ then there is some σ u ∈ µ ( A , B ) such that for every σ V ∈ µ ( A , B ) it holds that U ⊆ V . Proof . Suppose that σ U , σ V ∈ µ ( A , B ) such that U and V are minimal , i . e . for any U ′ ⊂ U or V ′ ⊂ V we have σ U ′ / ∈ µ ( A , B ) and σ V ′ / ∈ µ ( A , B ) . Now suppose U 6 = V , i . e . suppose that there is some pair ( i 1 , i 2 ) ∈ U \ V and some pair ( j 1 , j 2 ) ∈ V \ U . First assume i 1 = j 1 . Since U and V were assumed to be minimal , we have i 1 , j 1 ∈ δ ( A ) and thus we must also have i 2 , j 2 ∈ δ ( B ) . However , that means ϕ ( B ) contains some f ∈ F i 2 and some g ∈ F j 2 , while ( i 2 , j 2 ) ∈∼ . We thus ﬁnd from Lemma 3 that B I = ∅ , or in other words that ϕ ( B ) = F . This also entails that ϕ ( A ) = F . The only way to choose σ U and σ V such that U and V are minimal is thus to choose U = V = ∅ . Now assume there is no pair ( j 1 , j 2 ) ∈ V \ U such that i 1 = j 1 . Since U was assumed to be minimal , we must have some f ∈ F i 1 ∩ ϕ ( A ) . Since , by assumption , we have no pair of the form ( i 1 , j ) in V , we must also have f ∈ ϕ ( B ) . We thus ﬁnd that f and σ U ( f ) both belong to ϕ ( B ) , but f ∈ F i 1 and σ U ( f ) ∈ F i 2 . Since U was assumed to be minimal , we also have i 1 6 = i 2 , hence it again follows that B I = ∅ , and thus ϕ ( A ) = ϕ ( B ) = F and U = V = ∅ . ❏ From Lemma 4 , we know that µ ( A , B ) contains some ele - ment σ U such that U ⊆ V for each σ V ∈ µ ( A , B ) . Now suppose U 6 = V and let ( i , j ) ∈ V \ U . Note that by ( 13 ) we have that i ∈ δ ( A ) . We can thus only have σ U ( ϕ ( A ) ) = σ V ( ϕ ( A ) ) if U contains a pair of the form ( i , k ) . That means that i , k ∈ δ ( B ) with i 6 = k , and thus A I = B I = ∅ ( using Lemma 3 ) . Proof of Proposition 5 We ﬁrst show the following lemma . Lemma 5 . Suppose that σ X ∈ µ ( A 1 , A 2 ) . Then σ X ` ∈ µ ( A 2 , A 1 ) . Proof . We ﬁrst show that tgt ( X ` ) ∩ ( δ ( A 2 ) \ src ( X ` ) ) = ∅ which is equivalent to : src ( X ) ∩ ( δ ( A 2 ) \ tgt ( X ) ) = ∅ Let i ∈ δ ( A 2 ) \ tgt ( X ) . Then there must be some f ∈ ϕ ( A 2 ) such that f ∈ F i . But since i / ∈ tgt ( X ) this is only possible if f ∈ ϕ ( A 1 ) and i / ∈ src ( X ) . We thus have src ( X ) ∩ ( δ ( A 2 ) \ tgt ( X ) ) = ∅ . We now show that ϕ ( A 1 ) = { σ X ` ( f ) | f ∈ ϕ ( A 2 ) } . Since σ X ∈ µ ( A 1 , A 2 ) , this means that we need to show : ϕ ( A 1 ) = { σ X ` ( σ X ( g ) ) | g ∈ ϕ ( A 1 ) } which follows immediately from Proposition 2 . Finally , it is also clear that ( 13 ) is satisﬁed for σ X ` if this condition is satisﬁed for σ X ❏ Since ( U ` ) ` = U , we have the following corollary . Corollary 1 . It holds that : µ ( A 2 , A 1 ) = { σ U ` | σ U ∈ µ ( A 1 , A 2 ) } The main result directly follows from this corollary . Proof of Proposition 6 We show both transitivity properties separately . Lemma 6 . It holds that : { A 1 ⊲A 2 : : B 1 ⊲B 2 , B 1 ⊲B 2 : : C 1 ⊲C 2 } | = A 1 ⊲A 2 : : C 1 ⊲C 2 Proof . Assume that A 1 ⊲A 2 : : B 1 ⊲B 2 and B 1 ⊲B 2 : : C 1 ⊲C 2 are satisﬁed in some domain - constrained interpretation I . We then have that there is some σ U ∈ µ ( A 1 , A 2 ) ∩ µ ( B 1 , B 2 ) and some σ V ∈ µ ( B 1 , B 2 ) ∩ µ ( C 1 , C 2 ) . By Proposition 4 , we have σ U = σ V and thus we ﬁnd that µ ( A 1 , A 2 ) ∩ µ ( C 1 , C 2 ) 6 = ∅ . ❏ Lemma 7 . It holds that : { A 1 ⊲A 2 : : B 1 ⊲B 2 , A 2 ⊲A 3 : : B 2 ⊲B 3 } | = A 1 ⊲A 3 : : B 1 ⊲B 3 Proof . Assume that A 1 ⊲A 2 : : B 1 ⊲B 2 and A 2 ⊲A 3 : : B 2 ⊲B 3 are satisﬁed in some domain - constrained interpretation I . Then there exists some σ U ∈ µ ( A 1 , A 2 ) ∩ µ ( B 1 , B 2 ) and some σ V ∈ µ ( A 2 , A 3 ) ∩ µ ( B 2 , B 3 ) . By Proposition 3 we then have that σ U ⊕ V ∈ µ ( A 1 , A 3 ) ∩ µ ( B 1 , B 3 ) , and hence that A 1 ⊲A 3 : : B 1 ⊲B 3 is satisﬁed . ❏ Proof of Proposition 7 Assume that A 1 ⊲B 1 : : B 2 ⊲A 2 and A 1 ⊲C 1 : : C 2 ⊲A 2 are satis - ﬁed in some domain - constrained interpretation I . There ex - ist some σ U ∈ µ ( A 1 , B 1 ) ∩ µ ( B 2 , A 2 ) and some σ V ∈ µ ( A 1 , C 1 ) ∩ µ ( C 2 , A 2 ) . First assume that A I 1 = ∅ . Then clearly we also have B I 1 = C I 1 = ∅ , since ϕ ( A 1 ) = F and | ϕ ( A 1 ) | = | ϕ ( B 1 ) | = | ϕ ( C 1 ) | . If moreover A I 2 = ∅ , then we similarly also ﬁnd B I 2 = C I 2 = ∅ and the result is trivially satisﬁed . If A I 2 6 = ∅ , then the only possibility is that U = V = ∅ . Indeed , if e . g . ( i , k ) ∈ V then V would need to contain some element of the form ( j , i ) with ( i , j ) ∈∼ , which would entail C I 2 = ∅ since src ( V ) ⊆ δ ( C 2 ) and i , j ∈ δ ( C 2 ) implies C I 2 = 0 by Lemma 3 . Thus we have A I 2 = B I 2 = C I 2 , meaning that the result is satisﬁed . The case where A I 2 = ∅ and A I 1 6 = ∅ is analogous . We now show that the result holds for the case where A I 1 6 = ∅ and A I 2 6 = ∅ . From Corollary 1 and Proposition 3 we know that then µ U ` ⊕ V ∈ µ ( B 1 , C 1 ) and µ V ⊕ U ` ∈ µ ( C 2 , B 2 ) . To complete the proof , we show that µ U ` ⊕ V = µ V ⊕ U ` = µ U ` ∪ V , from which it follows in particular that µ U ` ⊕ V ∈ µ ( B 1 , C 1 ) ∩ µ ( C 2 , B 2 ) , meaning that A 1 ⊲A 3 : : B 1 ⊲B 3 is sat - isﬁed . Suppose that there are elements i , j , k such that ( i , j ) ∈ U ` and ( j , k ) ∈ V . Then we have i ∈ δ ( A 2 ) since src ( U ` ) ⊆ δ ( A 2 ) . However , we also have k ∈ δ ( A 2 ) since src ( V ) ⊆ δ ( C 2 ) and ϕ ( A 2 ) = σ V ( ϕ ( C 2 ) ) . Since ( i , k ) ∈∼ and we assumed A I 2 6 = ∅ , it follows that i = k . Since this is the case for all i , j , k such that ( i , j ) ∈ U ` and ( j , k ) ∈ V , it follows from the deﬁnition of ⊕ that U ` ⊕ V = U ` ∪ V . In the same way we ﬁnd that V ⊕ U ` = U ` ∪ V . Proof of Proposition 8 We ﬁrst show the following lemma . Lemma 8 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a domain - constrained interpretation satisfying ( A 1 ⊓ B 1 ) I 6 = ∅ and ( A 2 ⊓ B 2 ) I 6 = ∅ . Let σ U ∈ µ ( A 1 , B 1 ) and σ V ∈ µ ( A 2 , B 2 ) . It holds that σ U ∪ V ∈ µ ( A 1 ⊓ B 1 , A 2 ⊓ B 2 ) . Proof . We ﬁrst show that σ U ∪ V is a valid domain translation : • All pairs in U ∪ V should have a different source domain , i . e . we must have that for all ( i , j ) ∈ U and ( i , k ) ∈ V it holds that j = k . To see why this is satisﬁed , note that ( i , j ) ∈ U and ( i , k ) ∈ V imply that j ∈ δ ( A 2 ) and k ∈ δ ( B 2 ) . From Lemma 3 , we know that j 6 = k would imply ( A 2 ⊓ B 2 ) I = ∅ . • All pairs in U ∪ V should have a different target domain , i . e . for all ( i , k ) ∈ U and ( j , k ) ∈ V we must have that i = j . To see why this is satisﬁed , note that ( i , k ) ∈ U and ( j , k ) ∈ V mean i ∈ δ ( A 1 ) and j ∈ δ ( B 1 ) . We thus ﬁnd that i 6 = j would imply ( A 1 ⊓ B 1 ) I = ∅ . Next we show that tgt ( U ∪ V ) ∩ ( δ ( A 1 ⊓ B 1 ) \ src ( U ∪ V ) ) = ∅ . Suppose that there were some i ∈ tgt ( U ∪ V ) ∩ ( δ ( A 1 ⊓ B 1 ) \ src ( U ∪ V ) ) . In other words , suppose we had i ∈ tgt ( U ) ∪ tgt ( V ) , i ∈ δ ( A 1 ) ∪ δ ( B 1 ) , i / ∈ src ( U ) and i / ∈ src ( V ) . Suppose in particular that i ∈ tgt ( U ) ; the case where i ∈ tgt ( V ) is entirely analogous . Since σ U ∈ µ ( A 1 , A 2 ) and i / ∈ src ( U ) we know that i / ∈ δ ( A 1 ) , and thus in particular that i ∈ δ ( B 1 ) . From i ∈ tgt ( U ) , we know that there must be some ( j , i ) ∈ U such that j ∈ δ ( A 1 ) and ( j , i ) ∈∼ . Together with i ∈ δ ( B 1 ) we ﬁnd i , j ∈ δ ( A 1 ⊓ B 1 ) , which would imply ( A 1 ⊓ B 1 ) I = ∅ , using Lemma 3 . Next we show that for f ∈ ϕ ( A 1 ) it must be the case that σ U ∪ V ( f ) = σ U ( f ) . Assume f ∈ F i . If i ∈ src ( U ) then there is some element ( i , j ) ∈ U and σ U ∪ V ( f ) = σ U ( f ) = σ ( i , j ) ( f ) . If i / ∈ src ( U ∪ V ) then we trivially have σ U ∪ V ( f ) = σ U ( f ) = f . Finally , assume that i ∈ src ( V ) \ src ( U ) , then V contains some element ( i , j ) from ∼ such that i ∈ δ ( A 2 ) and j ∈ δ ( B 2 ) , but this would imply ( A 2 ⊓ B 2 ) I = ∅ using Lemma 3 . Similarly , we also ﬁnd that for f ∈ ϕ ( B 1 ) it must be the case that σ U ∪ V ( f ) = σ V ( f ) . It follows that ϕ ( A 2 ⊓ B 2 ) = { σ U ∪ V ( f ) | f ∈ ϕ ( A 1 ⊓ B 1 ) } . Indeed : { σ U ∪ V ( f ) | f ∈ ϕ ( A 1 ⊓ B 1 ) } = { σ U ∪ V ( f ) | f ∈ ϕ ( A 1 ) } ∪ { σ U ∪ V ( f ) | f ∈ ϕ ( B 1 ) } = { σ U ( f ) | f ∈ ϕ ( A 1 ) } ∪ { σ V ( f ) | f ∈ ϕ ( B 1 ) } = ϕ ( A 2 ) ∪ ϕ ( B 2 ) = ϕ ( A 1 ⊓ B 2 ) ❏ Now we return to the main result . From A 1 ⊲A 2 : : A 3 ⊲A 4 and B 1 ⊲B 2 : : B 3 ⊲B 4 we know that there exists some σ U ∈ µ ( A 1 , A 2 ) ∩ µ ( A 3 , A 4 ) and σ V ∈ µ ( B 1 , B 2 ) ∩ µ ( B 3 , B 4 ) . From Lemma 8 we then ﬁnd σ U ∪ V ∈ µ ( A 1 ⊓ B 1 , A 2 ⊓ B 2 ) ∩ µ ( A 3 ⊓ B 2 , A 4 ⊓ B 4 ) , which means that ( A 1 ⊓ B 1 ) ⊲ ( A 2 ⊓ B 2 ) : : ( A 3 ⊓ B 3 ) ⊲ ( A 4 ⊓ B 4 ) is satisﬁed . Proof of Proposition 9 Lemma 9 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a domain constrained interpretation and let r be an intra - domain role . It holds that µ ( A , B ) ⊆ µ ( ∃ r . A , ∃ r . B ) . Proof . Let σ U ∈ µ ( A , B ) . We ﬁrst show that ϕ ( ∃ r . B ) = σ U ( ϕ ( ∃ r . A ) ) . We ﬁnd : σ U ( ϕ ( ∃ r . A ) ) = σ U ( κ r ( ϕ ( A ) ) ) = κ r ( σ U ( ϕ ( A ) ) ) = κ r ( ϕ ( B ) ) = ϕ ( ∃ r . B ) Finally , the fact that src ( U ) ⊆ δ ( ∃ r . A ) and tgt ( U ) ∩ ( δ ( ∃ r . A ) \ src ( U ) ) = ∅ are satisﬁed , follows from the fact that σ U ∈ µ ( A , B ) and the fact that δ ( ∃ r . A ) = δ ( A ) , where the latter follows immediately from the deﬁnition of intra - domain relation . ❏ We now show that ( 18 ) and ( 19 ) hold . Since A⊲B : : C⊲D is satisﬁed , there must exist some σ U ∈ µ ( A , B ) ∩ µ ( C , D ) . From Lemma 9 , we ﬁnd that σ U ∈ µ ( ∃ r . A , ∃ r . B ) ∩ µ ( ∃ r . C , ∃ r . D ) , and thus that ( 18 ) is satisﬁed . Similarly , we also ﬁnd that σ U ∈ µ ( A , B ) ∩ µ ( ∃ r . C , ∃ r . D ) , and thus that ( 19 ) is satisﬁed . Proof of Proposition 10 Assume that I satisﬁes A 1 ⊲B 1 : : A 2 ⊲B 2 and A 1 ⊑ A 2 . We need to show that I satisﬁes B 1 ⊑ B 2 , or equivalently , that ϕ ( B 2 ) ⊆ ϕ ( B 1 ) . Let f ∈ ϕ ( B 2 ) . Since I satis - ﬁes A 1 ⊲B 1 : : A 2 ⊲B 2 there exists some σ U ∈ µ ( A 1 , B 2 ) ∩ µ ( A 2 , B 2 ) . Hence there must be some g ∈ ϕ ( A 2 ) such that σ U ( g ) = f . Since A 1 ⊑ A 2 is satisﬁed , we have g ∈ ϕ ( A 1 ) , which in turn implies that σ U ( g ) ∈ ϕ ( B 1 ) , i . e . f ∈ ϕ ( A 1 ) . Proof of Proposition 11 If A I 4 = ∅ then the conclusion holds trivially . More - over , if A I 3 = ∅ then we have ϕ ( A 3 ) = F , hence from A 1 ⊲A 2 : : A 3 ⊲A 4 we ﬁnd ϕ ( A 4 ) = F and thus A I 4 = ∅ , hence again the conclusion holds trivially . From A I 1 6 = ∅ we sim - ilarly ﬁnd A I 2 6 = ∅ . If B I 4 = ∅ then we also have B I 3 = ∅ , which would imply A I 3 = ∅ and thus also A I 4 = ∅ , meaning that the conclusion is again trivially satisﬁed . The same holds whenever B I 3 = ∅ . Finally , since A I 1 6 = ∅ , it must be the case that A I 2 6 = ∅ , B I 1 6 = ∅ and B I 2 6 = ∅ . In the following , we can thus assume w . l . o . g . that A I i 6 = ∅ and B I i 6 = ∅ for i ∈ { 1 , 2 , 3 , 4 } Suppose that I satisﬁes the stated condition . Let σ U ∈ µ ( A 1 , A 2 ) ∩ µ ( A 3 , A 4 ) , σ U ′ ∈ µ ( A 1 , A 3 ) ∩ µ ( A 2 , A 4 ) , σ V ∈ µ ( B 1 , B 2 ) ∩ µ ( B 3 , B 4 ) and σ V ′ ∈ µ ( B 1 , B 3 ) ∩ µ ( B 2 , B 4 ) . We need to show that I satisﬁes A 4 ⊑ B 4 , which is equiva - lent to ϕ ( B 4 ) ⊆ ϕ ( A 4 ) . Let f ∈ ϕ ( B 4 ) , with f ∈ F i . Then there must be some g ∈ ϕ ( A 3 ) such that σ Y ( g ) = f . • If f = g , then it must be the case that either i ∈ δ ( B 1 ) ∩ δ ( B 2 ) or that i / ∈ δ ( B 1 ) ∪ δ ( B 2 ) . – Suppose i ∈ δ ( B 1 ) ∩ δ ( B 2 ) , then there some h ∈ ϕ ( B 1 ) ∩ ϕ ( B 2 ) ∩ F i . Since A 1 ⊑ B 1 and A 2 ⊑ B 2 are satisﬁed , that means h ∈ ϕ ( A 1 ) ∩ ϕ ( A 2 ) , and in particular i ∈ δ ( A 1 ) ∩ δ ( A 2 ) , which implies i / ∈ src ( U ) . From f ∈ ϕ ( B 3 ) , we ﬁnd f ∈ ϕ ( A 3 ) , since A 3 ⊑ B 3 is satisﬁed , which in turn entails f ∈ ϕ ( A 4 ) since i / ∈ src ( U ) and σ U ∈ µ ( A 3 , A 4 ) . – Suppose i / ∈ δ ( B 1 ) ∪ δ ( B 2 ) . If i / ∈ src ( U ) , we ﬁnd f ∈ ϕ ( A 4 ) as in the previous case . Now suppose i ∈ src ( U ) . Since σ U ′ ∈ µ ( B 1 , B 3 ) there must be some ( j , i ) ∈ U ′ such that j ∈ δ ( B 1 ) . Note that i / ∈ δ ( B 1 ) hence i 6 = j . Since A 1 ⊑ B 1 is satisﬁed , we then also have j ∈ δ ( A 1 ) . However , from i ∈ src ( U ) it follows that i ∈ δ ( A 1 ) . Using Lemma 3 , from i , j ∈ δ ( A 1 ) and i 6 = j we ﬁnd A I 1 = ∅ , which contradicts our assumption that A 1 was non - empty . Hence the case where i ∈ src ( U ) cannot occur . • Now suppose f 6 = g , and let g ∈ F j . Then we have ( j , i ) ∈ U , with i 6 = j , and thus j ∈ δ ( B 1 ) and i ∈ δ ( B 2 ) . Since A 1 ⊑ B 1 , A 2 ⊑ B 2 and A 3 ⊑ B 3 are satisﬁed , we also have j ∈ δ ( A 1 ) ∩ δ ( A 3 ) and i ∈ δ ( A 2 ) . From i 6 = j and Lemma 3 , it follows that i / ∈ δ ( A 1 ) and j / ∈ δ ( A 2 ) . Moreover , by Lemma 3 and the non - emptiness of A 1 , there cannot be any l ∈ δ ( A 1 ) such that l 6 = j and ( l , i ) ∈∼ , as this would also imply ( l , j ) ∈∼ . We thus have that ( j , i ) ∈ U . Given that g ∈ ϕ ( B 3 ) and the fact that A 3 ⊑ B 3 is satisﬁed , we ﬁnd g ∈ ϕ ( A 3 ) . Since ( j , i ) ∈ U and σ U ∈ µ ( A 3 , A 4 ) , it follows that f ∈ ϕ ( A 4 ) . B Counterexamples Counterexamples for Section 3 . 2 The following example shows that rule extrapolation is not valid for analogical proportions . Example 6 . Consider a feature - enriched interpretation I s . t . : ϕ ( A 1 ) = ϕ ( A 2 ) = ϕ ( C 2 ) = ϕ ( C 4 ) = { f } ϕ ( A 3 ) = ϕ ( A 4 ) = ϕ ( C 1 ) = ϕ ( C 3 ) = ∅ Then A 1 : A 2 : : A 3 : A 4 , C 1 : C 2 : : C 3 : C 4 , A 1 ⊑ C 1 , A 2 ⊑ C 2 and A 3 ⊑ C 3 are satisﬁed in I , whereas A 4 ⊑ C 4 is not . The following example shows that from A 1 : B 1 : : C 1 : D 1 and A 2 : B 2 : : C 2 : D 2 , in general we cannot infer ( A 1 ⊓ A 2 ) : ( B 1 ⊓ B 2 ) : : ( C 1 ⊓ C 2 ) : ( D 1 ⊓ D 2 ) . Example 7 . Consider a feature - enriched interpretation I s . t . : ϕ ( A 1 ) = ϕ ( A 2 ) = ϕ ( B 1 ) = ϕ ( C 2 ) = ∅ ϕ ( C 1 ) = ϕ ( D 1 ) = ϕ ( B 2 ) = ϕ ( D 2 ) = { f } Then A 1 : B 1 : : C 1 : D 1 and A 2 : B 2 : : C 2 : D 2 are satisﬁed in I , while ( A 1 ⊓ A 2 ) : ( B 1 ⊓ B 2 ) : : ( C 1 ⊓ C 2 ) : ( D 1 ⊓ D 2 ) is not , since ϕ ( B 1 ⊓ B 2 ) \ ϕ ( A 1 ⊓ A 2 ) = { f } ϕ ( D 1 ⊓ D 2 ) \ ϕ ( C 1 ⊓ C 2 ) = ∅ Counterexamples for Section 4 . 3 We show in the following counterexample that the condition B 1 ⊲B 3 : : B 2 ⊲B 4 in Proposition 11 is indeed required . Example 8 . Let I = ( I , [ F 1 , F 2 ] , X , π , ∼ , S ) be a domain constrained interpretation , where X = { F } and the sets of features F i are deﬁned as follows : F 1 = { f } F 2 = { g } Now consider natural concepts A 1 , A 2 , A 3 , A 4 , B 1 , B 2 , B 3 , B 4 with the following feature assignments : ϕ ( A 1 ) = { f } ϕ ( A 2 ) = { g } ϕ ( A 3 ) = { f } ϕ ( A 4 ) = { g } ϕ ( B 1 ) = ∅ ϕ ( B 2 ) = ∅ ϕ ( B 3 ) = { f } ϕ ( B 4 ) = { f } Furthermore , suppose ∼ = { 1 , 2 } × { 1 , 2 } and σ 12 ( f ) = g . It is easy to verify that , apart from B 1 ⊲B 3 : : B 2 ⊲B 4 , the con - ditions from Proposition 11 ( i . e . the assertions in K ) are all satisﬁed , whereas the conclusion A 4 ⊑ B 4 is not satisﬁed . Counterexamples for Section 4 . 4 The next two examples show that C - transitivity is not satis - ﬁed under the weak semantics , for standard analogy asser - tions and strong analogy assertions respectively . Example 9 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 4 and the sets of features F i are deﬁned as follows : F 1 = { a 1 , a ′ 1 } F 2 = { a 2 , a ′ 2 } F 3 = { a 3 , a ′ 3 } F 4 = { a 4 , a ′ 4 } Now consider natural concepts A 1 , A 2 , A 3 , B 1 , B 2 , B 3 with the following feature assignments : ϕ ( A 1 ) = { a 1 , a 2 } ϕ ( A 2 ) = { a 3 , a 4 } ϕ ( A 3 ) = { a ′ 1 , a ′ 2 } ϕ ( A 4 ) = { a 3 , a 4 } ϕ ( A 5 ) = { a ′ 1 , a ′ 2 } ϕ ( A 6 ) = { a ′ 3 , a ′ 4 } Furthermore , suppose ∼ = { 1 , 2 , 3 , 4 } × { 1 , 2 , 3 , 4 } . The dif - ferent bijections σ ( i , j ) are deﬁned as follows : a 1 ✠✠✠✠ ✠✠ ✺✺✺✺ ✺✺ ✺ a ′ 2 a 3 a ′ 4 ✹✹✹✹✹✹ ✡✡✡✡✡✡ a 2 ✠✠✠✠ ✠✠ ✺✺✺✺ ✺✺ ✺ a ′ 1 a 4 a ′ 3 ✹✹✹✹✹✹ ✡✡✡✡✡✡ In these diagrams , features from different domains F i and F j are connected if they are mapped to each other by the corre - sponding bijections σ ( i , j ) and σ ( j , i ) . For instance , according to these diagrams , we have σ ( 1 , 4 ) ( a 1 ) = a ′ 4 . We have that µ ( A 1 , A 2 ) = { σ { ( 1 , 3 ) , ( 2 , 4 ) } } µ ( A 2 , A 3 ) = { σ { ( 3 , 2 ) , ( 4 , 1 ) } } µ ( A 4 , A 5 ) = { σ { ( 3 , 2 ) , ( 4 , 1 ) } } µ ( A 5 , A 6 ) = { σ { ( 1 , 3 ) , ( 2 , 4 ) } } from which we ﬁnd that A 2 ⊲A 3 : : A 4 ⊲A 5 and A 1 ⊲A 2 : : A 5 ⊲A 6 are satisﬁed . On the other hand , we have : µ ( A 1 , A 3 ) = { σ { ( 1 , 2 ) , ( 2 , 1 ) } } µ ( A 4 , A 6 ) = { σ { ( 3 , 4 ) , ( 4 , 3 ) } } meaning that A 1 ⊲A 3 : : A 4 ⊲A 6 is not satisﬁed . Example 10 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 4 and the sets of features F i are deﬁned as follows : F 1 = { a 1 } F 2 = { b 1 } F 3 = { a 2 } F 4 = { b 2 } Now consider natural concepts A 1 , A 2 , A 3 , A 4 , A 5 , A 6 with the following feature assignments : ϕ ( A 1 ) = { a 1 , a 2 } ϕ ( A 2 ) = { b 1 , b 2 } ϕ ( A 3 ) = { a 1 , a 2 } ϕ ( A 4 ) = { b 1 , b 2 } ϕ ( A 5 ) = { a 1 , a 2 } ϕ ( A 6 ) = { b 1 , b 2 } Furthermore , suppose ∼ = { 1 , 2 , 3 , 4 } × { 1 , 2 , 3 , 4 } . The dif - ferent bijections σ ( i , j ) are uniquely deﬁned , given that the do - mains are singletons , e . g . we have σ ( 1 , 2 ) ( a 1 ) = b 1 . Then clearly we have that A 2 ◮ A 3 : : B 1 ◮ B 2 and A 1 ◮ A 2 : : A 5 ◮ A 6 are satisﬁed , but A 1 ◮ A 3 : : A 4 ◮ A 6 is not , as µ ( A 1 , A 3 ) = { σ ∅ , σ { ( 1 , 3 ) , ( 3 , 1 ) } } µ ( B 1 , B 3 ) = { σ ∅ , σ { ( 2 , 4 ) , ( 4 , 2 ) } } Next , we show that ( 16 ) is no longer valid for standard anal - ogy assertions . Example 11 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 4 and the sets of features F i are deﬁned as follows : F 1 = { a 1 , b 1 , c 1 , d 1 , e 1 } F 2 = { a 2 , b 2 , c 2 , d 2 , e 2 } F 3 = { a 3 , b 3 , c 3 , d 3 , e 3 } F 4 = { a 4 , b 4 , c 4 , d 4 , e 4 } Now consider natural concepts A 1 , A 2 , B 1 , B 2 , C 1 , C 2 with the following feature assignments : ϕ ( A 1 ) = { a 1 , a 2 } ϕ ( A 2 ) = { a 3 , a 4 } ϕ ( B 1 ) = { b 1 , b 2 } ϕ ( B 2 ) = { b 3 , b 4 } ϕ ( C 1 ) = { c 1 , c 2 } ϕ ( C 2 ) = { c 3 , c 4 } Furthermore , suppose ∼ = { 1 , 2 , 3 , 4 } × { 1 , 2 , 3 , 4 } . The dif - ferent bijections σ ( i , j ) are deﬁned by the following diagrams : a 1 ✠✠✠✠✠✠ ✺✺✺✺✺✺ d 2 d 4 a 3 ✺✺✺✺✺✺✺ ✠✠✠✠✠✠✠ d 1 ✠✠✠✠✠✠✠ ✺✺✺✺✺✺✺ a 2 a 4 d 3 ✺✺✺✺✺✺ ✠✠✠✠✠✠ b 1 ✡✡✡✡✡✡ ✹✹✹✹✹✹ b 2 b 4 b 3 ✹✹✹✹✹✹ ✡✡✡✡✡✡ c 1 ✠✠✠✠✠✠ ✺✺✺✺✺✺ e 2 c 4 e 3 ✺✺✺✺✺✺ ✠✠✠✠✠✠ e 1 ✠✠✠✠✠✠ ✺✺✺✺✺✺ c 2 e 4 c 3 ✺✺✺✺✺✺ ✠✠✠✠✠✠ It can now readily be veriﬁed that this interpretation satisﬁes A 1 ⊲A 2 : : B 1 ⊲B 2 , which is witnessed by the domain transla - tion σ { ( 1 , 3 ) , ( 2 , 4 ) } , and that this interpretation also satisﬁes B 1 ⊲B 2 : : C 1 ⊲C 2 , which is witnessed by the domain transla - tion σ { ( 1 , 4 ) , ( 2 , 3 ) } . But there is no domain translation that can witness A 1 ⊲A 2 : : C 1 ⊲C 2 . Next we show that Proposition 9 is not valid for strong anal - ogy assertions . Example 12 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 4 and the sets of features F i are deﬁned as follows : F 1 = { a 1 , b 1 , c 1 , d 1 , e 1 } F 2 = { a 2 , b 2 , c 2 , d 2 , e 2 } F 3 = { a 3 , b 3 , c 3 , d 3 , e 3 } F 4 = { a 4 , b 4 , c 4 , d 4 , e 4 } Now consider natural concepts A 1 , A 2 , B 1 , B 2 with the fol - lowing feature assignments : ϕ ( A 1 ) = { a 1 , a 2 } ϕ ( A 2 ) = { a 3 , a 4 } ϕ ( B 1 ) = { b 1 , b 2 } ϕ ( B 2 ) = { b 3 , b 4 } Furthermore , let κ r be deﬁned such that κ r ( A 1 ) = { c 1 , c 2 } κ r ( A 2 ) = { c 3 , c 4 } κ r ( B 1 ) = { d 1 , d 2 } κ r ( B 2 ) = { d 3 , d 4 } Furthermore , suppose ∼ = { 1 , 2 , 3 , 4 } × { 1 , 2 , 3 , 4 } . The dif - ferent bijections σ ( i , j ) are deﬁned as follows : a 1 ✟✟✟✟✟✟ ✻✻✻✻✻✻ a 2 a 3 a 4 ✻✻✻✻✻✻ ✟✟✟✟✟✟ b 1 ✡✡✡✡✡✡ ✹✹✹✹✹✹ b 2 b 3 b 4 ✹✹✹✹✹✹ ✡✡✡✡✡✡ c 1 ✠✠✠✠✠✠ ✺✺✺✺✺✺ c 2 c 3 c 4 ✺✺✺✺✺✺ ✠✠✠✠✠✠ d 1 ✡✡✡✡✡✡✡ ✹✹✹✹✹✹ e 2 d 3 e 4 ✺✺✺✺✺✺✺ ✠✠✠✠✠✠✠ e 1 ✠✠✠✠✠✠ ✺✺✺✺✺✺✺ d 2 e 3 d 4 ✹ ✹✹✹✹✹ ✡✡✡✡✡✡ Then we have that µ ( A 1 , A 2 ) = µ ( B 1 , B 2 ) = { σ { ( 1 , 3 ) , ( 2 , 4 ) } , σ { ( 1 , 4 ) , ( 2 , 3 ) } } µ ( ∃ r . A 1 , ∃ r . A 2 ) = { σ { ( 1 , 3 ) , ( 2 , 4 ) } , σ { ( 1 , 4 ) , ( 2 , 3 ) } } µ ( ∃ r . B 1 , ∃ r . B 2 ) = { σ { ( 1 , 3 ) , ( 2 , 4 ) } } from which we ﬁnd that A 1 ◮ A 2 : : B 1 ◮ B 1 is satis - ﬁed while ( ∃ r . A 1 ) ◮ ( ∃ r . A 2 ) : : ( ∃ r . B 1 ) ◮ ( ∃ r . B 2 ) and A 1 ◮ A 2 : : ( ∃ r . B 1 ) ◮ ( ∃ r . B 2 ) are not . The next example clariﬁes why Proposition 8 is not satisﬁed under the weak semantics , neither for standard nor for strong analogy assertions . Example 13 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 2 and the sets of features F i are deﬁned as follows : F 1 = { f } F 2 = { g } Now consider natural concepts A 1 , A 2 , A 3 , A 4 , B 1 , B 2 , B 3 , B 4 with the following feature assignments : ϕ ( A 1 ) = { f } ϕ ( A 2 ) = { g } ϕ ( A 3 ) = { f } ϕ ( A 4 ) = { g } ϕ ( B 1 ) = { f } ϕ ( B 2 ) = { f } ϕ ( B 3 ) = { f } ϕ ( B 4 ) = { f } Let ∼ = { 1 , 2 } × { 1 , 2 } and σ ( 1 , 2 ) ( f ) = g . Then it is clear that A 1 ⊲A 2 : : A 3 ⊲A 4 , B 1 ⊲B 2 : : B 3 ⊲B 4 , A 1 ◮ A 2 : : A 3 ◮ A 4 and B 1 ◮ B 2 : : B 3 ◮ B 4 are all satisﬁed , while ( A 1 ⊓ B 1 ) ⊲ ( A 2 ⊓ B 2 ) : : ( A 3 ⊓ B 3 ) ⊲ ( A 4 ⊓ B 4 ) and ( A 1 ⊓ B 1 ) ◮ ( A 2 ⊓ B 2 ) : : ( A 3 ⊓ B 3 ) ◮ ( A 4 ⊓ B 4 ) are not . Finally we show that ( 11 ) is not satisﬁed under the weak se - mantics . Example 14 . Let I = ( I , [ F 1 , . . . , F k ] , X , π , ∼ , S ) be a weak domain constrained interpretation , where X = { F } , k = 2 and the sets of features F i are deﬁned as follows : F 1 = { f } F 2 = { g } Now consider natural concepts A 1 , A 2 , A 3 , A 4 , B 1 , B 2 , B 3 , B 4 with the following feature assignments : ϕ ( A 1 ) = { f , g } ϕ ( A 2 ) = { f , g } ϕ ( A 3 ) = { f } ϕ ( A 4 ) = { f } ϕ ( B 1 ) = { f } ϕ ( B 2 ) = { g } ϕ ( B 3 ) = { f } ϕ ( B 4 ) = { g } Let ∼ = { 1 , 2 } × { 1 , 2 } and σ ( 1 , 2 ) ( f ) = g . Then it is clear that A 1 ⊲A 2 : : A 3 ⊲A 4 , B 1 ⊲B 2 : : B 3 ⊲B 4 , B 1 ⊲B 3 : : B 2 ⊲B 4 , A 1 ◮ A 2 : : A 3 ◮ A 4 , B 1 ◮ B 2 : : B 3 ◮ B 4 and B 1 ◮ B 3 : : B 2 ◮ B 4 are all satisﬁed , as well as A 1 ⊑ B 1 , A 2 ⊑ B 2 and A 3 ⊑ B 3 . However , A 4 ⊑ B 4 is not satisﬁed . References [ Baader et al . , 2017 ] Franz Baader , Ian Horrocks , Carsten Lutz , and Ulrike Sattler . An Introduction to Description Logic . Cambridge University Press , 2017 . [ Balazevic et al . , 2019 ] Ivana Balazevic , Carl Allen , and Timothy M . Hospedales . Tucker : Tensor factorization for knowledge graph completion . In Proceedings EMNLP , pages 5184 – 5193 , 2019 . [ Barbot et al . , 2019 ] Nelly Barbot , Laurent Miclet , and Henri Prade . Analogy between concepts . Artiﬁcial In - telligence , 275 : 487 – 539 , 2019 . [ Bayoudh et al . , 2007 ] Sabri Bayoudh , Laurent Miclet , and Arnaud Delhay . Learning by analogy : A classiﬁcation rule for binary and nominal data . In Proceedings IJCAI , pages 678 – 683 , 2007 . [ Beltagy et al . , 2013 ] Islam Beltagy , Cuong Chau , Gemma Boleda , Dan Garrette , Katrin Erk , and Raymond Mooney . Montague meets Markov : Deep semantics with probabilis - tic logical form . In Proceedings of * SEM , pages 11 – 21 , 2013 . [ Bordes et al . , 2013 ] A . Bordes , N . Usunier , A . Garcia - Duran , J . Weston , and O . Yakhnenko . Translating embed - dings for modeling multi - relational data . In Proc . of NIPS , pages 2787 – 2795 . 2013 . [ Bouraoui and Schockaert , 2019 ] Zied Bouraoui and Steven Schockaert . Automated rule base completion as bayesian concept induction . In Proceedings AAAI , pages 6228 – 6235 , 2019 . [ Brown et al . , 2020 ] Tom B . Brown , Benjamin Mann , et al . Language models are few - shot learners . In Proceedings NeurIPS , 2020 . [ d’Amato et al . , 2006 ] Claudia d’Amato , Nicola Fanizzi , and Floriana Esposito . Analogical reasoning in descrip - tion logics . In Proceedings of the Second ISWC Workshop on Uncertainty Reasoning for the Semantic Web , 2006 . [ Gentner , 1983 ] Dedre Gentner . Structure - mapping : A theoretical framework for analogy . Cognitive science , 7 ( 2 ) : 155 – 170 , 1983 . [ Hofstadter et al . , 1995 ] Douglas R Hofstadter , Melanie Mitchell , et al . The copycat project : A model of mental ﬂuidity and analogy - making . Advances in Connectionist and Neural Computation Theory , 2 : 205 – 267 , 1995 . [ Holyoak and Thagard , 1997 ] Keith J Holyoak and Paul Thagard . The analogical mind . American psychologist , 52 ( 1 ) : 35 – 44 , 1997 . [ Hug et al . , 2016 ] Nicolas Hug , Henri Prade , Gilles Richard , and Mathieu Serrurier . Analogical classiﬁers : A theoret - ical perspective . In Proceedings ECAI , pages 689 – 697 , 2016 . [ Ib´a˜nez - Garc´ıa et al . , 2020 ] Yazm´ın Ib´a˜nez - Garc´ıa , V´ıctor Guti´errez - Basulto , and Steven Schockaert . Plausible rea - soning about el - ontologies using concept interpolation . In Proceedings KR , pages 506 – 516 , 2020 . [ Medina et al . , 2004 ] Jes´us Medina , Manuel Ojeda - Aciego , and Peter Vojt´as . Similarity - based uniﬁcation : a multi - adjoint approach . Fuzzy Sets and Systems , 146 ( 1 ) : 43 – 62 , 2004 . [ Mikolov et al . , 2013 ] Tomas Mikolov , Wen - tau Yih , and Geoffrey Zweig . Linguistic regularities in continuous space word representations . In Proceedings NAACL - HLT , pages 746 – 751 , 2013 . [ Prade and Richard , 2013 ] Henri Prade and Gilles Richard . From analogical proportion to logical proportions . Logica Universalis , 7 ( 4 ) : 441 – 505 , 2013 . [ Prade and Richard , 2014 ] Henri Prade and Gilles Richard . From analogical proportion to logical proportions : A sur - vey . In Computational Approaches to Analogical Reason - ing : Current Trends , pages 217 – 244 . 2014 . [ Rockt¨aschel and Riedel , 2017 ] Tim Rockt¨aschel and Sebas - tian Riedel . End - to - end differentiable proving . In Proc . NIPS , pages 3791 – 3803 , 2017 . [ Trouillon et al . , 2017 ] Th´eo Trouillon , Christopher R . Dance , ´Eric Gaussier , Johannes Welbl , Sebastian Riedel , and Guillaume Bouchard . Knowledge graph completion via complex tensor factorization . J . Mach . Learn . Res . , 18 : 130 : 1 – 130 : 38 , 2017 . [ Turney , 2006 ] Peter D . Turney . Similarity of semantic rela - tions . Comput . Linguistics , 32 ( 3 ) : 379 – 416 , 2006 . [ Tversky , 1977 ] Amos Tversky . Features of similarity . Psy - chological Review , 84 ( 4 ) : 327 – 352 , 1977 . [ Yang et al . , 2015 ] Bishan Yang , Wen - tau Yih , Xiaodong He , Jianfeng Gao , and Li Deng . Embedding entities and relations for learning and inference in knowledge bases . In Proceedings ICLR , 2015 .