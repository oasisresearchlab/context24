Graph Convolution over Pruned Dependency Trees Improves Relation Extraction Yuhao Zhang , * Peng Qi , * Christopher D . Manning Stanford University Stanford , CA 94305 { yuhaozhang , pengqi , manning } @ stanford . edu Abstract Dependency trees help relation extraction models capture long - range relations between words . However , existing dependency - based models either neglect crucial information ( e . g . , negation ) by pruning the dependency trees too aggressively , or are computationally inef - ﬁcient because it is difﬁcult to parallelize over different tree structures . We propose an ex - tension of graph convolutional networks that is tailored for relation extraction , which pools information over arbitrary dependency struc - tures efﬁciently in parallel . To incorporate rel - evant information while maximally removing irrelevant content , we further apply a novel pruning strategy to the input trees by keeping words immediately around the shortest path between the two entities among which a rela - tion might hold . The resulting model achieves state - of - the - art performance on the large - scale TACRED dataset , outperforming existing se - quence and dependency - based neural models . We also show through detailed analysis that this model has complementary strengths to se - quence models , and combining them further improves the state of the art . 1 Introduction Relation extraction involves discerning whether a relation exists between two entities in a sentence ( often termed subject and object , respectively ) . Successful relation extraction is the cornerstone of applications requiring relational understanding of unstructured text on a large scale , such as ques - tion answering ( Yu et al . , 2017 ) , knowledge base population ( Zhang et al . , 2017 ) , and biomedical knowledge discovery ( Quirk and Poon , 2017 ) . Models making use of dependency parses of the input sentences , or dependency - based models , ∗ Equal contribution . The order of authorship was decided by a tossed coin . I had an e - mail exchange with Benjamin Cane of Popular Mechanics which showed that he was not a relative of Mike Cane . relative that a Cane Mike of he was not … Prediction from dependency path : per : other _ family Gold label : no _ relation Figure 1 : An example modiﬁed from the TAC KBP challenge corpus . A subtree of the original UD de - pendency tree between the subject ( “he” ) and object ( “Mike Cane” ) is also shown , where the shortest depen - dency path between the entities is highlighted in bold . Note that negation ( “not” ) is off the dependency path . have proven to be very effective in relation ex - traction , because they capture long - range syntac - tic relations that are obscure from the surface form alone ( e . g . , when long clauses or complex scop - ing are present ) . Traditional feature - based models are able to represent dependency information by featurizing dependency trees as overlapping paths along the trees ( Kambhatla , 2004 ) . However , these models face the challenge of sparse feature spaces and are brittle to lexical variations . More re - cent neural models address this problem with dis - tributed representations built from their computa - tion graphs formed along parse trees . One com - mon approach to leverage dependency information is to perform bottom - up or top - down computation along the parse tree or the subtree below the low - est common ancestor ( LCA ) of the entities ( Miwa and Bansal , 2016 ) . Another popular approach , in - spired by Bunescu and Mooney ( 2005 ) , is to re - duce the parse tree to the shortest dependency path between the entities ( Xu et al . , 2015a , b ) . However , these models suffer from several a r X i v : 1809 . 10185v1 [ c s . C L ] 26 S e p 2018 drawbacks . Neural models operating directly on parse trees are usually difﬁcult to parallelize and thus computationally inefﬁcient , because aligning trees for efﬁcient batch training is usually non - trivial . Models based on the shortest dependency path between the subject and object are compu - tationally more efﬁcient , but this simplifying as - sumption has major limitations as well . Figure 1 shows a real - world example where crucial infor - mation ( i . e . , negation ) would be excluded when the model is restricted to only considering the de - pendency path . In this work , we propose a novel extension of the graph convolutional network ( Kipf and Welling , 2017 ; Marcheggiani and Titov , 2017 ) that is tailored for relation extraction . Our model encodes the dependency structure over the input sentence with efﬁcient graph convolution opera - tions , then extracts entity - centric representations to make robust relation predictions . We also ap - ply a novel path - centric pruning technique to re - move irrelevant information from the tree while maximally keeping relevant content , which further improves the performance of several dependency - based models including ours . We test our model on the popular SemEval 2010 Task 8 dataset and the more recent , larger TAC - RED dataset . On both datasets , our model not only outperforms existing dependency - based neu - ral models by a signiﬁcant margin when combined with the new pruning technique , but also achieves a 10 – 100x speedup over existing tree - based mod - els . On TACRED , our model further achieves the state - of - the - art performance , surpassing a compet - itive neural sequence model baseline . This model also exhibits complementary strengths to sequence models on TACRED , and combining these two model types through simple prediction interpola - tion further improves the state of the art . To recap , our main contributions are : ( i ) we pro - pose a neural model for relation extraction based on graph convolutional networks , which allows it to efﬁciently pool information over arbitrary de - pendency structures ; ( ii ) we present a new path - centric pruning technique to help dependency - based models maximally remove irrelevant infor - mation without damaging crucial content to im - prove their robustness ; ( iii ) we present detailed analysis on the model and the pruning technique , and show that dependency - based models have complementary strengths with sequence models . 2 Models In this section , we ﬁrst describe graph convo - lutional networks ( GCNs ) over dependency tree structures , and then we introduce an architecture that uses GCNs at its core for relation extraction . 2 . 1 Graph Convolutional Networks over Dependency Trees The graph convolutional network ( Kipf and Welling , 2017 ) is an adaptation of the convolu - tional neural network ( LeCun et al . , 1998 ) for en - coding graphs . Given a graph with n nodes , we can represent the graph structure with an n × n adjacency matrix A where A ij = 1 if there is an edge going from node i to node j . In an L - layer GCN , if we denote by h ( l − 1 ) i the input vector and h ( l ) i the output vector of node i at the l - th layer , a graph convolution operation can be written as h ( l ) i = σ (cid:0) n (cid:88) j = 1 A ij W ( l ) h ( l − 1 ) j + b ( l ) (cid:1) , ( 1 ) where W ( l ) is a linear transformation , b ( l ) a bias term , and σ a nonlinear function ( e . g . , ReLU ) . Intuitively , during each graph convolution , each node gathers and summarizes information from its neighboring nodes in the graph . We adapt the graph convolution operation to model dependency trees by converting each tree into its corresponding adjacency matrix A , where A ij = 1 if there is a dependency edge between to - kens i and j . However , naively applying the graph convolution operation in Equation ( 1 ) could lead to node representations with drastically different magnitudes , since the degree of a token varies a lot . This could bias our sentence representation towards favoring high - degree nodes regardless of the information carried in the node ( see details in Section 2 . 2 ) . Furthermore , the information in h ( l − 1 ) i is never carried over to h ( l ) i , since nodes never connect to themselves in a dependency tree . We resolve these issues by normalizing the acti - vations in the graph convolution before feeding it through the nonlinearity , and adding self - loops to each node in the graph : h ( l ) i = σ (cid:0) n (cid:88) j = 1 ˜ A ij W ( l ) h ( l − 1 ) j / d i + b ( l ) (cid:1) , ( 2 ) where ˜ A = A + I with I being the n × n identity matrix , and d i = (cid:80) nj = 1 ˜ A ij is the degree of token i in the resulting graph . He was not a relative of Mike Cane GCN He was not a relative of Mike Cane f f f Concatenation Pooling GCN Output GCN Input h sent h s h o h ( l   1 ) h ( l ) h ( 0 ) h ( L ) Figure 2 : Relation extraction with a graph convolutional network . The left side shows the overall architecture , while on the right side , we only show the detailed graph convolution computation for the word “relative” for clarity . A full unlabeled dependency parse of the sentence is also provided for reference . Stacking this operation over L layers gives us a deep GCN network , where we set h ( 0 ) 1 , . . . , h ( 0 ) n to be input word vectors , and use h ( L ) 1 , . . . , h ( L ) n as output word representations . All operations in this network can be efﬁciently implemented with ma - trix multiplications , making it ideal for batching computation over examples and running on GPUs . Moreover , the propagation of information between tokens occurs in parallel , and the runtime does not depend on the depth of the dependency tree . Note that the GCN model presented above uses the same parameters for all edges in the depen - dency graph . We also experimented with : ( 1 ) us - ing different transformation matrices W for top - down , bottom - up , and self - loop edges ; and ( 2 ) adding dependency relation - speciﬁc parameters for edge - wise gating , similar to ( Marcheggiani and Titov , 2017 ) . We found that modeling directions does not lead to improvement , 1 and adding edge - wise gating further hurts performance . We hypoth - esize that this is because the presented GCN model is usually already able to capture dependency edge patterns that are informative for classifying rela - tions , and modeling edge directions and types does not offer additional discriminative power to the network before it leads to overﬁtting . For exam - ple , the relations entailed by “ A ’s son , B ” and “ B ’s son , A ” can be readily distinguished with “’s” at - tached to different entities , even when edge direc - tionality is not considered . 1 We therefore treat the dependency graph as undirected , i . e . ∀ i , j , A ij = A ji . 2 . 2 Encoding Relations with GCN We now formally deﬁne the task of relation ex - traction . Let X = [ x 1 , . . . , x n ] denote a sentence , where x i is the i th token . A subject entity and an object entity are identiﬁed and correspond to two spans in the sentence : X s = [ x s 1 , . . . , x s 2 ] and X o = [ x o 1 , . . . , x o 2 ] . Given X , X s , and X o , the goal of relation extraction is to predict a relation r ∈ R ( a predeﬁned relation set ) that holds be - tween the entities or “no relation” otherwise . After applying an L - layer GCN over word vec - tors , we obtain hidden representations of each to - ken that are directly inﬂuenced by its neighbors no more than L edges apart in the dependency tree . To make use of these word representations for re - lation extraction , we ﬁrst obtain a sentence repre - sentation as follows ( see also Figure 2 left ) : h sent = f (cid:0) h ( L ) (cid:1) = f (cid:0) GCN ( h ( 0 ) ) (cid:1) , ( 3 ) where h ( l ) denotes the collective hidden represen - tations at layer l of the GCN , and f : R d × n → R d is a max pooling function that maps from n output vectors to the sentence vector . We also observe that information close to entity tokens in the dependency tree is often central to relation classiﬁcation . Therefore , we also obtain a subject representation h s from h ( L ) as follows h s = f (cid:0) h ( L ) s 1 : s 2 (cid:1) , ( 4 ) as well as an object representation h o similarly . Inspired by recent work on relational learning between entities ( Santoro et al . , 2017 ; Lee et al . , 2017 ) , we obtain the ﬁnal representation used for classiﬁcation by concatenating the sentence and the entity representations , and feeding them through a feed - forward neural network ( FFNN ) : h ﬁnal = FFNN (cid:0) [ h sent ; h s ; h o ] (cid:1) . ( 5 ) This h ﬁnal representation is then fed into a linear layer followed by a softmax operation to obtain a probability distribution over relations . 2 . 3 Contextualized GCN The network architecture introduced so far learns effective representations for relation extraction , but it also leaves a few issues inadequately ad - dressed . First , the input word vectors do not con - tain contextual information about word order or disambiguation . Second , the GCN highly depends on a correct parse tree to extract crucial informa - tion from the sentence ( especially when pruning is performed ) , while existing parsing algorithms produce imperfect trees in many cases . To resolve these issues , we further apply a Con - textualized GCN ( C - GCN ) model , where the input word vectors are ﬁrst fed into a bi - directional long short - term memory ( LSTM ) network to gener - ate contextualized representations , which are then used as h ( 0 ) in the original model . This BiL - STM contextualization layer is trained jointly with the rest of the network . We show empirically in Section 5 that this augmentation substantially im - proves the performance over the original model . We note that this relation extraction model is conceptually similar to graph kernel - based mod - els ( Zelenko et al . , 2003 ) , in that it aims to utilize local dependency tree patterns to inform relation classiﬁcation . Our model also incorporates crucial off - path information , which greatly improves its robustness compared to shortest dependency path - based approaches . Compared to tree - structured models ( e . g . , Tree - LSTM ( Tai et al . , 2015 ) ) , it not only is able to capture more global informa - tion through the use of pooling functions , but also achieves substantial speedup by not requiring re - cursive operations that are difﬁcult to parallelize . For example , we observe that on a Titan Xp GPU , training a Tree - LSTM model over a minibatch of 50 examples takes 6 . 54 seconds on average , while training the original GCN model takes only 0 . 07 seconds , and the C - GCN model 0 . 08 seconds . 3 Incorporating Off - path Information with Path - centric Pruning Dependency trees provide rich structures that one can exploit in relation extraction , but most of the information pertinent to relations is usually con - tained within the subtree rooted at the lowest com - mon ancestor ( LCA ) of the two entities . Previous studies ( Xu et al . , 2015b ; Miwa and Bansal , 2016 ) have shown that removing tokens outside this scope helps relation extraction by eliminating ir - relevant information from the sentence . It is there - fore desirable to combine our GCN models with tree pruning strategies to further improve perfor - mance . However , pruning too aggressively ( e . g . , keeping only the dependency path ) could lead to loss of crucial information and conversely hurt ro - bustness . For instance , the negation in Figure 1 is neglected when a model is restricted to only look - ing at the dependency path between the entities . Similarly , in the sentence “ She was diagnosed with cancer last year , and succumbed this June ” , the dependency path She ← diagnosed → cancer is not sufﬁcient to establish that cancer is the cause of death for the subject unless the conjunction depen - dency to succumbed is also present . Motivated by these observations , we propose path - centric pruning , a novel technique to incor - porate information off the dependency path . This is achieved by including tokens that are up to dis - tance K away from the dependency path in the LCA subtree . K = 0 , corresponds to pruning the tree down to the path , K = 1 keeps all nodes that are directly attached to the path , and K = ∞ retains the entire LCA subtree . We combine this pruning strategy with our GCN model , by directly feeding the pruned trees into the graph convolu - tional layers . 2 We show that pruning with K = 1 achieves the best balance between including rele - vant information ( e . g . , negation and conjunction ) and keeping irrelevant content out of the resulting pruned tree as much as possible . 4 Related Work At the core of fully - supervised and distantly - supervised relation extraction approaches are sta - tistical classiﬁers , many of which ﬁnd syntac - tic information beneﬁcial . For example , Mintz et al . ( 2009 ) explored adding syntactic features to a statistical classiﬁer and found them to be use - ful when sentences are long . Various kernel - based approaches also leverage syntactic information to measure similarity between training and test ex - amples to predict the relation , ﬁnding that tree - 2 For our C - GCN model , the LSTM layer still operates on the full sentence regardless of the pruning . based kernels ( Zelenko et al . , 2003 ) and depen - dency path - based kernels ( Bunescu and Mooney , 2005 ) are effective for this task . Recent studies have found neural models ef - fective in relation extraction . Zeng et al . ( 2014 ) ﬁrst applied a one - dimensional convolutional neu - ral network ( CNN ) with manual features to encode relations . Vu et al . ( 2016 ) showed that combin - ing a CNN with a recurrent neural network ( RNN ) through a voting scheme can further improve per - formance . Zhou et al . ( 2016 ) and Wang et al . ( 2016 ) proposed to use attention mechanisms over RNN and CNN architectures for this task . Apart from neural models over word sequences , incorporating dependency trees into neural models has also been shown to improve relation extrac - tion performance by capturing long - distance rela - tions . Xu et al . ( 2015b ) generalized the idea of de - pendency path kernels by applying a LSTM net - work over the shortest dependency path between entities . Liu et al . ( 2015 ) ﬁrst applied a recur - sive network over the subtrees rooted at the words on the dependency path and then applied a CNN over the path . Miwa and Bansal ( 2016 ) applied a Tree - LSTM ( Tai et al . , 2015 ) , a generalized form of LSTM over dependency trees , in a joint entity and relation extraction setting . They found it to be most effective when applied to the subtree rooted at the LCA of the two entities . More recently , Adel et al . ( 2016 ) and Zhang et al . ( 2017 ) have shown that relatively simple neural models ( CNN and augmented LSTM , re - spectively ) can achieve comparable or superior performance to dependency - based models when trained on larger datasets . In this paper , we study dependency - based models in depth and show that with a properly designed architecture , they can outperform and have complementary advantages to sequence models , even in a large - scale setting . Finally , we note that a technique similar to path - centric pruning has been applied to reduce the space of possible arguments in semantic role la - beling ( He et al . , 2018 ) . The authors showed prun - ing words too far away from the path between the predicate and the root to be beneﬁcial , but reported the best pruning distance to be 10 , which almost always retains the entire tree . Our method differs in that it is applied to the shortest dependency path between entities , and we show that in our tech - nique the best pruning distance is 1 for several dependency - based relation extraction models . 5 Experiments 5 . 1 Baseline Models We compare our models with several competitive dependency - based and neural sequence models . Dependency - based models . In our main ex - periments we compare with three types of dependency - based models . ( 1 ) A logistic regres - sion ( LR ) classiﬁer which combines dependency - based features with other lexical features . ( 2 ) Shortest Dependency Path LSTM ( SDP - LSTM ) ( Xu et al . , 2015b ) , which applies a neural sequence model on the shortest path between the subject and object entities in the dependency tree . ( 3 ) Tree - LSTM ( Tai et al . , 2015 ) , which is a recursive model that generalizes the LSTM to arbitrary tree structures . We investigate the child - sum variant of Tree - LSTM , and apply it to the dependency tree ( or part of it ) . In practice , we ﬁnd that modifying this model by concatenating dependency label em - beddings to the input of forget gates improves its performance on relation extraction , and therefore use this variant in our experiments . Earlier , our group compared ( 1 ) and ( 2 ) with sequence models ( Zhang et al . , 2017 ) , and we report these results ; for ( 3 ) we report results with our own implemen - tation . Neural sequence model . Our group presented a competitive sequence model that employs a position - aware attention mechanism over LSTM outputs ( PA - LSTM ) , and showed that it outper - forms several CNN and dependency - based models by a substantial margin ( Zhang et al . , 2017 ) . We compare with this strong baseline , and use its open implementation in further analysis . 3 5 . 2 Experimental Setup We conduct experiments on two relation extrac - tion datasets : ( 1 ) TACRED : Introduced in ( Zhang et al . , 2017 ) , TACRED contains over 106k men - tion pairs drawn from the yearly TAC KBP 4 chal - lenge . It represents 41 relation types and a spe - cial no relation class when the mention pair does not have a relation between them within these cat - egories . Mentions in TACRED are typed , with subjects categorized into person and organization , and objects into 16 ﬁne - grained types ( e . g . , date and location ) . We report micro - averaged F 1 scores on this dataset as is conventional . ( 2 ) SemEval 3 https : / / github . com / yuhaozhang / tacred - relation 4 https : / / tac . nist . gov / 2017 / KBP / index . html System P R F 1 LR † ( Zhang + 2017 ) 73 . 5 49 . 9 59 . 4 SDP - LSTM † ( Xu + 2015b ) 66 . 3 52 . 7 58 . 7 Tree - LSTM ‡ ( Tai + 2015 ) 66 . 0 59 . 2 62 . 4 PA - LSTM † ( Zhang + 2017 ) 65 . 7 64 . 5 65 . 1 GCN 69 . 8 59 . 0 64 . 0 C - GCN 69 . 9 63 . 3 66 . 4 ∗ GCN + PA - LSTM 71 . 7 63 . 0 67 . 1 ∗ C - GCN + PA - LSTM 71 . 3 65 . 4 68 . 2 ∗ Table 1 : Results on TACRED . Underscore marks high - est number among single models ; bold marks highest among all . † marks results reported in ( Zhang et al . , 2017 ) ; ‡ marks results produced with our implemen - tation . ∗ marks statistically signiﬁcant improvements over PA - LSTM with p < . 01 under a bootstrap test . 2010 Task 8 : The SemEval dataset is widely used in recent work , but is signiﬁcantly smaller with 8 , 000 examples for training and 2 , 717 for testing . It contains 19 relation classes over untyped men - tion pairs : 9 directed relations and a special Other class . On SemEval , we follow the convention and report the ofﬁcial macro - averaged F 1 scores . For fair comparisons on the TACRED dataset , we follow the evaluation protocol used in ( Zhang et al . , 2017 ) by selecting the model with the me - dian dev F 1 from 5 independent runs and report - ing its test F 1 . We also use the same “entity mask” strategy where we replace each subject ( and ob - ject similarly ) entity with a special SUBJ - < NER > token . For all models , we also adopt the “multi - channel” strategy by concatenating the input word embeddings with POS and NER embeddings . Traditionally , evaluation on SemEval is con - ducted without entity mentions masked . However , as we will discuss in Section 6 . 4 , this method en - courages models to overﬁt to these mentions and fails to test their actual ability to generalize . We therefore report results with two evaluation proto - cols : ( 1 ) with - mention , where mentions are kept for comparison with previous work ; and ( 2 ) mask - mention , where they are masked to test the gener - alization of our model in a more realistic setting . Due to space limitations , we report model train - ing details in the supplementary material . 5 . 3 Results on the TACRED Dataset We present our main results on the TACRED test set in Table 1 . We observe that our GCN model System with - m mask - m SVM † ( Rink + 2010 ) 82 . 2 – SDP - LSTM † ( Xu + 2015b ) 83 . 7 – SPTree † ( Miwa + 2016 ) 84 . 4 – PA - LSTM ‡ ( Zhang + 2017 ) 82 . 7 75 . 3 Our Model ( C - GCN ) 84 . 8 ∗ 76 . 5 ∗ Table 2 : F 1 scores on SemEval . † marks results re - ported in the original papers ; ‡ marks results pro - duced by using the open implementation . The last two columns show results from with - mention evaluation and mask - mention evaluation , respectively . ∗ marks statistically signiﬁcant improvements over PA - LSTM with p < . 05 under a bootstrap test . outperforms all dependency - based models by at least 1 . 6 F 1 . By using contextualized word rep - resentations , the C - GCN model further outper - forms the strong PA - LSTM model by 1 . 3 F 1 , and achieves a new state of the art . In addition , we ﬁnd our model improves upon other dependency - based models in both precision and recall . Com - paring the C - GCN model with the GCN model , we ﬁnd that the gain mainly comes from improved recall . We hypothesize that this is because the C - GCN is more robust to parse errors by capturing local word patterns ( see also Section 6 . 2 ) . As we will show in Section 6 . 2 , we ﬁnd that our GCN models have complementary strengths when compared to the PA - LSTM . To leverage this result , we experiment with a simple interpolation strategy to combine these models . Given the out - put probabilities P G ( r | x ) from a GCN model and P S ( r | x ) from the sequence model for any relation r , we calculate the interpolated probability as P ( r | x ) = α · P G ( r | x ) + ( 1 − α ) · P S ( r | x ) where α ∈ [ 0 , 1 ] is chosen on the dev set and set to 0 . 6 . This simple interpolation between a GCN and a PA - LSTM achieves an F 1 score of 67 . 1 , outper - forming each model alone by at least 2 . 0 F 1 . An interpolation between a C - GCN and a PA - LSTM further improves the result to 68 . 2 . 5 . 4 Results on the SemEval Dataset To study the generalizability of our proposed model , we also trained and evaluated our best C - GCN model on the SemEval test set ( Table 2 ) . We ﬁnd that under the conventional with - entity eval - uation , our C - GCN model outperforms all exist - ing dependency - based neural models on this sep - 0 1 2 ∞ Full Tree 62 64 66 68 Path - centric Pruning Distance ( K ) D e v F 1 C - GCN GCN Tree - LSTM Figure 3 : Performance of dependency - based models under different pruning strategies . For each model we show the F 1 score on the TACRED dev set averaged over 5 runs , and error bars indicate standard deviation of the mean estimate . K = ∞ is equivalent to using the subtree rooted at the LCA . arate dataset . Notably , by properly incorporating off - path information , our model outperforms the previous shortest dependency path - based model ( SDP - LSTM ) . Under the mask - entity evaluation , our C - GCN model also outperforms PA - LSTM by a substantial margin , suggesting its generalizabil - ity even when entities are not seen . 5 . 5 Effect of Path - centric Pruning To show the effectiveness of path - centric prun - ing , we compare the two GCN models and the Tree - LSTM when the pruning distance K is var - ied . We experimented with K ∈ { 0 , 1 , 2 , ∞ } on the TACRED dev set , and also include results when the full tree is used . As shown in Figure 3 , the performance of all three models peaks when K = 1 , outperforming their respective depen - dency path - based counterpart ( K = 0 ) . This con - ﬁrms our hypothesis in Section 3 that incorporat - ing off - path information is crucial to relation ex - traction . Miwa and Bansal ( 2016 ) reported that a Tree - LSTM achieves similar performance when the dependency path and the LCA subtree are used respectively . Our experiments conﬁrm this , and further show that the result can be improved by path - centric pruning with K = 1 . We ﬁnd that all three models are less effective when the entire dependency tree is present , indi - cating that including extra information hurts per - formance . Finally , we note that contextualizing the GCN makes it less sensitive to changes in the tree structures provided , presumably because the 0 - 10 11 - 15 16 - 20 21 - 25 26 - 30 31 - 35 > 36 40 50 60 70 Distance between Entities D e v F 1 C - GCN GCN PA - LSTM Figure 4 : Dev set performance with regard to distance between the entities in the sentence for C - GCN , GCN and PA - LSTM . Error bars indicate standard deviation of the mean estimate over 5 runs . Model Dev F 1 Best C - GCN 67 . 4 – h s , h o , and Feedforward ( FF ) 66 . 4 – LSTM Layer 65 . 5 – Dependency tree structure 64 . 2 – FF , LSTM , and Tree 57 . 1 – FF , LSTM , Tree , and Pruning 47 . 4 Table 3 : An ablation study of the best C - GCN model . Scores are median of 5 models . model can use word sequence information in the LSTM layer to recover any off - path information that it needs for correct relation extraction . 6 Analysis & Discussion 6 . 1 Ablation Study To study the contribution of each component in the C - GCN model , we ran an ablation study on the TACRED dev set ( Table 3 ) . We ﬁnd that : ( 1 ) The entity representations and feedforward layers contribute 1 . 0 F 1 . ( 2 ) When we remove the de - pendency structure ( i . e . , setting ˜ A to I ) , the score drops by 3 . 2 F 1 . ( 3 ) F 1 drops by 10 . 3 when we remove the feedforward layers , the LSTM compo - nent and the dependency structure altogether . ( 4 ) Removing the pruning ( i . e . , using full trees as in - put ) further hurts the result by another 9 . 7 F 1 . 6 . 2 Complementary Strengths of GCNs and PA - LSTMs To understand what the GCN models are capturing and how they differ from a sequence model such as the PA - LSTM , we compared their performance Benoit B . Mandelbrot , a maverick mathematician who developed an innovative theory of roughness and applied it to physics , biology , finance and many other fields , died Thursday in Cambridge , Mass . Anil Kumar , a former director at the consulting firm McKinsey & Co , pleaded guilty on Thursday to providing inside information to Raj Rajaratnam , the founder of the Galleon Group , in exchange for payments of at least $ 175 million from 2004 through 2009 . died Relation : org : founded _ by Relation : per : city _ of _ death Rajaratnam Raj to founder Group the of the Galleon Thursday Cambridge in Mass Mandelbrot Benoit B . In a career that spanned seven decades , Ginzburg authored several groundbreaking studies in various fields - - such as quantum theory , astrophysics , radio - astronomy and diffusion of cosmic radiation in the Earth ' s atmosphere - - that were of “Nobel Prize caliber , ” said Gennady Mesyats , the director of the Lebedev Physics Institute in Moscow , where Ginzburg worked . Institute Physics Lebedev the of Moscow worked Ginzburg where Relation : per : employee _ of Figure 5 : Examples and the pruned dependency trees where the C - GCN predicted correctly . Words are shaded by the number of dimensions they contributed to h sent in the pooling operation , with punctuation omitted . Relation Dependency Tree Edges per : children S - PER ← son son → O - PER S - PER ← survived per : other family S - PER ← stepson niece → O - PER O - PER ← stepdaughter per : employee of a ← member S - PER ← worked S - PER ← played per : schools attended S - PER ← graduated S - PER ← earned S - PER ← attended org : founded founded → O - DATE established → O - DATE was ← founded org : number of employees S - ORG ← has S - ORG → employs O - NUMBER ← employees org : subsidiaries S - ORG ← O - ORG S - ORG → ’s O - ORG → division org : shareholders buffett ← O - PER shareholder → S - ORG largest ← shareholder Table 4 : The three dependency edges that contribute the most to the classiﬁcation of different relations in the TACRED dev set . For clarity , we removed edges which 1 ) connect to common punctuation ( i . e . , commas , periods , and quotation marks ) , 2 ) connect to common prepositions ( i . e . , of , to , by ) , and 3 ) connect between tokens within the same entity . We use PER , ORG for entity types of PERSON , ORGANIZATION . We use S - and O - to denote subject and object entities , respectively . We also include edges for more relations in the supplementary material . over examples in the TACRED dev set . Speciﬁ - cally , for each model , we trained it for 5 indepen - dent runs with different seeds , and for each exam - ple we evaluated the model’s accuracy over these 5 runs . For instance , if a model correctly classiﬁes an example for 3 out of 5 times , it achieves an ac - curacy of 60 % on this example . We observe that on 847 ( 3 . 7 % ) dev examples , our C - GCN model achieves an accuracy at least 60 % higher than that of the PA - LSTM , while on 629 ( 2 . 8 % ) examples the PA - LSTM achieves 60 % higher . This comple - mentary performance explains the gain we see in Table 1 when the two models are combined . We further show that this difference is due to each model’s competitive advantage ( Figure 4 ) : dependency - based models are better at handling sentences with entities farther apart , while se - quence models can better leverage local word pat - terns regardless of parsing quality ( see also Fig - ure 6 ) . We include further analysis in the supple - mentary material . 6 . 3 Understanding Model Behavior To gain more insights into the C - GCN model’s be - havior , we visualized the partial dependency tree it is processing and how much each token’s ﬁnal representation contributed to h sent ( Figure 5 ) . We ﬁnd that the model often focuses on the depen - dency path , but sometimes also incorporates off - path information to help reinforce its prediction . The model also learns to ignore determiners ( e . g . , “the” ) as they rarely affect relation prediction . To further understand what dependency edges contribute most to the classiﬁcation of different re - lations , we scored each dependency edge by sum - ming up the number of dimensions each of its con - nected nodes contributed to h sent . We present the top scoring edges in Table 4 . As can be seen in the table , most of these edges are associated with indicative nouns or verbs of each relation . 5 6 . 4 Entity Bias in the SemEval Dataset In our study , we observed a high correlation be - tween the entity mentions in a sentence and its relation label in the SemEval dataset . We exper - imented with PA - LSTM models to analyze this 5 We do notice the effect of dataset bias as well : the name “Buffett” is too often associated with contexts where share - holder relations hold , and therefore ranks top in that relation . A L B A – t h e B o li va r i a n A l t er n a t i v e f o r t h e A m er i c a s – w a s f ound e d by V e n ez u e l a n P r e s i d e n t H ugo C h a v ez a nd C ub a n l ea d e r F i d e l C a s t r o i n 20 04 a nd a l s o i n c l ud e s B o li v i a , N i ca r a gu a a nd t h e C a r i bb ea n i s l a nd o f D o m i n i ca . B a s h a r d o s t w a s bo r n i n 1965 i n t h e s ou t h e r n G h a n z i p r ov i n ce a nd h i s f a m il y m i g r a t e d t o Ir a n a nd t h e n t o P ak i s t a n a f t e r s u cce ss i v e c oup a nd f ac ti on a l ﬁ gh ti ng i n A f gh a n i s t a n . F i gu r e 6 : D e v s e t e x a m p l e s w h e r e e it h e r t h e C - G C N ( upp e r ) o r t h e P A - L S T M ( l o w e r ) p r e d i c t e d c o rr ec tl y i n ﬁ v e i nd e p e nd e n t r un s . F o r eac h e x a m p l e , t h e p r e d i c t e d a nd p r un e d d e p e nd e n c y t r ee c o rr e s pond i ng t o K = 1 i n p a t h - ce n t r i c p r un i ng i s s ho w n , a nd t h e s ho r t e s t d e p e nd e n c y p a t h i s t h i c k e n e d . W e o m it e dg e s t o pun c t u a ti on f o r c l a r it y . T h e ﬁ r s t e x a m p l e s ho w s t h a t t h e C - G C N i s e ff ec ti v e a t l e v e r a g i ng l ong - r a ng e d e p e nd e n c i e s w h il e r e du c i ng no i s e w it h t h e h e l p o f p r un i ng ( w h il e t h e P A - L S T M p r e d i c t s no r e l a ti on t w i ce , o r g : a lt e r na t e na m e s t w i ce , a nd o r g : p a r e n t s on ce i n t h i s ca s e ) . T h e s ec ond e x a m p l e s ho w s t h a t t h e P A - L S T M i s b e tt e r a t l e v e r a g i ng t h e p r ox i m it y o f t h e w o r d “ m i g r a t e d ” r e g a r d l e ss o f a tt ac h m e n t e rr o r s i n t h e p a r s e ( w h il e t h e C - G C N i s m i s l e d t o p r e d i c t p e r : c oun t r y o f b i r t h t h r ee ti m e s , a nd no r e l a ti on t w i ce ) . phenomenon . 6 We started by simplifying every sentence in the SemEval training and dev sets to “ subject and object ” , where subject and object are the actual entities in the sentence . Surprisingly , a trained PA - LSTM model on this data is able to achieve 65 . 1 F 1 on the dev set if GloVe is used to initialize word vectors , and 47 . 9 dev F 1 even without GloVe initialization . To further evaluate the model in a more realistic setting , we trained one model with the original SemEval training set ( unmasked ) and one with mentions masked in the training set , following what we have done for TACRED ( masked ) . While the unmasked model achieves a 83 . 6 F 1 on the original SemEval dev set , F 1 drops drastically to 62 . 4 if we replace dev set entity mentions with a special < UNK > token to simulate the presence of unseen entities . In con - trast , the masked model is unaffected by unseen entity mentions and achieves a stable dev F 1 of 74 . 7 . This suggests that models trained without entities masked generalize poorly to new examples with unseen entities . Our ﬁndings call for more careful evaluation that takes dataset biases into ac - count in future relation extraction studies . 7 Conclusion We showed the success of a neural architecture based on a graph convolutional network for re - lation extraction . We also proposed path - centric pruning to improve the robustness of dependency - based models by removing irrelevant content with - out ignoring crucial information . We showed through detailed analysis that our model has com - plementary strengths to sequence models , and that the proposed pruning technique can be effectively applied to other dependency - based models . Acknowledgements We thank Arun Chaganty , Kevin Clark , Sebastian Schuster , Ivan Titov , and the anonymous review - ers for their helpful suggestions . This material is based in part upon work supported by the National Science Foundation under Grant No . IIS - 1514268 . Any opinions , ﬁndings , and conclusions or recom - mendations expressed in this material are those of the authors and do not necessarily reﬂect the views of the National Science Foundation . 6 We choose the PA - LSTM model because it is more amenable to our experiments with simpliﬁed examples . References Heike Adel , Benjamin Roth , and Hinrich Sch¨utze . 2016 . Comparing convolutional neural networks to traditional models for slot ﬁlling . Proceedings of the 2016 Conference of the North American Chap - ter of the Association for Computational Linguistics on Human Language Technology ( NAACL - HLT ) . Razvan C Bunescu and Raymond J Mooney . 2005 . A shortest path dependency kernel for relation ex - traction . In Proceedings of the Conference on Hu - man Language Technology and Empirical Methods in Natural Language Processing ( EMNLP 2005 ) , pages 724 – 731 . Shexia He , Zuchao Li , Hai Zhao , and Hongxiao Bai . 2018 . Syntax for semantic role labeling , to be , or not to be . In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics . Nanda Kambhatla . 2004 . Combining lexical , syntactic , and semantic features with maximum entropy mod - els for extracting relations . In Proceedings of the ACL 2004 Interactive poster and demonstration ses - sions . Association for Computational Linguistics . Thomas N Kipf and Max Welling . 2017 . Semi - supervised classiﬁcation with graph convolutional networks . International Conference on Learning Representations ( ICLR 2017 ) . Yann LeCun , L ´ eon Bottou , Yoshua Bengio , and Patrick Haffner . 1998 . Gradient - based learning applied to document recognition . Proceedings of the IEEE , 86 ( 11 ) : 2278 – 2324 . Kenton Lee , Luheng He , Mike Lewis , and Luke Zettle - moyer . 2017 . End - to - end neural coreference res - olution . Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2017 ) . Yang Liu , Furu Wei , Sujian Li , Heng Ji , Ming Zhou , and Houfeng Wang . 2015 . A dependency - based neural network for relation classiﬁcation . Proceed - ings of the 53th Annual Meeting of the Association for Computational Linguistics ( ACL 2015 ) . Christopher D . Manning , Mihai Surdeanu , John Bauer , Jenny Finkel , Steven J . Bethard , and David Mc - Closky . 2014 . The Stanford CoreNLP natural lan - guage processing toolkit . In Association for Compu - tational Linguistics ( ACL ) System Demonstrations , pages 55 – 60 . Diego Marcheggiani and Ivan Titov . 2017 . Encoding sentences with graph convolutional networks for se - mantic role labeling . Proceedings of the 2017 Con - ference on Empirical Methods in Natural Language Processing ( EMNLP 2017 ) . Mike Mintz , Steven Bills , Rion Snow , and Dan Juraf - sky . 2009 . Distant supervision for relation extrac - tion without labeled data . In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP , pages 1003 – 1011 . Makoto Miwa and Mohit Bansal . 2016 . End - to - end re - lation extraction using LSTMs on sequences and tree structures . Proceedings of the 54th Annual Meet - ing of the Association for Computational Linguistics ( ACL 2016 ) . Joakim Nivre , Marie - Catherine de Marneffe , Filip Gin - ter , Yoav Goldberg , Jan Hajic , Christopher D Man - ning , Ryan McDonald , Slav Petrov , Sampo Pyysalo , Natalia Silveira , et al . 2016 . Universal dependen - cies v1 : A multilingual treebank collection . In Pro - ceedings of the 10th International Conference on Language Resources and Evaluation ( LREC 2016 ) , pages 1659 – 1666 . Jeffrey Pennington , Richard Socher , and Christopher D Manning . 2014 . GloVe : Global vectors for word representation . In Proceedings of the 2014 Con - ference on Empirical Methods in Natural Language Processing ( EMNLP 2014 ) , volume 14 , pages 1532 – 1543 . Chris Quirk and Hoifung Poon . 2017 . Distant super - vision for relation extraction beyond the sentence boundary . Proceedings of the 15th Conference of the European Association for Computational Lin - guistics ( EACL 2017 ) . Bryan Rink and Sanda Harabagiu . 2010 . UTD : Clas - sifying semantic relations by combining lexical and semantic resources . In Proceedings of the 5th Inter - national Workshop on Semantic Evaluation , pages 256 – 259 . Association for Computational Linguis - tics . Adam Santoro , David Raposo , David G Barrett , Ma - teusz Malinowski , Razvan Pascanu , Peter Battaglia , and Tim Lillicrap . 2017 . A simple neural network module for relational reasoning . In Advances in neural information processing systems , pages 4974 – 4983 . Kai Sheng Tai , Richard Socher , and Christopher D Manning . 2015 . Improved semantic representations from tree - structured long short - term memory net - works . Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics ( ACL 2015 ) . Ngoc Thang Vu , Heike Adel , Pankaj Gupta , and Hin - rich Sch¨utze . 2016 . Combining recurrent and convo - lutional neural networks for relation classiﬁcation . In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa - tional Linguistics on Human Language Technology ( NAACL - HLT ) . Linlin Wang , Zhu Cao , Gerard de Melo , and Zhiyuan Liu . 2016 . Relation classiﬁcation via multi - level at - tention CNNs . In Proceedings of the 54th Annual Meeting of the Association for Computational Lin - guistics ( ACL 2016 ) . Kun Xu , Yansong Feng , Songfang Huang , and Dongyan Zhao . 2015a . Semantic relation classiﬁca - tion via convolutional neural networks with simple negative sampling . In Proceedings of the 2015 Con - ference on Empirical Methods in Natural Language Processing ( EMNLP 2015 ) . Yan Xu , Lili Mou , Ge Li , Yunchuan Chen , Hao Peng , and Zhi Jin . 2015b . Classifying relations via long short term memory networks along shortest depen - dency paths . In Proceedings of the 2015 Confer - ence on Empirical Methods in Natural Language Processing ( EMNLP 2015 ) , pages 1785 – 1794 . Mo Yu , Wenpeng Yin , Kazi Saidul Hasan , Cicero dos Santos , Bing Xiang , and Bowen Zhou . 2017 . Im - proved neural relation detection for knowledge base question answering . Proceedings of the 55th Annual Meeting of the Association for Computational Lin - guistics ( ACL 2017 ) . Dmitry Zelenko , Chinatsu Aone , and Anthony Richardella . 2003 . Kernel methods for relation ex - traction . Journal of machine learning research , 3 : 1083 – 1106 . Daojian Zeng , Kang Liu , Siwei Lai , Guangyou Zhou , Jun Zhao , et al . 2014 . Relation classiﬁcation via convolutional deep neural network . In Proceedings of the 24th International Conference on Compu - tational Linguistics ( COLING 2014 ) , pages 2335 – 2344 . Yuhao Zhang , Victor Zhong , Danqi Chen , Gabor An - geli , and Christopher D . Manning . 2017 . Position - aware attention and supervised data improve slot ﬁlling . In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing ( EMNLP 2017 ) . Peng Zhou , Wei Shi , Jun Tian , Zhenyu Qi , Bingchen Li , Hongwei Hao , and Bo Xu . 2016 . Attention - based bidirectional long short - term memory net - works for relation classiﬁcation . In Proceedings of the 54th Annual Meeting of the Association for Com - putational Linguistics ( ACL 2016 ) , page 207 . A Experimental Details A . 1 Hyperparameters TACRED We set LSTM hidden size to 200 in all neural models . We also use hidden size 200 for the output feedforward layers in the GCN model . We use 2 GCN layers and 2 feedforward ( FFNN ) layers in our experiments . We employ the ReLU function for all nonlinearities in the GCN layers and the standard max pooling operations in all pooling layers . For the Tree - LSTM model , we ﬁnd a 2 - layer architecture works substantially bet - ter than the vanilla 1 - layer model , and use it in all our experiments . For both the Tree - LSTM and our models , we apply path - centric pruning with K = 1 , as we ﬁnd that this generates best results for all models ( also see Figure 3 ) . We use the pre - trained 300 - dimensional GloVe vectors ( Penning - ton et al . , 2014 ) to initialize word embeddings , and we use embedding size of 30 for all other embed - dings ( i . e . , POS , NER ) . We use the dependency parse trees , POS and NER sequences as included in the original release of the dataset , which was generated with Stanford CoreNLP ( Manning et al . , 2014 ) . For regularization we apply dropout with p = 0 . 5 to all LSTM layers and all but the last GCN layers . SemEval We use LSTM hidden size of 100 and use 1 GCN layer for the SemEval dataset . We pre - process the dataset with Stanford CoreNLP to gen - erate the dependency parse trees , POS and NER annotations . All other hyperparameters are set to be the same . For both datasets , we work with the Universal Dependencies v1 formalism ( Nivre et al . , 2016 ) . A . 2 Training For training we use Stochastic Gradient Descent with an initial learning rate of 1 . 0 . We use a cut - off of 5 for gradient clipping . For GCN models , we train every model for 100 epochs on the TAC - RED dataset , and from epoch 5 we start to anneal the learning rate by a factor of 0 . 9 every time the F 1 score on the dev set does not increase after an epoch . For Tree - LSTM models we ﬁnd 30 total epochs to be enough . Due to the small size of the SemEval dataset , we train all models for 150 epochs , and use an initial learning rate of 0 . 5 with a decay rate of 0 . 95 . In our experiments we found that the output vector h sent tends to have large magnitude , and - 5 - 4 - 3 - 2 - 1 + 1 + 2 + 3 + 4 + 5 0 . 5 1 . 0 1 . 5 2 . 0 Number of Models N u m b e r o f E x a m p l e s ( × 10 3 ) C - GCN GCN PA - LSTM Figure 7 : Aggregated 5 - run difference compared to PA - LSTM on the TACRED dev set . For each example , if X out of 5 GCN models predicted its label correctly and Y PA - LSTM models did , it is aggregated in the bar labeled X − Y . “0” is omitted due to redundancy . therefore adding the following regularization term to the cross entropy loss of each example improves the results : (cid:96) reg = β · (cid:107) h sent (cid:107) 2 . ( 6 ) Here , (cid:96) reg functions as an l 2 regularization on the learned sentence representations . β controls the regularization strength and we set β = 0 . 003 . We empirically found this to be more effective than applying l 2 regularization on the convolu - tional weights . B Comparing GCN models and PA - LSTM on TACRED We compared the performance of both GCN mod - els with the PA - LSTM on the TACRED dev set . To minimize randomness that is not inherent to these models , we accumulate statistics over 5 in - dependent runs of each model , and report them in Figure 7 . As is shown in the ﬁgure , both GCN models capture very different examples from the PA - LSTM model . In the entire dev set of 22 , 631 examples , 1 , 450 had at least 3 more GCN models predicting the label correctly compared to the PA - LSTM , and 1 , 550 saw an improvement from us - ing the PA - LSTM . The C - GCN , on the other hand , outperformed the PA - LSTM by at least 3 models on a total of 847 examples , and lost by a margin of at least 3 on another 629 examples , as reported in the main text . This smaller difference is also reﬂected in the diminished gain from ensembling with the PA - LSTM shown in Table 1 . We hypoth - Hwang , architect of the Pyongyang regime ' s ideology of “juche” or self - reliance , was once secretary of the ruling Workers’ Party and a tutor to current leader Kim Jong - Il . Gwathmey was born in 1938 , the only child of painter Robert Gwathmey and his wife , Rosalie , a photographer . born was Gwathmey 1938 child the only Gwathmey Robert of and wife his Rosalie photographer secretary Hwang was once Party architect of Worker and tutor the ruling ’ Relation : per : parents Relation : per : employee _ of " It is with great sorrow that we note the passing of Merce Cunningham , who died peacefully in his home last night of natural causes " , the Cunningham Dance Foundation and the Merce Cunningham Dance Company said in a statement . Cunningham Relation : per : cause _ of _ death Merce of die home causes of natural who peacefully Figure 8 : More examples and the pruned dependency trees the C - GCN predicted correctly . Words are shaded by the number of dimensions they contributed to h sent in the pooling operation , with punctuation omitted . Relation Dependency Tree Edges per : children S - PER ← son son → O - PER S - PER ← survived per : parents S - PER ← born O - PER ← son S - PER ← mother per : siblings S - PER ← sister sister → O - PER brother → O - PER per : other family S - PER ← stepson niece → O - PER O - PER ← stepdaughter per : spouse wife → O - PER S - PER ← wife his ← wife per : city of death S - PER ← died died → O - CITY ROOT → died per : city of birth S - PER ← born was ← born born → O - CITY per : cities of residence in ← O - CITY O - CITY ← S - PER S - PER ← lived per : employee of a ← member S - PER ← worked S - PER ← played per : schools attended S - PER ← graduated S - PER ← earned S - PER ← attended per : title O - TITLE ← S - PER as ← O - TITLE former ← S - PER per : charges S - PER ← charged O - CHARGE ← charges S - PER ← faces per : cause of death died → O - CAUSE S - PER ← died from ← O - CAUSE per : age S - PER → O - NUMBER S - PER ← died age → O - NUMBER org : alternate names S - ORG → O - ORG O - ORG → ) ( ← O - ORG org : founded founded → O - DATE established → O - DATE was ← founded org : founded by O - PER → founder S - ORG ← O - PER founder → S - ORG org : top members S - ORG ← O - PER director → S - ORG O - PER ← said org : subsidiaries S - ORG ← O - ORG S - ORG → ’s O - ORG → division org : num of employees S - ORG ← has S - ORG → employs O - NUMBER ← employees org : shareholders buffett ← O - PER shareholder → S - ORG largest ← shareholder org : website S - ORG → O - URL ROOT → S - ORG S - ORG → : org : dissolved S - ORG ← forced forced → ﬁle ﬁle → insolvency org : political / religious afﬁliation S - ORG → group O - IDEOLOGY ← group group → established Table 5 : The three dependency edges that contribute the most to the classiﬁcation of different relations in the dev set of TACRED . For clarity , we removed edges which 1 ) connect to common punctuation ( i . e . , commas , periods , and quotation marks ) , 2 ) connect to common preposition ( i . e . , of , to , by ) , and 3 ) connect tokens within the same entities . We use PER , ORG , CHARGE , CAUSE for entity types of PERSON , ORGANIZATION , CRIMINAL CHARGE and CAUSE OF DEATH , respectively . We use S - and O - to denote subject and object entities , respectively . ROOT denotes the root node of the tree . esize that the diminishing difference results from the LSTM contextualization layer , which incorpo - rates more information readily available at the sur - face form , rendering the model’s behavior more similar to a sequence model . For reference , we also include in Figure 7 the comparison of another 5 different runs ( with dif - ferent seeds ) of the PA - LSTM to the original 5 runs of the PA - LSTM . This is to conﬁrm that the difference shown in the ﬁgure between the model classes is indeed due a to model difference , rather than an effect of different random seeds . More speciﬁcally , the two groups of PA - LSTM only see 99 and 121 examples exceeding the 3 - model mar - gin on either side over the 5 runs , much lower than the numbers reported above for the GCN models . C Understanding Model Behavior We present visualization of more TACRED dev set examples in Figure 8 . We also show the depen - dency edges that contribute the most to more rela - tion types in Table 5 .