Reflektor : An Exploration of Collaborative Music Playlist Creation for Social Context Jared S . Bauer University of Washington Seattle , WA USA jaredsb @ uw . edu Aubury L . Jellenek University of Washington Seattle , WA USA jellea @ uw . edu Julie A . Kientz University of Washington Seattle , WA USA jkientz @ uw . edu ABSTRACT Music is intrinsically linked to our social lives . As more mu - sic becomes available through streaming services , deciding what music is appropriate for social events becomes increas - ingly challenging and nuanced . While prior work has consid - ered the social role of music and the creation of music playlists for user contexts , how individuals utilize music to create social contexts is an area that has largely gone unex - plored . To investigate this topic , we created and evaluated a prototype music recommender system called Reflektor . Re - flektor interactively visualizes users’ chat conversations to generate music playlists . Our analysis of user conversations with Reflektor uncovered distinct strategies participants use to create the ambiance and conduct for social contexts . Our findings help to illuminate mismatches in the way metadata and recommendation systems align with user strategies to create social context . We elaborate on these strategies and discuss design implications for future collaborative music recommender systems . Author Keywords Contextual music recommendations ; group displays ; collabo - rative playlist creation ; mood boards ; natural language pro - cessing . ACM Classification Keywords H . 5 . m . Information interfaces and presentation ( e . g . , HCI ) : Miscellaneous ; INTRODUCTION Music is fundamental to the social lives of people around the world [ 8 ] . Whether it is Pomp and Circumstance played at a graduation ceremony , hymns sung by a congregation , or pop hits enjoyed by friends at a club , music is often present when people interact socially . In fact , researchers have argued that improvements to the portability , availability , and reproduci - bility of music has transformed its role in everyday life from cognitive and emotional to primarily social [ 20 ] . But music is not merely a component of social occasions ; music also helps to establish the ambiance and conduct that is expected . Mu - sic’s role in structuring social interaction has been studied extensively by ethnomusicologists who argue music acts as a “ framework for the organization of social agency , a frame - work for how people perceive ( consciously or subconscious - ly ) potential avenues of conduct ” [ 10 : 17 ] . Music’s ability to structure social conduct extends beyond the individual ; music acts as a medium through which individuals create social context [ 9 ] . One of the key challenges faced when designing music rec - ommender systems is determining how social context should be viewed . HCI research has defined context as the infor - mation that can be used to characterize the situation of an entity [ 12 , 13 ] or more recently , as an emergent property of individuals’ interaction [ 14 ] . While these views are useful ways to characterize context , they focus more on the situation an individual is engaged in and less on how an individual imposes meaning on a given situation . The role of meaning and meaning - making has become an increasingly important consideration in system design [ 21 , 38 ] . Because of the per - sonal relationship individuals have with music , how music is utilized to create social context is worth critical reflection . Social context in HCI has been defined as individuals’ social norms and cultural models , as well as the interaction between cultural models in a situation [ 28 ] . This definition of social context emphasizes the relationship between the meaning an individual brings to a context and the meaning that emerges from interaction between this meaning and the context . While this model , like other theoretical approaches , has been noted for challenges that it can create when designers try to apply it to a given problem space [ 34 ] , it does help to illus - trate how users’ understanding of their context influences their experience and conduct of that context . This emphasis on the individuals’ meaning and its relationship to their con - text aligns with ethnographic work that suggests music is fundamental to structuring social conduct [ 8 , 11 ] . While music is clearly important for social context , research - ers have not directly explored the design of recommender systems to accommodate music’s role in creating social con - text . Instead , researchers have explored how components of user context can be leveraged to create music recommenda - tions [ 2 , 3 , 29 ] , systems to select music socially [ 24 , 31 , 40 ] , or how music is shared and experienced socially [ 5 , 8 , 23 , 26 , 42 ] . Building upon prior work examining recommender systems , our research explores how groups utilize music to create so - cial context . To explore this topic , we designed a prototype recommender system called “Reflektor” ( Figure 1 ) . Reflektor Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita - tion on the first page . Copyrights for components of this work owned by others than the author ( s ) must be honored . Abstracting with credit is permitted . To copy other - wise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and / or a fee . Request permissions from Permissions @ acm . org . GROUP ' 18 , January 7 – 10 , 2018 , Sanibel Island , FL , USA © 2018 Copyright is held by the owner / author ( s ) . Publication rights licensed to ACM . ACM 978 - 1 - 4503 - 5562 - 9 / 18 / 01… $ 15 . 00 https : / / doi . org / 10 . 1145 / 3148330 . 3148331 Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 27 utilizes natural language processing techniques on user chat conversations to surface and visualize key ideas . This creates opportunities for users to negotiate the meaning of the ideas and their fit with the evolving notion for the social context . While much of this work focuses on the design of Reflektor , we do not feel that the Reflektor , as a system , is the main contribution of this work . Instead , Reflektor is best viewed as a prototype whose construction and evaluation was a useful tool to highlight some of the mismatches that occur between how recommender systems operate , the metadata on which they rely , and the strategies that users employ while discuss - ing music . Our evaluation of Reflektor provides insight into participant strategies to achieve mutual understanding around music recommendations for social context . These insights illuminate opportunities for designers of music recommenda - tion systems and other context - aware systems where social context is a key consideration . RELATED WORK Considerable research in the field of HCI has sought to de - termine what music should be played for social contexts . Prior work in this area can be largely organized as : research into how music is shared and experienced socially , the design of systems that automatically detect and create playlists for user contexts , and the design of interfaces to facilitate demo - cratic music selection . We discuss each of these foci below . The social role of music has also been studied in work that considers music in sharing and collaboration . Brown et al . ’s [ 5 ] study of music highlighted the role of sharing as a social practice and explored alternatives to illegal file sharing ser - vices . Voida’s work on practices of music sharing important - ly illustrates the role of impression management through mu - sic [ 42 ] . Sease & McDonald’s research on home media col - lections [ 36 ] contributed to Voida’s work by revealing the role that intimacy and proximity play in how music is used in impression management . More recent studies of how music is used in social activities provide insights into interactions surrounding music . This includes a transition away from a focus on physical media and an emphasis on social media platforms that accommodate sharing [ 26 ] . This focus on shared listening experiences was further developed through the use of a technological probe , Pocketsong [ 23 ] . Their work highlighted design challenges for negotiating self - expression , co - listening , and developing cultural capital through mobile music applications interface design . Our work contributes to these studies by providing insights into how individuals establish and utilize the relevance of music for a social context Research has also focused on the design of systems that de - tect and create playlists for groups of users automatically . One of the earliest examples was MusicFX [ 29 ] , a group based recommender system that created playlists for gym members based on overlap in their music preferences . Mu - sicFX determined what users were present from their ID badges when users entered the gym . One limitation of Mu - sicFX is that it required participants to manually state their music preferences to use the system . Building off that work , Flytrap [ 7 ] logged the users listening history to automate the processes of determining listener preferences . The system then used ID badges to determine user copresence in a lab setting and combined user listening history with rules on music compatibility to determine what music should be played . Prior work has also shown that determining user emotion can be helpful in creating music recommendations for individuals [ 22 ] . MoodMusic [ 2 ] extended this idea to collocated groups by using audio signal processing to deter - mine the group member’s mood and then selecting songs appropriate for that mood based on the music’s metadata and the group member’s listening history . In addition to work that seeks to determine group music pref - erences automatically , additional work has explored how group music preferences can be selected democratically . One early example is Jukola [ 31 ] , which was deployed at a club and provided mobile devices for users to vote with to deter - mine which songs would be played . UbiRockMachine also provides music for groups in public spaces based on mutual taste [ 24 ] . Figure 1 : Reflektor application interface Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 28 Unlike Jukola , UbiRockMachine also acted as a platform for unsigned musicians to share their work and gather feedback on their music . PartyVote [ 40 ] tried to address issues with users engaging in undemocratic behavior with group music recommendation systems by visualizing user influence on the recommendations . Sørensen , & Lagerl’s work on MEET [ 39 ] explored multi - user and multi - device influence on music selection . Their work highlighted challenges with the feed - back provided to users and the influence the environment has on collaboration . Our work contributes to prior work that aimed to automatically or democratically determine music playlists for groups by providing a new technique to accom - modate this process . Furthermore , our work provides insight into how individuals establish mutual understanding around the relevance of music for a social context . REFLEKTOR RESEARCH , DESIGN , AND DEVELOPMENT In this section , we discuss the research , design , and develop - ment of Reflektor ( see Figure 2 ) . Our work on Reflektor was part of a larger year - long study of how individuals interact with intelligent agents . While much of that work is out of the scope of this paper , our research did motivate our primary interaction model for Reflektor . Our primary model of inter - action is that intelligent agents , such as Amazon’s Alexa ( https : / / developer . amazon . com / alexa ) and Apple’s Siri ( https : / / www . apple . com / ios / siri / ) , are more likely to be situ - ated in our environments and expected to understand and respond to our environments without having to be explicitly asked to respond . This model of interaction aligns with prior work on implicit interaction through context [ 35 ] rather than explicit modes of interaction with intelligent agents [ 4 ] . As such , we sought to design a system that would enable users to interact with each other rather than directly with the technol - ogy . As intelligent agents become more prevalent in our daily life , we imagine a variety of scenarios of use for implicit models of interaction that could facilitate collaboration . For the purposes of this study we focused on a system that would infer and respond to group conversations and select music suitable for the context being discussed . Reflektor System Design After identifying a model of interaction that we hoped to facilitate , we began exploring design opportunities . To ac - commodate the multifaceted preferences of groups , we aimed to provide an interface that could represent a variety of crite - ria used to produce recommendations . This also suggested an interface that is transparent and modifiable . After extensive ideation , we were drawn to mood boards as a design meta - phor . Mood boards are often a collection of images or words and can be utilized to convey an overall design concept [ 30 ] . Mood boards represent an idea in a multifaceted way and can be used for framing and aligning views [ 27 ] . Because of the - se properties , we felt mood boards presented a useful mecha - nism for allowing groups to represent meaning . With mood boards as an organizing design metaphor for how interfaces could reflect users’ multifaceted views , the re - search team developed an interactive prototype of the inter - face using Processing ( https : / / processing . org / ) . After explor - ing several options to facilitate the creation of the mood boards , including scraping user’s social media for images or keywords , we determined that parsing chat conversations was ideal to explore how individuals utilize music to create social context . We opted to focus on user chat conversations because language is such a rich resource for contextual meaning - making [ 18 ] . It also allowed us to clearly scope the context to the user’s conversation . At this point , we felt that the concept for the system began to unify : a music recom - mender system that allowed groups to discuss music and passively visualize , or reflect , the systems understanding of the conversation . Ultimately , it was this vision that led us to the name Reflektor . Figure 2 : Overview of the components of Reflektor . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 29 Reflektor System Development Reflektor operates as one system but has three distinct com - ponents ( see Figure 2 ) . The first is the chat client where the participants can chat with one another , share , and vote on the keywords from their conversation . The second component is a server where a text parsing module determines the key - words and phrases based on the users’ conversation . The server uses those keywords to produce the visualization and music recommendations . The final component is an interac - tive visualization of the keywords from the participants’ con - versation . The participants interacted with the system using a smartphone running the chat client , and the visualization appeared on a wall - mounted display in the room where the study took place . Each of these components is explained in detail below . Chat Client The chat client is implemented using the JavaScript open source runtime environment node . js ( https : / / nodejs . org ) . The application used web sockets to instantiate a chat environ - ment for the users . In addition to operating as a chat client , the application also allows users to share and vote on the words or phrases from their conversation ( see Figure 1 ) . While users chat , the server suggests keywords or phrases that it determines to be important to the conversation . These words appear as a list in the Share page ( the process by which the server determines what words or phrases are sig - nificant is discussed in the Server section below ) . Users are then able to share or delete the suggested words depending on whether they feel the phrases are important components of their conversation . Once shared , the words appear in both users’ Vote page , thereby allowing the other participant to vote the phrase up or down . The system is thus a two - step process of collaboratively determining the content of the vis - ualization and consequently what music is suggested . Server To ensure that the application surfaced portions of the con - versation with social importance , we used a two - step filtering process . While users chat , each message is parsed and ana - lyzed by the server for keywords and phrases . In the first step of the filtering , the server uses text frequency inverse docu - ment frequency ( TF / IDF ) to select keywords from the users’ conversation . The server uses the NPS Chat Corpus from the Natural Language Tool Kit ( NLTK ) ( http : / / www . nltk . org / ) as a basis for the TF / IDF algorithm . The NPS Chat Corpus con - sists of 10 , 567 posts from of approximately 500 , 000 posts gathered from various online chat services in accordance with their terms of service . Therefore , making it a valuable corpus of common English language words . We determined a threshold for the words and phrases the system chose by processing posts from online music forums . The second step filtered phrases that passed the TF / IDF algorithm threshold using social media . This enabled us to surface socially signif - icant phrases . For each word or phrase that passed the TF / IDF threshold , Reflektor searched the Facebook API for corresponding Facebook Pages . Searching for a correspond - ing Facebook Page was crucial because the TF / IDF algo - rithm can only tell if a word or phrase is common or uncom - mon relative to a corpus . If a Facebook Page exists for a word or phrase , that means it was intentionally created by a Facebook user and therefore it is more likely to hold some social importance instead of just being an uncommon phrase or expression . To illustrate the point , in the sentence : “The new Kanye West album is great” the TF / IDF value for the bigram “Kanye West” is likely equal to the bigram “West album” or “new Kanye , ” since each of those bigrams is a phrase that is unlikely to appear in a chat corpus . However , the Facebook API will return a page with numerous Likes for Kanye West but not for the other phrases . To determine which pages to include for this method of so - cial filtering , we used pages with a number of “Likes” greater than 100 . The Page Like threshold was determined by itera - tively processing conversations from online music forums and adjusting the number of Likes until we felt the right bal - ance of results was achieved . During our calibration of the TF / IDF and Page Like threshold , we found some page cate - gories—such as Shopping / retail , Business service , and Pet supplies—returned consistently unhelpful results and chose to omit them . To disambiguate homonyms , the metadata re - turned from the Facebook API for the keyword or phrase is shown in the users’ Share page . The metadata included the page description and Facebook page category . For some words or phrases , multiple results are returned . In this situa - tion , each result is shown in the Share page and the users can choose the phrase for the category they are discussing . Interactive Visualization After a word or phrase is shared by a user , it then appears in the system’s visualization . We created the visualization using JavaScript and a jQuery plugin called freewall ( https : / / github . com / kombai / freewall ) . During the study , the visualization was displayed at full screen on a 60” wall - mounted monitor ( see Figure 3 ) . Reflektor visualizes phrases in two different ways : as a mood board or as a word cloud . The content of the visualization will update dynamically as users share and vote on phrases . Figure 3 : Room layout for the study showing an example mood board generated by the application on the wall moni - tor . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 30 To select images for the mood board visualization , Reflektor uses the Google Search API . The search included both the phrase and the category from the corresponding Facebook page in the search string . We initially created the mood board visualization using the images from the Facebook page itself , but while piloting the system , we found the quality of the images to be inconsistent . After further pilot testing , we felt that using the Google API produced the best mood boards in terms of consistent quality of images for the phrases . To encourage transparency of how the items in the visualiza - tion influence the music being selected , we chose to make the size of the items change relative to the number of votes the phrase received . After being shared , the phrases begin with a default size equal to approximately 10 % of the display . When voted on , the image size doubles to approximately 20 % for two votes and 40 % for three votes . If a phrase has zero votes , it is removed from the visualization . The text of the word cloud increases in size in the same manner as the images in the mood board . SYSTEM EVALUATION We conducted an evaluation of Reflektor with 10 sets of dy - ads , for a total of 20 participants . We recruited participants through online discussion boards and with paper flyers . We randomly assigned participants to each dyad . Their ages ranged from 18 to 28 with an average age of 21 . 6 . Eight par - ticipants identified as female and the remaining 12 identified as male . We compensated participants with a $ 20 gift card for their time . The study was conducted in a conference room on a university campus with a table in the center and a 60” monitor on the wall ( see Figure 3 ) . Our research objective was to explore how individuals utilize music to create social contexts . To encourage participants to engage in conversations that would elaborate on this relation - ship , we intentionally recruited individuals that were unac - quainted prior to the study . Because the participants were unacquainted , they did not have a shared understanding of each other’s views on the contextual relevance of music and therefore needed to establish it through their conversation . This approach draws on Garfinkel’s work studying essential features of common understanding , which sought to elicit “seen but unnoticed features of common discourse” [ 17 : 227 ] . While this approach to recruiting likely reduces the ecologi - cal validity of this work , we feel that it encouraged partici - pants to be explicit about their views on the relationship be - tween context and music and therefore provide more specific insights about the strategies participants use to create shared understanding . During the study , we instructed participants to use the chat client to discuss two hypothetical events and the music they would like to play at each event : a “quiet evening with friends” and a “party . ” We instructed them to discuss any - thing they felt was relevant to organizing each of those events . The order for the event they discussed was counter balanced along with the order for the visualization used . Each study session lasted approximately 90 minutes and in - cluded two rounds of the participants using the chat client to discuss music for each condition . The lab session began with the research staff demonstrating Reflektor to the participants . Between the conversations , the participants rated songs for the condition discussed and were asked about their experi - ence . After the second round of chatting , we conducted a longer interview . We video recorded each study session and logged the participants’ chat conversation along with phrases they shared , deleted , and voted on . Creating Recommendations To evaluate the quality of recommendations produced by the system , we created two sets consisting of five songs for both scenarios the participants discussed . To create the sets of songs we used two techniques : the first technique used a sim - ilarity ranking and the second used the system to conduct text parsing on the participant conversations . In the remainder of the paper we will refer to the techniques as similar and text parsing respectively . Prior to the study , we emailed each participant a spreadsheet and instructed them to list ten songs that—to quote from the instructions included in the spread - sheet—“you would want played during a quiet evening with friends” and ten songs “you would want played at a party with friends . ” We drew upon this data to generate a set of similar songs . For each dyad , we used the API of Last . fm ( http : / / www . last . fm / api ) . Last . fm is a social music service with millions of active users , which logs their listening histo - ry and make it publicly available . We utilized their API to search for music similar to the songs both participants pro - vided . Last . fm’s “Track . getSimilar ( ) ” function returns the most similar songs as determined from their extensive listen - ing history of its entire user base . Tracks returned from the API were ranked to produce a list that represented the most similar songs for both participants based on pre - study musi - cal preferences . To generate the songs for the text parsing condition , we searched the Last . fm API for songs tagged with the key words voted on by the participants . The process of creating the recommendations was run once at the end of each of the participants’ conversations . The songs were weighted by the number of participant votes . When the page for a phrase had the category “musician or band” we queried the Last . fm API for the top 10 tags for the musician and incorporated those tags into the song queries . The songs were then ranked and normalized by the number of tags . This allowed us to explore how musicians were used in the conversation , instead of al - lowing the participants to simply list musicians to generate recommendations . Chat Log Analysis The two lead researchers coded the chat logs of the partici - pants’ conversations . The participants’ chat conversations lasted approximately fifteen minutes per condition . On aver - age , each conversation had 72 lines of dialog ( σ = 21 . 5 ) and a mean word count of 438 words ( σ = 110 . 7 ) . The themes pre - sented in this paper emerged from the iterative coding and Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 31 refinement of the participants’ chat conversations . The au - thors refined and developed these themes by reviewing the videotaped interviews conducted with the participants during each study session . These codes were further developed by drawing on the sociological research presented by DeNora in Music in Everyday Life [ 10 ] , which explores the social and personal role that music plays in people’s lives . Between one and three codes were used on each section of the participants’ conversation . To ensure that the codes were applied consist - ently , the authors independently coded the first two inter - views and compared the results to determine how consistent - ly the codes were applied . The authors then iterated and re - fined codes that were applied inconsistently and reviewed sections of the conversations where variation in codes were found . After revising the codes , the authors then coded one additional interview and compared the consistency with which the codes were applied . After the second round of cod - ing , the raters achieved agreement in > 70 % of the codes they applied to the transcripts . The authors then applied the codes to the remaining chat logs independently ( Table 1 ) . FINDINGS We have organized the findings into two sections : the first section discusses our analysis of the participants’ chat logs and the themes that emerged in the strategies the participants used to ground their views on music and context . The second section presents the participants’ ratings of the recommended music and their views on the associated visualization . All names used in this paper are anonymous identifiers given to participants during the lab study . Understanding Views on Music and Context As mentioned above , the participants were unacquainted prior to the study . We intentionally recruited unacquainted participants so that they would have to establish what consti - tuted the two conditions of the study—a party or a quiet evening with friends . In this sense , the participants were re - quired to make the common sense understanding visible , surface background understanding , and then incorporate their understanding into their evolving discussion about the con - text and appropriate music for that context . We saw participants develop common understanding in a variety of ways . In general terms , this process consisted of one of the participants specifying what the context should consist of , or what music would be appropriate for that con - text . Then , participants determined if that suggestion was aligned with the evolving notion of the current context . To accomplish this , the participants often utilized one of three criteria , discussed below : sonic properties of the music , in - teraction styles associated with the context of the event , or what location enables similar forms of interaction . Sonic Properties of Music and Their Fit for Context Discussing what music would be appropriate for the two con - texts necessitated that the participants unpack their language to ensure the other participant understood what they were proposing . This was the case in all participant conversations as they tried to determine what constituted a quiet evening with friends , or “a chill party” as it was often described . In the example below from Interview 2 , we can see the two participants discuss what the language means and subse - quently how the meaning of the words might correspond to what music is appropriate . Bonnie : cool . so what do you do at chill parties ? Brian : Music , drink , conversation . . . Bonnie : alright . so we probs want music that ' s easy to talk over Brian : What constitutes chill for you ? Slow tempo , repeti - tive , acoustic . . . ? We can see this conversation starts off as a discussion of the activities for the party , but then quickly Brian tries to match the word “chill” to sonic properties of the music . This invites Bonnie to provide more details on what chill means to her . Bonnie : music that ' s easy to talk over Bonnie : oh um Bonnie : probably beats that aren ' t too hard Bonnie : not too many wubs lol Bonnie : you ? Bonnie again discusses chill in terms of activities that the music would permit , specifically something that accommo - dates talking . Brian does not respond , thereby not validating her suggestion , so she further elaborates on her initial re - sponse by describing the music in terms of properties of the music . Instead of defining chill , she decides to negate things that are not chill . She does this by referencing “beats that Code Definition Elicit modes of con - duct Music suggests and elicits asso - ciated modes of conduct . Organize social inter - action Music acts as an affordance for social interaction . Emotional modulation and constitution Music is used to encourage de - sired emotional states . Promote concentration Music is used to create an envi - ronment that promotes concen - tration . Create space for inti - macy Music enables the possibility of intimate behavior . Secondary signifi - cance Music suggests connotations of additional aesthetic . Sonic properties Musical properties , such as tempo and rhythm , contribute to an environment that enables modes of interaction . Table 1 Summary of codes and their definitions from the analysis of chat transcripts . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 32 aren’t too hard” as being inappropriate features of chill mu - sic . She then goes on to elaborate that “wubs”—an expres - sion used to describe the bass modulation commonly used in dubstep music—would be uncharacteristic of chill music . The approach that Bonnie applies is characteristic of genera - tors in category theory [ 25 : 12 ] . Bonnie is establishing the idea of what music is part of her category of chill music by defining a rule that can be applied to music to “generate” the members of that category . Her formulation is : Music without hard beats – “wubs” = chill music This strategy is a lighthearted attempt to characterize the idea of chill , but it is specific enough that Brian seems to under - stand what she means and proceeds to prompt her to continue establishing what music should be played at their chill party . Using Activity to Establish Contextually Appropriate Music In every chat conversation , the participants discussed what activities they planned to engage in for the given context . This was the most common way that the interaction of the context was framed by the participants . This frequently oc - curred when participants discussed dancing and what music they felt would be appropriate for and encourage dancing . However , we also saw it extend beyond the direct influence that music has structuring physical interaction to activities that draw on music’s cultural significance to establish ambi - ance . This process is illustrated in the chat dialogue from Interview 4 when the participants discussed the context of a quiet evening with friends . The first few lines of the conver - sation consisted primarily of the participants making sure they are connected , but once it is clear they are both connect - ed , Dave states : Dave : I like jazz and crooners . After eight more lines of the participants discussing games , the following conversation begins in which they try to estab - lish music that corresponds to the game - playing activity that was suggested . Dan : jazz huh ? Dan : oh I’id say poker . how could you even play blackjack with friends lol Dave : Poker is fun . Bring some chips and cards . Dan : but let’s get a playlist with a lot of jazz piano Dan : yeah yeah will do Dave : Herbie Hancock Dan : do you know if Sarah is coming ? She’s cute . Dave : She might be . I dunno . Dan : how about Thelonious Monk or Art Tatum ? Dan : my brother plays sax so always sends me stuff to lis - ten to Dave : Monk might be a bit on the strange side . Same with Tatum . But I would say Tatum or Monk . Dave : What about Miles Davis ? not piano but he is pretty good . Dave : Frank Sinatra ? Dan : ok well specifics aren’t super important . we can mix in Sinatra or Ella Fitzgerald too Dan : the important thing is what are we going to be drink - ing Dave : Whiskey or wine . Both go well with Jazz and Sinatra I feel . From this portion of the participants’ conversation , we can see them trying to match styles of music with activities in which they hope to engage . This begins with card playing but quickly evolves into a more holistic context when Dan asks if Sarah is coming to their quiet evening with friends . Because these participants did not know each other , this was evidently an imaginary person and the idea of getting to talk with a person that he thought was “cute” was used as a suggestion for a form of interaction that they hoped to establish— namely flirting . In all , the participants outline card playing , flirting , and drinking as being appropriate modes of interac - tion . This portion of their conversation illustrates how the activities establish and contribute to the criterion of what is appropriate for the context that extends beyond the sonic properties of the music . Presumably one could play card games to any type of music . But , for the context that they hope to establish where drinking wine , whiskey , and cock - tails while people play cards and flirt , jazz music is viewed by the participants as being appropriate because it is presum - ably viewed as being more sophisticated . This example illu - minates the interplay between activity and music for creating social context . Location as an Indication of Music Type Another strategy participants employed to establish under - standing was utilizing physical locations as indicators of what music could be defined as appropriate for the context . In Interview 9 , participants had little overlap in their musical tastes and therefore struggled to determine what chill music would be appropriate . After some discussion of the music , Ira began to suggest various clubs to establish common under - standing . Ian : but there is electronic music that is pretty chill too Ira : same era as Fleetwood Mac Ian : I might wanna check it Ian : the blues I mean Ira : yeah : [ a local club ] specialize s in that stuff Ira : gimme some electronic recommendations Ian : yeah like [ a local club ] . I went to a few clubs [ down - town ] and they play stuff that is like that In this example , we can see Ian suggest electronic music , but rather than establish the type of electronic music he would like by suggesting an artist , Ira contributes to the idea of elec - tronic music by associating it with a popular local club . Ira then asks Ian to make some suggestions to which Ian also provides downtown clubs to establish mutual understanding . This technique seems to be effective in helping them further refine what music would be most appropriate because it causes them to refine the idea of electronic music . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 33 By using the club as a stand - in for a type of electronic music , participants use metonymy to a valuable way to reference the relevant ambiance and music . Metonymy is a principle by which a well - understood or easy - to - perceive aspect of some - thing and use it to stand either for the object as a whole for some other aspect or part of it [ 25 : 77 ] . An example of me - tonymy is the entire movie industry in the United States be - ing referred to as “Hollywood . ” By referencing the club , Ira easily alludes to the music played there and its ambience . Recommendations and Visual Representation Now that we have discussed how participants established what music would be appropriate for the different contexts , we will discuss the music that was recommended to partici - pants and the impact of the visualizations on the participants’ ratings . After the participants chatted for each condition , their con - versation was used to generate a playlist of five songs using the text parsing technique described in the section Creating Recommendations . These songs were combined with the five similar songs generated for the participants prior to the study . The lists of text parsed and similar songs were then combined into one randomly ordered playlist , which participants rated on a Likert scale from 1 to 5 based on 1 ) how much they enjoyed the songs , 2 ) how appropriate the songs were based on what they had discussed , and 3 ) how familiar they were with the songs . In our analysis of their ratings , we used R [ 33 ] and lme4 [ 1 ] to perform a linear mixed effects analysis of the relationship between the visualization type , recommendation technique , and the participants’ ratings of the music for appropriateness , familiarity , and enjoyment of the music . As fixed effects , we entered visualization type ( mood board or word cloud ) , rec - ommender type ( text parsing or similarity ranking ) , scenario , and order into the model . As random effects , we included intercepts for participants and participant dyads . Visual in - spection of the residual plots did not reveal any obvious de - viation from homoscedasticity or normality for the enjoyment and appropriateness dependent variables . The familiarity ratings were largely bi - modal with modes at both 1 and 5 ratings . P - values were obtained by likelihood ratio tests of the full model with the effect in question against a model without the effect . Our analysis found that neither the visual - ization nor the recommendation type had a significant effect on participants ' ratings for any of the dependent measures . A likelihood ratio test for interaction also showed no significant effect on participants ' ratings for any dependent measure . Visual Representation and Mutual Understanding The statistical analysis did not demonstrate that the visualiza - tion type had a significant influence on the participant’s per - ceived quality of the recommendations . However , in six ses - sions , the participants expressed sentiment that the mood board provided a useful way to contextualize the recommen - dations and insights into what music would or would not be appropriate to suggest . “If I saw just this and had no knowledge of the conversation I probably wouldn’t suggest Beethoven or Miles David , but I might suggest Bruce Springsteen or Tom Petty . ” ( Dave , In - terview 4 ) At times when the other participant was unfamiliar with a musician suggested by the other participant , the mood board helped provide insight into what a musician or band might be like . “No I hadn’t heard of [ the band ] . The mood board helped me see who it was . Because we were talking about mellow music , so that could be… That’s something we could play at a mellow party” ( Eve , Interviews 5 ) However , participants were sometimes confused when the system selected a homonym for the phrase that was selected . For example , displaying a house after the participants had discussed the house music genre . The system sought to dis - ambiguate homonyms by using the Facebook category as part of the search string when searching for the images to populate the mood board . However , when the incorrect im - ages were selected and images with meanings that differed from the intended sentiment were displayed , participants felt that the mood board was less useful than the word cloud . “ I would say that the photographs are a little more confus - ing , because of their association with the word . So , there are like two levels of association we need to make . ” ( Ira , Inter - view 9 ) Based on comments of this type , the mood board was helpful when the images were understood by both participants or when it seemed consistent with the ambiance . However , when an image was unclear , it was more confusing to the participants than the phrase in the word cloud . From Conversation to Recommendation We were encouraged that , from the participants’ brief con - versation , Reflektor produced recommendations they rated as equally enjoyable , appropriate , and familiar to music from the Last . FM API . To further explore the differences in how the recommendation technique operates , we analyzed how the text parsing algorithm created recommendations and how this differed from traditional techniques . One of the key differences in how the system operates , com - pared to a traditional recommender system , is by emphasiz - ing how individuals utilize music in the creation of shared social context . To encourage the notion that the context was social , we drew on the Facebook API to provide a form of social filtering of key words and phrases . However , they were not always terms that could be easily associated with musical choices . This meant that the strategies that partici - pants found useful to create understanding with the other participant did not always result in improved music recom - mendations . To illustrate how these strategies influenced what music was recommended , we return to the participants’ conversation in the section Understanding Views on Music and Context . In Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 34 Interview 4 , we saw participants use activities to establish common understanding . The participants discussed card games , which appeared in their visualization ( see Figure 4 ) and ultimately factored into their music recommendations . However , only seven songs on Last . fm are tagged with the phrase “card games” which led to none of these songs being chosen for their playlists . Similarly , in Interview 2 , the partic - ipants’ chat conversation had a total of 409 words . Of these 409 words , twenty - one words or phrases were eventually shared by the participants—meaning that these twenty - one phrases appeared in the visualization and were used to pro - duce the music recommendations . Interestingly , despite Bon - nie’s vivid description of what chill meant to her , none of those terms appeared in the visualization and therefore were not used to create the playlists . While her phrase “wubs” did have associated tags on Last . fm , there were no Facebook Pages returned by the initial query so her description went unaccounted for . The participants from Interview 9 who used clubs to denote which music was appropriate had a total of twenty - two unique shared phrases from their conversation . After inspect - ing the results of the suggested terms , we found that clubs mentioned did have associated Facebook Pages but did not have associated metadata in the Last . fm API . Unfortunately , this resulted in a loss of a rich way to explain contextualized music . From each of these strategies , we can see the same result : a mismatch between how context is understood and a lack of metadata available to support the participant’s strate - gy . DISCUSSION Based on our findings from the evaluation , we will now dis - cuss the key insights and their implications for the design of context - aware music recommendation systems . Our discus - sion begins with the strategies participants utilized while creating understanding around music for social context and how music recommendation systems can be designed to ac - commodate these strategies . We then discuss the mismatches revealed in the way existing metadata and recommendation systems align with user strategies to create social context . Strategies for Achieving Mutual Understanding Our findings suggest that to achieve mutual understanding about music for social context , participants utilized three strategies : 1 ) the sonic properties of music , 2 ) the activities associated with the social interaction or activity they hoped to encourage , and 3 ) the location where this ambiance or mode of interaction is prevalent . These three strategies were used in concert with suggesting musicians directly and therefore of - fer opportunities for designers of music recommendation systems to augment how recommendations are created for social context . Discussing the sonic properties of music was a common strategy utilized by participants throughout the interviews . Prior recommender systems have allowed users to create recommendations based on musical features such as tempo [ 16 , 19 ] , but we did not see participants use this language extensively when discussing music . In fact , only one partici - pant seemed to be interested in engaging in a discussion of music using the formal language from music theory . Partici - pants drew on more common language to describe the music , such as Bonnie’s use of the phrase “wubs . ” As was men - tioned in the findings , her method for describing music also leveraged the use of generators in the descriptions of music . We imagine this approach could allow for a more flexible method of describing the sonic properties of music for users without extensive knowledge of music . Using common lan - guage has been explored for movie recommendations [ 41 ] , and through commercial services such as APM Music ( https : / / www . apmmusic . com / ) ; a digital music production company whose extensive track library can be accessed online . Allowing for more flexible forms of expression with this metadata than current systems afford offers additional opportunities for recommender system design . The participants also leveraged activity while discussing so - cial context . Using activity to create music recommendations has been explored in prior work , but has primarily focused on matching sonic properties to physical activity such as danc - ing [ 6 ] or exercising [ 32 ] . While dancing was a large topic of conversation in the interviews , music was clearly key in structuring activities where the participants emphasized the cultural connotations of the music instead of the sonic prop - erties alone . In DeNora’s work exploring the role of music in everyday life , she refers to “scenes” that are constructed by drawing on music as a cultural material [ 10 : 123 ] . This in - cludes the connotations that the music suggests . Participants clearly hoped to establish specific scenes and used activity in conjunction with music as a resource in the creation of those scenes . This provides opportunities to explore activity and cultural connotations , instead of mapping physical activity to the sonic properties of music . Because music is so highly personal , a generalized dataset of cultural significance would be impractical to create . However , the extensive body of work on personal informatics and lived experience [ 15 ] could Figure 4 : Mood board from Interview 4 . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 35 be leveraged to create personally significant music recom - mendations for social contexts . This creates opportunities for designers to explore how users can create associations be - tween their music and the activities in which they engage . We emphasize that this should allow the user to determine the scope of the activity and its relationship to the music ra - ther than relying on automatic detection and inference . The critical step for designers is emphasizing the personal nature of music and its relationship to users’ contexts . Participants’ use of metonymy to describe music that would be appropriate suggested additional opportunities for design . While systems such as [ 3 , 29 , 37 ] have leveraged location as a mechanism for improving music recommendations , their focus has been on the songs played at the location . Instead , our findings suggested that participants hoped to use the loca - tion as a resource in meaning making . The design of future recommender systems could emphasize the ambiance of the location over the music at the location as a resource in creat - ing recommendations for social context . Additionally , the interface should enable users to personalize their relationship with their location and what that location means to the user . Mismatches Between Recommender Systems and user Strategies to Create Social Context When participants discussed music for social contexts , their goal was not to find specific songs per se , but rather to find music that enables , or at least does not inhibit , modes of in - teraction . Unfortunately , recommender systems generally emphasize similarity in music—based on features of the songs or user listening histories—instead of similarity in the modes of interaction the music enables . We feel it is im - portant that social music recommenders provide an overview of how songs fit modes of interaction . In fact , we have seen a trend toward this in how music playlists are organized on music streaming services . Examples of this include playlists entitled “Gaming , ” “Focus , ” and “Sleep” . How these meth - ods of organization extend to other modes of social interac - tion is an underexplored area and offers opportunities for research in recommender systems and interface design that seek to capture the nuanced relationship between the users’ views of music’s role in creating context . Orienting toward how users interact with music and away from the music itself is further supported by the strategies used by participants for discovering music . In every inter - view , we observed participants suggesting musicians as a strategy to ground the conversation . In the instances where the band was unfamiliar to the other participant , this effec - tively ended the conversation . While this could lead to the design implication that recommenders should incorporate an easier form of previewing music , we instead feel that it reveals a limitation of how recommenders normally oper - ate . By relying on similarity in the music without the user behavior to contextualize the music , recommender system designers rely on familiarity with musicians to encourage discovery . By leveraging methods for grounding conversa - tions , designers can provide recommendations better suited for the group context without having to rely on the specifics of the musicians being recommended . LIMITATIONS One limitation of this study arose from focusing on how mu - sic is communicated . We choose to focus on communication because language is such a rich resource in meaning making . By focusing on communication , we were given insight into how individuals communicated what music was appropriate for a given context . By limiting the interaction of the partici - pants to just computer mediated communication , we encour - aged the participants to unpack their views in a way that may not have been as necessary with a richer mode of interaction . However , because we relied on chat - conversations over a short duration of time , we limited behavior that would occur in real world setting and therefore the ecological validity of the findings . An additional limitation of this study came from recruiting individuals that did not know each other . The aim again was to require participants to elaborate their views on what music would be appropriate for different contexts ; if participants had a personal relationship , the relevance of the music was more likely to be established and therefore not need explicit elaboration . However , by recruiting unfamiliar dyads , we likely missed out on more natural forms of interac - tion that would occur among friends or acquaintances . De - spite these limitations , we feel that the findings provide use - ful insights into the process and practices of group context - specific music recommendations . CONCLUSION In this paper , we presented a study with a music recommend - er prototype called Reflector , which we used to explore how users utilize music in the creation of shared social context . Our study and analysis of the participants’ conversations while using Reflektor revealed the importance of establishing mutual understanding when determining context - specific music . To accomplish this , participants drew on the sonic properties of the music , the modes of interaction that the mu - sic enabled and the locations where the music is prevalent . When designing recommender systems to accommodate so - cial context , our findings suggest designers should focus on strategies used to create mutual understanding and how this will correspond to metadata . By identifying these practices as being key to creating socially situated music recommenda - tions , this work provides useful insights into a previously underexplored area of context - aware recommendation re - search . ACKNOWLEDGMENTS We would like to thank the study participants who participat - ed in this research . We also acknowledge Intel’s generous gift funding for this research . All research was reviewed and approved by the University of Washington’s Human Subjects Division . Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 36 REFERENCES 1 . Douglas Bates , Martin Mächler , Ben Bolker , and Steve Walker . 2014 . Fitting Linear Mixed - Effects Models using lme4 . submitted to Journal of Statistical Software 67 , 1 : 51 . http : / / doi . org / 10 . 18637 / jss . v067 . i01 2 . Jared S . Bauer , Alex Jansen , and Jesse Cirimele . 2011 . MoodMusic : A Method for Cooperative , Generative Music Playlist Creation . In Proceedings of the 24th annual ACM symposium adjunct on User interface software and technology - UIST ’11 Adjunct , 85 . http : / / doi . org / 10 . 1145 / 2046396 . 2046435 3 . Stephan Baumann , Björn Jung , Arianna Bassoli , and Martin Wisniowski . 2007 . BluetunA : let your neighbour know what music you like . Proceedings of ACM CHI 2007 Conference on Human Factors in Computing Systems 2 : 1941 – 1946 . http : / / doi . org / 10 . 1145 / 1240866 . 1240929 4 . Timothy W . Bickmore and Justine Cassell . 2005 . Social Dialogue with Embodied Conversational Agents . 23 – 54 . 5 . Barry Brown , Abigail J . Sellen , and Erik Geelhoed . 2001 . Music Sharing as a Computer Supported Collaborative Application . In Proceedings of Ecscw 2001 , 179 – 198 . 6 . Dave Cliff . 2006 . hpDJ : An automated DJ with floorshow feedback . In Consuming Music Together , Kenton O’Hara and Barry Brown ( eds . ) . Dordrecht , The Netherlands , 241 – 264 . http : / / doi . org / 10 . 1007 / 1 - 4020 - 4097 - 0 _ 12 7 . Andrew Crossen , Jay Budzik , and Kristian J . Hammond . 2002 . Flytrap : intelligent group music recommendation . Proceedings of the 7th international conference on Intelligent user interfaces - IUI ’02 : 184 . http : / / doi . org / 10 . 1145 / 502716 . 502748 8 . Jane W . Davidson . 2004 . Music as Social behavior . In Empirical Musicology : Aims , Methods , Prospects , Eric Clarke and Nicholas Cook ( eds . ) . Oxford University Press , New York , New York , USA , 57 – 76 . http : / / doi . org / 10 . 1093 / acprof : oso / 9780195167498 . 003 . 0 004 9 . Tia Denora . 1999 . Music as a technology of the self . Poetics 27 , 1 : 31 – 56 . http : / / doi . org / 10 . 1016 / S0304 - 422X ( 99 ) 00017 - 0 10 . Tia DeNora . 2000 . Music in everyday life . Cambridge University Press . 11 . Tia DeNora . 2005 . Music and Social Experience . In The Blackwell Companion to the Sociology of Culture , Blackwell ( Jacobs M , ) , Mark D . Jacobs and Nancy Weiss Hanrahan ( eds . ) . Blackwell Publishing Ltd . , Malden , MA , 147 – 159 . 12 . Anind K . Dey . 2001 . Understanding and using context . Personal and ubiquitous computing : 4 – 7 . http : / / doi . org / 10 . 1007 / s007790170019 13 . Anind K . Dey and Gregory D . Abowd . 2000 . Towards a better understanding of context and context - awareness . In CHI 2000 workshop on the what , who , where , when , and how of context - awareness , 1 – 6 . 14 . Paul Dourish . 2004 . What we talk about when we talk about context . Personal and Ubiquitous Computing 8 , 1 : 19 – 30 . http : / / doi . org / 10 . 1007 / s00779 - 003 - 0253 - 8 15 . Daniel A Epstein , An Ping , James Fogarty , Sean A Munson , Computer Science , and Human Centered Design . 2015 . A Lived Informatics Model of Personal Informatics . In UbiComp ’15 , 731 – 742 . http : / / doi . org / 10 . 1145 / 2750858 . 2804250 16 . Yazhong Feng , Yueting Zhuang , and Yunhe Pan . 2003 . Popular music retrieval by detecting mood . In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval - SIGIR ’03 , 375 . http : / / doi . org / 10 . 1145 / 860500 . 860508 17 . Harold Garfinkel . 1964 . Studies of the Routine Grounds of Everyday Activities . Social Problems 11 , 3 : 225 – 250 . 18 . Charles Goodwin and Marjorie Harness Goodwin . 1992 . Assessments and the construction of context . In Rethinking Context : Language as an Interactive Phenomenon . 147 – 189 . http : / / doi . org / 10 . 2307 / 2074658 19 . Byeong Jun Han , Seungmin Rho , Sanghoon Jun , and Eenjun Hwang . 2010 . Music emotion classification and context - based music recommendation . Multimedia Tools and Applications 47 , 3 : 433 – 460 . http : / / doi . org / 10 . 1007 / s11042 - 009 - 0332 - 6 20 . David J . Hargreaves and Adrian C . North . 1999 . The Functions of Music in Everyday Life : Redefining the Social in Music Psychology . Psychology of Music 27 : 71 – 83 . http : / / doi . org / 10 . 1177 / 0305735699271007 21 . Steve Harrison , Deborah Tatar , and Phoebe Sengers . 2007 . The three paradigms of HCI . In alt . CHI . 22 . Jennifer Healey , Rosalind W . Picard , and Frank Dabek . 1998 . A New Affect - Perceiving Interface and Its Application to Personalized Music Selection . In In Workshop on Perceptual User Interfaces , ( San Francisco ) . 23 . David S Kirk , Abigail Durrant , Gavin Wood , Tuck Wah Leong , Peter Wright , and Newcastle Tyne . 2016 . Understanding the Sociality of Experience in Mobile Music Listening with Pocketsong . In DIS 2016 , 50 – 61 . http : / / doi . org / 10 . 1145 / 2901790 . 2901874 24 . Hannu Kukka and Rodolfo Patino . 2009 . UbiRockMachine : A Multimodal Music Voting Service for Shared Urban Spaces . In Proceedings of the 8th International Conference on Mobile and Ubiquitous Multimedia - MUM 09 , 1 – 8 . http : / / doi . org / 10 . 1145 / 1658550 . 1658559 Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 37 25 . George Lakoff . 1987 . Women , Fire , and Dangerous Things : What Categories Reveal about the Mind . The University of Chicago Press . 26 . Tuck W . Leong and Peter C . Wright . 2013 . Revisiting social practices surrounding music . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems - CHI ’13 , 951 . http : / / doi . org / 10 . 1145 / 2470654 . 2466122 27 . Andrés Lucero . 2012 . Framing , aligning , paradoxing , abstracting , and directing . In Proceedings of the Designing Interactive Systems Conference on - DIS ’12 , 438 . http : / / doi . org / 10 . 1145 / 2317956 . 2318021 28 . Giuseppe Mantovani . 1996 . Social context in HCl : A new framework for mental models , cooperation , and communication . Cognitive Science 20 : 237 – 269 . http : / / doi . org / 10 . 1016 / S0364 - 0213 ( 99 ) 80007 - X 29 . Joseph F . E . McCarthy and Theodore D . Anagnost . 1998 . MUSICFX : an arbiter of group preferences for computer supported collaborative workouts . In CSCW ’1998 Proceedings of the 1998 ACM conference on Computer supported cooperative work , 348 . 30 . Deana McDonagh and Howard Denton . 2005 . Exploring the degree to which individual students share a common perception of specific mood boards : observations relating to teaching , learning and team - based design . Design Studies 26 , 1 : 35 – 53 . http : / / doi . org / 10 . 1016 / j . destud . 2004 . 05 . 008 31 . Kenton O’Hara , Matthew Lipson , Marcel Jansen , Axel Unger , Huw Jeffries , and Peter Macer . 2004 . Jukola : Democratic Music Choice in a Public Space . In Proceedings of the 2004 conference on Designing interactive systems processes , practices , methods , and techniques - DIS ’04 , 145 . http : / / doi . org / 10 . 1145 / 1013115 . 1013136 32 . Nuria Oliver and Fernando Flores - Mangas . 2006 . MPTrain : a mobile , music and physiology - based personal trainer . Proceedings of the 8th conference on Human - computer interaction with mobile devices and services Helsinki , : 21 – 28 . http : / / doi . org / 10 . 1145 / 1152215 . 1152221 33 . R Core Team . 2012 . R : A language and environment for statistical computing . Vienna , Austria . 34 . Yvonne Rogers . 2004 . New theoretical approaches for human - computer interaction . Annual Review of Information Science and Technology 38 , 1 : 87 – 143 . 35 . Albrecht Schmidt . 2000 . Implicit human computer interaction through context . Personal Technologies 4 , 2 – 3 : 191 – 199 . http : / / doi . org / 10 . 1007 / BF01324126 36 . Robin Sease and David W . McDonald . 2009 . Musical fingerprints : Collaboration around home media collections . Proceedings of the ACM 2009 international conference on Supporting group work : 331 – 340 . http : / / doi . org / 10 . 1145 / 1531674 . 1531724 37 . Jan Seeburger , Marcus Foth , and Dian Tjondronegoro . 2012 . The sound of music : sharing song selections between collocated strangers in public urban places . In Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia - MUM ’12 , 1 . http : / / doi . org / 10 . 1145 / 2406367 . 2406409 38 . Abigail J . Sellen , Yvonne Rogers , Richard Harper , and Tom Rodden . 2009 . Reflecting human values in the digital age . Communications of the ACM 52 , 3 : 58 . http : / / doi . org / 10 . 1145 / 1467247 . 1467265 39 . Henrik Sørensen and Selma Lagerl . 2012 . The Interaction Space of a Multi - Device , Multi - User Music Experience . In NordiCHI ’12 Proceedings of the 7th Nordic Conference on Human - Computer Interaction : Making Sense Through Design Pages 504 - 513 , 504 – 513 . http : / / doi . org / 10 . 1145 / 2399016 . 2399094 40 . David Sprague , Fuqu Wu , and Melanie Tory . 2008 . Music selection using the PartyVote democratic jukebox . In Proceedings of the working conference on Advanced visual interfaces - AVI ’08 , 433 . http : / / doi . org / 10 . 1145 / 1385569 . 1385652 41 . Jesse Vig , Shilad Sen , and John Riedl . 2012 . The Tag Genome : Encoding Community Knowledge to Support Novel Interaction . ACM Transactions on Interactive Intelligent Systems 2 , 3 : 1 – 44 . http : / / doi . org / 10 . 1145 / 2362394 . 2362395 42 . Amy Voida , Rebecca E . Grinter , Nicolas Ducheneaut , W Keith Edwards , and Mark W . Newman . 2005 . Listening in : practices surrounding iTunes music sharing . In Proceedings of the 2005 Annual Conference on Human Factors in Computing Systems - CHI ’05 . http : / / doi . org / 10 . 1145 / 1054972 . 1054999 Paper Session : Metadata , Sensemaking and Depersonalization GROUP 2018 , Jan . 7 – 10 , 2018 , Sanibel Island , FL , USA 38