How Many Scientists Fabricate and Falsify Research ? A Systematic Review and Meta - Analysis of Survey Data Daniele Fanelli * INNOGEN and ISSTI - Institute for the Study of Science , Technology & Innovation , The University of Edinburgh , Edinburgh , United Kingdom Abstract The frequency with which scientists fabricate and falsify data , or commit other forms of scientific misconduct is a matter of controversy . Many surveys have asked scientists directly whether they have committed or know of a colleague who committed research misconduct , but their results appeared difficult to compare and synthesize . This is the first meta - analysis of these surveys . To standardize outcomes , the number of respondents who recalled at least one incident of misconduct was calculated for each question , and the analysis was limited to behaviours that distort scientific knowledge : fabrication , falsification , ‘‘cooking’’ of data , etc… Survey questions on plagiarism and other forms of professional misconduct were excluded . The final sample consisted of 21 surveys that were included in the systematic review , and 18 in the meta - analysis . A pooled weighted average of 1 . 97 % ( N = 7 , 95 % CI : 0 . 86 – 4 . 45 ) of scientists admitted to have fabricated , falsified or modified data or results at least once – a serious form of misconduct by any standard – and up to 33 . 7 % admitted other questionable research practices . In surveys asking about the behaviour of colleagues , admission rates were 14 . 12 % ( N = 12 , 95 % CI : 9 . 91 – 19 . 72 ) for falsification , and up to 72 % for other questionable research practices . Meta - regression showed that self reports surveys , surveys using the words ‘‘falsification’’ or ‘‘fabrication’’ , and mailed surveys yielded lower percentages of misconduct . When these factors were controlled for , misconduct was reported more frequently by medical / pharmacological researchers than others . Considering that these surveys ask sensitive questions and have other limitations , it appears likely that this is a conservative estimate of the true prevalence of scientific misconduct . Citation : Fanelli D ( 2009 ) How Many Scientists Fabricate and Falsify Research ? A Systematic Review and Meta - Analysis of Survey Data . PLoS ONE 4 ( 5 ) : e5738 . doi : 10 . 1371 / journal . pone . 0005738 Editor : Tom Tregenza , University of Exeter , United Kingdom Received January 6 , 2009 ; Accepted April 19 , 2009 ; Published May 29 , 2009 Copyright : (cid:1) 2009 Fanelli . This is an open - access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use , distribution , and reproduction in any medium , provided the original author and source are credited . Funding : The author is supported by a Marie Curie Intra European Fellowship ( Grant Agreement Number PIEF - GA - 2008 - 221441 ) . The funders had no role in study design , data collection and analysis , decision to publish , or preparation of the manuscript . Competing Interests : The author has declared that no competing interests exist . * E - mail : dfanelli @ staffmail . ed . ac . uk Introduction The image of scientists as objective seekers of truth is periodically jeopardized by the discovery of a major scientific fraud . Recent scandals like Hwang Woo - Suk’s fake stem - cell lines [ 1 ] or Jan Hendrik Scho¨n’s duplicated graphs [ 2 ] showed how easy it can be for a scientist to publish fabricated data in the most prestigious journals , and how this can cause a waste of financial and human resources and might pose a risk to human health . How frequent are scientific frauds ? The question is obviously crucial , yet the answer is a matter of great debate [ 3 , 4 ] . A popular view propagated by the media [ 5 ] and by many scientists ( e . g . [ 6 ] ) sees fraudsters as just a ‘‘few bad apples’’ [ 7 ] . This pristine image of science is based on the theory that the scientific community is guided by norms including disinterestedness and organized scepticism , which are incompatible with misconduct [ 8 , 9 ] . Increasing evidence , however , suggests that known frauds are just the ‘‘tip of the iceberg’’ , and that many cases are never discovered . The debate , therefore , has moved on to defining the forms , causes and frequency of scientific misconduct [ 4 ] . What constitutes scientific misconduct ? Different definitions are adopted by different institutions , but they all agree that fabrication ( invention of data or cases ) , falsification ( wilful distortion of data or results ) and plagiarism ( copying of ideas , data , or words without attribution ) are serious forms of scientific misconduct [ 7 , 10 ] . Plagiarism is qualitatively different from the other two because it does not distort scientific knowledge , although it has important consequences for the careers of the people involved , and thus for the whole scientific enterprise [ 11 ] . There can be little doubt about the fraudulent nature of fabrication , but falsification is a more problematic category . Scientific results can be distorted in several ways , which can often be very subtle and / or elude researchers’ conscious control . Data , for example , can be ‘‘cooked’’ ( a process which mathematician Charles Babbage in 1830 defined as ‘‘an art of various forms , the object of which is to give to ordinary observations the appearance and character of those of the highest degree of accuracy’’ [ 12 ] ) ; it can be ‘‘mined’’ to find a statistically significant relationship that is then presented as the original target of the study ; it can be selectively published only when it supports one’s expectations ; it can conceal conflicts of interest , etc… [ 10 , 11 , 13 , 14 , 15 ] . Depend - ing on factors specific to each case , these misbehaviours lie somewhere on a continuum between scientific fraud , bias , and simple carelessness , so their direct inclusion in the ‘‘falsification’’ category is debatable , although their negative impact on research can be dramatic [ 11 , 14 , 16 ] . Henceforth , these misbehaviours will be indicated as ‘‘questionable research practices’’ ( QRP , but for a technical definition of the term see [ 11 ] ) . Ultimately , it is impossible to draw clear boundaries for scientific misconduct , just as it is impossible to give a universal definition of professional malpractice [ 10 ] . However , the intention to deceive is a key element . Unwilling errors or honest differences PLoS ONE | www . plosone . org 1 May 2009 | Volume 4 | Issue 5 | e5738 in designing or interpreting a research are currently not considered scientific misconduct [ 10 ] . To measure the frequency of misconduct , different approaches have been employed , and they have produced a corresponding variety of estimates . Based on the number of government confirmed cases in the US , fraud is documented in about 1 every 100 . 000 scientists [ 11 ] , or 1 every 10 . 000 according to a different counting [ 3 ] . Paper retractions from the PubMed library due to misconduct , on the other hand , have a frequency of 0 . 02 % , which led to speculation that between 0 . 02 and 0 . 2 % of papers in the literature are fraudulent [ 17 ] . Eight out of 800 papers submitted to The Journal of Cell Biology had digital images that had been improperly manipulated , suggesting a 1 % frequency [ 11 ] . Finally , routine data audits conducted by the US Food and Drug Administration between 1977 and 1990 found deficiencies and flaws in 10 – 20 % of studies , and led to 2 % of clinical investigators being judged guilty of serious scientific misconduct [ 18 ] . All the above estimates are calculated on the number of frauds that have been discovered and have reached the public domain . This significantly underestimates the real frequency of misconduct , because data fabrication and falsification are rarely reported by whistleblowers ( see Results ) , and are very hard to detect in the data [ 10 ] . Even when detected , misconduct is hard to prove , because the accused scientists could claim to have committed an innocent mistake . Distinguishing intentional bias from error is obviously difficult , particularly when the falsification has been subtle , or the original data destroyed . In many cases , therefore , only researchers know if they or their colleagues have wilfully distorted their data . Over the years , a number of surveys have asked scientists directly about their behaviour . However , these studies have used different methods and asked different questions , so their results have been deemed inconclusive and / or difficult to compare ( e . g . [ 19 , 20 ] ) . A non - systematic review based on survey and non - survey data led to estimate that the frequency of ‘‘serious misconduct’’ , including plagiarism , is near 1 % [ 11 ] . This study provides the first systematic review and meta - analysis of survey data on scientific misconduct . Direct comparison between studies was made possible by calculating , for each survey question , the percentage of respondents that admitted or observed misconduct at least once , and by limiting the analysis to qualitatively similar forms of misconduct - specifically on fabrica - tion , falsification and any behaviour that can distort scientific data . Meta - analysis yielded mean pooled estimates that are higher than most previous estimates . Meta - regression analysis identified key methodological variables that might affect the accuracy of results , and suggests that misconduct is reported more frequently in medical research . Methods Searching Electronic resources were searched during the first two weeks of August 2008 . Publication and journal databases were searched in English , while the Internet and resources for unpublished and ‘‘grey’’ literature were searched using English , Italian , French and Spanish words . Citation databases . The Boolean string ‘‘research misconduct’’ OR ‘‘research integrity’’ OR ‘‘research malpractice’’ OR ‘‘scientific fraud’’ OR ‘‘fabrication , falsification’’ OR ‘‘falsification , fabrication’’ was used to search : Science Citation Index Expanded ( SCI - EXPANDED ) , Social Sciences Citation Index ( SSCI ) , Arts & Humanities Citation Index ( A & HCI ) , Conference Proceedings Citation Index - Science ( CPCI - S ) , BIOSIS Previews , MEDLINE , Business Source Premier , CINAHL Plus , SPORTDiscus , Library , Information Science & Technology Abstracts , International Bibliography of the Social Sciences , America : History & Life , Teacher Reference Center , Applied Social Sciences Index And Abstracts ( ASSIA ) , ERIC , Index Islamicus , CSA linguistics and language behaviour , Physical Education Index , PILOTS , Social Services Abstracts , Sociological Abstracts , Proquest Dissertation & Theses , ECONLIT , Educational Research Abstracts ( ERA ) Online , Article First , Economic and Social Data Service , Francis , Geobase , Georefs , Global Health ( CABI ) , Index to Theses , International Bibliography of the Social Sciences ( IBSS ) , IEEE Xplore , INSPEC , JSTOR , Mathematical Sciences Net ( MathSciNet ) , PubMEd , Russian Academy of Sciences bibliographies , Sciencedirect , Teacher Reference Center , EMBASE , EMBASE Classics , PSYCHINFO . Scientific journals . The Boolean string ‘‘research misconduct’’ OR ‘‘research integrity’’ OR ‘‘research malpractice’’ OR ‘‘scientific fraud’’ OR ‘‘fabrication , falsification’’ OR ‘‘falsification , fabrication’’ was used to search : Interdisciplinary Science Reviews , American Journal of Sociology , Annual Review of Sociology , PNAS , Issues in Science & Technology , Journal of Medical Ethics , PLoSONE , Science and Engineering Ethics , Sociology of Health & Illness , Minerva , The Scientific World Journal , Social Science Research , Social Studies of Science , Science in Context . Grey literature databases . The Boolean string ‘‘research misconduct’’ OR ‘‘research integrity’’ OR ‘‘research malpractice’’ OR ‘‘scientific fraud’’ OR ‘‘fabrication , falsification’’ OR ‘‘falsification , fabrication’’ was used to search : SIGLE , National Technical Information Service , British Library Collections , British Library Direct , Canadian Evaluation Society , Bioethics Literature Database . The Italian string ‘‘etica AND ricerca’’ was used in : CNR database . The French string ‘‘scientifique AND ‘‘ethique’’ OR ‘‘fraude’’ OR ‘‘faute’’ OR ‘‘enquete’’ OR ‘‘sondage’’ was used in : LARA - Libre acces aux rapports scientifiques et techiques Internet search engines . The Boolean string ‘‘research misconduct’’ OR ‘‘research integrity’’ OR ‘‘research malpractice’’ OR ‘‘scientific fraud’’ OR ‘‘fabrication , falsification’’ OR ‘‘falsification , fabrication’’ , the Spanish Boolean string ‘‘e´tica cientifica’’ OR ‘‘faltas e´ticas’’ the French Boolean string ‘‘faute scientifique’’ OR ‘‘e´thique scientifique’’ were used to search : ScienceResearch . com , Scirus . Titles and available abstracts of all records were examined , and the full text of all potentially relevant studies was retrieved . The references list of the retrieved studies and of other documents was also examined in search of potentially relevant papers . Selection Only quantitative survey data assessing how many researchers have committed or observed colleagues committing scientific misconduct in the past were included in this review . Surveys asking only opinions or perceptions about the frequency of misconduct were not included . To allow direct quantitative comparison across data sets , studies were included only if they presented data in frequency or percentage categories , one of which was a ‘‘never’’ or ‘‘none’’ or ‘‘nobody’’ category - indicating that the respondent had never committed or observed the behaviour in question . Studies lacking such a category , or presenting results in statistical formats that prevented the retrieval of this information ( e . g . mean and standard deviation ) were excluded . Respondents of any professional position and scientific discipline were included , as long as they were actively conducting publishable research , or directly involved in it How Many Falsify Research ? PLoS ONE | www . plosone . org 2 May 2009 | Volume 4 | Issue 5 | e5738 ( e . g . research administrators ) . Surveys addressing misconduct in undergraduate students were excluded , because it was unclear if the misconduct affected publishable scientific data or only scholastic results . This review focused on all and only behaviours that can falsify or bias scientific knowledge through the unjustified alteration of data , results or their interpretation ( e . g . any form of fabrication and falsification , intentional non - publication of results , biased methodology , misleading reporting , etc… ) . Plagiarism and profes - sional misconduct ( e . g . withholding information from colleagues , guest authorship , exploitation of subordinates etc… ) were excluded from this review . Surveys that made no clear distinction between the former and latter types of misconduct ( e . g . that asked about fabrication , falsification and plagiarism in the same question ) were excluded . Any available data on scientists’ reaction to alleged cases of misconduct was extracted from included studies . Since these data provided only additional information that was not the focus of the review , survey questions that did not distinguish between data manipulation and plagiarism were included in this section of the results , but clearly identified . Validity assessment Surveys that did not sample respondents at random , or that did not provide sufficient information on the sampling methods employed where given a quality score of zero and excluded from the meta - analysis . All remaining papers were included , and were not graded on a quality scale , because the validity and use of quality measures in meta - analysis is controversial [ 21 , 22 ] . Instead of using an arbitrary measure of quality , the actual effect of methodological characteristics on results was tested and then controlled for with regression analysis . In the tables listing study characteristics , the actual words reported in the paper by the authors are quoted directly whenever possible . The few cases where a direct quotation could not be retrieved are clearly indicated . Data abstraction For each question , the percentage of respondents who recalled committing or who observed ( i . e . had direct knowledge of ) a colleague who committed one or more times the specified behaviour was calculated . In the majority of cases , this required summing up the responses in all categories except the ‘‘none’’ or ‘‘never’’ category , and the ‘‘don’t know’’ category . Some studies subdivided the sample of respondents according to a variety of demographic characteristics ( e . g . gender , career level , professional position , academic discipline , etc… ) and disaggregat - ed the response data accordingly . In all these cases , the data was re - aggregated . Given the objectivity of the information collected and the fact that all details affecting the quality of studies are reported in this paper , it was not necessary to have the data extracted / verified by more than one person . Quantitative data synthesis The main outcome of the meta - analysis was the percentage ( proportion ) of respondents that recalled committing or that knew of a colleague committing the specified behaviour at least once in the given recall period . This measure was not normally distributed ( Kolmogorov - Smirnov test : 0 . 240 , df = 19 , P = 0 . 005 ) so it was logit transformed [ 23 ] , and weighted by inverse variance of logit transformed proportion using the following equations for effect size , standard error and weight , respectively : ES ~ Log e p 1 { p ð Þ (cid:1) (cid:2) SE ~ ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 1 np z 1 n 1 { p ð Þ s W ~ 1 SE 2 ~ np 1 { p ð Þ Where p is the proportion of respondents recalling at least one case of the specified behaviour , and n is the total number of respondents . The distribution of the logit - transformed effect sizes was not significantly different from normal ( K - S : 0 . 109 , df = 19 , P = 0 . 2 ) . To facilitate their interpretation , the final logit results ( ES and 95 % CI ) were back - transformed in percentages using the following equations for proportion and percentages , respectively : p ~ e x e x z 1 % ~ 100 p Where x is either ES or each of the corresponding 95 % CI values . Mean pooled effect size was calculated assuming a random effects model , and homogeneity was tested with Chochran’s Q test . Differences between groups of studies were tested using inverse variance weighted one - way ANOVA . The combined effect of independent variables on effect sizes was tested with inverse variance weighted regression assuming a random effects model and estimated via iterative maximum likelihood . To avoid the biasing effect of multiple outcomes within the same study , all meta - analyses on the main outcome of interest ( i . e . the prevalence of data fabrication , falsification and alteration ) were conducted using only one outcome per study . For the same reason , in the regression analysis , which combined all available effect sizes on data fabrication , falsification and alteration , studies that had data both on self - and on non self - where used only for the former . The regression model first tested the combined effect of three methodological factors measured by binary variables ( self - vs non - self - reports , handed vs mailed questionnaire , questions using the word ‘‘falsification’’ or ‘‘fabrication’’ vs questions using ‘‘alter - ation’’ , ‘‘modification’’ etc… ) . Then , the effect of several study characteristics was tested ( year when the survey was conducted , surveys conducted in the USA vs anywhere else , surveys conducted exclusively on researchers vs any other , biomedical vs other types of research , social sciences vs natural sciences , medical consultants and practitioners vs other ) . To avoid over - fitting , each study characteristic was tested independently of the others . Questions on behaviours of secondary interest ( questionable research practices ) where too diverse to allow meaningful meta - analysis , so they were combined in broad categories for which only crude unweighted parameters were calculated . All statistical analyses were run on SPSS software package . Meta - analyses were conducted using the ‘‘MeanES’’ , ‘‘MetaF’’ and ‘‘MetaReg’’ macros by David B . Wilson [ 24 ] . Publication bias - Sensitivity analysis The popular funnel - plot - based methods to test for publication bias in meta - analysis are inappropriate and potentially misleading How Many Falsify Research ? PLoS ONE | www . plosone . org 3 May 2009 | Volume 4 | Issue 5 | e5738 when the number of included studies is small and heterogeneity is large [ 25 , 26 ] . However , the robustness of results was assessed with a sensitivity analysis . Pooled weighted estimates for effect size and regression parameters were calculated leaving out one study at a time , and then compared to identify influential studies . In addition , to further assess the robustness of conclusions , meta - analyses and meta - regression were run without logit transforma - tion . Results Flow of included studies Electronic search produced an initial list of 3276 references . Examination of titles and abstracts , and further examination of the references lists in the retrieved papers and in other sources led to a preliminary list of 69 potentially relevant studies . Of these , 61 were published in peer - reviewed journals , three were dissertations theses , three were published in non - peer reviewed popular science magazines , one was published in a book chapter , and one was published in a report . All studies were published in English except for one in Spanish . After examination of full text , 33 studies were excluded because they did not have any relevant or original data , two because they presented data exclusively in a format that could not be used in this review ( e . g . means and standard deviations ) , eight because their sample included non - researchers ( e . g . students ) and / or because they addressed forms of academic misconduct not directly related to research ( e . g . cheating on school projects ) , five because they do not distinguish fabrication and falsification from types of misconduct not relevant to the scopes of this review ( Table S1 ) . Therefore , 21 studies were included in the review . Three of these did not match the quality requirements to be included in the meta - analysis . Data from these three studies was only used to estimate crude unweighted means for QRP and more generic questions , and not for analyzing the main outcome of interest ( data fabrication , falsification , modification ) . Therefore , the meta - analysis was conducted on 18 studies ( Figure 1 ) . Study characteristics Table 1 lists the characteristics of included studies and their quality score for inclusion in meta - analysis . Included surveys were published between 1987 and 2008 , but had been conducted between 1986 ca and 2005 . Respondents were based in the United States in 15 studies ( 71 % ca of total ) , in the United Kingdom in 3 studies ( 14 % ca ) , two studies had a multi - national sample ( 10 % ca ) and one study was based in Australia . Six studies had been conducted among biomedical researchers , eight were more specifically targeted at researchers holding various positions in the medical / clinical sciences ( including pharmacology , nursing , health education , clinical biostatistics , and addiction - studies ) , six surveys had multi - disciplinary samples , one surveyed economists . Quantitative data analysis Scientists admitting misconduct . When explicitly asked if they ever fabricated or falsified research data , or if they altered or modified results to improve the outcome ( see Table S2 , questions 1 , 4 , 6 , 8 , 10 , 17 , 26 ) , between 0 . 3 % and 4 . 9 % of scientists replied affirmatively ( N = 7 , crude unweighted mean : 2 . 59 % , 95 % CI = 1 . 06 – 4 . 13 ) . Meta - analysis yielded a pooled weighted Figure 1 . Study selection flow diagram . doi : 10 . 1371 / journal . pone . 0005738 . g001 How Many Falsify Research ? PLoS ONE | www . plosone . org 4 May 2009 | Volume 4 | Issue 5 | e5738 T a b l e 1 . C h a r a c t e r i s t i c s o f s t u d i e s i n c l u d e d i n t h e r e v i e w . I D D a t e C oun t r y S a m p l e M e t ho d N ( % ) S e l f - / N on s e l f - Q u a li t y T a n g n e y , 1987 [ 32 ] n . s U S R e s e a r c h e r s i n a ‘‘ h i g h l y r a n k e d A m e r i c a n un i v e r s i t y ’’ . D i s t r i b u t e d w i t h i n d e p a r t m e n t 245 ( 22 ) n 1 L o c k , 1988 [ 29 ] 1988 U K P r o f e ss o r s o f m e d i c i n e o r s u r g e r y , o t h e r a c a d e m i c s , d o c t o r s , r e s e a r c h m a n a g e r s , e d i t o r s o f m e d i c a l j ou r n a l s non - r a n d o m l y c on t a c t e d b y t h e a u t ho r M a il e d + p r e - p a i d r e t u r n 79 ( 98 . 7 ) n 0 S i mm on s , 1991 [ 54 ] 1989 U S A c t i v e m e m b e r s o f t h e S o c i e t y o f U n i v e r s i t y S u r g e on s n . s . 202 ( 82 ) n 0 K a li c h m a n , 1992 [ 35 ] 1990 U S R e s e a r c h t r a i n ee s i n t h e c li n i c a l a n d b a s i c b i o m e d i c a l s c i e n c e s a t t h e U n i v e r s i t y o f C a li f o r n i a , S a n D i e g o D i s t r i b u t e d t h r ou g h t h e d e p a r t m e n t 549 ( 27 ) s + n 1 S w a z e y , 1993 [ 53 ] 1990 U S D o c t o r a l s t u d e n t s a n d f a c u l t y , f r o m 99 o f t h e l a r g e s t g r a d u a t e d e p a r t m e n t s i n c h e m i s t r y , c i v il e n g i n ee r i n g , m i c r o b i o l o g y a n d s o c i o l o g y M a il e d + p r e p a i d r e t u r n + p o s t c a r d t o c on f i r m r e s p on s e 2620 ( 65 . 5 ) n 1 G li c k , 1993 [ 55 ] 1992 U S B i o t e c hno l o g y c o m p a n i e s ’ e x e c u t i v e s k no w n b y t h e a u t ho r A d m i n i s t e r e d o r a ll y , on t h e p hon e 15 * ( n . s ) n 0 G r ee n b e r g , 1994 [ 20 ] 1991 U S M e m b e r s o f t h e S o c i e t y f o r R i s k A n a l y s i s , A ss o c i a t i on o f E n v i r on m e n t a l a n d R e s ou r c e E c ono m i s t s , A m e r i c a n I n d u s t r i a l H y g i e n e A ss o c i a t i on M a il e d 478 ( 32 ) n 1 G li c k , 1994 [ 30 ] 1993 U S A tt e n d ee s a t t h e T h i r d C on f e r e n c e on R e s e a r c h P o li c i e s a n d Q u a li t y A ss u r a n c e H a n d e d ou t , p e r s on a ll y r e t u r n e d b y r e s p on d e n t s on t h e s a m e 36 ( 34 ) n 1 E a s t w oo d , 1996 [ 56 ] 1993 U S A ll p o s t d o c t o r a l f e ll o w s r e g i s t e r e d w i t h t h e O ff i c e o f R e s e a r c h A ff a i r s o f t h e U n i v e r s i t y o f C a li f o r n i a , S a n F r a n c i s c o M a il e d + f o ll o w - u p l e tt e r 324 ( 32 . 8 ) s + n 1 B e b e a u , 1996 [ 33 ] 1995 U S P r o g r a m c h a i r s a n d o ff i c e r s o f t h e A m e r i c a n A ss o c i a t i on f o r D e n t a l R e s e a r c h M a il e d + p r e p a i d r e t u r n + p o s t c a r d t o c on f i r m r e s p on s e 76 ( 78 ) n 1 R a n k i n , 1997 [ 57 ] 1995 U S R e s e a r c h c oo r d i n a t o r s o r d i r e c t o r s o f m a s t e r ’ s a n d d o c t o r a l nu r s i n g p r o g r a m s M a il e d 88 ( 43 ) n 1 M a y , 1998 [ 34 ] 1997 U K R a n d o m l y s e l e c t e d a u t ho r s o f p a p e r s p u b li s h e d i n t h e p a s t 3 y e a r s on a dd i c t i on - r e l a t e d s u b j e c t s M a il e d 36 ( 51 ) n 1 R a n s t a m , 2000 [ 46 ] 1998 V a r i ou s M e m b e r s o f t h e I n t e r n a t i on a l S o c i e t y o f C li n i c a l B i o s t a t i s t i c s M a il e d + on li n e e l e c t r on i c v e r s i on 163 ( 37 ) n 1 L i s t , 2001 [ 28 ] 1998 U S P a r t i c i p a n t s t o t h e J a nu a r y 1998 m ee t i n g s o f t h e A m e r i c a n E c ono m i c A ss o c i a t i on H a n d - d e li v e r e d , D i r e c t R e s p on s e + R a n d o m R e s p on s e m e t ho d , d r o p b o x f o r r e t u r n i n g r e s p on s e s 94 ( 23 . 5 ) s 1 G e gg i e , 2001 [ 58 ] 2000 U K M e d i c a l c on s u l t a n t s a pp o i n t e d b e t w ee n J a n 1995 a n d J a n 2000 w o r k i n g i n 7 ho s p i t a l t r u s t s i n t h e M e r s e y r e g i on M a il e d + p r e - p a i d r e t u r n 194 ( 63 . 6 ) s + n 1 M e y e r , 2004 [ 59 ] n . s U S M e m b e r s o f e d i t o r i a l b o a r d s o f A m e r i c a n A cc oun t i n g A ss o c i a t i on j ou r n a l s , a n d p a r t i c i p a n t s a t t h e 1998 , 1999 , a n d 2000 A m e r i c a n A cc oun t i n g A ss o c i a t i on N e w F a c u l t y C on s o r t i a E m a il a s k i n g t o r e p l y i f u n w illi n g t o p a r t i c i p a t e , m a il e d + p r e - p a i d r e t u r n 176 ( 48 . 5 ) n 1 M a r t i n s on , 2005 [ 19 ] 2002 U S R e s e a r c h e r s f un d e d b y t h e N a t i on a l I n s t i t u t e s o f H e a l t h M a il e d , p r e - p a i d r e t u r n , 2 $ 3247 ( 47 . 2 ) s 1 H e n r y , 2005 [ 60 ] 2002 A u s t r a li a M e d i c a l s p e c i a li s t s , f r o m t h e 2002 e d i t i on o f t h e M e d i c a l d i r e c t o r y o f A u s t r a li a , i n v o l v e d i n p h a r m a c e u t i c a l i n d u s t r y - s p on s o r e d r e s e a r c h M a il e d 338 * ( n . a . ) s 1 G a r d n e r , 2005 [ 27 ] 2002 V a r i ou s A u t ho r s o f p h a r m a c e u t i c a l c li n i c a l t r i a l s p u b li s h e d i n t h e C o c h r a n e D a t a b a s e o f S y s t e m a t i c R e v i e w s , e q u a ll y s e l e c t e d b e t w ee n f i r s t , m i dd l e a n d l a s t a u t ho r . M a il e d + 10 $ c h e c k + s e c o n d s u r v e y t o non - r e s p on d e n t s + f o ll o w - u p c a ll o r e m a il 322 ( 64 ) s + n 1 K a tt e n b r a k e r 2007 [ 61 ] 2005 U S H e a l t h e d u c a t i on p r o f e ss o r s a t e v e r y r a n k , t e a c h i n g a t 94 i n s t i t u t i o n o f h i g h e r e d u c a t i on E m a il + w e b - b a s e d s u r v e y + f o ll o w u p e m a il + f i n a l r e m i n d e r 153 ( 25 . 8 ) n 1 T i t u s , 2008 [ 31 ] 2005 U S R e s e a r c h e r s f un d e d b y t h e N a t i on a l I n s t i t u t e s o f H e a l t h , on e p e r d e p a r t m e n t P r e - no t i f i c a t i on + m a il e d + r e m i n d e r p o s t c a r d + a dd i t i on a l s u r v e y p a c k e t + f o ll o w - u p l e tt e r 2212 ( 52 ) n 1 A bb r e v i a t i on s : ‘‘ D a t e ’’ i s t h e y e a r w h e n t h e s u r v e y w a s a c t u a ll y c on d u c t e d , ‘‘ N ’’ i s t h e nu m b e r o f r e s p on d e n t s w ho r e t u r n e d t h e q u e s t i onn a i r e , ‘‘ % ’’ i s t h e r e s p on s e r a t e o f t h e s u r v e y . * N u m b e r o f r e s p on d e n t s w ho a d e n g a g e d i n i n d u s t r y - s p on s o r e d r e s e a r c h i n t h e p r e v i ou s 12 m on t h s , ou t o f a t o t a l s a m p l e o f 2253 , w i t h 39 % r e s p o n s e r a t e . d o i : 10 . 1371 / j ou r n a l . p on e . 0005738 . t 001 How Many Falsify Research ? PLoS ONE | www . plosone . org 5 May 2009 | Volume 4 | Issue 5 | e5738 estimate of 1 . 97 % ( 95 % CI : 0 . 86 – 4 . 45 ) , with significant heterogeneity ( Cochran’s Q = 61 . 7777 , df = 6 , P , 0 . 0001 ) ( Figure 2 ) . If only questions explicitly using the words ‘‘fabrication’’ or ‘‘falsification’’ were included ( Table S2 , questions 3 , 6 , 10 , 26 ) , the pooled weighted estimate was 1 . 06 % ( N = 4 , 95 % CI : 0 . 31 – 3 . 51 ) Other questionable practices were admitted by up to 33 . 7 % of respondents ( Table S2 ) ( Figure 3 , N = 20 ( six studies ) , crude unweighted mean : 9 . 54 % , 95 % CI = 5 . 15 – 13 . 94 ) . Consistently across studies , scientists admitted more frequently to have ‘‘modified research results’’ to improve the outcome than to have reported results they ‘‘knew to be untrue’’ ( Inverse Variance Weighted Oneway ANOVA Q ( 1 , 4 ) = 14 . 8627 , P = 0 . 011 ) In discussing limitations of results , two studies [ 19 , 27 ] suggested that their results were very conservative with respect to the actual occurrence of misconduct , while the other studies made no clear statement . Non - response bias was recognized as a limitation by most surveys . One study employed a Random - Response technique on part of its sample to control for non - response bias , and found no evidence for it [ 28 ] ( see Discussion for further details ) . Scientists observing misconduct . When asked if they had personal knowledge of a colleague who fabricated or falsified research data , or who altered or modified research data ( Table S3 , questions , 1 , 6 , 7 , 10 , 20 , 21 , 29 , 32 , 34 , 37 , 45 , 54 ) between 5 . 2 % and 33 . 3 % of respondents replied affirmatively ( N = 12 , crude unweighted mean : 16 . 66 % , 95 % CI = 9 . 91 – 23 . 40 ) . Meta - analysis yielded a pooled weighted estimate of 14 . 12 % ( 95 % CI : 9 . 91 – 19 . 72 ) ( Figure 4 ) . If only questions explicitly using the words ‘‘fabrication’’ or ‘‘falsification’’ were included ( Table S3 , questions 1 , 6 , 7 , 10 , 17 , 21 , 29 , 32 , 37 , 45 , 54 ) , the pooled weighted estimate was 12 . 34 % ( N = 11 , 95 % CI : 8 . 43 – 17 . 71 ) Between 6 . 2 % and 72 % of respondents had knowledge of various questionable research practices ( Table S3 ) ( Figure 3 , Figure 2 . Forrest plot of admission rates of data fabrication , falsification and alteration in self reports . Area of squares represents sample size , horizontal lines are 95 % confidence interval , diamond and vertical dotted line show the pooled weighted estimate . doi : 10 . 1371 / journal . pone . 0005738 . g002 Figure 3 . Admission rates of Questionable Research Practices ( QRP ) in self - and non - self - reports . N indicates the number of survey questions . Boxplots show median and interquartiles . doi : 10 . 1371 / journal . pone . 0005738 . g003 Figure 4 . Forrest plot of admission rates of data fabrication , falsification and alteration in non - self reports . Area of squares represents sample size , horizontal lines are 95 % confidence interval , diamond and vertical dotted line show the pooled weighted estimate . doi : 10 . 1371 / journal . pone . 0005738 . g004 How Many Falsify Research ? PLoS ONE | www . plosone . org 6 May 2009 | Volume 4 | Issue 5 | e5738 N = 23 ( 6 studies ) , crude unweighted mean : 28 . 53 % , 95 % CI = 18 . 85 – 38 . 2 ) . When surveys asked about more generic questions ( e . g . ‘‘do you have knowledge of any cases of fraud ? ’’ [ 29 , 30 ] ) or defined misconduct in more comprehensive ways ( e . g . ‘‘experimental deficiencies , reporting deficiencies , misrepresenta - tion of data , falsification of data’’ [ 30 ] ) between 12 % and 92 % replied affirmatively ( Table S3 ) ( N = 10 ( seven studies ) , crude unweighted mean : 46 . 24 , 95 % CI = 16 . 53 – 75 . 95 ) . In discussing their results , three studies [ 27 , 29 , 31 ] considered them to be conservative , four [ 30 , 32 , 33 , 34 ] suggested that they overestimated the actual occurrence of misconduct , and the remaining 13 made no clear statement . Scientists reporting misconduct . Five of the included studies asked respondents what they had done to correct or prevent the act of misconduct they had witnessed . Around half of the alleged cases of misconduct had any action taken against them ( Table 2 ) . No study asked if these actions had the expected outcome . One survey [ 27 ] found that 29 % of the cases of misconduct known by respondents were never discovered . Factors influencing responses . Methodological differences between studies explained a large portion of the variance among effect sizes ( N = 15 , one outcome per study , Table 3 ) . Lower percentages of misconduct were reported in self reports , in surveys using the words ‘‘falsification’’ or ‘‘fabrication’’ , and in mailed surveys . Mailed surveys had also higher response rates than handed - out surveys ( Mean : 26 . 63 % 6 2 . 67SE and 48 . 53 % 6 4 . 02SE respectively , t - test : t = 2 2 . 812 , df = 16 , P = 0 . 013 ) , while no difference in response rates was observed between self - and non - self - reports ( Mean : 42 . 44 6 6 . 24SE and 44 . 44 6 5 . 1SE respectively , t = 2 0 . 246 , P = 0 . 809 ) and between surveys using or not ‘‘fabrication or falsification’’ ( Mean : 42 . 98 % 6 6 . 0SE and 44 . 51 6 4 . 76SE respectively , t = 2 0 . 19 , P = 0 . 85 ) . Excluding all surveys that were not mailed , were not self - reports and that did not use the words ‘‘falsification’’ or ‘‘fabrication’’ yielded a maximally conservative pooled weighted estimate of 0 . 64 % ( N = 3 , 95 % CI : 0 . 25 – 1 . 63 ) . When the three methodological factors above where controlled for , a significant effect was found for surveys targeted at medical and clinical researchers , who reported higher percentages of misconduct than respondents in biomedical research and other fields ( Table 3 ) . The effect of this parameter would remain significant if Bonferroni - corrected for multiple comparisons . If self - Table 2 . Actions taken against misconduct . ID N cases Action taken % Tangney , 1987 [ 32 ] 78 Took some action to verify their suspicions of fraud or to remedy the situation 46 Rankin , 1997 [ 57 ] 31 [ ffp ] In alleged cases of scientific misconduct a disciplinary action was taken by the dean 32 . 4 Some authority was involved in a disciplinary action 20 . 5 Ranstam , 2000 [ 46 ] 49 I interfered to prevent it from happening 28 . 6 I reported it to a relevant person or organization 22 . 4 Kattenbraker , 2007 [ 61 ] 33 Confronted individual 55 . 5 Reported to supervisor 36 . 4 Reported to Institutional Review Board 12 . 1 Discussed with colleagues 36 . 4 Titus , 2008 [ 31 ] 115 [ ffp ] The suspected misconduct was reported by the survey respondent 24 . 4 The suspected misconduct was reported by someone else 33 . 3 Abbreviations : ‘‘N cases’’ is the total number of cases of misconduct observed by respondents , [ ffp ] indicates that the number includes cases of plagiarism , ‘‘ % ’’ is the percentage of cases that had the specified action taken against them . All responses are mutually exclusive except in Kattenbraker 2007 . doi : 10 . 1371 / journal . pone . 0005738 . t002 Table 3 . Inverse variance - weighted regression on admission rates . Variable B 6 SE P Stand . Coeff . Model R 2 Base Model Constant 2 4 . 53 6 0 . 81 , 0 . 0001 0 0 . 82 Self - / Non - self 2 3 . 02 6 0 . 38 , 0 . 0001 2 1 . 04 Mailed / Handed 2 1 . 17 6 0 . 4 0 . 0032 2 0 . 33 ‘‘Fabricated , Falsified’’ / ‘‘Modified’’ 2 1 . 02 6 0 . 39 0 . 0086 2 0 . 34 Candidate co - variables Year 2 0 . 03 6 0 . 03 0 . 3 2 0 . 14 0 . 83 USA / other 2 0 . 71 6 0 . 4 0 . 08 2 0 . 2 0 . 85 Researcher / other 2 0 . 33 6 0 . 33 0 . 32 2 0 . 11 0 . 83 Biomedical / other 0 . 17 6 0 . 39 0 . 66 0 . 06 0 . 82 Medical / other 0 . 85 6 0 . 28 0 . 0022 0 . 29 0 . 89 Social Sc . / other 2 0 . 03 6 0 . 37 0 . 94 2 0 . 01 0 . 82 The table shows model parameters of an initial model including three methodological factors ( top four rows ) and the parameter values for each sample characteristic , entered one at a time in the basic model . All variables are binary . Regression slopes measure the change in admission rates when respondents fall in the first category . doi : 10 . 1371 / journal . pone . 0005738 . t003 How Many Falsify Research ? PLoS ONE | www . plosone . org 7 May 2009 | Volume 4 | Issue 5 | e5738 and non - self - reports were tested separately for the effect of study characteristics ( one characteristic at a time ) , a significant effect was found only in self - reports for year when survey was conducted ( k = 7 , b = 2 0 . 1425 6 0 . 0519 , P = 0 . 006 ) and a nearly significant effect was found again in self - reports for survey delivery method ( k = 7 , b = 2 1 . 2496 6 0 . 6382 , P = 0 . 0502 ) Sensitivity analysis Self - report admission rates varied between 1 . 65 % - following the removal of Kalichman and Friedman ( 1992 ) [ 35 ] - and 2 . 93 % - following the removal of Martinson et al . ( 2005 ) [ 19 ] ( Figure 5 ) . Reports on colleagues’ misconduct varied between 12 . 85 % ( when Tangney ( 1987 ) [ 32 ] was removed ) and 15 . 41 % ( when Titus et al . ( 2008 ) [ 31 ] was removed ( Figure 6 ) . Weighted pooled estimates on non - logit - trasformed data yielded self - and non - self - admission rates of 2 . 33 % ( 95 % CI 0 . 94 – 3 . 73 % ) and 14 . 48 % ( 95 % CI : 11 . 14 – 17 . 81 % ) respectively , showing that the results are robust and conservative . Results of the regression analysis were robust to the leave - one - study - out test : the four significant variables remained statistically significant when anyone of the studies was excluded ( Table S4 ) . The largest portion of variance was explained when Titus et al . ( 2008 ) [ 31 ] was removed ( R 2 = 0 . 9202 ) . Meta - regression on non - transformed data showed similar trends to that on transformed data for all four parameters , but only two parameters remained statistically significant ( self - / non - self - and delivery method , P , 0 . 0001 and p = 0 . 0083 respectively ) , and the overall portion of variance explained by the model was lower ( R 2 = 0 . 6904 ) . Discussion This is the first meta - analysis of surveys asking scientists about their experiences of misconduct . It found that , on average , about 2 % of scientists admitted to have fabricated , falsified or modified data or results at least once – a serious form of misconduct my any standard [ 10 , 36 , 37 ] – and up to one third admitted a variety of other questionable research practices including ‘‘dropping data points based on a gut feeling’’ , and ‘‘changing the design , methodology or results of a study in response to pressures from a funding source’’ . In surveys asking about the behaviour of colleagues , fabrication , falsification and modification had been observed , on average , by over 14 % of respondents , and other questionable practices by up to 72 % . Over the years , the rate of admissions declined significantly in self - reports , but not in non - self - reports . A large portion of the between - studies variance in effect size was explained by three basic methodological factors : whether the survey asked about self or not , whether it was mailed or handed out to respondents , and whether it explicitly used the words ‘‘fabrication’’ and ‘‘falsification’’ . Once these factors were controlled for , surveys conducted among clinical , medical and pharmacological researchers appeared to yield higher rates of misconduct than surveys in other fields or in mixed samples . All the above results were robust with respect to inclusion or exclusion of any particular study , with perhaps one exception : Martinson et al . ( 2005 ) [ 19 ] , which is one of the largest and most frequently cited surveys on misconduct published to date . This study appears to be rather conservative , because without it the pooled average frequency with which scientists admit they have committed misconduct would jump to nearly 3 % . Figure 5 . Sensitivity analysis of admission rates of data fabrication , falsification and alteration in self reports . Plots show the weighted pooled estimate and 95 % confidence interval obtained when the corresponding study was left out of the analysis . doi : 10 . 1371 / journal . pone . 0005738 . g005 Figure 6 . Sensitivity analysis of admission rates of data fabrication , falsification and alteration in non - self reports . Plots show the weighted pooled estimate obtained when the corresponding study was left out of the analysis . doi : 10 . 1371 / journal . pone . 0005738 . g006 How Many Falsify Research ? PLoS ONE | www . plosone . org 8 May 2009 | Volume 4 | Issue 5 | e5738 How reliable are these numbers ? And what can they tell us on the actual frequency of research misconduct ? Below it will be argued that , while surveys asking about colleagues are hard to interpret conclusively , self - reports systematically underestimate the real frequency of scientific misconduct . Therefore , it can be safely concluded that data fabrication and falsification – let alone other questionable research practices - are more prevalent than most previous estimates have suggested . The procedure adopted to standardize data in the review clearly has limitations that affect the interpretation of results . In particular , the percentage of respondents that recall at least one incident of misconduct is a very rough measure of the frequency of misconduct , because some of the respondents might have committed several frauds , but others might have ‘‘sinned’’ only once . In this latter case , the frequencies reported in surveys would tend to overestimate the prevalence of biased or falsified data in the literature . The history of science , however , shows that those responsible of misconduct have usually committed it more than once [ 38 , 39 ] , so the latter case might not be as likely as the former . In any case , many of the included studies asked to recall at least one incident , so this limitation is intrinsic to large part of the raw data . The distinction made in this review between ‘‘fabrication , falsification and alteration’’ of results and QRP is somewhat arbitrary . Not all alterations of data are acts of falsification , while ‘‘dropping data points based on a gut feeling’’ or ‘‘failing to publish data that contradicts one’s previous research’’ ( e . g . [ 19 ] ) might often be . As explained in the introduction , any boundary defining misconduct will be arbitrary , but intention to deceive is the key aspect . Scientists who answered ‘‘yes’’ to questions asking if they ever fabricated or falsified data are clearly admitting their intention to misrepresent results . Questions about altering and modifying data ‘‘to improve the outcome’’ might be more ambiguously interpreted , which might explain why these questions yield higher admission rates . However , even if we limited the meta - analysis to the most restrictive types of questions in self - reports , we would still have an average admission rate above 1 % , which is higher than previous estimates ( e . g . [ 11 ] ) . The accuracy of self - reports on scientific misconduct might be biased by the effect of social expectations . In self - reports on criminal behaviour , social expectations make many respondents less likely to admit a crime they committed ( typically , females and older people ) and make others likely to report a crime they have not really committed ( typically , young males ) [ 40 ] . In the case of scientists , however , social expectations should always lead to underreporting , because a reputation of honesty and objectivity is fundamental in any stage of a scientific career . Anyone who has ever falsified research is probably unwilling to reveal it and / or to respond to the survey despite all guarantees of anonymity [ 41 ] . The opposite ( scientists admitting misconduct they didn’t do ) appears very unlikely . Indeed , there seems to be a large discrepancy between what researchers are willing to do and what they admit in a survey . In a sample of postdoctoral fellows at the University of California San Francisco , USA , only 3 . 4 % said they had modified data in the past , but 17 % said they were ‘‘willing to select or omit data to improve their results’’ [ 42 ] . Among research trainees in biomedical sciences at the University of California San Diego , 4 . 9 % said they had modified research results in the past , but 81 % were ‘‘willing to select , omit or fabricate data to win a grant or publish a paper’’ [ 35 ] . Mailed surveys yielded lower frequencies of misconduct than handed out surveys . Which of the two is more accurate ? Mailed surveys were often combined with follow - up letters and other means of encouraging responses , which ensured higher response rates . However , the accuracy of responses to sensitive questions is often independent of response rates , and depends strongly on respondents’ perception of anonymity and confidentiality [ 43 , 44 ] . Questionnaires that are handed to , and returned directly by respondents might better entrust anonymity than surveys that need to be mailed or emailed . Therefore , we cannot rule out the possibility that handed out surveys are more accurate despite the lower response rates . This latter interpretation would be supported by one of the included studies : a handed out survey that attempted to measure non - response bias using a Random - Response ( RR ) technique on part of its sample [ 28 ] . Differently from the usual Direct Response technique , in RR , respondents toss coins to determine whether they will respond to the question or just mark ‘‘yes’’ . This still allows admission rates to be calculated , yet it guarantees full anonymity to respondents because no one can tell whether an individual respondent answered ‘‘yes’’ to the question or because of chance . Contrary to author’s expectations , response and admission rates were not higher with RR compared to DR , suggesting that in this handed out survey non - response bias was absent . The effect of social expectations in surveys asking about colleagues is less clear , and could depend on the particular interests of respondents . In general , scientists might tend to protect the reputation of their field , by minimizing their knowledge of misconduct [ 27 ] . On the other hand , certain categories of respondents ( e . g . participants at a Conference on Research Policies and Quality Assurance [ 30 ] ) might have particular experience with misconduct and might be very motivated to report it . Surveys on colleagues’ behaviour might tend to inflate estimates of misconduct also because the same incident might be reported by many respondents . One study controlled for this factor by asking only one researcher per department to recall cases that he had observed in that department in the past three years [ 31 ] . It found that falsification and fabrication had been observed by 5 . 2 % of respondents , which is lower than all previous non - self reports . However , since one individual will not be aware of all cases occurring around him / her , this is a conservative estimate [ 31 ] . In the sensitivity analysis run on the regression model , exclusion of this study caused the single largest increase in explained variance , which further suggests that findings of this study are unusual . Another critical factor in interpreting survey results is the respondents’ perception of what does and does not constitute research misconduct . As mentioned before , scientists were less likely to reply affirmatively to questions using the words ‘‘fabrication’’ and ‘‘falsification’’ rather than ‘‘alteration’’ or ‘‘modification’’ . Moreover , three surveys found that scientists admitted more frequently to have ‘‘modified’’ or ‘‘altered’’ research to ‘‘improve the outcome’’ than to have reported results they ‘‘knew to be untrue’’ . In other words , many did not think that the data they ‘‘improved’’ were falsified . To some extent , they were arguably right . But the fuzzy boundary between removing noise from results and biasing them towards a desired outcome might be unknowingly crossed by many researchers [ 10 , 14 , 45 ] . In a sample of biostatisticians , who are particularly well trained to see this boundary , more than half said they had personally witnessed false or deceptive research in the preceding 10 years [ 46 ] . The grey area between licit , questionable , and fraudulent practices is fertile ground for the ‘‘Mohammed Ali effect’’ , in which people perceive themselves as more honest than their peers . This effect was empirically proven in academic economists [ 28 ] and in a large sample of biomedical researchers ( in a survey assessing their adherence to Mertonian norms [ 47 ] ) , and may help to explain the lower frequency with which misconduct is admitted in self - reports : researchers might be overindulgent with their behaviour and overzealous in judging their colleagues . In support of this , one study How Many Falsify Research ? PLoS ONE | www . plosone . org 9 May 2009 | Volume 4 | Issue 5 | e5738 found that 24 % of cases observed by respondents did not meet the US federal definition of research misconduct [ 31 ] . The decrease in admission rates observed over the years in self - reports but not in non - self - reports could be explained by a combination of the Mohammed Ali effect and social expectations . The level and quality of research and training in scientific integrity has expanded in the last decades , raising awareness among scientists and the public [ 11 ] . However , there is little evidence that researchers trained in recognizing and dealing with scientific misconduct have a lower propensity to commit it [ 47 , 48 , 49 ] . Therefore , these trends might suggest that scientists are no less likely to commit misconduct or to report what they see their colleagues doing , but have become less likely to admit it for themselves . Once methodological differences were controlled for , cross - study comparisons indicated that samples drawn exclusively from medical ( including clinical and pharmacological ) research reported misconduct more frequently than respondents in other fields or in mixed samples . To the author’s knowledge , this is the first cross - disciplinary evidence of this kind , and it suggests that misconduct in clinical , pharmacological and medical research is more widespread than in other fields . This would support growing fears that the large financial interests that often drive medical research are severely biasing it [ 50 , 51 , 52 ] . However , as all survey - based data , this finding is open to the alternative interpretation that respondents in the medical profession are simply more aware of the problem and more willing to report it . This could indeed be the case , because medical research is a preferred target of research and training programs in scientific integrity , and because the severe social and legal consequences of misconduct in medical research might motivate respondents to report it . However , the effect of this parameter was not robust to one of the sensitivity analyses , so it would need to be confirmed by independent studies before being conclusively accepted . The lack of statistical significance for the effect of country , professional position and other sample characteristics is not strong evidence against their relevance , because the high between - study variance caused by methodological factors limited the power of the analysis ( the regression had to control for three methodological factors before testing any other effect ) . However , it suggests that such differences need to be explored at the study level , with large surveys designed specifically to compare groups . A few of the included studies had done so and found , for example , that admission rates tend to be higher in males compared to females [ 42 ] and in mid - career compared to early career scientists [ 19 ] , and that they tend to differ between disciplines [ 41 , 53 ] . If more studies attempted to replicate these results , possibly using standardized methodologies , then a meta - analysis could reveal important correlates of scientific misconduct . In conclusion , several surveys asking scientists about misconduct have been conducted to date , and the differences in their results are largely due to differences in methods . Only by controlling for these latter can the effects of country , discipline , and other demographic characteristics be studied in detail . Therefore , there appears to be little scope for conducting more small descriptive surveys , unless they adopted standard methodologies . On the other hand , there is ample scope for surveys aimed at identifying sociological factors associated with scientific misconduct . Overall , admission rates are consistent with the highest estimates of misconduct obtained using other sources of data , in particular FDA data audits [ 11 , 18 ] . However , it is likely that , if on average 2 % of scientists admit to have falsified research at least once and up to 34 % admit other questionable research practices , the actual frequencies of misconduct could be higher than this . Supporting Information Table S1 Studies excluded from the review . Found at : doi : 10 . 1371 / journal . pone . 0005738 . s001 ( 0 . 14 MB DOC ) Table S2 Self - report questions included in review , and respons - es . Found at : doi : 10 . 1371 / journal . pone . 0005738 . s002 ( 0 . 07 MB DOC ) Table S3 Non - self report questions included in the review , and responses . Found at : doi : 10 . 1371 / journal . pone . 0005738 . s003 ( 0 . 11 MB DOC ) Table S4 Sensitivity analysis for meta - regression model . Found at : doi : 10 . 1371 / journal . pone . 0005738 . s004 ( 0 . 07 MB DOC ) Acknowledgments I wish to thank Nicholas Steneck , Tom Tregenza , Gavin Stewart , Robin Williams and two anonymous referees for comments that helped to improve the manuscript , and Moyra Forrest for helping to search the literature . Author Contributions Conceived and designed the experiments : DF . Performed the experiments : DF . Analyzed the data : DF . Wrote the paper : DF . References 1 . Saunders R , Savulescu J ( 2008 ) Research ethics and lessons from Hwanggate : what can we learn from the Korean cloning fraud ? Journal of Medical Ethics 34 : 214 – 221 . 2 . Service RF ( 2003 ) Scientific misconduct - More of Bell Labs physicist’s papers retracted . Science 299 : 31 – 31 . 3 . Marshall E ( 2000 ) Scientific misconduct - How prevalent is fraud ? That’s a million - dollar question . Science 290 : 1662 – 1663 . 4 . Sovacool BK ( 2008 ) Exploring scientific misconduct : isolated individuals , impure institutions , or an inevitable idiom of modern science ? Journal of Bioethical Inquiry 5 : 271 – 282 . 5 . Bogner A , Menz W ( 2006 ) Science crime : the Korean cloning scandal and the role of ethics . Science & Public Policy 33 : 601 – 612 . 6 . Koshland DE ( 1987 ) Fraud in Science . Science 235 : 141 . 7 . La Follette MC ( 2000 ) The evolution of the ‘‘scientific misconduct’’ issues : an historical overview . Procedings of the Society for Experimental Biology and Medicine 224 : 211 – 215 . 8 . Merton RK ( 1942 ) The normative structure of science . In : Merton RK , ed ( 1942 ) The Sociology of Science : Theoretical and Empirical Investigations . Chicago , IL : University of Chicago Press . 9 . Sismondo S ( 2004 ) An introduction to science and technology studies . Malden , Mass . : Blackwell . 10 . Smith R ( 2000 ) What is research misconduct ? The COPE Report 2000 : the Committee on Publication Ethics . 11 . Steneck NH ( 2006 ) Fostering integrity in research : definitions , current knowledge , and future directions . Science and Engineering Ethics 12 : 53 – 74 . 12 . Babbage C ( 1830 ) Reflections on the decline of science in England and on some of its causes . In : Campbell - Kelly M , ed ( 1830 ) The Works of Charles Babbage . London Pickering . 13 . Krimsky S ( 2007 ) When conflict - of - interest is a factor in scientific misconduct . Medicine and Law 26 : 447 – 463 . 14 . De Vries R , Anderson MS , Martinson BC ( 2006 ) Normal misbehaviour : scientists talk about the ethics of research . Journal of Empirical Research on Human Research Ethics 1 : 43 – 50 . 15 . Guston DH ( 1999 ) Changing explanatory frameworks in the US government’s attempt to define research misconduct . Science and Engineering Ethics 5 : 137 – 154 . 16 . Steneck NH ( 2003 ) The role of professional societies in promoting integrity in research . American Journal of Health Behaviour 27 : S239 – S247 . How Many Falsify Research ? PLoS ONE | www . plosone . org 10 May 2009 | Volume 4 | Issue 5 | e5738 17 . Claxton LD ( 2005 ) Scientific authorship Part 1 . A window into scientific fraud ? Mutation Research - Reviews in Mutation Research 589 : 17 – 30 . 18 . Glick JL ( 1992 ) Scientific data audit - a key management tool . Accountability in Research 2 : 153 – 168 . 19 . Martinson BC , Anderson MS , de Vries R ( 2005 ) Scientists behaving badly . Nature 435 : 737 – 738 . 20 . Greenberg M , Goldberg L ( 1994 ) Ethical challenges to risk scientists : an exploratory analysis of survey data . Science , Technology , and Human Values 19 : 223 – 241 . 21 . Greenland S ( 1994 ) Quality scores are useless and potentially misleading - Reply to Re - a Critical - Look at Some Popular Analytic Methods . American Journal of Epidemiology 140 : 300 – 301 . 22 . Juni P , Witschi A , Bloch R , Egger M ( 1999 ) The hazards of scoring the quality of clinical trials for meta - analysis . Jama - Journal of the American Medical Association 282 : 1054 – 1060 . 23 . Lipsey M , Wilson DB ( 2001 ) Practical meta - analysis . California : Sage Publications . 24 . Wilson DB ( 2005 ) SPSS Macros for Meta - analysis , Available at : http : / / mason . gmu . edu / , dwilsonb / ma . html . 25 . Terrin N , Schmid CH , Lau J , Olkin I ( 2003 ) Adjusting for publication bias in the presence of heterogeneity . Statistics in Medicine 22 : 2113 – 2126 . 26 . Macaskill P , Walter SD , Irwig L ( 2001 ) A comparison of methods to detect publication bias in meta - analysis . Statistics in Medicine 20 : 641 – 654 . 27 . Gardner W , Lidz CW , Hartwig KC ( 2005 ) Authors’ reports about research integrity problems in clinical trials . Contemporary Clinical Trials 26 : 244 – 251 . 28 . List JA , et al . ( 2001 ) Academic economists behaving badly ? A survey on three areas of unethical behaviour . Economic Inquiry 39 : 162 – 170 . 29 . Lock S ( 1988 ) Misconduct in medical research : does it exist in Britain ? British Medical Journal 297 : 1531 – 1535 . 30 . Glick LJ , Shamoo AE ( 1994 ) Results of a survey on research practices , completed by attendees at the third conference on research policies and quality assurance . Accountability in Research 3 : 275 – 280 . 31 . Titus SL , Wells JA , Rhoades LJ ( 2008 ) Repairing research integrity . Nature 453 : 980 – 982 . 32 . Tangney JP ( 1987 ) Fraud will out ? Or will it ? New Scientist 115 : 62 – 63 . 33 . Bebeau MJ , Davis EL ( 1996 ) Survey of ethical issues in dental research . Journal of Dental Research 75 : 845 – 855 . 34 . May C , Campbell S , Doyle H ( 1998 ) Research misconduct : A pilot study of British addiction researchers . Addiction Research 6 : 371 – 373 . 35 . Kalichman MW , Friedman PJ ( 1992 ) A pilot study of biomedical trainees’ perceptions concerning research ethics . Academic Medicine 67 : 769 – 775 . 36 . COPE ( 2000 ) The COPE report 2000 . Committee on Publication Ethics . 37 . Berk RA , Korenman SG , Wenger NS ( 2000 ) Measuring consensus about scientific research norms . Science and Engineering Ethics 6 : 315 – 340 . 38 . Judson HF ( 2004 ) The Great Betrayal : Fraud in Science . Orlando , Florida : Harcourt . 39 . Grant J ( 2007 ) Corrupted Science : Fraud , Ideology and Politics in Science . Wisley , UK : Facts , Figures and Fun ( AAPPL ) . 40 . Farrington DP ( 2003 ) What has been learned from self - reports about criminal careers and the causes of offending . London : Home Office . 41 . Martinson BC , Anderson MS , Crain LA , De Vries R ( 2006 ) Scientists’ perceptions of organizational justice and self - reported misbehaviours . Journal of Empirical Research on Human Research Ethics 1 : 51 – 66 . 42 . Eastwood S , Derish P , Leash E , Ordway S ( 1996 ) Ethical issues in biomedical research : Perceptions and practices of postdoctoral research fellows responding to a survey . Science and Engineering Ethics 2 : 89 – 114 . 43 . Tourangeau R , Smith TW ( 1996 ) Asking sensitive questions - The impact of data collection mode , question format , and question context . Public Opinion Quarterly 60 : 275 – 304 . 44 . Bates SC , Cox JM ( 2008 ) The impact of computer versus paper - pencil survey , and individual versus group administration , on self - reports of sensitive behaviours . Computers in Human Behaviour 24 : 903 – 916 . 45 . Lyno¨e N , Jacobsson L , Lundgren E ( 1999 ) Fraud , misconduct or normal science in medical research - an empirical study of demarcation . Journal of Medical Ethics 25 : 501 – 506 . 46 . Ranstam J , Buyse M , George SL , Evans S , Geller NL , et al . ( 2000 ) Fraud in medical research : An international survey of biostatisticians . Controlled Clinical Trials 21 : 415 – 427 . 47 . Anderson MS , Martinson BC , De Vries R ( 2007 ) Normative dissonance in science : results from a national survey of US scientists . Journal of Empirical Research on Human Research Ethics 2 : 3 – 14 . 48 . Plemmons DK , Brody SA , Kalichman MW ( 2006 ) Student perceptions of the effectiveness of education in the responsible conduct of research . Science and Engineering Ethics 12 : 571 – 582 . 49 . Turrens JF ( 2005 ) Teaching research integrity and bioethics to science undergraduates . Cell Biol Educ 4 : 330 – 334 . 50 . Angell M ( 2000 ) Is academic medicine for sale ? New England Journal of Medicine 342 : 1516 – 1518 . 51 . Bekelman JE , Li Y , Gross CP ( 2003 ) Scope and impact of financial conflicts of interest in biomedical research - A systematic review . Jama - Journal of the American Medical Association 289 : 454 – 465 . 52 . Sismondo S ( 2008 ) Pharmaceutical company funding and its consequences : a qualitative systematic review . Contemporary Clinical Trials 29 : 109 – 113 . 53 . Swazey J , Anderson M , Karen L ( 1993 ) Ethical problems in academic research . American Scientist 81 : 542 – 553 . 54 . Simmons RL , Polk HCJ , Williams B , Mavroudis C ( 1991 ) Misconduct and fraud in research : social and legislative issues symposium of the Society of University Surgeons . Surgery 110 : 1 – 7 . 55 . Glick JL ( 1993 ) Perceptions concerning research integrity and the practice of data audit in the biotechnology industry . Account Res 3 : 187 – 195 . 56 . Eastwood S , Derish P , Leash E , Ordway S ( 1996 ) Ethical issues in biomedical research : perceptions and practices of postdoctoral research fellows responding to a survey . Science and Engineering Ethics 2 : 89 – 114 . 57 . Rankin M , Esteves MD ( 1997 ) Perceptions of scientific misconduct in nursing . Nursing Research 46 : 270 – 276 . 58 . Geggie D ( 2001 ) A survey of newly appointed consultants’ attitudes towards research fraud . Journal of Medical Ethics 27 : 344 – 346 . 59 . Meyer MJ , McMahon D ( 2004 ) An examination of ethical research conduct by experienced and novice accounting academics . Issues in Accounting Education 19 : 413 – 442 . 60 . Henry DA , Kerridge IH , Hill SR , McNeill PM , Doran E , et al . ( 2005 ) Medical specialists and pharmaceutical industry - sponsored research : a survey of the Australian experience . Medical Journal of Australia 182 : 557 – 560 . 61 . Kattenbraker MS ( 2007 ) Health education research and publication : ethical considerations and the response of health educators . Carbondale : Southern Illinois University . Doctoral dissertation . How Many Falsify Research ? PLoS ONE | www . plosone . org 11 May 2009 | Volume 4 | Issue 5 | e5738