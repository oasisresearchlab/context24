PortraitSketch : Face Sketching Assistance for Novices Jun Xie Univ . of Washington Aaron Hertzmann Adobe Research Wilmot Li Adobe Research Holger Winnem¨oller Adobe Research 9 / 9 Figure 1 : Results generated with PortraitSketch . Starting from image ( a ) , a novice user created sketch ( b ) using our system without automated assistance . The same user created sketch ( e ) with automated assistance . For direct comparison , we post - adjusted ( b ) to generate ( c ) . The assisted results ( c and e ) exhibit cleaner , more accurate outlines and more evenly distributed shading , compared to the unassisted drawing ( b ) . All nine of our independent judges voted that ( c ) is a better drawing than ( b ) . Image credits : ( a ) and ( d ) : Levy Carneiro Jr and chris zerbes , under a Creative Commons license . ABSTRACT We present PortraitSketch , an interactive drawing system that helps novices create pleasing , recognizable face sketches without requiring prior artistic training . As the user traces over a source portrait photograph , PortraitSketch automati - cally adjusts the geometry and stroke parameters ( thickness , opacity , etc . ) to improve the aesthetic quality of the sketch . We present algorithms for adjusting both outlines and shad - ing strokes based on important features of the underlying source image . In contrast to automatic stylization systems , PortraitSketch is designed to encourage a sense of owner - ship and accomplishment in the user . To this end , all ad - justments are performed in real - time , and the user ends up directly drawing all strokes on the canvas . The ﬁndings from our user study suggest that users prefer drawing with some automatic assistance , thereby producing better drawings , and that assistance does not decrease the perceived level of in - volvement in the creative process . Author Keywords Sketching ; Portraits ; Novices ; Creativity Support Tool ACM Classiﬁcation Keywords H . 5 . 2 HCI : User Interfaces Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full cita - tion on the ﬁrst page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or re - publish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and / or a fee . Request permissions from permissions @ acm . org . UIST 2014 , October 5 – 8 , 2014 , Honolulu , HI , USA . Copyright c (cid:13) 2014 ACM 978 - 1 - 4503 - 3069 - 5 / 14 / 10 . . . $ 15 . 00 . http : / / dx . doi . org / 10 . 1145 / 2642918 . 2647399 INTRODUCTION Drawing / sketching is arguably one of the most accessible art forms , requiring only a drawing tool , some paper , and the willingness to engage in a creative task . However , many peo - ple feel that they lack the ability to draw well and end up cre - ating primitive , iconic sketches [ 8 ] . According to many art books , a high - level problem is that non - artists tend to draw “ what they know , ” instead of “ what they see . ” In other words , non - artists draw objects based on their knowledge of the ob - ject geometry whereas artists choose which lines to draw based on the pose and lighting of the scene they are trying to depict . Furthermore , non - artists often lack low - level techni - cal skills that can affect drawing quality , such as the ability to produce accurate , clean outlines or shaded regions with even tone . Art books and courses can help novices improve their drawing ability , but most people do not have the time to attend classes and hone their skills through dedicated practice . The goal of our work is to develop a digital drawing system for novices , which they can use to create better sketches with - out requiring formal artistic training . There are several im - portant requirements for such a system . Since novices are the target audience , the system should be easy to learn and ro - bust to input from users with poor drawing skills , while still producing good results . The system should also promote the users’ sense of ownership over their drawings . If a user feels he signiﬁcantly contributed to the creation of a drawing that is of sufﬁcient aesthetic quality , he might perceive the process as a rewarding experience of creative expression . Addition - ally , every user draws lines slightly differently , which results in a unique style . Ideally , the system should preserve style . Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 407 There clearly is tension between these requirements . A com - pletely automatic system that generates drawings at the push of a button is easy to learn and robust to unskilled input , but does not preserve a user’s style or encourage ownership over the results . Conversely , a completely manual drawing sys - tem preserves style but is not robust . In our view , resolving this tension is the main challenge in designing a successful drawing system for novices . In essence , our goal is a system that assists with the low - level mechanics of drawing , such as ensuring that lines align well with the image , but where all high - level decisions are made by the user . In this paper , we present PortraitSketch , an interactive draw - ing system that helps users create drawings of faces . Faces have clear social importance but are very difﬁcult to draw . In our recruiting survey ( 59 respondents ) , 85 % said they would like to draw Portraits ( vs . Landscape 70 % , Abstract 61 % , Still Life 56 % , Other 3 % ) . The main drawing interaction of PortraitSketch involves users tracing over a transparent version of a source portrait photograph . The system has three key features that address the requirements described above : Automatic outline adjustment . PortraitSketch automatically adjusts the shape , position , thickness and opacity of outline strokes based on important visual features in the source image , such as strong gradients and facial landmarks . In this , we build on the work of Limpaecher et al . [ 16 ] , while making a number of improvements . Automatic shading adjustment . The system adjusts shading strokes to produce more even tones that match the shading variations in the source portrait . Shading guidance . PortraitSketch provides an interactive shading visualization , suggesting where users might add additional shading strokes to better match the source image . These features make the system robust to novice input by improving the accuracy and quality of the outline and shading strokes , and by helping users visualize where to add shading . At the same time , the fact that PortraitSketch allows users to add every stroke in the ﬁnal image themselves keeps them highly involved in the creative process and gives them signiﬁcant control over the style of the output . Figures 1 and 7 show results generated using our system , both with and without automatic assistance . Note that our system makes very subtle changes , but with a substantial effect on the quality of the resulting drawing . In general , the assisted drawings are more aesthetically pleasing and show a range of interesting stylistic variations . To evaluate our system , we recruited 24 novices to create drawings using PortraitSketch , with different levels of assis - tance . We collected self - rating data about the drawing behav - ior , drawing results , and subjective ownership experienced across the assistance conditions . We also asked independent judges to evaluate the resulting drawings . Our ﬁndings sug - gest that users prefer drawing with some amount of assis - tance over no assistance , and that assistance does improve the quality of the drawings . There is no evidence that assis - tance diminishes the perceived involvement of users in the creative task , and visual inspection of the drawings indicates that many unique stylistic qualities of individual users are pre - served across all levels of assistance . RELATED WORK There exists extensive work on producing artistic renderings of portraits ( see Zhao and Zhu [ 22 ] for an overview ) . How - ever , these techniques are designed to work automatically , while we aim to provide an interactive drawing experience where the user actively engages in the creative process . Our work does share some technical details with recent work by Berger et al . [ 3 ] , who adopt a data - driven method for gen - erating face images in a range of different styles . Our face feature analysis and edge detection model is similar to theirs , and a measure related to their importance estimation of edges for level - of - detail abstraction is heuristically encoded in our parametric adjustments for facial outlines . Still , their high - level goal remains the automatic synthesis of images rather than interactive assistance . Furthermore , their model does not address shading , which is a key component of our system . A related topic is sketch reﬁnement or beautiﬁcation [ 1 , 2 , 17 ] . These systems aggressively modify the user’s drawing to produce results that meet speciﬁc critiera and in the process signiﬁcantly change the style of input strokes , often combin - ing or removing them entirely . Moreover , beautiﬁcation sys - tems typically do not provide assistance during the drawing process . Our method also modiﬁes strokes , but it does so in an interactive manner that is designed to both assist novice users and preserve their unique drawing style . We note that Zit - nick [ 23 ] does present a real - time sketch beautiﬁcation sys - tem that aims to preserve style , but the approach focuses on handwriting ( or other repetitive symbols ) rather than faces . Some previous work on drawing has focused on teaching tra - ditional skills . Dixon et al . [ 7 ] help users learn to draw faces by providing step - by - step instructions , analyzing a user’s per - formance , and giving feedback about inaccuracies . Cum - mings et al . [ 6 ] apply the same approach to eyes . While such systems help users improve their drawing ability , this process takes time . Our aim is to enable novices to create compelling results at their current skill level . Although users may even - tually learn some transferable skills after creating drawings with PortraitSketch , this is not our primary goal . In addition , most teaching systems require manual curation or preparation of the learning content , which makes it difﬁcult scale to new content ( e . g . , arbitrary source photographs ) . One exception is the work of Iarussi et al . [ 12 ] , who analyze a source image and propose construction lines used in traditional drawing to guide the user and help them learn how to perceive and trans - fer shape and proportions to the page . While we also use image analysis to assist novice users as they draw , we adopt different techniques that are designed to work well with faces . The most relevant previous efforts are those that focus specif - ically on real - time assistance for creative drawing tasks . Fer - nquist et al . [ 9 ] allow users to follow tutorials that are auto - matically generated from artists recorded performances and provide corrective feedback of the tutorial . However , this process still requires manual , expert curation . Lee et al . [ 14 ] Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 408 compare user strokes to edges in a database of images to sug - gest possible future lines using a blended - average shadow visualization . Their system is geared toward serendipitous exploration of the database content , whereas our focus is on assisting users in drawing a speciﬁc portrait . Flagg et al . [ 10 ] propose a multi - projector display to offer visual paint - ing guidance for real - world painting . We would like to offer a simple solution without complex hardware requirements . The DrawAFriend system [ 16 ] for tracing portrait photographs is most closely related to PortraitSketch . However , rather than using image analysis and computer vision to assist the user , they rely on crowd - sourcing . While this approach works well for common , popular images ( e . g . photos of celebrities ) , DrawAFriend does not help an individual user draw a spe - ciﬁc personal photo . In addition , since the consensus for de - termining an ideal sketch in DrawAFriend is deduced from many novice peers , it is possible that common novice mis - takes ( e . g . , drawing eyes as simpliﬁed almond shapes ) may result in sub - optimal drawing corrections . Additionally , we use facial landmarks to ensure that any single outline stroke is only mapped to a single facial feature ( e . g . , eye or mouth ) . Finally , we also aim to help users create hatched shading re - gions . While Salisbury et al . [ 18 ] provide high - level tools for creating hatching in user - speciﬁed regions , our system allows users to participate more actively in the drawing process by directly drawing their own shading strokes . SYSTEM PortraitSketch is designed for ease - of - use . The user simply loads a facial portrait photograph , and starts tracing over the image with a drawing tool . The system is used with a Wacom stylus and tablet , though a mouse or touch interface could be used instead . The tracing is shown on a white background with the portrait faded , and opacity controlled by a slider . Only two tools are available to the user : The outline tool , to depict the shapes of an image , and the shading tool , option - ally used to apply different types of shading , such as hatching , cross - hatching , scumbling , or “ﬁll . ” Using two tools , instead of one , has several advantages . We ﬁnd that users obtain bet - ter results when starting with at least a basic outline of a face before shading it , and using two tools encourages this work - ﬂow . Outlines and shading are often drawn in different styles ( line thickness etc . ) and the two tools can be conceptualized as presets for these styles . Finally , the system can give more targeted assistance if it knows the type of line being drawn . To help users overcome their artistic and technical challenges , PortraitSketch offers several forms of assistance : ( 1 ) Stroke beautiﬁcation , which makes strokes look better ; ( 2 ) Geomet - ric corrections , which improves shape depiction ; ( 3 ) Seman - tic corrections , which de - emphasizes strokes that a skilled artist would be unlikely to draw ; and ( 4 ) Visualization , which guides users in where to draw next . To foster a user’s sense of ownership over the results , we ad - here to the following guidelines when providing assistance : each stroke shown by the system is drawn by the user ; no strokes are generated automatically . Adjustments are kept “small ; ” strokes may not be dramatically altered , and , even when altered , we aim to preserve the user’s style . OUTLINE TOOL The outline tool assists in drawing outlines and contours . The user draws strokes , represented initially as polylines , and the system applies several types of adjustments to the strokes . These adjustments are based on the typical problems with strokes drawn by novices . In particular , strokes may be un - certain and jittery , they may lack dynamics ( skillful pressure variations of an artist’s pen ) , they may represent “incorrect” lines due to semantic bias , and even correct lines may be mis - placed due to poor hand - eye - coordination . The latter issue can also arise for trained artists when using a low - ﬁdelity in - put device , such as a touch - screen ( “fat ﬁnger problem” ) . Beautiﬁcation The raw polyline input for each stroke must be resampled and smoothed , to reduce data - size and jitter . To avoid discarding intentional curvature variations , smoothing is performed in a curvature - adapted manner , similar to Zitnick [ 23 ] , in which we sequentially re - sample the input stroke based both on the amount of curvature and the distance of samples . The re - sampled points are ﬁtted with cubic B - splines , which are ren - dered as thick triangle strips , with optional tapering or brush textures for increased realism . This approach is simple to im - plement , yet supports a variety of styles . Geometric Adjustment : Outline The geometric adjustment stage modiﬁes stroke positions to better align with image contours , while still preserving the user’s stroke style . This helps when a user has difﬁculty fol - lowing the shape of curves in the reference image . Guidance Map and Face Part Labeling — Geometric adjustment requires the system to have a best guess as to where strokes should be drawn . Prior to the drawing process , we produce a binary Guidance Map , where black pixels represent sug - gested locations for strokes ( Figure 2 ) . We also identify fa - cial landmark positions , corresponding to facial parts , such as eyes , nose , etc . Additionally , each black pixel in the Guid - ance Map is labeled with the closest facial part . Previous ﬁndings have shown that many artist - drawn strokes can be explained in terms of image intensity gradients [ 4 ] . Motivated by this , we had two artists draw outlines and shading of several faces . We then evaluated various edge - detection ﬁlters before settling on the eXtended Difference - of - Gaussians ( XDoG ) [ 21 ] ﬁlter , which produces a binary image resembing a line drawing . As shown in Figure 2 , the XDoG yields a reasonable approximation not only of the out - lines an artist might draw , but also indicates shading regions well . The XDoG ﬁlter produces an image curvature ( κ ) value for each pixel , which we use to compute pixelwise correspon - dences , since pixels with similar curvatures are more likely to correspond . Facial landmarks ( Figure 2 ( f ) ) are located using an exist - ing labeling algorithm [ 19 ] that identiﬁes points on the face corresponding to the eyes , eyebrows , nose , mouth and con - tour . We also manually add eye iris and forehead landmarks , though the labeling algorithm could easily be trained to detect Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 409 ( a ) ( b ) ( c ) ( d ) ( e ) ( f ) Figure 2 : Guidance map . ( a ) Source portrait . ( b ) Output of original XDoG algorithm . ( c ) Overlay of outline sketch by a trained artist over the XDoG response . ( d ) Output of XDoG algorithm with settings for shading . ( e ) Overlay of artist’s shading sketch and XDoG response . ( f ) Facial landmarks . Each landmark is a point on the face . Landmarks are connected by line segments , for visualization ( and curvature computation . ) . Image credits : Erich Ferdinand , under a Creative Commons license . them automatically . The landmarks are connected by pre - determined polylines , and per - landmark curvatures ( κ ) are computed from the angles of the polyline . We also precompute a part labeling of each pixel in the Guid - ance Map . Each black pixel in the Guidance Map is assigned the label of the nearest landmark in ( x , y , κ ) space . Non - face pixels are labeled as background . Optimization — Given the input stroke and the precomputed maps , our goal is to correct a user’s input stroke toward the closest guidance feature , while retaining as much of the in - put stroke’s stylistic variations as possible . We formulate an energy function comprised of a Guidance Map energy , face landmark energy , and user input variation : E = αE guide + βE land + γE var ( 1 ) The weights α , β , γ adjust the contribution of each compo - nent . For our study , we experimentally choose their values to be 4 , 2 , and 1 , respectively . The input stroke is described by a list of N points in 2D : p 1 : N = [ p 1 , . . . , p N ] , and the opti - mization produces a new list of points q 1 : N = [ q 1 , . . . , q N ] . Prior to optimization , the algorithm assigns a face - part la - bel for the stroke , to determine correspondence between the stroke and the Guidance Map . Assuming that users typically draw a stroke for one face feature at a time , we disambiguate conﬂicting labels of a stroke’s control points by majority vot - ing . Namely , each control point is assigned the nearest label from the nearest landmark . Thus , unlike the DrawAFriend system [ 16 ] , our system effectively prevents a single stroke from being aligned to multiple facial features ( e . g . , the eye and eyebrow ) . This gives N votes , and the majority label is assigned to the stroke . Ties are broken in favor of the label with the smallest average distance to nearest neighbors . The objective terms are as follows . For alignment with Guid - ance Map edges , we deﬁne E guide ( q 1 : N ) = N (cid:88) i = 1 (cid:107) q i − g i (cid:107) 2 (cid:107) p i − g i (cid:107) ( 2 ) where g i is the position of the closest Guidance Map pixel to p i with the same part label as the stroke . The denominator is used to downweight this term for distant pixels that are less likely to represent a correct guidance match . Similarly , for face landmark alignment , we deﬁne E land ( q 1 : N ) = N (cid:88) i = 1 (cid:107) q i − f i (cid:107) 2 (cid:107) p i − f i (cid:107) ( 3 ) where f i is the facial feature closest to p i with the same la - bel as the stroke . To preserve stylistic input variations , we minimize changes to the curve tangents , similar to [ 16 ] : E var ( q 1 : N ) = n (cid:88) i = 2 (cid:107) ( q i − q i − 1 ) − ( p i − p i − 1 ) (cid:107) 2 ( 4 ) Subﬁgures 3 ( b , c , d ) show an example of an outline sketch before and after geometric correction . The optimization in Equation 1 is solved by a least squares solver . We also provide a level - of - assistance parameter λ ∈ [ 0 . . . 1 ] . Given the optimized stroke q ∗ , the ﬁnal output stroke is a lin - ear interpolation of the input stroke and the optimized stroke : q out i = λ q ∗ i + ( 1 − λ ) p i ( 5 ) Semantic Correction : Outline Even when tracing , a novice may draw lines that a trained artist would not . This is typically caused by a semantic bias , where knowledge of object properties bias a novice to depict lines that are either weak or merely imagined . To mitigate this problem , our system emphasizes lines that are deemed to be “correctly” drawn , whereas de - emphasizing lines that are drawn “incorrectly” . For each point on an outline stroke , the algorithm computes the distance from the point to the nearest Guidance Map pixel . This distance is smoothed along the stroke , and then used to adjust the width and opacity of the stroke . Emphasized strokes are wider and / or more opaque while de - emphasis uses the opposite mechanism . Figure 3 ( e ) shows the sketch result after semantic correction . Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 410 ( a ) ( b ) ( c ) ( d ) ( e ) Figure 3 : Outline Adjustment Comparison . ( a ) Source portrait . ( b ) No assistance . ( c ) Geometric correction . ( d ) Overlay of no assistance ( red ) and geometric correction ( black ) . ( e ) Semantic correction . Note the geometric correction of the lower eyelid and semantic correction of the teeth and right bridge of the nose . Here , we use opacity for stroke emphasis . Freehand Strokes Outline strokes are left unadjusted in 2 situations , as follows . First , input strokes too far from guidance features are left un - adjusted . This case is detecting by checking if 1 N N (cid:88) i = 1 max ( (cid:107) p i − g i (cid:107) , (cid:107) p i − f i (cid:107) ) ( 6 ) passes above a preset threshold . In this case , λ is set to zero . Second , strokes drawn in “ ﬁll ” regions are uncorrected . We deﬁne ﬁll regions as dense XDoG regions whose response is close to the shading response ( see below ) . For example , hair regions often exhibit too many edges to meaningfully align user strokes . We detect such regions by comparison with shading regions and locally set λ = 0 . SHADING TOOL Shading gives visual cues about lighting , 3D shape of a de - picted object , and can indicate material properties and tex - ture such as hair . Shading is a more advanced skill than out - line drawing , and is particularly challenging and tedious for novices . We now describe a novel tool for assisting in the drawing of shading strokes . Shading Region Detection The shading tool takes as input a Shading Map , indicating parts of the image requiring shading . This is used in the inter - active system both for shading visualization and assistance . The Shading Map is generated by ﬁrst deﬁning the total face area ( using face feature data ) minus eyes and mouth regions , as these should not be shaded . The color histogram of the remaining face pixels typically exhibits two peaks , intuitively corresponding to skin color and shadow . These regions are clustered by ﬁtting a Gaussian Mixture Model with two clus - ters as N ( µ 1 , σ 1 ) and N ( µ 2 , σ 2 ) . XDoG is run twice on the image with two different threshold parameter settings : (cid:15) 1 = µ 1 − 3 σ 1 and (cid:15) 2 = µ 2 − 3 σ 2 . The difference of the ﬁlter responses deﬁnes the shading region . We also run the Mean Shift algorithm [ 5 ] to extract shadable skin regions outside the face ( e . g . , neck , shoulders ) . The ﬁnal shading region is shown in Figure 4 ( a ) . Shading Guidance Visualization The suggested shading regions are overlaid on the reference image in transparent red with opacity corresponding to shad - ing intensity . An optional feedback mode fades the shading guidance according to the amount of shading strokes already applied by the user . Shading Strokes Correction As soon as they are drawn , shading strokes are re - sampled and smoothed in the same way outlines are . Then , the system adjusts the spacing of shading strokes to distribute them more evenly to produce an even tone [ 18 ] . Our hatching stroke correction uses an energy minimization inspired by the streamline placement method of Turk and Banks [ 20 ] . When the user places a new shading stroke , we optimize all strokes in a local neighborhood of the new stroke , including the input stroke . Let k index this set of K strokes , so that P ( k ) = [ p ( k ) 1 , . . . p ( k ) N k ] is the k - th stroke . Our goal is to produce updated positions Q ( k ) . We minimize an energy over all control points of all neighboring strokes : E ( Q ( 1 : K ) ) = E tone ( Q ( 1 : K ) ) + E var ( Q ( 1 : K ) ) ( 7 ) The ﬁrst term E tone , encourages strokes to be evenly dis - tributed while matching the target tone . Let S be a binary image of all strokes , and G ∗ S be a Gaussian - blurred version of this image , and let the target ( suggested ) shading map from preprocessing be T . The energy is : E tone ( Q ( 1 : K ) ) = (cid:107) G ∗ S ( Q ( 1 : K ) ) − T (cid:107) 2 ( 8 ) This energy is summed over all pixels in the image , though in implementation only pixels nearby the control points being optimized need to be considered . As in ( Equation 4 ) , E var preserves input stroke tangents : E var = K (cid:88) k = 1 N k (cid:88) j = 2 w j (cid:107) ( q ( k ) j − q ( k ) j − 1 ) − ( p ( k ) j − p ( k ) j − 1 ) (cid:107) 2 ( 9 ) where w downweights strokes that are perpendicular to the input stroke to allow for cross - hatching . In particular , let d ( k ) = q ( k ) N k − q ( k ) 1 be the average direction of a stroke . We Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 411 ( a ) ( b ) ( c ) ( d ) Figure 4 : Shading Adjustment Comparison . ( a ) Source portrait with visual shading guidance . ( b ) No assistance . ( c ) Geometric correction . ( d ) Semantic correction . set w inversely proportional to d ( k ) · d ( in ) . When the angle between these directions is greater than > 30 ◦ , the weight is set to zero , which typically corresponds to cross - hatches . The level of assistance is adjusted by the λ parameter as in Eq . 5 . We solve the above optimization as follows . The al - gorithm computes the blur map G ∗ S . Then , each control point is separately updated by a few gradient descent steps , and the process repeats . Image gradients are computed by ﬁ - nite differences . The algorithm runs about 10 - 30 iterations to convergence , requiring about 1 - 2 ms per iteration . Multi - stroke Support Fine hatching can be tedious and difﬁcult . To make it eas - ier , the hatching tool draws multiple parallel stroke for each user stroke ( similar to [ 13 ] ) . The number of strokes reduces locally in areas with little shading to allow for ﬁner shad - ing control . The multi - stroke feature naturally creates evenly spaced lines , thereby enhancing overall stroke distribution . Semantic Correction : Shading Semantic adjustment is used to de - emphasize strokes in re - gions that need no shading . We use the previous shading map T and the stroke map S as guidance sources . We ﬁrst lower the dynamic range of T to prevent excessive variations in shading appearance . For each new shading stroke Q , the shading error is computed at each control point as : (cid:15) shading ( q i ) = k · λ ( T ( q i ) − min ( G ∗ S ( x i ) , δ s ) ) ( 10 ) where k is a constant and the level - of - assistance λ is used to modulate this correction . The shading density parameter δ s can be adjusted via the UI . As in the outline tool , this value is used to de - emphasize strokes by making them smaller and more transparent when the value of (cid:15) is large . As more shad - ing strokes are added to a region , new strokes become thinner and lighter , to prevent the region from darkening too much . Figure 4 shows a shading sketch before and after adding assis - tance . In the zoomed - in window , shading strokes are placed in a more regular pattern compared to the original input . After the semantic adjustment , the shading also has a better inter - pretation of the face’s structure and luminance variations . EVALUATION To evaluate how well PortraitSketch achieves our stated goals , we consider the following three questions : 1 . Do novices prefer the assisted behavior of PortraitSketch over unassisted drawing ? 2 . Do novices create better drawings with assistance ? 3 . Do novices feel ownernship over their assisted drawings ? The remainder of this section describes the methodology of the user study we designed to help answer these questions . Methodology Our evaluation consists of two phases . First , we asked novice participants to create drawings using four versions of Por - traitSketch with different levels of assistance . After complet - ing the drawings , subjects answered several questions about the drawing behavior , drawing results and their perceived level of involvement in the creative process across the four conditions . In the second phase , we asked independent judges to evaluate the novice drawings . Novice Drawing Study For our novice drawing study , we recruited 24 participants who self - rated their drawing skills at 2 or lower ( on a scale from 1 – Novice to 5 – Expert ) , who draw infrequently ( monthly or less ) , and are interesting in drawing more . To evaluate how well our system works for different drawing styles , we also asked potential participants to rate their level of interest in creating drawings in one of three target styles ( Figure 5 ) . We picked styles that resemble many example portrait sketches that we found online and have visual charac - teristics that are distinct from one another ( e . g . , width , length ( a ) Style 1 ( b ) Style 2 ( c ) Style 3 Figure 5 : Target styles for user study . Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 412 and “cleanness” of outlines , type of shading , etc . ) Based on their responses , we assigned participants to draw in one of the three target styles such that each style had eight participants and all subjects were assigned their ( co - ) favourite style . For the study itself , we used a within - subjects design , where each subject created drawings of four different source images using four different levels of assistance : None ( λ = 0 ) , Low ( λ = 13 ) , Med ( λ = 23 ) , and High ( λ = 1 ) . We modiﬁed the UI to show an example sketch in the target style ( as a reference image ) to the right of the drawing canvas ( please refer to the submission video ) . For the source images , we selected an equal number of male and female portrait photos with ( approximately ) fronto - parallel viewing angles . Three of our source images are from the DrawAFriend dataset of celebrity photos [ 16 ] . For each target style , we counterbal - anced the order of assistance conditions and the pairings be - tween conditions and source images based on a Greco - Latin Square design that accounts for both immediate ordering ef - fects and condition - stimulus pairing effects [ 15 ] . At the beginning of each study session , we played a brief video introducing the key features of the PortraitSketch UI . We then allowed users to practice with the unassisted ver - sion of PortraitSketch for up to ten minutes to get comfort - able with the setup ( a Wacom tablet and stylus in front of a 24” display ) and to clarify any questions about the UI . After the practice session , we asked subjects to create four draw - ings . We explained that some system parameters affecting drawing behavior would change between each drawing , but we deliberately said nothing about the nature of the changes . This was done to alert subjects to behavior changes without biasing their experience . For each task , we asked users to do their best to draw the given source image in the target style in eight minutes or less . After completing the tasks , subjects ﬁlled out an exit ques - tionnaire . To determine whether users could identify the dif - ferent types of drawing assistance , we asked subjects to ex - plain what differences they noticed ( if any ) about the draw - ing behavior . We also asked subjects to rate how much they liked the drawing behaviors and their actual drawing results across the four conditions on a scale from 1 ( strongly dislike ) to 5 ( strongly like ) and to explain these ratings by describing what they liked and disliked about the behavior and results . Finally , to assess ownership , we asked users to rate on a scale from 1 ( strongly disagree ) to 5 ( strongly agree ) the following two statements : “I created the image by myself , ” and “The system helped me with creating the image . ” Independent Judges To gain more insight into the quality of the assisted versus unassisted drawings , we asked independent judges to eval - uate the drawings . We recruited two experts , who are both professional designers with extensive formal training and ex - perience in drawing . We also recruited seven non - artists to act as peer judges . We asked the experts to give absolute rank - ings for each set of four drawings created by the same user on a scale from 1 ( Worst ) to 4 ( Best ) based on two different cri - teria : 1 ) the artistic quality of the drawings and 2 ) the artistic quality of the drawings as a likeness of the subject of the por - trait . While we expected these two rankings to be correlated , we felt there might be some cases where one drawing was ar - tistically superior but a worse likeness and vice versa . To help keep the two rankings independent , we ﬁrst asked the judges to rank all 24 sets of images using the ﬁrst criterion , before adding the source images and asking the judges to rank all 24 sets of images again based on the second criterion . The ranking tasks described above require judges to evaluate drawings from four different source images . For more di - rect comparisons , we took each None ( no assistance ) drawing created by a novice participant and generated an auto adjusted version AutoMed by playing back the recorded strokes in Por - traitSketch with the Med assistance settings . We chose this assistance level because it typically produces noticeable dif - ferences , and as reported below , the Med condition received the highest mean drawing behavior rating . These auto ad - justed drawings represent a worst - case version of the assisted output from PortraitSketch since users tends to adjust their drawing behavior based on visual feedback from the system during real drawing sessions . After generating the assisted images , we asked both our expert and peer judges to select the better result from each pair of None and AutoMed draw - ings . ( We added peer judges for this evaluation as it required less expertise to compare . ) For all ranking tasks , we randomized the order in which the image quadruples / pairs were presented , and for each individ - ual ranking task , we also randomized the layout of the draw - ings , which were arranged in a horizontal row . RESULTS To summarize the data from our study , we present boxplots that show the median and interquartile ranges for each set of ratings / rankings , with upper and lower quartiles computed using the method of Freund and Perles [ 11 ] . For brevity , we aggregate ratings across the three target styles . Do novices enjoy the assisted drawing behavior ? Figure 6a summarizes the drawing behavior ratings for all 24 participants . Both the Low and Med conditions are rated more favorably than the None condition . Interestingly , the High condition received very similar ratings to the None con - dition . Looking more closely at the explanations of these ratings from the exit questionnaire , the relative lack of en - thusiasm for High was likely due to the perception that the automated assistance was overly aggressive in this condition , which several participants noted . This highlights the trade - off between user control and assistance ; even when the High setting produced the best results , some users were frustrated by the system not following their input . Do novices create better drawings with assistance ? Overall , the drawing result ratings increase with increasing levels of assistance ( Figure 6b ) , which suggests that partici - pants generally preferred the drawings they created with more assistance . The rankings from expert judges also show a pref - erence for the assisted drawings over the None condition ( Fig - ures 6e – f ) . Finally , the comparisons between the None and AutoMed ( auto adjusted ) image pairs produced the clearest results ; judges preferred the assisted drawings 70 % of the Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 413 Figure 6 : Results from user study . Boxplots a – d show ag - gregated self - rating results from our exit questionnaire ( 1 : strongly dislike . . . 5 : strongly like ) . Boxplots e – f show ex - pert ranking results ( 1 : Worst . . . 4 : Best ) . Overall , the results suggest that users prefer drawing with some assistance over no assistance ( a ) and that assistance results in better drawings ( b , e , f ) . The responses also suggest that while users clearly notice the system helping more at higher assistance levels ( d ) , this may not impact their feelings of involvement in the cre - ative process ( c ) . The thick black line in each colored box indicates the median . time , with only ﬁve of the 24 None drawings receiving more than four out of nine possible votes . In general , both the out - lines and shading contribute to the improved quality of the assisted drawings . As shown in Figure 7 , more accurate out - lines tend to make the sketch more similar to the source im - age , and more even shading increases the technical quality of the result . Do novices feel ownernship over assisted drawings ? While this is a difﬁcult question to answer conclusively , the ratings for the statements “ I created the image by myself ” and “ The system helped me with creating the image ” pro - vide some insight . For the ﬁrst statement , there is no obvious trend across the four conditions . None and Low have a sim - ilar distribution of ratings , with Med rated somewhat higher and High somewhat lower ( Figure 6c ) . However , the ratings for the second statement clearly increase with increasing as - sistance ( Figure 6d ) . Thus , while participants notice the in - creasing levels of assistance , this does not seem to diminish their sense of involvement in the creative process , at least up until the Med condition . We consider this a desirable result . Moreover , the ability of the system to preserve characteris - tics of individual users’ drawing style may also contribute to a sense of ownership . While we did not evalute style preservation explicitly in our study , almost all of the drawings from different users exhibit clear stylistic differences ( even the drawings in the same target style ) . For example , Figure 8 shows four sets of drawings in two different target styles with various levels of assistance . In the top row , subject 129 uses very loose , messy outlines and shading , while subject 136 has a much tighter , more controlled style with lots of structured , parallel shading lines . In the bottom row , subject 144 uses fairly clean outlines and focuses on details around the eyes , while subject 138 draws with long , wavy outlines and rela - tively little detail , which gives the drawings a more abstract look . These types of differences suggest that , even with as - sistance , PortraitSketch users are still able to create drawings in their own unique styles . Free - form responses We asked users to describe the drawing behavior changes they noticed . Only 2 users noticed no difference and most users correctly identiﬁed assistance as the behavior change . We analyzed the given descriptions and grouped them into three connotation categories : Positive ( e . g . help , assistance ) , Neutral ( e . g . snapping , correction ) , and Negative ( e . g . re - strictive ) . If a description used words from multiple cate - gories , we counted the less favorable one . 5 users made posi - tive mention , 8 users were neutral , and 3 users made negative comments about the assistance . Several users noticed behav - ior changes that were not real , and might reﬂect a subjective learning experience . This evaluation mirrors the quantitative data in that most users seemed comfortable with the given assistance , or even appreciated it . For positive feedback , 8 users speciﬁcally mentioned liking the assistance ; 5 users thought that tracing made the task fun and manageable ; 6 users mentioned the shading visualiza - tion ; and 9 users commented on the usefulness of adjusting the opacity of the reference image . Suggested system improvements include : An eraser tool to delete arbitrary lines ( 12 users ) ; manual adjustment of outline and shading thickness ( 11 users ) ; additional shading styles ( 3 users ) ; and ability to adjust assistance ( 3 users ) . Interesting feedback from a general comments question in - clude : ( 146 ) “ [ . . . ] I found when I tried to use the shading system I was more focused on the guide than the image itself which had some bad results . ” ; ( 132 ) “i can create wonderful sketch with this software” ; ( 120 ) “Fun factor [ . . . ] I think that will help in freehand drawing” ; ( 110 ) “It was surpris - Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 414 8 / 9 7 / 9 6 / 9 ( e ) Figure 7 : Some results from user study . We show unassisted ( b ) , auto adjusted ( c ) , and assisted ( e ) drawings by three different novice users ( organized by row ) in our study . PortraitSketch’s automatic adjustments produce more accurate outlines ( compare the face contours and eyes in columns ( b ) and ( c ) ) and more even shading ( e . g . , the hair and neck in top row drawings ) . While some differences are subtle , several small adjustments often produce noticeable improvements in the overall drawing . The blue numbers in column ( c ) indicate the fraction of independent judges who preferred the auto adjusted images over the unassisted drawings in column ( b ) . All three users produced the assisted drawing ( e ) before the unassisted one ( b ) in their study sessions . Image credits : ( a ) top to bottom : Levy Carneiro Jr , Edgar Meritano and chris zerbes . ( d ) top to bottom : chris zerbes , chris zerbes and Pete Souza . All are under a Creative Commons license . ingly fast and easy to use and understand . I also feel like I could quickly draw something , if tasked” ; ( 166 ) “I lack cre - ativity , so I like that there was a ‘tracing’ aspect to help me draw” ; ( 127 ) “Overall , I was very impressed when I saw the outcome . Can’t wait to try out more drawings , it’s addictive : - ) ” ; ( 138 ) “ [ An exercise ] that gave me hope that maybe I ac - tually could produce something worth looking at ! : ) ” ; ( 121 ) “It gave me hope that I could actually learn to draw” . DISCUSSION & FUTURE WORK Our system assists novices in creating sketches by making subtle adjustments to technical qualities of their drawings . Two situations may lead to sub - optimal assistance conditions : 1 ) Facial feature detection and XDoG edge extraction may fail ( due to low contrast , facial occlusion , etc . ) 2 ) The user creates drawings with little correspondence to the source im - age . Our study gives preliminary evidence that this kind of as - sistance enhances the resulting drawings , enhances user’s en - joyment and pride in their work , while maintaining the sense of ownership they would feel in a conventional interface . The Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 415 ( c ) Style 3 , Subject 138 ( d ) Style 3 , Subject 144 ( a ) Style 1 , Subject 129 ( b ) Style 1 , Subject 136 Figure 8 : Preserving stylistic differences . Each set of three drawings was created by one of our study participants using three different levels of assistance . The drawings by each user exhibit unique characteristics that distinguish them from the drawings by other users . These stylistic differences are present even when comparing drawings in the same target style ; for example , ( a – b ) are in target style 1 , and ( c – d ) are in target style 3 . behavior and drawing result ratings suggest that there may be a sweet spot around the Med level of assistance , which pro - vides enough help to noticeably improve drawing quality but does not modify user outlines and shading too aggressively . We chose not to explain the nature of the assistance to partic - ipants , but we observed that some users who ﬁgured out our system produced better results . We observed several potential sources of noise in our study , including unfamiliarity with the Wacom tablet , learning ef - fects , and variation between the different types of source im - ages . Although we counterbalanced for each of these effects , they did reduce the observed effect sizes . Many novices are interested in creative expression but lack the conﬁdence and skills to partake in art projects . Indeed , several study participants initially apologized for their lack of drawing skills , but , at the end , were thrilled with their re - sults . One user even captured her drawings with her phone to immediately share with her friends . We think that additional guidance for difﬁcult drawing elements , such as hair or cloth - ing could be useful . While we focus on novices , even pro - fessional artists , who quickly have to produce a rough sketch , might beneﬁt from image - based drawing assistance . We see the encouraging results from our user study as evidence that building creative assistance tools for novices is an important goal and we intend to apply our assistance approach to other artistic domains in the future . REFERENCES 1 . Arvo , J . , and Novins , K . Fluid Sketches : Continuous Recognition and Morphing of Simple Hand - drawn Shapes . In Proc . UIST ( 2000 ) , 73 – 80 . 2 . Barla , P . , Thollot , J . , and Sillion , F . Geometric Clustering for Line Drawing Simpliﬁcation . In Proc . EGSR ( 2005 ) . 3 . Berger , I . , Shamir , A . , Mahler , M . , Carter , E . , and Hodgins , J . Style and Abstraction in Portrait Sketching . ACM Trans . Graph . 32 , 4 ( July 2013 ) . 4 . Cole , F . , Golovinskiy , A . , Limpaecher , A . , Barros , H . S . , Finkelstein , A . , Funkhouser , T . , and Rusinkiewicz , S . Where Do People Draw Lines ? ACM Trans . Graph . 27 , 3 ( Aug . 2008 ) . 5 . Comaniciu , D . , and Meer , P . Mean Shift : A Robust Approach Toward Feature Space Analysis . IEEE Trans . PAMI 24 , 5 ( May 2002 ) , 603 – 619 . 6 . Cummmings , D . , Vides , F . , and Hammond , T . I Don’t Believe My Eyes ! : Geometric Sketch Recognition for a Computer Art Tutorial . In Proc . SBIM ( 2012 ) . 7 . Dixon , D . , Prasad , M . , and Hammond , T . iCanDraw : Using Sketch Recognition and Corrective Feedback to Assist a User in Drawing Human Faces . In Proc . CHI ( 2010 ) . 8 . Eitz , M . , Hays , J . , and Alexa , M . How Do Humans Sketch Objects ? ACM Trans . Graph . 31 , 4 ( July 2012 ) . Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 416 9 . Fernquist , J . , Grossman , T . , and Fitzmaurice , G . Sketch - sketch Revolution : An Engaging Tutorial System for Guided Sketching and Application Learning . In Proc . UIST ( 2011 ) . 10 . Flagg , M . , and Rehg , J . M . Projector - guided painting . In Proc . UIST ( 2006 ) . 11 . Freund , J . , and Perles , B . A new look at quartiles of ungrouped data . American Stat 41 ( 1987 ) , 200 – 203 . 12 . Iarussi , E . , Bousseau , A . , and Tsandilas , T . The Drawing Assistant : Automated Drawing Guidance and Feedback from Photographs . In Proc . UIST ( 2013 ) . 13 . Kazi , R . H . , Igarashi , T . , Zhao , S . , and Davis , R . Vignette : Interactive texture design and manipulation with freeform gestures for pen - and - ink illustration . In Proc . CHI ( 2012 ) . 14 . Lee , Y . J . , Zitnick , C . L . , and Cohen , M . F . ShadowDraw : Real - time User Guidance for Freehand Drawing . ACM Trans . Graph . 30 , 4 ( July 2011 ) . 15 . Lewis , J . R . Pairs of latin squares to counterbalance sequential effects and pairing of conditions and stimuli . In Proc . Human Factors and Ergonomics ( 1989 ) . 16 . Limpaecher , A . , Feltman , N . , Treuille , A . , and Cohen , M . Real - time Drawing Assistance Through Crowdsourcing . ACM Trans . Graph . 32 , 4 ( July 2013 ) . 17 . Pusch , R . , Samavati , F . , Nasri , A . , and Wyvill , B . Improving the sketch - based interface . The Visual Computer 23 , 9 - 11 ( 2007 ) , 955 – 962 . 18 . Salisbury , M . P . , Anderson , S . E . , Barzel , R . , and Salesin , D . H . Interactive pen - and - ink illustration . In Proc . SIGGRAPH ( 1994 ) . 19 . Saragih , J . M . , Lucey , S . , and Cohn , J . F . Deformable Model Fitting by Regularized Landmark Mean - Shift . Int . J . Comput . Vision 91 , 2 ( Jan . 2011 ) , 200 – 215 . 20 . Turk , G . , and Banks , D . Image - guided Streamline Placement . In Proc . SIGGRAPH ( 1996 ) , 453 – 460 . 21 . Winnem¨oller , H . , Kyprianidis , J . E . , and Olsen , S . C . XDoG : An eXtended difference - of - Gaussians compendium including advanced image stylization . Computers & Graphics 36 , 6 ( 2012 ) , 740 – 753 . 22 . Zhao , M . , and Zhu , S . - C . Artistic Rendering of Portraits . In Image and Video - Based Artistic Stylisation , P . Rosin and J . Collomosse , Eds . Springer , London , 2013 . 23 . Zitnick , C . L . Handwriting Beautiﬁcation Using Token Means . ACM Trans . Graph . 32 , 4 ( July 2013 ) . Creative Tools UIST’14 , October 5 – 8 , 2014 , Honolulu , HI , USA 417