To appear in IEEE Transactions on Visualization and Computer Graphics Retrieve - Then - Adapt : Example - based Automatic Generation for Proportion - related Infographics Chunyao Qian , Shizhao Sun , Weiwei Cui , Jian - Guang Lou , Haidong Zhang , and Dongmei Zhang 32 % of us use at least two types of social media everyday . User Information Example Library … Retrieved Example Query Retrieval Initialization Adaption 57 % ofinspiration comefrompractice ( a ) ( b ) ( c ) ( d ) 32 % of us use at least two different types of social media everyday . “32 % ” + “of … everyday . ” + + 32 % ofususeatleasttwodifferent typesofsocialmediaeveryday . Initial Draft New Infographic Figure 1 . An example - based approach for automatic infographics generation . a ) The user information ( top ) and the example library ( bottom ) built by crawling infographics from the Internet . ( b ) The example ( bottom ) retrieved from the example library according to the query ( top ) generated from the user information . ( c ) The initial draft obtained by directly ﬁtting user information into the design of the retrieved example . ( d ) The new infographic generated by adapting the design of the initial draft ( e . g . , enlarging the bottom text box ) . Abstract — Infographic is a data visualization technique which combines graphic and textual descriptions in an aesthetic and effective manner . Creating infographics is a difﬁcult and time - consuming process which often requires signiﬁcant attempts and adjustments even for experienced designers , not to mention novice users with limited design expertise . Recently , a few approaches have been proposed to automate the creation process by applying predeﬁned blueprints to user information . However , predeﬁned blueprints are often hard to create , hence limited in volume and diversity . In contrast , good infogrpahics have been created by professionals and accumulated on the Internet rapidly . These online examples often represent a wide variety of design styles , and serve as exemplars or inspiration to people who like to create their own infographics . Based on these observations , we propose to generate infographics by automatically imitating examples . We present a two - stage approach , namely retrieve - then - adapt . In the retrieval stage , we index online examples by their visual elements . For a given user information , we transform it to a concrete query by sampling from a learned distribution about visual elements , and then ﬁnd appropriate examples in our example library based on the similarity between example indexes and the query . For a retrieved example , we generate an initial drafts by replacing its content with user information . However , in many cases , user information cannot be perfectly ﬁtted to retrieved examples . Therefore , we further introduce an adaption stage . Speciﬁcally , we propose a MCMC - like approach and leverage recursive neural networks to help adjust the initial draft and improve its visual appearance iteratively , until a satisfactory result is obtained . We implement our approach on widely - used proportion - related infographics , and demonstrate its effectiveness by sample results and expert reviews . Index Terms —Infographics , automatic visualization . 1 I NTRODUCTION Infographics [ 31 ] , which often fuse text descriptions and graphic ele - ments [ 28 ] to convey the information , are widely used in advertisements , posters , magazines , etc . Compared with plain texts , infographics are obviously easier to capture viewers’ attention and help them quickly understand complex information [ 1 ] . However , creating a successful infographic is not an easy task which requires professional skills and tremendous time . Novice users will easily get lost in the vast amount of design choices . Even experienced designers have to go through many iterations of adjustment before proposing a ﬁnal infographic [ 15 ] . To lower the authoring barrier for casual users , predeﬁned blueprints are widely used to automate the design of infographics in both com - mercial software ( e . g . , Microsoft PowerPoint and Adobe Illustrator ) • S . Sun , W . Cui , J . Lou , H . Zhang , and D . Zhang are with Microsoft Research Asia . Emails : { shizsu , weiweicu , jlou , haizhang , and dongmeiz } @ microsoft . com . • C . Qian is with Peking University , and this work was done during an internship at Microsoft Research Asia . Email : cyqvanilla @ pku . edu . cn . and new research paradigms ( e . g . , Text - to - Viz [ 7 ] ) . However , such blueprint - based approach has some limitations as well . First , as the number of predeﬁned blueprints is limited , such approach may easily make the generated infographics limited and deja vu in terms of designs . Moreover , it is difﬁcult to enrich the blueprint library with low efforts as designing blueprints is both complicated and laborious . For example , to build a useful template , designers need to consider numerous factors : what visual elements are allowed in the template ; how they are spatially arranged ; what is the size of each element ; what is the font or font size ; what is the ideal length for a text element in it , etc . These consider - ations are typically formulated as constraints in the template . Strict constraints can ensure good results , but often reduce the diversity of the results generated by the corresponding template . Loose constraints are more ﬂexible , but can potentially yield strange or even wrong results . Therefore , designers need to thoroughly experiment and ensure the template can deliver good results with any valid input . On the other hand , there is a large collection of well - designed infographics on the Internet , called online examples for ease of reference . Currently , they are widely used as exemplars or inspirations for people who would like to create their own infographics . Compared to predeﬁned blueprints , online examples are inherently rich in diversity and quantity . More 1 a r X i v : 2008 . 01177v1 [ c s . H C ] 31 J u l 2020 importantly , design choices in these examples are generally appropriate and viable in practice , as they are made and endorsed by professionals . Based on the above observations , we seek to generate infographics by automatically imitating online examples . However , there are two critical challenges when developing such an example - based approach for infographics . First , in a large collection of examples , how to ﬁnd appropriate ones whose designs can be transferred to a speciﬁc piece of information . Second , even we ﬁnd such a matching online example , it is unlikely that the information is a perfect ﬁt in terms of every design aspect . For instance , the text length in the user information may be different with that in the example . To address these challenges , we pro - pose a two - stage approach , called retrieve - then - adapt , to automatically convert a piece of information to its infographic equivalents . In the retrieval stage , we build a retrieval system that indexes ex - amples with their visual elements , such as charts , icons , and texts . Then , for a piece of information given by users , we need to effectively transform it to a concrete query to collect appropriate examples in the example library . Speciﬁcally , we ﬁrst deconstruct the information and identify candidate visual elements that are applicable to individual information components . Then , we encode the visual elements into a valid query to retrieve examples that are composed of similar ele - ments . Obviously , an information component may have multiple ways to present visually . Therefore , to ensure an authentic diversity that is consistent with the common practice of designers , we generate viable queries based on the distribution about visual elements observed in the crowdsourced examples . For example , if the proportion - related infor - mation is more frequently visualized using donut charts with icons than pure icons in the collected examples , our method will be more likely to issue a query about donuts with icons than pure icons , accordingly . In the adaption stage , we address the second challenge by automati - cally adjusting the designs in retrieved examples to make them more suitable for user information . In most cases , the design of the retrieved example cannot be perfectly matched with user information in every aspect . Fortunately , it provides a good start point to customize and reﬁne to achieve an appealing result . Speciﬁcally , we ﬁrst directly adopt the design choices ( e . g . , position , color , font , etc . ) from the ex - ample to create an initial draft for user information . Then , we propose a MCMC - like approach [ 29 ] to iteratively make small changes to the design of the initial draft and gradually improve the visual quality over the iterations , until there is no better design can be proposed and a stable state is reached . To help evaluate the improvement after each iteration and ensure visual quality improves monotonically , we leverage recursive neural networks [ 23 , 32 ] to encode hierarchical structures of infographics into hidden vectors and build a scorer upon them to compare the visual qualities before and after a small change is applied . To evaluate our approach , we collect a real - world dataset about proportion - related infographics from the Internet and implement our approach based on them . We present sample results to qualitatively demonstrate the performance of our approach . Moreover , we interview four experts and collect their comments for our generated infographics . Both sample results and expert reviews demonstrate that our approach can generate diverse infographics by imitating online examples . 2 R ELATED W ORK 2 . 1 Infographics Research work on infographics mainly includes three aspects , i . e . , effect , understanding and auto - generation . First , traditional studies focus on exploring what effects infographics have on humans . For example , Bateman et al . [ 3 ] compare embellished charts with plain ones by measuring interpretation accuracy and long - term recall . Haroz et al . [ 11 ] ﬁnd that using pictographs can improve the performance of information exchanging in terms of memorability , reading speed , and engagement . In addition , many studies are conducted to understand the underlying message or the visual structure of an infographic . For example , Bylinskii et al . [ 4 ] adopt OCR techniques to assign hashtags to infographics for information retrieval purpose . Lu et al . [ 25 ] ﬁnd 12 different Visual Information Flow ( VIF ) patterns in infographics . Recently , there has been a growing interest in generating infograph - ics . Many design tools [ 17 , 30 , 35 ] have been developed to facilitate the creation of infographics in an interactive manner . However , these tools cannot completely automate the creation process . Users are still required to understand advanced operations and concepts in these tools , and use their design expertise to make choices among numerous visual elements and attributes . To further automate the process , Cui et al . [ 7 ] propose generating infographics from natural language statements with predeﬁned blueprints . However , predeﬁned blueprints are expensive to create and easily homogenize designs . These limitations of predeﬁned blueprints motivate us to consider leveraging online examples , which are easy to get and inherently diverse . 2 . 2 Reusing Examples Examples play an important role in design practice . On the one hand , experienced designers usually get inspirations from examples because they can offer rich design styles [ 15 ] : color schemes , visual expression , etc . On the other hand , for novice users , it is far easier to adjust an existing example than to create a design from scratch [ 20 ] . Such critical role of examples inspires researchers to investigate reusing examples to create new designs in many different tasks , such as web pages design and charts design . In web page design , Bricolage [ 19 ] tries to match visually and semantically similar page elements between the content source and a web example , and then transfers the content of the source page to the best matching element in the example . Different from Bricolage that only considers one page , WebCrystal [ 5 ] extracts and combines styling information from different existing websites . In chart design , much attention has been paid to converting existing charts into reusable style templates that can be easily applied to new data sources . Harper et al . [ 12 ] present a pair of tools for deconstructing and restyling existing D3 visualizations . The deconstruction tool analyzes a D3 visualization by extracting the data , marks , and mappings between them . The restyling tool lets users modify the visual attributes of marks as well as the mappings from data to these attributes . The deconstruction approach is further extended to take into account non data - encoding marks and their visual attributes [ 13 , 16 ] . All these existing approaches focus on how to reuse designs from existing examples . Our approach also falls into this category . However , we focus on a different type of data : infographics . The unique design space of infographics proposes two critical challenges besides design extraction , i . e . , how to ﬁnd appropriate examples for a speciﬁc piece of information and how to adapt the example’s design to make it more suitable for the information . 2 . 3 Automatic Layout Generation Our adaption stage is inspired by existing automatic layout generation methods for traditional tasks , e . g . , graphics design and indoor scene generation . Early approaches [ 26 , 27 , 29 ] investigate Markov Chain Monte Carlo ( MCMC ) methods to generate layouts , which iteratively propose new layout and choose the better layout until no better layout can be proposed . The performance of those approaches is sensitive to layout evaluation metrics . However , these evaluation metrics are usually task - speciﬁc and heavily rely on human intuition , limiting them in modeling infographic design . Recently , deep neural networks have been explored for layout generations [ 21 , 22 , 23 , 34 , 38 ] . Those meth - ods regard layout generation as a special case of image generation , and then leverage generative adversarial networks ( GAN ) [ 10 ] or variational auto - encoder ( VAE ) [ 8 ] to solve it . For example , LayoutGAN [ 22 ] proposes a wireframe rendering layer to learn the alignment ; READ [ 9 ] leverages a recursive autoencoder to model highly structured layouts using less training data ; ContentGAN [ 38 ] synthesizes layouts by con - sidering visual and textual semantics . Although those methods do not rely on handcrafted features , they often fail to achieve comparable performance as MCMC methods due to the limited training data . The adaption stage in this work is similar to MCMC methods . How - ever , instead of handcrafting evaluation metrics , we learn a recursive neural network from the example library about how to evaluate designs . 3 P RELIMINARIES Our approach is highly related to Text - to - Vis [ 7 ] . In that work , Cui et al . ﬁrst analyze and describe the text and visual spaces of proportion - 2 To appear in IEEE Transactions on Visualization and Computer Graphics It is estimated that more than 74 % of users are female . of users are female . Itisestimatedthat more than 74 % Input Processing ( a ) ( b ) ( c ) Text Analyzer Graphics Generator Itisestimated that morethan 74 % of users are female . Before Modifier Number After IconGenerator … … ChartGenerator Infographic Generation Figure 2 . Example for our setting of infographics generation , where the input is a proportion - related natural language statement ( see ( a ) ) and the output is an infographic representing the information ( see ( c ) ) . In this setting , ( a ) the input is ﬁrst analyzed to obtain ( b ) various candidates of visual elements , which are then used to synthesize the infographic . related facts . Then , a blueprint - based solution is built to bridge these two spaces , which automatically converts a proportion - related natural language statement to its infographic equivalents . According to their study , the motivation behind this input / output setting is two - fold . First , the natural language is the most common way to convey information . Second , the proportion - related infographic is the main category of infographics used in practice . In this work , we adopt the same input / output setting of infographic generation ( Figure 2 ) , but on top of which we build our novel example - based approach . In addition to the input / output setting , we also adopt the input processing pipeline ( i . e . , ( a ) to ( b ) in Figure 2 ) to help prepare queries for examples . In this section , we brieﬂy introduce these adopted algorithms and concepts that are used in the remainder of this paper . More details can be found in the work of Text - to - Vis [ 7 ] . 3 . 1 Input Processing In this work , we follow the same input processing pipeline of Text - to - Vis to collect candidates of visual elements , since this module is not the core interest of this work and existing algorithms can already provide sufﬁcient information to support our example - based approach . Speciﬁcally , given a input statement that contains proportion - related information ( e . g . , Figure 2 ( a ) ) , a text analyzer , essentially a supervised CNN + CRF model , is utilized to split the statement into four different segments , namely , before , modiﬁer , number , and after . In addition , two separate graphic generators are used to generate graphical elements . Speciﬁcally , an icon generator is used to extract representative icons according to the semantics of the input statement from a predeﬁned icon library and a chart generator is used to generate pies , donuts , and bars according to the percentage value in the input statement . All these text segments and graphics are candidate visual elements for information components in the input statement , and then will be used to construct viable queries for retrieving compatible examples in the example library ( see Section 6 ) . 3 . 2 Visual Elements Following the visual space described in Text - to - Vis [ 7 ] , we rank and select the top ten frequently used visual elements in online examples . Textual Elements . They are characterized by the contained infor - mation , which correspond with segments extracted by the text analyzer . • Before . This refers to simple clauses in forms like “It is estimated that” , “Compared with last month” or “By the year 2020 , ” . They always appear at the beginning of the statement . • Modiﬁer . This refers to adjunct words or phrases used before a number , such as “only” , “more than” , “around” or “nearly” . • Number . This refers to the most important numerical information in a proportion - related fact . They have obvious textual patterns like “10 % ” , “1 in 10” , “1 out of 10” or “1 / 10” . • After . This refers to the remaining texts after the number . For example , “ . . . of companies will be using artiﬁcial intelligence for driving digital revenue” or “ . . . of people would like to receive promotions on social media” . 4in5smartphoneowners checktheirphoneswithin15minutesofwakingup . ONLY 20 % ofretailproductsarepurchasedthroughdirectsalesreps Before Number Bar After Modifier Number After Pie Single Icon Number After Donut Pictograph Statement By the year 2020 , 60 % ofcompanieswillbeusingartificialintelligencefordrivingdigitalrevenue . 1 7 % ofpeoplewouldliketoreceivepromotionsonsocialmedia . % Figure 3 . Examples for visual elements in proportion - related infographics . • Statement . An input utterance may exist in the infographic as one text block sometimes . We consider the text block as a state - ment element because it dose not split the input utterance into meaningful segments . Graphical Elements . They are also critical parts in infographics , targeting attractive visual effects to emphasize the key points in the underlying information . • Single icon . Elements of this type are semantically related to the input utterance . Since icons are not explicitly provide in the input , we use the aforementioned icon generator ( Figure 2 ) to collect meaningful icons to represent the input . • Donut / Pie / Bar . Elements of these types encode the numerical information of the input in a vivid way . In our implementation , they are programmatically generated according to the numerical information by chart generator ( Figure 2 ) . • Pictograph . Compared with the previous four elements , pic - tographs not only encode numerical information , but also empha - size the subject of the proportion - related fact . In our implementa - tion , they are created with icon generator as well . Attributes of these textual elements and graphical elements are man - ually labeled in examples , and then used to index examples in the example library ( see Section 6 ) . 4 S YSTEM O VERVIEW Formally , we denote the example library as D = { D m } Mm = 1 , which contains M infographics D m crawled from the Internet . The input is denoted by U , which is a proportion - related natural language statement like “More than 74 % of users are female” . Thus , our approach aims to automatically generate an infographic G from U , by imitating designs in D . Figure 1 illustrates the workﬂow of our approach , which contains three key steps as follows . Retrieval . The ﬁrst stage is to ﬁnd appropriate examples whose designs can be transferred to the input U . We address this challenge by building a retrieval system that takes U as the query to look up D and returns an appropriate example ˜ D ∈ D , i . e . , ˜ D = f retrieval ( D , U ) . Specif - ically , we index each example by its visual elements , e . g . , charts , icons , and texts . Then , we transform an input U to a concrete query in the same format of the example index . Finally , we retrieve examples based on the similarity between example indexes and queries ( Figure 1 ( b ) ) . However , in many cases , U has multiple valid infographic designs . For example , it can be visualized either as statement + bar or state - ment + pictograph , which are different in terms of queries . To resolve this one - to - many mapping issue , we generate effective queries based on the distribution observed in the crowdsourced examples . Intuitively , we assume the example library indicates the likelihood of different design choices that are adopted in practice . This motivates us to gen - erate queries by ﬁrst learning a distribution about visual elements from the example library and then sampling from the distribution . In this way , we ensure that examples are retrieved based on the popu - larity of their design choices in the real world . Moreover , by sam - pling from the learned distribution multiple times , it is possible to obtain different design choices ( i . e . , different concrete queries for the same U ) , leading to improved diversity of generated infographics . Fig - ure 1 ( b ) shows a concrete query which contains visual elements “num - 3 “elements” : [ { “type” : “Canvas” , “built - in attribute” : 1 . 2 , “position” : [ x l , y l , x r , y r ] , “color” : [ “ # FFFFFFFF ” ] , “text - specific attribute” : [ { “Font” : None , “ isBold ” : False , “ isItalic ” : False } ] } , { “type” : “Singleicon” , “built - in attribute” : 1 . 1 , “position” : [ x l , y l , x r , y r ] , “color” : [ “ # FF7F00” , “ # 855E42” ] , “text - specific attribute” : [ { “Font” : None , “ isBold ” : False , “ isItalic ” : False } ] } , { “type” : “Number” , “built - in attribute” : 3 , “position” : [ x l , y l , x r , y r ] , “color” : [ “ # B873333” ] , “text - specific attribute” : [ { “Font” : Font1 , “ isBold ” : True , “ isItalic ” : False } ] } , } ] ( a ) Original ( b ) Proportional Crop Label … Image Infographic ( c ) Infographic Annotations Figure 4 . Illustration for the pipeline of example library construction . ber + after + donut + single icon” and the corresponding retrieved example . Initialization . We generate an initial draft ˜ G by directly applying the design of the retrieved example ˜ D to U , i . e . , ˜ G = f init (cid:0) ˜ D , U (cid:1) . We apply positions , colors , and text - speciﬁed attributes to the visual ele - ments speciﬁed by the query ( Figure 1 ( c ) ) . If the retrieval stage returns multiple examples , we generate one initial draft for each example . Adaption . In many cases , directly applying the design may not work perfectly due to the mismatches between visual elements in the retrieved example and those used in the query . For example , text lengths or aspect ratios of icons may be slightly different , which may lead to a strange look in ˜ G , such as overlapping , excessive white space or improper font size ( Figure 1 ( c ) ) . We propose an adaption stage to reﬁne ˜ G and make it more natural and suitable for the input U , i . e . , G = f adaption (cid:0) ˜ G (cid:1) . Speciﬁcally , we propose a MCMC - like approach to adjust the design of the initial draft ˜ G iteratively . First , a candidate design is proposed by randomly making a small change to the position or size of a visual element in the current design . Then , we compare the visual qualities of the current and candidate designs and choose the better one as the starting point for the next round of iteration . However , evaluating designs is a nontrivial task as the criteria for a good design is intricate and hard to be quantiﬁed [ 14 , 26 ] . To address this problem , we train a recursive neural network from the example library to evaluate the change in the aforementioned iteration . 5 E XAMPLE L IBRARY C ONSTRUCTION The foundation of our work is a collection of online examples , which serves three purposes in our approach . First , we analyze the examples to extract the distribution about visual elements . Since there are no design preferences indicated in the input statement , we use the distribution to guide the query generation , so that the generated results have an authentic diversity consistent with real world examples . Second , we index these examples in a database for our system to query and construct the initial draft for a given input . Third , we use the example corpus to train a recursive neural network that is used in the adaption stage to evaluate the change at every iteration . In this work , we build an example library by crawling and process - ing infographic exemplars from the Internet . First , we collect a set of infographic sheets from the Internet . Then , as shown in Figure 4 ( a ) , an infographic sheet usually contains multiple infographic units . There - fore , we crop the proportion - related units from each sheet . Finally , we label the visual elements and their attributes in the cropped infographics . We introduce each step in detail as follows ( Figure 4 ) . Collection . We search Google Image by using a primary keyword “infographic” , as well as a secondary keyword indicating a topic to ensure the diversity of dataset . Speciﬁcally , we consider ten common topics , i . e . , education , health , commerce , ecology , diet , sports , animals , wedding , technology , and medical . In total , we downloaded 1000 infographic sheets with 100 under each topic . Cropping . Proportion - related infographics convey statistical infor - mation about how much a part occupies the whole , e . g . , “More than 74 % of users are female” , which provides obvious indications for us to crop them from the downloaded sheets . Speciﬁcally , three coauthors review all the original sheets and crop proportion - related infographics from them independently . In total , we obtain 829 examples . Modi . Bef . Sta . Num . After Icon Picto . Don . Pie Bar 0 . 00 0 . 05 0 . 10 0 . 15 0 . 20 ( a ) 0 50 100 150 200 Text Length 0 . 00 0 . 01 0 . 02 0 . 03 0 . 04 ( b ) 0 . 0000 0 . 0025 0 . 0050 ( c ) 0 . 000 0 . 005 0 . 010 ( d ) 0 . 000 0 . 005 0 . 010 ( e ) 0 . 0000 0 . 0025 0 . 0050 ( f ) 0 . 000 0 . 002 0 . 004 ( g ) 0 . 000 0 . 002 0 . 004 ( h ) 0 . 0000 0 . 0025 0 . 0050 ( i ) 0 . 000 0 . 002 0 . 004 ( j ) 0 . 000 0 . 002 0 . 004 ( k ) 0 . 0000 0 . 0015 0 . 0030 ( l ) Figure 5 . ( a ) - ( b ) The distributions of element type and text length . ( c ) - ( l ) The position distributions of number , before , modiﬁer , after , statement , single icon , bar , pie , donut , and pictograph . Labeling . These examples are all stored as bitmap images . For each visual element , we manually label the following visual attributes : • Element type t , which can be one of the visual elements intro - duced in Section 3 . 2 , including before , modiﬁer , number , after , statement , single icon , donut , pie , bar and pictograph . • Built - in attribute b , which is the length of characters for a textual element and the aspect ratio for a graphical element . • Position g = ( x l , y l , x r , y r ) , which is the top - left coordinate and bottom - right coordinate for the element boundary . • Color c , where we label at most two colors for an element . Specif - ically , we label one outline color and one ﬁll color for each icon to ensure that its style can be matched when new infographics are generated . Besides , we label the dominant font color when there are multiple font colors in one text box . • Text - speciﬁc attributes a , which includes the font and whether there is an italic and bold effect in the textual element 1 . Speciﬁ - cally , we label the dominant font type and font effect ( e . g . , bold ) when there are multiple ones in one text box . We treat canvas as a special graphical element and label above attributes for it . Figure 4 ( c ) shows a concrete labeling result for the infographic in Figure 4 ( b ) . Figure 5 shows distributions of labeling results . Although there are other subtle visual attributes , we leave them for future work as essential visual attributes described above can already help us generate good infographics in many cases . We think there are several possible ways to effectively enrich visual attributes . For example , labeling process is quite simple and does not require design expertise , and thus it is possible to accelerate it by crowdsourcing . On the other hand , with the growth of computer vision techniques , current manual labeling process can be replaced by machines [ 6 ] , which will make the example library construction even more scalable and effective . Copyright is another big concern of this approach , as it is a viola - tion of intellectual property rights to fully imitate an example without owning appropriate copyrights . To resolve this issue , we leverage two datasets in our implementation . One dataset of 50 infographics is cre - ated by our designers , which is used to retrieve examples for imitation . The other dataset of 829 infographics is collected from the Internet and used in the non - copyright related parts of our approach , e . g . , extract - ing the distribution of visual elements and training a recursive neural network . The copyright issue is further discussed in Section 10 . 2 . 6 R ETRIEVAL On top of the example library , we build a retrieval system to help ﬁnd appropriate examples whose designs can be potentially adapted to the input statement given by the user . 1 The font is recognized by using https : / / www . myfonts . com / WhatTheFont / . 4 To appear in IEEE Transactions on Visualization and Computer Graphics Infographic Graphical Elements Icon Pie Donut Bar Pictograph Textual Elements Semantic Segments Before Modifier Number After Statement Figure 6 . Illustration for design choices about visual elements . 6 . 1 Example Index Intuitively , if the input U can be represented by an icon and a text statement , examples that exactly have one icon and one text box are more likely to be candidates for reuse . Moreover , if the text ( or icon ) of the input has a similar length ( or aspect ratio ) to that in an example , the design of this example will be ideal for reuse . This motivates us to index examples by visual element types t and their built - in attributes b , including the number of characters for textual elements and the aspect ratio for graphical elements . Formally , for each example D m ∈ D , its index I m can be denoted as I m = { ( t nm , b nm ) } Nn = 1 , where N is the number of visual elements in the example . 6 . 2 Query Generation As I m is composed of visual elements types and built - in attributes , we need to transform the input U to concrete queries of the same form . On the one hand , there are usually many valid ways to represent the same piece of information using infographics . For example , “More than 74 % of users are female” can be visualized as statement + pie or statement + donut + icon . On the other hand , the example library indicates the likelihood of different representations adopted in the practice . Therefore , we propose to ﬁrst learn a distribution about visual elements from the example library and then generate user queries by sampling from the distribution . Learning distribution about visual elements . Figure 6 shows design choices about visual elements . First , an infographic usually contains two main categories of visual elements , i . e . , textual elements and graphical elements . Then , there are many design choices under these two categories ( ﬁlled rectangles in Figure 6 ) . For textual ele - ments , there are two design choices , i . e . , regarding the input statement as a whole and splitting the input statement into segments by seman - tics , denoted by statement and semantic segments in Figure 6 . Note that semantic segments can be expanded to concrete visual elements , which may further yield valid combinations , e . g . , number + after and before + number + after . For graphical elements , there are also multiple choices among the combinations over icon , bar , pie , donut and picto - graph , e . g . , bar + icon and donut + icon . Formally , for a given design choice about visual elements ( u 1 , . . . , u K ) , we calculate its occurrence probability by p ( u 1 , . . . , u K ) = # ( u 1 , . . . , u K ) M , where # stands for the occur - rences of ( u 1 , . . . , u K ) in D of size M , 1 ≤ K ≤ 7 , and u k ∈ { statement , semantic segments , icon , bar , pie , donut , pictograph } . Generating user queries . To ensure the diversity of generated in - fographics , for a given input U , we generate M (cid:48) queries by following steps . First , we sample M (cid:48) different design choices from p , where p is the learned distribution of design choices about visual elements . Sec - ond , we specify design choices with concrete visual elements and then get their built - in attributes . Speciﬁcally , if semantic segments exists in a query , we expand it to the corresponding visual elements , e . g . , before , modiﬁer , number and after ( Section 3 ) . If icon or pictograph exists in a query , we leverage the result of icon generator , which extracts representative icons according to semantics of the input statement . If pie , donut or bar exists in a query , we leverage the result of chart gener - ator , which generates a speciﬁc chart according to the percentage in the input statement . Finally , we generate a set of queries Q = { Q m (cid:48) } M (cid:48) m (cid:48) = 1 where each user query corresponds to one design choice about visual elements . Formally , we encode the user query Q m (cid:48) by visual element types ˜ t n (cid:48) m (cid:48) and built - in attributes ˜ b n (cid:48) m (cid:48) , i . e . , Q m (cid:48) = { ( ˜ t n (cid:48) m (cid:48) , ˜ b n (cid:48) m (cid:48) ) } N (cid:48) n (cid:48) = 1 , where N (cid:48) is the number of visual elements in the query . 83 % use secure home Wi - fi ( a ) ( b ) ( c ) 74 % of consumers prefer le 74 % of consumers prefer less cooking oil in their daily foods . Figure 7 . Example of initialization . ( a ) A retrieved example . ( b ) The initial draft generated by directly applying positions in the retrieved example . ( c ) The initial draft generated by scaling the graphical elements and recalculating the font size of textual elements . 6 . 3 Retrieving Strategy We retrieve examples by comparing the distance between example indexes and user queries . Speciﬁcally , for each query Q m (cid:48) ∈ Q , we extract one example ˜ D ∈ D whose example index has the smallest distance to the query . This will result in a set of retrieved examples with size M (cid:48) . Concretely , for a given example index I m and a user query Q m (cid:48) , we ﬁrst match their elements by type . Then , we calculate the distance between them by considering whether they have similar visual elements types and built - in attributes , S ( I m , Q m (cid:48) ) = ∑ n s n (cid:0) t n m , b n m , ˜ t nm (cid:48) , ˜ b nm (cid:48) (cid:1) , where s n =   1 , if t nm (cid:54) = ˜ t nm (cid:48) , | b n m − ˜ b n m (cid:48) | ˜ b nm (cid:48) , otherwise . 7 I NITIALIZATION In the previous stage , we transform the input to a set of queries and retrieve one example for each query . In this section , for each retrieved example , we generate one initial draft by reusing its design . Position . For a graphical element , the aspect ratio speciﬁed in the query is usually not the same as that used in the example . Therefore , if we directly apply positions ( i . e . , the top - left and bottom - right coordi - nates ) of the one in the retrieved example , the new graphical element in the initial result will be easily distorted ( Figure 7 ( b ) ) . To avoid such distortion , we reuse the top - left coordinate used in the retrieved exam - ple , and recalculate the bottom - right coordinate by uniformly scaling the new graphical element to ﬁt the space occupied by the old one ( Figure 7 ( c ) ) . For a textual element , the number of characters used in the user query is usually not the same as that used in the example either . If we do not recalculate the font size , there will easily be truncated text or large white space in the text box ( Figure 7 ( b ) ) . To tackle this problem , we recalculate the font size by making the font size as large as possible while maintaining the text information complete ( Figure 7 ( c ) ) . Color / Text - Speciﬁed Attributes . For the other extracted design choices , e . g . , color and font type , we directly reuse them for the visual elements speciﬁed by the corresponding query . 8 A DAPTION In the previous stage , we generate an initial draft by reusing the design of the retrieved example . While the initial draft roughly conforms to design principles , spatial relationships between visual elements are not good enough in many cases . This is mainly caused by that built - in attributes in the query are often slightly different from that in the retrieved example . For instance , in Figure 7 ( c ) , there is an excessive white space to the right side of the icon . In addition , when the text of the query is placed in the same text box of the retrieved example , the font size is too small to read . Therefore , to ensure the quality of generated infographics , it is necessary to adjust spatial relationships between visual elements in the initial draft . In this section , we introduce an adaption stage , which is a MCMC - like approach , to solve this problem . 8 . 1 MCMC - Like Approach As shown in Figure 7 , despite imperfectness , the initial draft provides a good start point in the complex and huge design space . Intuitively , if we search around the initial draft in the design space , there stands a good chance of ﬁnding a better design . Actually , this simple intuition is consistent with the core concept of Markov chain Monte Carlo ( MCMC ) methods used in traditional tasks of layout generation ( e . g . , graphics design or indoor scene generation [ 29 , 37 ] ) . For these tasks , 5 Enlarge Textbox Move Icon … ( b ) ( c ) ( a ) 74 % of consumers prefer less cooking oil in their daily foods . 74 % of consumers prefer less cooking oil in their daily foods . 74 % of consumers prefer less cooking oil in their daily foods . Figure 8 . An illustrative example for our MCMC - like approach . ( a ) The initial draft . ( b ) A candidate design proposed by enlarging the bottom text box in ( a ) . It is accepted as the start point for the next round of proposal . ( c ) A candidate design proposed by moving the icon in ( b ) . It will be accepted with a low acceptance probability as it causes incorrect overlap . If it is not accepted , the design in ( b ) will continue to be used as the start point for the next round of proposal . MCMC methods start from a random layout , then iteratively propose a candidate layout according to a prior proposal distribution and accept the candidate with a certain probability . After Markov chain converges , an ideal layout that obeys the target distribution is naturally achieved . Inspired by MCMC methods , we propose a MCMC - like approach to adjust spatial relationships in the initial draft by following three steps , where the last two steps are executed iteratively until there is no better proposal . Figure 8 illustrates an example for our MCMC - like approach . Set a Start Point . As the previous stage has generated an initial draft roughly conforming to design principles , we take the initial draft as the start point instead of randomly sampling one ( Figure 8 ( a ) ) . Propose a Candidate Design . To adjust spatial relationships ef - fectively , we propose candidate designs by making a small change to the current result ( the initial draft for the ﬁrst iteration ) . Spatial rela - tionships often relate to two factors , i . e . , positions and sizes of visual elements . Therefore , we design two simple dynamics corresponding to these two factors , i . e . , position modiﬁcation and size modiﬁcation , and utilize them randomly to propose candidate designs . • Position modiﬁcation . This dynamic randomly chooses a visual element , and proposes a new position ˜ g by adding a random variable δ g to the current position g ( i . e . , ˜ g ← g + δ g ) of the element , where δ g follows a bivariate normal distribution . • Size modiﬁcation . This dynamic randomly chooses a visual element , samples a scale from a normal distribution , and uses the scale to resize the corresponding visual element . Compare Candidate and Current Designs . Once we propose a candidate design , we must determine whether to accept it for the next iteration . We adopt a similar mechanism to Metropolis - Hasting algorithm , where the candidate design is accepted with an acceptance probability α = min { 1 , d ( D (cid:48) ) / d ( D ) } . Here D (cid:48) and D stand for the candidate and current designs respectively , and d ( · ) measures the qual - ity of the spatial relationships in a given design . Speciﬁcally , if spatial relationships in the candidate design are better than those in the current design , i . e . , d ( D (cid:48) ) > d ( D ) , we always accept the candidate design ( see Figure 8 ( b ) ) . Otherwise , we accept the candidate design with the accep - tance probability of d ( D (cid:48) ) / d ( D ) ( see Figure 8 ( c ) ) . The key challenge is evaluating spatial relationships of designs , i . e . , estimating d ( · ) . 8 . 2 Recursive Neural Networks for Evaluation The acceptance probability α relates to the score d ( · ) , which reﬂects the quality of spatial relationships in a design . Typical MCMC methods use hand - crafted energy functions to evaluate spatial relationships in a layout . However , it is difﬁcult to comprehensively and accurately represent complex spatial relationships in infographics by hand - crafted energy functions . To tackle this problem , we learn from the example library about spatial relationships evaluation . Formally , we aim to learn a mapping h that takes a pair of designs ( D (cid:48) , D ) as the input and predict a pair of scores ( d ( D (cid:48) ) , d ( D ) ) as the output , i . e . , h : ( D (cid:48) , D ) → ( d ( D (cid:48) ) , d ( D ) ) . Then , ( d ( D (cid:48) ) and d ( D ) ) will be used to calculate α . To learn such a mapping , we have to address two challenges . First , we should construct a training set with effective labels from the example library . The challenge is that the example library only contains labels for visual elements and attributes while our task requires labels reﬂecting the quality of spatial relationships in a design . Second , we should learn a good feature representation for spatial relationships in infographics . 74 % of consumers prefer less cooking oil in their daily foods . Candidate Design Hidden vectors fc 0 1 ( a ) Input ( b ) Tree Builder ( c ) Feature Extractor ( d ) Scorer CurrentDesign type pos . built - in attr . node feat . relation feat . cut ratio Hiddenvectors 74 % of consumers prefer less cooking oil in their daily foods . Num . After Icon Hori . node Vert . node Boxlayer Vert . layer Hori . layer Boxlayer Boxlayer Figure 9 . Concrete model architecture for spatial relationships evaluation . 8 . 2 . 1 Training Set Construction As examples in our library are created by professionals , we naturally hypothesize that they have good spatial relationships . Besides , we assume that , if we make random perturbations on these examples , resulting designs have worse spatial relationships than original ones . The larger the perturbation is , the worse the spatial relationships are . This provides us a good opportunity to construct training set effec - tively . Speciﬁcally , for each example D ∈ D , we generate a set of new designs ˆ D j ( j ≥ 1 ) through randomly choosing one visual elements and randomly changing the position or size of the labeled bounding boxes . Then , we construct training data by following two patterns . • Take a pair of the original design and a perturbed design ( i . e . , (cid:0) D , ˆ D j (cid:1) or (cid:0) ˆ D j , D (cid:1) ) as the input , and ( 1 , 0 ) or ( 0 , 1 ) as the label . Here , original designs serve as good examples . This type of train - ing data will help our model learn to differentiate ideal and bad spatial relationships , which are more common in late iterations . • Take a pair of perturbed designs with different perturbation de - grees ( i . e . , (cid:0) ˆ D i , ˆ D j (cid:1) or (cid:0) ˆ D j , ˆ D i (cid:1) ) as the input , and take ( 1 , 0 ) or ( 0 , 1 ) as the label . Here , the design with smaller perturbation degree is denoted as ˆ D i and serves as the good example . This type of training data will help our model learn to pick a better design when neither of them has ideal spatial relationships , which are more common in early iterations . In our implementation , we generate 20000 pairs for training and 2000 pairs for validation by following the above two patterns . 8 . 2 . 2 Model Architecture The spatial relationships of infographics are inherently hierarchical . Taking Figure 9 ( a ) as an example , its spatial structure can be repre - sented by a tree , where the text box for number and the single icon are horizontally arranged and then these two elements and the text box for after are vertically arranged . On the other hand , recursive neural networks is a widely adopted and the state - of - the - art model to encode such hierarchical structures in existing works [ 9 , 23 ] . Therefore , we also leverage recursive neural networks , instead of convolutional neural networks [ 18 ] , in our approach . Figure 9 illustrates the model architecture . First , the tree builder transforms an infographic into a hierarchical tree in a top - down fashion . Then , the feature extractor , which is a recursive neural network , en - codes the infographic into hidden vectors according to the hierarchical tree in a bottom - up manner . Finally , the scorer built upon those hidden vectors computes scores for spatial relationships in the infographic . Tree Builder . It takes an infographic as input and outputs a hierar - chical tree . Initially , the root node contains all the visual elements in the infographic . Then , we recursively split tree nodes until there is no node can be split according to following criteria . • Horizontal divisibility . It means there exists a horizontal line that can divide visual elements in the current node into two groups . The current node is marked as a horizontal node and split into two child nodes , each of which contains a group of visual elements . If there is no such cutting line , we turn to the next criterion . • Vertical divisibility . Similar to the previous criterion , it means there exists a vertical cutting line that can divide visual elements in the current node into two groups . The current node is marked 6 To appear in IEEE Transactions on Visualization and Computer Graphics as vertical node and is split into two child nodes . If this criterion does not apply either , we turn to the last criterion . • Indivisibility . If there neither exists a vertical cutting line nor a horizontal cutting line , we mark this node as an indivisible node . Feature Extractor . It is a recursive neural network that encodes an infographic into hidden vectors according to the hierarchical tree . To better encode different spatial relationships , we use four distinct layers in our recursive neural network , including box layer , horizontal layer , vertical layer and overlap layer . These layers are organized according to the hierarchical tree in a bottom - up manner ( Figure 9 ( c ) ) . Each of them is a two - layer perceptron although their weights are different . Inputs for these layers are as following : • Box layer . It encodes the status of the leaf node in the hierarchical tree , i . e . , the visual element . The input includes : 1 ) the element type , a one - hot encoding , 2 ) the position , a vector representing the top - left and bottom - right coordinates , and 3 ) the built - in attribute , a scalar indicating the aspect ratio or text length . • Horizontal / vertical / overlap layers . They encode horizontal , vertical , and overlap relationships between different nodes in the hierarchical tree , respectively . The input includes : 1 ) node representations for two child nodes , 2 ) the relation representation between two child nodes , which is a vector representing the offset of the right child relative to the left child , and 3 ) the cut ratio , a scalar indicating the position of the cutting line ( only for the horizontal and vertical layer ) . Scorer . After the feature extractor , we get hidden vectors repre - senting spatial relationships of the current design D and the candidate design D (cid:48) , respectively . Then , we concatenate them and feed them into the scorer to get the score for spatial relationships of the infographic . Speciﬁcally , the scorer consists of a fully connected hidden layer and a Softmax layer , and is jointly trained with the aforementioned feature extractor by minimizing the cross - entropy loss . 9 E VALUATION We implement a prototype system targeting widely - used proportion - related infographics . To demonstrate the system , we use 30 descriptions with average length of 74 . We randomly pick 5 descriptions and gener - ate 5 infographics for each of them . For the remaining descriptions , we generate 1 infographic for each of them . In this way , we generate 50 infographics in total and show them to the experts . Our experiments are run on a CPU Windows server ( Intel Xeon E5 2 . 6GHz ) . During the adaption , each initial draft is adjusted for 1000 iterations , taking 3 . 5s on average . Note that the adaption process is efﬁcient because the initial draft provides a good starting point and only the inference step of the recursive neural network is used . 9 . 1 Sample Infographics Figure 10 shows several typical samples from the 50 results . Note that if there is a pictograph , we will generate multiple candidate infographics by traversing the number of icons in the pictograph from 3 to 10 , and then leverage the model introduced in Section 8 . 2 to choose the one that achieves the best score . For pies , donuts , and bars , we render them by referring to the percentage provided in the input statement and reusing the annotated positions and colors of the retrieved example . Figures 10 ( a ) - ( d ) are all generated from the same input utterance “1 out of 3 patients have used a portal to connect with doctors . ” by using different queries . Speciﬁcally , we sample four different queries , including donut + single icon + number + after ( Figure 10 ( a ) ) , pictograph + number + after ( Figure 10 ( b ) ) , pie + single icon + statement ( Figure 10 ( c ) ) and single icon + number + after ( Figure 10 ( d ) ) . We can observe that these generated infographics have different styles in terms of the choices for visual elements , the layout , the color and the font . Figures 10 ( e ) - ( j ) demonstrate that our approach provides great ﬂexi - bility and diversity in dealing with different inputs . First , our approach can generate both concise and complex designs due to the natural di - versity of examples . For example , Figure 10 ( e ) concisely represents information in a simple up - down structure , while Figure 10 ( g ) - ( j ) rep - resent information by multiple text blocks and graphic elements in a complicated structure . Moreover , our approach is capable of high - lighting the important information in various ways . For example , in Figure 10 ( e ) - ( j ) , number elements are set the biggest font size to at - tract visual attention , while in Figure 10 ( g ) - ( j ) , icons and charts are used simultaneously to emphasize the semantic meaning and numerical information . Furthermore , our approach can create different design styles by imitating color schemes of different examples . For example , although element types are almost the same in Figure 10 ( e ) and ( f ) , the former one shows a sense of mature and calm while the latter is more lively and vigorous . In addition , even some results have the same visual element combinations ( e . g . , Figure 10 ( a ) , ( g ) and ( h ) all have donut + icon + number + after ) , they can have totally different layouts and colors if they are generated by imitating different examples . Figures 10 ( k ) - ( m ) show generated compositional infographics with multiple proportional facts by imitating corresponding examples . To generate them , we run our approach twice . The ﬁrst round generates individual proportion - related infographics by adapting an example re - trieved according to element types and built - in attributes . The second round generates the compositional results by adapting an composi - tional example retrieved based on the number and aspect ratio of the individual infographics generated in the ﬁrst round . These composi - tional infographics can facilitate effective comparison among multiple proportional facts and provide a richer representation . Figures 10 ( n ) - ( o ) compare the retrieved example , the initial draft generated by directly applying the retrieved example’s design , and the ﬁnal infographic after adaption . We observe that the initial draft roughly conforms to design principles while spatial relationships between visual elements are not good enough sometimes . For example , in Figure 10 ( n ) , the font size is a little small while in Figure 10 ( o ) , there is an excessive white space between the single icon and the after . After adaption , the spatial relationships in the initial draft are greatly improved . 9 . 2 Expert Review To understand the effectiveness and usability of our method , we con - ducted an evaluation study with 4 designers . All of them have graduated ( E1 , E4 ) from or were enrolled ( E2 , E3 ) in professional schools of de - sign disciplines . E1 and E4 are professional designers in a technology company . Both of them have around ten years of design experience in user interface , graphics , and video . E2 and E3 are senior graduate students and have been interns in design positions . Both of them have more than two years of design experience . For each designer , we conduct a 60 - minute interview . First , we use 10 minutes to introduce the background of this work and system workﬂow . Since our approach does not involve much interactions , we do not ask the designers to try out our system . Instead , we show them sample infographics generated by our approach , each containing a proportion - related natural language statement , a retrieved example , and a generated infographic . The statement and generated infographics are the input and output of our system . In particular , we show the designers the retrieved example side - by - side with the generated infographic , since we like to know their opinions about the resemblance between them . After that , a semi - structured interview was conducted to understand professional opinions on the usability and quality of our approach . Overall , designers were very impressed by the convenience and intelligence that our approach provides to create infographics . For example , E1 mentioned that “The capability of automatically imitating existing online examples is really smart and amazing , because it is quite time - consuming for me to do it manually . ” , and E2 said that “By intelligently imitating online examples , this approach enables so many potential ways of presenting the user information , which cannot be ﬁnished by me in a short period . It does a great job . ” Regarding how much assistance our approach can provide to users in real - world scenarios , designers thought at least two types of people would beneﬁt from it . One is casual users with limited design expertise . From casual users’ perspective , infographics are mainly used to enrich their reports or dashboards in informal communication . Designers believed that our generated results were good enough for them . For example , E3 mentioned that “The generated infographics can fully ex - press the original information and can be used directly by casual users . ” 7 ( h ) ( f ) ( g ) 1 out of 3 patienthaveusedaportaltoconnectwithdoctors ( a ) 1 outof 3 PATIENTHAVEUSED APORTALTOCONNECTWITHDOCTORS ( b ) 1OUTOF3PATIENT HAVE USED A PORTALTO CONNECT WITH DOCTORS z ( c ) ( d ) 80 % TEENAGERS PLAYMOBILE PHONESATHOMEATNIGHT 59 % Nearly of all global cream liqueur is produced in Ireland ( e ) Around 60 % of that data is filtered out before it reaches the brain ( n ) 1 in 5 students in private colleges and universities canhardly afford to complete college . 83 % ofofflineconsumersstatedthatrewardsonofferareveryimportantwhentheychooseacurrent accountorcreditcard ( o ) ( j ) of workingwomensaytheyare concernedaboutlosingtheirjobsbefore , during , andevenafterpregnancy . OVER 60 % of the researchers in sciences who use the Internet agreed that Internet use had a positive impact on their study and research . Around 80 % Around of the researchers in sciences who use the Internet agreed that Internet use had a positive impact on their study and research . 80 % 1 in 5 people live in rural areas ofuniversitystudentswillbuynewbooks . 54 % 1 in 5 people live in rural areas ( l ) ( m ) Budget Check 80 % 70 % 60 % 40 % of coffee budget is gone . of fruit budget is completed . of snack budget is wentwell . of meat budget is unexpected . Online Activities among Teens 62 % of teens visit a social network . 36 % of teens send an instant message . 34 % of teens listen to music . 15 % of teens do research for school . 36 % 40 % ( k ) patienthaveusedaportaltoconnectwithdoctors ( i ) Retrieved Examples of ( k ) - ( m ) Retrieved Examples of ( a ) - ( d ) Retrieved Examples of ( e ) - ( j ) 50 % Lessthanhalfofallteenmothersevergraduatehighschool . 1 in 3 SMALLBUSINESS CURRENTLYUSESACRMSYSTEM 84 . 9 % OFNPSSEEPATIENTS COVEREDBYMEDICARE wouldliketousemobilebanking ( UK ) Acandidate’spostsonFacebookcanalsocostthemajob 30 % wererejected forprovocativeorinappropriatephotographsorinformation . 31 % wererejected forinformationaboutalcoholordruguse . 14 % wererejectedfor bad - mouthingtheir previouscompanyorfellowemployees . 63 % wererejected fordiscriminatorycomments . @ # % # & $ @ # % # & $ KEYFINDINGSOFOURSTUDY 99 % 90 % 82 % 30 % o f w e b a pp l i c a t i o n s h a v e a t l e a s t 1 v u l n e r a b i l i t y o f h a c k i n g i n c i d e n t s a r e n o t r e p o r t e d p u b l i c l y 33 % o f t h e h a c k e d o r g a n i z a t i o n s k n o w t h e v u l n e r a b i l i t y b e f o r e h a n d ofwebapplicationshaveatlast1high / critical vulnerability 91 % OFGLOBALCONSUMERSWORLDSWITCHBRANDSIFADIFFERENTBRANDOFSIMILARPRICEANDQUALITYSUPPORTAGOODCAUSE . 20 % ONLY ofadultsmetbothoftheaboveguidelinesin2010 6 in 10 email messages was identified as phishing in February 2012 FAVOURITEACTIVITIESDURINGLEISURETIME PURSUINGINTERESTSANDHOBBIES ARTSANDCULTURES TAKINGACTIVITIESANDSPORTS GETTINGAROUNDTHEWORLDINDEPENDENTLY SEEINGPEOPLEWHOAREMOSTIMPORTANT 17 % 6 % 8 % 36 % 40 % Figure 10 . ( a ) - ( j ) and ( k ) - ( m ) shows infographics with single and multiple proportional facts respectively . ( n ) - ( o ) shows a triple , including the retrieved example , the initial draft generated by directly applying the retrieved example’s design and the ﬁnal infographic after the adaption . For better visual appearance , embellished shapes ( in ( i ) and ( l ) ) and the color transparency of the icon ( in ( c ) and ( g ) ) are added by post - editing . To avoid the copyright issue , infographics displayed here are generated by adapting the examples retrieved from a dataset created by our designers . E4 said “Compared to the uniqueness and creativity of the design , ca - sual users usually prefer to follow popular designs , which is exactly what this approach provides . ” The other one is professional designers themselves . While our approach initially targets casual users , all the de - signers express the appreciation for the help our approach could provide for them as well . As admitted by all the designers , they had to immerse themselves with myriad examples to get inspirations during the design process . They usually login to multiple design websites and manually check which design satisﬁes their requirements . First , experts really ap - preciated the capability of automatically retrieving the examples which meet user requirements by our approach . “When I propose a design to a client , if no existing ones are referenced and attached , the proposal will be rejected with high probability . I have to manually search the Internet to ﬁnd references . I think the retrieval stage in this approach can save my time on ﬁnding intent references” , said one of the designers . E3 said , “Sometimes I even do not have clear thought about my designs . This approach can provide me various previews about different designs on my data . It is really informative . ” Moreover , designers thought the adaption stage by itself was very helpful . For example , E2 commented , “When I want to reuse some designs , I have to manually adjust visual elements to make it suitable for my data . It is amazing that the adaption stage can automatically do it . I think it would save much time if I could make adjustment on the automatically - adapted version provided by this approach . ” . In addition , designers further agree that the generated results could be used as their initial design drafts . E4 said , “Even from a professional point of view , it can deﬁnitely be used as an initial design draft for designers , which can save us lots of time and efforts . ” . In terms of the quality of our generated infographics , four experts rate the results separately and think that roughly 68 % of them are reasonable . The comments of designers mainly center on three aspects . First , for most exhibited cases , the designers feel that they were ﬂexible and diverse enough . Two designers commented regarding the element combination that “This approach provides the ﬂexibility of composing various visual elements to create a complex infographic . ” ( E4 ) , and “overall it is very diverse , and each case shows a unique combination of elements . ” ( E2 ) . Another designer also commented on the layout of the generated infographics : “even though the element combinations are similar , it generates quite different infographics by laying elements out in different ways . ” ( E1 ) . Second , almost all designers had said that the important characteristics of the example were completely preserved by our approach . For example , E1 said that “the generated infographic looks very similar to that of the retrieved example . Only by scrutiny , 8 To appear in IEEE Transactions on Visualization and Computer Graphics could I tell the minor differences” . Finally , all the designers thought that generated results accurately convey the original information . E2 commented that “The key information of user input , especially the numerical information , is correctly highlighted by using a larger font size or leveraging data driven graphics like bars , pies and donuts . ” . We also receive suggestions that implied further necessary improve - ments to our approach . First , it is suggested to use icon combination instead of a single icon to represent the semantic meaning of the input statement . For example , when seeing a key phrase “phishing mail” in the input statement , E1 expressed the intent to compound a “ﬁsh” icon and an “email” icon together to convey such information . We think the latest work ICONATE [ 36 ] can be integrated to our approach to improve performance . Moreover , designers also made suggestions on further adding a reference line in bar charts used in our results . “Al - though this is a trivial detail , the reference line makes multiple bar charts easier to be understood . ” said by one of designers . 10 D ISCUSSION 10 . 1 Example - Based Infographic Generation Creating infographics is non - trivial , which requires tremendous design expertise and is time - consuming . Therefore , automating the genera - tion process of infographics is very meaningful and useful . Previous studies try to automatically generate infographics by using predeﬁned blueprints . However , the deﬁciency of blueprints largely constrains the diversity of generated results . By contrast , there are enormous info - graphics on the Internet . This motivates us to consider example - based approach , i . e . , generating infographics by imitating existing infograph - ics . One concern for this approach is that crowdsourced examples might not always ﬁt right design principles and thus may have negative inﬂuence on the generation performance . To alleviate such inﬂuence , in our implementation , we control the quality of crowdsourced examples by letting annotators discard the designs with obvious errors during the labeling process and collecting examples from professional websites . Moreover , in real scenarios , both designers and casual users get inspired from existing infographics . For designers , they usually explore lots of online examples to learn advanced design principles and accu - mulate design materials , which will be used in their future designs . For casual users , who have no design background , they even have strong desires to directly reuse a favorite existing infographic on their own data . These scenarios make us believe that our example - based approach is useful for casual users and even potentially helpful for designers . In addition , we aim to use the automatic generation of infographics as the assistance but not the replacement for humans . On the one hand , it is almost impossible to automatically generate a perfect infographic . On the other hand , the design process is subjective . Therefore , human interaction is indispensable during the design process . Our approach can generate editable infographics that roughly conform to design principles and meet user requirements , based on which people can easily get desirable infographics by polishing and ﬁne - tuning . 10 . 2 Copyright Issue Copyright is a big concern for our example - based approach . It is a violation of intellectual property rights to fully imitate an example without owning appropriate copyrights . Practically , although designers explore online examples for inspirations , they hardly adopt every design aspect from a single example . During the interview , the designers mentioned that may largely reuse high - level designs , e . g . , layouts and colors , but they will rethink details , e . g . , shading and textures , based on their personal tastes . In this work , to demonstrate the capability of our approach , the algorithm is designed to imitate examples as much as possible . There are several solutions to deploy our technique in production . The simplest way is to directly use an example library with proper copyrights . As infographics are often easier to purchase than blueprints , it may still achieve a good diversity . In addition , as our approach contains two consecutive stages , it is also possible to allow users to directly provide an example with a correct copyright for the adaption stage . Another promising solution is to combine designs from multiple examples , instead of reusing every aspect from a single one . We believe this solution is more aligned with the common practice of designers , and plan to improve our approach in this respect . 10 . 3 Opportunities for New Usage We think there are at least three opportunities for new usage . From Proportion Infographics to Others . Although this work focuses on proportion - related infographics , it is possible to generalize our approach to more types of infographics , e . g . , time - line , location , or process . In our approach , both the retrieval and adaption stage are pro - posed independent of the infographics type . Thus , it can accommodate other types of infographics once the visual elements are redeﬁned and an annotated example library are provided . Customized Searching Tool for Infographics . The retrieval stage in our approach can be extended to a customized searching tool for infographics . In practice , people often intend to ﬁnd infographics with certain kinds of visual attributes . However , they usually cannot get satisfactory results by typing descriptions in traditional search engines , e . g . , Google or Bing . For example , when people want to get inspiration from existing infographics about how to design infographics with unusual canvas size ( like 5 : 1 ) , traditional search engines can hardly provide related infographics . Thus , a customized searching tool for infographics , which indexes visual attributes of infographics , is of great value . The retrieval stage of this work has already indexed some essential visual attributes . A extended version of it can greatly improve the searching efﬁciency for infographics . Automatic Layout Adaption Tool . Techniques used in our adap - tion stage can be potentially integrated into mainstream software to offer automatic reﬁnement . To lower the authoring barrier , commercial software ( e . g . , PowerPoint or Adobe Illustrator ) usually provide pre - deﬁned blueprints to users . However , the user data usually cannot be perfectly ﬁtted into these predeﬁned blueprints , requiring tedious reﬁne - ment after applying blueprints . If users can make edits based on designs that have been automatically adjusted by our adaption techniques , both of authoring efﬁciency and user experience can be improved . 10 . 4 Limitations There are several limitations of our approach . First , the implementation for our approach is limited to proportion - related infographics although it can be potentially generalized to other types of infographics . Second , when constructing the example library , visual elements and attributes can be further enriched to improve the performance of retrieval . For instance , various properties of charts can be added , e . g . , the inner radius of donut charts or explode slices in pie charts . For another instance , embellished shapes can be added , e . g . , stars , banners or speech / thought bubbles . Third , the current retrieval stage only considers attributes of candidate visual elements but ignores the user preference on visual styles ( e . g . , the concise style , the lively colors , or the landscape layout ) . In the future , we can index examples by their visual styles and improve the retrieval strategy to consider the consistence between the user pref - erence and the example’s visual style . Fourth , the adaption efﬁciency can be potentially improved by designing more efﬁcient strategies to propose candidate designs . In addition , we only adjust spatial relation - ships as it is the most easily disturbed attributes after the initialization . Other attributes can also be adjusted to further boost the performance . 11 C ONCLUSION AND F UTURE W ORK In this paper , we introduce retrieve - then - adapt , an automatic approach to generate infographics by imitating online examples . Speciﬁcally , we present a retrieval stage that indexes and retrieves online examples based on the element types and build - in attributes , and an adaption stage that automatically adjust spatial relationships by a MCMC - like approach to make the retrieved example’s design more suitable for the user information . We demonstrate the expressiveness and usability of our approach through sample results and expert reviews . We believe this work opens up a new paradigm for automatically generating in - fographics , i . e . , example - based approach . We plan to further extend this framework by considering other types of infographics , considering more design choices and mixing designs of different examples , in order to better meet users’ growing demands . 9 R EFERENCES [ 1 ] N . S . Alrwele . Effects of infographics on student achievement and students’ perceptions of the impacts of infographics . Journal of Education and Human Development , 6 ( 3 ) : 104 – 117 , 2017 . [ 2 ] H . Bahng , S . Yoo , W . Cho , D . Keetae Park , Z . Wu , X . Ma , and J . Choo . Coloring with words : Guiding image coloriza - tion through text - based palette generation . In Proceedings of the european conference on computer vision , pages 431 – 447 , 2018 . [ 3 ] S . Bateman , R . L . Mandryk , C . Gutwin , A . Genest , D . McDine , and C . Brooks . Useful junk ? the effects of visual embellishment on comprehension and memorability of charts . In Proceedings of the SIGCHI conference on human factors in computing systems , pages 2573 – 2582 , 2010 . [ 4 ] Z . Bylinskii , S . Alsheikh , S . Madan , A . Recasens , K . Zhong , H . Pﬁster , F . Durand , and A . Oliva . Understanding infographics through textual and visual tag prediction . [ 5 ] S . P . Chang and B . A . Myers . Webcrystal : understanding and reusing examples in web authoring . 2012 . [ 6 ] Z . Chen , Y . Wang , Q . Wang , Y . Wang , and H . Qu . Towards auto - mated infographic design : Deep learning - based auto - extraction of extensible timeline . IEEE transactions on visualization and computer graphics , 26 ( 1 ) : 917 – 926 , 2019 . [ 7 ] W . Cui , X . Zhang , Y . Wang , H . Huang , B . Chen , L . Fang , H . Zhang , J . - G . Lou , and D . Zhang . Text - to - viz : Automatic gen - eration of infographics from proportion - related natural language statements . IEEE transactions on visualization and computer graphics , 2019 . [ 8 ] C . Doersch . Tutorial on variational autoencoders . arXiv preprint arXiv : 1606 . 05908 , 2016 . [ 9 ] A . Gadi Patil , O . Ben - Eliezer , O . Perel , and H . Averbuch - Elor . Read : Recursive autoencoders for document layout generation . arXiv preprint arXiv : 1909 . 00302 , 2019 . [ 10 ] I . Goodfellow , J . Pouget - Abadie , M . Mirza , B . Xu , D . Warde - Farley , S . Ozair , A . Courville , and Y . Bengio . Generative adver - sarial nets . In Advances in neural information processing systems , pages 2672 – 2680 , 2014 . [ 11 ] S . Haroz , R . Kosara , and S . L . Franconeri . Isotype visualization : Working memory , performance , and engagement with pictographs . In Proceedings of the 33rd annual ACM conference on human factors in computing systems , pages 1191 – 1200 , 2015 . [ 12 ] J . Harper and M . Agrawala . Deconstructing and restyling d3 visualizations . In Proceedings of the 27th annual ACM symposium on User interface software and technology , pages 253 – 262 , 2014 . [ 13 ] J . Harper and M . Agrawala . Converting basic d3 charts into reusable style templates . IEEE transactions on visualization and computer graphics , 24 ( 3 ) : 1274 – 1286 , 2017 . [ 14 ] S . J . Harrington , J . F . Naveda , R . P . Jones , P . Roetling , and N . Thakkar . Aesthetic measures for automated document lay - out . In Proceedings of the 2004 ACM symposium on Document engineering , pages 109 – 111 , 2004 . [ 15 ] S . R . Herring , C . - C . Chang , J . Krantzler , and B . P . Bailey . Getting inspired ! understanding how and why examples are used in cre - ative design practice . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 87 – 96 , 2009 . [ 16 ] E . Hoque and M . Agrawala . Searching the visual style and struc - ture of d3 visualizations . IEEE transactions on visualization and computer graphics , 26 ( 1 ) : 1236 – 1245 , 2019 . [ 17 ] N . W . Kim , E . Schweickart , Z . Liu , M . Dontcheva , W . Li , J . Popovic , and H . Pﬁster . Data - driven guides : Supporting ex - pressive design for information graphics . IEEE transactions on visualization and computer graphics , 23 ( 1 ) : 491 – 500 , 2016 . [ 18 ] A . Krizhevsky , I . Sutskever , and G . E . Hinton . Imagenet classiﬁ - cation with deep convolutional neural networks . In Advances in neural information processing systems , pages 1097 – 1105 , 2012 . [ 19 ] R . Kumar , J . O . Talton , S . Ahmad , and S . R . Klemmer . Bricolage : example - based retargeting for web design . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems , pages 2197 – 2206 , 2011 . [ 20 ] B . Lee , S . Srivastava , R . Kumar , R . Brafman , and S . R . Klemmer . Designing with interactive example galleries . 2010 . [ 21 ] H . - Y . Lee , W . Yang , L . Jiang , M . Le , I . Essa , H . Gong , and M . - H . Yang . Neural design network : Graphic layout generation with constraints . arXiv preprint arXiv : 1912 . 09421 , 2019 . [ 22 ] J . Li , J . Yang , A . Hertzmann , J . Zhang , and T . Xu . Layoutgan : Generating graphic layouts with wireframe discriminators . arXiv preprint arXiv : 1901 . 06767 , 2019 . [ 23 ] M . Li , A . G . Patil , K . Xu , S . Chaudhuri , O . Khan , A . Shamir , C . Tu , B . Chen , D . Cohen - Or , and H . Zhang . Grains : Generative recursive autoencoders for indoor scenes . ACM Transactions on Graphics ( TOG ) , 38 ( 2 ) : 12 , 2019 . [ 24 ] S . Lin , J . Fortuna , C . Kulkarni , M . Stone , and J . Heer . Selecting semantically - resonant colors for data visualization . In Computer Graphics Forum , pages 401 – 410 , 2013 . [ 25 ] M . Lu , C . Wang , J . Lanir , N . Zhao , H . Pﬁster , D . Cohen - Or , and H . Huang . Exploring visual information ﬂows in infographics . [ 26 ] P . ODonovan , A . Agarwala , and A . Hertzmann . Learning layouts for single - pagegraphic designs . IEEE transactions on visualiza - tion and computer graphics , 20 ( 8 ) : 1200 – 1213 , 2014 . [ 27 ] P . O’Donovan , A . Agarwala , and A . Hertzmann . Designscape : Design with interactive layout suggestions . In Proceedings of the 33rd annual ACM conference on human factors in computing systems , pages 1221 – 1224 . ACM , 2015 . [ 28 ] H . C . Purchase , K . Isaacs , T . Bueti , B . Hastings , A . Kassam , A . Kim , and S . van Hoesen . A classiﬁcation of infographics . In International Conference on Theory and Application of Diagrams , pages 210 – 218 . Springer , 2018 . [ 29 ] S . Qi , Y . Zhu , S . Huang , C . Jiang , and S . - C . Zhu . Human - centric indoor scene synthesis using stochastic grammar . In Proceed - ings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5899 – 5908 , 2018 . [ 30 ] A . Satyanarayan and J . Heer . Lyra : An interactive visualization design environment . Computer Graphics Forum , 33 ( 3 ) : 351 – 360 , 2014 . [ 31 ] W . V . Siricharoen . Infographics : the new communication tools in digital age . In The international conference on e - technologies and business on the web ( ebw2013 ) , pages 169 – 174 , 2013 . [ 32 ] R . Socher , C . C . Lin , C . Manning , and A . Y . Ng . Parsing natural scenes and natural language with recursive neural networks . In Proceedings of the 28th international conference on machine learning , pages 129 – 136 , 2011 . [ 33 ] T . - H . Sun , C . - H . Lai , S . - K . Wong , and Y . - S . Wang . Adversar - ial colorization of icons based on contour and color conditions . In Proceedings of the 27th ACM International Conference on Multimedia , pages 683 – 691 , 2019 . [ 34 ] K . Wang , M . Savva , A . X . Chang , and D . Ritchie . Deep convo - lutional priors for indoor scene synthesis . ACM Transactions on Graphics ( TOG ) , 37 ( 4 ) : 70 , 2018 . [ 35 ] Y . Wang , H . Zhang , H . Huang , X . Chen , Q . Yin , Z . Hou , D . Zhang , Q . Luo , and H . Qu . Infonice : Easy creation of information graphics . In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems , pages 1 – 12 , 2018 . [ 36 ] N . Zhao , N . W . Kim , L . M . Herman , H . Pﬁster , R . W . Lau , J . Echevarria , and Z . Bylinskii . Iconate : Automatic compound icon generation and ideation . To appear in the ACM Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems , 2020 . [ 37 ] Y . Zhao and S . - C . Zhu . Image parsing with stochastic scene grammar . In Advances in Neural Information Processing Systems , pages 73 – 81 , 2011 . [ 38 ] X . Zheng , X . Qiao , Y . Cao , and R . W . Lau . Content - aware generative modeling of graphic design layouts . ACM Transactions on Graphics , 38 ( 4 ) : 133 , 2019 . 10 To appear in IEEE Transactions on Visualization and Computer Graphics About 1 in 5 students attending private black colleges and universities are unsure whether they can afford to complete college 75 % of Americans who will live in poverty at some point in their life before age 65 95 % of the total lead burden is contained within bone in occupationally exposed adults . ofconsumersreportsubstantialconcernaboutfoodsafety 60 % ( a ) ( b ) ( c ) ( d ) Only 11 % ofemployeesdiscussedarecentmentalhealthproblemwiththeirlinemanager . 90 % ofemployeesthatofferaHealthSavingsAccountdonotcontributetotheplan 8 % OFALLHIGHSCHOOLSENIORSREPORTEDUSINGCONCAINATLEASTONEDURINGHIGHSCHOLLS 31 % Theconstructionindustryaccountsforoverathirdofworkplacefatalities Retrieved examples of ( a ) - ( d ) Figure 11 . Failure cases . A F AILURE C ASES We also observe some failure cases during the evaluation . Figure 11 shows examples for common failures . One typical failure is that the generated infographic does not meet people’s aesthetic . For example , Figure 11 ( a ) shows a ‘green’ coin because the color is directly inherited from the retrieved example . How - ever , the gold or the silver is more appropriate considering the semantic meaning of the coins . Since several techniques [ 2 , 24 ] have been inves - tigated to identify semantically relevant colors from natural language statements , we expect to improve the colorization by integrating such techniques into our approach . For another example , in Figure 11 ( b ) , there is a slight misalignment between the icon and the texts , which makes the generated infographic look less neat . Such misalignment is caused by that the evaluation model makes wrong predictions during the adaption . We think there are at least two possible ways to alleviate the misalignment problem . On the one hand , the performance of the evaluation model can be improved by feeding more training data . One the other hand , a large proportion of these slight misalignments can be easily solved by post - processing generated infographics , i . e . , forcing two elements to be aligned when the gap between their edges is minute . Besides , another main failure is that the visual appearance of the generated infographic is not identical to that of the retrieved example . For the retrieved example of Figure 11 ( c ) , its icon has rich color and it looks appealing . However , as we only inherits the dominant color of the icon , the generated infographics in Figure 11 ( c ) looks much plain . We think labeling as much colors as possible will not fundamentally solve this problem . One possible solution is to leverage computer vi - sion techniques to automatically colorize the icon [ 33 ] . For another instance , in the retrieved example of Figure 11 ( d ) , there is a connecting line between the bar chart and the number ‘90 % ’ . In the generated in - fographic , there is no such line as we do not label it during the example library construction . We can observe that although the generated result is a reasonable infographics after adapting the spatial relationships , its overall visual appearance is different with that of the retrieved example . We believe that when more design choices are added into our system , such visual appearance gap can be gradually narrowed down . 11