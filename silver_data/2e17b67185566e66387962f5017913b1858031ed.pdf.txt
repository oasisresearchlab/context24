Memory Access Characteristics of Neural Network Workloads and Their Implications Soyeon Park Dept . of Computer Engineering Ewha University Seoul , Republic of Korea sypark9646 @ ewhain . net Hyokyung Bahn * Dept . of Computer Engineering Ewha University Seoul , Republic of Korea bahn @ ewha . ac . kr Abstract — With the recent advances in machine learning and many - core computing technologies , neural networks are widely used in various service domains of the 4th industrial revolution . As the data set of neural network is becoming increasingly large , it is important to analyze the memory access characteristics of neural network workloads . In this paper , we perform a comprehensive analysis of memory access behaviors in four types of neural network configurations , i . e . , CNN ( convolutional neural networks ) , RNN ( recurrent neural networks ) , DNN ( deep neural networks ) , and ANN ( artificial neural networks ) . From this analysis , we observe the following characteristics , which are quite different from traditional desktop and smartphone memory accesses . First , we analyze the access bias of memory locations and find that most memory accesses occur in a certain limited memory locations . Second , the identity of these hot locations is the data and heap regions , which account for over 90 % of total memory accesses . Third , the bias of memory access in neural network workloads is relatively weaker than other desktop or smartphone workloads , specially for write operations . Fourth , write operations account for about twice of read operations regardless of neural network types . Fifth , in predicting re - access likelihood , temporal locality provides better information than access frequency in read operations , but combining the two properties is necessary for accurate estimation in write operations . We anticipate that the analysis of this study will be a good guideline for designing an efficient memory system for neural network workloads . Keywords — memory access characteristics , neural network , machine learning , access bias , artificial intelligence I . I NTRODUCTION With the recent proliferation of AI ( artificial intelligence ) applications and the rapid development of many - core computing technologies , machine learning has become an essential component of modern software design in the era of the 4th industrial revolution [ 1 , 2 , 3 ] . More and more software internally makes use of machine learning techniques , and various services including autonomous driving [ 4 , 5 , 6 ] , image recognition [ 7 , 8 , 9 ] , and genome analysis are advancing every day [ 10 , 11 ] . Recently , mobile applications in smartphones also utilize some kinds of AI techniques for intelligent services [ 12 , 13 , 14 ] . To accommodate the ever growing data size of AI workloads , the memory capacity of the system continues to grow . However , increasing the memory capacity is not easy due to the scalability limitations of DRAM and power consumption issues [ 15 , 16 ] . It is difficult to scale down the density of DRAM to below 5nm , which is almost reached . Also , the power consumption of memory systems becomes increasingly large as the DRAM capacity of the system grows . Because DRAM is a volatile medium , each memory cell requires consistent recharge of power to maintain data even if the memory location is not accessed [ 17 ] . This recharge of power , which we call the refresh operation , is responsible for a significant portion of memory power consumption as the size of DRAM increases [ 16 , 18 ] . Thus , it is necessary to analyze the memory access patterns of AI workloads for efficient memory management with respect to performance and power . In this paper , we analyze the memory access behavior of AI applications specially focusing on neural networks , and observe that memory accesses in AI workloads are different from those of traditional desktop or smartphone systems . To do this , we first track each memory access of neural network workloads and log them . Then , we analyze the extracted memory access traces . In particular , we analyze the access bias of memory locations and find out that most memory accesses occur in a certain limited memory regions regardless of neural network types . We further quantify the identity of these hot memory regions and find that they are data and heap regions , which account for over 90 % of total memory accesses . For further analysis , we separately investigate read and write operations of memory accesses . From this analysis , we observe that the ratio of reads to writes is invariant regardless of neural network types . Specifically , write operations account for about twice of read operations in all types of neural networks including CNN ( convolutional neural networks ) , RNN ( recurrent neural networks ) , DNN ( deep neural networks ) , and ANN ( artificial neural networks ) . To see the memory access characteristics in page granularity , we sort memory pages based on their access frequency rank , and observe read / write access counts . From this analysis , we observe that the write frequency is higher than the read frequency if the page rank is less than 10 3 , but from that point the write frequency drops sharply while the read frequency is still high until the rank is around 10 4 . This implies that the distribution of hot memory pages is different according to operation types , so managing hot pages considering reads and writes is challenging in neural network workloads . Note also that such phenomenon is quite different from desktop or smartphone workloads [ 19 , 20 ] . 2 022 I EEE A s i a - P a c i f i c C o n f e r e n c e o n C o m pu t e r S c i e n c e a nd D a t a E n g i n ee r i n g ( C S D E ) | 978 - 1 - 6654 - 5305 - 9 / 22 / $ 31 . 00 © 2022 I EEE | D O I : 1 0 . 1109 / C S D E 56538 . 2022 . 10089326 We further analyze read / write characteristics and observe that the access bias between memory pages is relatively weak in machine learning workloads compared to other applications , specially for write operations . In particular , 20 % of top ranked memory pages account for less than 40 % of total write accesses in neural network workloads , whereas the same top 20 % account for over 80 % in smartphone workloads [ 19 ] . We , then , analyze the memory accesses in terms of temporal locality and access frequency to quantify their effects on the likelihood of future memory re - access . Our analysis shows that temporal locality provides better information than access frequency , in predicting re - access likelihood in read operations , implying that recently read locations are likely to be read again in the near future . However , combining the two properties is necessary for accurate estimation in write operations . From the analysis performed in this paper , we can conclude that efficient memory management for neural network workloads is more challenging than traditional desktop or smartphone workloads due to their peculiar access characteristics . We expect our analysis to be applied in designing efficient memory management policies ( e . g . , page replacement or allocation ) for neural network workloads by configuring hybrid memory architectures and taking into account the asymmetric access characteristics of reads and writes . The remainder of this paper is organized as follows . Section II explains how we collect memory access traces of neural network workloads . In Section III , we describe the analysis results of memory access behaviors in neural network workloads focusing on access bias . Section IV describes how to estimate future memory accesses based on temporal locality and access frequency properties in neural network workloads . Section V summarizes the analysis result of this study and their implications . Finally , we conclude this paper in Section VI . II . M EMORY A CCESS T RACE C OLLECTION To collect memory access traces of neural network workloads , we inject trace extraction codes to Valgrind toolset [ 21 ] . Specifically , we insert trace collection codes in Cachegrind module . Then , to explore a wide spectrum of neural network workloads , we capture memory access traces while executing various machine learning models consisting of ANN , CNN , DNN , and RNN that use Pytorch libraries [ 22 ] . The basic characteristics of these traces are given in Table I . We also list the memory access characteristics of some desktop and smartphone workloads in Table I for comparison purpose [ 19 , 23 ] . As we see from this table , in neural network workloads , the ratio of reads to writes is similar regardless of the neural network types . Specifically , write operations account for about twice of read operations . However , in desktop and smartphone workloads , reads account for a majority of memory accesses in most cases . In case of multimedia player , write is dominant as it needs to decode the data to a playable stream , and stores the decoded data which is usually much larger than the encoded data , to another memory locations [ 23 ] . TABLE I . M EMORY A CCESS C HARACTERISTICS OF N EURAL N ETWORK W ORKLOADS IN C OMPARISON WITH O THER W ORKLOADS . System workload Memory Access Count Memory footprint ( KB ) read write total read : write read write total AI ANN 21468777 42681468 64150245 1 : 1 . 9881 958144 2151564 2452000 CNN 49531466 73800872 123332338 1 : 1 . 4900 2636852 3626932 4149864 DNN 21580887 42516599 64097486 1 : 1 . 9701 958880 2172052 2472036 RNN 28915545 51086382 80001927 1 : 1 . 7667 1412700 2561328 2910300 Desktop Game software 430135 60040 490175 7 . 1641 : 1 9072 2416 10084 Multimedia player 190697 978242 1168939 1 : 5 . 1298 7412 2992 8052 Office software 1600941 132822 1733763 12 . 0533 : 1 13044 3960 14460 PDF viewer 1442595 103540 1546135 13 . 9327 : 1 16916 2704 17388 Photo viewer 265286 345399 610685 1 : 1 . 3020 5900 3924 7428 Smartphone Mobile game 14419370 3782347 18201717 3 . 8123 : 1 76936 45724 76936 Web browser 14378093 3551427 17929520 4 . 0485 : 1 84736 53856 84736 Social network 8920373 1239403 10159776 7 . 1973 : 1 44284 20608 44284 Network game 13122852 2101818 15224670 6 . 2436 : 1 53736 29452 53740 Streaming service 15034275 3162229 18196504 4 . 7543 : 1 68628 40948 68640 ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 1 . Memory access count that occurs on each memory location of the logical address space for neural network workloads . III . A NSLYSIS OF M EMORY A CCESS B IAS IN AI W ORKLOADS In this section , we analyze the characteristics of memory accesses in neural network workloads focusing on access bias . This is important to find the hot working set size of neural network workloads , and also to determine an appropriate memory size for systems executing the workloads . Fig . 1 shows the memory access count that occurs on each memory location of the logical address space for the four neural network configurations that we analyze . In the figure , the red plot represents the read access and the blue plot the write access . As we see from this figure , a certain limited memory locations are responsible for most of memory accesses . ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 2 . Identities of hot memory regions in neural network workloads . To analyze the hot access characteristics of neural network workloads further , we investigate the memory access count for each memory region . Fig . 2 shows which regions account for hot accesses for the four types of neural network workloads . As shown in the figure , most memory accesses in neural network workloads occur on data regions , and the trends are similar irrespective of the types of neural network workloads . The data region accounts for 77 % to 91 % of total memory accesses . The heap region also exhibits large portion of accesses in some types of neural network configurations . Both data and heap regions account for over 90 % of total memory accesses in all types of neural network workloads . Fig . 3 shows the distributions of memory accesses as the page ranks are varied . For efficient management of memory , a certain size of memory locations are grouped , which is called the page . Note that the size of a page in our system is 4KB , which is the typical size used in modern operating systems . In the figure , the x - axis represents the rank of pages sorted by their access count and the y - axis represents the number of accesses on that rank . Note also that we separately plot read and write accesses in these graphs . The curve in the figure shows that memory accesses generated by neural network workloads are concentrated to some hot pages . When comparing read and write operations , the bias is stronger in write operations , and the write count is greater than the read count for hot pages of ranks 1 to 10 3 . However , after the ranks of around 10 3 or more , the write count of pages drops sharply whereas the read count is still high until the rank is around 10 4 . This implies that managing hot pages considering reads and writes is necessary in neural network workloads . Note also that such phenomenon is quite different from other desktop or smartphone workloads [ 19 , 20 ] . ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 3 . Distributions of memory accesses as the page ranks are varied . ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 4 . Cumulative distribution of memory accesses sorted by page ranking . In Fig . 4 , we plot the cumulative distribution of accesses for the fraction of the page ranks . Note that the pages of the x - axis are sorted in descending order by the number of accesses . As shown in the figure , the top 20 % of pages account for 30 - 40 % of write accesses , while the same top 20 % account for 40 - 60 % of read accesses . Note that this access bias is relatively weaker than smartphone or desktop memory accesses specially for write operations . In case of smartphones , the popularity bias is very strong such that the top 10 - 15 % of pages account for about 80 % of total accesses [ 19 ] . IV . E STIMATION OF M EMORY R E - ACCESS To improve memory system performances , it is important to reduce the number of storage I / O operations by accurately estimating the re - access likelihood of pages and maintaining hot pages in memory as much as possible . To do so , we need to find good properties for predicting future memory accesses . Temporal locality and access frequency are two well - known properties used to estimate the re - access likelihood of pages [ 24 , 25 ] . We compare the two properties in terms of memory re - access in neural network workloads and analyze which leads to better estimations . Fig . 5 shows the effect of temporal locality on page accesses for the four neural network configurations . In the figure , the x - axis represents the page rank with respect to the temporal locality ( which is also called the LRU stack distance ) , and the y - axis shows the access count on the page rank given in the x - axis . For example , rank 1 means the page at the most recently accessed position in a chronologically sorted list . Increase in ranks along the x - axis indicates that longer time has passed since the pages have been accessed . The red and blue plots represent read and write accesses , respectively , which separately maintain page ranks based on operation types ( i . e . , read or write ) and count when the corresponding operation occurs . As can be seen from this figure , the shape of the curve decreases monotonically within a certain top ranking , indicating that recently accessed pages are more likely to be accessed again in the near future . When comparing reads and writes , the plots of reads are located above those of writes in the top ranks of 10 0 to 10 3 , implying that the temporal locality of read is stronger than that of write . Similar to temporal locality , the effect of access frequency on memory pages can be characterized by page ranks . To do so , we maintain the ranks of pages based on their access counts and plot the number of accesses that occur again for each rank . In Fig . 6 , the x - axis depicts the rank of pages based on their past read count ( red plot ) and write count ( blue plot ) , and the y - axis represents the number of reads ( red plot ) and writes ( blue plot ) that occurred on the corresponding rank , respectively . To plot this curve , we maintain the ranks of pages , and when a page in a certain rank is accessed again , we accumulate the access count for that rank , which may result in the reordering of the ranks . As we see from the figures , the shape of the blue curve ( i . e . , write operation ) decreases monotonically , which implies that a more frequently accessed page is more likely to be re - accessed . However , the red curve ( i . e . , read operation ) shows rather irregular patterns . That is , a more frequently accessed page shows a smaller fraction of re - accesses in some ranges of ranks . Based on this observation , we can conclude that the frequency property does not well estimate the re - access of memory pages in terms of read operations . Let us now compare the access frequency and the temporal locality properties . Based on the analysis result in Figs . 5 and 6 , the re - access estimation can be more accurately conducted by temporal locality than access frequency in read operations . That is , pages that have been recently read are likely to be read again ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 5 . Memory access distributions based on page ranks of temporal locality . in the near future . In case of write operations , however , the temporal locality plots ( blue plots in Fig . 5 ) are located above the access frequency plots ( blue plots in Fig . 6 ) in the top ranks of 10 0 to 10 1 . However , in the page ranks of middle ranges of 10 1 to 10 3 , the access frequency plots ( blue plots in Fig . 6 ) are located above the temporal locality plots ( blue plots in Fig . 5 ) . To accurately compare the two curves , we extract the write curves from Figs . 5 and 6 and then plot them again in Fig . 7 . As clearly shown in this figure , the two curves intersect roughly at rank 10 1 . This implies that the temporal locality based estimation is more accurate than the frequency based estimation at the highest ranks , but the frequency based estimation provides better information in the middle range . That is , if we need to select a certain limited number of pages for maintaining in memory , choosing the top 10 pages of temporal locality first , and then some high ranked pages of access frequency will lead to the best results . In summary , temporal locality is a better property than access frequency in estimating the re - access likelihood of read operations in neural network workloads , but combining the two properties is needed in write operations . V . S UMMARY AND I MPLICATIONS Our observations from the analysis of memory access behavior in neural network workloads can be summarized as follows .  A limited memory locations account for a majority of memory accesses in neural network workloads . We investigated the identities of these hot memory locations , and found that they consist of data and heap regions , which account for over 90 % of total memory accesses .  Memory accesses of neural network workloads are write - intensive . Specifically , write operations account for about twice of read operations regardless of neural network configurations . This is different from memory accesses of desktop or smartphone workloads , where most of memory accesses are read - intensive .  Though memory accesses of neural network workloads are write - intensive , their access bias is weaker than desktop or smartphone workloads . Specifically , 20 % of top ranked memory pages account for less than 40 % of total write accesses in neural network workloads , whereas the same top 20 % account for over 80 % in smartphone workloads .  In predicting future memory accesses , temporal locality indicates better than access frequency in read operations . However , in case of write operations , combining both temporal locality and access frequency is necessary for accurate estimation of future memory accesses . VI . C ONCLUSIONS We performed comprehensive analysis of memory access behaviors for AI workloads specially focusing on neural networks . To do this , we gathered memory access traces for four popular neural network configurations , i . e . , ANN , CNN , RNN , and DNN , and then performed various analyses on these traces . Specifically , we analyzed the access bias of memory locations and found that over 90 % of memory accesses occurred on data and heap regions . We also observed that the access bias of memory locations is relatively weaker than that of desktop or smartphone workloads . This indicates that efficient memory management for neural network workloads is more challenging . ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 7 . Comparison of the effects of temporal locality ( expressed as LRU ) and access frequency ( expressed as LFU ) on memory write operations . ( a ) ANN ( b ) CNN ( c ) DNN ( d ) RNN Fig . 6 . Memory access distributions based on page ranks of access frequency . For further analysis , we separately investigated memory reads and writes , and observed that writes account for about twice of reads . In predicting future memory accesses , we showed that temporal locality provides better information than access frequency , in predicting re - access likelihood of read operations . However , in case of write operations , combining both temporal locality and access frequency is necessary for accurate estimation of future memory accesses . Through the analysis performed in this paper , we conclude that memory management for neural network workloads is more difficult than traditional desktop or smartphone workloads due to their peculiar access characteristics . We expect our result to be utilized in the design of efficient memory management policies for neural network workloads by configuring appropriate memory architectures . A CKNOWLEDGMENT This work was supported by the National Research Foundation of Korea ( NRF ) grant funded by the Korea government ( MSIP ) ( No . 2019R1A2C1009275 ) and also by the ICT R & D program of MSIT / IITP ( 2020 - 0 - 00121 , development of data improvement and dataset correction technology based on data quality assessment ) . R EFERENCES [ 1 ] S . Idowu , D . Strüber , and T . Berger , “ Asset management in machine learning : state - of - research and state - of - practice , ” ACM Computing Surveys , online published , 2022 . https : / / doi . org / 10 . 1145 / 3543847 [ 2 ] P . Liu , “ Teaching management of music academies based on multi - core processors and machine learning , ” Journal of Ambient Intelligence and Humanized Computing , online published , 2021 . https : / / doi . org / 10 . 1007 / s12652 - 021 - 03207 - 8 [ 3 ] J . Li , N . Mirza , B . Rahat , an d D . Xiong , “Machine learning and credit ratings prediction in the age of fourth industrial revolution , ” Technological Forecasting and Social Change , vol . 161 , 2020 . https : / / doi . org / 10 . 1016 / j . techfore . 2020 . 120309 . [ 4 ] H . Fujiyoshi , T . Hirakawa , and T . Yamashit a , “Deep learning - based image recognition for autonomous driving , ” IATSS Research , vol . 43 , no . 4 , pp . 244 - 252 , 2019 . https : / / doi . org / 10 . 1016 / j . iatssr . 2019 . 11 . 008 . [ 5 ] B . Wu , F . Iandola , P . Jin and K . Keutzer , “SqueezeDet : u nified , small , low power fully convolutional neural networks for real - time object detection for autonomous driving , ” Proc . of IEEE CVPR Workshops , pp . 446 - 454 , 2017 . https : / / doi . org / 10 . 1109 / CVPRW . 2017 . 60 [ 6 ] L . Liu , S . Lu , R . Zhong , B . Wu , Y . Yao et al . , “Computing systems for autonomous driving : state of the art and challenges , ” IEEE Internet of Things Journal , vol . 8 , no . 8 , pp . 6469 – 6486 , 2021 . https : / / doi . org / 10 . 1109 / JIOT . 2020 . 3043716 [ 7 ] J . Xiong , D . Yu , S . Liu , L . Shu , X . Wang , and Z . Liu , “ A review of plant phenotypic image recognition technology based on deep learning , ” Electronics , vol . 10 , no . 1 , article 81 , 2021 . https : / / doi . org / 10 . 3390 / electronics10010081 [ 8 ] P . Tam , S . Math , C . Nam and S . Kim , “Adaptive resource optimized edge federated learning in real - time image sensing classifications , ” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing , vol . 14 , pp . 10929 - 10940 , 2021 . https : / / doi . org / 10 . 1109 / JSTARS . 2021 . 3120724 [ 9 ] M . Pak and S . Kim , “ A review of deep learning in image recognition , ” Proc . of 4th International Conference on Computer Applications and Information Processing Technology ( CAIPT ) , pp . 1 - 3 , 2017 . https : / / doi . org / 10 . 1109 / CAIPT . 2017 . 8320684 . [ 10 ] R . Layer , B . Pedersen , T . DiSera , G . Marth , J . Gertz , and A . Quinlan , “ GIGGLE : a search engine for large - scale integrated genome analysis , ” Nature Methods , vol . 15 , pp . 123 - 126 , 2018 . https : / / doi . org / 10 . 1038 / nmeth . 4556 [ 11 ] S . Dargan , M . Kumar , M . R . Ayyagari , and G . Kumar , “A s urvey of deep learning and its applications : a new paradigm to machine learning , ” Archives of Computational Methods in Engineering , vol . 27 , pp . 1071 - 1092 , 2020 . https : / / doi . org / 10 . 1007 / s11831 - 019 - 09344 - w [ 12 ] I . H . Sarker , M . M . Hoque , M . K . Uddin , and T . Alsanoosy , “M obile data science and intelligent apps : concepts , AI - based modeling and research directions , ” Mobile Networks and Applications , vol . 26 , pp . 285 - 303 , 2021 . https : / / doi . org / 10 . 1007 / s11036 - 020 - 01650 - z [ 13 ] E . Lee and H . Bahn , “ Electricity usage scheduling in smart building environments using smart devices , ” The Scientific World Journal , vol . 2013 , article 468097 , 2013 . https : / / doi . org / 10 . 1155 / 2013 / 468097 [ 14 ] D . Kim , S . Lee , and H . Bahn , “ An adaptive location detection scheme for energy - efficiency of smartphones , ” Pervasive and Mobile Computing , vol . 31 , pp . 67 - 78 , 2016 . https : / / doi . org / 10 . 1016 / j . pmcj . 2016 . 04 . 012 [ 15 ] S . Yoon , H . Park , K . Cho , and H . Bahn “Supporting swap in real - time task scheduling for unified power - saving in CPU and memory , ” IEEE Access , vol . 10 , pp . 3559 - 3570 , 2022 . https : / / doi . org / 0 . 1109 / ACCESS . 2021 . 3140166 [ 16 ] D . T . Nguyen , H . Kim , H . - J . Lee and I . - J . Chang , “ An approximate memory architecture for a reduction of refresh power consumption in deep learning applications , ” Proc . of IEEE International Symposium on Circuits and Systems ( ISCAS ) , pp . 1 - 5 , 2018 . https : / / doi . org / 10 . 1109 / ISCAS . 2018 . 8351021 . [ 17 ] E . Lee , H . Kang , H . Bahn and K . G . Shin , “ Eliminating periodic flush overhead of file I / O with non - volatile buffer cache , ” IEEE Transactions on Computers , vol . 65 , no . 4 , pp . 1145 - 1157 , 2016 . https : / / doi . org / 10 . 1109 / TC . 2014 . 2349525 . [ 18 ] S . Yoo , Y . Jo and H . Bahn , “ Integrated scheduling of real - time and interactive tasks for configurable industrial systems , ” IEEE Transactions on Industrial Informatics , vol . 18 , no . 1 , pp . 631 - 641 , 2022 . https : / / doi . org / 10 . 1109 / TII . 2021 . 3067714 [ 19 ] S . Lee and H . Bahn , “Characterization of Android memory references and implication to hybrid memory management , ” IEEE Access , vol . 9 , pp . 60997 - 61009 , 2021 . https : / / doi . org / 10 . 1109 / ACCESS . 2021 . 3074179 [ 20 ] S . Lee , H . Bahn , and S . Noh , “CLOCK - DWF : a write - history - aware page replacement algorithm for hybrid PCM and DRAM memory architectures , ” IEEE Transactions on Computers , vol . 63 , no . 9 , pp . 2187 - 2200 , 2013 . https : / / doi . org / 10 . 1109 / TC . 2013 . 98 [ 21 ] N . Nethercote and J . Seward , “ Valgrind : a framework for heavyweight dynamic binary instrumentation , ” ACM SIGPLAN Notices , vol . 42 , no . 6 , pp . 89 - 100 , 2007 . https : / / doi . org / 10 . 1145 / 1273442 . 1250746 [ 22 ] PyTorch , https : / / pytorch . org [ 23 ] J . Park , H . Lee , S . Hyun , K . Koh , and H . Bahn , “A cost - aware page replacement algorithm for NAND flash based mobile embedded systems , ” Proc . of the 9th ACM International Conference on Embedded Software ( EMSOFT ) , pp . 315 - 324 , 2009 . https : / / doi . org / 10 . 1145 / 1629335 . 1629377 [ 24 ] H . Bahn , S . Noh , S . Min , and K . Koh , “Using full reference history for efficient document replacement in web caches , ” Proc . of the 2nd USENIX Symposium on Internet Technologies and Systems , pp . 187 - 196 , 1999 . https : / / dl . acm . org / doi / abs / 10 . 5555 / 1251480 . 1251497 [ 25 ] H . Bahn , K . Koh , S . Noh , and S . Lyul , “ Efficient replacement of nonuniform objects in web caches , ” Computer , vol . 35 , no . 6 , pp . 65 - 73 , 2002 . https : / / doi . org / 10 . 1109 / MC . 2002 . 1009170