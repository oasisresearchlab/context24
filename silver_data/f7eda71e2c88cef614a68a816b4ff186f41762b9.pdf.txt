M OJI T ALK : Generating Emotional Responses at Scale Xianda Zhou Dept . of Computer Science and Technology Tsinghua University Beijing , 100084 China zhou - xd13 @ mails . tsinghua . edu . cn William Yang Wang Department of Computer Science University of California , Santa Barbara Santa Barbara , CA 93106 USA william @ cs . ucsb . edu Abstract Generating emotional language is a key step towards building empathetic natural language processing agents . However , a major challenge for this line of research is the lack of large - scale labeled training data , and previous studies are limited to only small sets of human annotated sen - timent labels . Additionally , explicitly con - trolling the emotion and sentiment of gen - erated text is also difﬁcult . In this paper , we take a more radical approach : we ex - ploit the idea of leveraging Twitter data that are naturally labeled with emojis . We collect a large corpus of Twitter con - versations that include emojis in the re - sponse and assume the emojis convey the underlying emotions of the sentence . We investigate several conditional variational autoencoders training on these conversa - tions , which allow us to use emojis to con - trol the emotion of the generated text . Ex - perimentally , we show in our quantitative and qualitative analyses that the proposed models can successfully generate high - quality abstractive conversation responses in accordance with designated emotions . 1 Introduction A critical research problem for artiﬁcial intelli - gence is to design intelligent agents that can per - ceive and generate human emotions . In the past decade , there has been signiﬁcant progress in sen - timent analysis ( Pang et al . , 2002 , 2008 ; Liu , 2012 ) and natural language understanding—e . g . , classifying the sentiment of online reviews . To build empathetic conversational agents , machines must also have the ability to learn to generate emo - tional sentences . Figure 1 : An example Twitter conversation with emoji in the response ( top ) . We collected a large amount of these conversations , and trained a rein - forced conditional variational autoencoder model to automatically generate abstractive emotional re - sponses given any emoji . One of the major challenges is the lack of large - scale , manually labeled emotional text datasets . Due to the cost and complexity of manual anno - tation , most prior research studies primarily focus on small - sized labeled datasets ( Pang et al . , 2002 ; Maas et al . , 2011 ; Socher et al . , 2013 ) , which are not ideal for training deep learning models with a large number of parameters . In recent years , a handful of medium to large scale , emotional corpora in the area of emotion analysis ( Go et al . , 2016 ) and dialog ( Li et al . , 2017b ) are proposed . However , all of them are limited to a traditional , small set of labels , for ex - ample , “happiness , ” “sadness , ” “anger , ” etc . or simply binary “positive” and “negative . ” Such coarse - grained classiﬁcation labels make it difﬁ - cult to capture the nuances of human emotion . To avoid the cost of human annotation , we propose the use of naturally - occurring emoji - rich Twitter data . We construct a dataset using Twit - ter conversations with emojis in the response . The ﬁne - grained emojis chosen by the users in the re - sponse can be seen as the natural label for the emo - tion of the response . We assume that the emotions and nuances of emojis are established through the extensive us - age by Twitter users . If we can create agents that a r X i v : 1711 . 04090v2 [ c s . C L ] 12 M a y 2018 are able to imitate Twitter users’ language style when using those emojis , we claim that , to some extent , we have captured those emotions . Using a large collection of Twitter conversations , we then trained a conditional generative model to automat - ically generate the emotional responses . Figure 1 shows an example . To generate emotional responses in dialogs , an - other technical challenge is to control the tar - get emotion labels . In contrast to existing work ( Huang et al . , 2017 ) that uses information retrieval to generate emotional responses , the re - search question we are pursuing in this paper , is to design novel techniques that can generate ab - stractive responses of any given arbitrary emo - tions , without having human annotators to label a huge amount of training data . To control the target emotion of the response , we investigate several encoder - decoder genera - tion models , including a standard attention - based SEQ 2 SEQ model as the base model , and a more so - phisticated CVAE model ( Kingma and Welling , 2013 ; Sohn et al . , 2015 ) , as VAE is recently found convenient in dialog generation ( Zhao et al . , 2017 ) . To explicitly improve emotion expression , we then experiment with several extensions to the CVAE model , including a hybrid objective with policy gradient . The performance in emotion ex - pression is automatically evaluated by a separate sentence - to - emoji classiﬁer ( Felbo et al . , 2017 ) . Additionally , we conducted a human evaluation to assess the quality of the generated emotional text . Results suggest that our method is capable of generating state - of - the - art emotional text at scale . Our main contributions are three - fold : • We provide a publicly available , large - scale dataset of Twitter conversation - pairs natu - rally labeled with ﬁne - grained emojis . • We are the ﬁrst to use naturally labeled emo - jis for conducting large - scale emotional re - sponse generation for dialog . • We apply several state - of - the - art generative models to train an emotional response gener - ation system , and analysis conﬁrms that our models deliver strong performance . In the next section , we outline related work on sentiment analysis and emoji on Twitter data , as well as neural generative models . Then , we will introduce our new emotional research dataset and formalize the task . Next , we will describe the neu - ral models we applied for the task . Finally , we will show automatic evaluation and human evalua - tion results , and some generated examples . Exper - iment details can be found in supplementary ma - terials . 2 Related Work In natural language processing , sentiment anal - ysis ( Pang et al . , 2002 ) is an area that in - volves designing algorithms for understanding emotional text . Our work is aligned with some recent studies on using emoji - rich Twit - ter data for sentiment classiﬁcation . Eisner et al . ( 2016 ) proposes a method for training emoji embedding EMOJI 2 VEC , and combined with word2vec ( Mikolov et al . , 2013 ) , they apply the embeddings for sentiment classiﬁcation . Deep - Moji ( Felbo et al . , 2017 ) is closely related to our study : It makes use of a large , naturally la - beled Twitter emoji dataset , and train an atten - tive bi - directional long short - term memory net - work ( Hochreiter and Schmidhuber , 1997 ) model for sentiment analysis . Instead of building a sen - timent classiﬁer , our work focuses on generating emotional responses , given the context and the tar - get emoji . Our work is also in line with the recent progress of the application of Variational Autoencoder ( VAE ) ( Kingma and Welling , 2013 ) in dialog gen - eration . VAE ( Kingma and Welling , 2013 ) en - codes data in a probability distribution , and then samples from the distribution to generate exam - ples . However , the original frameworks do not support end - to - end generation . Conditional VAE ( CVAE ) ( Sohn et al . , 2015 ; Larsen et al . , 2015 ) was proposed to incorporate conditioning option in the generative process . Recent research in di - alog generation shows that language generated by VAE models enjoy signiﬁcantly greater di - versity than traditional SEQ 2 SEQ models ( Zhao et al . , 2017 ) , which is a preferable property toward building a true - to - life dialog agents . In dialog research , our work aligns with recent advances in sequence - to - sequence mod - els ( Sutskever et al . , 2014 ) using long short - term memory networks ( Hochreiter and Schmid - huber , 1997 ) . A slightly altered version of this model serves as our base model . Our modiﬁca - tion enabled it to condition on single emojis . Li 184 , 500 9 , 505 5 , 558 2 , 771 38 , 479 9 , 455 5 , 114 2 , 532 30 , 447 9 , 298 5 , 026 2 , 332 25 , 018 8 , 385 4 , 738 2 , 293 19 , 832 8 , 341 4 , 623 1 , 698 16 , 934 8 , 293 4 , 531 1 , 534 17 , 009 8 , 144 4 , 287 1 , 403 15 , 563 7 , 101 4 , 205 1 , 258 15 , 046 6 , 939 4 , 066 1 , 091 14 , 121 6 , 769 3 , 973 698 13 , 887 6 , 625 3 , 841 627 13 , 741 6 , 558 3 , 863 423 13 , 147 6 , 374 3 , 236 250 10 , 927 6 , 031 3 , 072 243 10 , 104 5 , 849 3 , 088 154 9 , 546 5 , 624 2 , 969 130 Table 1 : All 64 emoji labels , and number of con - versations labeled by each emoji . et al . ( 2016 ) use a reinforcement learning algo - rithm to improve the vanilla sequence - to - sequence model for non - task - oriented dialog systems , but their reinforced and its follow - up adversarial mod - els ( Li et al . , 2017a ) also do not model emotions or conditional labels . Zhao et al . ( 2017 ) recently introduced conditional VAE for dialog modeling , but neither did they model emotions in the con - versations , nor explore reinforcement learning to improve results . Given a dialog history , Xie et . al . ’s work recommends suitable emojis for current conversation . Xie et . al . ( 2016 ) compress the dia - log history to vector representation through a hi - erarchical RNN and then map it to a emoji by a classiﬁer , while in our model , the representation for original tweet , combined with the emoji em - bedding , is used to generate a response . 3 Dataset We start by describing our dataset and approaches to collecting and processing the data . Social me - dia is a natural source of conversations , and people use emojis extensively within their posts . How - ever , not all emojis are used to express emotion and frequency of emojis are unevenly distributed . Inspired by DeepMoji ( Felbo et al . , 2017 ) , we use 64 common emojis as labels ( see Table 1 ) , and col - lect a large corpus of Twitter conversations con - Before : @ amy miss you soooo much ! ! ! After : miss you soo much ! Label : Figure 2 : An artiﬁcial example illustrating prepro - cess procedure and choice of emoji label . Note that emoji occurrences in responses are counted before the deduplication process . taining those emojis . Note that emojis with the dif - ference only in skin tone are considered the same emoji . 3 . 1 Data Collection We crawled conversation pairs consisting of an original post and a response on Twitter from 12th to 14th of August , 2017 . The response to a con - versation must include at least one of the 64 emoji labels . Due to the limit of Twitter streaming API , tweets are ﬁltered on the basis of words . In our case , a tweet can be reached only if at least one of the 64 emojis is used as a word , meaning it has to be a single character separated by blank space . However , this kind of tweets is arguably cleaner , as it is often the case that this emoji is used to wrap up the whole post and clusters of repeated emojis are less likely to appear in such tweets . For both original tweets and responses , only En - glish tweets without multimedia contents ( such as URL , image or video ) are allowed , since we as - sume that those contents are as important as the text itself for the machine to understand the con - versation . If a tweet contains less than three alpha - betical words , the conversation is not included in the dataset . 3 . 2 Emoji Labeling Then we label responses with emojis . If there are multiple types of emoji in a response , we use the emoji with most occurrences inside the response . Among those emojis with same occurrences , we choose the least frequent one across the whole cor - pus , on the hypothesis that less frequent tokens better represent what the user wants to express . See Figure 2 for example . 3 . 3 Data Preprocessing During preprocessing , all mentions and hashtags are removed , and punctuation 1 and emojis are sep - arated if they are adjacent to words . Words with digits are all treated as the same special token . In some cases , users use emojis and symbols in a cluster to express emotion extensively . To normalize the data , words with more than two re - peated letters , symbol strings of more than one re - peated punctuation symbols or emojis are short - ened , for example , ‘ ! ! ! ! ’ is shortened to ‘ ! ’ , and ‘yessss’ to ‘yess’ . Note that we do not reduce du - plicate letters completely and convert the word to the ‘correct’ spelling ( ‘yes’ in the example ) since the length of repeated letters represents the inten - sity of emotion . By distinguishing ‘yess’ from ‘yes’ , the emotional intensity is partially preserved in our dataset . Then all symbols , emojis , and words are tok - enized . Finally , we build a vocabulary of size 20K according to token frequency . Any tokens outside the vocabulary are replaced by the same special token . We randomly split the corpus into 596 , 959 / 32 , 600 / 32 , 600 conversation pairs for train / vali - dation / test set 2 . Distribution of emoji labels within the corpus is presented in Table 1 . 4 Generative Models In this work , our goal is to generate emotional re - sponses to tweets with the emotion speciﬁed by an emoji label . We assembled several generative models and trained them on our dataset . 4 . 1 Base : Attention - Based Sequence - to - Sequence Model Traditional studies use deep recurrent architecture and encoder - decoder models to generate conver - sation responses , mapping original texts to target responses . Here we use a sequence - to - sequence ( SEQ 2 SEQ ) model ( Sutskever et al . , 2014 ) with global attention mechanism ( Luong et al . , 2015 ) as our base model ( See Figure 3 ) . We use randomly initialized embedding vectors to represent each word . To speciﬁcally model the 1 Emoticons ( e . g . ‘ : ) ’ , ‘ ( - : ’ ) are made of mostly punctua - tion marks . They are not examined in this paper . Common emoticons are treated as words during preprocessing . 2 We will release the dataset with all tweets in its original form before preprocessing . To comply with Twitter’s policy , we will include the tweet IDs in our release , and provide a script for downloading the tweets using the ofﬁcial API . No information of the tweet posters is collected . Figure 3 : From bottom to top is a forward pass of data during training . Left : the base model encodes the original tweets in v o , and generates responses by decoding from the concatenation of v o and the embedded emoji , v e . Right : In the CVAE model , all additional components ( outlined in gray ) can be added incrementally to the base model . A separate encoder encodes the responses in x . Recognition network inputs x and produces the latent variable z by reparameterization trick . During training , The latent variable z is concatenated with v o and v e and fed to the decoder . emotion , we compute the embedding vector of the emoji label the same way as word embeddings . The emoji embedding is further reduced to smaller size vector v e through a dense layer . We pass the embeddings of original tweets through a bidirec - tional RNN encoder of GRU cells ( Schuster and Paliwal , 1997 ; Chung et al . , 2014 ) . The encoder outputs a vector v o that represents the original tweet . Then v o and v e are concatenated and fed to a 1 - layer RNN decoder of GRU cells . A response is then generated from the decoder . 4 . 2 Conditional Variational Autoencoder ( CVAE ) Having similar encoder - decoder structures , SEQ 2 SEQ can be easily extended to a Conditional Variational Autoencoder ( CVAE ) ( Sohn et al . , 2015 ) . Figure 3 illustrates the model : response encoder , recognition network , and prior network are added on top of the SEQ 2 SEQ model . Re - sponse encoder has the same structure to original tweet encoder , but it has separate parameters . We use embeddings to represent Twitter responses and pass them through response encoder . Mathematically , CVAE is trained by maximiz - ing a variational lower bound on the conditional likelihood of x given c , according to : p ( x | c ) = (cid:90) p ( x | z , c ) p ( z | c ) dz ( 1 ) z , c and x are random variables . z is the la - tent variable . In our case , the condition c = [ v o ; v e ] , target x represents the response . De - coder is used to approximate p ( x | z , c ) , denoted as p D ( x | z , c ) . Prior network is introduced to ap - proximate p ( z | c ) , denoted as p P ( z | c ) . Recogni - tion network q R ( z | x , c ) is introduced to approx - imate true posterior p ( z | x , c ) and will be absent during generation phase . By assuming that the la - tent variable has a multivariate Gaussian distribu - tion with a diagonal covariance matrix , the lower bound to log p ( x | c ) can then be written by : −L ( θ D , θ P , θ R ; x , c ) = KL ( q R ( z | x , c ) | | p P ( z | c ) ) − E q R ( z | x , c ) ( log p D ( x | z , c ) ) ( 2 ) θ D , θ P , θ R are parameters of those networks . In recognition / prior network , we ﬁrst pass the variables through an MLP to get the mean and log variance of z ’s distribution . Then we run a repa - rameterization trick ( Kingma and Welling , 2013 ) to sample latent variables . During training , z by the recognition network is passed to the decoder and trained to approximate z (cid:48) by the prior network . While during testing , the target response is absent , and z (cid:48) by the prior network is passed to the de - coder . Our CVAE inherits the same attention mecha - nism from the base model connecting the original tweet encoder to the decoder , which makes our model deviate from previous works of CVAE on text data . Based on the attention memory as well as c and z , a response is ﬁnally generated from the decoder . When handling text data , the VAE models that apply recurrent neural networks as the structure of their encoders / decoders may ﬁrst learn to ig - nore the latent variable , and explain the data with the more easily optimized decoder . The latent variables lose its functionality , and the VAE de - teriorates to a plain SEQ 2 SEQ model mathemati - cally ( Bowman et al . , 2015 ) . Some previous meth - ods effectively alleviate this problem . Such meth - ods are also important to keep a balance between the two items of the loss , namely KL loss and re - construction loss . We use techniques of KL an - nealing , early stopping ( Bowman et al . , 2015 ) and bag - of - word loss ( Zhao et al . , 2017 ) in our models . The general loss with bag - of - word loss ( see sup - plementary materials for details ) is rewritten as : L (cid:48) = L + L bow ( 3 ) 4 . 3 Reinforced CVAE In order to further control the emotion of our gen - eration more explicitly , we combine policy gradi - ent techniques on top of the CVAE above and pro - posed Reinforced CVAE model for our task . We ﬁrst train an emoji classiﬁer on our dataset sepa - rately and ﬁx its parameters thereafter . The classi - ﬁer is used to produce reward for the policy train - ing . It is a skip connected model of Bidirectional GRU - RNN layers ( Felbo et al . , 2017 ) . During the policy training , we ﬁrst get the gen - erated response x (cid:48) by passing x and c through the CVAE , then feeding generation x (cid:48) to classiﬁer and get the probability of the emoji label as reward R . Let θ be parameters of our network , REINFORCE algorithm ( Williams , 1992 ) is used to maximize the expected reward of generated responses : J ( θ ) = E p ( x | c ) ( R θ ( x , c ) ) ( 4 ) The gradient of Equation 4 is approximated using the likelihood ratio trick ( Glynn , 1990 ; Williams , 1992 ) : ∇J ( θ ) = ( R − r ) ∇ | x | (cid:88) t log p ( x t | c , x 1 : t − 1 ) ( 5 ) r is the baseline value to keep estimate unbiased and reduce its variance . In our case , we directly pass x through emoji classiﬁer and compute the probability of the emoji label as r . The model then encourages response generation that has R > r . As REINFORCE objective is unrelated to re - sponse generation , it may make the generation model quickly deteriorate to some generic re - sponses . To stabilize the training process , we pro - pose two straightforward techniques to constrain the policy training : 1 . Adjust rewards according to the position of the emoji label when all labels are ranked from high to low in order of the probabil - ity given by the emoji classiﬁer . When the probability of the emoji label is of high rank among all possible emojis , we assume that the model has succeeded in emotion expres - sion , thus there is no need to adjust param - eters toward higher probability in this re - sponse . Modiﬁed policy gradient is written as : ∇J (cid:48) ( θ ) = α ( R − r ) ∇ | x | (cid:88) t log p ( x t | c , x 1 : t − 1 ) ( 6 ) where α ∈ [ 0 , 1 ] is a variant coefﬁcient . The higher R ranks in all types of emoji label , the closer α is to 0 . 2 . Train Reinforced CVAE by a hybrid objective of REINFORCE and variational lower bound objective , learning towards both emotion ac - curacy and response appropriateness : min θ L (cid:48)(cid:48) = L (cid:48) − λ J (cid:48) ( 7 ) λ is a balancing coefﬁcient , which is set to 1 in our experiments . The algorithm outlining the training process of Reinforced CVAE can be found in the supplemen - tary materials . 5 Experimental Results and Analyses We conducted several experiments to ﬁnalize the hyper - parameters of our models ( Table 2 ) . During training , fully converged base SEQ 2 SEQ model is used to initialize its counterparts in CVAE models . Pretraining is vital to the success of our models since it is essentially hard for them to learn a latent variable space from total randomness . For more details , please refer to the supplementary materi - als . In this section , we ﬁrst report and analyze the general results of our models , including perplex - ity , loss and emotion accuracy . Then we take a closer look at the generation quality as well as our models’ capability of expressing emotion . 5 . 1 General To generally evaluate the performance of our mod - els , we use generation perplexity and top - 1 / top - 5 Emoji Accuracy Model Perplexity Top1 Top5 Development Base 127 . 0 34 . 2 % 57 . 6 % CVAE 37 . 1 40 . 7 % 75 . 3 % Reinforced CVAE 38 . 1 42 . 2 % 76 . 9 % Test Base 130 . 6 33 . 9 % 58 . 1 % CVAE 36 . 9 41 . 4 % 75 . 1 % Reinforced CVAE 38 . 3 42 . 1 % 77 . 3 % Table 2 : Generation perplexity and emoji accuracy of the three models . emoji accuracy on the test set . Perplexity indicates how much difﬁculty the model is having when generating responses . We also use top - 5 emoji ac - curacy , since the meaning of different emojis may overlap with only a subtle difference . The ma - chine may learn that similarity and give multiple possible labels as the answer . Note that we use the same emoji classiﬁer for evaluation . Its accuracy ( see supplementary ma - terials ) may not seem perfect , but it is the state - of - the - art emoji classiﬁer given so many classes . Also , it’s reasonable to use the same classiﬁer in training for automated evaluation , as is in ( Hu et al . , 2017 ) . We can obtain meaningful results as long as the classiﬁer is able to capture the se - mantic relationship between emojis ( Felbo et al . , 2017 ) . As is shown in Table 2 , CVAE signiﬁcantly re - duces the perplexity and increases the emoji ac - curacy over base model . Reinforced CVAE also adds to the emoji accuracy at the cost of a slight increase in perplexity . These results conﬁrm that proposed methods are effective toward the gener - ation of emotional responses . When converged , the KL loss is 27 . 0 / 25 . 5 for the CVAE / Reinforced CVAE respectively , and re - construction loss 42 . 2 / 40 . 0 . The models achieved a balance between the two items of loss , conﬁrm - ing that they have successfully learned a meaning - ful latent variable . 5 . 2 Generation Diversity S EQ 2 SEQ generates in a monotonous way , as several generic responses occur repeatedly , while the generation of CVAE models is of much more diversity . To showcase this disparity , we calculated the type - token ratios of uni - grams / bigrams / trigrams in generated responses as Figure 4 : Top5 emoji accuracy of the ﬁrst 32 emoji labels . Each bar represents an emoji and its length represents how many of all responses to the origi - nal tweets are top5 accurate . Different colors rep - resent different models . Emojis are numbered in the order of frequencies in the dataset . No . 0 is , for instance , No . 1 and so on . Top : CVAE v . Base . Bottom : Reinforced CVAE v . CVAE . If Rein - forced CVAE scores higher , the margin is marked in orange . If lower , in black . the diversity score . As shown in Table 3 , results show that CVAE models beat the base models by a large margin . Diversity scores of Reinforced CVAE are reason - ably compromised since it’s generating more emo - tional responses . 5 . 3 Controllability of Emotions There are potentially multiple types of emotion in reaction to an utterance . Our work makes it possi - ble to generate a response to an arbitrary emotion by conditioning the generation on a speciﬁc type of emoji . In this section , we generate one response in reply to each original tweet in the dataset and condition on each emoji of the selected 64 emo - Model Unigram Bi - Tri - Base 0 . 0061 0 . 0199 0 . 0362 CVAE 0 . 0191 0 . 131 0 . 365 Reinforced CVAE 0 . 0160 0 . 118 0 . 337 Target responses 0 . 0353 0 . 370 0 . 757 Table 3 : Type - token ratios of the generation by the three models . Scores of tokenized human - generated target responses are given for reference . Setting Model v . Base Win Lose Tie reply CVAE 42 . 4 % 43 . 0 % 14 . 6 % reply Reinforced CVAE 40 . 6 % 39 . 6 % 19 . 8 % emoji CVAE 48 . 4 % 26 . 2 % 25 . 4 % emoji Reinforced CVAE 50 . 0 % 19 . 6 % 30 . 4 % Table 4 : Results of human evaluation . Tests are conducted pairwise between CVAE models and the base model . jis . We may have recorded some original tweets with different replies in the dataset , but an original tweet only need to be used once for each emoji , so we eliminate duplicate original tweets in the dataset . There are 30 , 299 unique original tweets in the test set . Figure 4 shows the top - 5 accuracy of each type of the ﬁrst 32 emoji labels when the models gen - erates responses from the test set conditioning on the same emoji . The results show that CVAE mod - els increase the accuracy over every type of emoji label . Reinforced CVAE model sees a bigger in - crease on the less common emojis , conﬁrming the effect of the emoji - speciﬁed policy training . 5 . 4 Human Evaluation We employed crowdsourced judges to evaluate a random sample of 100 items ( Table 4 ) , each be - ing assigned to 5 judges on the Amazon Mechan - ical Turk . We present judges original tweets and generated responses . In the ﬁrst setting of human evaluation , judges are asked to decide which one of the two generated responses better reply the original tweet . In the second setting , the emoji label is presented with the item discription , and judges are asked to pick one of the two generated responses that they decide better ﬁts this emoji . ( These two settings of evaluation are conducted separately so that it will not affect judges’ ver - dicts . ) Order of two generated responses under one item is permuted . Ties are permitted for an - Content sorry guys , was gunna stream tonight but i ’m still feeling like crap and my voice disappeared . i will make it up to you Target Emotion Base i ’m sorry you ’re going to be missed it i ’m sorry for your loss i ’m sorry you ’re going to be able to get it CVAE hope you are okay hun ! hi jason , i ’ll be praying for you im sorry u better suck u off ReinforcedCVAE hope you ’re feeling it hope you had a speedy recovery man ! hope you feel better soon , please get well soon dude i ’m so sorry for that i wanna hear it and i ’m sorry i can ’t go to canada with you but i wanna be away from canada Content add me in there my bro Target Emotion Base i ’m not sure you ’ll be there i ’m here for you i ’m not ready for you CVAE you know , you need to tell me in your hometown ! you will be ﬁne bro , i ’ll be in the gym for you i can ’t wait ReinforcedCVAE you might have to get me hip hop off . good luck bro ! this is about to be healthy i ’m still undecided and i ’m still waiting Content don ’t tell me match of the day is delayed because of this shit Target Emotion Base i ’m not even a fan of the game i ’m not sure if you ever have any chance to talk to someone else i ’m sorry i ’m not doubting you CVAE you can ’t do it bc you ’re in my mentions see now a good point hiya , unfortunately , it ’s not ReinforcedCVAE oh my god i ’m saying this as long as i remember my twitter fab mate , you ’ll enjoy the game and you ’ll get a win it ’s the worst Content g i needed that laugh lmfaoo Target Emotion Base i ’m glad you enjoyed it i ’m not gonna lie i ’m sorry i ’m not laughing CVAE good ! have a good time i don ’t plan on that me too . but it ’s a lot of me . ReinforcedCVAE thank you for your tweet , you didn ’t know how much i guess that ’s a bad idea , u gotta hit me up on my phone i feel bad at this and i hope you can make a joke Table 5 : Some examples from our generated emotional responses . Context is the original tweet , and target emotion is speciﬁed by the emoji . Following are the responses generated by each of the three models based on the context and the target emotion . swers . We batch ﬁve items as one assignment and insert an item with two identical outputs as the sanity check . Anyone who failed to choose “tie” for that item is considered as a careless judge and is therefore rejected from our test . We then conducted a simpliﬁed Turing test . Each item we present judges an original tweet , its reply by a human , and its response generated from Reinforced CVAE model . We ask judges to de - cide which of the two given responses is written by a human . Other parts of the setting are similar to above - mentioned tests . It turned out 18 % of the test subjects mistakenly chose machine - generated responses as human written , and 27 % stated that they were not able to distinguish between the two responses . In regard of the inter - rater agreement , there are four cases . The ideal situation is that all ﬁve judges choose the same answer for a item , and in the worst - case scenario , at most two judges choose the same answer . In light of this , we have counted that 32 % / 33 % / 31 % / 5 % of all items have 5 / 4 / 3 / 2 judges in agreement , showing that our experiment has a reasonably reliable inter - rater agreement . 5 . 5 Case Study We sampled some generated responses from all three models , and list them in Figure 5 . Given an original tweet , we would like to generate re - sponses with three different target emotions . S EQ 2 SEQ only chooses to generate most fre - quent expressions , forming a predictable pattern for its generation ( See how every sampled re - sponse by the base model starts with “I’m” ) . On the contrary , generation from the CVAE model is diverse , which is in line with previous quantita - tive analysis . However , the generated responses are sometimes too diversiﬁed and unlikely to re - ply to the original tweet . Reinforced CVAE somtetimes tends to gener - ate a lengthy response by stacking up sentences ( See the responses to the ﬁrst tweet when condi - tioning on the ‘folded hands’ emoji and the ‘sad face’ emoji ) . It learns to break the length limit of sequence generation during hybrid training , since the variational lower bound objective is competing with REINFORCE objective . The situation would be more serious is λ in Equation 7 is set higher . However , this phenomenon does not impair the ﬂuency of generated sentences , as can be seen in Figure 5 . 6 Conclusion and Future Work In this paper , we investigate the possibility of using naturally annotated emoji - rich Twitter data for emotional response generation . More speciﬁ - cally , we collected more than half a million Twit - ter conversations with emoji in the response and assumed that the ﬁne - grained emoji label chosen by the user expresses the emotion of the tweet . We applied several state - of - the - art neural models to learn a generation system that is capable of giv - ing a response with an arbitrarily designated emo - tion . We performed automatic and human evalu - ations to understand the quality of generated re - sponses . We trained a large scale emoji classiﬁer and ran the classiﬁer on the generated responses to evaluate the emotion accuracy of the generated response . We performed an Amazon Mechanical Turk experiment , by which we compared our mod - els with a baseline sequence - to - sequence model on metrics of relevance and emotion . Experimen - tally , it is shown that our model is capable of gen - erating high - quality emotional responses , without the need of laborious human annotations . Our work is a crucial step towards building intelli - gent dialog agents . We are also looking forward to transferring the idea of naturally - labeled emo - jis to task - oriented dialog and multi - turn dialog generation problems . Due to the nature of social media text , some emotions , such as fear and dis - gust , are underrepresented in the dataset , and the distribution of emojis is unbalanced to some ex - tent . We will keep accumulating data and increase the ratio of underrepresented emojis , and advance toward more sophisticated abstractive generation methods . References Samuel R . Bowman , Luke Vilnis , Oriol Vinyals , An - drew M . Dai , Rafal J´ozefowicz , and Samy Ben - gio . 2015 . Generating sentences from a continuous space . CONLL . Junyoung Chung , C¸aglar G¨ulc¸ehre , KyungHyun Cho , and Yoshua Bengio . 2014 . Empirical evaluation of gated recurrent neural networks on sequence model - ing . NIPS 2014 Deep Learning and Representation Learning Workshop . Ben Eisner , Tim Rockt ¨ aschel , Isabelle Augenstein , Matko Bo ˇ snjak , and Sebastian Riedel . 2016 . emoji2vec : Learning emoji representations from their description . SocialNLP at EMNLP . Bjarke Felbo , Alan Mislove , Anders Søgaard , Iyad Rahwan , and Sune Lehmann . 2017 . Using millions of emoji occurrences to learn any - domain represen - tations for detecting sentiment , emotion and sar - casm . EMNLP . Xavier Glorot and Yoshua Bengio . 2010 . Understand - ing the difﬁculty of training deep feedforward neural networks . In International Conference on Artiﬁcial Intelligence and Statistics , pages 249 – 256 . Peter W Glynn . 1990 . Likelihood ratio gradient esti - mation for stochastic systems . Communications of the ACM , 33 ( 10 ) : 75 – 84 . Alec Go , Richa Bhayani , and Lei Huang . 2016 . Sen - timent140 . http : / / help . sentiment140 . com / . Sepp Hochreiter and J ¨ urgen Schmidhuber . 1997 . Long short - term memory . Neural computation , 9 ( 8 ) : 1735 – 1780 . Zhiting Hu , Zichao Yang , Xiaodan Liang , Ruslan Salakhutdinov , and Eric P Xing . 2017 . Toward con - trolled generation of text . In International Confer - ence on Machine Learning , pages 1587 – 1596 . Chieh - Yang Huang , Tristan Labetoulle , Ting - Hao Ken - neth Huang , Yi - Pei Chen , Hung - Chen Chen , Vallari Srivastava , and Lun - Wei Ku . 2017 . Moodswipe : A soft keyboard that suggests messages based on user - speciﬁed emotions . EMNLP Demo . Diederik P Kingma and Max Welling . 2013 . Auto - encoding variational bayes . ICLR . Anders Boesen Lindbo Larsen , Søren Kaae Sønderby , Hugo Larochelle , and Ole Winther . 2015 . Autoen - coding beyond pixels using a learned similarity met - ric . ICML . Jiwei Li , Will Monroe , Alan Ritter , and Dan Juraf - sky . 2016 . Deep reinforcement learning for dialogue generation . EMNLP . Jiwei Li , Will Monroe , Tianlin Shi , Alan Ritter , and Dan Jurafsky . 2017a . Adversarial learning for neu - ral dialogue generation . EMNLP . Yanran Li , Hui Su , Xiaoyu Shen , Wenjie Li , Ziqiang Cao , and Shuzi Niu . 2017b . Dailydialog : A manu - ally labelled multi - turn dialogue dataset . IJCNLP . Bing Liu . 2012 . Sentiment analysis and opinion min - ing . Synthesis lectures on human language tech - nologies , 5 ( 1 ) : 1 – 167 . Minh - Thang Luong , Hieu Pham , and Christopher D Manning . 2015 . Effective approaches to attention - based neural machine translation . EMNLP . Andrew L Maas , Raymond E Daly , Peter T Pham , Dan Huang , Andrew Y Ng , and Christopher Potts . 2011 . Learning word vectors for sentiment analysis . In Proceedings of the 49th Annual Meeting of the Asso - ciation for Computational Linguistics : Human Lan - guage Technologies - Volume 1 , pages 142 – 150 . As - sociation for Computational Linguistics . Tomas Mikolov , Kai Chen , Greg Corrado , and Jeffrey Dean . 2013 . Efﬁcient estimation of word represen - tations in vector space . ICLR . Bo Pang , Lillian Lee , and Shivakumar Vaithyanathan . 2002 . Thumbs up ? : sentiment classiﬁcation using machine learning techniques . In Proceedings of the ACL - 02 conference on Empirical methods in natural language processing - Volume 10 , pages 79 – 86 . As - sociation for Computational Linguistics . Bo Pang , Lillian Lee , et al . 2008 . Opinion mining and sentiment analysis . Foundations and Trends R (cid:13) in In - formation Retrieval , 2 ( 1 – 2 ) : 1 – 135 . Mike Schuster and Kuldip K Paliwal . 1997 . Bidirec - tional recurrent neural networks . IEEE Transactions on Signal Processing , 45 ( 11 ) : 2673 – 2681 . Richard Socher , Alex Perelygin , Jean Wu , Jason Chuang , Christopher D Manning , Andrew Ng , and Christopher Potts . 2013 . Recursive deep models for semantic compositionality over a sentiment tree - bank . In Proceedings of the 2013 conference on empirical methods in natural language processing , pages 1631 – 1642 . Kihyuk Sohn , Honglak Lee , and Xinchen Yan . 2015 . Learning structured output representation using deep conditional generative models . In Advances in Neural Information Processing Systems , pages 3483 – 3491 . Ilya Sutskever , Oriol Vinyals , and Quoc V Le . 2014 . Sequence to sequence learning with neural net - works . In Advances in neural information process - ing systems , pages 3104 – 3112 . Ronald J Williams . 1992 . Simple statistical gradient - following algorithms for connectionist reinforce - ment learning . Machine learning , 8 ( 3 - 4 ) : 229 – 256 . Ruobing Xie , Zhiyuan Liu , Rui Yan , and Maosong Sun . 2016 . Neural emoji recommendation in dialogue systems . arXiv preprint arXiv : 1612 . 04609 . Tiancheng Zhao , Ran Zhao , and Maxine Eskenazi . 2017 . Learning discourse - level diversity for neural dialog models using conditional variational autoen - coders . ACL . A Supplementary Materials A . 1 Bag - of - Word Loss In the idea of BoW loss , x can be decomposed into x o of word order and x bow of words without order . By assuming that x o and x bow are conditionally independent , p ( x | z , c ) = p ( x o | z , c ) p ( x bow | z , c ) . Given z and c , p ( x bow | z , c ) is the product over probability of every token in the text : p ( x bow | z , c ) = | x | (cid:89) t = 1 p ( x t | z , c ) = | x | (cid:89) t = 1 softmax ( f ( x t , z , c ) ) ( 8 ) Function f ﬁrst maps z , c to space R V , where V is the vocabulary size , and then chose the element corresponding to token x t as its logit . Now the modiﬁed objective is written by : L (cid:48) ( θ D , θ P , θ R ; x , c ) = L ( θ D , θ P , θ R ; x , c ) + E q R ( z | x , c ) ( log p ( x bow | z , c ) ) ( 9 ) Finally , CVAE is trained by minimizing L (cid:48) . A . 2 Emoji Classiﬁer The emoji classiﬁer is a skip connected model of Bidirectional GRU - RNN layers and has the same structure as the classiﬁer in ( Felbo et al . , 2017 ) . This separate neural network uses the same set of hyper - parameters ( embedding size , hidden state size , etc . ) as in the generation models described below . We train it on our train set by mapping re - sponse Tweets to their emoji label , with a dropout rate of 0 . 2 and an Adam optimizer of a 1e - 3 learn - ing rate with gradient clipped to 5 . RNN lay - ers and word embeddings in the classiﬁer have a Figure 5 : Top - 1 and top - 5 accuracy of emoji classiﬁer by each emoji label on test set . dimension of 128 . All weights of dense layers are initialized by Glorot uniform initializer ( Glo - rot and Bengio , 2010 ) and word embeddings are initialized by sampling from the uniform distribu - tion [ - 4e - 3 , 4e - 3 ] . The classiﬁer gives the probability of all 64 emoji labels . For 32 . 1 % responses in the test set , the probability of the emoji label ranks highest of all emoji labels . In 57 . 8 % of cases , the probability of emoji label is among the ﬁve highest . We re - fer to the two ﬁgures as top - 1 and top - 5 accuracy . Figure 5 shows the top - 1 and top - 5 accuracy of the 32 most frequent emoji labels . Accuracy for less common emojis may be low since they are under - represented in the dataset . A . 3 Training Process of the Reinforced CVAE Algorithm 1 outlines the training process of the Reinforced CVAE . The ﬁrst step of pretraining is described in the next section . For every training batch , we ﬁrst compute the variational objective L (cid:48) and obtain the generated text . Then we com - pute the policy gradient J (cid:48) from the word proba - bility in the previously generated text and the re - wards determined by the emoji classiﬁer . Finally , we conduct gradient descent on the CVAE com - ponents using the hybrid objective L (cid:48)(cid:48) that is com - prised of L (cid:48) and J (cid:48) . A . 4 Experiment Setting Hyper - parameters For the hyper - parameters of the base model and CVAE models , we use word embeddings of 128 dimensions and RNN layers of 128 hidden units for all encoders and decoders . The size of emojis’ embeddings is contracted to 12 through a dense layer of tanh non - linearity . We set the size of latent variables to 268 . MLPs in recognition / prior network are 3 layered with tanh input : Total training step N , Training batches , λ 1 Pretrain CVAE by minimizing Eq . 9 ; 2 i = 0 ; 3 while i < N do 4 Get next batch B and target responses T in B ; 5 procedure Forward pass B through CVAE 6 get generation G ; 7 get probability P of all words in G ; 8 get variational lower bound objective L (cid:48) ; 9 Compute R , α by emoji classiﬁer using G ; 10 Compute r by emoji classiﬁer using T ; 11 J (cid:48) = α ( R − r ) (cid:80) log P ; 12 L (cid:48)(cid:48) = L (cid:48) − λ J (cid:48) ; 13 Conduct gradient descent on CVAE using L (cid:48)(cid:48) ; 14 i + + ; 15 endAlgorithm 1 : Training of the Reinforced CVAE . non - linearity . All other training settings are the same as the emoji classiﬁer . For Reinforced CVAE 3 , λ in hybrid objective ( Eq . 6 of the paper ) is set to 1 , and α in Eq . 5 of the paper is empirically given by : α x (cid:48) , e =   0 , 0 . 5 , 1 , R ranks 1 in all labels R ranks 2 to 5 in all labels otherwise ( 10 ) where reward R is the probability of emoji label e computed by the classiﬁer , and x (cid:48) is the generated response . 3 We will release the source code for MOJITALK and pre - trained models on Github . com . Training Setting We use fully converged base SEQ 2 SEQ model to initialize its counterparts in CVAE models . When training the Reinforced CVAE with emoji classiﬁer , instead of using hy - brid loss function from the beginning , we intro - duce the policy loss only after 2 epochs of train - ing . For our ﬁnal models , we use bow loss along with KL annealing to 0 . 5 at the end of the 6th epoch . Note that KL weight does not anneal to 1 at last , meaning that our models do not strictly follow the objective of CVAE ( Equation 9 ) . How - ever , lower KL weight gives the model more free - dom to generate text . We can view this technique as early stopping ( Bowman et al . , 2015 ) , ﬁnding a better result before model converges on the origi - nal objective . Generation To exploit the randomness of the la - tent variable , during generation , we sample the result of CVAE models 5 times and choose the generated response with the highest probability of designated emoji label as the ﬁnal generation .