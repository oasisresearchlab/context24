Master thesis on Sound and Music Computing Universitat Pompeu Fabra Generating sound palettes for a Freesound concatenative synthesizer to support creativity Gonzalo Nieto Montero Supervisor : Frederic Font Corbera June 2021 Master thesis on Sound and Music Computing Universitat Pompeu Fabra Generating sound palettes for a Freesound concatenative synthesizer to support creativity Gonzalo Nieto Montero Supervisor : Frederic Font Corbera June 2021 Contents 1 Introduction 1 1 . 1 Freesound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 1 . 2 Concatenative Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1 . 3 Creativity Support Evaluation . . . . . . . . . . . . . . . . . . . . . . . 6 1 . 4 Thesis structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2 Implementation 10 3 Evaluation Methodology 17 4 Results and Discussion 21 4 . 1 Quantitative Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . 21 4 . 2 Qualitative Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 5 Conclusions 29 Bibliography 32 A Quantitative Evaluation : Form 36 B Semi - Structured Interview Guide Questions 47 Abstract Browsing large audio and music collections can be a challenging and time - consuming process . An enhanced way to navigate them is by using text - based queries together with content - based exploration . The success of a search can be measured in terms of recall and precision , but this is not enough when the search is part of a creative process . In this thesis , we focus on the speciﬁc case of a concatenative synthesizer connected to Freesound and evaluate the impact of two search methods on the creative workﬂow of a user . This synthesizer is dedicated to sound textures and has a two - dimensional grid map on which sounds are represented and manipulated with a mouse . The map can be ﬁlled with two diﬀerent search methods : a text - query and a special query - by - four - examples . In an attempt to asses how these two methods aﬀect the creative process , the evaluation process consists of quantitative – Creativity Support Index plus other questions – and qualitative – semi - structured interviews – user evaluation with 5 expert participants . Results show that the search method does not seem to have a signiﬁcant inﬂuence on the CSI score and thus on the creative process , and there is also no clear favourite in the qualitative assessment . Nevertheless , the small data sample size ( N = 5 ) , among other limitations , does not allow any strong conclusions to be drawn . In addition to this , participants seem to like the synthesizer overall , but further research and more users would be needed to understand its eﬀect on the creative process . Keywords : Freesound ; Concatenative Synthesis ; Creativity Support Evaluation Chapter 1 Introduction Browsing and navigating large sound collections can be a diﬃcult and time - consuming process . The most common way for users to interact with these collections is through text - based search engines . The user may be searching for speciﬁc sounds that have distinct and detailed features that may be hard to put into words , such as timbre qualities , or that might not be included in the text metadata of the sound , such as a concrete event , i . e a door closing . Thus , text search might not be enough , even after reformulating queries , or after using some kind of tag - based ﬁlters . As a result , content - based search methods , based on the acoustical features of the sounds , oﬀer an alternative for developing innovative approaches to navigating search results in such big libraries . In fact , text - based queries together with content - based explo - ration , are proposed in several publications as a good combination [ 1 , 2 ] . Users are familiar with using words , i . e . high - level descriptions , to search for media assets , and this can be augmented with content - based ﬁlters and / or similarity representations that use audio descriptors . Additionally , searches can be approached in diﬀerent ways . Sometimes the user will be looking for a very speciﬁc sound and sometimes they will have an idea in mind that they will narrow down by navigating through diﬀerent possibilities – sometimes called " exploratory search " – depending on the application . When this search is part of a creative process , it is interesting to know how much the search supports this 1 2 Chapter 1 . Introduction process rather than how eﬀective it is in terms of precision and recall . Here is where this work is framed , trying to asses how browsing with diﬀerent search methods can aﬀect the creative workﬂow of a user , in a music - making use case . In order to study the topic speciﬁcally and not in abstract , this is done in the speciﬁc context of a Freesound - connected concatenative synthesizer . This particular context stems from , on the one hand , the exploration of the creative possibilities of Freesound as a unique sound library with a wide variety of sounds , and on the other hand , the advantage that concatenative synthesis can take from this variety . We thus start from the assumption that the instrument resulting from the combination of Freesound with a concatenative synthesizer is musically and creatively interesting . Moreover , it is feasible to design and implement two interfaces of this instrument within the time constraints of a master thesis . Further narrowing the framework , it is decided to speciﬁcally implement a concatenative synthesizer aimed at sound textures and to create two interfaces that both use a two - dimensional grid map on which sounds are represented and manipulated with a mouse . In this way , the research can be focused on two search methods that ﬁll the map with sounds : a text - based approach and a query - by - example approach . To gain insight into how much each approach aids the creative process , we need creativity support evaluation methods . Therefore , to introduce this master thesis three main technologies / topics have to be introduced and contextualized : Freesound , Concatenative Synthesis and Creativity Support Evaluation . 1 . 1 Freesound One of the most common uses of the internet nowadays is media sharing , and audio is not an exception . Started as an academic research project in 2005 , Freesound 1 is an online collaborative database of sounds shared by users under Creative Commons licenses [ 3 ] . The web page has made possible more than 171M downloads in all its 1 https : / / freesound . org / 1 . 1 . Freesound 3 years of history and hosts a more than 500 , 000 sounds of all sorts , from ﬁeld record - ings to music instrument samples , foley , speech and loops ( data from 2021 [ 4 ] ) , with the only common denominator being that they can be recycled in new contexts . Moreover , reusing sound recordings has become commonplace as computers have become more important in music production and sound processing . Consequently , the sound exchanges carried out in Freesound happen not only for the sake of ex - changing opinions and memories , as in other social media networks , but also because of the possibilities for recombination of sound materials . A good example of this tendency is the usage of Freesound’s Application Program - ming Interface ( API ) . Since 2011 , the platform oﬀers an API which allows develop - ers to browse , search , and retrieve information about Freesound users , packs , and sounds themselves , as well as to upload , comment , rate and bookmark sounds . From that point on , more than 40 projects are using or have used Freesound data ( data from February 2021 [ 5 ] ) . These projects vary from an eurorack sample streaming and sound synthesis module ( CTAG’s Strämpler ) , to an online DAW with direct integration of Freesound search ( Spotify’s Sountrap ) . Specially inspiring for this thesis are Le Sound’s AudioTexture Free , a granular synthesizer that transforms Freesound clips ( see Figure 1 ) , and Freesound Explorer [ 6 ] , a visual interface for exploring Freesound in a 2 - dimensional space while creating music at the same time ( see Figure 2 ) . Figure 1 : Le Sound’s AudioTexture Free plugin . Freesound browser ( left ) and granular synthesizer ( right ) . 4 Chapter 1 . Introduction Figure 2 : Freesound Explorer web . Nonetheless , as it is a relatively new tool – ten years since the API was ﬁrst intro - duced – the creative potential of the integration of Freesound’s variety and ever - growing quantity of sounds in other applications is still to research and develop . Precisely , this wide variety and number of sounds ( and thus sound textures ) could be exploited by a concatenative synthesizer , since it needs a corpus of sounds to gen - erate its output , and it is often used to create textures – this is where the present work focuses . 1 . 2 Concatenative Synthesis The term “Concatenative Synthesis” has been extensively used to characterize mu - sical systems that produce sound by automatically reusing existing ones , according to some well - deﬁned collection of criteria and algorithmic procedures [ 7 ] . It can be considered a natural extension to granular synthesis , where grains of sound also in - clude some descriptive information – audio features – that determine the sequencing of the ﬁnal output . Although there are numerous implementations and variations , there are three common steps that can be identiﬁed in every concatenative synthesis process [ 8 ] : 1 . 2 . Concatenative Synthesis 5 1 . Sound Segmentation : dividing automatically larger sound ﬁles into smaller units . These units can range from the size of microsounds ( 5 - 200 ms ) , to beats , bars ( using some onset detection algorithm ) or complete audios . 2 . Feature Extraction : selecting and obtaining signiﬁcant music descriptors that can be used to represent and compare units of sound eﬀectively . 3 . Unit Selection : combining sound units according to some criteria , typically using a target to compare features against . This process is ﬁrst applied in 1996 to speech generation – Text - To - Speech synthesis speciﬁcally – before music . Musical concatenative synthesis is introduced in 2000 by Schwarz [ 9 ] . Since then , numerous systems are developed , including commercial implementations such as Loopmash ( discontinued in 2018 ) , a software plugin and mobile application for automatically creating mashups from existing looped content . Ó Nuanáin [ 10 ] presents a comprehensive table compiling a summary of a large number of concatenative systems – as of 2016 – , with remarks on interaction and visualisation features , support for rhythm , and whether any user evaluation was carried out , which we reproduce in 1 . It is noticeable that only 2 out of 20 systems in this list were evaluated with users ( 3 out of 21 counting Ó Nuanáin’s system as well ) , and none of them were evaluated on how they support creativity . Leaving rhythmic purposes aside and focusing on textures generation , it is worth mentioning – in chronological order – the following systems : CataRT [ 11 ] , Audio - Garden [ 12 ] , AudioGuide [ 13 ] and EarGram [ 14 ] . These four systems are specially interesting in the context of this master thesis , since they all present a 2D repre - sentation of sounds as an interface for the user to manipulate the concatenation . In Figures 3 2 and 4 , cataRT and AudioGarden interfaces is shown as examples . This interface can be useful to explore the Freesound database intuitively , to prevent the retrieving of content from being a diﬃcult and time - consuming task . Research by Favory et . al . on browsing large sound collections [ 15 ] could suggest that combin - ing a text query with a 2D - visualisation might be a useful approach , although one 2 Image taken from http : / / ismm . ircam . fr / catart / 6 Chapter 1 . Introduction Table 1 : Summary of concatenative synthesis systems , as collected by Ó Nuanáin in [ 10 ] . should take care of the interpretability of the dimensions of the space . In this speciﬁc context of textural Concatenative Synthesis and Freesound combined , we assume that the approach used to search and the 2 - D representation of sounds is what aﬀects the creative result the most . To measure this impact , we use creativity support evaluation methods . 1 . 3 Creativity Support Evaluation In the ﬁeld of human - computer interaction , there is research on how to design in - terfaces to support the creative process of the end user [ 16 ] , which is based on the assumption that creativity can be enhanced and promoted and that there that there are common characteristics across diﬀerent domains of creative activities [ 17 ] . How - ever , it is challenging to evaluate the ability of these interfaces or tools to support creativity , because creativity itself is not easily deﬁned . There are many deﬁnitions of creativity in the literature , but Shneiderman et al . [ 18 ] suggest that consider - ing creativity a multidimensional concept could encompass the majority of them , stating : Recognition of the fact that there are multiple dimensions to creativity 1 . 3 . Creativity Support Evaluation 7 Figure 3 : CataRT interface , a real - time corpus - based concatenative synthesizer by Diemo Schwarz . Figure 4 : AudioGarden interface , a concatenative synthesis system by Picard et al . . and in creativity research , leads us to propose that these various as - pects of creativity research and creativity should be thought of as being 8 Chapter 1 . Introduction diﬀerent dimensions of a taxonomy for creativity studies and creativity support tools . In other words , the problem of developing Creativity Sup - port Tools is one in which one must ﬁrst decide in which intersection of the n - dimensional taxonomy one wishes to study and work . This could be coherent with the deﬁnition from Jordanous and Keller , who used a statistical language processing techniques to identify fourteen main components of creativity , which integrates in some manner other deﬁnitions of creativity throughout history [ 19 ] . Given this context , the Creativity Support Index ( CSI ) by E . Cherry and C . Lat - ulipe [ 20 ] seems like a reasonable measurement for this complex concept . Instead of attempting to deﬁne creativity , CSI looks at what factors are most relevant to fos - tering creative work processes . It is a quantitative , psychometric tool that aims to be a standardized survey metric . In speciﬁc , users provide ratings for six dimensions of creativity support : Enjoyment , Exploration , Expressiveness , Immersion , Results Worth Eﬀort , and Collaboration [ 21 ] . Therefore , the CSI helps researchers to un - derstand not only how eﬀectively a tool facilitates creative work in general , but also what aspects may need improvement . Nevertheless , both the authors of the CSI and Shneiderman et al . [ 18 ] point out that one single metric is not suﬃcient , researchers need to use a variety of metrics to show convergence . Methods used for measuring creativity support tools in the sound and music ﬁeld also seem to point towards an interdisciplinary and open - ended approach to evaluate systems within the ﬁeld [ 22 ] . One possible approach to overcome this is complementing the CSI score with a qualitative evaluation . A feasible and extended way of performing qualitative evaluation is through semi - structured interviews . To analyse the answers of these interviews , thematic analysis is an often used method [ 23 ] , as it provides a systematic manner to analyse qualitative data [ 24 ] . In addition to this , using the CSI evaluation metric in combination with other evaluation methods is a common practice in the evaluation of recent musical and non - musical systems [ 25 , 26 , 27 , 28 , 29 , 30 , 31 ] . 1 . 4 . Thesis structure 9 1 . 4 Thesis structure To summarize , in this master thesis , a Freesound - connected concatenative synthe - sizer is built to test in practice how diﬀerent searching techniques impact a user’s creative process . This synthesizer is oriented towards the creation of textures and features a two - dimensional grid map on which sounds are represented and modi - ﬁed using a mouse . The map can be ﬁlled with two diﬀerent search methods : a text - query and a special query - by - four - examples . The implementation of these two methods starts with a Python non - real - time pro - totype - in a Colab 3 notebook , to facilitate reproducibility . After that , part of it is migrated to C + + ( within the JUCE framework 4 ) , so it can be manipulated in real - time – see Implementation for a detailed description . Then , these two sound palettes are evaluated using the Creativity Support Index and semi - structured inter - viewing ( described in Evaluation Methodology ) . Finally , the results are presented and discussed in Results and Discussion , while conclusions are drawn in Conclusions . 3 https : / / colab . research . google . com 4 https : / / juce . com / Chapter 2 Implementation The implementation of the concatenative synthesiser that serves as base for this thesis is divided into two phases : ﬁrst , a prototype was made entirely in a Python colab notebook 1 , non real - time and without mouse interaction ( this interaction is therefore simulated ) . Then , part of this prototype is ported to C + + ( JUCE frame - work ) to allow real - time audio and interaction with the mouse , which is modiﬁed and optimized afterwards . The synthesizer is named Freecat after Free - sound and con - cat - enation – this name is used throughout the thesis . The general operation of the synthesiser revolves around a sound map that has 25 points representing 25 sounds . When the user clicks on the map , the sound closest to this point is played . However , because the synthesizer is concatenative , the sounds are split into grains ( whose size is adjustable by the user ) , and it is these grains that are played when the user clicks on them , not the whole sounds . How this map is ﬁlled in , i . e . , how the sounds are searched ( how the corpus is created ) , is what leads to two diﬀerent interfaces . On the one hand , approach number one – Text Query ( TQ from now on ) – down - loads the ﬁrst 25 results of a text query introduced by the user . On the other hand , approach number two – Query By Examples ( QBE from now on ) – takes 1 https : / / colab . research . google . com / drive / 1HjfxnNMnSfaUwmid - 2dTPjsVSMyq - tKL ? usp = sharing 10 11 four Freesound unique sound identiﬁers ( IDs ) as input , which correspond to the 4 corners of the rectangle - shaped map . Then , taking their mean MFCC coeﬃcients as references , it interpolates linearly 2 along the 21 grid points ( 5 x 5 grid minus the four references ) in between – see Figure 5 for visual reference . These calculated MFCC coeﬃcients in between are searched in Freesound , obtaining the sounds that are close to these values . After this content - based search there is a total of 25 downloaded sounds 3 . Figure 5 : Grid interpolation of the QBE method . Squares in blue represent the MFCC mean values of the four sounds given by the user as references . Red dots are the points of the 5 x 5 grid where the linear interpolation happens . 2 The exact interpolation used is Scipy’s griddata function set to its ’linear’ method . More information available at ( accessed 05 - 07 - 2021 ) : https : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . griddata . html 3 Note that there is no remote audio processing – the API or the API descriptors are used to implement the functionality of selecting sounds , but the processing of the sounds is oﬄine . Hence , there is no Web Audio involved . 12 Chapter 2 . Implementation Afterwards , QBE approach uses the already calculated grid points to locate each sound in space . TQ approach , on the other hand , uses the standardized mean MFCCs values of the sounds , reduced to two dimensions with Principal Compo - nent Analysis . These values have to be then arranged into a 5 x 5 grid , so they are represented the same way as in QBE and the two interfaces are comparable . To make these values ﬁt into the above - mentioned grid , they are ordered from lowest to highest according to their root mean square value and linked to a grid ordered in the same manner . Note that , although using only MFCC means is not ideal to represent sounds , as there are more audio features relevant to timbre , this approach is used because a content - based search ( QBE ) in Freesound with more parameters would be too speciﬁc and diﬃcult to match – and TQ interface also uses MFCCs to be comparable to QBE . In Figures 6 and 7 the grid can be seen in the context of the complete synthesizer . Throughout this document , the two implementations of TQ and QBE , are interchangeably referred to as interfaces , tools , or search methods – although these words are not strict synonyms , they are treated as so . Figure 6 : Freecat’s Text Query interface after querying the term " kid " . Thereafter , sounds are sliced into units or grains ( size adjustable by the user ) and 13 Figure 7 : Freecat’s Query By Examples interface after feeding it with four sound IDs . their loudness level is calculated using Essentia 4 . Speciﬁcally , the loudness of an audio signal deﬁned by Steven’s power law described here 5 , but normalized by the size in samples of the signal , and taken in logarithmic units . However , these small units are not represented in the map , because the focus of the interface is on complete sounds , which are the ones represented in the map . Moreover , in order to be coherent with this idea , we design a grain selection method that tries to capture the essence of each sound while at the same time retaining some continuity between grains . The same loudness that is calculated for each grain is calculated for the complete sound and is considered the ’target loudness’ . This target loudness is used to select the grains that are concatenated when the user clicks on a sound : only units within the range of + 6 / - 6dB around the target get randomly ( uniform distribution ) selected . In case there are no grains in this range , the threshold changes to values greater than - 12dB below the target . This way , there is certain texture continuity , in terms of dynamic range , and at the same time we are not stuck in the same grain repeating over and over when playing a single 4 https : / / essentia . upf . edu / 5 https : / / essentia . upf . edu / reference / streaming _ Loudness . html ( accessed 04 - 08 - 2021 ) 14 Chapter 2 . Implementation sound . Finally , euclidean distance is used to dictate which is the closest sound point to the mouse clicks . Concatenation and playback occur when the mouse is pressed and held . C + + and python parts of the program communicate via OSC , and python part runs inside a docker container , to facilitate the installation of all dependencies and to reach the main platforms . Python handles the interaction with the Freesound API and the feature extraction process using Essentia , while C + + handles real - time concatenation , playback and interaction . The python program is irrelevant to the user , it only needs to be run at the background one time at the beginning ( see Figures 8 and 9 for examples of this python ’backend’ ) – further work could be to implement all in C + + using the JUCE client library of the Freesound API 6 . Figure 8 : Freecat’s Text Query interface : python backend after querying " kid " . The synthesizer is implemented using the JUCE framework for the application to be multi - platform and to run as a Digital Audio Workstation ( DAW ) plugin ( see Figure 10 ) . Thus , it could be used by music producers and sound designers in their 6 https : / / github . com / mtg / freesound - juce 15 Figure 9 : Freecat’s Query By Examples interface : python backend after feeding it with four sound IDs . usual working environment . Note that in both approaches a ﬁlter is applied to the queries , so that only sounds of 0 . 5s - 5s of duration are downloaded – this is done , on the one hand , to bring the average of the MFCC coeﬃcients closer to representing the full sound and , on the other hand , to speed up the downloading of the sounds and their processing . For more details , all code is available at the authors Github repository 7 . 7 https : / / github . com / gonznm / freecat - prototype 16 Chapter 2 . Implementation Figure 10 : Freecat running as a Logic Pro plugin . Chapter 3 Evaluation Methodology To evaluate how the two implemented systems support creativity , user - based evalu - ation is utilised . Quantitative evaluation is done using the CSI score and qualitative evaluation is carried out through semi - structured interviews . According to its authors , the CSI is speciﬁc to a particular tool , used for a particular task by a particular type of user ( with a particular level of expertise ) . For this reason , two experiments per user are performed doing the same task , but with the two diﬀerent developed tools – the two diﬀerent interfaces , TQ and QBE . A task has to be speciﬁc enough – so it can compare – while at the same time should be possible to resolve it in diﬀerent creative ways . The selected task is " create a texture of 15 seconds by imitating or getting inspiration from the following sound " , accompanied by a reference textural sound of a storm . This sound is chosen because it is possible to imitate it relatively fast looking at the big picture or spend a lot of time trying to capture its details , the user can decide . Rather than attempting to deﬁne creativity , CSI examines the elements that are most helpful to promote creative work processes . In speciﬁc , users rate six factors of creativity support : Enjoyment , Exploration , Expressiveness , Immersion , Results Worth Eﬀort , and Collaboration . In the form , there is a section of agreement state - ments where users rate two assertions related to each factor . There is also a paired comparison section , where users have to choose between two factors for all the com - 17 18 Chapter 3 . Evaluation Methodology binations of the six ( 15 in total ) . The concrete questions of the form , as well as how to calculate the score , are well described in [ 21 ] . Note that " system or tool " is substituted by " Freecat " and each paired factor comparison is presented alone , to prevent participants from lining up their answers , as recommended by the authors . Collaboration agreement statements are omitted , because they do not make sense in the context of Freecat , but collab - oration statements are still shown in the paired comparisons , to keep the CSI score standardised - once again , recommended by the authors . The order of these com - parisons is also shuﬄed . Appendix A shows the exact questionnaire used , which also includes three initial questions about the level of expertise of the user and two ﬁnal questions regarding overall valuation of Freecat and the impact of being able to use Freesound . Regarding the semi - structured interviews , some open - ended questions are prepared in advance , but they are adapted to each case , so that participants can express their opinions and ideas freely . They are also asked to add any comment they ﬁnd relevant at the end of the interview . The core questions that are asked to all participants are presented in Appendix B . They intend to ﬁnd out more about the perceived diﬀerences between the two interfaces / tools . First , two pilot experiments are performed , in order to detect possible problems and improve aspects of the test . These pilots revealed that : 1 . The instrument itself , Freecat , lacks informative labels that help to know the function of each parameter fast . Therefore , a quick explanation on how to use it should be given at the beginning of the experiment . 2 . When ﬁlling in the agreement statements , users tend to forget they are in the context of this particular task and interface . The interviewer should emphasise this orally . 3 . When ﬁlling in the paired factor comparisons , users tend to forget they are in the context of this particular task but they can think of any tool , not only 19 Freecat . The interviewer should emphasise this orally . 4 . Some questions of the initial semi - structured interview could be better asked in the form , to have a numeric answer . These are the extra questions included in the ﬁnal form that do not belong to the standard CSI form - three initial questions on the user’s level of knowledge and two ﬁnal questions on the overall assessment of Freecat and the impact of being able to use Freesound . 5 . Some questions of the initial semi - structured interview seemed redundant with the form for the users . They were removed . At the end , 5 experiments are performed , since the resources and scale of this re - search are not large . The 5 participants are experienced with audio / music produc - tion tools , but they are asked in the evaluation to rate their level of expertise , to study in detail how this aﬀects the results . Since Freecat is not aimed at the general public , but at music producers / sound designers , participants should be experienced in order to obtain valid results in the evaluation [ 32 ] . This sample size is too small for quantitative evaluation if we do not make any assumptions on the data ( see 4 for more details ) , but has been used by other researchers in qualitative user evaluations [ 15 ] . One interview is performed in English , and the other four are in Spanish – the quotes that appear in following chapters are translations done by the author . Experiments were carried out on site , using the author’s computer , as the installation of the complete system is not trivial , and all interviews were recorded to be able to re - listen and transcribe them . The participants were presented certain guidelines as well as verbal explanations from the examiner , who was present during the entire session . At the beginning , they were asked to play around with Freecat to get to know the instrument a bit . Then , participants were asked to ﬁll in the quantitative form , which involves the realisation of two tasks with the TQ and QBE interfaces . Finally , semi - structured interviews were carried out . Basic statistical analysis is used to process the data obtained in the quantitative forms . Thematic analysis , which is a method that is often employed to analyse data in primary qualitative research [ 23 ] , is used to examine the interviews , following the 20 Chapter 3 . Evaluation Methodology 6 phases described in [ 33 ] . Note that several steps involve the authors criteria and biases to ﬁnd the emerging themes . The outcomes of these assessments are discussed in Results and Discussion . Chapter 4 Results and Discussion In this chapter , both quantitative and qualitative results of the experiments with 5 participants are presented . 4 . 1 Quantitative Evaluation This part gathers the results obtained in the form ﬁlled by the participants . The ﬁrst questions in the form ask about the level of expertise of the user . In Table 2 we can see that all participants are familiar with audio / music production tools , as it was expected . None of the participants are very familiar with the term " concatenative synthesis " , which probably means that they had not used concatenative synthesizers in the past . Since all participants were " A bit " familiar with the term " concatenative synthe - sis " , we can omit this variable and translate the self - perceived levels of expertise to a relative level of expertise within the experiment . Thus , three combinations of Familiarity with audio / music production - Use of sound textures expertise appear ( from smallest to largest ) : 1 ) A bit - Sometimes , 2 ) Very much - Sometimes and 3 ) Very much - Always . This leads to three relative categories of expertise : minimum , middle and maximum ( see Table 3 ) . This relative categorization is done in order to try to observe the inﬂuence of the level of expertise in the CSI score . According to 21 22 Chapter 4 . Results and Discussion Table 2 : Participants self - perceived level of expertise . Options were [ Not at all , A bit , Very much ] and [ Never , Sometimes , Always ] . Participant number Familiarity with audio / music production Familiarity with concatenative synthesis Use of sound textures 1 Very much A bit Sometimes 2 A bit A bit Sometimes 3 Very much A bit Sometimes 4 Very much A bit Always 5 Very much A bit Always the CSI authors , one could expect a similar CSI score for the same tool performing the same task with the same level of expertise . Table 3 : Participants self - perceived and relative level of expertise . Participant number Familiarity with audio / music production Use of sound textures Relative expertise 1 Very much Sometimes Middle 2 A bit Sometimes Minimum 3 Very much Sometimes Middle 4 Very much Always Maximum 5 Very much Always Maximum In Table 4 we can see the relative expertise of each participants with their CSI scores for each tool , Text Query and Query By Examples . Apparently , participants with the same level of expertise do not score similar CSI for the same tool ( 1 vs . 3 or 4 vs . 5 ) , which may mean that participants CSI scores could also depend on other factors , such us relative level of demand or state of mind of the subject . Moreover , it has to be taken into account that self - perception is subjective by deﬁnition . One could argue that the expertise diﬀerences we are taking into account here are too subtle , and we could consider all participants experts in the ﬁeld . This reasoning , together with the apparent disconnection between the CSI score and the more precise level of expertise , leads us to consider all participants experts in the ﬁeld – all participants are considered equals – for the interpretation of the following results . 4 . 1 . Quantitative Evaluation 23 Table 4 : CSI scores for both Text Query and Query By Examples tools . Participant Relative expertise TQ CSI ( % ) QBE CSI ( % ) 1 Middle 91 . 33 96 . 33 2 Minimum 78 . 00 81 . 33 3 Middle 71 . 67 86 . 67 4 Maximum 94 . 67 94 . 00 5 Maximum 69 . 33 68 . 33 Looking into the CSI scores for each tool , it seems like the score depends more on the subject than on the tool used . Assuming that CSI scores are normally distributed and that sample data is collected from a representative , randomly selected portion of the population of music / audio producers – which may be a big assumption to make - , we can calculate the mean and standard deviation for each tool and interpret them . In Table 5 we can observe that there is a 4 point diﬀerence between the means of the tools , having the Query By Examples interface the best result with a 85 . 33 CSI . The standard deviations of both groups are very similar . Table 5 : Mean and standard deviation of the CSI scores for Text Query and Query By Examples interfaces . TQ CSI QBE CSI Mean 81 . 00 85 . 33 Std Dev 10 . 25 10 . 02 To see if this diﬀerence is statistically signiﬁcant , a t - test is performed . Once again , we are making some assumptions that have to be taken into account : ( i ) the depen - dent CSI variable is normally distributed and ( ii ) sample data is collected from a representative , randomly selected portion of the population of music / audio produc - ers . The t - test has to be paired ( also known as a dependent or correlated t - test ) , since the two groups we want to compare ( TQ and TBE ) are actually the same group of participants using diﬀerent tools . There are two possible hypotheses in a paired t - test : 24 Chapter 4 . Results and Discussion 1 . The null hypothesis ( H0 ) asserts that the means of the two groups are not signiﬁcantly diﬀerent . This translates as the tool having no apparent inﬂuence in the CSI score . 2 . The alternative hypothesis ( H1 ) asserts that there is a signiﬁcant diﬀerence between the two population means , which is unlikely to be due to sampling error or chance . This would mean that the interface or tool may inﬂuence the CSI score . Table 6 shows the results of the t - test , which is a p - value of 0 . 2101 > 0 . 05 . This value fails to reject the H0 hypothesis , i . e . , there is insuﬃcient statistical evidence to reject it - the means diﬀerence is considered to be not statistically signiﬁcant . Therefore , the interface may not inﬂuence the CSI score signiﬁcantly , and thus may not inﬂuence the creative process of the user . However , this result should be interpreted with great caution . First of all , we are assuming that the shape of the population distribution is normal and that we do not have any outliers in our sample data . If any of these assumptions fail , the sample size of 5 that we are using is too small , implying that our t - test has no meaning at all . Moreover , a larger sample size would improve the test statistical power . Secondly , how the CSI score relates to the actual support of creativity can be also discussed . Table 6 : Paired t - test results using a 95 % conﬁdence interval . t - value 1 . 4915 p - value 0 . 2101 > . 05 Finally , two general questions are asked at the end of the form which connect with the semi - structured interview . In Table 7 we can see that participants liked Freecat overall , as all of them score it at or above 4 out of 5 . They also thought that being able to use Freesound had a positive impact in their creations , with a consensus of 5 points , the maximum of the Likert scale of this answer . This is further developed in the qualitative evaluation . Table 8 shows all the quantitative results together for each participant , to be able to 4 . 1 . Quantitative Evaluation 25 Table 7 : Ratings for the two ﬁnal questions of the form : [ . . . ] how do you like the instrument overall ? and Do you think that being able to use Freesound has had a positive impact on your creation ? Participant number Overall valuation of Freecat ( 1 - 5 ) Positive impact of Freesound ( 1 - 5 ) 1 5 5 2 4 5 3 4 5 4 5 5 5 5 5 have the big picture and to look for relationships between them . There seems to be no correlation between the level of expertise of the participants and their overall val - uation of Freecat or their judge on Freesound’s impact in their creations . Moreover , partipants that give the lowest CSI scores , rate quite positively the instrument in any case . It should be noted that , since the researcher was present during the entire experiments , participants could have tend to please what they think the researcher wants to obtain , altering unavoidably the results . Table 8 : Quantitative results . Participantnumber Familiarity with audio / music production Familiarity with concatenativesynthesis Use of soundtextures Relativeexpertise TQ CSI ( % ) QBE CSI ( % ) Overall valuation of Freecat ( 1 - 5 ) Positive impact of Freesound ( 1 - 5 ) 1 Very much A bit Sometimes Middle 91 . 33 96 . 33 5 5 2 A bit A bit Sometimes Minimum 78 . 00 81 . 33 4 5 3 Very much A bit Sometimes Middle 71 . 67 86 . 67 4 5 4 Very much A bit Always Maximum 94 . 67 94 . 00 5 5 5 Very much A bit Always Maximum 69 . 33 68 . 33 5 5 26 Chapter 4 . Results and Discussion 4 . 2 Qualitative Evaluation This part presents the thematic analysis of the interviews performed after the quan - titative evaluation . When playing around at the beginning , participants usually started with and spent more time using the Text Query interface , as it is the most straightforward of the two . All participants asked how grains were selected when clicking on the same sound , which may mean that this design decision is not very intuitive for the user . Two participants said that Freesound is the key behind Freecat , as " at the end of the day , it’s a quick way to explore Freesound " , while the other three did not de - velop much their answers . Regarding the understanding of the dimensional space , participants were divided . One participant did not make any sense of the map , nei - ther for TQ nor QBE interfaces , since sounds seemed " random , chaotic " to them . Two participants found sounds in the QBE map as " timbrically continuous " , while sounds in TQ were " counter - intuitively " or " more chaotically " arranged - this may have to do with the RMS - based arrangement of the TQ palette . Another partici - pant felt that TQ interface represented sounds better , because with QBE they was " expecting an interpolation that was not so exact " . This was agreed by the last participant , for whom " the space in between is not very clear " . Expectations play a role in the latter two , as they are higher for the QBE interface and therefore more diﬃcult to meet . On the one hand , this conﬁrms the fact that timbre is a complex , perceptual magnitude , and that MFC coeﬃcients – let alone the MFCC mean of an entire sound – are not suﬃcient to characterise it . On the other hand , it has to be taken into account that each subject did diﬀerent queries that led to completely dif - ferent sound maps . Given the nature of Freesound , sometimes queries return similar sounds that may have a timbral continuity , while other times they may return very disparate sounds that have to be included in the grid in any case . Although the grid helps to manipulate the sounds with the mouse , it does not help to understand the dimensions of the space , and therefore it is diﬃcult for the user to foresee the positions in which a sound will be found . Freesound queries combined with a grid 4 . 2 . Qualitative Evaluation 27 to represent the sounds present , therefore , a trade - oﬀ between manageability and interpretability . One approach to go deeper into this issue would be to do a quali - tative user evaluation with ﬁxed queries , in order to learn more about how people perceive the space . Connected to this matter , another aspect that subjects mentioned is the implications of having or not having references in the map . One participant said that " it’s very diﬀerent when you have a preconceived idea " . TBE search method implies knowing the four sounds in the palette corners , while TQ method was overall more " surprising " . Comparing the two interfaces , QBE was generally described as more manipulable or " controllable " , whereas TQ was considered more " exploratory " or " experimental " . QBE let users modify their queries more precisely or speciﬁcally , while modifying the queries of TQ led to more unpredictable results for the users . Figure 11 shows a mind map with the observed themes around the two search methods . The design of each interface directly inﬂuences this : one has one parameter ( text query ) to tune , while the other one has four parameters ( sound IDs ) – apart from the common grain size parameter . Text Query method Experiment General Open - ended Exploration Query By Examples method Speciﬁc Expecta - tions Control Thorough Figure 11 : Mind map with emerging themes around the two search methods . Although the QBE method was perceived as more speciﬁc overall , two participants 28 Chapter 4 . Results and Discussion mention that " you cannot expect super speciﬁc results from Freecat in general " . This could perhaps change if users were able to use Freecat for a long time and master it . Three participants commented on the " little expressiveness " oﬀered by the instru - ment . Two participants mentioned a touch screen and polyphony ( i . e , being able to touch and listen to at least two points at the same time ) as possible solutions that could make the instrument more expressive . Although these are good proposals , one could argue that it is diﬃcult to be expressive with an instrument that you have just learned to use – it would be diﬃcult to be expressive with a saxophone if you cannot make it sound , for instance . Moreover , the concept of " expressiveness " may not be the same for each participant and could be discussed . The main focus of the prototype was not on expressiveness , but they are certainly interesting ideas . Given their diﬀerences , one subject preferred TQ over QBE , two subjects preferred QBE over TQ and two were not clear . It was connected to what subjects prioritized : exploration ( TQ ) over control ( QBE ) , or the other way around . This reinforces the idea that creativity is understood in diﬀerent ways , and that the manner in which the CSI is calculated is coherent with this idea , as it multiplies each factor ( enjoyment , exploration , expressiveness , immersion , results worth eﬀort , and collaboration ) by the importance that the user confers to this factor ( its factor comparison count ) . Chapter 5 Conclusions One of the main outcomes of this thesis is the comparison of Text Query and Query By Examples interfaces in the context of a concatenative synthesizer , trying to asses how they support creativity . The evaluation process consists of quantitative – Creativity Support Index plus other questions – and qualitative – semi - structured interviews – user evaluation with 5 expert participants . Participants with the same precise degree of skill do not appear to have similar CSI ratings for the same search method , which might indicate that CSI scores are inﬂu - enced by other factors such as relative level of demand or the subject’s state of mind . This apparent mismatch between the CSI score and a this precise level of expertise leads us to consider all participants experts in the ﬁeld for the interpretation of the rest of the results . There seems to be no link between the participants’ degree of skill and their overall assessment of Freecat or their assessment of Freesound’s inﬂuence in their creations . Furthermore , even those who give the lowest CSI ratings give the instrument a high rating , which is the general trend . It should be emphasized that because the researcher was present throughout the experiments , participants may have tended to please what they believe the researcher wants , causing the results to be biased . It seems like the CSI score depends more on the subject than on the tool used . 29 30 Chapter 5 . Conclusions Moreover , there appears to be no statistically signiﬁcant diﬀerence between the means of the CSI ratings for TQ and TBE tools . Therefore , the tool may not inﬂuence the CSI score signiﬁcantly , and thus may not inﬂuence the creative process of the user . This ﬁnding , however , should be taken with extreme caution . First and foremost , we assume that the population distribution of music / audio producers is normal and that our sample data does not contain any outliers – which could be assuming too much . The sample size ( N = 5 ) of the experiment is too small to determine if our results are meaningful . Second , the relationship between the CSI score and real creativity support may be debatable . Thematic analysis of the semi - structured interviews illustrates that timbre is a com - plex , perceptual magnitude , and that the MFC coeﬃcients are insuﬃcient to rep - resent it . However , it must be remembered that each subject used distinct queries , which resulted in entirely diﬀerent sound maps . Due to the nature of Freesound , certain searches will return related sounds with timbral continuity amongst them , while others will return completely dissimilar sounds that must be included in the grid regardless . Although the grid facilitates the manipulation of sounds , it does not aid in understanding the dimensions of the space , making it diﬃcult for the user to foresee where a sound is . One possible way to further study this issue would be to perform a qualitative user evaluation with ﬁxed queries , trying to gain insight into how people interpret the space . When comparing the two interfaces , QBE was thought to be more manipulable or " controllable " , whereas TQ was thought to be more " exploratory " or " experimen - tal " . Due to the number of parameters of each interface ( four in QBE , one in TQ ) , QBE let users modify their queries more precisely or speciﬁcally than TQ . Another condition that may play a role here is the fact that using QBE implies knowing the four sounds in the four palette corners , as opposed to not having any reference in TQ . Apart from linking TQ search method to " exploration " and QBE to " control " , there was no consensus among participants on which method they preferred . This could support the premise that creativity is a multidimensional concept that changes 31 depending on the application and the user , and that the CSI’s calculation method is congruent with this idea , since it multiplies each factor ( enjoyment , etc . ) by the ’importance’ that the user confers to this factor . Thus , there seems to be no interface that supports creativity better than the other . In any case , since the possibilities of interfaces could be virtually endless , and we evaluate just two , perhaps the most valuable outcome of this research is applying the evaluation methodology of CSI together with semi - structured interviews to con - catenative synthesizers . It turns out to be a viable creativity support evaluation system , so other researchers could use it in the future . However , a bigger sample size should be applied , specially for the quantitative tests . In addition to this , the developed concatenative synthesizer code integrated with Freesound both in Python and C + + , can be used in the future to create more applications . There are other implementations of concatenative synthesizers already available as open - source , but not integrated with Freesound . On the other hand , already existing concatenative software that incorporates the Freesound API is not open - source ( to the author’s knowledge ) . Overall , the synthesizer presents a diﬀerent way of accessing Freesound , which users seem to ﬁnd interesting , even if there is room for improvement in many aspects . This thesis is a ﬁrst step that could be continued in the future . Bibliography [ 1 ] Font , F . Design and evaluation of a visualization interface for querying large unstructured sound databases . Ph . D . thesis , Universitat Pompeu Fabra ( 2010 ) . URL https : / / doi . org / 10 . 5281 / zenodo . 1173914 . [ 2 ] Cano Vila , P . Content - based audio search : from ﬁngerprinting to semantic audio retrieval . TDX ( Tesis Doctorals en Xarxa ) ( 2007 ) . URL http : / / www . tdx . cat / handle / 10803 / 7543 . [ 3 ] Font , F . , Roma , G . & Serra , X . Freesound technical demo . MM 2013 - Pro - ceedings of the 2013 ACM Multimedia Conference 411 – 412 ( 2013 ) . [ 4 ] Freesound Team . The Freesound Blog : 2020 in numbers . https : / / blog . freesound . org / ? p = 1291 ( 2020 ) . Accessed : 2021 - 02 - 18 . [ 5 ] Freesound Team . Freesound Labs . https : / / labs . freesound . org / ( 2021 ) . Ac - cessed : 2021 - 02 - 20 . [ 6 ] Font , F . & Bandiera , G . Freesound Explorer : Make Music While Discovering Freesound ! Proceedings of the Web Audio Conference ( 2016 ) . [ 7 ] Schwarz , D . Concatenative sound synthesis : The early years . Journal of New Music Research 35 , 3 – 22 ( 2006 ) . [ 8 ] Nuanáin , C . Ó . Connecting Time and Timbre : Computational Methods for Generative Rhythmic Loops in Symbolic and Signal Domains . TDX ( Tesis Doctorals en Xarxa ) 257 ( 2018 ) . 32 BIBLIOGRAPHY 33 [ 9 ] Schwarz , D . A System for Data - Driven Concatenative Sound Synthesis . Pro - ceedings of the COST G - 6 Conference on Digital Audio Eﬀects ( DAFX - 00 ) ( 2000 ) . [ 10 ] Ó Nuanáin , C . , Jordà , S . & Herrera , P . Towards User - Tailored Creative Ap - plications of Concatenative Synthesis in Electronic Dance Music . International Workshop on Musical Metacreation ( MUME ) ( 2016 ) . [ 11 ] Schwarz , D . , Grégory , B . , Bruno , V . & Sam , B . Real - time corpus - based con - catenative synthesis with catart . Proc . of the 9th Int . Conference on Digital Audio Eﬀects ( DAFx - 06 ) 1 – 7 ( 2006 ) . [ 12 ] Picard , C . , Frisson , C . & Tardieu , D . AudioGarden : Towards a Usable Tool for Composite Audio Creation . QPSR of the numediart research program 3 , 33 – 36 ( 2010 ) . [ 13 ] Schwarz , D . & Hackbarth , B . Navigating variation : Composing for audio mo - saicing . ICMC 2012 : Non - Cochlear Sound - Proceedings of the International Computer Music Conference 2012 604 – 607 ( 2012 ) . [ 14 ] Bernardes , G . , Guedes , C . & Pennycook , B . EarGram : An application for interactive exploration of concatenative sound synthesis in pure data . Lecture Notes in Computer Science ( including subseries Lecture Notes in Artiﬁcial In - telligence and Lecture Notes in Bioinformatics ) 7900 LNCS , 110 – 129 ( 2013 ) . [ 15 ] Favory , X . , Font , F . & Serra , X . Search result clustering in collaborative sound collections . ICMR 2020 - Proceedings of the 2020 International Conference on Multimedia Retrieval 207 – 214 ( 2020 ) . 2004 . 03985 . [ 16 ] Shneiderman , B . Supporting Creativity with Advanced Information - Abundant User Interfaces . Frontiers of Human - Centered Computing , Online Communities and Virtual Environments 16 , 469 – 480 ( 2001 ) . [ 17 ] Wu , Y . & Bryan - Kinns , N . Musicking with an interactive musical system : The eﬀects of task motivation and user interface mode on non - musicians’ creative engagement ( 2019 ) . 34 BIBLIOGRAPHY [ 18 ] Shneiderman , B . et al . Creativity Support Tools : A workshop sponsored by the National Science Foundation . International Journal of Human - Computer Interaction 20 , 1 – 83 ( 2005 ) . [ 19 ] Carnovalini , F . & Rodà , A . Computational Creativity and Music Generation Systems : An Introduction to the State of the Art . Frontiers in Artiﬁcial Intel - ligence 3 ( 2020 ) . [ 20 ] Carroll , E . A . , Latulipe , C . , Fung , R . & Terry , M . Creativity factor evaluation : Towards a standardized survey metric for creativity support . C and C 2009 - Proceedings of the 2009 ACM SIGCHI Conference on Creativity and Cognition 127 – 136 ( 2009 ) . [ 21 ] Cherry , E . & Latulipe , C . Quantifying the creativity support of digital tools through the creativity support index . ACM Transactions on Computer - Human Interaction 21 ( 2014 ) . [ 22 ] Anna Xambó , M . B . Report on novel methods for measuring creativity support . Deliverable of AudioCommons project 1 – 20 ( 2018 ) . [ 23 ] Thomas , J . & Harden , A . Methods for the thematic synthesis of qualitative research in systematic reviews . BMC Medical Research Methodology 8 , 1 – 10 ( 2008 ) . [ 24 ] Nowell , L . S . , Norris , J . M . , White , D . E . & Moules , N . J . Thematic Anal - ysis : Striving to Meet the Trustworthiness Criteria . International Journal of Qualitative Methods 16 , 1 – 13 ( 2017 ) . [ 25 ] Zaman , L . et al . GEM - NI : A system for creating and managing alternatives in generative design . Conference on Human Factors in Computing Systems - Proceedings 2015 - April , 1201 – 1210 ( 2015 ) . [ 26 ] Gonçalves , F . , Cabral , D . & Campos , P . CreaSenses : Fostering Creativity Through Olfactory Cues . ACM International Conference Proceeding Series ( 2018 ) . BIBLIOGRAPHY 35 [ 27 ] Stolﬁ , A . , Milo , A . , Ceriani , M . & Barthet , M . Participatory musical impro - visations with Playsound . space . Proceedings of the International Web Audio Conference ( 2018 ) . [ 28 ] Koch , J . , Lucero , A . , Hegemann , L . & Oulasvirta , A . May AI ? Design ideation with cooperative contextual bandits . Conference on Human Factors in Com - puting Systems - Proceedings 1 – 12 ( 2019 ) . [ 29 ] Turchet , L . & Barthet , M . An ubiquitous smart guitar system for collaborative musical practice . Journal of New Music Research 48 , 352 – 365 ( 2019 ) . URL https : / / doi . org / 09298215 . 2019 . 1637439 . [ 30 ] Paolocci , G . , Baldi , T . L . , Barcelli , D . & Prattichizzo , D . Combining Wristband Display and Wearable Haptics for Augmented Reality . Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces , VRW 2020 633 – 634 ( 2020 ) . [ 31 ] Graf , M . , Opara , H . C . & Barthet , M . An Audio - Driven System For Real - Time Music Visualisation . AES Convention 150 ( 2021 ) . URL http : / / arxiv . org / abs / 2106 . 10134 . 2106 . 10134 . [ 32 ] Remy , C . , Macdonald Vermeulen , L . , Frich , J . , Biskjaer , M . M . & Dalsgaard , P . Evaluating creativity support tools in HCI research . DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference 457 – 476 ( 2020 ) . [ 33 ] Braun , V . & Clarke , V . Using thematic analysis in psychology . Qualitative Research in Psychology 3 , 77 – 101 ( 2006 ) . Appendix A Quantitative Evaluation : Form An implementation of the CSI questionnaire for two tools performing the same task has been created by the author following the instructions of [ 21 ] . In addition to the standard questions , three more questions are asked at the beginning to know the level of expertise of the user , and two more at the end regarding overall valuation of Freecat and the impact of being able to use Freesound . 36 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 1 / 10 We are conducting research to find out more about the creation of sound ' palettes ' or ' maps ' and how they support creativity . Thank you for participating in this survey ! Freecat is the instrument you will be using , a concatenative synthesizer connected to Freesound . First , play around with Freecat as much as you want , and then answer the following questions . * Required 1 . How familiar are you with audio / music production tools ( such as DAWs and plugins inside them ) ? * Mark only one oval . Not at all A bit Very much 2 . How familiar were you with the term “concatenative synthesis” ? * Mark only one oval . Not at all A bit Very much 3 . How often do you create and / or use sound textures in your musical activity ? * Mark only one oval . Never Sometimes Always 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 2 / 10 Agreement Statements Tool 1 http : / / youtube . com / watch ? v = wjDgiF1AXJw 4 . I would be happy to use Freecat on a regular basis . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 5 . I enjoyed using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 6 . It was easy for me to explore many different ideas , options , designs , or outcomes , using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 3 / 10 7 . I was able to be very creative while doing the activity inside Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 8 . Freecat was helpful in allowing me to track different ideas , outcomes , or possibilities . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 9 . Freecat allowed me to be very expressive . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 10 . My attention was fully tuned to the activity , and I forgot I was using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 11 . I was satisfied with what I got out of Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 4 / 10 12 . I became so absorbed in the activity that I forgot I was using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 13 . What I was able to produce was worth the effort I had to exert to produce it . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree Agreement Statements Tool 2 http : / / youtube . com / watch ? v = wjDgiF1AXJw 14 . I would be happy to use Freecat on a regular basis . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree Using the query - by - four - examples method , we ask you to create a texture of 15 seconds by imitating or getting inspiration from the following sound ( see video below ) . 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 5 / 10 15 . I enjoyed using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 16 . It was easy for me to explore many different ideas , options , designs , or outcomes , using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 17 . Freecat was helpful in allowing me to track different ideas , outcomes , or possibilities . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 18 . I was able to be very creative while doing the activity inside Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 6 / 10 19 . Freecat allowed me to be very expressive . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 20 . My attention was fully tuned to the activity , and I forgot I was using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 21 . I was satisfied with what I got out of Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 22 . I became so absorbed in the activity that I forgot I was using Freecat . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 23 . What I was able to produce was worth the effort I had to exert to produce it . * Mark only one oval . 1 2 3 4 5 6 7 8 9 10 Highly Disagree Highly Agree 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 7 / 10 Paired - factor comparison section 24 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Work with other people . Explore many different ideas , outcomes , or possibilities . 25 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Enjoy using the system or tool . Be creative and expressive . 26 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Work with other people . Become immersed in the activity . 27 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Be creative and expressive . Explore many different ideas , outcomes , or possibilities . 28 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Become immersed in the activity . Enjoy using the system or tool . 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 8 / 10 29 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Be creative and expressive . Become immersed in the activity . 30 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Enjoy using the system or tool . Explore many different ideas , outcomes , or possibilities . 31 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Become immersed in the activity . Produce results that are worth the effort I put in . 32 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Produce results that are worth the effort I put in . Be creative and expressive . 33 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Produce results that are worth the effort I put in . Work with other people . 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 9 / 10 34 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Explore many different ideas , outcomes , or possibilities . Become immersed in the activity . 35 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Explore many different ideas , outcomes , or possibilities . Produce results that are worth the effort I put in . 36 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Produce results that are worth the effort I put in . Enjoy using the system or tool . 37 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Be creative and expressive . Work with other people . 38 . When doing this task , it ' s most important that I ' m able to . . . * Mark only one oval . Enjoy using the system or tool . Work with other people . 01 / 8 / 2021 Comparing sound palettes for Freecat , a Freesound - connected concatenative synthesizer 10 / 10 Final general questions 39 . Omitting design issues ( as Freecat is a prototype ) , how do you like the instrument overall ? Mark only one oval . 1 2 3 4 5 No way Very much 40 . Do you think that being able to use Freesound has had a positive impact on your creation ? Mark only one oval . 1 2 3 4 5 Not at all Very much Appendix B Semi - Structured Interview Guide Questions 1 . Do you think that being able to use Freesound has had a positive impact on your creation ? Can you elaborate on this idea ? [ this is a continuation of the last question in the form ] 2 . Did you get any sense of spatial order in the maps ? Why / Why not ? 3 . Can you tell me things you liked from any of the interfaces / methods ? 4 . Can you describe any clear disadvantage you see in one interface as opposed to the other ? 5 . Which interface better represented the sounds you were imaging / expecting ? Why do you think that ? 6 . Which interface provided more positive surprises ( results you were not expect - ing but you liked ) ? Why do you think that ? 47