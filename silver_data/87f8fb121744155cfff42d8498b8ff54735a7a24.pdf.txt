The Information Society , 20 : 127 – 139 , 2004 Copyright c (cid:1) Taylor & Francis Inc . ISSN : 0197 - 2243 print / 1087 - 6537 online DOI : 10 . 1080 / 01972240490423030 “Go Away” : Participant Objections to Being Studied and the Ethics of Chatroom Research James M . Hudson and Amy Bruckman College of Computing , Georgia Institute of Technology , Atlanta , Georgia , USA In this article we present an empirical study aimed at better understanding the potential for harm when conducting research in chatrooms . For this study , we entered IRC chatrooms on the ICQ network and posted one of three messages to tell participants that we were recording them : a recording message , an opt - in message , or an opt - out message . In the fourth condition , we entered the cha - troom but did not post a message . We recorded and analyzed how subjectsrespondedtobeingstudied . Resultsofaregressionanalysis indicate signiﬁcantly more hostility in the three conditions where we said something than in the control condition . We were kicked out of 63 . 3 % of the chatrooms we entered in the three message con - ditions compared with 29 % of the chatrooms in the control con - dition . There were no signiﬁcant differences between any of these three conditions . Notably , when given a chance to opt in , only 4 of 766 potential subjects chose to do so . Results also indicate signiﬁ - cant effects for both size and the number of moderators . For every 13 additional people in a chatroom , the likelihood getting kicked out was cut in half . While legal and ethical concerns are distinct , we conclude by arguing that studying chatrooms constitutes hu - man subjects research under U . S . law , but that a waiver of consent is appropriate in most cases as obtaining consent is impracticable . Keywords chatrooms , ethics , informed consent , IRB , online research , waiver of consent Learning what will in fact beneﬁt may require exposing persons to risk . The problem posed by these imperatives is to decide when it is justiﬁable to seek certain beneﬁts despite Received 28 May 2003 ; accepted 4 September 2003 . We are grateful to those in the Electronic Learning Communities ( ELC ) research group and the Georgia Tech Institutional Review Board for valuable discussion in trying to conduct this type of research ethi - cally . Thanks to Dave Robertson and Gilad Chen for advice on statistics and Sameer Patil for suggesting ICQ . Special thanks to Charles Ess for comments on an earlier draft . Thanks to Susan Herring , Brenda Danet , and two anonymous reviewers for their comments . Address correspondence to James M . Hudson , College of Comput - ing , Georgia Institute of Technology , Atlanta , GA 30332 - 0280 , USA . E - mail : jhudson @ cc . gatech . edu the risks involved , and when the beneﬁts should be foregone because of the risks . ( Department of Health , Education , and Welfare [ DHEW ] , 1979 , The Belmont Report , section B . 2 ) To determine whether a study involving human sub - jects should be carried out , we must weigh risks and bene - ﬁts ( DHEW , 1979 , The Belmont Report ) . All research has some degree of risk . At minimum , the risks are compara - ble to those encountered in everyday life . At maximum , subjects , especially those in medical studies , may risk their lives . In any study , the degree of risk is weighed against the potential beneﬁt of the study to both the individual and society . To complete this analysis , we must understand the nature of risks involved . Starting in the early 1990s , the Internet grew from a tool used by a small population of specialists to a pop - ular medium . Behavior of Internet users and accompa - nying changes in culture are of great interest to scholars from a wide variety of disciplines . Thoughtful research on this new medium can help us both understand its present and shape its future . However , such research must be conducted ethically , or we risk both harming individu - als and also disturbing the very phenomena we seek to understand . Research on the Internet raises a host of novel ethical challenges ( e . g . , Bassett & O’Riordan , 2002 ; Boehlefeld , 1996 ; Bruckman , 2002 ; Ess , 2002 ; Eysenbach & Till , 2001 ; Frankel & Siang , 1999 ; Herring , 1996 ; King , 1996 ; Schrum , 1997 ; Walther , 2002 ; Waskul & Douglass , 1996 ) . Traditionally , research ethics relies on distinctions such as public versus private spaces , identiﬁed versus anonymous individuals , and published versus unpublished informa - tion . However , online , these categories become blurred ( Bruckman , 2002 ; Eysenbach & Till , 2001 ) . Consequently , it can be difﬁcult to translate our intuitions to the new do - main of Internet research . Despite signiﬁcant efforts from the American Psychological Association ( Kraut et al . , 2004 ) , the American Association for the Advancement of Science ( Frankel & Siang , 1999 ) , and the Association of Internet Research ( Ess , 2002 ) , many questions regarding the ethical conduct of online research remain . 127 128 J . M . HUDSON AND A . BRUCKMAN A host of particularly thorny ethical issues surround research on synchronous text - based computer - mediated communication or “chat . ” Is it ethical to enter a chatroom and record the conversation for research purposes ? Under what circumstances ? Is it necessary to obtain consent from participants ? If so , what kind of consent ? Is it sufﬁcient to announce the researcher’s presence and offer users a way to opt out of participation ? Is it feasible to announce the re - searcher’s presence but only record data if participants type a command to opt in ? Is the process of obtaining consent more disruptive than the actual study ? How should data collected from chatrooms be protected ? Is it necessary to change pseudonyms of participants in written accounts ? Is it acceptable to retain chatroom logs for long periods of time , or should they be coded for target behaviors and then destroyed to protect the privacy of participants ? These are just a few of the difﬁcult ethical questions this new medium raises . These questions of course cannot be answered in the abstract , but must be addressed in the context of a par - ticular set of research questions and methods . For exam - ple , a great deal more care was needed in Sheana Bull and Mary McFarlane’s ( 2000 ) study of sexual behavior stemming from chatrooms catering to homosexuals than in Brenda Danet’s ( 2001a ) study of text - based art in IRC ( Internet Relay Chat ) chatrooms as a new form of folk art . Danet recorded activity in chatrooms in which individuals trade art derived from ASCII characters . In publishing on the subject , she included users’ online pseudonyms un - changed , in order to give them credit for their creative work ( Danet , 2001b ) . In this low - risk situation , not only were careful human subjects’ protections not needed , but it could be argued that such protections would do her sub - jects a disservice by denying appropriate credit ( Herring , 1996 ) . In fact , in follow - up research , Danet’s institutional review board ( IRB ) provided a complete waiver of consent ( Danet , personal communication , 2003 ) . In contrast , Bull and McFarlane recorded chatrooms that typically cater to homosexuals . They were interested in particular in evi - dence of online activity leading directly to risky face - to - face behaviors . Before beginning their study , they ﬁrst ob - tained a certiﬁcate of conﬁdentiality—a legal document granting them the right to refuse to turn over their data even if faced with a court subpoena . After recording chatroom activity , they immediately coded the logs for instances of target behaviors—such as whether individuals made plans to meet face to face , and whether their HIV status was discussed in the course of making such plans . Once the frequency of such behaviors was coded and checked , the original logs were destroyed . These two studies at opposite ends of the risk spectrum necessitated quite different ap - proaches to data management , retention , and publication . In analyzing the ethical issues in any chatroom study , one key piece of information to understand is : How much do users object to being studied when they are aware of the study ? In this article , we address this question empirically . Our intent is by no means to declare any particular type of work ethical or unethical , but simply to contribute con - crete , empirically validated evidence to help researchers and IRBs make informed decisions . Of course , even with full knowledge of how users feel , difﬁcult ethical decisions remain . In our discussion , we raise some of these issues . Even if recording chatrooms is found to be extremely displeasing to users , that does not mean such research may not proceed . In fact , this study itself is an example of one that we could reasonably anticipate would annoy users greatly . However , after careful discussion with our IRB and specifying appropriate precautions to protect subjects , it was determined that the beneﬁts outweighed the risks . Our goal in conducting this research is simply to help others make more informed decisions in planning future research . BACKGROUND In attempting to determine appropriate ethical conduct of Internet - based research , researchers tend to rely on a num - ber of different metaphors for explaining the nature of the Internet . These metaphors , however , lead to different conclusions about whether or not individuals in Internet forums should be treated as human subjects . For some researchers , the Internet is like a public square , and for others , a private living room , a town hall meeting , or a newspaper letters column . Each of these metaphors leads to different ethical conclusions . In a public square , a re - searcher may observe behavior in a generalized way and write about aggregated results . In a private living room , permission of the participants is required for any research . A newspaper letters column does not require permission , but requires appropriate citations . Relying on the metaphor that Internet chat is like a pri - vate space , many researchers take a perspective that indi - viduals in chatrooms should be treated as human subjects . The human subjects approach to Internet research treats postings in online environments not as copyrighted state - ments , but as comments from individual subjects . Storm King ( 1996 ) argues that the same features that make In - ternet communication a worthy area of study also make it easier for a researcher to objectify the Internet - based sub - jects . As such , he proposes that Internet researchers must be cognizant of the fact that online contributors are , in fact , human subjects . When publishing research reports , King suggests that anonymity of both the subjects and the online forum itself are often necessary in order to pro - tect all involved from harm . In this approach to Internet research , it is also necessary to obtain informed consent from the subjects of the research ( Reid , 1996 ; Schrum , 1997 ) . Exceptions occur , but the human subjects approach THE ETHICS OF RESEARCHING CHATROOMS 129 to ethical research assumes informed consent as a default position . In keeping with a tradition of examining the reasonable expectations of potential research subjects ( e . g . , Elgesem , 2002 ; Walther , 2002 ) , Elizabeth Bassett and Kathleen O’Riordan ( 2002 ) have suggested that examining the in - tent of those posting messages on the Internet might in - form these ethical debates . In some spaces , online authors clearly use the Internet as a public forum in which to spread their ideas . Bassett and O’Riordan argue that human sub - jects protections ( i . e . , anonymity , informed consent , etc . ) in these cases would do the authors a disservice and might even constitute unethical behavior . For example , when au - thors use the Internet to promote minority voices , such as alternative versions of newsworthy events , anonymiza - tion reinforces the dominant paradigm from which they are trying to escape . In other spaces , however , authors’ comments clearly suggest that they consider the space to be relatively private . In such cases , human subjects protec - tions might apply . As Bassett and O’Riordan point out , the challenge arises when different stakeholders suggest con - tradictory stances , such as when the operator of an online forum stresses the publicity and seeks to use the forum to promote a political cause while individual users treat it as a private space . In the second author’s previous work , Amy Bruckman ( 2002 ) suggests that the degree of potential harm might dictate how research is conducted and reported . In gen - eral , researchers work with dichotomies such as public versus private and published versus unpublished . Works on the Internet , however , turn these dichotomies into con - tinua . Because these traditional distinctions blur online , she suggests that most online comments are semipub - lished and semipublic . This introduces a new dimension into the ethics of doing Internet research ; there is a new continuum between individuals on the Internet deserving credit for their work and needing anonymity for protec - tion . Bruckman concludes that a careful weighing of each of these dimensions in Internet research should suggest the amount of human subjects protections accorded to online subjects . Coming from a view of online conversations as being like a newspaper letters column , some view online dis - cussions as copyrighted material . In looking at U . S . law , for example , Edward Cavazos and Gavino Morin ( 1994 , pp . 61 – 62 ) note : If a chat participant is capturing the chat transcript , he or she is satisfying the ﬁxing in a tangible medium required by the Copyright Act . . . . Users actively involved in on - line chat sessions probably should not consider their expressions pro - tected unless those expressions are being transcribed , buffe - red , or captured to disk . . . . The moment the writing , typing , or copying occurs , the copyright law covers the situation , giving the speakers immediate protection . Since written materials on the Internet such as tran - scripts of chat sessions are considered copyrighted , they may be studied by academics within the bounds of fair use . Under this particular legal system , authors of such mate - rial do not have to consent to such use , nor do they have the right to withdraw consent . At the same time , however , researchers using such material may not anonymize their subjects in any way . When claiming “fair use , ” academics are legally required to cite their sources . If a researcher claims that consent is not necessary for fair use of ma - terial on the Internet , anonymizing the sources of such material is legally actionable . Cavazos and Morin do note , however , that these legal positions have not been clariﬁed in court . Susan Herring’s ( 1996 ) critique of these arguments holds that they presuppose a speciﬁc research paradigm that excludes other legitimate types of research . In partic - ular , none of these perspectives allows for linguistic re - search where the focus is on the form of the message , not the content . She concludes that research on the Internet is simply too broad to be covered by one set of ethical guide - lines . Rather , each profession needs its own set of guide - lines for dealing with Internet research . Only in this way is it possible for guidelines to account for the unique consid - erations of different approaches to research . Note that this perspective does not account for the fact that Internet re - searchers now often publish in multidisciplinary journals . As such , some minimal ethical guidelines are needed so that these different professions can appropriately talk to one another . The study described in the next sections represents an attempt to systematically examine how potential subjects react to various methods of being studied . While one study cannot provide deﬁnitive answers to these difﬁcult ethical questions , it can provide us with valuable insight . We con - clude by reﬂecting on how these reactions alter the debate on the ethical conduct of research on the Internet . TERMINOLOGY Internet Relay Chat ( IRC ) is a protocol that allows indi - viduals to communicate with one another through realtime text messages . While there are a number of ways to con - nect to IRC , a popular instant messenger client ( ICQ 1 ) provides a web - based interface that many less technologi - cally aware individuals use . A number of chatrooms on any IRC server have a moderator , sometimes called an opera - tor . The moderator has the ability to control many features of conversation in a given chatroom . For our purposes , the most important moderator ability is the ability to kick or boot someone out of the chatroom . When this happens , the individual who has been kicked out will immediately ﬁnd himself or herself disconnected from that chatroom . The moderator can set an additional ban that will keep 130 J . M . HUDSON AND A . BRUCKMAN the booted individual from returning to the chatroom for a given time period . For a number of reasons , bots are often used to aid moderators . Bots , where the name is derived from robots , connect to IRC like any other individual , but they are sim - ply automated software programs that can be controlled by other ( speciﬁed ) individuals . From the perspective of individuals in the chatrooms , bots look like any other indi - vidual ; there is nothing that distinguishes bots from people . When an authorized user sends a command to the bot , it will perform the speciﬁed action . Bots can also be pro - grammed to perform various automated tasks . METHOD To understand how potential participants react to partic - ipating in online studies , we experimentally studied how individuals in online chatrooms reacted to a variety of con - ditions . We designed a study where we entered a number of online chatrooms , informed the participants that we were recording them to study language use , and recorded how individuals responded . Speciﬁcally , we examined partic - ipants in chatrooms on ICQ Chat . 2 Since ICQ Chat uses IRC servers , we were able to conduct this study without worrying about proprietary software ( such as MSN Chat ) . Also , ICQ Chat’s web - based interface offered a population that is generally less technologically aware than standard IRC populations . Because of this web - based interface , we have reason to believe that individuals using ICQ Chat are more representative of the general population of Internet users than those on most other IRC servers . First , we downloaded a list of the available chatrooms each evening at 9 : 50 p . m . 3 On any given day , the mean size of available chatrooms on most IRC networks tends to be positively skewed : There are a large number of small chatrooms , but fewer large ones . Figure 1 illustrates the distribution of chatrooms on one typical day in our study . Note that a couple of the larger chatrooms—those with more than 100 participants—are not pictured for the sake of visual clarity . In order to ensure that we adequately covered the range of potential chatroom sizes , we arbi - trarily divided the available chatrooms into four buckets : very small ( 2 – 4 participants ) , small ( 5 – 10 participants ) , medium ( 10 – 29 participants ) , and large ( 30 or more par - ticipants ) . This means we sampled a much larger percent - age of the available large chatrooms than of the available smaller chatrooms . Using these buckets , we randomly chose 16 chatrooms from each . Each set of 16 chatrooms was further ( ran - domly ) subdivided into groups of 4 . Each group of four was assigned to one of our recording conditions . In each condition , we varied the message we said to the chatroom . In the No Message condition , we simply entered using the nickname “Chat Study” and said nothing . In the Recording FIG . 1 . Distribution of chatrooms on a typical day at 10 : 00 p . m . Note : A few chatrooms with more than 100 par - ticipants have been removed from this ﬁgure for the sake of visual clarity . Message condition , we entered as “Chat Study” but an - nounced that we were recording the chatroom for a study . The Opt In Message and Opt Out Message conditions were similar , but allowed individuals to choose to opt in or opt out of the study by typing a response . The exact messages used are listed in Table 1 . Once chatrooms were randomly assigned to conditions , we entered the chatrooms ( in a random order ) and con - ducted the study . Upon joining a room , we waited 1 minute before posting our message . Then , we waited another 5 minutes before leaving the chatroom . If we had not been kicked out of the chatroom by this time , we posted the following message before exiting : This research is actually not about language use . Rather , it is designed to study how individuals in chatrooms react to researchers studying them . Further information is available at http : / / www . cc . gatech . edu / elc / chatstudy . Thanks ! By entering chatrooms two at a time and staggering our conditions , we were able to test 64 chatrooms within a 1 - hour period ( 10 : 00 p . m . – 11 : 00 p . m . ) . For each chatroom , we noted the number of partici - pants at the time we entered , whether or not a moder - ator was present , whether or not conversation occurred , and whether or not we were kicked out of the room . If a chatroom did not have a moderator or we did not observe conversation , it was removed from the study prior to data analysis . Running this study each evening from 1 March until 14 March 2003 , 4 we sampled 525 chatrooms . Of these , we retained the 137 chatrooms with moderators and active conversation for our data analysis . Figure 2 presents a rough breakdown of the topics under discussion , based on the name of the chatroom . We later present both quanti - tative and qualitative analyses of how individuals in these chatrooms responded to us . THE ETHICS OF RESEARCHING CHATROOMS 131 TABLE 1 Announcement messages Condition Message broadcast No message None Recording message We are researchers recording this chatroom for a study on language use in online environments . For questions or comments , email study @ mail . chatstudy . cc . gatech . edu . Thank you ! Opt out message We are researchers recording this chatroom for a study on language use in online environments . If you don’t want to be recorded , please whisper “Chatstudy opt out” to us . For questions or comments , email study @ mail . chatstudy . cc . gatech . edu . Thank you ! Opt in message We are researchers and would like to record this conversation for a study on language use in online environments . If we may record you , please whisper “Chatstudy volunteer” to us . For questions or comments , email study @ mail . chatstudy . cc . gatech . edu . Thank you ! Note . The “study on language use” was chosen as a speciﬁc innocuous study . Ethical Issues Before we delve into the results , there were a number of ethical issues that arose in the design and conduct of this study . In essence , this is a deceptive study conducted on 2260 subjects 5 without their consent . In conducting this research , we decided to work under the most restrictive of the proposed ethical stances—the human subjects model . As such , we sought permission from Georgia Tech’s Insti - tutional Review Board ( IRB ) for conducting this research . Our IRB had three primary concerns in reviewing this re - search : the use of deception , the lack of consent , and the potential for harm . Responding to concerns over the potential for harm is quite difﬁcult in a study designed to evaluate the potential for harm in studies like it . Since most reported cases of signiﬁcant harm as a result of this type of research have involved conversations about sensitive topics ( Bassett & O’Riordan , 2002 ; Reid , 1996 ) , we agreed to review all po - FIG . 2 . Distribution of chatrooms in our study . tential chatrooms before entering them to ensure that sensi - tive discussions seemed unlikely . While we never formally deﬁned what we meant by “sensitive topics , ” we used emo - tional support groups such as “breast cancer survivors” as the prototypical discussions to avoid . In conducting the study , we encountered no such chatrooms . While we do not provide speciﬁc chatrooms names here , Figure 2 shows the general types of chatrooms encountered . To further minimize harm , we agreed to limit the scope of our study to only comments directly pertaining to us . Speciﬁcally , after reading through the transcripts once , we removed all comments that were not directed to or about us . All data analysis was performed on these cleaned transcripts . Generally in deception - based research , subjects consent to participate in a research study , but are deceived about the exact nature of the research ( e . g . , Milgram , 1974 ; Latan´e & Darley , 1970 ) . When this is justiﬁed , subjects should be debriefed to the extent possible about the true nature of the research . To do so , we pointed subjects to a web page with information about our study before we left the chatroom . We decided , with the help of our IRB , that we would not debrief chatrooms where we had been kicked out . Decisions about debrieﬁng in this type of study involve balancing subjects’ right to be debriefed with their right to be left alone . Since kicking us out of the chatroom would indicate a strong desire to be left alone , we gave this right greater weight . We felt that the additional disruption would cause more harm than the beneﬁt that debrieﬁng provided . Our study had an additional challenge in that we were not getting consent from subjects to participate in the study at all . Based on the U . S . federal regulations governing research , informed consent may be waived only when four conditions are met : 1 . The research involves no more than minimal risk to the subjects . 2 . Thewaiveroralterationwillnotadverselyaffecttherightsandwelfareofthesubjects . 132 J . M . HUDSON AND A . BRUCKMAN 3 . The research could not practicably be carried out without the waiver or alteration . 4 . Whenever appropriate , the subjects will be provided with additional pertinent information after participation ( 45 CFR 46 . 116 . d ) . After much discussion , our IRB felt that we met all four of these conditions and qualiﬁed for a waiver of informed consent . More discussion on waivers of consent is provided in our data analysis . A Note on Generalizability Like all research studies , we must deal with a number of questions of generalizability . Do our ﬁndings from ICQ Chat generalize to other chat environments such as EFnet , DALnet , or MSN Chat ? How might our ﬁndings from chat environments generalize to other online environments ? Do our methods generalize to communities where researchers are already a member of the community being studied ? In choosing a speciﬁc site for this research , we wanted to meet several criteria . We wanted a chat environment with a large enough base of users to obtain a reasonable sample size . At the same time , however , we wanted the par - ticipants’ backgrounds to be as similar to general Internet users as possible . Since IRC users tend to be more techno - logically savvy than mainstream Internet users , this limited us to ICQ Chat , MSN Chat , and Yahoo ! Chat . Since it was important for us to automate our data collection , we had to avoid chat systems with proprietary chat software . This left us with ICQ Chat . The similarities between all of these text - based chat environments , however , lead us to believe that ﬁndings from ICQ Chat will likely largely generalize to other such spaces . We believe that our ﬁndings will likely generalize to other types of online environments to the extent that they are similar to chat environments . The Internet is not mono - lithic ; many different types of online spaces exist . Some focus more on chat - style discussions but use avatars ( e . g . , the Palace , EverQuest , Ultima Online ) or audio instead of text ( e . g . , X - box Live ) . Some environments remain in text , but do not feature synchronous interaction ( e . g . , news - groups , message boards ) . Others contain more identifying information such as pictures ( e . g . , personal webpages ) , personal stories ( e . g . , blogs ) , or video ( e . g . , CUSeeMe ) . TABLE 2 Descriptive statistics of conditions Broadcast message n Mean size Minimum size Maximum size Standard deviation Kicked frequency None 28 17 . 36 2 139 27 . 542 29 % Recording 34 16 . 62 2 99 21 . 061 56 % Opt out 36 12 . 31 2 46 10 . 485 72 % Opt in 39 19 . 64 2 201 36 . 604 62 % While we expect our ﬁndings to generalize to some of these environments , we cannot predict to what extent without further studies . There are also questions about how well this research method will extend to other means of data collection . In anthropological work , there are two basic types of research strategies : emic and etic ( Headland et al . , 1990 ) . In emic research , it is the interpretation of those being studied that is most valued ( Rosaldo , 1989 ) . Often , emic research oc - curs in online environments when a researcher realizes that there is something scientiﬁcally interesting about a community he or she is part of . In this case , the researcher approaches studying the community as an insider . In etic research , however , the interpretation of the scientiﬁc com - munity is more valued than that of the community mem - bers ( Rosaldo , 1989 ) . Researchers from this perspective approach a community as an outsider . They announce their afﬁliation as researchers from the outset of their research . In the study described here , we are engaging in the most prototypical type of etic research . How these ﬁndings gen - eralize to emic methods is debatable . Studies conducted by true community insiders still raise a host of ethical is - sues , but those issues are likely to differ substantially from those described in this paper . Once again , more research is needed to sort out all of these complicated ethical issues . RESULTS The results of this study are divided into two parts . In the ﬁrst section , we perform a quantitative analysis of the fac - tors that inﬂuence whether or not we were kicked out of a chatroom . The second section presents a more qualita - tive analysis of comments to or about us . Table 2 presents descriptive statistics about each of our conditions . A one - way analysis of variance ( ANOVA ) analysis on the av - erage size of a chatroom in each condition revealed that there were no signiﬁcant differences between the condi - tions ( F ( 3 , 133 ) = 0 . 513 , p = . 674 ) . Quantitative Analysis To analyze which factors contributed to whether or not we were kicked out of the chatrooms , we conducted a hierarchical logistic regression analysis . Our dependent THE ETHICS OF RESEARCHING CHATROOMS 133 TABLE 3 Contrast coding for broadcast message Contrast 1 : Contrast 2 : Contrast 3 : Broadcast No message Announce and opt out Announce message vs . message vs . opt in vs . opt out None 1 0 0 Recording − 1 / 3 1 / 2 1 Opt out − 1 / 3 1 / 2 − 1 Opt in − 1 / 3 − 1 0 variable was whether or not we were kicked out of the chatroom . ( A “1” indicated that we were kicked out . ) The ﬁrst step of the analysis looked at possible order effects based on the day that we collected data . Since this study was spread over 2 weeks , this step attempted to control for cross - pollution that might result from word of our pres - ence getting around . In the second step of the analysis , we introduced two additional variables : the size of the chat - room and the number of moderators in the chatroom . With the number of moderators , we were interested in measur - ing the number of individuals who could potentially kick us out of the chatroom . However , since chatrooms often have bots with operator status and individuals who can use these bots to obtain operator status , this is an imper - fect measure . In the ﬁnal step of the regression analysis , we introduced our experimental condition in the form of three contrast coded variables . These contrasts are listed in Table 3 . Recall that contrast coding of four experimental conditions requires three orthogonal contrasts . Therefore , while our third contrast ( between the recording message condition and the opt out condition ) is not a hypothesis that we were explicitly interested in , it is required for this type of statistical analysis . Table 4 presents our correlation matrix . Table 5 presents the results of our analysis . Results from this analysis indicate that both size ( Wald ( 1 ) = 5 . 407 , p = . 020 ) and the number of mod - TABLE 4 Correlation matrix Number of Condition Condition Condition Order Size moderators Contrast 1 Contrast 2 Contrast 3 Order 1 . 000 Size 0 . 465 1 . 000 Number of moderators 0 . 012 − 0 . 287 1 . 000 Condition Contrast 1 − 0 . 009 0 . 124 − 0 . 206 1 . 000 Condition Contrast 2 0 . 047 0 . 008 − 0 . 030 − 0 . 019 1 . 000 Condition Contrast 3 − 0 . 123 − 0 . 007 − 0 . 110 0 . 038 − 0 . 025 1 . 000 Note . All correlations are relatively small . Therefore , multicollinearity does not present a problem in this analysis ( Pedhazur , 1997 ) . erators ( Wald ( 1 ) = 7 . 491 , p = . 006 ) signiﬁcantly pre - dicted when we were kicked out of chatrooms . Brieﬂy , the likelihood of being kicked out of a chatroom decreased as the number of people present increased . We were twice as likely to be kicked out of a room with 5 people than a room with 18 people , holding other factors constant ; for every 13 additional people in a chatroom , the chances of being kicked out were cut in half . Conversely , increased numbers of moderators lead to increased chances of being kicked out . In addition , our experimental conditions are signiﬁcant predictors ( χ 2 ( 3 , 137 ) = 15 . 554 , p = . 001 ) over and above all other variables . The No Message condition is signiﬁ - cantly different from the other three conditions ( Contrast 1 : Wald ( 1 ) = 12 . 286 , p < . 001 ) , but there were no other differences found between conditions . In other words , it did not matter what we said . Any indication of recording the chatroom signiﬁcantly increased our likelihood of be - ing kicked out . In fact , holding other variables constant , we were nearly four times more likely to be kicked out when we said something . Qualitative Analysis When We Were Kicked Out . In IRC , when an operator chooses to kick someone out of the chatroom , he or she has the option of providing additional text to explain why that decision was made . Since everyone in the chatroom can see this message , any text is written as much for the members of the chatroom as it is for the individual kicked out . When we examine the messages explaining why we were kicked out in this study , we see a number of gen - eral themes : prohibitions against spamming , opposition to being studied , general requests to leave , and insults . Of the 77 times that we were kicked out , 13 messages ( 17 % ) explicitly referred to our study as spamming : (cid:1) “You’re being banned for 43200 minutes , for spamming . ” 134 J . M . HUDSON AND A . BRUCKMAN TABLE 5 Regression results Step 1 : Controlling for Order Effects . Did the day we ran the study on affect whether or not we were kicked out of the rooms ? Effects were found not signiﬁcant Variable B Wald Exp ( B ) Percentage correct (cid:9)χ 2 ( 1 ) χ 2 ( 1 ) Order 0 . 072 2 . 136 1 . 075 62 . 8 % 2 . 180 2 . 180 Step 2 : Controlling for Size and Moderators . Did the size of the chatroom affect whether or not we were kicked out of the rooms ? Did the number of moderators affect whether or not we were kicked out ? Effects for both cases were found signiﬁcant Variable B Wald Exp ( B ) Percentage correct (cid:9)χ 2 ( 2 ) χ 2 ( 3 ) Order − 0 . 002 0 . 001 0 . 998 Size − 0 . 048 ∗ 5 . 348 ∗ 0 . 0953 ∗ Number of moderators 0 . 090 ∗ 5 . 502 ∗ 1 . 094 ∗ 67 . 2 % 16 . 202 ∗∗ 18 . 381 ∗∗ Step 3 : Evaluating Message Conditions . Were there any differences between any of our conditions ? Signiﬁcant effects were found for the difference between saying something and saying nothing , but no other differences existed Variable B Wald Exp ( B ) Percentage correct (cid:9)χ 2 ( 3 ) χ 2 ( 6 ) Order 0 . 008 0 . 016 1 . 008 Size − 0 . 055 ∗ 5 . 407 ∗ 0 . 947 ∗ Number of moderators 0 . 113 ∗ 7 . 491 ∗ 1 . 119 ∗ Condition Contrast 1 − 1 . 335 ∗∗ 12 . 286 ∗∗ 0 . 263 ∗∗ Condition Contrast 2 0 . 013 0 . 002 1 . 013 Condition Contrast 3 0 . 106 1 . 684 0 . 700 69 . 3 % 15 . 554 ∗∗ 33 . 936 ∗∗ Note . Signiﬁcance : ∗ p < . 05 ; ∗∗ p < . 001 . (cid:1) “Go Advertise Somewhere Else” (cid:1) “do not advertise here” (cid:1) “no spamming” (cid:1) “spam” (cid:1) “Don’t fucking advertise” (cid:1) “spam” (cid:1) “lame ass spamm . . . get a life” (cid:1) “No spamming . ” (cid:1) “don’t spam” (cid:1) “no spammers thnx” (cid:1) “Advertisment Kick (cid:5) No advertising in # (cid:6) deleted (cid:5) ” (cid:1) “no spam ! ” Note that each chatroom only saw our message once . Any suggestion of “spam” comes from either the con - tent or length of our message . Herring’s ( 1999 ) research on one chat server , for example , suggests that most cha - troom messages are signiﬁcantly shorter than the one we posted . Ten other chatrooms ( 13 % ) explicitly voiced opposition to being studied : (cid:1) “no” (cid:1) “how bout no” (cid:1) “no , thank you ! ” (cid:1) “we dont do studies” (cid:1) “No studying” (cid:1) “No , dammit ! ! ” (cid:1) “This is a private room , no studies needed” (cid:1) “No thanks , we gave at the ofﬁce . ” (cid:1) “study somewhere else” (cid:1) “That behaviuor is not allowed in here - You can leave now ! ! ” For these chatrooms , it is clear that the concept of being studied was antagonistic . The comments explicitly express a desire not to be studied . Several kick messages expressed a desire for us to leave the room : (cid:1) “go away ! ! ! ! ! ! ! ! ! ” (cid:1) “go away , ” (cid:1) “bye bye dont bother us” (cid:1) “You are frightening our customers , we must ask you to leave” (cid:1) “Bye ! ” (cid:1) “I SAID SHOO” (cid:1) “soo long duud” THE ETHICS OF RESEARCHING CHATROOMS 135 Others simply offered a variety of insulting remarks : (cid:1) “Would you like fries with that ? ” (cid:1) “oh please . . . u can kiss my ass : ) ” (cid:1) “Excuse me . . . I’d like to ASS you a few ques - tions ! ! ! ” (cid:1) “ . . . study this . . . ” (cid:1) “ . . . and there was much rejoicing . . . ” (cid:1) “Yo momma so ugly she turned Medusa to stone ! ” (cid:1) “I’m only doing this because I care” (cid:1) “Quit ﬂappin your lips , know your role beeyatch” (cid:1) “Talk to the foot ! ” (cid:1) “Oh ! Oh ! Kick me again ! - tempban 1 hr” (cid:1) “A Fast One , Like It ? ! ? ! ” (cid:1) “Boot to the head ! ” The remaining comments were simply descriptive ( e . g . , “Chat Study is banned ( u are not welcome or wanted byessss ) ” ) or irrelevant ( e . g . , “I’m too lazy to give you a real kick message . ” ) . When We Were Not Kicked Out . Of the 60 times that we were not kicked out of the chatrooms , 20 ( 33 % ) of them were in the No Message condition . In most of these cases , the participants gave no indication that they were aware of our study . Sometimes individuals greeted us , but usually we were ignored . In the 40 cases where subjects were aware that we were studying them , however , we only noted one pattern : Trivia chatrooms tend not to kick us out . In these chatrooms , a bot asks trivia questions for the audience of participants to answer . The bot is able to de - termine who gets the questions right and award the appro - priate points . Eight of the 11 trivia chatrooms did not kick us out . Of these , however , three were in the No Message condition . While this is far from conclusive , it suggests that the attitudes of participants in trivia chats might be somewhat different from those in other chatrooms . Opting In and Opting Out . Based on the results from the Opt In and Opt Out conditions , there is little reason to believe that these are viable ways of conducting research . In the Opt Out condition , we were kicked out of the chat - rooms 72 % of the time . With Opt In , it was 62 % of the time . ( There is no signiﬁcant difference between these two con - ditions . ) Of the 443 individuals who could have responded in the Opt Out condition , only two individuals opted out . A few others , however , did express what might be called a desire to opt out ( e . g . , “hey chat fuk off , ” “yeah up urs chat - study ! ! ” ) . Of the 766 individuals in the Opt In condition , only four chose to do so . Even in this condition , some indi - viduals expressed strong disagreement with the possibil - ity of being recorded ( e . g . , “please leave Chat Study u do not have permission . . . now all we need is for Chat Study to fuck Off . ” ) . For the most part , however , the negative comments we received in these two conditions were less frequent and less vehement than those we received in the Recording condition ( e . g . , “ (cid:6) deleted (cid:5) kicks Chat Study’s ass so hard . . . . Chat Study will be shitting out of it for - head for a week ! ” , “Hey Chat Study dont you ever talk to me like that again you fucking ﬂaccid , nasty , skank ugly , idiotic no brained , small dicked , stinking nasty pimp daddy wannabe , go wave that limp nasty scab encrusted dick somewhere else bitch ! ” ) . DISCUSSION Based on this study , we can safely conclude that individ - uals in online environments such as chatrooms generally do not approve of being studied without their consent . The vehement reaction of many in our study indicates that they object to being studied . Further , when given the option to opt in or opt out of research , potential subjects still object . The fundamental limitation of these data , however , is that we cannot distinguish between those who are opposed to being studied and those who are opposed to the consent process . In some of the kick messages , there’s an indi - cation that subjects were opposed to being studied ( e . g . , “This is a private room , no studies needed” ) . On the other hand , the high level of hostility in the Opt In condition suggests that the consent process caused some of the re - sponse we observed . We should note that an alternative explanation holds that the potential subjects in the Opt In condition ( correctly ) did not trust us to record them only with explicit consent . Further research is needed to be able to distinguish between these confounds . These data raise a number of tricky questions . What ex - actly do subjects’ reactions indicate about their thoughts or feelings ? Even if we could say that subjects perceived harm in this study , what should we do about it ? We cannot know based on solely this study . Without further research , the an - swers are disputable . We can , however , say that these data suggest it is impracticable to obtain consent for studying behavior in chatrooms . In conditions where we informed subjects of our study , they kicked us out of the chatrooms nearly two - thirds of the time . Regardless of whether we were kicked out of the chatroom , many individuals reacted with hostile statements . When given the option to opt in to our study , only 4 individuals out of 766 potential sub - jects chose to do so . Opting in to the study—the closest analog to traditional informed consent—was clearly not viable in this study . While we cannot draw conclusions from one study , these results suggest that obtaining con - sent for studying online chatrooms is impracticable . Of course , further research that manipulates many of the de - tails of this study is necessary to understand the nuances involved in obtaining consent in this type of environment . This leads us to the question : If subjects are not aware that a researcher is recording the conversation in a chat - room , is there still harm ? A teleological perspective such 136 J . M . HUDSON AND A . BRUCKMAN as utilitarianism holds that no harm has been done ( Mill , 1998 ) . The subject unaware of research cannot feel dis - rupted or harmed . Therefore , the beneﬁts of the situation outweigh the potential for harm . It is important to note that this line of ethical reasoning hinges on the ( arguably tenu - ous ) assumption that subjects will never become aware of the research . A more deontological perspective holds that there are certain rights that are fundamental ( Kant , 1981 ) . As The Belmont Report ( DHEW , 1979 ) states : Respect for persons requires that subjects , to the degree that they are capable , be given the opportunity to choose what shall or shall not happen to them . . . . An agreement to partici - pate in research constitutes a valid consent only if voluntarily given . ( Part C . 1 ) A violation of these rights , whether or not the subject is aware of the violation , constitutes harm . Therefore , violat - ing a subject’s right to consent to participate in a study is harm even if the subject is unaware that the right has been violated . Tied in with this question , we must ask about the ethics of harming potential subjects through the consent process . Our data indicates that chatroom participants kicked us out roughly two - thirds of the time when we attempted to obtain informed consent . Which is the greater harm—annoying two - thirds of potential subjects or not obtaining consent ? Once again , this is a difﬁcult question where reasonable people can disagree . While we cannot seek to solve these ethical problems in this article , the results of this study lead us to believe that research in preexisting chatrooms can be conducted most productively when subjects are unaware of the study . In - dividual researchers must decide for themselves whether or not it is ethically right to do so . Given this conclusion , however , there are three ways under the U . S . 6 regulations governing academic research that we can go about doing research without the consent of potential subjects : ( a ) De - termine that the research is not human subjects research , ( b ) determine that the research is exempt from IRB over - sight , or ( c ) convince an IRB to issue a formal waiver of consent . As we will show , the ﬁrst two of these approaches are problematic . Assuming that a researcher has decided it is ethically appropriate to conduct a given study without obtaining subjects’ consent , we conclude that obtaining a waiver of consent from an IRB is the most appropriate way to conduct chatroom research under U . S . regulatory law . In exploring the issue of consent , we should also con - sider appropriate means of data protection . Should log ﬁles be anonymized or not ? Should they be kept at all ? For how long ? Are ethnographic - style ﬁeld notes more appro - priate ? Certainly , there is no one answer , but these issues affect the degree of potential harm . Different levels of data protection are required for different studies depending on both the sensitivity of the discussion and the research ques - tions asked . As we discuss the human subjects issues next , we highlight some appropriate types of data protection . It is our belief that , with few exceptions , chatroom re - search classiﬁes as human subjects research . The federal guidelines deﬁne a human subject as : Human subject means a living individual about whom an investigator ( whether professional or student ) conducting research obtains : ( 1 ) Data through intervention or interaction with the indi - vidual , or ( 2 ) Identiﬁable private information . ( 45 CFR 46 . 102 . f ) Research on chatrooms becomes human subjects research as soon as the researcher interacts with the participants . Clearly , this includes any form of participant observa - tion . Even without interaction , though , most observation of chatrooms is human subjects research because the log - ging of conversations generally involves collecting identi - ﬁable private information . The researcher doing this type of work collects pseudonyms and , potentially , IP addresses of each participant . The American Association for the Ad - vancement of Science ( AAAS ) report on online research points out that pseudonyms both function as real names and often can be linked to real names ( Frankel & Siang , 1999 ) . While some researchers debate the ease with which pseudonyms and real names can be linked , it is hard to know a priori the difﬁculty of such linking . Likewise , IP addresses can often be traced back to individual comput - ers ( Nosek et al . , 2002 ) . In fact , new federal regulations on the protection of health information ( HIPAA ) specif - ically deﬁne IP addresses as identifying information ( 45 CFR 160 . 514 . b . 2 . i . O ) . It is reasonable to assume that this same deﬁnition would be applied to other types of research . Therefore , it is our belief that this information does consti - tute “identiﬁable private information . ” As such , observa - tional research on chatrooms constitutes human subjects research . It is important to note that the deﬁnition of human sub - jects research does not consider the nature of the research questions being asked . In fact , the speciﬁc research ques - tions are irrelevant for determining if a project constitutes human subjects research . Note that the formal deﬁnition of “research”—“a systematic investigation . . . designed to develop or contribute to generalizable knowledge” ( 45 CFR 46 . 102 . d ) —does not deal with the nature of the spe - ciﬁc research questions either . This issue , however , is con - sidered in determining the beneﬁts and risks of a study when considering the possibility of exemption or waivers of consent . For human subjects research , it is often possible for an IRB to declare research exempt from IRB oversight . Of the possible categories for exemption , one is relevant to this type of research : THE ETHICS OF RESEARCHING CHATROOMS 137 Research involving the use of educational tests ( cognitive , diagnostic , aptitude achievement ) , survey procedures , inter - view procedures or observation of public behavior , unless : ( i ) Information obtained is recorded in such a manner that human subjects can be identiﬁed , directly or through identiﬁers linked to the subjects ; and ( ii ) any disclosure of the human subjects’ responses outside theresearchcouldreasonablyplacethesubjectsatriskofcriminalorcivilliabilityorbedamagingtothesubjects’ﬁnancialstanding , employability , or reputation . ( 45 CFR 46 . 101 . b . 2 , emphasis added ) Note that decisions regarding exemption are the sole purview of the IRB and should not be made by researchers alone . In general , this exemption will not apply to chatroom research since the potential for harm is unclear . When the topics of discussion online are sensitive , the poten - tial for harm is clear and strong data protection measures appropriate . In others , though , harm tends to arise in unex - pected ways . For example , records of an online ﬂirtation may be subpoenaed in a divorce case . While the poten - tial for harm can never be fully determined in advance , the question should be discussed with the IRB and appro - priate data protection should be considered . Researchers interested in general behavioral questions might keep tran - scripts for only a short time period while ﬁeld notes are made . Researchers interested primarily in the form of mes - sages might want to remove identiﬁers from the transcript . Speciﬁc details are tricky and should be discussed with the IRB . The American Heritage Dictionary of the English Lan - guage ( 2000 ) deﬁnes privacy as “the state of being free from unsanctioned intrusion . ” While chatrooms are con - sidered by many to be public spaces , this study provides ev - idence that many participants consider them private spaces , which inﬂuences the potential for harm ( King , 1996 ) . Clearly , many subjects felt that our presence as researchers in the chatroom constituted “unsanctioned in - trusion . ” As Eysenbach and Till ( 2001 ) hypothesized , the signiﬁcance of size in our regression analysis indicates that individuals in smaller chatrooms are more likely to perceive the space as private than those in larger chat - rooms . While smaller chatrooms are publicly accessible , research methods should account for these greater feelings of privacy . 7 Chatrooms are publicly accessible spaces , but researchers must be sensitive to subjects’ perceptions of privacy when choosing appropriate research methods . The ﬁnal potential harm that researchers and IRBs should discuss is the possibility of minors as research sub - jects . In chatrooms , it is usually difﬁcult or impossible to ascertain the age of potential research subjects . Com - bined with the growing number of children and teenagers using the Internet , this implies that often minors will be involved in chatroom research . Although the name of a chatroom might give some indication about the expected age of the participants , there is usually no clear way to exclude minors from chatroom research . Since research involving minors generally requires more stringent subject protection , researchers and IRBs should carefully discuss the implications of minors in an online study . Given this list of challenges in conducting Internet re - search , most IRBs will likely feel uncomfortable giving exemption from oversight . Researchers will often need to obtain a waiver of consent to conduct research in chat - rooms without the participants’ knowledge . As we dis - cussed earlier , waiving informed consent requires that four conditions be met by the research : 1 . The research involves no more than minimal risk to the subjects . 2 . Thewaiveroralterationwillnotadverselyaffecttherights and welfare of the subjects . 3 . The research could not practicably be carried out without the waiver or alteration . 4 . Whenever appropriate , the subjects will be provided with additional pertinent information after participation . ( 45 CFR 46 . 116 . d ) A researcher requesting a waiver of informed consent will need to explicitly deal with each of these four conditions . The results of this study provide speciﬁc evidence that most studies in chatrooms could not be practicably carried out without a waiver of consent . Note that IRBs grant - ing waivers of consent will require regular review of the protocol . Typically , IRBs will require annual review—the maximum time allowed by U . S . regulations . It is possi - ble , however , for IRBs to require shorter review cycles . In this particular study , for example , the Georgia Tech IRB required that we submit information to review every three months . When obtaining a waiver of consent for sensitive dis - cussions , the most stringent data protection will be neces - sary . If researchers need to maintain transcripts of online conversations , such as in linguistics studies , it will be nec - essary to remove all identifying information as soon as possible . When exact transcripts are not necessary , how - ever , researchers might maintain the transcripts for a short period of time while documenting ethnographic - style ﬁeld notes ( e . g . , Bull & McFarlane , 2000 ) . After the notes are written , the transcripts can be destroyed . An alternative approach is to create a chatroom speciﬁcally for research purposes ( e . g . , Hudson & Bruckman , 2002 ) . Creating a new chatroom allows researchers to set expectations so that subjects are aware of being studied . Since there is a range of ethically defensible responses , depending on the details of the study design , potential participants , etc . , dis - cussions between researchers and the IRB can help clarify some of the potential issues and their resolutions . 138 J . M . HUDSON AND A . BRUCKMAN CONCLUSION The ﬁndings of this study suggest that individuals in cha - trooms react with hostility when they are aware of being studied . In the three conditions where subjects were ex - plicitly aware of our study , we were kicked out of 63 % of the chatrooms . When subjects only had our name ( “Chat Study” ) as evidence of our research , however , we were only kicked out of 29 % of the chatrooms . There were no signiﬁcant differences in being kicked out depending on what we speciﬁcally said . Notably , when given the chance to opt in , only 4 out of 766 potential individuals chose to do so . Results also suggest that the level of perceived privacy in chatrooms varies based on the size of the chatroom . In smaller chatrooms , we experienced signiﬁcantly greater hostility than in larger chatrooms . In fact , for every 13 ad - ditional individuals in the chatroom , the chances of being kicked out were cut in half . Further research is necessary to understand the source of this perception of privacy—for example , issues of control , insider – outsider dynamics , or other alternative explanations . These ﬁndings lead to the conclusion that obtaining con - sent in investigating chatroom environments is imprac - ticable . This conclusion , however , raises difﬁcult ques - tions : Is it ethically right to study chatroom participants without their consent ? Is it right to annoy / disturb signif - icant numbers of participants in order to obtain consent from a few ? The answers are not clear . Different ethi - cal frameworks lead to different conclusions . For exam - ple , a utilitarian framework weighs the beneﬁts and harms of a given course of action . If the subject will not ex - perience any concrete harm , the beneﬁts ethically justify carrying out the research without a subject’s consent . A deontological framework , however , holds that individuals have certain rights that cannot be violated without caus - ing harm . Even though the subject is unaware of the vi - olation , conducting research without his or her consent causes harm . The challenge in doing ethical research often involves making difﬁcult choices about competing ethical claims ( DHEW , 1979 , The Belmont Report ) . Is it ethi - cally acceptable to forgo an individual’s right to consent to research in order to further scientiﬁc understanding that might provide many beneﬁts ? Competing ethical claims make this a difﬁcult issue . In offering guidelines for re - solving these difﬁcult ethical dilemmas , The Belmont Re - port ( DHEW , 1979 ) takes an explicitly utilitarian perspec - tive , urging researchers to weigh the potential risks and beneﬁts of any given research project on a case - by - case basis . While we cannot answer these questions here , one thing seems clear : the details matter . When researchers discuss these types of studies with their IRBs , they must keep in mind several important questions : (cid:1) Consent : Is there reason to believe that obtaining consent will be difﬁcult ? Will the process of re - questing consent itself cause harm ? Is it possible to obtain consent in some other way ( e . g . , create a special chatroom explicitly for the study ) ? (cid:1) Harm : What are the potential harms in conducting the study ? What if someone links a subject with this study ? Will this study deal with sensitive top - ics ( e . g . , health support , illegal activities , etc . ) ? Is there reason to believe that children might be subjects ? (cid:1) Data protection and retention : How long are data records maintained ? Who will have access to these records ? (cid:1) Anonymization : What types of identiﬁers exist in the data record ? Real names ? Pseudonyms ? IP ad - dresses ? Will the researchers remove these iden - tiﬁers before data analysis ? If so , how long will it take before identiﬁers are removed ? (cid:1) Credit : Are the subjects likely to deserve or desire credit for their work ? Will subjects feel their copy - right has been violated if they are anonymized in research publications ? Answers to these questions inﬂuence the potential for harm in any given study . As such , researchers and IRBs must carefully consider these issues . In this article , we have provided evidence that it is prob - ably infeasible to study preexisting chatrooms as an out - sider while also obtaining informed consent from the par - ticipants . This offers evidence that waivers of consent may be appropriate for this type of research , provided ( 1 ) that the other criteria for waivers of consent are met and ( 2 ) that the researcher decides that research without consent is eth - ically defensible . When an IRB is considering granting such a waiver , however , it is important to carefully con - sider issues of data protection and retention . Since there are no easy answers in obtaining and analyzing data , con - siderations should occur on a case - by - case basis through dialog between researchers and IRBs . NOTES 1 . http : / / www . icq . com . 2 . http : / / www . icq . com / ircqnet . 3 . Note that all times are Eastern Standard Time . 4 . Due to technical problems with the software and the network respectively , no data were collected for Tuesday 4 March or Friday 14 March . 5 . This represents the number of unique usernames involved in our study . There is not necessarily a one - to - one mapping between individ - uals and user names . 6 . SinceourpersonalresearchexperiencehasoccurredintheUnited States , we focus on U . S . laws . The ﬁrst author ( Hudson ) is a member of Georgia Tech’s Institutional Review Board ( IRB ) . The second author THE ETHICS OF RESEARCHING CHATROOMS 139 ( Bruckman ) has served on a number of panels on the ethics of Internet research , including the American Psychological Association ( APA ) , the American Association for the Advancement of Science ( AAAS ) , and the Association for Internet Research ( AoIR ) . In focusing on U . S . law , we acknowledge that legal considerations are often not the same as ethical considerations . We also note that U . S . law differs substan - tially from other legal systems and that international requirements may vary . 7 . This issue comes up in nonelectronic research contexts . It’s de - batable how subjects would respond if we did this same study at the local coffee shop . The issues are complex and must be understood on a case - by - case basis . REFERENCES American Heritage Dictionary of the English Language . 2000 . 4th ed . Boston : Houghton Mifﬂin . Bassett , Elizabeth H . , and O’Riordan , Kate . 2002 . Ethics of Internet research : Contesting the human subjects research model . Ethics and Information Technology 4 ( 3 ) : 233 – 247 . Boehlefeld , Sharon Polancic . 1996 . Doing the right think : Ethical cy - berspace research . The Information Society 12 ( 2 ) : 141 – 152 . Bruckman , Amy . 2002 . Studying the amateur artist : A perspective on disguising data collected in human subjects research on the Internet . Ethics and Information Technology 4 ( 3 ) : 217 – 231 . Bull , Sheana , and McFarlane , Mary . 2000 . Soliciting sex on the Inter - net : What are the risks for sexually transmitted diseases and HIV ? Sexually Transmitted Diseases 27 ( 9 ) : 545 – 550 . Cavazos , Edward A . , and Morin , Gavino . 1994 . Cyberspace and the law : Your rights and duties in the on - line world . Cambridge , MA : MIT Press . Danet , Brenda . 2001a . Cyberpl @ y : Communicating online . New York : New York University Press . Danet , Brenda . 2001b . Studies of cyberpl @ y : Ethical and methodolog - ical aspects . Case study prepared for the Ethics Working Group , Association of Internet Researchers . (cid:6) http : / / atar . mscc . huji . ac . il / ∼ msdanet / papers / ethics2 . pdf (cid:5) Department of Health , Education , and Welfare . 1979 . The Belmont report : Ethical principles and guidelines for the protection of human subjects of research . Washington , DC : OPRR Reports . Elgesem , Dag . 2002 . What is special about the ethical issues in online research ? Ethics and Information Technology 4 ( 3 ) : 195 – 203 . Ess , Charles . 2002 . Ethical decision - making and Internet research : Recommendations from the AoIR Ethics Working Committee . As - sociation of Internet Researchers ( AoIR ) . (cid:6) http : / / aior . org / reports / ethics . pdf (cid:5) Eysenbach , Gunther , and Till , James E . 2001 . Ethical issues in qualita - tive research on Internet communities . British Medical Journal , 10 November : 1103 – 1105 . Frankel , Mark S . , and Siang , Sanyin . 1999 . Ethical and legal aspects of human subjects research on the Internet . American Association for the Advancement of Science ( AAAS ) . (cid:6) http : / / www . aaas . org / spp / sfri / projects / intres / report . pdf (cid:5) Headland , Thomas N . , Pike , Kenneth , and Marvin , Harris , eds . 1990 . Emics and etics : The insider / outsider debate . Newbury Park , CA : Sage Press . Herring , Susan . 1996 . Linguistic and critical analysis of computer - mediated communication : Some ethical and scholarly considera - tions . The Information Society 12 ( 2 ) : 153 – 168 . Herring , Susan C . 1999 . The rhetorical dynamics of gender harassment online . The Information Society 15 ( 3 ) : 151 – 167 . Hudson , James M . , and Bruckman , Amy . 2002 . IRC Fran¸cais : The creation of an Internet - based SLA community . Computer Assisted Language Learning 15 ( 2 ) : 109 – 134 . Kant , Immanuel . 1981 . Grounding for the metaphysics of morals , trans . J . W . Ellington . Indianapolis , IN : Hackett . King , Storm A . 1996 . Researching Internet communities : Proposed ethical guidelines for reporting of results . The Information Society 12 ( 2 ) : 119 – 127 . Kraut , Robert , Olson , Judith , Banaji , Mahzarin , Bruckman , Amy , Cohen , Jeffery , and Mick , Couper . 2004 . Psychological research on - line : Report of Board of Scientiﬁc affairs’ advisory group on the con - duct of research on the internet . American Psychologist 59 ( 4 ) : 1 – 13 . Latan´e , Bibb , and Darley , John M . 1970 . The unresponsive bystander : Why doesn’t he help ? , eds . K . MacCorquodale , G . Lindzey , and K . E . Clark . Century Psychology Series . New York : Appleton - Century - Crofts . Milgram , Stanley . 1974 . Obedience to authority : An experimental view . New York : Harper Perennial . Mill , John Stuart . 1998 . Utilitarianism . In J . S . Mill : Utilitarianism , ed . R . Crisp . New York : Oxford University Press . Nosek , Brian A . , Banaji , Mahzarin R . , and Greenwald , Anthony G . 2002 . E - Research : Ethics , security , design , and control in psycho - logical research on the Internet . Journal of Social Issues 58 ( 1 ) : 161 – 176 . Pedhazur , Elazar J . 1997 . Multiple regression in behavioral research : Explanation and prediction , 3rd ed . New York : Harcourt . Reid , Elizabeth . 1996 . Informed consent in the study of on - line com - munities : A reﬂection on the effects of computer - mediated social research . The Information Society 12 ( 2 ) : 169 – 174 . Rosaldo , Renato . 1989 . Culture and truth : The remaking of social anal - ysis . Boston : Beacon Press . Schrum , Lynne . 1997 . Ethical research in the information age : Begin - ning the dialog . Computers in Human Behavior 13 ( 2 ) : 117 – 125 . Walther , Joseph B . 2002 . Research ethics in internet - enabled research : Human subjects issues and methodological myopia . Ethics and In - formation Technology 4 ( 3 ) : 205 – 216 . Waskul , Dennis , and Douglass , Mark . 1996 . Considering the electronic participant : Some polemical observations on the ethics of on - line research . The Information Society 12 ( 2 ) : 129 – 139 .