{"CAPTION FIG1.png": "'Figure 1: New model architectures. The CBOW architecture predicts the current word based on the context, and the Skip-gram predicts surrounding words given the current word.\\n\\n'", "CAPTION TAB1.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}{c}{} \\\\\\\\ \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}\\n\\n'", "CAPTION TAB2.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{_Accuracy on subset of the Semantic-Syntactic Word Relationship test set, using word vectors from the CBOW architecture with limited vocabulary. Only questions containing words from the most frequent 30k words are used._} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 2: _Accuracy on subset of the Semantic-Syntactic Word Relationship test set, using word vectors from the CBOW architecture with limited vocabulary. Only questions containing words from the most frequent 30k words are used._'", "CAPTION TAB3.png": "'\\n\\n'", "CAPTION TAB4.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}{c}{} \\\\\\\\ \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}\\n\\n'", "CAPTION TAB5.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{_Comparison of models trained for three epochs on the same data and models trained for one epoch. Accuracy is reported on the full Semantic-Syntactic data set._} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 5: _Comparison of models trained for three epochs on the same data and models trained for one epoch. Accuracy is reported on the full Semantic-Syntactic data set._'", "CAPTION TAB6.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{_Comparison of models trained using the DistBelief distributed framework. Note that training of NNLM with 1000-dimensional vectors would take too long to complete._} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 6: _Comparison of models trained using the DistBelief distributed framework. Note that training of NNLM with 1000-dimensional vectors would take too long to complete._'", "CAPTION TAB7.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}{c}{} & \\\\multicolumn{'", "CAPTION TAB8.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{_Examples of the word pair relationships, using the best word vectors from Table \\\\(\\\\cline{2-3}\\\\hskip-4.0pt\\\\)_\\\\(\\\\sharp\\\\)_(_Skip-gram model trained on 783M words with 300 dimensionality_)._} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 8: _Examples of the word pair relationships, using the best word vectors from Table \\\\(\\\\cline{2-3}\\\\hskip-4.0pt\\\\)_\\\\(\\\\sharp\\\\)_(_Skip-gram model trained on 783M words with 300 dimensionality_)._'"}