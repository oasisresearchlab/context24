{"CAPTION FIG1.png": "'Figure 1: Excerpts from human evaluators\u201d explanations for why they believe a GPT3-generated story (also excerpted) was written by a human (left) or a machine (right). The evaluators point to a wide range of text attributes to make their decisions, sometimes using the same aspect of the text to come to opposite conclusions.\\n\\n'", "CAPTION FIG2.png": "'Figure 2: The task interface (story domain)\\n\\n'", "CAPTION FIG4.png": "'Figure 4: Histogram of scores classifying human and GPT3 texts.\\n\\n'", "CAPTION FIG7.png": "'Figure 7: The Example training (left) and Comparison training (right) in the story domain. The instructions are the same for both, except \u201cChoose the one you think was written by a machine.\u201d was in Comparison only.\\n\\n'", "CAPTION TAB1.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline  & \\\\\\\\ \\\\end{tabular}\\n\\\\end{table}\\nTable 1: \\\\(\\\\lx@sectionsign\\\\)2 results, broken down by domain and model, along with the \\\\(F_{1}\\\\), precision, and recall at identifying machine-generated text, Krippendorff\u2019s \\\\(\\\\alpha\\\\), \\\\(\\\\%\\\\) human-written guesses, and \\\\(\\\\%\\\\) confident guesses (i.e., _Definitely_ machine- or human-authored). * indicates the accuracies significantly better than random (two-sided \\\\(t\\\\)-test, for Bonferroni-corrected \\\\(p<0.00333\\\\)).\\n\\n'", "CAPTION TAB2.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l'", "CAPTION TAB3.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l} \\\\hline \\\\hline \\\\multicolumn{1}{c}{} & \\\\multicolumn{1}{c}{} & \\\\multicolumn{'", "CAPTION TAB4.png": "'\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l'", "CAPTION TAB5.png": "'\\n\\n## References\\n\\n* [1] A. A. K. K.\\n\\n'"}